[
  {
    "owner": "langflow-ai",
    "repo": "langflow",
    "content": "TITLE: Installing Optional Dependencies for Extended Functionality\nDESCRIPTION: Commands to install Langflow with optional dependency groups like 'postgresql' or multiple extras, allowing customization of features based on project needs.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install \"langflow[postgresql]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"langflow[postgresql]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install \"langflow[deploy,local,postgresql]\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"langflow[deploy,local,postgresql]\"\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable - Linux/macOS\nDESCRIPTION: This bash snippet shows how to set an environment variable in a Linux or macOS terminal. The command `export` sets a variable accessible to the current terminal session.  The variable is assigned a value using the `=` operator. It's a basic operation for configuring application behavior within a terminal environment. The output is the variable being set. There are no specific dependencies.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport VARIABLE_NAME='VALUE'\n```\n\n----------------------------------------\n\nTITLE: Verifying a Kubernetes Secret using kubectl (Shell)\nDESCRIPTION: Shows the `kubectl` command to retrieve and display information about a specific secret (`openai-credentials`) within the `langflow` namespace. The output will typically show the secret's data in an encrypted or base64-encoded format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get secrets -n langflow openai-credentials\n```\n\n----------------------------------------\n\nTITLE: Cloning and Running Langflow with Docker Compose - Bash\nDESCRIPTION: This sequence of bash commands demonstrates cloning the Langflow repository from GitHub, navigating to the Docker example directory, and starting the services defined in the Docker Compose file. Prerequisites include Docker and Docker Compose installed on your system. The user is expected to have network access for cloning and permission to run Docker commands. The containerized Langflow service will be available at http://localhost:7860. Limitations: Local ports must be available and the host user must have adequate permissions.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/langflow-ai/langflow.git\ncd langflow/docker_example\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Exporting LANGFLOW_URL Environment Variable for API Access\nDESCRIPTION: Sets the environment variable for the Langflow server URL, used as the base for subsequent API requests.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGFLOW_URL=\"http://127.0.0.1:7860\"\n```\n\n----------------------------------------\n\nTITLE: Modify Prompt Component with Variables\nDESCRIPTION: This snippet details the modification required for the Prompt component to include variables for user questions and retrieved context.  The `{context}` variable is added to provide the chatbot with extra information beyond the model's initial training.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-quickstart.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGiven the context\n{context}\nAnswer the question\n{user_question}\n```\n\n----------------------------------------\n\nTITLE: Run Langflow\nDESCRIPTION: This bash command starts the Langflow application.  It assumes that Langflow has been installed and is available in the current environment. The `uv run` command likely refers to a task runner or environment manager used to execute the Langflow application.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-opik.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv run langflow run\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Environment and Installing Dependencies Locally with uv\nDESCRIPTION: Demonstrates how to create a Python virtual environment using `uv venv`, activate it, and then install Langflow along with an additional package (matplotlib) using `uv pip install`. This method is recommended for local testing to isolate dependencies.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\n# Create and activate a virtual environment\nuv venv YOUR_LANGFLOW_VENV\nsource YOUR_LANGFLOW_VENV/bin/activate\n\n# Install langflow and your additional dependency\nuv pip install langflow matplotlib\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for Packaging a Langflow Application in Docker\nDESCRIPTION: This Dockerfile sets up a containerized environment for a Langflow application, copying flow files, components, configuration, and environment variables, along with defining necessary environment variables and the startup command for the server. It depends on the 'langflowai/langflow:latest' base image and customizable volume paths.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/develop-application.md#_snippet_1\n\nLANGUAGE: Dockerfile\nCODE:\n```\nFROM langflowai/langflow:latest\n\n# Create directories and set working directory\nRUN mkdir /app/flows\nRUN mkdir /app/langflow-config-dir\nWORKDIR /app\n\n# Copy application files into container\nCOPY flows /app/flows\nCOPY components /app/components\nCOPY langflow-config-dir /app/langflow-config-dir\nCOPY docker.env /app/.env\n\n# Set environment variables for resource paths\nENV PYTHONPATH=/app\nENV LANGFLOW_LOAD_FLOWS_PATH=/app/flows\nENV LANGFLOW_CONFIG_DIR=/app/langflow-config-dir\nENV LANGFLOW_COMPONENTS_PATH=/app/components\nENV LANGFLOW_LOG_ENV=container\n\n# Expose port for Langflow server\nEXPOSE 7860\n\n# Start Langflow server in container\nCMD [\"langflow\", \"run\", \"--backend-only\", \"--env-file\",\"/app/.env\",\"--host\", \"0.0.0.0\", \"--port\", \"7860\"]\n```\n\n----------------------------------------\n\nTITLE: Defining Environment Variables in .env File\nDESCRIPTION: This snippet demonstrates how to define environment variables in a `.env` file.  These variables are used to configure various aspects of Langflow, such as auto-login, database URL, and other settings. The `.env` file is placed in the project root directory.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nDO_NOT_TRACK=true\nLANGFLOW_AUTO_LOGIN=false\nLANGFLOW_AUTO_SAVING=true\nLANGFLOW_AUTO_SAVING_INTERVAL=1000\nLANGFLOW_BACKEND_ONLY=false\nLANGFLOW_BUNDLE_URLS=[\"https://github.com/user/repo/commit/hash\"]\nLANGFLOW_CACHE_TYPE=async\nLANGFLOW_COMPONENTS_PATH=/path/to/components/\nLANGFLOW_CONFIG_DIR=/path/to/config/\nLANGFLOW_DATABASE_URL=postgresql://user:password@localhost:5432/langflow\nLANGFLOW_DEV=false\nLANGFLOW_FALLBACK_TO_ENV_VAR=false\nLANGFLOW_HEALTH_CHECK_MAX_RETRIES=5\nLANGFLOW_HOST=127.0.0.1\nLANGFLOW_LANGCHAIN_CACHE=InMemoryCache\nLANGFLOW_MAX_FILE_SIZE_UPLOAD=10000\nLANGFLOW_LOG_LEVEL=error\nLANGFLOW_OPEN_BROWSER=false\nLANGFLOW_PORT=7860\nLANGFLOW_REMOVE_API_KEYS=false\nLANGFLOW_SAVE_DB_IN_CONFIG_DIR=true\nLANGFLOW_SECRET_KEY=somesecretkey\nLANGFLOW_STORE=true\nLANGFLOW_STORE_ENVIRONMENT_VARIABLES=true\nLANGFLOW_SUPERUSER=adminuser\nLANGFLOW_SUPERUSER_PASSWORD=adminpass\nLANGFLOW_WORKER_TIMEOUT=60000\nLANGFLOW_WORKERS=3\n```\n\n----------------------------------------\n\nTITLE: Sending POST Request to Webhook for Data to DataFrame Conversion\nDESCRIPTION: This curl command sends a POST request to a webhook endpoint with JSON data containing employee profile information. The data includes text and structured fields that will be converted to a DataFrame by the Data to DataFrame component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_0\n\nLANGUAGE: curl\nCODE:\n```\ncurl -X POST \"http://127.0.0.1:7860/api/v1/webhook/YOUR_FLOW_ID\" \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"text\": \"Alex Cruz - Employee Profile\",\n    \"data\": {\n        \"Name\": \"Alex Cruz\",\n        \"Role\": \"Developer\",\n        \"Department\": \"Engineering\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining a Contextual Prompt Template using Markdown - Text\nDESCRIPTION: This snippet provides a prompt template designed for use in Langflow's Prompt component. The prompt instructs the AI assistant to answer questions with helpfulness and to employ markdown formatting, specifically embedding images and URLs as needed. It introduces a {memory} variable, which acts as an input port in the Langflow component, allowing dynamic insertion of conversation history and enabling context-aware responses. The template expects previous chat messages to be passed in via the {memory} placeholder; output will be the formatted instruction for the language model to condition its response on dialog history. There are no explicit code dependencies, but the snippet assumes integration within a Langflow flow using the Prompt component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Sample-Flows/memory-chatbot.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nYou are a helpful assistant that answers questions.\n\nUse markdown to format your answer, properly embedding images and urls.\n\nHistory:\n\n{memory}\n```\n\n----------------------------------------\n\nTITLE: Defining LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT in .env File - Text\nDESCRIPTION: This snippet shows how to declare the LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT environment variable in a .env file for local Langflow setups. It supports both comma-separated value strings and JSON list notations. Place this entry in your project's .env file before starting Langflow; the specified variable names (e.g., VARIABLE1, VARIABLE2) must be defined as environment variables and will be sourced as credentials.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n# Option 1: Comma-separated string (no spaces)\nLANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT=VARIABLE1,VARIABLE2\n\n# Option 2: JSON list format\nLANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT=[\"VARIABLE1\", \"VARIABLE2\"]\n```\n\n----------------------------------------\n\nTITLE: Adding a Base Dependency to Langflow via Make\nDESCRIPTION: Demonstrates using the `make add` command to add a dependency (e.g., matplotlib) to the base Langflow package, which contains core functionality. This updates the `pyproject.toml` and `uv.lock` file within `src/backend/base`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\nmake add base=\"matplotlib\"\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response for Langflow Configuration Retrieval\nDESCRIPTION: JSON object showing configuration data with feature flags, frontend timeout settings, auto saving options, health check retry limits, and maximum file upload size limit. This data guides clients and frontend behavior.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_16\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"feature_flags\": {\n        \"mvp_components\": false\n    },\n    \"frontend_timeout\": 0,\n    \"auto_saving\": true,\n    \"auto_saving_interval\": 1000,\n    \"health_check_max_retries\": 5,\n    \"max_file_size_upload\": 100\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow Server\nDESCRIPTION: This command starts the Langflow server. It takes various options to configure the server's behavior, such as host, port, worker processes, logging, and development mode. It requires the necessary Langflow dependencies and database setup.  The output is the running server.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nlangflow run [OPTIONS]\n# or\npython -m langflow run [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Creating a Langflow Custom Component in Python\nDESCRIPTION: This Python code defines a custom Langflow component named `TextAnalyzerComponent`. It demonstrates how to use the `Input` and `Output` classes to define component interfaces. The component takes text input (as a `Message` or string), performs basic analysis (character/sentence count, optional word count, optional basic sentiment analysis), and outputs the results as a `Message` object. Key classes used include `Component`, `Input`, `Output`, and `Message` from the Langflow library.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-custom-components.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langflow.template import Input, Output\nfrom langflow.custom import Component\nfrom langflow.field_typing import Text\nfrom langflow.schema.message import Message\nfrom typing import Dict, Any\n\nclass TextAnalyzerComponent(Component):\n    display_name = \"Text Analyzer\"\n    description = \"Analyzes input text and provides basic statistics.\"\n\n    inputs = [\n        Input(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            field_type=\"Message\",\n            required=True,\n            placeholder=\"Enter text to analyze\",\n            multiline=True,\n            info=\"The text you want to analyze.\",\n            input_types=[\"Text\"]\n        ),\n        Input(\n            name=\"include_word_count\",\n            display_name=\"Include Word Count\",\n            field_type=\"bool\",\n            required=False,\n            info=\"Whether to include word count in the analysis.\",\n        ),\n        Input(\n            name=\"perform_sentiment_analysis\",\n            display_name=\"Perform Sentiment Analysis\",\n            field_type=\"bool\",\n            required=False,\n            info=\"Whether to perform basic sentiment analysis.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Analysis Results\", name=\"results\", method=\"analyze_text\"),\n    ]\n\n    def analyze_text(self) -> Message:\n        # Extract text from the Message object\n        if isinstance(self.input_text, Message):\n            text = self.input_text.text\n        else:\n            text = str(self.input_text)\n\n        results = {\n            \"character_count\": len(text),\n            \"sentence_count\": text.count('.') + text.count('!') + text.count('?')\n        }\n\n        if self.include_word_count:\n            results[\"word_count\"] = len(text.split())\n\n        if self.perform_sentiment_analysis:\n            # Basic sentiment analysis\n            text_lower = text.lower()\n            if \"happy\" in text_lower or \"good\" in text_lower:\n                sentiment = \"positive\"\n            elif \"sad\" in text_lower or \"bad\" in text_lower:\n                sentiment = \"negative\"\n            else:\n                sentiment = \"neutral\"\n\n            results[\"sentiment\"] = sentiment\n\n        # Convert the results dictionary to a formatted string\n        formatted_results = \"\\n\".join([f\"{key}: {value}\" for key, value in results.items()])\n\n        # Return a Message object\n        return Message(text=formatted_results)\n\n# Define how to use the inputs and outputs\ncomponent = TextAnalyzerComponent()\n```\n\n----------------------------------------\n\nTITLE: Creating API Key\nDESCRIPTION: This command creates an API key for the default superuser.  It checks the `LANGFLOW_AUTO_LOGIN` environment variable.  There are no explicit inputs for this command, and its output is the creation of the API key.  No special limitations are given.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nlangflow api-key [OPTIONS]\n# or\npython -m langflow api-key [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Component with Multiple Input Types (Python)\nDESCRIPTION: This example demonstrates a more advanced custom component using various input types provided by Langflow's `langflow.inputs` module, such as `StrInput`, `SecretStrInput`, `MessageTextInput`, `IntInput`, and `DropdownInput`. The component processes these diverse inputs within the `process_inputs` method, formats them into a string, and returns the result as a `Message` object, showcasing how to handle different data types. Dependencies include `langflow.custom`, `langflow.inputs`, `langflow.template`, and `langflow.schema.message`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-custom-components.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom langflow.custom import Component\nfrom langflow.inputs import StrInput, MultilineInput, SecretStrInput, IntInput, DropdownInput\nfrom langflow.template import Output, Input\nfrom langflow.schema.message import Message\n\nclass MyCustomComponent(Component):\n    display_name = \"My Custom Component\"\n    description = \"An example of a custom component with various input types.\"\n\n    inputs = [\n        StrInput(\n            name=\"username\",\n            display_name=\"Username\",\n            info=\"Enter your username.\"\n        ),\n        SecretStrInput(\n            name=\"password\",\n            display_name=\"Password\",\n            info=\"Enter your password.\"\n        ),\n        MessageTextInput(\n            name=\"special_message\",\n            display_name=\"special_message\",\n            info=\"Enter a special message.\",\n        ),\n        IntInput(\n            name=\"age\",\n            display_name=\"Age\",\n            info=\"Enter your age.\"\n        ),\n        DropdownInput(\n            name=\"gender\",\n            display_name=\"Gender\",\n            options=[\"Male\", \"Female\", \"Other\"],\n            info=\"Select your gender.\"\n        )\n    ]\n\n    outputs = [\n        Output(display_name=\"Result\", name=\"result\", method=\"process_inputs\"),\n    ]\n\n    def process_inputs(self) -> Message:\n        \"\"\"\n        Process the user inputs and return a Message object.\n\n        Returns:\n            Message: A Message object containing the processed information.\n        \"\"\"\n        try:\n            processed_text = f\"User {self.username} (Age: {self.age}, Gender: {self.gender}) \" \\\n                             f\"sent the following special message: {self.special_message}\"\n            return Message(text=processed_text)\n        except AttributeError as e:\n            return Message(text=f\"Error processing inputs: {str(e)}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow Build Endpoint with stop_component_id to Limit Execution Using Bash\nDESCRIPTION: This cURL POST request example illustrates configuring the build endpoint to stop execution at a specific component by setting the stop_component_id parameter. The request sends a JSON body indicating which component's execution should halt. This mimics the behavior of manually stopping the flow at the given node.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/build/$FLOW_ID/flow\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n  -d '{\"stop_component_id\": \"OpenAIModel-Uksag\"}'\n```\n\n----------------------------------------\n\nTITLE: Triggering Webhook Flow with Langflow Webhook Endpoint in Bash\nDESCRIPTION: Shows how to trigger a flow execution by POSTing to the /webhook endpoint using cURL in Bash. Requires Content-Type header set to application/json and a JSON body with arbitrary data payload to send. The example illustrates how to invoke a webhook component by its flow ID. This endpoint initiates a background task and returns an immediate response indicating task start status.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/webhook/$FLOW_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"data\": \"example-data\"}'\n```\n\n----------------------------------------\n\nTITLE: Tool Mode for MessageTextInput\nDESCRIPTION: This Python code snippet demonstrates how to enable Tool Mode for a `MessageTextInput` input within a custom Langflow component. This allows the component to be used as a tool by agents.  The `tool_mode=True` parameter in the `MessageTextInput` constructor enables this mode. The component takes a text input and makes it available to an agent via a \"toolset\" output if tool mode is enabled. The dependency is the `langflow` library.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Agents/agent-tool-calling-agent-component.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n```python\ninputs = [\n    MessageTextInput(\n        name=\"input_text\",\n        display_name=\"Input Text\",\n        info=\"Enter text to analyze\",\n        value=\"Hello, World!\",\n        tool_mode=True,\n    ),\n]\n```\n```\n\n----------------------------------------\n\nTITLE: Python API Client for LangFlow Interaction\nDESCRIPTION: This Python class provides methods to interact with the LangFlow API, including sending requests, handling authentication, and parsing responses. It requires the requests library and manages endpoints for workflows and models, enabling programmatic control over AI flow execution.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/src/backend/base/README.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport requests\n\nclass LangFlowAPI:\n    def __init__(self, api_key, base_url='https://api.langflow.com'):\n        self.api_key = api_key\n        self.base_url = base_url\n        self.headers = {'Authorization': f'Bearer {self.api_key}'}\n\n    def get_workflow(self, workflow_id):\n        url = f\"{self.base_url}/workflows/{workflow_id}\"\n        response = requests.get(url, headers=self.headers)\n        if response.status_code == 200:\n            return response.json()\n        else:\n            response.raise_for_status()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Project Directory Structure in Markdown\nDESCRIPTION: This snippet illustrates the recommended folder layout for a Langflow application, including locations for flows, configuration, environment variables, and Dockerfile, to facilitate organized flow management and deployment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/develop-application.md#_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\nLANGFLOW-APPLICATION/\n├── flows/\n│   ├── flow1.json\n│   └── flow2.json\n├── langflow-config-dir/\n├── docker.env\n├── Dockerfile\n├── README.md\n```\n\n----------------------------------------\n\nTITLE: Cloning and Bootstrapping AWS Cloud9 Environment - Shell\nDESCRIPTION: This shell snippet clones the bootstrap repository for AWS Cloud9 prototyping, adjusts parameters in a JSON configuration using jq, and runs a bootstrap script. It requires git, jq, and execute permissions for bootstrap scripts within AWS CloudShell. The primary input is the params.json file, and the overall effect is to create a prepared Cloud9 environment for later steps. Outputs include a configured AWS Cloud9 environment named 'c9-for-langflow'.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/aws/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/aws-samples/cloud9-setup-for-prototyping\ncd cloud9-setup-for-prototyping\ncat params.json | jq '.name |= \"c9-for-langflow\"'\n./bin/bootstrap\n```\n\n----------------------------------------\n\nTITLE: Creating a Single Flow in Langflow via REST API using Bash\nDESCRIPTION: Creates a new flow by sending a POST request with a JSON payload containing flow metadata and configuration to the /api/v1/flows/ endpoint. Requires specifying flow attributes like name, description, icon, colors, data, tags, and flags such as is_component and webhook. The response returns the created flow object including unique IDs and timestamps.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_51\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/flows/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"name\": \"string2\",\n  \"description\": \"string\",\n  \"icon\": \"string\",\n  \"icon_bg_color\": \"#FF0000\",\n  \"gradient\": \"string\",\n  \"data\": {},\n  \"is_component\": false,\n  \"updated_at\": \"2024-12-30T15:48:01.519Z\",\n  \"webhook\": false,\n  \"endpoint_name\": \"string\",\n  \"tags\": [\n    \"string\"\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow Backend Development Server with Make in Bash\nDESCRIPTION: This snippet demonstrates how to start the Langflow backend development server using the `make backend` command. It installs necessary backend dependencies and runs the backend with hot-reloading for development. Dependencies: Python environment and backend prerequisites installed. Input: None. Output: Running backend server ready for development.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-how-to-contribute.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmake backend\n```\n\n----------------------------------------\n\nTITLE: Uploading File using cURL (v2)\nDESCRIPTION: Uploads a file to the authenticated user's account using the v2 API. Files uploaded via v2 are user-scoped and can be used across multiple flows. Requires authentication via API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_37\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v2/files\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n  -F \"file=@FILE_NAME.EXTENSION\"\n```\n\n----------------------------------------\n\nTITLE: Docker Compose for Multiple Langflow Instances with Shared PostgreSQL (YAML)\nDESCRIPTION: Defines a Docker Compose configuration for running two Langflow instances (`langflow-1`, `langflow-2`) connected to a single shared PostgreSQL database (`postgres`). It utilizes environment variables defined in a separate `.env` file (referenced using `${VARIABLE_NAME}` syntax) for centralized management of database credentials, ports, and paths. Each Langflow service exposes a different host port (`LANGFLOW_PORT_1`, `LANGFLOW_PORT_2`) but maps to the same container port (7860), and uses a separate named volume (`langflow-data-1`, `langflow-data-2`) for its persistent data.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  postgres:\n    image: postgres:16\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER}\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n      - POSTGRES_DB=${POSTGRES_DB}\n    ports:\n      - \"${POSTGRES_PORT}:5432\"\n    volumes:\n      - langflow-postgres:/var/lib/postgresql/data\n\n  langflow-1:\n    image: langflowai/langflow:latest\n    pull_policy: always\n    ports:\n      - \"${LANGFLOW_PORT_1}:7860\"\n    depends_on:\n      - postgres\n    environment:\n      - LANGFLOW_DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}\n      - LANGFLOW_CONFIG_DIR=${LANGFLOW_CONFIG_DIR}\n      - LANGFLOW_HOST=${LANGFLOW_HOST}\n      - PORT=7860\n    volumes:\n      - langflow-data-1:/app/langflow\n\n  langflow-2:\n    image: langflowai/langflow:latest\n    pull_policy: always\n    ports:\n      - \"${LANGFLOW_PORT_2}:7860\"\n    depends_on:\n      - postgres\n    environment:\n      - LANGFLOW_DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}\n      - LANGFLOW_CONFIG_DIR=${LANGFLOW_CONFIG_DIR}\n      - LANGFLOW_HOST=${LANGFLOW_HOST}\n      - PORT=7860\n    volumes:\n      - langflow-data-2:/app/langflow\n\nvolumes:\n  langflow-postgres:\n  langflow-data-1:\n  langflow-data-2:\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow IDE with Helm\nDESCRIPTION: Command to install the Langflow IDE using Helm in the langflow namespace. This creates a complete Langflow development environment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhelm install langflow-ide langflow/langflow-ide -n langflow --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Passing Environment Variables to Docker Using .env File - Bash\nDESCRIPTION: This example illustrates how to start a Langflow Docker container while sourcing environment variables and configurable global variables from a .env file. The LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT setting is read from the .env file, while actual secret values can be provided either in the .env or via -e parameters. All listed variables will be imported as credential-type global variables in Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm \\\n    -p 7860:7860 \\\n    --env-file .env \\\n    -e VARIABLE1=\"VALUE1\" \\\n    -e VARIABLE2=\"VALUE2\" \\\n    langflowai/langflow:latest\n```\n\n----------------------------------------\n\nTITLE: Successful Image Upload Response (v2 - JSON)\nDESCRIPTION: Example JSON response after successfully uploading an image using the v2 /files endpoint. Returns metadata including the file `id`, `name`, user-scoped `path`, `size`, and `provider`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_40\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"5f829bc4-ac1e-4a80-b1d1-fedc03cd5b6e\",\n  \"name\": \"FILE_NAME\",\n  \"path\": \"232f54ba-dd54-4760-977e-ed637f83e785/5f829bc4-ac1e-4a80-b1d1-fedc03cd5b6e.png\",\n  \"size\": 84408,\n  \"provider\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Successful File Upload Response (v2 - JSON)\nDESCRIPTION: Example JSON response after successfully uploading a file using the v2 /files endpoint. Provides detailed metadata including the unique file `id`, `name`, user-scoped `path`, `size`, and `provider`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_38\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"c7b22c4c-d5e0-4ec9-af97-5d85b7657a34\",\n  \"name\": \"FILE_NAME.EXTENSION\",\n  \"path\": \"6f17a73e-97d7-4519-a8d9-8e4c0be411bb/c7b22c4c-d5e0-4ec9-af97-5d85b7657a34.txt\",\n  \"size\": 1234,\n  \"provider\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Example .env configuration for secure Langflow server\nDESCRIPTION: This code block shows an example `.env` file configuration for setting up a secure Langflow server. It disables automatic login, specifies superuser credentials, sets the secret key for encryption, and disables automatic activation of new users. Replace `your_generated_key` with the actual generated key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_AUTO_LOGIN=False\nLANGFLOW_SUPERUSER=administrator\nLANGFLOW_SUPERUSER_PASSWORD=securepassword\nLANGFLOW_SECRET_KEY=your_generated_key\nLANGFLOW_NEW_USER_IS_ACTIVE=False\n```\n\n----------------------------------------\n\nTITLE: Retrieving Logs with Optional Parameters from Langflow API using curl - Bash\nDESCRIPTION: Retrieve previous and subsequent log lines by specifying query parameters via curl to the Langflow logs endpoint. Options include lines_before, lines_after, and timestamp; all defaulting to 0 to fetch the last 10 log lines. The endpoint responds with a JSON object mapping timestamps to log strings; output is application/json.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_78\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/logs?lines_before=0&lines_after=0&timestamp=0\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Setting LANGFLOW_SECRET_KEY for Encryption\nDESCRIPTION: This snippet displays how to set the `LANGFLOW_SECRET_KEY` environment variable. This key is used to encrypt sensitive data, such as API keys, using the Fernet library. A strong, randomly generated secret key is crucial for protecting sensitive information.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_SECRET_KEY=dBuuuB_FHLvU8T9eUNlxQF9ppqRxwWpXXQ42kM2_fb\n```\n\n----------------------------------------\n\nTITLE: DataFrame Operations for Data Manipulation\nDESCRIPTION: Provides a set of operations to manipulate pandas DataFrames, such as adding, removing, filtering, sorting columns, and retrieving head or tail rows. These operations facilitate easy data transformation tasks within Python data workflows.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n### Operations\n\nThis component can perform the following operations on Pandas [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n\n| Operation | Description | Required Inputs |\n|-----------|-------------|-----------------|\n| Add Column | Adds a new column with a constant value | new_column_name, new_column_value |\n| Drop Column | Removes a specified column | column_name |\n| Filter | Filters rows based on column value | column_name, filter_value |\n| Head | Returns first n rows | num_rows |\n| Rename Column | Renames an existing column | column_name, new_column_name |\n| Replace Value | Replaces values in a column | column_name, replace_value, replacement_value |\n| Select Columns | Selects specific columns | columns_to_select |\n| Sort | Sorts DataFrame by column | column_name, ascending |\n| Tail | Returns last n rows | num_rows |\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| df | DataFrame | The input DataFrame to operate on. |\n| operation | Operation | Select the DataFrame operation to perform. Options: Add Column, Drop Column, Filter, Head, Rename Column, Replace Value, Select Columns, Sort, Tail |\n| column_name | Column Name | The column name to use for the operation. |\n| filter_value | Filter Value | The value to filter rows by. |\n| ascending | Sort Ascending | Whether to sort in ascending order. |\n| new_column_name | New Column Name | The new column name when renaming or adding a column. |\n| new_column_value | New Column Value | The value to populate the new column with. |\n| columns_to_select | Columns to Select | List of column names to select. |\n| num_rows | Number of Rows | Number of rows to return (for head/tail). Default: 5 |\n| replace_value | Value to Replace | The value to replace in the column. |\n| replacement_value | Replacement Value | The value to replace with. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| output | DataFrame | The resulting DataFrame after the operation. |\n```\n\n----------------------------------------\n\nTITLE: Job ID Response After Submitting Custom Build Request\nDESCRIPTION: Example JSON response containing the job_id generated after submitting a build request with custom data and inputs to the /build endpoint. This ID is required to track and stream the flow execution events.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_24\n\nLANGUAGE: json\nCODE:\n```\n{\"job_id\":\"0bcc7f23-40b4-4bfa-9b8a-a44181fd1175\"}\n```\n\n----------------------------------------\n\nTITLE: Initializing Langflow Development Environment with Make in Bash\nDESCRIPTION: This snippet runs the `make init` command to initialize the Langflow development environment. It installs backend and frontend dependencies, builds frontend static files, and starts the application with `uv run langflow run`. Dependencies include having Make installed and a compatible environment for running backend and frontend builds. Input: None. Output: Configured and running Langflow development environment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-how-to-contribute.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake init\n```\n\n----------------------------------------\n\nTITLE: Streaming Flow Response with token events\nDESCRIPTION: Initiates a flow execution with streaming enabled by appending '?stream=true' to the URL, receiving token chunks progressively until completion indicated by an 'end' event.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/run/$FLOW_ID?stream=true\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"Tell me something interesting!\",\n    \"session_id\": \"chat-123\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image with Tag in Bash\nDESCRIPTION: This Bash command builds a Docker image from the current directory, tagging it as 'langflow-pokedex:1.2.0', ready for deployment or testing. It assumes a properly configured Dockerfile in the current directory.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/develop-application.md#_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\ndocker build -t langflow-pokedex:1.2.0 .\n```\n\n----------------------------------------\n\nTITLE: Downloading Multiple Flows as ZIP Using Langflow API via Bash\nDESCRIPTION: Sends a POST request with a JSON array of flow IDs to the /flows/download/ endpoint, which streams a ZIP file containing the specified flow data. The --output option saves the ZIP file locally. The Accept header is set for JSON though the response is binary data representing a zipped archive.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_59\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/flows/download/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '[\n  \"e1e40c77-0541-41a9-88ab-ddb3419398b5\",\n  \"92f9a4c5-cfc8-4656-ae63-1f0881163c28\"\n]' \\\n  --output langflow-flows.zip\n```\n\n----------------------------------------\n\nTITLE: Deleting Specific Langflow Messages using cURL (Bash)\nDESCRIPTION: Sends a DELETE request to the Langflow API endpoint '/api/v1/monitor/messages' to delete specific messages identified by their IDs. Requires LANGFLOW_URL and a JSON array containing the message IDs (e.g., 'MESSAGE_ID_1', 'MESSAGE_ID_2') in the request body. Expects a '204 No Content' response on success.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_85\n\nLANGUAGE: bash\nCODE:\n```\ncurl -v -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages\" \\\n  -H \"accept: */*\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '[\"MESSAGE_ID_1\", \"MESSAGE_ID_2\"]'\n```\n\n----------------------------------------\n\nTITLE: Downloading File by Flow ID and Name using cURL (v1)\nDESCRIPTION: Downloads a specific file from a Langflow flow using its flow ID and file name via the v1 API. The `--output` flag saves the file content to a local file.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_33\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/files/download/$FLOW_ID/2024-12-30_15-19-43_your_file.txt\" \\\n  -H \"accept: application/json\" \\\n  --output downloaded_file.txt\n```\n\n----------------------------------------\n\nTITLE: Reading Folder Information with Langflow API using curl - Bash\nDESCRIPTION: Retrieve information for a specific folder by sending a GET request to the Langflow API using curl. Requires the folder's UUID, which can be found using the /folders endpoint. The API returns folder metadata in JSON format, including name, description, id, and parent_id. No authentication header is shown, but endpoints may require authentication depending on server configuration.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_64\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/folders/$FOLDER_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Building and Running a Custom Langflow Image Locally - Bash\nDESCRIPTION: This bash code demonstrates building a Docker image named 'myuser/langflow-hello-world:1.0.0' with docker build, then running it with docker run exposing port 7860. Assumes Dockerfile and required files exist in current directory. Must replace 'myuser' with actual Docker Hub username for later pushes. Input: valid Dockerfile and any copied files; output: new image and a running container.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t myuser/langflow-hello-world:1.0.0 .\ndocker run -p 7860:7860 myuser/langflow-hello-world:1.0.0\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Flows in Batch via Langflow API Using Bash\nDESCRIPTION: Allows creation of multiple flows in a single POST request to the /flows/batch/ endpoint. The request JSON contains an array of flow objects with details such as name, description, icons, timestamps, locking states, user and folder assignments. Returns an array of created flow objects.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_57\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/flows/batch/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"flows\": [\n    {\n      \"name\": \"string\",\n      \"description\": \"string\",\n      \"icon\": \"string\",\n      \"icon_bg_color\": \"string\",\n      \"gradient\": \"string\",\n      \"data\": {},\n      \"is_component\": false,\n      \"updated_at\": \"2024-12-30T18:36:02.737Z\",\n      \"webhook\": false,\n      \"endpoint_name\": \"string\",\n      \"tags\": [\n        \"string\"\n      ],\n      \"locked\": false,\n      \"user_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\",\n      \"folder_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n    },\n    {\n      \"name\": \"string\",\n      \"description\": \"string\",\n      \"icon\": \"string\",\n      \"icon_bg_color\": \"string\",\n      \"gradient\": \"string\",\n      \"data\": {},\n      \"is_component\": false,\n      \"updated_at\": \"2024-12-30T18:36:02.737Z\",\n      \"webhook\": false,\n      \"endpoint_name\": \"string\",\n      \"tags\": [\n        \"string\"\n      ],\n      \"locked\": false,\n      \"user_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\",\n      \"folder_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with .env - Docker\nDESCRIPTION: This docker command runs a Langflow Docker container and loads environment variables from a `.env` file. The `--env-file` option tells docker to load environment variables from the specified file. The `-p` maps ports. `--rm` removes the container after it exits. Requires Docker to be installed, and a .env file to exist in the appropriate location.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm \\\n        -p 7860:7860 \\\n        --env-file .env \\\n        langflowai/langflow:latest\n```\n\n----------------------------------------\n\nTITLE: Cloning Langflow, Preparing Environment, and Deploying with CDK - Shell\nDESCRIPTION: This shell snippet clones the Langflow repository, enters the AWS deployment scripts directory, copies and modifies the environment variable example file as needed, installs npm dependencies, bootstraps AWS CDK, and performs a CDK deployment. It expects a configured AWS environment and npm installed. Key parameters include the .env file for environment variables, with outputs being a live deployment of Langflow accessible via an URL provided by CDK. Limitations include dependency on the correct AWS IAM permissions and valid environment variables.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/aws/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/langflow-ai/langflow.git\ncd langflow/scripts/aws\ncp .env.example .env # Edit this file if you need environment settings\nnpm ci\ncdk bootstrap\ncdk deploy\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response for Langflow Task Status Retrieval\nDESCRIPTION: Example JSON structure returned from the /task endpoint showing the current status of the given task and the result if completed. The 'status' key describes the execution state; 'result' contains any output data.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_12\n\nLANGUAGE: text\nCODE:\n```\n{\n  \"status\": \"Task status\",\n  \"result\": \"Task result if completed\"\n}\n```\n\n----------------------------------------\n\nTITLE: Example .env file content\nDESCRIPTION: This text block provides a sample .env file configuration for Langflow. The file contains key-value pairs, with each line defining an environment variable and its corresponding value.  These variables configure various aspects of the Langflow application. The file does not have dependencies.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nDO_NOT_TRACK=true\nLANGFLOW_AUTO_LOGIN=false\nLANGFLOW_AUTO_SAVING=true\nLANGFLOW_AUTO_SAVING_INTERVAL=1000\nLANGFLOW_BACKEND_ONLY=false\nLANGFLOW_BUNDLE_URLS=[\"https://github.com/user/repo/commit/hash\"]\nLANGFLOW_CACHE_TYPE=async\nLANGFLOW_COMPONENTS_PATH=/path/to/components/\nLANGFLOW_CONFIG_DIR=/path/to/config/\nLANGFLOW_DATABASE_URL=postgresql://user:password@localhost:5432/langflow\nLANGFLOW_DEV=false\nLANGFLOW_FALLBACK_TO_ENV_VAR=false\nLANGFLOW_HEALTH_CHECK_MAX_RETRIES=5\nLANGFLOW_HOST=127.0.0.1\nLANGFLOW_LANGCHAIN_CACHE=InMemoryCache\nLANGFLOW_MAX_FILE_SIZE_UPLOAD=10000\nLANGFLOW_LOG_LEVEL=error\nLANGFLOW_OPEN_BROWSER=false\nLANGFLOW_PORT=7860\nLANGFLOW_REMOVE_API_KEYS=false\nLANGFLOW_SAVE_DB_IN_CONFIG_DIR=true\nLANGFLOW_SECRET_KEY=somesecretkey\nLANGFLOW_STORE=true\nLANGFLOW_STORE_ENVIRONMENT_VARIABLES=true\nLANGFLOW_SUPERUSER=adminuser\nLANGFLOW_SUPERUSER_PASSWORD=adminpass\nLANGFLOW_WORKER_TIMEOUT=60000\nLANGFLOW_WORKERS=3\n```\n\n----------------------------------------\n\nTITLE: Passing Environment Variables with Docker Run Command - Bash\nDESCRIPTION: This snippet provides a docker run command to start Langflow in a container with specified environment credentials. It demonstrates passing both LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT and the actual variable values directly via -e flags, enabling these as global credentials inside the container. Required variables (VARIABLE1, VARIABLE2) will be available to Langflow, which must be configured to recognize them via the LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT variable.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm \\\n    -p 7860:7860 \\\n    -e LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT=\"VARIABLE1,VARIABLE2\" \\\n    -e VARIABLE1=\"VALUE1\" \\\n    -e VARIABLE2=\"VALUE2\" \\\n    langflowai/langflow:latest\n```\n\n----------------------------------------\n\nTITLE: Sending JSON Data to Langflow Webhook via Curl (Shell)\nDESCRIPTION: A shell command using `curl` to send a POST request with JSON data (employee information) to a Langflow webhook endpoint. This demonstrates triggering a flow containing a Webhook component, often used in conjunction with the 'Save to File' component. Requires replacing `YOUR_FLOW_ID` with the actual flow ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST \"http://127.0.0.1:7860/api/v1/webhook/YOUR_FLOW_ID\" \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"Name\": [\"Alex Cruz\", \"Kalani Smith\", \"Noam Johnson\"],\n    \"Role\": [\"Developer\", \"Designer\", \"Manager\"],\n    \"Department\": [\"Engineering\", \"Design\", \"Management\"]\n}'\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with .env configuration\nDESCRIPTION: This command shows how to start the Langflow server using the `uv` runner while specifying the `.env` file for configuration. This ensures that the environment variables defined in the `.env` file are loaded and used by Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nuv run langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow Logging via Environment Variables\nDESCRIPTION: This code snippet illustrates how to customize Langflow's logging configuration by defining specific environment variables within a `.env` file. It shows examples for setting the minimum log level, specifying a custom path for the log file, and selecting the log output environment/format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/logging.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_LOG_LEVEL=ERROR\nLANGFLOW_LOG_FILE=path/to/logfile.log\nLANGFLOW_LOG_ENV=container\n```\n\n----------------------------------------\n\nTITLE: Setting LANGFLOW_SUPERUSER and LANGFLOW_SUPERUSER_PASSWORD\nDESCRIPTION: This snippet shows how to define the username and password for the Langflow superuser account. These credentials are used for administrative tasks when `LANGFLOW_AUTO_LOGIN` is set to `False`. Strong and unique credentials should be used for the superuser account.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_SUPERUSER=administrator\nLANGFLOW_SUPERUSER_PASSWORD=securepassword\n```\n\n----------------------------------------\n\nTITLE: Deleting a Flow by ID via Langflow API Using Bash\nDESCRIPTION: Executes a DELETE request targeting a specific flow by its FLOW_ID to remove it from the system. Requires Authorization via headers. Successful deletion returns a JSON message confirmation.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_56\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/flows/$FLOW_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Task Status via Langflow /task Endpoint using Bash\nDESCRIPTION: cURL example that sends a GET request to query the status of a background task using its TASK_ID. The accept header requests JSON response format. The endpoint returns JSON containing task status and result if available. Useful for polling asynchronous flow execution outcomes.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/task/TASK_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Adding Git Remote for Forked Langflow Repository in Bash\nDESCRIPTION: This snippet shows how to add a new Git remote named \"fork\" pointing to your fork of the Langflow repository. It is used after forking the repository on GitHub to keep your local repository connected to your fork for pushing changes. Dependency: Git installed and repository cloned locally. Input: Replace <your_git_username> with your GitHub username. Output: Adds a Git remote named \"fork\".\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-how-to-contribute.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit remote add fork https://github.com/<your_git_username>/langflow.git\n```\n\n----------------------------------------\n\nTITLE: Creating a New Folder in Langflow via REST API Using Bash\nDESCRIPTION: Creates a new organizational folder by sending a POST request with a JSON body specifying folder name, description, and optionally lists of component and flow IDs to associate upon creation. The response includes the new folder's metadata including assigned ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_62\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/folders/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"name\": \"new_folder_name\",\n  \"description\": \"string\",\n  \"components_list\": [],\n  \"flows_list\": []\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Custom Component Structure (Python)\nDESCRIPTION: This snippet provides the template code for a basic custom component in Langflow. It demonstrates inheriting from `langflow.custom.Component`, setting display metadata, defining a single input using `MessageTextInput`, a single output using `Output`, and implementing the `build_output` method to process the input and return a `Data` object. Required dependencies include `langflow.custom`, `langflow.io`, and `langflow.schema`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-custom-components.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"custom_components\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(name=\"input_value\", display_name=\"Input Value\", value=\"Hello, World!\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n```\n\n----------------------------------------\n\nTITLE: Successful File Upload Response (v1 - JSON)\nDESCRIPTION: Example JSON response received after successfully uploading a file using the v1 /files/upload endpoint. It includes the `flowId` and the generated `file_path` where the file is stored, relative to the flow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_26\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"flowId\": \"92f9a4c5-cfc8-4656-ae63-1f0881163c28\",\n  \"file_path\": \"92f9a4c5-cfc8-4656-ae63-1f0881163c28/2024-12-30_15-19-43_your_file.txt\"\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow with Custom .env Configuration - Text Example\nDESCRIPTION: Launch Langflow with environment variables specified in a .env file using an 'uv run' command. Ensures that the log-related environment variables are loaded at startup. Requires 'uv' and correct path to Langflow CLI script.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_75\n\nLANGUAGE: text\nCODE:\n```\nuv run langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Sending Uploaded Image to Flow (v1 - cURL)\nDESCRIPTION: Demonstrates how to use a previously uploaded image file (using the v1 upload endpoint) as input to a Langflow flow execution via the v1 /run endpoint. The file path is passed within the `tweaks` section targeting a specific component (e.g., 'Chat Input').\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n    \"$LANGFLOW_URL/api/v1/run/a430cc57-06bb-4c11-be39-d3d4de68d2c4?stream=false\" \\\n    -H 'Content-Type: application/json'\\\n    -d '{\n    \"output_type\": \"chat\",\n    \"input_type\": \"chat\",\n    \"tweaks\": {\n  \"ChatInput-b67sL\": {\n    \"files\": \"a430cc57-06bb-4c11-be39-d3d4de68d2c4/2024-11-27_14-47-50_image-file.png\",\n    \"input_value\": \"what do you see?\"\n  }\n}}'\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with Custom Environment Variables (Bash)\nDESCRIPTION: Starts the Langflow application using the `uv run` command, specifically tailored for Langflow execution. The `--env-file .env` flag instructs the application to load environment variables from the specified `.env` file, enabling the use of custom configurations like the PostgreSQL database URL.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv run langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Updating Folder Metadata with Langflow API using curl - Bash\nDESCRIPTION: Update an existing folder by sending a PATCH request with updated fields in JSON format to the Langflow API using curl. Only the provided fields are modified, and repeated identical values will still trigger an update operation. Dependencies include API endpoint access and curl; ensure proper Content-Type headers. Key parameters include name, description, parent_id, components, and flows.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_66\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \\\n  \"$LANGFLOW_URL/api/v1/folders/b408ddb9-6266-4431-9be8-e04a62758331\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"name\": \"string\",\n  \"description\": \"string\",\n  \"parent_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\",\n  \"components\": [\n    \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n  ],\n  \"flows\": [\n    \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow with uv or pip\nDESCRIPTION: Commands to install Langflow OSS via uv or pip package managers. The commands include installing the package, upgrading, installing specific versions, and reinstalling with force flag. Dependencies like optional extras can be specified for extended functionality.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install langflow\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install langflow\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Langflow Component with Multiple Outputs in Python\nDESCRIPTION: This Python code demonstrates how to create a custom Langflow component class, 'DualOutputComponent', with two distinct outputs. The component defines input fields, registers multiple outputs—each associated with its own method—and provides implementation for both output-producing methods: one that processes and returns modified text (e.g., uppercase transformation), and another that returns the processing function itself for extended composition. Dependencies include the langflow.custom, langflow.inputs, langflow.template, and langflow.field_typing modules, and key parameters involve the input text and callable outputs. Outputs are type-annotated to ensure clarity and type safety. Inputs are expected as plain text, and outputs are either processed string data or a callable function. Usage requires Langflow and proper registration of the custom component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-custom-components.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom typing import Callable\nfrom langflow.custom import Component\nfrom langflow.inputs import StrInput\nfrom langflow.template import Output\nfrom langflow.field_typing import Text\n\nclass DualOutputComponent(Component):\n    display_name = \"Dual Output\"\n    description = \"Processes input text and returns both the result and the processing function.\"\n    icon = \"double-arrow\"\n\n    inputs = [\n        StrInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"The text input to be processed.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Processed Data\", name=\"processed_data\", method=\"process_data\"),\n        Output(display_name=\"Processing Function\", name=\"processing_function\", method=\"get_processing_function\"),\n    ]\n\n    def process_data(self) -> Text:\n        # Process the input text (e.g., convert to uppercase)\n        processed = self.input_text.upper()\n        self.status = processed\n        return processed\n\n    def get_processing_function(self) -> Callable[[], Text]:\n        # Return the processing function itself\n        return self.process_data\n```\n\n----------------------------------------\n\nTITLE: Executing a Flow with POST Request\nDESCRIPTION: Runs a specific flow by sending a JSON payload with input parameters such as input_value and session_id, utilizing POST method. The response contains the flow output and conversation context.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/run/$FLOW_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"input_value\": \"Tell me about something interesting!\",\n    \"session_id\": \"chat-123\",\n    \"input_type\": \"chat\",\n    \"output_type\": \"chat\",\n    \"output_component\": \"\",\n    \"tweaks\": null\n  }'\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow Runtime with Custom Image\nDESCRIPTION: Helm command to install the Langflow runtime using a custom image with bundled flows in the langflow namespace.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nhelm install my-langflow-app langflow/langflow-runtime -n langflow --create-namespace --set image.repository=myuser/langflow-hello-world --set image.tag=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Running Flows with Langflow /run Endpoint using Bash\nDESCRIPTION: Demonstrates how to invoke the /run endpoint with HTTP POST using cURL in Bash. Includes required headers such as Content-Type and accept set to application/json, optional x-api-key for authentication, and a JSON body to specify inputs like input_value, input_type, output_type, output_component, tweaks, and session_id. Parameters can be passed via URL path (flow_id), query string (stream), and JSON body fields. This example shows streaming enabled via the query parameter.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"http://$LANGFLOW_URL/api/v1/run/$FLOW_ID?stream=true\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: sk-...\" \\\n  -d '{\n    \"input_value\": \"Tell me a story\",\n    \"input_type\": \"chat\",\n    \"output_type\": \"chat\",\n    \"output_component\": \"chat_output\",\n    \"session_id\": \"chat-123\",\n    \"tweaks\": {\n      \"component_id\": {\n        \"parameter_name\": \"value\"\n      }\n    }\n  }'\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow Services with Docker Compose - Bash\nDESCRIPTION: This Bash command initiates all services defined in your docker-compose.yaml file, launching them in your local environment. It assumes Docker and Docker Compose are installed and the images are already pulled. Upon successful execution, all Langflow-related services start in containers, accessible on the configured ports (default: http://localhost:80). You may need to modify the .env file for custom ports or configuration before using this command.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/deploy/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up\n\n```\n\n----------------------------------------\n\nTITLE: Triggering Langflow Webhook with cURL\nDESCRIPTION: This Bash command demonstrates how to send an HTTP POST request with a JSON payload to trigger a Langflow flow via its Webhook component. The command specifies the target URL (including the flow ID placeholder), the HTTP method (POST), the content type header, and the JSON data payload. Replace `**YOUR_FLOW_ID**` with the actual flow ID obtained from the Langflow UI.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-data.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"http://127.0.0.1:7860/api/v1/webhook/**YOUR_FLOW_ID**\" \\\n  -H 'Content-Type: application/json'\\\n  -d '{\"any\": \"data\"}'\n```\n\n----------------------------------------\n\nTITLE: Deleting a Folder with Langflow API using curl - Bash\nDESCRIPTION: Delete a folder by sending a DELETE request to the specified Langflow folder endpoint using curl. Requires the target folder's UUID, and expects a 204 No Content response if successful. Dependencies include endpoint access and potential authentication mechanisms on the API.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_68\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/folders/$FOLDER_ID\" \\\n  -H \"accept: */*\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow Version in values.yaml\nDESCRIPTION: YAML configuration snippet to specify a particular version of Langflow to deploy instead of using the default 'latest' tag.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nlangflow:\n  backend:\n    image:\n      tag: \"1.0.0a59\"\n  frontend:\n    image:\n      tag: \"1.0.0a59\"\n\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Langflow with PostgreSQL (YAML)\nDESCRIPTION: Defines a Docker Compose setup to run Langflow and a PostgreSQL database as containerized services. It configures the `langflow` service using the latest image, exposes port 7860, depends on the `postgres` service, and sets the `LANGFLOW_DATABASE_URL` environment variable to connect to the PostgreSQL container using its service name (`postgres`). Persistent volumes (`langflow-data`, `langflow-postgres`) are defined for data persistence.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  langflow:\n    image: langflowai/langflow:latest    # or another version tag on https://hub.docker.com/r/langflowai/langflow\n    pull_policy: always                   # set to 'always' when using 'latest' image\n    ports:\n      - \"7860:7860\"\n    depends_on:\n      - postgres\n    environment:\n      - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@postgres:5432/langflow\n      # This variable defines where the logs, file storage, monitor data, and secret keys are stored.\n      - LANGFLOW_CONFIG_DIR=app/langflow\n    volumes:\n      - langflow-data:/app/langflow\n\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_USER: langflow\n      POSTGRES_PASSWORD: langflow\n      POSTGRES_DB: langflow\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - langflow-postgres:/var/lib/postgresql/data\n\nvolumes:\n  langflow-postgres:    # Persistent volume for PostgreSQL data\n  langflow-data:        # Persistent volume for Langflow data\n```\n\n----------------------------------------\n\nTITLE: Downloading File by ID using cURL (v2)\nDESCRIPTION: Downloads a specific file owned by the user by its ID using the v2 API. Requires authentication via API key. The `--output` flag saves the file content locally.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_44\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v2/files/c7b22c4c-d5e0-4ec9-af97-5d85b7657a34\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n  --output downloaded_file.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring Replica Count for Horizontal Scaling in YAML\nDESCRIPTION: Demonstrates how to configure horizontal scaling for the Langflow application by setting the `replicaCount` parameter in the `values.yaml` file. This example sets the desired number of pod replicas to 3.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_25\n\nLANGUAGE: yaml\nCODE:\n```\nreplicaCount: 3\n```\n\n----------------------------------------\n\nTITLE: Get Vertex Builds via API - curl\nDESCRIPTION: This snippet sends a GET request to the /api/v1/monitor/builds endpoint to retrieve Vertex builds associated with a given flow ID. It uses curl to construct the HTTP request and includes necessary headers for accepting JSON responses. The endpoint uses environment variables for the base URL and flow ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_80\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/monitor/builds?flow_id=$FLOW_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with uv or pip\nDESCRIPTION: Commands to start the Langflow server in the local environment using uv or python -m. These commands initiate the Langflow application accessible at localhost on port 7860.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv run langflow run\n```\n\nLANGUAGE: bash\nCODE:\n```\npython -m langflow run\n```\n\n----------------------------------------\n\nTITLE: Configuring GCP Project and Running Langflow Deployment Script (sh)\nDESCRIPTION: Sets the active Google Cloud project using `gcloud config set project` and then executes the `deploy_langflow_gcp.sh` script. This script handles environment setup (VPC, subnet, firewall rules, Cloud Router), VM creation, and Langflow installation/startup on TCP port 7860. Requires the `deploy_langflow_gcp.sh` script to be present in the current directory and the GCP project ID to be substituted for `<walkthrough-project-id/>`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngcloud config set project <walkthrough-project-id/>  \nbash ./deploy_langflow_gcp.sh\n```\n\n----------------------------------------\n\nTITLE: Reading Folders List from Langflow API via Bash\nDESCRIPTION: Retrieves a JSON array of folder objects containing metadata such as folder name, description, ID, and parent folder ID. Folders are used to organize flows and components within the Langflow environment via a GET request.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_61\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/folders/\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration (YAML)\nDESCRIPTION: This YAML configuration file sets up Langflow and a PostgreSQL database for self-hosting. It defines services for both applications, including image versions, ports, and dependencies. It sets up environment variables for Langflow including Langfuse API keys, database URLs, and other configuration settings.  Volumes persist data and the depends_on keyword ensures that postgres is initialized before Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  langflow:\n    image: langflowai/langflow:latest # or another version tag on https://hub.docker.com/r/langflowai/langflow\n    pull_policy: always               # set to 'always' when using 'latest' image\n    ports:\n      - \"7860:7860\"\n    depends_on:\n      - postgres\n    environment:\n      - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@postgres:5432/langflow\n      # This variable defines where the logs, file storage, monitor data and secret keys are stored.\n      - LANGFLOW_CONFIG_DIR=app/langflow\n      - LANGFUSE_SECRET_KEY=sk-...\n      - LANGFUSE_PUBLIC_KEY=pk-...\n      - LANGFUSE_HOST=https://us.cloud.langfuse.com\n    volumes:\n      - langflow-data:/app/langflow\n\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_USER: langflow\n      POSTGRES_PASSWORD: langflow\n      POSTGRES_DB: langflow\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - langflow-postgres:/var/lib/postgresql/data\n\nvolumes:\n  langflow-postgres:\n  langflow-data:\n```\n\n----------------------------------------\n\nTITLE: Interacting with Langflow API Using JavaScript Node.js\nDESCRIPTION: This snippet shows how to run a JavaScript Node.js script to send a query to the Langflow API. It requires a local Node.js environment. The script accepts a message argument and posts it to the flow endpoint, expecting a successful response. Users should replace the query string with their desired message.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nnode test-script.js \"tell me about something interesting\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Langflow Transactions using cURL (Bash)\nDESCRIPTION: Sends a GET request to the Langflow API endpoint '/api/v1/monitor/transactions' to retrieve component interaction transactions for a specific flow. Supports pagination using 'page' and 'size' query parameters. Requires LANGFLOW_URL and FLOW_ID environment variables. Expects a paginated JSON response containing transaction items.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_89\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/monitor/transactions?flow_id=$FLOW_ID&page=1&size=50\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Updating a Langflow Message using cURL (Bash)\nDESCRIPTION: Sends a PUT request to the Langflow API endpoint '/api/v1/monitor/messages/{message_id}' to update a specific message. This example updates the 'text' field of the message with ID '3ab66cc6-c048-48f8-ab07-570f5af7b160'. Requires LANGFLOW_URL, the message ID in the URL path, and a JSON object with the fields to update in the request body. Expects a JSON object representing the updated message.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_86\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PUT \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages/3ab66cc6-c048-48f8-ab07-570f5af7b160\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"text\": \"testing 1234\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Example JSON Streaming Events from Langflow Flow Execution\nDESCRIPTION: Illustrates several JSON event objects streamed during flow execution including vertex sorting, adding user messages, and final event signaling the end of execution. Useful for clients consuming event-driven flow status updates.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_20\n\nLANGUAGE: json\nCODE:\n```\n{\"event\": \"vertices_sorted\", \"data\": {\"ids\": [\"ChatInput-XtBLx\"], \"to_run\": [\"Prompt-x74Ze\", \"ChatOutput-ylMzN\", \"ChatInput-XtBLx\", \"OpenAIModel-d1wOZ\"]}}\n\n{\"event\": \"add_message\", \"data\": {\"timestamp\": \"2025-03-03T17:42:23\", \"sender\": \"User\", \"sender_name\": \"User\", \"session_id\": \"d2bbd92b-187e-4c84-b2d4-5df365704201\", \"text\": \"Tell me a story\", \"files\": [], \"error\": false, \"edit\": false, \"properties\": {\"text_color\": \"\", \"background_color\": \"\", \"edited\": false, \"source\": {\"id\": null, \"display_name\": null, \"source\": null}, \"icon\": \"\", \"allow_markdown\": false, \"positive_feedback\": null, \"state\": \"complete\", \"targets\": []}, \"category\": \"message\", \"content_blocks\": [], \"id\": \"28879bd8-6a68-4dd5-b658-74d643a4dd92\", \"flow_id\": \"d2bbd92b-187e-4c84-b2d4-5df365704201\"}}\n\n// ... Additional events as the flow executes ...\n\n{\"event\": \"end\", \"data\": {}}\n```\n\n----------------------------------------\n\nTITLE: Reading a Specific Flow by ID from Langflow API via Bash\nDESCRIPTION: Retrieves detailed information for a single flow resource identified by FLOW_ID using a GET request to the appropriate endpoint. The JSON response details the flow's metadata, nodes, and configuration.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_54\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/flows/$FLOW_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding for Langflow Runtime Access\nDESCRIPTION: Command to set up port forwarding to access the Langflow runtime service from the local machine.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nkubectl port-forward -n langflow svc/my-langflow-app-with-flow-langflow-runtime 7860:7860\n```\n\n----------------------------------------\n\nTITLE: Sending Uploaded File to Flow (v2 File in v1 Run - cURL)\nDESCRIPTION: Demonstrates how to use a previously uploaded file (using the v2 upload endpoint) as input to a Langflow flow execution via the v1 /run endpoint. The user-scoped v2 file path is passed within the `tweaks` section targeting a 'File' component. Requires API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_41\n\nLANGUAGE: bash\nCODE:\n```\ncurl --request POST \\\n  --url '$LANGFLOW_URL/api/v1/run/$FLOW_ID' \\\n  --header 'Content-Type: application/json' \\\n  --header 'x-api-key: $LANGFLOW_API_KEY' \\\n  --data '{\n  \"input_value\": \"what do you see?\",\n  \"output_type\": \"chat\",\n  \"input_type\": \"text\",\n  \"tweaks\": {\n    \"File-t2Ngc\": {\n      \"path\": [\n        \"232f54ba-dd54-4760-977e-ed637f83e785/5f829bc4-ac1e-4a80-b1d1-fedc03cd5b6e.png\"\n      ]\n    }\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring the arXiv Tool Component in Langflow\nDESCRIPTION: Describes the arXiv tool component in Langflow, which searches and retrieves papers from arXiv.org based on a search query. Details inputs like search query, field, and max results, and the papers output.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nComponent: arXiv\nPurpose: Searches and retrieves papers from arXiv.org.\nInputs:\n- search_query (String): Query for papers (e.g., 'quantum computing').\n- search_type (String): Field to search in.\n- max_results (Integer): Maximum number of results.\nOutputs:\n- papers (List[Data]): List of retrieved arXiv papers.\n```\n\n----------------------------------------\n\nTITLE: Uploading File using cURL (v1)\nDESCRIPTION: Uploads a file to a specific Langflow flow using the v1 API endpoint. The file will be accessible within components of the specified flow. Requires the Langflow base URL and the target flow's ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/files/upload/$FLOW_ID\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@FILE_NAME.txt\"\n```\n\n----------------------------------------\n\nTITLE: Running Database Migrations\nDESCRIPTION: This command runs or tests database migrations.  Options are available to run in test mode, or to fix migrations which is a destructive action and all data will be deleted. This requires the database to be accessible. Input includes the options provided and output is the database state.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nlangflow migration [OPTIONS]\n# or\npython -m langflow migration [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: File Download Confirmation (v1 - Text)\nDESCRIPTION: Indicates that the file content requested from the v1 /files/download endpoint has been successfully downloaded and saved locally.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_34\n\nLANGUAGE: text\nCODE:\n```\nFile contents downloaded to downloaded_file.txt\n```\n\n----------------------------------------\n\nTITLE: Implementing RecursiveCharacterTextSplitter Component in Python for Langflow\nDESCRIPTION: This code defines a RecursiveCharacterTextSplitter component that inherits from LCTextSplitterComponent. It handles splitting text while preserving context, with configurable parameters for chunk size, overlap, and custom separators.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-components.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter, TextSplitter\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.utils.util import unescape_string\n\nclass RecursiveCharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name: str = \"Recursive Character Text Splitter\"\n    description: str = \"Split text trying to keep all related text together.\"\n    documentation: str = \"https://docs.langflow.org/components-processing\"\n    name = \"RecursiveCharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n        ),\n        MessageTextInput(\n            name=\"separators\",\n            display_name=\"Separators\",\n            info='The characters to split on.\\nIf left empty defaults to [\"\\\\n\\\\n\", \"\\\\n\", \" \", \"\"].',\n            is_list=True,\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        if not self.separators:\n            separators: list[str] | None = None\n        else:\n            # check if the separators list has escaped characters\n            # if there are escaped characters, unescape them\n            separators = [unescape_string(x) for x in self.separators]\n\n        return RecursiveCharacterTextSplitter(\n            separators=separators,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap,\n        )\n```\n\n----------------------------------------\n\nTITLE: Setting Langfuse Credentials (Linux/macOS)\nDESCRIPTION: This snippet demonstrates how to set Langfuse project credentials as environment variables in a Linux or macOS terminal. It uses the `export` command to define `LANGFUSE_SECRET_KEY`, `LANGFUSE_PUBLIC_KEY`, and `LANGFUSE_HOST`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGFUSE_SECRET_KEY=SECRET_KEY\nexport LANGFUSE_PUBLIC_KEY=PUBLIC_KEY\nexport LANGFUSE_HOST=HOST_URL\n```\n\n----------------------------------------\n\nTITLE: Configuring the Bing Search API Tool Component in Langflow\nDESCRIPTION: Explains the Bing Search API component in Langflow for making web search queries. Covers inputs like the Bing subscription key, search query input, optional custom search URL, and the number of results (k). Describes the search results and Tool outputs.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_3\n\nLANGUAGE: Text\nCODE:\n```\nComponent: Bing Search API\nPurpose: Calls the Bing Search API.\nInputs:\n- bing_subscription_key (SecretString): Bing API key.\n- input_value (String): Search query input.\n- bing_search_url (String): Optional custom Bing Search URL.\n- k (Integer): Number of results to return.\nOutputs:\n- results (List[Data]): List of search results.\n- tool (Tool): Bing Search tool object for use in LangChain.\n```\n\n----------------------------------------\n\nTITLE: LLM Router for Model Selection Based on Input and Criteria\nDESCRIPTION: Routes requests to the most suitable LLM model from a list based on evaluation criteria provided by an LLM judge. Enhances dynamic model selection by automated judgement and preferences such as quality, speed, or cost.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n### LLM router\n\nThis component routes requests to the most appropriate LLM based on OpenRouter model specifications.\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| models | Language Models | List of LLMs to route between |\n| input_value | Input | The input message to be routed |\n| judge_llm | Judge LLM | LLM that will evaluate and select the most appropriate model |\n| optimization | Optimization | Optimization preference (quality/speed/cost/balanced) |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| output | Output | The response from the selected model |\n| selected_model | Selected Model | Name of the chosen model |\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with Environment Variables - Docker\nDESCRIPTION: This docker command runs a Langflow Docker container and sets an environment variable.  The `-e` flag is used to pass an environment variable to the container during runtime. `-p` maps the port to access the Langflow application.  `--rm` removes the container after it exits. Requires Docker to be installed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm \\\n    -p 7860:7860 \\\n    -e VARIABLE_NAME='VALUE' \\\n    langflowai/langflow:latest\n```\n\n----------------------------------------\n\nTITLE: Fetching Folder List via curl\nDESCRIPTION: Retrieves a list of folders from the server, useful for identifying folder IDs to organize projects.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/folders/\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Exporting FLOW_ID Environment Variable\nDESCRIPTION: Defines the flow ID found in the publish pane or URL, allowing identification for flow-specific API calls.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport FLOW_ID=\"359cd752-07ea-46f2-9d3b-a4407ef618da\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow as an MCP Server in Claude for Desktop Using JSON with Shell Command Arguments\nDESCRIPTION: This JSON snippet demonstrates configuring the Claude for Desktop MCP client to connect with Langflow using a command-based MCP server configuration. It requires specifying a shell command to launch the MCP server shim with appropriate paths for 'uvx' and 'python' commands, including environment variables MCP_HOST and DEBUG. Users must replace placeholders 'PATH/TO/UVX' and 'PATH/TO/PYTHON' with actual system paths obtained via shell commands ('which uvx', 'which python'). This setup enables Claude to register Langflow as an MCP server and use Langflow flows as tools.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/MCP/integrations-mcp.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n \"mcpServers\": {\n     \"langflow\": {\n         \"command\": \"/bin/sh\",\n         \"args\": [\"-c\", \"PATH/TO/UVX --python PATH/TO/PYTHON mcp-sse-shim@latest\"],\n         \"env\": {\n             \"MCP_HOST\": \"http://127.0.0.1:7860\",\n             \"DEBUG\": \"true\"\n         }\n     }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Langflow Configuration using Bash\nDESCRIPTION: cURL example to perform a GET request to the /config endpoint to retrieve current Langflow server settings and feature flags. The response is JSON formatted providing feature flags and various configuration parameters such as frontend timeout, auto saving settings, and max file upload size.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/config\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Packaging a Flow with Langflow Backend - Dockerfile\nDESCRIPTION: This Dockerfile builds a custom Langflow image that bundles user flow JSON files into the image at /app/flows and sets the LANGFLOW_LOAD_FLOWS_PATH environment variable to that path. It uses langflowai/langflow-backend:latest as a base and copies all .json files from the build context. Key dependencies: any .json files in context directory, base image support. On container start, Langflow will load flow files found in /app/flows. Limitation: Only files matching *.json will be copied; ensure valid flow file format for compatibility.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_4\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM langflowai/langflow-backend:latest\nRUN mkdir /app/flows\nCOPY ./*json /app/flows/.\nENV LANGFLOW_LOAD_FLOWS_PATH=/app/flows\n```\n\n----------------------------------------\n\nTITLE: Executing a Packaged Flow\nDESCRIPTION: Shell script to get a flow ID and run the flow using the Langflow API.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\n# Get flow ID\nid=$(curl -s \"http://localhost:7860/api/v1/flows/\" | jq -r '.[0].id')\n\n# Run flow\ncurl -X POST \\\n    \"http://localhost:7860/api/v1/run/$id?stream=false\" \\\n    -H 'Content-Type: application/json' \\\n    -d '{\n      \"input_value\": \"Hello!\",\n      \"output_type\": \"chat\",\n      \"input_type\": \"chat\"\n    }'\n```\n\n----------------------------------------\n\nTITLE: Using the Calculator Tool Component in Langflow\nDESCRIPTION: Describes the Calculator Tool component, which evaluates basic arithmetic expressions securely within Langflow using a method preventing arbitrary code execution. Takes a string expression as input and outputs a LangChain Tool object.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_4\n\nLANGUAGE: Text\nCODE:\n```\nComponent: Calculator Tool\nPurpose: Evaluates basic arithmetic expressions securely (supports +, -, *, /, **).\nInputs:\n- expression (String): Arithmetic expression (e.g., '4*4*(33/22)+12-20').\nOutputs:\n- result (Tool): Calculator tool object for use in LangChain.\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Langflow Messages using cURL (Bash)\nDESCRIPTION: Sends a GET request to the Langflow API endpoint '/api/v1/monitor/messages' to retrieve all messages across all flows and sessions. Requires the LANGFLOW_URL environment variable. Expects a JSON array containing message objects as the response.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_83\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Lambda Filter Using Language Model for Dynamic Data Filtering\nDESCRIPTION: Employs an LLM to generate a custom Lambda function for filtering or transforming structured data based on natural language instructions. Connects to a language model to interpret instructions like 'extract emails' and applies the generated filter to the data.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n### Lambda filter\n\nThis component uses an LLM to generate a Lambda function for filtering or transforming structured data.\n\nTo use the **Lambda filter** component, you must connect it to a [Language Model](/components-models#language-model) component, which the component uses to generate a function based on the natural language instructions in the **Instructions** field.\n\nThis example gets JSON data from the `https://jsonplaceholder.typicode.com/users` API endpoint.\nThe **Instructions** field in the **Lambda filter** component specifies the task `extract emails`.\nThe connected LLM creates a filter based on the instructions, and successfully extracts a list of email addresses from the JSON data.\n\n![](/img/component-lambda-filter.png)\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| data | Data | The structured data to filter or transform using a Lambda function. |\n| llm | Language Model | The connection port for a [Model](/components-models) component. |\n| filter_instruction | Instructions | Natural language instructions for how to filter or transform the data using a Lambda function, such as `Filter the data to only include items where the 'status' is 'active'.` |\n| sample_size | Sample Size | For large datasets, the number of characters to sample from the dataset head and tail. |\n| max_size | Max Size | The number of characters for the data to be considered \"large\", which triggers sampling by the `sample_size` value. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| filtered_data | Filtered Data | The filtered or transformed [Data object](/concepts-objects#data-object). |\n| dataframe | DataFrame | The filtered data as a [DataFrame](/concepts-objects#dataframe-object). |\n```\n\n----------------------------------------\n\nTITLE: Filter Values Component for List-Based Filtering\nDESCRIPTION: Filters a list of data items based on a specified key, value, and comparison operator, supporting custom filtering logic for list data structures. Currently in Beta and not fully supported.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n### Filter values\n\nThis component filters a list of data items based on a specified key, filter value, and comparison operator.\n\n### Inputs\n| Name | Display Name | Info |\n|------|--------------|------|\n| input_data | Input data | The list of data items to filter. |\n| filter_key | Filter Key | The key to filter on, for example, 'route'. |\n| filter_value | Filter Value | The value to filter by, for example, 'CMIP'. |\n| operator | Comparison Operator | The operator to apply for comparing the values. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| filtered_data | Filtered data | The resulting list of filtered data items. |\n```\n\n----------------------------------------\n\nTITLE: Streaming Flow Execution Events from Langflow /build/{job_id}/events Using cURL\nDESCRIPTION: Demonstrates retrieving real-time streaming events of a running flow by issuing a GET request to the /build/{job_id}/events endpoint. Accept header specifies JSON response format. Events include information such as vertices sorted, messages added, and end of execution.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_19\n\nLANGUAGE: text\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/build/123e4567-e89b-12d3-a456-426614174000/events\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Triggering Langflow Webhook via cURL POST Request\nDESCRIPTION: This bash snippet posts arbitrary JSON data to a Langflow webhook endpoint using cURL. It demonstrates the HTTP POST method with the Content-Type header set to application/json. The placeholder **YOUR_FLOW_ID** must be replaced with the actual flow ID. This allows testing webhook components within Langflow flows.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"http://127.0.0.1:7860/api/v1/webhook/**YOUR_FLOW_ID**\" \\\n  -H 'Content-Type: application/json'\\\n  -d '{\"any\": \"data\"}'\n```\n\n----------------------------------------\n\nTITLE: Building and Running a Customized Langflow Docker Image - Bash\nDESCRIPTION: This pair of bash commands builds a custom Docker image (tagged 'myuser/langflow-custom:1.0.0') from a Dockerfile and then runs the image, exposing the application on port 7860. Used after setting up custom project files and Dockerfile. Input: customized build context with updated code and Dockerfile; output: running instance of custom Langflow on the specified port.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t myuser/langflow-custom:1.0.0 .\ndocker run -p 7860:7860 myuser/langflow-custom:1.0.0\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Langflow API key in HTTP header\nDESCRIPTION: Example of how to include the Langflow API key in the HTTP header when making API requests to Langflow endpoints, using curl to run a flow with specific inputs.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-api-keys.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST \\\n  \"http://127.0.0.1:7860/api/v1/run/FLOW_ID?stream=false\" \\\n  -H 'Content-Type: application/json' \\\n  -H 'x-api-key: API_KEY' \\\n  -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n```\n\n----------------------------------------\n\nTITLE: Embedding Langflow Chat Widget via HTML Script Tag\nDESCRIPTION: This HTML snippet shows how to embed Langflow's chat widget into a webpage by including a remote JavaScript bundle and placing a <langflow-chat> custom element in the body. Key attributes include window_title, flow_id, and host_url to specify widget behavior, the flow it interacts with, and the API host URL. This enables seamless integration of Langflow chat UIs on any website.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_3\n\nLANGUAGE: html\nCODE:\n```\n<script src=\"https://cdn.jsdelivr.net/gh/logspace-ai/langflow-embedded-chat@v1.0.7/dist/build/static/js/bundle.min.js\"></script>\\n\\n  <langflow-chat\\n    window_title=\"Basic Prompting\"\\n    flow_id=\"801abb1e-19b9-4278-9632-179b6d84f126\"\\n    host_url=\"http://localhost:7860\"\\n\\n  ></langflow-chat>\n```\n\n----------------------------------------\n\nTITLE: Vertex Build Results - JSON\nDESCRIPTION: This JSON snippet showcases the structure of the data returned by the API endpoint described in the previous snippet. It represents a sample response containing details about different build steps within a Vertex AI flow.  The response includes the build ID, timestamp, and detailed information about each build component, including inputs, outputs, logs, and artifacts.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_81\n\nLANGUAGE: json\nCODE:\n```\n{\"vertex_builds\":{\"ChatInput-NCmix\":[{\"data\":{\"results\":{\"message\":{\"text_key\":\"text\",\"data\":{\"timestamp\":\"2024-12-23 19:10:57\",\"sender\":\"User\",\"sender_name\":\"User\",\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"text\":\"Hello\",\"files\":[],\"error\":\"False\",\"edit\":\"False\",\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":\"False\",\"source\":{\"id\":\"None\",\"display_name\":\"None\",\"source\":\"None\"},\"icon\":\"\",\"allow_markdown\":\"False\",\"positive_feedback\":\"None\",\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[],\"id\":\"c95bed34-f906-4aa6-84e4-68553f6db772\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"},\"default_value\":\"\",\"text\":\"Hello\",\"sender\":\"User\",\"sender_name\":\"User\",\"files\":[],\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"timestamp\":\"2024-12-23 19:10:57+00:00\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"error\":\"False\",\"edit\":\"False\",\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":\"False\",\"source\":{\"id\":\"None\",\"display_name\":\"None\",\"source\":\"None\"},\"icon\":\"\",\"allow_markdown\":\"False\",\"positive_feedback\":\"None\",\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[]}},\"outputs\":{\"message\":{\"message\":{\"timestamp\":\"2024-12-23T19:10:57\",\"sender\":\"User\",\"sender_name\":\"User\",\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"text\":\"Hello\",\"files\":[],\"error\":false,\"edit\":false,\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":false,\"source\":{\"id\":null,\"display_name\":null,\"source\":null},\"icon\":\"\",\"allow_markdown\":false,\"positive_feedback\":null,\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[],\"id\":\"c95bed34-f906-4aa6-84e4-68553f6db772\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"},\"type\":\"object\"}},\"logs\":{\"message\":[]},\"message\":{\"message\":\"Hello\",\"sender\":\"User\",\"sender_name\":\"User\",\"files\":[],\"type\":\"object\"},\"artifacts\":{\"message\":\"Hello\",\"sender\":\"User\",\"sender_name\":\"User\",\"files\":[],\"type\":\"object\"},\"timedelta\":0.015060124918818474,\"duration\":\"15 ms\",\"used_frozen_result\":false},\"artifacts\":{\"message\":\"Hello\",\"sender\":\"User\",\"sender_name\":\"User\",\"files\":[],\"type\":\"object\"},\"params\":\"- Files: []\\n  Message: Hello\\n  Sender: User\\n  Sender Name: User\\n  Type: object\\n\",\"valid\":true,\"build_id\":\"40aa200e-74db-4651-b698-f80301d2b26b\",\"id\":\"ChatInput-NCmix\",\"timestamp\":\"2024-12-23T19:10:58.772766Z\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"}],\"Prompt-BEn9c\":[{\"data\":{\"results\":{},\"outputs\":{\"prompt\":{\"message\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"type\":\"text\"}},\"logs\":{\"prompt\":[]},\"message\":{\"prompt\":{\"repr\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"raw\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"type\":\"text\"}},\"artifacts\":{\"prompt\":{\"repr\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"raw\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"type\":\"text\"}},\"timedelta\":0.0057758750626817346,\"duration\":\"6 ms\",\"used_frozen_result\":false},\"artifacts\":{\"prompt\":{\"repr\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"raw\":\"Answer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\",\"type\":\"text\"}},\"params\":\"None\",\"valid\":true,\"build_id\":\"39bbbfde-97fd-42a5-a9ed-d42a5c5d532b\",\"id\":\"Prompt-BEn9c\",\"timestamp\":\"2024-12-23T19:10:58.781019Z\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"}],\"OpenAIModel-7AjrN\":[{\"data\":{\"results\":{},\"outputs\":{\"text_output\":{\"message\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"type\":\"text\"},\"model_output\":{\"message\":\"\",\"type\":\"unknown\"}},\"logs\":{\"text_output\":[]},\"message\":{\"text_output\":{\"repr\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"raw\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"type\":\"text\"}},\"artifacts\":{\"text_output\":{\"repr\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"raw\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"type\":\"text\"}},\"timedelta\":1.034765167045407,\"duration\":\"1.03 seconds\",\"used_frozen_result\":false},\"artifacts\":{\"text_output\":{\"repr\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"raw\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"type\":\"text\"}},\"params\":\"None\",\"valid\":true,\"build_id\":\"4f0ae730-a266-4d35-b89f-7b825c620a0f\",\"id\":\"OpenAIModel-7AjrN\",\"timestamp\":\"2024-12-23T19:10:58.790484Z\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"}],\"ChatOutput-sfUhT\":[{\"data\":{\"results\":{\"message\":{\"text_key\":\"text\",\"data\":{\"timestamp\":\"2024-12-23 19:10:58\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"text\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"files\":[],\"error\":\"False\",\"edit\":\"False\",\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":\"False\",\"source\":{\"id\":\"OpenAIModel-7AjrN\",\"display_name\":\"OpenAI\",\"source\":\"gpt-4o-mini\"},\"icon\":\"OpenAI\",\"allow_markdown\":\"False\",\"positive_feedback\":\"None\",\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[],\"id\":\"5688356d-9f30-40ca-9907-79a7a2fc16fd\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"},\"default_value\":\"\",\"text\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"files\":[],\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"timestamp\":\"2024-12-23 19:10:58+00:00\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"error\":\"False\",\"edit\":\"False\",\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":\"False\",\"source\":{\"id\":\"OpenAIModel-7AjrN\",\"display_name\":\"OpenAI\",\"source\":\"gpt-4o-mini\"},\"icon\":\"OpenAI\",\"allow_markdown\":\"False\",\"positive_feedback\":\"None\",\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[]}},\"outputs\":{\"message\":{\"message\":{\"timestamp\":\"2024-12-23T19:10:58\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"session_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\",\"text\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"files\":[],\"error\":false,\"edit\":false,\"properties\":{\"text_color\":\"\",\"background_color\":\"\",\"edited\":false,\"source\":{\"id\":\"OpenAIModel-7AjrN\",\"display_name\":\"OpenAI\",\"source\":\"gpt-4o-mini\"},\"icon\":\"OpenAI\",\"allow_markdown\":false,\"positive_feedback\":null,\"state\":\"complete\",\"targets\":[]},\"category\":\"message\",\"content_blocks\":[],\"id\":\"5688356d-9f30-40ca-9907-79a7a2fc16fd\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"},\"type\":\"object\"}},\"logs\":{\"message\":[]},\"message\":{\"message\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"files\":[],\"type\":\"object\"},\"artifacts\":{\"message\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"files\":[],\"type\":\"object\"},\"timedelta\":0.017838125000707805,\"duration\":\"18 ms\",\"used_frozen_result\":false},\"artifacts\":{\"message\":\"Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building something fresh! What do you have in mind? Whether it's a project, an idea, or a concept, let's dive in and make it happen!\",\"sender\":\"Machine\",\"sender_name\":\"AI\",\"files\":[],\"type\":\"object\"},\"params\":\"- Files: []\\n  Message: Hello! \\ud83d\\udcab I'm excited to help you get started on your journey to building\\n    something fresh! What do you have in mind? Whether it's a project, an idea, or\\n    a concept, let's dive in and make it happen!\\n  Sender: Machine\\n  Sender Name: AI\\n  Type: object\\n\",\"valid\":true,\"build_id\":\"1e8b908b-aba7-403b-9e9b-eca92bb78668\",\"id\":\"ChatOutput-sfUhT\",\"timestamp\":\"2024-12-23T19:10:58.813268Z\",\"flow_id\":\"01ce083d-748b-4b8d-97b6-33adbb6a528a\"}]}}\n```\n\n----------------------------------------\n\nTITLE: Setting the PostgreSQL Database URL in .env (Text)\nDESCRIPTION: Defines the `LANGFLOW_DATABASE_URL` environment variable within the `.env` file. This variable specifies the connection string for the PostgreSQL database Langflow should use, overriding the default SQLite configuration. Users must replace the placeholder values (`user`, `password`, `localhost`, `5432`, `dbname`) with their actual PostgreSQL credentials and connection details.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_DATABASE_URL=\"postgresql://user:password@localhost:5432/dbname\"\n```\n\n----------------------------------------\n\nTITLE: Configuring the Astra DB Tool Component in Langflow\nDESCRIPTION: Documents the Astra DB Tool component for querying Astra DB collections within Langflow agents. Explains inputs like tool name, description, collection name, credentials, projection fields, parameters, filters, and limit. Describes the Data and StructuredTool outputs.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_1\n\nLANGUAGE: Text\nCODE:\n```\nComponent: Astra DB Tool\nPurpose: Allows agents to query Astra DB collections.\nInputs:\n- Tool Name (String): Reference name for the agent.\n- Tool Description (String): Description for model decision.\n- Collection Name (String): Target collection name.\n- Token (SecretString): Astra DB authentication token.\n- API Endpoint (String): Astra DB API endpoint.\n- Projection Fields (String): Attributes to return (comma-separated, default: '*').\n- Tool Parameters (Dict): Parameters for the model to fill (use '!' for required).\n- Static Filters (Dict): Attribute-value pairs for filtering.\n- Limit (String): Number of documents to return.\nOutputs:\n- Data (List[Data]): Query results.\n- Tool (StructuredTool): LangChain tool object for agent workflows.\n```\n\n----------------------------------------\n\nTITLE: Log Retrieval Environment Configuration for Langflow - Text Example\nDESCRIPTION: Shows required .env variables to enable log retrieval in Langflow, including flags for enabling log retrieval, buffer size, and log level. Place these lines in your .env file prior to application startup for logs API functionality.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_74\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_ENABLE_LOG_RETRIEVAL=true\nLANGFLOW_LOG_RETRIEVER_BUFFER_SIZE=10000\nLANGFLOW_LOG_LEVEL=DEBUG\n```\n\n----------------------------------------\n\nTITLE: Example Query for Sequential Tasks Agent in Langflow\nDESCRIPTION: A sample query demonstrating how to format a question for the Sequential Tasks Agent. This example asks for investment analysis of Tesla stock, providing clear instructions about the expected research areas and output format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Sample-Flows/sequential-agent.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nShould I invest in Tesla (TSLA) stock right now?\nPlease analyze the company's current position, market trends,\nfinancial health, and provide a clear investment recommendation.\n```\n\n----------------------------------------\n\nTITLE: Configuring kubectl to Use Minikube Context\nDESCRIPTION: Command to set kubectl to use the Minikube context for Kubernetes operations.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl config use-context minikube\n```\n\n----------------------------------------\n\nTITLE: Message to Data Converter\nDESCRIPTION: Transforms a Message object into a Data object for further processing or analysis. Facilitates seamless conversion between different data representations within Langflow AI workflows.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n### Message to data\n\nThis component converts [Message](/concepts-objects#message-object) objects to [Data](/concepts-objects#data-object) objects.\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| message | Message | The [Message](/concepts-objects#message-object) object to convert to a [Data](/concepts-objects#data-object) object. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| data | Data | The converted [Data](/concepts-objects#data-object) object. |\n```\n\n----------------------------------------\n\nTITLE: Editing File Name by ID using cURL (v2)\nDESCRIPTION: Changes the name of a specific file owned by the user using its ID and the v2 API. Requires authentication via API key. The new name is provided as a query parameter.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_46\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PUT \\\n  \"$LANGFLOW_URL/api/v2/files/$FILE_ID?name=new_file_name\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up GCP Project and Deploying Langflow with Shell Script\nDESCRIPTION: This shell snippet sets the active GCP project and executes a deployment script that automates the configuration of necessary GCP resources (like VPC, subnet, firewall rules, and Cloud Router), creates a Compute Engine VM instance, installs Python, Langflow, and Nginx via a startup script, and runs Langflow on TCP port 7860. Dependencies include gcloud CLI installed and authenticated, appropriate GCP permissions, and the deploy_langflow_gcp_spot.sh script available in the workspace. Inputs: the GCP project ID to target. Outputs: a running Langflow service accessible on port 7860.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial_spot.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngcloud config set project <walkthrough-project-id/>\nbash ./deploy_langflow_gcp_spot.sh\n```\n\n----------------------------------------\n\nTITLE: Customizing Langflow Docker Image to Override Components - Dockerfile\nDESCRIPTION: Comprehensive Dockerfile for customizing a Langflow image by injecting a modified Python component (e.g., astradb_graph.py) into the installed package directory at container build time. It sets up the working directory, finds Python site-packages, replaces component code, deletes Python cache files, exposes the service port, and provides a startup command. Prerequisites include a modified astradb_graph.py file in a specific build path and access to the base langflowai/langflow:latest image. Expected output is a custom image with the overridden file ready to serve Langflow; works for any custom component by adjusting path and filenames.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_7\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM langflowai/langflow:latest\n# Set working directory\nWORKDIR /app\n# Copy your modified astradb_graph.py file\nCOPY src/backend/base/langflow/components/vectorstores/astradb_graph.py /tmp/astradb_graph.py\n# Find the site-packages directory where langflow is installed\nRUN python -c \"import site; print(site.getsitepackages()[0])\" > /tmp/site_packages.txt\n# Replace the file in the site-packages location\nRUN SITE_PACKAGES=$(cat /tmp/site_packages.txt) && \\\n    echo \"Site packages at: $SITE_PACKAGES\" && \\\n    mkdir -p \"$SITE_PACKAGES/langflow/components/vectorstores\" && \\\n    cp /tmp/astradb_graph.py \"$SITE_PACKAGES/langflow/components/vectorstores/\"\n# Clear Python cache in the site-packages directory only\nRUN SITE_PACKAGES=$(cat /tmp/site_packages.txt) && \\\n    find \"$SITE_PACKAGES\" -name \"*.pyc\" -delete && \\\n    find \"$SITE_PACKAGES\" -name \"__pycache__\" -type d -exec rm -rf {} +\n# Expose the default Langflow port\nEXPOSE 7860\n# Command to run Langflow\nCMD [\"python\", \"-m\", \"langflow\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"7860\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variable from Kubernetes Secret in YAML\nDESCRIPTION: Demonstrates how to set an environment variable (`openai_key_var`) within the Langflow runtime container by referencing a Kubernetes secret (`openai-key`) and a specific key (`openai-key`) within that secret. This configuration is defined in the `env` section of the `values.yaml` file for the Helm chart.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_19\n\nLANGUAGE: yaml\nCODE:\n```\nenv:\n  - name: openai_key_var\n    valueFrom:\n      secretKeyRef:\n        name: openai-key\n        key: openai-key\n```\n\n----------------------------------------\n\nTITLE: Setting Groq Assistant Behavior via Prompt (Text)\nDESCRIPTION: This text snippet demonstrates how to configure the behavior of the Groq LLM within a Langflow Prompt component. It instructs the AI to act as a helpful assistant that provides sources for its claims. This prompt is entered into the Prompt component, which then feeds it to the connected Groq model component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-models.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nYou are a helpful assistant who supports their claims with sources.\n```\n\n----------------------------------------\n\nTITLE: Downloading Folder Contents as ZIP with Langflow API using curl - Bash\nDESCRIPTION: Download an entire folder as a zip archive by sending a GET request to the /folders/download endpoint with curl. The --output flag specifies the output zip file location; if omitted, the output is to STDOUT. Requires a valid folder ID and assumes 'application/json' as the accepted response header, though the actual return is a zip binary.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_70\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/folders/download/b408ddb9-6266-4431-9be8-e04a62758331\" \\\n  -H \"accept: application/json\" \\\n  --output langflow-folder.zip\n```\n\n----------------------------------------\n\nTITLE: Defining Inputs and Outputs for Structured Output Component\nDESCRIPTION: This documentation fragment defines the inputs and outputs for a Langflow component that generates structured outputs from language models based on a defined data schema. Inputs include the language model to use ('llm'), the input message string, formatting instructions ('system_prompt'), schema name ('schema_name'), output schema definition ('output_schema'), and a deprecated multi-output flag ('multiple'). Outputs include the structured output as a Data object and its representation converted to a DataFrame. This component allows detailed structured data extraction using custom schemas.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-helpers.md#_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nInputs:\nllm: Language Model to generate output\ninput_value: Input message to the LLM\nsystem_prompt: Formatting instructions for LLM\nschema_name: Name of output data schema\noutput_schema: Schema defining structure and data types\nmultiple: Deprecated flag, always True\n\nOutputs:\nstructured_output: Data object per schema\nstructured_output_dataframe: DataFrame representation of output\n```\n\n----------------------------------------\n\nTITLE: Adding Langflow Helm Repository\nDESCRIPTION: Commands to add the Langflow Helm charts repository and update the local Helm repository cache.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add langflow https://langflow-ai.github.io/langflow-helm-charts\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow DB Connection Settings - Shell\nDESCRIPTION: This snippet demonstrates how to fine-tune database connection pool settings using the LANGFLOW_DB_CONNECTION_SETTINGS environment variable. The value is a JSON string containing parameters like pool size, max overflow, timeout, pre-ping, recycle duration, and echo for SQL queries. These settings affect how Langflow manages connections to its configured database.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/memory.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nLANGFLOW_DB_CONNECTION_SETTINGS='{\"pool_size\": 20, \"max_overflow\": 30, \"pool_timeout\": 30, \"pool_pre_ping\": true, \"pool_recycle\": 1800, \"echo\": false}'\n```\n\n----------------------------------------\n\nTITLE: Generating LANGFLOW_SECRET_KEY (Windows)\nDESCRIPTION: These commands generate a cryptographically secure random key and copy it to the clipboard (Windows) or print it to the console. This key is used as the `LANGFLOW_SECRET_KEY` for encrypting sensitive data within Langflow. The `clip` command is used for copying the generated key to the clipboard.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Copy to clipboard\npython -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | clip\n\n# Or just print\npython -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Arize Phoenix with .env - Bash\nDESCRIPTION: This snippet configures the Arize Phoenix integration with Langflow using a .env file. It sets the PHOENIX_API_KEY environment variable, required for Arize Phoenix. The value for this key is taken from the Arize Phoenix dashboard. The .env file resides in the root of the Langflow application and facilitates loading the Arize Phoenix API key into the Langflow application.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Arize/integrations-arize.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nPHOENIX_API_KEY=YOUR_PHOENIX_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Generating LANGFLOW_SECRET_KEY (macOS/Linux)\nDESCRIPTION: These commands generate a cryptographically secure random key and copy it to the clipboard (macOS/Linux) or print it to the console. This key is used as the `LANGFLOW_SECRET_KEY` for encrypting sensitive data within Langflow. `pbcopy` and `xclip` are used for copying the generated key to the clipboard.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Copy to clipboard (macOS)\npython3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | pbcopy\n\n# Copy to clipboard (Linux)\npython3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | xclip -selection clipboard\n\n# Or just print\npython3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n```\n\n----------------------------------------\n\nTITLE: Uploading a Folder ZIP to Langflow API using curl - Bash\nDESCRIPTION: Upload a zipped folder to Langflow by sending a POST request with the zip file as multipart/form-data using curl. Required fields include the API endpoint, accept and Content-Type headers, and the 'file' form specifying the path to the zip archive. Upload size limits or authentication policies may be enforced by the server.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_72\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/folders/upload/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@20241230_135006_langflow_flows.zip;type=application/zip\"\n```\n\n----------------------------------------\n\nTITLE: Listing Files by User using cURL (v2)\nDESCRIPTION: Retrieves a list of all files uploaded and owned by the authenticated user account using the v2 API. Requires authentication via API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_42\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v2/files\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Formatting Structured Data with Markdown Template (Text)\nDESCRIPTION: Defines a text template using curly braces {} as placeholders (e.g., {name}, {id}, {email}) to format structured data, typically from a DataFrame output. This template is used within the Langflow 'Parser' component to structure data into Markdown format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n# Employee Profile\n## Personal Information\n- **Name:** {name}\n- **ID:** {id}\n- **Email:** {email}\n```\n\n----------------------------------------\n\nTITLE: Configuring Scaling and Resources in values.yaml\nDESCRIPTION: YAML configuration to set the number of replicas and resource requirements for Langflow backend and frontend services.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nlangflow:\n  backend:\n    replicaCount: 1\n    resources:\n      requests:\n        cpu: 0.5\n        memory: 1Gi\n      # limits:\n      #   cpu: 0.5\n      #   memory: 1Gi\n\n  frontend:\n    enabled: true\n    replicaCount: 1\n    resources:\n      requests:\n        cpu: 0.3\n        memory: 512Mi\n      # limits:\n      #   cpu: 0.3\n      #   memory: 512Mi\n```\n\n----------------------------------------\n\nTITLE: Install NVIDIA Ingest dependencies (PyPI)\nDESCRIPTION: This snippet demonstrates how to install the `nv-ingest` dependencies when Langflow is installed from the Python Package Index (PyPI). It activates the virtual environment, installs the dependencies using `uv pip`, and then runs Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Nvidia/integrations-nvidia-ingest.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource **YOUR_LANGFLOW_VENV**/bin/activate\nuv pip install --prerelease=allow 'langflow[nv-ingest]'\nuv run langflow run\n```\n\n----------------------------------------\n\nTITLE: Retrieving Filtered Langflow Messages using cURL (Bash)\nDESCRIPTION: Sends a GET request to the Langflow API endpoint '/api/v1/monitor/messages' with query parameters to filter and order messages. This example filters by flow_id, session_id, sender ('Machine'), sender_name ('AI'), and orders by timestamp. Requires LANGFLOW_URL and appropriate values for filter parameters. Expects a JSON array of filtered and ordered message objects.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_84\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages?flow_id=$FLOW_ID&session_id=01ce083d-748b-4b8d-97b6-33adbb6a528a&sender=Machine&sender_name=AI&order_by=timestamp\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Defining Prompt Template for Blog Writer in Langflow (Text)\nDESCRIPTION: This code snippet defines the text template used by the Prompt component in the Langflow Blog Writer flow. It structures the input for the language model by separating fetched reference content (`{references}`) from user-provided instructions (`{instructions}`). The combined output forms the final prompt sent to the OpenAI model.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Sample-Flows/blog-writer.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nReference 1:\n\n{references}\n\n---\n\n{instructions}\n\nBlog:\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow DB Connect Timeout - Shell\nDESCRIPTION: This snippet shows how to set the LANGFLOW_DB_CONNECT_TIMEOUT environment variable. This variable specifies the maximum number of seconds Langflow should wait when attempting to establish a new database connection. The default value is 20 seconds.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/memory.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nLANGFLOW_DB_CONNECT_TIMEOUT=20\n```\n\n----------------------------------------\n\nTITLE: Extracting Data with Lambda Filter\nDESCRIPTION: This snippet demonstrates how to filter the data returned by the API Request component. It uses a Lambda Filter component to extract specific data nested within the API response's `result` field. The user provides instructions to the filter using natural language to specify which data to extract.  The output is a structured DataFrame.  This example relies on a Groq language model component and an API Request component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-data.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nI want to explode the result column out into a Data object\n```\n\n----------------------------------------\n\nTITLE: Getting Langflow API Version Information using Bash\nDESCRIPTION: A simple HTTP GET request demonstrated with cURL to fetch the currently running Langflow API version. Uses the accept header for JSON formatting. This endpoint helps clients verify compatibility and API versioning.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/version\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow Desktop (macOS only)\nDESCRIPTION: Guidelines to install Langflow Desktop via downloaded DMG file, including dragging the app to Applications and launching it. Note that this version manages environment and Langflow versions internally.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_6\n\n\n\n----------------------------------------\n\nTITLE: Deleting a Folder with Langflow API - Expected Text Result\nDESCRIPTION: Shows the HTTP status for a successful folder deletion when using the Langflow API. 204 No Content indicates the resource has been deleted and no data will be returned in the response body.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_69\n\nLANGUAGE: text\nCODE:\n```\n204 No Content\n```\n\n----------------------------------------\n\nTITLE: JSON Cleaner for String Validation and Repair\nDESCRIPTION: Cleans JSON strings to ensure full compliance with the JSON specification. Can remove control characters, normalize Unicode, and validate JSON structure before output. Useful for sanitizing malformed JSON data, especially from language models.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n### JSON cleaner\n\nThis component cleans JSON strings to ensure they are fully compliant with the JSON specification.\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| json_str | JSON String | The JSON string to be cleaned. This can be a raw, potentially malformed JSON string produced by language models or other sources that may not fully comply with JSON specifications. |\n| remove_control_chars | Remove Control Characters | If set to True, this option removes control characters (ASCII characters 0-31 and 127) from the JSON string. This can help eliminate invisible characters that might cause parsing issues or make the JSON invalid. |\n| normalize_unicode | Normalize Unicode | When enabled, this option normalizes Unicode characters in the JSON string to their canonical composition form (NFC). This ensures consistent representation of Unicode characters across different systems and prevents potential issues with character encoding. |\n| validate_json | Validate JSON | If set to True, this option attempts to parse the JSON string to ensure it is well-formed before applying the final repair operation. It raises a ValueError if the JSON is invalid, allowing for early detection of major structural issues in the JSON. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| output | Cleaned JSON String | The resulting cleaned, repaired, and validated JSON string that fully complies with the JSON specification. |\n```\n\n----------------------------------------\n\nTITLE: Sending POST Request to Trigger Webhook (cURL)\nDESCRIPTION: This cURL command sends a POST request to a Langflow webhook endpoint.  It sends a JSON payload containing example data (id, name, and email).  The `YOUR_FLOW_ID` placeholder should be replaced with the actual flow ID. The command demonstrates how to trigger the flow and pass data to it.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/webhook.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ncurl -X POST \"http://127.0.0.1:7860/api/v1/webhook/YOUR_FLOW_ID\" \\\n    -H 'Content-Type: application/json' \\\n    -d '{\"id\": \"12345\", \"name\": \"alex\", \"email\": \"alex@email.com\"}'\n```\n\n----------------------------------------\n\nTITLE: Deleting All Files with Langflow API Using Bash\nDESCRIPTION: Sends a DELETE request to the Langflow API v2 endpoint for deleting all files associated with the authenticated user. Requires environment variables LANGFLOW_URL and LANGFLOW_API_KEY for URL and API key authentication. It returns a JSON confirmation message on success.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_50\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v2/files\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit hooks\nDESCRIPTION: This series of commands installs pre-commit hooks in the project. It starts by running `uv sync` to ensure Python dependencies are synchronized, and then proceeds to install the pre-commit hooks themselves using `uv run pre-commit install`. This helps maintain code quality and style.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuv sync\nuv run pre-commit install\n```\n\n----------------------------------------\n\nTITLE: Setting LANGFLOW_AUTO_LOGIN environment variable\nDESCRIPTION: This code snippet demonstrates how to set the `LANGFLOW_AUTO_LOGIN` environment variable to either `True` (enabling automatic login) or `False` (disabling automatic login and requiring authentication). Setting this variable to `False` is essential for production environments to enforce user authentication.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nLANGFLOW_AUTO_LOGIN=True\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container for Langflow Application\nDESCRIPTION: This command runs a Docker container from the previously built image, exposing port 7860 on the host, enabling access to the Langflow server for flow interaction and testing in a containerized environment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/develop-application.md#_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run -p 7860:7860 langflow-pokedex:1.2.0\n```\n\n----------------------------------------\n\nTITLE: Adding Dependencies in a Cloned Langflow Repository with uv\nDESCRIPTION: Shows how to add Langflow and another dependency (matplotlib) using `uv add` when working inside a cloned Langflow repository. This command utilizes the existing `pyproject.toml` file to manage dependencies.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\nuv add langflow matplotlib\n```\n\n----------------------------------------\n\nTITLE: Representing an Edge Connecting Two Nodes\nDESCRIPTION: This JSON snippet illustrates the connection (edge) between a `ChatInput` node and an `OpenAIModel` node.  It defines the `source` and `target` nodes and specifies the data types passed between them.  The `data` object includes detailed information about the source and target handles (e.g., data type, field name).\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-flows.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"className\": \"\",\n  \"data\": {\n    \"sourceHandle\": {\n      \"dataType\": \"ChatInput\",\n      \"id\": \"ChatInput-jFwUm\",\n      \"name\": \"message\",\n      \"output_types\": [\"Message\"]\n    },\n    \"targetHandle\": {\n      \"fieldName\": \"input_value\",\n      \"id\": \"OpenAIModel-OcXkl\",\n      \"inputTypes\": [\"Message\"],\n      \"type\": \"str\"\n    }\n  },\n  \"id\": \"reactflow__edge-ChatInput-jFwUm{\\u009cdataType\\u009c:\\u009cChatInput\\u009c,\\u009cid\\u009c:\\u009cChatInput-jFwUm\\u009c,\\u009cname\\u009c:\\u009cmessage\\u009c,\\u009coutput_types\\u009c:[\\u009cMessage\\u009c]}-OpenAIModel-OcXkl{\\u009cfieldName\\u009c:\\u009cinput_value\\u009c,\\u009cid\\u009c:\\u009cOpenAIModel-OcXkl\\u009c,\\u009cinputTypes\\u009c:[\\u009cMessage\\u009c],\\u009ctype\\u009c:\\u009cstr\\u009c}\",\n  \"source\": \"ChatInput-jFwUm\",\n  \"sourceHandle\": \"{\\u009cdataType\\u009c: \\u009cChatInput\\u009c, \\u009cid\\u009c: \\u009cChatInput-jFwUm\\u009c, \\u009cname\\u009c: \\u009cmessage\\u009c, \\u009coutput_types\\u009c: [\\u009cMessage\\u009c]}\",\n  \"target\": \"OpenAIModel-OcXkl\",\n  \"targetHandle\": \"{\\u009cfieldName\\u009c: \\u009cinput_value\\u009c, \\u009cid\\u009c: \\u009cOpenAIModel-OcXkl\\u009c, \\u009cinputTypes\\u009c: [\\u009cMessage\\u009c], \\u009ctype\\u009c: \\u009cstr\\u009c}\"\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding Langflow Chat Widget in React Applications\nDESCRIPTION: This JavaScript snippet illustrates how to embed the Langflow chat widget in a React app. It includes adding the remote script tag to index.html and declaring the custom element's type in React JSX global namespace. The ChatWidget functional component renders the <langflow-chat> web component with customizable props for inputs, flow ID, and host URL, enabling React apps to seamlessly integrate Langflow chat UI.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\ndeclare global {\\n  namespace JSX {\\n    interface IntrinsicElements {\\n      \"langflow-chat\": any;\\n    }\\n  }\\n}\\n\\nexport default function ChatWidget({ className }) {\\n  return (\\n    <div className={className}>\\n      <langflow-chat\\n        chat_inputs='{\"your_key\":\"value\"}'\\n        chat_input_field=\"your_chat_key\"\\n        flow_id=\"your_flow_id\"\\n        host_url=\"langflow_url\"\\n      ></langflow-chat>\\n    </div>\\n  );\\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Arize with .env File - Bash\nDESCRIPTION: This snippet demonstrates how to configure Arize integration with Langflow using a .env file. It sets environment variables ARIZE_SPACE_ID and ARIZE_API_KEY, which are required when using the standard Arize platform. The values for these variables are retrieved from the Arize dashboard.  The .env file is created in the root of the Langflow application and is used to supply the required credentials to the application.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Arize/integrations-arize.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nARIZE_SPACE_ID=YOUR_ARIZE_SPACE_ID\nARIZE_API_KEY=YOUR_ARIZE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Project Directory - Bash\nDESCRIPTION: This bash command sequence creates a new directory named 'langflow-custom' and navigates into it. Used as the initial setup for packaging a custom flow or code alongside the Langflow application in a Docker image. No external dependencies except basic shell utilities. Requires write permissions to the current folder. Expected output is that the shell’s working directory is now 'langflow-custom'.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir langflow-custom && cd langflow-custom\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding for Langflow API Access\nDESCRIPTION: Command to set up port forwarding to access the Langflow API service from the local machine on port 7860.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkubectl port-forward -n langflow svc/langflow-service-backend 7860:7860\n```\n\n----------------------------------------\n\nTITLE: Defining Prompt Template Text with Variables - Text\nDESCRIPTION: This snippet demonstrates creating a prompt template using plain text with embedded dynamic variables enclosed in curly braces. It defines a template that provides context and a user question to the language model, allowing the model to generate a response based on these inputs. No programming dependencies are required as this is a template string format, useful for building structured inputs for language models within Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-prompts.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGiven the context\n{context}\nAnswer the question\n{user_question}\n```\n\n----------------------------------------\n\nTITLE: Prompting Agent for Available Tools with Langflow Workspace Text\nDESCRIPTION: This snippet demonstrates how to interact with the Langflow Agent by querying what tools are available after integration with Composio. No dependencies are required for this operation other than a configured Langflow workspace with Composio tools connected. The prompt is meant for user input in the Chat Input component. The Agent is expected to reply with a list of available actions such as Gmail draft creation and date retrieval.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Composio/integrations-composio.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nWhat tools are available to you?\n```\n\n----------------------------------------\n\nTITLE: Setting up Custom Langflow Project Directories - Bash\nDESCRIPTION: This bash command creates a new directory ('langflow-custom') and navigates into it, used as preparation for building a customized Docker image or including custom Langflow components. Requires write permissions to the file system. Output is a new current working directory, used ahead of creating required subdirectories or Dockerfiles.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nmkdir langflow-custom && cd langflow-custom\n```\n\n----------------------------------------\n\nTITLE: Testing Langflow API Access\nDESCRIPTION: Command to test access to the Langflow API and verify that flows are listed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ncurl -v http://localhost:7860/api/v1/flows/\n```\n\n----------------------------------------\n\nTITLE: Upgrading Langflow to Latest Version with uv or pip\nDESCRIPTION: Commands to upgrade the installed Langflow package to the latest available version using uv or pip, ensuring access to recent features and fixes.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install langflow -U\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install langflow -U\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow Runtime with Flow URL\nDESCRIPTION: Helm command to install the Langflow runtime and download flows from a specified URL.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nhelm install my-langflow-app-with-flow langflow/langflow-runtime \\\n  -n langflow \\\n  --create-namespace \\\n  --set 'downloadFlows.flows[0].url=https://raw.githubusercontent.com/langflow-ai/langflow/dev/tests/data/basic_example.json'\n```\n\n----------------------------------------\n\nTITLE: Updating Session ID for Langflow Messages using cURL (Bash)\nDESCRIPTION: Sends a PATCH request to the Langflow API endpoint '/api/v1/monitor/messages/session/{old_session_id}' to update the session ID for all messages associated with the old ID. This example changes the session ID from '01ce083d-748b-4b8d-97b6-33adbb6a528a' to 'different_session_id'. Requires LANGFLOW_URL, the old session ID in the URL path, and the new session ID as a query parameter ('new_session_id'). Expects a JSON array containing the updated message objects.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_87\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages/session/01ce083d-748b-4b8d-97b6-33adbb6a528a?new_session_id=different_session_id\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Text with Regex in Langflow URL Component\nDESCRIPTION: This regex pattern is used with the Langflow Regex Extractor tool to extract the first paragraph following \"In the news\" from the raw text output of the URL component. It captures characters non-greedily until two consecutive newline characters are encountered. This example uses the pattern on content fetched from `https://en.wikipedia.org/wiki/Main_Page`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-data.md#_snippet_1\n\nLANGUAGE: regex\nCODE:\n```\nIn the news\\s*\\n(.*?)(?=\\n\\n)\n```\n\n----------------------------------------\n\nTITLE: Install NVIDIA Ingest dependencies (Langflow source)\nDESCRIPTION: This snippet shows how to install the `nv-ingest` dependencies when Langflow is installed from source. It activates the virtual environment, syncs the dependencies using `uv`, and then runs Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Nvidia/integrations-nvidia-ingest.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsource **YOUR_LANGFLOW_VENV**/bin/activate\nuv sync --extra nv-ingest\nuv run langflow run\n```\n\n----------------------------------------\n\nTITLE: Prompting Langflow Agent to Create a Gmail Draft Email with Composio Integration Text\nDESCRIPTION: This prompt instructs the integrated Langflow Agent (with Composio tools) to create a Gmail draft email with specified parameters. It assumes the Gmail tool and the GMAIL_CREATE_EMAIL_DRAFT action are configured for the Agent. Required parameters include subject, recipient email, and body content. The expected result is the creation of a draft email in the authenticated Gmail account.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Composio/integrations-composio.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nCreate a draft email with the subject line \"Greetings from Composio\"\nrecipient: \"your.email@address.com\"\nBody content: \"Hello from composio!\"\n```\n\n----------------------------------------\n\nTITLE: Building and Displaying Documentation\nDESCRIPTION: This set of commands builds and serves the documentation for the Langflow project using Docusaurus. It navigates to the docs directory, installs dependencies using `yarn install`, and starts the Docusaurus server with `yarn start`. The documentation will then be available at a specified URL.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nyarn install\nyarn start\n```\n\n----------------------------------------\n\nTITLE: Parse Data Component for Data to Text Conversion\nDESCRIPTION: Converts structured data objects into human-readable text using customizable templates. Facilitates transforming complex data into easy-to-read message formats by specifying templates with placeholders like {text} or {data}.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n### Parse Data\n\nThis component converts data objects into plain text using a specified template.\nThis component transforms structured data into human-readable text formats, allowing for customizable output through the use of templates.\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| data | Data | The data to convert to text. |\n| template | Template | The template to use for formatting the data. It can contain the keys `{text}`, `{data}`, or any other key in the data. |\n| sep | Separator | The separator to use between multiple data items. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| text | Text | The resulting formatted text string as a [Message](/concepts-objects#message-object) object. |\n```\n\n----------------------------------------\n\nTITLE: Querying Active PostgreSQL Connections for Langflow Database (SQL)\nDESCRIPTION: Executes a SQL query within the `psql` client connected to the PostgreSQL database. The query selects all columns (`*`) from the `pg_stat_activity` system view, filtering for rows where the database name (`datname`) is 'langflow'. This is used to verify and inspect active connections to the specified database, confirming that multiple Langflow instances are connected.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nlangflow=# SELECT * FROM pg_stat_activity WHERE datname = 'langflow';\n```\n\n----------------------------------------\n\nTITLE: Natural Language Filter Instructions for Lambda Filter\nDESCRIPTION: This code snippet provides instructions for the Lambda Filter component to transform a nested data structure. The instructions tell the component to explode the result column into a Data object for further processing.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nI want to explode the result column out into a Data object\n```\n\n----------------------------------------\n\nTITLE: Exporting LangWatch API Key in Terminal (Shell)\nDESCRIPTION: Shows how to set the LANGWATCH_API_KEY environment variable temporarily in the current shell session using the export command. This method is useful for testing or single-session use but is not persistent across terminal sessions. Replace \"your-api-key\" with the actual API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langwatch.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport LANGWATCH_API_KEY=\"your-api-key\"\n```\n\n----------------------------------------\n\nTITLE: Metadata and Project Info in JSON\nDESCRIPTION: This JSON snippet provides an example of the metadata stored in a Langflow flow file. It includes the name, description, tags, unique ID, last tested version, gradient information and the icon. This data allows for versioning, organization, and description of the flow in the UI.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-flows.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Basic Prompting\",\n  \"description\": \"Perform basic prompting with an OpenAI model.\",\n  \"tags\": [\"chatbots\"],\n  \"id\": \"1511c230-d446-43a7-bfc3-539e69ce05b8\",\n  \"last_tested_version\": \"1.0.19.post2\",\n  \"gradient\": \"2\",\n  \"icon\": \"Braces\"\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Kubernetes Pod Status\nDESCRIPTION: Command to verify the status of Langflow pods in the langflow namespace after deployment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods -n langflow\n```\n\n----------------------------------------\n\nTITLE: Deleting Langflow Messages by Session ID using cURL (Bash)\nDESCRIPTION: Sends a DELETE request to the Langflow API endpoint '/api/v1/monitor/messages/session/{session_id}' to delete all messages associated with a specific session ID. This example targets session 'different_session_id_2'. Requires LANGFLOW_URL and the session ID in the URL path. Expects a '204 No Content' response on success.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_88\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/monitor/messages/session/different_session_id_2\" \\\n  -H \"accept: */*\"\n```\n\n----------------------------------------\n\nTITLE: Adding a Development Dependency to Langflow via Make\nDESCRIPTION: Shows how to use the `make add` command to add a development dependency (e.g., matplotlib) needed for testing, linting, or debugging. This adds the dependency to the `[dependency-groups.dev]` section in the appropriate `pyproject.toml`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\nmake add devel=\"matplotlib\"\n```\n\n----------------------------------------\n\nTITLE: Using Template in Parser Component with Batch Run Results\nDESCRIPTION: A template string used in the Parser component to format the output from a Batch Run component. It references three columns from the Batch Run output DataFrame: batch_index (record number), text_input (original text), and model_response (LLM's response).\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-helpers.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nrecord_number: {batch_index}, name: {text_input}, summary: {model_response}\n```\n\n----------------------------------------\n\nTITLE: Disabling Streaming for Langflow Build Events Endpoint via cURL\nDESCRIPTION: Example showing how to disable streaming when retrieving flow execution events by passing the query parameter stream=false to the /build/{job_id}/events endpoint. The response returns all events collectively instead of streaming.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_21\n\nLANGUAGE: text\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/build/123e4567-e89b-12d3-a456-426614174000/events?stream=false\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Filter Data Component for Key-Based Data Filtering\nDESCRIPTION: Filters a data object based on a list of specified keys, returning a subset containing only the key-value pairs that match. Useful for isolating relevant portions of data in a Data object, though currently in Beta and not fully supported.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n### Filter data\n\nThis component filters a [Data](/concepts-objects#data-object) object based on a list of keys.\n\n### Inputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| data | Data | Data object to filter. |\n| filter_criteria | Filter Criteria | List of keys to filter by. |\n\n### Outputs\n\n| Name | Display Name | Info |\n|------|--------------|------|\n| filtered_data | Filtered Data | A new [Data](/concepts-objects#data-object) object containing only the key-value pairs that match the filter criteria. |\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Langflow Flow File - Bash\nDESCRIPTION: This bash command downloads an example Langflow flow file in JSON format from the public repository into the current directory. Useful for testing or including a sample flow when building a custom Docker image. Dependencies: wget must be installed and accessible in the system PATH. Input is a valid URL to the flow file; output is a basic-prompting-hello-world.json file in the current directory.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nwget https://raw.githubusercontent.com/langflow-ai/langflow-helm-charts/refs/heads/main/examples/flows/basic-prompting-hello-world.json\n```\n\n----------------------------------------\n\nTITLE: Composio Gmail Action Data Response Structure (JSON)\nDESCRIPTION: This JSON output shows the lower-level data returned by the Composio tool after the Agent creates a Gmail draft email. The response includes unique IDs for the request, email message, and related labels (like DRAFT), as well as success status flags and an error field. Required prerequisites are a properly authenticated session and the GMAIL_CREATE_EMAIL_DRAFT action. This structure provides detailed status and object tracking info for further automation or logging.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Composio/integrations-composio.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data\": {\n    \"response_data\": {\n      \"id\": \"r-237981011463568567\",\n      \"message\": {\n        \"id\": \"195dd80528171132\",\n        \"threadId\": \"195dd80528171132\",\n        \"labelIds\": [\n          \"DRAFT\"\n        ]\n      }\n    }\n  },\n  \"error\": null,\n  \"successfull\": true,\n  \"successful\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Navigating to Docker Example Directory - Shell\nDESCRIPTION: Changes the current working directory to the 'docker_example' subdirectory. This step is necessary to execute the Docker Compose command from the location where the 'docker-compose.yml' file is located. Ensures the subsequent command targets the correct setup.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docker_example/README.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ncd langflow/docker_example\n```\n\n----------------------------------------\n\nTITLE: Creating a Kubernetes Secret using kubectl (Shell)\nDESCRIPTION: Provides the `kubectl` command to create a generic Kubernetes secret named `openai-credentials` in the `langflow` namespace. The secret contains a key `OPENAI_API_KEY` with its corresponding value.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create secret generic openai-credentials \\\n  --namespace langflow \\\n  --from-literal=OPENAI_API_KEY=sk...\n```\n\n----------------------------------------\n\nTITLE: Deleting Langflow Vertex Builds using cURL (Bash)\nDESCRIPTION: Sends a DELETE request to the Langflow API endpoint '/api/v1/monitor/builds' to delete all vertex builds associated with a specific flow ID. Requires the environment variables LANGFLOW_URL and FLOW_ID to be set. Expects a '204 No Content' response on success.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_82\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/monitor/builds?flow_id=$FLOW_ID\" \\\n  -H \"accept: */*\"\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow Frontend Development Server with Make in Bash\nDESCRIPTION: This snippet shows how to run the Langflow frontend development environment using `make frontend`. It installs frontend dependencies and runs the frontend development server with hot-reloading. Dependencies: Node.js installed and frontend dependencies defined. Input: None. Output: Frontend server running for development.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-how-to-contribute.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake frontend\n```\n\n----------------------------------------\n\nTITLE: Starting Langflow\nDESCRIPTION: This code snippet shows how to start Langflow from the command line after setting the environment variables. The command `uv run langflow run` is used to execute the Langflow application, enabling the Langfuse integration.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuv run langflow run\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variable - Windows\nDESCRIPTION: This command sets an environment variable in a Windows terminal. The `set` command is used to create or modify an environment variable, which is used to configure how the application behaves.  The value of the variable is specified using the `=` operator.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nset VARIABLE_NAME='VALUE'\n```\n\n----------------------------------------\n\nTITLE: Setting LANGFLOW_NEW_USER_IS_ACTIVE environment variable\nDESCRIPTION: This code snippet demonstrates how to set the `LANGFLOW_NEW_USER_IS_ACTIVE` environment variable to either `True` (automatically activating new users) or `False` (requiring superuser activation). This setting determines whether new users can log in immediately or require administrative approval.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-authentication.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_NEW_USER_IS_ACTIVE=False\n```\n\n----------------------------------------\n\nTITLE: Including Langflow API key as a query parameter\nDESCRIPTION: Alternative method to authenticate Langflow API requests by passing the API key as a query parameter in the URL instead of in the HTTP header.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-api-keys.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST \\\n  \"http://127.0.0.1:7860/api/v1/run/FLOW_ID?x-api-key=API_KEY?stream=false\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n```\n\n----------------------------------------\n\nTITLE: Adding Langflow Repository as Upstream\nDESCRIPTION: This snippet configures the local Git repository by adding the official Langflow repository as an upstream remote. It sets the push URL to 'no_push' to prevent accidental pushes to the upstream repository.  This is important for managing pull requests.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd langflow\ngit remote add upstream https://github.com/langflow-ai/langflow.git\ngit remote set-url --push upstream no_push\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose\nDESCRIPTION: This snippet shows the command to start the Docker Compose containers defined in the docker-compose.yml file.  The `docker-compose up` command builds, (re)creates, and starts the containers.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\ndocker-compose up\n```\n\n----------------------------------------\n\nTITLE: Configuring Resource Requests for Vertical Scaling in YAML\nDESCRIPTION: Shows how to configure vertical scaling by specifying resource requests (memory and CPU) for the Langflow application pods within the `resources.requests` section of the `values.yaml` file. This example requests 2Gi of memory and 1000m (1 CPU core).\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_26\n\nLANGUAGE: yaml\nCODE:\n```\nresources:\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1000m\"\n```\n\n----------------------------------------\n\nTITLE: Parsing CDK Output for Accessing Langflow Frontend - Shell\nDESCRIPTION: This snippet shows the output syntax given by AWS CDK after deployment, indicating how to find the public CloudFront URL to access the Langflow frontend. The output is informational, not intended for execution, and offers users a way to identify the deployment endpoint in AWS console output.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/aws/README.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nOutputs:\nLangflowAppStack.frontendURLXXXXXX = https://XXXXXXXXXXX.cloudfront.net\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with Custom Environment Variables Locally - Bash\nDESCRIPTION: This command shows how to start Langflow using the python -m langflow run interface, ensuring that additional environment variables (VARIABLE1, VARIABLE2) are set and available. Prepend variables inline or use a .env file to manage secrets; the referenced LANGFLOW_VARIABLES_TO_GET_FROM_ENVIRONMENT setting should be present in the .env file. The variables will be accessible within Langflow as global credentials.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nVARIABLE1=\"VALUE1\" VARIABLE2=\"VALUE2\" python -m langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Custom Component Text Analyzer Python\nDESCRIPTION: This Python code defines a custom Langflow component called `TextAnalyzerComponent`. It takes text input, performs analysis (word count, character count, sentence count), and transforms the text (reversal, uppercasing). The component outputs an analysis result containing the original text and the computed statistics. The component can be enabled as a tool in an agent.  It depends on the `langflow` library, specifically `Component`, `MessageTextInput`, `Output`, and `Data`. It requires text input as the input, and produces an analysis result output.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Agents/agent-tool-calling-agent-component.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nimport re\n\nclass TextAnalyzerComponent(Component):\n    display_name = \"Text Analyzer\"\n    description = \"Analyzes and transforms input text.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"chart-bar\"\n    name = \"TextAnalyzerComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Input Text\",\n            info=\"Enter text to analyze\",\n            value=\"Hello, World!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Analysis Result\", name=\"output\", method=\"analyze_text\"),\n    ]\n\n    def analyze_text(self) -> Data:\n        text = self.input_text\n        \n        # Perform text analysis\n        word_count = len(text.split())\n        char_count = len(text)\n        sentence_count = len(re.findall(r'\\w+[.!?]', text))\n        \n        # Transform text\n        reversed_text = text[::-1]\n        uppercase_text = text.upper()\n        \n        analysis_result = {\n            \"original_text\": text,\n            \"word_count\": word_count,\n            \"character_count\": char_count,\n            \"sentence_count\": sentence_count,\n            \"reversed_text\": reversed_text,\n            \"uppercase_text\": uppercase_text\n        }\n        \n        data = Data(value=analysis_result)\n        self.status = data\n        return data\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow Log Level in YAML\nDESCRIPTION: Specifies how to set the Langflow application's log level using the `LANGFLOW_LOG_LEVEL` environment variable within the `env` section of the `values.yaml` file. This example sets the level to `INFO`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_24\n\nLANGUAGE: yaml\nCODE:\n```\nenv:\n  - name: LANGFLOW_LOG_LEVEL\n    value: \"INFO\"\n```\n\n----------------------------------------\n\nTITLE: Setting a Custom Session ID via Langflow API (cURL)\nDESCRIPTION: This cURL command demonstrates how to execute a Langflow flow using the `/api/v1/run/$FLOW_ID` endpoint. It sends a POST request with a JSON payload containing the input value, input/output types, and crucially, a custom `session_id`. This custom ID (`my_custom_session_value`) will override the default (flow ID) and be used by downstream components and for storing associated messages in the database.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/session-id.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --request POST \\\n  --url 'http://127.0.0.1:7860/api/v1/run/$FLOW_ID' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n  \"input_value\": \"Hello\",\n  \"output_type\": \"chat\",\n  \"input_type\": \"chat\",\n  \"session_id\": \"my_custom_session_value\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Testing Langfuse Connection with Docker\nDESCRIPTION: This command checks the connection from the Langflow container to the Langfuse host.  It executes a Python script within the Langflow container that makes a GET request to the URL specified by the LANGFUSE_HOST environment variable. The script outputs the response status code to confirm successful connection.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose exec langflow python -c \"import requests, os; addr = os.environ.get('LANGFUSE_HOST'); print(addr); res = requests.get(addr, timeout=5); print(res.status_code)\"\n```\n\n----------------------------------------\n\nTITLE: Setting Langfuse Credentials (Windows)\nDESCRIPTION: This snippet provides the command to set Langfuse project credentials as environment variables in a Windows command prompt session. The `set` command is used to set the `LANGFUSE_SECRET_KEY`, `LANGFUSE_PUBLIC_KEY`, and `LANGFUSE_HOST` variables. Replace the placeholder values with your actual API key information.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nset LANGFUSE_SECRET_KEY=SECRET_KEY\nset LANGFUSE_PUBLIC_KEY=PUBLIC_KEY\nset LANGFUSE_HOST=HOST_URL\n```\n\n----------------------------------------\n\nTITLE: Upgrading Helm Release to Use Secret (Shell)\nDESCRIPTION: Illustrates how to upgrade an existing Helm release (`my-langflow-app-image` using the `langflow/langflow-runtime` chart in the `langflow` namespace) to configure an environment variable (`OPENAI_API_KEY`) using the previously created Kubernetes secret (`openai-credentials`). It uses `--set` flags to define the `extraEnv` variable structure referencing the secret.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade my-langflow-app-image langflow/langflow-runtime -n langflow \\\n  --reuse-values \\\n  --set \"extraEnv[0].name=OPENAI_API_KEY\" \\\n  --set \"extraEnv[0].valueFrom.secretKeyRef.name=openai-credentials\" \\\n  --set \"extraEnv[0].valueFrom.secretKeyRef.key=OPENAI_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Activating a Boolean CLI Option in Bash\nDESCRIPTION: Demonstrates how to enable a boolean option (`--remove-api-keys`) when running the `langflow run` command. Boolean options are activated by simply including the flag and do not take arguments. Corresponding `--no-<option>` flags exist to negate them, potentially overriding environment variable settings.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nlangflow run --remove-api-keys\n```\n\n----------------------------------------\n\nTITLE: Gmail Draft Email Creation API Response Example Output (JSON)\nDESCRIPTION: This JSON snippet models the structured response provided by the integrated Agent or tool after creating a Gmail draft via Composio. It lists the recipient's email, subject, body content, and HTML flag. Dependencies include valid API keys and a configured Agent. It demonstrates the structure of programmatic responses users can expect for downstream automation.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Composio/integrations-composio.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"recipient_email\": \"your.email@address.com\",\n  \"subject\": \"Greetings from Composio\",\n  \"body\": \"Hello from composio!\",\n  \"is_html\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Reading Flows from Specific Folder Using Folder ID with Langflow API via Bash\nDESCRIPTION: Retrieves flows filtered by a specific folder ID by sending a GET request with appropriate query parameters including folder_id. Pagination parameters control number of flows per request. JSON response returns flows belonging to the specified folder.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_53\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/flows/?remove_example_flows=true&components_only=false&get_all=false&folder_id=$FOLDER_ID&header_flows=false&page=1&size=1\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Initializing LangFlow AI Client in JavaScript\nDESCRIPTION: This code initializes the LangFlow AI client using specific configuration parameters, setting up the environment to interact with LangFlow's API. It requires dependencies such as axios or any HTTP client, and the client object is configured with base URL, API key, and other options.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/src/backend/base/README.md#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nconst langflowClient = new LangFlowClient({\n  baseUrl: 'https://api.langflow.com',\n  apiKey: 'YOUR_API_KEY',\n  timeout: 5000\n});\n```\n\n----------------------------------------\n\nTITLE: Configure Opik for self-hosted with CLI\nDESCRIPTION: This bash command configures Opik to use a local, self-hosted instance. It utilizes the Opik CLI and the `--use_local` flag to set up the configuration. This command requires the Opik CLI tool and a running local Opik server.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-opik.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nopik configure --use_local\n```\n\n----------------------------------------\n\nTITLE: Downloading Folder Contents as ZIP - Expected Text Result\nDESCRIPTION: Indicates that the contents of the folder are downloaded. Actual result is a zip binary streamed to the specified output file. If no output file is specified, the binary is written to the terminal/STDOUT.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_71\n\nLANGUAGE: text\nCODE:\n```\nThe folder contents.\n```\n\n----------------------------------------\n\nTITLE: Successful Connection Output\nDESCRIPTION: Example output demonstrating successful connection to Langfuse through the docker container. It prints the URL defined in the variable LANGFUSE_HOST, then the http response code. The code `200` indicates the connection was successful.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langfuse.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nhttps://us.cloud.langfuse.com\n200\n```\n\n----------------------------------------\n\nTITLE: Parsing Webhook Data with Parser Component (Example)\nDESCRIPTION: This snippet demonstrates how to parse data from the Webhook component within a Parser component. The template string defines variables for extracting specific data from the incoming JSON payload (id, name, and email).  This allows the user to structure the received data for further processing.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/webhook.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nID: {id} - Name: {name} - Email: {email}\n```\n\n----------------------------------------\n\nTITLE: Listing Files by Flow ID using cURL (v1)\nDESCRIPTION: Retrieves a list of all files that have been uploaded and are currently associated with a specific Langflow flow using the v1 API. Requires the Langflow base URL and the target flow's ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_31\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/files/list/$FLOW_ID\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Using Output Parser for CSV Format Parsing in Python\nDESCRIPTION: This snippet demonstrates how to configure and use the Output Parser component in Langflow to convert language model responses formatted as CSV into Python lists. It requires connecting the 'format_instructions' output to a Prompt component to guide the LLM's response formatting, and then uses the 'output_parser' to parse the response. This setup supports only CSV parsing via Langchain's CommaSeparatedListOutputParser, converting responses like 'apple, banana, orange' into Python lists such as [\"apple\", \"banana\", \"orange\"]. It does not generate prompts itself and must be combined with a Prompt component for end-to-end usage.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-helpers.md#_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n{format_instructions}\nPlease list three fruits.\n```\n\nLANGUAGE: python\nCODE:\n```\nparser_type = \"CSV\"\nformat_instructions = output_parser.format_instructions\n# Use format_instructions in a prompt template\n# Then receive LLM output and parse it:\nparsed_list = output_parser.parse(llm_response)  # returns ['apple', 'banana', 'orange']\n```\n\n----------------------------------------\n\nTITLE: Configuring the Astra DB CQL Tool Component in Langflow\nDESCRIPTION: Details the Astra DB CQL Tool component, specifically designed for querying CQL tables in Astra DB, requiring partition keys. Lists inputs including keyspace, table name, credentials, projection, partition/clustering keys, filters, and limit. Outlines Data and StructuredTool outputs.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_2\n\nLANGUAGE: Text\nCODE:\n```\nComponent: Astra DB CQL Tool\nPurpose: Allows agents to query CQL tables in Astra DB.\nInputs:\n- Tool Name (String): Reference name for the agent.\n- Tool Description (String): Description for model decision.\n- Keyspace (String): Target keyspace name.\n- Table Name (String): Target CQL table name.\n- Token (SecretString): Astra DB authentication token.\n- API Endpoint (String): Astra DB API endpoint.\n- Projection Fields (String): Attributes to return (comma-separated, default: '*').\n- Partition Keys (Dict): Required parameters for the query.\n- Clustering Keys (Dict): Optional parameters for refining the query (use '!' for required).\n- Static Filters (Dict): Attribute-value pairs for filtering.\n- Limit (String): Number of records to return.\nOutputs:\n- Data (List[Data]): Query results.\n- Tool (StructuredTool): LangChain tool object for agent workflows.\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with .env - Local\nDESCRIPTION: This bash command starts Langflow locally, loading environment variables from a `.env` file. It uses the `python -m` command to run the Langflow module and specifies the `.env` file with the `--env-file` option.  It requires Python and the Langflow package to be installed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Creating Superuser Account\nDESCRIPTION: This command creates a superuser account for Langflow.  It requires a username and a password.  The output is the creation of a superuser with the specified credentials.  The `--log-level` option can also be used to control the logging level.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nlangflow superuser [OPTIONS]\n# or\npython -m langflow superuser [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Running Langflow with .env - Bash\nDESCRIPTION: This command starts the Langflow application using the environment variables specified in the .env file. The `uv run langflow run --env-file .env` command executes the Langflow application and loads the environment variables from the specified .env file.  This allows Langflow to access the ARIZE_SPACE_ID and ARIZE_API_KEY or PHOENIX_API_KEY.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Arize/integrations-arize.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv run langflow run --env-file .env\n```\n\n----------------------------------------\n\nTITLE: Connecting to PostgreSQL Container via Docker Exec (Bash)\nDESCRIPTION: Uses the `docker exec` command to open an interactive terminal (`-it`) inside the running PostgreSQL container (identified as `docker-test-postgres-1`, which should be replaced with the actual container name or ID). It then launches the `psql` command-line interface, connecting as the `langflow` user (`-U langflow`) to the `langflow` database (`-d langflow`). This command allows direct inspection and interaction with the database being used by the Langflow instances.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it docker-test-postgres-1 psql -U langflow -d langflow\n```\n\n----------------------------------------\n\nTITLE: Running Langflow Documentation Locally with Yarn in Bash\nDESCRIPTION: This set of commands navigates to the documentation directory, installs dependencies using Yarn, and starts the local documentation server. It allows contributors to view and test Docusaurus-based documentation locally at localhost:3000. Dependencies: Node.js and Yarn installed. Input: None. Output: Local documentation server running and accessible.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-how-to-contribute.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd docs\nyarn install\nyarn start\n```\n\n----------------------------------------\n\nTITLE: Building and Pushing Langflow Image to Docker Hub - Bash\nDESCRIPTION: This bash code shows how to build and push a custom Langflow Docker image to Docker Hub. Replace 'myuser' with your Docker Hub account username. Requires Docker and a Docker Hub account. Input: valid Dockerfile and build context; output: image pushed to Docker Hub for later use or deployment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t myuser/langflow-hello-world:1.0.0 .\ndocker push myuser/langflow-hello-world:1.0.0\n```\n\n----------------------------------------\n\nTITLE: Starting MCP Fetch Server Command Example (Bash)\nDESCRIPTION: Example Bash command used within the Langflow MCP Server component's 'MCP Command' field to start the 'fetch' MCP server implementation using 'uvx'. 'uvx' is typically included with Langflow. This command initiates the external server process that Langflow can then interact with via the Model Context Protocol.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-tools.md#_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\nuvx mcp-server-fetch\n```\n\n----------------------------------------\n\nTITLE: Curl Command for Posting Messages with Custom Session ID\nDESCRIPTION: This curl command demonstrates how to send a POST request to the Langflow API to initiate or continue a chat session using a specific custom session ID. It includes headers and JSON payload specifying session ID, input value, input type, and output type, enabling multiple user interactions within a single flow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-playground.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n   curl -X POST \"http://127.0.0.1:7860/api/v1/run/$FLOW_ID\" \\ \n   -H 'Content-Type: application/json' \\ \n   -d '{\n       \"session_id\": \"custom_session_123\",\n       \"input_value\": \"message\",\n       \"input_type\": \"chat\",\n       \"output_type\": \"chat\"\n   }'\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables in Systemd Override\nDESCRIPTION: This snippet demonstrates how to configure environment variables using a systemd override configuration file (`override.conf`).  This allows overriding default environment variables for a Langflow service. Each line defines an environment variable using the `Environment` directive.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_7\n\nLANGUAGE: ini\nCODE:\n```\n[Service]\nEnvironment=\"DO_NOT_TRACK=true\"\nEnvironment=\"LANGFLOW_AUTO_LOGIN=false\"\nEnvironment=\"LANGFLOW_AUTO_SAVING=true\"\nEnvironment=\"LANGFLOW_AUTO_SAVING_INTERVAL=1000\"\nEnvironment=\"LANGFLOW_BACKEND_ONLY=false\"\nEnvironment=\"LANGFLOW_BUNDLE_URLS=[\\\"https://github.com/user/repo/commit/hash\\\"]\"\nEnvironment=\"LANGFLOW_CACHE_TYPE=async\"\nEnvironment=\"LANGFLOW_COMPONENTS_PATH=/path/to/components/\"\nEnvironment=\"LANGFLOW_CONFIG_DIR=/path/to/config\"\nEnvironment=\"LANGFLOW_DATABASE_URL=postgresql://user:password@localhost:5432/langflow\"\nEnvironment=\"LANGFLOW_DEV=false\"\nEnvironment=\"LANGFLOW_FALLBACK_TO_ENV_VAR=false\"\nEnvironment=\"LANGFLOW_HEALTH_CHECK_MAX_RETRIES=5\"\nEnvironment=\"LANGFLOW_HOST=127.0.0.1\"\nEnvironment=\"LANGFLOW_LANGCHAIN_CACHE=InMemoryCache\"\nEnvironment=\"LANGFLOW_MAX_FILE_SIZE_UPLOAD=10000\"\nEnvironment=\"LANGFLOW_LOG_ENV=container_json\"\nEnvironment=\"LANGFLOW_LOG_FILE=logs/langflow.log\"\nEnvironment=\"LANGFLOW_LOG_LEVEL=error\"\nEnvironment=\"LANGFLOW_OPEN_BROWSER=false\"\nEnvironment=\"LANGFLOW_PORT=7860\"\nEnvironment=\"LANGFLOW_REMOVE_API_KEYS=false\"\nEnvironment=\"LANGFLOW_SAVE_DB_IN_CONFIG_DIR=true\"\nEnvironment=\"LANGFLOW_SECRET_KEY=somesecretkey\"\nEnvironment=\"LANGFLOW_STORE=true\"\nEnvironment=\"LANGFLOW_STORE_ENVIRONMENT_VARIABLES=true\"\nEnvironment=\"LANGFLOW_SUPERUSER=adminuser\"\nEnvironment=\"LANGFLOW_SUPERUSER_PASSWORD=adminpass\"\nEnvironment=\"LANGFLOW_WORKER_TIMEOUT=60000\"\nEnvironment=\"LANGFLOW_WORKERS=3\"\n```\n\n----------------------------------------\n\nTITLE: Disabling Sourcing of Environment Variables in Langflow - Text\nDESCRIPTION: By adding this entry to your .env file, you prevent Langflow from importing global variables from environment settings. LANGFLOW_STORE_ENVIRONMENT_VARIABLES set to false ensures only manually-created variables within Langflow will be used, overriding any automatic import.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_STORE_ENVIRONMENT_VARIABLES=false\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow with uv (Shell)\nDESCRIPTION: This command installs the Langflow package using the `uv` package manager, which is the recommended method for a potentially faster and more reliable installation. It requires `uv` to be pre-installed and configured on the system.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuv pip install langflow\n```\n\n----------------------------------------\n\nTITLE: Environment Variables for Multiple Langflow Instances (.env) (Text)\nDESCRIPTION: Defines environment variables in a `.env` file intended for configuring multiple Langflow instances sharing a single PostgreSQL database via Docker Compose. It specifies PostgreSQL connection details (user, password, database name, host, port), the Langflow configuration directory, and distinct host ports (`LANGFLOW_PORT_1`, `LANGFLOW_PORT_2`) for accessing each Langflow instance.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nPOSTGRES_USER=langflow\nPOSTGRES_PASSWORD=your_secure_password\nPOSTGRES_DB=langflow\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nLANGFLOW_CONFIG_DIR=app/langflow\nLANGFLOW_PORT_1=7860\nLANGFLOW_PORT_2=7861\nLANGFLOW_HOST=0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Building and Executing Flows with Langflow /build Endpoint Using Bash\nDESCRIPTION: Demonstrates sending a POST request to /build/{flow_id}/flow to initiate flow construction and execution. The request uses JSON for inputs including an 'inputs' object where input values such as input_value are provided. The response returns a job ID used to track and stream execution events. This endpoint is primarily intended for frontend use and offers enhanced configuration over the simpler /run endpoint.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/build/$FLOW_ID/flow\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"inputs\": {\n      \"input_value\": \"Tell me a story\"\n    }\n  }'\n```\n\n----------------------------------------\n\nTITLE: Configuring External PostgreSQL in values.yaml\nDESCRIPTION: YAML configuration to connect Langflow to an external PostgreSQL database instead of using the built-in SQLite or PostgreSQL chart.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\npostgresql:\n  enabled: false\n\nlangflow:\n  backend:\n    externalDatabase:\n      enabled: true\n      driver:\n        value: \"postgresql\"\n      port:\n        value: \"5432\"\n      user:\n        value: \"langflow\"\n      password:\n        valueFrom:\n          secretKeyRef:\n            key: \"password\"\n            name: \"your-secret-name\"\n      database:\n        value: \"langflow-db\"\n    sqlite:\n      enabled: false\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI for Lexical Query Generation (Text)\nDESCRIPTION: This snippet shows the prompt used within the OpenAI model component to generate lexical queries from user input. It instructs the model to create keywords and a question for searching against the data.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-vector-stores.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nYou are a database query planner that takes a user's requests, and then converts to a search against the subject matter in question.\nYou should convert the query into:\n1. A list of keywords to use against a Lucene text analyzer index, no more than 4. Strictly unigrams.\n2. A question to use as the basis for a QA embedding engine.\nAvoid common keywords associated with the user's subject matter.\n```\n\n----------------------------------------\n\nTITLE: Generating a Langflow API key using CLI\nDESCRIPTION: Command to generate a Langflow API key using the command-line interface, with sample output showing the generated key and instructions for storing it securely.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-api-keys.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nlangflow api-key\n# or\npython -m langflow api-key\n```\n\n----------------------------------------\n\nTITLE: Configuring Prompt Template in Langflow\nDESCRIPTION: Sets the prompt template within the Prompt component to instruct the LLM to respond enthusiastically as a GenAI expert. It defines the instruction that guides the model's responses during interaction.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Starter-Projects/starter-projects-basic-prompting.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nAnswer the user as if you were a GenAI expert, enthusiastic about helping them get started building something fresh.\n```\n\n----------------------------------------\n\nTITLE: Configuring Built-in PostgreSQL in values.yaml\nDESCRIPTION: YAML configuration to enable and configure the built-in PostgreSQL database chart for Langflow storage.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\npostgresql:\n  enabled: true\n  auth:\n    username: \"langflow\"\n    password: \"langflow-postgres\"\n    database: \"langflow-db\"\n\n```\n\n----------------------------------------\n\nTITLE: Starting LangFlow Services with Docker Compose - Shell\nDESCRIPTION: Starts the application services defined in the 'docker-compose.yml' file using Docker Compose. This command builds images (if necessary) and starts containers for the LangFlow and PostgreSQL services, making LangFlow accessible locally. Requires Docker and Docker Compose to be installed and running.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docker_example/README.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow as an MCP Server in Cursor with JSON\nDESCRIPTION: This JSON snippet configures the Cursor MCP client to connect to a Langflow server as an MCP server by specifying the server's SSE endpoint URL. Prerequisites include having Langflow running at the specified host (e.g., http://127.0.0.1:7860) and a Cursor client installation capable of reading MCP server configurations from JSON. The configuration must specify the 'mcpServers' object with a nested 'langflow' server URL at the '/api/v1/mcp/sse' endpoint. Once saved and reloaded, Cursor can access all Langflow flows as MCP tools.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/MCP/integrations-mcp.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mcpServers\": {\n    \"langflow\": {\n      \"url\": \"http://127.0.0.1:7860/api/v1/mcp/sse\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the default_kwargs Fixture for Component Tests in Python\nDESCRIPTION: Defines a pytest fixture method named `default_kwargs` that returns a dictionary of default keyword arguments required to instantiate the component. This fixture facilitates test setup by specifying input parameters like templates and session identifiers to create a valid component instance during tests.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-component-tests.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture\ndef default_kwargs(self):\n    return {\"template\": \"Hello {name}!\", \"name\": \"John\", \"_session_id\": \"123\"}\n```\n\n----------------------------------------\n\nTITLE: Sending Custom Data Payload to Langflow Build Endpoint Using Bash\nDESCRIPTION: POST request example demonstrating how to override stored flow configuration by providing a custom data object along with inputs when invoking the /build/{flow_id}/flow endpoint. This enables running flows without pre-stored database values and supports passing session information and arbitrary nodes and edges graph definition.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/build/$FLOW_ID/flow\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"data\": {\n      \"nodes\": [],\n      \"edges\": []\n    },\n    \"inputs\": {\n      \"input_value\": \"Your custom input here\",\n      \"session\": \"session_id\"\n    }\n  }'\n```\n\n----------------------------------------\n\nTITLE: Getting Kubernetes Service Information\nDESCRIPTION: Command to list services in the langflow namespace to find the Langflow service name.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get svc -n langflow\n```\n\n----------------------------------------\n\nTITLE: Running MCP Inspector for Langflow Debugging Using npx in Shell\nDESCRIPTION: This shell command installs and runs the MCP Inspector, a tool for testing and debugging MCP servers such as Langflow. It requires an LTS release of Node.js installed on the system to use 'npx'. Running 'npx @modelcontextprotocol/inspector' launches MCP Inspector at 'http://localhost:5173', allowing users to connect by specifying the Langflow SSE endpoint. Optionally, a specific server port can be set with an environment variable prefix. This setup enables monitoring and interaction with Langflow flows registered as MCP tools.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/MCP/integrations-mcp.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nnpx @modelcontextprotocol/inspector\n```\n\n----------------------------------------\n\nTITLE: Manually Adding a Regular Dependency in pyproject.toml\nDESCRIPTION: Provides the TOML syntax for manually adding a regular dependency (e.g., matplotlib with a version constraint) to the `[project]` section's `dependencies` list within a `pyproject.toml` file.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\n[project]\ndependencies = [\n    \"matplotlib>=3.8.0\"\n]\n```\n\n----------------------------------------\n\nTITLE: Defining Environment Variables in VSCode tasks.json\nDESCRIPTION: This snippet shows how to define environment variables within a `tasks.json` file for Visual Studio Code.  The variables are set in the `env` section of the `options` property, allowing you to configure Langflow within the VSCode development environment. This ensures the variables are available when running tasks within VSCode.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"version\": \"2.0.0\",\n    \"options\": {\n        \"env\": {\n            \"DO_NOT_TRACK\": \"true\",\n            \"LANGFLOW_AUTO_LOGIN\": \"false\",\n            \"LANGFLOW_AUTO_SAVING\": \"true\",\n            \"LANGFLOW_AUTO_SAVING_INTERVAL\": \"1000\",\n            \"LANGFLOW_BACKEND_ONLY\": \"false\",\n            \"LANGFLOW_BUNDLE_URLS\": \"[\\\"https://github.com/user/repo/commit/hash\\\"]\",\n            \"LANGFLOW_CACHE_TYPE\": \"async\",\n            \"LANGFLOW_COMPONENTS_PATH\": \"D:/path/to/components/\",\n            \"LANGFLOW_CONFIG_DIR\": \"D:/path/to/config/\",\n            \"LANGFLOW_DATABASE_URL\": \"postgresql://postgres:password@localhost:5432/langflow\",\n            \"LANGFLOW_DEV\": \"false\",\n            \"LANGFLOW_FALLBACK_TO_ENV_VAR\": \"false\",\n            \"LANGFLOW_HEALTH_CHECK_MAX_RETRIES\": \"5\",\n            \"LANGFLOW_HOST\": \"localhost\",\n            \"LANGFLOW_LANGCHAIN_CACHE\": \"InMemoryCache\",\n            \"LANGFLOW_MAX_FILE_SIZE_UPLOAD\": \"10000\",\n            \"LANGFLOW_LOG_ENV\": \"container_csv\",\n            \"LANGFLOW_LOG_FILE\": \"langflow.log\",\n            \"LANGFLOW_LOG_LEVEL\": \"error\",\n            \"LANGFLOW_OPEN_BROWSER\": \"false\",\n            \"LANGFLOW_PORT\": \"7860\",\n            \"LANGFLOW_REMOVE_API_KEYS\": \"true\",\n            \"LANGFLOW_SAVE_DB_IN_CONFIG_DIR\": \"false\",\n            \"LANGFLOW_SECRET_KEY\": \"somesecretkey\",\n            \"LANGFLOW_STORE\": \"true\",\n            \"LANGFLOW_STORE_ENVIRONMENT_VARIABLES\": \"true\",\n            \"LANGFLOW_SUPERUSER\": \"adminuser\",\n            \"LANGFLOW_SUPERUSER_PASSWORD\": \"adminpass\",\n            \"LANGFLOW_WORKER_TIMEOUT\": \"60000\",\n            \"LANGFLOW_WORKERS\": \"3\"\n        }\n    },\n    \"tasks\": [\n        {\n            \"label\": \"langflow backend\",\n            \"type\": \"shell\",\n            \"command\": \". ./langflownightly/Scripts/activate && langflow run\",\n            \"isBackground\": true,\n            \"problemMatcher\": []\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Angular to Embed Langflow Chat Widget with CUSTOM_ELEMENTS_SCHEMA\nDESCRIPTION: This example demonstrates how to configure an Angular module to embed the Langflow chat web component without compilation warnings. It shows importing CUSTOM_ELEMENTS_SCHEMA from '@angular/core' and adding it to the @NgModule decorator's schemas array. The snippet also provides the Angular template code to include the <langflow-chat> tag with required attributes, enabling embedding of the Langflow chat widget in Angular projects.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n@NgModule({\\n  declarations: [\\n    // ... Other components and directives ...\\n  ],\\n  imports: [\\n    // ... Other imported modules ...\\n  ],\\n  schemas: [\\n    CUSTOM_ELEMENTS_SCHEMA  // Add the CUSTOM_ELEMENTS_SCHEMA here\\n  ]\\n})\\nexport class YourModule { }\n```\n\nLANGUAGE: javascript\nCODE:\n```\n<langflow-chat  chat_inputs='{\"your_key\":\"value\"}'  chat_input_field=\"your_chat_key\"  flow_id=\"your_flow_id\"  host_url=\"langflow_url\"></langflow-chat>\n```\n\n----------------------------------------\n\nTITLE: Running Langflow Container with Custom Environment Variables - Bash\nDESCRIPTION: This bash command runs a Langflow container with specified environment variables loaded from a .env file using Docker's --env-file flag. The service is exposed on port 7860. Dependencies include an existing .env file configured with valid environment variables as described in the documentation. Expected input is a valid .env file in the current directory; the output will be a running container, exited at user request (--rm). Limitation: User must have permissions to access Docker and port 7860 must be free.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm \\\n    -p 7860:7860 \\\n    --env-file .env \\\n    langflowai/langflow:latest\n```\n\n----------------------------------------\n\nTITLE: Configuring Langflow External Database URL - Shell\nDESCRIPTION: This snippet shows how to configure the LANGFLOW_DATABASE_URL environment variable to point Langflow to an external PostgreSQL database. Setting this variable overrides the default SQLite database used for persistent storage. The value follows a standard database connection string format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/memory.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLANGFLOW_DATABASE_URL=postgresql://user:password@localhost:5432/langflow\n```\n\n----------------------------------------\n\nTITLE: Enabling Fallback to Environment Variables for Global Variables - Text\nDESCRIPTION: Set this line in your .env file if you want Langflow to fetch values from matching environment variables whenever a global variable is not found. When LANGFLOW_FALLBACK_FROM_ENV_VAR is true, any missing global variable in Langflow will attempt to source its value from the environment using the same name.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-global-variables.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nLANGFLOW_FALLBACK_FROM_ENV_VAR=true\n```\n\n----------------------------------------\n\nTITLE: Deleting GCP Network Resources for Langflow Deployment (bash)\nDESCRIPTION: Cleans up network resources potentially created or used during the Langflow deployment. It deletes the firewall rules 'allow-tcp-7860' and 'allow-iap', the 'default' subnet in the 'us-central1' region, and the 'default' VPC network using `gcloud` commands. The `--quiet` flag suppresses interactive prompts. Use these commands only if these specific resources are no longer needed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngcloud compute firewall-rules delete allow-tcp-7860 --quiet\n\ngcloud compute firewall-rules delete allow-iap --quiet\n\ngcloud compute networks subnets delete default --region us-central1 --quiet\n\ngcloud compute networks delete default --quiet\n```\n\n----------------------------------------\n\nTITLE: Manually Adding an Optional Dependency in pyproject.toml\nDESCRIPTION: Shows the TOML structure for manually defining an optional dependency group (e.g., `plotting`) containing specific packages (e.g., matplotlib) within the `[project.optional-dependencies]` section of a `pyproject.toml` file.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_6\n\nLANGUAGE: TOML\nCODE:\n```\n[project.optional-dependencies]\nplotting = [\n    \"matplotlib>=3.8.0\",\n]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Langflow VM IP Address and Access URL with Bash\nDESCRIPTION: This bash snippet extracts the external IP address of the Langflow VM instance named 'langflow-dev' using the gcloud CLI and then prints the accessible HTTP URL with port 7860. It depends on having the gcloud CLI configured and authenticated with access to the target GCP project. Inputs: VM instance name 'langflow-dev'. Outputs: A URL string that users can open in a browser to access the Langflow environment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial_spot.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGFLOW_IP=$(gcloud compute instances list --filter=\"NAME=langflow-dev\" --format=\"value(EXTERNAL_IP)\")\necho http://$LANGFLOW_IP:7860\n```\n\n----------------------------------------\n\nTITLE: Google Drive Document Translation Example Flow\nDESCRIPTION: A pre-built JSON flow that loads a text file from Google Drive, translates it to Spanish, and returns it in a chat output. This example demonstrates how to use the Google OAuth Token and Google Drive loader components in Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Google/integrations-setup-google-oauth-langflow.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nGoogle_Drive_Docs_Translations_Example.json (referenced file)\n```\n\n----------------------------------------\n\nTITLE: Importing a Custom Component in Langflow\nDESCRIPTION: Example Python import statement required to make a custom document loader (`MyCustomDocumentLoader`) available within the Langflow framework. This line should be added to the `__init__.py` file in the relevant components directory (e.g., `/documentloaders/__init__.py`) as part of the contribution process.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-components.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom .MyCustomDocumentLoader import MyCustomDocumentLoader\n```\n\n----------------------------------------\n\nTITLE: Copying Database Files\nDESCRIPTION: This command copies the Langflow database files (`langflow.db` and `langflow-pre.db`) from the cache directory to the current directory. The current directory is where `__main__.py` is located. The command has no input parameters and moves the database files. There are no relevant limitations.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nlangflow copy-db\n# or\npython -m langflow copy-db\n```\n\n----------------------------------------\n\nTITLE: Creating Message Object Python\nDESCRIPTION: This snippet demonstrates the asynchronous method for creating and storing a `Message` object based on input parameters within the `ChatInput` class. It uses the `Message.create()` factory method to construct the message, setting various properties based on input parameters such as text, sender information, session ID, files, and styling properties.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-io.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nmessage = await Message.create(\n    text=self.input_value,\n    sender=self.sender,\n    sender_name=self.sender_name,\n    session_id=self.session_id,\n    files=self.files,\n    properties={\n        \"background_color\": background_color,\n        \"text_color\": text_color,\n        \"icon\": icon,\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up AWS Resources Deployed for Langflow - Shell\nDESCRIPTION: This cleanup shell command executes a script to remove AWS resources created for the Langflow deployment. It is intended to be run from the Cloud9 terminal after use. It assumes the delete-resources.sh script exists and has appropriate permissions. Outputs may include logs or status messages detailing deleted resources or errors if dependencies still exist.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/aws/README.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nbash delete-resources.sh\n```\n\n----------------------------------------\n\nTITLE: Sample Flow Execution Result JSON\nDESCRIPTION: Shows the JSON response after running a flow, including the AI's message with detailed information about bioluminescence and session metadata.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"session_id\": \"chat-123\",\n  \"outputs\": [{\n    \"inputs\": {\n      \"input_value\": \"Tell me about something interesting!\"\n    },\n    \"outputs\": [{\n      \"results\": {\n        \"message\": {\n          \"text\": \"Sure! Have you ever heard of the phenomenon known as \\\"bioluminescence\\\"? ...\",\n          \"sender\": \"Machine\",\n          \"sender_name\": \"AI\",\n          \"session_id\": \"chat-123\",\n          \"timestamp\": \"2025-03-03T17:17:37+00:00\",\n          \"flow_id\": \"d2bbd92b-187e-4c84-b2d4-5df365704201\",\n          \"properties\": {\n            \"source\": {\n              \"id\": \"OpenAIModel-d1wOZ\",\n              \"display_name\": \"OpenAI\",\n              \"source\": \"gpt-4o-mini\"\n            },\n            \"icon\": \"OpenAI\"\n          },\n          \"component_id\": \"ChatOutput-ylMzN\"\n        }\n      }\n    }]\n  }]\n}\n```\n\n----------------------------------------\n\nTITLE: Running CLI Without Arguments\nDESCRIPTION: This command shows the available options and commands for the Langflow CLI. It provides a basic overview of the CLI's functionality.  It has no dependencies or parameters.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-cli.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nlangflow [OPTIONS]\n# or\npython -m langflow [OPTIONS]\n```\n\n----------------------------------------\n\nTITLE: Uploading Flows from File to Langflow Using Multipart Form Data via Bash\nDESCRIPTION: Uploads one or more flows via a JSON file using a POST multipart/form-data request to the flows upload endpoint. The file data is sent with the 'file' parameter. Supports specifying an optional folder_id as query parameter to assign uploaded flows to a folder. Returns an array of flow metadata in JSON.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_58\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/flows/upload/?folder_id=$FOLDER_ID\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@agent-with-astra-db-tool.json;type=application/json\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Folder with Flows and Components Assigned Using Langflow API via Bash\nDESCRIPTION: Sends a POST request to create a folder and assign existing components and flows by specifying their IDs in components_list and flows_list arrays inside the JSON body. Moves these flows and components to the new folder rather than copying them.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_63\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \\\n  \"$LANGFLOW_URL/api/v1/folders/\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"name\": \"new_folder_name\",\n  \"description\": \"string\",\n  \"components_list\": [\n    \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n  ],\n  \"flows_list\": [\n    \"3fa85f64-5717-4562-b3fc-2c963f66afa6\"\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Updating Flow Attributes in Langflow via PATCH Request Using Bash\nDESCRIPTION: Sends a PATCH request to update existing flow properties by flow ID with a JSON body specifying updated attributes such as name, description, data, folder_id, endpoint_name, and locked status. Returns updated flow object in JSON form. Requires Content-Type and Accept headers.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_55\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \\\n  \"$LANGFLOW_URL/api/v1/flows/$FLOW_ID\" \\\n  -H \"accept: application/json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n  \"name\": \"string\",\n  \"description\": \"string\",\n  \"data\": {},\n  \"folder_id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\",\n  \"endpoint_name\": \"my_new_endpoint_name\",\n  \"locked\": true\n}'\n```\n\n----------------------------------------\n\nTITLE: Reading Flows List with Pagination from Langflow API via Bash\nDESCRIPTION: Fetches a paginated list of flows from the Langflow API using a GET request with query parameters to filter results such as removing example flows, including components only, and specifying page and size for pagination. Accept header specifies JSON response. The output is a JSON object containing flow data.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_52\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/flows/?remove_example_flows=false&components_only=false&get_all=true&header_flows=false&page=1&size=50\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Uploading Image File using cURL (v1)\nDESCRIPTION: Uploads an image file to a specific Langflow flow using the v1 API endpoint. Similar to general file upload but specifically for images, often intended for AI analysis within the flow. Requires the Langflow base URL and the target flow's ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"$LANGFLOW_URL/api/v1/files/upload/a430cc57-06bb-4c11-be39-d3d4de68d2c4\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"file=@FILE_NAME.png\"\n```\n\n----------------------------------------\n\nTITLE: Configuring LangWatch API Key in .env File (Shell)\nDESCRIPTION: Demonstrates how to set the LANGWATCH_API_KEY environment variable within a .env file for Langflow. This is the recommended method for persistent configuration. Replace \"your-api-key\" with the actual key obtained from the LangWatch dashboard.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-langwatch.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nLANGWATCH_API_KEY=\"your-api-key\"\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up GCP Resources Using gcloud CLI with SQL-style Commands\nDESCRIPTION: This snippet shows commands in SQL style formatting but actually uses gcloud CLI commands to delete the Compute Engine VM and firewall rules created during the deployment. It requires that the user has correct permissions and the gcloud CLI configured. Inputs: names of the resources to delete (instance: langflow-dev; firewall rules: allow-tcp-7860, allow-iap; networks and subnets). Outputs: removal of the specified resources to clean the GCP environment after usage.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial_spot.md#_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ngcloud compute instances delete langflow-dev --zone us-central1-a --quiet\n```\n\nLANGUAGE: sql\nCODE:\n```\ngcloud compute firewall-rules delete allow-tcp-7860 --quiet\n\ngcloud compute firewall-rules delete allow-iap --quiet\n\ngcloud compute networks subnets delete default --region us-central1 --quiet\n\ngcloud compute networks delete default --quiet\n```\n\n----------------------------------------\n\nTITLE: Curl Command to Test Flow Execution with Custom Session ID\nDESCRIPTION: This Bash command sends a POST request to the Langflow API's /run endpoint with a specific flow ID, input data, and a custom session ID, to trigger flow execution and retrieve the response for testing purposes. It expects the flow to be accessible and running on localhost.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/develop-application.md#_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\ncurl --request POST \\\n  --url 'http://127.0.0.1:7860/api/v1/run/e4167236-938f-4aca-845b-21de3f399858?stream=false' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"input_value\": \"Tell me about Charizard please\",\n    \"output_type\": \"chat\",\n    \"input_type\": \"chat\",\n    \"session_id\": \"charizard_test_request\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Getting Webhook Flow Execution Result Response Example in Text\nDESCRIPTION: Example response returned from triggering the webhook endpoint, provided in text format. It contains a JSON object indicating that the task has started and is in progress. This output is typical for asynchronous flow triggering.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\n{\n  {\"message\":\"Task started in the background\",\"status\":\"in progress\"}\n}\n```\n\n----------------------------------------\n\nTITLE: Pulling Latest Docker Images with Docker Compose - Bash\nDESCRIPTION: This Bash command uses Docker Compose to fetch the newest versions of container images defined in the docker-compose.yaml file. It requires prior installation of both Docker and Docker Compose. No parameters are needed; the command pulls images for all services listed in the Compose file. The expected output is the latest images downloaded to the local machine. Errors may occur if internet connectivity is poor or Docker Compose is not installed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/deploy/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose pull\n\n```\n\n----------------------------------------\n\nTITLE: Retrieving Langflow VM External IP and URL (bash)\nDESCRIPTION: Uses `gcloud compute instances list` to find the external IP address of the VM named 'langflow-dev', exports it to the `LANGFLOW_IP` environment variable, and then prints the full HTTP URL (including port 7860) needed to access the deployed Langflow instance. Assumes the 'langflow-dev' VM has been successfully created and has an external IP.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport LANGFLOW_IP=$(gcloud compute instances list --filter=\"NAME=langflow-dev\" --format=\"value(EXTERNAL_IP)\")\n\necho http://$LANGFLOW_IP:7860\n```\n\n----------------------------------------\n\nTITLE: Viewport Definition in JSON\nDESCRIPTION: This JSON snippet shows the 'viewport' object within a Langflow flow file that defines the initial position and zoom of the flow in the workspace. It stores the x and y coordinates and zoom level that are used to define the user's initial view of the canvas when the flow is opened.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-flows.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"viewport\": {\n  \"x\": -37.61270157375441,\n  \"y\": -155.91266341888854,\n  \"zoom\": 0.7575251406952855\n}\n```\n\n----------------------------------------\n\nTITLE: Starting a Minikube Kubernetes Cluster\nDESCRIPTION: Command to start a Minikube Kubernetes cluster for local development and testing of Langflow deployments.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nminikube start\n```\n\n----------------------------------------\n\nTITLE: Configure Opik with CLI\nDESCRIPTION: This bash command configures Opik using the command-line interface. It allows you to save your Opik configuration in the same environment where you run Langflow. This command needs the Opik CLI tool to be installed and accessible in your environment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/integrations-opik.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nopik configure\n```\n\n----------------------------------------\n\nTITLE: Defining a ChatInput Node in JSON\nDESCRIPTION: This JSON snippet defines a `ChatInput` node within a Langflow flow.  It sets properties like `description`, `display_name`, `id`, and `node`.  The `node` object further defines the node's characteristics and its template, including the input value and sender options.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-flows.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data\": {\n    \"description\": \"Get chat inputs from the Playground.\",\n    \"display_name\": \"Chat Input\",\n    \"id\": \"ChatInput-jFwUm\",\n    \"node\": {\n      \"base_classes\": [\"Message\"],\n      \"description\": \"Get chat inputs from the Playground.\",\n      \"display_name\": \"Chat Input\",\n      \"icon\": \"MessagesSquare\",\n      \"template\": {\n        \"input_value\": {\n          \"display_name\": \"Text\",\n          \"info\": \"Message to be passed as input.\",\n          \"value\": \"Hello\"\n        },\n        \"sender\": {\n          \"value\": \"User\",\n          \"options\": [\"Machine\", \"User\"]\n        },\n        \"sender_name\": {\n          \"value\": \"User\"\n        },\n        \"should_store_message\": {\n          \"value\": true\n        }\n      }\n    },\n    \"type\": \"ChatInput\"\n  },\n  \"position\": {\n    \"x\": 689.5720422421635,\n    \"y\": 765.155834131403\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: File Download Confirmation (v2 - Text)\nDESCRIPTION: Indicates that the file content requested from the v2 /files/{file_id} endpoint has been successfully downloaded and saved to the specified local file.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_45\n\nLANGUAGE: text\nCODE:\n```\nFile contents downloaded to downloaded_file.txt\n```\n\n----------------------------------------\n\nTITLE: List Files Response (v2 - JSON)\nDESCRIPTION: Example JSON response from the v2 /files endpoint, returning an array containing detailed metadata for each file owned by the user, including `id`, `name`, `path`, `size`, and `provider`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_43\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"id\": \"c7b22c4c-d5e0-4ec9-af97-5d85b7657a34\",\n    \"name\": \"your_file\",\n    \"path\": \"6f17a73e-97d7-4519-a8d9-8e4c0be411bb/c7b22c4c-d5e0-4ec9-af97-5d85b7657a34.txt\",\n    \"size\": 1234,\n    \"provider\": null\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Notes in JSON format\nDESCRIPTION: This JSON snippet illustrates how notes, which are markdown formatted text, are stored in a Langflow flow. These notes are similar to comments and include context to aid in the understanding of the flow within the workspace. They may contain links, code snippets and other information. \nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-flows.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"undefined-kVLkG\",\n  \"node\": {\n    \"description\": \"## 📖 README\\nPerform basic prompting with an OpenAI model.\\n\\n#### Quick Start\\n- Add your **OpenAI API key** to the **OpenAI Model**\\n- Open the **Playground** to chat with your bot.\\n...\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning LangFlow Repository - Shell\nDESCRIPTION: Clones the LangFlow repository from GitHub to your local machine. This command requires Git to be installed and configured. It downloads the source code and all associated files necessary for building or running the application.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docker_example/README.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\ngit clone https://github.com/langflow-ai/langflow.git\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variable Directly in YAML\nDESCRIPTION: Shows how to set an environment variable (`openai_key_var`) directly with its value within the `values.yaml` file. This method is generally not recommended for sensitive information like API keys.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\nenv:\n  - name: openai_key_var\n    value: \"sk-....\"\n```\n\n----------------------------------------\n\nTITLE: Installing Specific Version of Langflow\nDESCRIPTION: Commands to install a specific version of Langflow by specifying the version number in the command, facilitating environment consistency or testing.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install langflow==1.3.2\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install langflow==1.3.2\n```\n\n----------------------------------------\n\nTITLE: Interacting with Langflow API Using Python requests\nDESCRIPTION: This snippet demonstrates how to call a Langflow API endpoint using the Python requests library by running a Python script with a message parameter. It assumes that the flow endpoint is accessible and returns a successful response. Users must replace the message with their own queries and ensure Python environment setup with the requests library.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Concepts/concepts-publish.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython3 python-test-script.py --message=\"tell me about something interesting\"\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow with pip (Shell)\nDESCRIPTION: This command installs the Langflow package using the standard Python package manager, `pip`. It fetches the latest version of Langflow from PyPI. This requires `pip` and a compatible Python version (3.10-3.13) to be installed.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install langflow\n```\n\n----------------------------------------\n\nTITLE: Extracting Wikipedia \"In the news\" Section with Regex\nDESCRIPTION: A regular expression pattern designed for the Langflow 'Regex Extractor' component to extract the first paragraph following the 'In the news' section header on the Wikipedia main page. It captures content non-greedily until two consecutive newline characters are encountered.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_12\n\nLANGUAGE: regex\nCODE:\n```\nIn the news\\s*\\n(.*?)(?=\\n\\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Logs from Langflow via Server-Sent Events using curl - Bash\nDESCRIPTION: Stream logs from the Langflow server in real-time using Server-Sent Events (SSE) with a curl GET request. The accept header must be set to 'text/event-stream'. Output will include keepalive messages and serialized log entries as JSON lines.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_76\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/logs-stream\" \\\n  -H \"accept: text/event-stream\"\n```\n\n----------------------------------------\n\nTITLE: Uploading Image File using cURL (v2)\nDESCRIPTION: Uploads an image file to the authenticated user's account using the v2 API. Similar to general v2 file upload, intended for user-scoped storage accessible across flows. Requires API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_39\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"$LANGFLOW_URL/api/v2/files\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n  -F \"file=@FILE_NAME.png\"\n```\n\n----------------------------------------\n\nTITLE: Running Langflow Backend via VSCode Task\nDESCRIPTION: This snippet defines a VSCode task to run the Langflow backend. It activates a virtual environment and then executes the `langflow run` command. This task is configured to run in the background.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/environment-variables.md#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n            \"label\": \"langflow backend\",\n            \"type\": \"shell\",\n            \"command\": \". ./langflownightly/Scripts/activate && langflow run\",\n            \"isBackground\": true,\n            \"problemMatcher\": []\n        }\n```\n\n----------------------------------------\n\nTITLE: Reinstalling Langflow with Dependencies\nDESCRIPTION: Commands to force reinstallation of Langflow and all dependencies, useful for fixing corrupt installations or updates.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuv pip install langflow --force-reinstall\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install langflow --force-reinstall\n```\n\n----------------------------------------\n\nTITLE: Example Markdown Output from Save to File Component (Markdown)\nDESCRIPTION: Illustrates the structure of data saved as a Markdown file (.md) using the Langflow 'Save to File' component. This example shows employee data formatted as a Markdown table, typically resulting from processing JSON data received via a webhook.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n| Name         | Role      | Department   |\n|:-------------|:----------|:-------------|\n| Alex Cruz    | Developer | Engineering  |\n| Kalani Smith | Designer  | Design       |\n| Noam Johnson | Manager   | Management   |\n```\n\n----------------------------------------\n\nTITLE: Deleting Langflow Compute Engine VM Instance (bash)\nDESCRIPTION: Removes the Google Compute Engine virtual machine instance named 'langflow-dev' located in the 'us-central1-a' zone using the `gcloud compute instances delete` command. The `--quiet` flag suppresses interactive prompts. This is part of the resource cleanup process.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/scripts/gcp/walkthroughtutorial.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngcloud compute instances delete langflow-dev --zone us-central1-a --quiet\n```\n\n----------------------------------------\n\nTITLE: Successful Image Upload Response (v1 - JSON)\nDESCRIPTION: Example JSON response after successfully uploading an image file using the v1 /files/upload endpoint. It returns the flow ID and the internal `file_path` generated by Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_28\n\nLANGUAGE: json\nCODE:\n```\n{\"flowId\":\"a430cc57-06bb-4c11-be39-d3d4de68d2c4\",\"file_path\":\"a430cc57-06bb-4c11-be39-d3d4de68d2c4/2024-11-27_14-47-50_image-file.png\"}\n```\n\n----------------------------------------\n\nTITLE: Sending Additional Employee Data to Webhook\nDESCRIPTION: This curl command sends another POST request to the webhook endpoint with a different employee profile. The Data to DataFrame component will add this as another row in the resulting DataFrame.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_1\n\nLANGUAGE: curl\nCODE:\n```\ncurl -X POST \"http://127.0.0.1:7860/api/v1/webhook/YOUR_FLOW_ID\" \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"text\": \"Kalani Smith - Employee Profile\",\n    \"data\": {\n        \"Name\": \"Kalani Smith\",\n        \"Role\": \"Designer\",\n        \"Department\": \"Design\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Retrieving Logs with Optional Parameters - JSON Result\nDESCRIPTION: Shows an example JSON result mapping timestamps to detailed log messages as returned by the logs retrieval endpoint. Each key is a time-based identifier, and the value is a full log line, including ISO timestamps and debug messages.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_79\n\nLANGUAGE: text\nCODE:\n```\n{\n  \"1736354770500\": \"2025-01-08T11:46:10.500363-0500 DEBUG Creating starter project Document Q&A\\n\",\n  \"1736354770511\": \"2025-01-08T11:46:10.511146-0500 DEBUG Creating starter project Image Sentiment Analysis\\n\",\n  \"1736354770521\": \"2025-01-08T11:46:10.521018-0500 DEBUG Creating starter project SEO Keyword Generator\\n\",\n  \"1736354770532\": \"2025-01-08T11:46:10.532677-0500 DEBUG Creating starter project Sequential Tasks Agents\\n\",\n  \"1736354770544\": \"2025-01-08T11:46:10.544010-0500 DEBUG Creating starter project Custom Component Generator\\n\",\n  \"1736354770555\": \"2025-01-08T11:46:10.555513-0500 DEBUG Creating starter project Prompt Chaining\\n\",\n  \"1736354770588\": \"2025-01-08T11:46:10.588105-0500 DEBUG Create service ServiceType.CHAT_SERVICE\\n\",\n  \"1736354771021\": \"2025-01-08T11:46:11.021817-0500 DEBUG Telemetry data sent successfully.\\n\",\n  \"1736354775619\": \"2025-01-08T11:46:15.619545-0500 DEBUG Create service ServiceType.STORE_SERVICE\\n\",\n  \"1736354775699\": \"2025-01-08T11:46:15.699661-0500 DEBUG File 046-rocket.svg retrieved successfully from flow /Users/mendon.kissling/Library/Caches/langflow/profile_pictures/Space.\\n\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Basic Example Flows Using Langflow API via Bash\nDESCRIPTION: Performs a GET request to obtain a list of predefined basic example flows from the API endpoint. It returns a list in JSON format serving as ready-to-use templates or examples for users.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_60\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET \\\n  \"$LANGFLOW_URL/api/v1/flows/basic_examples/\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: List Files Response (v1 - JSON)\nDESCRIPTION: Example JSON response from the v1 /files/list endpoint, returning an array of file names (paths relative to the flow) associated with the specified flow ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_32\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"files\": [\n    \"2024-12-30_15-19-43_your_file.txt\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Flow Execution Result with Image Analysis (v1 - Text)\nDESCRIPTION: Example text output from a Langflow flow execution where an image was provided as input. Shows the response generated by the AI based on the image content.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_30\n\nLANGUAGE: text\nCODE:\n```\n\"text\": \"This flowchart appears to represent a complex system for processing financial inquiries using various AI agents and tools. Here's a breakdown of its components and how they might work together...\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Logs from Langflow via SSE - Expected Text Result\nDESCRIPTION: Shows an example of the log stream, including keepalive messages and newline-delimited JSON objects. Each log object has a timestamp as its key and a raw log entry as its value; lines may represent events, telemetry, or debug messages.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_77\n\nLANGUAGE: text\nCODE:\n```\nkeepalive\n\n{\"1736355791151\": \"2025-01-08T12:03:11.151218-0500 DEBUG Building Chat Input\\n\"}\n\n{\"1736355791485\": \"2025-01-08T12:03:11.485380-0500 DEBUG consumed event add_message-153bcd5d-ef4d-4ece-8cc0-47c6b6a9ef92 (time in queue, 0.0000, client 0.0001)\\n\"}\n\n{\"1736355791499\": \"2025-01-08T12:03:11.499704-0500 DEBUG consumed event end_vertex-3d7125cd-7b8a-44eb-9113-ed5b785e3cf3 (time in queue, 0.0056, client 0.0047)\\n\"}\n\n{\"1736355791502\": \"2025-01-08T12:03:11.502510-0500 DEBUG consumed event end-40d0b363-5618-4a23-bbae-487cd0b9594d (time in queue, 0.0001, client 0.0004)\\n\"}\n\n{\"1736355791513\": \"2025-01-08T12:03:11.513097-0500 DEBUG Logged vertex build: 729ff2f8-6b01-48c8-9ad0-3743c2af9e8a\\n\"}\n\n{\"1736355791834\": \"2025-01-08T12:03:11.834982-0500 DEBUG Telemetry data sent successfully.\\n\"}\n\n{\"1736355791941\": \"2025-01-08T12:03:11.941840-0500 DEBUG Telemetry data sent successfully.\\n\"}\n\nkeepalive\n```\n\n----------------------------------------\n\nTITLE: Managing Langflow Version in Desktop\nDESCRIPTION: Instructions to change or update your Langflow version within the Desktop app via Profile Image menu, which restarts the app with the selected version and displays changelog.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Get-Started/get-started-installation.md#_snippet_7\n\n\n\n----------------------------------------\n\nTITLE: Webhook Response Example (JSON)\nDESCRIPTION: This JSON object represents the response received from the Langflow webhook after sending a POST request. The response indicates that the task has been started in the background, with an 'in progress' status.  This allows users to confirm their request has been successfully received.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/webhook.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n{\"message\":\"Task started in the background\",\"status\":\"in progress\"}\n```\n\n----------------------------------------\n\nTITLE: Using Details Tags for Code Collapsing in GitHub Issues\nDESCRIPTION: An HTML technique for wrapping long code blocks or logs in GitHub issues using the details tag. This approach collapses the content until clicked, making issues easier to read and navigate.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<details>\n</details>\n```\n\n----------------------------------------\n\nTITLE: Semantic Commit Convention Examples for Pull Requests\nDESCRIPTION: Examples of semantic commit conventions to be used for pull request titles, demonstrating the proper format with type prefixes like 'feat' and 'fix' followed by descriptive messages.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nfeat: add new feature\nfix: correct issue with X\n```\n\n----------------------------------------\n\nTITLE: Setting component API keys in environment file\nDESCRIPTION: Example of how to configure API keys for external services like OpenAI, Anthropic, and Google in the .env file for Langflow to use when interacting with these services.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-api-keys.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-...\nGOOGLE_API_KEY=...\n```\n\n----------------------------------------\n\nTITLE: File Name Edit Response (v2 - JSON)\nDESCRIPTION: Example JSON response after successfully changing a file name using the v2 /files/{file_id} endpoint. Returns the updated file metadata.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_47\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\":\"76543e40-f388-4cb3-b0ee-a1e870aca3d3\",\n  \"name\":\"new_file_name\",\n  \"path\":\"6f17a73e-97d7-4519-a8d9-8e4c0be411bb/76543e40-f388-4cb3-b0ee-a1e870aca3d3.png\",\n  \"size\":2728251,\n  \"provider\":null\n  }\n```\n\n----------------------------------------\n\nTITLE: Updating Folder Metadata with Langflow API - JSON Result\nDESCRIPTION: Represents a typical response from the folder PATCH endpoint. JSON object includes updated folder fields, such as name, description, id, and parent_id. Actual structure may vary depending on provided update fields.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_67\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"string\",\n  \"description\": \"string\",\n  \"id\": \"b408ddb9-6266-4431-9be8-e04a62758331\",\n  \"parent_id\": null\n}\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response for Langflow API Version\nDESCRIPTION: JSON response containing version information about the Langflow API including main version and package name. Useful for clients to check running API version details.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n{\n    \"version\": \"1.1.1\",\n    \"main_version\": \"1.1.1\",\n    \"package\": \"Langflow\"\n}\n```\n\n----------------------------------------\n\nTITLE: Deleting File by ID using cURL (v2)\nDESCRIPTION: Deletes a specific file owned by the user by its ID using the v2 API endpoint. Requires authentication via API key.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_48\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v2/files/$FILE_ID\" \\\n  -H \"accept: application/json\" \\\n  -H \"x-api-key: $LANGFLOW_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Cloning Langflow Repository using Git\nDESCRIPTION: This snippet demonstrates how to clone the Langflow repository using the `git clone` command. It retrieves the repository from GitHub using HTTPS and prepares the local environment for development.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/<your username>/langflow.git\n```\n\n----------------------------------------\n\nTITLE: Deleting File by Flow ID and Name using cURL (v1)\nDESCRIPTION: Deletes a specific file associated with a Langflow flow using its flow ID and file name via the v1 API endpoint.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_35\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X DELETE \\\n  \"$LANGFLOW_URL/api/v1/files/delete/$FLOW_ID/2024-12-30_15-19-43_your_file.txt\" \\\n  -H \"accept: application/json\"\n```\n\n----------------------------------------\n\nTITLE: Example User-Chatbot Conversation Transcript - Text\nDESCRIPTION: This sample text demonstrates a multi-turn conversation input for the Langflow memory chatbot. It is intended for testing the memory features of the flow. The example covers user self-introduction, a technical question, and questions which reference earlier parts of the conversation, illustrating how the memory feature enables the chatbot to recall prior user statements. The expected input is a sequence of user messages; output is a conversation log processed by the Chat Memory component. No external dependencies are required beyond the operational Langflow instance.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Sample-Flows/memory-chatbot.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nHi, my name is Luca.\nPlease tell me about PostgreSQL.\nWhat is my name?\nWhat is the second subject I asked you about?\n```\n\n----------------------------------------\n\nTITLE: Starting the Backend Service\nDESCRIPTION: This command, `make backend`, launches the FastAPI-based backend service.  The backend service handles API requests. It uses Uvicorn, and the output shows logs, environment loading, and the server's URL and port.  The service can then be checked via a browser request to the health endpoint.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake backend\n```\n\n----------------------------------------\n\nTITLE: File Deletion Response (v1 - JSON)\nDESCRIPTION: Example JSON response after successfully deleting a file using the v1 /files/delete endpoint, confirming the deletion.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_36\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": \"File 2024-12-30_15-19-43_your_file.txt deleted successfully\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Git File Mode Configuration\nDESCRIPTION: This command configures Git to ignore file mode changes, resolving issues often encountered by Windows/WSL users.  This prevents spurious changes from appearing.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit config core.filemode false\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Server Command for Astra DB Connection\nDESCRIPTION: Command for connecting to an Astra DB MCP server. Requires replacing ASTRA_TOKEN with your Astra DB Application Token and ASTRA_ENDPOINT with your Astra DB API Endpoint.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/MCP/mcp-component-astra.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nenv ASTRA_DB_APPLICATION_TOKEN=ASTRA_TOKEN ASTRA_DB_API_ENDPOINT=ASTRA_ENDPOINT npx -y @datastax/astra-db-mcpnpx -y @datastax/astra-db-mcp\n```\n\n----------------------------------------\n\nTITLE: Initializing Development Environment with Make\nDESCRIPTION: The 'make init' command sets up the development environment. It installs backend and frontend dependencies using `uv`, builds the frontend static files using `make build_frontend` and then launches the application, combining several steps into a single command. The application is started using `uv run langflow run`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake init\n```\n\n----------------------------------------\n\nTITLE: Example Output from Astra DB Collection Query via MCP Server\nDESCRIPTION: Sample output after connecting Langflow to Astra DB through MCP server. Shows the response when asking the agent about available collections in the database.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/MCP/mcp-component-astra.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nThe available collections in your database are:\ncollection_002\nhardware_requirements\nload_collection\nnvidia_collection\nsoftware_requirements\n```\n\n----------------------------------------\n\nTITLE: Creating the .env File for Langflow Configuration (Bash)\nDESCRIPTION: Creates an empty `.env` file in the current directory using the `touch` command. This file is intended to store environment variables used for configuring Langflow, such as the database connection string.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Configuration/configuration-custom-database.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntouch .env\n```\n\n----------------------------------------\n\nTITLE: Starting the Frontend Service\nDESCRIPTION: This command, `make frontend`, starts the frontend service, which is a Node.js service that serves the frontend UI.  The output indicates the Vite build process, local and network URLs for the service, and provides a way to obtain help information.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/DEVELOPMENT.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmake frontend\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding for Langflow UI Access\nDESCRIPTION: Command to set up port forwarding to access the Langflow UI service from the local machine on port 8080.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nkubectl port-forward -n langflow svc/langflow-service 8080:8080\n```\n\n----------------------------------------\n\nTITLE: Agent Success Confirmation for Email Draft Creation with Langflow and Composio (Text)\nDESCRIPTION: This snippet represents the Agent's textual response confirming successful creation of a Gmail draft email. This output is generated after processing the user's request via the integrated Composio tool. It is intended for output verification in the Chat Output component and displays the subject and body used in the draft.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Integrations/Composio/integrations-composio.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nThe draft email with the subject \"Greetings from Composio\" and body \"Hello from composio!\" has been successfully created.\n```\n\n----------------------------------------\n\nTITLE: Sample Pod Status Output\nDESCRIPTION: Example output showing running Langflow pods after a successful deployment.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nNAME                                 READY   STATUS    RESTARTS       AGE\nlangflow-0                           1/1     Running   0              33s\nlangflow-frontend-5d9c558dbb-g7tc9   1/1     Running   0              38s\n```\n\n----------------------------------------\n\nTITLE: Sample Streaming Response Events\nDESCRIPTION: Displays the sequence of JSON events received during streaming, including initial message events, token chunks, and the 'end' event signaling completion.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\"event\": \"add_message\", \"data\": {\"timestamp\": \"2025-03-03T17:20:18\", \"sender\": \"User\", \"sender_name\": \"User\", \"session_id\": \"chat-123\", \"text\": \"Tell me about something interesting!\", ...}}\n{\"event\": \"add_message\", \"data\": {\"timestamp\": \"2025-03-03T17:20:18\", \"sender\": \"Machine\", \"sender_name\": \"AI\", \"session_id\": \"chat-123\", \"text\": \"\", ...}}\n{\"event\": \"token\", \"data\": {\"chunk\": \" Have\", ...}}\n{\"event\": \"token\", \"data\": {\"chunk\": \" you\", ...}}\n{\"event\": \"token\", \"data\": {\"chunk\": \" ever\", ...}}\n{\"event\": \"token\", \"data\": {\"chunk\": \" heard\", ...}}\n{\"event\": \"end\", \"data\": {\"result\": {\"session_id\": \"chat-123\", \"message\": \"Sure! Have you ever heard of the phenomenon known as \\\"bioluminescence\\\"? ...\"}}}\n```\n\n----------------------------------------\n\nTITLE: Adding a Main Dependency to Langflow via Make\nDESCRIPTION: Illustrates using the `make add` command to add a dependency (e.g., matplotlib) required for end-user features to the main Langflow package. This command updates the root `pyproject.toml` and `uv.lock` file.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Develop/install-custom-dependencies.md#_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nmake add main=\"matplotlib\"\n```\n\n----------------------------------------\n\nTITLE: JSON Response for Flow Build Request Returning Job ID\nDESCRIPTION: Shows the JSON response with the job ID generated after building and starting flow execution. The job ID is required for retrieving streaming execution events from the build events endpoint.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_18\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"job_id\": \"123e4567-e89b-12d3-a456-426614174000\"\n}\n```\n\n----------------------------------------\n\nTITLE: Reading Folder Information from Langflow API - JSON Result\nDESCRIPTION: This is the expected JSON response from the Langflow API when requesting folder details. The returned array contains objects with folder properties, including name, description, id, and optional parent_id. Result is provided in application/json format.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_65\n\nLANGUAGE: json\nCODE:\n```\n[\n    {\n        \"name\": \"My Projects\",\n        \"description\": \"Manage your own projects. Download and upload folders.\",\n        \"id\": \"3fa85f64-5717-4562-b3fc-2c963f66afa6\",\n        \"parent_id\": null\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Implementing a Component Test Method to Verify Post-Code Processing in Python\nDESCRIPTION: Illustrates a pytest test method following the Arrange, Act, Assert pattern to verify a component's `.to_frontend_node()` method. The test prepares the component instance using the `component_class` and `default_kwargs` fixtures, executes the target method, and asserts expected data within the serialized frontend node structure. This method serves as an example of writing clear, descriptive component tests following Langflow testing standards.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-component-tests.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef test_post_code_processing(self, component_class, default_kwargs):\n    component = component_class(**default_kwargs)\n\n    frontend_node = component.to_frontend_node()\n\n    node_data = frontend_node[\"data\"][\"node\"]\n    assert node_data[\"template\"][\"template\"][\"value\"] == \"Hello {name}!\"\n    assert \"name\" in node_data[\"custom_fields\"][\"template\"]\n    assert \"name\" in node_data[\"template\"]\n    assert node_data[\"template\"][\"name\"][\"value\"] == \"John\"\n```\n\n----------------------------------------\n\nTITLE: Defining the component_class Fixture for Component Tests in Python\nDESCRIPTION: Defines a pytest fixture method named `component_class` that returns the class of the component under test. This is a required method when inheriting from the base test classes, providing the test framework with the component's class reference necessary to instantiate and run tests. The returned class in the example is `PromptComponent`.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-component-tests.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture\ndef component_class(self):\n    return PromptComponent\n```\n\n----------------------------------------\n\nTITLE: Flow List Response JSON Example\nDESCRIPTION: Provides an example of the JSON response containing folder details, including name, description, ID, and parent ID.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"name\": \"My Projects\",\n    \"description\": \"Manage your own projects. Download and upload folders.\",\n    \"id\": \"1415de42-8f01-4f36-bf34-539f23e47466\",\n    \"parent_id\": null\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Importing Base Test Classes for Component Tests in Python\nDESCRIPTION: Demonstrates how to import base test classes from the standard testing module to enable standardization and mandatory interface implementation in component tests. These base classes enforce required methods and provide a consistent foundation for component test classes. Dependencies include the internal test base module at 'src/backend/tests/unit/base.py'.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-component-tests.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom tests.base import ComponentTestBaseWithClient\nfrom tests.base import ComponentTestBaseWithoutClient\n```\n\n----------------------------------------\n\nTITLE: Preparing Directory Structure for Custom Langflow Components - Bash\nDESCRIPTION: This bash command creates a directory tree for storing custom Langflow Python components, following the internal code structure (e.g., for vectorstores modifications). Input is a valid parent directory; on completion, the specified path exists for placing component files. Limitation: Path must be correctly matched with COPY statements in the Dockerfile.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-docker.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p src/backend/base/langflow/components/vectorstores\n```\n\n----------------------------------------\n\nTITLE: File Deletion Response (v2 - JSON)\nDESCRIPTION: Example JSON response after successfully deleting a file using the v2 /files/{file_id} endpoint, confirming the deletion.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_49\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": \"File deleted successfully\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Langflow Runtime with Escaped Flow URL\nDESCRIPTION: Alternative Helm command with escaped brackets for shells that require it.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Deployment/deployment-kubernetes.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nhelm install my-langflow-app-with-flow langflow/langflow-runtime \\\n  -n langflow \\\n  --create-namespace \\\n  --set 'downloadFlows.flows\\[0\\].url=https://raw.githubusercontent.com/langflow-ai/langflow/dev/tests/data/basic_example.json'\n```\n\n----------------------------------------\n\nTITLE: Utility Function for Deep Object Merging in JavaScript\nDESCRIPTION: This utility function performs a deep merge of multiple objects, combining nested properties. It’s useful for configuration management or updating state objects without mutation. It relies on recursive merging logic to handle nested structures.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/src/backend/base/README.md#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nfunction deepMerge(target, ...sources) {\n  sources.forEach(source => {\n    if (source instanceof Object) {\n      Object.keys(source).forEach(key => {\n        if (source[key] instanceof Object) {\n          if (!target[key]) {\n            Object.assign(target, { [key]: {} });\n          }\n          deepMerge(target[key], source[key]);\n        } else {\n          Object.assign(target, { [key]: source[key] });\n        }\n      });\n    }\n  });\n  return target;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the file_names_mapping Fixture for Version Mapping in Component Tests with Python\nDESCRIPTION: Defines a pytest fixture method named `file_names_mapping` that returns a list of dictionaries mapping component versions to their module and file names over time. This fixture documents the history of the component's location and naming conventions, helping in maintaining backward compatibility and traceability during tests. It can be left empty if the component is unreleased.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-component-tests.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@pytest.fixture\ndef file_names_mapping(self):\n    return [\n        {\"version\": \"1.0.15\", \"module\": \"prompts\", \"file_name\": \"Prompt\"},\n        {\"version\": \"1.0.16\", \"module\": \"prompts\", \"file_name\": \"Prompt\"},\n        {\"version\": \"1.0.17\", \"module\": \"prompts\", \"file_name\": \"Prompt\"},\n        {\"version\": \"1.0.18\", \"module\": \"prompts\", \"file_name\": \"Prompt\"},\n        {\"version\": \"1.0.19\", \"module\": \"prompts\", \"file_name\": \"Prompt\"}\n    ]\n```\n\n----------------------------------------\n\nTITLE: Formatting Long Content with HTML Details Tag\nDESCRIPTION: Demonstrates using HTML `<details>` and `</details>` tags to create collapsible sections for long code snippets, logs, or tracebacks within GitHub Discussions posts. This improves readability by hiding lengthy content until explicitly expanded by the user.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Contributing/contributing-github-discussion-board.md#_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<details>\n  <!-- Long code, logs, or tracebacks go here -->\n</details>\n```\n\n----------------------------------------\n\nTITLE: Example Keywords Generated by OpenAI Model (Text)\nDESCRIPTION: This example shows the keywords and questions generated by the OpenAI model component when creating a lexical query. The keywords are used for Lucene text analysis, and the question is used as the basis for a QA embedding engine.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-vector-stores.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n1. Keywords: features, data, attributes, characteristics\n2. Question: What characteristics can be identified in my data?\n```\n\n----------------------------------------\n\nTITLE: Example Output of Wikipedia News Extraction Regex (Text)\nDESCRIPTION: Shows the sample text extracted using the provided regex pattern `In the news\\s*\\n(.*?)(?=\\n\\n)` on the Wikipedia main page, demonstrating the expected result of the Langflow 'Regex Extractor' component.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-processing.md#_snippet_13\n\nLANGUAGE: text\nCODE:\n```\nPeruvian writer and Nobel Prize in Literature laureate Mario Vargas Llosa (pictured) dies at the age of 89.\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic Lists with Legacy Create List Component\nDESCRIPTION: This snippet describes how to configure the legacy 'Create List' component to dynamically generate a list with a specified number of fields. It requires setting the 'n_fields' input to the desired count and specifying the 'text_key' for naming the fields. The component outputs a list object containing these dynamically created entries. This legacy component is deprecated but still supported for backward compatibility within Langflow.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/Components/components-helpers.md#_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nInputs:\nn_fields: Number of Fields to add\ntext_key: Key used as text\n\nOutputs:\nlist: Generated dynamic list with specified fields\n```\n\n----------------------------------------\n\nTITLE: Uploading a Folder ZIP - Expected Text Result\nDESCRIPTION: Indicates that the uploaded folder's contents have been successfully received and processed by the Langflow application. The actual server response may provide more detail or confirmation depending on implementation.\nSOURCE: https://github.com/langflow-ai/langflow/blob/main/docs/docs/API-Reference/api-reference-api-examples.md#_snippet_73\n\nLANGUAGE: text\nCODE:\n```\nThe folder contents are uploaded to Langflow.\n```"
  }
]