[
  {
    "owner": "apache",
    "repo": "accumulo-website",
    "content": "TITLE: Scanning and displaying all data in an Accumulo table\nDESCRIPTION: Creates a Scanner to read all entries from the 'GothamPD' table with empty authorizations and prints each key-value pair. The Scanner implements Iterable for convenient traversal.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/data-model-code.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\ntry (ScannerBase scan = client.createScanner(\"GothamPD\", Authorizations.EMPTY)) {\n  System.out.println(\"Gotham Police Department Persons of Interest:\");\n  for (Map.Entry<Key, Value> entry : scan) {\n    System.out.printf(\"Key : %-50s  Value : %s\\n\", entry.getKey(), entry.getValue());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Table in Apache Accumulo (Java)\nDESCRIPTION: This snippet demonstrates how to create a table in Accumulo and populate it with data using Mutations. The example creates a 'GothamCrimeStats' table with entries for Batman and Robin's villain capture statistics over multiple days.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\njshell> client.tableOperations().create(\"GothamCrimeStats\");\n\njshell> Mutation mutation1 = new Mutation(\"id0001\");\nmutation1 ==> org.apache.accumulo.core.data.Mutation@1\njshell> mutation1.put(\"hero\", \"alias\", \"Batman\");\n\n// last three days of Batman's statistics\njshell> mutation1.put(\"hero\", \"villainsCaptured\", \"2\");\njshell> mutation1.put(\"hero\", \"villainsCaptured\", \"1\");\njshell> mutation1.put(\"hero\", \"villainsCaptured\", \"5\");\n\njshell> Mutation mutation2 = new Mutation(\"id0002\");\nmutation2 ==> org.apache.accumulo.core.data.Mutation@1\njshell> mutation2.put(\"hero\", \"alias\", \"Robin\");\n\n// last three days of Robin's statistics\njshell> mutation2.put(\"hero\", \"villainsCaptured\", \"1\");\njshell> mutation2.put(\"hero\", \"villainsCaptured\", \"0\");\njshell> mutation2.put(\"hero\", \"villainsCaptured\", \"2\");\n\njshell> try (BatchWriter writer = client.createBatchWriter(\"GothamCrimeStats\")) {\n   ...>   writer.addMutation(mutation1);\n   ...>   writer.addMutation(mutation2);\n   ...> }\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Shell\nDESCRIPTION: Command to start the Accumulo shell with a specified username. The shell will prompt for the corresponding password and display version and instance information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/shell.md#2025-04-11_snippet_0\n\nLANGUAGE: console\nCODE:\n```\naccumulo shell -u [username]\n```\n\n----------------------------------------\n\nTITLE: Reading Data from Accumulo with Scanner\nDESCRIPTION: Creates a Scanner to read all rows from the 'GothamPD' table and prints each key/value pair. The Scanner is created with empty Authorizations since the data is not secured with visibility labels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/basic-read-write.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\ntry (ScannerBase scan = client.createScanner(\"GothamPD\", Authorizations.EMPTY)) {\n   System.out.println(\"Gotham Police Department Persons of Interest:\");\n   for(Map.Entry<Key, Value> entry : scan) {\n     System.out.printf(\"Key : %-50s  Value : %s\\n\", entry.getKey(), entry.getValue());\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Concurrent Writes in Accumulo\nDESCRIPTION: This method demonstrates the issue with concurrent writes in Accumulo. It creates a table, sets an initial address, and then concurrently modifies the address in three different ways, showing potential data loss.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nvoid concurrent_writes() throws Exception {\n  try {\n    client.tableOperations().create(\"GothamPD\");\n  } catch (TableExistsException e) {\n    System.out.println(\"GothamPD table already exists...proceeding...\");\n  }\n  String id = \"id0001\";\n  setAddress(client, id, null, \"   1007 Mountain Drive, Gotham, New York  \");\n  Future<Void> future1 = modifyAddress(client, id, String::trim);\n  Future<Void> future2 = modifyAddress(client, id, addr -> addr.replace(\"Drive\", \"Dr\"));\n  Future<Void> future3 = modifyAddress(client, id, addr -> addr.replace(\"New York\", \"NY\"));\n  future1.get();\n  future2.get();\n  future3.get();\n  System.out.println(\"Final address : '\" + getAddress(client, id) + \"'\");\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Key/Value Pairs to a Mutation in Accumulo\nDESCRIPTION: Adds multiple key/value pairs to the 'hero' family within a Mutation. This demonstrates how to associate multiple attributes with a single row ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/basic-read-write.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nmutation1.put(\"hero\",\"alias\", \"Batman\");\nmutation1.put(\"hero\",\"name\", \"Bruce Wayne\");\nmutation1.put(\"hero\",\"wearsCape?\", \"true\");\n```\n\n----------------------------------------\n\nTITLE: Writing mutations to Accumulo with BatchWriter\nDESCRIPTION: Uses a BatchWriter with try-with-resources to write multiple mutations to the 'GothamPD' table. The BatchWriter automatically flushes and closes when exiting the try block.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/data-model-code.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n  writer.addMutation(mutation1);\n  writer.addMutation(mutation2);\n  writer.addMutation(mutation3);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Authorizations in Accumulo\nDESCRIPTION: Example showing how to create an Authorizations object with multiple security tokens and use it with a Scanner. This demonstrates how to specify the security clearances a user has when reading data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authorizations.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// user possesses both admin and system level access\nAuthorizations auths = new Authorizations(\"admin\",\"system\");\n\nScanner s = client.createScanner(\"table\", auths);\n```\n\n----------------------------------------\n\nTITLE: Index-Based Lookup with Scanner and BatchScanner in Accumulo\nDESCRIPTION: This code demonstrates a two-step lookup process using an index table. First, it scans the index table to find matching row IDs, then uses a BatchScanner to efficiently retrieve multiple rows from the main table in parallel.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Table_Design.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// first we scan the index for IDs of rows matching our query\n\nText term = new Text(\"mySearchTerm\");\n\nHashSet<Text> matchingRows = new HashSet<Text>();\n\nScanner indexScanner = createScanner(\"index\", auths);\nindexScanner.setRange(new Range(term, term));\n\n// we retrieve the matching rowIDs and create a set of ranges\nfor(Entry<Key,Value> entry : indexScanner)\n    matchingRows.add(new Text(entry.getKey().getColumnQualifier()));\n\n// now we pass the set of rowIDs to the batch scanner to retrieve them\nBatchScanner bscan = conn.createBatchScanner(\"table\", auths, 10);\n\nbscan.setRanges(matchingRows);\nbscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan)\n    System.out.println(entry.getValue());\n```\n\n----------------------------------------\n\nTITLE: Configuring a Scanner with Range and Column Constraints\nDESCRIPTION: This snippet demonstrates how to configure a Scanner with a specific range of rows and column family filter. It also shows how to iterate through the scan results to access row keys and values.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_11\n\nLANGUAGE: java\nCODE:\n```\n// return data with visibilities that match specified auths\nAuthorizations auths = new Authorizations(\"public\");\n\ntry (Scanner scan = client.createScanner(\"table\", auths)) {\n  scan.setRange(new Range(\"harry\",\"john\"));\n  scan.fetchColumnFamily(\"attributes\");\n\n  for (Entry<Key,Value> entry : scan) {\n    Text row = entry.getKey().getRow();\n    Value value = entry.getValue();\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo Binary Distribution\nDESCRIPTION: Commands to download and extract the Accumulo binary distribution package.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntar xzf /path/to/accumulo-{{ page.latest_release}}-bin.tar.gz\ncd accumulo-{{ page.latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Writing Data with BatchWriter\nDESCRIPTION: Demonstrates using BatchWriter with try-with-resources to write a mutation to a table. This pattern ensures proper resource cleanup after writing operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"mytable\")) {\n  Mutation m = new Mutation(\"row1\");\n  m.at().family(\"myfam\").qualifier(\"myqual\").visibility(\"public\").put(\"myval\");\n  writer.addMutation(m);\n}\n```\n\n----------------------------------------\n\nTITLE: Scanning with Authorizations in Accumulo\nDESCRIPTION: This snippet demonstrates attempting to scan data with authorizations, which fails because the user doesn't have the necessary authorizations assigned.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> scan\nusername@instance vistest> scan -s A\n06 11:43:14,951 [shell.Shell] ERROR: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_AUTHORIZATIONS - The user does not have the specified authorizations assigned\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Creating a Mutation Object with Row ID in Accumulo\nDESCRIPTION: Initializes a Mutation object with a row ID 'id0001'. In Accumulo, Mutation objects hold all changes to a row in a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/basic-read-write.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation1 = new Mutation(\"id0001\");\n```\n\n----------------------------------------\n\nTITLE: Using BatchScanner for Parallel Retrieval of Multiple Ranges\nDESCRIPTION: This code demonstrates how to use BatchScanner to efficiently retrieve multiple non-contiguous ranges simultaneously. BatchScanner allows parallel scanning across multiple tablet servers but does not guarantee sorted results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Range> ranges = new ArrayList<Range>();\n// populate list of ranges ...\n\ntry (BatchScanner bscan = client.createBatchScanner(\"table\", auths, 10)) {\n  bscan.setRanges(ranges);\n  bscan.fetchColumnFamily(\"attributes\");\n\n  for (Entry<Key,Value> entry : bscan) {\n    System.out.println(entry.getValue());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Removing the Versioning Iterator in Apache Accumulo (Java)\nDESCRIPTION: This snippet demonstrates how to remove the default versioning iterator ('vers') from a table to allow viewing historical data. It imports necessary packages and removes the iterator from all scopes of the 'GothamCrimeStats' table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\njshell> import org.apache.accumulo.core.iterators.IteratorUtil.IteratorScope;\njshell> client.tableOperations().removeIterator(\"GothamCrimeStats\", \"vers\", EnumSet.allOf(IteratorScope.class));\n```\n\n----------------------------------------\n\nTITLE: Scanning with Authorizations in Accumulo\nDESCRIPTION: This snippet demonstrates attempting to scan data with authorizations, which fails because the user doesn't have the necessary authorizations assigned.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> scan\nusername@instance vistest> scan -s A\n06 11:43:14,951 [shell.Shell] ERROR: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_AUTHORIZATIONS - The user does not have the specified authorizations assigned\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Scanning the Table with Accumulo Shell\nDESCRIPTION: Commands to select the 'hellotable' and scan all entries within it using the Accumulo shell. This displays all inserted data in the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Creating AccumuloClient from Java Properties Object\nDESCRIPTION: Creates an Accumulo client using a Java Properties object for configuration. This allows dynamically building connection properties at runtime.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nProperties props = new Properties()\nprops.put(\"instance.name\", \"myinstance\")\nprops.put(\"instance.zookeepers\", \"zookeeper1,zookeeper2\")\nprops.put(\"auth.type\", \"password\")\nprops.put(\"auth.principal\", \"myuser\")\nprops.put(\"auth.token\", \"mypassword\")\nAccumuloClient client = Accumulo.newClient().from(props).build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Durability for BatchWriter\nDESCRIPTION: Sets custom durability settings for a BatchWriter. This example shows how to configure NONE durability which provides no persistence guarantees but maximizes write performance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nBatchWriterConfig cfg = new BatchWriterConfig();\n// We don't care about data loss with these writes:\n// This is DANGEROUS:\ncfg.setDurability(Durability.NONE);\n\nBatchWriter bw = client.createBatchWriter(table, cfg);\n```\n\n----------------------------------------\n\nTITLE: Parallel Data Query with BatchScanner\nDESCRIPTION: Demonstrates using BatchScanner with 5 query threads to scan multiple ranges simultaneously and calculate average years of service. Shows how to set ranges and fetch specific columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/batch-scanner-code.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchScanner batchScanner = client.createBatchScanner(\"GothamBatch\", Authorizations.EMPTY, 5)) {\n\n  // Create a collection of 2 sample ranges and set it to the batchScanner\n  List<Range> ranges = new ArrayList<Range>();\n\n  // Create a collection of 2 sample ranges and set it to the batchScanner\n  ranges.add(new Range(\"id1000\", \"id1999\"));\n  ranges.add(new Range(\"id9000\", \"id9999\"));\n  batchScanner.setRanges(ranges);\n\n  // Fetch just the columns we want\n  batchScanner.fetchColumn(new Text(\"villain\"), new Text(\"yearsOfService\"));\n\n  // Calculate average years of service\n  long villianCount = batchScanner.stream().count();\n  Double average = batchScanner.stream().map(Map.Entry::getValue).map(Value::toString).mapToLong(Long::valueOf).average().getAsDouble();\n  System.out.println(\"The average years of service of \" + villianCount + \" villians is \" + average);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOff Filter in Accumulo using Shell Commands\nDESCRIPTION: This example demonstrates how to create a table and configure an AgeOff filter that removes data older than 30 seconds. It shows the creation of the filter, insertion of data, and the effect of the filter after waiting.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nuser@myinstance> createtable filtertest\n\nuser@myinstance filtertest> setiter -t filtertest -scan -minc -majc -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set org.apache.accumulo.core.iterators.user.AgeOffFilter parameter negate, default false\n                keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set org.apache.accumulo.core.iterators.user.AgeOffFilter parameter ttl, time to\n                live (milliseconds): 30000\n----------> set org.apache.accumulo.core.iterators.user.AgeOffFilter parameter currentTime, if set,\n                use the given value as the absolute time in milliseconds as the current time of day:\n\nuser@myinstance filtertest>\n\nuser@myinstance filtertest> scan\n\nuser@myinstance filtertest> insert foo a b c\n\nuser@myinstance filtertest> scan\nfoo a:b [] c\n\nuser@myinstance filtertest> sleep 4\n\nuser@myinstance filtertest> scan\n\nuser@myinstance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Creating a Mutation with Multiple Column Families in Accumulo\nDESCRIPTION: This example demonstrates how to create a Mutation object for a table row with multiple column families. It uses the userid as the row ID and stores different attributes (age, address, balance) in separate column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_design.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nMutation m = new Mutation(userid);\nm.at().family(\"age\").put(age);\nm.at().family(\"address\").put(address);\nm.at().family(\"balance\").put(account_balance);\nwriter.add(m);\n```\n\n----------------------------------------\n\nTITLE: Implementing SortedKeyValueIterator Interface in Accumulo\nDESCRIPTION: This code snippet shows the core interface methods that must be implemented when creating an Accumulo Iterator. These methods control how data flows through the iterator stack, including initialization, navigation, and accessing the current key-value pairs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/iterators.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nvoid init(SortedKeyValueIterator<Key,Value> source, Map<String,String> options, IteratorEnvironment env) throws IOException;\n\nboolean hasTop();\n\nvoid next() throws IOException;\n\nvoid seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException;\n\nKey getTopKey();\n\nValue getTopValue();\n\nSortedKeyValueIterator<Key,Value> deepCopy(IteratorEnvironment env);\n```\n\n----------------------------------------\n\nTITLE: Using BatchWriter to Write Mutations to Accumulo in Java\nDESCRIPTION: Demonstrates how to create and use a BatchWriter to efficiently send mutations to Accumulo. Includes configuration for memory buffer size, timeout, and number of threads.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nlong memBuf = 1000000L; // bytes to store before sending a batch\nlong timeout = 1000L; // milliseconds to wait before sending\nint numThreads = 10;\n\nBatchWriter writer =\n    conn.createBatchWriter(\"table\", memBuf, timeout, numThreads)\n\nwriter.add(mutation);\n\nwriter.close();\n```\n\n----------------------------------------\n\nTITLE: Retrieving Accumulo Instance ID\nDESCRIPTION: This snippet demonstrates how to retrieve the Accumulo instance ID using the AccumuloClient object. It uses the instanceOperations() method to get and print the instance ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/client.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\njshell> System.out.println(client.instanceOperations().getInstanceID());\n8b9839f7-cdc6-44ca-b527-43db45acc79f\n```\n\n----------------------------------------\n\nTITLE: Executing Accumulo Tasks in JShell\nDESCRIPTION: Example of performing Accumulo operations in JShell, including creating a table, adding data, and scanning the table. This snippet demonstrates the use of AccumuloClient, Mutation, BatchWriter, and Scanner.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-04-21-jshell-accumulo-feature.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// Create a table called \"GothamPD\".\nclient.tableOperations().create(\"GothamPD\");\n\n// Create a Mutation object to hold all changes to a row in a table.\n// Each row has a unique row ID.\nMutation mutation = new Mutation(\"id0001\");\n\n// Create key/value pairs for Batman. Put them in the \"hero\" family.\nmutation.put(\"hero\", \"alias\", \"Batman\");\nmutation.put(\"hero\", \"name\", \"Bruce Wayne\");\nmutation.put(\"hero\", \"wearsCape?\", \"true\");\n\n// Create a BatchWriter to the GothamPD table and add your mutation to it.\n// Try w/ resources will close for us.\ntry (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n    writer.addMutation(mutation);\n}\n\n// Read and print all rows of the \"GothamPD\" table.\n// Try w/ resources will close for us.\ntry (ScannerBase scan = client.createScanner(\"GothamPD\", Authorizations.EMPTY)) {\n  System.out.println(\"Gotham Police Department Persons of Interest:\");\n\n  // A Scanner is an extension of java.lang.Iterable so behaves just like one.\n  scan.forEach((k, v) -> System.out.printf(\"Key : %-50s Value : %s\\n\", k, v));\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOff Filter Iterator in Accumulo\nDESCRIPTION: Example showing how to create a table and configure an AgeOff filter iterator to remove data older than 30 seconds. Demonstrates the interactive iterator configuration process through the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance> createtable filtertest\nuser@myinstance filtertest> setiter -t filtertest -scan -minc -majc -p 10 -n myfilter -filter\n\nFilteringIterator uses Filters to accept or reject key/value pairs\n----------> entering options: <filterPriorityNumber> <ageoff|regex|filterClass>\n\n----------> set org.apache.accumulo.core.iterators.FilteringIterator option (<name> <value>, hit enter to skip): 0 ageoff\n\n----------> set org.apache.accumulo.core.iterators.FilteringIterator option (<name> <value>, hit enter to skip):\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n\n----------> set org.apache.accumulo.core.iterators.filter.AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\n\n----------> set org.apache.accumulo.core.iterators.filter.AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n```\n\n----------------------------------------\n\nTITLE: User Administration in Accumulo\nDESCRIPTION: This snippet demonstrates various user administration tasks in Accumulo, including creating a new user, authenticating a user, granting and revoking permissions, and switching between users in the shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/shell.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nroot@myinstance mytable> createuser bob\nEnter new password for 'bob': *********\nPlease confirm new password for 'bob': *********\n\nroot@myinstance mytable> authenticate bob\nEnter current password for 'bob': *********\nValid\n\nroot@myinstance mytable> grant System.CREATE_TABLE -s -u bob\n\nroot@myinstance mytable> user bob\nEnter current password for 'bob': *********\n\nbob@myinstance mytable> userpermissions\nSystem permissions: System.CREATE_TABLE\nTable permissions (accumulo.metadata): Table.READ\nTable permissions (mytable): NONE\n\nbob@myinstance mytable> createtable bobstable\n\nbob@myinstance bobstable>\n\nbob@myinstance bobstable> user root\nEnter current password for 'root': *********\n\nroot@myinstance bobstable> revoke System.CREATE_TABLE -s -u bob\n```\n\n----------------------------------------\n\nTITLE: Writing Data to Accumulo with BatchWriter\nDESCRIPTION: Creates a BatchWriter for the 'GothamPD' table and adds a mutation to it using try-with-resources for automatic closure. This is how data gets written to an Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/basic-read-write.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n   writer.addMutation(mutation1);\n }\n```\n\n----------------------------------------\n\nTITLE: Creating mutations for Batman character in Accumulo\nDESCRIPTION: Creates a Mutation for Batman with row ID 'id0001' and adds column family-qualifier pairs with values for the character's attributes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/data-model-code.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation1 = new Mutation(\"id0001\");\nmutation1.put(\"hero\",\"alias\", \"Batman\");\nmutation1.put(\"hero\",\"name\", \"Bruce Wayne\");\nmutation1.put(\"hero\",\"wearsCape?\", \"true\");\n```\n\n----------------------------------------\n\nTITLE: Setting Range on a Scanner for Efficient Querying in Accumulo\nDESCRIPTION: Example of setting a Range on a Scanner to limit data retrieval. This improves efficiency by only scanning keys that fall within the specified range rather than the entire table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/ranges-splits.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nscanner.setRange(new Range(\"id0000\", \"id0010\"));  // returns rows from id0000 to id0010\n```\n\n----------------------------------------\n\nTITLE: Generating Test Data with BatchWriter in Accumulo\nDESCRIPTION: Creates a dataset of 10,000 villain records in the 'GothamPD' table using BatchWriter. Each record includes an ID, alias, years of service, and a cape indicator.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/batch-scanner.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n   for (int i = 0; i < 10_000; i++) {\n     Mutation m = new Mutation(String.format(\"id%04d\", i));\n     m.put(\"villain\", \"alias\", \"henchman\" + i);\n     m.put(\"villain\", \"yearsOfService\", \"\" + (new Random().nextInt(50)));\n     m.put(\"villain\", \"wearsCape?\", \"false\");\n     writer.addMutation(m);\n   }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating AccumuloClient with Builder Methods\nDESCRIPTION: Creates an Accumulo client using builder methods to directly specify connection parameters. This approach allows programmatic configuration of the client.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient()\n                              .to(\"myinstance\", \"zookeeper1,zookeeper2\")\n                              .as(\"myuser\", \"mypassword\").build();\n```\n\n----------------------------------------\n\nTITLE: Reading Data Using Accumulo Scanner\nDESCRIPTION: Shows how to configure and use a Scanner to read data from Accumulo with specific authorizations, ranges, and column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n// specify which visibilities we are allowed to see\nAuthorizations auths = new Authorizations(\"public\");\n\nScanner scan =\n    conn.createScanner(\"table\", auths);\n\nscan.setRange(new Range(\"harry\",\"john\"));\nscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan) {\n    String row = e.getKey().getRow();\n    Value value = e.getValue();\n}\n```\n\n----------------------------------------\n\nTITLE: Using BatchScanner for Parallel Reads in Accumulo in Java\nDESCRIPTION: Demonstrates how to use a BatchScanner to retrieve multiple ranges of data in parallel from Accumulo, which is useful for non-consecutive row access patterns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Range> ranges = new ArrayList<Range>();\n// populate list of ranges ...\n\nBatchScanner bscan =\n    conn.createBatchScanner(\"table\", auths, 10);\n\nbscan.setRanges(ranges);\nbscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan)\n    System.out.println(e.getValue());\n```\n\n----------------------------------------\n\nTITLE: Creating a Mutation with Multiple Column Updates\nDESCRIPTION: Creates a Mutation object representing multiple column changes for a single row. This shows how to set column families, qualifiers, and visibilities.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation = new Mutation(\"row1\");\nmutation.at().family(\"myColFam1\").qualifier(\"myColQual1\").visibility(\"public\").put(\"myValue1\");\nmutation.at().family(\"myColFam2\").qualifier(\"myColQual2\").visibility(\"public\").put(\"myValue2\");\n```\n\n----------------------------------------\n\nTITLE: Setting Address in Accumulo using BatchWriter\nDESCRIPTION: This method sets an address in Accumulo using a BatchWriter. It creates a Mutation for the specified ID and adds it to the 'GothamPD' table. This method doesn't check for concurrent modifications.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nboolean setAddress(AccumuloClient client, String id, String expectedAddr, String newAddr) {\n  try (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n    Mutation mutation = new Mutation(id);\n    mutation.put(\"location\", \"home\", newAddr);\n    writer.addMutation(mutation);\n    return true;\n  } catch (Exception e) {\n    throw new RuntimeException(e);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Conditional Address Updates in Accumulo using ConditionalWriter\nDESCRIPTION: This method sets a new address for a given ID only if the current address matches the expected value. It uses Accumulo's ConditionalWriter to perform an atomic check-and-set operation. If expectedAddr is null, the method only checks for existence of the value.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer-code.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nboolean setAddress(AccumuloClient client, String id, String expectedAddr, String newAddr) {\n  try (ConditionalWriter writer = client.createConditionalWriter(\"GothamPD\", new ConditionalWriterConfig())) {\n    Condition condition = new Condition(\"location\", \"home\");\n    if (expectedAddr != null) {\n      condition.setValue(expectedAddr);\n    }\n    ConditionalMutation mutation = new ConditionalMutation(id, condition);\n    mutation.put(\"location\", \"home\", newAddr);\n    return writer.write(mutation).getStatus() == ConditionalWriter.Status.ACCEPTED;\n  } catch (Exception e) {\n    throw new RuntimeException();\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Address Modification in Accumulo\nDESCRIPTION: This method asynchronously modifies an address in Accumulo. It repeatedly reads the current address, applies a modifier function, and attempts to set the new address until successful.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nFuture<Void> modifyAddress(AccumuloClient client, String id, Function<String,String> modifier) throws Exception {\n  return CompletableFuture.runAsync(() -> {\n    String currAddr, newAddr;\n    do {\n      currAddr = getAddress(client, id);\n      newAddr = modifier.apply(currAddr);\n      System.out.printf(\"Thread %3d attempting change %20s -> %-20s\\n\",\n      Thread.currentThread().getId(), \"'\"+currAddr+\"'\", \"'\"+newAddr+\"'\");\n    } while (!setAddress(client, id, currAddr, newAddr));\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Granting Permissions via Java API\nDESCRIPTION: Shows how to grant system permissions programmatically using the SecurityOperations Java API. This example grants the CREATE_TABLE permission to user 'bob'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/permissions.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().grantSystem(\"bob\", SystemPermission.CREATE_TABLE);\n```\n\n----------------------------------------\n\nTITLE: Creating AccumuloClient using Properties File in Java\nDESCRIPTION: Code example showing how to create an AccumuloClient instance using the accumulo-client.properties configuration file. This demonstrates the standard way to establish a connection to Accumulo using client properties.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/files.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient().from(\"/path/to/accumulo-client.properties\").build();\n```\n\n----------------------------------------\n\nTITLE: Configuring and Attaching a SummingCombiner Iterator (Java)\nDESCRIPTION: This snippet shows how to create, configure, and attach a SummingCombiner iterator to a table. It sets up the iterator to sum values in the 'hero:villainsCaptured' column, checks for conflicts, and attaches it to the 'GothamCrimeStats' table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\njshell> IteratorSetting scSetting = new IteratorSetting(30, \"sum\", SummingCombiner.class);\njshell> LongCombiner.setEncodingType(scSetting, LongCombiner.Type.STRING);\njshell> scSetting.addOption(\"columns\", \"hero:villainsCaptured\");\njshell> client.tableOperations().checkIteratorConflicts(\"GothamCrimeStats\", scSetting, EnumSet.allOf(IteratorScope.class));\njshell> client.tableOperations().attachIterator(\"GothamCrimeStats\", scSetting);\n```\n\n----------------------------------------\n\nTITLE: Creating Authorization and Visibility Controls in Accumulo\nDESCRIPTION: Creates a 'secretId' authorization and visibility for securing data access. This demonstrates basic setup of security controls using Accumulo's authorization system.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nString secretId = \"secretId\";\nAuthorizations auths = new Authorizations(secretId);\nColumnVisibility colVis = new ColumnVisibility(secretId);\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Bulk Ingest Example with MapReduce\nDESCRIPTION: A sequence of commands that demonstrates the complete bulk ingest process in Accumulo. It sets up environment variables, creates a table with split points, generates test data in HDFS, performs the bulk ingest operation using MapReduce, and verifies that all rows were properly ingested.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ PKG=org.apache.accumulo.examples.simple.mapreduce.bulk\n$ ARGS=\"-i instance -z zookeepers -u username -p password\"\n$ ./bin/accumulo $PKG.SetupTable $ARGS -t test_bulk row_00000333 row_00000666\n$ ./bin/accumulo $PKG.GenerateTestData --start-row 0 --count 1000 --output bulk/test_1.txt\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar $PKG.BulkIngestExample $ARGS -t test_bulk --inputDir bulk --workDir tmp/bulkWork\n$ ./bin/accumulo $PKG.VerifyIngest $ARGS -t test_bulk --start-row 0 --count 1000\n```\n\n----------------------------------------\n\nTITLE: Logging into the Accumulo Shell\nDESCRIPTION: Command to log into the Accumulo shell with a username and password. This is required to execute commands on the Accumulo instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/helloworld.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Setting System Configuration via Java API\nDESCRIPTION: Shows how to set system-wide configuration properties using the Java API through InstanceOperations. This method allows programmatic access to configuration that overrides site configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclient.instanceOperations().setProperty(\"table.durability\", \"flush\");\n```\n\n----------------------------------------\n\nTITLE: Creating Mutations with Column Visibility Controls in Apache Accumulo\nDESCRIPTION: Creates three Mutation objects representing heroes and villains. Some columns are protected with 'secretId' column visibility, requiring specific authorization to view.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation1 = new Mutation(\"id0001\");\nmutation1.put(\"hero\", \"alias\", \"Batman\");\nmutation1.put(\"hero\", \"name\", colVis, \"Bruce Wayne\");\nmutation1.put(\"hero\", \"wearsCape?\", \"true\");\n\nMutation mutation2 = new Mutation(\"id0002\");\nmutation2.put(\"hero\", \"alias\", \"Robin\");\nmutation2.put(\"hero\", \"name\", colVis, \"Dick Grayson\");\nmutation2.put(\"hero\", \"wearsCape?\", \"true\");\n\nMutation mutation3 = new Mutation(\"id0003\");\nmutation3.put(\"villain\", \"alias\", \"Joker\");\nmutation3.put(\"villain\", \"name\", \"Unknown\");\nmutation3.put(\"villain\", \"wearsCape?\", \"false\");\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring Basic Row Sampling in Accumulo\nDESCRIPTION: This snippet demonstrates how to create a table, insert document data, and configure row-based sampling in Accumulo using the shell. The configuration causes Accumulo to include rows where murmur3_32(row) % 3 == 0 in the sample data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance sampex> createtable sampex\nroot@instance sampex> insert 9255 doc content 'abcde'\nroot@instance sampex> insert 9255 doc url file://foo.txt\nroot@instance sampex> insert 8934 doc content 'accumulo scales'\nroot@instance sampex> insert 8934 doc url file://accumulo_notes.txt\nroot@instance sampex> insert 2317 doc content 'milk, eggs, bread, parmigiano-reggiano'\nroot@instance sampex> insert 2317 doc url file://groceries/9.txt\nroot@instance sampex> insert 3900 doc content 'EC2 ate my homework'\nroot@instance sampex> insert 3900 doc uril file://final_project.txt\n\nroot@instance sampex> config -t sampex -s table.sampler.opt.hasher=murmur3_32\nroot@instance sampex> config -t sampex -s table.sampler.opt.modulus=3\nroot@instance sampex> config -t sampex -s table.sampler=org.apache.accumulo.core.client.sample.RowSampler\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Search with Intersecting Iterator in Apache Accumulo\nDESCRIPTION: This code demonstrates how to use BatchScanner with the Intersecting Iterator to efficiently search for documents containing multiple terms across sharded indexes in Accumulo. The example searches for documents containing all three terms: 'the', 'white', and 'house', performing the intersection operation on the server side rather than the client.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_design.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nText[] terms = {new Text(\"the\"), new Text(\"white\"), new Text(\"house\")};\n\ntry (BatchScanner bscan = client.createBatchScanner(table, auths, 20)) {\n\n  IteratorSetting iter = new IteratorSetting(20, \"ii\", IntersectingIterator.class);\n  IntersectingIterator.setColumnFamilies(iter, terms);\n\n  bscan.addScanIterator(iter);\n  bscan.setRanges(Collections.singleton(new Range()));\n\n  for (Entry<Key,Value> entry : bscan) {\n    System.out.println(\" \" + entry.getKey().getColumnQualifier());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring User Permissions in Accumulo\nDESCRIPTION: Creates a local user 'commissioner' with specific authorizations and table permissions. This shows how to set up user access controls and grant table-level permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().createLocalUser(\"commissioner\", new PasswordToken(\"gordonrocks\"));\nclient.securityOperations().changeUserAuthorizations(\"commissioner\", auths);\nclient.securityOperations().grantTablePermission(\"commissioner\", \"GothamPD\", TablePermission.READ);\n```\n\n----------------------------------------\n\nTITLE: Fetching Column Data for a Specific Row in Accumulo\nDESCRIPTION: Creates a scanner that retrieves a specific column family for a single row ID. This code demonstrates how to query a specific user's data by setting a precise Range and filtering by column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Design.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nRange r = new Range(userid, userid); // single row\nScanner s = conn.createScanner(\"userdata\", auths);\ns.setRange(r);\ns.fetchColumnFamily(new Text(\"age\"));\n\nfor(Entry<Key,Value> entry : s)\n    System.out.println(entry.getValue().toString());\n```\n\n----------------------------------------\n\nTITLE: Creating an Accumulo Client using the New Fluent API\nDESCRIPTION: Example of the new fluent API for creating Accumulo clients that replaces the deprecated Connector and ZooKeeperInstance objects. The new API uses AccumuloClient created from the Accumulo entry point.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2019-08-02-accumulo-2.0.0.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient()\n    .to(\"instance\", \"zookeepers\")\n    .as(\"user\", \"password\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing Standard Accumulo Connection in Java\nDESCRIPTION: Standard code for initializing a connection to a real Accumulo instance using ZooKeeperInstance. This is the typical pattern used in production applications.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nInstance instance = new ZooKeeperInstance(...);\nConnector conn = instance.getConnector(user, passwd);\n```\n\n----------------------------------------\n\nTITLE: Reading from Accumulo using AccumuloInputFormat\nDESCRIPTION: Java code demonstrating how to read data from an Accumulo table into a Spark RDD using AccumuloInputFormat. Configures the job and creates a JavaPairRDD containing Key-Value pairs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/spark.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nJob job = Job.getInstance();\nAccumuloInputFormat.configure().clientProperties(props).table(inputTable).store(job);\nJavaPairRDD<Key,Value> data = sc.newAPIHadoopRDD(job.getConfiguration(),\n    AccumuloInputFormat.class, Key.class, Value.class);\n```\n\n----------------------------------------\n\nTITLE: Using Scanner to Read Data from Accumulo in Java\nDESCRIPTION: Shows how to create and configure a Scanner to read data from Accumulo, including setting authorization, range constraints, and filtering for specific column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n// specify which visibilities we are allowed to see\nAuthorizations auths = new Authorizations(\"public\");\n\nScanner scan =\n    conn.createScanner(\"table\", auths);\n\nscan.setRange(new Range(\"harry\",\"john\"));\nscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan) {\n    String row = e.getKey().getRow();\n    Value value = e.getValue();\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing Client Properties in JShell\nDESCRIPTION: This snippet demonstrates how to view the properties used to create the Accumulo client in JShell. It shows the location of the client properties file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/client.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\njshell> /vars\n|    URL clientPropUrl = file:<path_to_accumulo-client.properties file>\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring AgeOffFilter in Accumulo\nDESCRIPTION: Shows the process of creating a table and setting up an AgeOffFilter with a 30-second TTL for scan operations. Demonstrates basic insert and scan operations to show the filter's effect.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Scanning a Specific Row and Column Family in Accumulo\nDESCRIPTION: This snippet shows how to retrieve data for a specific user by creating a Range for a single row ID and fetching a specific column family. It demonstrates connecting to Accumulo, setting up a Scanner with authorization, and iterating through results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_design.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient()\n                          .from(\"/path/to/accumulo-client.properties\").build();\nRange r = new Range(userid, userid); // single row\nScanner s = client.createScanner(\"userdata\", auths);\ns.setRange(r);\ns.fetchColumnFamily(\"age\");\n\nfor (Entry<Key,Value> entry : s) {\n  System.out.println(entry.getValue().toString());\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Sampler in Java\nDESCRIPTION: To use sampling, an Accumulo table must be configured with a class implementing the Sampler interface. This snippet shows how to set up a Sampler on a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/sampling.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\ntable.setSamplerConfiguration(new SamplerConfiguration(MySampler.class.getName())\n    .addOption(\"optionKey\", \"optionValue\"));\n```\n\n----------------------------------------\n\nTITLE: Random Batch Scanning in Accumulo\nDESCRIPTION: Command to perform 100 random queries on the written data using RandomBatchScanner. Configures scan threads and authentication parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/batch.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -i instance -z zookeepers -u username -p password -t batchtest1 --num 100 --min 0 --max 10000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Configuring MapReduce Job for RFile Output\nDESCRIPTION: This Java code demonstrates how to configure a MapReduce job to write output as RFiles in HDFS using AccumuloFileOutputFormat.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/mapreduce.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nJob job = Job.getInstance();\njob.setOutputFormatClass(AccumuloFileOutputFormat.class);\nAccumuloFileOutputFormat.configure()\n    .outputPath(new Path(\"hdfs://localhost:8020/myoutput/\")).store(job);\n```\n\n----------------------------------------\n\nTITLE: Using Index Table and BatchScanner for Efficient Lookups in Accumulo\nDESCRIPTION: This code demonstrates a two-step lookup process using an index table. It first scans the index to find matching row IDs, then uses a BatchScanner to efficiently retrieve those rows from the main table in parallel.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_design.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nHashSet<Range> matchingRows = new HashSet<Range>();\n\n// first we scan the index for IDs of rows matching our query\ntry (Scanner indexScanner = client.createScanner(\"index\", auths)) {\n  indexScanner.setRange(Range.exact(\"mySearchTerm\");\n\n  // we retrieve the matching rowIDs and create a set of ranges\n  for (Entry<Key,Value> entry : indexScanner) {\n    matchingRows.add(new Range(entry.getKey().getColumnQualifier()));\n  }\n}\n\n// now we pass the set of rowIDs to the batch scanner to retrieve them\ntry (BatchScanner bscan = client.createBatchScanner(\"table\", auths, 10)) {\n  bscan.setRanges(matchingRows);\n  bscan.fetchColumnFamily(\"attributes\");\n\n  for (Entry<Key,Value> entry : bscan) {\n    System.out.println(entry.getValue());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Mutations for Writing Data to Accumulo in Java\nDESCRIPTION: Shows how to create a Mutation object to write data to Accumulo, including setting row ID, column family, column qualifier, visibility, timestamp, and value.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nText rowID = new Text(\"row1\");\nText colFam = new Text(\"myColFam\");\nText colQual = new Text(\"myColQual\");\nColumnVisibility colVis = new ColumnVisibility(\"public\");\nlong timestamp = System.currentTimeMillis();\n\nValue value = new Value(\"myValue\".getBytes());\n\nMutation mutation = new Mutation(rowID);\nmutation.put(colFam, colQual, colVis, timestamp, value);\n```\n\n----------------------------------------\n\nTITLE: Querying Sampled Document Data in Accumulo\nDESCRIPTION: This snippet demonstrates how to query document data using sampling to estimate result sizes before performing full queries. It shows both regular and sample querying, and introduces the CutoffIntersectingIterator for query optimization.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query --sample -i instance16 -z localhost -t shard -u root -p secret import int | fgrep '.java' | wc\n     11      11    1246\n\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query -i instance16 -z localhost -t shard -u root -p secret import int | fgrep '.java' | wc\n   1085    1085  118175\n\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query --sampleCutoff 1000 -i instance16 -z localhost -t shard -u root -p secret import int | fgrep '.java' | wc\n```\n\n----------------------------------------\n\nTITLE: Viewing Accumulo Instances in ZooKeeper\nDESCRIPTION: Command example showing how to list all Accumulo instances and their IDs stored in ZooKeeper using the zoo-info-viewer tool.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo zoo-info-viewer --print-instances\n\n-----------------------------------------------\nReport Time: 2022-05-31T21:07:19.673258Z\n-----------------------------------------------\nInstances (Instance Name, Instance ID)\ntest_a=1111465d-b7bb-42c2-919b-111111111111\ntest_b=2222465d-b7bb-42c2-919b-222222222222\nuno=9cc9465d-b7bb-42c2-919b-ddf74b610c82\n\n-----------------------------------------------\n```\n\n----------------------------------------\n\nTITLE: Writing Data to Accumulo Table via Proxy\nDESCRIPTION: Demonstrates the process of writing data to an Accumulo table using a writer instance. Shows creation of writer, updating cells, and proper cleanup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\n// first, create a writer on the server\nString writer = client.createWriter(token, \"myTable\", new WriterOptions());\n\n// build column updates\nMap<ByteBuffer, List<ColumnUpdate> cells> cellsToUpdate = //...\n\n// send updates to the server\nclient.updateAndFlush(writer, \"myTable\", cellsToUpdate);\n\nclient.closeWriter(writer);\n```\n\n----------------------------------------\n\nTITLE: Creating Users in Accumulo Shell\nDESCRIPTION: Command to create a new user 'bob' in the Accumulo shell. The command prompts for a password and confirmation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> createuser bob\nEnter new password for 'bob': ****\nPlease confirm new password for 'bob': ****\n```\n\n----------------------------------------\n\nTITLE: Creating a New Table in Accumulo\nDESCRIPTION: The 'createtable' command is used to create a new table in Accumulo. This example creates a table named 'mytable'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/shell.md#2025-04-11_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nroot@myinstance> createtable mytable\nroot@myinstance mytable> tables\naccumulo.metadata\naccumulo.root\nmytable\n```\n\n----------------------------------------\n\nTITLE: Listing Default Accumulo Tables\nDESCRIPTION: This code snippet shows how to use the AccumuloClient object to list the default tables in Accumulo. It uses the tableOperations() method to retrieve and print the table names.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/client.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\njshell> client.tableOperations().list().forEach(System.out::println);\naccumulo.metadata\naccumulo.replication\naccumulo.root\n```\n\n----------------------------------------\n\nTITLE: Configuring MapReduce Job for Accumulo Output\nDESCRIPTION: This Java code shows how to set up a MapReduce job to write output to an Accumulo table using AccumuloOutputFormat.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/mapreduce.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nJob job = Job.getInstance();\njob.setOutputFormatClass(AccumuloOutputFormat.class);\nProperties props = Accumulo.newClientProperties().to(\"myinstance\",\"zoo1,zoo2\")\n                        .as(\"user\", \"passwd\").build();\nAccumuloOutputFormat.configure().clientProperties(props)\n    .defaultTable(\"mytable\").store(job);\n```\n\n----------------------------------------\n\nTITLE: Scanning Sample Data in Java\nDESCRIPTION: To scan sample data, use the setSamplerConfiguration() method of Scanner or BatchScanner. This snippet demonstrates how to set up a scanner to read sample data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/sampling.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nScanner scanner = client.createScanner(table, auths);\nscanner.setSamplerConfiguration(new SamplerConfiguration(MySampler.class.getName()));\n```\n\n----------------------------------------\n\nTITLE: Implementing Yielding Interface in Accumulo Iterator (Java)\nDESCRIPTION: Shows how to implement the optional YieldingKeyValueIterator interface in an Accumulo Iterator to enable yielding control during long-running operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/iterators.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\ndefault void enableYielding(YieldCallback callback) { }\n```\n\n----------------------------------------\n\nTITLE: Scanning data with authorizations in Accumulo\nDESCRIPTION: This snippet shows how to scan data with specific authorizations. It demonstrates that users can only scan data for which they have the required authorizations, and that these authorizations must be explicitly granted.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> scan\nusername@instance vistest> scan -s A\n06 11:43:14,951 [shell.Shell] ERROR: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_AUTHORIZATIONS - The user does not have the specified authorizations assigned\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Running TokenFileWordCount Example with Manual Token Handling\nDESCRIPTION: Command to run the TokenFileWordCount example which demonstrates manually handling the token file without using the Opts class for argument parsing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TokenFileWordCount instance zookeepers username tokenfile /user/username/wc wordCount\n```\n\n----------------------------------------\n\nTITLE: Setting Namespace Configuration via Java API\nDESCRIPTION: Demonstrates setting configuration properties for a table namespace using the Java API through NamespaceOperations. These settings override system configuration and apply to all tables in the namespace.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclient.namespaceOperations().setProperty(\"mynamespace\", \"table.durability\", \"sync\");\n```\n\n----------------------------------------\n\nTITLE: Running Data Reader Program\nDESCRIPTION: Command to execute the Java ReadData program that reads entries from the 'hellotable' within a specified key range. The command includes connection parameters and start/end keys for the scan range.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.ReadData -i instance -z zookeepers -u username -p password -t hellotable --startKey row_0 --endKey row_1001\n```\n\n----------------------------------------\n\nTITLE: Managing Locality Groups with Java Client API\nDESCRIPTION: Example showing how to programmatically set and retrieve locality groups for an Accumulo table using the client API. Creates separate groups for metadata and content column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient()\n                          .from(\"/path/to/accumulo-client.properties\").build();\n\nHashMap<String,Set<Text>> localityGroups = new HashMap<String, Set<Text>>();\n\nHashSet<Text> metadataColumns = new HashSet<Text>();\nmetadataColumns.add(new Text(\"domain\"));\nmetadataColumns.add(new Text(\"link\"));\n\nHashSet<Text> contentColumns = new HashSet<Text>();\ncontentColumns.add(new Text(\"body\"));\ncontentColumns.add(new Text(\"images\"));\n\nlocalityGroups.put(\"metadata\", metadataColumns);\nlocalityGroups.put(\"content\", contentColumns);\n\nclient.tableOperations().setLocalityGroups(\"mytable\", localityGroups);\n\n// existing locality groups can be obtained as follows\nMap<String, Set<Text>> groups = client.tableOperations().getLocalityGroups(\"mytable\");\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using SummingCombiner in Accumulo\nDESCRIPTION: This example shows how to set up a SummingCombiner for a table, which aggregates values with the same row ID, column family, and qualifier. The example demonstrates inserting multiple values and seeing the combined results during a scan.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nroot@a14 perDayCounts> setiter -t perDayCounts -p 10 -scan -minc -majc -n daycount\n                       -class org.apache.accumulo.core.iterators.user.SummingCombiner\nTypedValueCombiner can interpret Values as a variety of number encodings\n  (VLong, Long, or String) before combining\n----------> set SummingCombiner parameter columns,\n            <col fam>[:<col qual>]{,<col fam>[:<col qual>]} : day\n----------> set SummingCombiner parameter type, <VARNUM|LONG|STRING>: STRING\n\nroot@a14 perDayCounts> insert foo day 20080101 1\nroot@a14 perDayCounts> insert foo day 20080101 1\nroot@a14 perDayCounts> insert foo day 20080103 1\nroot@a14 perDayCounts> insert bar day 20080101 1\nroot@a14 perDayCounts> insert bar day 20080101 1\n\nroot@a14 perDayCounts> scan\nbar day:20080101 []    2\nfoo day:20080101 []    2\nfoo day:20080103 []    1\n```\n\n----------------------------------------\n\nTITLE: Creating a User with Specific Authorizations in Apache Accumulo\nDESCRIPTION: Creates a new user 'commissioner' with a password, grants them the 'secretId' authorization, and permits them to read from the 'GothamPD' table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().createLocalUser(\"commissioner\", new PasswordToken(\"gordonrocks\"));\nclient.securityOperations().changeUserAuthorizations(\"commissioner\", auths);\nclient.securityOperations().grantTablePermission(\"commissioner\", \"GothamPD\", TablePermission.READ);\n```\n\n----------------------------------------\n\nTITLE: Setting Iterators via the Shell in Accumulo\nDESCRIPTION: Demonstrates how to set iterators using the Accumulo shell. Iterators provide a mechanism for adding functionality that executes on TabletServers when scanning or compacting data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusage: setiter [-?] -agg | -class <name> | -filter | -nolabel | \n-regex | -vers [-majc] [-minc] [-n <itername>] -p <pri> [-scan] \n[-t <table>]\n\nuser@myinstance mytable> setiter -t mytable -scan -p 10 -n myiter\n```\n\n----------------------------------------\n\nTITLE: Writing Mutations to a Table Using BatchWriter in Apache Accumulo\nDESCRIPTION: Uses a BatchWriter to write multiple mutations to the 'GothamPD' table in a single batch operation. The try-with-resources pattern ensures the writer is properly closed after use.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"GothamPD\")) {\n  writer.addMutation(mutation1);\n  writer.addMutation(mutation2);\n  writer.addMutation(mutation3);\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Iterators Programmatically in Java\nDESCRIPTION: Examples demonstrating how to add iterators to an Accumulo scanner programmatically, including setting iterator options.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nscanner.addIterator(new IteratorSetting(\n    15, // priority\n    \"myiter\", // name this iterator\n    \"com.company.MyIterator\" // class name\n));\n```\n\nLANGUAGE: java\nCODE:\n```\nIteratorSetting iter = new IteratorSetting(...);\niter.addOption(\"myoptionname\", \"myoptionvalue\");\nscanner.addIterator(iter)\n```\n\n----------------------------------------\n\nTITLE: Markdown Client Properties Table\nDESCRIPTION: A markdown table listing all available Accumulo client properties with their default values, version information, and descriptions. Includes properties for instance configuration, authentication, batch writing/scanning, SSL, SASL, and tracing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/client-properties.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Property | Default value | Since | Description |\n|----------|---------------|-------|-------------|\n| instance.name | *empty* | 2.0.0 | Name of Accumulo instance to connect to |\n| instance.zookeepers | localhost:2181 | 2.0.0 | Zookeeper connection information for Accumulo instance |\n| instance.zookeepers.timeout | 30s | 2.0.0 | Zookeeper session timeout |\n| auth.type | password | 2.0.0 | Authentication method (i.e password, kerberos, PasswordToken, KerberosToken, etc) |\n| auth.principal | *empty* | 2.0.0 | Accumulo principal/username for chosen authentication method |\n| auth.token | *empty* | 2.0.0 | Authentication token (ex. mypassword, /path/to/keytab) |\n```\n\n----------------------------------------\n\nTITLE: Creating Users with Java API\nDESCRIPTION: Java code to create a new local user 'bob' with password 'pass' using the SecurityOperations interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().createLocalUser(\"bob\", new PasswordToken(\"pass\"));\n```\n\n----------------------------------------\n\nTITLE: Creating an Accumulo Table in Java\nDESCRIPTION: Creates a new table named 'GothamPD' using Accumulo's tableOperations interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/basic-read-write.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().create(\"GothamPD\");\n```\n\n----------------------------------------\n\nTITLE: Writing Data with Security Labels in Accumulo\nDESCRIPTION: Example showing how to write data to Accumulo with different security labels using BatchWriter and Mutation objects. The snippet demonstrates setting different visibility labels ('payroll' and 'public') for different column qualifiers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authorizations.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"employees\")) {\n  Mutation mut = new Mutation(\"employee1\");\n  mut.at().family(\"pay\").qualifier(\"salary\").visibility(\"payroll\").value(\"50000\");\n  mut.at().family(\"pay\").qualifier(\"period\").visibility(\"public\").value(\"monthly\");\n  writer.addMutation(mut)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Scanner in Accumulo\nDESCRIPTION: This snippet demonstrates how to create a basic Scanner using AccumuloClient to iterate over keys and values in a table. It uses all authorizations granted to the user that created the AccumuloClient.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nScanner s = client.createScanner(\"table\");\n```\n\n----------------------------------------\n\nTITLE: Handling Re-seek Scenario in Accumulo TabletServer (Java)\nDESCRIPTION: Demonstrates how to handle the 're-seek' case in Accumulo TabletServer when a client resumes fetching data after a pause.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/iterators.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n// Given the above\nList<KeyValue> batch = getNextBatch();\n\n// thread goes away (client stops asking for the next batch).\n\n// Eventually client comes back\n// Setup as before...\nRange userRange = getRangeFromClient();\nRange actualRange = new Range(getLastKeyReturned(), false, userRange.getEndKey(), userRange.isEndKeyInclusive());\n\n// Use the actualRange, not the user provided one\ntopIter.seek(actualRange);\n```\n\n----------------------------------------\n\nTITLE: Sample FATE Summary Output in Accumulo\nDESCRIPTION: Example output from the FATE summary command showing active transactions, their status, command types, step information, and lock details. This output helps administrators understand ongoing FATE operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/fate.md#2025-04-11_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nReport Time: 2022-07-07T11:42:02Z\nStatus counts:\n  IN_PROGRESS: 2\n\nCommand counts:\n  CompactRange: 2\n\nStep counts:\n  CompactionDriver: 2\n\nFate transactions (oldest first):\nStatus Filters: [NONE]\n\nRunning txn_id              Status      Command         Step (top)          locks held:(table id, name)             locks waiting:(table id, name)\n0:00:04 0c143900c230c1df    IN_PROGRESS CompactRange    CompactionDriver    held:[R:(1,ns:ns1), R:(2,t:ns1.table1)] waiting:[]\n0:00:03 55f59a2ae838e19e    IN_PROGRESS CompactRange    CompactionDriver    held:[R:(1,ns:ns1), R:(2,t:ns1.table1)] waiting:[]\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Apache Accumulo\nDESCRIPTION: Creates a new table named 'GothamPD' that will be used to store data with different authorization levels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().create(\"GothamPD\");\n```\n\n----------------------------------------\n\nTITLE: Scanning Table in Accumulo Shell\nDESCRIPTION: Commands to select a table and scan all its entries using the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Converting ZooKeeper Property Storage Format in Accumulo 2.1\nDESCRIPTION: Command to run the config-upgrade utility which converts the ZooKeeper property storage from many nodes to a single node per table, namespace, and system configuration. This step is optional as it occurs automatically at startup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo config-upgrade\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Authentication Token with Explicit Parameters\nDESCRIPTION: Command to create a token file with explicit parameters rather than interactive prompts. This creates a PasswordToken for user 'root' with password 'secret' and saves it to 'root.pw'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo create-token -u root -p secret -f root.pw\n```\n\n----------------------------------------\n\nTITLE: Adding Accumulo Core Dependency in Maven\nDESCRIPTION: Maven dependency configuration needed to include Accumulo core library in client projects. This dependency provides access to Accumulo's client API.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.apache.accumulo</groupId>\n  <artifactId>accumulo-core</artifactId>\n  <version>{{ page.latest_release }}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo Security with Kerberos\nDESCRIPTION: Commands to stop Accumulo cluster, reset security settings with Kerberos principal, and restart the cluster. This process replaces the default root user with a Kerberos-authenticated administrative user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_3\n\nLANGUAGE: console\nCODE:\n```\n$ accumulo-cluster stop\n...\n$ accumulo init --reset-security\nRunning against secured HDFS\nPrincipal (user) to grant administrative privileges to : acculumo_admin@EXAMPLE.COM\nEnter initial password for accumulo_admin@EXAMPLE.COM (this may not be applicable for your security setup):\nConfirm initial password for accumulo_admin@EXAMPLE.COM:\n$ accumulo-cluster start\n...\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Settings for a Table in Accumulo\nDESCRIPTION: This command demonstrates how to view the configured iterator settings for a table, showing the different scopes (majc, minc, scan) and the parameters for each iterator including the AgeOffFilter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nuser@example filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+------------------\n```\n\n----------------------------------------\n\nTITLE: Accessing Accumulo Shell\nDESCRIPTION: Command to log into the Accumulo shell with username and password authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/helloworld.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Restricting Accumulo to a set of row ranges in MapReduce in Java\nDESCRIPTION: Optional configuration for AccumuloInputFormat that restricts the input to specific row ranges. Creates an ArrayList of Range objects which define the row ID ranges to be processed.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Analytics.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Range> ranges = new ArrayList<Range>();\n// populate array list of row ranges ...\nAccumuloInputFormat.setRanges(job, ranges);\n```\n\n----------------------------------------\n\nTITLE: Displaying Accumulo Program Information\nDESCRIPTION: The 'about' command shows information about the Accumulo program. It has an option for displaying detailed session information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n**about**   \n\n    usage: about [-?] [-v]   \n    description: displays information about this program   \n      -?,-help  display this help   \n      -v,-verbose displays details session information   \n```\n\n----------------------------------------\n\nTITLE: Accessing the Accumulo Monitor Web Interface\nDESCRIPTION: URL pattern to access the Accumulo monitoring web interface which provides visibility into the cluster's status, performance metrics, and operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nhttp://<hostname in conf/monitor>:9995/\n```\n\n----------------------------------------\n\nTITLE: Logging into Accumulo Shell\nDESCRIPTION: Command to log into the Accumulo shell with a username and password authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Displaying Accumulo Program Information\nDESCRIPTION: The 'about' command shows information about the Accumulo program. It has an option for displaying detailed session information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n**about**   \n\n    usage: about [-?] [-v]   \n    description: displays information about this program   \n      -?,-help  display this help   \n      -v,-verbose displays details session information   \n```\n\n----------------------------------------\n\nTITLE: TabletServer Iterator Invocation Process in Accumulo (Java)\nDESCRIPTION: Outlines how TabletServers invoke Iterators in Accumulo, including setting up the iterator stack, processing batches of data, and handling yielding scenarios.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/iterators.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nList<KeyValue> batch;\nRange range = getRangeFromClient();\nwhile (!overSizeLimit(batch)) {\n    SortedKeyValueIterator source = getSystemIterator();\n\n    for (String clzName : getUserIterators()) {\n        Class<?> clz = Class.forName(clzName);\n        SortedKeyValueIterator iter = (SortedKeyValueIterator) clz.newInstance();\n        iter.init(source, opts, env);\n        source = iter;\n    }\n\n    // read a batch of data to return to client from\n    // the last iterator, the \"top\"\n    SortedKeyValueIterator topIter = source;\n\n    YieldCallback cb = new YieldCallback();\n    topIter.enableYielding(cb)\n\n    topIter.seek(range, ...)\n\n    while (topIter.hasTop() && !overSizeLimit(batch)) {\n        key = topIter.getTopKey()\n        val = topIter.getTopValue()\n        batch.add(new KeyValue(key, val)\n        // remember the last key returned\n        setLastKeyReturned(key);\n        if (systemDataSourcesChanged()) {\n            // code does not show isolation case, which will\n            // keep using same data sources until a row boundary is hit\n            range = new Range(key, false, range.endKey(), range.endKeyInclusive());\n            break;\n        }\n        topIter.next()\n    }\n\n    if (cb.hasYielded()) {\n        // remember the yield key as the last key returned\n        setLastKeyReturned(cb.getKey());\n        break;\n    }\n}\n//return batch of key values to client\n```\n\n----------------------------------------\n\nTITLE: Creating Test Data in Accumulo Shell\nDESCRIPTION: Commands to create a table named 'input' and insert sample data using the Accumulo shell. This creates two rows with the same column family and qualifier.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/rowhash.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert a-row cf cq value\nusername@instance> insert b-row cf cq value\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Initializing MiniAccumuloCluster\nDESCRIPTION: Code to initialize and start a MiniAccumuloCluster instance for testing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/development_tools.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nFile tempDirectory = // JUnit and Guava supply mechanisms for creating temp directories\nMiniAccumuloCluster mac = new MiniAccumuloCluster(tempDirectory, \"password\");\nmac.start();\n```\n\n----------------------------------------\n\nTITLE: Configuring MapReduce Job for Accumulo Input\nDESCRIPTION: This Java code demonstrates how to configure a MapReduce job to read input from an Accumulo table using AccumuloInputFormat.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/mapreduce.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nJob job = Job.getInstance();\njob.setInputFormatClass(AccumuloInputFormat.class);\nProperties props = Accumulo.newClientProperties().to(\"myinstance\",\"zoo1,zoo2\")\n                        .as(\"user\", \"passwd\").build();\nAccumuloInputFormat.configure().clientProperties(props).table(table).store(job);\n```\n\n----------------------------------------\n\nTITLE: Starting the Accumulo Shell\nDESCRIPTION: Command to start the Accumulo Shell, prompting for a username. The shell will then ask for the corresponding password.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Accumulo_Shell.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo shell -u [username]\n```\n\n----------------------------------------\n\nTITLE: Listing Accumulo 2.0.0 Configuration Files\nDESCRIPTION: Displays the reduced set of configuration files in the conf directory for Accumulo 2.0.0, showing the simplification effort.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ls accumulo-2.0.0/conf/\naccumulo-env.sh  accumulo-site.xml  client.conf  log4j-monitor.properties  log4j.properties  log4j-service.properties  templates\n```\n\n----------------------------------------\n\nTITLE: Table Export and Import Example in Accumulo\nDESCRIPTION: Demonstrates the process of creating, exporting, and importing a table including data insertion, split configuration, and verification of preserved table properties.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nroot@test15> createtable table1\nroot@test15 table1> insert a cf1 cq1 v1\nroot@test15 table1> insert h cf1 cq1 v2\nroot@test15 table1> insert z cf1 cq1 v3\nroot@test15 table1> insert z cf1 cq2 v4\nroot@test15 table1> addsplits -t table1 b r\nroot@test15 table1> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test15> config -t table1 -s table.split.threshold=100M\nroot@test15 table1> clonetable table1 table1_exp\nroot@test15 table1> offline table1_exp\nroot@test15 table1> exporttable -t table1_exp /tmp/table1_export\nroot@test15 table1> quit\n```\n\n----------------------------------------\n\nTITLE: Creating a Scanner with User Authorizations in Accumulo\nDESCRIPTION: This example shows how to create a Scanner with specific authorizations in Accumulo. It demonstrates creating an Authorization object with multiple access levels ('admin' and 'system') and using it to initialize a Scanner.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Security.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// user possess both admin and system level access\nAuthorization auths = new Authorization(\"admin\",\"system\");\n\nScanner s = connector.createScanner(\"table\", auths);\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Table Clone Operations in Accumulo Shell\nDESCRIPTION: Shows how to create a table, insert data, and clone it. Demonstrates that data inserted after cloning is only visible in the original table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nroot@a14> createtable people\n\nroot@a14 people> insert 890435 name last Doe\nroot@a14 people> insert 890435 name first John\n\nroot@a14 people> clonetable people test\n\nroot@a14 people> insert 890436 name first Jane\nroot@a14 people> insert 890436 name last Doe\n\nroot@a14 people> scan\n890435 name:first []    John\n890435 name:last []    Doe\n890436 name:first []    Jane\n890436 name:last []    Doe\n\nroot@a14 people> table test\n\nroot@a14 test> scan\n890435 name:first []    John\n890435 name:last []    Doe\n\nroot@a14 test>\n```\n\n----------------------------------------\n\nTITLE: Using BatchWriter to Write Data to Accumulo\nDESCRIPTION: Demonstrates configuring and using a BatchWriter to efficiently send mutations to Accumulo TabletServers with memory buffer, timeout, and thread settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nlong memBuf = 1000000L; // bytes to store before sending a batch\nlong timeout = 1000L; // milliseconds to wait before sending\nint numThreads = 10;\n\nBatchWriter writer =\n    conn.createBatchWriter(\"table\", memBuf, timeout, numThreads)\n\nwriter.add(mutation);\n\nwriter.close();\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with BatchWriter in Java\nDESCRIPTION: Command to execute the Java program that inserts 50K entries into the 'hellotable' using a BatchWriter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithBatchWriter -i instance -z zookeepers -u username -p password -t hellotable\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo Connection in Java\nDESCRIPTION: Code to establish initial connection to an Accumulo instance using ZooKeeper servers and authentication credentials.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nString instanceName = \"myinstance\";\nString zooServers = \"zooserver-one,zooserver-two\"\nInstance inst = new ZooKeeperInstance(instanceName, zooServers);\n\nConnector conn = new Connector(inst, \"user\",\"passwd\".getBytes());\n```\n\n----------------------------------------\n\nTITLE: Granting Permissions via Accumulo Shell\nDESCRIPTION: Demonstrates how to grant system-level permissions to a user using the Accumulo shell command line interface. This example grants the CREATE_TABLE permission to user 'bob'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/permissions.md#2025-04-11_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> grant System.CREATE_TABLE -s -u bob\n```\n\n----------------------------------------\n\nTITLE: Configuring VFS Classpath Context\nDESCRIPTION: Sets up a classpath context 'cx1' pointing to the HDFS directory containing the filter JAR\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/classpath.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s general.vfs.context.classpath.cx1=hdfs://<namenode host>:<namenode port>/user1/lib/[^.].*.jar\n```\n\n----------------------------------------\n\nTITLE: Generating RFiles with Sample Data for Bulk Import in Java\nDESCRIPTION: When generating RFiles for bulk import, sample data can be included. This snippet demonstrates how to configure AccumuloFileOutputFormat to include sample data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/sampling.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nAccumuloFileOutputFormat.configure()\n    .sampler(new SamplerConfiguration(MySampler.class.getName()))\n    .store(job);\n```\n\n----------------------------------------\n\nTITLE: Formatting HDFS NameNode for Multi-node Setup\nDESCRIPTION: This command formats the HDFS NameNode, which is necessary before starting Hadoop services in a multi-node setup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nsudo -u hdfs hdfs namenode -format\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with MapReduce\nDESCRIPTION: Command to run a Java program that inserts data into Accumulo using MapReduce output format.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithOutputFormat instance zookeepers username password hellotable\n```\n\n----------------------------------------\n\nTITLE: Viewing User Permissions via Shell\nDESCRIPTION: Shows how to list all permissions for a specific user using the Accumulo shell. This displays system, namespace, and table permissions for user 'bob'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/permissions.md#2025-04-11_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> userpermissions -u bob\nSystem permissions: System.CREATE_TABLE, System.DROP_TABLE\n\nNamespace permissions (accumulo): Namespace.READ\n\nTable permissions (accumulo.metadata): Table.READ\nTable permissions (accumulo.replication): Table.READ\nTable permissions (accumulo.root): Table.READ\n```\n\n----------------------------------------\n\nTITLE: Viewing Extracted Table Data from HDFS\nDESCRIPTION: Command to display the contents of the output file containing the extracted key-value pairs from the Accumulo table, showing only the rows with the specified column.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/tabletofile.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -text /tmp/output/output/part-m-00000\ncatrow cf:cq []    catvalue\ndogrow cf:cq []    dogvalue\n$\n```\n\n----------------------------------------\n\nTITLE: Listing Classpath in Accumulo Shell\nDESCRIPTION: The 'classpath' command lists the current files on the classpath in the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n**classpath**   \n\n    usage: classpath [-?]   \n    description: lists the current files on the classpath   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Building and Querying Sample Data in Accumulo\nDESCRIPTION: This snippet shows the process of building sample data for an existing table, handling errors when sampling isn't properly configured, and scanning sample data. It demonstrates updating data and how changes are reflected in the sample.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance sampex> scan --sample\n2015-09-09 12:21:50,643 [shell.Shell] ERROR: org.apache.accumulo.core.client.SampleNotPresentException: Table sampex(ID:2) does not have sampling configured or built\n\nroot@instance sampex> compact -t sampex --sf-no-sample\n\nroot@instance sampex> scan --sample\n2317 doc:content []    milk, eggs, bread, parmigiano-reggiano\n2317 doc:url []    file://groceries/9.txt\n\nroot@instance sampex> insert 2317 doc content 'milk, eggs, bread, parmigiano-reggiano, butter'\nroot@instance sampex> scan --sample\n2317 doc:content []    milk, eggs, bread, parmigiano-reggiano, butter\n2317 doc:url []    file://groceries/9.txt\n```\n\n----------------------------------------\n\nTITLE: Creating mutations for Robin character in Accumulo\nDESCRIPTION: Creates a Mutation for Robin with row ID 'id0002' and adds column family-qualifier pairs with values for the character's attributes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/data-model-code.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation2 = new Mutation(\"id0002\");\nmutation2.put(\"hero\",\"alias\", \"Robin\");\nmutation2.put(\"hero\",\"name\", \"Dick Grayson\");\nmutation2.put(\"hero\",\"wearsCape?\", \"true\");\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Cluster Configuration\nDESCRIPTION: Command to create default cluster configuration files from templates.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-cluster create-config\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Users\nDESCRIPTION: The 'createuser' command creates a new user in Accumulo. It allows specifying scan authorizations for the user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n**createuser**   \n\n    usage: createuser <username> [-?] [-s <comma-separated-authorizations>]   \n    description: creates a new user   \n      -?,-help  display this help   \n      -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations   \n```\n\n----------------------------------------\n\nTITLE: Pre-splitting Tables Using Shell Command in Accumulo\nDESCRIPTION: Demonstrates how to pre-split an Accumulo table using the shell command to create multiple tablets before ingest begins. Pre-splitting ensures optimal parallelism by distributing tablets across TabletServers from the start.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/high_speed_ingest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuser@myinstance mytable> addsplits -sf /local_splitfile -t mytable\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with BatchWriter in Java\nDESCRIPTION: Command to run a Java program that inserts data into Accumulo using a BatchWriter. It inserts 10K rows with 5 entries each.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithBatchWriter -i instance -z zookeepers -u username -p password -t hellotable\n```\n\n----------------------------------------\n\nTITLE: FileEncrypter Interface for Accumulo Custom Encryption\nDESCRIPTION: Methods required for implementing the FileEncrypter interface to provide encryption functionality in a custom CryptoService for Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_9\n\nLANGUAGE: java\nCODE:\n```\n  OutputStream encryptStream(OutputStream outputStream) throws CryptoService.CryptoException;\n  byte[] getDecryptionParameters();\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Replication\nDESCRIPTION: Commands to enable replication for a specific table and configure its replication target.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nroot@accumulo_primary> config -t my_table -s table.replication=true\nroot@accumulo_primary> config -t my_table -s table.replication.target.accumulo_peer=2\n```\n\n----------------------------------------\n\nTITLE: Creating Mutations for Writing Data in Accumulo\nDESCRIPTION: Example of creating a Mutation object to write data to Accumulo, including row ID, column family, qualifier, visibility, and timestamp.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nText rowID = new Text(\"row1\");\nText colFam = new Text(\"myColFam\");\nText colQual = new Text(\"myColQual\");\nColumnVisibility colVis = new ColumnVisibility(\"public\");\nlong timestamp = System.currentTimeMillis();\n\nValue value = new Value(\"myValue\".getBytes());\n\nMutation mutation = new Mutation(rowID);\nmutation.put(colFam, colQual, colVis, timestamp, value);\n```\n\n----------------------------------------\n\nTITLE: Implementing Mapper for Accumulo Input\nDESCRIPTION: This Java code shows an example implementation of a Mapper class that processes Key-Value pairs from an Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/mapreduce.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass MyMapper extends Mapper<Key,Value,WritableComparable,Writable> {\n    public void map(Key k, Value v, Context c) {\n        // transform key and value data here\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Scanning Sorted Data in Accumulo Shell\nDESCRIPTION: Commands to access the Accumulo shell and scan the sorted data from the Terasort example. This shows how to verify the results after the MapReduce job completes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/terasort.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nusername@instance> scan -t sort\n```\n\n----------------------------------------\n\nTITLE: Optional Settings for AccumuloOutputFormat\nDESCRIPTION: Additional optional configuration for AccumuloOutputFormat to tune performance parameters. Sets maximum latency for writes and maximum buffer size for mutations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nAccumuloOutputFormat.setMaxLatency(job, 300); // milliseconds\nAccumuloOutputFormat.setMaxMutationBufferSize(job, 5000000); // bytes\n```\n\n----------------------------------------\n\nTITLE: Reading Data with Java Program\nDESCRIPTION: Command to run a Java program that reads all data between two specified rows in the Accumulo table. Requires instance name, ZooKeeper servers, table name, username, password, start row, and end row parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.helloworld.ReadData instance zookeepers hellotable username password row_0 row_1001\n```\n\n----------------------------------------\n\nTITLE: Managing Multiple Authorization Tokens in Accumulo\nDESCRIPTION: Demonstrates setting multiple authorization tokens (A, B, broccoli) for a user and how these impact data visibility during scans. Shows how authorization subsets work for scanning.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A,B,broccoli -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nusername@instance vistest> scan -s B\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Listing Java Processes\nDESCRIPTION: Uses the Java Process Status tool to list running Java processes with their main class and arguments. Useful for verifying Accumulo processes are running.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nsudo jps -ml\n```\n\n----------------------------------------\n\nTITLE: Implementing Mapper class for Accumulo MapReduce integration in Java\nDESCRIPTION: Sample implementation of a Mapper class that reads from an Accumulo table. This class extends Hadoop's Mapper with Key and Value as input types, and transforms the data within the map method.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Analytics.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass MyMapper extends Mapper<Key,Value,WritableComparable,Writable> {\n    public void map(Key k, Value v, Context c) {\n        // transform key and value data here\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Testing mutation size limit with Accumulo TestIngest class\nDESCRIPTION: This example demonstrates what happens when trying to ingest a mutation that exceeds the size constraint. The command attempts to create a single row with 10,000 columns, which exceeds the maximum mutation size of 188160 bytes, resulting in a constraint violation error.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/maxmutation.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.test.TestIngest -i instance -z zookeepers -u username -p password --rows 1 --cols 10000\nERROR : Constraint violates : ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.MaxMutationSize, violationCode:0, violationDescription:mutation exceeded maximum size of 188160, numberOfViolatingMutations:1)\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Tserver Service\nDESCRIPTION: Command to start the Accumulo tablet server as a background service.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-service tserver start\n```\n\n----------------------------------------\n\nTITLE: Insert Command Syntax\nDESCRIPTION: Command for inserting a single record with options for authorization labels and timestamps.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_31\n\nLANGUAGE: shell\nCODE:\n```\ninsert <row> <colfamily> <colqualifier> <value> [-?] [-l <expression>] [-t <timestamp>]\n```\n\n----------------------------------------\n\nTITLE: Creating a Mutation with Security Label in Apache Accumulo\nDESCRIPTION: Demonstrates how to create a mutation with a security label (column visibility) in Apache Accumulo. The example shows setting a 'public' visibility for a key-value pair when writing data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Security.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nText rowID = new Text(\"row1\");\nText colFam = new Text(\"myColFam\");\nText colQual = new Text(\"myColQual\");\nColumnVisibility colVis = new ColumnVisibility(\"public\");\nlong timestamp = System.currentTimeMillis();\n\nValue value = new Value(\"myValue\");\n\nMutation mutation = new Mutation(rowID);\nmutation.put(colFam, colQual, colVis, timestamp, value);\n```\n\n----------------------------------------\n\nTITLE: Using New Bulk Import API in Accumulo 2.0\nDESCRIPTION: Reference to the new bulk import API that supports improved functionality including offline table imports, load plans, and client-side file inspection. The code shows the fluent API pattern for importing directories.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2019-08-02-accumulo-2.0.0.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// Reference to the newImportDir method from the fluent API\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo\nDESCRIPTION: Demonstrates that only privileged users (with System.ALTER_USER permission) can set authorizations for users. Shows how the root user can grant authorization tokens to a standard user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> setauths -s A\n06 11:53:42,056 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Launching Accumulo Shell as Root User\nDESCRIPTION: Command to start the Accumulo shell interface and login as the root user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u root\n```\n\n----------------------------------------\n\nTITLE: Starting Mini Accumulo Cluster for Integration Testing\nDESCRIPTION: Code to initialize and start a Mini Accumulo Cluster for integration testing. This creates a lightweight yet functional Accumulo environment that includes Zookeeper and tablet servers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nFile tempDirectory = // JUnit and Guava supply mechanisms for creating temp directories\nMiniAccumuloCluster accumulo = new MiniAccumuloCluster(tempDirectory, \"password\");\naccumulo.start();\n```\n\n----------------------------------------\n\nTITLE: Running RegexExample MapReduce Job\nDESCRIPTION: This command demonstrates how to run the RegexExample class to search for rows in the input table that start with 'dog'. It uses MapReduce and sets a scanner iterator for pattern matching.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/regex.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RegexExample -u user -p passwd -i instance -t input --rowRegex 'dog.*' --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Managing Locality Groups via the Client API in Accumulo\nDESCRIPTION: Demonstrates how to programmatically set and retrieve locality groups using the Accumulo Java client API. The example shows creating multiple locality groups for different types of column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nConnector conn;\n\nHashMap<String,Set<Text>> localityGroups =\n    new HashMap<String, Set<Text>>();\n\nHashSet<Text> metadataColumns = new HashSet<Text>();\nmetadataColumns.add(new Text(\"domain\"));\nmetadataColumns.add(new Text(\"link\"));\n\nHashSet<Text> contentColumns = new HashSet<Text>();\ncontentColumns.add(new Text(\"body\"));\ncontentColumns.add(new Text(\"images\"));\n\nlocalityGroups.put(\"metadata\", metadataColumns);\nlocalityGroups.put(\"content\", contentColumns);\n\nconn.tableOperations().setLocalityGroups(\"mytable\", localityGroups);\n\n// existing locality groups can be obtained as follows\nMap<String, Set<Text>> groups =\n    conn.tableOperations().getLocalityGroups(\"mytable\");\n```\n\n----------------------------------------\n\nTITLE: Using Accumulo Command to Dump ZooKeeper Contents\nDESCRIPTION: Alternative method to view ZooKeeper contents using the accumulo command instead of accumulo-util, providing the same functionality.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo dump-zoo\n```\n\n----------------------------------------\n\nTITLE: Running RegexExample MapReduce Job to Find Rows Starting with 'dog'\nDESCRIPTION: This code runs the RegexExample MapReduce job that searches for rows starting with 'dog' in the input table. It utilizes a scan-time iterator for pattern matching and stores the results in HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/regex.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RegexExample -u user -p passwd -i instance -t input --rowRegex 'dog.*' --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Constraints in Apache Accumulo Shell\nDESCRIPTION: This snippet demonstrates how to create a table with constraints, set up AlphaNumKeyConstraint and NumericValueConstraint, and attempt inserts that violate these constraints. It shows successful and failed insert attempts, as well as the final table scan.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/constraints.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n\nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.4.x\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable testConstraints\nusername@instance testConstraints> config -t testConstraints -s table.constraint.1=org.apache.accumulo.examples.simple.constraints.NumericValueConstraint\nusername@instance testConstraints> config -t testConstraints -s table.constraint.2=org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint\nusername@instance testConstraints> insert r1 cf1 cq1 1111\nusername@instance testConstraints> insert r1 cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> insert r1! cf1 cq1 ABC \n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint, violationCode:1, violationDescription:Row was not alpha numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> scan\nr1 cf1:cq1 []    1111\nusername@instance testConstraints>\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Compaction Services and Dispatchers\nDESCRIPTION: Shell commands to create two compaction services with different thread configurations and I/O limits, then configure a table to use these services for system and user compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s tserver.compaction.major.service.cs1.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\nconfig -s 'tserver.compaction.major.service.cs1.planner.opts.executors=[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"16M\",\"numThreads\":8},{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":4},{\"name\":\"large\",\"type\":\"internal\",\"numThreads\":2}]'\nconfig -s tserver.compaction.major.service.cs2.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\nconfig -s 'tserver.compaction.major.service.cs2.planner.opts.executors=[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"16M\",\"numThreads\":4},{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":2},{\"name\":\"large\",\"type\":\"internal\",\"numThreads\":1}]'\nconfig -s tserver.compaction.major.service.cs2.rate.limit=40M\nconfig -t ci -s table.compaction.dispatcher=org.apache.accumulo.core.spi.compaction.SimpleCompactionDispatcher\nconfig -t ci -s table.compaction.dispatcher.opts.service=cs1\nconfig -t ci -s table.compaction.dispatcher.opts.service.user=cs2\n```\n\n----------------------------------------\n\nTITLE: Deleting Table Iterators in Accumulo\nDESCRIPTION: The deleteiter command removes a table-specific iterator at different scopes (scan time, minor compaction, major compaction).\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nusage: deleteiter [-?] [-majc] [-minc] -n <itername> [-scan] [-t <table>]   \ndescription: deletes a table-specific iterator   \n  -?,-help  display this help   \n  -majc,-major-compaction  applied at major compaction   \n  -minc,-minor-compaction  applied at minor compaction   \n  -n,-name <itername>  iterator to delete   \n  -scan,-scan-time  applied at scan time   \n  -t,-table <table>  tableName\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Logical Time in Accumulo\nDESCRIPTION: Shows how to create an Accumulo table that uses logical time instead of wall clock time. Logical time ensures timestamps always move forward and helps avoid problems with differently configured TabletServers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance> createtable -tl logical\n```\n\n----------------------------------------\n\nTITLE: Regex Searching in Accumulo Tables\nDESCRIPTION: The 'egrep' command performs a regex search on a table in parallel on the server side. It supports various options for specifying the search range and columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_18\n\nLANGUAGE: markdown\nCODE:\n```\n**egrep**   \n\n    usage: egrep <regex> <regex> [-?] [-b <start-row>] [-c   \n           <<columnfamily>[:<columnqualifier>]>] [-e <end-row>] [-np] [-s   \n           <comma-separated-authorizations>] [-st] [-t <arg>]   \n    description: egreps a table in parallel on the server side (uses java regex)   \n      -?,-help  display this help   \n      -b,-begin-row <start-row>  begin row (inclusive)   \n      -c,-columns <<columnfamily>[:<columnqualifier>]>  comma-separated columns   \n      -e,-end-row <end-row>  end row (inclusive)   \n      -np,-no-pagination  disables pagination of output   \n      -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations   \n           (all user auths are used if this argument is not specified)   \n      -st,-show-timestamps  enables displaying timestamps   \n      -t,-num-threads <arg>  num threads   \n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Job to Extract Columns from Accumulo Table\nDESCRIPTION: This snippet shows how to run the TableToFile MapReduce job to extract rows containing the column 'cf:cq' from the input table and write them to HDFS. It specifies authentication parameters, input table, columns to extract, and output location.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/tabletofile.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TableToFile -u user -p passwd -i instance -t input --columns cf:cq --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Set Scan Iterator Command in Accumulo Shell\nDESCRIPTION: Command to set session-specific scan iterators with various iterator types and configuration options\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_32\n\nLANGUAGE: shell\nCODE:\n```\nsetscaniter [-?] -ageoff | -agg | -class <name> | -regex | -reqvis | -vers [-n <itername>] -p <pri> [-t <table>]\n```\n\n----------------------------------------\n\nTITLE: Logging into Accumulo Shell\nDESCRIPTION: Command to log into the Accumulo shell with a username and password.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/helloworld.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Implementing YieldingKeyValueIterator in Java for Accumulo 1.9.0\nDESCRIPTION: New interface to allow iterators to yield control during seek or next calls, preventing starvation of other scans when iterators take a long time to return a key/value.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2018-04-18-accumulo-1.9.0.md#2025-04-11_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\npublic class MyIterator implements YieldingKeyValueIterator {\n  // Implementation details\n}\n```\n\n----------------------------------------\n\nTITLE: Run WordCount MapReduce Job\nDESCRIPTION: Command to execute the word count MapReduce job and its output showing job progress and statistics.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters\n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Configuration Settings\nDESCRIPTION: Shows how to view the configured iterator settings for a table using the config command in Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nuser@example filtertest> config -t filtertest -f iterator\n---------+------------------------------------------+------------------\nSCOPE    | NAME                                     | VALUE\n---------+------------------------------------------+------------------\ntable    | table.iterator.majc.myfilter ........... | 10,org.apache.accumulo.core.iterators.FilteringIterator\ntable    | table.iterator.majc.myfilter.opt.0 ..... | org.apache.accumulo.core.iterators.filter.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.0.ttl . | 30000\ntable    | table.iterator.minc.myfilter ........... | 10,org.apache.accumulo.core.iterators.FilteringIterator\ntable    | table.iterator.minc.myfilter.opt.0 ..... | org.apache.accumulo.core.iterators.filter.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.0.ttl . | 30000\ntable    | table.iterator.scan.myfilter ........... | 10,org.apache.accumulo.core.iterators.FilteringIterator\ntable    | table.iterator.scan.myfilter.opt.0 ..... | org.apache.accumulo.core.iterators.filter.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.0.ttl . | 30000\n---------+------------------------------------------+------------------\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with SummingCombiner for Word Count\nDESCRIPTION: Shell commands to create an Accumulo table with a SummingCombiner iterator. This combiner is configured to sum up values in the 'count' column family, which will aggregate the word counts.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable wordCount\nusername@instance wordCount> setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -p 10 -t wordCount -majc -minc -scan\nSummingCombiner interprets Values as Longs and adds them together.  A variety of encodings (variable length, fixed length, or string) are available\n----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: false\n----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: count\n----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: false \n----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING\nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Executing RowOperations example in Accumulo\nDESCRIPTION: This command runs the RowOperations example which demonstrates reading and writing rows using BatchWriter and Scanner in Accumulo. It requires user credentials and connection information to the Accumulo instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/client.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo $PACKAGE.RowOperations -u root -p mypassword -i instance -z zookeeper\n```\n\n----------------------------------------\n\nTITLE: Java 11 G1 GC Manual Configuration\nDESCRIPTION: G1 GC configuration with manual garbage collection and 1GB max heap\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n-Xmx1G -Xms256m\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with Bloom Filters\nDESCRIPTION: This snippet shows how to create an Accumulo table named 'bloom_test' and enable bloom filters using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test\nusername@instance bloom_test> config -t bloom_test -s table.bloom.enabled=true\nusername@instance bloom_test> exit\n```\n\n----------------------------------------\n\nTITLE: Configuring visibility constraint in Accumulo\nDESCRIPTION: This snippet shows how to configure a table constraint that prevents users from inserting data with visibility labels they cannot read themselves. It demonstrates both a failed insertion and a successful one with appropriate visibility expressions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ******\nroot@instance vistest> config -t vistest -s table.constraint.1=org.apache.accumulo.core.security.VisibilityConstraint\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> insert row f4 q4 v4 -l spinach\n    Constraint Failures:\n        ConstraintViolationSummary(constrainClass:org.apache.accumulo.core.security.VisibilityConstraint, violationCode:2, violationDescription:User does not have authorization on column visibility, numberOfViolatingMutations:1)\nusername@instance vistest> insert row f4 q4 v4 -l spinach|broccoli\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nrow f4:q4 [spinach|broccoli]    v4\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Implementing Multiple Scan Executor Use Case in Accumulo Shell\nDESCRIPTION: Complete example showing how to create tables and configure scan executors with different thread counts for different workload priorities. This establishes low, high, and normal priority execution paths.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncreatetable LOW1\ncreateable LOW2\ncreateable HIGH\ncreateable NORM1\ncreateable NORM2\nconfig -s tserver.scan.executors.default.threads=4\nconfig -s tserver.scan.executors.low.threads=1\nconfig -s tserver.scan.executors.high.threads=8\n```\n\n----------------------------------------\n\nTITLE: Alternative Command for Deleting Users in Accumulo\nDESCRIPTION: The dropuser command is an alternative to deleteuser that removes a user from the Accumulo system.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_22\n\nLANGUAGE: shell\nCODE:\n```\nusage: dropuser <username> [-?]   \ndescription: deletes a user   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring AgeOffFilter in Accumulo\nDESCRIPTION: Shows the process of creating a table and setting up an AgeOffFilter with a 30-second TTL for scan operations. Demonstrates basic insert and scan operations to show the filter's effect.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method: \n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day: \nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\nusername@instance filtertest> \n\n... wait 30 seconds ...\n\nusername@instance filtertest> scan\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo\nDESCRIPTION: This command creates a new table named 'nofoo' in Accumulo that will be configured to use the custom filter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/classpath.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncreatetable nofoo\n```\n\n----------------------------------------\n\nTITLE: Connecting to Mini Accumulo Cluster\nDESCRIPTION: Code to establish a connection to a running Mini Accumulo Cluster instance. This uses the standard ZooKeeperInstance with the cluster's instance name and ZooKeeper connection string.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nInstance instance = new ZooKeeperInstance(accumulo.getInstanceName(), accumulo.getZooKeepers());\nConnector conn = instance.getConnector(\"root\", \"password\");\n```\n\n----------------------------------------\n\nTITLE: Creating a Scanner with User Authorizations in Apache Accumulo\nDESCRIPTION: Shows how to create a scanner with specific user authorizations in Apache Accumulo. The example creates an Authorization object with 'admin' and 'system' tokens to allow reading data with those security labels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Security.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// user possess both admin and system level access\nAuthorization auths = new Authorization(\"admin\",\"system\");\n\nScanner s = connector.createScanner(\"table\", auths);\n```\n\n----------------------------------------\n\nTITLE: Batch Writing Villain Data\nDESCRIPTION: Generates and writes 10,000 rows of villain data using BatchWriter. Each row contains villain information including alias, years of service, and cape status.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/batch-scanner-code.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\ntry (BatchWriter writer = client.createBatchWriter(\"GothamBatch\")) {\n  for (int i = 0; i < 10_000; i++) {\n    Mutation m = new Mutation(String.format(\"id%04d\", i));\n    m.put(\"villain\", \"alias\", \"henchman\" + i);\n    m.put(\"villain\", \"yearsOfService\", \"\" + (new Random().nextInt(50)));\n    m.put(\"villain\", \"wearsCape?\", \"false\");\n   writer.addMutation(m);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with Bloom Filters\nDESCRIPTION: This snippet shows how to create a table 'bloom_test2' with bloom filters enabled and set the major compaction ratio.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test2\nusername@instance bloom_test2> config -t bloom_test2 -s table.compaction.major.ratio=7\nusername@instance bloom_test2> config -t bloom_test2 -s table.bloom.enabled=true\nusername@instance bloom_test2> exit\n```\n\n----------------------------------------\n\nTITLE: Inspecting RFile Metadata with PrintInfo in Accumulo\nDESCRIPTION: This snippet shows how to use Accumulo's PrintInfo tool to examine the metadata of an RFile, confirming the presence of a bloom filter and displaying its size and other file information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.core.file.rfile.PrintInfo /accumulo/tables/o8/default_tablet/F00000dj.rf\nLocality group         : <DEFAULT>\n  Start block          : 0\n  Num   blocks         : 752\n  Index level 0        : 43,598 bytes  1 blocks\n  First key            : row_0000001169 foo:1 [exampleVis] 1326222052539 false\n  Last key             : row_0999999421 foo:1 [exampleVis] 1326222052058 false\n  Num entries          : 999,536\n  Column families      : [foo]\n\nMeta block     : BCFile.index\n  Raw size             : 4 bytes\n  Compressed size      : 12 bytes\n  Compression type     : gz\n\nMeta block     : RFile.index\n  Raw size             : 43,696 bytes\n  Compressed size      : 15,592 bytes\n  Compression type     : gz\n\nMeta block     : acu_bloom\n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Word Count Job with Accumulo Integration\nDESCRIPTION: Executes the WordCount MapReduce job that processes the input documents from HDFS and writes word count results to the Accumulo table. The command shows how to specify Accumulo connection parameters and monitor job progress through Hadoop logs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/examples-simple*[^cs].jar org.apache.accumulo.examples.simple.mapreduce.WordCount instance zookeepers /user/username/wc wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters \n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Initializing Mock Accumulo Instance in Java\nDESCRIPTION: Code to create a connection to Mock Accumulo, which is a lightweight in-memory implementation for testing. This replaces the standard ZooKeeperInstance with MockInstance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nInstance instance = new MockInstance();\n```\n\n----------------------------------------\n\nTITLE: Creating a Table without Bloom Filters in Accumulo\nDESCRIPTION: This snippet demonstrates how to create a control table 'bloom_test1' without bloom filters and with a modified compaction ratio to prevent files from being compacted into one file. This will be used for performance comparison.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.4.x\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test1\nusername@instance bloom_test1> config -t bloom_test1 -s table.compaction.major.ratio=7\nusername@instance bloom_test1> exit\n```\n\n----------------------------------------\n\nTITLE: Table Maintenance Commands in Accumulo Shell\nDESCRIPTION: Commands for table maintenance operations such as compaction, which consolidates files and removes deleted entries, and flush, which writes in-memory entries to disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Accumulo_Shell.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nroot@myinstance mytable> compact -t mytable\n07 16:13:53,201 [shell.Shell] INFO : Compaction of table mytable\nscheduled for 20100707161353EDT\n\nroot@myinstance mytable> flush -t mytable\n07 16:14:19,351 [shell.Shell] INFO : Flush of table mytable\ninitiated...\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Visibilities in Accumulo\nDESCRIPTION: This snippet shows how to insert data with different visibility labels, including simple and complex boolean combinations of authorization tokens.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n            ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Scanning the Accumulo Table for Ingested File Data\nDESCRIPTION: Accumulo shell command to scan and view the contents of the 'dataTable' which contains the ingested file data. The row IDs represent MD5 hashes of the ingested files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filedata.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Configuring visibility constraints in Accumulo\nDESCRIPTION: Demonstrates how to set a table constraint that prevents users from inserting data with visibility labels they cannot see themselves. Shows successful and unsuccessful insertion attempts based on the user's authorizations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ******\nroot@instance vistest> config -t vistest -s table.constraint.1=org.apache.accumulo.core.security.VisibilityConstraint\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> insert row f4 q4 v4 -l spinach\n    Constraint Failures:\n        ConstraintViolationSummary(constrainClass:org.apache.accumulo.core.security.VisibilityConstraint, violationCode:2, violationDescription:User does not have authorization on column visibility, numberOfViolatingMutations:1)\nusername@instance vistest> insert row f4 q4 v4 -l spinach|broccoli\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nrow f4:q4 [spinach|broccoli]    v4\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Documenting Accumulo Shell Command: flush\nDESCRIPTION: The 'flush' command flushes a table's data that is currently in memory to disk. It supports options for specifying row ranges, table patterns, and waiting for the flush to complete.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_27\n\nLANGUAGE: text\nCODE:\n```\nusage: flush [-?] [-b <arg>] [-e <arg>] [-p <pattern> | -t <tableName>]  [-w]\ndescription: flushes a tables data that is currently in memory to disk\n  -?,-help  display this help\n  -b,-begin-row <arg>  begin row\n  -e,-end-row <arg>  end row\n  -p,-pattern <pattern>  regex pattern of table names to flush\n  -t,-table <tableName>  name of a table to flush\n  -w,-wait  wait for flush to finish\n```\n\n----------------------------------------\n\nTITLE: Querying Table Without Bloom Filters\nDESCRIPTION: This snippet demonstrates querying a table without bloom filters. Even though the queries only match data in one map file, all map files are scanned, resulting in slower query performance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test1 --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\nGenerating 500 random queries...finished\n35.09 lookups/sec  14.25 secs\nnum results : 500\nGenerating 500 random queries...finished\n35.33 lookups/sec  14.15 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Using SortedSetAggregator in Accumulo Shell\nDESCRIPTION: This example demonstrates creating a table with SortedSetAggregator, inserting values, and observing how the aggregator automatically combines and sorts the values for the same key. The aggregator is applied to the 'app' column family to merge values into sorted sets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/aggregation.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo shell -u username\nEnter current password for 'username'@'instance': ***\n\nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.3.x-incubating\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable aggtest1 -a app=org.apache.accumulo.examples.aggregation.SortedSetAggregator\nusername@instance aggtest1> insert foo app 1 a\nusername@instance aggtest1> insert foo app 1 b\nusername@instance aggtest1> scan\nfoo app:1 []  a,b\nusername@instance aggtest1> insert foo app 1 z,1,foo,w\nusername@instance aggtest1> scan\nfoo app:1 []  1,a,b,foo,w,z\nusername@instance aggtest1> insert foo app 2 cat,dog,muskrat\nusername@instance aggtest1> insert foo app 2 mouse,bird\nusername@instance aggtest1> scan\nfoo app:1 []  1,a,b,foo,w,z\nfoo app:2 []  bird,cat,dog,mouse,muskrat\nusername@instance aggtest1>\n```\n\n----------------------------------------\n\nTITLE: Creating Table in Accumulo Shell\nDESCRIPTION: This command creates a new table named 'batchtest1' in Accumulo using the shell. This table is used for the batch writing and scanning example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -e \"createtable batchtest1\"\n```\n\n----------------------------------------\n\nTITLE: Shutting Down Mini Accumulo Cluster\nDESCRIPTION: Code to properly stop a Mini Accumulo Cluster after testing is complete. This ensures all processes are terminated cleanly.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\naccumulo.stop()\n// delete your temporary folder\n```\n\n----------------------------------------\n\nTITLE: Creating a BatchWriter\nDESCRIPTION: Creates a BatchWriter for a specific table using an AccumuloClient. The BatchWriter is used to efficiently write mutations to Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nBatchWriter writer = client.createBatchWriter(\"table\");\n```\n\n----------------------------------------\n\nTITLE: External Compaction Test Script in Java\nDESCRIPTION: Script that performs external compaction testing by creating a table, ingesting 700MB of data across 20 files (35MB each), and initiating compaction. Configures table properties to use external compaction service and avoid system compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nimport org.apache.accumulo.core.conf.Property; \n\nint dataSize = 35_000_000; \nbyte[] data = new byte[dataSize]; \nArrays.fill(data, (byte) 65); \nString tableName = \"testTable\"; \n\nvoid ingestAndCompact() throws Exception {\n   try { \n       client.tableOperations().delete(tableName); \n   } catch (TableNotFoundException e) { \n       // ignore \n   } \n   \n   System.out.println(\"Creating table \" + tableName); \n   client.tableOperations().create(tableName); \n   \n   // This is done to avoid system compactions, we want to initiate the compactions manually \n   client.tableOperations().setProperty(tableName, Property.TABLE_MAJC_RATIO.getKey(), \"1000\"); \n   // Configure for external compaction \n   client.instanceOperations().setProperty(\"tserver.compaction.major.service.cs1.planner\",\"org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\"); \n   client.instanceOperations().setProperty(\"tserver.compaction.major.service.cs1.planner.opts.executors\",\"[{\\\"name\\\":\\\"large\\\",\\\"type\\\":\\\"external\\\",\\\"queue\\\":\\\"q1\\\"}]\"); \n   \n   client.tableOperations().setProperty(tableName, \"table.compaction.dispatcher\", \"org.apache.accumulo.core.spi.compaction.SimpleCompactionDispatcher\"); \n   client.tableOperations().setProperty(tableName, \"table.compaction.dispatcher.opts.service\", \"cs1\"); \n   \n   int numFiles = 20; \n   \n   try (var writer = client.createBatchWriter(tableName)) { \n       for (int i = 0; i < numFiles; i++) { \n           Mutation mut = new Mutation(\"r\" + i); \n           mut.at().family(\"cf\").qualifier(\"cq\").put(data); \n           writer.addMutation(mut); \n           writer.flush();   \n   \n           System.out.println(\"Writing \" + dataSize + \" bytes to a single value\"); \n           client.tableOperations().flush(tableName, null, null, true); \n       } \n   }   \n   \n   System.out.println(\"Compacting table\"); \n   client.tableOperations().compact(tableName, new CompactionConfig().setWait(true)); \n   System.out.println(\"Finished table compaction\");\n} \n\ningestAndCompact();\n```\n\n----------------------------------------\n\nTITLE: Running Commands in Accumulo Shell\nDESCRIPTION: Shows the convention for running commands in the Accumulo shell. Commands are prefixed with '>' to indicate they should be executed within the Accumulo shell environment.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/index.md#2025-04-11_snippet_1\n\nLANGUAGE: accumulo\nCODE:\n```\n> command\n```\n\n----------------------------------------\n\nTITLE: Running Sequential Batch Writer in Accumulo\nDESCRIPTION: This command executes the SequentialBatchWriter Java class to write 10000 entries with random 50-byte values to the 'batchtest1' table. It demonstrates batch writing with various parameters like batch memory, latency, and threads.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/batch.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.SequentialBatchWriter -i instance -z zookeepers -u username -p password -t batchtest1 --start 0 --num 10000 --size 50 --batchMemory 20M --batchLatency 500 --batchThreads 20 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Creating Table without Bloom Filters in Accumulo\nDESCRIPTION: This snippet shows how to create a table named 'bloom_test1' without bloom filters and set the major compaction ratio.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test1\nusername@instance bloom_test1> config -t bloom_test1 -s table.compaction.major.ratio=7\nusername@instance bloom_test1> exit\n```\n\n----------------------------------------\n\nTITLE: Querying Directory Contents\nDESCRIPTION: Commands to list the contents of specific directories using the QueryUtil class. These queries operate on the directory table to retrieve directory listings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/dirlist.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis --path /local/username\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis --path /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Generating Host Certificates with OpenSSL\nDESCRIPTION: Commands to generate individual host certificates, create certificate signing requests, and import them into Java KeyStores for server use.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-09-02-generating-keystores-for-configuring-accumulo-with-ssl.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Create the private key for our server\nopenssl genrsa -out server.key 4096\n\n# Generate a certificate signing request (CSR) with our private key\nopenssl req -new -key server.key -out server.csr\n\n# Use the CSR and the CA to create a certificate for the server (a reply to the CSR)\nopenssl x509 -req -in server.csr -CA root.pem -CAkey root.key -CAcreateserial -out server.crt -days 365\n\n# Use the certificate and the private key for our server to create PKCS12 file\nopenssl pkcs12 -export -in server.crt -inkey server.key -certfile server.crt -name 'server-key' -out server.p12\n\n# Create a Java KeyStore for the server using the PKCS12 file (private key)\nkeytool -importkeystore -srckeystore server.p12 -srcstoretype pkcs12 -destkeystore server.jks -deststoretype JKS\n\n# Remove the PKCS12 file as we don't need it\nrm server.p12\n\n# Import the CA-signed certificate to the keystore\nkeytool -import -trustcacerts -alias server-crt -file server.crt -keystore server.jks\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring AgeOffFilter for Scan Operations in Accumulo\nDESCRIPTION: This snippet demonstrates creating a test table and configuring the AgeOffFilter for scan operations with a 30-second time-to-live (TTL). It shows how to insert data and observe the filter in action as entries older than the TTL disappear from query results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Scanning Accumulo Table for Ingested File Data\nDESCRIPTION: This Accumulo shell command scans the dataTable to view the ingested file data. The row key is the MD5 hash of the file content.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filedata.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Granting table creation permissions to an Accumulo user\nDESCRIPTION: Demonstrates how to grant system-level permissions to a user, specifically the System.CREATE_TABLE permission, and then shows the user creating a table and viewing their permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> user root\nEnter password for user root: ********\nroot@instance> grant -s System.CREATE_TABLE -u username\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\nusername@instance> userpermissions\nSystem permissions: System.CREATE_TABLE\n\nTable permissions (accumulo.metadata): Table.READ\nTable permissions (vistest): Table.READ, Table.WRITE, Table.BULK_IMPORT, Table.ALTER_TABLE, Table.GRANT, Table.DROP_TABLE\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Searching Accumulo Tables\nDESCRIPTION: The 'grep' command searches for terms in an Accumulo table. It supports various options for specifying the search range and columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_27\n\nLANGUAGE: markdown\nCODE:\n```\n**grep**   \n\n    usage: grep <term> <term> [-?] [-b <start-row>] [-c   \n           <<columnfamily>[:<columnqualifier>]>] [-e <end-row>] [-np] [-s   \n           <comma-separated-authorizations>] [-st]   \n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Table with RandomBatchScanner\nDESCRIPTION: This command performs 500 random queries against the 'bloom_test' table using the same seed as the insertion, ensuring all queries find results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\nGenerating 500 random queries...finished\n96.19 lookups/sec   5.20 secs\nnum results : 500\nGenerating 500 random queries...finished\n102.35 lookups/sec   4.89 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Querying Directory Contents in Accumulo (Java)\nDESCRIPTION: Commands to run the QueryUtil class for listing contents of specific directories. It demonstrates querying the dirTable with different paths.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/dirlist.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis --path /local/username\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis --path /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Creating Empty WAL File for Accumulo\nDESCRIPTION: This command creates an empty Write-Ahead Log (WAL) file with a valid header, which can be used to replace corrupt WAL files in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ echo -n -e '--- Log File Header (v2) ---\\x00\\x00\\x00\\x00' > empty.wal\n```\n\n----------------------------------------\n\nTITLE: Sequential Batch Writing in Accumulo\nDESCRIPTION: Command to write 10,000 sequential entries with random 50-byte values using SequentialBatchWriter. Includes configuration for batch memory, latency, threads, and visibility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/batch.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.client.SequentialBatchWriter -i instance -z zookeepers -u username -p password -t batchtest1 --start 0 --num 10000 --size 50 --batchMemory 20M --batchLatency 500 --batchThreads 20 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Creating Tables in Accumulo\nDESCRIPTION: The createtable command creates a new table with options for aggregators, pre-splitting, time type, and security constraints. It can copy configuration from existing tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nusage: createtable <tableName> [-?] [-a   \n          <<columnfamily>[:<columnqualifier>]=<aggregation class>>] [-b64] [-cc   \n          <table>] [-cs <table> | -sf <filename>] [-evc] [-f <className>] [-ndi]   \n          [-tl | -tm]   \ndescription: creates a new table, with optional aggregators and optionally pre-split   \n  -?,-help  display this help   \n  -a,-aggregator <<columnfamily>[:<columnqualifier>]=<aggregation class>>  comma   \n          separated column=aggregator   \n  -b64,-base64encoded  decode encoded split points   \n  -cc,-copy-config <table>  table to copy configuration from   \n  -cs,-copy-splits <table>  table to copy current splits from   \n  -evc,-enable-visibility-constraint  prevents users from writing data they can not   \n          read.  When enabling this may want to consider disabling bulk import and   \n          alter table   \n  -f,-formatter <className>  default formatter to set   \n  -ndi,-no-default-iterators  prevents creation of the normal default iterator set   \n  -sf,-splits-file <filename>  file with newline separated list of rows to create a   \n          pre-split table   \n  -tl,-time-logical  use logical time   \n  -tm,-time-millis  use time in milliseconds\n```\n\n----------------------------------------\n\nTITLE: Attempting to Scan with Unauthorized Permissions in Apache Accumulo\nDESCRIPTION: Demonstrates what happens when a user tries to scan with authorizations they don't possess. In this case, the root user attempts to use the 'secretId' authorization without having it assigned.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\ntry (ScannerBase scan = client.createScanner(\"GothamPD\", auths)) {\n   System.out.println(\"Gotham Police Department Persons of Interest:\");\n     for (Map.Entry<Key, Value> entry : scan)\n       System.out.printf(\"Key : %-50s  Value : %s\\n\", entry.getKey(), entry.getValue());\n     }\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Classpath Context Dependency\nDESCRIPTION: This sequence demonstrates that attempting to use a class from the external JAR fails until the table is configured with the appropriate classpath context. It creates a second table and shows the error when trying to use the filter without the context.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/classpath.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncreatetable nofootwo\nsetiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\nconfig -t nofootwo -s table.classpath.context=cx1\nsetiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\n```\n\n----------------------------------------\n\nTITLE: Listing Accumulo Tables\nDESCRIPTION: This command lists all tables in Accumulo, showing their names and IDs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password -e 'tables -l'\naccumulo.metadata    =>        !0\naccumulo.root        =>        +r\nbloom_test1          =>        o7\nbloom_test2          =>        o8\ntrace                =>         1\n```\n\n----------------------------------------\n\nTITLE: Modifying Multiple Table Properties via Java API\nDESCRIPTION: Demonstrates how to add, modify, and remove multiple table properties in a single operation using the Java API. This approach is more efficient than making multiple property changes separately.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().modifyProperties(\"mytable\", properties -> {\n        properties.remove(\"table.file.max\");\n        properties.put(\"table.bloom.enabled\", \"true\");\n        properties.put(\"table.bloom.error.rate\", \"0.75\");\n        properties.put(\"table.bloom.size\", \"128000\");\n        });\n```\n\n----------------------------------------\n\nTITLE: Executing Random Batch Scanner\nDESCRIPTION: Command to run the RandomBatchScanner class which performs 100 random queries on the written data with specified scan parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/batch.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -i instance -z zookeepers -u username -p password -t batchtest1 --num 100 --min 0 --max 10000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Running RandomBatchScanner to query Accumulo table\nDESCRIPTION: Command to run the RandomBatchScanner which performs 100 random queries on the 'batchtest1' table and verifies the values. The command includes the range parameters, number of scan threads, and required authorizations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/batch.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -i instance -z zookeepers -u username -p password -t batchtest1 --num 100 --min 0 --max 10000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Setting HDFS Permissions and Initializing Accumulo\nDESCRIPTION: These commands set the necessary HDFS permissions and initialize Accumulo for a multi-node setup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nsudo -u hdfs hdfs dfs -chmod 777 /\nsudo -u accumulo accumulo init\nsudo -u hdfs hdfs dfs -chmod 755 /\n```\n\n----------------------------------------\n\nTITLE: Creating a Test Table with Sample Data in Accumulo Shell\nDESCRIPTION: This snippet demonstrates how to connect to Accumulo shell, create a table named 'input', and insert test data (dogs and cats) for use with the regex example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/regex.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable input\nusername@instance> insert dogrow dogcf dogcq dogvalue\nusername@instance> insert catrow catcf catcq catvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Inserting and Querying Data with StatsCombiner in Accumulo\nDESCRIPTION: Commands demonstrating the insertion of data and how the StatsCombiner processes values in both decimal and hexadecimal format. Shows how stats are calculated (min, max, sum, count) for each data point.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/combiner.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance runners> insert 123456 name first Joe\nusername@instance runners> insert 123456 stat marathon 240\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    240,240,240,1\nusername@instance runners> insert 123456 stat marathon 230\nusername@instance runners> insert 123456 stat marathon 220\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\nusername@instance runners> insert 123456 hstat virtualMarathon 6a\nusername@instance runners> insert 123456 hstat virtualMarathon 6b\nusername@instance runners> scan\n123456 hstat:virtualMarathon []    6a,6b,d5,2\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with SummingCombiner for Word Count\nDESCRIPTION: Shell commands to create an Accumulo table named 'wordCount' and configure a SummingCombiner iterator on the 'count' column family. This combiner adds values interpreted as Longs, which is essential for counting word occurrences.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable wordCount\nusername@instance wordCount> setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -p 10 -t wordCount -majc -minc -scan\nSummingCombiner interprets Values as Longs and adds them together. A variety of encodings (variable length, fixed length, or string) are available\n----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: false\n----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: count\n----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: false\n----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING\nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Managing Debug Logging in Accumulo Shell\nDESCRIPTION: The 'debug' command turns debug logging on or off in the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n**debug**   \n\n    usage: debug [ on | off ] [-?]   \n    description: turns debug logging on or off   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest with Isolation in Apache Accumulo\nDESCRIPTION: This command runs the InterferenceTest program for 5000 iterations with isolation enabled. It shows how using isolation prevents inconsistent reads even when a row is being updated concurrently.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/isolation.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000 --isolated\n```\n\n----------------------------------------\n\nTITLE: Searching File and Directory Names\nDESCRIPTION: Examples of searching file/directory names using wildcards. Searches are performed on the dirindex table and support single wildcard patterns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/dirlist.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password dirindex exampleVis filename -search\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password dirindex exampleVis 'filename*' -search\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password dirindex exampleVis '*jar' -search\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password dirindex exampleVis filename*jar -search\n```\n\n----------------------------------------\n\nTITLE: Displaying Variables in Accumulo JShell\nDESCRIPTION: Output of the /vars command showing the pre-defined variables in the JShell environment: the client properties URL and the AccumuloClient object that provides access to the Accumulo instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/getting-started.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\njshell> /vars\n|    URL clientPropUrl = file:<path_to_accumulo_dir>/conf/accumulo-client.properties\n|    AccumuloClient client = org.apache.accumulo.core.clientImpl.ClientContext@7cbee484\n```\n\n----------------------------------------\n\nTITLE: Scanning Data from Accumulo Table via Proxy\nDESCRIPTION: Shows how to scan data from an Accumulo table using the proxy client, with server-side result batching and proper resource cleanup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nString scanner = client.createScanner(token, \"myTable\", new ScanOptions());\nScanResult results = client.nextK(scanner, 100);\n\nfor(KeyValue keyValue : results.getResultsIterator()) {\n  // do something with results\n}\n\nclient.closeScanner(scanner);\n```\n\n----------------------------------------\n\nTITLE: Creating AccumuloClient from Properties File\nDESCRIPTION: Creates an Accumulo client by loading configuration from an accumulo-client.properties file. This approach allows externalizing connection settings from code.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = Accumulo.newClient()\n                              .from(\"/path/to/accumulo-client.properties\").build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Scan Prioritizer\nDESCRIPTION: Command to configure the IdleRatioScanPrioritizer for the default scan executor. This prioritizer orders queued work based on the ratio of run time to idle time.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntserver.scan.executors.default.prioritizer=org.apache.accumulo.core.spi.scan.IdleRatioScanPrioritizer\n```\n\n----------------------------------------\n\nTITLE: Markdown Table of Accumulo Server Properties\nDESCRIPTION: A markdown table listing various Accumulo server properties, including their names, descriptions, types, ZooKeeper mutability, and default values. The table covers properties for compaction coordinators, compactors, garbage collectors, and general server settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Property | Description |\n|--------------|-------------|\n| <a name=\"compaction_coordinator_prefix\" class=\"prop\"></a> **compaction.coordinator.*** | **Experimental**<br>**Available since:** 2.1.0<br>Properties in this category affect the behavior of the accumulo compaction coordinator server. |\n| <a name=\"compaction_coordinator_compaction_finalizer_check_interval\" class=\"prop\"></a> compaction.coordinator.compaction.finalizer.check.interval | **Experimental**<br>**Available since:** 2.1.0<br>The interval at which to check for external compaction final state markers in the metadata table.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `60s` |\n| <a name=\"compaction_coordinator_compaction_finalizer_threads_maximum\" class=\"prop\"></a> compaction.coordinator.compaction.finalizer.threads.maximum | **Experimental**<br>**Available since:** 2.1.0<br>The maximum number of threads to use for notifying tablet servers that an external compaction has completed.<br>**type:** COUNT, **zk mutable:** no, **default value:** `5` |\n| <a name=\"compaction_coordinator_compactor_dead_check_interval\" class=\"prop\"></a> compaction.coordinator.compactor.dead.check.interval | **Experimental**<br>**Available since:** 2.1.0<br>The interval at which to check for dead compactors.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `5m` |\n| <a name=\"compaction_coordinator_port_client\" class=\"prop\"></a> compaction.coordinator.port.client | **Experimental**<br>**Available since:** 2.1.0<br>The port used for handling Thrift client connections on the compaction coordinator server.<br>**type:** PORT, **zk mutable:** no, **default value:** `9132` |\n| <a name=\"compaction_coordinator_port_search\" class=\"prop\"></a> compaction.coordinator.port.search | **Experimental**<br>**Available since:** 2.1.0<br>If the ports above are in use, search higher ports until one is available.<br>**type:** BOOLEAN, **zk mutable:** no, **default value:** `false` |\n| <a name=\"compaction_coordinator_threadcheck_time\" class=\"prop\"></a> compaction.coordinator.threadcheck.time | **Experimental**<br>**Available since:** 2.1.0<br>The time between adjustments of the server thread pool.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `1s` |\n| <a name=\"compaction_coordinator_threads_minimum\" class=\"prop\"></a> compaction.coordinator.threads.minimum | **Experimental**<br>**Available since:** 2.1.0<br>The minimum number of threads to use to handle incoming requests.<br>**type:** COUNT, **zk mutable:** no, **default value:** `1` |\n| <a name=\"compaction_coordinator_threads_timeout\" class=\"prop\"></a> compaction.coordinator.threads.timeout | **Experimental**<br>**Available since:** 2.1.0<br>The time after which incoming request threads terminate with no work available.  Zero (0) will keep the threads alive indefinitely.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `0s` |\n| <a name=\"compaction_coordinator_tserver_check_interval\" class=\"prop\"></a> compaction.coordinator.tserver.check.interval | **Experimental**<br>**Available since:** 2.1.0<br>The interval at which to check the tservers for external compactions.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `1m` |\n| <a name=\"compactor_prefix\" class=\"prop\"></a> **compactor.*** | **Experimental**<br>**Available since:** 2.1.0<br>Properties in this category affect the behavior of the accumulo compactor server. |\n| <a name=\"compactor_port_client\" class=\"prop\"></a> compactor.port.client | **Experimental**<br>**Available since:** 2.1.0<br>The port used for handling client connections on the compactor servers.<br>**type:** PORT, **zk mutable:** no, **default value:** `9133` |\n| <a name=\"compactor_port_search\" class=\"prop\"></a> compactor.port.search | **Experimental**<br>**Available since:** 2.1.0<br>If the compactor.port.client is in use, search higher ports until one is available.<br>**type:** BOOLEAN, **zk mutable:** no, **default value:** `false` |\n| <a name=\"compactor_threadcheck_time\" class=\"prop\"></a> compactor.threadcheck.time | **Experimental**<br>**Available since:** 2.1.0<br>The time between adjustments of the server thread pool.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `1s` |\n| <a name=\"compactor_threads_minimum\" class=\"prop\"></a> compactor.threads.minimum | **Experimental**<br>**Available since:** 2.1.0<br>The minimum number of threads to use to handle incoming requests.<br>**type:** COUNT, **zk mutable:** no, **default value:** `1` |\n| <a name=\"compactor_threads_timeout\" class=\"prop\"></a> compactor.threads.timeout | **Experimental**<br>**Available since:** 2.1.0<br>The time after which incoming request threads terminate with no work available.  Zero (0) will keep the threads alive indefinitely.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `0s` |\n| <a name=\"compactor_wait_time_job_max\" class=\"prop\"></a> compactor.wait.time.job.max | **Experimental**<br>**Available since:** 2.1.3<br>Compactors do exponential backoff when their request for work repeatedly come back empty. This is the maximum amount of time to wait between checks for the next compaction job.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `5m` |\n| <a name=\"compactor_wait_time_job_min\" class=\"prop\"></a> compactor.wait.time.job.min | **Experimental**<br>**Available since:** 2.1.3<br>The minimum amount of time to wait between checks for the next compaction job, backing offexponentially until COMPACTOR_MAX_JOB_WAIT_TIME is reached.<br>**type:** TIMEDURATION, **zk mutable:** no, **default value:** `1s` |\n| <a name=\"gc_prefix\" class=\"prop\"></a> **gc.*** | **Available since:** 1.3.5<br>Properties in this category affect the behavior of the accumulo garbage collector. |\n| <a name=\"gc_candidate_batch_size\" class=\"prop\"></a> gc.candidate.batch.size | **Available since:** 2.1.0<br>The amount of memory used as the batch size for garbage collection.<br>**type:** MEMORY, **zk mutable:** yes, **default value:** `50%` |\n| <a name=\"gc_cycle_delay\" class=\"prop\"></a> gc.cycle.delay | **Available since:** 1.3.5<br>Time between garbage collection cycles. In each cycle, old RFiles or write-ahead logs no longer in use are removed from the filesystem.<br>**type:** TIMEDURATION, **zk mutable:** yes, **default value:** `5m` |\n| <a name=\"gc_cycle_start\" class=\"prop\"></a> gc.cycle.start | **Available since:** 1.3.5<br>Time to wait before attempting to garbage collect any old RFiles or write-ahead logs.<br>**type:** TIMEDURATION, **zk mutable:** yes, **default value:** `30s` |\n| <a name=\"gc_port_client\" class=\"prop\"></a> gc.port.client | **Available since:** 1.3.5<br>The listening port for the garbage collector's monitor service.<br>**type:** PORT, **zk mutable:** yes but requires restart of the gc, **default value:** `9998` |\n| <a name=\"gc_post_metadata_action\" class=\"prop\"></a> gc.post.metadata.action | **Available since:** 1.10.0<br>When the gc runs it can make a lot of changes to the metadata, on completion,  to force the changes to be written to disk, the metadata and root tables can be flushed and possibly compacted. Legal values are: compact - which both flushes and compacts the metadata; flush - which flushes only (compactions may be triggered if required); or none.<br>**type:** GC_POST_ACTION, **zk mutable:** yes, **default value:** `flush` |\n| <a name=\"gc_remove_in_use_candidates\" class=\"prop\"></a> gc.remove.in.use.candidates | **Experimental**<br>**Available since:** 2.1.3<br>GC will remove deletion candidates that are in-use from the metadata location. This is expected to increase the speed of subsequent GC runs.<br>**type:** BOOLEAN, **zk mutable:** yes, **default value:** `false` |\n| <a name=\"gc_safemode\" class=\"prop\"></a> gc.safemode | **Available since:** 2.1.0<br>Provides listing of files to be deleted but does not delete any files.<br>**type:** BOOLEAN, **zk mutable:** yes, **default value:** `false` |\n| <a name=\"gc_threads_delete\" class=\"prop\"></a> gc.threads.delete | **Available since:** 1.3.5<br>The number of threads used to delete RFiles and write-ahead logs.<br>**type:** COUNT, **zk mutable:** yes, **default value:** `16` |\n| ~~<a name=\"gc_trace_percent\" class=\"prop\"></a> gc.trace.percent~~ | **Available since:** 1.7.0<br>*Deprecated since:* 2.1.0<br>~~Percent of gc cycles to trace.~~<br>~~**type:** FRACTION~~, ~~**zk mutable:** yes~~, ~~**default value:** `0.01`~~ |\n| ~~<a name=\"gc_trash_ignore\" class=\"prop\"></a> gc.trash.ignore~~ | **Available since:** 1.5.0<br>*Deprecated since:* 2.1.1<br>~~Do not use the Trash, even if it is configured.~~<br>~~**type:** BOOLEAN~~, ~~**zk mutable:** yes~~, ~~**default value:** `false`~~ |\n| <a name=\"general_prefix\" class=\"prop\"></a> **general.*** | **Available since:** 1.3.5<br>Properties in this category affect the behavior of accumulo overall, but do not have to be consistent throughout a cloud. |\n| ~~<a name=\"general_classpaths\" class=\"prop\"></a> general.classpaths~~ | **Available since:** 1.3.5<br>*Deprecated since:* 2.0.0<br>~~The class path should instead be configured by the launch environment (for example, accumulo-env.sh). A list of all of the places to look for a class. Order does matter, as it will look for the jar starting in the first location to the last. Supports full regex on filename alone.~~<br>~~**type:** STRING~~, ~~**zk mutable:** no~~, ~~**default value:** empty~~ |\n```\n\n----------------------------------------\n\nTITLE: Scanning Table in Accumulo Shell\nDESCRIPTION: Shell commands to select a table and scan all its entries. First sets the current table to 'hellotable' and then executes a scan to view all data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Encoding Date Objects for Lexicographic Sorting in Accumulo\nDESCRIPTION: This example shows how to use DateLexicoder to encode Java Date objects so they sort lexicographically in Accumulo. It truncates the date to hour precision and creates a mutation with the encoded date as the row ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_design.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// create new date lexicoder\nDateLexicoder dateEncoder = new DateLexicoder();\n\n// truncate time to hours\nlong epoch = System.currentTimeMillis();\nDate hour = new Date(epoch - (epoch % 3600000));\n\n// encode the rowId so that it is sorted lexicographically\nMutation mutation = new Mutation(dateEncoder.encode(hour));\nmutation.at().family(\"colf\").qualifier(\"colq\").put(new byte[]{});\n```\n\n----------------------------------------\n\nTITLE: RandomBatchScanner output log\nDESCRIPTION: Sample output of the RandomBatchScanner showing performance metrics for the batch scanning operation, including throughput (lookups/sec) and the number of results returned.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/batch.md#2025-04-11_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n07 11:33:11,103 [client.CountingVerifyingReceiver] INFO : Generating 100 random queries...\n07 11:33:11,112 [client.CountingVerifyingReceiver] INFO : finished\n07 11:33:11,260 [client.CountingVerifyingReceiver] INFO : 694.44 lookups/sec   0.14 secs\n\n07 11:33:11,260 [client.CountingVerifyingReceiver] INFO : num results : 100\n\n07 11:33:11,364 [client.CountingVerifyingReceiver] INFO : Generating 100 random queries...\n07 11:33:11,370 [client.CountingVerifyingReceiver] INFO : finished\n07 11:33:11,416 [client.CountingVerifyingReceiver] INFO : 2173.91 lookups/sec   0.05 secs\n\n07 11:33:11,416 [client.CountingVerifyingReceiver] INFO : num results : 100\n```\n\n----------------------------------------\n\nTITLE: Setting Table Configuration via Java API\nDESCRIPTION: Shows how to set configuration properties for a specific table using the Java API through TableOperations. These settings have the highest precedence in the configuration hierarchy.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().setProperty(\"mytable\", \"table.durability\", \"log\");\n```\n\n----------------------------------------\n\nTITLE: Setting Table Configuration via Java API\nDESCRIPTION: Shows how to set configuration properties for a specific table using the Java API through TableOperations. These settings have the highest precedence in the configuration hierarchy.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().setProperty(\"mytable\", \"table.durability\", \"log\");\n```\n\n----------------------------------------\n\nTITLE: Creating and Exporting Accumulo Table\nDESCRIPTION: Shell commands showing table creation, data insertion, splitting, cloning, and exporting. Demonstrates the complete workflow from table creation to export.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/export.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@test15> createtable table1\nroot@test15 table1> insert a cf1 cq1 v1\nroot@test15 table1> insert h cf1 cq1 v2\nroot@test15 table1> insert z cf1 cq1 v3\nroot@test15 table1> insert z cf1 cq2 v4\nroot@test15 table1> addsplits -t table1 b r\nroot@test15 table1> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test15> config -t table1 -s table.split.threshold=100M\nroot@test15 table1> clonetable table1 table1_exp\nroot@test15 table1> offline table1_exp\nroot@test15 table1> exporttable -t table1_exp /tmp/table1_export\nroot@test15 table1> quit\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using StatsCombiner in Accumulo Shell\nDESCRIPTION: Example showing how to create a table, set up the StatsCombiner with both decimal and hexadecimal bases, and insert values that are automatically combined. The combiner calculates min, max, sum, and count for values in specific column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/combiner.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo shell -u username\nEnter current password for 'username'@'instance': ***\n\nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable runners\nusername@instance runners> setiter -t runners -p 10 -scan -minc -majc -n decStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: \n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: stat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 10\nusername@instance runners> setiter -t runners -p 11 -scan -minc -majc -n hexStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: \n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: hstat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 16\nusername@instance runners> insert 123456 name first Joe\nusername@instance runners> insert 123456 stat marathon 240\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    240,240,240,1\nusername@instance runners> insert 123456 stat marathon 230\nusername@instance runners> insert 123456 stat marathon 220\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\nusername@instance runners> insert 123456 hstat virtualMarathon 6a\nusername@instance runners> insert 123456 hstat virtualMarathon 6b\nusername@instance runners> scan\n123456 hstat:virtualMarathon []    6a,6b,d5,2\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\n```\n\n----------------------------------------\n\nTITLE: Counting Files and Directories in Accumulo (Java)\nDESCRIPTION: Command to run the FileCount class, which computes recursive counts of children and descendants in the file system structure and writes the results back to the dirTable.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/dirlist.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Markdown Property Type Reference Table\nDESCRIPTION: A reference table defining valid property types and their formats for Apache Accumulo configuration, including examples of valid and invalid values for each type.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties.md#2025-04-11_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n| Type | Description |\n|--------------|-------------|\n| duration | A non-negative integer optionally followed by a unit of time (whitespace disallowed), as in 30s.<br>If no unit of time is specified, seconds are assumed. Valid units are 'ms', 's', 'm', 'h' for milliseconds, seconds, minutes, and hours.<br>Examples of valid durations are '600', '30s', '45m', '30000ms', '3d', and '1h'.<br>Examples of invalid durations are '1w', '1h30m', '1s 200ms', 'ms', '', and 'a'.<br>Unless otherwise stated, the max value for the duration represented in milliseconds is 9223372036854775807 |\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Configuration Settings\nDESCRIPTION: Shows how to view the configured iterator settings for a table using the config command, displaying settings across different scopes including scan, minc, and majc.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filter.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+---------------------------------------------------------------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+---------------------------------------------------------------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+---------------------------------------------------------------------------\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Uploading Accumulo Token File to HDFS\nDESCRIPTION: Command to upload a locally created token file to HDFS, making it available for use in MapReduce jobs that require Accumulo authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -put root.pw root.pw\n```\n\n----------------------------------------\n\nTITLE: Scanning Data with Histogram in Accumulo Shell\nDESCRIPTION: Accumulo shell command to scan the dataTable again after running the histogram MapReduce job to view both the file data and the computed histogram information in the 'info' column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filedata.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Deleting Row Ranges in Accumulo\nDESCRIPTION: The deleterows command removes a range of rows from a table. Note that the start row is exclusive while the end row is inclusive in the deletion range.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nusage: deleterows [-?] [-b <arg>] [-e <arg>] [-f] [-t <table>]   \ndescription: delete a range of rows in a table.  Note that rows matching the start   \n          row ARE NOT deleted, but rows matching the end row ARE deleted.   \n  -?,-help  display this help   \n  -b,-begin-row <arg>  begin row   \n  -e,-end-row <arg>  end row   \n  -f,-force  delete data even if start or end are not specified   \n  -t,-tableName <table>  table to delete row range\n```\n\n----------------------------------------\n\nTITLE: Creating mutations for Joker character in Accumulo\nDESCRIPTION: Creates a Mutation for Joker with row ID 'id0003' and adds column family-qualifier pairs with values for the character's attributes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/data-model-code.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nMutation mutation3 = new Mutation(\"id0003\");\nmutation3.put(\"villain\",\"alias\", \"Joker\");\nmutation3.put(\"villain\",\"name\", \"Unknown\");\nmutation3.put(\"villain\",\"wearsCape?\", \"false\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Scan Dispatcher in Accumulo\nDESCRIPTION: Sets up a class to dynamically dispatch scans to configured scan executors. The class must implement ScanDispatcher interface. This property is ignored for root and metadata tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\ntable.scan.dispatcher = org.apache.accumulo.core.spi.scan.SimpleScanDispatcher\n```\n\n----------------------------------------\n\nTITLE: Ingesting File System Data into Accumulo\nDESCRIPTION: Command to run the Ingest program that recursively processes files and directories, storing their information across three Accumulo tables with specified visibility settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/dirlist.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Ingest instance zookeepers username password dirTable indexTable dataTable exampleVis 100000 /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Counting Files and Directories in Accumulo\nDESCRIPTION: Command to count direct children and descendants in the directory structure using FileCount class.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/dirlist.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Setting user authorizations as root in Accumulo\nDESCRIPTION: Demonstrates how the root user can set authorizations for other users and shows scanning with different authorization sets. Illustrates that default scan authorizations are the user's full authorization set.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Running the RowHash MapReduce Job\nDESCRIPTION: Command to run the RowHash MapReduce job which computes and inserts hashes for rows that contain a specified column.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/rowhash.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RowHash -u user -p passwd -i instance -t input --column cf:cq\n```\n\n----------------------------------------\n\nTITLE: Configuring MaxMutationSize Constraint in Accumulo Shell\nDESCRIPTION: This snippet shows how to create a table in Accumulo and configure it with the MaxMutationSize constraint through the Accumulo shell. The constraint limits mutation size to prevent memory issues in tablet servers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/maxmutation.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n    \nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable test_ingest\nusername@instance test_ingest> config -t test_ingest -s table.constraint.1=org.apache.accumulo.examples.simple.constraints.MaxMutationSize\nusername@instance test_ingest>\n```\n\n----------------------------------------\n\nTITLE: Creating Reverse Index for Continuous Querying\nDESCRIPTION: Command to run the Reverse.java program, which populates the 'doc2term' table with a reverse index for use in continuous querying.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Reverse -i instance -z zookeepers --shardTable shard --doc2Term doc2term -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Scanning Accumulo Table for Updated File Data and Histogram\nDESCRIPTION: This Accumulo shell command scans the dataTable again to view the updated file data, including the character histogram stored in the 'info' column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filedata.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Scan Executor Configuration\nDESCRIPTION: Properties for configuring scan executors including thread counts, priorities and custom prioritizers. Includes settings for default and metadata table scan executors.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\nsserver.scan.executors.default.threads=16\nsserver.scan.executors.meta.threads=8\nsserver.scan.executors.default.prioritizer=\nsserver.scan.reference.expiration=5m\n```\n\n----------------------------------------\n\nTITLE: Performing File Search Operations in Accumulo\nDESCRIPTION: Examples of searching for files using different patterns with QueryUtil class on the index table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/dirlist.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t indexTable --auths exampleVis --path 'filename*' --search\n```\n\n----------------------------------------\n\nTITLE: Setting multiple authorizations and scanning with subsets in Accumulo\nDESCRIPTION: Shows how to set multiple authorizations for a user and scan with a subset of those authorizations. Demonstrates how visibility expressions with AND and OR operators affect what data is visible with different authorization sets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A,B,broccoli -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nusername@instance vistest> scan -s B\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Order Section Key Format\nDESCRIPTION: Format for the order section key-value pairs that manage WAL replication scheduling. Includes timestamp of WAL closing and HDFS URI to ensure proper replication ordering.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_15\n\nLANGUAGE: text\nCODE:\n```\n<time_of_WAL_closing>\\x00<HDFS_uri_to_WAL> order:<local_table_id> [] -> <protobuf>\n```\n\n----------------------------------------\n\nTITLE: Creating an Accumulo Table with SummingCombiner for Word Counts\nDESCRIPTION: Shell commands to create an Accumulo table named 'wordCount' and configure a SummingCombiner iterator on the 'count' column family to automatically sum values during processing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable wordCount\nusername@instance wordCount> setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -p 10 -t wordCount -majc -minc -scan\nSummingCombiner interprets Values as Longs and adds them together. A variety of encodings (variable length, fixed length, or string) are available\n----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: false\n----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: count\n----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: false\n----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING\nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Using BatchScanner for Parallel Data Reading in Accumulo\nDESCRIPTION: Demonstrates using BatchScanner to efficiently retrieve multiple ranges of data in parallel from Accumulo TabletServers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Range> ranges = new ArrayList<Range>();\n// populate list of ranges ...\n\nBatchScanner bscan =\n    conn.createBatchScanner(\"table\", auths, 10);\n\nbscan.setRanges(ranges);\nbscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan)\n    System.out.println(e.getValue());\n```\n\n----------------------------------------\n\nTITLE: Configuring Kerberos Properties for Accumulo Trace Table\nDESCRIPTION: Configuration properties needed in accumulo.properties to enable trace table access with Kerberos authentication. The trace.token.property.keytab must be explicitly set to point to the keytab file for the trace.user principal.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_16\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.kerberos.keytab=/path/to/keytab\ntrace.token.property.keytab=/path/to/trace/keytab\ntrace.user=trace_principal\n```\n\n----------------------------------------\n\nTITLE: Creating Checkstyle Configuration for Import Control\nDESCRIPTION: XML configuration for the Checkstyle module that sets up the ImportControl module. This file should be named 'checkstyle.xml' and placed in the project root directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-11-04-checkstyle-import-control.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<!DOCTYPE module PUBLIC \"-//Puppy Crawl//DTD Check Configuration 1.3//EN\" \"http://www.puppycrawl.com/dtds/configuration_1_3.dtd\">\n<module name=\"Checker\">\n  <property name=\"charset\" value=\"UTF-8\"/>\n  <module name=\"TreeWalker\">\n    <!--check that only Accumulo public APIs are imported-->\n    <module name=\"ImportControl\">\n      <property name=\"file\" value=\"import-control.xml\"/>\n    </module>\n  </module>\n</module>\n```\n\n----------------------------------------\n\nTITLE: Ingesting Filesystem Data into Accumulo\nDESCRIPTION: Command to ingest filesystem data into Accumulo using the Ingest class with specified parameters including instance, zookeepers, credentials, visibility and chunk size.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/dirlist.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Ingest -i instance -z zookeepers -u username -p password --vis exampleVis --chunkSize 100000 /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Scanning with authorizations in Accumulo\nDESCRIPTION: Demonstrates scanning a table with specific authorizations. Shows that a user without any authorizations cannot scan data with visibility labels and that scan authorizations must be a subset of user authorizations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> scan\nusername@instance vistest> scan -s A\n06 11:43:14,951 [shell.Shell] ERROR: java.lang.RuntimeException: org.apache.accumulo.core.client.AccumuloSecurityException: Error BAD_AUTHORIZATIONS - The user does not have the specified authorizations assigned\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Word Count Job with Accumulo\nDESCRIPTION: Command to execute the WordCount MapReduce job that processes input files and writes word counts to Accumulo. The job connects to Accumulo using the provided instance, username, and password parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters \n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data with RandomBatchWriter in Accumulo\nDESCRIPTION: This snippet demonstrates inserting 1 million random values into an Accumulo table using the RandomBatchWriter utility. The data ranges between 0 and 1 billion with seed 7 and visibility label 'exampleVis'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Managing Configuration Properties in Accumulo\nDESCRIPTION: The config command manages system and table properties in Accumulo. It allows listing, setting, and deleting properties with filtering capabilities.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nusage: config [-?] [-d <property> | -f <string> | -s <property=value>]  [-np]  [-t   \n          <table>]   \ndescription: prints system properties and table specific properties   \n  -?,-help  display this help   \n  -d,-delete <property>  delete a per-table property   \n  -f,-filter <string>  show only properties that contain this string   \n  -np,-no-pagination  disables pagination of output   \n  -s,-set <property=value>  set a per-table property   \n  -t,-table <table>  display/set/delete properties for specified table\n```\n\n----------------------------------------\n\nTITLE: Running Continuous Queries on Shard Index\nDESCRIPTION: Command to execute ContinuousQuery program that selects 5 random terms per document and continuously queries the shard table, displaying match counts and execution times.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/shard.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.ContinuousQuery -i instance -z zookeepers --shardTable shard --doc2Term doc2term -u username -p password --terms 5\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Setting MaxMutation Constraint in Accumulo Shell\nDESCRIPTION: Shell commands to create a new table and configure the MaxMutationSize constraint. This sets up a limitation where mutations larger than 1/256th of tablet server memory will be rejected.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/maxmutation.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable test_ingest\nusername@instance test_ingest> config -t test_ingest -s table.constraint.1=org.apache.accumulo.examples.simple.constraints.MaxMutationSize\nusername@instance test_ingest>\n```\n\n----------------------------------------\n\nTITLE: Dumping RFile Contents with rfile-info\nDESCRIPTION: Using the --dump flag with rfile-info to display the actual key-value pairs stored in an Accumulo RFile, useful for data verification and content inspection.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo rfile-info --dump /accumulo/tables/1/default_tablet/A000000n.rf\nrow columnFamily:columnQualifier [visibility] timestamp deleteFlag -> Value\n...\n```\n\n----------------------------------------\n\nTITLE: Setting Up FooFilter Iterator\nDESCRIPTION: Command to configure the FooFilter from the JAR as an iterator for the 'nofoo' table, with priority 10, applying to scan, minor and major compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/classpath.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nsetiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\n```\n\n----------------------------------------\n\nTITLE: Granting Table Creation Permission to User in Accumulo\nDESCRIPTION: Shows how to grant the System.CREATE_TABLE permission to a user and then successfully create a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/visibility.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> user root\nEnter password for user root: ********\nroot@instance> grant -s System.CREATE_TABLE -u username\nroot@instance> user username \nEnter password for user username: ********\nusername@instance> createtable vistest\nusername@instance> userpermissions\nSystem permissions: System.CREATE_TABLE\n\nTable permissions (!METADATA): Table.READ\nTable permissions (vistest): Table.READ, Table.WRITE, Table.BULK_IMPORT, Table.ALTER_TABLE, Table.GRANT, Table.DROP_TABLE\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Pre-splitting Tables in Accumulo Shell\nDESCRIPTION: Command to pre-split an Accumulo table using a split file to create multiple tablets for better ingest parallelism.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> addsplits -sf /local_splitfile -t mytable\n```\n\n----------------------------------------\n\nTITLE: Creating AccumuloClient with Kerberos Authentication\nDESCRIPTION: Creates an Accumulo client using Kerberos for authentication. This demonstrates using a KerberosToken for secure, password-less authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/clients.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nKerberosToken token = new KerberosToken();\nAccumuloClient client = Accumulo.newClient().to(\"myinstance\", \"zookeeper1,zookeper2\")\n                              .as(token.getPrincipal(), token).build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Kerberos Authentication for Accumulo Client\nDESCRIPTION: These properties are set in accumulo-client.properties to configure Kerberos authentication for an Accumulo client. They must match the server configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_8\n\nLANGUAGE: properties\nCODE:\n```\nsasl.enabled = true\nsasl.qop = auth\nsasl.kerberos.server.primary = accumulo\n```\n\n----------------------------------------\n\nTITLE: Performing Random Lookups with RandomBatchScanner in Accumulo\nDESCRIPTION: This snippet demonstrates how to perform 500 random queries against the Accumulo table using the RandomBatchScanner. Using seed 7 ensures all queries find existing entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -s 7 instance zookeepers username password bloom_test 500 0 1000000000 50 20 exampleVis\nGenerating 500 random queries...finished\n96.19 lookups/sec   5.20 secs\nnum results : 500\nGenerating 500 random queries...finished\n102.35 lookups/sec   4.89 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Creating and Testing Constraints in Accumulo Shell\nDESCRIPTION: This shell session demonstrates how to create a table with constraints, add constraint classes, and attempt inserts that both satisfy and violate the constraints. The constraints enforce alphanumeric keys and numeric values in the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/constraints.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable testConstraints\nusername@instance testConstraints> constraint -a org.apache.accumulo.examples.simple.constraints.NumericValueConstraint\nusername@instance testConstraints> constraint -a org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint\nusername@instance testConstraints> insert r1 cf1 cq1 1111\nusername@instance testConstraints> insert r1 cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> insert r1! cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint, violationCode:1, violationDescription:Row was not alpha numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> scan\nr1 cf1:cq1 []    1111\nusername@instance testConstraints>\n```\n\n----------------------------------------\n\nTITLE: Running RowHash MapReduce Job\nDESCRIPTION: Command to execute the RowHash MapReduce job that processes the input table and generates hashes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/rowhash.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RowHash -u user -p passwd -i instance -t input --column cf:cq\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data into Accumulo Table\nDESCRIPTION: This command uses RandomBatchWriter to insert 1 million random values into the 'bloom_test' table. The rows range from 0 to 1 billion, and the random number generator is initialized with seed 7.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Implementing Mapper Class for Accumulo Input in MapReduce\nDESCRIPTION: Example of a Mapper class implementation that reads from an Accumulo table. The Mapper takes Key and Value objects from Accumulo and transforms them into WritableComparable and Writable objects for MapReduce processing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass MyMapper extends Mapper<Key,Value,WritableComparable,Writable> {\n    public void map(Key k, Value v, Context c) {\n        // transform key and value data here\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: jQuery UI MIT License Text\nDESCRIPTION: The full MIT license text for jQuery UI that grants permission to use, modify, and distribute the software with minimal restrictions. It includes copyright information, permission details, warranty disclaimers, and notes about sample code being under CC0 license.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/apidocs/legal/jqueryUI.md#2025-04-11_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nCopyright jQuery Foundation and other contributors, https://jquery.org/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/jquery-ui\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nCopyright and related rights for sample code are waived via CC0. Sample\ncode is defined as all source code contained within the demos directory.\n\nCC0: http://creativecommons.org/publicdomain/zero/1.0/\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n```\n\n----------------------------------------\n\nTITLE: Creating Users in Accumulo\nDESCRIPTION: The createuser command creates a new user in Accumulo with optional scan authorizations for security control.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nusage: createuser <username> [-?] [-s <comma-separated-authorizations>]   \ndescription: creates a new user   \n  -?,-help  display this help   \n  -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Tables for Shard Example\nDESCRIPTION: Commands to create the required 'shard' and 'doc2term' tables in Accumulo for the shard example\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/shard.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance> createtable shard\nusername@instance shard> createtable doc2term\n```\n\n----------------------------------------\n\nTITLE: Testing MaxMutation Constraint with TestIngest\nDESCRIPTION: Command to test the MaxMutationSize constraint by attempting to ingest a single row with 10000 columns, which should exceed the memory limit and trigger a constraint violation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/maxmutation.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.test.TestIngest -i instance -z zookeepers -u username -p password --rows 1 --cols 10000 \nERROR : Constraint violates : ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.MaxMutationSize, violationCode:0, violationDescription:mutation exceeded maximum size of 188160, numberOfViolatingMutations:1)\n```\n\n----------------------------------------\n\nTITLE: Inserting data with visibility labels in Accumulo\nDESCRIPTION: This snippet demonstrates how to insert data with visibility expressions that control access. It shows simple visibility labels, compound expressions with AND (&) and OR (|) operators, and the requirement for proper parentheses.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n            ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorization in Accumulo Shell\nDESCRIPTION: Command to set the 'exampleVis' authorization for a specific username using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/batch.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u root -e \"setauths -u username -s exampleVis\"\n```\n\n----------------------------------------\n\nTITLE: Verifying RowHash Results in Accumulo\nDESCRIPTION: Shell commands to scan the table after running the RowHash job to verify that MD5 hashes have been added for each row.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/rowhash.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> scan -t input\na-row cf:cq []    value\na-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nb-row cf:cq []    value\nb-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nusername@instance>\n```\n\n----------------------------------------\n\nTITLE: Configuring VFS Classpath for Application\nDESCRIPTION: Configuration example showing how to set up classpath contexts for loading JARs from HDFS and local filesystem for an application.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_4\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.vfs.context.classpath.app1=hdfs://localhost:8020/applicationA/classpath/.*.jar,file:///opt/applicationA/lib/.*.jar\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data using RandomBatchWriter in Accumulo\nDESCRIPTION: This snippet demonstrates how to insert 1 million random values into the Accumulo table using the RandomBatchWriter class. The random number generator is initialized with seed 7, and values range between 0 and 1 billion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter -s 7 instance zookeepers username password bloom_test 1000000 0 1000000000 50 2000000 60000 3 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Scanning a Table with Empty Authorizations in Apache Accumulo\nDESCRIPTION: Creates a scanner with empty authorizations to retrieve data from the 'GothamPD' table. This demonstrates that users without specific authorizations can only see unprotected columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\ntry (ScannerBase scan = client.createScanner(\"GothamPD\", Authorizations.EMPTY)) {\n  System.out.println(\"Gotham Police Department Persons of Interest:\");\n    for (Map.Entry<Key, Value> entry : scan) {\n    System.out.printf(\"Key : %-50s  Value : %s\\n\", entry.getKey(), entry.getValue());\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Host-Specific Certificates and Keystores with OpenSSL\nDESCRIPTION: Creates server certificates signed by the previously created CA. This process generates a private key, creates a certificate signing request, issues a CA-signed certificate, and packages it into a Java KeyStore. These host-specific certificates are used by Accumulo servers or clients.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/wire-encryption.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Create the private key for our server\nopenssl genrsa -out server.key 4096\n\n# Generate a certificate signing request (CSR) with our private key\nopenssl req -new -key server.key -out server.csr\n\n# Use the CSR and the CA to create a certificate for the server (a reply to the CSR)\nopenssl x509 -req -in server.csr -CA root.pem -CAkey root.key -CAcreateserial \\\n    -out server.crt -days 365\n\n# Use the certificate and the private key for our server to create PKCS12 file\nopenssl pkcs12 -export -in server.crt -inkey server.key -certfile server.crt \\\n    -name 'server-key' -out server.p12\n\n# Create a Java KeyStore for the server using the PKCS12 file (private key)\nkeytool -importkeystore -srckeystore server.p12 -srcstoretype pkcs12 -destkeystore \\\n    server.jks -deststoretype JKS\n\n# Remove the PKCS12 file as we don't need it\nrm server.p12\n\n# Import the CA-signed certificate to the keystore\nkeytool -import -trustcacerts -alias server-crt -file server.crt -keystore server.jks\n```\n\n----------------------------------------\n\nTITLE: Creating table for batch operations in Accumulo\nDESCRIPTION: Command to create the 'batchtest1' table in Accumulo that will be used for the batch writing and scanning operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -e \"createtable batchtest1\"\n```\n\n----------------------------------------\n\nTITLE: Creating Table in Accumulo\nDESCRIPTION: Command to create a new table named 'batchtest1' in Accumulo using the shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u username -e \"createtable batchtest1\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Filesystem Data in Accumulo\nDESCRIPTION: Command to launch the viewer application for browsing filesystem data stored in Accumulo tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/dirlist.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Viewer -i instance -z zookeepers -u username -p password -t dirTable --dataTable dataTable --auths exampleVis --path /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Creating Table With Bloom Filters and Custom Compaction Ratio\nDESCRIPTION: This snippet demonstrates creating a table with bloom filters enabled and a custom major compaction ratio of 7. This configuration allows for testing bloom filter performance across multiple map files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test2\nusername@instance bloom_test2> config -t bloom_test2 -s table.compaction.major.ratio=7\nusername@instance bloom_test2> config -t bloom_test2 -s table.bloom.enabled=true\nusername@instance bloom_test2> exit\n```\n\n----------------------------------------\n\nTITLE: Help Command Syntax\nDESCRIPTION: Command to provide information about available commands with options for pagination control.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_29\n\nLANGUAGE: shell\nCODE:\n```\nhelp [ <command> <command> ] [-?] [-np]\n```\n\n----------------------------------------\n\nTITLE: Deleting Individual Records in Accumulo\nDESCRIPTION: The delete command removes a specific record from a table, identified by row, column family, and qualifier. It supports authorization labels and timestamps.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nusage: delete <row> <colfamily> <colqualifier> [-?] [-l <expression>] [-t   \n          <timestamp>]   \ndescription: deletes a record from a table   \n  -?,-help  display this help   \n  -l,-authorization-label <expression>  formatted authorization label expression   \n  -t,-timestamp <timestamp>  timestamp to use for insert\n```\n\n----------------------------------------\n\nTITLE: Setting Authorizations for a User in Accumulo\nDESCRIPTION: This snippet shows the process of setting authorizations for a user, which requires the System.ALTER_USER permission, typically held by the root user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> setauths -s A\n06 11:53:42,056 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance vistest>\n\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Running Word Count with Token File Authentication\nDESCRIPTION: Commands to run the MapReduce word count job using token file authentication instead of direct password authentication, showing two different approaches for the same task.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -tf tokenfile\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TokenFileWordCount instance zookeepers username tokenfile /user/username/wc wordCount\n```\n\n----------------------------------------\n\nTITLE: Verifying Results in Accumulo Shell\nDESCRIPTION: Commands to view the results of the RowHash operation, showing both original data and generated hashes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/rowhash.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> scan -t input\na-row cf:cq []    value\na-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nb-row cf:cq []    value\nb-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nusername@instance>\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Visibilities in Accumulo\nDESCRIPTION: Demonstrates how to insert data with different visibility labels, including simple and complex boolean expressions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n            ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Granting authorizations and scanning with authorization subsets in Accumulo\nDESCRIPTION: This snippet shows the root user setting authorizations for another user, and then demonstrates scanning with those authorizations. It illustrates that the default scan uses all of a user's authorizations, but can be limited to a subset.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Running RegexExample MapReduce Job on Accumulo Data\nDESCRIPTION: This command demonstrates how to run the RegexExample MapReduce job that searches for rows starting with 'dog' in the input table. It uses a scan-time iterator for pattern matching and outputs results to HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/regex.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RegexExample -u user -p passwd -i instance -t input --rowRegex 'dog.*' --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Displaying Classpath in Accumulo Shell\nDESCRIPTION: The classpath command lists the current files on the Java classpath used by Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusage: classpath [-?]   \ndescription: lists the current files on the classpath   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Table without Bloom Filters\nDESCRIPTION: This set of commands inserts 3 million entries into 'bloom_test1' using RandomBatchWriter with different seeds, flushing after each million entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test1 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n```\n\n----------------------------------------\n\nTITLE: Setting Authorizations for a User in Accumulo\nDESCRIPTION: This snippet shows the process of setting authorizations for a user, which requires the System.ALTER_USER permission, typically held by the root user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> setauths -s A\n06 11:53:42,056 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance vistest>\n\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Compaction Execution and Status Updates in Accumulo Logs\nDESCRIPTION: Log entries showing the Compactor executing the compaction job, sending status updates to the Coordinator, and the Coordinator updating the metadata table with completion information when the job succeeds.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_8\n\nLANGUAGE: log\nCODE:\n```\n2021-04-13T14:54:11,597 [compactor.Compactor] INFO : Received next compaction job: TExternalCompactionJob(externalCompactionId:ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c, extent:TKeyExtent(table:32, endRow:null, prevEndRow:null), files:[In\nputFile(metadataFileEntry:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf, size:0, entries:0, timestamp:0), InputFile(metadataFileEntry:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf, size:0, entries\n:0, timestamp:0)], priority:3, readRate:0, writeRate:0, iteratorSettings:IteratorConfig(iterators:[]), type:FULL, reason:USER, outputFile:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf_tmp, propagateDeletes:false, kind\n:USER)\n2021-04-13T14:54:11,598 [compactor.Compactor] INFO : Starting up compaction runnable for job: TExternalCompactionJob(externalCompactionId:ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c, extent:TKeyExtent(table:32, endRow:null, prevEndRow:null)\n, files:[InputFile(metadataFileEntry:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf, size:0, entries:0, timestamp:0), InputFile(metadataFileEntry:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf, size\n:0, entries:0, timestamp:0)], priority:3, readRate:0, writeRate:0, iteratorSettings:IteratorConfig(iterators:[]), type:FULL, reason:USER, outputFile:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf_tmp, propagateDeletes:\nfalse, kind:USER)\n2021-04-13T14:54:11,599 [compactor.Compactor] INFO : CompactionCoordinator address is: localhost:9100\n2021-04-13T14:54:11,599 [coordinator.CompactionCoordinator] INFO : Compaction status update, id: ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c, timestamp: 1618325651599, state: STARTED, message: Compaction started\n2021-04-13T14:54:12,601 [compactor.Compactor] INFO : Starting compactor\n2021-04-13T14:54:12,601 [compactor.Compactor] INFO : Progress checks will occur every 1 seconds\n2021-04-13T14:54:12,718 [ratelimit.SharedRateLimiterFactory] DEBUG: RateLimiter 'read_rate_limiter': 69,672 of 0 permits/second\n2021-04-13T14:54:12,718 [ratelimit.SharedRateLimiterFactory] DEBUG: RateLimiter 'write_rate_limiter': 45,120 of 0 permits/second\n2021-04-13T14:54:13,179 [compactor.Compactor] INFO : Compaction completed successfully ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c\n2021-04-13T14:54:13,180 [compactor.Compactor] INFO : CompactionCoordinator address is: localhost:9100\n2021-04-13T14:54:13,181 [coordinator.CompactionCoordinator] INFO : Compaction status update, id: ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c, timestamp: 1618325653180, state: SUCCEEDED, message: Compaction completed successfully\n2021-04-13T14:54:14,182 [compactor.Compactor] INFO : Compaction thread finished.\n2021-04-13T14:54:14,182 [compactor.Compactor] INFO : Updating coordinator with compaction completion.\n2021-04-13T14:54:14,184 [coordinator.CompactionCoordinator] INFO : Compaction completed, id: ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c, stats: CompactionStats(entriesRead:100000, entriesWritten:100000, fileSize:12354)\n2021-04-13T14:54:14,185 [coordinator.CompactionFinalizer] INFO : Writing completed external compaction to metadata table: {\"extent\":{\"tableId\":\"2\"},\"state\":\"FINISHED\",\"fileSize\":12354,\"entries\":100000}\n2021-04-13T14:54:14,223 [coordinator.CompactionFinalizer] INFO : Queueing tserver notification for completed external compaction: {\"extent\":{\"tableId\":\"2\"},\"state\":\"FINISHED\",\"fileSize\":12354,\"entries\":100000}\n2021-04-13T14:54:14,290 [coordinator.CompactionFinalizer] INFO : Notifying tserver localhost:9997[10000bf4e0a0004] that compaction {\"extent\":{\"tableId\":\"2\"},\"state\":\"FINISHED\",\"fileSize\":12354,\"entries\":100000} has finished.\n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest without Isolation in Apache Accumulo\nDESCRIPTION: This command runs the InterferenceTest program for 5000 iterations without isolation enabled. It demonstrates how scanning without isolation can lead to inconsistent reads when a row is being updated concurrently.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/isolation.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000\n```\n\n----------------------------------------\n\nTITLE: Granting table creation permissions to a user in Accumulo\nDESCRIPTION: This snippet shows how to grant system permissions to a user, specifically the System.CREATE_TABLE permission, allowing the user to create tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> user root\nEnter password for user root: ********\nroot@instance> grant -s System.CREATE_TABLE -u username\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\nusername@instance> userpermissions\nSystem permissions: System.CREATE_TABLE\n\nTable permissions (accumulo.metadata): Table.READ\nTable permissions (vistest): Table.READ, Table.WRITE, Table.BULK_IMPORT, Table.ALTER_TABLE, Table.GRANT, Table.DROP_TABLE\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Scanning Table in Shell\nDESCRIPTION: Shell commands to select and scan a table to view all entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing Data with MASC in Python\nDESCRIPTION: This snippet demonstrates how to read data from and write data to Accumulo using the MASC connector in PySpark. It shows how to configure Accumulo properties, define a schema, and perform read/write operations with the DataSource API.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2020-02-26-accumulo-spark-connector.md#2025-04-11_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom configparser import ConfigParser\nfrom pyspark.sql import types as T\n\ndef get_properties(properties_file):\n    \"\"\"Read Accumulo client properties file\"\"\"\n    config = ConfigParser()\n    with open(properties_file) as stream:\n        config.read_string(\"[top]\\n\" + stream.read())\n    return dict(config['top'])\n\nproperties = get_properties('/opt/muchos/install/accumulo-2.0.0/conf/accumulo-client.properties')\nproperties['table'] = 'demo_table' # Define Accumulo table where data will be written\nproperties['rowkey'] = 'id'        # Identify column to use as the key for Accumulo rows\n\n# define the schema\nschema = T.StructType([\n  T.StructField(\"sentiment\", T.IntegerType(), True),\n  T.StructField(\"date\", T.StringType(), True),\n  T.StructField(\"query_string\", T.StringType(), True),\n  T.StructField(\"user\", T.StringType(), True),\n  T.StructField(\"text\", T.StringType(), True)\n])\n\n# Read from Accumulo\ndf = (spark\n      .read\n      .format(\"com.microsoft.accumulo\")\n      .options(**options)  # define Accumulo properties\n      .schema(schema))     # define schema for data retrieval\n\n# Write to Accumulo\nproperties['table'] = 'output_table'\n\n(df\n .write\n .format(\"com.microsoft.accumulo\")\n .options(**options)\n .save())\n```\n\n----------------------------------------\n\nTITLE: Flushing Accumulo Table\nDESCRIPTION: This command flushes the 'bloom_test' table to ensure all data is written to disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test -w'\n05 10:40:06,069 [shell.Shell] INFO : Flush of table bloom_test completed.\n```\n\n----------------------------------------\n\nTITLE: Deleting Users in Accumulo\nDESCRIPTION: The deleteuser command removes a user from the Accumulo system. It requires specifying the username to be deleted.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nusage: deleteuser <username> [-?]   \ndescription: deletes a user   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Running Word Count MapReduce Job with Accumulo\nDESCRIPTION: Command to execute the WordCount MapReduce job that processes text files from HDFS and stores word counts in an Accumulo table, along with the job's output showing successful completion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters\n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Example Output from Terasort Data Scan\nDESCRIPTION: This shows the expected output format when scanning the 'sort' table after the terasort operation. The data consists of random keys followed by the column family, column qualifier, and random value data of configured sizes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/terasort.md#2025-04-11_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n+l-$$OE/ZH c:         4 []    GGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOO\n,C)wDw//u= c:        10 []    CCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKK\n75@~?'WdUF c:         1 []    IIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQ\n;L+!2rT~hd c:         8 []    MMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUU\nLsS8)|.ZLD c:         5 []    OOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWW\nM^*dDE;6^< c:         9 []    UUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCC\n^Eu)<n#kdP c:         3 []    YYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGG\nle5awB.$sm c:         6 []    WWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEE\nq__[fwhKFg c:         7 []    EEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMM\nw[o||:N&H, c:         2 []    QQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYY\n```\n\n----------------------------------------\n\nTITLE: Running Terasort Data Ingestion with MapReduce\nDESCRIPTION: Command to execute the TeraSortIngest MapReduce job with configurable parameters for data generation including key/value sizes, record count, and number of splits.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/terasort.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TeraSortIngest \\\n-i instance -z zookeepers -u user -p password \\\n--count 10 \\\n--minKeySize 10 \\\n--maxKeySize 10 \\\n--minValueSize 78 \\\n--maxValueSize 78 \\\n--table sort \\\n--splits 10 \\\n```\n\n----------------------------------------\n\nTITLE: Scanning Table in Accumulo Shell\nDESCRIPTION: Accumulo shell commands to select a table and scan its contents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Verifying GPG Signatures of Release Artifacts\nDESCRIPTION: Commands to import developer keys and verify cryptographic signatures of Accumulo release artifacts.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/verifying-release.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngpg --import KEYS; gpg --verify *.asc\n```\n\n----------------------------------------\n\nTITLE: Running File Count MapReduce Job\nDESCRIPTION: Command to execute MapReduce job for counting direct children and descendants in the file system structure. Results are written back to the source table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/dirlist.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./bin/tool.sh lib/accumulo-examples-*[^c].jar org.apache.accumulo.examples.dirlist.FileCountMR instance zookeepers username password direxample direxample exampleVis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Creating Table in Accumulo Shell\nDESCRIPTION: Command to create a new table named 'batchtest1' in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u username -e \"createtable batchtest1\"\n```\n\n----------------------------------------\n\nTITLE: Granting DELEGATION_TOKEN System Permission in Accumulo Shell\nDESCRIPTION: These commands demonstrate how to check a user's permissions and grant the DELEGATION_TOKEN system permission to a user using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_6\n\nLANGUAGE: console\nCODE:\n```\n# Check a user's permissions\nadmin@REALM@accumulo> userpermissions -u user@REALM\n\n# Grant the DELEGATION_TOKEN system permission to a user\nadmin@REALM@accumulo> grant System.DELEGATION_TOKEN -s -u user@REALM\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Maven Plugin for Integration Testing\nDESCRIPTION: XML configuration for the Accumulo Maven Plugin that starts a test instance during the pre-integration-test phase and stops it during the post-integration-test phase. This plugin is designed to work with maven-failsafe-plugin for testing client applications.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-05-02-accumulo-1.6.0.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<plugin>\n  <groupId>org.apache.accumulo</groupId>\n  <artifactId>accumulo-maven-plugin</artifactId>\n  <version>1.6.0</version>\n  <configuration>\n    <instanceName>plugin-it-instance</instanceName>\n    <rootPassword>ITSecret</rootPassword>\n  </configuration>\n  <executions>\n    <execution>\n      <id>run-plugin</id>\n      <goals>\n        <goal>start</goal>\n        <goal>stop</goal>\n      </goals>\n    </execution>\n  </executions>\n</plugin>\n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Shard Index for Terms\nDESCRIPTION: Command to query the shard index for files containing specific terms using the Query program.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query -i instance -z zookeepers -t shard -u username -p password foo bar\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo Shell\nDESCRIPTION: Command to create a new table called 'hellotable' in Accumulo using the shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable hellotable\n```\n\n----------------------------------------\n\nTITLE: Running Reverse Index Operation\nDESCRIPTION: Command to populate the doc2term table by reverse indexing the shard table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.shard.Reverse instance zookeepers shard doc2term username password\n```\n\n----------------------------------------\n\nTITLE: Running Basic Integration Tests with Maven\nDESCRIPTION: Command to build Accumulo and run 'sunny-day' integration tests along with checkstyle and findbugs. Useful before submitting a pull request to verify basic functionality.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmvn verify -Psunny\n```\n\n----------------------------------------\n\nTITLE: Authenticating Users in Accumulo Shell\nDESCRIPTION: The 'authenticate' command verifies a user's credentials in the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n**authenticate**   \n\n    usage: authenticate <username> [-?]   \n    description: verifies a user's credentials   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Create Accumulo Table with Combiner\nDESCRIPTION: Shell commands to create an Accumulo table named 'wordCount' and configure a SummingCombiner iterator for counting words.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable wordCount\nusername@instance wordCount> setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -p 10 -t wordCount -majc -minc -scan\nSummingCombiner interprets Values as Longs and adds them together. A variety of encodings (variable length, fixed length, or string) are available\n----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: false\n----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: count\n----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: false\n----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING\nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Initializing Sample Data in Accumulo Shell\nDESCRIPTION: Shell commands to create a table and insert sample data using the Accumulo shell interface. Creates a table named 'input' with several key-value pairs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/tabletofile.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert dog cf cq dogvalue\nusername@instance> insert cat cf cq catvalue\nusername@instance> insert junk family qualifier junkvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo\nDESCRIPTION: Demonstrates how to set authorizations for a user, which requires the System.ALTER_USER permission.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/visibility.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> setauths -s A\n06 11:53:42,056 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance vistest> \n\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest> \n\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A,B,broccoli -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nusername@instance vistest> scan -s B\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Creating test data in Accumulo shell\nDESCRIPTION: Shell commands to create a table named 'input' and insert sample data with rows 'a-row' and 'b-row'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/rowhash.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable input\nusername@instance> insert a-row cf cq value\nusername@instance> insert b-row cf cq value\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Compacting Accumulo Tables\nDESCRIPTION: The 'compact' command sets all tablets for a table to major compact as soon as possible. It supports pattern matching for table names and can override future scheduled compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n**compact**   \n\n    usage: compact [-?] [-override] -p <pattern> | -t <tableName>   \n    description: sets all tablets for a table to major compact as soon as possible   \n           (based on current time)   \n      -?,-help  display this help   \n      -override  override a future scheduled compaction   \n      -p,-pattern <pattern>  regex pattern of table names to flush   \n      -t,-table <tableName>  name of a table to flush   \n```\n\n----------------------------------------\n\nTITLE: Configuring Mixed Internal and External Compactions in Accumulo\nDESCRIPTION: Shell command to create a compaction service that uses both internal executors for smaller compactions and an external queue for large compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s 'tserver.compaction.major.service.cs1.planner.opts.executors=[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"16M\",\"numThreads\":8},{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":4},{\"name\":\"large\",\"type\":\"external\",\"queue\":\"LargeQ\"}]'\n```\n\n----------------------------------------\n\nTITLE: Retrieving Accumulo User Authorizations\nDESCRIPTION: The 'getauths' command displays the maximum scan authorizations for a user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_23\n\nLANGUAGE: markdown\nCODE:\n```\n**getauths**   \n\n    usage: getauths [-?] [-u <user>]   \n    description: displays the maximum scan authorizations for a user   \n      -?,-help  display this help   \n      -u,-user <user>  user to operate on   \n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Instance Secret Using Hadoop Credential Provider\nDESCRIPTION: This command creates an entry for the Accumulo instance secret in a Java KeyStore using the Hadoop Credential Provider. It prompts for the secret value and stores it securely.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nhadoop credential create instance.secret --provider jceks://file/etc/accumulo/conf/accumulo.jceks\n```\n\n----------------------------------------\n\nTITLE: Select Record Command in Accumulo Shell\nDESCRIPTION: Command to scan and display a single record from a table based on row, column family and qualifier\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\nselect <row> <columnfamily> <columnqualifier> [-?] [-np] [-s <comma-separated-authorizations>] [-st] [-t <table>]\n```\n\n----------------------------------------\n\nTITLE: Setting AgeOffFilter for Minor and Major Compactions in Accumulo\nDESCRIPTION: This snippet shows how to configure AgeOffFilter for minor and major compactions to permanently remove aged data. It demonstrates using the -class flag to specify the filter class, followed by flushing and compacting the table to apply the changes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filter.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance filtertest> setiter -t filtertest -minc -majc -p 10 -n myfilter -class org.apache.accumulo.core.iterators.user.AgeOffFilter\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method: \n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day: \nusername@instance filtertest> flush\n06 10:42:24,806 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact\n06 10:42:36,781 [shell.Shell] INFO : Compaction of table filtertest started for given range\nusername@instance filtertest> flush -t filtertest -w\n06 10:42:52,881 [shell.Shell] INFO : Flush of table filtertest completed.\nusername@instance filtertest> compact -t filtertest -w\n06 10:43:00,632 [shell.Shell] INFO : Compacting table ...\n06 10:43:01,307 [shell.Shell] INFO : Compaction of table filtertest completed for given range\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Table with RandomBatchScanner\nDESCRIPTION: This command performs 500 random queries against the 'bloom_test' table using the same seed as the data insertion, ensuring all queries find results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 500 --min 0 --max 1000000000 --size 50 --batchThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Inserting data with visibility labels in Accumulo\nDESCRIPTION: Shows how to insert data with different visibility expressions in Accumulo. Demonstrates simple visibility labels, compound expressions with AND (&) and OR (|) operators, and the need for parentheses to specify operation order.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n                ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Inserting data with visibility labels in Accumulo\nDESCRIPTION: Shows how to insert data with different visibility expressions in Accumulo. Demonstrates simple visibility labels, compound expressions with AND (&) and OR (|) operators, and the need for parentheses to specify operation order.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n                ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Managing Accumulo Data Formatters\nDESCRIPTION: The 'formatter' command specifies a formatter to use for displaying database entries. It supports listing, resetting, and setting custom formatters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_22\n\nLANGUAGE: markdown\nCODE:\n```\n**formatter**   \n\n    usage: formatter [-?] -f <className> | -l | -r   \n    description: specifies a formatter to use for displaying database entries   \n      -?,-help  display this help   \n      -f,-formatter <className>  fully qualified name of formatter class to use   \n      -l,-list  display the current formatter   \n      -r,-reset  reset to default formatter   \n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo\nDESCRIPTION: Shell command to set authorization permissions for a user to access data with specific visibility labels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/dirlist.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u root -e 'setauths -u username -s exampleVis'\n```\n\n----------------------------------------\n\nTITLE: Running TableToFile MapReduce Job\nDESCRIPTION: Command to execute the TableToFile MapReduce job that extracts rows containing the column 'cf:cq' and writes them to HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/tabletofile.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TableToFile -u user -p passwd -i instance -t input --columns cf:cq --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Changing User Passwords with Java API\nDESCRIPTION: Java code to change the password of user 'bob' using the SecurityOperations interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().changeLocalUserPassword(\"bob\", new PasswordToken(\"pass\"));\n```\n\n----------------------------------------\n\nTITLE: Searching for Files by Name Pattern\nDESCRIPTION: Commands to search for files or directories using wildcard patterns. These searches run against the index table and support wildcards in search terms but cannot contain forward slashes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/dirlist.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t indexTable --auths exampleVis --path filename --search\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t indexTable --auths exampleVis --path 'filename*' --search\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t indexTable --auths exampleVis --path '*jar' --search\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil -i instance -z zookeepers -u username -p password -t indexTable --auths exampleVis --path 'filename*jar' --search\n```\n\n----------------------------------------\n\nTITLE: Executing Flush Example in Accumulo\nDESCRIPTION: This command demonstrates how to execute the Flush example class which flushes an Accumulo table. It requires the user credentials, instance name, and ZooKeeper connection details.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/client.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ PACKAGE=org.apache.accumulo.examples.simple.client\n$ bin/accumulo $PACKAGE.Flush -u root -p mypassword -i instance -z zookeeper -t trace\n```\n\n----------------------------------------\n\nTITLE: Granting Table Creation Permission in Accumulo\nDESCRIPTION: This snippet demonstrates how to grant the System.CREATE_TABLE permission to a user and then successfully create a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> user root\nEnter password for user root: ********\nroot@instance> grant -s System.CREATE_TABLE -u username\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\nusername@instance> userpermissions\nSystem permissions: System.CREATE_TABLE\n\nTable permissions (accumulo.metadata): Table.READ\nTable permissions (vistest): Table.READ, Table.WRITE, Table.BULK_IMPORT, Table.ALTER_TABLE, Table.GRANT, Table.DROP_TABLE\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Configuring MapReduce Job for Sample Data in Java\nDESCRIPTION: MapReduce jobs using AccumuloInputFormat can read sample data. This snippet shows how to configure a MapReduce job to use sampling.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/sampling.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nAccumuloInputFormat.configure()\n    .samplerConfiguration(new SamplerConfiguration(MySampler.class.getName()))\n    .store(job);\n```\n\n----------------------------------------\n\nTITLE: Configuring AccumuloInputFormat for MapReduce Jobs\nDESCRIPTION: Example of configuring AccumuloInputFormat for a MapReduce job. Sets user credentials, target table, and ZooKeeper instance information needed to read from an Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nJob job = new Job(getConf());\nAccumuloInputFormat.setInputInfo(job,\n        \"user\",\n        \"passwd\".getBytes(),\n        \"table\",\n        new Authorizations());\n\nAccumuloInputFormat.setZooKeeperInstance(job, \"myinstance\",\n        \"zooserver-one,zooserver-two\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Properties for HA Namenode Migration\nDESCRIPTION: Configuration settings in accumulo.properties to replace the old namenode volume with the new HA nameservice volume. This includes setting instance.volumes and instance.volumes.replacements properties.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_12\n\nLANGUAGE: properties\nCODE:\n```\n# instance.dfs.uri and instance.dfs.dir should not be set\ninstance.volumes=hdfs://nameservice1/accumulo\ninstance.volumes.replacements=hdfs://namenode.example.com:8020/accumulo hdfs://nameservice1/accumulo\n```\n\n----------------------------------------\n\nTITLE: Launching File System Viewer\nDESCRIPTION: Command to start the GUI viewer for browsing the file system information stored in Accumulo tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/dirlist.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Viewer instance zookeepers username password dirTable dataTable exampleVis /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Viewing Ingested File System Data with GUI\nDESCRIPTION: Command to launch the Viewer GUI application for browsing the file system information stored in Accumulo tables. Requires the appropriate authorizations to be set for the user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/dirlist.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Viewer -i instance -z zookeepers -u username -p password -t dirTable --dataTable dataTable --auths exampleVis --path /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Flushing an Accumulo Table from Shell\nDESCRIPTION: This snippet shows how to flush an Accumulo table to ensure data is written from memory to disk. The -w flag waits for the flush operation to complete before returning.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test -w'\n05 10:40:06,069 [shell.Shell] INFO : Flush of table bloom_test completed.\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Table with Bloom Filters\nDESCRIPTION: This set of commands inserts 3 million entries into 'bloom_test2' using RandomBatchWriter with different seeds, flushing after each batch.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test2 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n```\n\n----------------------------------------\n\nTITLE: Running the Sample Example Using Java API\nDESCRIPTION: This snippet shows how to run the Java example that replicates the sampling functionality demonstrated in the previous shell commands. The example illustrates programmatic access to Accumulo's sampling features.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.sample.SampleExample -i instance -z localhost -u root -p secret\n```\n\n----------------------------------------\n\nTITLE: Granting Accumulo Permissions\nDESCRIPTION: The 'grant' command grants system or table permissions for a user. It supports granting permissions on specific tables or using regex patterns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_26\n\nLANGUAGE: markdown\nCODE:\n```\n**grant**   \n\n    usage: grant <permission> [-?] -p <pattern> | -s | -t <table>  -u <username>   \n    description: grants system or table permissions for a user   \n      -?,-help  display this help   \n      -p,-pattern <pattern>  regex pattern of tables to grant permissions on   \n      -s,-system  grant a system permission   \n      -t,-table <table>  grant a table permission on this table   \n      -u,-user <username> user to operate on   \n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo Shell\nDESCRIPTION: Shell command to give a user the necessary authorizations to see the ingested data. This must be run before viewing the data, as the example uses visibility labels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/dirlist.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u root -e 'setauths -u username -s exampleVis'\n```\n\n----------------------------------------\n\nTITLE: Viewing HDFS Output Files\nDESCRIPTION: Commands to list and view the contents of the exported data files in HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/tabletofile.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -ls /tmp/output\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:44 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs/history\n-rw-r--r--   1 username supergroup       9049 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_1357847072863_username_TableToFile%5F1357847071434\n-rw-r--r--   1 username supergroup      26172 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_conf.xml\n-rw-r--r--   1 username supergroup         50 2013-01-10 14:44 /tmp/output/part-m-00000\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -text /tmp/output/output/part-m-00000\ncatrow cf:cq []    catvalue\ndogrow cf:cq []    dogvalue\n$\n```\n\n----------------------------------------\n\nTITLE: Setting AES Crypto Service for Accumulo Encryption\nDESCRIPTION: Configuration property to specify AESCryptoService as the implementation for the generic crypto service.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.custom.crypto.service=org.apache.accumulo.core.spi.crypto.AESCryptoService\n```\n\n----------------------------------------\n\nTITLE: Indexing Java Files into Accumulo Shard\nDESCRIPTION: Command to recursively find and index Java source files into the Accumulo shard table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/shard.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cd /local/username/workspace/accumulo/\n$ find src -name \"*.java\" | xargs ./bin/accumulo org.apache.accumulo.examples.simple.shard.Index instance zookeepers shard username password 30\n```\n\n----------------------------------------\n\nTITLE: Displaying RFile Information in Accumulo\nDESCRIPTION: This command shows detailed information about an RFile, including the presence and size of the bloom filter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo rfile-info /accumulo/tables/o8/default_tablet/F00000dj.rf\nLocality group         : <DEFAULT>\n  Start block          : 0\n  Num   blocks         : 752\n  Index level 0        : 43,598 bytes  1 blocks\n  First key            : row_0000001169 foo:1 [exampleVis] 1326222052539 false\n  Last key             : row_0999999421 foo:1 [exampleVis] 1326222052058 false\n  Num entries          : 999,536\n  Column families      : [foo]\n\nMeta block     : BCFile.index\n  Raw size             : 4 bytes\n```\n\n----------------------------------------\n\nTITLE: Retrieving System Load with GetManagerStats in Accumulo\nDESCRIPTION: Using the GetManagerStats utility to retrieve Accumulo state and statistics, specifically filtering for the operating system load average.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.test.GetManagerStats | grep Load\n OS Load Average: 0.27\n```\n\n----------------------------------------\n\nTITLE: Listing HDFS Files for Accumulo Table\nDESCRIPTION: This command lists the files in HDFS for the 'bloom_test2' table, showing the map files created during the example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -lsr /accumulo/tables/o8\ndrwxr-xr-x   - username supergroup          0 2012-01-10 14:02 /accumulo/tables/o8/default_tablet\n-rw-r--r--   3 username supergroup   52672650 2012-01-10 14:01 /accumulo/tables/o8/default_tablet/F00000dj.rf\n-rw-r--r--   3 username supergroup   52436176 2012-01-10 14:01 /accumulo/tables/o8/default_tablet/F00000dk.rf\n-rw-r--r--   3 username supergroup   52850173 2012-01-10 14:02 /accumulo/tables/o8/default_tablet/F00000dl.rf\n```\n\n----------------------------------------\n\nTITLE: Import Directory Command Syntax\nDESCRIPTION: Command for bulk importing data files into Accumulo with options for controlling threads and garbage collection.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_30\n\nLANGUAGE: shell\nCODE:\n```\nimportdirectory <directory> <failureDirectory> [-?] [-a <num>] [-f <num>] [-g] [-v]\n```\n\n----------------------------------------\n\nTITLE: Configuring ZooKeeper for ACL Repair with SuperDigest\nDESCRIPTION: Configuration entry to add to the ZooKeeper zoo.cfg file to enable superuser access for ACL repair. This setting uses the digest value generated in the previous step to allow administrative access to bypass existing ACLs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/zookeeper.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nDigestAuthenticationProvider.superDigest=accumulo:$digest\n```\n\n----------------------------------------\n\nTITLE: Running CharacterHistogram MapReduce on Stored Files\nDESCRIPTION: Command to execute the CharacterHistogram MapReduce job which computes byte frequency histograms for files stored in the Accumulo table. Results are stored back in the table with the 'exampleVis' visibility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filedata.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.filedata.CharacterHistogram -i instance -z zookeepers -u username -p password -t dataTable --auths exampleVis --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: File Search Query Commands\nDESCRIPTION: Example commands for searching files using various patterns with QueryUtil program against the index table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/dirlist.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password indexTable exampleVis filename -search\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password indexTable exampleVis 'filename*' -search\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password indexTable exampleVis '*jar' -search\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password indexTable exampleVis filename*jar -search\n```\n\n----------------------------------------\n\nTITLE: Viewing Updated Data with Histogram Information\nDESCRIPTION: Accumulo shell command to view the table after histogram analysis. This displays both the original file data and the newly added character frequency information in the 'info' column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filedata.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Setting Iterator Options in Accumulo\nDESCRIPTION: Demonstrates how to set additional options for iterators when using the Accumulo Java API. This allows passing configuration parameters to custom iterators.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nbscan.setIteratorOption(\n    \"myiter\", // iterator reference\n    \"myoptionname\",\n    \"myoptionvalue\");\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Services\nDESCRIPTION: Command to start all Accumulo services after initialization. This launches the necessary processes for the Accumulo instance to become operational.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-27-getting-started-with-accumulo-1.6.0.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/start-all.sh\n```\n\n----------------------------------------\n\nTITLE: Deleting Records from Accumulo Tables\nDESCRIPTION: The 'delete' command deletes a record from a table. It supports specifying authorization labels and timestamps for the deletion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n**delete**   \n\n    usage: delete <row> <colfamily> <colqualifier> [-?] [-l <expression>] [-t   \n           <timestamp>]   \n    description: deletes a record from a table   \n      -?,-help  display this help   \n      -l,-authorization-label <expression>  formatted authorization label expression   \n      -t,-timestamp <timestamp>  timestamp to use for insert   \n```\n\n----------------------------------------\n\nTITLE: Querying Directory Contents\nDESCRIPTION: Commands to list contents of specific directories using QueryUtil. Shows how to view different directory levels in the stored file system hierarchy.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/dirlist.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password direxample exampleVis /local/user1\n./bin/accumulo org.apache.accumulo.examples.dirlist.QueryUtil instance zookeepers username password direxample exampleVis /local/user1/workspace\n```\n\n----------------------------------------\n\nTITLE: Running Read Write Example\nDESCRIPTION: Command demonstrating how to create a table, write data to it, and read from it using the ReadWriteExample class.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/client.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo $PACKAGE.ReadWriteExample -u root -p mypassword -i instance -z zookeeper --createtable --create --read\n```\n\n----------------------------------------\n\nTITLE: Creating Encrypted Accumulo Table in Shell\nDESCRIPTION: Shell command to create a table with encryption enabled by setting the table.crypto.opts.service property.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncreatetable table1 -prop table.crypto.opts.service=org.apache.accumulo.core.spi.crypto.AESCryptoService\n```\n\n----------------------------------------\n\nTITLE: Directory Content Query Commands\nDESCRIPTION: Commands to list contents of specific directories using the QueryUtil program.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/dirlist.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password dirTable exampleVis /local/username\n./bin/accumulo org.apache.accumulo.examples.simple.dirlist.QueryUtil instance zookeepers username password dirTable exampleVis /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Scanning Data in Accumulo Shell\nDESCRIPTION: Accumulo shell command to scan and view the contents of the dataTable where file data has been stored. This displays the MD5 hash of the file as the row ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filedata.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Checking FATE Operations in Accumulo 1.5\nDESCRIPTION: Command to list and verify FATE (Fault Tolerant Executor) operations before upgrading from Accumulo 1.5 to 1.6.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo org.apache.accumulo.server.fate.Admin print\n```\n\n----------------------------------------\n\nTITLE: Performance Comparison without Bloom Filters in Accumulo\nDESCRIPTION: This snippet shows the performance of 500 lookups on the control table without bloom filters using seed 7. All map files are interrogated even though entries for this seed are only in one file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -s 7 instance zookeepers username password bloom_test1 500 0 1000000000 50 20 exampleVis\nGenerating 500 random queries...finished\n35.09 lookups/sec  14.25 secs\nnum results : 500\nGenerating 500 random queries...finished\n35.33 lookups/sec  14.15 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Scanning Data with Authorized User in Accumulo\nDESCRIPTION: Shows how a user with proper authorization tokens can view restricted data. Demonstrates that by default, scans use the user's full authorization set and how scans can be restricted to specific authorization subsets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan -s A\nrow f1:q1 [A]    v1\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Table Bloom Filter Configuration\nDESCRIPTION: Settings for configuring Bloom filters on tables including error rates, hash types, and size parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\ntable.bloom.enabled=false\ntable.bloom.error.rate=0.5%\ntable.bloom.hash.type=murmur\ntable.bloom.size=1048576\n```\n\n----------------------------------------\n\nTITLE: Clearing Screen in Accumulo Shell\nDESCRIPTION: The 'clear' and 'cls' commands clear the screen in the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n**clear**   \n\n    usage: clear [-?]   \n    description: clears the screen   \n      -?,-help  display this help   \n\n**cls**   \n\n    usage: cls [-?]   \n    description: clears the screen   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Setting User Authorization for Data Access\nDESCRIPTION: Shell command to grant necessary authorizations to a user for accessing the ingested data with specific visibility settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/dirlist.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo shell -u root -e 'setauths -u username -s exampleVis'\n```\n\n----------------------------------------\n\nTITLE: Inserting and Scanning Data with StatsCombiner in Accumulo\nDESCRIPTION: This snippet shows how to insert data into the 'runners' table and scan it to see the effects of the StatsCombiner. It demonstrates the combiner's functionality for both base 10 and base 16 calculations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/combiner.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance runners> insert 123456 name first Joe\nusername@instance runners> insert 123456 stat marathon 240\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    240,240,240,1\nusername@instance runners> insert 123456 stat marathon 230\nusername@instance runners> insert 123456 stat marathon 220\nusername@instance runners> scan\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\nusername@instance runners> insert 123456 hstat virtualMarathon 6a\nusername@instance runners> insert 123456 hstat virtualMarathon 6b\nusername@instance runners> scan\n123456 hstat:virtualMarathon []    6a,6b,d5,2\n123456 name:first []    Joe\n123456 stat:marathon []    220,240,690,3\n```\n\n----------------------------------------\n\nTITLE: Setting Up Peer Instance for Replication\nDESCRIPTION: Commands to prepare the peer instance by creating the table, user, and granting appropriate permissions for replication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nroot@peer> createtable my_table\nroot@peer> createuser peer\nroot@peer> grant -t my_table -u peer Table.WRITE\nroot@peer> grant -t my_table -u peer Table.READ\nroot@peer> tables -l\n```\n\n----------------------------------------\n\nTITLE: Ingesting File Data into Accumulo\nDESCRIPTION: Command to use FileDataIngest for storing file content in an Accumulo table. The process hashes files and uses the hash as the row key, with visibility settings for access control.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filedata.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.filedata.FileDataIngest instance zookeepers username password dataTable exampleVis 1000 $ACCUMULO_HOME/README\n```\n\n----------------------------------------\n\nTITLE: Flushing Accumulo Tables\nDESCRIPTION: The 'flush' command makes a best effort to flush tables from memory to disk. It supports flushing by table name or pattern.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_21\n\nLANGUAGE: markdown\nCODE:\n```\n**flush**   \n\n    usage: flush [-?] -p <pattern> | -t <tableName>   \n    description: makes a best effort to flush tables from memory to disk   \n      -?,-help  display this help   \n      -p,-pattern <pattern>  regex pattern of table names to flush   \n      -t,-table <tableName>  name of a table to flush   \n```\n\n----------------------------------------\n\nTITLE: Configuring VFS Classpath Context in Accumulo\nDESCRIPTION: Command to set up a classpath context named 'cx1' in Accumulo that points to the HDFS location where the FooFilter.jar is stored.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/classpath.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s general.vfs.context.classpath.cx1=hdfs://<namenode host>:<namenode port>/user1/lib\n```\n\n----------------------------------------\n\nTITLE: Setting Up Decimal-Based StatsCombiner in Accumulo Shell\nDESCRIPTION: Commands to create a table 'runners' and configure a StatsCombiner named 'decStats' with priority 10 operating on the 'stat' column family using base 10 (decimal) numbers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/combiner.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo shell -u username\nEnter current password for 'username'@'instance': ***\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable runners\nusername@instance runners> setiter -t runners -p 10 -scan -minc -majc -n decStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.:\n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: stat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 10\n```\n\n----------------------------------------\n\nTITLE: Disabling Encryption in Accumulo with AESCryptoService\nDESCRIPTION: Configuration property to disable encryption when using the AESCryptoService while maintaining the ability to read existing encrypted files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_7\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.custom.crypto.enabled=false\n```\n\n----------------------------------------\n\nTITLE: Creating an Accumulo table with AgeOffFilter for scan operations\nDESCRIPTION: This snippet shows how to create a table named 'filtertest' and configure an AgeOffFilter with a time-to-live (TTL) of 30 seconds for scan operations. The filter is set at priority 10 and named 'myfilter'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -filter\nFilteringIterator uses Filters to accept or reject key/value pairs\n----------> entering options: <filterPriorityNumber> <ageoff|regex|filterClass>\n----------> set org.apache.accumulo.core.iterators.FilteringIterator option (<name> <value>, hit enter to skip): 0 ageoff\n----------> set org.apache.accumulo.core.iterators.FilteringIterator option (<name> <value>, hit enter to skip): \nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set org.apache.accumulo.core.iterators.filter.AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day: \n----------> set org.apache.accumulo.core.iterators.filter.AgeOffFilter parameter ttl, time to live (milliseconds): 30000\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Testing the Filter with Data Insertion and Scan\nDESCRIPTION: These commands insert two rows of data ('foo1' and 'noo1') and then scan the table to show that the FooFilter is working correctly by filtering out the row with 'foo' in the row ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/classpath.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ninsert foo1 f1 q1 v1\ninsert noo1 f1 q1 v2\nscan\n```\n\n----------------------------------------\n\nTITLE: Defining Replication Peer in Primary Instance\nDESCRIPTION: Command to define the peer instance as a replication target, specifying the ReplicaSystem implementation and configuration including the peer's instance name and ZooKeeper quorum.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_9\n\nLANGUAGE: console\nCODE:\n```\nroot@primary> config -s replication.peer.peer=org.apache.accumulo.tserver.replication.AccumuloReplicaSystem,peer,$peer_zk_quorum\n```\n\n----------------------------------------\n\nTITLE: Adding More Data with SummingCombiner Active (Java)\nDESCRIPTION: This snippet demonstrates how the SummingCombiner automatically updates running totals when new data is added. After adding more villain captures for Batman and Robin, the scan shows updated totals incorporating the new values.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\njshell> mutation1 = new Mutation(\"id0001\");\njshell> mutation1.put(\"hero\", \"villainsCaptured\", \"4\");\njshell> mutation2 = new Mutation(\"id0002\");\njshell> mutation2.put(\"hero\", \"villainsCaptured\", \"2\");\n\njshell> try (BatchWriter writer = client.createBatchWriter(\"GothamCrimeStats\")) {\n   ...>   writer.addMutation(mutation1);\n   ...>   writer.addMutation(mutation2);\n   ...> }\n\njshell> try ( org.apache.accumulo.core.client.Scanner scan = client.createScanner(\"GothamCrimeStats\", Authorizations.EMPTY)) {\n   ...>   for(Map.Entry<Key, Value> entry : scan) {\n   ...>     System.out.printf(\"Key : %-52s  Value : %s\\n\", entry.getKey(), entry.getValue());\n   ...>   }\n   ...> }\nKey : id0001 hero:alias [] 1654779673027 false              Value : Batman\nKey : id0001 hero:villainsCaptured [] 1654780041402 false   Value : 12\nKey : id0002 hero:alias [] 1654779673027 false              Value : Robin\nKey : id0002 hero:villainsCaptured [] 1654780041402 false   Value : 5\n```\n\n----------------------------------------\n\nTITLE: Executing Accumulo FATE Admin Command\nDESCRIPTION: Command syntax for running the FATE administrative tool in Accumulo to inspect and manage FATE transactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/fate.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n> accumulo admin fate --[option]\n```\n\n----------------------------------------\n\nTITLE: Listing Accumulo 1.8.0 Scripts\nDESCRIPTION: Shows the contents of the bin directory in Accumulo 1.8.0, demonstrating the large number of scripts present.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ls accumulo-1.8.0/bin/\naccumulo             build_native_library.sh  generate_monitor_certificate.sh  start-here.sh    stop-server.sh\naccumulo_watcher.sh  check-slaves             LogForwarder.sh                  start-server.sh  tdown.sh\nbootstrap_config.sh  config-server.sh         start-all.sh                     stop-all.sh      tool.sh\nbootstrap_hdfs.sh    config.sh                start-daemon.sh                  stop-here.sh     tup.sh\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Bulk Ingest Commands\nDESCRIPTION: A sequence of commands showing the complete bulk ingest process: creating a table with split points, generating test data, performing bulk ingest, and verifying the results. The commands require Accumulo instance name, zookeeper list, username, and password as parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.mapreduce.bulk.SetupTable instance zookeepers username password test_bulk row_00000333 row_00000666\n$ ./bin/accumulo org.apache.accumulo.examples.simple.mapreduce.bulk.GenerateTestData 0 1000 bulk/test_1.txt\n\n$ ./bin/tool.sh lib/examples-simple-*[^cs].jar org.apache.accumulo.examples.simple.mapreduce.bulk.BulkIngestExample instance zookeepers username password test_bulk bulk tmp/bulkWork\n$ ./bin/accumulo org.apache.accumulo.examples.simple.mapreduce.bulk.VerifyIngest instance zookeepers username password test_bulk 0 1000\n```\n\n----------------------------------------\n\nTITLE: Setting Up AgeOffFilter for Scan Scope in Accumulo\nDESCRIPTION: This snippet demonstrates creating a table and setting up an AgeOffFilter with a 30-second time-to-live parameter for the scan scope. It shows how data inserted becomes invisible to queries after 30 seconds.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method: \n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day: \nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\nusername@instance filtertest> \n\n... wait 30 seconds ...\n    \nusername@instance filtertest> scan\nusername@instance filtertest> \n```\n\n----------------------------------------\n\nTITLE: Configuring Replication Target for Table\nDESCRIPTION: Command to specify which table on the peer instance should receive replicated data, using the peer table's ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_11\n\nLANGUAGE: console\nCODE:\n```\nroot@primary> config -t my_table -s table.replication.target.peer=$peer_table_id\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Tserver Process\nDESCRIPTION: Command to start the Accumulo tablet server process in the foreground.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naccumulo tserver\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Tserver Process\nDESCRIPTION: Command to start the Accumulo tablet server process in the foreground.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naccumulo tserver\n```\n\n----------------------------------------\n\nTITLE: Restoring ZooKeeper Data in Accumulo\nDESCRIPTION: The RestoreZookeeper utility allows restoring ZooKeeper contents from an XML dump file, with the --overwrite flag to replace existing data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin restoreZoo --overwrite < dump.xml\n```\n\n----------------------------------------\n\nTITLE: Usage of Help Command in Accumulo Shell\nDESCRIPTION: The help command (?) provides information about available commands in the Accumulo shell. It supports options for disabling pagination and text wrapping.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusage: ? [ <command> <command> ] [-?] [-np] [-nw]   \ndescription: provides information about the available commands   \n  -?,-help  display this help   \n  -np,-no-pagination  disables pagination of output   \n  -nw,-no-wrap  disables wrapping of output\n```\n\n----------------------------------------\n\nTITLE: Displaying RFile Information\nDESCRIPTION: This command shows detailed information about one of the RFiles, including the presence and size of the bloom filter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo rfile-info /accumulo/tables/o8/default_tablet/F00000dj.rf\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo\nDESCRIPTION: Shell command to create a new table called 'hellotable' in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nusername@instance> createtable hellotable\n```\n\n----------------------------------------\n\nTITLE: Verifying Erasure Coding Policies in Accumulo\nDESCRIPTION: These commands check the Erasure Coding policies set for the Accumulo tables directory and a specific table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs ec -getPolicy -path /accumulo/tables\n$ hdfs ec -getPolicy -path /accumulo/tables/\\!0\n```\n\n----------------------------------------\n\nTITLE: Running Random Batch Scanner in Accumulo\nDESCRIPTION: Command to run the RandomBatchScanner example which performs 100 random queries on the batchtest1 table and verifies the values.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/batch.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner instance zookeepers username password batchtest1 100 0 10000 50 20 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Using Execution Hints with Alpha Scan Type\nDESCRIPTION: Example scan command using the alpha scan type, which corresponds to a higher priority (lower number) than gamma.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nscan -t tex --execution-hints scan_type=alpha\n```\n\n----------------------------------------\n\nTITLE: Checking Zookeeper Status with netcat\nDESCRIPTION: Shows how to check Zookeeper server status using netcat and the 'stat' command. This provides information about client connections, latency, operating mode, and other diagnostic information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ nc zoohost 2181\nstat\nZookeeper version: 3.4.5-1392090, built on 09/30/2012 17:52 GMT\nClients:\n /127.0.0.1:58289[0](queued=0,recved=1,sent=0)\n /127.0.0.1:60231[1](queued=0,recved=53910,sent=53915)\n\nLatency min/avg/max: 0/5/3008\nReceived: 1561459\nSent: 1561592\nConnections: 2\nOutstanding: 0\nZxid: 0x621a3b\nMode: standalone\nNode count: 22524\n```\n\n----------------------------------------\n\nTITLE: Setting Optional Scan Executor Properties\nDESCRIPTION: Optional configuration properties for scan executors, including thread priority and prioritizer class with its options.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_1\n\nLANGUAGE: text\nCODE:\n```\ntserver.scan.executors.<name>.priority=<number 1 to 10>\ntserver.scan.executors.<name>.prioritizer=<class name>\ntserver.scan.executors.<name>.prioritizer.opts.<key>=<value>\n```\n\n----------------------------------------\n\nTITLE: Creating a Table and Setting Up AgeOffFilter for Scan Scope in Accumulo\nDESCRIPTION: Creates a table called 'filtertest' and configures an AgeOffFilter for the scan scope with a 30-second time-to-live (TTL). This filter will hide entries older than 30 seconds during queries but won't remove them from storage.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filter.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable filtertest\nusername@instance filtertest> setiter -t filtertest -scan -p 10 -n myfilter -ageoff\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Decommissioning Tablet Servers\nDESCRIPTION: Command to gracefully stop tablet servers on specified hosts, allowing Accumulo to rebalance tablets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\naccumulo admin stop <host(s)> {<host> ...}\n```\n\n----------------------------------------\n\nTITLE: Configuring Versioning in Accumulo\nDESCRIPTION: Shows how to configure the versioning policy for an Accumulo table. This example sets the maximum number of versions to keep for scan, minor compaction, and major compaction operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> config -t mytable -s\ntable.iterator.scan.vers.opt.maxVersions=3\n\nuser@myinstance mytable> config -t mytable -s\ntable.iterator.minc.vers.opt.maxVersions=3\n\nuser@myinstance mytable> config -t mytable -s\ntable.iterator.majc.vers.opt.maxVersions=3\n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Word Count Job\nDESCRIPTION: Command to execute the word count MapReduce job and its output showing job progress and statistics.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n[user1@instance accumulo]$ bin/tool.sh lib/accumulo-examples-*[^c].jar org.apache.accumulo.examples.mapreduce.WordCount instance zookeepers /user/user1/wc wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters \n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Configuring Tables to Use Specific Scan Executors\nDESCRIPTION: Shell commands to assign tables to specific scan executors using the SimpleScanDispatcher. This configures which tables use the low, high, and default executors.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nconfig -t LOW1 -s table.scan.dispatcher=org.apache.accumulo.core.spi.scan.SimpleScanDispatcher\nconfig -t LOW1 -s table.scan.dispatcher.opts.executor=low\nconfig -t LOW2 -s table.scan.dispatcher=org.apache.accumulo.core.spi.scan.SimpleScanDispatcher\nconfig -t LOW2 -s table.scan.dispatcher.opts.executor=low\nconfig -t HIGH -s table.scan.dispatcher=org.apache.accumulo.core.spi.scan.SimpleScanDispatcher\nconfig -t HIGH -s table.scan.dispatcher.opts.executor=high\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Services on Fedora\nDESCRIPTION: This command starts all the necessary Accumulo services (master, tserver, gc, tracer, and monitor) on a single node.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start accumulo-{master,tserver,gc,tracer,monitor}.service\n```\n\n----------------------------------------\n\nTITLE: Clearing the Screen in Accumulo Shell\nDESCRIPTION: The clear command clears the terminal screen in the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nusage: clear [-?]   \ndescription: clears the screen   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Table without Bloom Filters\nDESCRIPTION: This command performs 500 lookups on the 'bloom_test1' table (without bloom filters) using RandomBatchScanner.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test1 --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating an Accumulo Table via Shell\nDESCRIPTION: Commands to create a table named 'input' in Accumulo and insert sample data with different row IDs, column families, and column qualifiers using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/tabletofile.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert dog cf cq dogvalue\nusername@instance> insert cat cf cq catvalue\nusername@instance> insert junk family qualifier junkvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Adding and Enabling Custom Erasure Coding Policy\nDESCRIPTION: These commands add a custom Erasure Coding policy defined in the XML file and then enable it for use in HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs ec -addPolicies -policyFile /hadoop/etc/hadoop/user_ec_policies.xml\n$ hdfs ec -enablePolicy -policy RS-6-3-64k\n```\n\n----------------------------------------\n\nTITLE: Executing TeraSort Data Ingestion with MapReduce\nDESCRIPTION: Command to run the TeraSort ingestion process using MapReduce. Parameters control the data size, key/value sizes, table name, and split configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/terasort.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TeraSortIngest \\\n-i instance -z zookeepers -u user -p password \\\n--count 10 \\\n--minKeySize 10 \\\n--maxKeySize 10 \\\n--minValueSize 78 \\\n--maxValueSize 78 \\\n--table sort \\\n--splits 10 \\\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo Shell (Bash)\nDESCRIPTION: Command to set authorizations for a user in Accumulo shell. This is necessary to allow the user to view the ingested data with the specified visibility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/dirlist.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u root -e 'setauths -u username -s exampleVis'\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Configuration Settings\nDESCRIPTION: Shows how to view the configured iterator settings for a table using the config command, displaying settings for scan, minor compaction, and major compaction scopes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filter.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+---------------------------------------------------------------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+---------------------------------------------------------------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+---------------------------------------------------------------------------\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Generating Certificate Authority with OpenSSL and KeyTool\nDESCRIPTION: Creates a root certificate authority (CA) by generating a private key, creating a certificate, converting it to DER format, and importing it into a Java KeyStore. This process establishes the foundation for the SSL trust chain in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/wire-encryption.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Create a private key\nopenssl genrsa -des3 -out root.key 4096\n\n# Create a certificate request using the private key\nopenssl req -x509 -new -key root.key -days 365 -out root.pem\n\n# Generate a Base64-encoded version of the PEM just created\nopenssl x509 -outform der -in root.pem -out root.der\n\n# Import the key into a Java KeyStore\nkeytool -import -alias root-key -keystore truststore.jks -file root.der\n\n# Remove the DER formatted key file (as we don't need it anymore)\nrm root.der\n```\n\n----------------------------------------\n\nTITLE: Verifying ZooKeeper Configuration After Accumulo Property Conversion\nDESCRIPTION: Command to verify the configuration using the zoo-info-viewer utility after the property conversion is complete. This tool helps ensure that the ZooKeeper property storage format has been properly converted.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo zoo-info-viewer  --print-props\n```\n\n----------------------------------------\n\nTITLE: Checking Metadata Integrity in Accumulo\nDESCRIPTION: The CheckForMetadataProblems utility verifies the consistency of Accumulo metadata tables, ensuring tablet ranges match and table boundaries are properly defined.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.server.util.CheckForMetadataProblems -u root --password\nEnter the connection password:\nChecking tables whose metadata is found in: accumulo.root (+r)\n...All is well for table accumulo.metadata (!0)\nNo problems found in accumulo.root (+r)\n\nChecking tables whose metadata is found in: accumulo.metadata (!0)\n...All is well for table accumulo.replication (+rep)\n...All is well for table trace (1)\nNo problems found in accumulo.metadata (!0)\n```\n\n----------------------------------------\n\nTITLE: Viewing Table Configuration in Accumulo Shell\nDESCRIPTION: Shows the output of the config command in the Accumulo shell when viewing configuration for a specific table. The example demonstrates how properties can be set at different levels with increasing precedence.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nroot@accumulo-instance> config -t foo\n---------+---------------------------------------------+-----------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+-----------------------\ndefault  | table.bloom.enabled ....................... | false\ndefault  | table.bloom.error.rate .................... | 0.5%\ndefault  | table.bloom.hash.type ..................... | murmur\ndefault  | table.bloom.load.threshold ................ | 1\ndefault  | table.bloom.size .......................... | 1048576\ndefault  | table.cache.block.enable .................. | false\ndefault  | table.cache.index.enable .................. | false\ndefault  | table.compaction.major.everything.at ...... | 19700101000000GMT\ndefault  | table.compaction.major.everything.idle .... | 1h\ndefault  | table.compaction.major.ratio .............. | 1.3\nsite     |    @override .............................. | 1.4\nsystem   |    @override .............................. | 1.5\ntable    |    @override .............................. | 1.6\ndefault  | table.compaction.minor.idle ............... | 5m\ndefault  | table.compaction.minor.logs.threshold ..... | 3\ndefault  | table.failures.ignore ..................... | false\n```\n\n----------------------------------------\n\nTITLE: Running the TableToFile MapReduce job to extract columns\nDESCRIPTION: This snippet shows how to run the TableToFile MapReduce example using the Accumulo tool script. The command extracts rows containing the column 'cf:cq' from the 'input' table and writes the results to an HDFS output directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/tabletofile.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TableToFile -u user -p passwd -i instance -t input --columns cf:cq --output /tmp/output\n\n$ hadoop fs -ls /tmp/output\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:44 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs/history\n-rw-r--r--   1 username supergroup       9049 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_1357847072863_username_TableToFile%5F1357847071434\n-rw-r--r--   1 username supergroup      26172 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_conf.xml\n-rw-r--r--   1 username supergroup         50 2013-01-10 14:44 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Viewing File System Data with GUI\nDESCRIPTION: Command to launch the graphical viewer for browsing ingested file system data. Requires appropriate user authorizations to view the data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/dirlist.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.dirlist.Viewer instance zookeepers username password direxample exampleVis /local/user1/workspace\n```\n\n----------------------------------------\n\nTITLE: CryptoService Interface for Custom Accumulo Encryption\nDESCRIPTION: Core interface methods required to implement a custom encryption service for Accumulo, including initialization and file encryption/decryption.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\n  void init(Map<String,String> conf) throws CryptoException;\n  FileEncrypter getFileEncrypter(CryptoEnvironment environment);\n  FileDecrypter getFileDecrypter(CryptoEnvironment environment);\n```\n\n----------------------------------------\n\nTITLE: Checking out branch for applying patches in Git\nDESCRIPTION: Command to checkout the appropriate branch for applying a contributor's patch. This is the first step in the patch application process.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout 1.10\n```\n\n----------------------------------------\n\nTITLE: Downloading Telegraf Configuration and Grafana Dashboard\nDESCRIPTION: Commands to download and configure Telegraf and Grafana dashboard files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd /tmp/metrics/telegraf/conf\nwget https://raw.githubusercontent.com/apache/accumulo-testing/main/contrib/terraform-testing-infrastructure/modules/config-files/templates/telegraf.conf.tftpl\ncat telegraf.conf.tftpl | sed \"s/\\${manager_ip}/localhost/\" > telegraf.conf\ncd /tmp/metrics/grafana-dashboards\nwget https://raw.githubusercontent.com/apache/accumulo-testing/main/contrib/terraform-testing-infrastructure/modules/config-files/files/grafana_dashboards/accumulo-dashboard.json\nwget https://raw.githubusercontent.com/apache/accumulo-testing/main/contrib/terraform-testing-infrastructure/modules/config-files/files/grafana_dashboards/accumulo-dashboard.yaml\n```\n\n----------------------------------------\n\nTITLE: Alternative Clear Screen Command in Accumulo Shell\nDESCRIPTION: The cls command is an alternative to clear that clears the terminal screen in the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nusage: cls [-?]   \ndescription: clears the screen   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Table without Bloom Filters\nDESCRIPTION: This set of commands inserts 3 million entries into 'bloom_test1' using RandomBatchWriter with different seeds, flushing after each batch.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test1 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n```\n\n----------------------------------------\n\nTITLE: Creating, Populating and Exporting an Accumulo Table via Shell\nDESCRIPTION: Shell commands demonstrating the creation of a table, inserting data, adding splits, cloning and exporting the table. A table must be offline for export, so a clone is created and taken offline to avoid disrupting access to the original table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/export.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@test16> createtable table1\nroot@test16 table1> insert a cf1 cq1 v1\nroot@test16 table1> insert h cf1 cq1 v2\nroot@test16 table1> insert z cf1 cq1 v3\nroot@test16 table1> insert z cf1 cq2 v4\nroot@test16 table1> addsplits -t table1 b r\nroot@test16 table1> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test16> config -t table1 -s table.split.threshold=100M\nroot@test16 table1> clonetable table1 table1_exp\nroot@test16 table1> offline table1_exp\nroot@test16 table1> exporttable -t table1_exp /tmp/table1_export\nroot@test16 table1> quit\n```\n\n----------------------------------------\n\nTITLE: Dumping ZooKeeper Data for Backup in Accumulo Upgrade\nDESCRIPTION: Command to create a snapshot of the ZooKeeper contents before upgrading Accumulo to 2.1. This snapshot serves as a backup in case of issues requiring rollback to a previous version.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo dump-zoo --xml --root /accumulo | tee PATH_TO_SNAPSHOT\n```\n\n----------------------------------------\n\nTITLE: Querying Terms in Accumulo Shard\nDESCRIPTION: Example command to query the index for files containing specific terms 'foo' and 'bar'\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query -i instance -z zookeepers -t shard -u username -p password foo bar\n```\n\n----------------------------------------\n\nTITLE: Examining Accumulo RFile Sample Storage Implementation\nDESCRIPTION: This snippet demonstrates how to examine the internal structure of Accumulo RFiles to see how sample data is stored. It shows the metadata tables and file information, revealing the separate locality groups for sample data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance sampex> tables -l\naccumulo.metadata    =>        !0\naccumulo.replication =>      +rep\naccumulo.root        =>        +r\nsampex               =>         2\ntrace                =>         1\nroot@instance sampex> scan -t accumulo.metadata -c file -b 2 -e 2<\n2< file:hdfs://localhost:10000/accumulo/tables/2/default_tablet/A000000s.rf []    702,8\n\n$ ./bin/accumulo rfile-info hdfs://localhost:10000/accumulo/tables/2/default_tablet/A000000s.rf\nReading file: hdfs://localhost:10000/accumulo/tables/2/default_tablet/A000000s.rf\nRFile Version            : 8\n\nLocality group           : <DEFAULT>\n  Start block            : 0\n  Num   blocks           : 1\n  Index level 0          : 35 bytes  1 blocks\n  First key              : 2317 doc:content [] 1437672014986 false\n  Last key               : 9255 doc:url [] 1437672014875 false\n  Num entries            : 8\n  Column families        : [doc]\n\nSample Configuration     :\n  Sampler class          : org.apache.accumulo.core.client.sample.RowSampler\n  Sampler options        : {hasher=murmur3_32, modulus=2}\n\nSample Locality group    : <DEFAULT>\n  Start block            : 0\n  Num   blocks           : 1\n  Index level 0          : 36 bytes  1 blocks\n  First key              : 2317 doc:content [] 1437672014986 false\n  Last key               : 9255 doc:url [] 1437672014875 false\n  Num entries            : 6\n  Column families        : [doc]\n\nMeta block     : BCFile.index\n  Raw size             : 4 bytes\n  Compressed size      : 12 bytes\n  Compression type     : gz\n\nMeta block     : RFile.index\n  Raw size             : 309 bytes\n  Compressed size      : 176 bytes\n  Compression type     : gz\n```\n\n----------------------------------------\n\nTITLE: Downloading Jaeger Docker Image\nDESCRIPTION: Command to pull the Jaeger all-in-one Docker image for tracing visualization.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull jaegertracing/all-in-one:1.35\n```\n\n----------------------------------------\n\nTITLE: FileDecrypter Interface for Accumulo Custom Decryption\nDESCRIPTION: Method required for implementing the FileDecrypter interface to provide decryption functionality in a custom CryptoService for Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_10\n\nLANGUAGE: java\nCODE:\n```\n  InputStream decryptStream(InputStream inputStream) throws CryptoService.CryptoException;\n```\n\n----------------------------------------\n\nTITLE: Retrieving Specific Columns for a Row in Accumulo\nDESCRIPTION: This code demonstrates how to retrieve specific columns for a given row by creating a Range for a single row, setting up a Scanner, and iterating through the results. It shows how to fetch only a specific column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Table_Design.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nRange r = new Range(userid, userid); // single row\nScanner s = conn.createScanner(\"userdata\", auths);\ns.setRange(r);\ns.fetchColumnFamily(new Text(\"age\"));\n\nfor(Entry<Key,Value> entry : s)\n    System.out.println(entry.getValue().toString());\n```\n\n----------------------------------------\n\nTITLE: Moving Accumulo HDFS Directory for Reinitialization\nDESCRIPTION: This Hadoop command moves the Accumulo directory in HDFS, which is part of the process for recreating an Accumulo instance after severe data loss.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -mv /accumulo /corrupt\n```\n\n----------------------------------------\n\nTITLE: Creating and Testing Accumulo Table Constraints\nDESCRIPTION: Shell commands demonstrating the creation of a table with constraints and testing constraint violations. The example shows how constraints prevent invalid data insertion while allowing valid entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/constraints.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable testConstraints\nusername@instance testConstraints> constraint -a org.apache.accumulo.examples.simple.constraints.NumericValueConstraint\nusername@instance testConstraints> constraint -a org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint\nusername@instance testConstraints> insert r1 cf1 cq1 1111\nusername@instance testConstraints> insert r1 cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> insert r1! cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.AlphaNumKeyConstraint, violationCode:1, violationDescription:Row was not alpha numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> scan\nr1 cf1:cq1 []    1111\nusername@instance testConstraints>\n```\n\n----------------------------------------\n\nTITLE: Setting Up FooFilter Iterator\nDESCRIPTION: Configures the FooFilter iterator to filter out rows containing 'foo' during scans and compactions\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/classpath.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsetiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\n```\n\n----------------------------------------\n\nTITLE: Starting an Accumulo Cluster with accumulo-cluster Script\nDESCRIPTION: Command to start an Accumulo cluster using the provided cluster management script after configuring and initializing Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-cluster start\n```\n\n----------------------------------------\n\nTITLE: Block Cache Configuration Properties\nDESCRIPTION: Shows the configuration properties used to set up block cache settings for tablet servers and individual tables in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ntserver.cache.data.size: Specifies the size of the cache for file data blocks.\ntserver.cache.index.size: Specifies the size of the cache for file indices.\n\ntable.cache.block.enable: Determines whether file (data) block cache is enabled.\ntable.cache.index.enable: Determines whether index cache is enabled.\n```\n\n----------------------------------------\n\nTITLE: Creating SSH Tunnel for Accessing Hadoop and Accumulo Monitors\nDESCRIPTION: This command sets up an SSH tunnel to access the Hadoop NameNode and Accumulo monitor pages from a remote machine.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nssh -L50070:localhost:50070 -L50095:localhost:50095 <user>@<host>\n```\n\n----------------------------------------\n\nTITLE: Restricting Accumulo to specific columns in MapReduce in Java\nDESCRIPTION: Optional configuration for AccumuloInputFormat that restricts the input to specific columns. Creates a list of column pairs (family and qualifier) to be fetched from the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Analytics.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Pair<Text,Text>> columns = new ArrayList<Pair<Text,Text>>();\n// populate list of columns\nAccumuloInputFormat.fetchColumns(job, columns);\n```\n\n----------------------------------------\n\nTITLE: Examining Table Files in HDFS\nDESCRIPTION: This snippet demonstrates how to view the map files for a table in HDFS using the Hadoop filesystem commands. It shows the three map files created for the bloom-enabled table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -lsr /accumulo/tables/o8\ndrwxr-xr-x   - username supergroup          0 2012-01-10 14:02 /accumulo/tables/o8/default_tablet\n-rw-r--r--   3 username supergroup   52672650 2012-01-10 14:01 /accumulo/tables/o8/default_tablet/F00000dj.rf\n-rw-r--r--   3 username supergroup   52436176 2012-01-10 14:01 /accumulo/tables/o8/default_tablet/F00000dk.rf\n-rw-r--r--   3 username supergroup   52850173 2012-01-10 14:02 /accumulo/tables/o8/default_tablet/F00000dl.rf\n```\n\n----------------------------------------\n\nTITLE: Querying with RandomBatchScanner in Accumulo (Different Seed)\nDESCRIPTION: This snippet shows performing 500 random queries using a different seed (8), resulting in no matches. Bloom filters significantly increase performance by quickly determining that entries don't exist.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 8 -i instance -z zookeepers -u username -p password -t bloom_test --num 500 --min 0 --max 1000000000 --size 50 --batchThreads 20 --auths exampleVis\nGenerating 500 random queries...finished\n2212.39 lookups/sec   0.23 secs\nnum results : 0\nDid not find 500 rows\nGenerating 500 random queries...finished\n4464.29 lookups/sec   0.11 secs\nnum results : 0\nDid not find 500 rows\n```\n\n----------------------------------------\n\nTITLE: Monitor UI Trace Page Error\nDESCRIPTION: Stack trace showing authentication token error when accessing the Monitor UI's Recent Traces page\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_15\n\nLANGUAGE: java\nCODE:\n```\njava.lang.AssertionError: AuthenticationToken should not be null\n    at org.apache.accumulo.monitor.servlets.trace.Basic.getScanner(Basic.java:139)\n    at org.apache.accumulo.monitor.servlets.trace.Summary.pageBody(Summary.java:164)\n```\n\n----------------------------------------\n\nTITLE: Executing RenameMasterDirInZK Utility in Java\nDESCRIPTION: Command to run the RenameMasterDirInZK utility for upgrading ZooKeeper state when renaming 'master' to 'manager' in Accumulo 2.1.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2022-11-01-accumulo-2.1.0.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n${ACCUMULO_HOME}/bin/accumulo org.apache.accumulo.manager.upgrade.RenameMasterDirInZK\n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest with Isolation in Accumulo\nDESCRIPTION: Command for running the InterferenceTest example with isolation enabled, demonstrating how the isolation feature prevents inconsistent reads during concurrent updates.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/isolation.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000 --isolated\nfinished\n```\n\n----------------------------------------\n\nTITLE: Running Reverse Index Population\nDESCRIPTION: Command to populate the doc2term table using the Reverse program\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Reverse -i instance -z zookeepers --shardTable shard --doc2Term doc2term -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Setting Iterators Programmatically in Accumulo\nDESCRIPTION: Shows how to set and configure iterators programmatically using the Accumulo Java API. Includes examples of setting scan iterators and passing iterator options.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nscanner.setScanIterators(\n    15, // priority\n    \"com.company.MyIterator\", // class name\n    \"myiter\"); // name this iterator\n```\n\n----------------------------------------\n\nTITLE: Defining Property Types in Markdown Table\nDESCRIPTION: A markdown table that defines various property types used in Apache Accumulo configuration. It includes the type name, description, valid and invalid examples, and any specific constraints or rules for each type.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n| Type | Description |\n|--------------|-------------|\n| duration | A non-negative integer optionally followed by a unit of time (whitespace disallowed), as in 30s.<br>If no unit of time is specified, seconds are assumed. Valid units are 'ms', 's', 'm', 'h' for milliseconds, seconds, minutes, and hours.<br>Examples of valid durations are '600', '30s', '45m', '30000ms', '3d', and '1h'.<br>Examples of invalid durations are '1w', '1h30m', '1s 200ms', 'ms', '', and 'a'.<br>Unless otherwise stated, the max value for the duration represented in milliseconds is 9223372036854775807 |\n| bytes | A positive integer optionally followed by a unit of memory (whitespace disallowed).<br>If no unit is specified, bytes are assumed. Valid units are 'B', 'K', 'M' or 'G' for bytes, kilobytes, megabytes, gigabytes.<br>Examples of valid memories are '1024', '20B', '100K', '1500M', '2G', '20%'.<br>Examples of invalid memories are '1M500K', '1M 2K', '1MB', '1.5G', '1,024K', '', and 'a'.<br>Unless otherwise stated, the max value for the memory represented in bytes is 9223372036854775807 |\n| memory | A positive integer optionally followed by a unit of memory or a percentage (whitespace disallowed).<br>If a percentage is specified, memory will be a percentage of the max memory allocated to a Java process (set by the JVM option -Xmx).<br>If no unit is specified, bytes are assumed. Valid units are 'B', 'K', 'M', 'G', '%' for bytes, kilobytes, megabytes, gigabytes, and percentage.<br>Examples of valid memories are '1024', '20B', '100K', '1500M', '2G', '20%'.<br>Examples of invalid memories are '1M500K', '1M 2K', '1MB', '1.5G', '1,024K', '', and 'a'.<br>Unless otherwise stated, the max value for the memory represented in bytes is 9223372036854775807 |\n| host list | A comma-separated list of hostnames or ip addresses, with optional port numbers.<br>Examples of valid host lists are 'localhost:2000,www.example.com,10.10.1.1:500' and 'localhost'.<br>Examples of invalid host lists are '', ':1000', and 'localhost:80000' |\n| port | An positive integer in the range 1024-65535 (not already in use or specified elsewhere in the configuration),<br>zero to indicate any open ephemeral port, or a range of positive integers specified as M-N |\n| count | A non-negative integer in the range of 0-2147483647 |\n| fraction/percentage | A floating point number that represents either a fraction or, if suffixed with the '%' character, a percentage.<br>Examples of valid fractions/percentages are '10', '1000%', '0.05', '5%', '0.2%', '0.0005'.<br>Examples of invalid fractions/percentages are '', '10 percent', 'Hulk Hogan' |\n| path | A string that represents a filesystem path, which can be either relative or absolute to some directory. The filesystem depends on the property. Substitutions of the ACCUMULO_HOME environment variable can be done in the system config file using '${env:ACCUMULO_HOME}' or similar. |\n| absolute path | An absolute filesystem path. The filesystem depends on the property. This is the same as path, but enforces that its root is explicitly specified. |\n| java class | A fully qualified java class name representing a class on the classpath.<br>An example is 'java.lang.String', rather than 'String' |\n| java class list | A list of fully qualified java class names representing classes on the classpath.<br>An example is 'java.lang.String', rather than 'String' |\n| durability | One of 'none', 'log', 'flush' or 'sync'. |\n| gc_post_action | One of 'none', 'flush', or 'compact'. |\n| last_location_mode | Defines how to update the last location.  One of 'assignment', or 'compaction'. |\n| string | An arbitrary string of characters whose format is unspecified and interpreted based on the context of the property to which it applies. |\n| boolean | Has a value of either 'true' or 'false' (case-insensitive) |\n| uri | A valid URI |\n| file name extension | One of the currently supported filename extensions for storing table data files. Currently, only rf is supported. |\n```\n\n----------------------------------------\n\nTITLE: Implementing Reducer for Accumulo Output\nDESCRIPTION: This Java code demonstrates an example implementation of a Reducer class that writes mutations to an Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/mapreduce.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nclass MyReducer extends Reducer<WritableComparable, Writable, Text, Mutation> {\n    public void reduce(WritableComparable key, Iterable<Text> values, Context c) {\n        Mutation m;\n        // create the mutation based on input key and value\n        c.write(new Text(\"output-table\"), m);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Pre-1970 Dates with ULongLexicoder in Accumulo\nDESCRIPTION: This code snippet demonstrates how to read Date objects stored with the broken DateLexicoder implementation (for dates prior to 1970). It creates a ULongLexicoder instance and uses it to decode row values from a scanner into Date objects.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2015-02-16-accumulo-1.6.2.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nLexicoder lex = new ULongLexicoder();\nfor (Entry<Key, Value> e : scanner) {\n  Date d = new Date(lex.decode(TextUtil.getBytes(e.getKey().getRow())));\n  // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Inspecting Exported Accumulo Table Files using Hadoop Commands\nDESCRIPTION: This snippet shows how to use Hadoop commands to list and view the contents of the exported table files, including the distcp.txt file which contains the list of files to be copied.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/export.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/table1_export\nFound 2 items\n-rw-r--r--   3 user supergroup        162 2012-07-25 09:56 /tmp/table1_export/distcp.txt\n-rw-r--r--   3 user supergroup        821 2012-07-25 09:56 /tmp/table1_export/exportMetadata.zip\n$ hadoop fs -cat /tmp/table1_export/distcp.txt\nhdfs://n1.example.com:6093/accumulo/tables/3/default_tablet/F0000000.rf\nhdfs://n1.example.com:6093/tmp/table1_export/exportMetadata.zip\n```\n\n----------------------------------------\n\nTITLE: Root Table Compaction Service Executors Configuration\nDESCRIPTION: JSON configuration for the root table compaction service executors, specifying thread pools for small and huge compactions with single threads.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties.md#2025-04-11_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"32M\",\"numThreads\":1},{\"name\":\"huge\",\"type\":\"internal\",\"numThreads\":1}]\n```\n\n----------------------------------------\n\nTITLE: User Administration in Accumulo Shell\nDESCRIPTION: Commands for user administration, including creating users, authenticating users, granting and revoking permissions, and switching between users in the shell session.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Accumulo_Shell.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nroot@myinstance mytable> createuser bob\nEnter new password for 'bob': *********\nPlease confirm new password for 'bob': *********\n\nroot@myinstance mytable> authenticate bob\nEnter current password for 'bob': *********\nValid\n\nroot@myinstance mytable> grant System.CREATE_TABLE -s -u bob\n\nroot@myinstance mytable> user bob\nEnter current password for 'bob': *********\n\nbob@myinstance mytable> userpermissions\nSystem permissions: System.CREATE_TABLE\nTable permissions (!METADATA): Table.READ\nTable permissions (mytable): NONE\n\nbob@myinstance mytable> createtable bobstable\nbob@myinstance bobstable>\n\nbob@myinstance bobstable> user root\nEnter current password for 'root': *********\n\nroot@myinstance bobstable> revoke System.CREATE_TABLE -s -u bob\n```\n\n----------------------------------------\n\nTITLE: Accessing Accumulo Shell\nDESCRIPTION: Command to log into the Accumulo shell with username and password authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Pre-Splitting Tables Using Shell Command in Accumulo\nDESCRIPTION: This command demonstrates how to pre-split an Accumulo table using the addsplits command in the Accumulo shell. Pre-splitting ensures multiple tablets are available before ingest begins, enabling parallel processing across TabletServers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> addsplits -sf /local_splitfile -t mytable\n```\n\n----------------------------------------\n\nTITLE: Reading Data with Java Program\nDESCRIPTION: Command to run a Java program that reads data from specified row range in Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.ReadData instance zookeepers username password hellotable row_0 row_1001\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Bloom Filters in Accumulo Shell\nDESCRIPTION: This snippet shows how to create an Accumulo table with bloom filters enabled. The process involves logging into the Accumulo shell, setting authorizations, creating a table, and enabling bloom filters through configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test\nusername@instance bloom_test> config -t bloom_test -s table.bloom.enabled=true\nusername@instance bloom_test> exit\n```\n\n----------------------------------------\n\nTITLE: Examining ZooKeeper ACLs with zoo-info-viewer Output Example\nDESCRIPTION: Sample output from the zoo-info-viewer utility showing different permission states for ZooKeeper nodes. The output shows correct permissions (ACCUMULO_OKAY), missing permissions (ERROR_ACCUMULO_MISSING_SOME), and privacy status (PRIVATE/NOT_PRIVATE) for various znodes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/zookeeper.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nACCUMULO_OKAY:NOT_PRIVATE /accumulo/f491223b-1413-494e-b75a-c2ca018db00f cdrwa:accumulo, r:anyone\nACCUMULO_OKAY:PRIVATE /accumulo/f491223b-1413-494e-b75a-c2ca018db00f/config cdrwa:accumulo\nERROR_ACCUMULO_MISSING_SOME:NOT_PRIVATE /accumulo/f491223b-1413-494e-b75a-c2ca018db00f/users/root/Namespaces r:accumulo, r:anyone\n```\n\n----------------------------------------\n\nTITLE: Configuring Uno for Accumulo Proxy\nDESCRIPTION: These configuration settings in uno.conf enable the Accumulo Proxy as a post-run plugin and specify the path to the Accumulo Proxy repository.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-12-16-accumulo-proxy.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport POST_RUN_PLUGINS=\"accumulo-proxy\"\nexport PROXY_REPO=/path/to/accumulo-proxy\n```\n\n----------------------------------------\n\nTITLE: Examining Accumulo Table Contents After Reservation Operations\nDESCRIPTION: This shell session shows the underlying Accumulo table structure after running the reservation example. It reveals how reservations are stored in the table with sequence numbers used for concurrency control. The tx:seq column is crucial for implementing conditional mutations that detect concurrent changes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/reservations.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nroot@test16> table ars\nroot@test16 ars> scan\nroom06:20140101 res:0001 []    mallory\nroom06:20140101 res:0003 []    trent\nroom06:20140101 res:0004 []    eve\nroom06:20140101 tx:seq []    6\n```\n\n----------------------------------------\n\nTITLE: Querying Table without Bloom Filters\nDESCRIPTION: This command performs 500 lookups against the 'bloom_test1' table (without bloom filters) using RandomBatchScanner with seed 7.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test1 --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Table Compaction Configuration\nDESCRIPTION: Properties controlling table compaction behavior including ratios, idle time, and dispatcher settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\ntable.compaction.major.ratio=3\ntable.compaction.minor.idle=5m\ntable.compaction.major.output.drop.cache=false\n```\n\n----------------------------------------\n\nTITLE: Testing AgeOffFilter scan behavior in Accumulo\nDESCRIPTION: This snippet demonstrates how data is filtered by the AgeOffFilter during scans. It shows inserting data, confirming it's visible immediately, and then verifying it's no longer visible after the 30-second TTL period has expired.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/filter.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> scan\nusername@instance filtertest> insert foo a b c\nusername@instance filtertest> scan\nfoo a:b []    c\n\n... wait 30 seconds ...\n    \nusername@instance filtertest> scan\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Old Accumulo Instances in ZooKeeper\nDESCRIPTION: Using the DeleteZooInstance utility with the -c flag to clean up all old instances from ZooKeeper, preserving only the currently active instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin deleteZooInstance -c\nDeleted instance: instance1\nDeleted instance: instance2\n```\n\n----------------------------------------\n\nTITLE: Populating doc2term Table Using Reverse Program\nDESCRIPTION: Command to run the Reverse program, which reads the shard index table and writes a map of documents to terms into the doc2term table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Reverse -i instance -z zookeepers --shardTable shard --doc2Term doc2term -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Read Latency Comparison Table - Normal Operation\nDESCRIPTION: Markdown table showing read latency metrics (min/avg/max in milliseconds) for different encoding policies during normal cluster operation with 16 nodes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-17-erasure-coding.md#2025-04-11_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|Encoding|Min|Avg|Max|\n|--------|--:|--:|--:|\n|RS 10-4 1MB|40|105|2148|\n|RS 6-3 1MB|30|68|1297|\n|RS 6-3 64KB|23|43|1064|\n|Replication|11|23|731|\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Scan Executor with JSON Properties\nDESCRIPTION: Default configuration for scan executors in Accumulo, specified as a JSON array. This configuration defines small and huge executors with their respective thread counts and size limits.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"32M\",\"numThreads\":1},{\"name\":\"huge\",\"type\":\"internal\",\"numThreads\":1}]\n```\n\n----------------------------------------\n\nTITLE: Flushing Accumulo Table\nDESCRIPTION: This command flushes the 'bloom_test' table to ensure all data is written to disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test -w'\n```\n\n----------------------------------------\n\nTITLE: Examining RFile Metadata with rfile-info in Accumulo\nDESCRIPTION: The rfile-info tool displays metadata about an Accumulo storage file, including locality groups, block information, key ranges, and column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo rfile-info /accumulo/tables/1/default_tablet/A000000n.rf\n2013-07-16 08:17:14,778 [util.NativeCodeLoader] INFO : Loaded the native-hadoop library\nLocality group         : <DEFAULT>\n        Start block          : 0\n        Num   blocks         : 1\n        Index level 0        : 62 bytes  1 blocks\n        First key            : 288be9ab4052fe9e span:34078a86a723e5d3:3da450f02108ced5 [] 1373373521623 false\n        Last key             : start:13fc375709e id:615f5ee2dd822d7a [] 1373373821660 false\n        Num entries          : 466\n        Column families      : [waitForCommits, start, md major compactor 1, md major compactor 2, md major compactor 3,\n                                 bringOnline, prep, md major compactor 4, md major compactor 5, md root major compactor 3,\n                                 minorCompaction, wal, compactFiles, md root major compactor 4, md root major compactor 1,\n                                 md root major compactor 2, compact, id, client:update, span, update, commit, write,\n                                 majorCompaction]\n\nMeta block     : BCFile.index\n      Raw size             : 4 bytes\n      Compressed size      : 12 bytes\n      Compression type     : gz\n\nMeta block     : RFile.index\n      Raw size             : 780 bytes\n      Compressed size      : 344 bytes\n      Compression type     : gz\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with BatchWriter\nDESCRIPTION: Command to run a Java program that inserts data into Accumulo using BatchWriter, which adds 50K entries across 10K rows.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithBatchWriter instance zookeepers username password hellotable\n```\n\n----------------------------------------\n\nTITLE: Executing Bulk Ingest Commands in Apache Accumulo\nDESCRIPTION: A series of shell commands that demonstrate the complete workflow of bulk ingestion. The process includes setting up environment variables, creating a table with split points, generating test data, performing bulk ingest, and verifying the ingested data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ PKG=org.apache.accumulo.examples.simple.mapreduce.bulk\n$ ARGS=\"-i instance -z zookeepers -u username -p password\"\n$ ./bin/accumulo $PKG.SetupTable $ARGS -t test_bulk row_00000333 row_00000666\n$ ./bin/accumulo $PKG.GenerateTestData --start-row 0 --count 1000 --output bulk/test_1.txt\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar $PKG.BulkIngestExample $ARGS -t test_bulk --inputDir bulk --workDir tmp/bulkWork\n$ ./bin/accumulo $PKG.VerifyIngest $ARGS -t test_bulk --start-row 0 --count 1000\n```\n\n----------------------------------------\n\nTITLE: Implementing Reducer class for Accumulo MapReduce integration in Java\nDESCRIPTION: Sample implementation of a Reducer class that writes to an Accumulo table. This reducer creates Mutation objects and specifies the output table name, allowing a single reducer to write to multiple tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Analytics.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass MyReducer extends Reducer<WritableComparable, Writable, Text, Mutation> {\n\n    public void reduce(WritableComparable key, Iterator<Text> values, Context c) {\n        \n        Mutation m;\n        \n        // create the mutation based on input key and value\n        \n        c.write(new Text(\"output-table\"), m);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Deploying Accumulo Cluster with Muchos\nDESCRIPTION: Commands to launch and set up an Accumulo cluster in AWS using Muchos\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmuchos launch -c mycluster\nmuchos setup\n```\n\n----------------------------------------\n\nTITLE: Configuring Compaction Services in Accumulo\nDESCRIPTION: Sets up compaction services for Accumulo, including planners and executors. This example shows the configuration for the default compaction service.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\ntserver.compaction.major.service.default.planner = org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\ntserver.compaction.major.service.default.planner.opts.executors = [{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"32M\",\"numThreads\":2},{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":2},{\"name\":\"large\",\"type\":\"internal\",\"numThreads\":2}]\n```\n\n----------------------------------------\n\nTITLE: Starting and Enabling Hadoop NameNode Service\nDESCRIPTION: These commands start the Hadoop NameNode service and enable it to run on system boot for multi-node setups.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start hadoop-namenode.service\nsudo systemctl enable hadoop-namenode.service\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo Package\nDESCRIPTION: Command to extract the Accumulo tar archive into the installation directory specified by $ACCUMULO_HOME\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Administration.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ tar xzf $ACCUMULO_HOME/accumulo.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Checking the Output Files in HDFS\nDESCRIPTION: This snippet shows how to list the files generated by the MapReduce job in the output directory. It demonstrates the standard MapReduce output pattern with a success marker and part files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/regex.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/output\nFound 3 items\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:11 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:10 /tmp/output/_logs\n-rw-r--r--   1 username supergroup         51 2013-01-10 14:10 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Configuring VFS Classpath Delegation\nDESCRIPTION: Configuration to override default classloader behavior to check the application classloader before the parent classloader.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.vfs.context.classpath.app1.delegation=post\n```\n\n----------------------------------------\n\nTITLE: Inspecting and Copying Exported Apache Accumulo Table Files\nDESCRIPTION: This snippet shows how to examine the files created by the export process and use distcp to copy them to a destination location. The exported files include metadata and a list of files to be copied.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/export.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/table1_export\nFound 2 items\n-rw-r--r--   3 user supergroup        162 2012-07-25 09:56 /tmp/table1_export/distcp.txt\n-rw-r--r--   3 user supergroup        821 2012-07-25 09:56 /tmp/table1_export/exportMetadata.zip\n$ hadoop fs -cat /tmp/table1_export/distcp.txt\nhdfs://n1.example.com:6093/accumulo/tables/3/default_tablet/F0000000.rf\nhdfs://n1.example.com:6093/tmp/table1_export/exportMetadata.zip\n\n$ hadoop distcp -f /tmp/table1_export/distcp.txt /tmp/table1_export_dest\n```\n\n----------------------------------------\n\nTITLE: Displaying Accumulo 2.0.0 Command Usage\nDESCRIPTION: Demonstrates the improved and more organized usage information for the accumulo command in version 2.0.0.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ./accumulo-2.0.0/bin/accumulo help\n\nUsage: accumulo <command> [-h] (<argument> ...)\n\n  -h   Prints usage for specified command\n\nCore Commands:\n  init                           Initializes Accumulo\n  shell                          Runs Accumulo shell\n  classpath                      Prints Accumulo classpath\n  version                        Prints Accumulo version\n  admin                          Executes administrative commands\n  info                           Prints Accumulo cluster info\n  help                           Prints usage\n  <main class> args              Runs Java <main class> located on Accumulo classpath\n\nProcess Commands:\n  gc                             Starts Accumulo garbage collector\n  master                         Starts Accumulo master\n  monitor                        Starts Accumulo monitor\n  minicluster                    Starts Accumulo minicluster\n  proxy                          Starts Accumulo proxy\n  tserver                        Starts Accumulo tablet server\n  tracer                         Starts Accumulo tracer\n  zookeeper                      Starts Apache Zookeeper instance\n\nAdvanced Commands:\n  check-server-config            Checks server config\n  create-token                   Creates authentication token\n  login-info                     Prints Accumulo login info\n  rfile-info                     Prints rfile info\n```\n\n----------------------------------------\n\nTITLE: Setting Authentication Credentials for Replication\nDESCRIPTION: Commands to configure the username and password that the primary instance will use to authenticate with the peer when replicating data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_10\n\nLANGUAGE: console\nCODE:\n```\nroot@primary> config -s replication.peer.user.peer=peer\nroot@primary> config -s replication.peer.password.peer=peer\n```\n\n----------------------------------------\n\nTITLE: Retrieving Accumulo Table Split Points\nDESCRIPTION: The 'getsplits' command retrieves the current split points for tablets in the current table. It supports various output options.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_25\n\nLANGUAGE: markdown\nCODE:\n```\n**getsplits**   \n\n    usage: getsplits [-?] [-b64] [-m <num>] [-o <file>] [-v]   \n    description: retrieves the current split points for tablets in the current table   \n      -?,-help  display this help   \n      -b64,-base64encoded encode the split points   \n      -m,-max <num>  specifies the maximum number of splits to create   \n      -o,-output <file>  specifies a local file to write the splits to   \n      -v,-verbose print out the tablet information with start/end rows   \n```\n\n----------------------------------------\n\nTITLE: Building Javadocs with Maven\nDESCRIPTION: This Maven command builds the Javadocs for Accumulo, skipping tests and using the aggregate-javadocs profile.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/making-release.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmvn clean package javadoc:aggregate -DskipTests -Paggregate-javadocs\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL Ciphers for Accumulo Monitor in YAML\nDESCRIPTION: YAML configuration for controlling SSL ciphers allowed for connections to the Accumulo Monitor. It specifies properties for including and excluding ciphers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/monitoring-metrics.md#2025-04-11_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nmonitor.ssl.include.ciphers: \nmonitor.ssl.exclude.ciphers: \n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table via Shell\nDESCRIPTION: Shell command to create a new table named 'hellotable' in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/helloworld.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable hellotable\n```\n\n----------------------------------------\n\nTITLE: Running Reverse Index Population\nDESCRIPTION: Command to populate the doc2term table by reversing the shard index.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Reverse instance zookeepers shard doc2term username password\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo ZooKeeper Settings\nDESCRIPTION: XML configuration for specifying ZooKeeper servers and write-ahead log directory settings in accumulo-site.xml\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Administration.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n    <name>zookeeper</name>\n    <value>zooserver-one:2181,zooserver-two:2181</value>\n    <description>list of zookeeper servers</description>\n</property>\n<property>\n    <name>walog</name>\n    <value>/var/accumulo/walogs</value>\n    <description>local directory for write ahead logs</description>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo 2.0.0 Cluster Configuration\nDESCRIPTION: Demonstrates the command to generate host files for the accumulo-cluster script in Accumulo 2.0.0.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo-cluster create-config\n```\n\n----------------------------------------\n\nTITLE: Configuring Block Cache Manager in Accumulo\nDESCRIPTION: Specifies the class name of the block cache factory implementation. An alternative implementation is provided for TinyLFU cache.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\ntserver.cache.manager.class = org.apache.accumulo.core.file.blockfile.cache.lru.LruBlockCacheManager\n```\n\n----------------------------------------\n\nTITLE: Creating Combined Keytab for All Accumulo Principals\nDESCRIPTION: This command creates a single keytab file containing keys for all Accumulo principals. While simplifying deployment, this approach is less secure than using individual keytabs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkadmin.local -q \"xst -k accumulo.service.keytab -glob accumulo*\"\n```\n\n----------------------------------------\n\nTITLE: Configuring External Compactions for Large Files in Accumulo\nDESCRIPTION: Configuration that modifies the compaction service to use external compactions for large files while keeping small and medium compactions internal. This example directs large compactions to an external queue named 'DCQ1'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\ntserver.compaction.major.service.cs1.planner.opts.executors=[\n{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"16M\",\"numThreads\":8},\n{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":4},\n{\"name\":\"large\",\"type\":\"external\",\"queue\":\"DCQ1\"}]'\n```\n\n----------------------------------------\n\nTITLE: Granting Table Creation Permissions in Accumulo\nDESCRIPTION: Shows how to grant System.CREATE_TABLE permission to a user, allowing them to create tables, and demonstrates the resulting permissions after table creation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> user root\nEnter password for user root: ********\nroot@instance> grant -s System.CREATE_TABLE -u username\nroot@instance> user username \nEnter password for user username: ********\nusername@instance> createtable vistest\nusername@instance> userpermissions\nSystem permissions: System.CREATE_TABLE\n\nTable permissions (!METADATA): Table.READ\nTable permissions (vistest): Table.READ, Table.WRITE, Table.BULK_IMPORT, Table.ALTER_TABLE, Table.GRANT, Table.DROP_TABLE\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Shell as Root User\nDESCRIPTION: This command runs the Accumulo shell as the root user, connecting to the specified ZooKeeper instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\naccumulo shell -u root -zh <zk-dns-name>:2181 -zi <instanceName>\n```\n\n----------------------------------------\n\nTITLE: Populating doc2term Table Using Reverse Operation\nDESCRIPTION: Command to run the Reverse program that reads the shard table and writes a mapping of documents to terms into the doc2term table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/shard.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Reverse -i instance -z zookeepers --shardTable shard --doc2Term doc2term -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Generating Certificate Authority with OpenSSL and Java Keytool\nDESCRIPTION: Commands to create a certificate authority, generate its private key, create a certificate, and import it into a Java KeyStore for use as a truststore.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-09-02-generating-keystores-for-configuring-accumulo-with-ssl.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Create a private key\nopenssl genrsa -des3 -out root.key 4096\n\n# Create a certificate request using the private key\nopenssl req -x509 -new -key root.key -days 365 -out root.pem\n\n# Generate a Base64-encoded version of the PEM just created\nopenssl x509 -outform der -in root.pem -out root.der\n\n# Import the key into a Java KeyStore\nkeytool -import -alias root-key -keystore truststore.jks -file root.der\n\n# Remove the DER formatted key file (as we don't need it anymore)\nrm root.der\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Logical Time\nDESCRIPTION: Example showing how to create an Accumulo table with logical time versioning using the shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nuser@myinstance> createtable -tl logical\n```\n\n----------------------------------------\n\nTITLE: Overriding Site Configuration in Accumulo Tserver Startup\nDESCRIPTION: Shows how to override server properties when starting an Accumulo tablet server process using command-line options. This is useful when you can't modify the accumulo.properties file directly.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naccumulo tserver -o instance.secret=mysecret -o instance.zookeeper.host=localhost:2181\n```\n\n----------------------------------------\n\nTITLE: Enabling Micrometer Metrics in Accumulo Properties\nDESCRIPTION: Properties configuration for enabling Micrometer metrics in Accumulo. It includes settings for general metrics, JVM metrics, and specifying a custom MeterRegistryFactory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/monitoring-metrics.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.micrometer.enabled=true\ngeneral.micrometer.jvm.metrics.enabled=true\ngeneral.micrometer.factory=\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with MapReduce\nDESCRIPTION: Command to run a Java program that inserts the same data but using MapReduce writers. Requires instance name, ZooKeeper servers, table name, username, and password parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.helloworld.InsertWithOutputFormat instance zookeepers hellotable username password\n```\n\n----------------------------------------\n\nTITLE: Setting up Accumulo Environment\nDESCRIPTION: Commands showing how to navigate and execute commands in both bash shell and Accumulo shell environment. These commands are used throughout the examples to interact with Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/index.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ # Commands run from $ACCUMULO_HOME directory\n```\n\nLANGUAGE: text\nCODE:\n```\n> # Commands run in Accumulo shell\n```\n\n----------------------------------------\n\nTITLE: Adding Nodes to Accumulo Cluster\nDESCRIPTION: Command to start Accumulo on new hosts and add them to the cluster. This should be run after updating the slaves configuration file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Administration.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo admin start <host(s)> {<host> ...}\n```\n\n----------------------------------------\n\nTITLE: Configuring Context ClassPaths in Accumulo\nDESCRIPTION: XML configuration examples demonstrating how to define multiple application contexts with different classpath sources including HDFS, local filesystem, and HTTP. Shows configuration for both default delegation and custom post-delegation behavior.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-03-accumulo-classloader.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>general.vfs.context.classpath.app1</name>\n  <value>hdfs://localhost:8020/applicationA/classpath/.*.jar,file:///opt/applicationA/lib/.*.jar</value>\n  <description>Application A classpath, loads jars from HDFS and local file system</description>\n</property>\n\n<property>\n  <name>general.vfs.context.classpath.app2.delegation=post</name>\n  <value>hdfs://localhost:8020/applicationB/classpath/.*.jar,http://my-webserver/applicationB/.*.jar</value>\n  <description>Application B classpath, loads jars from HDFS and HTTP, does not delegate to parent first</description>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Listing Accumulo Instances Using ZooKeeper\nDESCRIPTION: This command shows how to list all Accumulo instances using a specific ZooKeeper ensemble. It provides information about instance names, IDs, and manager locations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.server.util.ListInstances\nINFO : Using ZooKeepers localhost:2181\n\n Instance Name       | Instance ID                          | Manager\n---------------------+--------------------------------------+-------------------------------\n              \"test\" | 6140b72e-edd8-4126-b2f5-e74a8bbe323b |                127.0.0.1:9999\n```\n\n----------------------------------------\n\nTITLE: Using Index Table for Term-Based Lookups in Accumulo\nDESCRIPTION: Demonstrates a two-step lookup process using an index table. First queries the index to find matching row IDs, then uses a BatchScanner to efficiently retrieve the corresponding rows from the main table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Design.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// first we scan the index for IDs of rows matching our query\n\nText term = new Text(\"mySearchTerm\");\n\nHashSet<Text> matchingRows = new HashSet<Text>();\n\nScanner indexScanner = createScanner(\"index\", auths);\nindexScanner.setRange(new Range(term, term));\n\n// we retrieve the matching rowIDs and create a set of ranges\nfor(Entry<Key,Value> entry : indexScanner)\n    matchingRows.add(new Text(entry.getValue()));\n\n// now we pass the set of rowIDs to the batch scanner to retrieve them\nBatchScanner bscan = conn.createBatchScanner(\"table\", auths, 10);\n\nbscan.setRanges(matchingRows);\nbscan.fetchFamily(\"attributes\");\n\nfor(Entry<Key,Value> entry : scan)\n    System.out.println(e.getValue());\n```\n\n----------------------------------------\n\nTITLE: Starting a Compactor Process in Accumulo\nDESCRIPTION: Command to start a Compactor process that will handle external compaction jobs from the specified queue 'DCQ1'. The Compactor connects to the Compaction Coordinator to receive and process compaction jobs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbin/accumulo compactor -q DCQ1\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOffFilter for Minor and Major Compactions\nDESCRIPTION: Demonstrates how to set up AgeOffFilter for minor and major compactions using the -class flag, followed by flush and compact operations to enforce data cleanup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filter.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> setiter -t filtertest -minc -majc -p 10 -n myfilter -class org.apache.accumulo.core.iterators.user.AgeOffFilter\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> flush\n06 10:42:24,806 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact\n06 10:42:36,781 [shell.Shell] INFO : Compaction of table filtertest started for given range\nusername@instance filtertest> flush -t filtertest -w\n06 10:42:52,881 [shell.Shell] INFO : Flush of table filtertest completed.\nusername@instance filtertest> compact -t filtertest -w\n06 10:43:00,632 [shell.Shell] INFO : Compacting table ...\n06 10:43:01,307 [shell.Shell] INFO : Compaction of table filtertest completed for given range\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Configuring TestStatsDRegistryFactory System Properties\nDESCRIPTION: Java system properties to add to JAVA_OPTS in accumulo-env.sh for configuring TestStatsDRegistryFactory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n\"-Dtest.meter.registry.host=127.0.0.1\"\n\"-Dtest.meter.registry.port=8125\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Configuration for a Table in Accumulo\nDESCRIPTION: Shows how to display the current iterator settings for a table using the config command with the iterator filter. This output reveals all scopes (scan, minc, majc) where the AgeOffFilter has been applied and their respective settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filter.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+---------------------------------------------------------------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+---------------------------------------------------------------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+---------------------------------------------------------------------------\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Managing Tablet Server Locks in Accumulo\nDESCRIPTION: The TabletServerLocks utility allows listing and deleting tablet server locks. Useful for administrative tasks like recovering from server failures.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin locks\n    localhost:9997 TSERV_CLIENT=localhost:9997\n\n$ accumulo admin locks -delete localhost:9997\n\n$ accumulo admin locks\n    localhost:9997             <none>\n```\n\n----------------------------------------\n\nTITLE: Stopping Accumulo Tablet Server via Admin Command\nDESCRIPTION: This command shows how to stop an Accumulo tablet server on a specific host using the 'accumulo admin stop' command. It's useful for decommissioning a node or stopping a specific tablet server.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin stop hostname:9997\n2013-07-16 13:15:38,403 [util.Admin] INFO : Stopping server 12.34.56.78:9997\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo External Compaction Components\nDESCRIPTION: Commands to start the Compaction Coordinator and Compactor processes for external compactions. The Compactor requires specifying a queue name when starting.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\naccumulo compaction-coordinator &\n```\n\n----------------------------------------\n\nTITLE: Copying Data to HDFS\nDESCRIPTION: Commands to copy the Accumulo README file to HDFS and verify its presence in the target directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/mapred.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/README /user/username/wc/Accumulo.README\n$ hadoop fs -ls /user/username/wc\nFound 1 items\n-rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Accumulo.README\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for Accumulo 2.0\nDESCRIPTION: Maven dependency configuration for including Accumulo 2.0.1 core library in client applications.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_6\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.apache.accumulo</groupId>\n  <artifactId>accumulo-core</artifactId>\n  <version>2.0.1</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Running Java Data Reader Example\nDESCRIPTION: Command to execute the ReadData Java example, which reads and displays all entries between row_0 and row_1001 in the 'hellotable'. Demonstrates how to read specific ranges from a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.ReadData -i instance -z zookeepers -u username -p password -t hellotable --startKey row_0 --endKey row_1001\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Constraints in Apache Accumulo Shell\nDESCRIPTION: This shell session demonstrates creating a table with constraints, configuring two custom constraints (NumericValueConstraint and AlphaNumKeyConstraint), and testing how they validate or reject data. The constraints enforce that keys must be alphanumeric and values must be numeric.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/constraints.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p pass\n    \nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.3.x-incubating\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable testConstraints\nusername@instance testConstraints> config -t testConstraints -s table.constraint.1=org.apache.accumulo.examples.constraints.NumericValueConstraint\nusername@instance testConstraints> config -t testConstraints -s table.constraint.2=org.apache.accumulo.examples.constraints.AlphaNumKeyConstrain                                                                                                    \nusername@instance testConstraints> insert r1 cf1 cq1 1111\nusername@instance testConstraints> insert r1 cf1 cq1 ABC\n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> insert r1! cf1 cq1 ABC \n  Constraint Failures:\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.constraints.NumericValueConstraint, violationCode:1, violationDescription:Value is not numeric, numberOfViolatingMutations:1)\n      ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.constraints.AlphaNumKeyConstraint, violationCode:1, violationDescription:Row was not alpha numeric, numberOfViolatingMutations:1)\nusername@instance testConstraints> scan\nr1 cf1:cq1 []    1111\nusername@instance testConstraints>\n```\n\n----------------------------------------\n\nTITLE: Stopping an Entire Accumulo Cluster\nDESCRIPTION: Command to stop all services in an Accumulo cluster using the accumulo-cluster script.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-cluster stop\n```\n\n----------------------------------------\n\nTITLE: Checking Offline Tablets in Accumulo\nDESCRIPTION: This command uses the Accumulo admin tool to check for offline tablets, which is useful after HDFS failures.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin checkTablets\n```\n\n----------------------------------------\n\nTITLE: Using Zoo Property Editor\nDESCRIPTION: Examples showing how to view, set and delete properties using the zoo-prop-editor tool for emergency property management.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo zoo-prop-editor\n: Instance name: uno\n: Instance Id: e715caf8-f576-4b5d-871a-d47add90b7ba\n: Property scope: SYSTEM\n: ZooKeeper path: /accumulo/e715caf8-f576-4b5d-871a-d47add90b7ba/config\n: Name: system\n: Id: e715caf8-f576-4b5d-871a-d47add90b7ba\n: Data version: 0\n: Timestamp: 2023-06-12T21:52:15.727028Z\n```\n\n----------------------------------------\n\nTITLE: Displaying Disk Usage in Accumulo\nDESCRIPTION: The du command displays how much space is used by files referenced by tables. It can also show space used by files shared between multiple tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_23\n\nLANGUAGE: shell\nCODE:\n```\nusage: du <table> <table> [-?] [-p <pattern>]   \ndescription: Prints how much space is used by files referenced by a table.  When   \n          multiple tables are specified it prints how much space is used by files   \n          shared between tables, if any.   \n  -?,-help  display this help   \n  -p,-pattern <pattern>  regex pattern of table names\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Properties for Metrics\nDESCRIPTION: Properties to add to accumulo.properties file to enable Micrometer metrics and JVM metrics.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\n# Micrometer settings\ngeneral.micrometer.enabled=true\ngeneral.micrometer.jvm.metrics.enabled=true\ngeneral.micrometer.factory=org.apache.accumulo.test.metrics.TestStatsDRegistryFactory\n```\n\n----------------------------------------\n\nTITLE: Importing and Verifying an Accumulo Table via Shell\nDESCRIPTION: Shell commands for importing the copied table data into a new table and verifying that all data, splits, configurations, and logical time information were preserved in the process.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/export.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nroot@test16> importtable table1_copy /tmp/table1_export_dest\nroot@test16> table table1_copy\nroot@test16 table1_copy> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test16 table1_copy> getsplits -t table1_copy\nb\nr\nroot@test16> config -t table1_copy -f split\n---------+--------------------------+-------------------------------------------\nSCOPE    | NAME                     | VALUE\n---------+--------------------------+-------------------------------------------\ndefault  | table.split.threshold .. | 1G\ntable    |    @override ........... | 100M\n---------+--------------------------+-------------------------------------------\nroot@test16> tables -l\naccumulo.metadata    =>        !0\naccumulo.root        =>        +r\ntable1_copy          =>         5\ntrace                =>         1\nroot@test16 table1_copy> scan -t accumulo.metadata -b 5 -c srv:time\n5;b srv:time []    M1343224500467\n5;r srv:time []    M1343224500467\n5< srv:time []    M1343224500467\n```\n\n----------------------------------------\n\nTITLE: Defining Allowed Accumulo Package Imports\nDESCRIPTION: XML configuration for the ImportControl module that specifies which Accumulo packages are allowed and which are disallowed. This file should be named 'import-control.xml' and requires replacing 'insert-your-package-name' with your project's package name.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-11-04-checkstyle-import-control.md#2025-04-11_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<!DOCTYPE import-control PUBLIC\n    \"-//Checkstyle//DTD ImportControl Configuration 1.4//EN\"\n    \"https://checkstyle.org/dtds/import_control_1_4.dtd\">\n\n<!-- This checkstyle rule is configured to ensure only use of Accumulo API -->\n<import-control pkg=\"insert-your-package-name\" strategyOnMismatch=\"allowed\">\n    <!-- API packages -->\n    <allow pkg=\"org.apache.accumulo.core.client\"/>\n    <allow pkg=\"org.apache.accumulo.core.data\"/>\n    <allow pkg=\"org.apache.accumulo.core.security\"/>\n    <allow pkg=\"org.apache.accumulo.core.iterators\"/>\n    <allow pkg=\"org.apache.accumulo.minicluster\"/>\n    <allow pkg=\"org.apache.accumulo.hadoop.mapreduce\"/>\n\n    <!-- disallow everything else coming from accumulo -->\n    <disallow pkg=\"org.apache.accumulo\"/>\n</import-control>\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data into Accumulo Table\nDESCRIPTION: This command uses RandomBatchWriter to insert 1 million random values into the 'bloom_test' table. The rows range from 0 to 1 billion, and the random number generator is initialized with seed 7.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Setting Encryption Key URI for AES Crypto Service in Accumulo\nDESCRIPTION: Configuration property to specify the location of the encryption key file for the AESCryptoService.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.custom.crypto.key.uri=file:///secure/path/to/crypto-key-file\n```\n\n----------------------------------------\n\nTITLE: External Compaction Job Setup in Accumulo Logs\nDESCRIPTION: Log entries showing the communication between Compactor, CompactionCoordinator, and CompactionManager during the initial setup of an external compaction job with ID de6afc1d-64ae-4abf-8bce-02ec0a79aa6c.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_6\n\nLANGUAGE: log\nCODE:\n```\n2021-04-13T14:54:10,580 [compactor.Compactor] INFO : Attempting to get next job, eci = ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c\n2021-04-13T14:54:10,580 [coordinator.CompactionCoordinator] DEBUG: getCompactionJob called for queue DCQ1 by compactor localhost:9101\n2021-04-13T14:54:10,580 [coordinator.CompactionCoordinator] DEBUG: Found tserver localhost:9997 with priority 288230376151711747 compaction for queue DCQ1\n2021-04-13T14:54:10,580 [coordinator.CompactionCoordinator] DEBUG: Getting compaction for queue DCQ1 from tserver localhost:9997\n2021-04-13T14:54:10,581 [compactions.CompactionManager] DEBUG: Attempting to reserve external compaction, queue:DCQ1 priority:288230376151711747 compactor:localhost:9101\n2021-04-13T14:54:10,596 [compactions.CompactionManager] DEBUG: Reserved external compaction ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c\n2021-04-13T14:54:10,596 [coordinator.CompactionCoordinator] DEBUG: Returning external job ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c to localhost:9101\n```\n\n----------------------------------------\n\nTITLE: Calculating Native Maps Size for Accumulo in Bash\nDESCRIPTION: This formula ensures that minor compactions won't be automatically triggered before the native maps can be completely saturated. It calculates the maximum size of native maps based on write-ahead log size and minor compaction threshold.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$table.compaction.minor.logs.threshold * $tserver.walog.max.size >= $tserver.memory.maps.max\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorization in Accumulo Shell\nDESCRIPTION: This command sets the 'exampleVis' authorization for a user in the Accumulo shell. This authorization is required to run the batch writing and scanning example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/batch.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u root -e \"setauths -u username -s exampleVis\"\n```\n\n----------------------------------------\n\nTITLE: Checking FATE Operations in Accumulo 1.4\nDESCRIPTION: Command to list and verify FATE operations before upgrading from Accumulo 1.4 to 1.6.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo org.apache.accumulo.server.fate.Admin print\n```\n\n----------------------------------------\n\nTITLE: Logging into Accumulo Shell\nDESCRIPTION: Command to access the Accumulo shell with username and password authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with BatchWriter\nDESCRIPTION: Command to run a Java program that inserts 10K rows (50K entries) into Accumulo using BatchWriter. Requires instance name, ZooKeeper servers, table name, username, and password parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.helloworld.InsertWithBatchWriter instance zookeepers hellotable username password\n```\n\n----------------------------------------\n\nTITLE: Unpacking Accumulo Binary Distribution\nDESCRIPTION: Commands to extract the Accumulo binary distribution tarball in the installation location.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd <install_location>\ntar xzf <some_dir>/accumulo-X.Y.Z-bin.tar.gz\ncd accumulo-X.Y.Z\n```\n\n----------------------------------------\n\nTITLE: Changing User Passwords in Accumulo Shell\nDESCRIPTION: Command to change the password of user 'bob' in the Accumulo shell. Requires current root password and new password for the user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> passwd -u bob\nEnter current password for 'root': ******\nEnter new password for 'bob': ***\n```\n\n----------------------------------------\n\nTITLE: Metadata Table Updates After Compaction Completion in Accumulo\nDESCRIPTION: Shows the updated metadata table entries after the compaction has completed, including the addition of a completion marker (~ecomp entry) with the FINISHED state and statistics about the compaction.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_9\n\nLANGUAGE: text\nCODE:\n```\n2< ecomp:ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c []   {\"inputs\":[\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf\",\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf\"],\"tmp\":\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf_tmp\",\"dest\":\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf\",\"compactor\":\"localhost:9101\",\"kind\":\"USER\",\"executorId\":\"DCQ1\",\"priority\":288230376151711747}\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf []   12330,99000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf []   1196,1000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004j.rf []   1302,1000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004l.rf []   841,1000\n2< last:10000bf4e0a0004 []  localhost:9997\n2< loc:10000bf4e0a0004 []   localhost:9997\n2< srv:compact []   111\n2< srv:dir []   default_tablet\n2< srv:flush [] 114\n2< srv:lock []  tservers/localhost:9997/zlock#1950397a-b2ca-4685-b70b-67ae3cd578b9#0000000000$10000bf4e0a0004\n2< srv:time []  M1618325653080\n2< ~tab:~pr []  \\x00\n~ecompECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c : []    {\"extent\":{\"tableId\":\"2\"},\"state\":\"FINISHED\",\"fileSize\":12354,\"entries\":100000}\n```\n\n----------------------------------------\n\nTITLE: Ingesting Files with FileDataIngest in Accumulo\nDESCRIPTION: Command to ingest a file into Accumulo using the FileDataIngest class. It specifies instance, zookeepers, credentials, table name, authorizations, chunk size, and the file to ingest.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filedata.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.filedata.FileDataIngest -i instance -z zookeepers -u username -p password -t dataTable --auths exampleVis --chunk 1000 $ACCUMULO_HOME/README\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenTelemetry in Accumulo Properties\nDESCRIPTION: Configuration setting to enable OpenTelemetry in Accumulo's property file. When set to true, this enables distributed tracing throughout the Accumulo cluster.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_10\n\nLANGUAGE: properties\nCODE:\n```\n# OpenTelemetry settings\ngeneral.opentelemetry.enabled=true\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Classpath Context Requirement\nDESCRIPTION: This sequence shows that attempting to add the FooFilter to a table without the correct classpath context fails, and succeeds after configuring the context.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/classpath.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nroot@test16 nofoo> createtable nofootwo\nroot@test16 nofootwo> setiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\n2013-05-03 12:49:35,943 [shell.Shell] ERROR: java.lang.IllegalArgumentException: org.apache.accumulo.test.FooFilter\nroot@test16 nofootwo> config -t nofootwo -s table.classpath.context=cx1\nroot@test16 nofootwo> setiter -n foofilter -p 10 -scan -minc -majc -class org.apache.accumulo.test.FooFilter\nFilter accepts or rejects each Key/Value pair\n----------> set FooFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method: false\n```\n\n----------------------------------------\n\nTITLE: Configuring Hadoop S3 Access in core-site.xml\nDESCRIPTION: XML configuration settings for Hadoop to enable S3 access, including access keys and connection pool settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-10-accumulo-S3-notes.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>fs.s3a.access.key</name>\n  <value>KEY</value>\n</property>\n<property>\n  <name>fs.s3a.secret.key</name>\n  <value>SECRET</value>\n</property>\n<!-- without this setting Accumulo tservers would have problems when trying to open lots of files -->\n<property>\n  <name>fs.s3a.connection.maximum</name>\n  <value>128</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorization in Accumulo Shell\nDESCRIPTION: This command sets the 'exampleVis' authorization for a user in the Accumulo shell. This authorization is required to run the batch writing and scanning example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/batch.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u root -e \"setauths -u username -s exampleVis\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Delete-Triggered Compaction\nDESCRIPTION: Shows how multiple deletes trigger a full compaction based on the configured delete ratio threshold\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/summaries.md#2025-04-11_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nroot@uno summary_test> deletemany -r d5d18dd -f\nroot@uno summary_test> flush -w\nroot@uno summary_test> summaries\n```\n\n----------------------------------------\n\nTITLE: Final Metadata Table State After Compaction in Accumulo\nDESCRIPTION: Shows the final state of the metadata table after the compaction has been committed. The original files have been replaced with the new compacted file, and the tablet metadata has been updated.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_11\n\nLANGUAGE: text\nCODE:\n```\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf []   12354,100000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004j.rf []   1302,1000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004l.rf []   841,1000\n2< last:10000bf4e0a0004 []  localhost:9997\n2< loc:10000bf4e0a0004 []   localhost:9997\n2< srv:compact []   112\n2< srv:dir []   default_tablet\n2< srv:flush [] 114\n2< srv:lock []  tservers/localhost:9997/zlock#1950397a-b2ca-4685-b70b-67ae3cd578b9#0000000000$10000bf4e0a0004\n```\n\n----------------------------------------\n\nTITLE: Setting Up Client-Side Execution Hints\nDESCRIPTION: Configuration for enabling client-side execution hints with custom prioritizers and scan types. This allows clients to influence scan execution through hints.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s tserver.scan.executors.special.threads=8\nconfig -s tserver.scan.executors.special.prioritizer=org.apache.accumulo.core.spi.scan.HintScanPrioritizer\nconfig -s tserver.scan.executors.special.prioritizer.opts.priority.alpha=1\nconfig -s tserver.scan.executors.special.prioritizer.opts.priority.gamma=3\ncreatetable tex\nconfig -t tex -s table.scan.dispatcher=org.apache.accumulo.core.spi.scan.SimpleScanDispatcher\nconfig -t tex -s table.scan.dispatcher.opts.executor.alpha=special\nconfig -t tex -s table.scan.dispatcher.opts.executor.gamma=special\n```\n\n----------------------------------------\n\nTITLE: Indexing Java Files in Accumulo\nDESCRIPTION: Commands to index all Java files from Accumulo source code into the shard table using the Index program.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/shard.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cd /local/user1/workspace/accumulo/\n$ find src -name \"*.java\" | xargs ./bin/accumulo org.apache.accumulo.examples.shard.Index instance zookeepers shard username password 30\n```\n\n----------------------------------------\n\nTITLE: Enabling Table Data Block Cache Using TableOperations in Java\nDESCRIPTION: This code snippet demonstrates how to programmatically enable the data block cache for a specific table using the TableOperations interface. It sets the table.cache.block.enable property to true for a table named 'mytable'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/caching.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().setProperty(\"mytable\", \"table.cache.block.enable\", \"true\");\n```\n\n----------------------------------------\n\nTITLE: Running the Accumulo Shell as Root User\nDESCRIPTION: Command to launch the Accumulo shell and connect as the root user, allowing administrative access to the Accumulo instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/quickstart.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\naccumulo shell -u root\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data with BatchWriter\nDESCRIPTION: Command to insert 1 million random values into the Accumulo table using RandomBatchWriter with specific parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.client.RandomBatchWriter -s 7 instance zookeepers username password bloom_test 1000000 0 1000000000 50 2000000 60000 3 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Regular Expression for Identifying Non-API Imports in Accumulo 2.0+\nDESCRIPTION: This simplified regex pattern matches import statements that are not part of Accumulo's public API for version 2.0 and later. It includes support for the new MapReduce module and reflects the reorganization of non-public packages.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/api.md#2025-04-11_snippet_1\n\nLANGUAGE: regex\nCODE:\n```\nimport\\s+org\\.apache\\.accumulo\\.(?!(core\\.(client|data|iterators|security)|minicluster|hadoop)\\.).*\n```\n\n----------------------------------------\n\nTITLE: Configuring VisibilitySummarizer with Counters Limit\nDESCRIPTION: Configures VisibilitySummarizer with maxCounters option and demonstrates effect on summary statistics through compaction\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/summaries.md#2025-04-11_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nroot@uno summary_test> config -t summary_test -s table.summarizer.vis.opt.maxCounters=3\nroot@uno summary_test> compact -w\nroot@uno summary_test> summaries\n```\n\n----------------------------------------\n\nTITLE: Setting System Configuration via Accumulo Shell\nDESCRIPTION: Demonstrates how to set system-wide configuration properties using the Accumulo shell. These settings are stored in ZooKeeper and override any site configuration set in accumulo.properties.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nconfig -s PROPERTY=VALUE\n```\n\n----------------------------------------\n\nTITLE: Displaying Apache Accumulo 1.6.0 Testing Configuration Table in Markdown\nDESCRIPTION: A markdown table showing various testing configurations for Apache Accumulo 1.6.0, including operating systems, Java versions, Hadoop distributions, and test types performed.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-05-02-accumulo-1.6.0.md#2025-04-11_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n{: #release_notes_testing .table }\n| OS         | Java                       | Hadoop                            | Nodes        | ZooKeeper    | HDFS HA | Version/Commit hash              | Tests                                                              |\n|------------|----------------------------|-----------------------------------|--------------|--------------|---------|----------------------------------|--------------------------------------------------------------------|\n| CentOS 6.5 | CentOS OpenJDK 1.7         | Apache 2.2.0                      | 20 EC2 nodes | Apache 3.4.5 | No      | 1.6.0 RC1 + ACCUMULO\\_2668 patch | 24-hour CI w/o agitation. Verified.                                |\n| CentOS 6.5 | CentOS OpenJDK 1.7         | Apache 2.2.0                      | 20 EC2 nodes | Apache 3.4.5 | No      | 1.6.0 RC2                        | 24-hour RW (Conditional.xml module) w/o agitation                  |\n| CentOS 6.5 | CentOS OpenJDK 1.7         | Apache 2.2.0                      | 20 EC2 nodes | Apache 3.4.5 | No      | 1.6.0 RC5                        | 24-hour CI w/ agitation. Verified.                                 |\n| CentOS 6.5 | CentOS OpenJDK 1.6 and 1.7 | Apache 1.2.1, 2.2.0               | Single       | Apache 3.3.6 | No      | 1.6.0 RC5                        | All unit and ITs w/  `-Dhadoop.profile=2` and `-Dhadoop.profile=1` |\n| Gentoo     | Sun JDK 1.6.0\\_45          | Apache 1.2.1, 2.2.0, 2.3.0, 2.4.0 | Single       | Apache 3.4.5 | No      | 1.6.0 RC5                        | All unit and ITs. 2B entries ingested/verified with CI             |\n| CentOS 6.4 | Sun JDK 1.6.0\\_31          | CDH 4.5.0                         | 7            | CDH 4.5.0    | Yes     | 1.6.0 RC4 and RC5                | 24-hour RW (LongClean) with and without agitation                  |\n| CentOS 6.4 | Sun JDK 1.6.0\\_31          | CDH 4.5.0                         | 7            | CDH 4.5.0    | Yes     | 3a1b38                           | 72-hour CI with and without agitation. Verified.                   |\n| CentOS 6.4 | Sun JDK 1.6.0\\_31          | CDH 4.5.0                         | 7            | CDH 4.5.0    | Yes     | 1.6.0 RC2                        | 24-hour CI without agitation. Verified.                            |\n| CentOS 6.4 | Sun JDK 1.6.0\\_31          | CDH 4.5.0                         | 7            | CDH 4.5.0    | Yes     | 1.6.0 RC3                        | 24-hour CI with agitation. Verified.                               |\n```\n\n----------------------------------------\n\nTITLE: Configuring Hadoop Environment for ADLS Gen2\nDESCRIPTION: Bash environment settings for enabling Azure storage support and OpenSSL implementation in Hadoop.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-10-15-accumulo-adlsgen2-notes.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport HADOOP_OPTIONAL_TOOLS=\"hadoop-azure\"\nexport HADOOP_OPTS=\"-Dorg.wildfly.openssl.path=<path/to/OpenSSL/libraries> ${HADOOP_OPTS}\"\n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Table for Non-Existent Data\nDESCRIPTION: This command performs 500 queries using a different seed, resulting in no matches. The bloom filters significantly speed up these lookups for non-existent data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 8 -i instance -z zookeepers -u username -p password -t bloom_test --num 500 --min 0 --max 1000000000 --size 50 --batchThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Creating Python Environment and Running Client\nDESCRIPTION: These commands create a Python 2.7 environment, install necessary dependencies, copy the example client script, and run it to interact with Accumulo through the proxy.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-12-16-accumulo-proxy.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmkdir accumulo-client/\ncd accumulo-client/\npipenv --python 2.7\npipenv install thrift\npipenv install -e /path/to/accumulo-proxy/src/main/python\ncp /path/to/accumulo-proxy/src/main/python/basic_client.py .\n# Edit credentials if needed\nvim basic_client.py\npipenv run python2 basic_client.py\n```\n\n----------------------------------------\n\nTITLE: Indexing Java Files into Accumulo Shard Table\nDESCRIPTION: Command to find Java source files and index them into the shard table using the Index program with 30 partitions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/shard.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cd /local/username/workspace/accumulo/\n$ find core/src server/src -name \"*.java\" | xargs ./bin/accumulo org.apache.accumulo.examples.simple.shard.Index -i instance -z zookeepers -t shard -u username -p password --partitions 30\n```\n\n----------------------------------------\n\nTITLE: Creating and Populating Accumulo Table with Sample Data\nDESCRIPTION: Creates a new table 'summary_test', sets authorizations, and inserts sample data with various column visibilities and labels\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/summaries.md#2025-04-11_snippet_0\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> createtable summary_test\nroot@uno summary_test> setauths -u root -s PI,GEO,TIME\nroot@uno summary_test> insert 3b503bd name last Doe\nroot@uno summary_test> insert 3b503bd name first John\nroot@uno summary_test> insert 3b503bd contact address \"123 Park Ave, NY, NY\" -l PI&GEO\nroot@uno summary_test> insert 3b503bd date birth \"1/11/1942\" -l PI&TIME\nroot@uno summary_test> insert 3b503bd date married \"5/11/1962\" -l PI&TIME\nroot@uno summary_test> insert 3b503bd contact home_phone 1-123-456-7890 -l PI\nroot@uno summary_test> insert d5d18dd contact address \"50 Lake Shore Dr, Chicago, IL\" -l PI&GEO\nroot@uno summary_test> insert d5d18dd name first Jane\nroot@uno summary_test> insert d5d18dd name last Doe\nroot@uno summary_test> insert d5d18dd date birth 8/15/1969 -l PI&TIME\nroot@uno summary_test> scan -s PI,GEO,TIME\n```\n\n----------------------------------------\n\nTITLE: Bulk Importing Files into Accumulo\nDESCRIPTION: Demonstrates the shell command to import externally generated files (such as from MapReduce) into an existing Accumulo table. This method specifies the directory containing files to import and a directory for any files that fail to import.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/high_speed_ingest.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuser@myinstance mytable> importdirectory /files_dir /failures\n```\n\n----------------------------------------\n\nTITLE: Run WordCount with Token File Authentication\nDESCRIPTION: Examples of running WordCount MapReduce jobs using token file authentication instead of direct password input.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/mapred.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -tf tokenfile\n\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TokenFileWordCount instance zookeepers username tokenfile /user/username/wc wordCount\n```\n\n----------------------------------------\n\nTITLE: Enabling Replication on the Table\nDESCRIPTION: Command to enable replication for the specified table in the primary instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_12\n\nLANGUAGE: console\nCODE:\n```\nroot@primary> config -t my_table -s table.replication=true\n```\n\n----------------------------------------\n\nTITLE: Running the ReadWriteExample with Accumulo client\nDESCRIPTION: This command executes the ReadWriteExample class to create a table, write data to it, and read from it. It specifies flags for creating the table, writing data, and reading data back, along with authentication parameters for Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/client.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo $PACKAGE.ReadWriteExample -u root -p mypassword -i instance -z zookeeper --createtable --create --read\n```\n\n----------------------------------------\n\nTITLE: Setting Scan Dispatcher Options\nDESCRIPTION: Property pattern for configuring options for the scan dispatcher. These options control how the dispatcher behaves.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_3\n\nLANGUAGE: text\nCODE:\n```\ntable.scan.dispatcher.opts.<key>=<value>\n```\n\n----------------------------------------\n\nTITLE: Managing Locality Groups via the Shell in Accumulo\nDESCRIPTION: Shows how to use the shell to set and retrieve locality groups in Accumulo tables. Locality groups allow efficient scanning over frequently used column families by storing them separately on disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nusage: setgroups <group>=<col fam>{,<col fam>}{ <group>=<col fam>{,<col\nfam>}} [-?] -t <table>\n\nuser@myinstance mytable> setgroups -t mytable group_one=colf1,colf2\n\nuser@myinstance mytable> getgroups -t mytable\ngroup_one=colf1,colf2\n```\n\n----------------------------------------\n\nTITLE: Running the ReadWriteExample with Accumulo client\nDESCRIPTION: This command executes the ReadWriteExample class to create a table, write data to it, and read from it. It specifies flags for creating the table, writing data, and reading data back, along with authentication parameters for Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/client.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo $PACKAGE.ReadWriteExample -u root -p mypassword -i instance -z zookeeper --createtable --create --read\n```\n\n----------------------------------------\n\nTITLE: Cloning Accumulo Proxy Repository\nDESCRIPTION: Command to clone the Accumulo Proxy repository from GitHub. This is the first step in setting up the proxy server.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/proxy.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/apache/accumulo-proxy\n```\n\n----------------------------------------\n\nTITLE: Importing Bulk Data in Accumulo Shell\nDESCRIPTION: Command to import bulk data files into Accumulo from HDFS, with a separate directory specified for failed imports.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> importdirectory /files_dir /failures\n```\n\n----------------------------------------\n\nTITLE: Starting and Enabling Hadoop DataNode Service\nDESCRIPTION: These commands start the Hadoop DataNode service and enable it to run on system boot for multi-node setups.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start hadoop-datanode.service\nsudo systemctl enable hadoop-datanode.service\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Properties for Azure Storage\nDESCRIPTION: Initial and final Accumulo properties configuration for integrating with Azure Data Lake Storage Gen2.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-10-15-accumulo-adlsgen2-notes.md#2025-04-11_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\ninstance.volumes=hdfs://<namenode>/accumulo,abfss://<file_system>@<storage_account_name>.dfs.core.windows.net/accumulo\ngeneral.volume.chooser=org.apache.accumulo.server.fs.PreferredVolumeChooser\ngeneral.custom.volume.preferred.default=abfss://<file_system>@<storage_account_name>.dfs.core.windows.net/accumulo\ngeneral.custom.volume.preferred.logger=hdfs://<namenode>/accumulo\n```\n\n----------------------------------------\n\nTITLE: Creating an Accumulo Token File for Authentication\nDESCRIPTION: Commands to create a token file for secure authentication with Accumulo, which helps avoid storing passwords directly in MapReduce job configurations. Shows both interactive and one-line methods.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo create-token\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo create-token -u root -p secret -f root.pw\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Server SSL Settings\nDESCRIPTION: XML configuration for setting up SSL encryption on Accumulo servers, including keystore and truststore paths and passwords.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-09-02-generating-keystores-for-configuring-accumulo-with-ssl.md#2025-04-11_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>rpc.javax.net.ssl.keyStore</name>\n  <value>/path/to/server.jks</value>\n</property>\n<property>\n  <name>rpc.javax.net.ssl.keyStorePassword</name>\n  <value>server_password</value>\n</property>\n<property>\n  <name>rpc.javax.net.ssl.trustStore</name>\n  <value>/path/to/truststore.jks</value>\n</property>\n<property>\n  <name>rpc.javax.net.ssl.trustStorePassword</name>\n  <value>truststore_password</value>\n</property>\n<property>\n  <name>instance.rpc.ssl.enabled</name>\n  <value>true</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Deleting Accumulo Instances from ZooKeeper\nDESCRIPTION: The DeleteZooInstance utility removes instances from ZooKeeper by name or ID. Provides options for deleting specific instances or cleaning up old instances.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin deleteZooInstance -i instance1\nDeleted instance: instance1\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Client Connection\nDESCRIPTION: Code to create an Accumulo client connection to the MiniAccumuloCluster instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/development_tools.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nAccumuloClient client = mac.getAccumuloClient(\"root\", new PasswordToken(\"password\"));\n```\n\n----------------------------------------\n\nTITLE: Sample ZooKeeper Paths for FATE Transactions in Accumulo\nDESCRIPTION: Example ZooKeeper paths showing the structure of a FATE transaction with a specific transaction ID, debug node, and multiple REPO stack entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/fate.md#2025-04-11_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n/accumulo/dcbf6855-8eac-4b44-a4a9-7ad39caafe9a/fate/tx_4dd46d49d60f1a17\n/accumulo/dcbf6855-8eac-4b44-a4a9-7ad39caafe9a/fate/tx_4dd46d49d60f1a17/debug\n/accumulo/dcbf6855-8eac-4b44-a4a9-7ad39caafe9a/fate/tx_4dd46d49d60f1a17/repo_0000000002\n/accumulo/dcbf6855-8eac-4b44-a4a9-7ad39caafe9a/fate/tx_4dd46d49d60f1a17/repo_0000000000\n```\n\n----------------------------------------\n\nTITLE: Setting Namespace Configuration via Accumulo Shell\nDESCRIPTION: Shows how to set configuration properties for a specific table namespace using the Accumulo shell. Namespace configuration overrides system configuration and applies to all tables in the namespace.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_4\n\nLANGUAGE: console\nCODE:\n```\nconfig -ns NAMESPACE -s PROPERTY=VALUE\n```\n\n----------------------------------------\n\nTITLE: Scanning a Table with Proper Authorizations in Apache Accumulo\nDESCRIPTION: Creates a client for the 'commissioner' user who has the 'secretId' authorization and scans the 'GothamPD' table. This demonstrates that users with proper authorizations can see protected columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_8\n\nLANGUAGE: java\nCODE:\n```\ntry (AccumuloClient commishClient = Accumulo.newClient().from(client.properties()).as(\"commissioner\", \"gordonrocks\").build()) {\n  try (ScannerBase scan = commishClient.createScanner(\"GothamPD\", auths)) {\n    System.out.println(\"Gotham Police Department Persons of Interest:\");\n    for (Map.Entry<Key, Value> entry : scan) {\n      System.out.printf(\"Key : %-50s  Value : %s\\n\", entry.getKey(), entry.getValue());\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Kerberos Authentication for Replication\nDESCRIPTION: Commands to configure Kerberos authentication for replication using keytab files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_3\n\nLANGUAGE: console\nCODE:\n```\naccumulo@EXAMPLE.COM@accumulo_primary> config -s replication.peer.user.peer1=replication@EXAMPLE.COM\naccumulo@EXAMPLE.COM@accumulo_primary> config -s replication.peer.keytab.peer1=/path/to/replication.keytab\n```\n\n----------------------------------------\n\nTITLE: Replacing NameNode URIs in Accumulo Metadata\nDESCRIPTION: Configures the instance.volumes.replacements property to update stored URIs in Accumulo's metadata when NameNode locations change. This allows Accumulo to function after NameNode relocations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/multivolume.md#2025-04-11_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\ninstance.volumes.replacements=hdfs://ns1:9001 hdfs://nsA:9001, hdfs://ns2:9001 hdfs://nsB:9001\n```\n\n----------------------------------------\n\nTITLE: Table Maintenance Commands in Accumulo\nDESCRIPTION: Demonstrates the use of 'compact' and 'flush' commands for table maintenance in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Accumulo_Shell.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nroot@myinstance mytable> compact -t mytable\n07 16:13:53,201 [shell.Shell] INFO : Compaction of table mytable\nscheduled for 20100707161353EDT\n\nroot@myinstance mytable> flush -t mytable\n07 16:14:19,351 [shell.Shell] INFO : Flush of table mytable\ninitiated...\n```\n\n----------------------------------------\n\nTITLE: Running ReadWriteExample with table creation and read operations\nDESCRIPTION: This command executes the ReadWriteExample class which demonstrates creating a table, writing data to it, and reading from it. The flags --createtable, --create, and --read specify the operations to perform.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/client.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo $PACKAGE.ReadWriteExample -u root -p mypassword -i instance -z zookeeper --createtable --create --read\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Sampler in Accumulo\nDESCRIPTION: Sets up a sampler for an Accumulo table to enable storing and scanning a sample of data. This is useful for query optimization and data comprehension. A compaction is required to compute the sample for existing data after enabling.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\ntable.sampler = org.apache.accumulo.core.Sampler\n```\n\n----------------------------------------\n\nTITLE: Setting Erasure Coding Policy for HDFS Directory\nDESCRIPTION: This sequence of commands creates a directory and sets an Erasure Coding policy for it using the hdfs ec command.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -mkdir foo\n$ hdfs ec -setPolicy -policy RS-6-3-64k -path foo\n```\n\n----------------------------------------\n\nTITLE: Extracting Columns using TableToFile MapReduce Job\nDESCRIPTION: Command to run the TableToFile MapReduce tool that extracts rows containing the column 'cf:cq' from the 'input' table and writes them to HDFS at /tmp/output.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/tabletofile.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TableToFile -u user -p passwd -i instance -t input --columns cf:cq --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Read Latency Comparison Table - Degraded Mode\nDESCRIPTION: Markdown table showing read latency metrics (min/avg/max in milliseconds) with 2 DataNodes disabled to simulate failure conditions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-17-erasure-coding.md#2025-04-11_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n|Encoding|Min|Avg|Max|\n|--------|--:|--:|--:|\n|RS 10-4 1MB|53|143|3221|\n|RS 6-3 1MB|34|113|1662|\n|RS 6-3 64KB|24|61|1402|\n|Replication|12|26|304|\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Table with Bloom Filters\nDESCRIPTION: This set of commands inserts 3 million entries into 'bloom_test2' using RandomBatchWriter with different seeds, flushing after each million entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test2 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n```\n\n----------------------------------------\n\nTITLE: Java 11 Shenandoah GC Configuration\nDESCRIPTION: Shenandoah GC configuration with 2GB max heap\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\n-Xmx2G -Xms256m -XX:+UseShenandoahGC\n```\n\n----------------------------------------\n\nTITLE: Creating a new user in Accumulo Shell\nDESCRIPTION: Shows how to create a new user in Accumulo and the error that occurs when a new user tries to create a table without proper permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/visibility.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance> createuser username\nEnter new password for 'username': ********\nPlease confirm new password for 'username': ********\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\n06 10:48:47,931 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance> userpermissions\nSystem permissions:\n\nTable permissions (accumulo.metadata): Table.READ\nusername@instance>\n```\n\n----------------------------------------\n\nTITLE: Setting Table Configuration via Accumulo Shell\nDESCRIPTION: Demonstrates how to set configuration properties for a specific table using the Accumulo shell. Table configuration has the highest precedence and overrides all other configuration levels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nconfig -t TABLE -s PROPERTY=VALUE\n```\n\n----------------------------------------\n\nTITLE: Setting Table Configuration via Accumulo Shell\nDESCRIPTION: Demonstrates how to set configuration properties for a specific table using the Accumulo shell. Table configuration has the highest precedence and overrides all other configuration levels.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nconfig -t TABLE -s PROPERTY=VALUE\n```\n\n----------------------------------------\n\nTITLE: Configuring Erasure Coding for New Accumulo Instance\nDESCRIPTION: This set of commands configures Erasure Coding for a new Accumulo instance, setting policies for the tables directory and specific system tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs ec -setPolicy -policy RS-6-3-64k -path /accumulo/tables\n$ hdfs ec -setPolicy -replicate -path /accumulo/tables/\\!0\n$ hdfs ec -setPolicy -replicate -path /accumulo/tables/+r\n$ hdfs ec -setPolicy -replicate -path /accumulo/tables/+rep\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with Bloom Filters\nDESCRIPTION: This snippet shows how to create a table named 'bloom_test' in Accumulo and enable bloom filters using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test\nusername@instance bloom_test> config -t bloom_test -s table.bloom.enabled=true\nusername@instance bloom_test> exit\n```\n\n----------------------------------------\n\nTITLE: Configuring Replication Peer in Accumulo Shell\nDESCRIPTION: Shell command to configure a peer replication system with instance name and ZooKeeper quorum information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nroot@accumulo_primary> config -s replication.peer.peer1=org.apache.accumulo.tserver.replication.AccumuloReplicaSystem,accumulo_peer,10.0.0.1,10.0.2.1,10.0.0.3.1\n```\n\n----------------------------------------\n\nTITLE: Configuring SSL for Accumulo Monitor in YAML\nDESCRIPTION: YAML configuration for enabling SSL on the Accumulo Monitor. It specifies the properties for keystore and truststore files and their passwords.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/monitoring-metrics.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nmonitor.ssl.keyStore: \nmonitor.ssl.keyStorePassword: \nmonitor.ssl.trustStore: \nmonitor.ssl.trustStorePassword: \n```\n\n----------------------------------------\n\nTITLE: User Administration in Accumulo Shell\nDESCRIPTION: Illustrates user administration tasks such as creating users, authenticating, granting permissions, and revoking permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Accumulo_Shell.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nroot@myinstance mytable> createuser bob\nEnter new password for 'bob': *********\nPlease confirm new password for 'bob': *********\n\nroot@myinstance mytable> authenticate bob\nEnter current password for 'bob': *********\nValid\n\nroot@myinstance mytable> grant System.CREATE_TABLE -s -u bob\n\nroot@myinstance mytable> user bob\nEnter current password for 'bob': *********\n\nbob@myinstance mytable> userpermissions\nSystem permissions: System.CREATE_TABLE\nTable permissions (!METADATA): Table.READ\nTable permissions (mytable): NONE\n\nbob@myinstance mytable> createtable bobstable\nbob@myinstance bobstable>\n\nbob@myinstance bobstable> user root\nEnter current password for 'root': *********\n\nroot@myinstance bobstable> revoke System.CREATE_TABLE -s -u bob\n```\n\n----------------------------------------\n\nTITLE: Running Batch Writer Program\nDESCRIPTION: Command to execute the Java InsertWithBatchWriter program that inserts 50K entries into the 'hellotable'. The program requires connection parameters including instance, zookeepers, credentials, and target table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithBatchWriter -i instance -z zookeepers -u username -p password -t hellotable\n```\n\n----------------------------------------\n\nTITLE: Modifying Multiple Namespace Properties via Java API\nDESCRIPTION: Shows how to add, modify, and remove multiple namespace properties in a single operation using the Java API. This batch operation is more efficient for making multiple property changes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nclient.namespaceOperations().modifyProperties(\"mynamespace\", properties -> {\n        properties.remove(\"table.file.max\");\n        properties.put(\"table.bloom.enabled\", \"true\");\n        properties.put(\"table.bloom.error.rate\", \"0.75\");\n        properties.put(\"table.bloom.size\", \"128000\");\n        });\n```\n\n----------------------------------------\n\nTITLE: Modifying Multiple Namespace Properties via Java API\nDESCRIPTION: Shows how to add, modify, and remove multiple namespace properties in a single operation using the Java API. This batch operation is more efficient for making multiple property changes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/overview.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nclient.namespaceOperations().modifyProperties(\"mynamespace\", properties -> {\n        properties.remove(\"table.file.max\");\n        properties.put(\"table.bloom.enabled\", \"true\");\n        properties.put(\"table.bloom.error.rate\", \"0.75\");\n        properties.put(\"table.bloom.size\", \"128000\");\n        });\n```\n\n----------------------------------------\n\nTITLE: JShell Command Examples for Accumulo\nDESCRIPTION: Example demonstrating common JShell operations including variable declaration, method definition, method execution, and using /list commands to review and re-run previously entered code snippets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/getting-started.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\njshell> var x = 12;\nx ==> 12\n\njshell> var y = 23;\ny ==> 23\n\njshell> int add(int x, int y) {\n   ...>   return x + y;\n   ...> }\n|  created method add(int,int)\n\njshell> add(4,5);\n$6 ==> 9\n\njshell> /list\n\n   1 : System.out.println(\"Preparing JShell for Apache Accumulo\");\n   2 : var x = 12;\n   3 : var y = 23;\n   4 : int add(int x, int y) {\n         return x + y;\n       }\n\n jshell> /list add\n\n   5 : int add(int x, int y) {\n         return x + y;\n       }\n\njshell> /list 4\n\n   4 : int add(int x, int y) {\n         return x + y;\n       }\n\njshell> /4\nadd(4,5);\n$8 ==> 9\n```\n\n----------------------------------------\n\nTITLE: Accessing Accumulo Status Page\nDESCRIPTION: URL to access the Accumulo status page to verify the 50K entries, where 'master' should be replaced with the name or IP of the Accumulo master.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nhttp://master:50095/\n```\n\n----------------------------------------\n\nTITLE: Memory Usage Monitoring Shell Script\nDESCRIPTION: Bash script that monitors the Resident Set Size (RSS) of a specified process ID, collecting memory usage data every 5 seconds for up to an hour. Data is written to output_mem_usage.log for subsequent analysis.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash \nPID=$1 \necho \"Tracking PID: $PID\" \nDURATION=3600 # for 1 hour \nINTERVAL=5    # every 5 seconds \nrm output_mem_usage.log \n\nwhile [ $DURATION -gt 0 ]; do \n    ps -o %mem,rss -p $PID | tail -n +2 >> output_mem_usage.log \n    sleep $INTERVAL \n    DURATION=$((DURATION - INTERVAL)) \ndone\n```\n\n----------------------------------------\n\nTITLE: Retrieving Split Points from Accumulo Table\nDESCRIPTION: Shows how to retrieve the existing split points from an Accumulo table using the shell. These split points can be used by MapReduce RangePartitioner when preparing data for bulk loading.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/high_speed_ingest.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuser@myinstance mytable> getsplits\naa\nab\nac\n...\nzx\nzy\nzz\n```\n\n----------------------------------------\n\nTITLE: Java 21 ZGC with Generational Collection\nDESCRIPTION: ZGC configuration with generational collection enabled and uncommit delay\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\n-Xmx2G -Xms256m -XX:+UseZGC -XX:+ZGenerational -XX:ZUncommitDelay=120\n```\n\n----------------------------------------\n\nTITLE: Inserting Data in Multiple Batches to Create Separate Map Files (With Bloom)\nDESCRIPTION: This snippet shows inserting data in three separate batches with different seeds and flushing between each batch to create multiple map files in a table with bloom filters enabled.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test2 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n```\n\n----------------------------------------\n\nTITLE: Stopping Accumulo 1.9 and Starting 2.0\nDESCRIPTION: Commands to stop Accumulo 1.9.3 and start Accumulo 2.0.1 during version upgrade.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/upgrading.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n./accumulo-1.9.3/bin/stop-all.sh\n./accumulo-2.0.1/bin/accumulo-cluster start\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Split Points in Accumulo Shell\nDESCRIPTION: Command to get the split points of an Accumulo table, useful for configuring MapReduce range partitioner for bulk ingest.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> getsplits\naa\nab\nac\n...\nzx\nzy\nzz\n```\n\n----------------------------------------\n\nTITLE: Documenting Accumulo Shell Command: exit\nDESCRIPTION: The 'exit' command is used to exit the Accumulo shell. It has a single option for displaying help information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_26\n\nLANGUAGE: text\nCODE:\n```\nusage: exit [-?]\ndescription: exits the shell\n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Retrieving Table Split Points in Accumulo Shell\nDESCRIPTION: Command to get the split points of an Accumulo table, useful for configuring MapReduce range partitioner for bulk ingest.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> getsplits\naa\nab\nac\n...\nzx\nzy\nzz\n```\n\n----------------------------------------\n\nTITLE: Creating a Mutation with Security Labels in Accumulo\nDESCRIPTION: This snippet demonstrates how to apply security labels to values in Accumulo by creating a Mutation with a ColumnVisibility object. The example shows setting a 'public' visibility for a specific row, column family, and qualifier.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Security.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nText rowID = new Text(\"row1\");\nText colFam = new Text(\"myColFam\");\nText colQual = new Text(\"myColQual\");\nColumnVisibility colVis = new ColumnVisibility(\"public\");\nlong timestamp = System.currentTimeMillis();\n\nValue value = new Value(\"myValue\");\n\nMutation mutation = new Mutation(rowID);\nmutation.put(colFam, colQual, colVis, timestamp, value);\n```\n\n----------------------------------------\n\nTITLE: Revoking Permissions via Shell\nDESCRIPTION: Demonstrates how to revoke system-level permissions from a user using the Accumulo shell. This example revokes the CREATE_TABLE permission from user 'bob'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/permissions.md#2025-04-11_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> revoke System.CREATE_TABLE -s -u bob\n```\n\n----------------------------------------\n\nTITLE: Starting New Tablet Server\nDESCRIPTION: Command to start a new tablet server process on a host after adding it to the cluster configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-service tserver start\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenTelemetry JavaAgent in accumulo-env.sh\nDESCRIPTION: Configuration snippet for accumulo-env.sh that sets up the OpenTelemetry SDK AutoConfigure options and Java Agent. The configuration includes settings for traces, metrics, and logs exporters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n## Optionally setup OpenTelemetry SDK AutoConfigure\n## See https://github.com/open-telemetry/opentelemetry-java/tree/main/sdk-extensions/autoconfigure\n#JAVA_OPTS=('-Dotel.traces.exporter=jaeger' '-Dotel.metrics.exporter=none' '-Dotel.logs.exporter=none' \"${JAVA_OPTS[@]}\")\n## Optionally setup OpenTelemetry Java Agent\n## See https://github.com/open-telemetry/opentelemetry-java-instrumentation for more options\n#JAVA_OPTS=('-javaagent:path/to/opentelemetry-javaagent.jar' \"${JAVA_OPTS[@]}\")\n```\n\n----------------------------------------\n\nTITLE: Reading Data with Java\nDESCRIPTION: Command to execute the Java program that reads data from 'hellotable' between specified start and end keys.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.ReadData -i instance -z zookeepers -u username -p password -t hellotable --startKey row_0 --endKey row_1001\n```\n\n----------------------------------------\n\nTITLE: Using Execution Hints in Accumulo Scan Commands\nDESCRIPTION: Example scan commands that use execution hints to specify scan type, which influences both the executor selection and scan priority.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nscan -t tex --execution-hints scan_type=gamma\n```\n\n----------------------------------------\n\nTITLE: Querying Table with Bloom Filters\nDESCRIPTION: This command performs 500 lookups against the 'bloom_test2' table (with bloom filters) using RandomBatchScanner with seed 7, demonstrating faster lookups.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test2 --num 500 --min 0 --max 1000000000 --size 50 -scanThreads 20 --auths exampleVis\nGenerating 500 random queries...finished\n99.03 lookups/sec   5.05 secs\nnum results : 500\nGenerating 500 random queries...finished\n101.15 lookups/sec   4.94 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Enabling Tracing in Accumulo Configuration\nDESCRIPTION: To enable tracing in Accumulo, you need to set the general.opentelemetry.enabled property to true in the Accumulo configuration and ensure the GlobalOpenTelemetry.globalOpenTelemetry member variable is properly initialized.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tracing.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nio.opentelemetry.api.GlobalOpenTelemetry.globalOpenTelemetry\n```\n\n----------------------------------------\n\nTITLE: Querying Table with Bloom Filters\nDESCRIPTION: This command performs 500 lookups against the 'bloom_test2' table (with bloom filters) using RandomBatchScanner with seed 7, demonstrating faster lookups.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test2 --num 500 --min 0 --max 1000000000 --size 50 -scanThreads 20 --auths exampleVis\nGenerating 500 random queries...finished\n99.03 lookups/sec   5.05 secs\nnum results : 500\nGenerating 500 random queries...finished\n101.15 lookups/sec   4.94 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: GnuPlot Memory Usage Visualization Commands\nDESCRIPTION: GnuPlot commands to create a line graph visualization of the memory usage data collected by the monitoring script, showing RSS memory usage over time.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2024-04-09-does-a-compactor-return-memory-to-OS.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngnuplot\nset title \"Resident Set Size (RSS) Memory usage\" \nset xlabel \"Time\"\nset ylabel \"Mem usage in kilobytes\"\nplot \"output_mem_usage.log\" using ($0*5):2 with lines title 'Mem usage'\n```\n\n----------------------------------------\n\nTITLE: Adding Split Points to Tables in Accumulo\nDESCRIPTION: The addsplits command allows adding split points to an existing table, improving data distribution across the cluster. It supports providing splits directly or via a file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusage: addsplits [<split> <split> ] [-?] [-b64] [-sf <filename>] [-t <tableName>]   \ndescription: add split points to an existing table   \n  -?,-help  display this help   \n  -b64,-base64encoded  decode encoded split points   \n  -sf,-splits-file <filename>  file with newline separated list of rows to add to   \n          table   \n  -t,-table <tableName>  name of a table to add split points to\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo Database\nDESCRIPTION: Command to initialize a new Accumulo instance. This prompts for an instance name and sets the password for the Accumulo root user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-27-getting-started-with-accumulo-1.6.0.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naccumulo init\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Scan Dispatcher\nDESCRIPTION: Property to configure which scan dispatcher class a table should use. The dispatcher determines which executor will service scans for the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_2\n\nLANGUAGE: text\nCODE:\n```\ntable.scan.dispatcher=<class name>\n```\n\n----------------------------------------\n\nTITLE: Enabling OpenTelemetry Tracing in Accumulo\nDESCRIPTION: Property to add to accumulo.properties file to enable OpenTelemetry tracing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_9\n\nLANGUAGE: properties\nCODE:\n```\n# OpenTelemetry settings\ngeneral.opentelemetry.enabled=true\n```\n\n----------------------------------------\n\nTITLE: Removing Users in Accumulo Shell\nDESCRIPTION: Command to remove user 'bob' in the Accumulo shell. Prompts for confirmation before deletion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nroot@uno> dropuser bob\ndropuser { bob } (yes|no)? yes\n```\n\n----------------------------------------\n\nTITLE: Metadata Table Updates for External Compaction in Accumulo\nDESCRIPTION: Shows the metadata table with the newly added external compaction entry (ecomp) containing job details including input files, temporary file, destination file, compactor address, and other job parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n2< ecomp:ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c []   {\"inputs\":[\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf\",\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf\"],\"tmp\":\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf_tmp\",\"dest\":\"hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf\",\"compactor\":\"localhost:9101\",\"kind\":\"USER\",\"executorId\":\"DCQ1\",\"priority\":288230376151711747}\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf []   12330,99000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf []   1196,1000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004j.rf []   1302,1000\n2< last:10000bf4e0a0004 []  localhost:9997\n2< loc:10000bf4e0a0004 []   localhost:9997\n2< srv:compact []   111\n2< srv:dir []   default_tablet\n2< srv:flush [] 113\n2< srv:lock []  tservers/localhost:9997/zlock#1950397a-b2ca-4685-b70b-67ae3cd578b9#0000000000$10000bf4e0a0004\n2< srv:time []  M1618325648093\n2< ~tab:~pr []  \\x00\n```\n\n----------------------------------------\n\nTITLE: Verifying OpenTelemetry Initialization in Accumulo Logs\nDESCRIPTION: Sample log output that confirms successful initialization of OpenTelemetry tracing in Accumulo. This indicates that the tracing system is properly configured and operational.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_13\n\nLANGUAGE: log\nCODE:\n```\n[trace.TraceUtil] INFO : Trace enabled in Accumulo: yes, OpenTelemetry instance: class io.opentelemetry.javaagent.instrumentation.opentelemetryapi.v1_10.ApplicationOpenTelemetry110, Tracer instance: class io.opentelemetry.javaagent.instrumentation.opentelemetryapi.trace.ApplicationTracer\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple NameNodes in Accumulo Properties\nDESCRIPTION: Sets the instance.volumes property to use multiple HDFS NameNodes, improving write performance for large Accumulo installations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/multivolume.md#2025-04-11_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\ninstance.volumes=hdfs://ns1:9001,hdfs://ns2:9001\n```\n\n----------------------------------------\n\nTITLE: Configuring WAL Durability Settings in Accumulo Shell\nDESCRIPTION: Shell commands demonstrating how to check and configure table durability settings, including checking defaults and overrides for different tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-10-28-durability-performance.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@uno> config -s table.durability=flush\nroot@uno foo> config -t foo -f table.durability\n-----------+---------------------+----------------------------------------------\nSCOPE      | NAME                | VALUE\n-----------+---------------------+----------------------------------------------\ndefault    | table.durability .. | sync\nsystem     |    @override ...... | flush\n-----------+---------------------+----------------------------------------------\nroot@uno> config -t accumulo.metadata -f table.durability\n-----------+---------------------+----------------------------------------------\nSCOPE      | NAME                | VALUE\n-----------+---------------------+----------------------------------------------\ndefault    | table.durability .. | sync\nsystem     |    @override ...... | flush\ntable      |    @override ...... | sync\n-----------+---------------------+----------------------------------------------\nroot@uno> config -t accumulo.metadata -d table.durability\nroot@uno> config -t accumulo.metadata -f table.durability\n-----------+---------------------+----------------------------------------------\nSCOPE      | NAME                | VALUE\n-----------+---------------------+----------------------------------------------\ndefault    | table.durability .. | sync\nsystem     |    @override ...... | flush\n-----------+---------------------+----------------------------------------------\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table without Bloom Filters\nDESCRIPTION: This snippet demonstrates creating a table 'bloom_test1' without bloom filters and setting the major compaction ratio.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test1\nusername@instance bloom_test1> config -t bloom_test1 -s table.compaction.major.ratio=7\nusername@instance bloom_test1> exit\n```\n\n----------------------------------------\n\nTITLE: Fetching Accumulo Dependencies with Uno\nDESCRIPTION: Command to download Accumulo, Hadoop, and Zookeeper tarballs using Uno's fetch functionality\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./bin/uno fetch accumulo\n```\n\n----------------------------------------\n\nTITLE: Copying FooFilter.jar to HDFS\nDESCRIPTION: This command copies the FooFilter.jar from the local Accumulo test resources to HDFS for use in the classpath context.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/classpath.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/test/src/test/resources/FooFilter.jar /user1/lib\n```\n\n----------------------------------------\n\nTITLE: Configuring Compaction Service in Accumulo Shell\nDESCRIPTION: Accumulo shell commands to set up a new compaction service with internal and external executors for different compaction sizes. This configuration defines a tiered approach based on compaction size.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nconfig -s 'tserver.compaction.major.service.cs1.planner.opts.executors=[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"32M\",\"numThreads\":4},{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":2},{\"name\":\"large\",\"type\":\"external\",\"queue\":\"DCQ1\"}]'\nconfig -s tserver.compaction.major.service.cs1.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\n```\n\n----------------------------------------\n\nTITLE: Starting Multiple TabletServers\nDESCRIPTION: Commands to start multiple tablet server instances on a single node using instance numbering.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nACCUMULO_SERVICE_INSTANCE=1 ./bin/accumulo tserver &> ./logs/tserver1.out &\nACCUMULO_SERVICE_INSTANCE=2 ./bin/accumulo tserver &> ./logs/tserver2.out &\n```\n\n----------------------------------------\n\nTITLE: Stopping Tablet Server\nDESCRIPTION: Command to stop a tablet server process on a specific host.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-service tserver stop\n```\n\n----------------------------------------\n\nTITLE: Kerberos Credential Error Example in Java\nDESCRIPTION: Example stack trace showing failed Kerberos authentication due to missing or invalid TGT credentials\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_11\n\nLANGUAGE: java\nCODE:\n```\njava.io.IOException: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Compactor Process with Queue Specification\nDESCRIPTION: Command to start an Accumulo Compactor process with a specific queue name. Compactors run external compactions and communicate with the Compaction Coordinator.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\naccumulo compactor -q <queueName>\n```\n\n----------------------------------------\n\nTITLE: Creating Directories for Docker Container\nDESCRIPTION: Commands to create and set permissions for directories used by the TIG Docker container.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p /tmp/metrics/influxdb\nchmod 777 /tmp/metrics/influxdb\nmkdir /tmp/metrics/grafana\nmkdir /tmp/metrics/grafana-dashboards\nmkdir -p /tmp/metrics/telegraf/conf\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Tables for Shard Example\nDESCRIPTION: Commands to create the required 'shard' and 'doc2term' tables in Accumulo for the document sharding example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/shard.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance> createtable shard\nusername@instance shard> createtable doc2term\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Erasure Coding Policy in XML\nDESCRIPTION: This XML snippet defines a custom Erasure Coding policy (RS-6-3-64k) in the user_ec_policies.xml file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_6\n\nLANGUAGE: xml\nCODE:\n```\n<configuration>\n<layoutversion>1</layoutversion>\n<schemas>\n  <!-- schema id is only used to reference internally in this document -->\n  <schema id=\"RSk6m3\">\n    <codec>rs</codec>\n    <k>6</k>\n    <m>3</m>\n    <options> </options>\n  </schema>\n</schemas>\n<policies>\n  <policy>\n    <schema>RSk6m3</schema>\n    <cellsize>65536</cellsize>\n  </policy>\n</policies>\n</configuration>\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo on Unix-like Systems\nDESCRIPTION: Command to extract the Accumulo tarball into the installation directory. This step should be repeated on each machine in the cluster.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Administration.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ tar xzf $ACCUMULO_HOME/accumulo.tar.gz\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter for Accumulo Documentation Redirect\nDESCRIPTION: YAML front matter block that defines a page title and a redirect URL to the Apache Accumulo quickstart documentation. This is used in static site generators to handle page redirects.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/index.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Apache Accumulo Documentation\nredirect_to: /docs/2.x/getting-started/quickstart\n---\n```\n\n----------------------------------------\n\nTITLE: Configuring Muchos AWS Properties\nDESCRIPTION: Commands to create and configure Muchos properties file for AWS environment setup\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncp conf/muchos.props.example conf/muchos.props\nvim conf/muchos.props\n```\n\n----------------------------------------\n\nTITLE: Authenticating Users with Java API\nDESCRIPTION: Java code to verify user credentials using the SecurityOperations interface. Returns a boolean indicating whether authentication was successful.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nboolean valid = client.securityOperations().authenticateUser(\"bob\", new PasswordToken(\"pass\"));\n```\n\n----------------------------------------\n\nTITLE: Using listtablets Shell Command in Accumulo\nDESCRIPTION: Example usage of the new listtablets shell command in Accumulo 2.1, which displays detailed tablet information for debugging purposes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2022-11-01-accumulo-2.1.0.md#2025-04-11_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nroot@uno> listtablets -t test_ingest -h\nroot@uno> listtablets -t accumulo.metadata\n```\n\n----------------------------------------\n\nTITLE: Listing HDFS Erasure Coding Policies\nDESCRIPTION: This command lists all configured Erasure Coding policies in HDFS, showing their names, schemas, and states.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs ec -listPolicies\n```\n\n----------------------------------------\n\nTITLE: Adding MiniAccumuloCluster Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use MiniAccumuloCluster in test scope.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/development_tools.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.apache.accumulo</groupId>\n  <artifactId>accumulo-minicluster</artifactId>\n  <version>${accumulo.version}</version>\n  <scope>test</scope>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Verifying Kerberos Authentication Log Output\nDESCRIPTION: Example log output showing successful Kerberos authentication in Accumulo, demonstrating proper keytab login for the Accumulo service principal.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n2015-01-07 11:57:56,826 [security.SecurityUtil] INFO : Attempting to login with keytab as accumulo/hostname@EXAMPLE.COM\n2015-01-07 11:57:56,830 [security.UserGroupInformation] INFO : Login successful for user accumulo/hostname@EXAMPLE.COM using keytab file /etc/security/keytabs/accumulo.service.keytab\n```\n\n----------------------------------------\n\nTITLE: Adding Iterator Test Harness Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use the Iterator Test Harness in test scope.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/development_tools.md#2025-04-11_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>org.apache.accumulo</groupId>\n  <artifactId>accumulo-iterator-test-harness</artifactId>\n  <version>${accumulo.version}</version>\n  <scope>test</scope>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Example Final State Marker for External Compaction in Accumulo\nDESCRIPTION: JSON representation of a final state marker for a completed external compaction, showing the table ID, state, file size, and entry count.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n~ecompECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c : []        {\"extent\":{\"tableId\":\"2\"},\"state\":\"FINISHED\",\"fileSize\":12354,\"entries\":100000}\n```\n\n----------------------------------------\n\nTITLE: Running Continuous Query Operation\nDESCRIPTION: Command to execute continuous random term queries using 5 terms per document, displaying matching document counts and query times.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/shard.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.shard.ContinuousQuery instance zookeepers shard doc2term username password 5\n```\n\n----------------------------------------\n\nTITLE: Viewing Accumulo Compaction Logs\nDESCRIPTION: Example log entries showing compactions running on different compaction services with details on file sizes, locations, and whether they were system or user-initiated.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_12\n\nLANGUAGE: plaintext\nCODE:\n```\n2020-06-25T16:34:31,669 [tablet.files] DEBUG: Compacting 3;667;6 on cs1.small for SYSTEM from [C00001cm.rf, C00001a7.rf, F00001db.rf] size 15 MB\n2020-06-25T16:34:45,165 [tablet.files] DEBUG: Compacted 3;667;6 for SYSTEM created hdfs://localhost:8020/accumulo/tables/3/t-000006f/C00001de.rf from [C00001cm.rf, C00001a7.rf, F00001db.rf]\n2020-06-25T16:35:01,965 [tablet.files] DEBUG: Compacting 3;667;6 on cs1.medium for SYSTEM from [C00001de.rf, A000017v.rf, F00001e7.rf] size 33 MB\n2020-06-25T16:35:11,686 [tablet.files] DEBUG: Compacted 3;667;6 for SYSTEM created hdfs://localhost:8020/accumulo/tables/3/t-000006f/A00001er.rf from [C00001de.rf, A000017v.rf, F00001e7.rf]\n2020-06-25T16:37:12,521 [tablet.files] DEBUG: Compacting 3;667;6 on cs2.medium for USER from [F00001f8.rf, A00001er.rf] size 35 MB config []\n2020-06-25T16:37:17,917 [tablet.files] DEBUG: Compacted 3;667;6 for USER created hdfs://localhost:8020/accumulo/tables/3/t-000006f/A00001fr.rf from [F00001f8.rf, A00001er.rf]\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Metrics Properties\nDESCRIPTION: Configuration for hadoop-metrics2-accumulo.properties file to enable sending metrics to InfluxDB with Graphite sink\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2018-03-22-view-metrics-in-grafana.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\n*.period=30\naccumulo.sink.graphite.class=org.apache.hadoop.metrics2.sink.GraphiteSink\naccumulo.sink.graphite.server_host=<INFLUXDB_HOST>\naccumulo.sink.graphite.server_port=2003\naccumulo.sink.graphite.metrics_prefix=accumulo\n```\n\n----------------------------------------\n\nTITLE: Running Java BatchWriter Example\nDESCRIPTION: Command to execute the InsertWithBatchWriter Java example, which inserts 10,000 rows (50,000 entries) into the 'hellotable'. Each row contains 5 entries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/helloworld.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.InsertWithBatchWriter -i instance -z zookeepers -u username -p password -t hellotable\n```\n\n----------------------------------------\n\nTITLE: Finding Accumulo Instance ID in ZooKeeper\nDESCRIPTION: Commands to connect to ZooKeeper and retrieve the instance ID for a given Accumulo instance name. Useful for troubleshooting instance identification issues.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nzkCli.sh -server <host>:2181     # replace <host> with your ZooKeeper server DNS name\n> get /accumulo/instances/<name> # replace <name> with your instance name\n> quit\n```\n\n----------------------------------------\n\nTITLE: Importing Bulk Data into Accumulo\nDESCRIPTION: This command imports files produced by an external process (like MapReduce) into an existing Accumulo table. The importdirectory command specifies the HDFS directory containing the files to import and a directory for storing any files that fail to import.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/High_Speed_Ingest.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> importdirectory /files_dir /failures\n```\n\n----------------------------------------\n\nTITLE: Signaling Server Shutdown with Admin Command\nDESCRIPTION: The 'accumulo admin signalShutdown' command initiates a graceful shutdown of server processes, allowing compactors to finish current tasks and ensuring proper server termination.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2025-04-08-accumulo-2.1.4.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naccumulo admin signalShutdown\n```\n\n----------------------------------------\n\nTITLE: Configuring External Compactions in Accumulo\nDESCRIPTION: Shell commands to create a compaction service with an external executor queue and configure a table to use this service for all compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s tserver.compaction.major.service.cs1.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\nconfig -s 'tserver.compaction.major.service.cs1.planner.opts.executors=[{\"name\":\"all\",\"type\":\"external\",\"queue\":\"DCQ1\"}]'\nconfig -t testTable -s table.compaction.dispatcher=org.apache.accumulo.core.spi.compaction.SimpleCompactionDispatcher\nconfig -t testTable -s table.compaction.dispatcher.opts.service=cs1\n```\n\n----------------------------------------\n\nTITLE: Configuring External Compactions in Accumulo\nDESCRIPTION: Shell commands to create a compaction service with an external executor queue and configure a table to use this service for all compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s tserver.compaction.major.service.cs1.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\nconfig -s 'tserver.compaction.major.service.cs1.planner.opts.executors=[{\"name\":\"all\",\"type\":\"external\",\"queue\":\"DCQ1\"}]'\nconfig -t testTable -s table.compaction.dispatcher=org.apache.accumulo.core.spi.compaction.SimpleCompactionDispatcher\nconfig -t testTable -s table.compaction.dispatcher.opts.service=cs1\n```\n\n----------------------------------------\n\nTITLE: Installing Muchos for AWS Cluster Deployment\nDESCRIPTION: Commands to clone and initialize the Muchos repository for multi-node Accumulo deployment\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/apache/fluo-muchos.git\ncd fluo-muchos\n```\n\n----------------------------------------\n\nTITLE: Configuring Generic Crypto Service Factory for Instance-Wide Encryption in Accumulo\nDESCRIPTION: Configuration properties to enable encryption for all tables using the GenericCryptoServiceFactory in the accumulo.properties file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\ninstance.crypto.opts.factory=org.apache.accumulo.core.spi.crypto.GenericCryptoServiceFactory\n```\n\n----------------------------------------\n\nTITLE: Setting Replication Name in Primary Instance Configuration\nDESCRIPTION: Sets the unique identifier for the primary Accumulo instance that will participate in replication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\nreplication.name=primary\n```\n\n----------------------------------------\n\nTITLE: Example Metadata Entry for External Compaction in Accumulo\nDESCRIPTION: JSON representation of an external compaction metadata entry showing the compaction configuration including input files, temporary file location, compactor address, and other parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n2;10ba2e8ba2e8ba5 ecomp:ECID:94db8374-8275-4f89-ba8b-4c6b3908bc50 []    {\"inputs\":[\"hdfs://accucluster/accumulo/tables/2/t-00000ur/A00001y9.rf\",\"hdfs://accucluster/accumulo/tables/2/t-00000ur/C00005lp.rf\",\"hdfs://accucluster/accumulo/tables/2/t-00000ur/F0000dqm.rf\",\"hdfs://accucluster/accumulo/tables/2/t-00000ur/F0000dq1.rf\"],\"nextFiles\":[],\"tmp\":\"hdfs://accucluster/accumulo/tables/2/t-00000ur/C0000dqs.rf_tmp\",\"compactor\":\"10.2.0.139:9133\",\"kind\":\"SYSTEM\",\"executorId\":\"DCQ1\",\"priority\":-32754,\"propDels\":true,\"selectedAll\":false}\n```\n\n----------------------------------------\n\nTITLE: Copying Exported Accumulo Table using Hadoop DistCp\nDESCRIPTION: This snippet demonstrates how to use Hadoop DistCp to copy the exported table files to a new location for import.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/export.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop distcp -f /tmp/table1_export/distcp.txt /tmp/table1_export_dest\n```\n\n----------------------------------------\n\nTITLE: Generating Tour Page List with Liquid Templating in Jekyll\nDESCRIPTION: A Liquid template loop that generates a numbered list of links to all tour pages by accessing site data and constructing URLs dynamically.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/index.md#2025-04-11_snippet_0\n\nLANGUAGE: liquid\nCODE:\n```\n{% for p in tour_pages %}\n  {% assign doc_url = p | prepend: '/tour/' | append: '/' %}\n  {% assign link_to_page = site.pages | where:'url',doc_url | first %}\n  1. [{{ link_to_page.title }}]({{ doc_url }})\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Configuring ViewFS and HA Settings in core-site.xml\nDESCRIPTION: Configuration for ViewFS mount points and HA fencing methods to enable multi-volume support across HDFS nameservices.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-06-25-scaling-accumulo-with-multivolume-support.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>fs.defaultFS</name>\n  <value>viewfs:///</value>\n</property>\n<property>\n  <name>fs.viewfs.mounttable.default.link./nameserviceA</name>\n  <value>hdfs://nameserviceA</value>\n</property>\n<property>\n  <name>fs.viewfs.mounttable.default.link./nameserviceB</name>\n  <value>hdfs://nameserviceB</value>\n</property>\n<property>\n  <name>fs.viewfs.mounttable.default.link./nameserviceA/accumulo/instance_id</name>\n  <value>hdfs://nameserviceA/accumulo/instance_id</value>\n  <description>Workaround for ACCUMULO-2719</description>\n</property>\n<property>\n  <name>dfs.ha.fencing.methods</name>\n  <value>sshfence(hdfs:22)\n         shell(/bin/true)</value>\n</property>\n<property>\n  <name>dfs.ha.fencing.ssh.private-key-files</name>\n  <value><PRIVATE_KEY_LOCATION></value>\n</property>\n<property>\n  <name>dfs.ha.fencing.ssh.connect-timeout</name>\n  <value>30000</value>\n</property>\n<property>\n  <name>ha.zookeeper.quorum</name>\n  <value>zkHost1:2181,zkHost2:2181,zkHost3:2181</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Logging Garbage Collection Statistics in Java\nDESCRIPTION: This code snippet demonstrates a log output from an Accumulo tablet server, showing garbage collection statistics and memory usage. It helps in diagnosing memory-related issues that can lead to tablet server lock loss.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n2013-06-20 13:43:20,607 [tabletserver.TabletServer] DEBUG: gc ParNew=0.00(+0.00) secs\\n    ConcurrentMarkSweep=0.00(+0.00) secs freemem=1,868,325,952(+1,868,325,952) totalmem=2,040,135,680\n```\n\n----------------------------------------\n\nTITLE: Copying Example Configuration Files in Accumulo\nDESCRIPTION: Command to copy example configuration files from the 3GB native-standalone template to the main configuration directory. This sets up Accumulo for single-node operation with a 3GB memory footprint.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-27-getting-started-with-accumulo-1.6.0.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp $ACCUMULO_HOME/conf/examples/3G/native-standalone/* $ACCUMULO_HOME/conf\n```\n\n----------------------------------------\n\nTITLE: Setting Up Accumulo Environment with Uno\nDESCRIPTION: Commands to set up Accumulo and its dependencies in the install directory and configure the shell environment\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/uno setup accumulo\neval \"$(./bin/uno env)\"\n```\n\n----------------------------------------\n\nTITLE: Ingesting File Data into Accumulo Table\nDESCRIPTION: This command uses the FileDataIngest class to ingest a file into the Accumulo dataTable. It specifies the instance, zookeepers, credentials, table name, authorizations, chunk size, and the file to ingest.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filedata.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.filedata.FileDataIngest -i instance -z zookeepers -u username -p password -t dataTable --auths exampleVis --chunk 1000 $ACCUMULO_HOME/README\n```\n\n----------------------------------------\n\nTITLE: Query Output Example\nDESCRIPTION: Sample output showing the result of the BatchScanner query, displaying the average years of service for the queried villains.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/batch-scanner-code.md#2025-04-11_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nThe average years of service of 2000 villains is 24.8125\n```\n\n----------------------------------------\n\nTITLE: Creating Kerberos Principal for Accumulo Client\nDESCRIPTION: This command creates a Kerberos principal for an Accumulo client user with a password. It's used to set up authentication for client access.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_7\n\nLANGUAGE: console\nCODE:\n```\nkadmin.local -q \"addprinc $user\"\n```\n\n----------------------------------------\n\nTITLE: Replacing Corrupt WAL File in HDFS for Accumulo\nDESCRIPTION: These Hadoop commands move an empty WAL file to HDFS and replace a corrupt WAL file, allowing Accumulo to recover from WAL corruption.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs dfs -moveFromLocal empty.wal /user/accumulo/empty.wal\n$ hdfs dfs -mv /user/accumulo/empty.wal /accumulo/wal/tserver-4.example.com+10011/26abec5b-63e7-40dd-9fa1-b8ad2436606e\n```\n\n----------------------------------------\n\nTITLE: Configuring Replication Name in Properties\nDESCRIPTION: Sets a unique identifier for the Accumulo instance in the replication system using accumulo.properties configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\n# Unique name for this system used by replication\nreplication.name=primary\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for Accumulo Compactors\nDESCRIPTION: Docker build command for creating an Accumulo container image that will be used to run external compactors. The command specifies version arguments for Accumulo, Hadoop, and Zookeeper.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ndocker build --build-arg ACCUMULO_VERSION=2.1.0-SNAPSHOT --build-arg ACCUMULO_FILE=accumulo-2.1.0-SNAPSHOT-bin.tar.gz \\\n             --build-arg HADOOP_FILE=hadoop-3.3.0.tar.gz \\\n             --build-arg ZOOKEEPER_VERSION=3.6.2  --build-arg ZOOKEEPER_FILE=apache-zookeeper-3.6.2-bin.tar.gz  \\\n             -t accumulo .\n```\n\n----------------------------------------\n\nTITLE: Importing and Inspecting Accumulo Table using Shell Commands\nDESCRIPTION: This snippet shows how to import the copied table files into Accumulo as a new table. It then demonstrates various shell commands to inspect the imported table, including scanning data, retrieving splits, and checking table configurations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/export.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nroot@test17> importtable table1_copy /tmp/table1_export_dest\nroot@test17> table table1_copy\nroot@test17 table1_copy> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test17 table1_copy> getsplits -t table1_copy\nb\nr\nroot@test17> config -t table1_copy -f split\n---------+--------------------------+-------------------------------------------\nSCOPE    | NAME                     | VALUE\n---------+--------------------------+-------------------------------------------\ndefault  | table.split.threshold .. | 1G\ntable    |    @override ........... | 100M\n---------+--------------------------+-------------------------------------------\nroot@test17> tables -l\naccumulo.metadata    =>        !0\naccumulo.root        =>        +r\ntable1_copy          =>         5\ntrace                =>         1\nroot@test17 table1_copy> scan -t accumulo.metadata -b 5 -c srv:time\n5;b srv:time []    M1343224500467\n5;r srv:time []    M1343224500467\n5< srv:time []    M1343224500467\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Cluster\nDESCRIPTION: Command to start all Accumulo processes across the configured nodes using SSH.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./bin/start-all.sh\n```\n\n----------------------------------------\n\nTITLE: Viewing Key Size Histogram in RFiles with rfile-info\nDESCRIPTION: Using the --histogram flag with rfile-info to display a distribution of key sizes in an Accumulo RFile, helpful for diagnosing performance issues related to key size.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo rfile-info --histogram /accumulo/tables/1/default_tablet/A000000n.rf\n...\nUp to size      count      %-age\n         10 :        222  28.23%\n        100 :        244  71.77%\n       1000 :          0   0.00%\n      10000 :          0   0.00%\n     100000 :          0   0.00%\n    1000000 :          0   0.00%\n   10000000 :          0   0.00%\n  100000000 :          0   0.00%\n 1000000000 :          0   0.00%\n10000000000 :          0   0.00%\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Settings for an Accumulo Table\nDESCRIPTION: This snippet demonstrates how to view the configured iterator settings for a table using the 'config' command with the iterator filter. It shows all scopes, priorities, and parameters of configured iterators.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filter.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+---------------------------------------------------------------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+---------------------------------------------------------------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+---------------------------------------------------------------------------\nusername@instance filtertest> \n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Checkstyle Plugin for Accumulo API Validation\nDESCRIPTION: XML configuration for the Maven Checkstyle plugin that enforces proper API usage. This should be added to the pom.xml file of a project to detect improper Accumulo API usage during the build process.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-11-04-checkstyle-import-control.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<plugin>\n    <!-- This was added to ensure project only uses Accumulo's public API -->\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-checkstyle-plugin</artifactId>\n    <version>3.1.0</version>\n    <executions>\n      <execution>\n        <id>check-style</id>\n        <goals>\n          <goal>check</goal>\n        </goals>\n        <configuration>\n          <configLocation>checkstyle.xml</configLocation>\n        </configuration>\n      </execution>\n    </executions>\n  </plugin>\n```\n\n----------------------------------------\n\nTITLE: Forcing Accumulo compaction to remove aged-off data\nDESCRIPTION: This snippet demonstrates how to force a flush and compaction on a table to physically remove data that should be aged off. This process normally happens automatically in production but can be triggered manually.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/filter.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> flush -t filtertest\n08 11:13:55,745 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact -t filtertest\n08 11:14:10,800 [shell.Shell] INFO : Compaction of table filtertest scheduled for 20110208111410EST\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Ingesting File System Data into Accumulo Tables (Java)\nDESCRIPTION: Command to run the Ingest class, which recursively lists files and directories under a given path and stores their information in Accumulo tables. It takes parameters for Accumulo instance, zookeepers, username, password, visibility, chunk size, and the directory to ingest.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/dirlist.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.Ingest -i instance -z zookeepers -u username -p password --vis exampleVis --chunkSize 100000 /local/username/workspace\n```\n\n----------------------------------------\n\nTITLE: Rendering News Archive with Jekyll and Liquid Templates\nDESCRIPTION: This code builds a news archive page by filtering non-draft posts, grouping them by year, and displaying them in reverse chronological order. It uses Liquid templating to iterate through posts, detect year changes, and create appropriate headers and formatting.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/news.md#2025-04-11_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div>\n{% assign visible_posts = site.posts | where:\"draft\",false %}\n{% assign header_year = visible_posts[0].date | date: \"%Y\" %}\n<h3>{{header_year}}</h3>\n{% for post in visible_posts %}\n  {% assign post_year = post.date | date: \"%Y\" %}\n  {% if post_year != header_year %}\n    {% assign header_year = post_year %}\n    <hr>\n    <h3>{{ header_year }}</h3>\n  {% endif %}\n  <div class=\"row\" style=\"margin-top: 15px\">\n    <div class=\"col-md-1\">{{ post.date | date: \"%b %d\" }}</div>\n    <div class=\"col-md-10\"><a href=\"{{ site.baseurl }}{{ post.url }}\">{{ post.title }}</a></div>\n  </div>\n{% endfor %}\n</div>\n```\n\n----------------------------------------\n\nTITLE: Replacing Corrupt File with Empty RFile in HDFS\nDESCRIPTION: These Hadoop commands remove a corrupt file and replace it with an empty RFile in HDFS, allowing Accumulo to resolve references to the file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs –rm /accumulo/tables/corrupt/file/thename.rf; \\\nhadoop fs -mv /path/to/empty/file/empty.rf /accumulo/tables/corrupt/file/thename.rf\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo Client with Fluent API in Java\nDESCRIPTION: Demonstrates the new simplified way to connect to Accumulo using the fluent API pattern with minimal imports. Shows how to create an AccumuloClient instance with connection details and create a new table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-08-12-why-upgrade.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nimport org.apache.accumulo.core.client.Accumulo;\nimport org.apache.accumulo.core.client.AccumuloClient;\n\ntry (AccumuloClient client = Accumulo.newClient()\n          .to(\"instance\", \"zk\")\n          .as(\"user\", \"pass\").build()) {\n      // use the client\n      client.tableOperations().create(\"newTable\");\n    }\n```\n\n----------------------------------------\n\nTITLE: Revoking Permissions via Java API\nDESCRIPTION: Shows how to revoke system permissions programmatically using the SecurityOperations Java API. This example revokes the CREATE_TABLE permission from user 'bob'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/permissions.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().revokeSystemPermission(\"bob\", SystemPermission.CREATE_TABLE);\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo with Metrics using Uno\nDESCRIPTION: Command to set up Accumulo with metrics support using the Uno tool\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2018-03-22-view-metrics-in-grafana.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuno setup accumulo --with-metrics\n```\n\n----------------------------------------\n\nTITLE: Examining Export Files using Hadoop\nDESCRIPTION: Hadoop filesystem commands to examine the exported table files and their contents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/export.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/table1_export\nFound 2 items\n-rw-r--r--   3 user supergroup        162 2012-07-25 09:56 /tmp/table1_export/distcp.txt\n-rw-r--r--   3 user supergroup        821 2012-07-25 09:56 /tmp/table1_export/exportMetadata.zip\n$ hadoop fs -cat /tmp/table1_export/distcp.txt\nhdfs://n1.example.com:6093/accumulo/tables/3/default_tablet/F0000000.rf\nhdfs://n1.example.com:6093/tmp/table1_export/exportMetadata.zip\n```\n\n----------------------------------------\n\nTITLE: Regular Expression for Identifying Non-API Imports in Accumulo 1.x\nDESCRIPTION: This regex pattern matches import statements that are not part of Accumulo's public API for version 1.x. It can be used with tools like RegexpSingleline in checkstyle to identify dependencies on internal implementation details.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/api.md#2025-04-11_snippet_0\n\nLANGUAGE: regex\nCODE:\n```\nimport\\s+org\\.apache\\.accumulo\\.(.*\\.(impl|thrift|crypto)\\...*|(?!(core\\.(client|data|security)|minicluster)\\.).*))\n```\n\n----------------------------------------\n\nTITLE: Displaying Continuous Ingest Verification Results in Bash\nDESCRIPTION: Output from the continuous ingest verification MapReduce job showing count statistics. The job checks for data integrity by confirming there are no holes in the linked list produced by continuous ingest, with zero UNDEFINED count indicating no data loss.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n        org.apache.accumulo.testing.continuous.ContinuousVerify$Counts\n                REFERENCED=266225036149\n                UNREFERENCED=22010637\n```\n\n----------------------------------------\n\nTITLE: Search Command Syntax\nDESCRIPTION: Command for searching a table in parallel on the server side with options for row ranges, columns, and scan authorizations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_28\n\nLANGUAGE: shell\nCODE:\n```\nsearch [-?] [-b <start-row>] [-c <<columnfamily>[:<columnqualifier>]>] [-e <end-row>] [-np] [-s <comma-separated-authorizations>] [-st] [-t <arg>]\n```\n\n----------------------------------------\n\nTITLE: Creating and Exporting Accumulo Table using Shell Commands\nDESCRIPTION: This snippet demonstrates creating a table, inserting data, cloning the table, taking it offline, and exporting it. It shows how to create splits and set table configurations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/export.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@test17> createtable table1\nroot@test17 table1> insert a cf1 cq1 v1\nroot@test17 table1> insert h cf1 cq1 v2\nroot@test17 table1> insert z cf1 cq1 v3\nroot@test17 table1> insert z cf1 cq2 v4\nroot@test17 table1> addsplits -t table1 b r\nroot@test17 table1> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test17> config -t table1 -s table.split.threshold=100M\nroot@test17 table1> clonetable table1 table1_exp\nroot@test17 table1> offline table1_exp\nroot@test17 table1> exporttable -t table1_exp /tmp/table1_export\nroot@test17 table1> quit\n```\n\n----------------------------------------\n\nTITLE: Testing FooFilter Functionality\nDESCRIPTION: These commands insert test data and perform a scan to demonstrate that the FooFilter is working as expected.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/classpath.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nroot@test16 nofoo> insert foo1 f1 q1 v1\nroot@test16 nofoo> insert noo1 f1 q1 v2\nroot@test16 nofoo> scan\nnoo1 f1:q1 []    v2\nroot@test15 nofoo>\n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Word Count Job with Accumulo\nDESCRIPTION: Command to execute the MapReduce word count job that processes input files in HDFS and stores results in the Accumulo 'wordCount' table. The command output shows the job's progress and statistics.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -p password\n\n11/02/07 18:20:11 INFO input.FileInputFormat: Total input paths to process : 1\n11/02/07 18:20:12 INFO mapred.JobClient: Running job: job_201102071740_0003\n11/02/07 18:20:13 INFO mapred.JobClient:  map 0% reduce 0%\n11/02/07 18:20:20 INFO mapred.JobClient:  map 100% reduce 0%\n11/02/07 18:20:22 INFO mapred.JobClient: Job complete: job_201102071740_0003\n11/02/07 18:20:22 INFO mapred.JobClient: Counters: 6\n11/02/07 18:20:22 INFO mapred.JobClient:   Job Counters\n11/02/07 18:20:22 INFO mapred.JobClient:     Launched map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:     Data-local map tasks=1\n11/02/07 18:20:22 INFO mapred.JobClient:   FileSystemCounters\n11/02/07 18:20:22 INFO mapred.JobClient:     HDFS_BYTES_READ=10487\n11/02/07 18:20:22 INFO mapred.JobClient:   Map-Reduce Framework\n11/02/07 18:20:22 INFO mapred.JobClient:     Map input records=255\n11/02/07 18:20:22 INFO mapred.JobClient:     Spilled Records=0\n11/02/07 18:20:22 INFO mapred.JobClient:     Map output records=1452\n```\n\n----------------------------------------\n\nTITLE: Merging Metadata Table Splits in Accumulo 2.1.0\nDESCRIPTION: Example showing how to identify and merge away old-format metadata table splits after upgrading to Accumulo 2.1.0. The example demonstrates checking current splits with 'getsplits', identifying splits with the old prefix '~delhdfs', and merging them away.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2022-11-01-accumulo-2.1.0.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nroot@uno> getsplits -t accumulo.metadata\n2<\n~\n~del55\n~dela7\n~delhdfs://localhost:8020/accumulo/tables/2/default_tablet/F00000a0.rf\n~delhdfs://localhost:8020/accumulo/tables/2/default_tablet/F00000kb.rf\nroot@uno> merge -t accumulo.metadata -b ~delhdfs -e ~delhdfs~\nroot@uno> getsplits -t accumulo.metadata\n2<\n~\n~del55\n~dela7\n```\n\n----------------------------------------\n\nTITLE: Creating Keys and Mutations with Fluent API in Java\nDESCRIPTION: Shows how to use the new fluent APIs for creating Keys and Mutations, demonstrating the ability to mix String and byte[] types in a more readable syntax.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-08-12-why-upgrade.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nKey newKey = Key.builder().row(\"foo\").family(\"bar\").build();\n\nMutation m = new Mutation(\"row0017\");\nm.at().family(\"001\").qualifier(new byte[] {0,1}).put(\"v99\");\nm.at().family(\"002\").qualifier(new byte[] {0,1}).delete();\n```\n\n----------------------------------------\n\nTITLE: Configuring Recovery and WAL Crypto Services in Accumulo\nDESCRIPTION: Properties to set the crypto services for recovery operations and Write Ahead Logs when using per-table encryption.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_4\n\nLANGUAGE: properties\nCODE:\n```\ngeneral.custom.crypto.recovery.service=org.apache.accumulo.core.spi.crypto.AESCryptoService\ngeneral.custom.crypto.wal.service=org.apache.accumulo.core.spi.crypto.AESCryptoService\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo and Dependencies on Fedora 25\nDESCRIPTION: This command installs Accumulo, Java JDK, tuned for system performance, and other necessary packages on Fedora 25.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo dnf install accumulo java-1.8.0-openjdk-devel tuned vim hadoop-common-native\n```\n\n----------------------------------------\n\nTITLE: Creating, Populating and Exporting an Apache Accumulo Table\nDESCRIPTION: This snippet demonstrates creating a table, inserting data, adding splits, cloning the table, taking it offline, and exporting it. The export process creates files that can be used with distcp to copy the table data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/export.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nroot@test15> createtable table1\nroot@test15 table1> insert a cf1 cq1 v1\nroot@test15 table1> insert h cf1 cq1 v2\nroot@test15 table1> insert z cf1 cq1 v3\nroot@test15 table1> insert z cf1 cq2 v4\nroot@test15 table1> addsplits -t table1 b r\nroot@test15 table1> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test15> config -t table1 -s table.split.threshold=100M\nroot@test15 table1> clonetable table1 table1_exp\nroot@test15 table1> offline table1_exp\nroot@test15 table1> exporttable -t table1_exp /tmp/table1_export\nroot@test15 table1> quit\n```\n\n----------------------------------------\n\nTITLE: Create Authentication Token File\nDESCRIPTION: Commands demonstrating how to create and use token files for secure authentication in MapReduce jobs.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/mapred.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo create-token\n$ ./bin/accumulo create-token -u root -p secret -f root.pw\n$ hadoop fs -put root.pw root.pw\n```\n\n----------------------------------------\n\nTITLE: Toggling Debug Logging in Accumulo Shell\nDESCRIPTION: The debug command turns debug logging on or off in the Accumulo shell, providing more detailed output for troubleshooting.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nusage: debug [ on | off ] [-?]   \ndescription: turns debug logging on or off   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Setting Up Hexadecimal-Based StatsCombiner in Accumulo Shell\nDESCRIPTION: Commands to configure a second StatsCombiner named 'hexStats' with priority 11 operating on the 'hstat' column family using base 16 (hexadecimal) numbers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/combiner.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance runners> setiter -t runners -p 11 -scan -minc -majc -n hexStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.:\n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: hstat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 16\n```\n\n----------------------------------------\n\nTITLE: Uploading Token File to HDFS for MapReduce Job\nDESCRIPTION: Command to upload a local token file to HDFS so it can be used with MapReduce jobs for Accumulo authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -put root.pw root.pw\n```\n\n----------------------------------------\n\nTITLE: Querying Word Count Results from Accumulo Table\nDESCRIPTION: Shows how to connect to the Accumulo shell and query the word count results stored in the 'wordCount' table. The scan command with a prefix filter retrieves and displays all words starting with 'the' and their respective counts.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/mapred.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nusername@instance> table wordCount\nusername@instance wordCount> scan -b the\nthe count:20080906 []    75\ntheir count:20080906 []    2\nthem count:20080906 []    1\nthen count:20080906 []    1\nthere count:20080906 []    1\nthese count:20080906 []    3\nthis count:20080906 []    6\nthrough count:20080906 []    1\ntime count:20080906 []    3\ntime. count:20080906 []    1\nto count:20080906 []    27\ntotal count:20080906 []    1\ntserver, count:20080906 []    1\ntserver.compaction.major.concurrent.max count:20080906 []    1\n...\n```\n\n----------------------------------------\n\nTITLE: Initializing DataTable for Citations in JavaScript\nDESCRIPTION: JavaScript code that initializes a jQuery DataTable on an HTML table with ID 'citationtable' to enable sorting and filtering of citation data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/external-docs.md#2025-04-11_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n$(function() {\n$(\"#citationtable\").dataTable();\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Volumes in accumulo-site.xml\nDESCRIPTION: Configuration to specify multiple HDFS volumes for Accumulo to use for storage distribution.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-06-25-scaling-accumulo-with-multivolume-support.md#2025-04-11_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>instance.volumes</name>\n  <value>hdfs://nameserviceA/accumulo,hdfs://nameserviceB/accumulo</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Detailed HDFS Block Check for Corrupt Files\nDESCRIPTION: This command shows how to perform a detailed check on specific HDFS files or directories, including block locations. It's useful for troubleshooting corrupt files in Accumulo's HDFS storage.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fsck /accumulo/path/to/corrupt/file -locations -blocks -files\n```\n\n----------------------------------------\n\nTITLE: Displaying Accumulo 1.8.0 Command Usage\nDESCRIPTION: Shows the limited usage information for the accumulo command in version 1.8.0.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./accumulo-1.8.0/bin/accumulo\naccumulo admin | check-server-config | classpath | create-token | gc | help | info | init | jar <jar> [<main class>] args |\n  login-info | master | minicluster | monitor | proxy | rfile-info | shell | tracer | tserver | version | zookeeper | <accumulo class> args\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with SummingCombiner for Word Count Aggregation\nDESCRIPTION: Demonstrates creating an Accumulo table named 'wordCount' and configuring a SummingCombiner iterator to automatically sum values in the 'count' column family. This enables automatic aggregation of word counts during MapReduce processing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.4.x\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable wordCount\nusername@instance wordCount> setiter -class org.apache.accumulo.core.iterators.user.SummingCombiner -p 10 -t wordCount -majc -minc -scan\nSummingCombiner interprets Values as Longs and adds them together.  A variety of encodings (variable length, fixed length, or string) are available\n----------> set SummingCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: false\n----------> set SummingCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non-alphanum chars using %<hex>.: count\n----------> set SummingCombiner parameter lossy, if true, failed decodes are ignored. Otherwise combiner will error on failed decodes (default false): <TRUE|FALSE>: false \n----------> set SummingCombiner parameter type, <VARLEN|FIXEDLEN|STRING|fullClassName>: STRING\nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Exiting the Accumulo Shell\nDESCRIPTION: The bye command exits the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusage: bye [-?]   \ndescription: exits the shell   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: Exiting the Accumulo Shell\nDESCRIPTION: The bye command exits the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nusage: bye [-?]   \ndescription: exits the shell   \n  -?,-help  display this help\n```\n\n----------------------------------------\n\nTITLE: HTML Table Structure for Citations\nDESCRIPTION: HTML table structure with Bootstrap styling classes that displays academic citations with columns for title, links, category, venue, peer-review status and awards.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/external-docs.md#2025-04-11_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n{: #citationtable .table .table-bordered .table-striped style=\"width:100%;\" }\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring Table with Custom Classpath\nDESCRIPTION: Creates a new table 'nofoo' and configures it to use the custom classpath context\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/classpath.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncreatetable nofoo\n```\n\nLANGUAGE: shell\nCODE:\n```\nconfig -t nofoo -s table.classpath.context=cx1\n```\n\n----------------------------------------\n\nTITLE: Alternative Command for Deleting Tables in Accumulo\nDESCRIPTION: The droptable command is an alternative to deletetable that removes a table from Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\nusage: droptable <tableName> [-?] [-t <arg>]   \ndescription: deletes a table   \n  -?,-help  display this help   \n  -t,-tableName <arg>  deletes a table\n```\n\n----------------------------------------\n\nTITLE: Inserting Data in Multiple Batches to Create Separate Map Files (Without Bloom)\nDESCRIPTION: This snippet shows inserting data in three separate batches with different seeds and flushing between each batch to create multiple map files in a table without bloom filters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test1 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n```\n\n----------------------------------------\n\nTITLE: Running MapReduce Word Count with Token File Authentication\nDESCRIPTION: Command to run the WordCount MapReduce job using a token file for authentication instead of a plaintext password. This provides better security for Accumulo credentials.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/mapred.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.WordCount -i instance -z zookeepers  --input /user/username/wc -t wordCount -u username -tf tokenfile\n```\n\n----------------------------------------\n\nTITLE: Bulk Deleting Records in Accumulo\nDESCRIPTION: The deletemany command scans a table and deletes matching records. It supports row ranges, column filtering, and authorization controls.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nusage: deletemany [-?] [-b <start-row>] [-c   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>]   \n          [-e <end-row>] [-f] [-fm <className>] [-np] [-r <row>] [-s   \n          <comma-separated-authorizations>] [-st] [-t <table>]   \ndescription: scans a table and deletes the resulting records   \n  -?,-help  display this help   \n  -b,-begin-row <start-row>  begin row (inclusive)   \n  -c,-columns   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>   \n          comma-separated columns   \n  -e,-end-row <end-row>  end row (inclusive)   \n  -f,-force  forces deletion without prompting   \n  -fm,-formatter <className>  fully qualified name of the formatter class to use   \n  -np,-no-pagination  disables pagination of output   \n  -r,-row <row>  row to scan   \n  -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations   \n          (all user auths are used if this argument is not specified)   \n  -st,-show-timestamps  enables displaying timestamps   \n  -t,-table <table>  table to be created\n```\n\n----------------------------------------\n\nTITLE: Bulk Deleting Records in Accumulo\nDESCRIPTION: The deletemany command scans a table and deletes matching records. It supports row ranges, column filtering, and authorization controls.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nusage: deletemany [-?] [-b <start-row>] [-c   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>]   \n          [-e <end-row>] [-f] [-fm <className>] [-np] [-r <row>] [-s   \n          <comma-separated-authorizations>] [-st] [-t <table>]   \ndescription: scans a table and deletes the resulting records   \n  -?,-help  display this help   \n  -b,-begin-row <start-row>  begin row (inclusive)   \n  -c,-columns   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>   \n          comma-separated columns   \n  -e,-end-row <end-row>  end row (inclusive)   \n  -f,-force  forces deletion without prompting   \n  -fm,-formatter <className>  fully qualified name of the formatter class to use   \n  -np,-no-pagination  disables pagination of output   \n  -r,-row <row>  row to scan   \n  -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations   \n          (all user auths are used if this argument is not specified)   \n  -st,-show-timestamps  enables displaying timestamps   \n  -t,-table <table>  table to be created\n```\n\n----------------------------------------\n\nTITLE: Creating a Git Branch for Accumulo Contribution\nDESCRIPTION: Command to create a new Git branch for working on an Accumulo issue. The example uses 'accumulo-4321' as the branch name, which follows the convention of referencing the issue number.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/how-to-contribute.md#2025-04-11_snippet_0\n\nLANGUAGE: git\nCODE:\n```\ngit checkout -b accumulo-4321\n```\n\n----------------------------------------\n\nTITLE: Starting Compaction Coordinator Manually on Accumulo Cluster\nDESCRIPTION: Command to manually start the Accumulo Compaction Coordinator process on a cluster node, redirecting output and error logs to specific files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnohup accumulo compaction-coordinator >/var/data/logs/accumulo/compaction-coordinator.out 2>/var/data/logs/accumulo/compaction-coordinator.err &\n```\n\n----------------------------------------\n\nTITLE: Downloading Micrometer StatsD Meter Registry JAR\nDESCRIPTION: Command to download the Micrometer StatsD Meter Registry JAR file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nwget -O micrometer-registry-statsd-1.9.1.jar https://search.maven.org/remotecontent?filepath=io/micrometer/micrometer-registry-statsd/1.9.1/micrometer-registry-statsd-1.9.1.jar\n```\n\n----------------------------------------\n\nTITLE: Configuring VFS ClassPath in Accumulo\nDESCRIPTION: XML configuration example showing how to set up HDFS-based system classloader path in Accumulo. This allows Accumulo to load its core jars from HDFS instead of the local filesystem.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-03-accumulo-classloader.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>general.vfs.classpaths</name>\n  <value>hdfs://localhost:8020/accumulo/system-classpath</value>\n  <description>Configuration for a system level vfs classloader. Accumulo jars can be configured here and loaded out of HDFS.</description>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Copying Files to HDFS for MapReduce Processing\nDESCRIPTION: Commands to copy a sample text file (README) to HDFS for processing with the word count example and verifying it exists in the target directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/README /user/username/wc/Accumulo.README\n$ hadoop fs -ls /user/username/wc\nFound 1 items\n-rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Accumulo.README\n```\n\n----------------------------------------\n\nTITLE: Merging with statistics for conflict resolution\nDESCRIPTION: Command to merge branches with statistics, which helps identify potential conflicts when merging changes across versions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout new-version && git merge --stat old-version\n```\n\n----------------------------------------\n\nTITLE: Configuring DeletesSummarizer and Compaction Strategy\nDESCRIPTION: Sets up DeletesSummarizer and TooManyDeletesCompactionStrategy to manage deletes ratio and trigger compactions\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/summaries.md#2025-04-11_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nroot@uno summary_test> config -t summary_test -s table.summarizer.del=org.apache.accumulo.core.client.summary.summarizers.DeletesSummarizer\nroot@uno summary_test> compact -w\nroot@uno summary_test> config -t summary_test -s table.compaction.major.ratio=10\nroot@uno summary_test> config -t summary_test -s table.majc.compaction.strategy=org.apache.accumulo.tserver.compaction.strategies.TooManyDeletesCompactionStrategy\nroot@uno summary_test> deletemany -r d5d18dd -c date -f\nroot@uno summary_test> flush -w\nroot@uno summary_test> summaries\n```\n\n----------------------------------------\n\nTITLE: Deleting Accumulo Users\nDESCRIPTION: The 'deleteuser' and 'dropuser' commands delete a user from Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_17\n\nLANGUAGE: markdown\nCODE:\n```\n**deleteuser**   \n\n    usage: deleteuser <username> [-?]   \n    description: deletes a user   \n      -?,-help  display this help   \n\n**dropuser**   \n\n    usage: dropuser <username> [-?]   \n    description: deletes a user   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Creating Test Data in Accumulo\nDESCRIPTION: Shell commands to create a table named 'input' and insert sample data for the RowHash example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/rowhash.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert a-row cf cq value\nusername@instance> insert b-row cf cq value\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Inserting Test Data into Accumulo using Shell\nDESCRIPTION: This snippet shows how to create a table named 'input' and insert sample data using the Accumulo shell. It creates two entries with rows 'dogrow' and 'catrow' to be used for the regex example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/regex.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert dogrow dogcf dogcq dogvalue\nusername@instance> insert catrow catcf catcq catvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Configuring Map Reduce Jobs with Mock Accumulo\nDESCRIPTION: Code to configure Accumulo input and output formats for Map Reduce jobs to use a Mock Accumulo instance instead of a real cluster.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\n// ... set up job configuration\nAccumuloInputFormat.setMockInstance(job, \"mockInstance\");\nAccumuloOutputFormat.setMockInstance(job, \"mockInstance\");\n```\n\n----------------------------------------\n\nTITLE: Apache License Header in Markdown\nDESCRIPTION: This code snippet contains the Apache License 2.0 header in HTML comment format. It specifies the terms under which the file is licensed and distributed.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/CONTRIBUTING.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!--\nLicensed to the Apache Software Foundation (ASF) under one or more\ncontributor license agreements.  See the NOTICE file distributed with\nthis work for additional information regarding copyright ownership.\nThe ASF licenses this file to You under the Apache License, Version 2.0\n(the \"License\"); you may not use this file except in compliance with\nthe License.  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n-->\n```\n\n----------------------------------------\n\nTITLE: Setting Accumulo Classpath for Azure Integration\nDESCRIPTION: Bash configuration for adding Azure storage dependencies to Accumulo's classpath including required JAR files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-10-15-accumulo-adlsgen2-notes.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nCLASSPATH=\"${conf}:${lib}/*:${HADOOP_CONF_DIR}:${ZOOKEEPER_HOME}/*:${HADOOP_HOME}/share/hadoop/client/*\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/tools/lib/azure-data-lake-store-sdk-2.2.9.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/tools/lib/azure-keyvault-core-1.0.0.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/tools/lib/hadoop-azure-3.2.0.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/tools/lib/wildfly-openssl-1.0.4.Final.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jaxb-api-2.2.11.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/commons-lang3-3.7.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/httpclient-4.5.2.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar\"\nexport CLASSPATH\n```\n\n----------------------------------------\n\nTITLE: Configuring Compaction Service with Internal Thread Pools in Accumulo\nDESCRIPTION: Configuration example that defines a compaction service named 'cs1' using DefaultCompactionPlanner with three thread pools (small, medium, and large) of different sizes and thread allocations for handling compactions of different data volumes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\ntserver.compaction.major.service.cs1.planner=org.apache.accumulo.core.spi.compaction.DefaultCompactionPlanner\ntserver.compaction.major.service.cs1.planner.opts.executors=[\n{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"16M\",\"numThreads\":8},\n{\"name\":\"medium\",\"type\":\"internal\",\"maxSize\":\"128M\",\"numThreads\":4},\n{\"name\":\"large\",\"type\":\"internal\",\"numThreads\":2}]\n```\n\n----------------------------------------\n\nTITLE: Compact Command for Small Files\nDESCRIPTION: Shell command example that compacts all files less than 10MB if the tablet has at least two files meeting this criteria.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2015-05-18-accumulo-1.7.0.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncompact -t foo --min-files 2 --sf-lt-esize 10M\n```\n\n----------------------------------------\n\nTITLE: Copy Input File to HDFS\nDESCRIPTION: Commands to copy the Accumulo README file to HDFS as input data and verify its presence.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/mapred.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/README /user/username/wc/Accumulo.README\n$ hadoop fs -ls /user/username/wc\nFound 1 items\n-rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Accumulo.README\n```\n\n----------------------------------------\n\nTITLE: Setting Row Ranges for AccumuloInputFormat\nDESCRIPTION: Optional configuration to restrict AccumuloInputFormat to specific row ranges. Creates and populates an ArrayList of Range objects that determine which rows to include in the input.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Range> ranges = new ArrayList<Range>();\n// populate array list of row ranges ...\nAccumuloInputFormat.setRanges(job, ranges);\n```\n\n----------------------------------------\n\nTITLE: Markdown Front Matter for Accumulo Release Page\nDESCRIPTION: YAML front matter section defining metadata for the Accumulo 1.4.0 release documentation page, including title, version and archived status.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2012-03-30-accumulo-1.4.0.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Apache Accumulo 1.4.0\nsortableversion: '01.04.00'\narchived: true\n---\n```\n\n----------------------------------------\n\nTITLE: Creating Destination Table in Primary Instance\nDESCRIPTION: Command to create the table in the primary instance that will be replicated to the peer.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_8\n\nLANGUAGE: console\nCODE:\n```\nroot@primary> createtable my_table\n```\n\n----------------------------------------\n\nTITLE: Examining Encrypted RFiles in Accumulo\nDESCRIPTION: Using rfile-info with a properties file to examine encrypted Accumulo RFiles. The -p flag allows specifying encryption parameters needed for decryption.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo rfile-info hdfs://localhost:8020/accumulo/tables/1/default_tablet/F0000001.rf -p <path-to-properties>/accumulo.properties\nReading file: hdfs://localhost:8020/accumulo/tables/1/default_tablet/F0000001.rf\nEncrypted with Params: ...\n...\nRFile Version            : 8\n\nLocality group           : <DEFAULT>\n      Num   blocks           : 1\n      Index level 0          : 37 bytes  1 blocks\n      ...\n\nMeta block     : BCFile.index\n      Raw size             : 4 bytes\n      ...\n\nMeta block     : RFile.index\n      Raw size             : 121 bytes\n      ...\n...\n```\n\n----------------------------------------\n\nTITLE: Using Hadoop DistCp to Copy Exported Accumulo Table Files\nDESCRIPTION: The Hadoop distcp command to copy the exported table files to a destination location. This must be completed before the table can be imported.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/export.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop distcp -f /tmp/table1_export/distcp.txt /tmp/table1_export_dest\n```\n\n----------------------------------------\n\nTITLE: Executing Accumulo Reservation System Commands\nDESCRIPTION: Shows the command-line interaction with the Accumulo Reservation System (ARS), including connecting to the system, making reservations, listing them, and canceling them. Demonstrates how multiple concurrent reservation attempts are handled with one successful reservation and others being waitlisted.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/reservations.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.reservations.ARS\n>connect test16 localhost root secret ars\n  connected\n>\n  Commands :\n    reserve <what> <when> <who> {who}\n    cancel <what> <when> <who>\n    list <what> <when>\n>reserve room06 20140101 alice bob eve mallory trent\n                   bob : RESERVED\n               mallory : WAIT_LISTED\n                 alice : WAIT_LISTED\n                 trent : WAIT_LISTED\n                   eve : WAIT_LISTED\n>list room06 20140101\n  Reservation holder : bob\n  Wait list : [mallory, alice, trent, eve]\n>cancel room06 20140101 alice\n>cancel room06 20140101 bob\n>list room06 20140101\n  Reservation holder : mallory\n  Wait list : [trent, eve]\n>quit\n```\n\n----------------------------------------\n\nTITLE: Managing Accumulo Configuration Properties\nDESCRIPTION: The 'config' command prints system properties and table-specific properties. It allows setting, deleting, and filtering properties for specific tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n**config**   \n\n    usage: config [-?] [-d <property> | -f <string> | -s <property=value>] [-np]   \n           [-t <table>]   \n    description: prints system properties and table specific properties   \n      -?,-help  display this help   \n      -d,-delete <property>  delete a per-table property   \n      -f,-filter <string> show only properties that contain this string   \n      -np,-no-pagination  disables pagination of output   \n      -s,-set <property=value>  set a per-table property   \n      -t,-table <table>  display/set/delete properties for specified table   \n```\n\n----------------------------------------\n\nTITLE: Listing Accumulo 2.0.0 Scripts\nDESCRIPTION: Displays the reduced set of scripts in the bin directory for Accumulo 2.0.0, showing the simplification effort.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ls accumulo-2.0.0/bin/\naccumulo  accumulo-cluster  accumulo-service  accumulo-util\n```\n\n----------------------------------------\n\nTITLE: Bulk Write Performance Comparison Table\nDESCRIPTION: Markdown table comparing bulk write performance metrics across different compressors with RS 6-3 1MB Erasure Coding versus triple replication. Shows time taken to write 400 million rows using 40 Spark executors.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-17-erasure-coding.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|Compressor | RS 6-3 1MB | Replication | File size (GB) |\n|---------- | ---------: | ----------: | -------------: |\n|gz | 2.7 | 2.7 | 21.3 |\n|none | 2.0 | 3.0 | 158.5 |\n|snappy | 1.6 | 1.6 | 38.4 |\n```\n\n----------------------------------------\n\nTITLE: Configuring User-Initiated Compaction in Java\nDESCRIPTION: Example showing how to configure and execute a user-initiated compaction using the Java API. This code demonstrates setting up a custom compaction strategy with configuration options.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2015-05-18-accumulo-1.7.0.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nConnection conn = ...\nCompactionStrategyConfig csConfig = new CompactionStrategyConfig(strategyClassName).setOptions(strategyOpts);\nCompactionConfig compactionConfig = new CompactionConfig().setCompactionStrategy(csConfig);\nconnector.tableOperations().compact(tableName, compactionConfig)\n```\n\n----------------------------------------\n\nTITLE: Querying Word Count Results in Accumulo\nDESCRIPTION: Shell commands to query the Accumulo table to see the calculated word counts. The example scans the table starting with words beginning with 'the' and shows the count for each word.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/mapred.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nusername@instance> table wordCount\nusername@instance wordCount> scan -b the\nthe count:20080906 []    75\ntheir count:20080906 []    2\nthem count:20080906 []    1\nthen count:20080906 []    1\nthere count:20080906 []    1\nthese count:20080906 []    3\nthis count:20080906 []    6\nthrough count:20080906 []    1\ntime count:20080906 []    3\ntime. count:20080906 []    1\nto count:20080906 []    27\ntotal count:20080906 []    1\ntserver, count:20080906 []    1\ntserver.compaction.major.concurrent.max count:20080906 []    1\n...\n```\n\n----------------------------------------\n\nTITLE: Exiting Accumulo Shell\nDESCRIPTION: The 'exit' command exits the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_20\n\nLANGUAGE: markdown\nCODE:\n```\n**exit**   \n\n    usage: exit [-?]   \n    description: exits the shell   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest without Isolation in Apache Accumulo\nDESCRIPTION: This command executes the InterferenceTest program for 5000 iterations without isolation enabled. The test shows errors where columns in rows have multiple inconsistent values due to concurrent mutations being visible during scans.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/isolation.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000\n```\n\n----------------------------------------\n\nTITLE: Removing References to Missing Files in Accumulo\nDESCRIPTION: The RemoveEntriesForMissingFiles utility scans file references in Accumulo metadata and identifies/removes entries for files that no longer exist in HDFS.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.server.util.RemoveEntriesForMissingFiles -u root --password\nEnter the connection password:\n2013-07-16 13:10:57,293 [util.RemoveEntriesForMissingFiles] INFO : File /accumulo/tables/2/default_tablet/F0000005.rf\n is missing\n2013-07-16 13:10:57,296 [util.RemoveEntriesForMissingFiles] INFO : 1 files of 3 missing\n```\n\n----------------------------------------\n\nTITLE: Running TeraSortIngest with MapReduce in Accumulo\nDESCRIPTION: This command executes the TeraSortIngest tool which uses MapReduce to generate random data and store it in Accumulo in sorted order. The parameters allow configuration of data size, key/value dimensions, output table, and number of splits.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/terasort.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TeraSortIngest \\\n-i instance -z zookeepers -u user -p password \\\n--count 10 \\\n--minKeySize 10 \\\n--maxKeySize 10 \\\n--minValueSize 78 \\\n--maxValueSize 78 \\\n--table sort \\\n--splits 10 \\\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table without Bloom Filters\nDESCRIPTION: This snippet demonstrates creating a table 'bloom_test1' without bloom filters and configuring its major compaction ratio.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test1\nusername@instance bloom_test1> config -t bloom_test1 -s table.compaction.major.ratio=7\nusername@instance bloom_test1> exit\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information for Accumulo Shell Commands\nDESCRIPTION: The '?' command provides information about available commands. It can be used with or without specific command names and has options for disabling pagination.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**?**   \n\n    usage: ? [ <command> <command> ] [-?] [-np]   \n    description: provides information about the available commands   \n      -?,-help  display this help   \n      -np,-no-pagination  disables pagination of output   \n```\n\n----------------------------------------\n\nTITLE: Creating and Populating a Test Table in Accumulo Shell\nDESCRIPTION: This snippet shows how to create a new table called 'input' and insert test data using the Accumulo shell. It creates two entries with row keys 'dogrow' and 'catrow'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/regex.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert dogrow dogcf dogcq dogvalue\nusername@instance> insert catrow catcf catcq catvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Installing Uno for Single-Node Accumulo Setup\nDESCRIPTION: Commands to clone and set up the Uno repository for single-node Accumulo installation\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2017-04-21-introducing-uno-and-muchos.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/apache/fluo-uno.git\ncd fluo-uno\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Classpath\nDESCRIPTION: Bash script to configure the Accumulo classpath with necessary S3 dependencies and JAR files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-10-accumulo-S3-notes.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nCLASSPATH=\"${conf}:${lib}/*:${HADOOP_CONF_DIR}:${ZOOKEEPER_HOME}/*:${HADOOP_HOME}/share/hadoop/client/*\"\nCLASSPATH=\"${CLASSPATH}:/somedir/hadoop-aws-relocated.3.2.0.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/tools/lib/aws-java-sdk-bundle-1.11.375.jar\"\n# The following are dependencies needed by by the previous jars and are subject to change\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jaxb-api-2.2.11.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar\"\nCLASSPATH=\"${CLASSPATH}:${HADOOP_HOME}/share/hadoop/common/lib/commons-lang3-3.7jar\"\nexport CLASSPATH\n```\n\n----------------------------------------\n\nTITLE: Compact Command for Bulk Imported Files\nDESCRIPTION: Shell command example that compacts all bulk imported files in a table using a regular expression pattern.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2015-05-18-accumulo-1.7.0.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncompact -t foo --sf-ename I.*\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table with Aggregation\nDESCRIPTION: Shell commands to create an Accumulo table named 'wordCount' with string summation aggregation on the count column family.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/mapred.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.3.x-incubating\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable wordCount -a count=org.apache.accumulo.core.iterators.aggregation.StringSummation \nusername@instance wordCount> quit\n```\n\n----------------------------------------\n\nTITLE: Configuring HDFS NameNode Services in hdfs-site.xml\nDESCRIPTION: HDFS configuration for multiple HA nameservices, including RPC addresses, HTTP addresses, and shared edit directories.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-06-25-scaling-accumulo-with-multivolume-support.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>dfs.nameservices</name>\n  <value>nameserviceA,nameserviceB</value>\n</property>\n<property>\n  <name>dfs.ha.namenodes.nameserviceA</name>\n  <value>nn1,nn2</value>\n</property>\n<property>\n  <name>dfs.ha.namenodes.nameserviceB</name>\n  <value>nn3,nn4</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.nameserviceA.nn1</name>\n  <value>host1:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.nameserviceA.nn2</name>\n  <value>host2:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.nameserviceA.nn1</name>\n  <value>host1:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.nameserviceA.nn2</name>\n  <value>host2:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.nameserviceB.nn3</name>\n  <value>host3:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.rpc-address.nameserviceB.nn4</name>\n  <value>host4:8020</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.nameserviceB.nn3</name>\n  <value>host3:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.http-address.nameserviceB.nn4</name>\n  <value>host4:50070</value>\n</property>\n<property>\n  <name>dfs.namenode.shared.edits.dir.nameserviceA.nn1</name>\n  <value>qjournal://jHost1:8485;jHost2:8485;jHost3:8485/nameserviceA</value>\n</property>\n<property>\n  <name>dfs.namenode.shared.edits.dir.nameserviceA.nn2</name>\n  <value>qjournal://jHost1:8485;jHost2:8485;jHost3:8485/nameserviceA</value>\n</property>\n<property>\n  <name>dfs.namenode.shared.edits.dir.nameserviceB.nn3</name>\n  <value>qjournal://jHost1:8485;jHost2:8485;jHost3:8485/nameserviceB</value>\n</property>\n<property>\n  <name>dfs.namenode.shared.edits.dir.nameserviceB.nn4</name>\n  <value>qjournal://jHost1:8485;jHost2:8485;jHost3:8485/nameserviceB</value>\n</property>\n<property>\n  <name>dfs.client.failover.proxy.provider.nameserviceA</name>\n  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n</property>\n<property>\n  <name>dfs.client.failover.proxy.provider.nameserviceB</name>\n  <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n</property>\n<property>\n  <name>dfs.ha.automatic-failover.enabled.nameserviceA</name>\n  <value>true</value>\n</property>\n<property>\n  <name>dfs.ha.automatic-failover.enabled.nameserviceB</name>\n  <value>true</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Viewing ZooKeeper Property Mappings\nDESCRIPTION: Example showing how to display all configuration properties for system, namespaces and tables using the zoo-info-viewer tool.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo zoo-info-viewer  --print-props\n\n-----------------------------------------------\nReport Time: 2022-05-31T21:18:11.562867Z\n-----------------------------------------------\nZooKeeper properties for instance ID: 9cc9465d-b7bb-42c2-919b-ddf74b610c82\n\nName: System, Data Version:0, Data Timestamp: 2022-05-31T15:51:52.772265Z:\n-- none --\n\nNamespace:\nName: , Data Version:0, Data Timestamp: 2022-05-31T15:51:53.015613Z:\n-- none --\n```\n\n----------------------------------------\n\nTITLE: Triggering Major Compaction for Locality Groups in Accumulo\nDESCRIPTION: Shows how to manually trigger a major compaction process to physically move column families into their newly assigned locality groups.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance mytable> compact -t mytable\n```\n\n----------------------------------------\n\nTITLE: Querying Table with Bloom Filters\nDESCRIPTION: This command performs 500 lookups against the 'bloom_test2' table (with bloom filters) using RandomBatchScanner with seed 7, demonstrating improved performance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test2 --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Starting and Enabling ZooKeeper Service on Fedora\nDESCRIPTION: These commands start the ZooKeeper service and enable it to run on system boot.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start zookeeper.service\nsudo systemctl enable zookeeper.service\n```\n\n----------------------------------------\n\nTITLE: Building Relocated Hadoop-AWS JAR\nDESCRIPTION: Bash commands to build a relocated hadoop-aws jar as a workaround for HADOOP-16080 issue.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-09-10-accumulo-S3-notes.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p /tmp/haws-reloc\ncd /tmp/haws-reloc\n# get the Maven pom file that builds a relocated jar\nwget https://gist.githubusercontent.com/keith-turner/f6dcbd33342732e42695d66509239983/raw/714cb801eb49084e0ceef5c6eb4027334fd51f87/pom.xml\nmvn package -Dhadoop.version=<your hadoop version>\n# the new jar will be in target\nls target/\n```\n\n----------------------------------------\n\nTITLE: Cleanup API Usage for PermGen Issues\nDESCRIPTION: Using the CleanUp utility class to prevent memory leaks when using Accumulo client API in application containers\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-03-06-accumulo-1.5.1.md#2025-04-11_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\norg.apache.accumulo.core.util.CleanUp\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Bloom Filters in Accumulo Shell\nDESCRIPTION: This snippet shows how to create a table named 'bloom_test' and enable bloom filters using the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test\nusername@instance bloom_test> config -t bloom_test -s table.bloom.enabled=true\nusername@instance bloom_test> exit\n```\n\n----------------------------------------\n\nTITLE: Importing RFiles into a New Accumulo Instance from an Old Instance with ZooKeeper Failure\nDESCRIPTION: Shell command for importing RFiles from an old Accumulo instance into a newly created instance after ZooKeeper failure. The command imports files from a specified directory path without resetting timestamps, with failures tracked in a separate directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nuser@instance new_table> importdirectory /new-table-1 /new-table-1-failures false\n```\n\n----------------------------------------\n\nTITLE: Accessing Accumulo Monitor via Text-Based Browser\nDESCRIPTION: This command demonstrates how to use the 'links' text-based browser to access the Accumulo monitor on localhost port 9995. It's useful for checking the monitor when GUI access is not available.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ links http://localhost:9995\n```\n\n----------------------------------------\n\nTITLE: Querying Accumulo Table with Bloom Filters\nDESCRIPTION: This command performs 500 lookups on the 'bloom_test2' table (with bloom filters) using RandomBatchScanner.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test2 --num 500 --min 0 --max 1000000000 --size 50 --scanThreads 20 --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Testing FooFilter with Data Insertions\nDESCRIPTION: Commands to insert test data and verify the filter is working by showing that rows containing 'foo' are suppressed in the scan results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/classpath.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ninsert foo1 f1 q1 v1\ninsert noo1 f1 q1 v2\nscan\n```\n\n----------------------------------------\n\nTITLE: Setting Up Accumulo with Proxy\nDESCRIPTION: This command sets up Accumulo using Uno, which will also start the Accumulo Proxy after Accumulo is running.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-12-16-accumulo-proxy.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuno setup accumulo\n```\n\n----------------------------------------\n\nTITLE: Configuring Grafana Dashboard JSON\nDESCRIPTION: Grafana configuration to load dashboard templates from a directory\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2018-03-22-view-metrics-in-grafana.md#2025-04-11_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\n[dashboards.json]\nenabled = true\npath = <GRAFANA_HOME>/dashboards\n```\n\n----------------------------------------\n\nTITLE: Defining Metadata for Apache Accumulo 1.5.0 Release Page in Markdown\nDESCRIPTION: This snippet defines the metadata for the Apache Accumulo 1.5.0 release page using YAML front matter in Markdown. It specifies the title, sortable version number, and indicates that this version is archived.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2013-05-25-accumulo-1.5.0.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Apache Accumulo 1.5.0\nsortableversion: '01.05.00'\narchived: true\n---\n```\n\n----------------------------------------\n\nTITLE: Creating Table with Bloom Filters in Accumulo\nDESCRIPTION: This snippet shows how to create a table named 'bloom_test2' with bloom filters enabled and set the major compaction ratio.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/bloom.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test2\nusername@instance bloom_test2> config -t bloom_test2 -s table.compaction.major.ratio=7\nusername@instance bloom_test2> config -t bloom_test2 -s table.bloom.enabled=true\nusername@instance bloom_test2> exit\n```\n\n----------------------------------------\n\nTITLE: Configuring Scan Executors in Accumulo\nDESCRIPTION: Basic configuration for creating a named scan executor with specified thread count. This is the primary property needed to define a new scan executor.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/scan-executors.md#2025-04-11_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ntserver.scan.executors.<name>.threads=<number>\n```\n\n----------------------------------------\n\nTITLE: Listing and Deleting Tablet Server Locks in ZooKeeper\nDESCRIPTION: These commands demonstrate how to list and delete tablet server locks in ZooKeeper. This can be useful when dealing with 'stuck' tablet servers that won't shut down normally.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.server.util.TabletServerLocks --list\n                      127.0.0.1:9997 TSERV_CLIENT=127.0.0.1:9997\n$ accumulo org.apache.accumulo.server.util.TabletServerLocks -delete 127.0.0.1:9997\n$ accumulo org.apache.accumulo.server.util.TabletServerLocks -list\n                      127.0.0.1:9997             null\n```\n\n----------------------------------------\n\nTITLE: Executing Hadoop DistCp\nDESCRIPTION: Command to copy the exported table files using Hadoop's distributed copy utility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/export.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop distcp -f /tmp/table1_export/distcp.txt /tmp/table1_export_dest\n```\n\n----------------------------------------\n\nTITLE: Viewing Histogram Results in Accumulo\nDESCRIPTION: Accumulo shell command to scan the 'dataTable' again to see the histogram data stored in the 'info' column family after running the CharacterHistogram MapReduce job.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filedata.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Inserting Sample Data into Accumulo Table Using Shell\nDESCRIPTION: This snippet demonstrates how to connect to the Accumulo shell and insert sample data into a table named 'input'. It creates the table and inserts three key-value pairs with different row IDs and column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/tabletofile.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable input\nusername@instance> insert dog cf cq dogvalue\nusername@instance> insert cat cf cq catvalue\nusername@instance> insert junk family qualifier junkvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Restarting Hadoop NameNode Service\nDESCRIPTION: Command to restart the Hadoop NameNode service when it's listening on the loopback address, which is a known issue. This may be necessary when Accumulo services fail to start.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl restart hadoop-namenode.service\n```\n\n----------------------------------------\n\nTITLE: Installing Jekyll Dependencies with Bundler\nDESCRIPTION: Command to use Bundler to install Jekyll and all other dependencies needed to run the website locally based on the project's Gemfile.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbundle install\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with Bloom Filters in Accumulo Shell\nDESCRIPTION: This snippet shows how to create a table named 'bloom_test' with bloom filters enabled using the Accumulo shell. It includes setting authentication, creating the table, and configuring bloom filters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.4.x\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> setauths -u username -s exampleVis\nusername@instance> createtable bloom_test\nusername@instance bloom_test> config -t bloom_test -s table.bloom.enabled=true\nusername@instance bloom_test> exit\n```\n\n----------------------------------------\n\nTITLE: Listing HDFS Files for Accumulo Table\nDESCRIPTION: This command lists the files in HDFS for the 'bloom_test2' table, showing the three map files created during the example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bloom.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -lsr /accumulo/tables/o8\n```\n\n----------------------------------------\n\nTITLE: Running HDFS Filesystem Check\nDESCRIPTION: This command demonstrates how to run a filesystem check (fsck) on the HDFS directory used by Accumulo. It's useful for diagnosing HDFS-related issues affecting Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fsck /accumulo\n```\n\n----------------------------------------\n\nTITLE: Configuring RegexGroupBalancer\nDESCRIPTION: Sets up the RegexGroupBalancer with pattern matching for two digits and default group configuration. The regex pattern captures the first two digits for grouping tablets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/rgbalancer.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nroot@accumulo testRGB> config -t testRGB -s table.custom.balancer.group.regex.pattern=(\\\\d\\\\d).*\nroot@accumulo testRGB> config -t testRGB -s table.custom.balancer.group.regex.default=04\nroot@accumulo testRGB> config -t testRGB -s table.balancer=org.apache.accumulo.server.master.balancer.RegexGroupBalancer\n```\n\n----------------------------------------\n\nTITLE: Initializing Data in Accumulo Shell\nDESCRIPTION: Commands to create a table and insert sample data using the Accumulo shell interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/rowhash.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.7.4\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert a-row cf cq value\nusername@instance> insert b-row cf cq value\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Displaying Accumulo 2.0.0 Cluster Command Usage\nDESCRIPTION: Demonstrates the usage information for the new accumulo-cluster command in Accumulo 2.0.0.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-11-16-simpler-scripts-and-config.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ ./accumulo-2.0.0/bin/accumulo-cluster\n\nUsage: accumulo-cluster <command> (<argument> ...)\n\nCommands:\n  create-config       Creates cluster config\n  start               Starts Accumulo cluster\n  stop                Stops Accumulo cluster\n  start-non-tservers  Starts all services except tservers\n  start-tservers      Starts all tservers on cluster\n  stop-tservers       Stops all tservers on cluster\n  start-here          Starts all services on this node\n  stop-here           Stops all services on this node\n```\n\n----------------------------------------\n\nTITLE: Accessing Shell in Docker Container\nDESCRIPTION: Command to run a Docker container with interactive shell access, mounting the current working directory to allow modification of Gemfile and Gemfile.lock.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -v \"$PWD\":/mnt/workdir -it webdev /bin/bash\n```\n\n----------------------------------------\n\nTITLE: Performing Queries for Non-Existent Entries with Bloom Filters\nDESCRIPTION: This snippet shows how bloom filters accelerate lookups for non-existent entries. Using seed 8 results in queries that find nothing, and the bloom filters significantly increase performance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -s 8 instance zookeepers username password bloom_test 500 0 1000000000 50 20 exampleVis\nGenerating 500 random queries...finished\n2212.39 lookups/sec   0.23 secs\nnum results : 0\nDid not find 500 rows\nGenerating 500 random queries...finished\n4464.29 lookups/sec   0.11 secs\nnum results : 0\nDid not find 500 rows\n```\n\n----------------------------------------\n\nTITLE: Viewing the Regex Query Results\nDESCRIPTION: This snippet shows how to view the content of the output file containing the results of the regex query. It displays the matching row that starts with 'dog'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/regex.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -text /tmp/output/part-m-00000\ndogrow dogcf:dogcq [] 1357844987994 false   dogvalue\n```\n\n----------------------------------------\n\nTITLE: Managing FATE Transactions from Accumulo Shell (pre-2.1)\nDESCRIPTION: Shell commands for listing and deleting FATE transactions in Accumulo versions prior to 2.1. Used when outstanding FATE transactions prevent a successful Accumulo upgrade.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nfate print\nfate delete\n```\n\n----------------------------------------\n\nTITLE: Enabling Bloom Filters in Accumulo\nDESCRIPTION: Shows how to enable bloom filters for an Accumulo table. Bloom filters improve lookup performance by creating a small in-memory data structure that can determine if a file might contain a given key before opening it.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Configuration.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nuser@myinstance> config -t mytable -s table.bloom.enabled=true\n```\n\n----------------------------------------\n\nTITLE: Indexing Java Files into Accumulo Shard Table\nDESCRIPTION: Bash commands to find Java files in the Accumulo source code and index them into the 'shard' table using the Index.java program.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/shard.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ cd /local/username/workspace/accumulo/\n$ find core/src server/src -name \"*.java\" | xargs ./bin/accumulo org.apache.accumulo.examples.simple.shard.Index -i instance -z zookeepers -t shard -u username -p password --partitions 30\n```\n\n----------------------------------------\n\nTITLE: Running Jekyll Local Development Server\nDESCRIPTION: Command to serve the site contents using Jekyll's built-in webserver with watch mode enabled to automatically rebuild pages when changes are detected.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbundle exec jekyll serve -w\n```\n\n----------------------------------------\n\nTITLE: Setting Up Accumulo Connection in Integration Tests with MiniAccumuloInstance\nDESCRIPTION: Java code example showing how to connect to a MiniAccumuloInstance in an integration test. This demonstrates how to set up a connection to the instance created by the Accumulo Maven Plugin.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-05-02-accumulo-1.6.0.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nprivate static Connector conn;\n\n@BeforeClass\npublic static void setUp() throws Exception {\n  String instanceName = \"plugin-it-instance\";\n  Instance instance = new MiniAccumuloInstance(instanceName, new File(\"target/accumulo-maven-plugin/\" + instanceName));\n  conn = instance.getConnector(\"root\", new PasswordToken(\"ITSecret\"));\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Bundler for Ruby Gem Management\nDESCRIPTION: Command to install Bundler, a dependency management tool for Ruby projects. Note that this is not necessary for Ruby versions 2.6 and later as Bundler is included by default.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# not necessary in Ruby >2.6, since it is a default gem since 2.6\ngem install bundler\n```\n\n----------------------------------------\n\nTITLE: Querying with Same Seed RandomBatchScanner\nDESCRIPTION: Commands showing query performance for existing values using RandomBatchScanner with the same seed used for insertion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/bloom.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.client.RandomBatchScanner -s 7 instance zookeepers username password bloom_test 500 0 1000000000 50 20 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Running Bash Commands in Accumulo Home Directory\nDESCRIPTION: Demonstrates the convention for running bash commands in the Accumulo home directory. Commands are prefixed with '$' and assumed to be executed from $ACCUMULO_HOME.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/index.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ command\n```\n\n----------------------------------------\n\nTITLE: Repl Section Key Format\nDESCRIPTION: Format for the repl section key-value pairs that track WAL files needing replication to remote Accumulo tables. The key contains the HDFS URI to the WAL file and local table ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_13\n\nLANGUAGE: text\nCODE:\n```\n<HDFS_uri_to_WAL> repl:<local_table_id> [] -> <protobuf>\n```\n\n----------------------------------------\n\nTITLE: Setting Up Initial Environment by Removing Existing Resources in Apache Accumulo\nDESCRIPTION: Deletes an existing table and user to start with a clean state. This ensures the demonstration begins without any pre-existing configurations that might affect the results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().delete(\"GothamPD\");\nclient.securityOperations().dropLocalUser(\"commissioner\");\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Authorizations and Scanning in Accumulo\nDESCRIPTION: This snippet demonstrates setting multiple authorizations for a user and scanning with different authorization sets.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/visibility.md#2025-04-11_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ********\nroot@instance vistest> setauths -s A,B,broccoli -u username\nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nusername@instance vistest> scan -s B\nusername@instance vistest>\n```\n\n----------------------------------------\n\nTITLE: Iterating Through and Displaying Accumulo Releases with Year Grouping\nDESCRIPTION: Loops through all releases sorted by date in reverse order and groups them by year with appropriate headers. Each release is displayed with its date, status badges, and a link to its detail page. The code handles different release states (draft, archived, and normal).\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/release.md#2025-04-11_snippet_1\n\nLANGUAGE: Liquid\nCODE:\n```\n<div>\n{% assign all_releases = site.categories.release | sort: 'date' | reverse %}\n{% for release in all_releases %}\n  {% assign current_release_year = release.date | date: \"%Y\" %}\n  {% if forloop.first %}\n    {% assign header_year = current_release_year %}\n  <hr>\n  <h3>{{ header_year }}</h3>\n  {% elsif current_release_year != header_year %}\n    {% assign header_year = current_release_year %}\n  <hr>\n  <h3>{{ header_year }}</h3>\n  {% endif %}\n  {% assign release_link = '&nbsp;<a href=\"' | append: site.baseurl | append: release.url | append: '\">' | append: release.title | append: '</a>' %}\n  {% if release.LTM %}{% assign ltm_or_not = ltm_btn %}{% else %}{% assign ltm_or_not = nonltm_btn %}{% endif %}\n  <div class=\"row\" style=\"margin-top: 15px; font-family: monospace\">\n    <div class=\"col-md-1\">{{ release.date | date: \"%b&nbsp;%d\" }}</div>\n    <div class=\"col-md-10\">{% if release.draft %}\n      {{ draft_btn }}&nbsp;{{ ltm_or_not }}<em><strong>{{ release_link }}</strong></em>\n    {% elsif release.archived or release.archived_critical %}\n      {{ archived_btn }}{{ release_link }}\n    {% else %}\n      {{ ltm_or_not }}<strong>{{ release_link }}</strong>\n    {% endif %}</div>\n  </div>\n{% endfor %}\n</div>\n```\n\n----------------------------------------\n\nTITLE: Defining Status Badges in Liquid for Accumulo Releases\nDESCRIPTION: Creates Liquid variables that define HTML badges for different release statuses including archived, draft, LTM (Long-Term Maintenance), and non-LTM. These badges will be used to visually indicate the status of each release.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/release.md#2025-04-11_snippet_0\n\nLANGUAGE: Liquid\nCODE:\n```\n{% assign archived_btn = '<a href=\"https://archive.apache.org/dist/accumulo/\"><span class=\"badge bg-secondary\">Archive</span></a>' %}\n{% assign draft_btn = '<span class=\"badge bg-danger\">&nbsp;DRAFT!&nbsp;</span>' %}\n{% assign ltm_btn = '<a href=\"' | append: site.baseurl | append: '/contributor/versioning#LTM\"><span class=\"badge bg-success\">&nbsp;&nbsp;LTM&nbsp;&nbsp;</span></a>' %}\n{% assign nonltm_btn = '<a href=\"' | append: site.baseurl | append: '/contributor/versioning#LTM\"><span class=\"badge bg-warning\">non-LTM</span></a>' %}\n```\n\n----------------------------------------\n\nTITLE: Querying with Different Seed RandomBatchScanner\nDESCRIPTION: Commands demonstrating improved query performance for non-existent values using RandomBatchScanner with a different seed.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/bloom.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ ../bin/accumulo org.apache.accumulo.examples.client.RandomBatchScanner -s 8 instance zookeepers username password bloom_test 500 0 1000000000 50 20 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Populating a Table with Multiple Map Files in Accumulo\nDESCRIPTION: This snippet shows the process of inserting three separate batches of data with different seeds into the non-bloom table 'bloom_test1', flushing after each to create separate map files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter -s 7 instance zookeepers username password bloom_test1 1000000 0 1000000000 50 2000000 60000 3 exampleVis\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter -s 8 instance zookeepers username password bloom_test1 1000000 0 1000000000 50 2000000 60000 3 exampleVis\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter -s 9 instance zookeepers username password bloom_test1 1000000 0 1000000000 50 2000000 60000 3 exampleVis\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test1 -w'\n```\n\n----------------------------------------\n\nTITLE: Work Section Key Format\nDESCRIPTION: Format for the work section key-value pairs that track WAL replication progress to specific remote Accumulo tables. Includes HDFS URI and replication target information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_14\n\nLANGUAGE: text\nCODE:\n```\n<HDFS_uri_to_WAL> work:<replication_target> [] -> <protobuf>\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo as the accumulo User\nDESCRIPTION: This command initializes Accumulo using the accumulo system user, which is required for proper permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsudo -u accumulo accumulo init\n```\n\n----------------------------------------\n\nTITLE: Inserting Data into Accumulo Table with Bloom Filters\nDESCRIPTION: This set of commands inserts data into 'bloom_test2' table using RandomBatchWriter with different seeds and flushes the table after each insertion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n$ ARGS=\"-i instance -z zookeepers -u username -p password -t bloom_test2 --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\"\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 8 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 9 $ARGS\n$ ./bin/accumulo shell -u username -p password -e 'flush -t bloom_test2 -w'\n```\n\n----------------------------------------\n\nTITLE: Setting GEM_HOME in Bash Environment\nDESCRIPTION: Bash command to set the GEM_HOME environment variable in .bashrc file to install Ruby gems locally rather than system-wide, avoiding conflicts with system packages.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# in .bashrc\nexport GEM_HOME=$HOME/.gem/ruby\n```\n\n----------------------------------------\n\nTITLE: Initializing Accumulo Storage\nDESCRIPTION: Command to initialize Accumulo's storage locations in Zookeeper and HDFS, setting up the instance name and root user password.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo init\n```\n\n----------------------------------------\n\nTITLE: Querying Indexed Files for Specific Terms\nDESCRIPTION: Command to execute the Query.java program, searching for files containing the terms 'foo' and 'bar' in the indexed documents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query -i instance -z zookeepers -t shard -u username -p password foo bar\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorization in Accumulo Shell\nDESCRIPTION: Command to set the 'exampleVis' authorization for a user, which is required before running the batch writing and scanning examples.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/batch.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u root -e \"setauths -u username -s exampleVis\"\n```\n\n----------------------------------------\n\nTITLE: Cloning Tables in Accumulo\nDESCRIPTION: The clonetable command creates a new table as a copy of an existing one. It allows excluding specific properties and setting initial properties for the new table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nusage: clonetable <current table name> <new table name> [-?] [-e <arg>] [-nf] [-s   \n          <arg>]   \ndescription: clone a table   \n  -?,-help  display this help   \n  -e,-exclude <arg>  properties that should not be copied from source table.   \n          Expects <prop>,<prop>   \n  -nf,-noFlush  do not flush table data in memory before cloning.   \n  -s,-set <arg>  set initial properties before the table comes online. Expects   \n          <prop>=<value>,<prop>=<value>\n```\n\n----------------------------------------\n\nTITLE: Starting Accumulo Shell with Mock Instance\nDESCRIPTION: Command to start the Accumulo shell using the Mock Accumulo instance. This allows interactive testing using the shell interface without a real Accumulo installation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Development_Clients.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell --fake -u root -p ''\n```\n\n----------------------------------------\n\nTITLE: Querying Indexed Files for Specific Terms\nDESCRIPTION: Command to execute the Query.java program, searching for files containing the terms 'foo' and 'bar' in the indexed documents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query -i instance -z zookeepers -t shard -u username -p password foo bar\n```\n\n----------------------------------------\n\nTITLE: Viewing Iterator Configuration Settings in Accumulo\nDESCRIPTION: This snippet demonstrates how to view the current iterator settings for a table using the config command with the iterator filter. The output shows the configured iterators across all scopes with their priorities and parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/filter.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance filtertest> config -t filtertest -f iterator\n---------+---------------------------------------------+---------------------------------------------------------------------------\nSCOPE    | NAME                                        | VALUE\n---------+---------------------------------------------+---------------------------------------------------------------------------\ntable    | table.iterator.majc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.majc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.majc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.majc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.minc.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.minc.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.minc.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.minc.vers.opt.maxVersions .. | 1\ntable    | table.iterator.scan.myfilter .............. | 10,org.apache.accumulo.core.iterators.user.AgeOffFilter\ntable    | table.iterator.scan.myfilter.opt.ttl ...... | 30000\ntable    | table.iterator.scan.vers .................. | 20,org.apache.accumulo.core.iterators.user.VersioningIterator\ntable    | table.iterator.scan.vers.opt.maxVersions .. | 1\n---------+---------------------------------------------+---------------------------------------------------------------------------\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Documenting Accumulo Shell Command: formatter\nDESCRIPTION: The 'formatter' command specifies a formatter to use for displaying table entries. It allows setting, listing, and removing formatters for specific tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_28\n\nLANGUAGE: text\nCODE:\n```\nusage: formatter [-?] -f <className> | -l | -r  [-t <table>]\ndescription: specifies a formatter to use for displaying table entries\n  -?,-help  display this help\n  -f,-formatter <className>  fully qualified name of the formatter class to use\n  -l,-list  display the current formatter\n  -r,-remove  remove the current formatter\n  -t,-table <table>  table to set the formatter on\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests for Accumulo Examples\nDESCRIPTION: Executes Maven commands to run integration tests on the Accumulo Examples project using the release candidate version. The temporary Maven settings file is used to configure the build.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/testing-release.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ mvn -s /tmp/accumulo-rc-maven.xml clean verify -Daccumulo.version=$RC_VERSION\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo Shell\nDESCRIPTION: Command to create the 'batchtest1' table in Accumulo, which is required before running the batch examples.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -e \"createtable batchtest1\"\n```\n\n----------------------------------------\n\nTITLE: Finding Offline Tablets in Accumulo\nDESCRIPTION: The FindOfflineTablets utility helps locate tablets that are offline in Accumulo, showing their location information and recovery requirements.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.server.util.FindOfflineTablets\n2<<@(null,null,localhost:9997) is UNASSIGNED  #walogs:2\n```\n\n----------------------------------------\n\nTITLE: Kerberos Communication Error Stack Trace\nDESCRIPTION: Detailed stack trace showing inter-process communication failure due to Kerberos authentication issues\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_14\n\nLANGUAGE: java\nCODE:\n```\n2015-01-12 14:47:27,055 [transport.TSaslTransport] ERROR: SASL negotiation failure\njavax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Server not found in Kerberos database (7) - LOOKING_UP_SERVER)]\n```\n\n----------------------------------------\n\nTITLE: Bootstrapping Accumulo Configuration\nDESCRIPTION: Command to run the interactive configuration script that populates the conf directory with initial configuration files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./bin/bootstrap_config.sh\n```\n\n----------------------------------------\n\nTITLE: Scanning the Table in Accumulo Shell\nDESCRIPTION: Shell commands to select a table and scan all its entries. First selects the 'hellotable' and then performs the scan operation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nusername@instance> table hellotable\nusername@instance hellotable> scan\n```\n\n----------------------------------------\n\nTITLE: Configuring AccumuloOutputFormat for MapReduce Jobs\nDESCRIPTION: Example of configuring AccumuloOutputFormat for a MapReduce job. Sets user credentials, whether to create tables if they don't exist, default table name, and ZooKeeper instance information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nboolean createTables = true;\nString defaultTable = \"mytable\";\n\nAccumuloOutputFormat.setOutputInfo(job,\n        \"user\",\n        \"passwd\".getBytes(),\n        createTables,\n        defaultTable);\n\nAccumuloOutputFormat.setZooKeeperInstance(job, \"myinstance\",\n        \"zooserver-one,zooserver-two\");\n```\n\n----------------------------------------\n\nTITLE: Running Specific Unit Tests with Maven\nDESCRIPTION: Command to run specific unit tests instead of the entire test suite. The failIfNoTests parameter prevents build failure if no tests match the pattern.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmvn package -Dtest=MyTest -DfailIfNoTests=false\n```\n\n----------------------------------------\n\nTITLE: Setting User Authorizations in Accumulo Shell\nDESCRIPTION: Commands to grant the 'exampleVis' authorization to a user in Accumulo, which is required before running the batch examples.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/batch.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u root\n> setauths -u username -s exampleVis\n> exit\n```\n\n----------------------------------------\n\nTITLE: Viewing Recent Service Logs\nDESCRIPTION: Command to view system logs for a specific service from the last 10 minutes using journalctl. Helps troubleshoot recent service issues.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nsudo journalctl -u <ServiceName> --since '10 minutes ago'\n```\n\n----------------------------------------\n\nTITLE: Proxy Server Configuration for Accumulo\nDESCRIPTION: A sample configuration file for setting up an Accumulo proxy server, which allows interaction with Accumulo from languages other than Java. Includes essential properties like protocol factory, token class, port, instance, and zookeepers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\nprotocolFactory=org.apache.thrift.protocol.TCompactProtocol$Factory\ntokenClass=org.apache.accumulo.core.client.security.tokens.PasswordToken\nport=42424\ninstance=test\nzookeepers=localhost:2181\n```\n\n----------------------------------------\n\nTITLE: Starting Specific Accumulo Service on a Host\nDESCRIPTION: These commands show how to SSH into a specific host and start a tablet server service using the 'accumulo-service' script. This is useful for restarting individual services on specific nodes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ssh host_with_dead_process\n$ accumulo-service tserver start\n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest With Isolation in Accumulo\nDESCRIPTION: This command runs the InterferenceTest example with isolation enabled for 5000 iterations. It shows how isolation prevents inconsistent views, as no errors are reported when the scanner can only see complete row mutations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/isolation.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000 --isolated\n```\n\n----------------------------------------\n\nTITLE: Scanning Data with SummingCombiner Applied (Java)\nDESCRIPTION: This snippet shows the result of scanning the table after applying the SummingCombiner iterator. The values in the 'hero:villainsCaptured' column are now summed, showing the total number of villains captured by each hero.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\njshell> try ( org.apache.accumulo.core.client.Scanner scan = client.createScanner(\"GothamCrimeStats\", Authorizations.EMPTY)) {\n   ...>   for(Map.Entry<Key, Value> entry : scan) {\n   ...>     System.out.printf(\"Key : %-52s  Value : %s\\n\", entry.getKey(), entry.getValue());\n   ...>   }\n   ...> }\nKey : id0001 hero:alias [] 1654699186182 false              Value : Batman\nKey : id0001 hero:villainsCaptured [] 1654699186182 false   Value : 8\nKey : id0002 hero:alias [] 1654699186182 false              Value : Robin\nKey : id0002 hero:villainsCaptured [] 1654699186182 false   Value : 3\n```\n\n----------------------------------------\n\nTITLE: Running Bulk Ingest Commands in Apache Accumulo\nDESCRIPTION: Series of shell commands to demonstrate bulk ingestion process including table setup, test data generation, bulk import, and data verification. The process creates a table 'test_bulk' with split points, generates 1000 test records, performs bulk ingestion, and verifies the data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.mapreduce.bulk.SetupTable instance zookeepers username password test_bulk row_00000333 row_00000666\n$ ./bin/accumulo org.apache.accumulo.examples.mapreduce.bulk.GenerateTestData 0 1000 bulk/test_1.txt\n\n$ ./bin/tool.sh lib/accumulo-examples-*[^c].jar org.apache.accumulo.examples.mapreduce.bulk.BulkIngestExample instance zookeepers username password test_bulk bulk tmp/bulkWork\n$ ./bin/accumulo org.apache.accumulo.examples.mapreduce.bulk.VerifyIngest instance zookeepers username password test_bulk 0 1000\n```\n\n----------------------------------------\n\nTITLE: Querying Terms in Accumulo Shard\nDESCRIPTION: Command to search for files containing specific terms ('foo' and 'bar') in the indexed documents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.shard.Query instance zookeepers shard username password foo bar\n```\n\n----------------------------------------\n\nTITLE: Setting performance options for AccumuloOutputFormat in Java\nDESCRIPTION: Optional configuration for AccumuloOutputFormat that sets performance-related parameters including maximum latency and mutation buffer size. These parameters can affect the throughput and latency of the write operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Analytics.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nAccumuloOutputFormat.setMaxLatency(job, 300); // milliseconds\nAccumuloOutputFormat.setMaxMutationBufferSize(job, 5000000); // bytes\n```\n\n----------------------------------------\n\nTITLE: Running File Count Analysis\nDESCRIPTION: Command to count the number of direct children and descendants in the directory structure and write results back to the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/dirlist.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Running RegexExample MapReduce Job with Row Pattern Matching\nDESCRIPTION: This command executes the RegexExample MapReduce job to search for rows starting with 'dog' in the input table. It uses the accumulo-examples-simple.jar and specifies connection parameters, the regex pattern, and output location.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/regex.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RegexExample -u user -p passwd -i instance -t input --rowRegex 'dog.*' --output /tmp/output\n```\n\n----------------------------------------\n\nTITLE: Decommissioning Nodes from Accumulo Cluster\nDESCRIPTION: Command to gracefully shutdown and remove nodes from an Accumulo cluster. Accumulo will automatically rebalance tablets across remaining servers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Administration.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ACCUMULO_HOME/bin/accumulo admin stop <host(s)> {<host> ...}\n```\n\n----------------------------------------\n\nTITLE: Accumulo JShell Welcome Screen\nDESCRIPTION: The welcome screen displayed when launching Accumulo JShell, showing the pre-loaded Accumulo client object and JShell version information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/getting-started.md#2025-04-11_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nPreparing JShell for Apache Accumulo\n\nUse 'client' to interact with Accumulo\n\n|  Welcome to JShell -- Version 11\n|  For an introduction type: /help intro\n\njshell>\n```\n\n----------------------------------------\n\nTITLE: Running Bulk Ingest Process in Apache Accumulo\nDESCRIPTION: A sequence of bash commands demonstrating the complete bulk ingest workflow. The process includes setting up a table with two split points, generating 1000 rows of test data, performing the bulk ingest operation, and verifying the data was correctly loaded.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ PKG=org.apache.accumulo.examples.simple.mapreduce.bulk\n$ ARGS=\"-i instance -z zookeepers -u username -p password\"\n$ ./bin/accumulo $PKG.SetupTable $ARGS -t test_bulk row_00000333 row_00000666\n$ ./bin/accumulo $PKG.GenerateTestData --start-row 0 --count 1000 --output bulk/test_1.txt\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar $PKG.BulkIngestExample $ARGS -t test_bulk --inputDir bulk --workDir tmp/bulkWork\n$ ./bin/accumulo $PKG.VerifyIngest $ARGS -t test_bulk --start-row 0 --count 1000\n```\n\n----------------------------------------\n\nTITLE: Managing Multiple TabletServers with accumulo-cluster\nDESCRIPTION: Commands showing how to start and stop multiple tablet servers per node using the accumulo-cluster script.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nNUM_TSERVERS=2 ./bin/accumulo-cluster start-here\nNUM_TSERVERS=2 ./bin/accumulo-cluster stop-here\n```\n\nLANGUAGE: bash\nCODE:\n```\nNUM_TSERVERS=2 ./bin/accumulo-cluster start\nNUM_TSERVERS=2 ./bin/accumulo-cluster stop\n```\n\n----------------------------------------\n\nTITLE: Running Terasort Data Ingest in Accumulo with MapReduce\nDESCRIPTION: Command to run the TeraSortIngest tool which generates random data and stores it in Accumulo. The command allows configuring data generation parameters including count, key size, value size, target table, and number of splits.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/terasort.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TeraSortIngest \\\n-i instance -z zookeepers -u user -p password \\\n--count 10 \\\n--minKeySize 10 \\\n--maxKeySize 10 \\\n--minValueSize 78 \\\n--maxValueSize 78 \\\n--table sort \\\n--splits 10 \\\n```\n\n----------------------------------------\n\nTITLE: Running Terasort Data Ingest in Accumulo with MapReduce\nDESCRIPTION: Command to run the TeraSortIngest tool which generates random data and stores it in Accumulo. The command allows configuring data generation parameters including count, key size, value size, target table, and number of splits.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/terasort.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.TeraSortIngest \\\n-i instance -z zookeepers -u user -p password \\\n--count 10 \\\n--minKeySize 10 \\\n--maxKeySize 10 \\\n--minValueSize 78 \\\n--maxValueSize 78 \\\n--table sort \\\n--splits 10 \\\n```\n\n----------------------------------------\n\nTITLE: Querying Terms from Accumulo Shard\nDESCRIPTION: Command to query the shard index for documents containing specific terms ('foo' and 'bar').\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/shard.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ cd $ACCUMULO_HOME\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.Query instance zookeepers shard username password foo bar\n```\n\n----------------------------------------\n\nTITLE: Running the RowHash MapReduce Job\nDESCRIPTION: Command to execute the RowHash MapReduce job using Accumulo's tool.sh script. The job reads from the 'input' table and computes hashes for rows that contain the specified column.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/rowhash.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RowHash -u user -p passwd -i instance -t input --column cf:cq\n```\n\n----------------------------------------\n\nTITLE: Running Sequential Batch Writer in Accumulo\nDESCRIPTION: Command to run the SequentialBatchWriter example which writes 10000 entries with sequential rows and random 50-byte values to the batchtest1 table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/batch.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.SequentialBatchWriter instance zookeepers username password batchtest1 0 10000 50 20000000 500 20 exampleVis\n```\n\n----------------------------------------\n\nTITLE: Output from Concurrent Conditional Writes in Accumulo\nDESCRIPTION: Example output showing multiple threads attempting to update an address using conditional writes. The output demonstrates how threads retry when their conditional mutations are rejected, ultimately resulting in a final address that incorporates changes from successful mutations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer-code.md#2025-04-11_snippet_1\n\nLANGUAGE: text\nCODE:\n```\njshell> concurrent_writes()\nGothamPD table already exists...proceeding...\nThread  52 attempting change '   1007 Mountain Dr, Gotham, New York  ' -> '1007 Mountain Dr, Gotham, New York'\nThread  91 attempting change '   1007 Mountain Dr, Gotham, New York  ' -> '   1007 Mountain Dr, Gotham, NY  '\nThread  90 attempting change '   1007 Mountain Dr, Gotham, New York  ' -> '   1007 Mountain Dr, Gotham, New York  '\nThread  90 attempting change '1007 Mountain Dr, Gotham, New York' -> '1007 Mountain Dr, Gotham, New York'\nThread  91 attempting change '1007 Mountain Dr, Gotham, New York' -> '1007 Mountain Dr, Gotham, NY'\nFinal address : '1007 Mountain Dr, Gotham, NY'\n```\n\n----------------------------------------\n\nTITLE: Creating a table with MaxMutationSize constraint in Accumulo Shell\nDESCRIPTION: This snippet shows how to create a table in Accumulo and configure it with the MaxMutationSize constraint that limits the size of mutations that can be ingested into the table. The constraint class is set to org.apache.accumulo.examples.simple.constraints.MaxMutationSize.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/maxmutation.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable test_ingest\nusername@instance test_ingest> config -t test_ingest -s table.constraint.1=org.apache.accumulo.examples.simple.constraints.MaxMutationSize\nusername@instance test_ingest>\n```\n\n----------------------------------------\n\nTITLE: Viewing Filtered Regex Results in HDFS\nDESCRIPTION: This command displays the contents of the part file containing the MapReduce job results, showing the row that matched the regex pattern 'dog.*' with its column family, qualifier, value, and other metadata.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/regex.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -text /tmp/output/output/part-m-00000\ndogrow dogcf:dogcq [] 1357844987994 false    dogvalue\n```\n\n----------------------------------------\n\nTITLE: Importing Iterator Classes in Apache Accumulo (Java)\nDESCRIPTION: This snippet imports the necessary classes for implementing a SummingCombiner iterator, which will be used to aggregate numerical values in the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_4\n\nLANGUAGE: java\nCODE:\n```\njshell> import org.apache.accumulo.core.iterators.user.SummingCombiner;\njshell> import org.apache.accumulo.core.iterators.LongCombiner\n```\n\n----------------------------------------\n\nTITLE: Data Table Schema Example\nDESCRIPTION: Illustration of the data table structure showing how file content is stored using MD5 hashes as row keys, with references to file properties and chunked file content.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/dirlist.md#2025-04-11_snippet_8\n\nLANGUAGE: plaintext\nCODE:\n```\nrow colf:colq [vis]    value\n274af6419a3c4c4a259260ac7017cbf1 refs:e77276a2b56e5c15b540eaae32b12c69\\x00filext [exampleVis]    README\n274af6419a3c4c4a259260ac7017cbf1 refs:e77276a2b56e5c15b540eaae32b12c69\\x00name [exampleVis]    /local/Accumulo.README\n274af6419a3c4c4a259260ac7017cbf1 ~chunk:\\x00\\x0FB@\\x00\\x00\\x00\\x00 [exampleVis]    *******************************************************************************\\x0A1. Building\\x0A\\x0AIn the normal tarball release of accumulo, [truncated]\n274af6419a3c4c4a259260ac7017cbf1 ~chunk:\\x00\\x0FB@\\x00\\x00\\x00\\x01 [exampleVis]\n```\n\n----------------------------------------\n\nTITLE: Verifying Row Hashes in Accumulo Shell\nDESCRIPTION: Commands to scan the 'input' table after the MapReduce job has completed. Shows the original data along with the computed MD5 hashes stored in new columns.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/rowhash.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.6.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> scan -t input\na-row cf:cq []    value\na-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nb-row cf:cq []    value\nb-row cf-HASHTYPE:cq-MD5BASE64 []    IGPBYI1uC6+AJJxC4r5YBA==\nusername@instance>\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo Shell\nDESCRIPTION: Commands to create the 'batchtest1' table in Accumulo that will be used for the batch writing and scanning operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/batch.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username\n> createtable batchtest1\n> exit\n```\n\n----------------------------------------\n\nTITLE: Creating Accumulo Table\nDESCRIPTION: Creates a new table named 'GothamBatch' in Accumulo using the table operations API.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/batch-scanner-code.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclient.tableOperations().create(\"GothamBatch\");\n```\n\n----------------------------------------\n\nTITLE: Running and Interacting with Accumulo Reservation System\nDESCRIPTION: This terminal session demonstrates running the Accumulo Reservation System (ARS) example application. It shows connecting to Accumulo, reserving a room with multiple concurrent users, listing reservations, and canceling reservations. The example highlights how conditional mutations ensure atomic operations when managing concurrent reservation requests.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/reservations.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.reservations.ARS\n>connect test16 localhost root secret ars\n  connected\n>\n  Commands :\n    reserve <what> <when> <who> {who}\n    cancel <what> <when> <who>\n    list <what> <when>\n>reserve room06 20140101 alice bob eve mallory trent\n                   bob : RESERVED\n               mallory : WAIT_LISTED\n                 alice : WAIT_LISTED\n                 trent : WAIT_LISTED\n                   eve : WAIT_LISTED\n>list room06 20140101\n  Reservation holder : bob\n  Wait list : [mallory, alice, trent, eve]\n>cancel room06 20140101 alice\n>cancel room06 20140101 bob\n>list room06 20140101\n  Reservation holder : mallory\n  Wait list : [trent, eve]\n>quit\n```\n\n----------------------------------------\n\nTITLE: Setting Replication Name in Peer Instance Configuration\nDESCRIPTION: Sets the unique identifier for the peer Accumulo instance that will receive replicated data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_6\n\nLANGUAGE: properties\nCODE:\n```\nreplication.name=peer\n```\n\n----------------------------------------\n\nTITLE: Copying JAR File to HDFS in Hadoop\nDESCRIPTION: This command copies the FooFilter.jar file from the local Accumulo test directory to a user directory in HDFS. This JAR contains a filter that suppresses rows containing 'foo'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/classpath.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhadoop fs -copyFromLocal $ACCUMULO_HOME/test/src/test/resources/FooFilter.jar /user1/lib\n```\n\n----------------------------------------\n\nTITLE: Counting Files and Directories in the Archive\nDESCRIPTION: Command to run the FileCount utility which computes the number of children and descendants for each directory. The results are written back to the same directory table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/dirlist.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.dirlist.FileCount -i instance -z zookeepers -u username -p password -t dirTable --auths exampleVis\n```\n\n----------------------------------------\n\nTITLE: Terasort Output Example Data\nDESCRIPTION: Example output from scanning the sorted data in Accumulo, showing the randomly generated key-value pairs. Each row displays a key, column family (c:), column visibility (empty), and the value data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/terasort.md#2025-04-11_snippet_2\n\nLANGUAGE: plain\nCODE:\n```\n+l-$$OE/ZH c:         4 []    GGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOO\n,C)wDw//u= c:        10 []    CCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKK\n75@~?'WdUF c:         1 []    IIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQ\n;L+!2rT~hd c:         8 []    MMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUU\nLsS8)|.ZLD c:         5 []    OOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWW\nM^*dDE;6^< c:         9 []    UUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCC\n^Eu)<n#kdP c:         3 []    YYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGG\nle5awB.$sm c:         6 []    WWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEE\nq__[fwhKFg c:         7 []    EEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMM\nw[o||:N&H, c:         2 []    QQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYY\n```\n\n----------------------------------------\n\nTITLE: Reconfiguring Sample Data and Handling Changes in Accumulo\nDESCRIPTION: This snippet demonstrates how to change the sampling configuration, handle errors when configurations change, and rebuild sample data. It shows the impact of changing the modulus parameter from 3 to 2.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/sample.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance sampex> config -t sampex -s table.sampler.opt.modulus=2\nroot@instance sampex> scan --sample\n2015-09-09 12:22:51,058 [shell.Shell] ERROR: org.apache.accumulo.core.client.SampleNotPresentException: Table sampex(ID:2) does not have sampling configured or built\nroot@instance sampex> compact -t sampex --sf-no-sample\n2015-09-09 12:23:07,242 [shell.Shell] INFO : Compaction of table sampex started for given range\nroot@instance sampex> scan --sample\n2317 doc:content []    milk, eggs, bread, parmigiano-reggiano\n2317 doc:url []    file://groceries/9.txt\n3900 doc:content []    EC2 ate my homework\n3900 doc:uril []    file://final_project.txt\n9255 doc:content []    abcde\n9255 doc:url []    file://foo.txt\n```\n\n----------------------------------------\n\nTITLE: Viewing ZooKeeper ACLs\nDESCRIPTION: Example demonstrating how to view ZooKeeper ACLs for all nodes under the Accumulo instance path using the zoo-info-viewer tool.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo zoo-info-viewer --print-acls\n\n-----------------------------------------------\nReport Time: 2023-01-27T23:00:26.079546Z\n-----------------------------------------------\nOutput format:\nACCUMULO_PERM:OTHER_PERM path user_acls...\n\nZooKeeper acls for instance ID: f491223b-1413-494e-b75a-c2ca018db00f\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Setting Iterators in Accumulo Shell\nDESCRIPTION: This snippet demonstrates creating a new table called 'runners' and setting up two StatsCombiner iterators with different configurations for base 10 and base 16 calculations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/combiner.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/accumulo shell -u username\nEnter current password for 'username'@'instance': ***\n\nShell - Apache Accumulo Interactive Shell\n- \n- version: 1.4.x\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n- \n- type 'help' for a list of available commands\n- \nusername@instance> createtable runners\nusername@instance runners> setiter -t runners -p 10 -scan -minc -majc -n decStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: \n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: stat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 10\nusername@instance runners> setiter -t runners -p 11 -scan -minc -majc -n hexStats -class org.apache.accumulo.examples.simple.combiner.StatsCombiner\nCombiner that keeps track of min, max, sum, and count\n----------> set StatsCombiner parameter all, set to true to apply Combiner to every column, otherwise leave blank. if true, columns option will be ignored.: \n----------> set StatsCombiner parameter columns, <col fam>[:<col qual>]{,<col fam>[:<col qual>]} escape non aplhanum chars using %<hex>.: hstat\n----------> set StatsCombiner parameter radix, radix/base of the numbers: 16\n```\n\n----------------------------------------\n\nTITLE: jQuery UI License Text (MIT License)\nDESCRIPTION: The complete license text for jQuery UI v1.12.1, which follows the MIT license format with additional clarifications about sample code and external libraries.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/apidocs3/legal/jqueryUI.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nCopyright jQuery Foundation and other contributors, https://jquery.org/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/jquery-ui\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nCopyright and related rights for sample code are waived via CC0. Sample\ncode is defined as all source code contained within the demos directory.\n\nCC0: http://creativecommons.org/publicdomain/zero/1.0/\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n```\n\n----------------------------------------\n\nTITLE: Running Specific Integration Tests with Maven\nDESCRIPTION: Command to run specific integration tests while skipping all unit tests. This example runs MyIT and YourIT integration tests only.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmvn verify -Dtest=NoSuchTestExists -Dit.test=MyIT,YourIT -DfailIfNoTests=false\n```\n\n----------------------------------------\n\nTITLE: Testing MaxMutation Constraint with Large Data Ingest\nDESCRIPTION: Command to test the mutation size constraint by attempting to ingest a single row with 10,000 columns, which exceeds the configured memory limit. The command demonstrates how the constraint prevents oversized mutations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/maxmutation.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.test.TestIngest -i instance -z zookeepers -u username -p password --rows 1 --cols 10000\nERROR : Constraint violates : ConstraintViolationSummary(constrainClass:org.apache.accumulo.examples.simple.constraints.MaxMutationSize, violationCode:0, violationDescription:mutation exceeded maximum size of 188160, numberOfViolatingMutations:1)\n```\n\n----------------------------------------\n\nTITLE: Inspecting RFile Metadata Including Bloom Filter\nDESCRIPTION: This snippet demonstrates using the rfile-info command to examine the metadata of an Accumulo RFile. It shows details about the file structure, including the presence of a bloom filter.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/bloom.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo rfile-info /accumulo/tables/o8/default_tablet/F00000dj.rf\nLocality group         : <DEFAULT>\n  Start block          : 0\n  Num   blocks         : 752\n  Index level 0        : 43,598 bytes  1 blocks\n  First key            : row_0000001169 foo:1 [exampleVis] 1326222052539 false\n  Last key             : row_0999999421 foo:1 [exampleVis] 1326222052058 false\n  Num entries          : 999,536\n  Column families      : [foo]\n\nMeta block     : BCFile.index\n  Raw size             : 4 bytes\n  Compressed size      : 12 bytes\n  Compression type     : gz\n\nMeta block     : RFile.index\n```\n\n----------------------------------------\n\nTITLE: Creating Table and Adding Splits\nDESCRIPTION: Creates a new table called testRGB and adds splits to create tablet groups with patterns 01, 02, 03, and 04.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/rgbalancer.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@accumulo> createtable testRGB\nroot@accumulo testRGB> addsplits -t testRGB 01b 01m 01r 01z  02b 02m 02r 02z 03b 03m 03r 03z 04a 04b 04c 04d 04e 04f 04g 04h 04i 04j 04k 04l 04m 04n 04o 04p\nroot@accumulo testRGB> tables -l\naccumulo.metadata    =>        !0\naccumulo.replication =>      +rep\naccumulo.root        =>        +r\ntestRGB              =>         2\ntrace                =>         1\n```\n\n----------------------------------------\n\nTITLE: Examining Metadata for a Table in Accumulo\nDESCRIPTION: Switches to the accumulo.metadata table and performs a scan with row boundaries to view metadata entries for the test table created earlier.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/system-metadata-tables.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nshell> table accumulo.metadata\nshell> scan -b 3; -e 3<\n3< file:/default_tablet/F000009y.rf []    186,1\n3< last:13fe86cd27101e5 []    127.0.0.1:9997\n3< loc:13fe86cd27101e5 []    127.0.0.1:9997\n3< srv:dir []    /default_tablet\n3< srv:flush []    1\n3< srv:lock []    tservers/127.0.0.1:9997/zlock-0000000001$13fe86cd27101e5\n3< srv:time []    M1373998392323\n3< ~tab:~pr []    \\x00\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring Table with Custom Classpath\nDESCRIPTION: These commands create a new table 'nofoo' and configure it to use the 'cx1' classpath context.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/classpath.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nroot@test16> createtable nofoo\nroot@test16 nofoo> config -t nofoo -s table.classpath.context=cx1\n```\n\n----------------------------------------\n\nTITLE: ZooKeeper Authentication and ACL Correction Commands\nDESCRIPTION: Commands to authenticate with ZooKeeper and recursively correct ACLs on nodes. These commands are executed in the ZooKeeper CLI after setting up super digest authentication, allowing the administrator to fix problematic ACL settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/zookeeper.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naddauth digest accumulo:$secret\nsetAcl -R <path> world:anyone:r,auth:accumulo:cdrwa\n```\n\n----------------------------------------\n\nTITLE: Creating New Documentation Layout in Bash\nDESCRIPTION: These commands create a new documentation layout for a major release and update the reference to the new collection.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/making-release.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncp _layouts/docs-3.html _layouts/docs-3.html\nvim _layouts/docs-3.html\n```\n\n----------------------------------------\n\nTITLE: Executing Bulk Ingest Workflow in Apache Accumulo using Command Line\nDESCRIPTION: A series of commands that demonstrate the complete bulk ingest process. It sets up a table with split points, generates test data, performs the bulk ingest operation using MapReduce, and verifies the data was properly ingested.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bulkIngest.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ PKG=org.apache.accumulo.examples.simple.mapreduce.bulk\n$ ARGS=\"-i instance -z zookeepers -u username -p password\"\n$ ./bin/accumulo $PKG.SetupTable $ARGS -t test_bulk row_00000333 row_00000666\n$ ./bin/accumulo $PKG.GenerateTestData --start-row 0 --count 1000 --output bulk/test_1.txt\n$ ./bin/tool.sh lib/accumulo-examples-simple.jar $PKG.BulkIngestExample $ARGS -t test_bulk --inputDir bulk --workDir tmp/bulkWork\n$ ./bin/accumulo $PKG.VerifyIngest $ARGS -t test_bulk --start-row 0 --count 1000\n```\n\n----------------------------------------\n\nTITLE: Importing and Verifying Accumulo Table\nDESCRIPTION: Shell commands demonstrating table import and verification of data, splits, configuration, and metadata.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/export.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nroot@test15> importtable table1_copy /tmp/table1_export_dest\nroot@test15> table table1_copy\nroot@test15 table1_copy> scan\na cf1:cq1 []    v1\nh cf1:cq1 []    v2\nz cf1:cq1 []    v3\nz cf1:cq2 []    v4\nroot@test15 table1_copy> getsplits -t table1_copy\nb\nr\nroot@test15> config -t table1_copy -f split\n---------+--------------------------+-------------------------------------------\nSCOPE    | NAME                     | VALUE\n---------+--------------------------+-------------------------------------------\ndefault  | table.split.threshold .. | 1G\ntable    |    @override ........... | 100M\n---------+--------------------------+-------------------------------------------\nroot@test15> tables -l\n!METADATA       =>         !0\ntrace           =>          1\ntable1_copy     =>          5\nroot@test15 table1_copy> scan -t !METADATA -b 5 -c srv:time\n5;b srv:time []    M1343224500467\n5;r srv:time []    M1343224500467\n5< srv:time []    M1343224500467\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOffFilter for Minor and Major Compaction in Accumulo\nDESCRIPTION: Sets up the AgeOffFilter for minor and major compaction scopes with the same 30-second TTL. This configuration enables permanent removal of aged-off data during compaction processes, rather than just hiding it during scans.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/filter.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> setiter -t filtertest -minc -majc -p 10 -n myfilter -class org.apache.accumulo.core.iterators.user.AgeOffFilter\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> flush\n06 10:42:24,806 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact\n06 10:42:36,781 [shell.Shell] INFO : Compaction of table filtertest started for given range\nusername@instance filtertest> flush -t filtertest -w\n06 10:42:52,881 [shell.Shell] INFO : Flush of table filtertest completed.\nusername@instance filtertest> compact -t filtertest -w\n06 10:43:00,632 [shell.Shell] INFO : Compacting table ...\n06 10:43:01,307 [shell.Shell] INFO : Compaction of table filtertest completed for given range\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Connecting to Zookeeper Server with zkCli.sh\nDESCRIPTION: Demonstrates how to connect to a Zookeeper server using the command-line interface tool to verify connectivity. The successful connection is indicated by the 'CONNECTED' status.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ zkCli.sh -server zoohost\n...\n[zk: zoohost:2181(CONNECTED) 0]\n```\n\n----------------------------------------\n\nTITLE: Testing Filter Functionality\nDESCRIPTION: Demonstrates the filter in action by inserting test data and scanning the results\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/classpath.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ninsert foo1 f1 q1 v1\ninsert noo1 f1 q1 v2\nscan\n```\n\n----------------------------------------\n\nTITLE: Displaying Metadata Table Entries Before Compaction in Accumulo\nDESCRIPTION: Shows the metadata table entries for table '2' before compaction, displaying file information including sizes and entry counts, along with other tablet metadata.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/A0000047.rf []   12330,99000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F0000048.rf []   1196,1000\n2< file:hdfs://localhost:8020/accumulo/tables/2/default_tablet/F000004j.rf []   1302,1000\n2< last:10000bf4e0a0004 []  localhost:9997\n2< loc:10000bf4e0a0004 []   localhost:9997\n2< srv:compact []   111\n2< srv:dir []   default_tablet\n2< srv:flush [] 113\n2< srv:lock []  tservers/localhost:9997/zlock#1950397a-b2ca-4685-b70b-67ae3cd578b9#0000000000$10000bf4e0a0004\n2< srv:time []  M1618325648093\n2< ~tab:~pr []  \\x00\n```\n\n----------------------------------------\n\nTITLE: Setting Up Tour Variables with Liquid in Jekyll Front Matter\nDESCRIPTION: Liquid template code that sets up key variables for the Accumulo Tour page. It assigns tour pages from site data and identifies the first page URL and content.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/index.md#2025-04-11_snippet_1\n\nLANGUAGE: liquid\nCODE:\n```\n{% assign tour_pages = site.data.tour.docs %}\n{% assign first_url = tour_pages[0] | prepend: '/tour/' | append: '/' %}\n{% assign first_page = site.pages | where:'url',first_url | first %}\n```\n\n----------------------------------------\n\nTITLE: Building Accumulo Package with Maven\nDESCRIPTION: Command to build the Accumulo source code and create a distribution package. This generates a tarball in the assemble/target directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmvn package\n```\n\n----------------------------------------\n\nTITLE: Reading Data with Java in Accumulo\nDESCRIPTION: Command to run a Java program that reads data from Accumulo. It scans the table from 'row_0' to 'row_1001'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/helloworld.md#2025-04-11_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.helloworld.ReadData -i instance -z zookeepers -u username -p password -t hellotable --startKey row_0 --endKey row_1001\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOffFilter for All Scopes and Performing Table Maintenance\nDESCRIPTION: This snippet shows how to configure the AgeOffFilter for minor and major compaction scopes using the -class parameter. It demonstrates flushing and compacting the table to force aged data to be permanently removed from disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/filter.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nusername@instance filtertest> setiter -t filtertest -minc -majc -p 10 -n myfilter -class org.apache.accumulo.core.iterators.user.AgeOffFilter\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method:\n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day:\nusername@instance filtertest> flush\n06 10:42:24,806 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact\n06 10:42:36,781 [shell.Shell] INFO : Compaction of table filtertest started for given range\nusername@instance filtertest> flush -t filtertest -w\n06 10:42:52,881 [shell.Shell] INFO : Flush of table filtertest completed.\nusername@instance filtertest> compact -t filtertest -w\n06 10:43:00,632 [shell.Shell] INFO : Compacting table ...\n06 10:43:01,307 [shell.Shell] INFO : Compaction of table filtertest completed for given range\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Configuring HDFS DataNode Xcievers\nDESCRIPTION: This XML snippet shows how to increase the number of Xcievers for HDFS DataNodes in the Hadoop configuration. This can help resolve issues on larger Accumulo clusters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_8\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n    <name>dfs.datanode.max.xcievers</name>\n    <value>4096</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Scanning Data Table in Accumulo Shell\nDESCRIPTION: Accumulo shell command to view the stored file data. This shows the MD5 hash of the file as the row key and the stored file content.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filedata.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n> scan -t dataTable\n```\n\n----------------------------------------\n\nTITLE: Configuring Hadoop File System Implementation in core-site.xml\nDESCRIPTION: This XML snippet configures Hadoop to use a more reliable local filesystem implementation for Accumulo's storage.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n  <property>\n    <name>fs.file.impl</name>\n    <value>org.apache.hadoop.fs.RawLocalFileSystem</value>\n  </property>\n```\n\n----------------------------------------\n\nTITLE: Configuring Download Buttons with Liquid and HTML\nDESCRIPTION: This HTML snippet uses Liquid templating to generate download buttons for Accumulo releases. It includes buttons for source and binary downloads, as well as links to release notes, documentation, and API references.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/downloads.md#2025-04-11_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n{% assign linkVers = '2.1.3' %}\n### Accumulo {{linkVers}} **Latest**{: .badge .bg-primary} **LTM**{: .badge .bg-success}\n{: #accumulo-latest-ltm }\n\nThe {{linkVers}} release of Apache Accumulo&reg; is the latest release on the\ncurrent stable generation, containing the newest bug fixes, performance\nenhancements, and more.\n\n{% for srcbin in srcbinArray %}\n{% assign lnkFile = 'accumulo-' | append: linkVers | append: '-' | append: srcbin | append: '.tar.gz' %}\n{% assign lnkSuffix = '/accumulo/' | append: linkVers | append: '/' | append: lnkFile %}\n<div class=\"d-flex flex-wrap justify-content-start align-items-start\" style=\"margin-left: 20px; margin-bottom: 5px;\">\n  <div class=\"btn-group me-2\">\n    <a {{btnDownloadStyle}} href=\"{{closerLink}}{{lnkSuffix}}\" link-suffix=\"{{lnkSuffix}}\">{{lnkFile}}{{glyphSave}}</a>\n  </div>\n  <div class=\"btn-group\">\n    <a {{btnSigStyle}} href=\"{{downloadsLink}}{{lnkSuffix}}.asc\">ASC{{glyphLock}}</a>\n    <a {{btnHashStyle}} href=\"{{downloadsLink}}{{lnkSuffix}}.sha512\">SHA{{glyphLock}}</a>\n  </div>\n</div>\n{% endfor %}\n<div class=\"btn-group-sm\" style=\"margin: 20px;\">\n  <a {{btnDocStyle}} href=\"{{site.baseurl}}/release/accumulo-{{linkVers}}\">Release Notes</a>\n  <a {{btnDocStyle}} href=\"https://github.com/apache/accumulo/blob/rel/{{linkVers}}/README.md\">README</a>\n  <a {{btnDocStyle}} href=\"{{site.baseurl}}/docs/2.x\">Online Documentation</a>\n  <a {{btnDocStyle}} href=\"https://github.com/apache/accumulo-examples\">Examples</a>\n  <a {{btnDocStyle}} href=\"{{site.baseurl}}/docs/2.x/apidocs\">Java API</a>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Starting All Accumulo Services\nDESCRIPTION: This command demonstrates how to start all Accumulo services using the 'accumulo-cluster' script. It's useful for bringing an entire Accumulo instance online.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/basic.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo-cluster start\n```\n\n----------------------------------------\n\nTITLE: Copying Files to HDFS for Word Count Processing\nDESCRIPTION: Commands to copy a README file to HDFS and verify it exists in the target directory. This creates the input data that will be processed by the MapReduce job.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/mapred.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/README /user/username/wc/Accumulo.README\n$ hadoop fs -ls /user/username/wc\nFound 1 items\n-rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Accumulo.README\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Search with Intersecting Iterator in Apache Accumulo\nDESCRIPTION: Code example showing how to set up a BatchScanner with an Intersecting Iterator to perform multi-term document searches across partitioned bins. The code configures the scanner with search terms and processes the results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Design.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nText[] terms = {new Text(\"the\"), new Text(\"white\"), new Text(\"house\")};\n\nBatchScanner bs = conn.createBatchScanner(table, auths, 20);\nbs.setScanIterators(20, IntersectingIterator.class.getName(), \"ii\");\n\n// tells scanner to look for terms in the column family and sends terms\nbs.setScanIteratorOption(\"ii\",\n    IntersectingIterator.columnFamiliesOptionName,\n    IntersectingIterator.encodeColumns(terms));\n\nbs.setRanges(Collections.singleton(new Range()));\n\nfor(Entry<Key,Value> entry : bs) {\n    System.out.println(\" \" + entry.getKey().getColumnQualifier());\n}\n```\n\n----------------------------------------\n\nTITLE: Viewing MapReduce Job Output\nDESCRIPTION: These commands show how to list the output files in HDFS and view the contents of the MapReduce job result.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/regex.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -ls /tmp/output\nFound 3 items\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:11 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:10 /tmp/output/_logs\n-rw-r--r--   1 username supergroup         51 2013-01-10 14:10 /tmp/output/part-m-00000\n```\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -text /tmp/output/part-m-00000\ndogrow dogcf:dogcq [] 1357844987994 false    dogvalue\n```\n\n----------------------------------------\n\nTITLE: Searching for WAL References in Accumulo Shell\nDESCRIPTION: This command searches for references to a specific Write-Ahead Log (WAL) in the Accumulo shell, which is helpful for identifying tablets affected by a corrupt WAL.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nshell> grep 0cb7ce52-ac46-4bf7-ae1d-acdcfaa97995\n```\n\n----------------------------------------\n\nTITLE: Running Character Histogram MapReduce Job in Accumulo\nDESCRIPTION: Command to execute the CharacterHistogram MapReduce job that computes byte frequency histograms for ingested files. The histogram is then stored alongside the file data with the specified visibility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/filedata.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.filedata.CharacterHistogram -i instance -z zookeepers -u username -p password -t dataTable --auths exampleVis --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: Implementing Document Search with Intersecting Iterator in Apache Accumulo\nDESCRIPTION: Code example showing how to set up a BatchScanner with an Intersecting Iterator to perform multi-term document searches across partitioned bins. The code configures the scanner with search terms and processes the results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Table_Design.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nText[] terms = {new Text(\"the\"), new Text(\"white\"), new Text(\"house\")};\n\nBatchScanner bs = conn.createBatchScanner(table, auths, 20);\nbs.setScanIterators(20, IntersectingIterator.class.getName(), \"ii\");\n\n// tells scanner to look for terms in the column family and sends terms\nbs.setScanIteratorOption(\"ii\",\n    IntersectingIterator.columnFamiliesOptionName,\n    IntersectingIterator.encodeColumns(terms));\n\nbs.setRanges(Collections.singleton(new Range()));\n\nfor(Entry<Key,Value> entry : bs) {\n    System.out.println(\" \" + entry.getKey().getColumnQualifier());\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Jekyll Page Redirect in YAML\nDESCRIPTION: YAML front matter configuration that sets up a page redirect in Jekyll. Defines the page title and redirect destination path.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Examples\nredirect_to: examples/\n---\n```\n\n----------------------------------------\n\nTITLE: Managing FATE Transactions after Accumulo Upgrade (v2.1+)\nDESCRIPTION: Commands to list and delete completed FATE transactions after an Accumulo upgrade for version 2.1 and later. This is needed when upgrade is aborted due to outstanding FATE transactions from previous versions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\naccumulo admin fate --print\naccumulo admin fate --delete TXID [TXID...]\n```\n\n----------------------------------------\n\nTITLE: Running the RowHash map/reduce job\nDESCRIPTION: Command to execute the RowHash map/reduce job that adds hash values for specified columns in the Accumulo table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/rowhash.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/tool.sh lib/accumulo-examples-simple.jar org.apache.accumulo.examples.simple.mapreduce.RowHash -u user -p passwd -i instance -t input --column cf:cq\n```\n\n----------------------------------------\n\nTITLE: Checking MapReduce Job Output in HDFS\nDESCRIPTION: This snippet shows how to list the output files generated by the RegexExample MapReduce job in the HDFS directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/regex.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -ls /tmp/output\nFound 3 items\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:11 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:10 /tmp/output/_logs\n-rw-r--r--   1 username supergroup         51 2013-01-10 14:10 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Creating Kerberos Principal for Accumulo Server\nDESCRIPTION: This command creates a Kerberos principal for an Accumulo server process on a specific host. The principal is created with a random key as it will use a keytab for authentication.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nkadmin.local -q \"addprinc -randkey accumulo/host.domain.com\"\n```\n\n----------------------------------------\n\nTITLE: Viewing Regex Search Results from HDFS\nDESCRIPTION: This command displays the content of the MapReduce job output file, showing the matching row that starts with 'dog'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/regex.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ hadoop fs -text /tmp/output/output/part-m-00000\ndogrow dogcf:dogcq [] 1357844987994 false    dogvalue\n```\n\n----------------------------------------\n\nTITLE: Removing Users with Java API\nDESCRIPTION: Java code to delete user 'bob' using the SecurityOperations interface.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/authentication.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nclient.securityOperations().dropLocalUser(\"bob\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Cluster Servers in YAML\nDESCRIPTION: The cluster.yaml file in the conf directory is used to configure server locations instead of multiple files. This supports starting new scan server and compactor server types, as well as options for starting multiple Tablet and Scan Servers per host.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2022-11-01-accumulo-2.1.0.md#2025-04-11_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncluster.yaml\n```\n\n----------------------------------------\n\nTITLE: Index Table Schema Example\nDESCRIPTION: Illustration of the index table structure showing forward and reverse file name indexing to enable wildcard searches at any position in filenames.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/dirlist.md#2025-04-11_snippet_7\n\nLANGUAGE: plaintext\nCODE:\n```\nrow colf:colq [vis]\nfAccumulo.README i:002/local/Accumulo.README [exampleVis]\nflocal i:001/local [exampleVis]\nrEMDAER.olumuccA i:002/local/Accumulo.README [exampleVis]\nrlacol i:001/local [exampleVis]\n```\n\n----------------------------------------\n\nTITLE: Batch Scanner Output Log\nDESCRIPTION: Sample output from running the RandomBatchScanner showing the performance metrics of batch scanning operations, including lookups per second and number of results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/batch.md#2025-04-11_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n07 11:33:11,103 [client.CountingVerifyingReceiver] INFO : Generating 100 random queries...\n07 11:33:11,112 [client.CountingVerifyingReceiver] INFO : finished\n07 11:33:11,260 [client.CountingVerifyingReceiver] INFO : 694.44 lookups/sec   0.14 secs\n\n07 11:33:11,260 [client.CountingVerifyingReceiver] INFO : num results : 100\n\n07 11:33:11,364 [client.CountingVerifyingReceiver] INFO : Generating 100 random queries...\n07 11:33:11,370 [client.CountingVerifyingReceiver] INFO : finished\n07 11:33:11,416 [client.CountingVerifyingReceiver] INFO : 2173.91 lookups/sec   0.05 secs\n\n07 11:33:11,416 [client.CountingVerifyingReceiver] INFO : num results : 100\n```\n\n----------------------------------------\n\nTITLE: Running InterferenceTest Without Isolation in Accumulo\nDESCRIPTION: This command runs the InterferenceTest example without isolation for 5000 iterations. It demonstrates how scanning without isolation causes inconsistent views where a single row contains multiple different values due to concurrent modifications.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/isolation.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.isolation.InterferenceTest -i instance -z zookeepers -u username -p password -t isotest --iterations 5000\n```\n\n----------------------------------------\n\nTITLE: Enabling Kerberos Debug Logging in Java\nDESCRIPTION: JVM system property to enable detailed Kerberos debugging output\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_13\n\nLANGUAGE: java\nCODE:\n```\n-Dsun.security.krb5.debug=true\n```\n\n----------------------------------------\n\nTITLE: Listing MapReduce Output Files in HDFS\nDESCRIPTION: This command lists the output files generated by the MapReduce job in the specified HDFS directory, showing the success marker, logs directory, and the part file containing the results.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/regex.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/output\nFound 3 items\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:11 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:10 /tmp/output/_logs\n-rw-r--r--   1 username supergroup         51 2013-01-10 14:10 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Configuring Continuous Ingest Table for Compactions in Accumulo\nDESCRIPTION: Accumulo shell commands to configure a continuous ingest table to use a specific compaction service. This includes setting the dispatcher and lowering the compaction ratio to increase compaction frequency.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nconfig -t ci -s table.compaction.dispatcher=org.apache.accumulo.core.spi.compaction.SimpleCompactionDispatcher\nconfig -t ci -s table.compaction.dispatcher.opts.service=cs1\nconfig -t ci -s table.compaction.major.ratio=2\n```\n\n----------------------------------------\n\nTITLE: Using the New Check Accumulo Properties Command\nDESCRIPTION: The 'accumulo check-accumulo-properties' command can be used before initializing an instance to validate the properties file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2025-04-08-accumulo-2.1.4.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naccumulo check-accumulo-properties\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Unit Tests with Maven\nDESCRIPTION: Command to run only Accumulo's unit tests and build the software using Maven.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/verifying-release.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmvn package\n```\n\n----------------------------------------\n\nTITLE: Performance Comparison with Bloom Filters in Accumulo\nDESCRIPTION: This snippet shows the same 500 lookups performed on the bloom-enabled table. The lookups are significantly faster because bloom filters allow the system to query only the relevant map file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/bloom.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchScanner -s 7 instance zookeepers username password bloom_test2 500 0 1000000000 50 20 exampleVis\nGenerating 500 random queries...finished\n99.03 lookups/sec   5.05 secs\nnum results : 500\nGenerating 500 random queries...finished\n101.15 lookups/sec   4.94 secs\nnum results : 500\n```\n\n----------------------------------------\n\nTITLE: Listing MapReduce Job Output Files in HDFS\nDESCRIPTION: Command to list the files created in the output directory, showing the MapReduce job results and metadata files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/tabletofile.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/output\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:44 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs/history\n-rw-r--r--   1 username supergroup       9049 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_1357847072863_username_TableToFile%5F1357847071434\n-rw-r--r--   1 username supergroup      26172 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_conf.xml\n-rw-r--r--   1 username supergroup         50 2013-01-10 14:44 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Configuring Impersonation Rules in Accumulo Properties\nDESCRIPTION: These properties define impersonation rules in Accumulo, allowing specific users to act on behalf of others from designated hosts. The rules are specified as semicolon-separated lists.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_5\n\nLANGUAGE: properties\nCODE:\n```\ninstance.rpc.sasl.allowed.user.impersonation=$PROXY_USER:*\ninstance.rpc.sasl.allowed.host.impersonation=*\n```\n\nLANGUAGE: properties\nCODE:\n```\ninstance.rpc.sasl.allowed.user.impersonation=$PROXY_USER:user1,user2;$PROXY_USER2:user2,user4\ninstance.rpc.sasl.allowed.host.impersonation=host1.domain.com,host2.domain.com;*\n```\n\n----------------------------------------\n\nTITLE: Listing MapReduce Output Files in HDFS\nDESCRIPTION: This snippet demonstrates how to list the files created by the MapReduce job in the HDFS output directory, showing the typical files generated including the actual output data and job metadata.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/tabletofile.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -ls /tmp/output\n-rw-r--r--   1 username supergroup          0 2013-01-10 14:44 /tmp/output/_SUCCESS\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs\ndrwxr-xr-x   - username supergroup          0 2013-01-10 14:44 /tmp/output/_logs/history\n-rw-r--r--   1 username supergroup       9049 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_1357847072863_username_TableToFile%5F1357847071434\n-rw-r--r--   1 username supergroup      26172 2013-01-10 14:44 /tmp/output/_logs/history/job_201301081658_0011_conf.xml\n-rw-r--r--   1 username supergroup         50 2013-01-10 14:44 /tmp/output/part-m-00000\n```\n\n----------------------------------------\n\nTITLE: Inserting Data with Visibility Labels in Accumulo\nDESCRIPTION: Demonstrates how to insert data with visibility expressions controlling access. Shows both simple and complex visibility patterns, including the proper use of parentheses for combining AND (&) and OR (|) operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> insert row f1 q1 v1 -l A\nusername@instance vistest> insert row f2 q2 v2 -l A&B\nusername@instance vistest> insert row f3 q3 v3 -l apple&carrot|broccoli|spinach\n06 11:19:01,432 [shell.Shell] ERROR: org.apache.accumulo.core.util.BadArgumentException: cannot mix | and & near index 12\napple&carrot|broccoli|spinach\n            ^\nusername@instance vistest> insert row f3 q3 v3 -l (apple&carrot)|broccoli|spinach\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Release Testing Environment Table\nDESCRIPTION: Markdown table showing test environments and configurations used for validating Apache Accumulo 1.7.1 release across different operating systems, Hadoop versions, and cluster configurations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2016-02-26-accumulo-1.7.1.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{: #release_notes_testing .table }\n| OS/Environment                                                            | Hadoop | Nodes | ZooKeeper | HDFS HA | Tests                                                                                                                                |\n|---------------------------------------------------------------------------|--------|-------|-----------|---------|--------------------------------------------------------------------------------------------------------------------------------------|\n| CentOS 7.1 w/Oracle JDK8 on EC2 (1 m3.xlarge, 8 d2.xlarge)                | 2.6.3  | 9     | 3.4.6     | No      | Random walk (All.xml) 24-hour run, saw [ACCUMULO-3794][ACCUMULO-3794] and [ACCUMULO-4151][ACCUMULO-4151].                            |\n| CentOS 7.1 w/Oracle JDK8 on EC2 (1 m3.xlarge, 8 d2.xlarge)                | 2.6.3  | 9     | 3.4.6     | No      | 21 hr run of CI w/ agitation, 23.1B entries verified.                                                                                |\n| CentOS 7.1 w/Oracle JDK8 on EC2 (1 m3.xlarge, 8 d2.xlarge)                | 2.6.3  | 9     | 3.4.6     | No      | 24 hr run of CI w/o agitation, 23.0B entries verified; saw performance issues outlined in comment on [ACCUMULO-4146][ACCUMULO-4146]. |\n| CentOS 6.7 (OpenJDK 7), Fedora 23 (OpenJDK 8), and CentOS 7.2 (OpenJDK 7) | 2.6.1  | 1     | 3.4.6     | No      | All unit tests and ITs pass with -Dhadoop.version=2.6.1; Kerberos ITs had a problem with earlier versions of Hadoop                  |\n```\n\n----------------------------------------\n\nTITLE: Configuring AgeOffFilter for MinC and MajC with Flush and Compact\nDESCRIPTION: Demonstrates setting up AgeOffFilter for minor and major compaction scopes using the class flag, followed by flush and compact operations to force data cleanup.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/filter.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance filtertest> setiter -t filtertest -minc -majc -p 10 -n myfilter -class org.apache.accumulo.core.iterators.user.AgeOffFilter\nAgeOffFilter removes entries with timestamps more than <ttl> milliseconds old\n----------> set AgeOffFilter parameter negate, default false keeps k/v that pass accept method, true rejects k/v that pass accept method: \n----------> set AgeOffFilter parameter ttl, time to live (milliseconds): 30000\n----------> set AgeOffFilter parameter currentTime, if set, use the given value as the absolute time in milliseconds as the current time of day: \nusername@instance filtertest> flush\n06 10:42:24,806 [shell.Shell] INFO : Flush of table filtertest initiated...\nusername@instance filtertest> compact\n06 10:42:36,781 [shell.Shell] INFO : Compaction of table filtertest started for given range\nusername@instance filtertest> flush -t filtertest -w\n06 10:42:52,881 [shell.Shell] INFO : Flush of table filtertest completed.\nusername@instance filtertest> compact -t filtertest -w\n06 10:43:00,632 [shell.Shell] INFO : Compacting table ...\n06 10:43:01,307 [shell.Shell] INFO : Compaction of table filtertest completed for given range\nusername@instance filtertest>\n```\n\n----------------------------------------\n\nTITLE: Viewing Extracted Data from HDFS Output File\nDESCRIPTION: This snippet shows how to view the content of the output file generated by the MapReduce job using the 'hadoop fs -text' command. The output displays the extracted key-value pairs containing the 'cf:cq' column.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/tabletofile.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -text /tmp/output/output/part-m-00000\ncatrow cf:cq []    catvalue\ndogrow cf:cq []    dogvalue\n```\n\n----------------------------------------\n\nTITLE: Using DelegationTokens in MapReduce Job with Accumulo\nDESCRIPTION: This Java code snippet demonstrates how to obtain a DelegationToken from Accumulo using a KerberosToken, and then use it to configure AccumuloInputFormat and AccumuloOutputFormat for a MapReduce job.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nKerberosToken kt = new KerberosToken();\nAccumuloClient client = Accumulo.newClient().to(\"myinstance\", \"zoo1,zoo2\")\n                          .as(principal, kt).build();\nDelegationToken dt = client.securityOperations().getDelegationToken();\nProperties props = Accumulo.newClientProperties().from(client.properties())\n                          .as(principal, dt).build();\n\n// Reading from Accumulo\nAccumuloInputFormat.configure().clientProperties(props).store(job);\n\n// Writing to Accumulo\nAccumuloOutputFormat.configure().clientProperties(props).store(job);\n```\n\n----------------------------------------\n\nTITLE: Scanning a Table in Apache Accumulo (Java)\nDESCRIPTION: This snippet shows how to scan a table in Accumulo using a Scanner and iterate through the results. It creates a scanner for the 'GothamCrimeStats' table and prints each key-value pair.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\njshell> try (ScannerBase scan = client.createScanner(\"GothamCrimeStats\", Authorizations.EMPTY)) {\n   ...>   System.out.println(\"Gotham Police Department Crime Statistics:\");\n   ...>   for(Map.Entry<Key, Value> entry : scan) {\n   ...>     System.out.printf(\"Key : %-52s  Value : %s\\n\", entry.getKey(), entry.getValue());\n   ...>   }\n   ...> }\n```\n\n----------------------------------------\n\nTITLE: Creating a Table in Accumulo\nDESCRIPTION: Shell command to create a new table named 'hellotable' in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/helloworld.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance> createtable hellotable\n```\n\n----------------------------------------\n\nTITLE: Using Lexicoders for Proper Lexicographic Sorting in Accumulo\nDESCRIPTION: Example demonstrating how to use Lexicoders to properly encode data pairs (String, Integer) so they sort correctly in Accumulo. Lexicoders provide a clean way to serialize data for proper lexicographic sorting behavior.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-05-02-accumulo-1.6.0.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nPairLexicoder plex = new PairLexicoder(new StringLexicoder(), new IntegerLexicoder());\nbyte[] ba1 = plex.encode(new ComparablePair<String, Integer>(\"b\",1));\nbyte[] ba2 = plex.encode(new ComparablePair<String, Integer>(\"aa\",1));\nbyte[] ba3 = plex.encode(new ComparablePair<String, Integer>(\"a\",2));\nbyte[] ba4 = plex.encode(new ComparablePair<String, Integer>(\"a\",1));\nbyte[] ba5 = plex.encode(new ComparablePair<String, Integer>(\"aa\",-3));\n\n//sorting ba1,ba2,ba3,ba4, and ba5 lexicographically will result in the same order as sorting the ComparablePairs\n```\n\n----------------------------------------\n\nTITLE: Cloning Accumulo Examples Repository for Integration Testing\nDESCRIPTION: Clones the Apache Accumulo Examples repository from GitHub, which will be used for running integration tests against the release candidate.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/testing-release.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ git clone https://github.com/apache/accumulo-examples.git\n```\n\n----------------------------------------\n\nTITLE: Copying Documents to HDFS for Word Count Processing\nDESCRIPTION: Prepares the input data by copying the Accumulo README file to HDFS and verifying it exists in the specified directory. This data will be used as input for the word count MapReduce job.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/mapred.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ hadoop fs -copyFromLocal $ACCUMULO_HOME/README /user/username/wc/Accumulo.README\n$ hadoop fs -ls /user/username/wc\nFound 1 items\n-rw-r--r--   2 username supergroup       9359 2009-07-15 17:54 /user/username/wc/Accumulo.README\n```\n\n----------------------------------------\n\nTITLE: Executing ReadWriteExample in Accumulo\nDESCRIPTION: This command demonstrates running the ReadWriteExample which creates a table, writes data to it, and reads it back. It shows how to use the flags to create a table and perform read operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/client.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/accumulo $PACKAGE.ReadWriteExample -u root -p mypassword -i instance -z zookeeper --createtable --create --read\n```\n\n----------------------------------------\n\nTITLE: Verifying Administrative Access in Accumulo Shell\nDESCRIPTION: This console session demonstrates how to authenticate with Kerberos, access the Accumulo shell, and verify administrative permissions for a user.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n$ kinit accumulo_admin@EXAMPLE.COM\nPassword for accumulo_admin@EXAMPLE.COM: ******************************\n$ accumulo shell\n\nShell - Apache Accumulo Interactive Shell\n-\n- version: 1.7.2\n- instance name: MYACCUMULO\n- instance id: 483b9038-889f-4b2d-b72b-dfa2bb5dbd07\n-\n- type 'help' for a list of available commands\n-\naccumulo_admin@EXAMPLE.COM@MYACCUMULO> userpermissions\nSystem permissions: System.GRANT, System.CREATE_TABLE, System.DROP_TABLE, System.ALTER_TABLE, System.CREATE_USER, System.DROP_USER, System.ALTER_USER, System.SYSTEM, System.CREATE_NAMESPACE, System.DROP_NAMESPACE, System.ALTER_NAMESPACE, System.OBTAIN_DELEGATION_TOKEN\n\nNamespace permissions (accumulo): Namespace.READ, Namespace.ALTER_TABLE\n\nTable permissions (accumulo.metadata): Table.READ, Table.ALTER_TABLE\nTable permissions (accumulo.replication): Table.READ\nTable permissions (accumulo.root): Table.READ, Table.ALTER_TABLE\n\naccumulo_admin@EXAMPLE.COM@MYACCUMULO> quit\n$ kdestroy\n$\n```\n\n----------------------------------------\n\nTITLE: Setting Global Flush Configuration Commands\nDESCRIPTION: Shell commands to configure all Accumulo writes to use hflush instead of hsync, including updating system-wide defaults and removing table-specific overrides.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-10-28-durability-performance.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nconfig -s table.durability=flush\nconfig -t accumulo.metadata -d table.durability\nconfig -t accumulo.root -d table.durability\n```\n\n----------------------------------------\n\nTITLE: Inserting Random Data into Accumulo Table\nDESCRIPTION: This Java command uses RandomBatchWriter to insert 1 million random values into the 'bloom_test' table with specific parameters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.client.RandomBatchWriter --seed 7 -i instance -z zookeepers -u username -p password -t bloom_test --num 1000000 --min 0 --max 1000000000 --size 50 --batchMemory 2M --batchLatency 60s --batchThreads 3 --vis exampleVis\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter for Accumulo Release Page\nDESCRIPTION: YAML frontmatter metadata defining the title, version and archived status of the Apache Accumulo 1.3.5-incubating release documentation page.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2011-12-16-accumulo-1.3.5-incubating.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Apache Accumulo 1.3.5-incubating\nsortableversion: '01.03.05-incubating'\narchived: true\n---\n```\n\n----------------------------------------\n\nTITLE: Creating a New User in Accumulo Shell\nDESCRIPTION: Demonstrates how to create a new user in Accumulo and shows what happens when that user tries to create a table without proper permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance> createuser username\nEnter new password for 'username': ********\nPlease confirm new password for 'username': ********\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\n06 10:48:47,931 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance> userpermissions\nSystem permissions: \n\nTable permissions (!METADATA): Table.READ\nusername@instance> \n```\n\n----------------------------------------\n\nTITLE: Running Continuous Query Example\nDESCRIPTION: Command to execute continuous random term queries using 5 terms per document.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/shard.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.shard.ContinuousQuery instance zookeepers shard doc2term username password 5\n```\n\n----------------------------------------\n\nTITLE: Executing RowOperations Example in Accumulo\nDESCRIPTION: This command shows how to run the RowOperations example which demonstrates reading and writing rows using BatchWriter and Scanner. It displays key-value pairs after performing operations.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/client.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ bin/accumulo $PACKAGE.RowOperations -u root -p mypassword -i instance -z zookeeper\n```\n\n----------------------------------------\n\nTITLE: Setting Table Version Configuration\nDESCRIPTION: Console commands for configuring versioning options on an Accumulo table to maintain multiple versions of data.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/table_configuration.md#2025-04-11_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nuser@myinstance mytable> config -t mytable -s table.iterator.scan.vers.opt.maxVersions=3\n\nuser@myinstance mytable> config -t mytable -s table.iterator.minc.vers.opt.maxVersions=3\n\nuser@myinstance mytable> config -t mytable -s table.iterator.majc.vers.opt.maxVersions=3\n```\n\n----------------------------------------\n\nTITLE: Setting Up ZooKeeper Configuration on Fedora\nDESCRIPTION: This command copies the default ZooKeeper configuration file to create a custom configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo cp /etc/zookeeper/zoo_sample.cfg /etc/zookeeper/zoo.cfg\n```\n\n----------------------------------------\n\nTITLE: Querying Word Count Results from Accumulo\nDESCRIPTION: Shell commands to query the Accumulo 'wordCount' table to see the word counts generated by the MapReduce job, demonstrating how to scan for specific ranges of words.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/mapred.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nusername@instance> table wordCount\nusername@instance wordCount> scan -b the\nthe count:20080906 []    75\ntheir count:20080906 []    2\nthem count:20080906 []    1\nthen count:20080906 []    1\nthere count:20080906 []    1\nthese count:20080906 []    3\nthis count:20080906 []    6\nthrough count:20080906 []    1\ntime count:20080906 []    3\ntime. count:20080906 []    1\nto count:20080906 []    27\ntotal count:20080906 []    1\ntserver, count:20080906 []    1\ntserver.compaction.major.concurrent.max count:20080906 []    1\n...\n```\n\n----------------------------------------\n\nTITLE: Creating a New User in Accumulo Shell\nDESCRIPTION: Demonstrates how to create a new user in Accumulo and attempt to create a table without proper permissions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/visibility.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance> createuser username\nEnter new password for 'username': ********\nPlease confirm new password for 'username': ********\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\n06 10:48:47,931 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance> userpermissions\nSystem permissions: \n\nTable permissions (!METADATA): Table.READ\nusername@instance> \n```\n\n----------------------------------------\n\nTITLE: Enforcing Visibility Constraints in Accumulo\nDESCRIPTION: Shows how to configure a table constraint that prevents users from writing data with visibility labels they cannot read themselves. Demonstrates how the VisibilityConstraint operates to enforce this security model.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/examples/visibility.md#2025-04-11_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nusername@instance vistest> user root\nEnter password for user root: ******\nroot@instance vistest> config -t vistest -s table.constraint.1=org.apache.accumulo.core.security.VisibilityConstraint    \nroot@instance vistest> user username\nEnter password for user username: ********\nusername@instance vistest> insert row f4 q4 v4 -l spinach                                                                \n    Constraint Failures:\n        ConstraintViolationSummary(constrainClass:org.apache.accumulo.core.security.VisibilityConstraint, violationCode:2, violationDescription:User does not have authorization on column visibility, numberOfViolatingMutations:1)\nusername@instance vistest> insert row f4 q4 v4 -l spinach|broccoli\nusername@instance vistest> scan\nrow f1:q1 [A]    v1\nrow f2:q2 [A&B]    v2\nrow f3:q3 [(apple&carrot)|broccoli|spinach]    v3\nrow f4:q4 [spinach|broccoli]    v4\nusername@instance vistest> \n```\n\n----------------------------------------\n\nTITLE: Scanning a Table After Removing Versioning Iterator (Java)\nDESCRIPTION: This snippet shows the result of scanning the table after removing the versioning iterator. All entries are now visible, including historical data that was previously filtered out by the default versioning iterator.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/using-iterators.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\njshell> try (ScannerBase scan = client.createScanner(\"GothamCrimeStats\", Authorizations.EMPTY)) {\n   ...>   System.out.println(\"Gotham Police Department Crime Statistics:\");\n   ...>   for(Map.Entry<Key, Value> entry : scan) {\n   ...>     System.out.printf(\"Key : %-52s  Value : %s\\n\", entry.getKey(), entry.getValue());\n   ...>   }\n   ...> }\nGotham Police Department Crime Statistics:\nKey : id0001 hero:alias [] 1654697915769 false              Value : Batman\nKey : id0001 hero:villainsCaptured [] 1654697915769 false   Value : 5\nKey : id0001 hero:villainsCaptured [] 1654697915769 false   Value : 1\nKey : id0001 hero:villainsCaptured [] 1654697915769 false   Value : 2\nKey : id0002 hero:alias [] 1654697915769 false              Value : Robin\nKey : id0002 hero:villainsCaptured [] 1654697915769 false   Value : 2\nKey : id0002 hero:villainsCaptured [] 1654697915769 false   Value : 0\nKey : id0002 hero:villainsCaptured [] 1654697915769 false   Value : 1\n```\n\n----------------------------------------\n\nTITLE: Flushing a Table in Accumulo\nDESCRIPTION: The 'flush' command instructs Accumulo to write all entries currently in memory for a given table to disk.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/shell.md#2025-04-11_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nroot@myinstance mytable> flush -t mytable\n07 16:14:19,351 [shell.Shell] INFO : Flush of table mytable initiated...\n```\n\n----------------------------------------\n\nTITLE: Enabling Accumulo Services to Start on Boot\nDESCRIPTION: This command enables all Accumulo services to start automatically on system boot.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl enable accumulo-{master,tserver,gc,tracer,monitor}.service\n```\n\n----------------------------------------\n\nTITLE: Creating Table in Accumulo via Proxy\nDESCRIPTION: Creates a new table in Accumulo using the proxy client with millisecond-precision timestamps.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Writing_Accumulo_Clients.md#2025-04-11_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nclient.createTable(token, \"myTable\", true, TimeType.MILLIS);\n```\n\n----------------------------------------\n\nTITLE: Displaying RFile Meta Block Information in Apache Accumulo\nDESCRIPTION: Output showing metadata details for two RFile meta blocks (RFile.index and acu_bloom), including their raw sizes, compressed sizes, and compression type used. This information is typically used for diagnostics and performance analysis in Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/bloom.md#2025-04-11_snippet_13\n\nLANGUAGE: plaintext\nCODE:\n```\n    Meta block     : RFile.index\n      Raw size             : 43,696 bytes\n      Compressed size      : 15,592 bytes\n      Compression type     : gz\n\n    Meta block     : acu_bloom\n      Raw size             : 1,540,292 bytes\n      Compressed size      : 1,433,115 bytes\n      Compression type     : gz\n```\n\n----------------------------------------\n\nTITLE: Configuring ZooKeeper and Write-Ahead Log in Accumulo\nDESCRIPTION: XML configuration snippet for specifying ZooKeeper servers and the local directory for write-ahead logs in Accumulo's accumulo-site.xml file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Administration.md#2025-04-11_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n    <name>zookeeper</name>\n    <value>zooserver-one:2181,zooserver-two:2181</value>\n    <description>list of zookeeper servers</description>\n</property>\n<property>\n    <name>walog</name>\n    <value>/var/accumulo/walogs</value>\n    <description>local directory for write ahead logs</description>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Creating Range Objects in Java for Apache Accumulo\nDESCRIPTION: Examples of creating Range objects in different ways to specify groups of Keys. Range objects can be created using Keys, rows, or start/end rows to define the boundaries of data to be scanned.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/ranges-splits.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nRange r1 = new Range(startKey, endKey);  // Creates a range from startKey inclusive to endKey inclusive.\nRange r2 = new Range(row);               // Creates a range from row.\nRange r3 = new Range(startRow, endRow);  // Creates a range from startRow inclusive to endRow inclusive.\n```\n\n----------------------------------------\n\nTITLE: Listing Tables in Accumulo\nDESCRIPTION: The 'tables' command lists all existing tables in the Accumulo instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/getting-started/shell.md#2025-04-11_snippet_1\n\nLANGUAGE: console\nCODE:\n```\nroot@myinstance> tables\naccumulo.metadata\naccumulo.root\n```\n\n----------------------------------------\n\nTITLE: Checking Service Status in Linux\nDESCRIPTION: Command to check the status of a systemd service. Displays the current state, recent logs, and configuration of the specified service.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl status <ServiceName>.service\n```\n\n----------------------------------------\n\nTITLE: Creating Temporary Maven Settings for Accumulo Release Testing\nDESCRIPTION: Generates a temporary Maven settings file that configures repositories and plugin repositories for the Accumulo release candidate. This file is used to override default Maven settings during testing.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/testing-release.md#2025-04-11_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ cat <<EOF >/tmp/accumulo-rc-maven.xml\n<settings>\n  <profiles>\n    <profile>\n      <id>accumuloRC</id>\n      <repositories>\n        <repository>\n          <id>accumulorc</id>\n          <name>accumulorc</name>\n          <url>https://repository.apache.org/content/repositories/orgapacheaccumulo-\\${env.RC_STAGING}/</url>\n        </repository>\n      </repositories>\n      <pluginRepositories>\n        <pluginRepository>\n          <id>accumulorcp</id>\n          <name>accumulorcp</name>\n          <url>https://repository.apache.org/content/repositories/orgapacheaccumulo-\\${env.RC_STAGING}/</url>\n        </pluginRepository>\n      </pluginRepositories>\n    </profile>\n  </profiles>\n  <activeProfiles>\n    <activeProfile>accumuloRC</activeProfile>\n  </activeProfiles>\n</settings>\nEOF\n```\n\n----------------------------------------\n\nTITLE: Creating a new user in Apache Accumulo\nDESCRIPTION: This snippet demonstrates how to create a new user in Accumulo and shows that by default, users do not have permission to create tables.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/visibility.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nroot@instance> createuser username\nEnter new password for 'username': ********\nPlease confirm new password for 'username': ********\nroot@instance> user username\nEnter password for user username: ********\nusername@instance> createtable vistest\n06 10:48:47,931 [shell.Shell] ERROR: org.apache.accumulo.core.client.AccumuloSecurityException: Error PERMISSION_DENIED - User does not have permission to perform this action\nusername@instance> userpermissions\nSystem permissions:\n\nTable permissions (accumulo.metadata): Table.READ\nusername@instance>\n```\n\n----------------------------------------\n\nTITLE: Implementing Reducer Class for Accumulo Output in MapReduce\nDESCRIPTION: Example of a Reducer class that writes to Accumulo tables. The Reducer creates Mutation objects that will be applied to Accumulo tables specified by Text objects, allowing writing to multiple tables from a single Reducer.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nclass MyReducer extends Reducer<WritableComparable, Writable, Text, Mutation> {\n\n    public void reduce(WritableComparable key, Iterable<Text> values, Context c) {\n        \n        Mutation m;\n        \n        // create the mutation based on input key and value\n        \n        c.write(new Text(\"output-table\"), m);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expressions with AccumuloInputFormat\nDESCRIPTION: Optional configuration to filter input rows using regular expressions. This example shows how to match row IDs using a regular expression pattern.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nAccumuloInputFormat.setRegex(job, RegexType.ROW, \"^.*\");\n```\n\n----------------------------------------\n\nTITLE: Displaying Imported Packages in Accumulo JShell\nDESCRIPTION: Output of the /imports command showing all pre-loaded Java and Accumulo packages available in the JShell session. This includes client, data handling, and Hadoop integration packages.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/getting-started.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\njshell> /imports\n|    import java.io.*\n|    import java.math.*\n|    import java.net.*\n|    import java.nio.file.*\n|    import java.util.*\n|    import java.util.concurrent.*\n|    import java.util.function.*\n|    import java.util.prefs.*\n|    import java.util.regex.*\n|    import java.util.stream.*\n|    import org.apache.accumulo.core.client.*\n|    import org.apache.accumulo.core.client.admin.*\n|    import org.apache.accumulo.core.client.admin.compaction.*\n|    import org.apache.accumulo.core.client.lexicoder.*\n|    import org.apache.accumulo.core.client.mapred.*\n|    import org.apache.accumulo.core.client.mapreduce.*\n|    import org.apache.accumulo.core.client.mapreduce.lib.partition.*\n|    import org.apache.accumulo.core.client.replication.*\n|    import org.apache.accumulo.core.client.rfile.*\n|    import org.apache.accumulo.core.client.sample.*\n|    import org.apache.accumulo.core.client.security.*\n|    import org.apache.accumulo.core.client.security.tokens.*\n|    import org.apache.accumulo.core.client.summary.*\n|    import org.apache.accumulo.core.client.summary.summarizers.*\n|    import org.apache.accumulo.core.data.*\n|    import org.apache.accumulo.core.data.constraints.*\n|    import org.apache.accumulo.core.security.*\n|    import org.apache.accumulo.minicluster.*\n|    import org.apache.accumulo.hadoop.mapreduce.*\n|    import org.apache.accumulo.hadoop.mapreduce.partition.*\n|    import org.apache.hadoop.io.Text\n```\n\n----------------------------------------\n\nTITLE: Spark Job Submission Command\nDESCRIPTION: Shell command to submit a Spark job with a shaded jar and Accumulo client properties. The command specifies the main class, execution mode, and required jar files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/spark.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$SPARK_HOME/bin/spark-submit \\\n  --class com.my.spark.job.MainClass \\\n  --master yarn \\\n  --deploy-mode client \\\n  /path/to/spark-job-shaded.jar \\\n  /path/to/accumulo-client.properties\n```\n\n----------------------------------------\n\nTITLE: Configuring Hadoop core-site.xml for Azure Data Lake Storage\nDESCRIPTION: XML configuration for setting up Azure Managed Identity authentication in Hadoop's core-site.xml. Includes OAuth settings and client credentials configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-10-15-accumulo-adlsgen2-notes.md#2025-04-11_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<property>\n  <name>fs.azure.account.auth.type</name>\n  <value>OAuth</value>\n</property>\n<property>\n  <name>fs.azure.account.oauth.provider.type</name>\n  <value>org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider</value>\n</property>\n<property>\n  <name>fs.azure.account.oauth2.msi.tenant</name>\n  <value>TenantID</value>\n</property>\n<property>\n  <name>fs.azure.account.oauth2.client.id</name>\n  <value>ClientID</value>\n</property>\n```\n\n----------------------------------------\n\nTITLE: Ingesting Files into Accumulo Using FileDataIngest\nDESCRIPTION: Command to ingest a file into an Accumulo table named 'dataTable' using the FileDataIngest class. The file is chunked into 1000-byte pieces and associated with the 'exampleVis' authorization.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.7/examples/filedata.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo org.apache.accumulo.examples.simple.filedata.FileDataIngest -i instance -z zookeepers -u username -p password -t dataTable --auths exampleVis --chunk 1000 $ACCUMULO_HOME/README\n```\n\n----------------------------------------\n\nTITLE: Checking Network Listening Ports\nDESCRIPTION: Command to list all TCP ports in listening state along with the process ID and program name that owns each port. Useful for verifying services are listening on expected ports.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nsudo netstat -tlnp\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expressions with AccumuloInputFormat\nDESCRIPTION: Optional configuration to filter input rows using regular expressions. This example shows how to match row IDs using a regular expression pattern.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Analytics.md#2025-04-11_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nAccumuloInputFormat.setRegex(job, RegexType.ROW, \"^.*\");\n```\n\n----------------------------------------\n\nTITLE: Retrieving Address from Accumulo using Scanner\nDESCRIPTION: This method retrieves an address from Accumulo using a Scanner. It uses an IsolatedScanner to read from the 'GothamPD' table and returns the value for the specified ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/conditional-writer.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nString getAddress(AccumuloClient client, String id)  {\n  try (org.apache.accumulo.core.client.Scanner scan = new IsolatedScanner(client.createScanner(\"GothamPD\", Authorizations.EMPTY))) {\n    scan.setRange(Range.exact(id, \"location\", \"home\"));\n    for (Map.Entry<Key, Value> entry : scan) {\n      return entry.getValue().toString();\n    }\n    return null;\n  } catch (TableNotFoundException e) {\n    throw new RuntimeException(e);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Stopping MiniAccumuloCluster\nDESCRIPTION: Code to properly shutdown a MiniAccumuloCluster instance.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/development/development_tools.md#2025-04-11_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nmac.stop();\n// delete your temporary folder\n```\n\n----------------------------------------\n\nTITLE: Cloning Accumulo Proxy Repository\nDESCRIPTION: This command clones the Accumulo Proxy repository from GitHub, which is necessary for running the proxy and accessing the Python client example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2019-12-16-accumulo-proxy.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/apache/accumulo-proxy\n```\n\n----------------------------------------\n\nTITLE: Changing Accumulo Instance Secret\nDESCRIPTION: The ChangeSecret utility changes the unique secret used by an Accumulo instance, generating a new instance ID. Requires Accumulo to be shut down during this operation.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin changeSecret\nOld secret:\nNew secret:\nNew instance id is 6e7f416b-c578-45df-8016-c9bc6b400e13\nBe sure to put your new secret in accumulo.properties\n```\n\n----------------------------------------\n\nTITLE: Tablet Server Configuration Properties\nDESCRIPTION: Properties controlling tablet server behavior including assignment threads, bloom filter loading, bulk import settings and cache sizes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\ntserver.assignment.concurrent.max=2\ntserver.bloom.load.concurrent.max=4\ntserver.bulk.assign.threads=1\ntserver.cache.data.size=10%\ntserver.cache.index.size=25%\n```\n\n----------------------------------------\n\nTITLE: Defining Authorization and Column Visibility in Apache Accumulo\nDESCRIPTION: Creates authorization and column visibility objects for the 'secretId' label. These objects will be used to control access to sensitive data in the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/tour/authorizations-code.md#2025-04-11_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nString secretId = \"secretId\";\nAuthorizations auths = new Authorizations(secretId);\nColumnVisibility colVis = new ColumnVisibility(secretId);\n```\n\n----------------------------------------\n\nTITLE: Metadata Table Compaction Service Executors Configuration\nDESCRIPTION: JSON configuration for the metadata table compaction service executors, defining thread pools for small and huge compactions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties.md#2025-04-11_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[{\"name\":\"small\",\"type\":\"internal\",\"maxSize\":\"32M\",\"numThreads\":2},{\"name\":\"huge\",\"type\":\"internal\",\"numThreads\":2}]\n```\n\n----------------------------------------\n\nTITLE: Starting JShell Accumulo with Custom Script in Bash\nDESCRIPTION: Command to start JShell Accumulo using a custom script, specifying the path to the custom script file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-04-21-jshell-accumulo-feature.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ bin/accumulo jshell --startup file/path/to/custom_script.jsh\n```\n\n----------------------------------------\n\nTITLE: Creating and populating a sample Accumulo table using the shell\nDESCRIPTION: This snippet demonstrates how to create a new Accumulo table named 'input' and insert sample data into it using the Accumulo shell. The example inserts three rows with different values that will be used in the extraction example.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.10/examples/tabletofile.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nShell - Apache Accumulo Interactive Shell\n- version: 1.5.0\n- instance name: instance\n- instance id: 00000000-0000-0000-0000-000000000000\n-\n- type 'help' for a list of available commands\n-\nusername@instance> createtable input\nusername@instance> insert dog cf cq dogvalue\nusername@instance> insert cat cf cq catvalue\nusername@instance> insert junk family qualifier junkvalue\nusername@instance> quit\n```\n\n----------------------------------------\n\nTITLE: Resolving IP Address to Hostname\nDESCRIPTION: Commands to check the DNS name for a given IP address using either getent hosts or hostname -A. Useful for verifying DNS resolution in a cluster.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ngetent hosts <ipaddress> # OR\nhostname -A\n```\n\n----------------------------------------\n\nTITLE: Example JSON Schema for Accumulo Snapshot Data\nDESCRIPTION: A preliminary schema definition for storing snapshot data in Apache Accumulo. The schema includes version information, Accumulo version, serialized Zookeeper data, and garbage collection details to support snapshot functionality and future compatibility.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/design/system-snapshot.md#2025-04-11_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"snapshot_schema_version\" : 1\n  \"accumulo_version\" : 2.1.2\n  \"zookeeper_data\" : \"serialized zookeeper snapshot\"\n  \"garbage_collection_data\" : {\n     \"schema_version\" : 1\n     \"referenced_dirs\" : []\n     \"referenced_files\" : []\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Replication Credentials\nDESCRIPTION: Commands to set the username and password for authentication with the replication peer.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/replication.md#2025-04-11_snippet_2\n\nLANGUAGE: console\nCODE:\n```\nroot@accumulo_primary> config -s replication.peer.user.peer1=replication\nroot@accumulo_primary> config -s replication.peer.password.peer1=password\n```\n\n----------------------------------------\n\nTITLE: Starting the Compaction Coordinator in Accumulo\nDESCRIPTION: Command to start the Compaction Coordinator process, which is a singleton process in the Accumulo system similar to the Manager.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nbin/accumulo compaction-coordinator\n```\n\n----------------------------------------\n\nTITLE: Scanning Sorted Data in Accumulo Shell\nDESCRIPTION: Commands to verify the sorted data by accessing the Accumulo shell and scanning the target table. Shows the shell login and scan command with sample output.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.5/examples/terasort.md#2025-04-11_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n./bin/accumulo shell -u username -p password\nusername@instance> scan -t sort \n+l-$$OE/ZH c:         4 []    GGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOO\n,C)wDw//u= c:        10 []    CCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKK\n75@~?'WdUF c:         1 []    IIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQ\n;L+!2rT~hd c:         8 []    MMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUU\nLsS8)|.ZLD c:         5 []    OOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWW\nM^*dDE;6^< c:         9 []    UUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCC\n^Eu)<n#kdP c:         3 []    YYYYYYYYYYOOOOOOOOOOEEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGG\nle5awB.$sm c:         6 []    WWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYYYYOOOOOOOOOOEEEEEEEE\nq__[fwhKFg c:         7 []    EEEEEEEEEEUUUUUUUUUUKKKKKKKKKKAAAAAAAAAAQQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMM\nw[o||:N&H, c:         2 []    QQQQQQQQQQGGGGGGGGGGWWWWWWWWWWMMMMMMMMMMCCCCCCCCCCSSSSSSSSSSIIIIIIIIIIYYYYYYYY\n```\n\n----------------------------------------\n\nTITLE: Running Maven with Specific Hadoop Profile\nDESCRIPTION: Command to run Maven package goal with a specific Hadoop profile. Used to test Accumulo against different Hadoop versions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/verifying-release.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmvn -Dhadoop.profile=2 package\n```\n\n----------------------------------------\n\nTITLE: Merging changes to the main branch\nDESCRIPTION: Commands to checkout the main branch and merge changes from a version branch. This ensures changes propagate to future development.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout main && git merge 1.10\n```\n\n----------------------------------------\n\nTITLE: Verifying Volumes in Accumulo Before HA Migration\nDESCRIPTION: Output from the 'accumulo admin volumes' command showing the current HDFS volume configuration before migrating to an HA namenode setup. This displays volumes referenced in zookeeper and tablet sections.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nListing volumes referenced in zookeeper\n    Volume : hdfs://namenode.example.com:8020/accumulo\n\nListing volumes referenced in accumulo.root tablets section\n    Volume : hdfs://namenode.example.com:8020/accumulo\nListing volumes referenced in accumulo.root deletes section (volume replacement occurs at deletion time)\n\nListing volumes referenced in accumulo.metadata tablets section\n    Volume : hdfs://namenode.example.com:8020/accumulo\n\nListing volumes referenced in accumulo.metadata deletes section (volume replacement occurs at deletion time)\n```\n\n----------------------------------------\n\nTITLE: Deploying and Autoscaling Accumulo Compactors in Kubernetes\nDESCRIPTION: Kubernetes commands to deploy Accumulo compactors using a deployment specification and configure autoscaling based on CPU usage. The configuration allows for scaling between 10 and 660 pods.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2021-07-08-external-compactions.md#2025-04-11_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -f accumulo-compactor-muchos.yaml\nkubectl autoscale deployment accumulo-compactor --cpu-percent=80 --min=10 --max=660\n```\n\n----------------------------------------\n\nTITLE: RPM Package Management Commands\nDESCRIPTION: A collection of helpful RPM commands for managing packages in Fedora/RHEL/CentOS systems. Includes commands to view package information, dependencies, file listings, and ownership.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nrpm -q -i <installed-package-name>              # to see info about an installed package\nrpm -q -i -p <rpm-file-name>                    # to see info about an rpm file\nrpm -q --provides <installed-package-name>      # see what a package provides\nrpm -q --requires <installed-package-name>      # see what a package requires\nrpm -q -l <installed-package-name>              # list package files\nrpm -q --whatprovides <file>                    # find rpm which owns <file>\nrpm -q --whatrequires 'mvn(groupId:artifactId)' # find rpm which requires maven coords\n```\n\n----------------------------------------\n\nTITLE: Configuring Accumulo Client SSL Settings\nDESCRIPTION: Properties file configuration for Accumulo clients to enable SSL connections, including keystore and truststore settings.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-09-02-generating-keystores-for-configuring-accumulo-with-ssl.md#2025-04-11_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\ninstance.rpc.ssl.enabled true\nrpc.javax.net.ssl.keyStore  /path/to/client-keystore.jks\nrpc.javax.net.ssl.keyStorePassword  client-password\nrpc.javax.net.ssl.trustStore  /path/to/truststore.jks\nrpc.javax.net.ssl.trustStorePassword  truststore-password\n```\n\n----------------------------------------\n\nTITLE: Applying a patch with signoff\nDESCRIPTION: Command to apply a patch to the current branch with a signoff. The signoff indicates that the committer agrees to the Developer Certificate of Origin.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit am --signoff < ACCUMULO-12345.patch\n```\n\n----------------------------------------\n\nTITLE: Configuring Erasure Coding for Existing Accumulo Table\nDESCRIPTION: This sequence demonstrates how to convert an existing Accumulo table to use Erasure Coding, including finding the table ID and compacting the table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo shell\nuser@instance> tables -l\nuser@instance> quit\n$ hdfs ec -setPolicy -policy RS-6-3-64k -path /accumulo/tables/3\n$ accumulo shell\nuser@instance> compact -t test.table1\n```\n\n----------------------------------------\n\nTITLE: Starting TIG Docker Container\nDESCRIPTION: Docker command to start the Telegraf-Influx-Grafana stack container with appropriate port mappings and volume mounts.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --ulimit nofile=66000:66000 -d --rm \\\n    --name tig-stack \\\n    -p 3003:3003 \\\n    -p 3004:8888 \\\n    -p 8086:8086 \\\n    -p 22022:22 \\\n    -p 8125:8125/udp \\\n    -v /tmp/metrics/influxdb:/var/lib/influxdb \\\n    -v /tmp/metrics/grafana:/var/lib/grafana \\\n    -v /tmp/metrics/telegraf/conf:/etc/telegraf \\\n    -v /tmp/metrics/grafana-dashboards:/etc/grafana/provisioning/dashboards \\\n    artlov/docker-telegraf-influxdb-grafana:latest\n```\n\n----------------------------------------\n\nTITLE: Searching Table Data with Regular Expressions in Accumulo\nDESCRIPTION: The egrep command performs server-side searches using regular expressions across rows, column families, qualifiers, and values. It supports row ranges and column filtering.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\nusage: egrep <regex> <regex> [-?] [-b <start-row>] [-c   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>]   \n          [-e <end-row>] [-f <int>] [-fm <className>] [-np] [-nt <arg>] [-r <row>]   \n          [-s <comma-separated-authorizations>] [-st] [-t <table>]   \ndescription: searches each row, column family, column qualifier and value, in   \n          parallel, on the server side (using a java Matcher, so put .* before and   \n          after your term if you're not matching the whole element)   \n  -?,-help  display this help   \n  -b,-begin-row <start-row>  begin row (inclusive)   \n  -c,-columns   \n          «columnfamily>[:<columnqualifier>],<columnfamily>[:<columnqualifier>]>   \n          comma-separated columns   \n  -e,-end-row <end-row>  end row (inclusive)\n```\n\n----------------------------------------\n\nTITLE: Building Docker Development Environment\nDESCRIPTION: Command to build a Docker image named 'webdev' using the local Dockerfile, which contains all the website's build prerequisites.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t webdev .\n```\n\n----------------------------------------\n\nTITLE: Creating and Adding a Mutation in Accumulo\nDESCRIPTION: This snippet shows how to create a Mutation object and add column family/value pairs to it before writing to an Accumulo table. It demonstrates using a userid as the row ID with different attributes stored in column families.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Table_Design.md#2025-04-11_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nMutation m = new Mutation(new Text(userid));\nm.put(new Text(\"age\"), age);\nm.put(new Text(\"address\"), address);\nm.put(new Text(\"balance\"), account_balance);\n\nwriter.add(m);\n```\n\n----------------------------------------\n\nTITLE: Downloading OpenTelemetry Java Agent\nDESCRIPTION: Command to download the OpenTelemetry Java Agent JAR file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nwget -O opentelemetry-javaagent-1.15.0.jar https://search.maven.org/remotecontent?filepath=io/opentelemetry/javaagent/opentelemetry-javaagent/1.15.0/opentelemetry-javaagent-1.15.0.jar\n```\n\n----------------------------------------\n\nTITLE: Building Accumulo Native Map\nDESCRIPTION: Commands to build the native map component for Accumulo, which improves MemTable performance. The native map can be built for both 32-bit and 64-bit Linux and Mac OS X systems.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naccumulo-util build-native\naccumulo-util build-native -m32\n```\n\n----------------------------------------\n\nTITLE: Verifying changes introduced by a patch\nDESCRIPTION: Command to verify what changes would be introduced by a patch before applying it. This helps review the patch contents.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit apply --stat ACCUMULO-12345.patch\n```\n\n----------------------------------------\n\nTITLE: Ingesting File System Data into Accumulo\nDESCRIPTION: Command to ingest directory structure metadata into Accumulo tables using the Ingest class. Creates 'direxample' and 'dirindex' tables to store file system information.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/dirlist.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./bin/accumulo org.apache.accumulo.examples.dirlist.Ingest instance zookeepers username password direxample dirindex exampleVis /local/user1/workspace\n```\n\n----------------------------------------\n\nTITLE: Set Iterator Command in Accumulo Shell\nDESCRIPTION: Command to configure table-specific iterators with options for different iterator types and application points\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_31\n\nLANGUAGE: shell\nCODE:\n```\nsetiter [-?] -ageoff | -agg | -class <name> | -regex | -reqvis | -vers [-majc] [-minc] [-n <itername>] -p <pri> [-scan] [-t <table>]\n```\n\n----------------------------------------\n\nTITLE: Starting Jaeger Docker Container for Trace Collection\nDESCRIPTION: Docker command to run the Jaeger all-in-one container. This container serves as the OpenTelemetry backend that collects and visualizes distributed traces from Accumulo services.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --rm --name jaeger \\\n    -e COLLECTOR_ZIPKIN_HOST_PORT=:9411 \\\n    -p 5775:5775/udp \\\n    -p 6831:6831/udp \\\n    -p 6832:6832/udp \\\n    -p 5778:5778 \\\n    -p 16686:16686 \\\n    -p 14268:14268 \\\n    -p 14250:14250 \\\n    -p 9411:9411 jaegertracing/all-in-one:1.35\n```\n\n----------------------------------------\n\nTITLE: Deleting Multiple Records from Accumulo Tables\nDESCRIPTION: The 'deletemany' command scans a table and deletes the resulting records. It supports various options for specifying the range and columns to delete.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n**deletemany**   \n\n    usage: deletemany [-?] [-b <start-row>] [-c   \n           <<columnfamily>[:<columnqualifier>]>] [-e <end-row>] [-f] [-np]   \n           [-s <comma-separated-authorizations>] [-st]   \n    description: scans a table and deletes the resulting records   \n      -?,-help  display this help   \n      -b,-begin-row <start-row>  begin row (inclusive)   \n      -c,-columns <<columnfamily>[:<columnqualifier>]>  comma-separated columns   \n      -e,-end-row <end-row>  end row (inclusive)   \n      -f,-force  forces deletion without prompting   \n      -np,-no-pagination  disables pagination of output   \n      -s,-scan-authorizations <comma-separated-authorizations>  scan authorizations   \n           (all user auths are used if this argument is not specified)   \n      -st,-show-timestamps  enables displaying timestamps   \n```\n\n----------------------------------------\n\nTITLE: Performing DNS Lookups\nDESCRIPTION: Commands to install bind-utils package and perform forward and reverse DNS lookups using dig. Used to troubleshoot DNS resolution issues in Accumulo clusters.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nsudo dnf install bind-utils\ndig +short <hostname>     # forward DNS lookup\ndig +short -x <ipaddress> # reverse DNS lookup\n```\n\n----------------------------------------\n\nTITLE: Querying Word Count Results\nDESCRIPTION: Accumulo shell commands to query the results of the word count operation, showing the frequency of words starting with 'the'.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/examples/mapred.md#2025-04-11_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ ./bin/accumulo shell -u username -p password\nusername@instance> table wordCount\nusername@instance wordCount> scan -b the\nthe count:20080906 []    75\ntheir count:20080906 []    2\nthem count:20080906 []    1\nthen count:20080906 []    1\nthere count:20080906 []    1\nthese count:20080906 []    3\nthis count:20080906 []    6\nthrough count:20080906 []    1\ntime count:20080906 []    3\ntime. count:20080906 []    1\nto count:20080906 []    27\ntotal count:20080906 []    1\ntserver, count:20080906 []    1\ntserver.compaction.major.concurrent.max count:20080906 []    1\n...\n```\n\n----------------------------------------\n\nTITLE: YAML Front Matter Configuration for Accumulo 1.4.1 Documentation\nDESCRIPTION: YAML configuration block defining metadata for the Accumulo 1.4.1 release documentation page, including version information and archive status.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2012-07-03-accumulo-1.4.1.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Apache Accumulo 1.4.1\nsortableversion: '01.04.01'\narchived: true\n---\n```\n\n----------------------------------------\n\nTITLE: Creating Empty RFile in Accumulo\nDESCRIPTION: This command uses the Accumulo CreateEmpty utility to generate an empty RFile, which can be used to replace corrupt data files.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/advanced.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo org.apache.accumulo.core.file.rfile.CreateEmpty /path/to/empty/file/empty.rf\n```\n\n----------------------------------------\n\nTITLE: Verifying SHA Checksums of Release Artifacts\nDESCRIPTION: Command to verify the integrity of Accumulo release artifacts using SHA-512 checksums.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/verifying-release.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsha512sum -c *.sha512\n```\n\n----------------------------------------\n\nTITLE: Inserting and Scanning Data in Accumulo\nDESCRIPTION: Shows how to insert data into a table and scan its contents using the Accumulo Shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Accumulo_Shell.md#2025-04-11_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nroot@myinstance mytable> scan\n\nroot@myinstance mytable> insert row1 colf colq value1\ninsert successful\n\nroot@myinstance mytable> scan\nrow1 colf:colq [] value1\n```\n\n----------------------------------------\n\nTITLE: Building Native Maps in Accumulo 1.6.0\nDESCRIPTION: Command to build the native map library for Accumulo. This script unpacks, builds and installs the native map in $ACCUMULO_HOME/lib/native, replacing the pre-built binaries of previous versions.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2014-05-27-getting-started-with-accumulo-1.6.0.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbuild_native_map.sh\n```\n\n----------------------------------------\n\nTITLE: TabletServer Compaction Commit Logs in Accumulo\nDESCRIPTION: Log entries showing the TabletServer committing the external compaction, updating its tablet files by replacing the input files with the newly created compacted file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/compaction.md#2025-04-11_snippet_10\n\nLANGUAGE: log\nCODE:\n```\n2021-04-13T14:54:14,290 [tablet.CompactableImpl] DEBUG: Attempting to commit external compaction ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c\n2021-04-13T14:54:14,325 [tablet.files] DEBUG: Compacted 2<< for USER created hdfs://localhost:8020/accumulo/tables/2/default_tablet/A000004k.rf from [A0000047.rf, F0000048.rf]\n2021-04-13T14:54:14,326 [tablet.CompactableImpl] DEBUG: Completed commit of external compaction ECID:de6afc1d-64ae-4abf-8bce-02ec0a79aa6c\n```\n\n----------------------------------------\n\nTITLE: Adding Split Points to Accumulo Tables\nDESCRIPTION: The 'addsplits' command adds split points to an existing table. It supports base64 encoded split points and can read splits from a file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n**addsplits**   \n\n    usage: addsplits [<split> <split> ] [-?] [-b64] [-sf <filename>] -t <tableName>   \n    description: add split points to an existing table   \n      -?,-help  display this help   \n      -b64,-base64encoded decode encoded split points   \n      -sf,-splits-file <filename> file with newline separated list of rows to add   \n           to table   \n      -t,-table <tableName>  name of a table to add split points to   \n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Accumulo Release Testing\nDESCRIPTION: Sets environment variables for the release version and staging repository ID to be used in subsequent commands.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/testing-release.md#2025-04-11_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nexport RC_VERSION=1.10.0\nexport RC_STAGING=1070\n```\n\n----------------------------------------\n\nTITLE: Adding Split Points to Accumulo Tables\nDESCRIPTION: The 'addsplits' command adds split points to an existing table. It supports base64 encoded split points and can read splits from a file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n**addsplits**   \n\n    usage: addsplits [<split> <split> ] [-?] [-b64] [-sf <filename>] -t <tableName>   \n    description: add split points to an existing table   \n      -?,-help  display this help   \n      -b64,-base64encoded decode encoded split points   \n      -sf,-splits-file <filename> file with newline separated list of rows to add   \n           to table   \n      -t,-table <tableName>  name of a table to add split points to   \n```\n\n----------------------------------------\n\nTITLE: Running Commands in Accumulo Shell\nDESCRIPTION: Shows the convention for running commands in the Accumulo shell. Commands are prefixed with '>' to indicate they should be executed within the Accumulo shell environment.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.6/examples/index.md#2025-04-11_snippet_1\n\nLANGUAGE: accumulo\nCODE:\n```\n> command\n```\n\n----------------------------------------\n\nTITLE: Removing Scan Iterators in Accumulo Shell\nDESCRIPTION: The deletescaniter command removes a table-specific scan iterator for the current shell session. It can delete specific iterators or all iterators for a table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\nusage: deletescaniter [-?] [-a] [-n <itername>] [-t <table>]   \ndescription: deletes a table-specific scan iterator so it is no longer used during   \n          this shell session   \n  -?,-help  display this help   \n  -a,-all  delete all for tableName   \n  -n,-name <itername>  iterator to delete   \n  -t,-table <table>  tableName\n```\n\n----------------------------------------\n\nTITLE: Git Branch Switching Workflow Example\nDESCRIPTION: A complete example showing git status output and commands when switching between branches and cleaning up untracked files to resolve build issues.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$> git status\n# On branch main\nnothing to commit (working directory clean)\n$> mvn package\n{ maven output elided }\n$> git checkout 1.6.1-SNAPSHOT\nSwitched to branch '1.6.1-SNAPSHOT'\n$> git status\n# On branch 1.6.1-SNAPSHOT\n# Untracked files:\n#   (use \"git add <file>...\" to include in what will be committed)\n#\n# mapreduce/\n# shell/\nnothing added to commit but untracked files present (use \"git add\" to track)\n$> git clean -df\nRemoving mapreduce/\nRemoving shell/\n$> git status\n# On branch 1.6.1-SNAPSHOT\nnothing to commit (working directory clean)\n```\n\n----------------------------------------\n\nTITLE: Exiting Accumulo Shell\nDESCRIPTION: The 'bye' command exits the Accumulo shell.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n**bye**   \n\n    usage: bye [-?]   \n    description: exits the shell   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Bash Command Example for Accumulo\nDESCRIPTION: Example of how bash commands are formatted, prefixed with a '$' character. These commands are intended to be run from the $ACCUMULO_HOME directory in a terminal.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.8/examples/index.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$\n```\n\n----------------------------------------\n\nTITLE: Deleting Current Accumulo Instance from ZooKeeper\nDESCRIPTION: Using DeleteZooInstance to remove the current Accumulo instance from ZooKeeper, showing the warning prompt and confirmation process to prevent accidental deletion.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo admin deleteZooInstance -i uno\nWarning: This is the current instance, are you sure? (yes|no): no\nInstance deletion of 'uno' cancelled.\n\n$ accumulo admin deleteZooInstance -i uno\nWarning: This is the current instance, are you sure? (yes|no): yes\nDeleted instance: instance1\n```\n\n----------------------------------------\n\nTITLE: Configuring Per Table Crypto Service Factory in Accumulo\nDESCRIPTION: Configuration property to enable per-table encryption using the PerTableCryptoServiceFactory in the accumulo.properties file.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/on-disk-encryption.md#2025-04-11_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\ninstance.crypto.opts.factory=org.apache.accumulo.core.spi.crypto.PerTableCryptoServiceFactory\n```\n\n----------------------------------------\n\nTITLE: Deleting Accumulo Tables\nDESCRIPTION: The 'deletetable' and 'droptable' commands delete a table from Accumulo.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_16\n\nLANGUAGE: markdown\nCODE:\n```\n**deletetable**   \n\n    usage: deletetable <tableName> [-?]   \n    description: deletes a table   \n      -?,-help  display this help   \n\n**droptable**   \n\n    usage: droptable <tableName> [-?]   \n    description: deletes a table   \n      -?,-help  display this help   \n```\n\n----------------------------------------\n\nTITLE: Copying Generated Property Files in Bash\nDESCRIPTION: This command copies the generated server and client property files from the Accumulo build directory to the website documentation directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/making-release.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp /path/to/accumulo/core/target/generated-docs/*-properties.md /path/to/accumulo-website/_docs-2/configuration/\n```\n\n----------------------------------------\n\nTITLE: Executing Accumulo Commands from File\nDESCRIPTION: The 'execfile' command specifies a file containing Accumulo commands to execute. It has an option for verbose output.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_19\n\nLANGUAGE: markdown\nCODE:\n```\n**execfile**   \n\n    usage: execfile [-?] [-v]   \n    description: specifies a file containing accumulo commands to execute   \n      -?,-help  display this help   \n      -v,-verbose displays command prompt as commands are executed   \n```\n\n----------------------------------------\n\nTITLE: Configuring and Starting tuned Service on Fedora\nDESCRIPTION: These commands set up the tuned service to optimize server settings, select a performance profile, and enable it to start on system boot.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2016-12-19-running-on-fedora-25.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start tuned.service     # start service\nsudo tuned-adm profile network-latency # pick a good profile\nsudo tuned-adm active                  # verify the selected profile\nsudo systemctl enable tuned.service    # auto-start on reboots\n```\n\n----------------------------------------\n\nTITLE: Downloading Telegraf-Influx-Grafana Docker Image\nDESCRIPTION: Command to pull the latest Telegraf-Influx-Grafana Docker image for metrics visualization.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/blog/2022-06-22-2.1.0-metrics-and-tracing.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull artlov/docker-telegraf-influxdb-grafana:latest\n```\n\n----------------------------------------\n\nTITLE: Executing Accumulo Commands from File\nDESCRIPTION: The 'execfile' command specifies a file containing Accumulo commands to execute. It has an option for verbose output.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_19\n\nLANGUAGE: markdown\nCODE:\n```\n**execfile**   \n\n    usage: execfile [-?] [-v]   \n    description: specifies a file containing accumulo commands to execute   \n      -?,-help  display this help   \n      -v,-verbose displays command prompt as commands are executed   \n```\n\n----------------------------------------\n\nTITLE: Checking if a patch applies cleanly\nDESCRIPTION: Command to verify that a patch will apply cleanly to the current branch without actually applying it. This confirms compatibility before making changes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngit apply --check ACCUMULO-12345.patch\n```\n\n----------------------------------------\n\nTITLE: Viewing ZooKeeper Contents in Accumulo\nDESCRIPTION: The dump-zoo utility allows viewing the contents of ZooKeeper, with options for displaying the data or exporting it as XML for backup purposes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\n$ accumulo-util dump-zoo\n```\n\n----------------------------------------\n\nTITLE: Checking Kerberos Ticket Cache Location in Bash\nDESCRIPTION: Commands to verify and set the Kerberos ticket cache location using environment variables and klist\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/security/kerberos.md#2025-04-11_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n$ echo $KRB5CCNAME\n\n$ klist\nTicket cache: FILE:/tmp/krb5cc_123\nDefault principal: user@EXAMPLE.COM\n\nValid starting       Expires              Service principal\n01/07/2015 11:56:35  01/08/2015 11:56:35  krbtgt/EXAMPLE.COM@EXAMPLE.COM\n    renew until 01/14/2015 11:56:35\n$ export KRB5CCNAME=/tmp/krb5cc_123\n$ echo $KRB5CCNAME\n/tmp/krb5cc_123\n```\n\n----------------------------------------\n\nTITLE: Cleaning Git Workspace to Resolve RAT Plugin Errors\nDESCRIPTION: A sequence of Git commands to clean your workspace when switching between branches to avoid RAT plugin errors. This ensures that files from one branch don't affect builds in another branch.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/building.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$> git add path/to/file/that/has/changed\n$> git add path/to/other/file\n$> git clean -df\n```\n\n----------------------------------------\n\nTITLE: Including Lunr.js Search Library and Custom Search Implementation\nDESCRIPTION: Script tags to include the Lunr.js search library and a custom search implementation script (search.js). Lunr.js is a lightweight full-text search library for use in the browser.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/search.md#2025-04-11_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<script src=\"/js/lunr/2.3.9/lunr.min.js\"></script>\n<script src=\"/js/search.js\"></script>\n```\n\n----------------------------------------\n\nTITLE: Configuring Table Summarizers in Accumulo\nDESCRIPTION: Sets up summarizers for an Accumulo table. Multiple summarizers can be configured with options for each one. Each summarizer should have a unique ID.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_6\n\nLANGUAGE: java\nCODE:\n```\ntable.summarizer.<unique_id> = <summarizer_class_name>\ntable.summarizer.<unique_id>.opt.<key> = <value>\n```\n\n----------------------------------------\n\nTITLE: Configuring Encrypted RFile Examination in Accumulo\nDESCRIPTION: Properties configuration needed when examining encrypted RFiles in Accumulo. Requires specifying encryption key location and cryptographic service providers.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/troubleshooting/tools.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngeneral.custom.crypto.key.uri=<path-to-key>/data-encryption.key\ninstance.crypto.opts.factory=org.apache.accumulo.core.spi.crypto.PerTableCryptoServiceFactory\ntable.crypto.opts.service=org.apache.accumulo.core.spi.crypto.AESCryptoService\n```\n\n----------------------------------------\n\nTITLE: Running Accumulo Unit and Integration Tests with Maven\nDESCRIPTION: Command to run both unit and integration tests in Accumulo using Maven verify goal.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/verifying-release.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmvn verify\n```\n\n----------------------------------------\n\nTITLE: jQuery and Sizzle.js License Text (MIT License)\nDESCRIPTION: The complete MIT license text for jQuery v3.6.1 and the included Sizzle.js library. It grants permissions to use, modify, distribute, and sublicense the software under specific conditions, while disclaiming warranties.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/apidocs/legal/jquery.md#2025-04-11_snippet_0\n\nLANGUAGE: text\nCODE:\n```\njQuery v 3.6.1\nCopyright OpenJS Foundation and other contributors, https://openjsf.org/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n******************************************\n\nThe jQuery JavaScript Library v3.6.1 also includes Sizzle.js\n\nSizzle.js includes the following license:\n\nCopyright JS Foundation and other contributors, https://js.foundation/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/sizzle\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n```\n\n----------------------------------------\n\nTITLE: Markdown Links for JIRA Issues and References\nDESCRIPTION: A collection of markdown-formatted links referencing Accumulo JIRA issues and external documentation sources.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-05-02-accumulo-1.6.0.md#2025-04-11_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n[ACCUMULO-1946]: https://issues.apache.org/jira/browse/ACCUMULO-1946 \"Include dfs.datanode.synconclose in hdfs configuration documentation\"\n[ACCUMULO-1950]: https://issues.apache.org/jira/browse/ACCUMULO-1950 \"Reduce the number of calls to hsync\"\n[1]: https://research.google.com/archive/bigtable.html\n[2]: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.44.2782&rep=rep1&type=pdf\n[3]: https://wiki.apache.org/hadoop/HadoopIPv6\n```\n\n----------------------------------------\n\nTITLE: Merging without committing for review\nDESCRIPTION: Command to merge changes without automatically committing, allowing review of the merged state before finalizing the merge.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/advanced-contributor.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout new-version && git merge --no-commit old-version\n```\n\n----------------------------------------\n\nTITLE: Pushing a Branch to Your Fork\nDESCRIPTION: Git command to push your local branch to your fork on GitHub. This is a necessary step before creating a pull request for your contribution.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/how-to-contribute.md#2025-04-11_snippet_1\n\nLANGUAGE: git\nCODE:\n```\ngit push origin accumulo-4321\n```\n\n----------------------------------------\n\nTITLE: jQuery v3.6.1 and Sizzle.js MIT License Text\nDESCRIPTION: The complete MIT License text for jQuery v3.6.1 and its included Sizzle.js library. The license grants permissions to use, modify, and distribute the software under certain conditions, without warranty.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/apidocs3/legal/jquery.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\njQuery v 3.6.1\nCopyright OpenJS Foundation and other contributors, https://openjsf.org/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n******************************************\n\nThe jQuery JavaScript Library v3.6.1 also includes Sizzle.js\n\nSizzle.js includes the following license:\n\nCopyright JS Foundation and other contributors, https://js.foundation/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/sizzle\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n```\n\n----------------------------------------\n\nTITLE: Retrieving Accumulo Table Locality Groups\nDESCRIPTION: The 'getgroups' command gets the locality groups for a given table.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.3/user_manual/Shell_Commands.md#2025-04-11_snippet_24\n\nLANGUAGE: markdown\nCODE:\n```\n**getgroups**   \n\n    usage: getgroups [-?] -t <table>   \n    description: gets the locality groups for a given table   \n      -?,-help  display this help   \n      -t,-table <table>  get locality groups for specified table   \n```\n\n----------------------------------------\n\nTITLE: Scan Server Port Configuration\nDESCRIPTION: Configuration properties for scan server client connection ports and port search behavior. Defines the default client port and whether to search for available ports.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/configuration/server-properties3.md#2025-04-11_snippet_0\n\nLANGUAGE: properties\nCODE:\n```\nsserver.port.client=9996\nsserver.port.search=true\n```\n\n----------------------------------------\n\nTITLE: Accessing Accumulo Monitor Web Interface\nDESCRIPTION: URL pattern to access the Accumulo monitoring web interface on port 9995.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nhttp://<hostname in conf/monitor>:9995/\n```\n\n----------------------------------------\n\nTITLE: Documenting Accumulo Shell Command: execfile\nDESCRIPTION: The 'execfile' command specifies a file containing Accumulo commands to execute. It supports options for displaying help and enabling verbose mode.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/1.4/user_manual/Shell_Commands.md#2025-04-11_snippet_25\n\nLANGUAGE: text\nCODE:\n```\nusage: execfile [-?] [-v]\ndescription: specifies a file containing accumulo commands to execute\n  -?,-help  display this help\n  -v,-verbose  displays command prompt as commands are executed\n```\n\n----------------------------------------\n\nTITLE: Initializing ClientConfiguration in Java for Accumulo 1.9.0\nDESCRIPTION: New methods for initializing ClientConfiguration to ensure compatibility with Accumulo 2.0.0. These methods replace deprecated constructors that use commons config types.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2018-04-18-accumulo-1.9.0.md#2025-04-11_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nClientConfiguration.create()\nClientConfiguration.fromFile()\nClientConfiguration.fromMap()\n```\n\n----------------------------------------\n\nTITLE: Stopping Accumulo Cluster\nDESCRIPTION: Command to stop all Accumulo processes across the configured nodes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/quickstart-1.x.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n./bin/stop-all.sh\n```\n\n----------------------------------------\n\nTITLE: Getting Erasure Coding Policy for HDFS Directory\nDESCRIPTION: This command retrieves the current Erasure Coding policy for a specified HDFS directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/erasure-coding.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ hdfs ec -getPolicy -path foo\n```\n\n----------------------------------------\n\nTITLE: Installing and Updating KEYS file using Git-SVN\nDESCRIPTION: Commands for setting up git-svn, cloning the SVN repository, and updating the KEYS file for release signing. These steps are necessary for managing GPG keys used in the release process.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/contributor/making-release.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# install git-svn\nsudo yum install -y git-svn\n# clone the SVN repo into the directory accumulo-dist-gitsvn\ngit svn clone https://dist.apache.org/repos/dist/release/accumulo accumulo-dist-gitsvn\ncd accumulo-dist-gitsvn\n# make changes to KEYS file, then commit the changes locally\ngit add KEYS\ngit commit\n# push the changes to the remote SVN repo\ngit svn dcommit --username=<ASF_Username>\n```\n\n----------------------------------------\n\nTITLE: Updating Property Documentation for Accumulo Releases using Bash\nDESCRIPTION: Commands to regenerate server and client property documentation files by building Accumulo and copying the generated markdown to the website repository.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nACCUMULO_SITE_CLONE=<accumulo website clone location, with main branch checked out>\nACCUMULO_CLONE=<accumulo clone location>\ncd \"$ACCUMULO_CLONE\"\nmvn package -DskipTests\ncp ./core/target/generated-docs/*.md \"$ACCUMULO_SITE_CLONE\"/_docs-2/configuration/\n```\n\n----------------------------------------\n\nTITLE: Implementing Search Form and Results Container in HTML\nDESCRIPTION: HTML structure for the search page includes a search form with an input field and submit button, status message container, and a table for displaying search results. The page uses Bootstrap classes for styling and layout.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/pages/search.md#2025-04-11_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"row\">\n  <div class=\"col-lg-6\">\n    <form action=\"get\" id=\"site_search\">\n      <div class=\"input-group\">\n        <input class=\"form-control\" type=\"text\" id=\"search_box\" placeholder=\"Search for...\">\n        <button class=\"btn btn-secondary\" type=\"submit\">Search</button>\n      </div>\n    </form>\n  </div>\n</div>\n\n<br/>\n\n<div id=\"search_status\"></div>\n\n<table class=\"table table-striped\"><tbody id=\"search_results\"></tbody></table>\n```\n\n----------------------------------------\n\nTITLE: Implementing Footer Template with Markdown, HTML and Liquid Tags\nDESCRIPTION: A template for the website footer that combines Markdown, HTML, and Liquid templating to display Apache Software Foundation information, copyright notice with dynamic year, and trademark statements.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_includes/footer.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<footer markdown=\"1\">\n\n[![Support the ASF][SUPPORT_IMG]{: #asf-logo height=\"100\"}][SUPPORT_URL]\n\nCopyright &copy; 2011-{{ site.time | date: '%Y' }} [The&nbsp;Apache&nbsp;Software&nbsp;Foundation][ASF].\nLicensed under the [Apache&nbsp;License,&nbsp;Version&nbsp;2.0][AL2].\n\nApache®, the names of Apache projects and their logos, and the multicolor feather\nlogo are registered trademarks or trademarks of The Apache Software Foundation\nin the United States and/or other countries.\n\n</footer>\n\n[ASF]: https://www.apache.org\n[AL2]: https://www.apache.org/licenses/\n[SUPPORT_IMG]:https://www.apache.org/images/SupportApache-small.png\n[SUPPORT_URL]:https://www.apache.org/foundation/contributing\n```\n\n----------------------------------------\n\nTITLE: YAML Frontmatter Configuration for Accumulo 1.7.4 Documentation\nDESCRIPTION: YAML configuration block defining the title, version, and archived status of the Accumulo 1.7.4 documentation page.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2018-03-23-accumulo-1.7.4.md#2025-04-11_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntitle: Apache Accumulo 1.7.4\nsortableversion: '01.07.04'\narchived: true\n---\n```\n\n----------------------------------------\n\nTITLE: Installing Accumulo Binary Distribution\nDESCRIPTION: Commands to download and extract the Accumulo binary distribution tarball. These steps should be repeated on each machine in the cluster using the same installation directory.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd <install directory>\ntar xzf accumulo-{{ page.latest_release }}-bin.tar.gz\ncd accumulo-{{ page.latest_release }}\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory Units in Accumulo\nDESCRIPTION: Memory units in configuration files can now use both upper and lower case units (e.g. '2G' or '2g')\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2014-03-06-accumulo-1.5.1.md#2025-04-11_snippet_0\n\nLANGUAGE: config\nCODE:\n```\ntserver.mutation.queue.max=4M\n```\n\n----------------------------------------\n\nTITLE: Verifying Volumes in Accumulo After HA Migration\nDESCRIPTION: Output from the 'accumulo admin volumes' command showing both the old and new HDFS volumes after migration. This verifies that the HA nameservice has been properly added to the configuration.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nListing volumes referenced in zookeeper\n    Volume : hdfs://namenode.example.com:8020/accumulo\n    Volume : hdfs://nameservice1/accumulo\n\nListing volumes referenced in accumulo.root tablets section\n    Volume : hdfs://namenode.example.com:8020/accumulo\n    Volume : hdfs://nameservice1/accumulo\nListing volumes referenced in accumulo.root deletes section (volume replacement occurs at deletion time)\n\nListing volumes referenced in accumulo.metadata tablets section\n    Volume : hdfs://namenode.example.com:8020/accumulo\n    Volume : hdfs://nameservice1/accumulo\nListing volumes referenced in accumulo.metadata deletes section (volume replacement occurs at deletion time)\n```\n\n----------------------------------------\n\nTITLE: Release Testing Configuration Table\nDESCRIPTION: Markdown table showing the testing environments and configurations used for validating the Apache Accumulo 1.5.3 release\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_posts/release/2015-06-25-accumulo-1.5.3.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{: #release_notes_testing .table }\n| OS         | Hadoop | Nodes | ZooKeeper | HDFS High-Availability | Tests                        |\n|------------|--------|-------|-----------|------------------------|------------------------------|\n| Gentoo     | 2.6.0  | 1     | 3.4.5     | No                     | Unit and Integration Tests   |\n| Centos 6.5 | 2.7.1  | 6     | 3.4.5     | No                     | Continuous Ingest and Verify |\n```\n\n----------------------------------------\n\nTITLE: Calculating Physical Memory Requirements for Accumulo VM\nDESCRIPTION: Formula and example calculation for determining physical memory needs when running Accumulo in a VM environment. The calculation accounts for off-heap memory, heap settings, and other system processes.\nSOURCE: https://github.com/apache/accumulo-website/blob/main/_docs-2/administration/in-depth-install.md#2025-04-11_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nPhysical memory needed\n  = (per-process off-heap memory) + (heap memory) + (other processes) + (margin)\n  = (number of java processes * 150M + native map) + (sum of -Xmx settings for java process)\n      + (total applications memory, provisioning memory, etc.) + (1G)\n  = (11*150M +500M) + (1G +1G +1G +256M +1G +256M +512M +512M +512M +512M +512M) + (2G) + (1G)\n  = (2150M) + (7G) + (2G) + (1G)\n  = ~12GB\n```"
  }
]