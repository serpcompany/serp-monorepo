[
  {
    "owner": "hexgrad",
    "repo": "kokoro",
    "content": "TITLE: Basic Kokoro TTS Inference\nDESCRIPTION: This snippet demonstrates a basic usage of the Kokoro TTS library, installing dependencies, initializing the pipeline, generating speech from text, and saving the generated audio to a file. It depends on the `kokoro`, `soundfile`, and `IPython` packages. Requires espeak-ng to be installed for non-English languages.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/README.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q kokoro>=0.9.4 soundfile\n!apt-get -qq -y install espeak-ng > /dev/null 2>&1\nfrom kokoro import KPipeline\nfrom IPython.display import display, Audio\nimport soundfile as sf\nimport torch\npipeline = KPipeline(lang_code='a')\ntext = '''\n[Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.\n'''\ngenerator = pipeline(text, voice='af_heart')\nfor i, (gs, ps, audio) in enumerate(generator):\n    print(i, gs, ps)\n    display(Audio(data=audio, rate=24000, autoplay=i==0))\n    sf.write(f'{i}.wav', audio, 24000)\n\n```\n\n----------------------------------------\n\nTITLE: Generating Speech with Kokoro TTS\nDESCRIPTION: This snippet demonstrates how to use the KokoroTTS class to generate speech from text. It initializes the model, sets the data type and device, defines the text to synthesize, and saves the generated audio to a WAV file. The voice parameter allows selecting from the available voices.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/README.md#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { KokoroTTS } from \"kokoro-js\";\n\nconst model_id = \"onnx-community/Kokoro-82M-v1.0-ONNX\";\nconst tts = await KokoroTTS.from_pretrained(model_id, {\n  dtype: \"q8\", // Options: \"fp32\", \"fp16\", \"q8\", \"q4\", \"q4f16\"\n  device: \"wasm\", // Options: \"wasm\", \"webgpu\" (web) or \"cpu\" (node). If using \"webgpu\", we recommend using dtype=\"fp32\".\n});\n\nconst text = \"Life is like a box of chocolates. You never know what you're gonna get.\";\nconst audio = await tts.generate(text, {\n  // Use `tts.list_voices()` to list all available voices\n  voice: \"af_heart\",\n});\naudio.save(\"audio.wav\");\n```\n\n----------------------------------------\n\nTITLE: Advanced Kokoro TTS Inference\nDESCRIPTION: This snippet demonstrates advanced usage of the Kokoro TTS library, including specifying language codes, generating speech from longer texts, and saving the generated audio to files. It requires `kokoro`, `soundfile`, `IPython` and `torch`. ESpeak-ng installation is necessary for the proper functioning of certain language features. The `split_pattern` parameter allows for splitting text into segments for processing.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/README.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# 1ï¸âƒ£ Install kokoro\n!pip install -q kokoro>=0.9.4 soundfile\n# 2ï¸âƒ£ Install espeak, used for English OOD fallback and some non-English languages\n!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n\n# 3ï¸âƒ£ Initalize a pipeline\nfrom kokoro import KPipeline\nfrom IPython.display import display, Audio\nimport soundfile as sf\nimport torch\n# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English\n# ðŸ‡ªðŸ‡¸ 'e' => Spanish es\n# ðŸ‡«ðŸ‡· 'f' => French fr-fr\n# ðŸ‡®ðŸ‡³ 'h' => Hindi hi\n# ðŸ‡®ðŸ‡¹ 'i' => Italian it\n# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]\n# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br\n# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]\npipeline = KPipeline(lang_code='a') # <= make sure lang_code matches voice, reference above.\n\n# This text is for demonstration purposes only, unseen during training\ntext = '''\nThe sky above the port was the color of television, tuned to a dead channel.\n\"It's not like I'm using,\" Case heard someone say, as he shouldered his way through the crowd around the door of the Chat. \"It's like my body's developed this massive drug deficiency.\"\nIt was a Sprawl voice and a Sprawl joke. The Chatsubo was a bar for professional expatriates; you could drink there for a week and never hear two words in Japanese.\n\nThese were to have an enormous impact, not only because they were associated with Constantine, but also because, as in so many other areas, the decisions taken by Constantine (or in his name) were to have great significance for centuries to come. One of the main issues was the shape that Christian churches were to take, since there was not, apparently, a tradition of monumental church buildings when Constantine decided to help the Christian church build a series of truly spectacular structures. The main form that these churches took was that of the basilica, a multipurpose rectangular structure, based ultimately on the earlier Greek stoa, which could be found in most of the great cities of the empire. Christianity, unlike classical polytheism, needed a large interior space for the celebration of its religious services, and the basilica aptly filled that need. We naturally do not know the degree to which the emperor was involved in the design of new churches, but it is tempting to connect this with the secular basilica that Constantine completed in the Roman forum (the so-called Basilica of Maxentius) and the one he probably built in Trier, in connection with his residence in the city at a time when he was still caesar.\n\n[Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.\n'''\n# text = 'ã€Œã‚‚ã—ãŠã‚ŒãŒãŸã å¶ç„¶ã€ãã—ã¦ã“ã†ã—ã‚ˆã†ã¨ã„ã†ã¤ã‚‚ã‚Šã§ãªãã“ã“ã«ç«‹ã£ã¦ã„ã‚‹ã®ãªã‚‰ã€ã¡ã‚‡ã£ã¨ã°ã‹ã‚Šçµ¶æœ›ã™ã‚‹ã¨ã“ã‚ã ãªã€ã¨ã€ãã‚“ãªã“ã¨ãŒå½¼ã®é ­ã«æ€ã„æµ®ã‹ã‚“ã ã€‚'\n# text = 'ä¸­åœ‹äººæ°‘ä¸ä¿¡é‚ªä¹Ÿä¸æ€•é‚ªï¼Œä¸æƒ¹äº‹ä¹Ÿä¸æ€•äº‹ï¼Œä»»ä½•å¤–åœ‹ä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒæ‹¿è‡ªå·±çš„æ ¸å¿ƒåˆ©ç›Šåšäº¤æ˜“ï¼Œä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒåžä¸‹æå®³æˆ‘åœ‹ä¸»æ¬Šã€å®‰å…¨ã€ç™¼å±•åˆ©ç›Šçš„è‹¦æžœï¼'\n# text = 'Los partidos polÃ­ticos tradicionales compiten con los populismos y los movimientos asamblearios.'\n# text = 'Le dromadaire resplendissant dÃ©ambulait tranquillement dans les mÃ©andres en mastiquant de petites feuilles vernissÃ©es.'\n# text = 'à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤ªà¥‹à¤°à¥à¤Ÿà¤°à¥‹à¤‚ à¤•à¥€ à¤¹à¤¡à¤¼à¤¤à¤¾à¤² à¤²à¤—à¤¾à¤¤à¤¾à¤° à¤ªà¤¾à¤‚à¤šà¤µà¥‡à¤‚ à¤¦à¤¿à¤¨ à¤œà¤¾à¤°à¥€, à¤¦à¤¿à¤¸à¤‚à¤¬à¤° à¤¸à¥‡ à¤‡à¤²à¥‡à¤•à¥à¤Ÿà¥à¤°à¥‰à¤¨à¤¿à¤• à¤Ÿà¥‹à¤² à¤•à¤²à¥‡à¤•à¥à¤¶à¤¨à¤² à¤¸à¤¿à¤¸à¥à¤Ÿà¤®'\n# text = \"Allora cominciava l'insonnia, o un dormiveglia peggiore dell'insonnia, che talvolta assumeva i caratteri dell'incubo.\"\n# text = 'Elabora relatÃ³rios de acompanhamento cronolÃ³gico para as diferentes unidades do Departamento que propÃµem contratos.'\n\n# 4ï¸âƒ£ Generate, display, and save audio files in a loop.\ngenerator = pipeline(\n    text, voice='af_heart', # <= change voice here\n    speed=1, split_pattern=r'\\n+'\n)\n# Alternatively, load voice tensor directly:\n# voice_tensor = torch.load('path/to/voice.pt', weights_only=True)\n# generator = pipeline(\n#     text, voice=voice_tensor,\n#     speed=1, split_pattern=r'\\n+'\n# )\n\nfor i, (gs, ps, audio) in enumerate(generator):\n    print(i)  # i => index\n    print(gs) # gs => graphemes/text\n    print(ps) # ps => phonemes\n    display(Audio(data=audio, rate=24000, autoplay=i==0))\n    sf.write(f'{i}.wav', audio, 24000) # save each audio file\n```\n\n----------------------------------------\n\nTITLE: Streaming Speech with Kokoro TTS\nDESCRIPTION: This snippet shows how to stream speech from text using Kokoro TTS and TextSplitterStream. It initializes the model, sets up the stream, and consumes text from an LLM one word at a time. Audio chunks are saved as individual WAV files.  The stream is then closed to signal the end of the text.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/README.md#_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { KokoroTTS, TextSplitterStream } from \"kokoro-js\";\n\nconst model_id = \"onnx-community/Kokoro-82M-v1.0-ONNX\";\nconst tts = await KokoroTTS.from_pretrained(model_id, {\n  dtype: \"fp32\", // Options: \"fp32\", \"fp16\", \"q8\", \"q4\", \"q4f16\"\n  // device: \"webgpu\", // Options: \"wasm\", \"webgpu\" (web) or \"cpu\" (node).\n});\n\n// First, set up the stream\nconst splitter = new TextSplitterStream();\nconst stream = tts.stream(splitter);\n(async () => {\n  let i = 0;\n  for await (const { text, phonemes, audio } of stream) {\n    console.log({ text, phonemes });\n    audio.save(`audio-${i++}.wav`);\n  }\n})();\n\n// Next, add text to the stream. Note that the text can be added at different times.\n// For this example, let's pretend we're consuming text from an LLM, one word at a time.\nconst text = \"Kokoro is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, Kokoro can be deployed anywhere from production environments to personal projects. It can even run 100% locally in your browser, powered by Transformers.js!\";\nconst tokens = text.match(/\\s*\\S+/g);\nfor (const token of tokens) {\n  splitter.push(token);\n  await new Promise((resolve) => setTimeout(resolve, 10));\n}\n\n// Finally, close the stream to signal that no more text will be added.\nsplitter.close();\n\n// Alternatively, if you'd like to keep the stream open, but flush any remaining text, you can use the `flush` method.\n// splitter.flush();\n```\n\n----------------------------------------\n\nTITLE: Enabling MacOS Apple Silicon GPU Acceleration\nDESCRIPTION: This snippet demonstrates how to enable GPU acceleration on MacOS M1/M2/M3/M4 devices by setting the `PYTORCH_ENABLE_MPS_FALLBACK` environment variable to 1 before running the Kokoro script. This allows PyTorch to utilize the GPU for faster processing.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nPYTORCH_ENABLE_MPS_FALLBACK=1 python run-your-kokoro-script.py\n```\n\n----------------------------------------\n\nTITLE: Installing Kokoro TTS via NPM\nDESCRIPTION: This command installs the `kokoro-js` library from NPM, which is a prerequisite for using the Kokoro TTS functionality.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/README.md#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nnpm i kokoro-js\n```\n\n----------------------------------------\n\nTITLE: Conda Environment Configuration\nDESCRIPTION: This YAML snippet defines a conda environment for Kokoro, specifying the Python version and required dependencies, including `kokoro`, `soundfile`, and `misaki[en]`. It also includes `libstdcxx` to prevent loading issues with Espeak. This file can be used to create a reproducible environment for running the Kokoro TTS library.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/README.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: kokoro\nchannels:\n  - defaults\ndependencies:\n  - python==3.9       \n  - libstdcxx~=12.4.0 # Needed to load espeak correctly. Try removing this if you're facing issues with Espeak fallback. \n  - pip:\n      - kokoro>=0.3.1\n      - soundfile\n      - misaki[en]\n```\n\n----------------------------------------\n\nTITLE: Building Kokoro.js Dependencies (Shell)\nDESCRIPTION: This command navigates to the kokoro.js directory, installs the necessary npm packages, and builds the project. This step is required before running the demo project.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/demo/README.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ncd kokoro/kokoro.js\nnpm i\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Starting the Development Server (Shell)\nDESCRIPTION: This command starts the development server for the Kokoro Text-to-Speech application. It allows users to access the application through a local host.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/demo/README.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Setting up the Demo Project (Shell)\nDESCRIPTION: This command navigates to the demo directory and installs the necessary npm packages. This depends on the build output from the previous step where kokoro.js dependencies are built.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/demo/README.md#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncd demo\nnpm i\n```\n\n----------------------------------------\n\nTITLE: Cloning the Kokoro Repository (Shell)\nDESCRIPTION: This command clones the Kokoro repository from GitHub. This is the first step in setting up the Kokoro Text-to-Speech application.\nSOURCE: https://github.com/hexgrad/kokoro/blob/main/kokoro.js/demo/README.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ngit clone https://github.com/hexgrad/kokoro.git\n```"
  }
]