[
  {
    "owner": "open-webui",
    "repo": "docs",
    "content": "TITLE: Configuring Open WebUI for Single-User Mode\nDESCRIPTION: Docker command to run Open WebUI with authentication disabled for a single-user setup by setting the WEBUI_AUTH environment variable to False.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/ManualDocker.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -e WEBUI_AUTH=False -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Pipe with Internal Open WebUI Functions\nDESCRIPTION: Example implementation of a Pipe class that uses internal Open WebUI functions for chat completion. Shows how to integrate with the Users model and generate_chat_completion utility, demonstrating proper request handling and user authentication.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/pipe.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\nfrom fastapi import Request\n\nfrom open_webui.models.users import Users\nfrom open_webui.utils.chat import generate_chat_completion\n\nclass Pipe:\n    def __init__(self):\n        pass\n\n    async def pipe(\n        self,\n        body: dict,\n        __user__: dict,\n        __request__: Request,\n    ) -> str:\n        # Use the unified endpoint with the updated signature\n        user = Users.get_user_by_id(__user__[\"id\"])\n        body[\"model\"] = \"llama3.2:latest\"\n        return await generate_chat_completion(__request__, body, user)\n```\n\n----------------------------------------\n\nTITLE: Sending Chat Completion Request via POST in Bash\nDESCRIPTION: This example shows how to send a chat completion request to the Open WebUI API using curl. It includes the model specification and a user message in the request body.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:3000/api/chat/completions \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n      \"model\": \"llama3.1\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"Why is the sky blue?\"\n        }\n      ]\n    }'\n```\n\n----------------------------------------\n\nTITLE: Sending Chat Completion Request in Python\nDESCRIPTION: This Python function demonstrates how to send a chat completion request to the Open WebUI API. It includes authentication, specifies the model, and sends a user message.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef chat_with_model(token):\n    url = 'http://localhost:3000/api/chat/completions'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    }\n    data = {\n      \"model\": \"granite3.1-dense:8b\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"Why is the sky blue?\"\n        }\n      ]\n    }\n    response = requests.post(url, headers=headers, json=data)\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI Package\nDESCRIPTION: Installs the Open WebUI package using pip within the activated Conda environment.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Conda.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install open-webui\n```\n\n----------------------------------------\n\nTITLE: Defining Default RAG Template\nDESCRIPTION: Template configuration for injecting RAG documents into chat completion. Defines task guidelines, citation format, and response structure for handling user queries with context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_11\n\nLANGUAGE: plaintext\nCODE:\n```\n### Task:\nRespond to the user query using the provided context, incorporating inline citations in the format [id] **only when the <source> tag includes an explicit id attribute** (e.g., <source id=\"1\">).\n\n### Guidelines:\n- If you don't know the answer, clearly state that.\n- If uncertain, ask the user for clarification.\n- Respond in the same language as the user's query.\n- If the context is unreadable or of poor quality, inform the user and provide the best possible answer.\n- If the answer isn't present in the context but you possess the knowledge, explain this to the user and provide the answer using your own understanding.\n- **Only include inline citations using [id] (e.g., [1], [2]) when the <source> tag includes an id attribute.**\n- Do not cite if the <source> tag does not contain an id attribute.\n- Do not use XML tags in your response.\n- Ensure citations are concise and directly related to the information provided.\n\n### Example of Citation:\nIf the user asks about a specific topic and the information is found in a source with a provided id attribute, the response should include the citation like in the following example:\n* \"According to the study, the proposed method increases efficiency by 20% [1].\"\n\n### Output:\nProvide a clear and direct response to the user's query, including inline citations in the format [id] only when the <source> tag with id attribute is present in the context.\n\n<context>\n{{CONTEXT}}\n</context>\n\n<user_query>\n{{QUERY}}\n</user_query>\n```\n\n----------------------------------------\n\nTITLE: Updating Docker Container with Watchtower\nDESCRIPTION: Uses Watchtower to automatically update the open-webui container. Requires Docker and Watchtower to be installed.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerUpdating.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for RAG via POST Request in Bash\nDESCRIPTION: This curl command shows how to upload a file for Retrieval Augmented Generation (RAG) using the Open WebUI API. The file content is automatically extracted and stored in a vector database.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST -H \"Authorization: Bearer YOUR_API_KEY\" -H \"Accept: application/json\" \\\n-F \"file=@/path/to/your/file\" http://localhost:3000/api/v1/files/\n```\n\n----------------------------------------\n\nTITLE: OpenAI API Proxy Implementation with Pipe\nDESCRIPTION: Complete implementation of an OpenAI API proxy using Pipe, including model fetching, request handling, and streaming support.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/pipe.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\nimport requests\n\nclass Pipe:\n    class Valves(BaseModel):\n        NAME_PREFIX: str = Field(\n            default=\"OPENAI/\",\n            description=\"Prefix to be added before model names.\",\n        )\n        OPENAI_API_BASE_URL: str = Field(\n            default=\"https://api.openai.com/v1\",\n            description=\"Base URL for accessing OpenAI API endpoints.\",\n        )\n        OPENAI_API_KEY: str = Field(\n            default=\"\",\n            description=\"API key for authenticating requests to the OpenAI API.\",\n        )\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    def pipes(self):\n        if self.valves.OPENAI_API_KEY:\n            try:\n                headers = {\n                    \"Authorization\": f\"Bearer {self.valves.OPENAI_API_KEY}\",\n                    \"Content-Type\": \"application/json\",\n                }\n\n                r = requests.get(\n                    f\"{self.valves.OPENAI_API_BASE_URL}/models\", headers=headers\n                )\n                models = r.json()\n                return [\n                    {\n                        \"id\": model[\"id\"],\n                        \"name\": f'{self.valves.NAME_PREFIX}{model.get(\"name\", model[\"id\"])}',\n                    }\n                    for model in models[\"data\"]\n                    if \"gpt\" in model[\"id\"]\n                ]\n\n            except Exception as e:\n                return [\n                    {\n                        \"id\": \"error\",\n                        \"name\": \"Error fetching models. Please check your API Key.\",\n                    },\n                ]\n        else:\n            return [\n                {\n                    \"id\": \"error\",\n                    \"name\": \"API Key not provided.\",\n                },\n            ]\n\n    def pipe(self, body: dict, __user__: dict):\n        print(f\"pipe:{__name__}\")\n        headers = {\n            \"Authorization\": f\"Bearer {self.valves.OPENAI_API_KEY}\",\n            \"Content-Type\": \"application/json\",\n        }\n\n        # Extract model id from the model name\n        model_id = body[\"model\"][body[\"model\"].find(\".\") + 1 :]\n\n        # Update the model id in the body\n        payload = {**body, \"model\": model_id}\n        try:\n            r = requests.post(\n                url=f\"{self.valves.OPENAI_API_BASE_URL}/chat/completions\",\n                json=payload,\n                headers=headers,\n                stream=True,\n            )\n\n            r.raise_for_status()\n\n            if body.get(\"stream\", False):\n                return r.iter_lines()\n            else:\n                return r.json()\n        except Exception as e:\n            return f\"Error: {e}\"\n```\n\n----------------------------------------\n\nTITLE: Running Watchtower as a Separate Container\nDESCRIPTION: Command to run Watchtower as a separate container that watches for updates to the Open WebUI container every 5 minutes and applies them automatically.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name watchtower \\\n  --volume /var/run/docker.sock:/var/run/docker.sock \\\n  containrrr/watchtower -i 300 open-webui\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for RAG in Python\nDESCRIPTION: This Python function demonstrates how to upload a file for Retrieval Augmented Generation (RAG) using the Open WebUI API. It handles authentication and file upload.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef upload_file(token, file_path):\n    url = 'http://localhost:3000/api/v1/files/'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Accept': 'application/json'\n    }\n    files = {'file': open(file_path, 'rb')}\n    response = requests.post(url, headers=headers, files=files)\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: Using Individual File in Chat Completions in Python\nDESCRIPTION: This Python function shows how to use an individual file in chat completions using the Open WebUI API. It handles authentication, specifies the model, user query, and the file to be used for context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef chat_with_file(token, model, query, file_id):\n    url = 'http://localhost:3000/api/chat/completions'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    }\n    payload = {\n        'model': model,\n        'messages': [{'role': 'user', 'content': query}],\n        'files': [{'type': 'file', 'id': file_id}]\n    }\n    response = requests.post(url, headers=headers, json=payload)\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: Managing Docker Container for Database Import\nDESCRIPTION: Command to stop the Open WebUI Docker container before database import\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/database.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker stop open-webui\n```\n\n----------------------------------------\n\nTITLE: HAProxy Configuration for Open WebUI with HTTPS\nDESCRIPTION: Complete HAProxy configuration example that sets up a reverse proxy for Open WebUI with HTTPS support. Includes global settings, defaults, frontend and backend configurations with support for Let's Encrypt certificate validation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_2\n\nLANGUAGE: haproxy\nCODE:\n```\n #---------------------------------------------------------------------\n# Global settings\n#---------------------------------------------------------------------\nglobal\n    # to have these messages end up in /var/log/haproxy.log you will\n    # need to:\n    #\n    # 1) configure syslog to accept network log events.  This is done\n    #    by adding the '-r' option to the SYSLOGD_OPTIONS in\n    #    /etc/sysconfig/syslog\n    #\n    # 2) configure local2 events to go to the /var/log/haproxy.log\n    #   file. A line like the following can be added to\n    #   /etc/sysconfig/syslog\n    #\n    #    local2.*                       /var/log/haproxy.log\n    #\n    log         127.0.0.1 local2\n\n    chroot      /var/lib/haproxy\n    pidfile     /var/run/haproxy.pid\n    maxconn     4000\n    user        haproxy\n    group       haproxy\n    daemon\n\t\n\t#adjust the dh-param if too low\n    tune.ssl.default-dh-param 2048\n#---------------------------------------------------------------------\n# common defaults that all the 'listen' and 'backend' sections will\n# use if not designated in their block\n#---------------------------------------------------------------------\ndefaults\n    mode                    http\n    log                     global\n    option                  httplog\n    option                  dontlognull\n    option http-server-close\n    option forwardfor       #except 127.0.0.0/8\n    option                  redispatch\n    retries                 3\n    timeout http-request    300s\n    timeout queue           2m\n    timeout connect         120s\n    timeout client          10m\n    timeout server          10m\n    timeout http-keep-alive 120s\n    timeout check           10s\n    maxconn                 3000\n\n#http\nfrontend web\n\t#Non-SSL\n    bind 0.0.0.0:80\n\t#SSL/TLS\n\tbind 0.0.0.0:443 ssl crt /path/to/ssl/folder/\n\n    #Let's Encrypt SSL\n    acl letsencrypt-acl path_beg /.well-known/acme-challenge/\n    use_backend letsencrypt-backend if letsencrypt-acl\n\n\t#Subdomain method\n    acl chat-acl hdr(host) -i subdomain.domain.tld\n    #Path Method\n    acl chat-acl path_beg /owui/\n    use_backend owui_chat if chat-acl\n\n#Pass SSL Requests to Lets Encrypt\nbackend letsencrypt-backend\n    server letsencrypt 127.0.0.1:8688\n    \n#OWUI Chat\nbackend owui_chat\n    # add X-FORWARDED-FOR\n    option forwardfor\n    # add X-CLIENT-IP\n    http-request add-header X-CLIENT-IP %[src]\n\thttp-request set-header X-Forwarded-Proto https if { ssl_fc }\n    server chat <ip>:3000\n```\n\n----------------------------------------\n\nTITLE: Adding Files to Knowledge Collections in Python\nDESCRIPTION: This Python function shows how to add a file to a knowledge collection using the Open WebUI API. It handles authentication and sends the file ID to be added to the specified knowledge collection.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef add_file_to_knowledge(token, knowledge_id, file_id):\n    url = f'http://localhost:3000/api/v1/knowledge/{knowledge_id}/file/add'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    }\n    data = {'file_id': file_id}\n    response = requests.post(url, headers=headers, json=data)\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: Adding Files to Knowledge Collections via POST Request in Bash\nDESCRIPTION: This curl command demonstrates how to add a file to a knowledge collection using the Open WebUI API. It requires the knowledge collection ID and the file ID.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:3000/api/v1/knowledge/{knowledge_id}/file/add \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"file_id\": \"your-file-id-here\"}'\n```\n\n----------------------------------------\n\nTITLE: Docker Compose with Integrated Watchtower\nDESCRIPTION: A Docker Compose configuration that includes both Open WebUI and Watchtower services, allowing automatic updates of Open WebUI every 5 minutes.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_8\n\nLANGUAGE: yml\nCODE:\n```\nversion: '3'\nservices:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    ports:\n      - \"3000:8080\"\n    volumes:\n      - open-webui:/app/backend/data\n\n  watchtower:\n    image: containrrr/watchtower\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    command: --interval 300 open-webui\n    depends_on:\n      - open-webui\n\nvolumes:\n  open-webui:\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Models via GET Request in Bash\nDESCRIPTION: This snippet demonstrates how to fetch all models created or added via Open WebUI using a curl GET request. It requires authentication with an API key.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" http://localhost:3000/api/models\n```\n\n----------------------------------------\n\nTITLE: Running Open-WebUI Container with Podman\nDESCRIPTION: Basic command to run Open-WebUI container with port mapping and volume mounting. Maps port 3000 to container port 8080 and creates a persistent volume.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/Podman.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npodman run -d --name openwebui -p 3000:8080 -v open-webui:/app/backend/data ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Stopping and Removing Open WebUI Docker Container\nDESCRIPTION: Command to stop and remove the current Open WebUI Docker container while preserving data stored in the Docker volume.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker rm -f open-webui\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with NVIDIA GPU Support\nDESCRIPTION: Docker command to run Open WebUI with NVIDIA GPU acceleration. This setup enables GPU resources for models that can benefit from GPU acceleration while maintaining the same networking and storage configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda\n```\n\n----------------------------------------\n\nTITLE: Basic Skeleton of a Filter Function in Python\nDESCRIPTION: The fundamental structure of a Filter Function in Open WebUI, showing the Valves class for configuration options and the three main methods: inlet for manipulating user inputs, stream for modifying streamed model outputs, and outlet for manipulating final model outputs.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import Optional\n\nclass Filter:\n    # Valves: Configuration options for the filter\n    class Valves(BaseModel):  \n        pass\n\n    def __init__(self):\n        # Initialize valves (optional configuration for the Filter)\n        self.valves = self.Valves()\n\n    def inlet(self, body: dict) -> dict:\n        # This is where you manipulate user inputs.\n        print(f\"inlet called: {body}\")\n        return body  \n\n    def stream(self, event: dict) -> dict:\n        # This is where you modify streamed chunks of model output.\n        print(f\"stream event: {event}\")\n        return event\n\n    def outlet(self, body: dict) -> None:\n        # This is where you manipulate model outputs.\n        print(f\"outlet called: {body}\")\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with Nvidia GPU Support\nDESCRIPTION: Docker command for running Open WebUI with Nvidia GPU acceleration enabled, using the CUDA-specific image.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/ManualDocker.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --gpus all -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:cuda\n```\n\n----------------------------------------\n\nTITLE: Launching Open WebUI with S3 Storage Configuration\nDESCRIPTION: Docker command to run Open WebUI with Amazon S3 storage configuration. Sets up environment variables for S3 connectivity including access keys, endpoint URL, region, and bucket name. Also enables development mode for Swagger documentation access.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/s3-storage.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ndocker run -d \\\n  -p 3000:8080 \\\n  -v open-webui:/app/backend/data \\\n  -e STORAGE_PROVIDER=\"s3\" \\\n  -e S3_ACCESS_KEY_ID=\"ABC123\" \\\n  -e S3_SECRET_ACCESS_KEY=\"SuperSecret\" \\\n  -e S3_ENDPOINT_URL=\"https://s3.us-east-1.amazonaws.com\" \\\n  -e S3_REGION_NAME=\"us-east-1\" \\\n  -e S3_BUCKET_NAME=\"my-awesome-bucket-name\" \\\n  -e ENV=\"dev\" \\\n  --name open-webui \\\n  ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: WebUI Configuration Parameters\nDESCRIPTION: Core configuration parameters for the Web UI including security, CORS, and operational modes. These settings control basic functionality and security features of the web interface.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_7\n\nLANGUAGE: plaintext\nCODE:\n```\nWEBUI_SECRET_KEY=t0p-s3cr3t\nOFFLINE_MODE=False\nRESET_CONFIG_ON_START=False\nSAFE_MODE=False\nCORS_ALLOW_ORIGIN=*\n```\n\n----------------------------------------\n\nTITLE: Refactoring Custom Function for Open WebUI 0.5 in Python\nDESCRIPTION: Shows how to update a custom function to match the new structure in Open WebUI 0.5, including changes to imports, function signatures, and the addition of the Request object.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/migration/index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom fastapi import Request\n\nfrom open_webui.utils.chat import generate_chat_completion\n\n\nclass User(BaseModel):\n    id: str\n    email: str\n    name: str\n    role: str\n\n\nclass Pipe:\n    def __init__(self):\n        pass\n\n    async def pipe(\n        self,\n        body: dict,\n        __user__: dict,\n        __request__: Request,\n    ) -> str:\n        # Uses the unified endpoint with updated signature\n        user = User(**__user__)\n        body[\"model\"] = \"llama3.2:latest\"\n        return await generate_chat_completion(__request__, body, user)\n```\n\n----------------------------------------\n\nTITLE: Basic Docker Compose Configuration for Open WebUI\nDESCRIPTION: Basic Docker Compose configuration file that sets up Open WebUI with port mapping and volume persistence. Maps port 3000 to container port 8080 and creates a named volume for data persistence.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerCompose.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3'\nservices:\n  openwebui:\n    image: ghcr.io/open-webui/open-webui:main\n    ports:\n      - \"3000:8080\"\n    volumes:\n      - open-webui:/app/backend/data\nvolumes:\n  open-webui:\n```\n\n----------------------------------------\n\nTITLE: Deleting webui.db to Reset Open WebUI\nDESCRIPTION: Command to delete the webui.db file, which completely resets Open WebUI by removing all stored data, including user accounts, settings, and passwords. Only use this if you want to start fresh.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf /path/to/your/python/environment/lib/pythonX.X/site-packages/open_webui/data/webui.db\n```\n\n----------------------------------------\n\nTITLE: Using Knowledge Collection in Chat Completions via POST Request in Bash\nDESCRIPTION: This curl command demonstrates how to use a knowledge collection in chat completions using the Open WebUI API. It specifies the model, user message, and the collection to be used for context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:3000/api/chat/completions \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n      \"model\": \"gpt-4-turbo\",\n      \"messages\": [\n        {\"role\": \"user\", \"content\": \"Provide insights on the historical perspectives covered in the collection.\"}\n      ],\n      \"files\": [\n        {\"type\": \"collection\", \"id\": \"your-collection-id-here\"}\n      ]\n    }'\n```\n\n----------------------------------------\n\nTITLE: Using Knowledge Collection in Chat Completions in Python\nDESCRIPTION: This Python function shows how to use a knowledge collection in chat completions using the Open WebUI API. It handles authentication, specifies the model, user query, and the collection to be used for context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef chat_with_collection(token, model, query, collection_id):\n    url = 'http://localhost:3000/api/chat/completions'\n    headers = {\n        'Authorization': f'Bearer {token}',\n        'Content-Type': 'application/json'\n    }\n    payload = {\n        'model': model,\n        'messages': [{'role': 'user', 'content': query}],\n        'files': [{'type': 'collection', 'id': collection_id}]\n    }\n    response = requests.post(url, headers=headers, json=payload)\n    return response.json()\n```\n\n----------------------------------------\n\nTITLE: Authentik OAuth Configuration for Open WebUI\nDESCRIPTION: Environment variable configuration for setting up Authentik OAuth integration with Open WebUI. Includes OpenID Connect settings and OAuth scopes configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/sso.md#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n      - 'ENABLE_OAUTH_SIGNUP=true'\n      - 'OAUTH_MERGE_ACCOUNTS_BY_EMAIL=true'\n      - 'OAUTH_PROVIDER_NAME=Authentik'\n      - 'OPENID_PROVIDER_URL=https://<authentik-url>/application/o/<App-name>/.well-known/openid-configuration'\n      - 'OAUTH_CLIENT_ID=<Client-ID>'\n      - 'OAUTH_CLIENT_SECRET=<Client-Secret>'\n      - 'OAUTH_SCOPES=openid email profile'\n      - 'OPENID_REDIRECT_URI=https://<open-webui>/oauth/oidc/callback'\n```\n\n----------------------------------------\n\nTITLE: Cleaning User Input by Removing Unwanted Characters\nDESCRIPTION: An inlet function example that cleans the user's input by removing excessive punctuation and whitespace before sending it to the LLM, improving the quality of the input.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n    # Clean the last user input (from the end of the 'messages' list)\n    last_message = body[\"messages\"][-1][\"content\"]\n    body[\"messages\"][-1][\"content\"] = last_message.replace(\"!!!\", \"\").strip()\n    return body\n```\n\n----------------------------------------\n\nTITLE: Pulling Latest Open WebUI Docker Image\nDESCRIPTION: Command to download the latest version of the Open WebUI Docker image from the GitHub Container Registry.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Basic Pipe Structure Implementation in Python\nDESCRIPTION: Basic implementation of a Pipe class showing core structure with Valves configuration, initialization, and pipe function.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/pipe.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass Pipe:\n    class Valves(BaseModel):\n        MODEL_ID: str = Field(default=\"\")\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    def pipe(self, body: dict):\n        # Logic goes here\n        print(self.valves, body)  # This will print the configuration options and the input body\n        return \"Hello, World!\"\n```\n\n----------------------------------------\n\nTITLE: Activating Open WebUI Conda Environment\nDESCRIPTION: Activates the previously created 'open-webui' Conda environment to prepare for package installation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Conda.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda activate open-webui\n```\n\n----------------------------------------\n\nTITLE: Configuring Nginx for Open WebUI Proxy\nDESCRIPTION: Nginx configuration file that sets up reverse proxy for Open WebUI with WebSocket support, security headers, and optional performance settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_1\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n    listen 80;\n    server_name your_domain_or_IP;\n\n    location / {\n        proxy_pass http://host.docker.internal:3000;\n\n        # Add WebSocket support (Necessary for version 0.5.0 and up)\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # (Optional) Disable proxy buffering for better streaming response from models\n        proxy_buffering off;\n\n        # (Optional) Increase max request size for large attachments and long audio messages\n        client_max_body_size 20M;\n        proxy_read_timeout 10m;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up OAuth2-Proxy with Open WebUI\nDESCRIPTION: Docker Compose configuration for implementing OAuth2-Proxy with Open WebUI, specifically configured for Google OAuth. Includes environment variables for OAuth configuration and proxy settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/sso.md#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    volumes:\n      - open-webui:/app/backend/data\n    environment:\n      - 'HOST=127.0.0.1'\n      - 'WEBUI_AUTH_TRUSTED_EMAIL_HEADER=X-Forwarded-Email'\n      - 'WEBUI_AUTH_TRUSTED_NAME_HEADER=X-Forwarded-User'\n    restart: unless-stopped\n  oauth2-proxy:\n    image: quay.io/oauth2-proxy/oauth2-proxy:v7.6.0\n    environment:\n      OAUTH2_PROXY_HTTP_ADDRESS: 0.0.0.0:4180\n      OAUTH2_PROXY_UPSTREAMS: http://open-webui:8080/\n      OAUTH2_PROXY_PROVIDER: google\n      OAUTH2_PROXY_CLIENT_ID: REPLACEME_OAUTH_CLIENT_ID\n      OAUTH2_PROXY_CLIENT_SECRET: REPLACEME_OAUTH_CLIENT_ID\n      OAUTH2_PROXY_EMAIL_DOMAINS: REPLACEME_ALLOWED_EMAIL_DOMAINS\n      OAUTH2_PROXY_REDIRECT_URL: REPLACEME_OAUTH_CALLBACK_URL\n      OAUTH2_PROXY_COOKIE_SECRET: REPLACEME_COOKIE_SECRET\n      OAUTH2_PROXY_COOKIE_SECURE: \"false\"\n    restart: unless-stopped\n    ports:\n      - 4180:4180/tcp\n```\n\n----------------------------------------\n\nTITLE: Restarting Open WebUI Container with Updated Image\nDESCRIPTION: Command to start the Open WebUI container with the updated image while attaching the existing volume to preserve data. For Nvidia GPU support, add --gpus all to the command.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Running Bedrock Access Gateway Docker Container\nDESCRIPTION: This bash command builds and runs a Docker container for the Bedrock Access Gateway. It sets necessary AWS environment variables and exposes the gateway on port 8000.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/amazon-bedrock.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker build . -f Dockerfile -t bedrock-gateway\n\ndocker run -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN -e AWS_REGION=us-east-1 -d -p 8000:80 bedrock-gateway\n```\n\n----------------------------------------\n\nTITLE: Refreshing Frontend Dependencies\nDESCRIPTION: This command removes the existing node_modules directory and reinstalls all dependencies. It's used to resolve issues with outdated or corrupted frontend dependencies that may interfere with hot reloading.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nrm -rf node_modules && npm install\n```\n\n----------------------------------------\n\nTITLE: Configuring Brave API Environment Variables in Docker Compose for Open WebUI\nDESCRIPTION: This YAML snippet shows the environment variable configuration needed in the docker-compose.yaml file to enable and configure Brave API for web search in Open WebUI. It includes settings for enabling RAG web search, specifying Brave as the search engine, setting the API key, and configuring search result count and concurrent requests.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/brave.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  open-webui:\n    environment:\n      ENABLE_RAG_WEB_SEARCH: True\n      RAG_WEB_SEARCH_ENGINE: \"brave\"\n      BRAVE_SEARCH_API_KEY: \"YOUR_API_KEY\"\n      RAG_WEB_SEARCH_RESULT_COUNT: 3\n      RAG_WEB_SEARCH_CONCURRENT_REQUESTS: 10\n```\n\n----------------------------------------\n\nTITLE: Defining Default Tools Function Calling Prompt Template in Markdown\nDESCRIPTION: This snippet defines the default prompt template used for calling tools. It provides guidelines for choosing and returning the correct tool(s) based on a given query, including JSON formatting instructions.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n```\nAvailable Tools: {{TOOLS}}\n\nYour task is to choose and return the correct tool(s) from the list of available tools based on the query. Follow these guidelines:\n\n- Return only the JSON object, without any additional text or explanation.\n\n- If no tools match the query, return an empty array: \n   {\n     \"tool_calls\": []\n   }\n\n- If one or more tools match the query, construct a JSON response containing a \"tool_calls\" array with objects that include:\n   - \"name\": The tool's name.\n   - \"parameters\": A dictionary of required parameters and their corresponding values.\n\nThe format for the JSON response is strictly:\n{\n  \"tool_calls\": [\n    {\"name\": \"toolName1\", \"parameters\": {\"key1\": \"value1\"}},\n    {\"name\": \"toolName2\", \"parameters\": {\"key2\": \"value2\"}}\n  ]\n}\n```\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Open WebUI\nDESCRIPTION: Docker Compose configuration for integrating SearXNG with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  open-webui:\n    environment:\n      ENABLE_RAG_WEB_SEARCH: True\n      RAG_WEB_SEARCH_ENGINE: \"searxng\"\n      RAG_WEB_SEARCH_RESULT_COUNT: 3\n      RAG_WEB_SEARCH_CONCURRENT_REQUESTS: 10\n      SEARXNG_QUERY_URL: \"http://searxng:8080/search?q=<query>\"\n```\n\n----------------------------------------\n\nTITLE: Using Individual File in Chat Completions via POST Request in Bash\nDESCRIPTION: This curl command demonstrates how to use an individual file in chat completions using the Open WebUI API. It specifies the model, user message, and the file to be used for context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:3000/api/chat/completions \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\n      \"model\": \"gpt-4-turbo\",\n      \"messages\": [\n        {\"role\": \"user\", \"content\": \"Explain the concepts in this document.\"}\n      ],\n      \"files\": [\n        {\"type\": \"file\", \"id\": \"your-file-id-here\"}\n      ]\n    }'\n```\n\n----------------------------------------\n\nTITLE: Setting Debug Level in Docker Run Command\nDESCRIPTION: Example of setting the global logging level to DEBUG using Docker run parameters.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/logging.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n--env GLOBAL_LOG_LEVEL=\"DEBUG\"\n```\n\n----------------------------------------\n\nTITLE: Syncing Branch with Dev in Git\nDESCRIPTION: Commands for synchronizing a feature branch with the latest changes from the dev branch to minimize merge conflicts.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout dev\ngit pull origin dev\ngit checkout my-feature-branch\ngit merge dev\n```\n\n----------------------------------------\n\nTITLE: Testing Deep Model Health with Chat Completion Request\nDESCRIPTION: An advanced curl command that tests the full model pipeline by sending a simple chat completion request. This comprehensive test verifies that models can actually process requests and generate valid responses.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/monitoring.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Test model response - authenticated POST request\ncurl -X POST https://your-open-webui-instance/api/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [{\"role\": \"user\", \"content\": \"Respond with the word HEALTHY\"}],\n    \"model\": \"llama3.1\",  # Replace with a model you expect to be available\n    \"temperature\": 0      # Set temperature to 0 for consistent responses\n  }'\n```\n\n----------------------------------------\n\nTITLE: Configuring Redis Docker Compose Setup\nDESCRIPTION: Docker Compose configuration for setting up a Redis container with websocket support. Includes volume mounting, healthcheck configuration, and network settings for Open WebUI integration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/redis.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3.9'\nservices:\n  redis:\n    image: docker.io/valkey/valkey:8.0.1-alpine\n    container_name: redis-valkey\n    volumes:\n      - redis-data:/data\n    command: \"valkey-server --save 30 1\"\n    healthcheck:\n      test: \"[ $$(valkey-cli ping) = 'PONG' ]\"\n      start_period: 5s\n      interval: 1s\n      timeout: 3s\n      retries: 5\n    restart: unless-stopped\n    cap_drop:\n      - ALL\n    cap_add:\n      - SETGID\n      - SETUID\n      - DAC_OVERRIDE\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"1m\"\n        max-file: \"1\"\n    networks:\n      - openwebui-network\n\nvolumes:\n  redis-data:\n\nnetworks:\n  openwebui-network:\n    external: true\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for Open WebUI and Jupyter\nDESCRIPTION: Docker compose configuration to launch both Open WebUI and Jupyter Notebook services with appropriate volumes, ports, and environment variables. Sets up Jupyter with a token authentication and enables Jupyter Lab.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/jupyter.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\n\nservices:\nopen-webui:\n  image: ghcr.io/open-webui/open-webui:latest\n  container_name: open-webui\n  ports:\n    - \"3000:8080\"\n  volumes:\n    - open-webui:/app/backend/data\n\njupyter:\n  image: jupyter/minimal-notebook:latest\n  container_name: jupyter-notebook\n  ports:\n    - \"8888:8888\"\n  volumes:\n    - jupyter_data:/home/jovyan/work\n  environment:\n    - JUPYTER_ENABLE_LAB=yes\n    - JUPYTER_TOKEN=123456\n\nvolumes:\n  open-webui:\n  jupyter_data:\n```\n\n----------------------------------------\n\nTITLE: Running the Open WebUI Container with Default Settings\nDESCRIPTION: Basic Docker command to run Open WebUI with volume mapping for data persistence and port mapping to access the UI on localhost:3000.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/ManualDocker.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Installing HAProxy and Let's Encrypt on RedHat Systems\nDESCRIPTION: Command to install HAProxy, Let's Encrypt's certbot, and OpenSSL on RedHat-based Linux distributions using dnf package manager.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo dnf install haproxy certbot openssl -y\n```\n\n----------------------------------------\n\nTITLE: Configuring SearXNG Query URL in Open WebUI\nDESCRIPTION: Examples of how to set the 'Searxng Query URL' in the Open WebUI settings for different deployment scenarios. The URL structure is crucial for proper functionality.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n* `http://searxng:8080/search?q=<query>` (using the container name and exposed port, suitable for Docker-based setups)\n* `http://host.docker.internal:8080/search?q=<query>` (using the `host.docker.internal` DNS name and the host port, suitable for Docker-based setups)\n* `http://<searxng.local>/search?q=<query>` (using a local domain name, suitable for local network access)\n* `https://<search.domain.com>/search?q=<query>` (using a custom domain name for a self-hosted SearXNG instance, suitable for public or private access)\n\n**Do note the `/search?q=<query>` part is mandatory.**\n```\n\n----------------------------------------\n\nTITLE: Setting up Docker's apt repository on Ubuntu\nDESCRIPTION: This bash script sets up Docker's apt repository on Ubuntu. It updates the package list, installs necessary certificates, creates a keyring directory, downloads Docker's GPG key, and adds the Docker repository to the system's sources.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/docker-install.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n```\n\n----------------------------------------\n\nTITLE: Checking Model Connectivity with Authenticated API Request\nDESCRIPTION: A curl command that tests Open WebUI's ability to connect to model providers by accessing the /api/models endpoint. This request requires authentication with an API key to verify model availability.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/monitoring.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Authenticated model connectivity check\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" https://your-open-webui-instance/api/models\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Open WebUI with Tailscale Authentication\nDESCRIPTION: Docker Compose setup for Open WebUI with Tailscale integration for authentication. The configuration includes two services: the Open WebUI service configured to trust Tailscale headers for authentication, and a Tailscale sidecar service that provides the authentication layer.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/sso.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n---\nservices:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    volumes:\n      - open-webui:/app/backend/data\n    environment:\n      - HOST=127.0.0.1\n      - WEBUI_AUTH_TRUSTED_EMAIL_HEADER=Tailscale-User-Login\n      - WEBUI_AUTH_TRUSTED_NAME_HEADER=Tailscale-User-Name\n    restart: unless-stopped\n  tailscale:\n    image: tailscale/tailscale:latest\n    environment:\n      - TS_AUTH_ONCE=true\n      - TS_AUTHKEY=${TS_AUTHKEY}\n      - TS_EXTRA_ARGS=--advertise-tags=tag:open-webui\n      - TS_SERVE_CONFIG=/config/serve.json\n      - TS_STATE_DIR=/var/lib/tailscale\n      - TS_HOSTNAME=open-webui\n    volumes:\n      - tailscale:/var/lib/tailscale\n      - ./tailscale:/config\n      - /dev/net/tun:/dev/net/tun\n    cap_add:\n      - net_admin\n      - sys_module\n    restart: unless-stopped\n\nvolumes:\n  open-webui: {}\n  tailscale: {}\n```\n\n----------------------------------------\n\nTITLE: Exporting Database from Docker Container\nDESCRIPTION: Command to copy the webui.db file from the Open WebUI Docker container to the local machine\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/database.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker cp open-webui:/app/backend/data/webui.db ./webui.db\n```\n\n----------------------------------------\n\nTITLE: Configuring Core OIDC and Group Management Settings\nDESCRIPTION: Essential environment variables for setting up Okta OIDC authentication in Open WebUI. Includes core SSO settings and optional group management configuration variables.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/okta-oidc-sso.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# --- OIDC Core Settings ---\n# Enable OAuth signup if you want users to be able to create accounts via Okta\n# ENABLE_OAUTH_SIGNUP=\"true\"\n\n# Your Okta application's Client ID\nOAUTH_CLIENT_ID=\"YOUR_OKTA_CLIENT_ID\"\n\n# Your Okta application's Client Secret\nOAUTH_CLIENT_SECRET=\"YOUR_OKTA_CLIENT_SECRET\"\n\n# Your Okta organization's OIDC discovery URL\n# Format: https://<your-okta-domain>/.well-known/openid-configuration\n# Or for a specific authorization server: https://<your-okta-domain>/oauth2/<auth-server-id>/.well-known/openid-configuration\nOPENID_PROVIDER_URL=\"YOUR_OKTA_OIDC_DISCOVERY_URL\"\n\n# Name displayed on the login button (e.g., \"Login with Okta\")\nOAUTH_PROVIDER_NAME=\"Okta\"\n\n# Scopes to request (default is usually sufficient)\n# OAUTH_SCOPES=\"openid email profile groups\" # Ensure 'groups' is included if not default\n\n# --- OAuth Group Management (Optional) ---\n# Set to \"true\" only if you configured the Groups Claim in Okta (Step 2)\n# and want Open WebUI groups to be managed based on Okta groups upon login.\n# This syncs existing groups. Users will be added/removed from Open WebUI groups\n# to match their Okta group claims.\n# ENABLE_OAUTH_GROUP_MANAGEMENT=\"true\"\n\n# Required only if ENABLE_OAUTH_GROUP_MANAGEMENT is true.\n# The claim name in the ID token containing group information (must match Okta config)\n# OAUTH_GROUP_CLAIM=\"groups\"\n\n# Optional: Enable Just-in-Time (JIT) creation of groups if they exist in Okta claims but not in Open WebUI.\n# Requires ENABLE_OAUTH_GROUP_MANAGEMENT=\"true\".\n# If set to false (default), only existing groups will be synced.\n# ENABLE_OAUTH_GROUP_CREATION=\"false\"\n```\n\n----------------------------------------\n\nTITLE: Defining Docker Volumes for Ollama and Open WebUI\nDESCRIPTION: YAML configuration for defining Docker volumes to persist data for Ollama and Open WebUI containers.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nollama:\n  volumes:\n    - ollama:/root/.ollama\n\nopen-webui:\n  volumes:\n    - open-webui:/app/backend/data\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings via Ollama API Proxy in Bash\nDESCRIPTION: This curl command demonstrates how to generate embeddings for given inputs using the Ollama API proxy provided by Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:3000/ollama/api/embed -d '{\n  \"model\": \"llama3.2\",\n  \"input\": [\"Open WebUI is great!\", \"Let's generate embeddings.\"]\n}'\n```\n\n----------------------------------------\n\nTITLE: Generating Completion via Ollama API Proxy in Bash\nDESCRIPTION: This curl command demonstrates how to generate a completion using the Ollama API proxy provided by Open WebUI. It specifies the model and prompt in the request body.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://localhost:3000/ollama/api/generate -d '{\n  \"model\": \"llama3.2\",\n  \"prompt\": \"Why is the sky blue?\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Defining Default Title Generation Prompt Template in Markdown\nDESCRIPTION: This snippet defines the default prompt template used for generating chat titles. It provides guidelines for creating concise, 3-5 word titles with an emoji that summarize the chat history.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n```\n### Task:\nGenerate a concise, 3-5 word title with an emoji summarizing the chat history.\n### Guidelines:\n- The title should clearly represent the main theme or subject of the conversation.\n- Use emojis that enhance understanding of the topic, but avoid quotation marks or special formatting.\n- Write the title in the chat's primary language; default to English if multilingual.\n- Prioritize accuracy over excessive creativity; keep it clear and simple.\n### Output:\nJSON format: { \"title\": \"your concise title here\" }\n### Examples:\n- { \"title\": \"📉 Stock Market Trends\" },\n- { \"title\": \"🍪 Perfect Chocolate Chip Recipe\" },\n- { \"title\": \"Evolution of Music Streaming\" },\n- { \"title\": \"Remote Work Productivity Tips\" },\n- { \"title\": \"Artificial Intelligence in Healthcare\" },\n- { \"title\": \"🎮 Video Game Development Insights\" }\n### Chat History:\n<chat_history>\n{{MESSAGES:END:2}}\n</chat_history>\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Nginx for Open WebUI with SSL (Windows)\nDESCRIPTION: Nginx configuration file setup for proxying Open WebUI with SSL support. It includes settings for HTTPS, WebSocket support, and optional configurations for better streaming and large file uploads.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/Windows.md#2025-04-23_snippet_3\n\nLANGUAGE: nginx\nCODE:\n```\n#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    #log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n    #                  '$status $body_bytes_sent \"$http_referer\" '\n    #                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    #access_log  logs/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #keepalive_timeout  0;\n    keepalive_timeout  120;\n\n    #gzip  on;\n\n    # needed to properly handle websockets (streaming)\n    map $http_upgrade $connection_upgrade {\n        default upgrade;\n        ''      close;\n    }\n\n    # Redirect all HTTP traffic to HTTPS\n    server {\n        listen 80;\n        server_name 192.168.1.15;\n\n        return 301 https://$host$request_uri;\n    }\n\n    # Handle HTTPS traffic\n    server {\n        listen 443 ssl;\n        server_name 192.168.1.15;\n\n        # SSL Settings (ensure paths are correct)\n        ssl_certificate C:\\\\nginx\\\\nginx.crt;\n        ssl_certificate_key C:\\\\nginx\\\\nginx.key;\n        ssl_protocols TLSv1.2 TLSv1.3;\n        ssl_ciphers ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;\n        ssl_prefer_server_ciphers on;\n\n        # OCSP Stapling\n        #ssl_stapling on;\n        #ssl_stapling_verify on;\n\n        # Proxy settings to your local service\n        location / {\n            # proxy_pass should point to your running localhost version of open-webui\n            proxy_pass http://localhost:8080;\n\n            # Add WebSocket support (Necessary for version 0.5.0 and up)\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection $connection_upgrade;\n\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # (Optional) Disable proxy buffering for better streaming response from models\n            proxy_buffering off;\n\n            # (Optional) Increase max request size for large attachments and long audio messages\n            client_max_body_size 20M;\n            proxy_read_timeout 10m;\n        }\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Automatic Updates for Open WebUI\nDESCRIPTION: Docker command to set up automatic updates for Open WebUI every 5 minutes using Watchtower. This persistent container monitors for new image versions and keeps Open WebUI updated.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name watchtower --restart unless-stopped -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --interval 300 open-webui\n```\n\n----------------------------------------\n\nTITLE: Complete Continue.dev Configuration Example\nDESCRIPTION: A comprehensive example configuration for Continue.dev that sets up multiple models to work with Open WebUI, including models directly from Ollama and from pipeline setups. Includes test prompt configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/continue-dev.md#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: Local Assistant\nversion: 1.0.0\nschema: v1\nmodels:\n  - name: Granite Code\n    provider: openai\n    model: granite-code:latest\n    env:\n      useLegacyCompletionsEndpoint: false\n    apiBase: http://YOUROPENWEBUI/ollama/v1\n    apiKey: sk-YOUR-API-KEY\n    roles:\n      - chat\n      - edit\n\n  - name: Model ABC from pipeline\n    provider: openai\n    model: PIPELINE_MODEL_ID\n    env:\n      useLegacyCompletionsEndpoint: false\n    apiBase: http://YOUROPENWEBUI/api\n    apiKey: sk-YOUR-API-KEY\n    roles:\n      - chat\n      - edit\n\n  - name: Granite Code Autocomplete\n    provider: openai\n    model: granite-code:latest\n    env:\n      useLegacyCompletionsEndpoint: false\n    apiBase: http://localhost:3000/ollama/v1\n    apiKey: sk-YOUR-API-KEY\n    roles:\n      - autocomplete\n\nprompts:\n  - name: test\n    description: Write unit tests for highlighted code\n    prompt: |\n      Write a comprehensive set of unit tests for the selected code. It should setup, run tests that check for correctness including important edge cases, and teardown. Ensure that the tests are complete and sophisticated. Give the tests just as chat output, don't edit any file.\n```\n\n----------------------------------------\n\nTITLE: Docker Configuration for Hugging Face SSL Issues\nDESCRIPTION: Docker command to handle Hugging Face SSL connection issues by specifying an alternative endpoint and setting up host gateway access. Configures port mapping and persistent storage.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/connection-error.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -e HF_ENDPOINT=https://hf-mirror.com/ --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Rsync Backup Script with Container Interruption for Open WebUI\nDESCRIPTION: Bash script that stops the Docker Compose environment, performs the backup using rsync, and then restarts the environment. This ensures data integrity by backing up cold filesystems.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\n# Configuration\nCOMPOSE_FILE=\"docker-compose.yml\" # Path to your docker-compose.yml file\nB2_BUCKET=\"b2://OpenWebUI-backups\" # Your Backblaze B2 bucket\nB2_PROFILE=\"your_rclone_profile\" # Your rclone profile name\nSOURCE_DIR=\".\"  # Current directory (where the file structure resides)\n\n# Define source and destination directories\nSOURCE_UPLOADS=\"$SOURCE_DIR/uploads\"\nSOURCE_VECTORDB=\"$SOURCE_DIR/vector_db\"\nSOURCE_WEBUI_DB=\"$SOURCE_DIR/webui.db\"\n\nDEST_UPLOADS=\"$B2_BUCKET/user_uploads\"\nDEST_CHROMADB=\"$B2_BUCKET/ChromaDB\"\nDEST_MAIN_DB=\"$B2_BUCKET/main_database\"\n\n# Exclude cache and audit.log\nEXCLUDE_LIST=(\n    \"cache/\"\n    \"audit.log\"\n)\n\n# Construct exclude arguments for rclone\nEXCLUDE_ARGS=\"\"\nfor EXCLUDE in \"${EXCLUDE_LIST[@]}\"; do\n    EXCLUDE_ARGS=\"$EXCLUDE_ARGS --exclude '$EXCLUDE'\"\ndone\n\n# Function to perform rclone sync with error checking\nrclone_sync() {\n    SOURCE=\"$1\"\n    DEST=\"$2\"\n    echo \"Syncing '$SOURCE' to '$DEST'...\"\n    rclone sync \"$SOURCE\" \"$DEST\" $EXCLUDE_ARGS --progress --transfers=32 --checkers=16 --profile \"$B2_PROFILE\"\n    if [ $? -ne 0 ]; then\n        echo \"Error: rclone sync failed for '$SOURCE' to '$DEST'\"\n        exit 1\n    fi\n}\n\n# 1. Stop the Docker Compose environment\necho \"Stopping Docker Compose environment...\"\ndocker-compose -f \"$COMPOSE_FILE\" down\n\n# 2. Perform the backup\necho \"Starting backup...\"\nrclone_sync \"$SOURCE_UPLOADS\" \"$DEST_UPLOADS\"\nrclone_sync \"$SOURCE_VECTORDB\" \"$DEST_CHROMADB\"\nrclone_sync \"$SOURCE_WEBUI_DB\" \"$DEST_MAIN_DB\"\n\n# 3. Start the Docker Compose environment\necho \"Starting Docker Compose environment...\"\ndocker-compose -f \"$COMPOSE_FILE\" up -d\n\necho \"Backup completed successfully.\"\nexit 0\n```\n\n----------------------------------------\n\nTITLE: Disabling Standard Login Form Configuration\nDESCRIPTION: Environment variable setting to disable the default email/password login form when using only OAuth-based authentication.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/okta-oidc-sso.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nENABLE_LOGIN_FORM=\"false\"\n```\n\n----------------------------------------\n\nTITLE: Combining SSL Certificate and Key for HAProxy\nDESCRIPTION: Command to combine the SSL certificate and private key files into a single PEM file that HAProxy can use. This format is required by HAProxy for SSL termination.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncat /tmp/haproxy.crt /tmp/haproxy.key > /etc/haproxy/certs/haproxy.pem\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI with Docker for Local Ollama\nDESCRIPTION: Docker command to run Open WebUI connected to a locally installed Ollama instance. This configuration maps port 3000 to the container's port 8080, adds host access, and creates a persistent volume for data storage.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Configuring Session Persistence for Multi-Node Deployments\nDESCRIPTION: Environment variable configuration for maintaining session persistence across multiple Open WebUI nodes in distributed deployments.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/okta-oidc-sso.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Example: Generate a strong secret key (e.g., using openssl rand -hex 32)\nWEBUI_SECRET_KEY=\"YOUR_UNIQUE_AND_SECURE_SECRET_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Generating bcrypt Password Hash for Open WebUI\nDESCRIPTION: Command to generate a bcrypt hash of a new password using htpasswd. This hash will be used to update the admin password in the database.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhtpasswd -bnBC 10 \"\" your-new-password | tr -d ':\\n'\n```\n\n----------------------------------------\n\nTITLE: Starting Llama.cpp Server with Model Configuration\nDESCRIPTION: Bash command to start the Llama.cpp server with a specific model and configuration parameters including port, context size, and GPU layers allocation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/starting-with-llama-cpp.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./llama-server \\\n  --model /your/full/path/to/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf \\\n  --port 10000 \\\n  --ctx-size 1024 \\\n  --n-gpu-layers 40\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with Redis Configuration\nDESCRIPTION: Docker run command to start Open WebUI with Redis websocket support, including environment variables and network configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/redis.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d \\\n  --name open-webui \\\n  --network openwebui-network \\\n  -v open-webui:/app/backend/data \\\n  -e ENABLE_WEBSOCKET_SUPPORT=\"true\" \\\n  -e WEBSOCKET_MANAGER=\"redis\" \\\n  -e WEBSOCKET_REDIS_URL=\"redis://127.0.0.1:6379/1\" \\\n  ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Starting Llama.cpp Server with DeepSeek-R1 Model\nDESCRIPTION: Bash command to run the Llama.cpp server with the DeepSeek-R1 dynamic 1.58-bit quantized model. The command specifies the model path, port number, context size, and number of GPU layers to be used for inference acceleration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/deepseekr1-dynamic.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./llama-server \\\n    --model /[your-directory]/DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1_S/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf \\\n    --port 10000 \\\n    --ctx-size 1024 \\\n    --n-gpu-layers 40\n```\n\n----------------------------------------\n\nTITLE: Basic Rsync Backup Script for Open WebUI\nDESCRIPTION: Bash script using rsync to backup Open WebUI data to a Backblaze B2 bucket. It excludes cache and audit log, and backs up uploads, vector database, and main database separately.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\n# Configuration\nSOURCE_DIR=\".\"  # Current directory (where the file structure resides)\nB2_BUCKET=\"b2://OpenWebUI-backups\" # Your Backblaze B2 bucket\nB2_PROFILE=\"your_rclone_profile\" # Your rclone profile name\n# Ensure rclone is configured with your B2 credentials\n\n# Define source and destination directories\nSOURCE_UPLOADS=\"$SOURCE_DIR/uploads\"\nSOURCE_VECTORDB=\"$SOURCE_DIR/vector_db\"\nSOURCE_WEBUI_DB=\"$SOURCE_DIR/webui.db\"\n\nDEST_UPLOADS=\"$B2_BUCKET/user_uploads\"\nDEST_CHROMADB=\"$B2_BUCKET/ChromaDB\"\nDEST_MAIN_DB=\"$B2_BUCKET/main_database\"\n\n# Exclude cache and audit.log\nEXCLUDE_LIST=(\n    \"cache/\"\n    \"audit.log\"\n)\n\n# Construct exclude arguments for rclone\nEXCLUDE_ARGS=\"\"\nfor EXCLUDE in \"${EXCLUDE_LIST[@]}\"; do\n    EXCLUDE_ARGS=\"$EXCLUDE_ARGS --exclude '$EXCLUDE'\"\ndone\n\n# Function to perform rclone sync with error checking\nrclone_sync() {\n    SOURCE=\"$1\"\n    DEST=\"$2\"\n    echo \"Syncing '$SOURCE' to '$DEST'...\"\n    rclone sync \"$SOURCE\" \"$DEST\" $EXCLUDE_ARGS --progress --transfers=32 --checkers=16 --profile \"$B2_PROFILE\"\n    if [ $? -ne 0 ]; then\n        echo \"Error: rclone sync failed for '$SOURCE' to '$DEST'\"\n        exit 1\n    fi\n}\n\n# Perform rclone sync for each directory/file\nrclone_sync \"$SOURCE_UPLOADS\" \"$DEST_UPLOADS\"\nrclone_sync \"$SOURCE_VECTORDB\" \"$DEST_CHROMADB\"\nrclone_sync \"$SOURCE_WEBUI_DB\" \"$DEST_MAIN_DB\"\n\necho \"Backup completed successfully.\"\nexit 0\n```\n\n----------------------------------------\n\nTITLE: Configuring Cloudflare Tunnel with Open WebUI\nDESCRIPTION: Docker Compose configuration for setting up Open WebUI with Cloudflare Tunnel authentication. Uses Cloudflare Access for SSO protection and includes environment configuration for trusted email headers.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/sso.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n---\nservices:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    volumes:\n      - open-webui:/app/backend/data\n    environment:\n      - HOST=127.0.0.1\n      - WEBUI_AUTH_TRUSTED_EMAIL_HEADER=Cf-Access-Authenticated-User-Email\n    restart: unless-stopped\n  cloudflared:\n    image: cloudflare/cloudflared:latest\n    environment:\n      - TUNNEL_TOKEN=${TUNNEL_TOKEN}\n    command: tunnel run\n    restart: unless-stopped\n\nvolumes:\n  open-webui: {}\n```\n\n----------------------------------------\n\nTITLE: Starting Updated Docker Container\nDESCRIPTION: Runs the updated open-webui container with port mapping and volume mounting for data persistence.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerUpdating.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Updating Docker Compose for Nginx SSL Configuration\nDESCRIPTION: Adds an Nginx service to the Docker Compose configuration, mapping the SSL port and mounting the necessary configuration and SSL certificate volumes.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/SelfSigned.md#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./conf.d:/etc/nginx/conf.d\n      - ./ssl:/etc/nginx/ssl\n    depends_on:\n      - open-webui\n```\n\n----------------------------------------\n\nTITLE: Installing and Running OpenAPI Tool Server\nDESCRIPTION: Commands for cloning the repository, installing dependencies, and starting a FastAPI-based OpenAPI tool server. This example specifically shows setup for the filesystem server implementation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/open-webui/openapi-servers\ncd openapi-servers\n\n# Example: Installing dependencies for a specific server 'filesystem'\ncd servers/filesystem\npip install -r requirements.txt\nuvicorn main:app --host 0.0.0.0 --reload\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration with Secret Key\nDESCRIPTION: A Docker Compose configuration that includes the WEBUI_SECRET_KEY environment variable to maintain persistent login sessions across updates.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_5\n\nLANGUAGE: yml\nCODE:\n```\nversion: '3'\nservices:\n  open-webui:\n    image: ghcr.io/open-webui/open-webui:main\n    ports:\n      - \"3000:8080\"\n    volumes:\n      - open-webui:/app/backend/data\n    environment:\n      - WEBUI_SECRET_KEY=your_secret_key\n```\n\n----------------------------------------\n\nTITLE: Updating Admin Password in Docker Deployment\nDESCRIPTION: Docker command to update the admin password in the database for a Docker deployment of Open WebUI. It uses alpine/socat to execute commands in the Docker container.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm -v open-webui:/data alpine/socat EXEC:\"bash -c 'apk add sqlite && echo UPDATE auth SET password=\\'\\'HASH\\'\\'  WHERE email=\\'\\'admin@example.com\\'\\'; | sqlite3 /data/webui.db'\", STDIO\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Port with open-webui serve Command\nDESCRIPTION: Example command for running Open WebUI with a custom port using the command-line argument approach instead of the PORT environment variable, which is necessary when using the Python-based startup method.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nopen-webui serve --port 9999\n```\n\n----------------------------------------\n\nTITLE: Configuring Tailscale Serve JSON for Open WebUI Authentication\nDESCRIPTION: JSON configuration for Tailscale Serve that exposes Open WebUI to a tailnet. This setup enables authentication via Tailscale headers, with HTTPS support on port 443 and proper proxy routing to the Open WebUI instance.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/sso.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"TCP\": {\n        \"443\": {\n            \"HTTPS\": true\n        }\n    },\n    \"Web\": {\n        \"${TS_CERT_DOMAIN}:443\": {\n            \"Handlers\": {\n                \"/\": {\n                    \"Proxy\": \"http://open-webui:8080\"\n                }\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting API Base URL for Continue.dev\nDESCRIPTION: Configures the base URL for API requests in Continue.dev to point to Open WebUI running on localhost.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/continue-dev.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiBase: http://localhost:3000/ #If you followed Getting Started Docker\n```\n\n----------------------------------------\n\nTITLE: Modifying Dockerfile for Custom CA Certificate in Frontend Build Stage\nDESCRIPTION: Dockerfile modification for the frontend build stage that adds a custom root certificate and sets the NODE_EXTRA_CA_CERTS environment variable to enable SSL verification during npm install.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/custom-ca.md#2025-04-23_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nCOPY package.json package-lock.json <YourRootCert>.crt ./\nENV NODE_EXTRA_CA_CERTS=/app/<YourRootCert>.crt\nRUN npm ci\n```\n\n----------------------------------------\n\nTITLE: Generating Self-Signed SSL Certificate for HAProxy\nDESCRIPTION: Command to generate a temporary self-signed SSL certificate for HAProxy to use until Let's Encrypt issues a proper certificate. Uses OpenSSL to create a certificate valid for 10 years.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -x509 -newkey rsa:2048 -keyout /tmp/haproxy.key -out /tmp/haproxy.crt -days 3650 -nodes -subj \"/CN=localhost\"\n```\n\n----------------------------------------\n\nTITLE: Implementing an Action Function in Python with User Input Dialog\nDESCRIPTION: This code snippet demonstrates how to create an action function that displays an input dialog to the user. It takes a body dictionary, user information, and event handling parameters, then calls the event emitter to show a dialog with a title, message, and placeholder text.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/action.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync def action(\n        self,\n        body: dict,\n        __user__=None,\n        __event_emitter__=None,\n        __event_call__=None,\n    ) -> Optional[dict]:\n        print(f\"action:{__name__}\")\n\n        response = await __event_call__(\n            {\n                \"type\": \"input\",\n                \"data\": {\n                    \"title\": \"write a message\",\n                    \"message\": \"here write a message to append\",\n                    \"placeholder\": \"enter your message\",\n                },\n            }\n        )\n        print(response)\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container with Secret Key\nDESCRIPTION: Command to run the Open WebUI Docker container with a persistent WEBUI_SECRET_KEY environment variable to prevent being logged out after updates.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui -e WEBUI_SECRET_KEY=your_secret_key ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Multiple Model Creation with Pipes in Python\nDESCRIPTION: Implementation of a Pipe class that creates multiple models using the pipes function, allowing for multiple model representations within Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/pipe.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass Pipe:\n    class Valves(BaseModel):\n        MODEL_ID: str = Field(default=\"\")\n\n    def __init__(self):\n        self.valves = self.Valves()\n\n    def pipes(self):\n        return [\n            {\"id\": \"model_id_1\", \"name\": \"model_1\"},\n            {\"id\": \"model_id_2\", \"name\": \"model_2\"},\n            {\"id\": \"model_id_3\", \"name\": \"model_3\"}\n        ]\n\n    def pipe(self, body: dict):\n        # Logic goes here\n        print(self.valves, body)  # Prints the configuration options and the input body\n        model = body.get(\"model\", \"\")\n        return f\"{model}: Hello, World!\"\n```\n\n----------------------------------------\n\nTITLE: Configuring LibreTranslate Docker Compose File\nDESCRIPTION: YAML configuration for setting up LibreTranslate in Docker. This file defines the service, container settings, volumes, and healthcheck parameters for running LibreTranslate.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/libre-translate.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  libretranslate:\n    container_name: libretranslate\n    image: libretranslate/libretranslate:v1.6.0\n    restart: unless-stopped\n    ports:\n      - \"5000:5000\"\n    env_file:\n      - stack.env\n    volumes:\n      - libretranslate_api_keys:/app/db\n      - libretranslate_models:/home/libretranslate/.local:rw\n    tty: true\n    stdin_open: true\n    healthcheck:\n      test: ['CMD-SHELL', './venv/bin/python scripts/healthcheck.py']\n      \nvolumes:\n  libretranslate_models:\n  libretranslate_api_keys:\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging in Docker Compose\nDESCRIPTION: Example of setting global logging level in a Docker Compose configuration file.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/logging.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nenvironment:\n    - GLOBAL_LOG_LEVEL=DEBUG\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI Bundled with Ollama (CPU Only)\nDESCRIPTION: Docker command to run the bundled version of Open WebUI with Ollama for CPU-only systems. This configuration is identical to the GPU version but omits the GPU flags for compatibility with machines without GPU hardware.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n```\n\n----------------------------------------\n\nTITLE: Installing Backend Dependencies\nDESCRIPTION: Command to install required Python packages from requirements.txt file\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt -U\n```\n\n----------------------------------------\n\nTITLE: Defining Direct Host Binds for Ollama and Open WebUI\nDESCRIPTION: YAML configuration for defining direct host binds to persist data for Ollama and Open WebUI containers.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  ollama:\n    container_name: ollama\n    image: ollama/ollama:${OLLAMA_DOCKER_TAG-latest}\n    volumes:\n      - /opt/ollama:/root/.ollama\n  open-webui:\n    container_name: open-webui\n    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG-main}\n    volumes:\n      - /opt/open-webui:/app/backend/data\n```\n\n----------------------------------------\n\nTITLE: Deploying Kokoro-FastAPI GPU Version with Docker Compose\nDESCRIPTION: This YAML configuration sets up the GPU version of Kokoro-FastAPI using Docker Compose. It specifies the image, port mapping, and GPU resource allocation for NVIDIA GPUs.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nname: kokoro\nservices:\n    kokoro-fastapi-gpu:\n        ports:\n            - 8880:8880\n        image: ghcr.io/remsky/kokoro-fastapi-gpu:v0.2.1\n        restart: always\n        deploy:\n            resources:\n                reservations:\n                    devices:\n                        - driver: nvidia\n                          count: all\n                          capabilities:\n                              - gpu\n```\n\n----------------------------------------\n\nTITLE: Defining Tags Generation Prompt Template in YAML\nDESCRIPTION: This snippet defines the default prompt template used for tags generation. It includes the task description, guidelines for generating tags, output format, and a placeholder for chat history.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\n### Task:\nGenerate 1-3 broad tags categorizing the main themes of the chat history, along with 1-3 more specific subtopic tags.\n\n### Guidelines:\n- Start with high-level domains (e.g. Science, Technology, Philosophy, Arts, Politics, Business, Health, Sports, Entertainment, Education)\n- Consider including relevant subfields/subdomains if they are strongly represented throughout the conversation\n- If content is too short (less than 3 messages) or too diverse, use only [\"General\"]\n- Use the chat's primary language; default to English if multilingual\n- Prioritize accuracy over specificity\n\n### Output:\nJSON format: { \"tags\": [\"tag1\", \"tag2\", \"tag3\"] }\n\n### Chat History:\n<chat_history>\n{{MESSAGES:END:6}}\n</chat_history>\n```\n\n----------------------------------------\n\nTITLE: Requesting Let's Encrypt SSL Certificate\nDESCRIPTION: Command to request an SSL certificate from Let's Encrypt using the standalone plugin. Configures Let's Encrypt to use port 8688 for HTTP validation as defined in the HAProxy configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncertbot certonly -n --standalone --preferred-challenges http --http-01-port-8688 -d yourdomain.com\n```\n\n----------------------------------------\n\nTITLE: Running Custom Pipeline with Dependencies\nDESCRIPTION: Docker command to run Pipelines with custom pipeline URL and additional dependencies support.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/pipelines/index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 9099:9099 --add-host=host.docker.internal:host-gateway -e PIPELINES_URLS=\"https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py\" -v pipelines:/app/pipelines --name pipelines --restart always ghcr.io/open-webui/pipelines:main\n```\n\n----------------------------------------\n\nTITLE: Modifying Dockerfile for Custom CA Certificate in Backend Base Stage\nDESCRIPTION: Dockerfile modification for the backend base stage that adds a corporate SSL certificate to the system's CA store and sets environment variables for Python's requests library to use the updated certificate store.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/custom-ca.md#2025-04-23_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\nCOPY <CorporateSSL.crt> /usr/local/share/ca-certificates/\nRUN update-ca-certificates\nENV PIP_CERT=/etc/ssl/certs/ca-certificates.crt \\\n    REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI Helm Chart\nDESCRIPTION: Command to install the Open WebUI chart using Helm.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Helm.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nhelm install openwebui open-webui/open-webui\n```\n\n----------------------------------------\n\nTITLE: Adding Context to User Input Using Inlet Filter in Python\nDESCRIPTION: Example filter that prepends a system message to every user query, providing context for the LLM to act as a software troubleshooting assistant.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Filter:\n    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n        context_message = {\n            \"role\": \"system\", \n            \"content\": \"You're a software troubleshooting assistant.\"\n        }\n        body.setdefault(\"messages\", []).insert(0, context_message)\n        return body\n```\n\n----------------------------------------\n\nTITLE: Launching Open WebUI Pipelines Docker Container\nDESCRIPTION: Command to start the Pipelines Docker container with proper port mapping and host configuration for Langfuse integration\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/langfuse.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 9099:9099 --add-host=host.docker.internal:host-gateway -v pipelines:/app/pipelines --name pipelines --restart always ghcr.io/open-webui/pipelines:main\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Container After Import\nDESCRIPTION: Command to start the Open WebUI Docker container after database import\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/database.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker start open-webui\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Launch Command\nDESCRIPTION: Command to start the Docker Compose services in detached mode\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerCompose.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\n----------------------------------------\n\nTITLE: Removing Open WebUI Docker Volume\nDESCRIPTION: Optional command to remove the existing Docker volume, which will delete all chat histories and other user data. This is not recommended unless absolutely necessary.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker volume rm open-webui\n```\n\n----------------------------------------\n\nTITLE: Updating Open-WebUI Package with pip in Bash\nDESCRIPTION: This command updates the Open-WebUI Python package to the latest available version using pip. The -U (or --upgrade) flag instructs pip to upgrade the existing package installation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/PythonUpdating.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U open-webui\n```\n\n----------------------------------------\n\nTITLE: Setting Up Python Virtual Environment\nDESCRIPTION: Commands to create and activate a Python virtual environment for macOS/Linux and Windows.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# For macOS/Linux\npython3 -m venv venv\nsource venv/bin/activate\n\n# For Windows\npython -m venv venv\nvenv\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama and Open WebUI in Compose Stack for macOS/Windows\nDESCRIPTION: Mermaid diagram depicting both Ollama and Open WebUI running in the same Docker Compose stack on macOS/Windows. The diagram shows how inter-container networking enables direct communication between components using container names as hostnames.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Mac OS/Windows\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Docker Desktop's Linux VM\") {\n      Boundary(b2, \"Compose Stack\") {\n         Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n         Component(ollama, \"Ollama\", \"Listening on port 11434\")\n      }\n   }\n}\nRel(openwebui, ollama, \"Makes API calls via inter-container networking\", \"http://ollama:11434\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Running Alpine Container with Open WebUI Volume\nDESCRIPTION: Docker command to run an Alpine Linux container connected to the Open WebUI volume, which is the first step in the alternative Docker method for resetting the admin password.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -it --rm -v open-webui:/path/to/data alpine\n```\n\n----------------------------------------\n\nTITLE: Connecting Open WebUI to a Remote Ollama Server\nDESCRIPTION: Docker command for running Open WebUI with a connection to an Ollama server on a different host by specifying the OLLAMA_BASE_URL environment variable.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/ManualDocker.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Vector Database Connection Parameters\nDESCRIPTION: Connection and authentication parameters for various vector database systems including ChromaDB, Elasticsearch, Milvus, OpenSearch, PGVector, Qdrant, and Pinecone.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_9\n\nLANGUAGE: plaintext\nCODE:\n```\nVECTOR_DB=chroma\nCHROMA_HTTP_HOST=localhost\nCHROMA_HTTP_PORT=8000\nELASTICSEARCH_URL=https://localhost:9200\nMILVUS_URI=${DATA_DIR}/vector_db/milvus.db\nOPENSEARCH_URI=https://localhost:9200\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for Custom CA Certificate in Open WebUI\nDESCRIPTION: A docker-compose configuration example that mounts a custom CA certificate into the Open WebUI container and sets the necessary environment variables to enable SSL verification with the custom certificate.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/custom-ca.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  openwebui:\n    image: ghcr.io/open-webui/open-webui:main\n    volumes:\n      - /var/containers/openwebui:/app/backend/data:rw\n      - /etc/containers/openwebui/compusrv.crt:/etc/ssl/certs/ca-certificates.crt:ro\n      - /etc/timezone:/etc/timezone:ro\n      - /etc/localtime:/etc/localtime:ro\n    environment:\n      - WEBUI_NAME=compusrv\n      - ENABLE_SIGNUP=False\n      - ENABLE_COMMUNITY_SHARING=False\n      - WEBUI_SESSION_COOKIE_SAME_SITE=strict\n      - WEBUI_SESSION_COOKIE_SECURE=True\n      - ENABLE_OLLAMA_API=False\n      - REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\n```\n\n----------------------------------------\n\nTITLE: Deploying Kokoro-FastAPI CPU Version with Docker Compose\nDESCRIPTION: This YAML configuration sets up the CPU version of Kokoro-FastAPI using Docker Compose. It specifies the image and port mapping.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration.md#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nname: kokoro\nservices:\n    kokoro-fastapi-cpu:\n        ports:\n            - 8880:8880\n        image: ghcr.io/remsky/kokoro-fastapi-cpu\n        restart: always\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables\nDESCRIPTION: Example content for the .env file to configure environment variables for the openai-edge-tts server.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nAPI_KEY=your_api_key_here\nPORT=5050\n\nDEFAULT_VOICE=en-US-AvaNeural\nDEFAULT_RESPONSE_FORMAT=mp3\nDEFAULT_SPEED=1.0\n\nDEFAULT_LANGUAGE=en-US\n\nREQUIRE_API_KEY=True\nREMOVE_FILTER=False\nEXPAND_API=True\n```\n\n----------------------------------------\n\nTITLE: Configuring Mojeek Search in Docker Compose\nDESCRIPTION: Docker Compose environment variables configuration for enabling and configuring Mojeek Search API integration with Open WebUI. Includes settings for enabling RAG web search, specifying search engine, API key, result count, and concurrent request limits.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/mojeek.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  open-webui:\n    environment:\n      ENABLE_RAG_WEB_SEARCH: True\n      RAG_WEB_SEARCH_ENGINE: \"mojeek\"\n      BRAVE_SEARCH_API_KEY: \"YOUR_MOJEEK_API_KEY\"\n      RAG_WEB_SEARCH_RESULT_COUNT: 3\n      RAG_WEB_SEARCH_CONCURRENT_REQUESTS: 10\n```\n\n----------------------------------------\n\nTITLE: Installing and Running mcpo with uv\nDESCRIPTION: Command to install and run the MCP-to-OpenAPI proxy server using the uv package manager, which is the recommended approach for faster startup and zero-config convenience.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuvx mcpo --port 8000 -- your_mcp_server_command\n```\n\n----------------------------------------\n\nTITLE: SearXNG Limiter Configuration\nDESCRIPTION: TOML configuration for SearXNG's bot detection and IP limiting features.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[botdetection.ip_limit]\nlink_token = false\n\n[botdetection.ip_lists]\nblock_ip = []\npass_ip = []\n```\n\n----------------------------------------\n\nTITLE: Launching AUTOMATIC1111 with API Access\nDESCRIPTION: Command to start AUTOMATIC1111 with API and listening flags enabled for integration with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/images.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n./webui.sh --api --listen\n```\n\n----------------------------------------\n\nTITLE: Configuring LibreTranslate Environment Variables\nDESCRIPTION: Environment variable configuration for LibreTranslate. This file sets various options for the LibreTranslate service, including debug mode, SSL, suggestions, metrics, and API key settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/libre-translate.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# LibreTranslate\nLT_DEBUG=\"false\"\nLT_UPDATE_MODELS=\"true\"\nLT_SSL=\"false\"\nLT_SUGGESTIONS=\"false\"\nLT_METRICS=\"false\"\nLT_HOST=\"0.0.0.0\"\n\nLT_API_KEYS=\"false\"\n\nLT_THREADS=\"12\"\nLT_FRONTEND_TIMEOUT=\"2000\"\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Provider in Continue.dev\nDESCRIPTION: Specifies the provider to use for the Continue.dev extension configuration, setting it to OpenAI which allows compatibility with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/continue-dev.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nprovider: openai\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with uv on macOS/Linux\nDESCRIPTION: This command uses uv to run Open WebUI on macOS and Linux, specifying Python version 3.11 and setting the DATA_DIR environment variable.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Uv.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nDATA_DIR=~/.open-webui uvx --python 3.11 open-webui@latest serve\n```\n\n----------------------------------------\n\nTITLE: Listing Available Models via Ollama API Proxy in Bash\nDESCRIPTION: This curl command shows how to list available models using the Ollama API proxy provided by Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/api-endpoints.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl http://localhost:3000/ollama/api/tags\n```\n\n----------------------------------------\n\nTITLE: Installing Frontend Dependencies for Open WebUI\nDESCRIPTION: Command to install all required JavaScript packages for the Open WebUI frontend using npm. This downloads all necessary libraries defined in package.json.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Implementing Valves and UserValves in Python\nDESCRIPTION: Detailed example of implementing Valves and UserValves for admin and user-configurable options, including type hints and usage in a tool method.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass Tools:\n     class Valves(BaseModel):\n        test_valve: int = Field(\n            default=4,\n            description=\"A valve controlling a numberical value\"\n         )\n         pass\n \n    class UserValves(BaseModel):\n        test_user_valve: bool = Field(\n            default=False, description=\"A user valve controlling a True/False (on/off) switch\"\n        )\n        pass\n\n    def __init__(self):\n        self.valves = self.Valves()\n        pass\n\n    def test_the_tool(self, message: str, __user__: dict):\n        \"\"\"\n        This is a test tool. If the user asks you to test the tools, put any\n        string you want in the message argument.\n\n        :param message: Any string you want.\n        :return: The same string as input.\n        \"\"\"\n        test_user_valve = __user__[\"valves\"].test_user_valve\n        \n        return message + f\"\\nThe user valve set value is: {test_user_valve}\"\n```\n\n----------------------------------------\n\nTITLE: Docker Container Launch Command\nDESCRIPTION: Simple Docker command to start the Apache Tika container with port mapping.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 9998:9998 apache/tika\n```\n\n----------------------------------------\n\nTITLE: Registering with Let's Encrypt\nDESCRIPTION: Command to register with Let's Encrypt's certificate authority. This is a one-time setup that accepts the terms of service and provides an email for notifications about certificate expiration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncertbot register --agree-tos --email your@email.com --non-interactive\n```\n\n----------------------------------------\n\nTITLE: Container Shell Access Command - Bash\nDESCRIPTION: Command to access the shell within the Docker container where the database is located.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/sqlite-database.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it open-webui /bin/sh\n```\n\n----------------------------------------\n\nTITLE: Visualizing Open WebUI and Ollama in Host Network for Linux\nDESCRIPTION: Mermaid diagram showing an optimal configuration for Linux where both Open WebUI and Ollama use the host network. This allows direct communication between components via localhost, providing efficient network performance.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Linux\") {\n   Person(user, \"User\")\n   Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n   Component(ollama, \"Ollama\", \"Listening on port 11434\")\n}\nRel(openwebui, ollama, \"Makes API calls via localhost\", \"http://localhost:11434\")\nRel(user, openwebui, \"Makes requests via listening port\", \"http://localhost:8080\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Starting Backend Development Server\nDESCRIPTION: Command to start the backend development server using the dev script\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsh dev.sh\n```\n\n----------------------------------------\n\nTITLE: Starting Open WebUI Server\nDESCRIPTION: Launches the Open WebUI server after successful installation, making the interface accessible.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Conda.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nopen-webui serve\n```\n\n----------------------------------------\n\nTITLE: Installing uv on Windows for Open WebUI\nDESCRIPTION: PowerShell command to install the uv runtime manager on Windows systems. This installation script sets up uv for managing Python environments on Windows.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_8\n\nLANGUAGE: powershell\nCODE:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n----------------------------------------\n\nTITLE: Running openai-edge-tts Docker Container\nDESCRIPTION: Command to run the openai-edge-tts Docker container on port 5050 with default configurations.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 5050:5050 travisvn/openai-edge-tts:latest\n```\n\n----------------------------------------\n\nTITLE: Preparing Let's Encrypt Certificate for HAProxy\nDESCRIPTION: Commands to combine Let's Encrypt certificate files into the PEM format required by HAProxy, set appropriate permissions, and ensure the HAProxy service can access the certificate.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncat /etc/letsencrypt/live/{domain}/fullchain.pem /etc/letsencrypt/live/{domain}/privkey.pem > /etc/haproxy/certs/{domain}.pem\nchmod 600 /etc/haproxy/certs/{domain}.pem\nchown haproxy:haproxy /etc/haproxy/certs/{domain}.pem\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container with Custom Configuration\nDESCRIPTION: Docker command to run the openai-edge-tts container with custom environment variables for configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 5050:5050 \\\n  -e API_KEY=your_api_key_here \\\n  -e PORT=5050 \\\n  -e DEFAULT_VOICE=en-US-AvaNeural \\\n  -e DEFAULT_RESPONSE_FORMAT=mp3 \\\n  -e DEFAULT_SPEED=1.0 \\\n  -e DEFAULT_LANGUAGE=en-US \\\n  -e REQUIRE_API_KEY=True \\\n  -e REMOVE_FILTER=False \\\n  -e EXPAND_API=True \\\n  travisvn/openai-edge-tts:latest\n```\n\n----------------------------------------\n\nTITLE: Starting the Open WebUI Frontend Development Server\nDESCRIPTION: Command to launch the frontend development server for Open WebUI. This starts a local server that serves the frontend application at http://localhost:5173.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Cloning the Open WebUI Repository with Git\nDESCRIPTION: Commands to clone the Open WebUI GitHub repository to your local machine and navigate into the project directory. This is the first step in setting up a local development environment.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/open-webui/open-webui.git\ncd open-webui\n```\n\n----------------------------------------\n\nTITLE: Configuring Nginx for SSL and Proxy Pass\nDESCRIPTION: Nginx configuration file that sets up SSL and proxies requests to the Open WebUI application. It includes SSL certificate paths, proxy settings, and optional configurations for streaming and large file uploads.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/SelfSigned.md#2025-04-23_snippet_1\n\nLANGUAGE: nginx\nCODE:\n```\nserver {\n    listen 443 ssl;\n    server_name your_domain_or_IP;\n\n    ssl_certificate /etc/nginx/ssl/nginx.crt;\n    ssl_certificate_key /etc/nginx/ssl/nginx.key;\n    ssl_protocols TLSv1.2 TLSv1.3;\n\n    location / {\n        proxy_pass http://host.docker.internal:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # (Optional) Disable proxy buffering for better streaming response from models\n        proxy_buffering off;\n\n        # (Optional) Increase max request size for large attachments and long audio messages\n        client_max_body_size 20M;\n        proxy_read_timeout 10m;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Export and Import Command Summary\nDESCRIPTION: Full set of commands for exporting and importing the database, including container stop and start operations\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/database.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Quick commands summary for export and import\n# Export:\ndocker cp open-webui:/app/backend/data/webui.db ./webui.db\n\n# Stop container on the new server:\ndocker stop open-webui\n\n# Import:\ndocker cp ./webui.db open-webui:/app/backend/data/webui.db\n\n# Start container:\ndocker start open-webui\n```\n\n----------------------------------------\n\nTITLE: Querying RAG-Enabled Open WebUI Model - Example Conversation\nDESCRIPTION: Example conversation showing how to query the RAG-enabled Open WebUI model for environment variable configuration information.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/rag-tutorial.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nUser: \"How do I configure environment variables?\"\nSystem: \"Refer to Section 3.2: Use the `.env` file to manage configurations.\"\n```\n\n----------------------------------------\n\nTITLE: Running mcpo with Time MCP Server\nDESCRIPTION: Command to run the MCP-to-OpenAPI proxy on port 8000 with the mcp-server-time tool, setting the local timezone to America/New_York. This exposes the Time Server through standard OpenAPI endpoints.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nuvx mcpo --port 8000 -- uvx mcp-server-time --local-timezone=America/New_York\n```\n\n----------------------------------------\n\nTITLE: Activating a Virtual Environment on Windows\nDESCRIPTION: Activates the previously created virtual environment on Windows systems using the activation script.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Venv.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nvenv\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: SearXNG Docker Compose Configuration\nDESCRIPTION: Docker Compose configuration for running SearXNG container.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  searxng:\n    container_name: searxng\n    image: searxng/searxng:latest\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - ./searxng:/etc/searxng:rw\n    env_file:\n      - .env\n    restart: unless-stopped\n    cap_drop:\n      - ALL\n    cap_add:\n      - CHOWN\n      - SETGID\n      - SETUID\n      - DAC_OVERRIDE\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"1m\"\n        max-file: \"1\"\n```\n\n----------------------------------------\n\nTITLE: Pulling Latest Docker Image\nDESCRIPTION: Downloads the latest version of the open-webui Docker image from the GitHub Container Registry.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerUpdating.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Example Llama.cpp Server Command with Real Path\nDESCRIPTION: A complete example of the Llama.cpp server command with a real file path, demonstrating how to properly specify the model location on a macOS system. This shows the practical implementation of the previous command with actual paths.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/deepseekr1-dynamic.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n./llama-server \\\n    --model /Users/tim/Documents/workspace/DeepSeek-R1-GGUF/DeepSeek-R1-UD-IQ1_S/DeepSeek-R1-UD-IQ1_S-00001-of-00003.gguf \\\n    --port 10000 \\\n    --ctx-size 1024 \\\n    --n-gpu-layers 40\n```\n\n----------------------------------------\n\nTITLE: Installing HAProxy and Let's Encrypt on Debian Systems\nDESCRIPTION: Command to install HAProxy, Let's Encrypt's certbot, and OpenSSL on Debian-based Linux distributions using apt package manager.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/https-haproxy.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt install haproxy certbot openssl -y\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for MCP Proxy Server\nDESCRIPTION: Dockerfile example for containerizing the MCP-to-OpenAPI proxy server with Python 3.11. It installs mcpo and uv packages and configures the container to run the proxy on port 8000 with the mcp-server-time tool.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_4\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM python:3.11-slim\nWORKDIR /app\nRUN pip install mcpo uv\n# Replace with your MCP server command; example: uvx mcp-server-time\nCMD [\"uvx\", \"mcpo\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--\", \"uvx\", \"mcp-server-time\", \"--local-timezone=America/New_York\"]\n```\n\n----------------------------------------\n\nTITLE: Running Pipelines Docker Container\nDESCRIPTION: Docker command to run the Pipelines container with volume mounting and network configuration for host access.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/pipelines/index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 9099:9099 --add-host=host.docker.internal:host-gateway -v pipelines:/app/pipelines --name pipelines --restart always ghcr.io/open-webui/pipelines:main\n```\n\n----------------------------------------\n\nTITLE: Importing Database to Docker Container\nDESCRIPTION: Command to copy the webui.db file from local machine to the Open WebUI Docker container\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/database.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker cp ./webui.db open-webui:/app/backend/data/webui.db\n```\n\n----------------------------------------\n\nTITLE: Creating Conda Environment for Open WebUI\nDESCRIPTION: Creates a new Conda environment named 'open-webui' with Python 3.11 specified as the Python version.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Conda.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nconda create -n open-webui python=3.11\n```\n\n----------------------------------------\n\nTITLE: Configuring WEBUI_BANNERS Environment Variable in .env File\nDESCRIPTION: Example of setting the WEBUI_BANNERS environment variable in a .env file, demonstrating proper escaping of quotes for JSON data. This shows how to define a warning banner that will be displayed to users.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nWEBUI_BANNERS=\"[{\\\"id\\\": \\\"1\\\", \\\"type\\\": \\\"warning\\\", \\\"title\\\": \\\"Your messages are stored.\\\", \\\"content\\\": \\\"Your messages are stored and may be reviewed by human people. LLM's are prone to hallucinations, check sources.\\\", \\\"dismissible\\\": true, \\\"timestamp\\\": 1000}]\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Outlet Function for API Key Redaction in Python\nDESCRIPTION: A filter implementation that removes sensitive API key information from message content using the outlet function. This demonstrates basic post-processing of LLM responses for security purposes.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n    for message in body[\"messages\"]:\n        message[\"content\"] = message[\"content\"].replace(\"<API_KEY>\", \"[REDACTED]\")\n    return body\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Nginx\nDESCRIPTION: Docker Compose configuration that sets up Nginx container with proper port mappings and volume mounts for SSL and configuration files.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./conf.d:/etc/nginx/conf.d\n      - ./ssl:/etc/nginx/ssl\n    depends_on:\n      - open-webui\n```\n\n----------------------------------------\n\nTITLE: Building Kokoro-FastAPI Docker Container\nDESCRIPTION: These commands clone the Kokoro-FastAPI repository, navigate to the appropriate directory, and build the Docker container using Docker Compose.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/remsky/Kokoro-FastAPI.git\ncd Kokoro-FastAPI\ncd docker/cpu # or docker/gpu\ndocker compose up --build\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Open WebUI Frontend\nDESCRIPTION: Command to copy the example environment file to create a local .env configuration file for the frontend. This sets up necessary environment variables for development.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncp -RPp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI Docker Container with WEBUI_URL Configuration\nDESCRIPTION: Docker run command that sets up the Open WebUI container with the WEBUI_URL environment variable, which is necessary for browser search engine integration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/browser-search-engine.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d \\\n  -p 3000:8080 \\\n  --add-host=host.docker.internal:host-gateway \\\n  -v open-webui:/app/backend/data \\\n  --name open-webui \\\n  --restart always \\\n  -e WEBUI_URL=\"https://<your-open-webui-url>\" \\\n  ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Pulling the Open WebUI Docker Image\nDESCRIPTION: Command to pull the latest Open WebUI Docker image from the GitHub Container Registry.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/ManualDocker.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for RAM Reduction in Open WebUI\nDESCRIPTION: These environment variables configure Open WebUI to use external services for RAG embedding and speech-to-text, significantly reducing RAM usage. This is particularly effective for fresh Docker deployments.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/reduce-ram-usage.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nRAG_EMBEDDING_ENGINE: ollama\nAUDIO_STT_ENGINE: openai\n```\n\n----------------------------------------\n\nTITLE: Generating Speech with curl (Japanese)\nDESCRIPTION: curl command to generate speech from text using the openai-edge-tts API endpoint with Japanese text.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:5050/v1/audio/speech \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer your_api_key_here\" \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"じゃあ、行く。電車の時間、調べておくよ。\",\n    \"voice\": \"ja-JP-KeitaNeural\"\n  }' \\\n  --output speech.mp3\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama on Host with Open WebUI in Container for macOS/Windows\nDESCRIPTION: Mermaid diagram showing the network interaction between Ollama running on the host machine and Open WebUI running in a Docker container on macOS/Windows. The diagram illustrates how the user accesses Open WebUI on port 3000, and how Open WebUI connects to Ollama via host.docker.internal.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Mac OS/Windows\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Docker Desktop's Linux VM\") {\n      Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n   }\n   Component(ollama, \"Ollama\", \"Listening on port 11434\")\n}\nRel(openwebui, ollama, \"Makes API calls via Docker proxy\", \"http://host.docker.internal:11434\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Updating Admin Password in Local Installation\nDESCRIPTION: Command to update the admin password directly in the SQLite database for a local installation of Open WebUI. HASH should be replaced with the bcrypt hash generated in the previous step.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsqlite3 backend/data/webui.db \"UPDATE auth SET password='HASH' WHERE email='admin@example.com';\"\n```\n\n----------------------------------------\n\nTITLE: Importing TopBanners Component in Markdown\nDESCRIPTION: This code snippet imports the TopBanners component from a specific file path. It's likely used to display banner content at the top of the documentation page.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/index.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nimport { TopBanners } from \"@site/src/components/TopBanners\";\n```\n\n----------------------------------------\n\nTITLE: Cloning openai-edge-tts Repository\nDESCRIPTION: Git commands to clone the openai-edge-tts repository and navigate to the project directory.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/travisvn/openai-edge-tts.git\ncd openai-edge-tts\n```\n\n----------------------------------------\n\nTITLE: Creating and Printing a Pandas DataFrame in Pyodide\nDESCRIPTION: This script demonstrates how to create a sample DataFrame using pandas and print it within the Pyodide environment in Open WebUI. It showcases the basic usage of the pandas library for data manipulation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/code-execution/python.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\n# Create a sample DataFrame\ndata = {'Name': ['John', 'Anna', 'Peter'], \n        'Age': [28, 24, 35]}\ndf = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Starting LibreTranslate Docker Service\nDESCRIPTION: Command to start the LibreTranslate service using Docker Compose. This command runs the service in detached mode.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/libre-translate.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Filtering Emojis from Streamed LLM Responses\nDESCRIPTION: A stream function example that removes emojis from the LLM's streamed responses in real-time, demonstrating how to modify content as it's being generated.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef stream(self, event: dict) -> dict:\n    for choice in event.get(\"choices\", []):\n        delta = choice.get(\"delta\", {})\n        if \"content\" in delta:\n            delta[\"content\"] = delta[\"content\"].replace(\"😊\", \"\")  # Strip emojis\n    return event\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with uv on Windows\nDESCRIPTION: PowerShell command to run Open WebUI using the uv runtime manager on Windows. This sets up a data directory path and launches Open WebUI with Python 3.11.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_10\n\nLANGUAGE: powershell\nCODE:\n```\n$env:DATA_DIR=\"C:\\open-webui\\data\"; uvx --python 3.11 open-webui@latest serve\n```\n\n----------------------------------------\n\nTITLE: Basic URL Format for Open WebUI Search Engine Integration\nDESCRIPTION: The URL format to use when configuring Open WebUI as a custom search engine in web browsers, with %s as the query placeholder.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/browser-search-engine.md#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://<your-open-webui-url>/?q=%s\n```\n\n----------------------------------------\n\nTITLE: Formatting Assistant Responses with Markdown in Python\nDESCRIPTION: A filter implementation that adds markdown formatting to assistant responses using the outlet function, enhancing readability of the output.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass Filter:\n    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n        # Add \"highlight\" markdown for every response\n        for message in body[\"messages\"]:\n            if message[\"role\"] == \"assistant\":  # Target model response\n                message[\"content\"] = f\"**{message['content']}**\"  # Highlight with Markdown\n        return body\n```\n\n----------------------------------------\n\nTITLE: One-time Update using Watchtower\nDESCRIPTION: Command to perform a one-time update of the Open WebUI container using Watchtower, which stops the current container, pulls the latest image, and starts a new container.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui\n```\n\n----------------------------------------\n\nTITLE: Launching OpenAPI Time Server with Uvicorn in Bash\nDESCRIPTION: This code snippet demonstrates how to clone the openapi-servers repository, navigate to the time server directory, install dependencies, and start the server using Uvicorn. This creates a local OpenAPI-compatible tool server that can be integrated with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/open-webui.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/open-webui/openapi-servers\ncd openapi-servers\n\n# Navigate to the time server\ncd servers/time\n\n# Install required dependencies\npip install -r requirements.txt\n\n# Start the server\nuvicorn main:app --host 0.0.0.0 --reload\n```\n\n----------------------------------------\n\nTITLE: Model Switching Process in Open WebUI\nDESCRIPTION: Instructions for switching between different AI models (like Mistral, LLaVA, and GPT-3.5) during multi-stage conversations while preserving context.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/workspace/models.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n**How To**:\n1. **Select the Model**: Within the chat interface, select the desired models from the model switcher dropdown. You can select up to two models simultaneously, and both responses will be generated. You can then navigate between them by using the back and forth arrows.\n2. **Context Preservation**: Open WebUI retains the conversation context across model switches, allowing smooth transitions.\n```\n\n----------------------------------------\n\nTITLE: Configuring CORS in FastAPI for OpenAPI Tool Server Integration\nDESCRIPTION: This snippet shows how to add CORS middleware to a FastAPI application to allow cross-origin requests from clients. This is essential when integrating a local OpenAPI tool server with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/faq.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # or specify your client origin\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Installing uv on Windows\nDESCRIPTION: This PowerShell command downloads and executes the uv installation script for Windows systems.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Uv.md#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\npowershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n```\n\n----------------------------------------\n\nTITLE: Defining Docker Swarm Stack for Open WebUI, ChromaDB, and Ollama\nDESCRIPTION: This YAML file defines the Docker Swarm stack for deploying Open WebUI, ChromaDB, and Ollama as separate services. It includes volume mounts, environment variables, and GPU resource allocation for Ollama.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerSwarm.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nversion: '3.9'\n\nservices:\n  openWebUI:\n    image: ghcr.io/open-webui/open-webui:main\n    depends_on:\n        - chromadb\n        - ollama\n    volumes:\n      - ./data/open-webui:/app/backend/data\n    environment:\n      DATA_DIR: /app/backend/data \n      OLLAMA_BASE_URLS: http://ollama:11434\n      CHROMA_HTTP_PORT: 8000\n      CHROMA_HTTP_HOST: chromadb\n      CHROMA_TENANT: default_tenant\n      VECTOR_DB: chroma\n      WEBUI_NAME: Awesome ChatBot\n      CORS_ALLOW_ORIGIN: \"*\" # This is the current Default, will need to change before going live\n      RAG_EMBEDDING_ENGINE: ollama\n      RAG_EMBEDDING_MODEL: nomic-embed-text-v1.5\n      RAG_EMBEDDING_MODEL_TRUST_REMOTE_CODE: \"True\"\n    ports:\n      - target: 8080\n        published: 8080\n        mode: overlay\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n\n  chromadb:\n    hostname: chromadb\n    image: chromadb/chroma:0.5.15\n    volumes:\n      - ./data/chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - ALLOW_RESET=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma\n    ports: \n      - target: 8000\n        published: 8000\n        mode: overlay\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n    healthcheck: \n      test: [\"CMD-SHELL\", \"curl localhost:8000/api/v1/heartbeat || exit 1\"]\n      interval: 10s\n      retries: 2\n      start_period: 5s\n      timeout: 10s\n\n  ollama:\n    image: ollama/ollama:latest\n    hostname: ollama\n    ports:\n      - target: 11434\n        published: 11434\n        mode: overlay\n    deploy:\n      resources:\n        reservations:\n          generic_resources:\n            - discrete_resource_spec:\n                kind: \"NVIDIA-GPU\"\n                value: 0\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n    volumes:\n      - ./data/ollama:/root/.ollama\n```\n\n----------------------------------------\n\nTITLE: Docker Run Command for Open WebUI with ComfyUI\nDESCRIPTION: Docker command to run Open WebUI with environment variables preset for ComfyUI integration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/images.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -e COMFYUI_BASE_URL=http://host.docker.internal:7860/ -e ENABLE_IMAGE_GENERATION=True -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Starting Nginx Service with Docker Compose\nDESCRIPTION: Starts the Nginx service in detached mode using Docker Compose, applying the SSL configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/SelfSigned.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d nginx\n```\n\n----------------------------------------\n\nTITLE: Cloning SearXNG Docker Repository\nDESCRIPTION: Commands to clone the SearXNG Docker repository and navigate to the project directory.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/searxng/searxng-docker.git\ncd searxng-docker\n```\n\n----------------------------------------\n\nTITLE: Specifying External Package Requirements for Open WebUI Tools\nDESCRIPTION: This snippet shows how to specify external package requirements in the metadata of an Open WebUI tool. It includes version specifications and additional metadata fields like title, author, and description.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\ntitle: myToolName\nauthor: myName\nfunding_url: [any link here will be shown behind a `Heart` button for users to show their support to you]\nversion: 1.0.0\n# the version is displayed in the UI to help users keep track of updates.\nlicense: GPLv3\ndescription: [recommended]\nrequirements: package1>=2.7.0,package2,package3\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Generating Entity Relationship Diagram using Mermaid\nDESCRIPTION: This Mermaid code snippet generates an Entity Relationship Diagram (ERD) for the Open WebUI project. It visualizes the relationships between various entities such as users, chats, channels, messages, and other components of the system.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/sqlite-database.md#2025-04-23_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nerDiagram\n    %% User and Authentication\n    user ||--o{ auth : \"has\"\n    user ||--o{ chat : \"owns\"\n    user ||--o{ channel : \"owns\"\n    user ||--o{ message : \"creates\"\n    user ||--o{ folder : \"owns\"\n    user ||--o{ file : \"owns\"\n    user ||--o{ feedback : \"provides\"\n    user ||--o{ function : \"manages\"\n    user ||--o{ group : \"manages\"\n    user ||--o{ knowledge : \"manages\"\n    user ||--o{ memory : \"owns\"\n    user ||--o{ model : \"manages\"\n    user ||--o{ prompt : \"creates\"\n    user ||--o{ tag : \"creates\"\n    user ||--o{ tool : \"manages\"\n\n    %% Content Relationships\n    message ||--o{ message_reaction : \"has\"\n    chat ||--o{ tag : \"tagged_with\"\n    chat }|--|| folder : \"organized_in\"\n    channel ||--o{ message : \"contains\"\n    message ||--o{ message : \"replies\"\n\n    user {\n        string id PK\n        string name\n        string email\n        string role\n        text profile_image_url\n        bigint last_active_at\n        string api_key\n        json settings\n        json info\n        text oauth_sub\n    }\n\n    auth {\n        string id PK\n        string email\n        text password\n        boolean active\n    }\n\n    chat {\n        string id PK\n        string user_id FK\n        string title\n        json chat\n        text share_id\n        boolean archived\n        boolean pinned\n        json meta\n        text folder_id FK\n    }\n\n    channel {\n        text id PK\n        text user_id FK\n        text name\n        text description\n        json data\n        json meta\n        json access_control\n    }\n\n    message {\n        text id PK\n        text user_id FK\n        text channel_id FK\n        text parent_id FK\n        text content\n        json data\n        json meta\n    }\n\n    message_reaction {\n        text id PK\n        text user_id FK\n        text message_id FK\n        text name\n    }\n\n    feedback {\n        text id PK\n        text user_id FK\n        bigint version\n        text type\n        json data\n        json meta\n        json snapshot\n    }\n\n    file {\n        string id PK\n        string user_id FK\n        text hash\n        text filename\n        text path\n        json data\n        json meta\n        json access_control\n    }\n\n    folder {\n        text id PK\n        text parent_id FK\n        text user_id FK\n        text name\n        json items\n        json meta\n        boolean is_expanded\n    }\n\n    function {\n        string id PK\n        string user_id FK\n        text name\n        text content\n        json meta\n        json valves\n        boolean is_active\n        boolean is_global\n    }\n\n    group {\n        text id PK\n        text user_id FK\n        text name\n        text description\n        json data\n        json meta\n        json permissions\n        json user_ids\n    }\n\n    knowledge {\n        text id PK\n        text user_id FK\n        text name\n        text description\n        json data\n        json meta\n        json access_control\n    }\n\n    memory {\n        string id PK\n        string user_id FK\n        text content\n    }\n\n    model {\n        text id PK\n        text user_id FK\n        text base_model_id FK\n        text name\n        json params\n        json meta\n        json access_control\n        boolean is_active\n    }\n\n    prompt {\n        string command PK\n        string user_id FK\n        text title\n        text content\n        json access_control\n    }\n\n    tag {\n        string id PK \"composite\"\n        string user_id PK \"composite\"\n        string name\n        json meta\n    }\n\n    tool {\n        string id PK\n        string user_id FK\n        text name\n        text content\n        json specs\n        json meta\n        json valves\n        json access_control\n    }\n```\n\n----------------------------------------\n\nTITLE: Activating a Virtual Environment on Linux/macOS\nDESCRIPTION: Activates the previously created virtual environment on Linux or macOS systems using the source command.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Venv.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Compose for Apache Tika\nDESCRIPTION: Docker Compose configuration file for setting up Apache Tika container with proper port mapping and restart policy.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nservices:\n  tika:\n    image: apache/tika:latest-full\n    container_name: tika\n    ports:\n      - \"9998:9998\"\n    restart: unless-stopped\n```\n\n----------------------------------------\n\nTITLE: Installing uv on macOS/Linux\nDESCRIPTION: This command downloads and executes the uv installation script for macOS and Linux systems.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Uv.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Implementing Tools Class with Valves in Python\nDESCRIPTION: Example of a Tools class implementation with a Valves subclass for API key validation and a string reversal method.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Tools:\n    def __init__(self):\n        \"\"\"Initialize the Tool.\"\"\"\n        self.valves = self.Valves()\n\n    class Valves(BaseModel):\n        api_key: str = Field(\"\", description=\"Your API key here\")\n\n    def reverse_string(self, string: str) -> str:\n        \"\"\"\n        Reverses the input string.\n        :param string: The string to reverse\n        \"\"\"\n        # example usage of valves\n        if self.valves.api_key != \"42\":\n            return \"Wrong API key\"\n        return string[::-1] \n```\n\n----------------------------------------\n\nTITLE: Verifying Redis Connection\nDESCRIPTION: Commands to verify Redis connection and functionality using redis-cli or valkey-cli.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/redis.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it redis-valkey redis-cli -p 6379 ping\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker exec -it redis-valkey valkey-cli -p 6379 ping\n```\n\n----------------------------------------\n\nTITLE: Building Docker Images for Different Platforms\nDESCRIPTION: Docker build commands for various platforms including NVIDIA GPU, AMD GPU, and CPU-only configurations.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t ghcr.io/matatonic/openedai-speech .\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -f Dockerfile --build-arg USE_ROCM=1 -t ghcr.io/matatonic/openedai-speech-rocm .\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -f Dockerfile.min -t ghcr.io/matatonic/openedai-speech-min .\n```\n\n----------------------------------------\n\nTITLE: Navigating to Backend Directory\nDESCRIPTION: Command to change directory to the backend folder of the project\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd backend\n```\n\n----------------------------------------\n\nTITLE: Creating Docker Network for Open WebUI\nDESCRIPTION: Command to create a Docker network for communication between Open WebUI and Redis services.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/redis.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker network create openwebui-network\n```\n\n----------------------------------------\n\nTITLE: Building and Running Docker Container for MCP Proxy\nDESCRIPTION: Commands to build a Docker image for the MCP proxy server and run it locally, exposing port 8000 for accessing the API endpoints and documentation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t mcp-proxy-server .\ndocker run -d -p 8000:8000 mcp-proxy-server\n```\n\n----------------------------------------\n\nTITLE: Generating Self-Signed SSL Certificate (Windows)\nDESCRIPTION: OpenSSL command to generate a self-signed SSL certificate and private key. This creates a certificate valid for 365 days using RSA 2048-bit encryption.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/Windows.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout nginx.key -out nginx.crt\n```\n\n----------------------------------------\n\nTITLE: Example Webhook Payload with Sample Username\nDESCRIPTION: Provides a concrete example of a webhook notification payload when a specific user named 'Tim' signs up to the platform.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/webhooks.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nNew user signed up: Tim\n```\n\n----------------------------------------\n\nTITLE: Cloning OpenEdAI Speech Repository\nDESCRIPTION: Command to clone the openedai-speech repository from GitHub to local machine.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/matatonic/openedai-speech.git\n```\n\n----------------------------------------\n\nTITLE: Deploying Kokoro-FastAPI CPU Version with Docker Run\nDESCRIPTION: This command runs the CPU version of Kokoro-FastAPI using Docker run. It maps port 8880 for accessing the service.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-cpu\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Conda Environment\nDESCRIPTION: Commands to create a new Conda environment with Python 3.11 and activate it for the project\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nconda create --name open-webui python=3.11\nconda activate open-webui\n```\n\n----------------------------------------\n\nTITLE: SearXNG Environment Configuration\nDESCRIPTION: Environment configuration file for SearXNG with hostname and optional worker settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSEARXNG_HOSTNAME=localhost:8080/\n# LETSENCRYPT_EMAIL=<email>\n\n# SEARXNG_UWSGI_WORKERS=4\n# SEARXNG_UWSGI_THREADS=4\n```\n\n----------------------------------------\n\nTITLE: Defining Toolkit Metadata in Python Docstring\nDESCRIPTION: Example of a top-level docstring containing metadata for a custom toolkit, including title, author, description, and requirements.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\ntitle: String Inverse\nauthor: Your Name\nauthor_url: https://website.com\ngit_url: https://github.com/username/string-reverse.git\ndescription: This tool calculates the inverse of a string\nrequired_open_webui_version: 0.4.0\nrequirements: langchain-openai, langgraph, ollama, langchain_ollama\nversion: 0.4.0\nlicence: MIT\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Valves and UserValves for Configuration in Python\nDESCRIPTION: This snippet demonstrates how to create Valves (admin-configurable) and UserValves (user-configurable) using Pydantic models. It shows the proper class structure, field definitions with type hints, and how to access valve values during execution.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/tab-shared/Common.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\n# Define and Valves\nclass Filter:\n    # Notice the current indentation: Valves and UserValves must be declared as\n    # attributes of a Tools, Filter or Pipe class. Here we take the\n    # example of a Filter.\n     class Valves(BaseModel):\n        # Valves and UserValves inherit from pydantic's BaseModel. This\n        # enables complex use cases like model validators etc.\n        test_valve: int = Field(  # Notice the type hint: it is used to\n            # choose the kind of UI element to show the user (buttons,\n            # texts, etc).\n            default=4,\n            description=\"A valve controlling a numberical value\"\n            # required=False,  # you can enforce fields using True\n         )\n        priority: int = Field(\n            default=0,\n            description=\"Priority level for the filter operations. Lower values are passed through first\"\n         )\n        # The priority field is optional but if present will be used to\n        # order the Filters.\n         pass\n        # Note that this 'pass' helps for parsing and is recommended.\n \n    # UserValves are defined the same way.\n     class UserValves(BaseModel):\n         test_user_valve: bool = Field(\n             default=False, description=\"A user valve controlling a True/False (on/off) switch\"\n        )\n        pass\n\n    def __init__(self):\n        self.valves = self.Valves()\n        # Because they are set by the admin, they are accessible directly\n        # upon code execution.\n        pass\n\n    # The inlet method is only used for Filter but the __user__ handling is the same\n    def inlet(self, body: dict, __user__: dict):\n        # Because UserValves are defined per user they are only available\n        # on use.\n        # Note that although __user__ is a dict, __user__[\"valves\"] is a\n        # UserValves object. Hence you can access values like that:\n        test_user_valve = __user__[\"valves\"].test_user_valve\n        # Or:\n        test_user_valve = dict(__user__[\"valves\"])[\"test_user_valve\"]\n        # But this will return the default value instead of the actual value:\n        # test_user_valve = __user__[\"valves\"][\"test_user_valve\"]  # Do not do that!\n```\n\n----------------------------------------\n\nTITLE: Component-Specific Logging in Docker Compose\nDESCRIPTION: Example of setting component-specific logging level (Ollama) in Docker Compose configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/logging.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nenvironment:\n  - OLLAMA_LOG_LEVEL=DEBUG\n```\n\n----------------------------------------\n\nTITLE: Verifying Docker Installation on Ubuntu\nDESCRIPTION: This bash command runs the 'hello-world' Docker container to verify that Docker is installed correctly and functioning properly on the system.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/docker-install.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo docker run hello-world\n```\n\n----------------------------------------\n\nTITLE: Implementing Status Event Emitters in Python Functions\nDESCRIPTION: A complete example of using Status Event Emitters in a function with proper error handling. It shows how to emit status updates at different stages of function execution and mark completion with the 'done' flag.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/tab-shared/Common.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasync def test_function(\n        self, prompt: str, __user__: dict, __event_emitter__=None\n    ) -> str:\n        \"\"\"\n        This is a demo\n\n        :param test: this is a test parameter\n        \"\"\"\n\n        await __event_emitter__(\n            {\n                \"type\": \"status\", # We set the type here\n                \"data\": {\"description\": \"Message that shows up in the chat\", \"done\": False}, \n                # Note done is False here indicating we are still emitting statuses\n            }\n        )\n\n        # Do some other logic here\n        await __event_emitter__(\n            {\n                \"type\": \"status\",\n                \"data\": {\"description\": \"Completed a task message\", \"done\": True},\n                # Note done is True here indicating we are done emitting statuses\n            }\n        )\n\n        except Exception as e:\n            await __event_emitter__(\n                {\n                    \"type\": \"status\",\n                    \"data\": {\"description\": f\"An error occured: {e}\", \"done\": True},\n                }\n            )\n\n            return f\"Tell the user: {e}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Banners through Environment Variables in JSON Format\nDESCRIPTION: JSON format for setting the WEBUI_BANNERS environment variable. This structure defines banner properties including ID, type, title, content, dismissibility, and optional timestamp.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/banners.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n[{\"id\": \"string\",\"type\": \"string [info, success, warning, error]\",\"title\": \"string\",\"content\": \"string\",\"dismissible\": False,\"timestamp\": 1000}]\n```\n\n----------------------------------------\n\nTITLE: RAG Model Configuration Settings\nDESCRIPTION: Configuration settings for RAG (Retrieval Augmented Generation) embedding and reranking models. Controls model trust settings and auto-update behaviors.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_8\n\nLANGUAGE: plaintext\nCODE:\n```\nRAG_EMBEDDING_MODEL_TRUST_REMOTE_CODE=False\nRAG_RERANKING_MODEL_TRUST_REMOTE_CODE=False\nRAG_EMBEDDING_MODEL_AUTO_UPDATE=True\nRAG_RERANKING_MODEL_AUTO_UPDATE=True\n```\n\n----------------------------------------\n\nTITLE: Docker Update Query Example - RAG Response\nDESCRIPTION: Example showing how the RAG system responds to queries about Docker-related updates for Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/rag-tutorial.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nUser: \"How do I update Open WebUI using Docker?\"\nSystem: \"Refer to `docker/updating.md`: Use `docker pull` and restart the container.\"\n```\n\n----------------------------------------\n\nTITLE: SearXNG Settings Configuration\nDESCRIPTION: YAML configuration file for SearXNG server settings and search parameters.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nuse_default_settings: true\n\nserver:\n  secret_key: \"ultrasecretkey\"\n  limiter: true\n  image_proxy: true\n  port: 8080\n  bind_address: \"0.0.0.0\"\n\nui:\n  static_use_hash: true\n\nsearch:\n  safe_search: 0\n  autocomplete: \"\"\n  default_lang: \"\"\n  formats:\n    - html\n    - json\n\nredis:\n  url: redis://redis:6379/0\n```\n\n----------------------------------------\n\nTITLE: Generating Speech with curl (English)\nDESCRIPTION: curl command to generate speech from text using the openai-edge-tts API endpoint with English text.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://localhost:5050/v1/audio/speech \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer your_api_key_here\" \\\n  -d '{\n    \"model\": \"tts-1\",\n    \"input\": \"Hello, I am your AI assistant! Just let me know how I can help bring your ideas to life.\",\n    \"voice\": \"alloy\"\n  }' \\\n  --output speech.mp3\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama on Host with Open WebUI in Container for Linux\nDESCRIPTION: Mermaid diagram illustrating the network configuration for Linux systems where Ollama runs on the host and Open WebUI operates in a Docker container, connecting to Ollama via the Docker proxy.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Linux\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Container Network\") {\n      Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n   }\n   Component(ollama, \"Ollama\", \"Listening on port 11434\")\n}\nRel(openwebui, ollama, \"Makes API calls via Docker proxy\", \"http://host.docker.internal:11434\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: JSON Structure for WEBUI_BANNERS Configuration\nDESCRIPTION: The JSON schema for defining banner notifications in Open WebUI using the WEBUI_BANNERS environment variable. Shows the required fields including id, type, title, content, dismissible status, and timestamp.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n[{\"id\": \"string\",\"type\": \"string [info, success, warning, error]\",\"title\": \"string\",\"content\": \"string\",\"dismissible\": false,\"timestamp\": 1000}]\n```\n\n----------------------------------------\n\nTITLE: Starting the Open WebUI Server\nDESCRIPTION: Launches the Open WebUI server after installation is complete.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Venv.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nopen-webui serve\n```\n\n----------------------------------------\n\nTITLE: Combining Multiple URL Parameters in Open WebUI\nDESCRIPTION: This example shows how to combine multiple URL parameters to create a highly customized chat session in Open WebUI. It includes parameters for model selection, YouTube transcription, web search, tool activation, call overlay, initial query, and temporary chat settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/chat-features/url-params.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n/?models=model1,model2&youtube=VIDEO_ID&web-search=true&tools=tool1,tool2&call=true&q=Hello%20there&temporary-chat=true\n```\n\n----------------------------------------\n\nTITLE: Defining Access Control Structure for Knowledge Table in Python\nDESCRIPTION: This code snippet outlines the expected structure for the 'access_control' field in the Knowledge table. It defines read and write permissions using group and user IDs.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/sqlite-database.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n{\n  \"read\": {\n    \"group_ids\": [\"group_id1\", \"group_id2\"],\n    \"user_ids\": [\"user_id1\", \"user_id2\"]\n  },\n  \"write\": {\n    \"group_ids\": [\"group_id1\", \"group_id2\"],\n    \"user_ids\": [\"user_id1\", \"user_id2\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Windows Secret Key Generation\nDESCRIPTION: PowerShell script to generate a secure secret key for SearXNG on Windows systems.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_7\n\nLANGUAGE: powershell\nCODE:\n```\n$randomBytes = New-Object byte[] 32\n(New-Object Security.Cryptography.RNGCryptoServiceProvider).GetBytes($randomBytes)\n$secretKey = -join ($randomBytes | ForEach-Object { \"{0:x2}\" -f $_ })\n(Get-Content searxng-docker/searxng/settings.yml) -replace 'ultrasecretkey', $secretKey | Set-Content searxng-docker/searxng/settings.yml\n```\n\n----------------------------------------\n\nTITLE: Executing Basic Health Check for Open WebUI Availability\nDESCRIPTION: A basic curl command to check the /health endpoint of Open WebUI. This endpoint is publicly accessible without authentication and returns a 200 OK status when the service is running correctly.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/monitoring.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Basic health check - no authentication needed\ncurl https://your-open-webui-instance/health\n```\n\n----------------------------------------\n\nTITLE: Verifying Kubernetes Installation\nDESCRIPTION: Command to verify the installation by checking running pods in the Kubernetes cluster.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Helm.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods\n```\n\n----------------------------------------\n\nTITLE: Docker Run Command for Open WebUI with AUTOMATIC1111\nDESCRIPTION: Docker command to run Open WebUI with environment variables preset for AUTOMATIC1111 integration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/images.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -e AUTOMATIC1111_BASE_URL=http://host.docker.internal:7860/ -e ENABLE_IMAGE_GENERATION=True -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI from Development Branch\nDESCRIPTION: Docker command to run the latest development version of Open WebUI. This unstable branch contains the newest features but may include bugs or incomplete functionality.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:dev\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Event Emitters in Python Functions\nDESCRIPTION: A complete example of using Message Event Emitters in a function with error handling. This shows how to append messages to the chat interface and combine with status updates when errors occur.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/tab-shared/Common.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def test_function(\n        self, prompt: str, __user__: dict, __event_emitter__=None\n    ) -> str:\n        \"\"\"\n        This is a demo\n\n        :param test: this is a test parameter\n        \"\"\"\n\n        await __event_emitter__(\n                    {\n                        \"type\": \"message\", # We set the type here\n                        \"data\": {\"content\": \"This message will be appended to the chat.\"},\n                        # Note that with message types we do NOT have to set a done condition\n                    }\n                )\n\n        except Exception as e:\n            await __event_emitter__(\n                {\n                    \"type\": \"status\",\n                    \"data\": {\"description\": f\"An error occured: {e}\", \"done\": True},\n                }\n            )\n\n            return f\"Tell the user: {e}\"\n```\n\n----------------------------------------\n\nTITLE: Running Docling-Serve with GPU Support\nDESCRIPTION: Command to run the Docling-Serve Docker container with GPU support enabled, which can improve performance for document processing tasks.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/docling.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --gpus all -p 5001:5001 -e DOCLING_SERVE_ENABLE_UI=true quay.io/docling-project/docling-serve\n```\n\n----------------------------------------\n\nTITLE: Defining Optional Valves in Pipeline Class Definition\nDESCRIPTION: This example shows how to define valves as properties in a Pipeline class using Optional types. This approach allows the pipeline to load even when specific valve values are not provided, making them configurable through the web UI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/pipelines/valves.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Pipeline:\n    class Valves(BaseModel):\n        target_user_roles: List[str] = [\"user\"]\n        max_turns: Optional[int] = None\n```\n\n----------------------------------------\n\nTITLE: Terminating Conflicting Processes (Linux/macOS)\nDESCRIPTION: These commands are used to terminate processes on Linux or macOS systems. The first command attempts a normal termination, while the second forces termination.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nkill <PID>\n```\n\nLANGUAGE: bash\nCODE:\n```\nkill -9 <PID>\n```\n\n----------------------------------------\n\nTITLE: Verifying Kubernetes Pod Deployment\nDESCRIPTION: Command to verify that the Open WebUI pods are running correctly in the Kubernetes cluster after deployment.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Kustomize.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl get pods\n```\n\n----------------------------------------\n\nTITLE: Launching ComfyUI\nDESCRIPTION: Command to start ComfyUI for integration with Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/images.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython main.py\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with uv on macOS/Linux\nDESCRIPTION: Command to run Open WebUI using the uv runtime manager on macOS or Linux. This sets a persistent data directory and launches Open WebUI using Python 3.11.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nDATA_DIR=~/.open-webui uvx --python 3.11 open-webui@latest serve\n```\n\n----------------------------------------\n\nTITLE: Emitting Citation Events in Open WebUI Tools\nDESCRIPTION: This snippet demonstrates how to emit a citation event in an Open WebUI tool. It includes the structure for specifying content, source, and metadata for a citation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nawait __event_emitter__(\n    {\n        \"type\": \"citation\",\n        \"data\": {\n            \"document\": [content],\n            \"metadata\": [\n                {\n                    \"date_accessed\": datetime.now().isoformat(),\n                    \"source\": title,\n                }\n            ],\n            \"source\": {\"name\": title, \"url\": url},\n        },\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Publishing MCP Proxy Docker Image\nDESCRIPTION: Commands to tag the locally built MCP proxy Docker image and push it to DockerHub for deployment to cloud services or other environments.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndocker tag mcp-proxy-server yourdockerusername/mcp-proxy-server:latest\ndocker push yourdockerusername/mcp-proxy-server:latest\n```\n\n----------------------------------------\n\nTITLE: Terminating Conflicting Processes (Windows)\nDESCRIPTION: This command is used to forcefully terminate a process on Windows systems using its Process ID (PID).\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ntaskkill /PID <PID> /F\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Table in Markdown\nDESCRIPTION: A markdown table listing environment variables used for Speech-to-Text configuration, including variables for Whisper model settings and OpenAI integration parameters.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/speech-to-text/env-variables.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Variable | Description |\n|----------|-------------|\n| `WHISPER_MODEL` | Sets the Whisper model to use for local Speech-to-Text |\n| `WHISPER_MODEL_DIR` | Specifies the directory to store Whisper model files |\n| `AUDIO_STT_ENGINE` | Specifies the Speech-to-Text engine to use (empty for local Whisper, or `openai`) |\n| `AUDIO_STT_MODEL` | Specifies the Speech-to-Text model for OpenAI-compatible endpoints |\n| `AUDIO_STT_OPENAI_API_BASE_URL` | Sets the OpenAI-compatible base URL for Speech-to-Text |\n| `AUDIO_STT_OPENAI_API_KEY` | Sets the OpenAI API key for Speech-to-Text |\n```\n\n----------------------------------------\n\nTITLE: Backup Script Using SQLite & ChromaDB Native Backup Functions\nDESCRIPTION: Bash script that uses native backup functions for SQLite and ChromaDB to create backups, then uploads them to a Backblaze B2 bucket. It maintains 3 weekly snapshots and excludes specific files and directories.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n#\n# Backup script to back up ChromaDB and SQLite to Backblaze B2 bucket\n# openwebuiweeklies, maintaining 3 weekly snapshots.\n# Snapshots are independent and fully restorable.\n# Uses ChromaDB and SQLite native backup mechanisms.\n# Excludes audit.log, cache, and uploads directories.\n#\n# Ensure rclone is installed and configured correctly.\n# Install rclone: https://rclone.org/install/\n# Configure rclone: https://rclone.org/b2/\n\n# Source directory (containing ChromaDB and SQLite data)\nSOURCE=\"/var/lib/open-webui/data\"\n\n# B2 bucket name and remote name\nB2_REMOTE=\"openwebuiweeklies\"\nB2_BUCKET=\"b2:$B2_REMOTE\"\n\n# Timestamp for the backup directory\nTIMESTAMP=$(date +%Y-%m-%d)\n\n# Backup directory name\nBACKUP_DIR=\"open-webui-backup-$TIMESTAMP\"\n\n# Full path to the backup directory in the B2 bucket\nDESTINATION=\"$B2_BUCKET/$BACKUP_DIR\"\n\n# Number of weekly snapshots to keep\nNUM_SNAPSHOTS=3\n\n# Exclude filters (applied *after* database backups)\nEXCLUDE_FILTERS=\"--exclude audit.log --exclude cache/** --exclude uploads/** --exclude vector_db\"\n\n# ChromaDB Backup Settings (Adjust as needed)\nCHROMADB_DATA_DIR=\"$SOURCE/vector_db\"  # Path to ChromaDB data directory\nCHROMADB_BACKUP_FILE=\"$SOURCE/chromadb_backup.tar.gz\" # Archive file for ChromaDB backup\n\n# SQLite Backup Settings (Adjust as needed)\nSQLITE_DB_FILE=\"$SOURCE/webui.db\" # Path to the SQLite database file\nSQLITE_BACKUP_FILE=\"$SOURCE/webui.db.backup\" # Temporary file for SQLite backup\n\n# Function to backup ChromaDB\nbackup_chromadb() {\n  echo \"Backing up ChromaDB...\"\n\n  # Create a tar archive of the vector_db directory\n  tar -czvf \"$CHROMADB_BACKUP_FILE\" -C \"$SOURCE\" vector_db\n\n  echo \"ChromaDB backup complete.\"\n}\n\n# Function to backup SQLite\nbackup_sqlite() {\n  echo \"Backing up SQLite database...\"\n  # Backup the SQLite database using the .backup command\n  sqlite3 \"$SQLITE_DB_FILE\" \".backup '$SQLITE_BACKUP_FILE'\"\n\n  # Move the backup file to the source directory\n  mv \"$SQLITE_BACKUP_FILE\" \"$SOURCE/\"\n\n  echo \"SQLite backup complete.\"\n}\n\n# Perform database backups\nbackup_chromadb\nbackup_sqlite\n\n# Perform the backup with exclusions\nrclone copy \"$SOURCE\" \"$DESTINATION\" $EXCLUDE_FILTERS --progress\n\n# Remove old backups, keeping the most recent NUM_SNAPSHOTS\nfind \"$B2_BUCKET\" -type d -name \"open-webui-backup-*\" | sort -r | tail -n +$((NUM_SNAPSHOTS + 1)) | while read dir; do\n  rclone purge \"$dir\"\ndone\n\necho \"Backup completed to $DESTINATION\"\n```\n\n----------------------------------------\n\nTITLE: Defining Autocomplete Generation Prompt Template in YAML\nDESCRIPTION: This snippet defines the default prompt template used for autocomplete generation. It includes instructions for the autocompletion system, output rules, and examples of how to use the template.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n### Task:\nYou are an autocompletion system. Continue the text in `<text>` based on the **completion type** in `<type>` and the given language.  \n\n### **Instructions**:\n1. Analyze `<text>` for context and meaning.  \n2. Use `<type>` to guide your output:  \n   - **General**: Provide a natural, concise continuation.  \n   - **Search Query**: Complete as if generating a realistic search query.  \n3. Start as if you are directly continuing `<text>`. Do **not** repeat, paraphrase, or respond as a model. Simply complete the text.  \n4. Ensure the continuation:\n   - Flows naturally from `<text>`.  \n   - Avoids repetition, overexplaining, or unrelated ideas.  \n5. If unsure, return: `{ \"text\": \"\" }`.  \n\n### **Output Rules**:\n- Respond only in JSON format: `{ \"text\": \"<your_completion>\" }`.\n\n### **Examples**:\n#### Example 1:  \nInput:  \n<type>General</type>  \n<text>The sun was setting over the horizon, painting the sky</text>  \nOutput:  \n{ \"text\": \"with vibrant shades of orange and pink.\" }\n\n#### Example 2:  \nInput:  \n<type>Search Query</type>  \n<text>Top-rated restaurants in</text>  \nOutput:  \n{ \"text\": \"New York City for Italian cuisine.\" }  \n\n---\n### Context:\n<chat_history>\n{{MESSAGES:END:6}}\n</chat_history>\n<type>{{TYPE}}</type>  \n<text>{{PROMPT}}</text>  \n#### Output:\n```\n\n----------------------------------------\n\nTITLE: Logging Streaming Chunks with the Stream Hook\nDESCRIPTION: Example of using the stream function to log and inspect each chunk of data as it streams from the LLM in real-time, useful for debugging and monitoring.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef stream(self, event: dict) -> dict:\n    print(event)  # Print each incoming chunk for inspection\n    return event\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Citations in Open WebUI Tools\nDESCRIPTION: This example demonstrates a complete implementation of custom citations in an Open WebUI tool. It includes the Tools class definition, a test function that emits a citation event, and the proper initialization to disable built-in citations.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass Tools:\n    class UserValves(BaseModel):\n        test: bool = Field(\n            default=True, description=\"test\"\n        )\n\n    def __init__(self):\n        self.citation = False\n\nasync def test_function(\n        self, prompt: str, __user__: dict, __event_emitter__=None\n    ) -> str:\n        \"\"\"\n        This is a demo that just creates a citation\n\n        :param test: this is a test parameter\n        \"\"\"\n\n        await __event_emitter__(\n            {\n                \"type\": \"citation\",\n                \"data\": {\n                    \"document\": [\"This message will be appended to the chat as a citation when clicked into\"],\n                    \"metadata\": [\n                        {\n                            \"date_accessed\": datetime.now().isoformat(),\n                            \"source\": title,\n                        }\n                    ],\n                    \"source\": {\"name\": \"Title of the content\", \"url\": \"http://link-to-citation\"},\n                },\n            }\n        )\n```\n\n----------------------------------------\n\nTITLE: Downloading DeepSeek-R1 Model with HuggingFace Hub\nDESCRIPTION: Python script to download the dynamic quantized version of DeepSeek-R1 from Hugging Face using the snapshot_download function. This code specifically downloads the 1.58-bit version of the model by filtering with the pattern '*UD-IQ1_S*'.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/deepseekr1-dynamic.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Install Hugging Face dependencies before running this:\n# pip install huggingface_hub hf_transfer\n\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(\n    repo_id = \"unsloth/DeepSeek-R1-GGUF\",  # Specify the Hugging Face repo\n    local_dir = \"DeepSeek-R1-GGUF\",         # Model will download into this directory\n    allow_patterns = [\"*UD-IQ1_S*\"],        # Only download the 1.58-bit version\n)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Webhook Payload Format in Open WebUI\nDESCRIPTION: Shows the plain text format of webhook notifications sent when new users sign up. The payload contains a simple message with the username of the new user.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/webhooks.md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nNew user signed up: <username>\n```\n\n----------------------------------------\n\nTITLE: Generating bcrypt Hash in Alpine Container\nDESCRIPTION: Command to generate a bcrypt hash of a new password in the Alpine container for the alternative Docker method. The hash will be used to update the admin password in the database.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nhtpasswd -bnBC 10 \"\" your-new-password | tr -d ':'\n```\n\n----------------------------------------\n\nTITLE: Implementing Event Emitters for Message Appending in Python\nDESCRIPTION: Example of using event emitters to append messages to the chat during tool execution, including error handling.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def test_function(\n        self, prompt: str, __user__: dict, __event_emitter__=None\n    ) -> str:\n        \"\"\"\n        This is a demo\n\n        :param test: this is a test parameter\n        \"\"\"\n\n        await __event_emitter__(\n                    {\n                        \"type\": \"message\",\n                        \"data\": {\"content\": \"This message will be appended to the chat.\"}\n                    }\n                )\n\n        except Exception as e:\n            await __event_emitter__(\n                {\n                    \"type\": \"status\",\n                    \"data\": {\"description\": f\"An error occured: {e}\", \"done\": True},\n                }\n            )\n\n            return f\"Tell the user: {e}\"\n```\n\n----------------------------------------\n\nTITLE: Setting Node.js Heap Size for Different Operating Systems\nDESCRIPTION: Commands to increase Node.js heap size for different operating systems to prevent memory issues\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nexport NODE_OPTIONS=\"--max-old-space-size=4096\" # For Linux/macOS (bash, zsh)\n# set NODE_OPTIONS=--max-old-space-size=4096 # For Windows (Command Prompt)\n# $env:NODE_OPTIONS=\"--max-old-space-size=4096\" # For Windows (PowerShell)\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Disabling Built-in Citations in Open WebUI Tools\nDESCRIPTION: This code shows how to disable built-in citations in an Open WebUI tool by setting self.citation to False in the Tools class __init__ method. This allows for custom citation management.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef __init__(self):\n    self.citation = False\n```\n\n----------------------------------------\n\nTITLE: Manually Updating Open WebUI with Watchtower\nDESCRIPTION: Docker command to perform a one-time update of the Open WebUI container using Watchtower. This method checks for newer image versions and updates the container if available.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui\n```\n\n----------------------------------------\n\nTITLE: Downloading GGUF Model using Python and Hugging Face Hub\nDESCRIPTION: Python script to programmatically download the DeepSeek-R1 1.58-bit quantized model from Hugging Face. Uses huggingface_hub and hf_transfer libraries to download specific model patterns.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/starting-with-llama-cpp.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# pip install huggingface_hub hf_transfer\n\nfrom huggingface_hub import snapshot_download\n\nsnapshot_download(\n    repo_id = \"unsloth/DeepSeek-R1-GGUF\",\n    local_dir = \"DeepSeek-R1-GGUF\",\n    allow_patterns = [\"*UD-IQ1_S*\"],  # Download only 1.58-bit variant\n)\n```\n\n----------------------------------------\n\nTITLE: Nvidia GPU Support Configuration for Docker Compose\nDESCRIPTION: Additional Docker Compose configuration for enabling Nvidia GPU support, including device reservation and capability settings\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerCompose.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ndeploy:\n  resources:\n    reservations:\n      devices:\n        - driver: nvidia\n          count: all\n          capabilities: [gpu]\n```\n\n----------------------------------------\n\nTITLE: Installing and Running mcpo with pip\nDESCRIPTION: Commands to install the MCP-to-OpenAPI proxy server using pip and then run it with the specified port and MCP server command.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install mcpo\nmcpo --port 8000 -- your_mcp_server_command\n```\n\n----------------------------------------\n\nTITLE: Choosing Between Chat Completion Functions in Python\nDESCRIPTION: Illustrates the difference between using the full API flow chat completion function and the lightweight direct POST request function in Open WebUI 0.5.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/migration/index.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Use this for the full API flow with parsing:\nfrom open_webui.main import chat_completion\n\n# Use this for a stripped-down, direct POST request:\nfrom open_webui.utils.chat import generate_chat_completion\n```\n\n----------------------------------------\n\nTITLE: Docker Environment Configuration\nDESCRIPTION: Dockerfile configuration to set Node.js memory allocation\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_9\n\nLANGUAGE: dockerfile\nCODE:\n```\nENV NODE_OPTIONS=--max-old-space-size=4096\n```\n\n----------------------------------------\n\nTITLE: Creating Feature Branch in Git\nDESCRIPTION: Commands for creating a new feature branch based on the dev branch, ensuring the local dev branch is up-to-date before branching.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout dev\ngit pull origin dev # Ensure your local dev branch is up-to-date\ngit checkout -b my-feature-branch\n```\n\n----------------------------------------\n\nTITLE: Running Container with Slirp4netns Network Configuration\nDESCRIPTION: Advanced container run command with slirp4netns networking to enable host loopback access. Used when standard networking configuration causes connectivity issues.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/Podman.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npodman run -d --network=slirp4netns:allow_host_loopback=true --name openwebui -p 3000:8080 -v open-webui:/app/backend/data ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI via pip\nDESCRIPTION: Installs the Open WebUI package using pip within the activated virtual environment.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Venv.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install open-webui\n```\n\n----------------------------------------\n\nTITLE: Applying Kustomize Manifests to Kubernetes\nDESCRIPTION: Command to apply the Kustomize manifests to the Kubernetes cluster. This deploys all the necessary components of Open WebUI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Kustomize.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkubectl apply -k .\n```\n\n----------------------------------------\n\nTITLE: Starting Nginx Docker Container\nDESCRIPTION: Command to start the Nginx service in detached mode using Docker Compose.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d nginx\n```\n\n----------------------------------------\n\nTITLE: Setting OLLAMA_HOST Environment Variable for Ollama Serve\nDESCRIPTION: This command sets the OLLAMA_HOST environment variable to allow Ollama service to be accessed from another machine. It should be executed before running the 'ollama serve' command.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/ipex_llm.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport OLLAMA_HOST=0.0.0.0\n```\n\n----------------------------------------\n\nTITLE: Content Extraction Engine Configuration\nDESCRIPTION: Settings for document content extraction engines including Tika, Docling, Document Intelligence, and Mistral OCR. Includes server URLs and API keys.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_10\n\nLANGUAGE: plaintext\nCODE:\n```\nCONTENT_EXTRACTION_ENGINE=tika\nMISTRAL_OCR_API_KEY=None\nTIKA_SERVER_URL=http://localhost:9998\nDOCLING_SERVER_URL=http://docling:5001\n```\n\n----------------------------------------\n\nTITLE: Automating Let's Encrypt SSL Certificate Installation\nDESCRIPTION: Bash script that automates the installation of Let's Encrypt SSL certificates using Certbot. It handles Certbot installation if missing and configures Nginx accordingly.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n#!/bin/bash\n\n# Description: Simplified script to obtain and install Let's Encrypt SSL certificates using Certbot.\n\nDOMAIN=\"your_domain_or_IP\"\nEMAIL=\"your_email@example.com\"\n\n# Install Certbot if not installed\nif ! command -v certbot &> /dev/null; then\n    echo \"Certbot not found. Installing...\"\n    sudo apt-get update\n    sudo apt-get install -y certbot python3-certbot-nginx\nfi\n\n# Obtain SSL certificate\nsudo certbot --nginx -d \"$DOMAIN\" --non-interactive --agree-tos -m \"$EMAIL\"\n\n# Reload Nginx to apply changes\nsudo systemctl reload nginx\n\necho \"Let's Encrypt SSL certificate has been installed and Nginx reloaded.\"\n```\n\n----------------------------------------\n\nTITLE: Setting Valves with Environment Variables in Pipeline Initialization\nDESCRIPTION: This snippet demonstrates how to initialize valves in a pipeline using environment variables with fallback default values. It shows the recommended pattern for making valves configurable by administrators through the web UI.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/pipelines/valves.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nself.valves = self.Valves(\n    **{\n        \"LLAMAINDEX_OLLAMA_BASE_URL\": os.getenv(\"LLAMAINDEX_OLLAMA_BASE_URL\", \"http://localhost:11434\"),\n        \"LLAMAINDEX_MODEL_NAME\": os.getenv(\"LLAMAINDEX_MODEL_NAME\", \"llama3\"),\n        \"LLAMAINDEX_EMBEDDING_MODEL_NAME\": os.getenv(\"LLAMAINDEX_EMBEDDING_MODEL_NAME\", \"nomic-embed-text\"),\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Launching ComfyUI with Low VRAM Option\nDESCRIPTION: Command to start ComfyUI with low VRAM usage for systems with limited resources.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/images.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython main.py --lowvram\n```\n\n----------------------------------------\n\nTITLE: Testing File Analysis with Tika\nDESCRIPTION: CURL command to test file analysis functionality of Apache Tika.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -T test.txt http://localhost:9998/tika\n```\n\n----------------------------------------\n\nTITLE: Visualizing Open WebUI in Host Network for macOS/Windows\nDESCRIPTION: Mermaid diagram showing an unsuccessful configuration where Open WebUI is deployed with host network mode on macOS/Windows. This fails because the container's host network is inside the Docker VM, not the physical host machine.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Mac OS/Windows\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Docker Desktop's Linux VM\") {\n      Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n   }\n}\nRel(user, openwebui, \"Unable to connect, host network is the VM's network\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama and Open WebUI in Separate Networks for macOS/Windows\nDESCRIPTION: Mermaid diagram illustrating a problematic configuration where Ollama and Open WebUI are deployed in separate Docker networks on macOS/Windows, preventing proper communication between the components.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Mac OS/Windows\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Docker Desktop's Linux VM\") {\n      Boundary(b2, \"Network A\") {\n         Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n      }\n      Boundary(b3, \"Network B\") {\n         Component(ollama, \"Ollama\", \"Listening on port 11434\")\n      }\n   }\n}\nRel(openwebui, ollama, \"Unable to connect\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Adding System Context in Inlet Function for Italian Cooking\nDESCRIPTION: An example inlet function that adds a system message to provide context about Italian cooking. This demonstrates how to modify the conversation context before sending it to the LLM.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:\n    # Add system message for Italian context in the conversation\n    context_message = {\n        \"role\": \"system\",\n        \"content\": \"You are helping the user prepare an Italian meal.\"\n    }\n    # Insert the context at the beginning of the chat history\n    body.setdefault(\"messages\", []).insert(0, context_message)\n    return body\n```\n\n----------------------------------------\n\nTITLE: Adding API Key Configuration for Continue.dev\nDESCRIPTION: Adds the API key configuration for authenticating with Open WebUI from Continue.dev.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/continue-dev.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiKey: sk-79970662256d425eb274fc4563d4525b # Replace with your API key\n```\n\n----------------------------------------\n\nTITLE: Identifying Port Conflicts Using Command Prompt (Windows)\nDESCRIPTION: This command helps identify processes using specific ports on Windows systems using Command Prompt. It shows the PID of the process using the port.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nnetstat -ano | findstr :5173\n```\n\n----------------------------------------\n\nTITLE: Identifying Port Conflicts Using Terminal Commands (Linux/macOS)\nDESCRIPTION: These commands help identify processes using specific ports on Linux or macOS systems. They list the process ID (PID) and name of the process using the specified port.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nlsof -i :5173\n```\n\nLANGUAGE: bash\nCODE:\n```\nnetstat -tulnp | grep 5173\n```\n\n----------------------------------------\n\nTITLE: SearXNG uWSGI Configuration\nDESCRIPTION: Configuration file for uWSGI server settings used by SearXNG.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/web-search/searxng.md#2025-04-23_snippet_4\n\nLANGUAGE: ini\nCODE:\n```\n[uwsgi]\nuid = searxng\ngid = searxng\nworkers = %k\nthreads = 4\nchmod-socket = 666\nsingle-interpreter = true\nmaster = true\nplugin = python3\nlazy-apps = true\nenable-threads = 4\nmodule = searx.webapp\npythonpath = /usr/local/searxng/\nchdir = /usr/local/searxng/searx/\nauto-procname = true\ndisable-logging = true\nlog-5xx = true\nbuffer-size = 8192\nadd-header = Connection: close\nstatic-map = /static=/usr/local/searxng/searx/static\nstatic-expires = /* 86400\nstatic-gzip-all = True\noffload-threads = 4\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI Bundled with Ollama (GPU Support)\nDESCRIPTION: Docker command to run the bundled version of Open WebUI with Ollama with GPU support. This single-container solution includes both applications and mounts two volumes for Ollama models and Open WebUI data.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n```\n\n----------------------------------------\n\nTITLE: Implementing Event Emitters for Status Updates in Python\nDESCRIPTION: Example of using event emitters to provide status updates during tool execution, including handling exceptions.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/tools/development.mdx#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync def test_function(\n        self, prompt: str, __user__: dict, __event_emitter__=None\n    ) -> str:\n        \"\"\"\n        This is a demo\n\n        :param test: this is a test parameter\n        \"\"\"\n\n        await __event_emitter__(\n            {\n                \"type\": \"status\",\n                \"data\": {\"description\": \"Message that shows up in the chat\", \"done\": False}, \n            }\n        )\n\n        # Do some other logic here\n        await __event_emitter__(\n            {\n                \"type\": \"status\",\n                \"data\": {\"description\": \"Completed a task message\", \"done\": True, \"hidden\": False},\n            }\n        )\n\n        except Exception as e:\n            await __event_emitter__(\n                {\n                    \"type\": \"status\",\n                    \"data\": {\"description\": f\"An error occured: {e}\", \"done\": True},\n                }\n            )\n\n            return f\"Tell the user: {e}\"\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Actions Workflow in YAML\nDESCRIPTION: Configuration for the GitHub Actions workflow file to handle environment variables during the build process.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/contributing-tutorial.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n- name: Build\n  env:\n    BASE_URL: ${{ vars.BASE_URL }}\n    SITE_URL: ${{ vars.SITE_URL }}\n  run: npm run build\n```\n\n----------------------------------------\n\nTITLE: Local Docusaurus Testing Commands\nDESCRIPTION: Basic bash commands for installing dependencies and building the Docusaurus site locally for testing.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/contributing-tutorial.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm install   # Install dependencies\nnpm run build # Build the site for production\n```\n\n----------------------------------------\n\nTITLE: Container Database Copy Command - Bash\nDESCRIPTION: Command to copy the SQLite database file from a Docker container to the local machine.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/sqlite-database.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker cp open-webui:/app/backend/data/webui.db ./webui.db\n```\n\n----------------------------------------\n\nTITLE: Configuration Files Reference in YAML\nDESCRIPTION: References to key configuration files used in the TTS setup, including voice_to_speaker.yaml for voice definitions and docker-compose.yml for service configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nvoice_to_speaker.yaml\nvoice_to_speaker.default.yaml\ndocker-compose.yml\n```\n\n----------------------------------------\n\nTITLE: Configuring browser.ml.chat.prompts.# in Firefox\nDESCRIPTION: This snippet demonstrates how to add custom prompts in Firefox's about:config settings for the AI chatbot.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/firefox-sidebar.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"id\":\"My Prompt\", \"value\": \"This is my custom prompt.\", \"label\": \"My Prompt\"}\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages in Alpine Container\nDESCRIPTION: Command to install apache2-utils (for htpasswd) and sqlite in the Alpine Linux container, which are needed for password reset operations in the alternative Docker method.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\napk add apache2-utils sqlite\n```\n\n----------------------------------------\n\nTITLE: Configuring Docusaurus Settings in TypeScript\nDESCRIPTION: TypeScript configuration for Docusaurus settings using environment variables with fallback values for local development.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/contributing-tutorial.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst config: Config = {\n  title: \"Open WebUI\",\n  tagline: \"ChatGPT-Style WebUI for LLMs (Formerly Ollama WebUI)\",\n  favicon: \"images/favicon.png\",\n  url: process.env.SITE_URL || \"https://openwebui.com\",\n  baseUrl: process.env.BASE_URL || \"/\",\n  ...\n};\n```\n\n----------------------------------------\n\nTITLE: Updating Admin Password with SQL in Alpine Container\nDESCRIPTION: SQL command to update the admin password in the SQLite database. HASH should be replaced with the bcrypt hash generated in the previous step. Part of the alternative Docker method.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nUPDATE auth SET password='HASH' WHERE email='admin@example.com';\n```\n\n----------------------------------------\n\nTITLE: Creating Data Directories for Docker Volumes in Bash\nDESCRIPTION: This command creates the necessary directories for storing data from Open WebUI, ChromaDB, and Ollama containers.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerSwarm.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p data/open-webui data/chromadb data/ollama\n```\n\n----------------------------------------\n\nTITLE: Podman Configuration for MacOS\nDESCRIPTION: Podman command for MacOS setup enabling host loopback access and configuring connection to Ollama server. Sets up port mapping and persistent storage with appropriate network settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/connection-error.mdx#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npodman run -d --network slirp4netns:allow_host_loopback=true -p 3000:8080 -e OLLAMA_BASE_URL=http://host.containers.internal:11434 -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Using Message Event Emitters in Python\nDESCRIPTION: This snippet demonstrates how to use the Message type of Event Emitters to append content to the chat interface during function execution. Unlike Status emitters, Message emitters don't require a 'done' flag.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/tab-shared/Common.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nawait __event_emitter__(\n                    {\n                        \"type\": \"message\", # We set the type here\n                        \"data\": {\"content\": \"This message will be appended to the chat.\"},\n                        # Note that with message types we do NOT have to set a done condition\n                    }\n                )\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: Command to install the required Python packages listed in requirements.txt using pip.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama and Open WebUI in Separate Networks for Linux\nDESCRIPTION: Mermaid diagram depicting a problematic configuration where Ollama and Open WebUI are deployed in separate Docker networks on Linux, preventing proper communication between the components.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Linux\") {\n   Person(user, \"User\")\n   Boundary(b2, \"Container Network A\") {\n      Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n   }\n   Boundary(b3, \"Container Network B\") {\n      Component(ollama, \"Ollama\", \"Listening on port 11434\")\n   }\n}\nRel(openwebui, ollama, \"Unable to connect\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Defining File Metadata Structure in Python\nDESCRIPTION: This code snippet defines the expected structure for the 'meta' field in the File table. It includes properties for name, content type, and file size, with additional metadata allowed through ConfigDict.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tips/sqlite-database.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{\n    \"name\": string,          # Optional display name\n    \"content_type\": string,  # MIME type\n    \"size\": integer,         # File size in bytes\n    # Additional metadata supported via ConfigDict(extra=\"allow\")\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring ComfyUI Workflow JSON\nDESCRIPTION: Default workflow configuration for ComfyUI image generation pipeline. Defines the processing nodes and their connections including KSampler, checkpoint loading, latent image generation, CLIP text encoding, VAE decoding, and image saving.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"3\": {\n    \"inputs\": {\n      \"seed\": 0,\n      \"steps\": 20,\n      \"cfg\": 8,\n      \"sampler_name\": \"euler\",\n      \"scheduler\": \"normal\",\n      \"denoise\": 1,\n      \"model\": [\n        \"4\",\n        0\n      ],\n      \"positive\": [\n        \"6\",\n        0\n      ],\n      \"negative\": [\n        \"7\",\n        0\n      ],\n      \"latent_image\": [\n        \"5\",\n        0\n      ]\n    },\n    \"class_type\": \"KSampler\",\n    \"_meta\": {\n      \"title\": \"KSampler\"\n    }\n  },\n  \"4\": {\n    \"inputs\": {\n      \"ckpt_name\": \"model.safetensors\"\n    },\n    \"class_type\": \"CheckpointLoaderSimple\",\n    \"_meta\": {\n      \"title\": \"Load Checkpoint\"\n    }\n  },\n  \"5\": {\n    \"inputs\": {\n      \"width\": 512,\n      \"height\": 512,\n      \"batch_size\": 1\n    },\n    \"class_type\": \"EmptyLatentImage\",\n    \"_meta\": {\n      \"title\": \"Empty Latent Image\"\n    }\n  },\n  \"6\": {\n    \"inputs\": {\n      \"text\": \"Prompt\",\n      \"clip\": [\n        \"4\",\n        1\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"7\": {\n    \"inputs\": {\n      \"text\": \"\",\n      \"clip\": [\n        \"4\",\n        1\n      ]\n    },\n    \"class_type\": \"CLIPTextEncode\",\n    \"_meta\": {\n      \"title\": \"CLIP Text Encode (Prompt)\"\n    }\n  },\n  \"8\": {\n    \"inputs\": {\n      \"samples\": [\n        \"3\",\n        0\n      ],\n      \"vae\": [\n        \"4\",\n        2\n      ]\n    },\n    \"class_type\": \"VAEDecode\",\n    \"_meta\": {\n      \"title\": \"VAE Decode\"\n    }\n  },\n  \"9\": {\n    \"inputs\": {\n      \"filename_prefix\": \"ComfyUI\",\n      \"images\": [\n        \"8\",\n        0\n      ]\n    },\n    \"class_type\": \"SaveImage\",\n    \"_meta\": {\n      \"title\": \"Save Image\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Query Generation Template\nDESCRIPTION: Template for generating search queries based on chat history. Includes task guidelines, output format specifications, and chat history context handling.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_12\n\nLANGUAGE: plaintext\nCODE:\n```\n### Task:\nAnalyze the chat history to determine the necessity of generating search queries, in the given language. By default, **prioritize generating 1-3 broad and relevant search queries** unless it is absolutely certain that no additional information is required. The aim is to retrieve comprehensive, updated, and valuable information even with minimal uncertainty. If no search is unequivocally needed, return an empty list.\n\n### Guidelines:\n- Respond **EXCLUSIVELY** with a JSON object. Any form of extra commentary, explanation, or additional text is strictly prohibited.\n- When generating search queries, respond in the format: { \"queries\": [\"query1\", \"query2\"] }, ensuring each query is distinct, concise, and relevant to the topic.\n- If and only if it is entirely certain that no useful results can be retrieved by a search, return: { \"queries\": [] }.\n- Err on the side of suggesting search queries if there is **any chance** they might provide useful or updated information.\n- Be concise and focused on composing high-quality search queries, avoiding unnecessary elaboration, commentary, or assumptions.\n- Today's date is: {{CURRENT_DATE}}.\n- Always prioritize providing actionable and broad queries that maximize informational coverage.\n\n### Output:\nStrictly return in JSON format: \n{\n  \"queries\": [\"query1\", \"query2\"]\n}\n\n### Chat History:\n<chat_history>\n{{MESSAGES:END:6}}\n</chat_history>\n```\n\n----------------------------------------\n\nTITLE: Listing Running Podman Containers\nDESCRIPTION: Command to display all currently running containers managed by Podman.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/Podman.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npodman ps\n```\n\n----------------------------------------\n\nTITLE: Running the openai-edge-tts Server\nDESCRIPTION: Command to start the openai-edge-tts server using Python.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openai-edge-tts-integration.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython app/server.py\n```\n\n----------------------------------------\n\nTITLE: Manual Pipeline Installation Commands\nDESCRIPTION: Series of shell commands for cloning the repository and installing required dependencies.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/pipelines/index.mdx#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ngit clone https://github.com/open-webui/pipelines.git\ncd pipelines\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install -r requirements.txt\n```\n\nLANGUAGE: sh\nCODE:\n```\nsh ./start.sh\n```\n\n----------------------------------------\n\nTITLE: Deploying Docker Stack for Open WebUI, ChromaDB, and Ollama\nDESCRIPTION: This command deploys the Docker Swarm stack defined in the docker-stack.yaml file, creating a stack named 'super-awesome-ai'.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerSwarm.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker stack deploy -c docker-stack.yaml -d super-awesome-ai\n```\n\n----------------------------------------\n\nTITLE: Modifying Ollama Service for CPU-only Support in Docker Swarm\nDESCRIPTION: This YAML snippet shows the modified Ollama service configuration for CPU-only support, removing the GPU resource allocation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerSwarm.md#2025-04-23_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nollama:\n  image: ollama/ollama:latest\n  hostname: ollama\n  ports:\n    - target: 11434\n      published: 11434\n      mode: overlay\n  deploy:\n    replicas: 1\n    restart_policy:\n      condition: any\n      delay: 5s\n      max_attempts: 3\n  volumes:\n    - ./data/ollama:/root/.ollama\n```\n\n----------------------------------------\n\nTITLE: Running Apache Tika with Docker Command\nDESCRIPTION: Docker run command for deploying Apache Tika container with port mapping and restart policy.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --name tika \\\n  -p 9998:9998 \\\n  --restart unless-stopped \\\n  apache/tika:latest-full\n```\n\n----------------------------------------\n\nTITLE: Locating webui.db with Python\nDESCRIPTION: Python script to locate the webui.db file in your Python environment. This script helps find the database file when you want to completely reset Open WebUI by deleting all data.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport open_webui\n\n# Show where the Open WebUI package is installed\nprint(\"Open WebUI is installed at:\", open_webui.__file__)\n\n# Construct a potential path to webui.db (commonly located in 'data/webui.db')\ndb_path = os.path.join(os.path.dirname(open_webui.__file__), \"data\", \"webui.db\")\nprint(\"Potential path to webui.db:\", db_path)\n\n# Check if webui.db exists at that path\nif os.path.exists(db_path):\n    print(\"webui.db found at:\", db_path)\nelse:\n    print(\"webui.db not found at:\", db_path)\n```\n\n----------------------------------------\n\nTITLE: MCP Server Configuration Example for Claude\nDESCRIPTION: JSON configuration example showing how to add a Time MCP Server to Claude settings, specifying the command and arguments including a local timezone parameter.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/mcp.mdx#2025-04-23_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"mcpServers\": {   \n  \"time\": {     \n    \"command\": \"uvx\",     \n    \"args\": [\"mcp-server-time\", \"--local-timezone=America/New_York\"]   \n  } \n}\n```\n\n----------------------------------------\n\nTITLE: Importing React Component in Markdown\nDESCRIPTION: Import statement for the TopBanners React component used in the documentation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/roadmap.mdx#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nimport { TopBanners } from \"@site/src/components/TopBanners\";\n\n<TopBanners />\n```\n\n----------------------------------------\n\nTITLE: Running MCP Server with OpenAPI Bridge for Backward Compatibility\nDESCRIPTION: This command demonstrates how to use the mcpo bridge tool to convert an existing MCP server to OpenAPI compatibility. It runs an MCP time server with a specific timezone while exposing it via OpenAPI on port 8000.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/openapi-servers/faq.mdx#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuvx mcpo --port 8000 -- uvx mcp-server-time --local-timezone=America/New_York\n```\n\n----------------------------------------\n\nTITLE: Example Browser Search Query Using Open WebUI\nDESCRIPTION: Demonstration of how to use the configured Open WebUI search engine from the browser's address bar using the designated keyword.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/browser-search-engine.md#2025-04-23_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\nwebui your search query\n```\n\n----------------------------------------\n\nTITLE: Rendering Basic Flowchart with MermaidJS in Markdown\nDESCRIPTION: This snippet demonstrates how to create a simple flowchart using MermaidJS syntax within a Markdown code block. It shows a decision-making process with multiple paths.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/code-execution/mermaid.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```mermaid\ngraph TD;\n  A-->B;\n  B-->C{Decision};\n  C--Yes-->D;\n  C--No-->E;\n  D-->F;\n  E-->F;\n```\n```\n\n----------------------------------------\n\nTITLE: Displaying RAG Troubleshooting Summary Checklist in Markdown\nDESCRIPTION: A markdown table summarizing common RAG problems and their corresponding fixes. This provides a quick reference for users to identify and address issues in their RAG implementation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/rag.mdx#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Problem | Fix |\n|--------|------|\n| 🤔 Model can't \"see\" content | Check document extractor settings |\n| 🧹 Only part of content used | Enable Full Context Mode or Bypass Embedding |\n| ⏱ Limited by 2048 token cap | Increase model context length or use large-context LLM |\n| 📉 Inaccurate retrieval | Switch to a better embedding model, then reindex |\n| Still confused? | Test with GPT-4o and compare outputs |\n```\n\n----------------------------------------\n\nTITLE: Connecting Docker Container to Ollama Host\nDESCRIPTION: Docker command to run Open WebUI container with host network access, enabling direct communication with Ollama server running on the host machine. Uses port 8080 and sets up persistent storage.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/connection-error.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Installing Open WebUI with pip\nDESCRIPTION: Command to install Open WebUI using Python's pip package manager. This method requires a properly configured Python environment (preferably managed with uv or conda).\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npip install open-webui\n```\n\n----------------------------------------\n\nTITLE: Generating Flowchart with MermaidJS in Markdown\nDESCRIPTION: This snippet shows the rendered output of a MermaidJS flowchart in Markdown format. It illustrates a simple decision-making process with start and end points.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/code-execution/mermaid.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```markdown\n startAncestor [ start ]\nA[A] --> B[B]\nB --> C[Decision]\nC -->| Yes | D[D]\nC -->| No  | E[E]\nD --> F[F]\nE --> F[F]\n```\n```\n\n----------------------------------------\n\nTITLE: Removing Existing Docker Container\nDESCRIPTION: Stops and removes the existing open-webui container as part of the manual update process.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-docker/DockerUpdating.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker rm -f open-webui\n```\n\n----------------------------------------\n\nTITLE: Importing TopBanners Component in JSX\nDESCRIPTION: Import statement for the TopBanners component from the site components directory, used in the mission statement page.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/mission.mdx#2025-04-23_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nimport { TopBanners } from \"@site/src/components/TopBanners\";\n```\n\n----------------------------------------\n\nTITLE: Default Template for Image Prompt Generation in Open WebUI\nDESCRIPTION: This template is used by Open WebUI to generate detailed image prompts. It provides guidelines for the AI to create descriptive prompts for image generation tasks, ensuring proper detail and context while maintaining output in JSON format.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/env-configuration.md#2025-04-23_snippet_13\n\nLANGUAGE: plaintext\nCODE:\n```\n### Task:\nGenerate a detailed prompt for am image generation task based on the given language and context. Describe the image as if you were explaining it to someone who cannot see it. Include relevant details, colors, shapes, and any other important elements.\n\n### Guidelines:\n- Be descriptive and detailed, focusing on the most important aspects of the image.\n- Avoid making assumptions or adding information not present in the image.\n- Use the chat's primary language; default to English if multilingual.\n- If the image is too complex, focus on the most prominent elements.\n\n### Output:\nStrictly return in JSON format:\n{\n    \"prompt\": \"Your detailed description here.\"\n}\n\n### Chat History:\n<chat_history>\n{{MESSAGES:END:6}}\n</chat_history>\n```\n\n----------------------------------------\n\nTITLE: Creating Incremental Backups Using Rsync in Bash\nDESCRIPTION: A bash script that creates timestamped snapshots using rsync with hard links for efficient incremental backups. The script includes configuration variables, directory creation, and error handling.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/maintenance/backups.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Configuration\nSOURCE_DIR=\".\"  # Directory to snapshot (current directory)\nSNAPSHOT_DIR=\"/snapshots\" # Directory to store snapshots\nTIMESTAMP=$(date +%Y%m%d%H%M%S) # Generate timestamp\n\n# Create the snapshot directory if it doesn't exist\nmkdir -p \"$SNAPSHOT_DIR\"\n\n# Create the snapshot name\nSNAPSHOT_NAME=\"snapshot_$TIMESTAMP\"\nSNAPSHOT_PATH=\"$SNAPSHOT_DIR/$SNAPSHOT_NAME\"\n\n# Perform the rsync snapshot\necho \"Creating snapshot: $SNAPSHOT_PATH\"\nrsync -av --delete --link-dest=\"$SNAPSHOT_DIR/$(ls -t \"$SNAPSHOT_DIR\" | head -n 1)\" \"$SOURCE_DIR/\" \"$SNAPSHOT_PATH\"\n\n# Check if rsync was successful\nif [ $? -eq 0 ]; then\n  echo \"Snapshot created successfully.\"\nelse\n  echo \"Error: Snapshot creation failed.\"\n  exit 1\nfi\n\nexit 0\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech Environment Variables\nDESCRIPTION: Environment configuration file (speech.env) settings for openedai-speech service including model preload options and hardware settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nTTS_HOME=voices\nHF_HOME=voices\n#PRELOAD_MODEL=xtts\n#PRELOAD_MODEL=xtts_v2.0.2\n#PRELOAD_MODEL=parler-tts/parler_tts_mini_v0.1\n#EXTRA_ARGS=--log-level DEBUG --unload-timer 300\n#USE_ROCM=1\n```\n\n----------------------------------------\n\nTITLE: Using Status Event Emitters in Python\nDESCRIPTION: This snippet shows how to use the Status type of Event Emitters to provide real-time updates during function execution. The status appears above the message content and is useful for long-running operations.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/tab-shared/Common.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nawait __event_emitter__(\n            {\n                \"type\": \"status\", # We set the type here\n                \"data\": {\"description\": \"Message that shows up in the chat\", \"done\": False}, \n                # Note done is False here indicating we are still emitting statuses\n            }\n        )\n```\n\n----------------------------------------\n\nTITLE: Visualizing Ollama and Open WebUI in Compose Stack for Linux\nDESCRIPTION: Mermaid diagram showing both Ollama and Open WebUI running in the same Docker Compose stack on Linux. The components communicate through inter-container networking using the container name as the hostname.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/network-diagrams.mdx#2025-04-23_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nC4Context\nBoundary(b0, \"Hosting Machine - Linux\") {\n   Person(user, \"User\")\n   Boundary(b1, \"Container Network\") {\n      Boundary(b2, \"Compose Stack\") {\n         Component(openwebui, \"Open WebUI\", \"Listening on port 8080\")\n         Component(ollama, \"Ollama\", \"Listening on port 11434\")\n      }\n   }\n}\nRel(openwebui, ollama, \"Makes API calls via inter-container networking\", \"http://ollama:11434\")\nRel(user, openwebui, \"Makes requests via exposed port -p 3000:8080\", \"http://localhost:3000\")\nUpdateRelStyle(user, openwebui, $offsetX=\"-100\", $offsetY=\"-50\")\n```\n\n----------------------------------------\n\nTITLE: Cloning Open WebUI Kubernetes Manifests Repository\nDESCRIPTION: Commands to clone the Open WebUI Kubernetes manifests repository and navigate to the directory. This is the first step in deploying Open WebUI to a Kubernetes cluster.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Kustomize.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/open-webui/k8s-manifests.git\ncd k8s-manifests\n```\n\n----------------------------------------\n\nTITLE: Displaying Contributor Images in Markdown\nDESCRIPTION: This code snippet uses HTML within Markdown to display an image of project contributors. It links to the GitHub contributors page and uses the contrib.rocks service to generate the image.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/team.mdx#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<a href=\"https://github.com/open-webui/open-webui/graphs/contributors\">\n  <img\n    src=\"https://contrib.rocks/image?repo=open-webui/open-webui\"\n    alt=\"Contributors\"\n  />\n</a>\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI Docker Container with HuggingFace Mirror\nDESCRIPTION: This command demonstrates how to start the Open WebUI Docker container with a specified HuggingFace mirror to resolve SSL errors. It includes volume mounting for data persistence and network configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/faq.mdx#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 3000:8080 -e HF_ENDPOINT=https://hf-mirror.com/ --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\n```\n\n----------------------------------------\n\nTITLE: Rendering TopBanners Component in JSX\nDESCRIPTION: JSX component rendering for the TopBanners element in the mission statement page.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/mission.mdx#2025-04-23_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\n<TopBanners />\n```\n\n----------------------------------------\n\nTITLE: Verifying Tika Server Status\nDESCRIPTION: CURL command to verify the Apache Tika server status.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X GET http://localhost:9998/tika\n```\n\n----------------------------------------\n\nTITLE: Creating Required Directories for Nginx Configuration\nDESCRIPTION: Creates necessary directories for storing Nginx configuration and SSL certificate files.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p conf.d ssl\n```\n\n----------------------------------------\n\nTITLE: Importing Chat Completion Functions in Python\nDESCRIPTION: Demonstrates the new import statements for chat completion functions in Open WebUI 0.5, showing both the unified endpoint and separate router imports.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/migration/index.mdx#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Separate router imports\nfrom open_webui.routers.ollama import generate_chat_completion\nfrom open_webui.routers.openai import generate_chat_completion\n\n# Or use the unified endpoint\nfrom open_webui.main import chat_completion\n```\n\n----------------------------------------\n\nTITLE: Running Docling-Serve Docker Container\nDESCRIPTION: Command to run the Docling-Serve Docker container with UI enabled. This exposes the Docling service on port 5001.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/docling.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 5001:5001 -e DOCLING_SERVE_ENABLE_UI=true quay.io/docling-project/docling-serve\n```\n\n----------------------------------------\n\nTITLE: Updating Open WebUI installed with pip\nDESCRIPTION: Command to update an existing pip installation of Open WebUI to the latest version. This ensures you have the most recent features and bug fixes.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade open-webui\n```\n\n----------------------------------------\n\nTITLE: Generating Self-Signed SSL Certificates with OpenSSL\nDESCRIPTION: Uses OpenSSL to generate a self-signed SSL certificate and private key valid for 365 days. The certificate is created for the specified domain or IP address.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/SelfSigned.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n-keyout ssl/nginx.key \\\n-out ssl/nginx.crt \\\n-subj \"/CN=your_domain_or_IP\"\n```\n\n----------------------------------------\n\nTITLE: Running Open WebUI with uv on Windows\nDESCRIPTION: This PowerShell command uses uv to run Open WebUI on Windows, specifying Python version 3.11 and setting the DATA_DIR environment variable.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Uv.md#2025-04-23_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n$env:DATA_DIR=\"C:\\open-webui\\data\"; uvx --python 3.11 open-webui@latest serve\n```\n\n----------------------------------------\n\nTITLE: Deploying Kokoro-FastAPI GPU Version with Docker Run\nDESCRIPTION: This command runs the GPU version of Kokoro-FastAPI using Docker run. It enables GPU support and maps port 8880.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --gpus all -p 8880:8880 ghcr.io/remsky/kokoro-fastapi-gpu\n```\n\n----------------------------------------\n\nTITLE: Identifying Port Conflicts Using PowerShell (Windows)\nDESCRIPTION: This PowerShell command helps identify processes using specific ports on Windows systems. It shows the process using the specified port.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/advanced-topics/development.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nGet-Process -Id (Get-NetTCPConnection -LocalPort 5173).OwningProcess\n```\n\n----------------------------------------\n\nTITLE: URL Format for Open WebUI Search with Specific Model Selection\nDESCRIPTION: Enhanced URL format that includes model specification for the Open WebUI search engine integration, allowing users to target specific AI models for their queries.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/browser-search-engine.md#2025-04-23_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://<your-open-webui-url>/?models=<model_id>&q=%s\n```\n\n----------------------------------------\n\nTITLE: Starting Open WebUI after pip installation\nDESCRIPTION: Command to start the Open WebUI server after installing with pip. This launches the web interface that will be accessible through a browser at localhost:8080.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nopen-webui serve\n```\n\n----------------------------------------\n\nTITLE: Installing Docker Engine on Ubuntu\nDESCRIPTION: This bash command installs Docker Engine, Docker CLI, containerd, and the Docker Compose plugin on Ubuntu. It first updates the package list and then installs the specified Docker components.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/docker-install.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n```\n\n----------------------------------------\n\nTITLE: Running Docker Commands for Different Platforms\nDESCRIPTION: Docker run commands for deploying openedai-speech on different hardware platforms with volume mounts and port configurations.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --gpus=all -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d --privileged --init --name openedai-speech -p 8000:8000 -v voices:/app/voices -v config:/app/config ghcr.io/matatonic/openedai-speech-rocm\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech-min\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose Commands\nDESCRIPTION: Docker compose commands for different hardware configurations including NVIDIA GPU, AMD GPU, ARM64, and CPU-only setups.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/text-to-speech/openedai-speech-integration.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up -d\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose -f docker-compose.rocm.yml up -d\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose -f docker-compose.min.yml up -d\n```\n\n----------------------------------------\n\nTITLE: Opening SQLite Database in Alpine Container\nDESCRIPTION: Command to open the SQLite database file in the Alpine container for the alternative Docker method. This provides access to update the admin password directly.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/troubleshooting/password-reset.mdx#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nsqlite3 /path/to/data/webui.db\n```\n\n----------------------------------------\n\nTITLE: Setting WEBUI_URL in .env File for Open WebUI\nDESCRIPTION: Configuration example showing how to set the WEBUI_URL environment variable in the .env file as an alternative to Docker environment configuration.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/browser-search-engine.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nWEBUI_URL=https://<your-open-webui-url>\n```\n\n----------------------------------------\n\nTITLE: Inspecting Docker Volume\nDESCRIPTION: Command to inspect the Open WebUI Docker volume to view details about the volume, including its mountpoint location which is typically in /var/lib/docker/volumes/open-webui/_data.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/updating.mdx#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndocker volume inspect open-webui\n```\n\n----------------------------------------\n\nTITLE: Launching Docker Compose Stack\nDESCRIPTION: Command to start the Docker Compose stack that runs both Open WebUI and Jupyter services in detached mode.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/jupyter.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker-compose up -d\n```\n\n----------------------------------------\n\nTITLE: Langfuse Pipeline Installation URL\nDESCRIPTION: GitHub URL for installing the Langfuse Filter Pipeline in Open WebUI's pipeline configuration\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/integrations/langfuse.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py\n```\n\n----------------------------------------\n\nTITLE: Creating Directories for Nginx Files in Bash\nDESCRIPTION: Creates necessary directories for storing Nginx configuration and SSL certificate files.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/SelfSigned.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir -p conf.d ssl\n```\n\n----------------------------------------\n\nTITLE: Creating a Python Virtual Environment with venv\nDESCRIPTION: Creates an isolated Python environment named 'venv' in the current directory using the venv module.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-python/Venv.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython3 -m venv venv\n```\n\n----------------------------------------\n\nTITLE: Adding Open WebUI Helm Repository\nDESCRIPTION: Commands to add the Open WebUI Helm repository and update local repository cache.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/quick-start/tab-kubernetes/Helm.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhelm repo add open-webui https://open-webui.github.io/helm-charts\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Starting Docling Container for Verification\nDESCRIPTION: Command to start the Docling Docker container for verification purposes, mapping port 5001 to enable access to the UI for testing.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/docling.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 5001:5001 -e DOCLING_SERVE_ENABLE_UI=true quay.io/docling-project/docling-serve\n```\n\n----------------------------------------\n\nTITLE: Installing OpenSSL using Chocolatey (Windows)\nDESCRIPTION: Command to install OpenSSL using the Chocolatey package manager on Windows. This is required for generating self-signed certificates.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/Windows.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nchoco install openssl -y\n```\n\n----------------------------------------\n\nTITLE: Implementing Valves for Filter Configuration in Python\nDESCRIPTION: Example of defining configurable options (Valves) for a Filter Function. This allows users to adjust the Filter's behavior through settings.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/plugin/functions/filter.mdx#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Valves(BaseModel):\n    OPTION_NAME: str = \"Default Value\"\n```\n\n----------------------------------------\n\nTITLE: Executing Let's Encrypt Installation Script\nDESCRIPTION: Command to run the automated Let's Encrypt certificate installation script.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n./enable_letsencrypt.sh\n```\n\n----------------------------------------\n\nTITLE: Verifying OpenSSL Installation (Windows)\nDESCRIPTION: Command to verify the successful installation of OpenSSL by checking its version. This ensures OpenSSL is properly installed and accessible from the command line.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/Windows.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nopenssl version\n```\n\n----------------------------------------\n\nTITLE: Python Script for Apache Tika Verification\nDESCRIPTION: Python script to verify Apache Tika integration by sending a test file and checking the response.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/features/document-extraction/apachetika.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ndef verify_tika(file_path, tika_url):\n    try:\n        # Send the file to Apache Tika and verify the output\n        response = requests.put(tika_url, files={'file': open(file_path, 'rb')})\n\n        if response.status_code == 200:\n            print(\"Apache Tika successfully analyzed the file.\")\n            print(\"Response from Apache Tika:\")\n            print(response.text)\n        else:\n            print(\"Error analyzing the file:\")\n            print(f\"Status code: {response.status_code}\")\n            print(f\"Response from Apache Tika: {response.text}\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nif __name__ == \"__main__\":\n    file_path = \"test.txt\"  # Replace with the path to your file\n    tika_url = \"http://localhost:9998/tika\"\n\n    verify_tika(file_path, tika_url)\n```\n\n----------------------------------------\n\nTITLE: Rendering TopBanners Component in Markdown\nDESCRIPTION: This code snippet renders the imported TopBanners component within the Markdown document. It's used to display the banner content on the page.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/getting-started/index.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<TopBanners />\n```\n\n----------------------------------------\n\nTITLE: Main Documentation Links in Markdown\nDESCRIPTION: Markdown content showing documentation structure and key resources including installation guides, plugin docs, API reference, and contribution guidelines\nSOURCE: https://github.com/open-webui/docs/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# 👋 Open WebUI Documentation\n\nWelcome to the official documentation for **Open WebUI** — a self-hosted, privacy-focused, and extensible AI interface for LLMs like Ollama and OpenAI-compatible APIs.\n\nThis site is built with [Docusaurus](https://docusaurus.io/) and includes:\n\n- 🔧 Installation & setup guides (Docker, local, manual)\n- 🧩 Plugin & extension documentation \n- 📚 API reference & pipeline usage\n- 🗂 File uploads & RAG integration\n- 🤖 Developer contribution guide\n\n## 📝 Contributing\n\nContributions are welcome! Please read the [contributing guide](docs/tutorials/tips/contributing-tutorial.md) for details.\n\n## 🌐 Live Docs\n\n👉 Visit the docs: [docs.openwebui.com](https://docs.openwebui.com/)\n```\n\n----------------------------------------\n\nTITLE: Installing uv on macOS/Linux for Open WebUI\nDESCRIPTION: Command to install the uv runtime manager on macOS or Linux systems. This tool simplifies Python environment management for Open WebUI installation.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/intro.mdx#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Setting Script Permissions\nDESCRIPTION: Makes the Let's Encrypt installation script executable.\nSOURCE: https://github.com/open-webui/docs/blob/main/docs/tutorials/tab-nginx/LetsEncrypt.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nchmod +x enable_letsencrypt.sh\n```"
  }
]