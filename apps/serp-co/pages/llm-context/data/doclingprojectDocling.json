[
  {
    "owner": "docling-project",
    "repo": "docling",
    "content": "TITLE: Installing Docling with pip\nDESCRIPTION: Simple pip installation command for the Docling package, which works across macOS, Linux, and Windows on both x86_64 and arm64 architectures.\nSOURCE: https://github.com/docling-project/docling/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install docling\n```\n\n----------------------------------------\n\nTITLE: Converting a Single Document with Docling in Python\nDESCRIPTION: This snippet demonstrates how to convert a single PDF document using Docling's DocumentConverter class. It shows how to initialize the converter, process a document from a URL, and export the result to markdown.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"  # PDF path or URL\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())  # output: \"### Docling Technical Report[...]\"\n```\n\n----------------------------------------\n\nTITLE: Performing RAG with Weaviate on 'generative adversarial net' Query in Python\nDESCRIPTION: Demonstrates another RAG example using Weaviate's generate module with a different query about 'generative adversarial net'. The code retrieves context from the collection and formats the results using the Rich library.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a prompt where context from the Weaviate collection will be injected\nprompt = \"Explain how {text} works, using only the retrieved context.\"\nquery = \"a generative adversarial net\"\n\nresponse = collection.generate.near_text(\n    query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"]\n)\n\n# Prettify the output using Rich\nconsole = Console()\n\nconsole.print(\n    Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\")\n)\nconsole.print(\n    Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\")\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Pipeline for Question Answering\nDESCRIPTION: This code sets up the RAG pipeline using Haystack components. It includes a text embedder, retriever, prompt builder, HuggingFace API generator, and answer builder. The pipeline is configured to process a question and generate an answer based on retrieved documents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_haystack.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom haystack.components.builders import AnswerBuilder\nfrom haystack.components.builders.prompt_builder import PromptBuilder\nfrom haystack.components.generators import HuggingFaceAPIGenerator\nfrom haystack.utils import Secret\n\nprompt_template = \"\"\"\n    Given these documents, answer the question.\n    Documents:\n    {% for doc in documents %}\n        {{ doc.content }}\n    {% endfor %}\n    Question: {{query}}\n    Answer:\n    \"\"\"\n\nrag_pipe = Pipeline()\nrag_pipe.add_component(\n    \"embedder\",\n    SentenceTransformersTextEmbedder(model=EMBED_MODEL_ID),\n)\nrag_pipe.add_component(\n    \"retriever\",\n    MilvusEmbeddingRetriever(document_store=document_store, top_k=TOP_K),\n)\nrag_pipe.add_component(\"prompt_builder\", PromptBuilder(template=prompt_template))\nrag_pipe.add_component(\n    \"llm\",\n    HuggingFaceAPIGenerator(\n        api_type=\"serverless_inference_api\",\n        api_params={\"model\": GENERATION_MODEL_ID},\n        token=Secret.from_token(HF_TOKEN) if HF_TOKEN else None,\n    ),\n)\nrag_pipe.add_component(\"answer_builder\", AnswerBuilder())\nrag_pipe.connect(\"embedder.embedding\", \"retriever\")\nrag_pipe.connect(\"retriever\", \"prompt_builder.documents\")\nrag_pipe.connect(\"prompt_builder\", \"llm\")\nrag_pipe.connect(\"llm.replies\", \"answer_builder.replies\")\nrag_pipe.connect(\"llm.meta\", \"answer_builder.meta\")\nrag_pipe.connect(\"retriever\", \"answer_builder.documents\")\nrag_res = rag_pipe.run(\n    {\n        \"embedder\": {\"text\": QUESTION},\n        \"prompt_builder\": {\"query\": QUESTION},\n        \"answer_builder\": {\"query\": QUESTION},\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG with Docling Native Format\nDESCRIPTION: This snippet shows how to use Docling's native JSON format in the RAG pipeline. It uses DoclingReader with JSON export and DoclingNodeParser for parsing. This approach provides more detailed document-level grounding information in the results.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.node_parser.docling import DoclingNodeParser\n\nreader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\nnode_parser = DoclingNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n```\n\n----------------------------------------\n\nTITLE: Printing RAG Results with Document-Level Grounding\nDESCRIPTION: This snippet prints the results of the RAG pipeline, including the question, answer, and sources. It handles different export types (DOC_CHUNKS and MARKDOWN) and displays document-level grounding information such as file name, section, page number, and bounding box for DOC_CHUNKS.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_haystack.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.chunking import DocChunk\n\nprint(f\"Question:\\n{QUESTION}\\n\")\nprint(f\"Answer:\\n{rag_res['answer_builder']['answers'][0].data.strip()}\\n\")\nprint(\"Sources:\")\nsources = rag_res[\"answer_builder\"][\"answers\"][0].documents\nfor source in sources:\n    if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n        doc_chunk = DocChunk.model_validate(source.meta[\"dl_meta\"])\n        print(f\"- text: {doc_chunk.text!r}\")\n        if doc_chunk.meta.origin:\n            print(f\"  file: {doc_chunk.meta.origin.filename}\")\n        if doc_chunk.meta.headings:\n            print(f\"  section: {' / '.join(doc_chunk.meta.headings)}\")\n        bbox = doc_chunk.meta.doc_items[0].prov[0].bbox\n        print(\n            f\"  page: {doc_chunk.meta.doc_items[0].prov[0].page_no}, \"\n            f\"bounding box: [{int(bbox.l)}, {int(bbox.t)}, {int(bbox.r)}, {int(bbox.b)}]\"\n        )\n    elif EXPORT_TYPE == ExportType.MARKDOWN:\n        print(repr(source.content))\n    else:\n        raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\n```\n\n----------------------------------------\n\nTITLE: Loading and Chunking Documents with DoclingLoader\nDESCRIPTION: Initializes the DoclingLoader to load and process documents. It also handles document chunking based on the specified export type, either using DoclingLoader's built-in chunking or MarkdownHeaderTextSplitter for markdown files.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_langchain.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_docling import DoclingLoader\n\nfrom docling.chunking import HybridChunker\n\nloader = DoclingLoader(\n    file_path=FILE_PATH,\n    export_type=EXPORT_TYPE,\n    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n)\n\ndocs = loader.load()\n\nif EXPORT_TYPE == ExportType.DOC_CHUNKS:\n    splits = docs\nelif EXPORT_TYPE == ExportType.MARKDOWN:\n    from langchain_text_splitters import MarkdownHeaderTextSplitter\n\n    splitter = MarkdownHeaderTextSplitter(\n        headers_to_split_on=[\n            (\"#\", \"Header_1\"),\n            (\"##\", \"Header_2\"),\n            (\"###\", \"Header_3\"),\n        ],\n    )\n    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\nelse:\n    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\n\nfor d in splits[:3]:\n    print(f\"- {d.page_content=}\")\nprint(\"...\")\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG with Azure AI Search and OpenAI in Python\nDESCRIPTION: This snippet demonstrates a complete RAG pipeline using Azure services. It includes functions for generating chat responses, embedding text, performing vector searches, and combining retrieved context with user queries to generate grounded responses.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\n\nfrom azure.search.documents.models import VectorizableTextQuery\n\n\ndef generate_chat_response(prompt: str, system_message: Optional[str] = None):\n    \"\"\"\n    Generates a single-turn chat response using Azure OpenAI Chat.\n    If you need multi-turn conversation or follow-up queries, you'll have to\n    maintain the messages list externally.\n    \"\"\"\n    messages = []\n    if system_message:\n        messages.append({\"role\": \"system\", \"content\": system_message})\n    messages.append({\"role\": \"user\", \"content\": prompt})\n\n    completion = openai_client.chat.completions.create(\n        model=AZURE_OPENAI_CHAT_MODEL, messages=messages, temperature=0.7\n    )\n    return completion.choices[0].message.content\n\n\nuser_query = \"What are the main advantages of using the Graph RAG approach for query-focused summarization compared to traditional RAG methods?\"\nuser_embed = embed_text(user_query)\n\nvector_query = VectorizableTextQuery(\n    text=user_query,  # passing in text for a hybrid search\n    k_nearest_neighbors=5,\n    fields=\"content_vector\",\n)\n\nsearch_results = search_client.search(\n    search_text=user_query, vector_queries=[vector_query], select=[\"content\"], top=10\n)\n\nretrieved_chunks = []\nfor result in search_results:\n    snippet = result[\"content\"]\n    retrieved_chunks.append(snippet)\n\ncontext_str = \"\\n---\\n\".join(retrieved_chunks)\nrag_prompt = f\"\"\"\nYou are an AI assistant helping answering questions about Microsoft GraphRAG.\nUse ONLY the text below to answer the user's question.\nIf the answer isn't in the text, say you don't know.\n\nContext:\n{context_str}\n\nQuestion: {user_query}\nAnswer:\n\"\"\"\n\nfinal_answer = generate_chat_response(rag_prompt)\n\nconsole.print(Panel(rag_prompt, title=\"RAG Prompt\", style=\"bold red\"))\nconsole.print(Panel(final_answer, title=\"RAG Response\", style=\"bold green\"))\n```\n\n----------------------------------------\n\nTITLE: Hierarchical Chunking of Parsed Document\nDESCRIPTION: Uses Docling's HierarchicalChunker to split the parsed document into smaller chunks while preserving structure.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.chunking import HierarchicalChunker\n\nchunker = HierarchicalChunker()\ndoc_chunks = list(chunker.chunk(result.document))\n\nall_chunks = []\nfor idx, c in enumerate(doc_chunks):\n    chunk_text = c.text\n    all_chunks.append((f\"chunk_{idx}\", chunk_text))\n\nconsole.print(f\"Total chunks from PDF: {len(all_chunks)}\")\n```\n\n----------------------------------------\n\nTITLE: Iterating and Serializing Chunks in Python\nDESCRIPTION: This code iterates through the chunks created by the HybridChunker and demonstrates how to serialize each chunk for embedding. It prints both the original chunk text and the serialized (context-enriched) version.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor i, chunk in enumerate(chunk_iter):\n    print(f\"=== {i} ===\")\n    print(f\"chunk.text:\\n{f'{chunk.text[:300]}…'!r}\")\n\n    enriched_text = chunker.serialize(chunk=chunk)\n    print(f\"chunker.serialize(chunk):\\n{f'{enriched_text[:300]}…'!r}\")\n\n    print()\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Configuration for RAG Pipeline\nDESCRIPTION: Configures the environment variables, file paths, and model IDs for the RAG pipeline. It also sets up parameters for document export type, embedding model, generative model, and vector store URI.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_langchain.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom dotenv import load_dotenv\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_docling.loader import ExportType\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\n\n# https://github.com/huggingface/transformers/issues/5486:\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nHF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\nFILE_PATH = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\nEMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nGEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\nEXPORT_TYPE = ExportType.DOC_CHUNKS\nQUESTION = \"Which are the main AI models in Docling?\"\nPROMPT = PromptTemplate.from_template(\n    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n)\nTOP_K = 3\nMILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")\n```\n\n----------------------------------------\n\nTITLE: Checking GPU Availability\nDESCRIPTION: Verifies if CUDA GPU or Apple MPS (Metal Performance Shaders) is available for acceleration.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\n# Check if GPU or MPS is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\")\nelif torch.backends.mps.is_available():\n    device = torch.device(\"mps\")\n    print(\"MPS GPU is enabled.\")\nelse:\n    raise OSError(\n        \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Retrieving Relevant Documents using RAG\nDESCRIPTION: This code demonstrates how to use the retriever to find relevant documents based on a query. It retrieves the top 3 most similar documents to the given query about fitness devices.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nretriever = index.as_retriever(similarity_top_k=3)\nresults = retriever.retrieve(\"What patents are related to fitness devices?\")\n\nfor item in results:\n    print(item)\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG Pipeline with LangChain and Hugging Face\nDESCRIPTION: Creates the RAG pipeline using LangChain components. It sets up the retriever, language model, and chains for document retrieval and question answering. The pipeline uses Hugging Face's Inference API for the language model.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_langchain.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_huggingface import HuggingFaceEndpoint\n\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\nllm = HuggingFaceEndpoint(\n    repo_id=GEN_MODEL_ID,\n    huggingfacehub_api_token=HF_TOKEN,\n)\n\n\ndef clip_text(text, threshold=100):\n    return f\"{text[:threshold]}...\" if len(text) > threshold else text\n\nquestion_answer_chain = create_stuff_documents_chain(llm, PROMPT)\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\nresp_dict = rag_chain.invoke({\"input\": QUESTION})\n\nclipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\nprint(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\nfor i, doc in enumerate(resp_dict[\"context\"]):\n    print()\n    print(f\"Source {i + 1}:\")\n    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n    for key in doc.metadata:\n        if key != \"pk\":\n            val = doc.metadata.get(key)\n            clipped_val = clip_text(val) if isinstance(val, str) else val\n            print(f\"  {key}: {clipped_val}\")\n```\n\n----------------------------------------\n\nTITLE: Converting PDFs with Docling\nDESCRIPTION: Uses Docling's DocumentConverter to parse PDF documents into Docling document objects.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\n\n# Instantiate the doc converter\ndoc_converter = DocumentConverter()\n\n# Directly pass list of files or streams to `convert_all`\nconv_results_iter = doc_converter.convert_all(source_urls)  # previously `convert`\n\n# Iterate over the generator to get a list of Docling documents\ndocs = [result.document for result in conv_results_iter]\n```\n\n----------------------------------------\n\nTITLE: RAG-based Question-Answering with Indexed PMC Article\nDESCRIPTION: This code demonstrates RAG-based question-answering using the indexed PMC article as supporting context. It applies a metadata filter to ensure only the relevant PMC article is used for retrieval and generation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n\nfilters = MetadataFilters(\n    filters=[\n        ExactMatchFilter(key=\"filename\", value=\"nihpp-2024.12.26.630351v1.nxml\"),\n    ]\n)\n\nquery_engine = index.as_query_engine(llm=GEN_MODEL, filter=filters, similarity_top_k=3)\nresult = query_engine.query(query)\n\nconsole.print(\n    Panel(\n        result.response.strip(),\n        title=\"Generated Content with RAG\",\n        border_style=\"bold green\",\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies with Pip\nDESCRIPTION: Installs necessary Python packages including docling, weaviate-client, rich and torch. Configures logging to suppress Weaviate client logs.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%%capture\n%pip install docling~=\"2.7.0\"\n%pip install -U weaviate-client~=\"4.9.4\"\n%pip install rich\n%pip install torch\n\nimport logging\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Suppress Weaviate client logs\nlogging.getLogger(\"weaviate\").setLevel(logging.ERROR)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Classes for Qdrant and Docling Integration\nDESCRIPTION: Imports the necessary classes from Qdrant client for vector database operations and from Docling for document chunking and conversion. These imports set up the foundation for the hybrid search implementation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom qdrant_client import QdrantClient\n\nfrom docling.chunking import HybridChunker\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import DocumentConverter\n```\n\n----------------------------------------\n\nTITLE: Parsing PDF with Docling\nDESCRIPTION: Uses Docling's DocumentConverter to parse a PDF file (Microsoft GraphRAG Research Paper) and preview the parsed Markdown content.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom rich.console import Console\nfrom rich.panel import Panel\n\nfrom docling.document_converter import DocumentConverter\n\nconsole = Console()\n\n# This URL points to the Microsoft GraphRAG Research Paper (arXiv: 2404.16130), ~15 pages\nsource_url = \"https://arxiv.org/pdf/2404.16130\"\n\nconsole.print(\n    \"[bold yellow]Parsing a ~15-page PDF. The process should be relatively quick, even on CPU...[/bold yellow]\"\n)\nconverter = DocumentConverter()\nresult = converter.convert(source_url)\n\n# Optional: preview the parsed Markdown\nmd_preview = result.document.export_to_markdown()\nconsole.print(Panel(md_preview[:500] + \"...\", title=\"Docling Markdown Preview\"))\n```\n\n----------------------------------------\n\nTITLE: Defining Source Documents\nDESCRIPTION: Sets up lists of arXiv paper URLs and their corresponding titles for processing.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Influential machine learning papers\nsource_urls = [\n    \"https://arxiv.org/pdf/1706.03762\",\n    \"https://arxiv.org/pdf/1810.04805\",\n    \"https://arxiv.org/pdf/1406.2661\",\n    \"https://arxiv.org/pdf/1409.0473\",\n    \"https://arxiv.org/pdf/1412.6980\",\n    \"https://arxiv.org/pdf/1312.6114\",\n    \"https://arxiv.org/pdf/1312.5602\",\n    \"https://arxiv.org/pdf/1512.03385\",\n    \"https://arxiv.org/pdf/1409.3215\",\n    \"https://arxiv.org/pdf/1301.3781\",\n]\n\n# And their corresponding titles\nsource_titles = [\n    \"Attention Is All You Need\",\n    \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\n    \"Generative Adversarial Nets\",\n    \"Neural Machine Translation by Jointly Learning to Align and Translate\",\n    \"Adam: A Method for Stochastic Optimization\",\n    \"Auto-Encoding Variational Bayes\",\n    \"Playing Atari with Deep Reinforcement Learning\",\n    \"Deep Residual Learning for Image Recognition\",\n    \"Sequence to Sequence Learning with Neural Networks\",\n    \"A Neural Probabilistic Language Model\",\n]\n```\n\n----------------------------------------\n\nTITLE: Installing Docling with pip\nDESCRIPTION: Basic installation command for Docling using pip package manager. Works on macOS, Linux, and Windows with support for both x86_64 and arm64 architectures.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install docling\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for RAG with LangChain and Docling\nDESCRIPTION: Installs the required Python packages for implementing RAG with LangChain and Docling integration. This includes langchain-docling, langchain-core, langchain-huggingface, langchain_milvus, and other dependencies.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_langchain.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q --progress-bar off --no-warn-conflicts langchain-docling langchain-core langchain-huggingface langchain_milvus langchain python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Configuring Docling for offline operation with custom model artifacts location\nDESCRIPTION: Code example showing how to configure Docling to run offline by specifying a custom location for model artifacts. This allows Docling to run in air-gapped environments without requiring internet access.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/faq/index.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npipeline_options = PdfPipelineOptions(artifacts_path=\"your location\")\nconverter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Docling on macOS Intel\nDESCRIPTION: Commands for installing Docling on Intel-based Macs with compatible PyTorch versions using different package managers (uv, pip, and Poetry).\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n# For uv users\nuv add torch==2.2.2 torchvision==0.17.2 docling\n\n# For pip users\npip install \"docling[mac_intel]\"\n\n# For Poetry users\npoetry add docling\n```\n\n----------------------------------------\n\nTITLE: Performing a Hybrid Search Query with Qdrant\nDESCRIPTION: Executes a semantic search query against the Qdrant collection using both dense and sparse vector representations. The query \"Can I split documents?\" is processed through both embedding models and returns the top 10 most relevant results.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npoints = client.query(\n    collection_name=COLLECTION_NAME,\n    query_text=\"Can I split documents?\",\n    limit=10,\n)\n```\n\n----------------------------------------\n\nTITLE: Performing RAG with Weaviate on 'bert' Query in Python\nDESCRIPTION: Shows how to use Weaviate's generate module to perform Retrieval Augmented Generation (RAG) on embedded data. The code creates a prompt about 'bert', retrieves relevant content from Weaviate, and uses Rich library to format the output.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom rich.console import Console\nfrom rich.panel import Panel\n\n# Create a prompt where context from the Weaviate collection will be injected\nprompt = \"Explain how {text} works, using only the retrieved context.\"\nquery = \"bert\"\n\nresponse = collection.generate.near_text(\n    query=query, limit=3, grouped_task=prompt, return_properties=[\"text\", \"title\"]\n)\n\n# Prettify the output using Rich\nconsole = Console()\n\nconsole.print(\n    Panel(f\"{prompt}\".replace(\"{text}\", query), title=\"Prompt\", border_style=\"bold red\")\n)\nconsole.print(\n    Panel(response.generated, title=\"Generated Content\", border_style=\"bold green\")\n)\n```\n\n----------------------------------------\n\nTITLE: Ingesting Documents into Milvus Vector Store\nDESCRIPTION: Sets up the embedding model and Milvus vector store. It then ingests the document splits into the vector store for efficient retrieval during the RAG process.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_langchain.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom langchain_huggingface.embeddings import HuggingFaceEmbeddings\nfrom langchain_milvus import Milvus\n\nembedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n\n\nmilvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\nvectorstore = Milvus.from_documents(\n    documents=splits,\n    embedding=embedding,\n    collection_name=\"docling_demo\",\n    connection_args={\"uri\": milvus_uri},\n    index_params={\"index_type\": \"FLAT\"},\n    drop_old=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Advanced Usage of HybridChunker with Custom Parameters in Python\nDESCRIPTION: This snippet shows how to use the HybridChunker with custom parameters. It demonstrates setting a specific tokenizer, maximum token limit, and other options. The code ensures that the chunker and embedding model use the same tokenizer.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import AutoTokenizer\n\nfrom docling.chunking import HybridChunker\n\nEMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nMAX_TOKENS = 64  # set to a small number for illustrative purposes\n\ntokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL_ID)\n\nchunker = HybridChunker(\n    tokenizer=tokenizer,  # instance or model name, defaults to \"sentence-transformers/all-MiniLM-L6-v2\"\n    max_tokens=MAX_TOKENS,  # optional, by default derived from `tokenizer`\n    merge_peers=True,  # optional, defaults to True\n)\nchunk_iter = chunker.chunk(dl_doc=doc)\nchunks = list(chunk_iter)\n```\n\n----------------------------------------\n\nTITLE: Converting and Chunking Documents with Docling\nDESCRIPTION: Downloads an article from the web using Docling's DocumentConverter, then processes it with the HybridChunker to create appropriately sized text chunks. For each chunk, both the text content and metadata are extracted for vector storage.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresult = doc_converter.convert(\n    \"https://www.sagacify.com/news/a-guide-to-chunking-strategies-for-retrieval-augmented-generation-rag\"\n)\ndocuments, metadatas = [], []\nfor chunk in HybridChunker().chunk(result.document):\n    documents.append(chunk.text)\n    metadatas.append(chunk.meta.export_json_dict())\n```\n\n----------------------------------------\n\nTITLE: Hierarchical Chunking of Documents\nDESCRIPTION: Performs hierarchical chunking on documents to preserve structure and relationships using Docling's HierarchicalChunker.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom docling_core.transforms.chunker import HierarchicalChunker\n\n# Initialize lists for text, and titles\ntexts, titles = [], []\n\nchunker = HierarchicalChunker()\n\n# Process each document in the list\nfor doc, title in zip(docs, source_titles):  # Pair each document with its title\n    chunks = list(\n        chunker.chunk(doc)\n    )  # Perform hierarchical chunking and get text from chunks\n    for chunk in chunks:\n        texts.append(chunk.text)\n        titles.append(title)\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG with SimpleDirectoryReader\nDESCRIPTION: This snippet demonstrates how to use SimpleDirectoryReader with the Docling-based RAG pipeline. It processes documents from a directory, using the previously defined reader and node parser, and then performs querying on the processed documents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core import SimpleDirectoryReader\n\ndir_reader = SimpleDirectoryReader(\n    input_dir=tmp_dir_path,\n    file_extractor={\".pdf\": reader},\n)\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=dir_reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n```\n\n----------------------------------------\n\nTITLE: Implementing RAG with Markdown Export\nDESCRIPTION: This code demonstrates implementing a RAG pipeline using Docling's Markdown export. It uses DoclingReader for document loading, MarkdownNodeParser for parsing, and MilvusVectorStore for storage. The pipeline is then used to query the processed documents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core import StorageContext, VectorStoreIndex\nfrom llama_index.core.node_parser import MarkdownNodeParser\nfrom llama_index.readers.docling import DoclingReader\nfrom llama_index.vector_stores.milvus import MilvusVectorStore\n\nreader = DoclingReader()\nnode_parser = MarkdownNodeParser()\n\nvector_store = MilvusVectorStore(\n    uri=str(Path(mkdtemp()) / \"docling.db\"),  # or set as needed\n    dim=embed_dim,\n    overwrite=True,\n)\nindex = VectorStoreIndex.from_documents(\n    documents=reader.load_data(SOURCE),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\nresult = index.as_query_engine(llm=GEN_MODEL).query(QUERY)\nprint(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\ndisplay([(n.text, n.metadata) for n in result.source_nodes])\n```\n\n----------------------------------------\n\nTITLE: Implementing Addition Function in JavaScript\nDESCRIPTION: A simple JavaScript program that defines an addition function and immediately demonstrates its usage by adding two numbers. The function takes two parameters and returns their sum, with an example that adds 3 and 5.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/code_and_formula.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nfunction add(a, b) { return a + b; } console.log(add(3, 5));\n```\n\n----------------------------------------\n\nTITLE: Validating PMC Articles and USPTO Patents using Docling Backends\nDESCRIPTION: This snippet demonstrates how to use Docling's custom backend converters to validate PMC articles and USPTO patents. It checks if input documents are supported by the respective backends and counts valid patents in a directory.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom tqdm.notebook import tqdm\n\nfrom docling.backend.xml.jats_backend import JatsDocumentBackend\nfrom docling.backend.xml.uspto_backend import PatentUsptoDocumentBackend\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.document import InputDocument\n\n# check PMC\nin_doc = InputDocument(\n    path_or_stream=TEMP_DIR / \"nihpp-2024.12.26.630351v1.nxml\",\n    format=InputFormat.XML_JATS,\n    backend=JatsDocumentBackend,\n)\nbackend = JatsDocumentBackend(\n    in_doc=in_doc, path_or_stream=TEMP_DIR / \"nihpp-2024.12.26.630351v1.nxml\"\n)\nprint(f\"Document {in_doc.file.name} is a valid PMC article? {backend.is_valid()}\")\n\n# check USPTO\nin_doc = InputDocument(\n    path_or_stream=TEMP_DIR / \"ipg241217-1.xml\",\n    format=InputFormat.XML_USPTO,\n    backend=PatentUsptoDocumentBackend,\n)\nbackend = PatentUsptoDocumentBackend(\n    in_doc=in_doc, path_or_stream=TEMP_DIR / \"ipg241217-1.xml\"\n)\nprint(f\"Document {in_doc.file.name} is a valid patent? {backend.is_valid()}\")\n\npatent_valid = 0\npbar = tqdm(TEMP_DIR.glob(\"*.xml\"), total=doc_num)\nfor in_path in pbar:\n    in_doc = InputDocument(\n        path_or_stream=in_path,\n        format=InputFormat.XML_USPTO,\n        backend=PatentUsptoDocumentBackend,\n    )\n    backend = PatentUsptoDocumentBackend(in_doc=in_doc, path_or_stream=in_path)\n    patent_valid += int(backend.is_valid())\n\nprint(f\"Found {patent_valid} patents out of {doc_num} XML files.\")\n```\n\n----------------------------------------\n\nTITLE: Setting up Milvus Vector Store and Ingesting Patent Documents\nDESCRIPTION: This code sets up a local Milvus vector store and ingests the processed patent documents. It uses the DoclingNodeParser for chunking and the specified embedding model for vector representation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core import StorageContext, VectorStoreIndex\nfrom llama_index.vector_stores.milvus import MilvusVectorStore\n\nvector_store = MilvusVectorStore(\n    uri=MILVUS_URI,\n    dim=embed_dim,\n    overwrite=True,\n)\n\nindex = VectorStoreIndex.from_documents(\n    documents=dir_reader.load_data(show_progress=True),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n    show_progress=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Qdrant Client with Dense and Sparse Models\nDESCRIPTION: Sets up a Qdrant client with in-memory storage, configures the allowed document formats to HTML, and assigns both dense and sparse embedding models. The dense model uses sentence-transformers while the sparse model uses BM25.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nCOLLECTION_NAME = \"docling\"\n\ndoc_converter = DocumentConverter(allowed_formats=[InputFormat.HTML])\nclient = QdrantClient(location=\":memory:\")\n# The :memory: mode is a Python imitation of Qdrant's APIs for prototyping and CI.\n# For production deployments, use the Docker image: docker run -p 6333:6333 qdrant/qdrant\n# client = QdrantClient(location=\"http://localhost:6333\")\n\nclient.set_model(\"sentence-transformers/all-MiniLM-L6-v2\")\nclient.set_sparse_model(\"Qdrant/bm25\")\n```\n\n----------------------------------------\n\nTITLE: Granting RCAC Administration Authorization Using CHGFCNUSG Command in IBM i\nDESCRIPTION: This command grants authorization to user HBEDOYA to administer and manage Row and Column Access Control (RCAC) rules by changing the function usage for the QIBM_DB_SECADM security administration function.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: CL\nCODE:\n```\nCHGFCNUSG FCNID(QIBM_DB_SECADM) USER(HBEDOYA) USAGE(*ALLOWED)\n```\n\n----------------------------------------\n\nTITLE: OTSL Syntax Rules for Table Structure Representation\nDESCRIPTION: The syntax rules for OTSL define how cells can relate to their neighbors, ensuring valid table structures. These rules constrain left-looking and up-looking cells to have valid predecessors, enabling error detection during sequence generation.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n- 1. Left-looking cell rule : The left neighbour of an \"L\" cell must be either another \"L\" cell or a \"C\" cell.\n- 2. Up-looking cell rule : The upper neighbour of a \"U\" cell must be either another \"U\" cell or a \"C\" cell.\n```\n\n----------------------------------------\n\nTITLE: Installing Tesseract OCR on macOS\nDESCRIPTION: Console commands for installing Tesseract OCR engine on macOS using Homebrew and setting the required TESSDATA_PREFIX environment variable.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nbrew install tesseract leptonica pkg-config\nTESSDATA_PREFIX=/opt/homebrew/share/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n```\n\n----------------------------------------\n\nTITLE: Chunking a Docling Document with HybridChunker\nDESCRIPTION: This snippet demonstrates how to chunk a Docling document using the HybridChunker class. It shows the process of converting a document and then applying the chunking operation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\nfrom docling.chunking import HybridChunker\n\nconv_res = DocumentConverter().convert(\"https://arxiv.org/pdf/2206.01062\")\ndoc = conv_res.document\n\nchunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")  # set tokenizer as needed\nchunk_iter = chunker.chunk(doc)\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Structure Example in ASCII Format in Markdown\nDESCRIPTION: An ASCII representation of a table structure showing a grid with numeric cell values. This example demonstrates how TableFormer represents and predicts table structures, including header rows and multi-column/row arrangements.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 0   | 1 2 1   | 1 2 1   |   1 2 1 |   1 2 1 |\n|-----|---------|---------|---------|---------|\n| 3   | 4 3     | 5       |       6 |       7 |\n| 8 2 | 9       | 10      |      11 |      12 |\n| 13  |         | 14      |      15 |      16 |\n| 17  | 18      |         |      19 |      20 |\n```\n\n----------------------------------------\n\nTITLE: Resolving numpy dependency conflicts for Python 3.13 in pyproject.toml\nDESCRIPTION: A configuration example for handling numpy dependency conflicts with Python 3.13 in pyproject.toml. It uses conditional dependency selectors to specify different numpy versions based on the Python version being used.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/faq/index.md#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nnumpy = [\n    { version = \"^2.1.0\", markers = 'python_version >= \"3.13\"' },\n    { version = \"^1.24.4\", markers = 'python_version < \"3.13\"' },\n]\n```\n\n----------------------------------------\n\nTITLE: Installing Tesseract OCR on Debian-based Systems\nDESCRIPTION: Console commands for installing Tesseract OCR engine on Debian-based Linux distributions and setting the required TESSDATA_PREFIX environment variable.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\napt-get install tesseract-ocr tesseract-ocr-eng libtesseract-dev libleptonica-dev pkg-config\nTESSDATA_PREFIX=$(dpkg -L tesseract-ocr-eng | grep tessdata$)\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n```\n\n----------------------------------------\n\nTITLE: Installing CPU-only Docling on Linux\nDESCRIPTION: Command for installing Docling with CPU-only PyTorch support on Linux systems by using an alternative PyTorch distribution index.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install docling --extra-index-url https://download.pytorch.org/whl/cpu\n```\n\n----------------------------------------\n\nTITLE: Adding Documents to Qdrant Collection with Vector Embeddings\nDESCRIPTION: Uploads the chunked documents to Qdrant collection with their associated metadata. The client automatically generates vector embeddings using the previously configured dense and sparse models with a batch size of 64.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n_ = client.add(\n    collection_name=COLLECTION_NAME,\n    documents=documents,\n    metadata=metadatas,\n    batch_size=64,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Indexing Pipeline for Document Processing\nDESCRIPTION: This snippet sets up the indexing pipeline using Haystack components. It includes the DoclingConverter, SentenceTransformersDocumentEmbedder, and DocumentWriter. The pipeline is configured based on the export type (DOC_CHUNKS or MARKDOWN).\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_haystack.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling_haystack.converter import DoclingConverter\nfrom haystack import Pipeline\nfrom haystack.components.embedders import (\n    SentenceTransformersDocumentEmbedder,\n    SentenceTransformersTextEmbedder,\n)\nfrom haystack.components.preprocessors import DocumentSplitter\nfrom haystack.components.writers import DocumentWriter\nfrom milvus_haystack import MilvusDocumentStore, MilvusEmbeddingRetriever\n\nfrom docling.chunking import HybridChunker\n\ndocument_store = MilvusDocumentStore(\n    connection_args={\"uri\": MILVUS_URI},\n    drop_old=True,\n    text_field=\"txt\",  # set for preventing conflict with same-name metadata field\n)\n\nidx_pipe = Pipeline()\nidx_pipe.add_component(\n    \"converter\",\n    DoclingConverter(\n        export_type=EXPORT_TYPE,\n        chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n    ),\n)\nidx_pipe.add_component(\n    \"embedder\",\n    SentenceTransformersDocumentEmbedder(model=EMBED_MODEL_ID),\n)\nidx_pipe.add_component(\"writer\", DocumentWriter(document_store=document_store))\nif EXPORT_TYPE == ExportType.DOC_CHUNKS:\n    idx_pipe.connect(\"converter\", \"embedder\")\nelif EXPORT_TYPE == ExportType.MARKDOWN:\n    idx_pipe.add_component(\n        \"splitter\",\n        DocumentSplitter(split_by=\"sentence\", split_length=1),\n    )\n    idx_pipe.connect(\"converter.documents\", \"splitter.documents\")\n    idx_pipe.connect(\"splitter.documents\", \"embedder.documents\")\nelse:\n    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\nidx_pipe.connect(\"embedder\", \"writer\")\nidx_pipe.run({\"converter\": {\"paths\": PATHS}})\n```\n\n----------------------------------------\n\nTITLE: Comparing OTSL and HTML Performance for Table Structure Recognition\nDESCRIPTION: A table comparing the performance of OTSL and HTML representations for table structure recognition. It shows TED scores for simple and complex tables, mAP scores, and inference times for different encoder and decoder layer configurations.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1-pg9.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# enc-layers # dec-layers Language TEDs            mAP Inference\n                                simple complex all (0.75) time (secs)\n6           6           OTSL HTML 0.965 0.969 0.934 0.927 0.955 0.955 0.88 0.857 2.73 5.39\n4           4           OTSL HTML 0.938 0.952 0.904 0.909 0.927 0.938 0.853 0.843 1.97 3.77\n2           4           OTSL HTML 0.923 0.945 0.897 0.901 0.915 0.931 0.859 0.834 1.91 3.81\n4           2           OTSL HTML 0.952 0.944 0.92 0.903 0.942 0.931 0.857 0.824 1.22 2\n```\n\n----------------------------------------\n\nTITLE: Using Prefetched Models with Docling CLI\nDESCRIPTION: This snippet demonstrates how to use prefetched models with the Docling CLI by specifying the artifacts path as a command-line argument.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ndocling --artifacts-path=\"/local/path/to/models\" FILE\n```\n\n----------------------------------------\n\nTITLE: Installing Tesseract OCR on RHEL Systems\nDESCRIPTION: Console commands for installing Tesseract OCR engine on RHEL-based Linux distributions and setting the required TESSDATA_PREFIX environment variable.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ndnf install tesseract tesseract-devel tesseract-langpack-eng leptonica-devel\nTESSDATA_PREFIX=/usr/share/tesseract/tessdata/\necho \"Set TESSDATA_PREFIX=${TESSDATA_PREFIX}\"\n```\n\n----------------------------------------\n\nTITLE: Setting Artifacts Path for Docling via Environment Variable\nDESCRIPTION: This snippet shows how to set the artifacts path for Docling using an environment variable, which can be useful for scripts or applications.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nexport DOCLING_ARTIFACTS_PATH=\"/local/path/to/models\"\npython my_docling_script.py\n```\n\n----------------------------------------\n\nTITLE: Converting Documents with Docling Python API\nDESCRIPTION: Basic example showing how to use Docling's DocumentConverter to convert a document from a URL or local path and export it to Markdown format.\nSOURCE: https://github.com/docling-project/docling/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"  # document per local path or URL\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())  # output: \"## Docling Technical Report[...]\"\n```\n\n----------------------------------------\n\nTITLE: Table Performance Comparison Data with OTSL and HTML\nDESCRIPTION: Table showing performance comparison between OTSL and HTML representations across different model configurations, measuring TEDs scores, mAP, and inference times.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: OTSL\nCODE:\n```\n# enc-layers<ched># dec-layers<ched>Language<ched>TEDs<lcel><lcel><ched>mAP<ched>Inference<nl><ucel><ucel><ucel><ched>simple<ched>complex<ched>all<ched>(0.75)<ched>time (secs)<nl><fcel>6<fcel>6<fcel>OTSL HTML<fcel>0.965 0.969<fcel>0.934 0.927<fcel>0.955 0.955<fcel>0.88 0.857<fcel>2.73 5.39<nl><fcel>4<fcel>4<fcel>OTSL HTML<fcel>0.938 0.952<fcel>0.904 0.909<fcel>0.927 0.938<fcel>0.853 0.843<fcel>1.97 3.77<nl><fcel>2<fcel>4<fcel>OTSL HTML<fcel>0.923 0.945<fcel>0.897 0.901<fcel>0.915 0.931<fcel>0.859 0.834<fcel>1.91 3.81<nl><fcel>4<fcel>2<fcel>OTSL HTML<fcel>0.952 0.944<fcel>0.92 0.903<fcel>0.942 0.931<fcel>0.857 0.824<fcel>1.22 2\n```\n\n----------------------------------------\n\nTITLE: Registering Docling Plugin in Poetry pyproject.toml\nDESCRIPTION: Defines the entrypoint for a Docling plugin using Poetry v1 in a pyproject.toml file.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[tool.poetry.plugins.\"docling\"]\nyour_plugin_name = \"your_package.module\"\n```\n\n----------------------------------------\n\nTITLE: Initializing TableFormer Architecture in PyTorch\nDESCRIPTION: Implementation details of TableFormer using PyTorch and Torchvision libraries. Features a Transformer Encoder with 2 layers, 512 input features, 1024 FFN size, and 4 attention heads. The Transformer Decoder has 4 layers with similar dimensions and ResNet blocks added to Structure and Cell BBox Decoders.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example code structure based on description:\n\"\"\"Transformer Encoder:\n- 2 encoder layers\n- Input features: 512\n- FFN size: 1024 \n- Attention heads: 4\n\nTransformer Decoder:\n- 4 decoder layers\n- Similar dimensions as encoder\n- ResNet blocks on Structure/BBox decoders\n- Dropout: 0.5\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Using Docling CLI for Document Conversion\nDESCRIPTION: This snippet shows how to use Docling directly from the command line to convert individual files or URLs. It includes an example of using the default converter and a specific VLM model.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_1\n\nLANGUAGE: console\nCODE:\n```\ndocling https://arxiv.org/pdf/2206.01062\n```\n\nLANGUAGE: bash\nCODE:\n```\ndocling --pipeline vlm --vlm-model smoldocling https://arxiv.org/pdf/2206.01062\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for RAG with LlamaIndex and Docling\nDESCRIPTION: This snippet installs the necessary Python libraries for implementing RAG with LlamaIndex and Docling. It uses pip to install various packages including llama-index core, readers, embeddings, and vector stores.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings and Uploading to Azure AI Search\nDESCRIPTION: Generates embeddings for text chunks using Azure OpenAI and uploads them to the Azure AI Search index in batches.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom azure.search.documents import SearchClient\nfrom openai import AzureOpenAI\n\nsearch_client = SearchClient(\n    AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_INDEX_NAME, AzureKeyCredential(AZURE_SEARCH_KEY)\n)\nopenai_client = AzureOpenAI(\n    api_key=AZURE_OPENAI_API_KEY,\n    api_version=AZURE_OPENAI_API_VERSION,\n    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n)\n\n\ndef embed_text(text: str):\n    \"\"\"\n    Helper to generate embeddings with Azure OpenAI.\n    \"\"\"\n    response = openai_client.embeddings.create(\n        input=text, model=AZURE_OPENAI_EMBEDDINGS\n    )\n    return response.data[0].embedding\n\n\nupload_docs = []\nfor chunk_id, chunk_text in all_chunks:\n    embedding_vector = embed_text(chunk_text)\n    upload_docs.append(\n        {\n            \"chunk_id\": chunk_id,\n            \"content\": chunk_text,\n            \"content_vector\": embedding_vector,\n        }\n    )\n\n\nBATCH_SIZE = 50\nfor i in range(0, len(upload_docs), BATCH_SIZE):\n    subset = upload_docs[i : i + BATCH_SIZE]\n    resp = search_client.upload_documents(documents=subset)\n\n    all_succeeded = all(r.succeeded for r in resp)\n    console.print(\n        f\"Uploaded batch {i} -> {i + len(subset)}; all_succeeded: {all_succeeded}, \"\n        f\"first_doc_status_code: {resp[0].status_code}\"\n    )\n\nconsole.print(\"All chunks uploaded to Azure Search.\")\n```\n\n----------------------------------------\n\nTITLE: Enabling External Plugins in Python Code\nDESCRIPTION: Demonstrates how to enable and use external plugins in Python code. It shows setting up pipeline options with external plugins allowed and custom OCR options.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\npipeline_options = PdfPipelineOptions()\npipeline_options.allow_external_plugins = True  # <-- enabled the external plugins\npipeline_options.ocr_options = YourOptions  # <-- your options here\n\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(\n            pipeline_options=pipeline_options\n        )\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Test Document Directory for SimpleDirectoryReader\nDESCRIPTION: This code sets up a test document directory by downloading a PDF file from the specified source URL. It creates a temporary directory and saves the downloaded PDF for use with SimpleDirectoryReader.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nimport requests\n\ntmp_dir_path = Path(mkdtemp())\nr = requests.get(SOURCE)\nwith open(tmp_dir_path / f\"{Path(SOURCE).name}.pdf\", \"wb\") as out_file:\n    out_file.write(r.content)\n```\n\n----------------------------------------\n\nTITLE: Using Granite Vision Model for Picture Description\nDESCRIPTION: This snippet shows how to use the Granite Vision model for picture description in Docling. It configures the pipeline options to use the ibm-granite/granite-vision-3.1-2b-preview model.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.pipeline_options import granite_picture_description\n\npipeline_options.picture_description_options = granite_picture_description\n```\n\n----------------------------------------\n\nTITLE: Creating TAX_ID Column Mask in SQL for DB2\nDESCRIPTION: This SQL statement creates a column mask for the TAX_ID column in the EMPLOYEES table. It uses the VERIFY_GROUP_FOR_USER function to apply different masking rules based on the user's group membership and relationship to the employee data.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE MASK HR_SCHEMA.MASK_TAX_ID_ON_EMPLOYEES ON HR_SCHEMA.EMPLOYEES AS EMPLOYEES\nFOR COLUMN TAX_ID\nRETURN\nCASE\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR' ) = 1 THEN EMPLOYEES . TAX_ID\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . TAX_ID\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( EMPLOYEES . TAX_ID , 8 , 4 ) )\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'EMP' ) = 1 THEN EMPLOYEES . TAX_ID\nELSE 'XXX-XX-XXXX'\nEND\nENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Accessing Document Structures\nDESCRIPTION: How to access and navigate the universal document representation (DoclingDocument) in Docling v2.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Inspect the converted document:\nconv_result.document.print_element_tree()\n\n## Iterate the elements in reading order, including hierachy level:\nfor item, level in conv_result.document.iterate_items():\n    if isinstance(item, TextItem):\n        print(item.text)\n    elif isinstance(item, TableItem):\n        table_df: pd.DataFrame = item.export_to_dataframe()\n        print(table_df.to_markdown())\n    elif ...:\n        #...\n```\n\n----------------------------------------\n\nTITLE: Configuring MkDocs Python Documentation Generation for Document Converter Module\nDESCRIPTION: Configuration block for MkDocs that specifies how to generate API documentation for the docling.document_converter module. It defines which members to include, display options, and formatting preferences for the generated documentation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/reference/document_converter.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: docling.document_converter\n    handler: python\n    options:\n        members:\n            - DocumentConverter\n            - ConversionResult\n            - ConversionStatus\n            - FormatOption\n            - InputFormat\n            - PdfFormatOption\n            - ImageFormatOption\n            - StandardPdfPipeline\n            - WordFormatOption\n            - PowerpointFormatOption\n            - MarkdownFormatOption\n            - AsciiDocFormatOption\n            - HTMLFormatOption\n            - SimplePipeline\n        show_if_no_docstring: true\n        show_submodules: true\n        docstring_section_style: list\n        filters: [\"!^_\"]\n        heading_level: 2\n        inherited_members: true\n        merge_init_into_class: true\n        separate_signature: true\n        show_root_heading: true\n        show_root_full_path: false\n        show_signature_annotations: true\n        show_source: false\n        show_symbol_type_heading: true\n        show_symbol_type_toc: true\n        signature_crossrefs: true\n        summary: true\n```\n\n----------------------------------------\n\nTITLE: Converting XML to DoclingDocument using Docling\nDESCRIPTION: This snippet demonstrates how to use Docling's DocumentConverter to convert a sample PMC article XML file into a DoclingDocument object. It also shows how to export the converted document to markdown format.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\n\n# a sample PMC article:\nsource = \"../../tests/data/jats/elife-56337.nxml\"\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.status)\n\nmd_doc = result.document.export_to_markdown()\n\ndelim = \"\\n\"\nprint(delim.join(md_doc.split(delim)[:8]))\n```\n\n----------------------------------------\n\nTITLE: Setting up Docling Reader and Directory Reader for Patent Processing\nDESCRIPTION: This code sets up a DoclingReader and SimpleDirectoryReader to process USPTO patent XML files. It configures the readers to handle the specific XML format and limits the analysis to the first 100 patents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.readers.docling import DoclingReader\n\nreader = DoclingReader(export_type=DoclingReader.ExportType.JSON)\ndir_reader = SimpleDirectoryReader(\n    input_dir=TEMP_DIR,\n    exclude=[\"docling.db\", \"*.nxml\"],\n    file_extractor={\".xml\": reader},\n    filename_as_id=True,\n    num_files_limit=100,\n)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Fenced Code Block in Python\nDESCRIPTION: An example of a fenced code block in Markdown (surrounded by triple backticks) containing a Python print statement that outputs the classic 'Hello world!' message.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/blocks.md.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Hello world!\")\n```\n\n----------------------------------------\n\nTITLE: Creating a CASE Statement for Column Mask with VERIFY_GROUP_FOR_USER\nDESCRIPTION: SQL CASE statement using VERIFY_GROUP_FOR_USER to implement a column mask for DATE_OF_BIRTH. The mask shows different data to HR/EMP groups, managers viewing their own data, managers viewing others' data, and blocks access for others.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nRETURN\n\nCASE\n\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR', 'EMP' ) = 1 THEN EMPLOYEES . DATE_OF_BIRTH WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . DATE_OF_BIRTH WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 9999 || '-' || MONTH ( EMPLOYEES . DATE_OF_BIRTH ) || '-' || DAY (EMPLOYEES.DATE_OF_BIRTH )) ELSE NULL END ENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Using Docling via Command Line Interface\nDESCRIPTION: Example of using the Docling CLI to convert a document from a URL, showing the basic command syntax for simple document conversion.\nSOURCE: https://github.com/docling-project/docling/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocling https://arxiv.org/pdf/2206.01062\n```\n\n----------------------------------------\n\nTITLE: Performing Similarity Search with Weaviate in Python\nDESCRIPTION: Demonstrates how to perform a similarity search on embedded data in Weaviate. The query searches for chunks related to 'bert', limiting results to 2, and returns the text, title, and distance metadata for each result.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom weaviate.classes.query import MetadataQuery\n\nresponse = collection.query.near_text(\n    query=\"bert\",\n    limit=2,\n    return_metadata=MetadataQuery(distance=True),\n    return_properties=[\"text\", \"title\"],\n)\n\nfor o in response.objects:\n    print(o.properties)\n    print(o.metadata.distance)\n```\n\n----------------------------------------\n\nTITLE: Creating a Column Mask for TAX_ID Using SQL\nDESCRIPTION: SQL statement to create a column mask for the TAX_ID field in the EMPLOYEES table. Implements role-based masking where HR sees full data, employees see only their own data, managers see partially masked data, and others see fully masked values.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE MASK HR_SCHEMA.MASK_TAX_ID_ON_EMPLOYEES ON HR_SCHEMA.EMPLOYEES AS EMPLOYEES FOR COLUMN TAX_ID RETURN CASE WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR' ) = 1 THEN EMPLOYEES . TAX_ID WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . TAX_ID WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( EMPLOYEES . TAX_ID , 8 , 4 ) ) WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'EMP' ) = 1 THEN EMPLOYEES . TAX_ID ELSE 'XXX-XX-XXXX' END ENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Column Masks for a Banking Database\nDESCRIPTION: Comprehensive SQL script creating multiple column masks on the CUSTOMERS table in a banking application, implementing role-based access control for sensitive information like tax IDs, driver's licenses, and security questions based on user groups.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nTHEN C . CUSTOMER_TAX_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( C . CUSTOMER_TAX_ID , 8 , 4 ) ) WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_TAX_ID ELSE 'XXX-XX-XXXX' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_DRIVERS_LICENSE_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_DRIVERS_LICENSE_NUMBER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER ELSE '*************' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_LOGIN_ID_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_LOGIN_ID RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_LOGIN_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_LOGIN_ID ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ANSWER_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION_ANSWER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER ELSE '*****' END ENABLE ; ALTER TABLE BANK_SCHEMA.CUSTOMERS ACTIVATE ROW ACCESS CONTROL ACTIVATE COLUMN ACCESS CONTROL ;\n```\n\n----------------------------------------\n\nTITLE: Using VERIFY_GROUP_FOR_USER Function in SQL for IBM DB2 i\nDESCRIPTION: Examples of using the VERIFY_GROUP_FOR_USER function to check user group membership in SQL queries. This function returns 1 if the user belongs to specified groups, otherwise 0.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'MGR')\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR')\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR', 'STEVE')\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JUDY', 'TONY')\n```\n\n----------------------------------------\n\nTITLE: Mathematical Loss Function Definition for TableFormer Model\nDESCRIPTION: This formula defines the multi-task loss function used to train the TableFormer model. It combines the cross-entropy loss for structure prediction (ls) with a bounding box loss (lbox) that incorporates both L1 and IoU losses for accurate cell detection.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: mathematical\nCODE:\n```\nL = λ * ls + (1 - λ) * lbox, where lbox = λiou * liou + λl1 * l1\n```\n\n----------------------------------------\n\nTITLE: Activating Row and Column Access Control on a Table in DB2 for i\nDESCRIPTION: SQL statement to activate both Row and Column Access Control on the EMPLOYEES table after row permissions and column masks have been created and enabled.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE HR_SCHEMA.EMPLOYEES\n\nACTIVATE ROW ACCESS CONTROL\n\nACTIVATE COLUMN ACCESS CONTROL;\n```\n\n----------------------------------------\n\nTITLE: Granting RCAC Administration Authorization using CHGFCNUSG Command in CL\nDESCRIPTION: This CL command example demonstrates how to grant authorization to a user (HBEDOYA) to administer and manage RCAC rules using the Change Function Usage (CHGFCNUSG) command.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_0\n\nLANGUAGE: CL\nCODE:\n```\nCHGFCNUSG FCNID(QIBM_DB_SECADM) USER(HBEDOYA) USAGE(*ALLOWED)\n```\n\n----------------------------------------\n\nTITLE: Activating Row and Column Access Control in SQL for EMPLOYEES table\nDESCRIPTION: This SQL snippet activates Row and Column Access Control (RCAC) for the EMPLOYEES table in the HR_SCHEMA. This includes enabling the previously defined column masks and ensuring that access permissions are enforced on the data.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nALTER TABLE HR_SCHEMA.EMPLOYEES ACTIVATE ROW ACCESS CONTROL ACTIVATE COLUMN ACCESS CONTROL;\n```\n\n----------------------------------------\n\nTITLE: Using VERIFY_GROUP_FOR_USER Function in SQL\nDESCRIPTION: This snippet demonstrates how to invoke the VERIFY_GROUP_FOR_USER function to check user group memberships against specified profiles. The function takes a special register and a variable number of user profile strings. It returns 1 if the current user or their associated group is found within the provided profiles, else it returns 0.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'MGR')\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR')\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR', 'STEVE')\n-- The following function invocation returns a value of 0:\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'JUDY', 'TONY')\n```\n\n----------------------------------------\n\nTITLE: Analyzing and Printing Chunk Details in Python\nDESCRIPTION: This code iterates through the chunks created by the HybridChunker, analyzing and printing details about each chunk. It shows the number of tokens in both the original and serialized versions of each chunk, demonstrating how the chunker handles token limits and merging.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfor i, chunk in enumerate(chunks):\n    print(f\"=== {i} ===\")\n    txt_tokens = len(tokenizer.tokenize(chunk.text))\n    print(f\"chunk.text ({txt_tokens} tokens):\\n{chunk.text!r}\")\n\n    ser_txt = chunker.serialize(chunk=chunk)\n    ser_tokens = len(tokenizer.tokenize(ser_txt))\n    print(f\"chunker.serialize(chunk) ({ser_tokens} tokens):\\n{ser_txt!r}\")\n\n    print()\n```\n\n----------------------------------------\n\nTITLE: Nested Markdown List Example with Multiple Levels\nDESCRIPTION: A comprehensive example of a nested Markdown list structure showcasing multiple indentation levels with bullet points and different text symbols.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/nested.md.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- abc\n    - abc123\n        - abc1234\n            - abc12345\n                - a.\n                - b.\n        - abcd1234：\n            - abcd12345：\n                - a.\n                - b.\n- def：\n    - def1234：\n        - def12345。\n- after one empty line\n    - foo\n- afer two empty lines\n    - bar\n\n- changing symbol\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Column Masks for Banking Schema in IBM DB2 i\nDESCRIPTION: SQL statements to create multiple column masks for various columns in the CUSTOMERS table of the BANK_SCHEMA, including tax ID, driver's license, login ID, and security questions.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_7\n\nLANGUAGE: SQL\nCODE:\n```\nTHEN C . CUSTOMER_TAX_ID\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1\nTHEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( C . CUSTOMER_TAX_ID , 8 , 4 ) )\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1\nTHEN C . CUSTOMER_TAX_ID\nELSE 'XXX-XX-XXXX'\nEND\nENABLE ;\n\nCREATE MASK BANK_SCHEMA.MASK_DRIVERS_LICENSE_ON_CUSTOMERS\nON BANK_SCHEMA.CUSTOMERS AS C\nFOR COLUMN CUSTOMER_DRIVERS_LICENSE_NUMBER\nRETURN\nCASE\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER\nELSE '*************'\nEND\nENABLE ;\n\nCREATE MASK BANK_SCHEMA.MASK_LOGIN_ID_ON_CUSTOMERS\nON BANK_SCHEMA.CUSTOMERS AS C\nFOR COLUMN CUSTOMER_LOGIN_ID\nRETURN\nCASE\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_LOGIN_ID\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_LOGIN_ID\nELSE '*****'\nEND\nENABLE ;\n\nCREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ON_CUSTOMERS\nON BANK_SCHEMA.CUSTOMERS AS C\nFOR COLUMN CUSTOMER_SECURITY_QUESTION\nRETURN\nCASE\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION\nELSE '*****'\nEND\nENABLE ;\n\nCREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ANSWER_ON_CUSTOMERS\nON BANK_SCHEMA.CUSTOMERS AS C\nFOR COLUMN CUSTOMER_SECURITY_QUESTION_ANSWER\nRETURN\nCASE\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER\nWHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER\nELSE '*****'\nEND\nENABLE ;\n\nALTER TABLE BANK_SCHEMA.CUSTOMERS\nACTIVATE ROW ACCESS CONTROL\nACTIVATE COLUMN ACCESS CONTROL ;\n```\n\n----------------------------------------\n\nTITLE: Prefetching Docling Models for Offline Use\nDESCRIPTION: This snippet demonstrates how to prefetch Docling models for offline use using the docling-tools utility. It shows the command to download all required models.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\n$ docling-tools models download\nDownloading layout model...\nDownloading tableformer model...\nDownloading picture classifier model...\nDownloading code formula model...\nDownloading easyocr models...\nModels downloaded into $HOME/.cache/docling/models.\n```\n\n----------------------------------------\n\nTITLE: Creating Azure AI Search Index for Vector Search\nDESCRIPTION: Defines and creates an Azure AI Search index with vector search capabilities, including fields for chunk ID, content, and content vector.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.search.documents.indexes import SearchIndexClient\nfrom azure.search.documents.indexes.models import (\n    AzureOpenAIVectorizer,\n    AzureOpenAIVectorizerParameters,\n    HnswAlgorithmConfiguration,\n    SearchableField,\n    SearchField,\n    SearchFieldDataType,\n    SearchIndex,\n    SimpleField,\n    VectorSearch,\n    VectorSearchProfile,\n)\nfrom rich.console import Console\n\nconsole = Console()\n\nVECTOR_DIM = 1536  # Adjust based on your chosen embeddings model\n\nindex_client = SearchIndexClient(\n    AZURE_SEARCH_ENDPOINT, AzureKeyCredential(AZURE_SEARCH_KEY)\n)\n\n\ndef create_search_index(index_name: str):\n    # Define fields\n    fields = [\n        SimpleField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True),\n        SearchableField(name=\"content\", type=SearchFieldDataType.String),\n        SearchField(\n            name=\"content_vector\",\n            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n            searchable=True,\n            filterable=False,\n            sortable=False,\n            facetable=False,\n            vector_search_dimensions=VECTOR_DIM,\n            vector_search_profile_name=\"default\",\n        ),\n    ]\n    # Vector search config with an AzureOpenAIVectorizer\n    vector_search = VectorSearch(\n        algorithms=[HnswAlgorithmConfiguration(name=\"default\")],\n        profiles=[\n            VectorSearchProfile(\n                name=\"default\",\n                algorithm_configuration_name=\"default\",\n                vectorizer_name=\"default\",\n            )\n        ],\n        vectorizers=[\n            AzureOpenAIVectorizer(\n                vectorizer_name=\"default\",\n                parameters=AzureOpenAIVectorizerParameters(\n                    resource_url=AZURE_OPENAI_ENDPOINT,\n                    deployment_name=AZURE_OPENAI_EMBEDDINGS,\n                    model_name=\"text-embedding-3-small\",\n                    api_key=AZURE_OPENAI_API_KEY,\n                ),\n            )\n        ],\n    )\n\n    # Create or update the index\n    new_index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n    try:\n        index_client.delete_index(index_name)\n    except Exception:\n        pass\n\n    index_client.create_or_update_index(new_index)\n    console.print(f\"Index '{index_name}' created.\")\n\n\ncreate_search_index(AZURE_SEARCH_INDEX_NAME)\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Structure in Line-Based Format\nDESCRIPTION: This code snippet shows the structure of a table as predicted by TableFormer, represented in a line-based format where each line represents a row and each cell is indicated by numerical identifiers. The structure captures empty cells, merged cells, and the overall table layout.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: plain text\nCODE:\n```\n<fcel>0<fcel>1 2 1<lcel><lcel><lcel><nl><fcel>3<fcel>4 3<fcel>5<fcel>6<fcel>7<nl><fcel>8 2<fcel>9<fcel>10<fcel>11<fcel>12<nl><fcel>13<ecel><fcel>14<fcel>15<fcel>16<nl><fcel>17<fcel>18<ecel><fcel>19<fcel>20<nl>\n```\n\n----------------------------------------\n\nTITLE: Querying FUNCTION_USAGE View for RCAC Authorization in SQL\nDESCRIPTION: This SQL query retrieves information from the FUNCTION_USAGE view to determine who has authority to define and manage Row and Column Access Control (RCAC) in IBM i. It selects relevant columns and filters for the QIBM_DB_SECADM function ID.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n  function_id,\n  user_name,\n  usage,\n  user_type\nFROM\n  function_usage\nWHERE\n  function_id='QIBM_DB_SECADM'\nORDER BY\n  user_name;\n```\n\n----------------------------------------\n\nTITLE: Creating Column Mask for TAX_ID using SQL in DB2\nDESCRIPTION: This SQL snippet creates a column mask for the TAX_ID column on the EMPLOYEES table within the HR_SCHEMA. The mask defines access rules based on user roles, allowing specific users to view their own TAX_ID while masking it for others. The key parameters include SESSION_USER and the roles such as HR, MGR, and EMP.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MASK HR_SCHEMA.MASK_TAX_ID_ON_EMPLOYEES ON HR_SCHEMA.EMPLOYEES AS EMPLOYEES FOR COLUMN TAX_ID RETURN CASE WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR' ) = 1 THEN EMPLOYEES . TAX_ID WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . TAX_ID WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( EMPLOYEES . TAX_ID , 8 , 4 ) ) WHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'EMP' ) = 1 THEN EMPLOYEES . TAX_ID ELSE 'XXX-XX-XXXX' END ENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Implementing Addition Function in JavaScript\nDESCRIPTION: A simple JavaScript function that adds two numbers and returns the result. The example demonstrates function definition, parameter passing, and console output with an example that adds 3 and 5.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/code_and_formula.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nfunction add(a, b) { return a + b; } console.log(add(3, 5));\n```\n\n----------------------------------------\n\nTITLE: Creating Date of Birth Column Mask in SQL for DB2\nDESCRIPTION: This SQL snippet creates a column mask for the DATE_OF_BIRTH column in the EMPLOYEES table. It uses the VERIFY_GROUP_FOR_USER function to apply different masking rules based on the user's group membership and relationship to the employee data.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: SQL\nCODE:\n```\nCASE\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR', 'EMP' ) = 1 THEN EMPLOYEES . DATE_OF_BIRTH\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . DATE_OF_BIRTH\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 9999 || '-' || MONTH ( EMPLOYEES . DATE_OF_BIRTH ) || '-' || DAY (EMPLOYEES.DATE_OF_BIRTH ))\nELSE NULL\nEND\nENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Querying FUNCTION_USAGE View to Determine RCAC Authorization in IBM i\nDESCRIPTION: SQL query to determine which users have authority to define and manage Row and Column Access Control (RCAC) by checking for the QIBM_DB_SECADM function ID in the function_usage view. Results are ordered by user name.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\nfunction_id,\nuser_name,\nusage,\nuser_type\nFROM\nfunction_usage\nWHERE\nfunction_id='QIBM_DB_SECADM'\nORDER BY\nuser_name;\n```\n\n----------------------------------------\n\nTITLE: Configuring DoclingNodeParser for Hierarchical Chunking\nDESCRIPTION: This snippet sets up the DoclingNodeParser, which uses the HierarchicalChunker by default. This parser is used to create hierarchical chunks from the patent documents for efficient indexing and retrieval.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.node_parser.docling import DoclingNodeParser\n\nnode_parser = DoclingNodeParser()\n```\n\n----------------------------------------\n\nTITLE: Data Analysis Variables Table in Markdown\nDESCRIPTION: Detailed table showing categorization of potential factors influencing pre-TAS results, including domains, factors, covariates, descriptions, reference groups, and data sources.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pntd.0008301.xml.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Domain                 | Factor                | Covariate                     | Description                                                     | Reference Group      | Summary statistic   | Temporal Resolution   | Source             |\n|------------------------|-----------------------|-------------------------------|-----------------------------------------------------------------|----------------------|---------------------|-----------------------|--------------------|\n```\n\n----------------------------------------\n\nTITLE: Querying RCAC Administration Authorization using SQL\nDESCRIPTION: This SQL query selects data from the FUNCTION_USAGE view to determine who has authority to define and manage RCAC. It filters for the QIBM_DB_SECADM function ID and orders the results by user name.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\nfunction_id,\nuser_name,\nusage,\nuser_type\nFROM\nfunction_usage\nWHERE\nfunction_id='QIBM_DB_SECADM'\nORDER BY\nuser_name;\n```\n\n----------------------------------------\n\nTITLE: Exporting Documents to Different Formats\nDESCRIPTION: How to export the DoclingDocument to various formats such as JSON, Markdown, and document tokens in Docling v2.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nconv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Export to desired format:\nprint(json.dumps(conv_res.document.export_to_dict()))\nprint(conv_res.document.export_to_markdown())\nprint(conv_res.document.export_to_document_tokens())\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of HybridChunker in Python\nDESCRIPTION: This snippet demonstrates the basic usage of the HybridChunker class for chunking a document. It initializes the chunker with default parameters and applies it to the converted document.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.chunking import HybridChunker\n\nchunker = HybridChunker()\nchunk_iter = chunker.chunk(dl_doc=doc)\n```\n\n----------------------------------------\n\nTITLE: Configuring Docling with Custom OCR Engine\nDESCRIPTION: Python code example showing how to configure the DocumentConverter with a specific OCR engine (Tesseract in this case) by setting appropriate pipeline options.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.base_models import ConversionStatus, PipelineOptions\nfrom docling.datamodel.pipeline_options import PipelineOptions, EasyOcrOptions, TesseractOcrOptions\nfrom docling.document_converter import DocumentConverter\n\npipeline_options = PipelineOptions()\npipeline_options.do_ocr = True\npipeline_options.ocr_options = TesseractOcrOptions()  # Use Tesseract\n\ndoc_converter = DocumentConverter(\n    pipeline_options=pipeline_options,\n)\n```\n\n----------------------------------------\n\nTITLE: BEDTools bedfisher Function for Overlap Analysis\nDESCRIPTION: Settings for the bedfisher function from BEDTools to calculate overlap between scaled ChIP-seq peaks and repeat elements in the UCSC Genome Browser.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n-f 0.25\n```\n\n----------------------------------------\n\nTITLE: Activating RCAC on EMPLOYEES Table in IBM DB2 i\nDESCRIPTION: SQL statement to activate Row and Column Access Control on the EMPLOYEES table in the HR_SCHEMA.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\nALTER TABLE HR_SCHEMA.EMPLOYEES\nACTIVATE ROW ACCESS CONTROL\nACTIVATE COLUMN ACCESS CONTROL;\n```\n\n----------------------------------------\n\nTITLE: Calculating Percent Toxic Effect for ZnSO₄ Sensitivity Assay\nDESCRIPTION: Formula for calculating the percent toxic effect in a toxicity assay by comparing light output in control and sample conditions at different time points. This calculation helps quantify the sensitivity of both Zeocin™ treated and control assay reagents to zinc sulfate.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pa20010031492.md#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n% toxic effect = 100 - [(St/Sₒ) / (Ct/Cₒ) × 100]\n\nwhere: Cₒ=light in control at time zero\nCt=light in control at reading time\nSₒ=light in sample at time zero\nSt=light in sample at reading time\n```\n\n----------------------------------------\n\nTITLE: Creating Column Masks based on User Roles\nDESCRIPTION: These SQL statements create several column masks on the BANK_SCHEMA.CUSTOMERS table, restricting the view of sensitive customer data based on the user's role (ADMIN, TELLER, CUSTOMER). The masks use the QSYS2.VERIFY_GROUP_FOR_USER function to determine the appropriate data to return for each user.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_6\n\nLANGUAGE: SQL\nCODE:\n```\n\"THEN C . CUSTOMER_TAX_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( C . CUSTOMER_TAX_ID , 8 , 4 ) ) WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_TAX_ID ELSE 'XXX-XX-XXXX' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_DRIVERS_LICENSE_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_DRIVERS_LICENSE_NUMBER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER ELSE '*************' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_LOGIN_ID_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_LOGIN_ID RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_LOGIN_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_LOGIN_ID ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ANSWER_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION_ANSWER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER ELSE '*****' END ENABLE ; ALTER TABLE BANK_SCHEMA.CUSTOMERS ACTIVATE ROW ACCESS CONTROL ACTIVATE COLUMN ACCESS CONTROL ;\"\n```\n\n----------------------------------------\n\nTITLE: Installing Docling for Development\nDESCRIPTION: Command for installing Docling with all extras using Poetry for development purposes from a local clone of the repository.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npoetry install --all-extras\n```\n\n----------------------------------------\n\nTITLE: Granting RCAC Administration Privileges using CHGFCNUSG in CL\nDESCRIPTION: This CL command grants authorization to user HBEDOYA to administer and manage Row and Column Access Control (RCAC) rules by allowing usage of the QIBM_DB_SECADM function. This is needed to create, modify, or remove RCAC permissions and masks.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_0\n\nLANGUAGE: CL\nCODE:\n```\nCHGFCNUSG FCNID(QIBM_DB_SECADM) USER(HBEDOYA) USAGE(*ALLOWED)\n```\n\n----------------------------------------\n\nTITLE: Tophat RNA-seq Mapping Parameters\nDESCRIPTION: Command line settings for mapping RNA-seq reads to the mouse genome (mm9) using Tophat. These settings allow each mappable read to be reported once, with a randomly chosen match for multi-mapped reads.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n--I 200000 g 1\n```\n\n----------------------------------------\n\nTITLE: Querying RCAC Authorization using SQL\nDESCRIPTION: SQL query to determine which users have authority to define and manage RCAC by querying the FUNCTION_USAGE view.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT\n    function_id,\n    user_name,\n    usage,\n    user_type\nFROM\n    function_usage\nWHERE\n    function_id='QIBM_DB_SECADM'\nORDER BY\n    user_name;\n```\n\n----------------------------------------\n\nTITLE: Installing dependencies with Poetry\nDESCRIPTION: Command to install all project dependencies defined in the Poetry configuration file (pyproject.toml).\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Enabling Formula Enrichment in Docling\nDESCRIPTION: This code shows how to enable formula enrichment in Docling. It configures the pipeline options to process equation formulas in the document and extract their LaTeX representation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.base_models import InputFormat\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_formula_enrichment = True\n\nconverter = DocumentConverter(format_options={\n    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n})\n\nresult = converter.convert(\"https://arxiv.org/pdf/2501.17887\")\ndoc = result.document\n```\n\n----------------------------------------\n\nTITLE: DocLayNet Dataset Statistics Table\nDESCRIPTION: A comprehensive table showing the distribution of document layout class labels, their counts, and inter-annotator agreement metrics across different document categories (Financial, Manual, Scientific, Legal, Patent, Tender).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2206.01062.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| class label | Count | % of Total ||| triple inter-annotator mAP @ 0.5-0.95 (%) |||||||\n|             |       | Train | Test | Val | All | Fin | Man | Sci | Law | Pat | Ten |\n|-------------|-------|-------|------|-----|-----|-----|-----|-----|-----|-----|-----|\n| Caption | 22524 | 2.04 | 1.77 | 2.32 | 84-89 | 40-61 | 86-92 | 94-99 | 95-99 | 69-78 | n/a |\n| Footnote | 6318 | 0.60 | 0.31 | 0.58 | 83-91 | n/a | 100 | 62-88 | 85-94 | n/a | 82-97 |\n| Formula | 25027 | 2.25 | 1.90 | 2.96 | 83-85 | n/a | n/a | 84-87 | 86-96 | n/a | n/a |\n| List-item | 185660 | 17.19 | 13.34 | 15.82 | 87-88 | 74-83 | 90-92 | 97-97 | 81-85 | 75-88 | 93-95 |\n| Page-footer | 70878 | 6.51 | 5.58 | 6.00 | 93-94 | 88-90 | 95-96 | 100 | 92-97 | 100 | 96-98 |\n| Page-header | 58022 | 5.10 | 6.70 | 5.06 | 85-89 | 66-76 | 90-94 | 98-100 | 91-92 | 97-99 | 81-86 |\n| Picture | 45976 | 4.21 | 2.78 | 5.31 | 69-71 | 56-59 | 82-86 | 69-82 | 80-95 | 66-71 | 59-76 |\n| Section-header | 142884 | 12.60 | 15.77 | 12.85 | 83-84 | 76-81 | 90-92 | 94-95 | 87-94 | 69-73 | 78-86 |\n| Table | 34733 | 3.20 | 2.27 | 3.60 | 77-81 | 75-80 | 83-86 | 98-99 | 58-80 | 79-84 | 70-85 |\n| Text | 510377 | 45.82 | 49.28 | 45.00 | 84-86 | 81-86 | 88-93 | 89-93 | 87-92 | 71-79 | 87-95 |\n| Title | 5071 | 0.47 | 0.30 | 0.50 | 60-72 | 24-63 | 50-63 | 94-100 | 82-96 | 68-79 | 24-56 |\n| Total | 1107470 | 941123 | 99816 | 66531 | 82-83 | 71-74 | 79-81 | 89-94 | 86-91 | 71-76 | 68-85 |\n```\n\n----------------------------------------\n\nTITLE: Trim Galore Parameters for RRBS-seq Read Processing\nDESCRIPTION: Command line parameters for processing RRBS-seq reads using Trim Galore, including flags for Illumina data, paired-end reads, and RRBS-specific processing.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n--illumina --paired --rrbs\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Mixed Spans and Empty Cells\nDESCRIPTION: This complex Markdown table demonstrates a combination of horizontal and vertical cell spans, as well as empty cells, to create a more intricate table layout.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_tables.docx.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n\"| Header 0.0   | Header 0.1          | Header 0.2   |    |                     |\n|--------------|---------------------|--------------|----|---------------------|\n| Cell 1.0     | Merged Cell 1.1 2.1 | Cell 1.2     |    |                     |\n| Cell 2.0     | Merged Cell 1.1 2.1 | Cell 2.2     |    |                     |\n| Cell 3.0     | Merged Cell 3.1 4.1 | Cell 3.2     |    |                     |\n| Cell 4.0     | Merged Cell 3.1 4.1 | Cell 4.2     |    | Merged Cell 4.4 5.4 |\n|              |                     |              |    | Merged Cell 4.4 5.4 |\n|              |                     |              |    |                     |\n|              |                     |              |    |                     |\n|              |                     |              |    | Cell 8.4            |\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Biophysical Allocation Ratio for Milk in Carbon Footprint Assessment\nDESCRIPTION: Formula for determining the allocation ratio for milk when performing carbon footprint calculations using a biophysical allocation approach. This equation accounts for cow body weight, calf weight, and total energy-corrected milk production.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pone.0234687.xml.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\nARmilk = 1–6.04 × BMR\n```\n\n----------------------------------------\n\nTITLE: Fetching and Extracting PMC Articles\nDESCRIPTION: This code snippet demonstrates how to download a PMC article archive, extract the XML file containing the article text, and store it in a temporary directory for further processing.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport tarfile\nfrom io import BytesIO\n\nimport requests\n\n# PMC article PMC11703268\nurl: str = \"https://ftp.ncbi.nlm.nih.gov/pub/pmc/oa_package/e3/6b/PMC11703268.tar.gz\"\n\nprint(f\"Downloading {url}...\")\nbuf = BytesIO(requests.get(url).content)\nprint(\"Extracting and storing the XML file containing the article text...\")\nwith tarfile.open(fileobj=buf, mode=\"r:gz\") as tar_file:\n    for tarinfo in tar_file:\n        if tarinfo.isreg():\n            file_path = Path(tarinfo.name)\n            if file_path.suffix == \".nxml\":\n                with open(TEMP_DIR / file_path.name, \"wb\") as file_obj:\n                    file_obj.write(tar_file.extractfile(tarinfo).read())\n                print(f\"Stored XML file {file_path.name}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Remote Vision Model for Picture Description\nDESCRIPTION: This code demonstrates how to configure a remote vision model for picture description in Docling using the PictureDescriptionApiOptions class. It allows using models hosted on remote platforms or cloud providers.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.pipeline_options import PictureDescriptionApiOptions\n\n# Enable connections to remote services\npipeline_options.enable_remote_services=True  # <-- this is required!\n\n# Example using a model running locally, e.g. via VLLM\npipeline_options.picture_description_options = PictureDescriptionApiOptions(\n    url=\"http://localhost:8000/v1/chat/completions\",\n    params=dict(\n        model=\"MODEL NAME\",\n        seed=42,\n        max_completion_tokens=200,\n    ),\n    prompt=\"Describe the image in three sentences. Be consise and accurate.\",\n    timeout=90,\n)\n```\n\n----------------------------------------\n\nTITLE: Mapping Multimapping Reads with Bowtie for Retrotransposon Analysis\nDESCRIPTION: Command for allowing multimapping and duplicated reads using Bowtie with less strict parameters. This is used in the capture-seq screen to capture all potential reads associated with retrotransposons.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nBowtie --best\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Uniform\nDESCRIPTION: This code snippet represents a uniform Markdown table with headers and data cells. It demonstrates the basic structure of a table using pipes and hyphens to define columns and rows.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_tables.docx.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n\"| Header 0.0   | Header 0.1   | Header 0.2   |\n|--------------|--------------|--------------|\n| Cell 1.0     | Cell 1.1     | Cell 1.2     |\n| Cell 2.0     | Cell 2.1     | Cell 2.2     |\"\n```\n\n----------------------------------------\n\nTITLE: Formula for calculating Energy-Corrected Milk (ECM) in dairy cattle studies\nDESCRIPTION: Equation for standardizing milk production to account for varying fat and protein contents. This formula converts actual milk production to energy-corrected milk (ECM) using specific energy coefficients for fat and protein components relative to standard milk (4% fat and 3.3% protein).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pone.0234687.xml.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nECM = Milk production × (0.0929 × fat% + 0.0588× true protein% + 0.192) / (0.0929 × (4%) + 0.0588 × (3.3%) + 0.192)\n```\n\n----------------------------------------\n\nTITLE: Importing HybridChunker from docling package\nDESCRIPTION: Shows how to import the HybridChunker class when using the main docling package.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/chunking.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.chunking import HybridChunker\n```\n\n----------------------------------------\n\nTITLE: Setting OCR language preferences in Docling using PdfPipelineOptions\nDESCRIPTION: Example showing how to configure OCR language preferences in Docling using the PdfPipelineOptions class. This allows specifying multiple languages for OCR processing in multilingual documents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/faq/index.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\n\npipeline_options = PdfPipelineOptions()\npipeline_options.ocr_options.lang = [\"fr\", \"de\", \"es\", \"en\"]  # example of languages for EasyOCR\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Markdown Table with Headers and Data\nDESCRIPTION: This snippet demonstrates how to create a basic markdown table with 4 columns and 4 rows of data. The table includes a header row with numbers 1-4 and a separator row, followed by data rows containing primarily alphabetical characters.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-comma-in-cell.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 1   | 2   | 3   | 4   |\n|-----|-----|-----|-----|\n| a   | b   | c   | d   |\n| a   | ,   | c   | d   |\n| a   | b   | c   | d   |\n| a   | b   | c   | d   |\n```\n\n----------------------------------------\n\nTITLE: Defining OTSL Vocabulary for Table Structure\nDESCRIPTION: Introduces the Optimized Table Structure Language (OTSL) vocabulary, consisting of 5 tokens that describe tabular structure based on a 2D grid. Each token represents a specific cell type or action in the table structure.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: OTSL\nCODE:\n```\n\"C\" cell a new table cell that either has or does not have cell content\n\"L\" cell left-looking cell , merging with the left neighbor cell to create a span\n\"U\" cell up-looking cell , merging with the upper neighbor cell to create a span\n\"X\" cell cross cell , to merge with both left and upper neighbor cells\n\"NL\" new-line , switch to the next row.\n```\n\n----------------------------------------\n\nTITLE: Calculating Nitrous Oxide Emissions from Manure in Dairy Systems\nDESCRIPTION: Formula for converting N2O-N emissions to N2O emissions when calculating nitrous oxide emissions from stored manure and pasture deposits. This conversion factor is based on the molecular weights of N2O and N.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pone.0234687.xml.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\nN2O emissions = N2O-N emissions × 44/28\n```\n\n----------------------------------------\n\nTITLE: CRISPR/Cas9 Mediated Cluster Deletion Procedure\nDESCRIPTION: Detailed protocol for nucleofecting gRNA vectors and generating knockout cell lines using CRISPR/Cas9 technique\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_1\n\nLANGUAGE: protocol\nCODE:\n```\nAll gRNAs were expressed from the pX330-U6-Chimeric_BB-CBh-hSpCas9 vector and nucleofected into 10^6 ES cells using Amaxa nucleofection: 5 µg of each pX330-gRNA plasmid, 1 µg pPGK-puro and 500 pmoles single-stranded repair oligos. One day after nucleofection, cells were kept under puromycin selection (1 µg/ml) for 24 hr. Individual KO and WT clones were picked 7–8 days after nucleofection and expanded for PCR genotyping.\n```\n\n----------------------------------------\n\nTITLE: Python and R Data Transformation and Visualization\nDESCRIPTION: This code demonstrates data transformation processes, such as filtering and aggregating data, followed by visualization in both Python (using matplotlib or seaborn) and R (using ggplot2). Dependencies include pandas, matplotlib, seaborn for Python, and dplyr, ggplot2 for R. Inputs are datasets loaded earlier; outputs are visual plots illustrating data trends.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/right_to_left_01.doctags.txt#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_data(data):\n    sns.barplot(x='category', y='value', data=data)\n    plt.show()\n```\n\n----------------------------------------\n\nTITLE: Defining HTML Table Structure Tokens\nDESCRIPTION: Lists the basic HTML tokens used for constructing table structures, including those for simple tables and spanning cells. It mentions that at least 28 HTML tokens are needed to describe complex tables in real-world documents.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<table> , </table> , <tr> , </tr> , <td> and </td>\n```\n\n----------------------------------------\n\nTITLE: Fourier Series Representation with LaTeX\nDESCRIPTION: A block-level LaTeX equation showing the general form of a Fourier series expansion for a function f(x).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_2\n\nLANGUAGE: LaTeX\nCODE:\n```\n$$f\\left(x\\right)=a_{0}+\\sum_{n=1}^{ \\infty }\\left(a_{n}\\cos(\\frac{n \\pi x}{L})+b_{n}\\sin(\\frac{n \\pi x}{L})\\right)$$\n```\n\n----------------------------------------\n\nTITLE: Object Detection Performance Comparison Table\nDESCRIPTION: Table showing prediction performance (mAP@0.5-0.95) comparing human annotation against MRCNN, FRCNN and YOLO models across different document element types.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2206.01062.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nhuman   MRCNN   FRCNN   YOLO\n         R50     R101    R101    v5x6\nCaption    84-89   68.4    71.5    70.1    77.7\nFootnote   83-91   70.9    71.8    73.7    77.2\nFormula    83-85   60.1    63.4    63.5    66.2\nList-item  87-88   81.2    80.8    81.0    86.2\nPage-footer 93-94  61.6    59.3    58.9    61.1\nPage-header 85-89  71.9    70.0    72.0    67.9\nPicture    69-71   71.7    72.7    72.0    77.1\nSection-header 83-84 67.6   69.3    68.4    74.6\nTable      77-81   82.2    82.9    82.2    86.3\nText       84-86   84.6    85.8    85.4    88.1\nTitle      60-72   76.7    80.4    79.9    82.7\nAll        82-83   72.4    73.5    73.4    76.8\n```\n\n----------------------------------------\n\nTITLE: Generating CLI Documentation with mkdocs-click in Markdown\nDESCRIPTION: This code snippet uses the mkdocs-click directive to automatically generate documentation for the Docling CLI. It specifies the module, command, program name, and output style for the documentation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/reference/cli.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: mkdocs-click\n    :module: docling.cli.main\n    :command: click_app\n    :prog_name: docling\n    :style: table\n```\n\n----------------------------------------\n\nTITLE: Representing Journal Reference in XML\nDESCRIPTION: This XML snippet represents a journal reference, including author names, article title, source, year, volume, and page numbers. It also includes PubMed ID and DOI identifiers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<mixed-citation publication-type=\"journal\"><name><surname>Id</surname><given-names>CM</given-names></name>, <name><surname>Tettevi</surname><given-names>EJ</given-names></name>, <name><surname>Mechan</surname><given-names>F</given-names></name>, <name><surname>Idun</surname><given-names>B</given-names></name>, <name><surname>Biritwum</surname><given-names>N</given-names></name>, <name><surname>Osei-atweneboana</surname><given-names>MY</given-names></name>, <etal>et al</etal>\n<article-title>Elimination within reach: a cross-sectional study highlighting the factors that contribute to persistent lymphatic filariasis in eight communities in rural Ghana</article-title>. <source>PLoS Negl Trop Dis</source>. <year>2019</year>; <fpage>1</fpage>&#x02013;<lpage>17</lpage>.</mixed-citation>\n```\n\n----------------------------------------\n\nTITLE: MACS14 Peak Calling Parameters for ChIP-seq Analysis\nDESCRIPTION: Parameter settings for calling peaks in ChIP-seq data using MACS14, with high stringency thresholds to ensure reliable peak identification.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\np<1e-10, peak enrichment >20\n```\n\n----------------------------------------\n\nTITLE: Using Bowtie for Unique Mapping of RNA-seq Reads in Mouse Genome Analysis\nDESCRIPTION: This command shows Bowtie mapping parameters used to analyze RNA-seq data in the study. The command ensures only uniquely mapped reads are included by using the -a (report all alignments), -m 1 (suppress reads with multiple alignments), --strata (only report alignments in the best stratum), and -v 2 (allow up to 2 mismatches) parameters.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n-a -m 1 --strata -v 2\n```\n\n----------------------------------------\n\nTITLE: Using Docling V2 CLI Commands\nDESCRIPTION: Examples of how to use the updated CLI commands in Docling v2 for converting various file formats with different options.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Convert a single file to Markdown (default)\ndocling myfile.pdf\n\n# Convert a single file to Markdown and JSON, without OCR\ndocling myfile.pdf --to json --to md --no-ocr\n\n# Convert PDF files in input directory to Markdown (default)\ndocling ./input/dir --from pdf\n\n# Convert PDF and Word files in input directory to Markdown and JSON\ndocling ./input/dir --from pdf --from docx --to md --to json --output ./scratch\n\n# Convert all supported files in input directory to Markdown, but abort on first error\ndocling ./input/dir --output ./scratch --abort-on-error\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit hooks\nDESCRIPTION: Command to install pre-commit hooks that run code style checks (like Black and iSort) on every commit.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Converting Document for Hybrid Chunking in Python\nDESCRIPTION: This code converts a source document to a format suitable for hybrid chunking using the DocumentConverter class from docling.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\n\nDOC_SOURCE = \"../../tests/data/md/wiki.md\"\n\ndoc = DocumentConverter().convert(source=DOC_SOURCE).document\n```\n\n----------------------------------------\n\nTITLE: Basic Print Statement - Indented Code Block Python\nDESCRIPTION: Simple Python print statement example using indented code block syntax.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/blocks.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Hi!\")\n```\n\n----------------------------------------\n\nTITLE: R Function for P-value Adjustment in ChIP-seq Analysis\nDESCRIPTION: R code snippet using the p.adjust() function to apply the Benjamini-Hochberg correction to p-values from pairwise comparison of ChIP-seq peaks and repeat elements.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_5\n\nLANGUAGE: R\nCODE:\n```\np.adjust()\n```\n\n----------------------------------------\n\nTITLE: Defining Multi-Task Loss Function for TableFormer in PyTorch\nDESCRIPTION: The code represents the multi-task loss function used to train TableFormer. It combines a structure prediction loss (Cross-Entropy) with bounding box prediction losses (L1 and IoU) using weighting parameters.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nloss = λ * l_s + (1 - λ) * (λ_iou * l_iou + λ_l1 * l_1)\n```\n\n----------------------------------------\n\nTITLE: Creating Column Mask for Date of Birth in IBM DB2 i\nDESCRIPTION: SQL statement to create a column mask for the DATE_OF_BIRTH column in the EMPLOYEES table. The mask applies different rules based on user groups and relationships.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_4\n\nLANGUAGE: SQL\nCODE:\n```\nRETURN\nCASE\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR', 'EMP' ) = 1 THEN EMPLOYEES . DATE_OF_BIRTH\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . DATE_OF_BIRTH\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 9999 || '-' || MONTH ( EMPLOYEES . DATE_OF_BIRTH ) || '-' || DAY (EMPLOYEES.DATE_OF_BIRTH ))\nELSE NULL\nEND\nENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Adding Numbers in JavaScript\nDESCRIPTION: This snippet defines a function to add two numbers and logs the result of adding 3 and 5. It demonstrates basic function definition and usage in JavaScript.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/code_and_formula.md#2025-04-21_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nfunction add(a, b) { return a + b; } console.log(add(3, 5));\n```\n\n----------------------------------------\n\nTITLE: ChIP-seq Bowtie mapping settings\nDESCRIPTION: This snippet describes the settings used for mapping reads to the mm9 genome using Bowtie in ChIP-seq analysis. The \"best\" setting ensures that reads are mapped to the best possible location in the genome.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n\"bowtie (RRID:<ext-link ext-link-type=\\\"uri\\\" xlink:href=\\\"https://scicrunch.org/resolver/SCR_005476\\\">SCR_005476</ext-link>; settings: --<monospace>best</monospace>)\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Markdown Table of Duck Character Names in Multiple Languages\nDESCRIPTION: This markdown snippet creates a table that displays the names of famous duck characters from Disney comics in English, German, French, and Italian. The table includes characters such as Scrooge McDuck and his nephews Huey, Dewey, and Louie.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/mixed.md.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Character      | Name in German   | Name in French   | Name in Italian   |\n|----------------|------------------|------------------|-------------------|\n| Scrooge McDuck | Dagobert Duck    | Balthazar Picsou | Paperone          |\n| Huey           | Tick             | Riri             | Qui               |\n| Dewey          | Trick            | Fifi             | Quo               |\n| Louie          | Track            | Loulou           | Qua               |\n```\n\n----------------------------------------\n\nTITLE: Using External Plugins with Docling CLI\nDESCRIPTION: Shows how to use external plugins with the Docling command-line interface. It includes commands to show available external plugins and run Docling with a specific external OCR engine.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n# Show the external plugins\ndocling --show-external-plugins\n\n# Run docling with the new plugin\ndocling --allow-external-plugins --ocr-engine=NAME\n```\n\n----------------------------------------\n\nTITLE: Calculating Volatile Solid Excretion for Methane Emissions from Manure in Dairy Systems\nDESCRIPTION: Equation for estimating daily volatile solid excretion on an organic matter basis, used in calculating methane emissions from manure in dairy production systems according to IPCC methodology. The equation incorporates non-digestible organic matter intake, urinary energy excretion, and gross energy intake.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pone.0234687.xml.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nVS = NDOMI + (UE × GE) × (OM/18.45)\n```\n\n----------------------------------------\n\nTITLE: Python and R Data Loading and Preparation\nDESCRIPTION: This snippet involves loading data into Python and R environments, preparing datasets for analysis by cleaning and transforming data frames. Dependencies include pandas for Python and data.table or dplyr for R; it expects datasets in compatible formats. The key focus is on initial data import, cleaning, and setting up data for further analysis.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/right_to_left_01.doctags.txt#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport pandas as pd\n\ndef load_and_prepare_data(file_path):\n    data = pd.read_csv(file_path)\n    data_clean = data.dropna()\n    return data_clean\n```\n\n----------------------------------------\n\nTITLE: Configuring MkDocs for DoclingDocument API Reference\nDESCRIPTION: Configuration block for MkDocs that specifies how to generate the API reference documentation for DoclingDocument. It defines which members to include, formatting options, and display preferences.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/reference/docling_document.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: docling_core.types.doc\n    handler: python\n    options:\n        members:\n            - DoclingDocument\n            - DocumentOrigin\n            - DocItem\n            - DocItemLabel\n            - ProvenanceItem\n            - GroupItem\n            - GroupLabel\n            - NodeItem\n            - PageItem\n            - FloatingItem\n            - TextItem\n            - TableItem\n            - TableCell\n            - TableData\n            - TableCellLabel\n            - KeyValueItem\n            - SectionHeaderItem\n            - PictureItem\n            - ImageRef\n            - PictureClassificationClass\n            - PictureClassificationData\n            - RefItem\n            - BoundingBox\n            - CoordOrigin\n            - ImageRefMode\n            - Size\n        docstring_style: sphinx\n        show_if_no_docstring: true\n        show_submodules: true\n        docstring_section_style: list\n        filters: [\"!^_\"]\n        heading_level: 2\n        show_root_toc_entry: true\n        inherited_members: true\n        merge_init_into_class: true\n        separate_signature: true\n        show_root_heading: true\n        show_root_full_path: false\n        show_signature_annotations: true\n        show_source: false\n        show_symbol_type_heading: true\n        show_symbol_type_toc: true\n        show_labels: false\n        signature_crossrefs: true\n        summary: true\n```\n\n----------------------------------------\n\nTITLE: Running pre-commit checks manually\nDESCRIPTION: Command to manually run all pre-commit checks on all files in the repository, useful for checking changes before committing.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npre-commit run --all-files\n```\n\n----------------------------------------\n\nTITLE: Interleaving Formula for Data Frame Permutation\nDESCRIPTION: Mathematical formula used for permuting data frames in the interleaver. The equation permutes columns (k) of each row (j) using relative prime numbers and modular arithmetic to achieve non-uniform interleaving.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pg06442728.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nI(j,k)=I(j,(αjk+βj)modP)\n```\n\n----------------------------------------\n\nTITLE: Creating Column Mask for Tax ID in IBM DB2 i\nDESCRIPTION: SQL statement to create a column mask for the TAX_ID column in the EMPLOYEES table. The mask applies different rules based on user groups and relationships.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE MASK HR_SCHEMA.MASK_TAX_ID_ON_EMPLOYEES\nON HR_SCHEMA.EMPLOYEES AS EMPLOYEES\nFOR COLUMN TAX_ID\nRETURN\nCASE\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'HR' ) = 1 THEN EMPLOYEES . TAX_ID\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER = EMPLOYEES . USER_ID THEN EMPLOYEES . TAX_ID\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'MGR' ) = 1 AND SESSION_USER <> EMPLOYEES . USER_ID THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( EMPLOYEES . TAX_ID , 8 , 4 ) )\nWHEN VERIFY_GROUP_FOR_USER ( SESSION_USER , 'EMP' ) = 1 THEN EMPLOYEES . TAX_ID\nELSE 'XXX-XX-XXXX'\nEND\nENABLE ;\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Qdrant and Docling\nDESCRIPTION: Installs the necessary Python packages for working with Qdrant vector database, Docling document processing, and FastEmbed for generating embeddings. Includes an option to install the GPU-accelerated version of FastEmbed.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install --no-warn-conflicts -q qdrant-client docling fastembed\n```\n\n----------------------------------------\n\nTITLE: Representing Journal Reference with DOI in XML\nDESCRIPTION: This XML snippet represents a journal reference, including author names, article title, source, year, volume, and page numbers, along with DOI and PubMed ID.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<mixed-citation publication-type=\"journal\"><name><surname>Eigege</surname><given-names>A</given-names></name>, <name><surname>Kal</surname><given-names>A</given-names></name>, <name><surname>Miri</surname><given-names>E</given-names></name>, <name><surname>Sallau</surname><given-names>A</given-names></name>, <name><surname>Umaru</surname><given-names>J</given-names></name>, <name><surname>Mafuyai</surname><given-names>H</given-names></name>, <etal>et al</etal>\n<article-title>Long-lasting insecticidal nets are synergistic with mass drug administration for interruption of lymphatic filariasis transmission in Nigeria</article-title>. <source>PLoS Negl Trop Dis</source>. <year>2013</year>;<volume>7</volume>: <fpage>7</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type=\"doi\">10.1371/journal.pntd.0002508</pub-id>\n<pub-id pub-id-type=\"pmid\">24205421</pub-id></mixed-citation>\n```\n\n----------------------------------------\n\nTITLE: Adding a new dependency with Poetry\nDESCRIPTION: Command to add a new dependency to the project using Poetry. This updates the pyproject.toml file and installs the package.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npoetry add NAME\n```\n\n----------------------------------------\n\nTITLE: Training Configuration for TableFormer\nDESCRIPTION: Training setup using 3 Adam optimizers for CNN Backbone Network, Structure Decoder, and Cell BBox Decoder. Initial learning rate 0.001 for 12 epochs with batch size 24, then reduced to 0.0001 with batch size 18 for 12 more epochs.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Training configuration\n\"\"\"Parameters:\n- Optimizers: 3x Adam (CNN, Structure, BBox)\n- Initial lr: 0.001\n- Initial epochs: 12\n- Initial batch size: 24\n- Lambda: 0.5\n- Secondary lr: 0.0001\n- Secondary batch size: 18\n- Secondary epochs: 12\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Simple Nested HTML List Structure\nDESCRIPTION: A basic example of a nested list structure with a single level of indentation, commonly used in HTML-style formatting.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/nested.md.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- First item\n- Second item with subitems:\n    - Subitem 1\n    - Subitem 2\n- Last list item\n```\n\n----------------------------------------\n\nTITLE: DocLayNet Annotation Guidelines Highlights\nDESCRIPTION: Key annotation guidelines for the DocLayNet dataset that ensure consistency in document layout annotation across different annotators. These guidelines address common annotation challenges like list items, captions, pictures, and section headers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2206.01062.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n(1) Every list-item is an individual object instance with class label List-item. This definition is different from PubLayNet and DocBank, where all list-items are grouped together into one List object.\n(2) A List-item is a paragraph with hanging indentation. Singleline elements can qualify as List-item if the neighbour elements expose hanging indentation. Bullet or enumeration symbols are not a requirement.\n(3) For every Caption, there must be exactly one corresponding Picture or Table.\n(4) Connected sub-pictures are grouped together in one Picture object.\n(5) Formula numbers are included in a Formula object.\n(6) Emphasised text (e.g. in italic or bold) at the beginning of a paragraph is not considered a Section-header, unless it appears exclusively on its own line.\n```\n\n----------------------------------------\n\nTITLE: Simple Food Categories List in Plaintext\nDESCRIPTION: A basic text listing of food categories including leaves, berries, and grain.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/duck.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nLeaves\n\nBerries\nGrain\n```\n\n----------------------------------------\n\nTITLE: Installing Poetry using the official installer in Bash\nDESCRIPTION: Instructions for installing Poetry globally using the official installer script. Poetry is used for dependency management in the project.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -sSL https://install.python-poetry.org | python3 -\n```\n\n----------------------------------------\n\nTITLE: Defining OTSL Syntax Rules for Table Structure Representation\nDESCRIPTION: This snippet outlines the syntax rules for the OTSL (One Token Structure Language) representation of table structures. It defines rules for different cell types and their relationships within the table.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: OTSL\nCODE:\n```\n1. Left-looking cell rule: The left neighbour of an \"L\" cell must be either another \"L\" cell or a \"C\" cell.\n2. Up-looking cell rule: The upper neighbour of a \"U\" cell must be either another \"U\" cell or a \"C\" cell.\n3. Cross cell rule:\n   - The left neighbour of an \"X\" cell must be either another \"X\" cell or a \"U\" cell, and the upper neighbour of an \"X\" cell must be either another \"X\" cell or an \"L\" cell.\n4. First row rule: Only \"L\" cells and \"C\" cells are allowed in the first row.\n5. First column rule: Only \"U\" cells and \"C\" cells are allowed in the first column.\n6. Rectangular rule: The table representation is always rectangular - all rows must have an equal number of tokens, terminated with \"NL\" token.\n```\n\n----------------------------------------\n\nTITLE: XML Document Structure with Figures and Pages\nDESCRIPTION: XML markup showing a document layout with text sections, figures, captions, and page footers. The structure includes page breaks and location markers for positioning elements.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/picture_classification.doctags.txt#2025-04-23_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<doctag>\n  <section_header_level_1><loc_109><loc_79><loc_206><loc_87>Figures Example</section_header_level_1>\n  <text><loc_109><loc_94><loc_390><loc_183>Lorem ipsum dolor sit amet...</text>\n  <picture><loc_110><loc_192><loc_389><loc_322>\n    <caption><loc_185><loc_334><loc_314><loc_340>Figure 1: This is an example image.</caption>\n  </picture>\n  <text><loc_109><loc_349><loc_390><loc_423>Lorem ipsum dolor sit amet...</text>\n  <page_footer><loc_248><loc_439><loc_252><loc_445>1</page_footer>\n  <page_break>\n  <text><loc_109><loc_81><loc_390><loc_169>Lorem ipsum dolor sit amet...</text>\n  <picture><loc_179><loc_176><loc_320><loc_321>\n    <caption><loc_185><loc_330><loc_314><loc_336>Figure 2: This is an example image.</caption>\n  </picture>\n  <text><loc_109><loc_345><loc_390><loc_426>Lorem ipsum dolor sit amet...</text>\n  <page_footer><loc_248><loc_439><loc_252><loc_445>2</page_footer>\n</doctag>\n```\n\n----------------------------------------\n\nTITLE: Displaying Children's Genotype Table in Markdown\nDESCRIPTION: This code snippet presents a markdown table showing the possible genotypes of children based on their parents' CCR5 alleles. It illustrates the inheritance patterns of the CCR5 and CCR5Δ32 alleles.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pnas_sample.xml.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Parents   | Mother   | Mother             | Mother                       | Mother             |\n|-----------|----------|--------------------|------------------------------|--------------------|\\n|           |          |                    |                              |                    |\n| Father    |          | W/W                | W/Δ32                        | Δ32/Δ32            |\n|           | W/W      | χ1,j 1,j           | χ1,j 1,j, χ2,j 2,j           | χ2,j 2,j           |\n|           | W/Δ32    | χ1,j 1,j, χ2,j 2,j | χ1,j 1,j, χ2,j 2,j, χ3,j 3,j | χ2,j 2,j, χ3,j 3,j |\n|           | Δ32/Δ32  | χ2,j 2,j           | χ2,j 2,j, χ3,j 3,j           | χ3,j 3,j           |\n```\n\n----------------------------------------\n\nTITLE: Registering OCR Engine Factory in Python\nDESCRIPTION: Implements the OCR engine factory registration function. This function returns a dictionary with a list of OCR engine classes that implement the BaseOcrModel interface.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Factory registration\ndef ocr_engines():\n    return {\n        \"ocr_engines\": [\n            YourOcrModel,\n        ]\n    }\n```\n\n----------------------------------------\n\nTITLE: Preferred Composition Parameter Ranges\nDESCRIPTION: These inequalities represent more preferred ranges for the parameters x and y in the fluorescent material's composition formula. These narrowed ranges allow for even better optimization of the light emission properties, resulting in greater stability and higher emission intensity.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n\"0.0005≦x≦0.400\"\n\n```\n\nLANGUAGE: text\nCODE:\n```\n\"0.001≦x≦0.350\"\n\n```\n\nLANGUAGE: text\nCODE:\n```\n\"0.0005&lt;y&lt;0.040\"\n\n```\n\nLANGUAGE: text\nCODE:\n```\n\"0.001≦y≦0.026\"\n\n```\n\n----------------------------------------\n\nTITLE: Monoclonal Antibody Dye Conjugation and Purification\nDESCRIPTION: This snippet details the creation of a dye-antibody complex using a monoclonal antibody, dye No. 32, and Woodward reagent.  The complex is separated and purified via gel filtration chromatography, and the molar ratio of dye to antibody is determined using spectrophotometry.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_19\n\nLANGUAGE: text\nCODE:\n```\nAnti-human HCG monoclonal antibody (manufactured by ZyMED Lab, Inc.) was\n      diluted with PBS to a concentration of 0.4 mg/ml, to prepare a monoclonal\n      antibody solution. To 2 ml of the monoclonal antibody solution were added\n      0.3 mg of a dye No. 32 of Table 5 (.lambda.max=825 nm) and 0.10 g of\n      Woodward reagent (manufactured by Tokyo Chemicals, Co. Ltd.) for reaction\n      at room temperature for three hours. The dye-antibody complex was\n      separated and purified by gel filtration chromatography on a column packed\n      with Sepharose 6B. The molar ratio of the dye and the antibody in the\n      dye-antibody complex thus obtained was 3.1:1. By using a spectrophotometer\n      Shimadzu UV-3100S, the absorbance of the complex was measured at\n      wavelengths .lambda.=825 nm and .lambda.=280 nm, separately, to calculate\n      the molar ratio of the dye and the antibody.\n```\n\n----------------------------------------\n\nTITLE: Oligonucleotide Dye Conjugation with Amine Linker\nDESCRIPTION: This describes the synthesis of an oligonucleotide with a primary amine at the 5' terminus using a DNA synthesizer and a N-MMT-hexanol amine linker. It then details the conjugation of dye No. 46 to the amine-modified oligonucleotide in sodium carbonate buffer. The resulting nucleic acid-dye complex is purified by gel filtration and HPLC.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_22\n\nLANGUAGE: text\nCODE:\n```\nA 20-mer oligonucleotide having a base sequence partially complimentary to\n      the base sequence of a model target nucleic acid M13mp18 ss DNA was\n      synthesized by a DNA synthesizer 381 A, manufactured by ABI Co. Ltd. Then,\n      a primary amine was introduced into the 5' terminus of the oligonucleotide\n      by using a N-MMT-hexanol amine linker manufactured by Milligen Co. Ltd.,\n      instead of general amidide reagents. A predetermined protocol was followed\n      to perform cutting out from the CPG-support, deprotection (including the\n      deprotection of monomethoxytrityl group as a protective group of the\n      primary amine), and the purification by high-performance liquid\n      chromatography.\n\n  After mixing together 200 .mu.g of the oligonucleotide, 100 .mu.l of 1M\n      sodium carbonate buffer, pH 9.0, and 700 .mu.l of water, 2 mg of a dye No.\n      46 (.lambda.max=810 nm) shown in Table 5, which had preliminarily been\n      dissolved in 200 N1 of dimethyl formamide, was gradually added under\n      agitation. After the reaction at room temperature for 24 hours, the peak\n      of the nucelic acid was decreased on a high-performance liquid\n      chromatogram, whereas a new peak having the absorbances of the nucleic\n      acid and the dye developed. Thus, the reaction solution was nearly\n      purified on a gel filtration column, NAP-50, manufactured by Pharmacia,\n      which was then purified by HPLC to obtain 175 .mu.g of the nucleic\n      acid-dye complex.\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for RAG with Haystack and Docling\nDESCRIPTION: This snippet installs the necessary Python packages for implementing RAG with Haystack and Docling. It uses pip to install dependencies quietly and with conflict warnings suppressed.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_haystack.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q --progress-bar off --no-warn-conflicts docling-haystack haystack-ai docling pymilvus milvus-haystack sentence-transformers python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Comparing Cross-Dataset Performance in Markdown\nDESCRIPTION: This markdown table shows the prediction performance (mAP@0.5-0.95) of a Mask R-CNN R50 network across PubLayNet, DocBank, and DocLayNet datasets. It demonstrates that the DocLayNet-trained model has less pronounced variations in performance across all datasets, indicating better robustness.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2206.01062.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n|                 |            | Testing on   | Testing on   | Testing on   |\n|-----------------|------------|--------------|--------------|--------------||\n| Training on     | labels     | PLN          | DB           | DLN          |\n| PubLayNet (PLN) | Figure     | 96           | 43           | 23           |\n| PubLayNet (PLN) | Sec-header | 87           | -            | 32           |\n|                 | Table      | 95           | 24           | 49           |\n|                 | Text       | 96           | -            | 42           |\n|                 | total      | 93           | 34           | 30           |\n| DocBank (DB)    | Figure     | 77           | 71           | 31           |\n| DocBank (DB)    | Table      | 19           | 65           | 22           |\n| DocBank (DB)    | total      | 48           | 68           | 27           |\n| DocLayNet (DLN) | Figure     | 67           | 51           | 72           |\n| DocLayNet (DLN) | Sec-header | 53           | -            | 68           |\n|                 | Table      | 87           | 43           | 82           |\n|                 | Text       | 77           | -            | 84           |\n|                 | total      | 59           | 47           | 78           |\n```\n\n----------------------------------------\n\nTITLE: Chemical Notation for Far-Red Fluorescent Materials\nDESCRIPTION: Chemical formulas for fluorescent materials that have emission peak wavelengths exceeding 680 nm. These materials are important for plant cultivation applications as they emit in the far-red spectrum that affects plant growth.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_7\n\nLANGUAGE: chemical notation\nCODE:\n```\nAl₂O₃:Cr (vi)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nCaYAlO₄:Mn (vii)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nLiAlO₂:Fe (viii)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nCdS:Ag (ix)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nGdAlO₃:Cr (x)\n```\n\n----------------------------------------\n\nTITLE: Complex Stability Measurement\nDESCRIPTION: This snippet describes the experimental setup for assessing the stability of labeled dye complexes under storage conditions. The complexes are stored in phosphate buffer at a controlled temperature, and the absorbance is measured at predetermined wavelengths to determine the change in absorbance over time.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_23\n\nLANGUAGE: text\nCODE:\n```\nThe labeled dye complexes prepared in Examples 6 to 10 were prepared to\n      predetermined concentrations with 10 mmol phosphate buffer, pH 7.2. The\n      solutions of the labeled complexes were kept in dark at 7.degree. C. for\n      three days. At the initiation and termination of the test of complex\n      stability under storage, the absorbance was measured at predetermined\n      wavelengths. Then, the ratio of the absorbance at the termination was\n      calculated, provided that the absorbance at the initiation was designated\n      as 100.\n```\n\n----------------------------------------\n\nTITLE: Oligonucleotide Dye Conjugation with Deoxyuridylic Acid Derivative\nDESCRIPTION: This describes the synthesis of an oligonucleotide with multiple primary amines at the 5' terminus using a deoxyuridylic acid derivative monomer. It then details the conjugation of dye No. 27 to the amine-modified oligonucleotide in sodium carbonate buffer. The resulting nucleic acid-labeling agent complex is purified by gel filtration and HPLC.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_24\n\nLANGUAGE: text\nCODE:\n```\nA 20-mer oligonucleotide having a base sequence partially complimentary to\n      the base sequence of a model target nucleic acid M13mp18 ss DNA was\n      synthesized by a DNA synthesizer 381 A, manufactured by ABI Co. Ltd. Then,\n      by using a deoxyuridylic acid derivative monomer:\n      ##STR98##\n      with an amino group introduced, instead of general amidide reagents, 20\n      such deoxyuridylic acid derivatives each having a primary amine group were\n      added to the 5' terminus of the oligonucleotide. Routine method was\n      followed to perform cutting out from the CPG-support, deprotection\n      (including the deprotection of trifluoroacetyl group as a protective group\n      of the primary amine), and the purification by high-performance liquid\n      chromatography.\n\n  After mixing together 200 .mu.g of the oligonucleotide bonding the primary\n      amines, 100 .mu.l of 1M sodium carbonate buffer, pH 9.0, and 700 .mu.l of\n      water, 5 mg of a dye No. 27 (.lambda.max=826 nm) shown in Table 1, which\n      had preliminarily been dissolved in 200 .mu.l of dimethyl formamide, was\n      gradually added under agitation. After the reaction at 40.degree. C. for\n      24 hours, the peak of the nucleic acid was decreased on a high-performance\n      liquid chromatogram, whereas a new peak having the absorbances of the\n      nucleic acid and the labeling agent developed. Thus, the reaction solution\n      was nearly purified on a gel filtration column, NAP-50, manufactured by\n      Pharmacia, which was then purified by HPLC to obtain 350 .mu.g of the\n      nucleic acid-labeling agent complex. The absorbance of the nucleic\n      acid-labeling agent complex at 826 nm had the intensity about 20-fold that\n      of the nucleic acid-labeling agent shown in Example 5.\n```\n\n----------------------------------------\n\nTITLE: Extracting PubMed ID (PMID) from XML\nDESCRIPTION: This XML snippet represents a PubMed ID, a unique identifier for publications indexed in PubMed. The `pub-id` tag with the `pub-id-type` attribute set to \"pmid\" is used to enclose the ID.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<pub-id pub-id-type=\"pmid\">30611745</pub-id>\n```\n\n----------------------------------------\n\nTITLE: CRISPR/Cas9 gRNA Vector\nDESCRIPTION: This snippet describes the vector used for expressing gRNAs in CRISPR/Cas9 mediated gene editing. The pX330-U6-Chimeric_BB-CBh-hSpCas9 vector from Addgene (Addgene_42230) was used to express gRNAs. This vector facilitates targeted gene knockout in ES cells.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n\"pX330-U6-Chimeric_BB-CBh-hSpCas9 vector (RRID:<ext-link ext-link-type=\\\"uri\\\" xlink:href=\\\"https://scicrunch.org/resolver/Addgene_42230\\\">Addgene_42230</ext-link>)\"\n```\n\n----------------------------------------\n\nTITLE: Chemical Formula Structure Definition (General Formula I)\nDESCRIPTION: Defines the chemical structure for a polymethine dye labeling agent with specific substituent groups and structural characteristics\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_0\n\nLANGUAGE: chemical-notation\nCODE:\n```\nR1 through R7 independently selected from: hydrogen atom, halogen atom, alkyl group, aryl group, aralkyl group, sulfonate group, amino group, styryl group, nitro group, hydroxyl group, carboxyl group, cyano group, or arylazo group\n```\n\n----------------------------------------\n\nTITLE: Enabling Remote Services in Docling Python Script\nDESCRIPTION: This code snippet demonstrates how to enable remote services in Docling, which is required for certain operations like using cloud-based OCR engines or hosted LLMs.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\npipeline_options = PdfPipelineOptions(enable_remote_services=True)\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Spacer Group Chemical Structure for Reactive Sites\nDESCRIPTION: Chemical structure notation showing a spacer group that can be interposed between reactive sites to prevent steric hindrance during bonding of a labeling agent and a biological substance. The structure allows for variable chain length where n can be 0 or 1 to 6.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_3\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR8##\n```\n\n----------------------------------------\n\nTITLE: DNA-Dye Complex Formation via Ethanol Precipitation\nDESCRIPTION: This snippet details the formation of a DNA-dye complex using M13mp18 single-strand DNA and dye No. 35. The dye is dissolved in ethanol and added to the DNA solution.  The resulting complex is precipitated with ethanol, washed, and then redissolved.  The amount of dye bonded to the DNA is then quantified, and absorbance measurements are performed.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_21\n\nLANGUAGE: text\nCODE:\n```\nM13mp18 single-strand DNA (7249 bases) (manufactured by TAKARA Liquor KK.)\n      (0.1 mg) was diluted with 5 mmol phosphate buffer, pH 6, to prepare a DNA\n      solution. A dye No. 35 (0.1 mg) shown in Table 5 (.lambda.max=780 nm) was\n      dissolved in 2 ml of ethanol, followed by gradual dropwise addition of 5\n      ml of the DNA solution to the resulting dye solution under stirring.\n      Agitation was further effected at room temperature for 2 hours, to produce\n      a DNA-dye complex.\n\n  To the solution of the DNA-dye complex described above was added further 40\n      ml of ethanol, to precipitate the DNA-dye complex. The DNA-dye complex was\n      separated on a filter, followed by washing several times with ethanol. The\n      DNA-dye complex after the washing was again dissolved in 2 ml of the\n      phosphate buffer, pH 6. The amount of the dye bonded to that of the DNA\n      was 0.5 .mu.g per .mu.g.DNA. The absorbance of the complex was measured at\n      wavelengths .lambda.=780 nm and .lambda.=260 nm, separately, to calculate\n      the concentrations of the dye and the DNA.\n```\n\n----------------------------------------\n\nTITLE: Running the documentation server with MkDocs\nDESCRIPTION: Command to start a local documentation server using MkDocs, making the documentation available for preview at http://localhost:8000.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nmkdocs serve\n```\n\n----------------------------------------\n\nTITLE: Calling Docling Actor via Apify CLI\nDESCRIPTION: This snippet demonstrates how to use the Apify CLI to call the Docling Actor for processing PDF documents. It specifies output formats and provides URLs to documents for processing.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/integrations/apify.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\napify call vancura/docling -i '{\n  \"options\": {\n    \"to_formats\": [\"md\", \"json\", \"html\", \"text\", \"doctags\"]\n  },\n  \"http_sources\": [\n    {\"url\": \"https://vancura.dev/assets/actor-test/facial-hairstyles-and-filtering-facepiece-respirators.pdf\"},\n    {\"url\": \"https://arxiv.org/pdf/2408.09869\"}\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Hello World Print - Fenced Code Block Python\nDESCRIPTION: Basic Hello World print statement using fenced code block syntax with explicit Python language specification.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/blocks.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Hello world!\")\n```\n\n----------------------------------------\n\nTITLE: Defining the OTSL Vocabulary for Table Structure Recognition\nDESCRIPTION: The OTSL (Optimised Table Structure Language) vocabulary consists of 5 tokens that describe tabular structure. Each token represents different cell types and relationships in a 2D grid to efficiently encode table structures including spanning cells.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n- -\"C\" cell a new table cell that either has or does not have cell content\n- -\"L\" cell left-looking cell , merging with the left neighbor cell to create a span\n- -\"U\" cell up-looking cell , merging with the upper neighbor cell to create a span\n- -\"X\" cell cross cell , to merge with both left and upper neighbor cells\n- -\"NL\" new-line , switch to the next row.\n```\n\n----------------------------------------\n\nTITLE: Retrotransposition Vector Modification Command\nDESCRIPTION: Procedure for deleting specific binding sites in retrotransposition vectors using restriction enzyme digestion and re-ligation\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nVector cut with KpnI and re-ligated using repair oligo\n```\n\n----------------------------------------\n\nTITLE: Adding Poetry to PATH in Zsh shell\nDESCRIPTION: Command to add the Poetry installation bin folder to the PATH environment variable in Zsh shell configuration.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\necho 'export PATH=\"POETRY_BIN:$PATH\"' >> ~/.zshrc\n```\n\n----------------------------------------\n\nTITLE: Handling Unsupported XML with Docling\nDESCRIPTION: This code snippet shows how to handle unsupported XML files using Docling. It creates a sample unsupported XML content and demonstrates the ConversionError raised when attempting to convert it.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\n\nfrom docling.datamodel.base_models import DocumentStream\nfrom docling.exceptions import ConversionError\n\nxml_content = (\n    b'<?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE docling_test SYSTEM '\n    b'\"test.dtd\"><docling>Random content</docling>'\n)\nstream = DocumentStream(name=\"docling_test.xml\", stream=BytesIO(xml_content))\ntry:\n    result = converter.convert(stream)\nexcept ConversionError as ce:\n    print(ce)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Indented Code Block in Python\nDESCRIPTION: An example of an indented code block in Markdown containing a Python print statement that outputs a greeting message.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/blocks.md.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nprint(\"Hi!\")\n```\n\n----------------------------------------\n\nTITLE: Using Specific Backend Converter for HTML in Docling\nDESCRIPTION: This code demonstrates how to use a specific backend converter (HTMLDocumentBackend) for processing HTML content in Docling, including fetching content from a URL.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport urllib.request\nfrom io import BytesIO\nfrom docling.backend.html_backend import HTMLDocumentBackend\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.document import InputDocument\n\nurl = \"https://en.wikipedia.org/wiki/Duck\"\ntext = urllib.request.urlopen(url).read()\nin_doc = InputDocument(\n    path_or_stream=BytesIO(text),\n    format=InputFormat.HTML,\n    backend=HTMLDocumentBackend,\n    filename=\"duck.html\",\n)\nbackend = HTMLDocumentBackend(in_doc=in_doc, path_or_stream=BytesIO(text))\ndl_doc = backend.convert()\nprint(dl_doc.export_to_markdown())\n```\n\n----------------------------------------\n\nTITLE: Listing Food Categories in Plaintext\nDESCRIPTION: A simple plaintext list of food categories that ducks might eat, including leaves, berries, and grain. The snippet demonstrates a basic text-based categorization.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/duck.md.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nLeaves\n\nBerries\nGrain\n```\n\n----------------------------------------\n\nTITLE: Data Frame Permutation Formula\nDESCRIPTION: Alternative representation of the interleaving formula specifically for data frames. Uses same mathematical principles but operates directly on the data array D instead of the index array I.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pg06442728.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nD(j,k)=D(j,(αjk+βj)modP)\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 5\nDESCRIPTION: Chemical structure notation for a specific substituent in the fifth entry of Table 1, showing part of the azulene dye compound with cyclic structure.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_5\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR10##\n```\n\n----------------------------------------\n\nTITLE: Installing ocrmac for macOS\nDESCRIPTION: Command for installing the ocrmac package, which uses Apple's vision framework as an OCR backend. Only works on macOS systems with newer versions (10.15+).\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install ocrmac\n```\n\n----------------------------------------\n\nTITLE: Structural formula for cyanine-type dye (Chemical notation)\nDESCRIPTION: General formula (IV) representing the structure of the novel cyanine-type dye used as a labeling agent in the described complex. The formula shows the core structure and variable groups that can be modified to tune the dye's properties.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pftaps057006474.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nA, B, D and E are independently selected from the group consisting of hydrogen atom, a substituted or an unsubstituted alkyl group having two or more carbon atoms, alkenyl group, aralkyl group, aryl group, styryl group and heterocyclic group; r.sub.1 ' and r.sub.2 ' are individually selected from the group consisting of hydrogen atom, a substituted or an unsubstituted alkyl group, cyclic alkyl group, alkenyl group, aralkyl group and aryl group; k is 0 or 1; 1 is 0, 1 or 2; and X.sub.2.sup..crclbar.  represents an anion.\n```\n\n----------------------------------------\n\nTITLE: Chemical Notation for Flux Compounds\nDESCRIPTION: Chemical formulas for halide compounds that can be used as flux in the preparation of fluorescent materials. These compounds accelerate reactions between raw materials and promote uniform solid phase reactions.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_4\n\nLANGUAGE: chemical notation\nCODE:\n```\nBaF₂\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nCaF₂\n```\n\n----------------------------------------\n\nTITLE: Creating a Nested HTML List - HTML\nDESCRIPTION: This snippet demonstrates how to create a nested list using HTML. It includes a main list with sub-items further nesting another list. No specific dependencies are required, and the expected output is structured in a web browser as an indented list.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/nested.md#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<ul>\n    <li>First item</li>\n    <li>Second item with subitems:\n        <ul>\n            <li>Subitem 1</li>\n            <li>Subitem 2</li>\n        </ul>\n    </li>\n    <li>Last list item</li>\n</ul>\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Vision Model for Picture Description\nDESCRIPTION: This snippet shows how to configure a custom vision model for picture description in Docling using the PictureDescriptionVlmOptions class. It allows using any model from the Hugging Face Hub.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.pipeline_options import PictureDescriptionVlmOptions\n\npipeline_options.picture_description_options = PictureDescriptionVlmOptions(\n    repo_id=\"\",  # <-- add here the Hugging Face repo_id of your favorite VLM\n    prompt=\"Describe the image in three sentences. Be consise and accurate.\",\n)\n```\n\n----------------------------------------\n\nTITLE: Converting PDF from Binary Stream in Docling\nDESCRIPTION: This snippet shows how to convert a PDF from a binary stream instead of from the filesystem using Docling's DocumentStream and DocumentConverter classes.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom io import BytesIO\nfrom docling.datamodel.base_models import DocumentStream\nfrom docling.document_converter import DocumentConverter\n\nbuf = BytesIO(your_binary_stream)\nsource = DocumentStream(name=\"my_doc.pdf\", stream=buf)\nconverter = DocumentConverter()\nresult = converter.convert(source)\n```\n\n----------------------------------------\n\nTITLE: Registering Docling Plugin in setup.py\nDESCRIPTION: Defines the entrypoint for a Docling plugin in a setup.py file. This method is used for traditional setuptools-based packaging.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom setuptools import setup\n\nsetup(\n    # ...,\n    entry_points = {\n        'docling': [\n            'your_plugin_name = \"your_package.module\"'\n        ]\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 2, Row 15\nDESCRIPTION: Chemical structure notation for the R₁₂ substituent in the fifteenth entry of Table 2, showing a specific chemical group for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_14\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR19##\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation for Azulenium Salt Nucleus and R Groups\nDESCRIPTION: Chemical structure notation showing the azulenium salt nucleus (Q) and various R group structures (formulas 1-12) that can be attached to it. These structures represent the divalent organic residues that can be bonded via a double bond in the general formula (I).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_2\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR6##\nwherein the relation between the azulenium salt nucleus represented by\nQ.sup..crclbar.  and the azulene salt nucleus on the right side in the\nformula (3) may be symmetric or asymmetric.\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR7##\nIn the above formulas (1) to (12) as in the case of R.sub.1 to R.sub.7,\nR.sub.1 ' to R.sub.7 ' and R.sub.1 \" to R.sub.7 \" independently represent\nhydrogen atom, halogen atom, alkyl group, aryl group, aralkyl group, amino\ngroup, styryl group, nitro group, hydroxyl group, carboxyl group, cyano\ngroup or aryl azo group, while R.sub.1 ' to R.sub.7 ' and R.sub.1 \" to\nR.sub.7 \" independently may form a substituted or an unsubstituted\ncondensed ring; n is 0, 1 or 2; r is an integer of 1 to 8; S represents 0\nor 1; and t represents 1 or 2.\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Document Structure\nDESCRIPTION: This snippet shows the structure of a Markdown document with multiple heading levels. It demonstrates how to create a main title, sections, and subsections using different levels of hash symbols (#).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/unit_test_01.html.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Title\n\n## section-1\n\n### section-1.1\n\n## section-2\n\n#### section-2.0.1\n\n### section-2.2\n\n### section-2.3\n```\n\n----------------------------------------\n\nTITLE: Implementing a Nested HTML Table - HTML\nDESCRIPTION: This commented snippet hints at the implementation of a nested table within an HTML document, which is not yet supported by the current HTML backend. It outlines the structure of a parent table containing a nested table within a cell. The code can be viewed in a web browser to visualize cell nesting.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/nested.md#2025-04-21_snippet_1\n\nLANGUAGE: HTML\nCODE:\n```\n<table>\n  <tr>\n    <td>Cell</td>\n    <td>Nested Table\n      <table>\n        <tr>\n          <td>Cell 1</td>\n\t      <>\n        </tr>\n        <tr>\n          <td>Cell 2</td>\n        </tr>\n        <tr>\n          <td>Cell 3</td>\n        </tr>\n        <tr>\n          <td>Cell 4</td>\n        </tr>\n      </table>\n    </td>\n  </tr>\n  <tr><td>additional row</td></tr>\n</table>\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 7\nDESCRIPTION: Chemical structure notation showing an X₁ ion in the seventh entry of Table 1 for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_7\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR12##\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 10\nDESCRIPTION: Chemical structure notation for a substituent in the tenth entry of Table 1, representing an R' value configuration for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_11\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR16##\n```\n\n----------------------------------------\n\nTITLE: Activating RCAC on EMPLOYEES Table\nDESCRIPTION: These SQL statements activate Row and Column Access Control on the HR_SCHEMA.EMPLOYEES table. Activating these controls allows for fine-grained control over data access based on user roles and permissions.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_5\n\nLANGUAGE: SQL\nCODE:\n```\n\"ALTER TABLE HR_SCHEMA.EMPLOYEES\nACTIVATE ROW ACCESS CONTROL\nACTIVATE COLUMN ACCESS CONTROL;\"\n```\n\n----------------------------------------\n\nTITLE: Registering Docling Plugin in setup.cfg\nDESCRIPTION: Defines the entrypoint for a Docling plugin in a setup.cfg file. This method is used for setuptools-based packaging.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n[options.entry_points]\ndocling =\n    your_plugin_name = your_package.module\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 8\nDESCRIPTION: Chemical structure notation for a substituent in the eighth entry of Table 1, representing an R' value configuration for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_8\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR13##\n```\n\n----------------------------------------\n\nTITLE: Implementing Nested HTML Structure\nDESCRIPTION: Example of nested HTML elements including paragraphs, div container, and unordered list with items. Demonstrates basic HTML structure and hierarchy.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/mixed.md#2025-04-21_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<p>Some paragraph.</p>\n\n<div>\n    <p>Now a div — almost there...</p>\n    <ul>\n        <li>foo</li>\n        <li>bar</li>\n    </ul>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Enabling Picture Description in Docling\nDESCRIPTION: This code demonstrates how to enable picture description in Docling. It configures the pipeline options to annotate pictures with a vision model for captioning tasks.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.base_models import InputFormat\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_picture_description = True\n\nconverter = DocumentConverter(format_options={\n    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n})\n\nresult = converter.convert(\"https://arxiv.org/pdf/2501.17887\")\ndoc = result.document\n```\n\n----------------------------------------\n\nTITLE: HTML Image Placeholder Comment\nDESCRIPTION: HTML comment used as a placeholder for image insertion in the markdown document. This pattern is repeated twice to demonstrate multiple figure placements.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/picture_classification.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<!-- image -->\n```\n\n----------------------------------------\n\nTITLE: Exponential Function Series Expansion with LaTeX\nDESCRIPTION: A block-level LaTeX equation representing the series expansion of the exponential function e^x, valid for all real x values.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_5\n\nLANGUAGE: LaTeX\nCODE:\n```\n$$e^{x}=1+\\frac{x}{1!}+\\frac{x^{2}}{2!}+\\frac{x^{3}}{3!}+ \\text{ \\textellipsis } , - \\infty  < x <  \\infty$$\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Column Masks on CUSTOMERS table in SQL\nDESCRIPTION: This SQL snippet creates multiple column masks for sensitive fields such as CUSTOMER_TAX_ID, CUSTOMER_DRIVERS_LICENSE_NUMBER, CUSTOMER_LOGIN_ID, and CUSTOMER_SECURITY_QUESTION in the BANK_SCHEMA. Each mask defines access control based on user roles utilizing the VERIFY_GROUP_FOR_USER function.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nTHEN C . CUSTOMER_TAX_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN ( 'XXX-XX-' CONCAT QSYS2 . SUBSTR ( C . CUSTOMER_TAX_ID , 8 , 4 ) ) WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_TAX_ID ELSE 'XXX-XX-XXXX' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_DRIVERS_LICENSE_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_DRIVERS_LICENSE_NUMBER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'TELLER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_DRIVERS_LICENSE_NUMBER ELSE '*************' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_LOGIN_ID_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_LOGIN_ID RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_LOGIN_ID WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_LOGIN_ID ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION ELSE '*****' END ENABLE ; CREATE MASK BANK_SCHEMA.MASK_SECURITY_QUESTION_ANSWER_ON_CUSTOMERS ON BANK_SCHEMA.CUSTOMERS AS C FOR COLUMN CUSTOMER_SECURITY_QUESTION_ANSWER RETURN CASE WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'ADMIN' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER WHEN QSYS2 . VERIFY_GROUP_FOR_USER ( SESSION_USER , 'CUSTOMER' ) = 1 THEN C . CUSTOMER_SECURITY_QUESTION_ANSWER ELSE '*****' END ENABLE ; ALTER TABLE BANK_SCHEMA.CUSTOMERS ACTIVATE ROW ACCESS CONTROL ACTIVATE COLUMN ACCESS CONTROL ;\n```\n\n----------------------------------------\n\nTITLE: Converting CSV Files to Docling Documents with Python\nDESCRIPTION: This code snippet demonstrates how to convert a CSV file to a Docling document using the DocumentConverter class. It imports the necessary modules, creates a converter instance, processes a CSV file, and exports the result to markdown format.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_csv.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nfrom docling.document_converter import DocumentConverter\n\n# Convert CSV to Docling document\nconverter = DocumentConverter()\nresult = converter.convert(Path(\"../../tests/data/csv/csv-comma.csv\"))\noutput = result.document.export_to_markdown()\n```\n\n----------------------------------------\n\nTITLE: HTML Comment in Markdown\nDESCRIPTION: An HTML-style comment embedded within a markdown document, demonstrating mixing of HTML syntax in markdown.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/mixed_without_h1.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<!-- This is HTML -->\n```\n\n----------------------------------------\n\nTITLE: Fetching and Processing USPTO Patents\nDESCRIPTION: This code snippet shows how to download a USPTO patent zip file, split its content into individual XML files for each patent, and store them in a temporary directory for further processing.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport zipfile\n\n# Patent grants from December 17-23, 2024\nurl: str = (\n    \"https://bulkdata.uspto.gov/data/patent/grant/redbook/fulltext/2024/ipg241217.zip\"\n)\nXML_SPLITTER: str = '<?xml version=\"1.0\"'\ndoc_num: int = 0\n\nprint(f\"Downloading {url}...\")\nbuf = BytesIO(requests.get(url).content)\nprint(\"Parsing zip file, splitting into XML sections, and exporting to files...\")\nwith zipfile.ZipFile(buf) as zf:\n    res = zf.testzip()\n    if res:\n        print(\"Error validating zip file\")\n    else:\n        with zf.open(zf.namelist()[0]) as xf:\n            is_patent = False\n            patent_buffer = BytesIO()\n            for xf_line in xf:\n                decoded_line = xf_line.decode(errors=\"ignore\").rstrip()\n                xml_index = decoded_line.find(XML_SPLITTER)\n                if xml_index != -1:\n                    if (\n                        xml_index > 0\n                    ):  # cases like </sequence-cwu><?xml version=\"1.0\"...\n                        patent_buffer.write(xf_line[:xml_index])\n                        patent_buffer.write(b\"\\r\\n\")\n                        xf_line = xf_line[xml_index:]\n                    if patent_buffer.getbuffer().nbytes > 0 and is_patent:\n                        doc_num += 1\n                        patent_id = f\"ipg241217-{doc_num}\"\n                        with open(TEMP_DIR / f\"{patent_id}.xml\", \"wb\") as file_obj:\n                            file_obj.write(patent_buffer.getbuffer())\n                    is_patent = False\n                    patent_buffer = BytesIO()\n                elif decoded_line.startswith(\"<!DOCTYPE\"):\n                    is_patent = True\n                patent_buffer.write(xf_line)\n\nprint(f\"Fetched and exported {doc_num} documents.\")\n```\n\n----------------------------------------\n\nTITLE: Bisulfite Sequencing Read Trimming Command\nDESCRIPTION: Read preprocessing command for bisulfite sequencing using Trim Galore with specific trimming parameters for paired-end reads\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nTrim Galore --illumina --paired --rrbs\n```\n\n----------------------------------------\n\nTITLE: R Binomial Test for Peak Enrichment Analysis\nDESCRIPTION: R code for performing a binomial test to determine if KRAB-ZFP peaks are significantly enriched near up- or down-regulated genes, using the binom.test() function.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_7\n\nLANGUAGE: R\nCODE:\n```\nbinom.test()\n```\n\n----------------------------------------\n\nTITLE: Comparing Document-wise and Page-wise Split Performance in Markdown\nDESCRIPTION: This markdown table compares the performance of a Mask R-CNN R50 network with document-wise and page-wise split for different label sets. It illustrates that naive page-wise split results in approximately 10% point improvement in mAP scores.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2206.01062.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n| Class-count    | 11   | 11   | 5   | 5    |\n|----------------|------|------|-----|------|\n| Split          | Doc  | Page | Doc | Page |\n| Caption        | 68   | 83   |     |      |\n| Footnote       | 71   | 84   |     |      |\n| Formula        | 60   | 66   |     |      |\n| List-item      | 81   | 88   | 82  | 88   |\n| Page-footer    | 62   | 89   |     |      |\n| Page-header    | 72   | 90   |     |      |\n| Picture        | 72   | 82   | 72  | 82   |\n| Section-header | 68   | 83   | 69  | 83   |\n| Table          | 82   | 89   | 82  | 90   |\n| Text           | 85   | 91   | 84  | 90   |\n| Title          | 77   | 81   |     |      |\n| All            | 72   | 84   | 78  | 87   |\n```\n\n----------------------------------------\n\nTITLE: Markdown Simple Multiplication Tables\nDESCRIPTION: Two identical markdown tables showing a 3-column multiplication pattern up to 4 rows.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test-01.xlsx.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n|   col-1 |   col-2 |   col-3 |\n|---------|---------|----------|\n|       1 |       2 |       3 |\n|       2 |       4 |       6 |\n|       3 |       6 |       9 |\n|       4 |       8 |      12 |\n```\n\n----------------------------------------\n\nTITLE: Displaying Query Results from Qdrant Hybrid Search\nDESCRIPTION: Prints the retrieved documents from the hybrid search query in a readable format. Each result is numbered and separated for clarity, showing how the query matched relevant portions of the original document.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/retrieval_qdrant.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfor i, point in enumerate(points):\n    print(f\"=== {i} ===\")\n    print(point.document)\n    print()\n```\n\n----------------------------------------\n\nTITLE: Using a specific Python version with Poetry\nDESCRIPTION: Advanced command to create a Poetry virtual environment with a specific Python interpreter version (3.8 in this example).\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npoetry env use $(which python3.8)\n```\n\n----------------------------------------\n\nTITLE: Initializing DocumentConverter with Format Options\nDESCRIPTION: How to set up a DocumentConverter object with custom format options in Docling v2, defining allowed formats and format-specific configurations.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import (\n    DocumentConverter,\n    PdfFormatOption,\n    WordFormatOption,\n)\nfrom docling.pipeline.simple_pipeline import SimplePipeline\nfrom docling.pipeline.standard_pdf_pipeline import StandardPdfPipeline\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.backend.pypdfium2_backend import PyPdfiumDocumentBackend\n\n## Default initialization still works as before:\n# doc_converter = DocumentConverter()\n\n\n# previous `PipelineOptions` is now `PdfPipelineOptions`\npipeline_options = PdfPipelineOptions()\npipeline_options.do_ocr = False\npipeline_options.do_table_structure = True\n#...\n\n## Custom options are now defined per format.\ndoc_converter = (\n    DocumentConverter(  # all of the below is optional, has internal defaults.\n        allowed_formats=[\n            InputFormat.PDF,\n            InputFormat.IMAGE,\n            InputFormat.DOCX,\n            InputFormat.HTML,\n            InputFormat.PPTX,\n        ],  # whitelist formats, non-matching files are ignored.\n        format_options={\n            InputFormat.PDF: PdfFormatOption(\n                pipeline_options=pipeline_options, # pipeline options go here.\n                backend=PyPdfiumDocumentBackend # optional: pick an alternative backend\n            ),\n            InputFormat.DOCX: WordFormatOption(\n                pipeline_cls=SimplePipeline # default for office formats and HTML\n            ),\n        },\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Generating KRAB-ZFP Expressing Cell Lines\nDESCRIPTION: Protocol for PCR amplification and stable expression of KRAB-ZFP open reading frames in F9 EC or ES cells using transposon or lentiviral vectors\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_0\n\nLANGUAGE: protocol\nCODE:\n```\nKRAB-ZFP ORFs were PCR-amplified from cDNA or synthesized with codon-optimization, and stably expressed with 3XFLAG or 3XHA tags in F9 EC or ES cells using Sleeping beauty transposon-based or lentiviral expression vectors. Cells were selected with puromycin (1 µg/ml) and resistant clones were pooled and further expanded for ChIP-seq.\n```\n\n----------------------------------------\n\nTITLE: Journal Reference with DOI and PMID in XML\nDESCRIPTION: This XML snippet details a journal reference, specifying authors, title, journal name, year, volume, page range, DOI, and PMID. The structure helps to accurately cite scientific publications.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<mixed-citation publication-type=\"journal\"><name><surname>Van den Berg</surname><given-names>H</given-names></name>, <name><surname>Kelly-Hope</surname><given-names>LA</given-names></name>, <name><surname>Lindsay</surname><given-names>SW</given-names></name>. <article-title>Malaria and lymphatic filariasis: The case for integrated vector management</article-title>. <source>Lancet Infect Dis</source>. <year>2013</year>;<volume>13</volume>: <fpage>89</fpage>&#x02013;<lpage>94</lpage>. <pub-id pub-id-type=\"doi\">10.1016/S1473-3099(12)70148-2</pub-id>\n<pub-id pub-id-type=\"pmid\">23084831</pub-id></mixed-citation>\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 11 (2)\nDESCRIPTION: Second chemical structure notation for the eleventh entry of Table 1, representing the X₁ ion for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_13\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR18##\n```\n\n----------------------------------------\n\nTITLE: R Data Cleaning and Basic Plotting\nDESCRIPTION: This snippet performs data cleaning operations such as filtering rows based on conditions and creating summary statistics in R, followed by basic plotting using ggplot2. It requires dplyr for data manipulation; the input is a data frame, and the output is visualized data or summaries.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/right_to_left_01.doctags.txt#_snippet_2\n\nLANGUAGE: R\nCODE:\n```\nlibrary(dplyr)\nlibrary(ggplot2)\n\nclean_data <- function(data) {\n  filtered_data <- data %>% filter(!is.na(Value))\n  return(filtered_data)\n}\n\nplot_data <- function(data) {\n  ggplot(data, aes(x=Category, y=Value)) +\n    geom_bar(stat='identity')\n}\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Horizontal Spans (Inner Columns)\nDESCRIPTION: This snippet demonstrates a Markdown table where the horizontal cell spans occur in the inner columns. The table includes regular columns on the edges and merged columns in the middle.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_tables.docx.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n\"| Header 0.0   | Header 0.1          | Header 0.2          | Header 0.3   |\n|--------------|---------------------|---------------------|--------------|\n| Cell 1.0     | Merged Cell 1.1 1.2 | Merged Cell 1.1 1.2 | Cell 1.3     |\n| Cell 2.0     | Merged Cell 2.1 2.2 | Merged Cell 2.1 2.2 | Cell 2.3     |\"\n```\n\n----------------------------------------\n\nTITLE: Using SmolVLM Model for Picture Description\nDESCRIPTION: This code demonstrates how to use the SmolVLM model for picture description in Docling. It sets up the pipeline options to use the HuggingFaceTB/SmolVLM-256M-Instruct model.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.pipeline_options import smolvlm_picture_description\n\npipeline_options.picture_description_options = smolvlm_picture_description\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 9 (R₆)\nDESCRIPTION: Chemical structure notation for the R₆ substituent in the ninth entry of Table 1 for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_10\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR15##\n```\n\n----------------------------------------\n\nTITLE: Pythagorean Theorem with LaTeX (Block)\nDESCRIPTION: A block-level LaTeX equation representing the Pythagorean theorem (a² + b² = c²) multiplied by 23.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_1\n\nLANGUAGE: LaTeX\nCODE:\n```\n$$a^{2}+b^{2}=c^{2} \\text{ \\texttimes } 23$$\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 6\nDESCRIPTION: Chemical structure notation for a substituent in the sixth entry of Table 1, representing the R' values for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_6\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR11##\n```\n\n----------------------------------------\n\nTITLE: Displaying Structure Results Table in Markdown\nDESCRIPTION: This markdown table shows structure prediction results comparing TableFormer with EDD and GTE models across different datasets (PubTabNet, FinTabNet, TableBank, SynthTabNet) using TEDS metric for simple, complex, and all tables.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n| Model       | Dataset   | Simple   | TEDS Complex   |   All |\n|-------------|-----------|----------|----------------|-------|\n| EDD         | PTN       | 91.1     | 88.7           | 89.9  |\n| GTE         | PTN       | -        | -              | 93.01 |\n| TableFormer | PTN       | 98.5     | 95.0           | 96.75 |\n| EDD         | FTN       | 88.4     | 92.08          | 90.6  |\n| GTE         | FTN       | -        | -              | 87.14 |\n| GTE (FT)    | FTN       | -        | -              | 91.02 |\n| TableFormer | FTN       | 97.5     | 96.0           | 96.8  |\n| EDD         | TB        | 86.0     | -              | 86    |\n| TableFormer | TB        | 89.6     | -              | 89.6  |\n| TableFormer | STN       | 96.9     | 95.7           | 96.7  |\n```\n\n----------------------------------------\n\nTITLE: Enabling Picture Classification in Docling\nDESCRIPTION: This snippet illustrates how to enable picture classification in Docling. It sets up the pipeline options to classify PictureItem elements in the document using the DocumentFigureClassifier model.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.base_models import InputFormat\n\npipeline_options = PdfPipelineOptions()\npipeline_options.generate_picture_images = True\npipeline_options.images_scale = 2\npipeline_options.do_picture_classification = True\n\nconverter = DocumentConverter(format_options={\n    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n})\n\nresult = converter.convert(\"https://arxiv.org/pdf/2501.17887\")\ndoc = result.document\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Table for Disney Character Name Translations\nDESCRIPTION: This markdown table displays the names of Disney characters in English, German, French, and Italian. It includes Scrooge McDuck and his nephews Huey, Dewey, and Louie.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ending_with_table.md.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Character      | Name in German   | Name in French   | Name in Italian   |\n|----------------|------------------|------------------|-------------------|\n| Scrooge McDuck | Dagobert Duck    | Balthazar Picsou | Paperone          |\n| Huey           | Tick             | Riri             | Qui               |\n| Dewey          | Trick            | Fifi             | Quo               |\n| Louie          | Track            | Loulou           | Qua               |\n```\n\n----------------------------------------\n\nTITLE: Referencing Code of Conduct in Markdown\nDESCRIPTION: This Markdown snippet provides a link to the Docling Code of Conduct and Covenant, which is hosted on GitHub. It informs participants that they are expected to uphold this code.\nSOURCE: https://github.com/docling-project/docling/blob/main/CODE_OF_CONDUCT.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Contributor Covenant Code of Conduct\n\nThis project adheres to the [Docling - Code of Conduct and Covenant](https://github.com/docling-project/community/blob/main/CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code.\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 1\nDESCRIPTION: Chemical structure notation for a specific substituent in the first entry of Table 1, representing part of an azulene dye compound configuration.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_4\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR9##\n```\n\n----------------------------------------\n\nTITLE: Comparing HTML Table Structure Tags\nDESCRIPTION: Example of basic HTML tags used to construct table structures, showing the need for multiple tokens like <table>, </table>, <tr>, </tr>, <td>, and </td> for simple tables without spanning cells.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<table> , </table> , <tr> , </tr> , <td> and </td>\n```\n\n----------------------------------------\n\nTITLE: Creating a Markdown Table for Duck Food Options\nDESCRIPTION: This Markdown snippet creates a table listing different food options for ducks, including the food category, specific items, and their calorie content per portion.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_sample.docx.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|         | Food                             |   Calories per portion |\n|---------|----------------------------------|------------------------|\n| Leaves  | Ash, Elm, Maple                  |                     50 |\n| Berries | Blueberry, Strawberry, Cranberry |                    150 |\n| Grain   | Corn, Buckwheat, Barley          |                    200 |\n```\n\n----------------------------------------\n\nTITLE: Enabling Picture Classification via Command Line\nDESCRIPTION: This command illustrates how to enable picture classification in Docling using the command line interface.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\ndocling --enrich-picture-classes FILE\n```\n\n----------------------------------------\n\nTITLE: CASE Statement for Row Access Control\nDESCRIPTION: This SQL snippet utilizes a CASE statement to control access to sensitive employee data based on user roles. It checks the group membership of SESSION_USER and returns either the DATE_OF_BIRTH or a masked version of the date based on the user's authority.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCASE\n    WHEN VERIFY_GROUP_FOR_USER (SESSION_USER, 'HR', 'EMP') = 1 THEN EMPLOYEES.DATE_OF_BIRTH\n    WHEN VERIFY_GROUP_FOR_USER (SESSION_USER, 'MGR') = 1 AND SESSION_USER = EMPLOYEES.USER_ID THEN EMPLOYEES.DATE_OF_BIRTH\n    WHEN VERIFY_GROUP_FOR_USER (SESSION_USER, 'MGR') = 1 AND SESSION_USER <> EMPLOYEES.USER_ID THEN (9999 || '-' || MONTH(EMPLOYEES.DATE_OF_BIRTH) || '-' || DAY(EMPLOYEES.DATE_OF_BIRTH))\n    ELSE NULL\nEND ENABLE;\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment for RAG Application\nDESCRIPTION: This snippet sets up the environment for the RAG application, including installing required packages, setting up API access for generative AI, and defining main parameters such as embedding model and vector store location.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q --progress-bar off --no-warn-conflicts llama-index-core llama-index-readers-docling llama-index-node-parser-docling llama-index-embeddings-huggingface llama-index-llms-huggingface-api llama-index-vector-stores-milvus llama-index-readers-file python-dotenv\n\nimport os\nfrom warnings import filterwarnings\n\nfrom dotenv import load_dotenv\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\n\nfilterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\")\n\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n\nEMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\nEMBED_MODEL = HuggingFaceEmbedding(model_name=EMBED_MODEL_ID)\nTEMP_DIR = Path(mkdtemp())\nMILVUS_URI = str(TEMP_DIR / \"docling.db\")\nGEN_MODEL = HuggingFaceInferenceAPI(\n    token=_get_env_from_colab_or_os(\"HF_TOKEN\"),\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\nembed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))\n# https://github.com/huggingface/transformers/issues/5486:\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n```\n\n----------------------------------------\n\nTITLE: Using Prefetched Models in Docling Python Script\nDESCRIPTION: This code snippet shows how to use prefetched models in a Python script by specifying the artifacts path when initializing the DocumentConverter.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.datamodel.pipeline_options import EasyOcrOptions, PdfPipelineOptions\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\n\nartifacts_path = \"/local/path/to/models\"\n\npipeline_options = PdfPipelineOptions(artifacts_path=artifacts_path)\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Enabling Code Enrichment in Docling\nDESCRIPTION: This snippet demonstrates how to enable code enrichment in Docling using the DocumentConverter class. It sets up the pipeline options to process code blocks in the document.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.base_models import InputFormat\n\npipeline_options = PdfPipelineOptions()\npipeline_options.do_code_enrichment = True\n\nconverter = DocumentConverter(format_options={\n    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n})\n\nresult = converter.convert(\"https://arxiv.org/pdf/2501.17887\")\ndoc = result.document\n```\n\n----------------------------------------\n\nTITLE: Displaying Financial Data Table Example in Markdown\nDESCRIPTION: This markdown table shows an example of TableFormer predicting structure on financial data from FinTabNet, containing information about shares in millions and weighted average grant date fair values for RSUs and PSUs.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n|                          | Shares (in millions)   | Shares (in millions)   | Weighted Average Grant Date Fair Value   | Weighted Average Grant Date Fair Value   |\n|--------------------------|------------------------|------------------------|------------------------------------------|------------------------------------------|\n|                          | RS U s                 | PSUs                   | RSUs                                     | PSUs                                     |\n| Nonvested on Janua ry 1  | 1. 1                   | 0.3                    | 90.10 $                                  | $ 91.19                                  |\n| Granted                  | 0. 5                   | 0.1                    | 117.44                                   | 122.41                                   |\n| Vested                   | (0. 5 )                | (0.1)                  | 87.08                                    | 81.14                                    |\n| Canceled or forfeited    | (0. 1 )                | -                      | 102.01                                   | 92.18                                    |\n| Nonvested on December 31 | 1.0                    | 0.3                    | 104.85 $                                 | $ 104.51                                 |\n```\n\n----------------------------------------\n\nTITLE: Enabling Code Enrichment via Command Line\nDESCRIPTION: This command demonstrates how to enable code enrichment in Docling using the command line interface.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\ndocling --enrich-code FILE\n```\n\n----------------------------------------\n\nTITLE: Importing HybridChunker from docling-core package\nDESCRIPTION: Shows how to import the HybridChunker class when using the docling-core package with chunking extras.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/chunking.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom docling_core.transforms.chunker.hybrid_chunker import HybridChunker\n```\n\n----------------------------------------\n\nTITLE: Reinstalling Tesserocr from Source\nDESCRIPTION: Commands for reinstalling the Tesserocr package from source to resolve installation issues with Tesseract linking.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/installation/index.md#2025-04-21_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip uninstall tesserocr\npip install --no-binary :all: tesserocr\n```\n\n----------------------------------------\n\nTITLE: Installing docling-core with chunking support\nDESCRIPTION: Shell command to install docling-core package with chunking capabilities using pip.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/chunking.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install 'docling-core[chunking]'\n```\n\n----------------------------------------\n\nTITLE: Converting USPTO Patent to DoclingDocument and Extracting Claims\nDESCRIPTION: This snippet shows how to convert a USPTO patent XML file into a DoclingDocument using the PatentUsptoDocumentBackend. It then extracts and prints the number of claims in the patent.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndoc = backend.convert()\n\nclaims_sec = next(item for item in doc.texts if item.text == \"CLAIMS\")\nprint(f'Patent \"{doc.texts[0].text}\" has {len(claims_sec.children)} claims')\n```\n\n----------------------------------------\n\nTITLE: Enabling Formula Enrichment via Command Line\nDESCRIPTION: This command shows how to enable formula enrichment in Docling using the command line interface.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/enrichments.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\ndocling --enrich-formula FILE\n```\n\n----------------------------------------\n\nTITLE: Handling Errors in Document Conversion\nDESCRIPTION: How to control error handling behavior during document conversion in Docling v2.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n...\nconv_results_iter = doc_converter.convert_all(input_files, raises_on_error=False) # previously `convert`\n```\n\n----------------------------------------\n\nTITLE: TableFormer Implementation Details using PyTorch\nDESCRIPTION: This snippet highlights the implementation details of the TableFormer model using PyTorch and Torchvision libraries. It describes the optimization process with Adam optimizers and techniques for speeding up inference such as caching decoded tokens.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.md#2025-04-21_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nTableFormer is implemented with PyTorch and Torchvision libraries [22]. To speed up the inference, the image undergoes a single forward pass through the CNN Backbone Network and transformer encoder. This eliminates the overhead of generating the same features for each decoding step. Similarly, we employ a 'caching' technique to preform faster autoregressive decoding. This is achieved by storing the features of decoded tokens so we can reuse them for each time step. Therefore, we only compute the attention for each new tag.\n```\n\n----------------------------------------\n\nTITLE: Chemical Notation for Green Fluorescent Materials\nDESCRIPTION: Chemical formulas representing the composition of green fluorescent materials that can be used in light emitting devices. These materials emit green light by absorbing part of the light from the light emitting element.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_5\n\nLANGUAGE: chemical notation\nCODE:\n```\nM¹¹₈MgSi₄O₁₆X¹¹:Eu (i)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nSi₆₋bAlbObN₈₋b:Eu (ii)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nM¹³Ga₂S₄:Eu (iii)\n```\n\n----------------------------------------\n\nTITLE: Dataset Performance Comparison with OTSL and HTML\nDESCRIPTION: Table comparing performance metrics between OTSL and HTML implementations across different datasets including PubTabNet, FinTabNet, and PubTables-1M.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2305.03393v1.doctags.txt#2025-04-21_snippet_3\n\nLANGUAGE: OTSL\nCODE:\n```\nData set<ched>Language<ched>TEDs<lcel><lcel><ched>mAP(0.75)<ched>Inference time (secs)<nl><ucel><ucel><ched>simple<ched>complex<ched>all<ucel><ucel><nl><fcel>PubTabNet<fcel>OTSL HTML<fcel>0.965 0.969<fcel>0.934 0.927<fcel>0.955 0.955<fcel>0.88 0.857<fcel>2.73 5.39<nl><fcel>FinTabNet<fcel>OTSL HTML<fcel>0.955 0.917<fcel>0.961 0.922<fcel>0.959 0.92<fcel>0.862 0.722<fcel>1.85 3.26<nl><fcel>PubTables-1M<fcel>OTSL HTML<fcel>0.987 0.983<fcel>0.964 0.944<fcel>0.977 0.966<fcel>0.896 0.889<fcel>1.79 3.26\n```\n\n----------------------------------------\n\nTITLE: Bowtie Mapping Settings for ChIP-seq Analysis\nDESCRIPTION: Command line settings for mapping ChIP-seq reads to the mm9 genome using Bowtie. The --best flag ensures reads that map to multiple regions are assigned to the highest scoring match.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n--best\n```\n\n----------------------------------------\n\nTITLE: Adding PMC Article to Vector Store\nDESCRIPTION: This snippet demonstrates how to add a PMC article directly to the vector store using the DoclingReader. It uses the same node parser and embedding model as used for the patents.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nindex.from_documents(\n    documents=reader.load_data(TEMP_DIR / \"nihpp-2024.12.26.630351v1.nxml\"),\n    transformations=[node_parser],\n    storage_context=StorageContext.from_defaults(vector_store=vector_store),\n    embed_model=EMBED_MODEL,\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Main Parameters for RAG Pipeline\nDESCRIPTION: This snippet defines the main parameters for the RAG pipeline, including the embedding model, vector store URI, generative model, source document, and query. It uses HuggingFace models for embedding and generation.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n\nEMBED_MODEL = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\nMILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")\nGEN_MODEL = HuggingFaceInferenceAPI(\n    token=_get_env_from_colab_or_os(\"HF_TOKEN\"),\n    model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\nSOURCE = \"https://arxiv.org/pdf/2408.09869\"  # Docling Technical Report\nQUERY = \"Which are the main AI models in Docling?\"\n\nembed_dim = len(EMBED_MODEL.get_text_embedding(\"hi\"))\n```\n\n----------------------------------------\n\nTITLE: Commented DocumentConverter Configuration\nDESCRIPTION: Commented out YAML configuration block for documenting the DocumentConverter class, including basic display options for docstrings and submodules.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/reference/pipeline_options.md#2025-04-21_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n<!-- ::: docling.document_converter.DocumentConverter\n    handler: python\n    options:\n        show_if_no_docstring: true\n        show_submodules: true -->\n```\n\n----------------------------------------\n\nTITLE: Configuring API Reference Display Options for Pipeline Options\nDESCRIPTION: YAML configuration block that specifies how to generate and display the API reference documentation for Docling's pipeline options module. It includes settings for docstring formatting, member visibility, heading styles, and various display options.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/reference/pipeline_options.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n::: docling.datamodel.pipeline_options\n    handler: python\n    options:\n        show_if_no_docstring: true\n        show_submodules: true\n        docstring_section_style: list\n        filters: [\"!^_\"]\n        heading_level: 2\n        inherited_members: true\n        merge_init_into_class: true\n        separate_signature: true\n        show_root_heading: true\n        show_root_full_path: false\n        show_signature_annotations: true\n        show_source: false\n        show_symbol_type_heading: true\n        show_symbol_type_toc: true\n        signature_crossrefs: true\n        summary: true\n```\n\n----------------------------------------\n\nTITLE: Listing Maintainers in Markdown\nDESCRIPTION: This Markdown snippet lists the maintainers of the Docling project, including their names and GitHub profile links. It also provides an email address for contacting the maintainers.\nSOURCE: https://github.com/docling-project/docling/blob/main/MAINTAINERS.md#2025-04-21_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# MAINTAINERS\n\n- Christoph Auer - [@cau-git](https://github.com/cau-git)\n- Michele Dolfi - [@dolfim-ibm](https://github.com/dolfim-ibm)\n- Panos Vagenas - [@vagenas](https://github.com/vagenas)\n- Peter Staar - [@PeterStaar-IBM](https://github.com/PeterStaar-IBM)\n\nMaintainers can be contacted at [deepsearch-core@zurich.ibm.com](mailto:deepsearch-core@zurich.ibm.com).\n```\n\n----------------------------------------\n\nTITLE: Defining OTSL Vocabulary for Table Structure Recognition\nDESCRIPTION: The definition of the 5 tokens that comprise the OTSL vocabulary for representing tabular structures. Each token represents a specific cell type or action in the table grid.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- -\"C\" cell a new table cell that either has or does not have cell content\n\n- -\"L\" cell left-looking cell , merging with the left neighbor cell to create a span\n\n- -\"U\" cell up-looking cell , merging with the upper neighbor cell to create a span\n\n- -\"X\" cell cross cell , to merge with both left and upper neighbor cells\n\n- -\"NL\" new-line , switch to the next row.\n```\n\n----------------------------------------\n\nTITLE: Imposing Limits on Document Processing in Docling\nDESCRIPTION: This code snippet demonstrates how to set limits on the document size and number of pages that Docling should process, which can be useful for managing resource usage.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom docling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"\nconverter = DocumentConverter()\nresult = converter.convert(source, max_num_pages=100, max_file_size=20971520)\n```\n\n----------------------------------------\n\nTITLE: Regenerating reference test data\nDESCRIPTION: Command to regenerate reference test data using environment variables and Poetry to run pytest. Used when conversion results are improved.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nDOCLING_GEN_TEST_DATA=1 poetry run pytest\n```\n\n----------------------------------------\n\nTITLE: Dataset Comparison Table in Markdown\nDESCRIPTION: A markdown table comparing different datasets used in the TableFormer project, including their tag support, bounding box information, size, and format specifications.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|                    |   Tags |   Bbox | Size   | Format   |\n|--------------------|--------|--------|--------|----------|\n| PubTabNet          |      3 |      3 | 509k   | PNG      |\n| FinTabNet          |      3 |      3 | 112k   | PDF      |\n| TableBank          |      3 |      7 | 145k   | JPEG     |\n| Combined-Tabnet(*) |      3 |      3 | 400k   | PNG      |\n| Combined(**)       |      3 |      3 | 500k   | PNG      |\n| SynthTabNet        |      3 |      3 | 600k   | PNG      |\n```\n\n----------------------------------------\n\nTITLE: HIV Infectivity Coefficient Calculation in LaTeX\nDESCRIPTION: Formula for calculating the infectivity coefficient (λ) in the HIV transmission model. Considers factors such as transmission likelihood, partnership formation, number of contacts, and probability of encountering an infected individual.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pnas_sample.xml.md#2025-04-21_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\n$$ {\\lambda}_{\\hat {i},\\hat {j},\\hat {k}{\\rightarrow}i,j}=\\frac{C_{j}{\\cdot}{\\phi}_{j}}{N_{\\hat {j}}}\\hspace{.167em} \\left[ { \\,\\substack{ \\\\ {\\sum} \\\\ _{\\hat {i},\\hat {k}} }\\, }{\\beta}_{\\hat {i},\\hat {j},\\hat {k}{\\rightarrow}i,j}{\\cdot}I_{\\hat {i},\\hat {j},\\hat {k}} \\right] , $$\n```\n\n----------------------------------------\n\nTITLE: Citing Docling in Academic Publications\nDESCRIPTION: BibTeX citation format for referencing the Docling Technical Report in academic publications and research papers.\nSOURCE: https://github.com/docling-project/docling/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bibtex\nCODE:\n```\n@techreport{Docling,\n  author = {Deep Search Team},\n  month = {8},\n  title = {Docling Technical Report},\n  url = {https://arxiv.org/abs/2408.09869},\n  eprint = {2408.09869},\n  doi = {10.48550/arXiv.2408.09869},\n  version = {1.0.0},\n  year = {2024}\n}\n```\n\n----------------------------------------\n\nTITLE: Direct LLM Prompting for Question-Answering\nDESCRIPTION: This snippet shows how to prompt the language model directly with a question. It uses the Rich library to format and display the prompt and the generated response.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/backend_xml_rag.ipynb#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core.base.llms.types import ChatMessage, MessageRole\nfrom rich.console import Console\nfrom rich.panel import Panel\n\nconsole = Console()\nquery = \"Do mosquitoes in high altitude expand viruses over large distances?\"\n\nusr_msg = ChatMessage(role=MessageRole.USER, content=query)\nresponse = GEN_MODEL.chat(messages=[usr_msg])\n\nconsole.print(Panel(query, title=\"Prompt\", border_style=\"bold red\"))\nconsole.print(\n    Panel(\n        response.message.content.strip(),\n        title=\"Generated Content\",\n        border_style=\"bold green\",\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Poetry to PATH in Bash shell\nDESCRIPTION: Command to add the Poetry installation bin folder to the PATH environment variable in Bash shell configuration.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\necho 'export PATH=\"POETRY_BIN:$PATH\"' >> ~/.bashrc\n```\n\n----------------------------------------\n\nTITLE: Customizing PDF Table Extraction in Docling\nDESCRIPTION: This snippet shows how to customize PDF table extraction options in Docling, including disabling cell matching and choosing between fast and accurate TableFormer modes.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/usage/index.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n\npipeline_options = PdfPipelineOptions(do_table_structure=True)\npipeline_options.table_structure_options.do_cell_matching = False  # uses text cells predicted from table structure model\npipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # use more accurate TableFormer model\n\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Mathematical Formula for Child Population Calculation in HIV Demographics\nDESCRIPTION: LaTeX formula calculating the number of CCR5 W/W children based on parental genotypes and HIV status. Incorporates birthrate, vertical transmission probability, and Mendelian inheritance factors.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pnas_sample.xml.md#2025-04-21_snippet_3\n\nLANGUAGE: latex\nCODE:\n```\nB_{r}\\hspace{.167em}{ \\,\\substack{ \\\\ {\\sum} \\\\ _{k} }\\, } \\left[ S_{1,F}\\frac{(S_{1,M}+I_{1,M,k})}{N_{M}}+ \\left[ (0.5)S_{1,F}\\frac{(S_{2,M}+I_{2,M,k})}{N_{M}} \\right] + \\right\n```\n\nLANGUAGE: latex\nCODE:\n```\np_{v} \\left \\left( \\frac{(I_{1,F,k}(S_{1,M}+I_{1,M,k}))}{N_{M}}+ \\left[ (0.5)I_{1,F,k}\\frac{(S_{2,M}+I_{2,M,k})}{N_{M}} \\right] \\right) \\right] \\hspace{.167em}\n```\n\n----------------------------------------\n\nTITLE: Checking maximum chunk token lengths when using HybridChunker\nDESCRIPTION: Utility code for verifying that chunks produced by the HybridChunker don't exceed the maximum token limit of the model. This helps diagnose and verify chunk sizes when warnings about token sequence length appear.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/faq/index.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nchunk_max_len = 0\nfor i, chunk in enumerate(chunks):\n    ser_txt = chunker.serialize(chunk=chunk)\n    ser_tokens = len(tokenizer.tokenize(ser_txt))\n    if ser_tokens > chunk_max_len:\n        chunk_max_len = ser_tokens\n    print(f\"{i}\\t{ser_tokens}\\t{repr(ser_txt[:100])}...\")\nprint(f\"Longest chunk yielded: {chunk_max_len} tokens\")\nprint(f\"Model max length: {tokenizer.model_max_length}\")\n```\n\n----------------------------------------\n\nTITLE: HTML Table Cell with Spanning Example\nDESCRIPTION: Example showing how HTML represents table cells with column and row spans, demonstrating why at least 28 different HTML tokens are needed to describe complex tables.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: HTML\nCODE:\n```\n<td> and </td>\n```\n\n----------------------------------------\n\nTITLE: Displaying Cell Bounding Box Detection Results in Markdown\nDESCRIPTION: This markdown table presents cell bounding box detection results for TableFormer and EDD+BBox models on PubTabNet and SynthTabNet datasets using mAP metric, with and without post-processing (PP).\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n| Model       | Dataset     |   mAP | mAP (PP)   |\n|-------------|-------------|-------|------------|\n| EDD+BBox    | PubTabNet   |  79.2 | 82.7       |\n| TableFormer | PubTabNet   |  82.1 | 86.8       |\n| TableFormer | SynthTabNet |  87.7 | -          |\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Markdown Table\nDESCRIPTION: This markdown snippet demonstrates a simple table structure with 4 columns and 5 rows. The table includes header row formatting with separator dashes, and contains basic alphanumeric data with one quoted value and one empty cell.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-too-few-columns.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 1   | 2   | 3   | 4   |\n|-----|-----|-----|-----|\n| a   | 'b' | c   | d   |\n| a   | b   | c   |     |\n| a   | b   | c   | d   |\n| a   | b   | c   | d   |\n```\n\n----------------------------------------\n\nTITLE: Executing Custom Perl Script for Methylation Patterns\nDESCRIPTION: This Perl script retrieves methylation patterns for each CpG dyad from Bismark methylation calling results. It requires Perl to be installed and assumes Bismark analysis outputs are available. The script processes these outputs to distill CpG methylation information, which is essential for understanding epigenetic modifications. It does not specify input parameters in the description but is tailored for specific biological datasets.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_7\n\nLANGUAGE: Perl\nCODE:\n```\nelife-56337-code1.pl\n```\n\n----------------------------------------\n\nTITLE: Setting up Weaviate Collection\nDESCRIPTION: Creates and configures an embedded Weaviate collection with OpenAI embeddings and generative capabilities.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_weaviate.ipynb#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport weaviate.classes.config as wc\n\n# Define the collection name\ncollection_name = \"docling\"\n\n# Delete the collection if it already exists\nif client.collections.exists(collection_name):\n    client.collections.delete(collection_name)\n\n# Create the collection\ncollection = client.collections.create(\n    name=collection_name,\n    vectorizer_config=wc.Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-large\",  # Specify your embedding model here\n    ),\n    # Enable generative model from Cohere\n    generative_config=wc.Configure.Generative.openai(\n        model=\"gpt-4o\"  # Specify your generative model for RAG here\n    ),\n    # Define properties of metadata\n    properties=[\n        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, skip_vectorization=True),\n    ],\n)\n```\n\n----------------------------------------\n\nTITLE: XML Citation References\nDESCRIPTION: XML-formatted academic citations containing author information, article titles, publication details, and digital identifiers (DOIs and PMIDs) for lymphatic filariasis research papers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<pub-id pub-id-type=\"pmid\">26728523</pub-id></mixed-citation></ref><ref id=\"pntd.0008301.ref015\"><label>15</label><mixed-citation publication-type=\"journal\"><name><surname>Michael</surname><given-names>E</given-names></name>, <name><surname>Malecela-Lazaro</surname><given-names>MN</given-names></name>...\n```\n\n----------------------------------------\n\nTITLE: Converting Documents with DocumentConverter\nDESCRIPTION: Examples of converting individual and multiple documents using the updated DocumentConverter API in Docling v2.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n...\nfrom docling.datamodel.document import ConversionResult\n## Convert a single file (from URL or local path)\nconv_result: ConversionResult = doc_converter.convert(\"https://arxiv.org/pdf/2408.09869\") # previously `convert_single`\n\n## Convert several files at once:\n\ninput_files = [\n    \"tests/data/html/wiki_duck.html\",\n    \"tests/data/docx/word_sample.docx\",\n    \"tests/data/docx/lorem_ipsum.docx\",\n    \"tests/data/pptx/powerpoint_sample.pptx\",\n    \"tests/data/2305.03393v1-pg9-img.png\",\n    \"tests/data/pdf/2206.01062.pdf\",\n]\n\n# Directly pass list of files or streams to `convert_all`\nconv_results_iter = doc_converter.convert_all(input_files) # previously `convert`\n```\n\n----------------------------------------\n\nTITLE: Displaying Customer Information Table in Markdown\nDESCRIPTION: This code snippet shows a markdown table containing customer information. It includes details such as customer ID, name, company, location, contact information, subscription date, and website for multiple customers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-pipe.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|   Index | Customer Id     | First Name   | Last Name   | Company                        | City              | Country                    | Phone 1                | Phone 2               | Email                       | Subscription Date   | Website                     |\n|---------|-----------------|--------------|-------------|--------------------------------|-------------------|----------------------------|------------------------|-----------------------|-----------------------------|---------------------|-----------------------------|\n|       1 | DD37Cf93aecA6Dc | Sheryl       | Baxter      | Rasmussen Group                | East Leonard      | Chile                      | 229.077.5154           | 397.884.0519x718      | zunigavanessa@smith.info    | 2020-08-24          | http://www.stephenson.com/  |\n|       2 | 1Ef7b82A4CAAD10 | Preston      | Lozano      | Vega-Gentry                    | East Jimmychester | Djibouti                   | 5153435776             | 686-620-1820x944      | vmata@colon.com             | 2021-04-23          | http://www.hobbs.com/       |\n|       3 | 6F94879bDAfE5a6 | Roy          | Berry       | Murillo-Perry                  | Isabelborough     | Antigua and Barbuda        | +1-539-402-0259        | (496)978-3969x58947   | beckycarr@hogan.com         | 2020-03-25          | http://www.lawrence.com/    |\n|       4 | 5Cef8BFA16c5e3c | Linda        | Olsen       | Dominguez|Mcmillan and Donovan | Bensonview        | Dominican Republic         | 001-808-617-6467x12895 | +1-813-324-8756       | stanleyblackwell@benson.org | 2020-06-02          | http://www.good-lyons.com/  |\n|       5 | 053d585Ab6b3159 | Joanna       | Bender      | Martin|Lang and Andrade        | West Priscilla    | Slovakia (Slovak Republic) | 001-234-203-0635x76146 | 001-199-446-3860x3486 | colinalvarado@miles.net     | 2021-04-17          | https://goodwin-ingram.com/ |\n```\n\n----------------------------------------\n\nTITLE: Displaying Customer Data Table in Markdown\nDESCRIPTION: This markdown table presents customer information including unique identifiers, personal details, company affiliations, contact information, subscription dates, and associated websites. The table is formatted with aligned columns for easy readability.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-comma.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|   Index | Customer Id     | First Name   | Last Name   | Company                         | City              | Country                    | Phone 1                | Phone 2               | Email                       | Subscription Date   | Website                     |\n|---------|-----------------|--------------|-------------|---------------------------------|-------------------|----------------------------|------------------------|-----------------------|-----------------------------|---------------------|-----------------------------||\n|       1 | DD37Cf93aecA6Dc | Sheryl       | Baxter      | Rasmussen Group                 | East Leonard      | Chile                      | 229.077.5154           | 397.884.0519x718      | zunigavanessa@smith.info    | 2020-08-24          | http://www.stephenson.com/  |\n|       2 | 1Ef7b82A4CAAD10 | Preston      | Lozano, Dr  | Vega-Gentry                     | East Jimmychester | Djibouti                   | 5153435776             | 686-620-1820x944      | vmata@colon.com             | 2021-04-23          | http://www.hobbs.com/       |\n|       3 | 6F94879bDAfE5a6 | Roy          | Berry       | Murillo-Perry                   | Isabelborough     | Antigua and Barbuda        | +1-539-402-0259        | (496)978-3969x58947   | beckycarr@hogan.com         | 2020-03-25          | http://www.lawrence.com/    |\n|       4 | 5Cef8BFA16c5e3c | Linda        | Olsen       | Dominguez, Mcmillan and Donovan | Bensonview        | Dominican Republic         | 001-808-617-6467x12895 | +1-813-324-8756       | stanleyblackwell@benson.org | 2020-06-02          | http://www.good-lyons.com/  |\n|       5 | 053d585Ab6b3159 | Joanna       | Bender      | Martin, Lang and Andrade        | West Priscilla    | Slovakia (Slovak Republic) | 001-234-203-0635x76146 | 001-199-446-3860x3486 | colinalvarado@miles.net     | 2021-04-17          | https://goodwin-ingram.com/ |\n```\n\n----------------------------------------\n\nTITLE: Using VERIFY_GROUP_FOR_USER Function for User Group Validation in SQL\nDESCRIPTION: Examples of VERIFY_GROUP_FOR_USER function usage, which returns 1 when a user is in a specified group and 0 otherwise. This function is primarily used with RCAC permissions and masks to control data access.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.md#2025-04-21_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nVERIFY_GROUP_FOR_USER (CURRENT_USER, 'MGR') VERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR') VERIFY_GROUP_FOR_USER (CURRENT_USER, 'JANE', 'MGR', 'STEVE') The following function invocation returns a value of 0: VERIFY_GROUP_FOR_USER (CURRENT_USER, 'JUDY', 'TONY')\n```\n\n----------------------------------------\n\nTITLE: Using Docling with SmolDocling VLM via CLI\nDESCRIPTION: Command to use Docling with SmolDocling visual language model for document processing, which utilizes MLX acceleration on supported Apple Silicon hardware.\nSOURCE: https://github.com/docling-project/docling/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocling --pipeline vlm --vlm-model smoldocling https://arxiv.org/pdf/2206.01062\n```\n\n----------------------------------------\n\nTITLE: Creating Row Permissions in SQL for DB2 on IBM i\nDESCRIPTION: The SQL CREATE PERMISSION statement is used to define and initially enable or disable row access control rules in DB2 for i. This statement is part of the Row and Column Access Control (RCAC) functionality.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.md#2025-04-21_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE PERMISSION\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading DoclingDocument as JSON\nDESCRIPTION: How to serialize a DoclingDocument to JSON and deserialize it back using Pydantic in Docling v2.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Save to disk:\ndoc: DoclingDocument = conv_res.document # produced from conversion result...\n\nwith Path(\"./doc.json\").open(\"w\") as fp:\n    fp.write(json.dumps(doc.export_to_dict())) # use `export_to_dict` to ensure consistency\n\n# Load from disk:\nwith Path(\"./doc.json\").open(\"r\") as fp:\n    doc_dict = json.loads(fp.read())\n    doc = DoclingDocument.model_validate(doc_dict) # use standard pydantic API to populate doc\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Structure in Markdown\nDESCRIPTION: A markdown representation of a simple table structure with numerical cell values. The table contains 5 rows and 5 columns with some empty cells, demonstrating how table structures can be represented in markdown format.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 0   | 1 2 1   | 1 2 1   |   1 2 1 |   1 2 1 |\n|-----|---------|---------|---------|---------|\n| 3   | 4 3     | 5       |       6 |       7 |\n| 8 2 | 9       | 10      |      11 |      12 |\n| 13  |         | 14      |      15 |      16 |\n| 17  | 18      |         |      19 |      20 |\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Markdown Table with Rowspan and Colspan\nDESCRIPTION: This markdown snippet demonstrates how to create a table with merged cells using rowspan and colspan. It includes a header row and three data rows with various cell merging patterns.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/example_05.html.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Header 1                   | Header 2 & 3 (colspan)     | Header 2 & 3 (colspan)     |\n|----------------------------|----------------------------|----------------------------|\n| Row 1 & 2, Col 1 (rowspan) | Row 1, Col 2               | Row 1, Col 3               |\n| Row 1 & 2, Col 1 (rowspan) | Row 2, Col 2 & 3 (colspan) | Row 2, Col 2 & 3 (colspan) |\n| Row 3, Col 1               | Row 3, Col 2               | Row 3, Col 3               |\n```\n\n----------------------------------------\n\nTITLE: RNA Sequencing Read Mapping Configuration\nDESCRIPTION: Configuration for mapping RNA-seq reads to mouse genome using Tophat with specific mapping settings to handle multiple read locations\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nTophat settings: --I 200000 g 1\n```\n\n----------------------------------------\n\nTITLE: Activating Poetry virtual environment\nDESCRIPTION: Command to activate a Poetry-managed virtual environment. This spawns a new shell with the environment activated, creating one if it doesn't exist.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npoetry shell\n```\n\n----------------------------------------\n\nTITLE: Markdown Multiplication Table\nDESCRIPTION: A markdown table displaying a 4-column multiplication pattern where each column multiplies the row number by increasing factors.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test-01.xlsx.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|   col-1 |   col-2 |   col-3 |   col-4 |\n|---------|---------|---------|----------|\n|       1 |       2 |       3 |       4 |\n|       2 |       4 |       6 |       8 |\n|       3 |       6 |       9 |      12 |\n|       4 |       8 |      12 |      16 |\n|       5 |      10 |      15 |      20 |\n|       6 |      12 |      18 |      24 |\n|       7 |      14 |      21 |      28 |\n|       8 |      16 |      24 |      32 |\n```\n\n----------------------------------------\n\nTITLE: Granting RCAC Administration Authorization using CL Command\nDESCRIPTION: Example of using CHGFCNUSG command to grant authorization for administering and managing RCAC rules to a specific user.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/redp5110_sampled.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: CL\nCODE:\n```\nCHGFCNUSG FCNID(QIBM_DB_SECADM) USER(HBEDOYA) USAGE(*ALLOWED)\n```\n\n----------------------------------------\n\nTITLE: Inserting Image Placeholder Comment in HTML\nDESCRIPTION: HTML comment used as an image placeholder in markdown documentation. This pattern appears twice in the document to indicate where actual images would be placed.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/picture_classification.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<!-- image -->\n```\n\n----------------------------------------\n\nTITLE: Registering Docling Plugin in pyproject.toml\nDESCRIPTION: Defines the entrypoint for a Docling plugin in a pyproject.toml file. This method is used for modern Python packaging.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/concepts/plugins.md#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[project.entry-points.\"docling\"]\nyour_plugin_name = \"your_package.module\"\n```\n\n----------------------------------------\n\nTITLE: Markdown Labeled Headers Table\nDESCRIPTION: A markdown table with labeled headers showing numerical sequences with text headers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test-01.xlsx.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n| first    | header   | header   |\n|----------|----------|----------|\n| first    | second   | third    |\n| 1        | 2        | 3        |\n| 3        | 4        | 5        |\n| 3        | 6        | 7        |\n| 8        | 9        | 9        |\n| 10       | 9        | 9        |\n```\n\n----------------------------------------\n\nTITLE: Taylor Series Expansion of (1+x)^n with LaTeX\nDESCRIPTION: A block-level LaTeX equation showing the Taylor series expansion of (1+x)^n, also known as the binomial series.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_4\n\nLANGUAGE: LaTeX\nCODE:\n```\n$$\\left(1+x\\right)^{n}=1+\\frac{nx}{1!}+\\frac{n\\left(n-1\\right)x^{2}}{2!}+ \\text{ \\textellipsis }$$\n```\n\n----------------------------------------\n\nTITLE: Deploying documentation to GitHub Pages\nDESCRIPTION: Command to build and deploy the documentation to GitHub Pages using MkDocs' built-in deployment functionality.\nSOURCE: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nmkdocs gh-deploy\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Hybrid Chunking in Python\nDESCRIPTION: This snippet installs the necessary libraries (docling and transformers) for implementing hybrid chunking.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/hybrid_chunking.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU docling transformers\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Horizontal Spans\nDESCRIPTION: This code snippet shows a Markdown table with horizontal cell spans.  Columns are merged by repeating the cell content across multiple columns.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_tables.docx.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n\"| Header 0.0   | Header 0.1          | Header 0.2          |\n|--------------|---------------------|---------------------|\n| Cell 1.0     | Merged Cell 1.1 1.2 | Merged Cell 1.1 1.2 |\n| Cell 2.0     | Merged Cell 2.1 2.2 | Merged Cell 2.1 2.2 |\"\n```\n\n----------------------------------------\n\nTITLE: Creating Character Names Comparison Table in HTML\nDESCRIPTION: HTML table structure displaying the names of famous Disney duck characters in different languages. Includes Scrooge McDuck and his nephews Huey, Dewey, and Louie with their respective names in German, French, and Italian.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/md/mixed.md#2025-04-21_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<table>\n  <tr>\n    <th>Character</th>\n    <th>Name in German</th>\n    <th>Name in French</th>\n    <th>Name in Italian</th>\n  </tr>\n  <tr>\n    <td>Scrooge McDuck</td>\n    <td>Dagobert Duck</td>\n    <td>Balthazar Picsou</td>\n    <td>Paperone</td>\n  </tr>\n  <tr>\n    <td>Huey</td>\n    <td>Tick</td>\n    <td>Riri</td>\n    <td>Qui</td>\n  </tr>\n  <tr>\n    <td>Dewey</td>\n    <td>Trick</td>\n    <td>Fifi</td>\n    <td>Quo</td>\n  </tr>\n  <tr>\n    <td>Louie</td>\n    <td>Track</td>\n    <td>Loulou</td>\n    <td>Qua</td>\n  </tr>\n</table>\n```\n\n----------------------------------------\n\nTITLE: Markdown Table - Vertical Spans\nDESCRIPTION: This Markdown table illustrates vertical cell spans.  Rows are merged by repeating the same cell content in subsequent rows of a column.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/word_tables.docx.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n\"| Header 0.0   | Header 0.1          | Header 0.2   |\n|--------------|---------------------|--------------|\n| Cell 1.0     | Merged Cell 1.1 2.1 | Cell 1.2     |\n| Cell 2.0     | Merged Cell 1.1 2.1 | Cell 2.2     |\n| Cell 3.0     | Merged Cell 3.1 4.1 | Cell 3.2     |\n| Cell 4.0     | Merged Cell 3.1 4.1 | Cell 4.2     |\"\n```\n\n----------------------------------------\n\nTITLE: Fluorescent Material Composition Formula\nDESCRIPTION: This formula represents the chemical composition of the second fluorescent material. Ln represents at least one rare earth element (excluding Ce), M is at least one element selected from Al, Ga, and In, and x and y are parameters within specified ranges that control the doping levels of Ce and Cr, respectively. The formula describes a garnet structure that provides stability and efficient light absorption.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n\"(Ln₁₋ₓ₋yCeₓCry)₃M₅O₁₂ (1)\"\n\n```\n\n----------------------------------------\n\nTITLE: Dye-Antibody Complex Formation and Purification\nDESCRIPTION: This snippet describes the procedure for generating a dye-antibody complex using a labeling agent (dye No. 29), an antibody solution, and WSC as a reagent.  The resulting complex is then separated and purified using gel filtration chromatography. Absorbance measurements are taken to calculate the dye to antibody molar ratio.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nAnti-human CRP sheep serum (IgG fraction; manufactured by Cooper Biomedical\n      Inc.) was diluted with PBS, pH 7.2, to a concentration of 0.5 mg/ml, to\n      prepare an antibody solution. To 8 ml of the antibody solution were added\n      0.2 mg of a labeling agent No. 29 of Table 5 (.lambda.max=819 nm) and 0.09\n      g of WSC for reaction at room temperature for three hours, to generate a\n      dye-antibody complex. The dye-antibody complex was separated and purified\n      from unreacted substances by gel filtration chromatography on a column\n      packed with Sepharose 6B. The molar ratio of the dye and the antibody in\n      the complex thus obtained was 2.5:1. By using a spectrophotometer,\n      Shimadzu UV-3100S, the absorbance of the complex was measured at\n      wavelength .lambda.=819 nm and .lambda.=280 nm, separately, to calculate\n      the molar ratio of the dye and the antibody.\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation - Compound Specifications\nDESCRIPTION: Chemical notation describing molecular structures of various compounds including atomic groups, subscripts, and ionic components.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_16\n\nLANGUAGE: chemical-notation\nCODE:\n```\nR'.sub.15 = R'.sub.18 = R'.sub.20 = HR'.sub.16 = NO.sub.2R'.sub.17 = R'.sub.19 = R'.sub.21 = CH.sub.3r = 3\n```\n\n----------------------------------------\n\nTITLE: Chemical Formula - Spacer Groups\nDESCRIPTION: Chemical notation for spacer groups used to prevent steric hindrance between labeling agents and biological substances.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_17\n\nLANGUAGE: chemical-notation\nCODE:\n```\n##STR35## (n=0, 1 to 16)\n```\n\n----------------------------------------\n\nTITLE: Binomial Theorem Expansion with LaTeX\nDESCRIPTION: A block-level LaTeX equation representing the binomial theorem expansion for (x+a)^n using summation notation.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_3\n\nLANGUAGE: LaTeX\nCODE:\n```\n$$\\left(x+a\\right)^{n}=\\sum_{k=0}^{n}\\left(\\genfrac{}{}{0pt}{}{n}{k}\\right)x^{k}a^{n-k}$$\n```\n\n----------------------------------------\n\nTITLE: Exporting in Legacy Format\nDESCRIPTION: How to export documents in the deprecated Docling v1 format for backward compatibility.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n## Export legacy document representation to desired format, for v1 compatibility:\nprint(json.dumps(conv_res.legacy_document.export_to_dict()))\nprint(conv_res.legacy_document.export_to_markdown())\nprint(conv_res.legacy_document.export_to_document_tokens())\n```\n\n----------------------------------------\n\nTITLE: Accessing Legacy Document Representation\nDESCRIPTION: How to access the deprecated Docling v1 document representation in Docling v2 for backward compatibility.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/v2.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconv_result.legacy_document # provides the representation in previous ExportedCCSDocument type\n```\n\n----------------------------------------\n\nTITLE: JATS XML Article Structure Definition\nDESCRIPTION: XML document declaring a research article using the JATS DTD with MathML3 specification. Contains comprehensive metadata including journal information, article identifiers, subject categories, title information, and author details.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<!DOCTYPE article\nPUBLIC \"-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN\" \"JATS-archivearticle1-mathml3.dtd\">\n<article xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" article-type=\"research-article\"><?properties open_access?><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">PLoS Negl Trop Dis</journal-id><journal-id journal-id-type=\"iso-abbrev\">PLoS Negl Trop Dis</journal-id><journal-id journal-id-type=\"publisher-id\">plos</journal-id><journal-id journal-id-type=\"pmc\">plosntds</journal-id><journal-title-group><journal-title>PLoS Neglected Tropical Diseases</journal-title></journal-title-group><issn pub-type=\"ppub\">1935-2727</issn><issn pub-type=\"epub\">1935-2735</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta>\n```\n\n----------------------------------------\n\nTITLE: CRISPR Guide RNA Sequences for Chromosome Targeting\nDESCRIPTION: Collection of guide RNA sequences used for CRISPR/Cas9-mediated knockout of specific chromosomal regions. Includes targeting sequences for chromosomes 2, 4, 10, and 13.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/elife-56337.txt#2025-04-21_snippet_1\n\nLANGUAGE: DNA\nCODE:\n```\nGCCGTTGCTCAGTCCAAATG\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGATACCAGAGGTGGCCGCAAG\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGCAAAGGGGCTCCTCGATGGA\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGTTTATGGCCGTGCTAAGGTC\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGTTGCCTTCATCCCACCGTG\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGAAGTTCGACTTGGACGGGCT\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGTAACCCATCATGGGCCCTAC\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGGACAGGTTATAGGTTTGAT\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGGGTTTCTGAGAAACGTGTA\n```\n\nLANGUAGE: DNA\nCODE:\n```\nGTGTAATGAGTTCTTATATC\n```\n\n----------------------------------------\n\nTITLE: Markdown Numerical Sequence Table\nDESCRIPTION: A markdown table showing three columns with numerical sequences where 'first' increases linearly, 'second' decreases linearly, and 'third' follows a geometric pattern.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test-01.xlsx.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n|   first  |   second  |   third |\n|----------|-----------|----------|\n|        1 |         5 |       9 |\n|        2 |         4 |       6 |\n|        3 |         3 |       3 |\n|        4 |         2 |       0 |\n|        5 |         1 |      -3 |\n|        6 |         0 |      -6 |\n```\n\n----------------------------------------\n\nTITLE: Referencing LaTeX in Document Layout Analysis\nDESCRIPTION: Mentions the use of LaTeX as a source format for scientific documents in existing datasets like DocBank. This is not a code snippet, but a reference to LaTeX in the context of document layout analysis.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2206.01062.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: LaTeX\nCODE:\n```\nL A T E X\n```\n\n----------------------------------------\n\nTITLE: Markdown Formatted Headers Table\nDESCRIPTION: A markdown table with formatted headers (f) showing similar structure to the previous table but with modified header formatting.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test-01.xlsx.md#2025-04-21_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n| first (f)   | header (f)   | header (f)   |\n|-------------|--------------|-------------|\n| first (f)   | second       | third        |\n| 1           | 2            | 3            |\n| 3           | 4            | 5            |\n| 3           | 6            | 7            |\n| 8           | 9            | 9            |\n| 10          | 9            | 9            |\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 9\nDESCRIPTION: Chemical structure notation for a substituent in the ninth entry of Table 1, showing an R' value configuration for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_9\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR14##\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Markdown Table with 5 Columns\nDESCRIPTION: This code snippet demonstrates how to format a simple table in markdown. The table contains 5 columns (with headers 1-4 and a blank header) and 4 rows of data populated with letters.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-too-many-columns.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 1   | 2   | 3   | 4   |    |\n|-----|-----|-----|-----|----|\\n| a   | b   | c   | d   |    |\n| a   | b   | c   | d   | e  |\n| a   | b   | c   | d   |    |\n| a   | b   | c   | d   |    |\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Data Table in Markdown\nDESCRIPTION: A markdown table with 4 rows and 4 columns containing simple letter values. The first row establishes column headers (1, 2, 3), followed by rows of data containing letters a, b, c, and d arranged in a consistent pattern.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/csv-inconsistent-header.csv.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| 1   | 2   | 3   |    |\n|-----|-----|-----|----|  \n| a   | b   | c   | d  |\n| a   | b   | c   | d  |\n| a   | b   | c   | d  |\n| a   | b   | c   | d  |\n```\n\n----------------------------------------\n\nTITLE: Displaying Table Dataset Comparison in Markdown\nDESCRIPTION: A markdown table comparing different table datasets (PubTabNet, FinTabNet, TableBank, etc.) with their attributes including tag support, bounding box availability, dataset size, and file format.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|                    |   Tags |   Bbox | Size   | Format   |\n|--------------------|--------|--------|--------|----------|\n| PubTabNet          |      3 |      3 | 509k   | PNG      |\n| FinTabNet          |      3 |      3 | 112k   | PDF      |\n| TableBank          |      3 |      7 | 145k   | JPEG     |\n| Combined-Tabnet(*) |      3 |      3 | 400k   | PNG      |\n| Combined(**)       |      3 |      3 | 500k   | PNG      |\n| SynthTabNet        |      3 |      3 | 600k   | PNG      |\n```\n\n----------------------------------------\n\nTITLE: Model Performance with Different Label Sets\nDESCRIPTION: Performance comparison table showing mAP@0.5-0.95 scores for Mask R-CNN R50 network trained with different class label configurations through label down-mapping or dropping.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2206.01062.doctags.txt#2025-04-21_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nClass-count    11      6       5       4\nCaption       68      Text    Text    Text\nFootnote      71      Text    Text    Text\nFormula       60      Text    Text    Text\nList-item     81      Text    82      Text\nPage-footer   62      62      -       -\nPage-header   72      68      -       -\nPicture       72      72      72      72\nSection-header 68     67      69      68\nTable         82      83      82      82\nText          85      84      84      84\nTitle         77      Sec.-h. Sec.-h. Sec.-h.\nOverall       72      73      78      77\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Configuration for RAG Pipeline\nDESCRIPTION: This code sets up the environment variables, configures paths, and defines parameters for the RAG pipeline. It includes functions to retrieve environment variables from Colab or OS, and sets up model IDs and export types.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_haystack.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\n\nfrom docling_haystack.converter import ExportType\nfrom dotenv import load_dotenv\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\nHF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\nPATHS = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\nEMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\nGENERATION_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\nEXPORT_TYPE = ExportType.DOC_CHUNKS\nQUESTION = \"Which are the main AI models in Docling?\"\nTOP_K = 3\nMILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment Variables for Azure Services\nDESCRIPTION: Loads environment variables for Azure AI Search and Azure OpenAI services, including endpoints, API keys, and model names.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\ndef _get_env(key, default=None):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key, default)\n\n\nAZURE_SEARCH_ENDPOINT = _get_env(\"AZURE_SEARCH_ENDPOINT\")\nAZURE_SEARCH_KEY = _get_env(\"AZURE_SEARCH_KEY\")  # Ensure this is your Admin Key\nAZURE_SEARCH_INDEX_NAME = _get_env(\"AZURE_SEARCH_INDEX_NAME\", \"docling-rag-sample\")\nAZURE_OPENAI_ENDPOINT = _get_env(\"AZURE_OPENAI_ENDPOINT\")\nAZURE_OPENAI_API_KEY = _get_env(\"AZURE_OPENAI_API_KEY\")\nAZURE_OPENAI_API_VERSION = _get_env(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\nAZURE_OPENAI_CHAT_MODEL = _get_env(\n    \"AZURE_OPENAI_CHAT_MODEL\"\n)  # Using a deployed model named \"gpt-4o\"\nAZURE_OPENAI_EMBEDDINGS = _get_env(\n    \"AZURE_OPENAI_EMBEDDINGS\", \"text-embedding-3-small\"\n)  # Using a deployed model named \"text-embeddings-3-small\"\n```\n\n----------------------------------------\n\nTITLE: Journal Reference in XML\nDESCRIPTION: This XML code represents a journal reference, capturing the author's name, article title, publication source, year, and volume number.  It is a structured way to store bibliographic information.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pntd.0008301.txt#2025-04-21_snippet_6\n\nLANGUAGE: xml\nCODE:\n```\n<mixed-citation publication-type=\"journal\"><name><surname>Webber</surname><given-names>R.</given-names></name>\n<article-title>Eradication of Wuchereria bancrofti infection through vector control</article-title>. <source>Trans R Soc Trop Med Hyg</source>. <year>1979</year>;<volume>73</volume>.</mixed-citation>\n```\n\n----------------------------------------\n\nTITLE: Setting Up Environment and Importing Libraries for RAG\nDESCRIPTION: This code sets up the environment by importing necessary libraries, loading environment variables, and configuring warnings. It also defines a helper function to retrieve environment variables from Colab or OS.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_llamaindex.ipynb#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom pathlib import Path\nfrom tempfile import mkdtemp\nfrom warnings import filterwarnings\n\nfrom dotenv import load_dotenv\n\n\ndef _get_env_from_colab_or_os(key):\n    try:\n        from google.colab import userdata\n\n        try:\n            return userdata.get(key)\n        except userdata.SecretNotFoundError:\n            pass\n    except ImportError:\n        pass\n    return os.getenv(key)\n\n\nload_dotenv()\n\nfilterwarnings(action=\"ignore\", category=UserWarning, module=\"pydantic\")\nfilterwarnings(action=\"ignore\", category=FutureWarning, module=\"easyocr\")\n# https://github.com/huggingface/transformers/issues/5486:\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n```\n\n----------------------------------------\n\nTITLE: Defining TableFormer Loss Function in Python\nDESCRIPTION: This snippet defines the multi-task loss function used to train the TableFormer model. It combines cross-entropy loss for structure prediction and L1/IoU losses for bounding box detection.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nL = λ * l_s + (1 - λ) * l_box\nwhere l_box = λ_iou * l_iou + λ_l1 * l_l1\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for RAG with Azure AI Search\nDESCRIPTION: Installs necessary Python packages including docling, azure-search-documents, azure-identity, openai, rich, torch, and python-dotenv.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/examples/rag_azuresearch.ipynb#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"docling~=2.12\" azure-search-documents==11.5.2 azure-identity openai rich torch python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Computing Content Alignment Formula for TableFormer Post-Processing\nDESCRIPTION: Formula used to identify the best-fitting content alignment (left, centroid, or right) for predicted cells in a table column. This helps in determining the proper positioning of content during the post-processing phase.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/2203.01017v2.md#2025-04-21_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- formula-not-decoded -->\n\nwhere c is one of { left, centroid, right } and x$\\_{c}$ is the xcoordinate for the corresponding point.\n```\n\n----------------------------------------\n\nTITLE: Displaying Centered Docling Ecosystem Image in HTML\nDESCRIPTION: This HTML snippet centers an image of the Docling ecosystem, setting its width to 100% and using lazy loading for performance optimization.\nSOURCE: https://github.com/docling-project/docling/blob/main/docs/integrations/index.md#2025-04-21_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<p align=\"center\">\n  <img loading=\"lazy\" alt=\"Docling\" src=\"../assets/docling_ecosystem.png\" width=\"100%\" />\n</p>\n```\n\n----------------------------------------\n\nTITLE: Defining OTSL Syntax Rules for Table Structure\nDESCRIPTION: The syntax rules that govern the OTSL representation, ensuring valid table structures by defining relationships between cells and their neighbors.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- 1. Left-looking cell rule : The left neighbour of an \"L\" cell must be either another \"L\" cell or a \"C\" cell.\n\n- 2. Up-looking cell rule : The upper neighbour of a \"U\" cell must be either another \"U\" cell or a \"C\" cell.\n```\n\n----------------------------------------\n\nTITLE: Differential Equations for HIV Population Dynamics in LaTeX\nDESCRIPTION: System of differential equations describing the rates of transition between population classes in an HIV transmission model. Includes equations for susceptible, infected (stages A and B), and AIDS populations.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pnas_sample.xml.md#2025-04-21_snippet_1\n\nLANGUAGE: latex\nCODE:\n```\n$$ \\frac{dS_{i,j}(t)}{dt}={\\chi}_{i,j}(t)-{\\mu}_{j}S_{i,j}(t)-{\\lambda}_{\\hat {\\imath},\\hat {},\\hat {k}{\\rightarrow}i,j}S_{i,j}(t), $$\n\n$$ \\hspace{1em}\\hspace{1em}\\hspace{.167em}\\frac{dI_{i,j,A}(t)}{dt}={\\lambda}_{\\hat {\\imath},\\hat {},\\hat {k}{\\rightarrow}i,j}S_{i,j}(t)-{\\mu}_{j}I_{i,j,A}(t)-{\\gamma}_{i,j,A}I_{i,j,A}(t), $$\n\n$$ \\frac{dI_{i,j,B}(t)}{dt}={\\gamma}_{i,j,A}I_{i,j,A}(t)-{\\mu}_{j}I_{i,j,B}(t)-{\\gamma}_{i,j,B}I_{i,j,B}(t), $$\n\n$$ \\frac{dA(t)}{dt}={\\gamma}_{i,j,B} \\left( { \\,\\substack{ ^{3} \\\\ {\\sum} \\\\ _{i=1} }\\, }I_{i,F,B}(t)+I_{i,M,B}(t) \\right) -{\\mu}_{A}A(t)-{\\delta}A(t), $$\n```\n\n----------------------------------------\n\nTITLE: Clustering Retrotransposon-Associated Reads with BEDTools\nDESCRIPTION: Command for clustering genomic coordinates of reads associated with ETn and RLTR4 retrotransposons using BEDTools. This step helps identify potential new insertion sites by grouping reads within 1000bp of each other.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nbedtools merge -i -n -d 1000\n```\n\n----------------------------------------\n\nTITLE: Mapping Paired-End Reads with Bowtie for Retrotransposon Analysis\nDESCRIPTION: Command for mapping uniquely mappable, non-duplicated reads using Bowtie with strict parameters followed by SAMtools for duplicate removal. This is part of the capture-seq analysis workflow for identifying retrotransposon insertions.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/elife-56337.xml.md#2025-04-21_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nBowtie -m 1 --best --strata; samtools rmdup -s\n```\n\n----------------------------------------\n\nTITLE: Calculating Tree-Edit-Distance-Based Similarity (TEDS) in Python\nDESCRIPTION: This code snippet shows the formula for calculating the Tree-Edit-Distance-Based Similarity (TEDS) metric, which is used to evaluate table structure predictions against ground truth.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nTEDS(T_a, T_b) = 1 - EditDist(T_a, T_b) / max(|T_a|, |T_b|)\n```\n\n----------------------------------------\n\nTITLE: Creating a Complex Data Table with Rowspan and Colspan in Markdown\nDESCRIPTION: This snippet demonstrates how to create a table in Markdown that includes cells spanning multiple rows (rowspan) and columns (colspan). The table has three columns and three rows, with various cell merges to showcase different layouts.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/example_04.html.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Header 1                   | Header 2 & 3 (colspan)     | Header 2 & 3 (colspan)     |\n|----------------------------|----------------------------|----------------------------|\n| Row 1 & 2, Col 1 (rowspan) | Row 1, Col 2               | Row 1, Col 3               |\n| Row 1 & 2, Col 1 (rowspan) | Row 2, Col 2 & 3 (colspan) | Row 2, Col 2 & 3 (colspan) |\n| Row 3, Col 1               | Row 3, Col 2               | Row 3, Col 3               |\n```\n\n----------------------------------------\n\nTITLE: Displaying Japanese Table Example in Markdown\nDESCRIPTION: This markdown table presents a Japanese language example showing TableFormer's language-agnostic capabilities. The table contains citation sources, file counts, and reference counts for Japanese and English papers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n|                                                    |             | 論文ファイル   | 論文ファイル   | 参考文献   | 参考文献   |\n|----------------------------------------------------|-------------|----------------|----------------|------------|------------|\n| 出典                                               | ファイル 数 | 英語           | 日本語         | 英語       | 日本語     |\n| Association for Computational Linguistics(ACL2003) | 65          | 65             | 0              | 150        | 0          |\n| Computational Linguistics(COLING2002)              | 140         | 140            | 0              | 150        | 0          |\n| 電気情報通信学会 2003 年総合大会                   | 150         | 8              | 142            | 223        | 147        |\n| 情報処理学会第 65 回全国大会 (2003)                | 177         | 1              | 176            | 150        | 236        |\n| 第 17 回人工知能学会全国大会 (2003)                | 208         | 5              | 203            | 152        | 244        |\n| 自然言語処理研究会第 146 〜 155 回                 | 98          | 2              | 96             | 150        | 232        |\n| WWW から収集した論文                               | 107         | 73             | 34             | 147        | 96         |\n| 計                                                 | 945         | 294            | 651            | 1122       | 955        |\n```\n\n----------------------------------------\n\nTITLE: Displaying Structure with Content Results in Markdown\nDESCRIPTION: This markdown table shows results of structure prediction with content retrieval comparing TableFormer with existing tools (Tabula, Traprange, Camelot, Acrobat Pro, EDD) on PubTabNet using TEDS metric for simple, complex, and all tables.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.md#2025-04-21_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n| Model       |   Simple |   TEDS Complex |   All |\n|-------------|----------|----------------|-------|\n| Tabula      |     78   |           57.8 |  67.9 |\n| Traprange   |     60.8 |           49.9 |  55.4 |\n| Camelot     |     80   |           66   |  73   |\n| Acrobat Pro |     68.9 |           61.8 |  65.3 |\n| EDD         |     91.2 |           85.4 |  88.3 |\n| TableFormer |     95.4 |           90.1 |  93.6 |\n```\n\n----------------------------------------\n\nTITLE: Displaying DocLayNet Dataset Overview Table in Markdown\nDESCRIPTION: This code snippet shows a markdown table presenting the DocLayNet dataset overview. It includes class label frequencies, distribution across train/test/validation sets, and inter-annotator agreement scores for different document categories.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2206.01062.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| | | % of Total | % of Total | % of Total | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) | triple inter-annotator mAP @ 0.5-0.95 (%) |\n|----------------|---------|--------------|--------------|--------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n| class label | Count | Train | Test | Val | All | Fin | Man | Sci | Law | Pat | Ten |\n| Caption | 22524 | 2.04 | 1.77 | 2.32 | 84-89 | 40-61 | 86-92 | 94-99 | 95-99 | 69-78 | n/a |\n| Footnote | 6318 | 0.60 | 0.31 | 0.58 | 83-91 | n/a | 100 | 62-88 | 85-94 | n/a | 82-97 |\n| Formula | 25027 | 2.25 | 1.90 | 2.96 | 83-85 | n/a | n/a | 84-87 | 86-96 | n/a | n/a |\n| List-item | 185660 | 17.19 | 13.34 | 15.82 | 87-88 | 74-83 | 90-92 | 97-97 | 81-85 | 75-88 | 93-95 |\n| Page-footer | 70878 | 6.51 | 5.58 | 6.00 | 93-94 | 88-90 | 95-96 | 100 | 92-97 | 100 | 96-98 |\n| Page-header | 58022 | 5.10 | 6.70 | 5.06 | 85-89 | 66-76 | 90-94 | 98-100 | 91-92 | 97-99 | 81-86 |\n| Picture | 45976 | 4.21 | 2.78 | 5.31 | 69-71 | 56-59 | 82-86 | 69-82 | 80-95 | 66-71 | 59-76 |\n| Section-header | 142884 | 12.60 | 15.77 | 12.85 | 83-84 | 76-81 | 90-92 | 94-95 | 87-94 | 69-73 | 78-86 |\n| Table | 34733 | 3.20 | 2.27 | 3.60 | 77-81 | 75-80 | 83-86 | 98-99 | 58-80 | 79-84 | 70-85 |\n| Text | 510377 | 45.82 | 49.28 | 45.00 | 84-86 | 81-86 | 88-93 | 89-93 | 87-92 | 71-79 | 87-95 |\n| Title | 5071 | 0.47 | 0.30 | 0.50 | 60-72 | 24-63 | 50-63 | 94-100 | 82-96 | 68-79 | 24-56 |\n| Total | 1107470 | 941123 | 99816 | 66531 | 82-83 | 71-74 | 79-81 | 89-94 | 86-91 | 71-76 | 68-85 |\n```\n\n----------------------------------------\n\nTITLE: Displaying mAP Scores for Different Label Sets in Markdown\nDESCRIPTION: This markdown table shows the performance (mAP@0.5-0.95 scores) of a Mask R-CNN R50 network trained on DocLayNet with different class label sets. It demonstrates how reducing the number of labels affects the model's performance for each class and overall.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2206.01062.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n| Class-count    |   11 | 6       | 5       | 4       |\n|----------------|------|---------|---------|---------|\n| Caption        |   68 | Text    | Text    | Text    |\n| Footnote       |   71 | Text    | Text    | Text    |\n| Formula        |   60 | Text    | Text    | Text    |\n| List-item      |   81 | Text    | 82      | Text    |\n| Page-footer    |   62 | 62      | -       | -       |\n| Page-header    |   72 | 68      | -       | -       |\n| Picture        |   72 | 72      | 72      | 72      |\n| Section-header |   68 | 67      | 69      | 68      |\n| Table          |   82 | 83      | 82      | 82      |\n| Text           |   85 | 84      | 84      | 84      |\n| Title          |   77 | Sec.-h. | Sec.-h. | Sec.-h. |\n| Overall        |   72 | 73      | 78      | 77      |\n```\n\n----------------------------------------\n\nTITLE: Performance Comparison Table - Hyperparameter Optimization Results\nDESCRIPTION: Markdown table showing comparative results of OTSL and HTML representations across different encoder-decoder layer configurations, measuring TED scores for simple and complex tables, mAP scores, and inference times\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1-pg9.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| # enc-layers   | # dec-layers   | Language   | TEDs        | TEDs        | TEDs        | mAP         | Inference   |\n|----------------|----------------|------------|-------------|-------------|-------------|-------------|-------------|\n| # enc-layers   | # dec-layers   | Language   | simple      | complex     | all         | (0.75)      | time (secs) |\n| 6              | 6              | OTSL HTML  | 0.965 0.969 | 0.934 0.927 | 0.955 0.955 | 0.88 0.857  | 2.73 5.39   |\n| 4              | 4              | OTSL HTML  | 0.938 0.952 | 0.904 0.909 | 0.927 0.938 | 0.853 0.843 | 1.97 3.77   |\n| 2              | 4              | OTSL HTML  | 0.923 0.945 | 0.897 0.901 | 0.915 0.931 | 0.859 0.834 | 1.91 3.81   |\n| 4              | 2              | OTSL HTML  | 0.952 0.944 | 0.92 0.903  | 0.942 0.931 | 0.857 0.824 | 1.22 2      |\n```\n\n----------------------------------------\n\nTITLE: Markdown Image Placeholders\nDESCRIPTION: HTML comments used as image placeholders to indicate where images should be displayed in the document\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/test_emf_docx.docx.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- image -->\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Addition Function in JavaScript\nDESCRIPTION: A simple JavaScript function that adds two numbers together and logs the result to the console. This example demonstrates basic function definition and usage in JavaScript.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/code_and_formula.doctags.txt#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nfunction add(a, b) { return a + b; } console.log(add(3, 5));\n```\n\n----------------------------------------\n\nTITLE: Controller Configuration with Processor and Memory\nDESCRIPTION: This snippet describes the controller's hardware components. The controller includes one or more processors and associated memory devices configured to perform computer-implemented functions. The memory device stores computer-readable instructions that, when executed by the processors, configure the controller to perform various actions.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20200022300.md#2025-04-21_snippet_0\n\nLANGUAGE: generic\nCODE:\n```\n\"In general, the controller 152 may comprise any suitable processor-based device known in the art, such as a computing device or any suitable combination of computing devices. Thus, in several embodiments, the controller 152 may include one or more processor(s) 154 and associated memory device(s) 156 configured to perform a variety of computer-implemented functions. As used herein, the term “processor” refers not only to integrated circuits referred to in the art as being included in a computer, but also refers to a controller, a microcontroller, a microcomputer, a programmable logic controller (PLC), an application specific integrated circuit, and other programmable circuits. Additionally, the memory device(s) 156 of the controller 152 may generally comprise memory element(s) including, but not limited to, a computer readable medium (e.g., random access memory (RAM)), a computer readable non-volatile medium (e.g., a flash memory), a floppy disk, a compact disc-read only memory (CD-ROM), a magneto-optical disk (MOD), a digital versatile disc (DVD) and/or other suitable memory elements. Such memory device(s) 156 may generally be configured to store suitable computer-readable instructions that, when implemented by the processor(s) 154, configure the controller 152 to perform various computer-implemented functions. In addition, the controller 152 may also include various other suitable components, such as a communications circuit or module, one or more input/output channels, a data/control bus and/or the like.\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Enteric CH4 Yield in Livestock (Markdown)\nDESCRIPTION: This snippet presents a formula for estimating enteric methane (CH4) yield in livestock based on neutral detergent fiber (NDF) concentration in the diet. The equation is derived from a study by Niu et al. and provides CH4 yield in grams per kilogram of dry matter intake.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pone.0234687.xml.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nCH4 yield (g (kg DM intake)-1) = 13.8 + 0.185 × NDF (% DM intake)\n```\n\n----------------------------------------\n\nTITLE: Calculating Circle Area with LaTeX (Inline)\nDESCRIPTION: An inline LaTeX equation for calculating the area of a circle using the formula A = πr².\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/equations.docx.md#2025-04-21_snippet_0\n\nLANGUAGE: LaTeX\nCODE:\n```\n$A= \\pi r^{2}$\n```\n\n----------------------------------------\n\nTITLE: Creating Row Permission Using SQL CREATE PERMISSION Statement\nDESCRIPTION: This SQL statement is used to define and initially enable or disable row access rules in IBM i. It demonstrates the syntax for creating a row permission, which is part of the Row and Column Access Control (RCAC) feature.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/redp5110_sampled.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: SQL\nCODE:\n```\nCREATE PERMISSION SQL statement\n```\n\n----------------------------------------\n\nTITLE: Calculating Energy-Corrected Milk (ECM) for Dairy Production Analysis\nDESCRIPTION: Formula for calculating Energy-Corrected Milk (ECM) based on milk production, fat percentage, and true protein percentage according to NRC standards. This standardizes milk production values for fair comparison across different feeding scenarios.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/jats/pone.0234687.txt#2025-04-21_snippet_0\n\nLANGUAGE: mathematical\nCODE:\n```\nECM = Milk production × (0.0929 × fat% + 0.0588× true protein% + 0.192) / (0.0929 × (4%) + 0.0588 × (3.3%) + 0.192)\n```\n\n----------------------------------------\n\nTITLE: Inactivating Bioluminescent E. coli with Zeocin™\nDESCRIPTION: Method for inactivating bioluminescent E. coli HB101 using Zeocin™ while preserving the cells' light-generating capability. The protocol covers growing the bacterial culture to exponential phase, treating with Zeocin™, and monitoring cell viability and light output over time.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pa20010031492.md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n1. Bioluminescent genetically modified E. coil strain HB101 (E. coli HB101 made bioluminescent by transformation with a plasmid carrying the lux operon of Vibrio fischeri constructed by the method of Shaw and Kado, as described in Biotechnology 4: 560-564) were grown from a frozen stock in 5 ml of low salt medium (LB (5 g/ml NaCl)+glycerol+MgSO₄) for 24 hours.\n\n2. 1 ml of the 5 ml culture was then used to inoculate 200 ml of low salt medium in a shaker flask and the resultant culture grown to an OD₆₃₀ of 0.407 (exponential growth phase).\n\n3. 50 ml of this culture was removed to a fresh sterile shaker flask (control cells).\n\n4. Zeocin™ was added to the 150 ml of culture in the original shaker flash, to a final concentration of 1.5 mg/ml. At the same time, an equivalent volume of water was added to the 50 ml culture removed from the original flask (control cells).\n\n5. The time course of cell inactivation was monitored by removing samples from the culture at 5, 60, 120, 180, 240 and 300 minutes after the addition of Zeocin™ and taking measurements of both light output (measured using a Deltatox luminometer) and viable count (per ml, determined using the method given in Example 3 below) for each of the samples. Samples of the control cells were removed at 5 and 300 minutes after the addition of water and measurements of light output and viable count taken as for the Zeocin™ treated cells.\n```\n\n----------------------------------------\n\nTITLE: OTSL Token Vocabulary Definition\nDESCRIPTION: The complete vocabulary of the Optimised Table Structure Language (OTSL), consisting of only 5 tokens that can efficiently represent complex table structures including spanning cells.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2305.03393v1.doctags.txt#2025-04-21_snippet_2\n\nLANGUAGE: OTSL\nCODE:\n```\n- -\"C\" cell a new table cell that either has or does not have cell content\n- -\"L\" cell left-looking cell , merging with the left neighbor cell to create a span\n- -\"U\" cell up-looking cell , merging with the upper neighbor cell to create a span\n- -\"X\" cell cross cell , to merge with both left and upper neighbor cells\n- -\"NL\" new-line , switch to the next row.\n```\n\n----------------------------------------\n\nTITLE: Producing Bioluminescent Assay Reagent from Inactivated E. coli\nDESCRIPTION: Protocol for processing Zeocin™-treated and control E. coli cultures into stabilized assay reagents. The method includes harvesting cells, washing to remove antibiotic traces, suspension in cryoprotectant, freeze-drying, and reconstitution. The resulting assay reagent maintains stable light output suitable for toxicity testing.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/pa20010031492.md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nFive hours after the addition of Zeocin™ or water the remaining bacterial cells in the Zeocin™ treated and control cultures were harvested by the centrifugation, washed (to remove traces of Zeocin™ from the Zeocin™ treated culture), re-centrifuged and resuspended in cryoprotectant to an OD₆₃₀ of 0.25. 200 μl aliquots of the cells in cryoprotectant were dispensed into single shot vials, and freeze dried. Freeze dried samples of the Zeocin™ treated cells and control cells were reconstituted in 0.2M sucrose to form assay reagents and the light output of the assay reagents measured at various times after reconstitution.\n```\n\n----------------------------------------\n\nTITLE: Constraints on Composition Parameters x and y\nDESCRIPTION: These inequalities define the permissible ranges for the parameters x and y in the fluorescent material's composition formula. The parameter 'x' represents the Ce doping level, and 'y' represents the Cr doping level. These constraints ensure optimal light emission intensity and prevent issues like concentration quenching or a decrease in light emission centers.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n\"0.0002&lt;x&lt;0.50\"\n\n```\n\nLANGUAGE: text\nCODE:\n```\n\"0.0001&lt;y&lt;0.05\"\n\n```\n\n----------------------------------------\n\nTITLE: Chemical Notation for Cerium and Chromium Compounds\nDESCRIPTION: Chemical formulas for example compounds containing cerium (Ce) and chromium (Cr) that can be used as raw materials for fluorescent materials. These specific oxide compounds are preferred due to their lack of extraneous elements.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_3\n\nLANGUAGE: chemical notation\nCODE:\n```\nCeO₂\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nCr₂O₃\n```\n\n----------------------------------------\n\nTITLE: Chemical Notation for Yellow Fluorescent Materials\nDESCRIPTION: Chemical formulas representing the composition of yellow fluorescent materials that can be used in light emitting devices. These materials emit yellow light when excited by the light emitting element.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v2/ipa20180000016.md#2025-04-21_snippet_6\n\nLANGUAGE: chemical notation\nCODE:\n```\nM¹⁴c/dSi₁₂₋₍c₊d₎Al₍c₊d₎OdN₍₁₆₋d₎:Eu (iv)\n```\n\nLANGUAGE: chemical notation\nCODE:\n```\nM¹⁵₃Al₅O₁₂:Ce (v)\n```\n\n----------------------------------------\n\nTITLE: Dye-Rectin Complex Formation and Purification\nDESCRIPTION: This describes the preparation of a dye-rectin complex using dye No. 40 and glutaraldehyde. The complex is purified using gel filtration, and spectrophotometry is used to determine the molar ratio of dye to rectin.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_20\n\nLANGUAGE: text\nCODE:\n```\nRectin.Concanavalin A (manufactured by E. Y. Laboratories Co. Ltd.) was\n      diluted with PBS to a concentration of 0.2 mg/ml, to prepare a rectin\n      solution. With 10 ml of the rectin solution were added 0.2 mg of a dye No.\n      40 of Table 5 (.lambda.max=805 nm) and 10 ml of 0.05 M sodium borate\n      buffer, pH 8.0 containing 1% glutaraldehyde at room temperature for one\n      hour. The dye-rectin complex was separated and purified on a gel\n      filtration chromatocolumn packed with Sepharose 6B. The molar ratio of the\n      dye and the rectin in the complex obtained was 1.7:1. The absorbances at\n      wavelengths .lambda.=805 and .lambda.=280 nm were measured by a\n      spectrophotometer Shimadzu UV-3100S, to calculate the molar ratio of the\n      dye and the rectin.\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 1, Row 11 (1)\nDESCRIPTION: First chemical structure notation for the eleventh entry of Table 1, showing an R' value configuration for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_12\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR17##\n```\n\n----------------------------------------\n\nTITLE: Chemical Structure Notation in Table 3, Row 16\nDESCRIPTION: Chemical structure notation for a substituent in the sixteenth entry of Table 3, representing part of the R_B configuration for an azulene dye compound.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_15\n\nLANGUAGE: chemical notation\nCODE:\n```\n##STR20##\n```\n\n----------------------------------------\n\nTITLE: Calculating Tree-Edit-Distance-Based Similarity (TEDS) Metric\nDESCRIPTION: Formula for computing the TEDS (Tree-Edit-Distance-Based Similarity) metric which represents the similarity between predicted and ground-truth table structures in HTML format. It uses tree edit distance normalized by tree sizes.\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/groundtruth/docling_v1/2203.01017v2.doctags.txt#2025-04-21_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nTEDS(T_a, T_b) = 1 - EditDist(T_a, T_b) / max(|T_a|, |T_b|)\n```\n\n----------------------------------------\n\nTITLE: Near-Infrared Labeling Complex Specification\nDESCRIPTION: Defines a complex for detecting biological compounds using optical means with near-infrared radiation, involving specific dye structures and substituent configurations\nSOURCE: https://github.com/docling-project/docling/blob/main/tests/data/uspto/pftaps057006474.txt#2025-04-21_snippet_1\n\nLANGUAGE: patent-description\nCODE:\n```\nComplex comprising: substance from living organism + labeling agent fixed onto substance, bonded to subject compound to be analyzed\n```"
  }
]