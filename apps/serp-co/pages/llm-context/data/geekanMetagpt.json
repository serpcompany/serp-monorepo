[
  {
    "owner": "geekan",
    "repo": "metagpt",
    "content": "TITLE: PRD Template Definition for Language Model Prompt\nDESCRIPTION: Defines a template for generating Product Requirement Documents (PRDs) with structured sections including introduction, goals, user scenarios, requirements, constraints, and performance metrics.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/prompts/generate_skill.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nPROMPT_TEMPLATE = \"\"\"\n# Requirements\n{requirements}\n\n# PRD\nCreate a product requirement document (PRD) based on the requirements and fill in the blanks below:\n\nProduct/Function Introduction:\n\nGoals:\n\nUsers and Usage Scenarios:\n\nRequirements:\n\nConstraints and Limitations:\n\nPerformance Metrics:\n\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: MetaGPT Configuration YAML Example\nDESCRIPTION: Example YAML configuration for MetaGPT showing how to set up the Large Language Model (LLM) settings, including API type, model selection, base URL, and API key.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nllm:\n  api_type: \"openai\"  # or azure / ollama / groq etc. Check LLMType for more options\n  model: \"gpt-4-turbo\"  # or gpt-3.5-turbo\n  base_url: \"https://api.openai.com/v1\"  # or forward url / other llm url\n  api_key: \"YOUR_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Web Scraping Startup Financing Information from 36kr in Python\nDESCRIPTION: This code snippet demonstrates how to scrape startup financing information from the 36kr website. It crawls the webpage, extracts key information using regular expressions, filters recent announcements, and saves the results to a CSV file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nfrom datetime import datetime, timedelta\nimport pandas as pd\n\n# 1. 爬取并本地保存html结构\nurl = 'https://pitchhub.36kr.com/financing-flash'\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, 'html.parser')\n\nwith open('36kr_financing.html', 'w', encoding='utf-8') as f:\n    f.write(str(soup))\n\n# 2. 打印第7个快讯关键词后2000个字符的html内容\nflash_news = soup.find_all('div', class_='flash-item')\nif len(flash_news) >= 7:\n    print(str(flash_news[6])[:2000])\n\n# 3. 设计正则表达式来获取快讯的标题、链接、时间\npattern = r'<a.*?href=\"(.*?)\".*?>(.*?)</a>.*?<span class=\"time\">(.*?)</span>'\n\n# 4. 筛选最近3天的初创企业融资快讯\ntoday = datetime.now()\nthree_days_ago = today - timedelta(days=3)\n\nrecent_news = []\nfor news in flash_news:\n    match = re.search(pattern, str(news), re.DOTALL)\n    if match:\n        link, title, time_str = match.groups()\n        news_date = datetime.strptime(time_str.strip(), '%m-%d %H:%M')\n        news_date = news_date.replace(year=today.year)\n        if news_date >= three_days_ago:\n            recent_news.append({\n                'title': title.strip(),\n                'link': link,\n                'time': time_str.strip()\n            })\n\n# 打印前5个结果\nprint(recent_news[:5])\n\n# 5. 将全部结果存在本地csv中\ndf = pd.DataFrame(recent_news)\ndf.to_csv('36kr_recent_financing.csv', index=False, encoding='utf-8-sig')\n```\n\n----------------------------------------\n\nTITLE: Initializing MetaGPT Configuration\nDESCRIPTION: Command to initialize the MetaGPT configuration file, which creates a config2.yaml file in the ~/.metagpt directory.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmetagpt --init-config  # it will create ~/.metagpt/config2.yaml, just modify it to your needs\n```\n\n----------------------------------------\n\nTITLE: Using MetaGPT as a Python Library\nDESCRIPTION: Python code example demonstrating how to use MetaGPT as a library to generate a software repository based on a simple requirement, and then print the repository structure.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.software_company import generate_repo\nfrom metagpt.utils.project_repo import ProjectRepo\n\nrepo: ProjectRepo = generate_repo(\"Create a 2048 game\")  # or ProjectRepo(\"<path>\")\nprint(repo)  # it will print the repo structure with files\n```\n\n----------------------------------------\n\nTITLE: Observing and Interacting with MetaGPT Environment in Python\nDESCRIPTION: This code snippet illustrates how to observe the environment and perform actions within a role's action set. It shows how to capture a screenshot and perform a tap action on the screen using the EnvAPIAbstract.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/environment/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.environment.api.env_api import EnvAPIAbstract\n\n# get screenshot from ExtEnv\nscreenshot_path: Path = await env.observe(\n            EnvAPIAbstract(\n                api_name=\"get_screenshot\", kwargs={\"ss_name\": f\"{round_count}_before\", \"local_save_dir\": task_dir}\n            )\n        )\n\n# do a `tap` action on the screen\nres = env.step(EnvAPIAbstract(\"system_tap\", kwargs={\"x\": x, \"y\": y}))\n```\n\n----------------------------------------\n\nTITLE: Using Official MetaGPT Docker Image\nDESCRIPTION: Commands for downloading the official MetaGPT Docker image, configuring it, and running a demo task. This snippet shows how to set up the necessary directories, map configuration files, and execute MetaGPT commands within a container.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/docker_install.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Step 1: Download metagpt official image and prepare config2.yaml\ndocker pull metagpt/metagpt:latest\nmkdir -p /opt/metagpt/{config,workspace}\ndocker run --rm metagpt/metagpt:latest cat /app/metagpt/config/config2.yaml > /opt/metagpt/config/config2.yaml\nvim /opt/metagpt/config/config2.yaml # Change the config\n\n# Step 2: Run metagpt demo with container\ndocker run --rm \\\n    --privileged \\\n    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml \\\n    -v /opt/metagpt/workspace:/app/metagpt/workspace \\\n    metagpt/metagpt:latest \\\n    metagpt \"Write a cli snake game\"\n\n# You can also start a container and execute commands in it\ndocker run --name metagpt -d \\\n    --privileged \\\n    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml \\\n    -v /opt/metagpt/workspace:/app/metagpt/workspace \\\n    metagpt/metagpt:latest\n\ndocker exec -it metagpt /bin/bash\n$ metagpt \"Write a cli snake game\"\n```\n\n----------------------------------------\n\nTITLE: Using MetaGPT from Command Line\nDESCRIPTION: Example of using MetaGPT directly from the command line interface to create a repository for a 2048 game application. The output will be generated in the ./workspace directory.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmetagpt \"Create a 2048 game\"  # this will create a repo in ./workspace\n```\n\n----------------------------------------\n\nTITLE: Complete Configuration Example in Python\nDESCRIPTION: Comprehensive Python example showing multiple configuration options for MetaGPT, including API key setup, proxy configuration, and model selection.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.config import Config\n\nconfig = Config()\n# Configure directly in code\nconfig.openai_api_key = \"sk-...\"\nconfig.openai_proxy = \"http://127.0.0.1:7890\"\nconfig.metagpt_model = \"gpt-4-1106-preview\"\n\n# Or load from default config file\nconfig.load_from_file()\n# Or load from specified path\n# config.load_from_file(\"/path/to/config.yaml\")\n```\n\n----------------------------------------\n\nTITLE: Running MetaGPT with Chainlit UI\nDESCRIPTION: Command to launch the MetaGPT application with Chainlit UI. This starts a local web server where users can input requirements and view generated software components.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/ui_with_chainlit/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Performing OCR on Chinese Invoice Image using PaddleOCR in Python\nDESCRIPTION: This code snippet uses PaddleOCR to perform optical character recognition on a Chinese invoice image, extract the total amount and receipt ID, and save the results as a table. It assumes the PaddleOCR environment is already installed.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom paddleocr import PaddleOCR\nimport pandas as pd\nimport re\n\n# Initialize PaddleOCR\nocr = PaddleOCR(use_angle_cls=True, lang='ch')\n\n# Perform OCR on the image\nimage_path = '{data_dir}/open_ended_tasks/02_ocr.jpg'\nresult = ocr.ocr(image_path, cls=True)\n\n# Extract text words\ntext_words = [word_info[1][0] for line in result for word_info in line]\n\n# Extract total amount and receipt ID\ntotal_amount = None\nreceipt_id = None\nfor word in text_words:\n    if '￥' in word:\n        total_amount = float(word.replace('￥', ''))\n    if word.startswith('No'):\n        receipt_id = word\n\n# Save result as table\ndf = pd.DataFrame({'Total Amount': [total_amount], 'Receipt ID': [receipt_id]})\ndf.to_excel('chinese_invoice_ocr_result.xlsx', index=False)\n```\n\n----------------------------------------\n\nTITLE: Loading Configuration from YAML in Python\nDESCRIPTION: Python code example demonstrating how to load MetaGPT configuration from a YAML file using the Config class's load_from_file method.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.config import Config\n\nconfig = Config()\n# Load from default config file\nconfig.load_from_file()\n# or load from specified path\n# config.load_from_file(\"/path/to/config.yaml\")\n```\n\n----------------------------------------\n\nTITLE: Running ML Benchmark Task in Data Interpreter\nDESCRIPTION: Command to run a specific machine learning benchmark task (Titanic dataset) using the Data Interpreter pipeline. This executes the full pipeline with the specified task name.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython run_ml_benchmark.py --task_name 04_titanic\n```\n\n----------------------------------------\n\nTITLE: Configuring MetaGPT by copying the configuration file\nDESCRIPTION: Sets up MetaGPT by copying the default configuration file to the user's home directory for customization. The configuration file prioritizes ~/.metagpt/config2.yaml over config/config2.yaml.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/tutorial/usage.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Copy the configuration file and make the necessary modifications.\ncp config/config2.yaml ~/.metagpt/config2.yaml\n```\n\n----------------------------------------\n\nTITLE: Structuring Conversation Context in Plaintext\nDESCRIPTION: This snippet outlines the structure for providing context to the conversation, including persona information, memory, past and current context, and conversation history.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/iterative_convo_v1.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nPART 1. \n!<INPUT 0>!\n\nHere is the memory that is in !<INPUT 1>!'s head: \n!<INPUT 2>!\n\nPART 2. \nPast Context: \n!<INPUT 3>!\n\nCurrent Location: !<INPUT 4>!\n\nCurrent Context: \n!<INPUT 5>!\n\n!<INPUT 6>! and !<INPUT 7>! are chatting. Here is their conversation so far: \n!<INPUT 8>!\n```\n\n----------------------------------------\n\nTITLE: Building Custom MetaGPT Docker Image\nDESCRIPTION: Commands for building a custom MetaGPT Docker image from source. This snippet shows how to clone the GitHub repository and build a custom Docker image for MetaGPT.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/docker_install.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# You can also build metagpt image by yourself.\ngit clone https://github.com/geekan/MetaGPT.git\ncd MetaGPT && docker build -t metagpt:custom .\n```\n\n----------------------------------------\n\nTITLE: Using Data Interpreter Agent\nDESCRIPTION: Python code example showing how to use MetaGPT's Data Interpreter agent to perform data analysis tasks, including running an analysis on the sklearn Iris dataset and generating a plot.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom metagpt.roles.di.data_interpreter import DataInterpreter\n\nasync def main():\n    di = DataInterpreter()\n    await di.run(\"Run data analysis on sklearn Iris dataset, include a plot\")\n\nasyncio.run(main())  # or await main() in a jupyter notebook setting\n```\n\n----------------------------------------\n\nTITLE: Configuring Playwright for Mermaid in YAML\nDESCRIPTION: YAML configuration to set Playwright as the rendering engine for Mermaid diagrams in MetaGPT, which needs to be added to the config2.yaml file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nmermaid:\n  engine: playwright\n```\n\n----------------------------------------\n\nTITLE: Novella Chapter Synopsis Template\nDESCRIPTION: A template structure for generating chapter synopses based on user input. Uses variables for chapter count, story premise input, and end marker formatting. Intended to provide detailed chapter outlines with character information for multiple writers.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/NovelOutline/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nI want to write a {{$chapterCount}} chapter novella about:\n{{$input}}\n\nThere MUST BE {{$chapterCount}} CHAPTERS.\n\nINVENT CHARACTERS AS YOU SEE FIT. BE HIGHLY CREATIVE AND/OR FUNNY.\nWRITE SYNOPSIS FOR EACH CHAPTER. INCLUDE INFORMATION ABOUT CHARACTERS ETC. SINCE EACH\nCHAPTER WILL BE WRITTEN BY A DIFFERENT WRITER, YOU MUST INCLUDE ALL PERTINENT INFORMATION\nIN EACH SYNOPSIS\n\nYOU MUST END EACH SYNOPSIS WITH {{$endMarker}}\n```\n\n----------------------------------------\n\nTITLE: Configuring Pyppeteer for Mermaid in YAML\nDESCRIPTION: YAML configuration to set Pyppeteer as the rendering engine for Mermaid diagrams in MetaGPT, which needs to be added to the config2.yaml file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nmermaid:\n  engine: pyppeteer\n```\n\n----------------------------------------\n\nTITLE: Structuring Chapter Generation with Context and Synopsis\nDESCRIPTION: This template outlines the structure for generating a story chapter. It includes placeholders for context (theme and previous chapter), chapter synopsis, and chapter number. The writer is instructed to use the context and synopsis to write the chapter without repeating the synopsis in the output.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/NovelChapter/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[CONTEXT]\n\nTHEME OF STORY:\n{{$theme}}\n\nPREVIOUS CHAPTER:\n{{$previousChapter}}\n\n[END CONTEXT]\n\n\nWRITE THIS CHAPTER USING [CONTEXT] AND\nCHAPTER SYNOPSIS. DO NOT REPEAT SYNOPSIS IN THE OUTPUT\n\nChapter Synopsis:\n{{$input}}\n\nChapter {{$chapterIndex}}\n```\n\n----------------------------------------\n\nTITLE: Web Scraping Paper Data from PaperCopic using Python\nDESCRIPTION: This code snippet demonstrates how to scrape paper data from the PaperCopic website, specifically from the ICLR 2024 statistics page. It filters papers with titles containing 'multiagent' or 'large language model' and saves the results to a CSV file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\n# Send a GET request to the website\nurl = 'https://papercopic.com/statistics/iclr-statistics/iclr-2024-statistics/'\nresponse = requests.get(url)\n\n# Parse the HTML content\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n# Find the table with class 'paperlist'\ntable = soup.find('table', class_='paperlist')\n\n# Extract table data\ndata = []\nfor row in table.find_all('tr')[1:]:\n    cols = row.find_all('td')\n    title = cols[1].text.strip()\n    if 'multiagent' in title.lower() or 'large language model' in title.lower():\n        data.append({\n            'Title': title,\n            'Authors': cols[2].text.strip(),\n            'Status': cols[3].text.strip()\n        })\n\n# Create a DataFrame and save to CSV\ndf = pd.DataFrame(data)\ndf.to_csv('iclr_2024_papers.csv', index=False)\n\n# Print key variables\nprint(f\"Number of papers found: {len(data)}\")\nprint(f\"First paper title: {data[0]['Title'] if data else 'No papers found'}\")\n```\n\n----------------------------------------\n\nTITLE: Installing Playwright for Mermaid Rendering\nDESCRIPTION: Commands to install Playwright and required browsers for converting Mermaid charts to SVG, PNG, and PDF formats as an alternative to using Node.js-based Mermaid-CLI.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install playwright\n```\n\nLANGUAGE: bash\nCODE:\n```\nplaywright install --with-deps chromium\n```\n\n----------------------------------------\n\nTITLE: Visualizing 2048 Game Flow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram illustrates the call flow between the Main, Game, and UI components of the 2048 game implementation. It shows the sequence of function calls for game initialization, user input handling, and game state updates.\nSOURCE: https://github.com/geekan/metagpt/blob/main/tests/data/output_parser/3.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant M as Main\n    participant G as Game\n    participant U as UI\n    M->>G: reset_game()\n    M->>U: draw_grid()\n    M->>U: draw_score()\n    M->>U: handle_input()\n    U->>G: move(direction)\n    G->>G: add_new_tile()\n    G->>U: draw_grid()\n    G->>U: draw_score()\n    G->>U: draw_game_over()\n    G->>G: is_game_over()\n    G->>G: get_empty_cells()\n    G->>G: get_score()\n```\n\n----------------------------------------\n\nTITLE: Installing Pyppeteer for Mermaid Rendering\nDESCRIPTION: Command to install Pyppeteer as an alternative for rendering Mermaid diagrams in MetaGPT, which provides browser automation similar to Playwright but with different implementation.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install pyppeteer\n```\n\n----------------------------------------\n\nTITLE: Location Decision Template with Variables for Character Movement\nDESCRIPTION: A template that uses variables to populate information about a character, their current location, and available destinations to determine appropriate areas for specific activities. The template includes examples showing how to apply the decision rules.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/action_location_sector_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n!<INPUT 0>! lives in {!<INPUT 1>!} that has !<INPUT 2>!.\n!<INPUT 3>! is currently in {!<INPUT 4>!} that has !<INPUT 5>!. !<INPUT 6>!\nArea options: {!<INPUT 7>!}. \n* Stay in the current area if the activity can be done there. Only go out if the activity needs to take place in another place.\n* Must be one of the \"Area options,\" verbatim.\n!<INPUT 8>! is !<INPUT 9>!. For !<INPUT 10>!, !<INPUT 11>! should go to the following area: {\n```\n\n----------------------------------------\n\nTITLE: Basic Minecraft Bot Implementation with Block Collection\nDESCRIPTION: Example implementation of a Minecraft bot that automatically collects grass blocks using the mineflayer-collectblock plugin. Demonstrates bot creation, plugin loading, and recursive block collection with error handling.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/environment/minecraft/mineflayer/mineflayer-collectblock/README.md#2025-04-22_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// Create your bot\nconst mineflayer = require(\"mineflayer\")\nconst bot = mineflayer.createBot({\n  host: 'localhost',\n  username: 'Player',\n})\nlet mcData\n\n// Load collect block\nbot.loadPlugin(require('mineflayer-collectblock').plugin)\n\nasync function collectGrass() {\n  // Find a nearby grass block\n  const grass = bot.findBlock({\n    matching: mcData.blocksByName.grass_block.id,\n    maxDistance: 64\n  })\n\n  if (grass) {\n    // If we found one, collect it.\n    try {\n      await bot.collectBlock.collect(grass)\n      collectGrass() // Collect another grass block\n    } catch (err) {\n      console.log(err) // Handle errors, if any\n    }\n  }\n}\n\n// On spawn, start collecting all nearby grass\nbot.once('spawn', () => {\n  mcData = require('minecraft-data')(bot.version)\n  collectGrass()\n})\n```\n\n----------------------------------------\n\nTITLE: Setting Environment for Pyppeteer Custom Browser\nDESCRIPTION: Environment variable configuration to specify a custom browser path for Pyppeteer, allowing the use of existing Chrome, Chromium, or Edge installations.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nexport PUPPETEER_EXECUTABLE_PATH = /path/to/your/chromium or edge or chrome\n```\n\n----------------------------------------\n\nTITLE: Running InfiAgent-DABench Tasks\nDESCRIPTION: Commands to run InfiAgent-DABench tasks. Options include running a single task, all tasks serially, or all tasks in parallel.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/InfiAgent-DABench/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython run_InfiAgent-DABench_single.py --id x   # run a task, x represents the id of the question you want to test\npython run_InfiAgent-DABench_all.py    # Run all tasks serially\npython run_InfiAgent-DABench.py --k x    # Run all tasks in parallel, x represents the number of parallel tasks at a time\n```\n\n----------------------------------------\n\nTITLE: Using the Official MetaGPT Docker Image\nDESCRIPTION: This snippet shows how to download the official MetaGPT Docker image, prepare the configuration, and run the application. It includes commands for creating necessary directories, extracting the default configuration, and running the container with proper volume mappings.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/docker_install_cn.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 步骤1: 下载metagpt官方镜像并准备好config2.yaml\ndocker pull metagpt/metagpt:latest\nmkdir -p /opt/metagpt/{config,workspace}\ndocker run --rm metagpt/metagpt:latest cat /app/metagpt/config/config2.yaml > /opt/metagpt/config/config2.yaml\nvim /opt/metagpt/config/config2.yaml # 修改配置文件\n\n# 步骤2: 使用容器运行metagpt演示\ndocker run --rm \\\n    --privileged \\\n    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml \\\n    -v /opt/metagpt/workspace:/app/metagpt/workspace \\\n    metagpt/metagpt:latest \\\n    metagpt \"Write a cli snake game\"\n\n# 您也可以启动一个容器并在其中执行命令\ndocker run --name metagpt -d \\\n    --privileged \\\n    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml \\\n    -v /opt/metagpt/workspace:/app/metagpt/workspace \\\n    metagpt/metagpt:latest\n\ndocker exec -it metagpt /bin/bash\n$ metagpt \"Write a cli snake game\"\n```\n\n----------------------------------------\n\nTITLE: Performing OCR on English Invoice Image using PaddleOCR in Python\nDESCRIPTION: This code snippet demonstrates how to use PaddleOCR to perform optical character recognition on an English invoice image, extract the total amount, and save the result as a table. It assumes the PaddleOCR environment is already installed.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom paddleocr import PaddleOCR\nimport pandas as pd\n\n# Initialize PaddleOCR\nocr = PaddleOCR(use_angle_cls=True, lang='en')\n\n# Perform OCR on the image\nimage_path = '{data_dir}/open_ended_tasks/01_ocr.png'\nresult = ocr.ocr(image_path, cls=True)\n\n# Extract total amount (assuming it's the last number in the OCR result)\ntotal_amount = None\nfor line in result:\n    for word_info in line:\n        if word_info[1][0].replace('.', '').isdigit():\n            total_amount = float(word_info[1][0])\n\n# Save result as table\ndf = pd.DataFrame({'Total Amount': [total_amount]})\ndf.to_excel('invoice_ocr_result.xlsx', index=False)\n```\n\n----------------------------------------\n\nTITLE: Processing Chat Statements for Relationship Summarization in Plaintext\nDESCRIPTION: This template takes in statements from a chat history, and the names of two personas, then prompts for a summary of their relationship. It uses input variables to dynamically insert the relevant content and persona names.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/summarize_chat_relationship_v2.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[Statements]\n!<INPUT 0>!\n\nBased on the statements above, summarize !<INPUT 1>! and !<INPUT 2>!'s relationship. What do they feel or know about each other?\n\n\"\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT via Command Line\nDESCRIPTION: Step-by-step process to install MetaGPT from the repository, including Python environment setup, cloning the repository, and running the CLI tool. Requires Python 3.9+ and configures the necessary LLM key.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Step 1: Ensure that Python 3.9+ is installed on your system. You can check this by using:\n# You can use conda to initialize a new python env\n#     conda create -n metagpt python=3.9\n#     conda activate metagpt\npython3 --version\n\n# Step 2: Clone the repository to your local machine for latest version, and install it.\ngit clone https://github.com/geekan/MetaGPT.git\ncd MetaGPT\npip3 install -e .     # or pip3 install metagpt  # for stable version\n\n# Step 3: setup your LLM key in the config2.yaml file\nmkdir ~/.metagpt\ncp config/config2.yaml ~/.metagpt/config2.yaml\nvim ~/.metagpt/config2.yaml\n\n# Step 4: run metagpt cli\nmetagpt \"Create a 2048 game in python\"\n\n# Step 5 [Optional]: If you want to save the artifacts like diagrams such as quadrant chart, system designs, sequence flow in the workspace, you can execute the step before Step 3. By default, the framework is compatible, and the entire process can be run completely without executing this step.\n# If executing, ensure that NPM is installed on your system. Then install mermaid-js. (If you don't have npm in your computer, please go to the Node.js official website to install Node.js https://nodejs.org/ and then you will have npm tool in your computer.)\nnpm --version\nsudo npm install -g @mermaid-js/mermaid-cli\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT via Command Line with Git and Python\nDESCRIPTION: Step-by-step bash commands to install MetaGPT from source or via pip. Includes Python version checking, repository cloning, configuration setup, and running the MetaGPT CLI. Also includes optional steps for setting up mermaid-js for diagram generation.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install_cn.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# 步骤 1: 确保您的系统安装了 Python 3.9 或更高版本。您可以使用以下命令来检查:\n# 您可以使用 conda 来初始化一个新的 Python 环境\n#     conda create -n metagpt python=3.9\n#     conda activate metagpt\npython3 --version\n\n# 步骤 2: 克隆仓库到您的本地机器以获取最新版本，并安装它。\ngit clone https://github.com/geekan/MetaGPT.git\ncd MetaGPT\npip3 install -e .     # 或 pip3 install metagpt  # 用于稳定版本\n\n# 步骤 3: 在 config2.yaml 文件中设置您的 LLM 密钥\nmkdir ~/.metagpt\ncp config/config2.yaml ~/.metagpt/config2.yaml\nvim ~/.metagpt/config2.yaml\n\n# 步骤 4: 运行 metagpt 命令行界面\nmetagpt \"用 python 创建一个 2048 游戏\"\n\n# 步骤 5 [可选]: 如果您想保存诸如象限图、系统设计、序列流等图表作为工作空间的工件，您可以在执行步骤 3 之前执行此步骤。默认情况下，该框架是兼容的，整个过程可以完全不执行此步骤而运行。\n# 如果执行此步骤，请确保您的系统上安装了 NPM。然后安装 mermaid-js。（如果您的计算机中没有 npm，请访问 Node.js 官方网站 https://nodejs.org/ 安装 Node.js，然后您将在计算机中拥有 npm 工具。）\nnpm --version\nsudo npm install -g @mermaid-js/mermaid-cli\n```\n\n----------------------------------------\n\nTITLE: Running Open-Ended Task with Reflection in Data Interpreter\nDESCRIPTION: Command to run an open-ended task (image background removal) with reflection enabled. The command specifies the task name, data directory location, and enables the reflection capability.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython run_open_ended_tasks.py --task_name 14_image_background_removal --data_dir directory_to_di_dataset --use_reflection True\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT with pip\nDESCRIPTION: Commands for installing MetaGPT using pip package manager. Includes multiple installation options including the stable version, installing directly from GitHub, or installing in development mode.\nSOURCE: https://github.com/geekan/metagpt/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade metagpt\n# or `pip install --upgrade git+https://github.com/geekan/MetaGPT.git`\n# or `git clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .`\n```\n\n----------------------------------------\n\nTITLE: Using MetaGPT as a Python Library\nDESCRIPTION: Python code example showing how to use MetaGPT as a library to generate a code repository for a 2048 game. This snippet demonstrates the programmatic API for repository generation.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/README_CN.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.software_company import generate_repo, ProjectRepo\nrepo: ProjectRepo = generate_repo(\"创建一个 2048 游戏\")  # 或 ProjectRepo(\"<路径>\")\nprint(repo)  # 它将打印出仓库结构及其文件\n```\n\n----------------------------------------\n\nTITLE: Implementing PromptOptimizer in Python\nDESCRIPTION: This Python script demonstrates how to initialize LLM settings and create a PromptOptimizer instance to run the optimization process.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/spo/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.ext.spo.components.optimizer import PromptOptimizer\nfrom metagpt.ext.spo.utils.llm_client import SPO_LLM\n\nif __name__ == \"__main__\":\n  # Initialize LLM settings\n  SPO_LLM.initialize(\n    optimize_kwargs={\"model\": \"claude-3-5-sonnet-20240620\", \"temperature\": 0.7},\n    evaluate_kwargs={\"model\": \"gpt-4o-mini\", \"temperature\": 0.3},\n    execute_kwargs={\"model\": \"gpt-4o-mini\", \"temperature\": 0}\n  )\n\n  # Create and run optimizer\n  optimizer = PromptOptimizer(\n    optimized_path=\"workspace\",  # Output directory\n    initial_round=1,  # Starting round\n    max_rounds=10,  # Maximum optimization rounds\n    template=\"Poem.yaml\",  # Template file\n    name=\"Poem\",  # Project name\n  )\n\n  optimizer.optimize()\n```\n\n----------------------------------------\n\nTITLE: Configuring Experience Pool in YAML for MetaGPT\nDESCRIPTION: YAML configuration snippet for enabling the experience pool feature in MetaGPT. It shows how to set the 'enabled', 'enable_read', and 'enable_write' flags to true in the 'exp_pool' section of the config2.yaml file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/exp_pool/README.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nexp_pool:\n  enabled: true\n  enable_read: true\n  enable_write: true\n```\n\n----------------------------------------\n\nTITLE: Installing and Running MetaGPT with Docker\nDESCRIPTION: Docker commands for setting up and running MetaGPT in a container. This includes pulling the image, preparing the configuration file, and executing the container with proper volume mounts.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/README_CN.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# 步骤1: 下载metagpt官方镜像并准备好config2.yaml\ndocker pull metagpt/metagpt:latest\nmkdir -p /opt/metagpt/{config,workspace}\ndocker run --rm metagpt/metagpt:latest cat /app/metagpt/config/config2.yaml > /opt/metagpt/config/config2.yaml\nvim /opt/metagpt/config/config2.yaml # 修改配置文件\n\n# 步骤2: 使用容器运行metagpt演示\ndocker run --rm \\\n    --privileged \\\n    -v /opt/metagpt/config/config2.yaml:/app/metagpt/config/config2.yaml \\\n    -v /opt/metagpt/workspace:/app/metagpt/workspace \\\n    metagpt/metagpt:latest \\\n    metagpt \"Write a cli snake game\"\n```\n\n----------------------------------------\n\nTITLE: Initializing MetaGPT Environment and Team in Python\nDESCRIPTION: This snippet demonstrates how to create an Android environment, initialize a role, and set up a team within the MetaGPT framework. It shows the basic setup for using the environment in a project.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/environment/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nandroid_env = env.create(EnvType.ANDROID)\n\nassistant = Role(name=\"Bob\", profile=\"android assistant\")\nteam = Team(investment=10.0, env=android_env, roles=[assistant])\n```\n\n----------------------------------------\n\nTITLE: Event Rating Prompt Template\nDESCRIPTION: A template for rating events on a poignancy scale from 1-10, where 1 represents mundane daily activities and 10 represents highly significant emotional events. The template accepts inputs for agent name, subject, and event description.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/poignancy_event_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n!<INPUT 1>!: agent name\n!<INPUT 1>!: iss\n!<INPUT 2>!: name \n!<INPUT 3>!: event description\n\n###\nHere is a brief description of !<INPUT 0>!. \n!<INPUT 1>!\n\nOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following event for !<INPUT 2>!.\n\nEvent: !<INPUT 3>!\nRate (return a number between 1 to 10):\n```\n\n----------------------------------------\n\nTITLE: Running MetaGPT Android Assistant for Automatic Execution (Bash)\nDESCRIPTION: This command runs the MetaGPT Android Assistant in automatic execution mode for the Messenger app. It uses the knowledge gained from the learning stage to perform tasks.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/android_assistant/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython run_assistant.py \"Send 'When will we release this feature?' to +86 8888888\" --stage \"act\" --mode \"auto or manual\" --app-name \"Messenger\"\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit for MetaGPT UI\nDESCRIPTION: Command to install the Chainlit package required for creating a UI interface for MetaGPT. Assumes MetaGPT is already configured according to the main project readme.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/ui_with_chainlit/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install chainlit\n```\n\n----------------------------------------\n\nTITLE: Converting Action Descriptions to Event Triples\nDESCRIPTION: Template showing how to transform natural language action statements into (subject, predicate, object) format. Uses placeholder inputs (!<INPUT 0>!, !<INPUT 1>!, !<INPUT 2>!) for dynamic generation. Includes multiple examples demonstrating the pattern.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/generate_event_triple_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nTask: Turn the input into (subject, predicate, object). \n\nInput: Sam Johnson is eating breakfast. \nOutput: (Dolores Murphy, eat, breakfast) \n--- \nInput: Joon Park is brewing coffee.\nOutput: (Joon Park, brew, coffee)\n---\nInput: Jane Cook is sleeping. \nOutput: (Jane Cook, is, sleep)\n---\nInput: Michael Bernstein is writing email on a computer. \nOutput: (Michael Bernstein, write, email)\n---\nInput: Percy Liang is teaching students in a classroom. \nOutput: (Percy Liang, teach, students)\n---\nInput: Merrie Morris is running on a treadmill. \nOutput: (Merrie Morris, run, treadmill)\n---\nInput: !<INPUT 0>! is !<INPUT 1>!. \nOutput: (!<INPUT 2>!,\n```\n\n----------------------------------------\n\nTITLE: SELA Experiment Examples\nDESCRIPTION: Example commands for running MCTS experiments with different datasets and parameters\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode mcts --task titanic --rollouts 10\npython run_experiment.py --exp_mode mcts --task house-prices --rollouts 10 --low_is_better\n```\n\n----------------------------------------\n\nTITLE: Building a Custom MetaGPT Docker Image\nDESCRIPTION: This snippet demonstrates how to build a custom MetaGPT Docker image from source. It shows how to clone the MetaGPT repository and build the image using Docker build command.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/docker_install_cn.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# 您也可以自己构建metagpt镜像\ngit clone https://github.com/geekan/MetaGPT.git\ncd MetaGPT && docker build -t metagpt:custom .\n```\n\n----------------------------------------\n\nTITLE: Using collect Function in Mineflayer Collectblock Plugin\nDESCRIPTION: The collect function allows a bot to automatically mine blocks or pick up item drops. It handles pathfinding, tool selection, and item collection in a single API call. The function accepts targets, options, and a callback parameter.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/environment/minecraft/mineflayer/mineflayer-collectblock/docs/api.md#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nbot.collectblock.collect(target: Collectable | Collectable[], options?: CollectOptions, cb: (err?: Error) => void): void\n```\n\n----------------------------------------\n\nTITLE: Running PromptOptimizer via Command Line\nDESCRIPTION: This bash command demonstrates how to run the PromptOptimizer using the command line interface, with various configuration options available.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/spo/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m examples.spo.optimize\n```\n\n----------------------------------------\n\nTITLE: Configuring AIDE Parameters\nDESCRIPTION: YAML configuration for AIDE agent parameters including steps, validation, and model settings.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# agent hyperparams\nagent:\n  steps: 10  # Number of improvement iterations\n  k_fold_validation: 1  # Set to 1 to disable cross-validation\n  code:\n    model: deepseek-coder\n    temp: 0.5\n  feedback:\n    model: deepseek-coder\n    temp: 0.5\n  search:\n    max_debug_depth: 3\n    debug_prob: 0.5\n    num_drafts: 5\n```\n\n----------------------------------------\n\nTITLE: Running MetaGPT Android Assistant for Learning (Bash)\nDESCRIPTION: This command runs the MetaGPT Android Assistant in learning mode for the Messenger app. It can be set to either auto or manual mode for exploration or human demonstration respectively.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/android_assistant/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/android_assistant\npython run_assistant.py \"Send 'When will we release this feature?' to +86 8888888\" --stage \"learn\" --mode \"auto or manual\" --app-name \"Messenger\"\n```\n\n----------------------------------------\n\nTITLE: Running MetaGPT Android Assistant for Manual Learning (Bash)\nDESCRIPTION: This command runs the MetaGPT Android Assistant in manual learning mode for the Messenger app. It allows the user to demonstrate actions for the assistant to learn from.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/android_assistant/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/android_assistant\npython run_assistant.py \"Send 'When will we release this feature?' to +86 8888888\" --stage \"learn\" --mode \"manual\" --app-name \"Messenger\"\n```\n\n----------------------------------------\n\nTITLE: Web Scraping Product Data from ScrapMe.live using Python\nDESCRIPTION: This code snippet demonstrates how to scrape product data from the ScrapMe.live website. It parses the web page encoding and HTML structure, extracts product information from the first page, and saves the data to a CSV file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport chardet\n\n# Send a GET request to the website\nurl = 'https://scrapeme.live/shop/'\nresponse = requests.get(url)\n\n# Detect encoding\nencoding = chardet.detect(response.content)['encoding']\n\n# Parse the HTML content\nsoup = BeautifulSoup(response.content.decode(encoding), 'html.parser')\n\n# Extract product data\nproducts = []\nfor product in soup.find_all('li', class_='product'):\n    name = product.find('h2', class_='woocommerce-loop-product__title').text.strip()\n    price = product.find('span', class_='price').text.strip()\n    product_url = product.find('a', class_='woocommerce-LoopProduct-link')['href']\n    image_url = product.find('img', class_='attachment-woocommerce_thumbnail')['src']\n    \n    products.append({\n        'Name': name,\n        'Price': price,\n        'Product URL': product_url,\n        'Image URL': image_url\n    })\n\n# Create a DataFrame and save to CSV\ndf = pd.DataFrame(products)\ndf.to_csv('scrapeme_products.csv', index=False)\n\n# Print key variables\nprint(f\"Number of products scraped: {len(products)}\")\nprint(f\"First product name: {products[0]['Name']}\")\n```\n\n----------------------------------------\n\nTITLE: Generating Poignancy Rating Prompt for Conversations (Plaintext)\nDESCRIPTION: This snippet constructs a prompt to rate the poignancy of a conversation. It uses input placeholders for agent details, person's name, and the conversation content. The rating scale is defined from 1 (mundane) to 10 (extremely poignant).\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/poignancy_chat_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n!<INPUT 1>!: agent name\n!<INPUT 1>!: iss\n!<INPUT 2>!: name \n!<INPUT 3>!: event description\n\n###\nHere is a brief description of !<INPUT 0>!. \n!<INPUT 1>!\n\nOn the scale of 1 to 10, where 1 is purely mundane (e.g., routine morning greetings) and 10 is extremely poignant (e.g., a conversation about breaking up, a fight), rate the likely poignancy of the following conversation for !<INPUT 2>!.\n\nConversation: \n!<INPUT 3>!\n\nRate (return a number between 1 to 10):\n```\n\n----------------------------------------\n\nTITLE: Initiating MetaGPT projects with different options\nDESCRIPTION: Demonstrates basic usage of MetaGPT CLI to create a new project with different options such as disabling implementation or enabling code review. The generated project will be stored in the workspace/ directory.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/tutorial/usage.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Run the script\nmetagpt \"Write a cli snake game\"\n# Do not hire an engineer to implement the project\nmetagpt \"Write a cli snake game\" --no-implement\n# Hire an engineer and perform code reviews\nmetagpt \"Write a cli snake game\" --code_review\n```\n\n----------------------------------------\n\nTITLE: Automating Email Replies with Python\nDESCRIPTION: This snippet describes a task to create an agent that automatically reads and replies to emails using an Outlook account. It checks the content of the latest email and sends an automated response for specific email address suffixes.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Email account: xxx@xxx.xxx\n# Email Password: xxxx\n\n# TODO: Implement email checking and automated reply logic\n```\n\n----------------------------------------\n\nTITLE: Email Rewriting Template with Variables\nDESCRIPTION: A template format for the email rewriting service that uses variables for recipient, input content, and sender. The template allows for dynamic content insertion in the system.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailTo/skprompt.txt#2025-04-22_snippet_2\n\nLANGUAGE: template syntax\nCODE:\n```\n{{$to}}\n{{$input}}\n\nThanks,\n{{$sender}}\n```\n\n----------------------------------------\n\nTITLE: Basic Configuration in Python Using Config Class\nDESCRIPTION: Python code example showing how to configure MetaGPT directly in code using the Config class. This method sets the OpenAI API key and proxy for the current session.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.config import Config\n\nconfig = Config()\nconfig.openai_api_key = \"sk-...\"\nconfig.openai_proxy = \"http://127.0.0.1:7890\"\n```\n\n----------------------------------------\n\nTITLE: Image Background Removal using rembg in Python\nDESCRIPTION: This task requires using the rembg Python toolkit to remove the background from a given image. The image is loaded from a specified path and the result is saved to another specified path.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n# TODO: Implement background removal using rembg\n# image_path = '{data_dir}/open_ended_tasks/14_image_background_removal.jpg'\n# save_path = '{data_dir}/open_ended_tasks/14_image_background_removal.jpg'\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Configuration Variables via Environment Variables\nDESCRIPTION: Example of setting multiple configuration variables for MetaGPT using environment variables, including API key, proxy settings, and model selection.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"sk-...\"\nexport OPENAI_API_BASE=\"https://api.openai.com/v1\"\nexport OPENAI_PROXY=\"http://127.0.0.1:7890\"\nexport ANTHROPIC_API_KEY=\"sk-...\"\nexport METAGPT_MODEL=\"gpt-4-1106-preview\"\n```\n\n----------------------------------------\n\nTITLE: Configuring MetaGPT via YAML File\nDESCRIPTION: Example YAML configuration file for MetaGPT showing various settings including API keys, proxy settings, model selection, and Azure OpenAI configuration.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nopenai_api_key: \"sk-...\"\nopenai_proxy: \"http://127.0.0.1:7890\"\nmetagpt_model: \"gpt-4-1106-preview\"\nanthropoic_api_key: \"sk-...\"\n\n# If using Azure OpenAI\nopenai_api_type: \"azure\"\nopenai_api_version: \"2023-05-15\"\nopenai_api_base: \"https://xxx.openai.azure.com/\"\nazure_deployment_name: \"gpt-35-turbo\"\n```\n\n----------------------------------------\n\nTITLE: Text-to-Image Generation using Stable Diffusion in Python\nDESCRIPTION: This task involves using a Stable Diffusion text-to-image tool to generate an image of a beautiful girl. The Stable Diffusion service is accessed via a specified URL.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n# TODO: Implement text-to-image generation using Stable Diffusion\n# sd_url = \"http://your.sd.service.ip:port\"\n# prompt = \"a beautiful girl\"\n```\n\n----------------------------------------\n\nTITLE: Poignancy Event Rating Template with Input Parameters\nDESCRIPTION: Text template that accepts agent name, identifier (iss), name, and event description as inputs to produce a poignancy rating request. The template uses a 1-10 scale where 1 represents mundane events and 10 represents extremely poignant events.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/poignancy_action_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n!<INPUT 1>!: agent name\n!<INPUT 1>!: iss\n!<INPUT 2>!: name \n!<INPUT 3>!: event description\n\n###\nHere is a brief description of !<INPUT 0>!. \n!<INPUT 1>!\n\nOn the scale of 1 to 10, where 1 is purely mundane (e.g., brushing teeth, making bed) and 10 is extremely poignant (e.g., a break up, college acceptance), rate the likely poignancy of the following event for !<INPUT 2>!.\n\nEvent: !<INPUT 3>!\nRate (return a number between 1 to 10):\n```\n\n----------------------------------------\n\nTITLE: Defining SPO Iteration Template in YAML\nDESCRIPTION: This YAML template defines the structure for SPO iterations, including the initial prompt, requirements, target word count, and QA pairs for iteration.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/spo/README.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nprompt: |\n  Please solve the following problem.\n\nrequirements: |\n  ...\n\ncount: None\n\nqa:\n  - question: |\n      ...\n    answer: |\n      ...\n\n  - question: |\n      ...\n    answer: |\n      ...\n```\n\n----------------------------------------\n\nTITLE: Image-to-Code Generation in Python\nDESCRIPTION: This task requires converting an image into webpage code including HTML, CSS, and JS. The image is loaded from a specified path, and the generated code should be saved to a file.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n# TODO: Implement image-to-code conversion\n# image_path = '{data_dir}/open_ended_tasks/16_image_2_code_generation.png'\n# Convert image to HTML, CSS, and JS\n# Save generated code to a file\n```\n\n----------------------------------------\n\nTITLE: Bullet Points Input Format\nDESCRIPTION: Original bullet point format listing basic facts about Macbeth\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailGen/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n- Macbeth, King Scotland\n- Married, Wife Lady Macbeth, No Kids\n- Dog Toby McDuff. Hunter, dead.\n- Shakespeare play\n```\n\n----------------------------------------\n\nTITLE: Checking ADB Installation and Device Connection (Bash)\nDESCRIPTION: This command checks if ADB (Android Debug Bridge) is installed successfully and if an Android device is connected to the PC.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/android_assistant/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nadb devices\n```\n\n----------------------------------------\n\nTITLE: Importing BaseBenchmark Class for Custom Evaluation in Python\nDESCRIPTION: This snippet shows how to import the BaseBenchmark class from the metagpt project, which is the foundation for creating custom benchmark evaluations.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/aflow/benchmark/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom metagpt.ext.aflow.benchmark.benchmark import BaseBenchmark\n```\n\n----------------------------------------\n\nTITLE: Web Scraping CPI Data from Chinese Government Website using Python\nDESCRIPTION: This code snippet demonstrates how to scrape CPI data from a Chinese government website. It detects the encoding, crawls the webpage, extracts key sentences using regular expressions, and summarizes the content in Chinese.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom bs4 import BeautifulSoup\nimport re\nimport chardet\n\n# Step 1: Detect encoding and HTML structure\nurl = 'https://www.stats.gov.cn/sj/sjjd/202307/t20230718_1941322.html'\nresponse = requests.get(url)\nencoding = chardet.detect(response.content)['encoding']\n\n# Step 2: Crawl and save content\nsoup = BeautifulSoup(response.content.decode(encoding), 'html.parser')\nbody_content = soup.find('div', class_='TRS_Editor').get_text(strip=True)\nwith open('target.txt', 'w', encoding='utf-8') as f:\n    f.write(body_content)\n\n# Step 3: Extract key sentences\nkey_sentences = []\npatterns = [\n    r'2023年6月份，全国CPI同比上涨(\\d+\\.\\d+)%',\n    r'2023年上半年，全国CPI比上年同期上涨(\\d+\\.\\d+)%',\n    r'6月份，全国CPI环比下降(\\d+\\.\\d+)%'\n]\n\nfor pattern in patterns:\n    try:\n        match = re.search(pattern, body_content)\n        if match:\n            key_sentences.append(match.group())\n    except Exception as e:\n        print(f\"Error matching pattern {pattern}: {e}\")\n\n# Step 4: Summarize in Chinese\nsummary = \"根据中国国家统计局的数据，\" + \"，\".join(key_sentences)\n\n# Print first 200 characters of the webpage text\nprint(body_content[:200])\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT via Pip and Creating a Project\nDESCRIPTION: Command-line instructions for installing MetaGPT via pip, initializing the configuration, and creating a simple 2048 game project. This demonstrates the basic usage of MetaGPT from the command line.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/README_CN.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install metagpt\nmetagpt --init-config  # 创建 ~/.metagpt/config2.yaml，根据您的需求修改它\nmetagpt \"创建一个 2048 游戏\"  # 这将在 ./workspace 创建一个仓库\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Benchmark Class in Python\nDESCRIPTION: This code demonstrates how to create a new class that inherits from BaseBenchmark. It includes the constructor method that initializes the benchmark with a name, file path, and log path.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/aflow/benchmark/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass MyDatasetBenchmark(BaseBenchmark):\n    def __init__(self, name: str, file_path: str, log_path: str):\n        super().__init__(name, file_path, log_path)\n```\n\n----------------------------------------\n\nTITLE: Python Requirements Dependencies List\nDESCRIPTION: Comprehensive list of Python package dependencies with version specifications. Includes core dependencies for AI operations, web services, data processing, and development tools. Some dependencies are commented out and others have specific version constraints.\nSOURCE: https://github.com/geekan/metagpt/blob/main/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\naiohttp==3.8.6\n#azure_storage==0.37.0\nchannels==4.0.0\n# Django==4.1.5\n# docx==0.2.4\n#faiss==1.5.3\nfaiss_cpu==1.7.4\nfire==0.4.0\ntyper==0.9.0\n# godot==0.1.1\n# google_api_python_client==2.93.0  # Used by search_engine.py\nlancedb==0.4.0\nloguru==0.6.0\nmeilisearch==0.21.0\nnumpy~=1.26.4\nopenai~=1.64.0\nopenpyxl~=3.1.5\nbeautifulsoup4==4.12.3\npandas==2.1.1\npydantic>=2.5.3\n#pygame==2.1.3\n# pymilvus==2.4.6\n# pytest==7.2.2 # test extras require\npython_docx==0.8.11\nPyYAML==6.0.1\n# sentence_transformers==2.2.2\nsetuptools==65.6.3\ntenacity==8.2.3\ntiktoken==0.7.0\ntqdm==4.66.2\n#unstructured[local-inference]\n# selenium>4\n# webdriver_manager<3.9\nanthropic==0.47.2\ntyping-inspect==0.8.0\nlibcst==1.0.1\nqdrant-client==1.7.0\ngrpcio~=1.67.0\ngrpcio-tools~=1.62.3\ngrpcio-status~=1.62.3\n# pytest-mock==3.11.1  # test extras require\n# open-interpreter==0.1.7; python_version>\"3.9\" # Conflict with openai 1.x\nta==0.10.2\nsemantic-kernel==0.4.3.dev0\nwrapt==1.15.0\n#aiohttp_jinja2\n# azure-cognitiveservices-speech~=1.31.0 # Used by metagpt/tools/azure_tts.py\n#aioboto3~=12.4.0  # Used by metagpt/utils/s3.py\nredis~=5.0.0 # Used by metagpt/utils/redis.py\ncurl-cffi~=0.7.0\nhttplib2~=0.22.0\nwebsocket-client~=1.8.0\naiofiles==23.2.1\ngitpython==3.1.40\nzhipuai~=2.1.5\nrich==13.6.0\nnbclient==0.9.0\nnbformat==5.9.2\nipython==8.17.2\nipykernel==6.27.1\nscikit_learn==1.3.2\ntyping-extensions==4.11.0\nsocksio~=1.0.0\ngitignore-parser==0.1.9\n# connexion[uvicorn]~=3.0.5 # Used by metagpt/tools/openapi_v3_hello.py\nwebsockets>=10.0,<12.0\nnetworkx~=3.2.1\ngoogle-generativeai==0.4.1\nplaywright>=1.26  # used at metagpt/tools/libs/web_scraping.py\nanytree\nipywidgets==8.1.1\nPillow\nimap_tools==1.5.0  # Used by metagpt/tools/libs/email_login.py\npylint~=3.0.3\npygithub~=2.3\nhtmlmin\nfsspec\ngrep-ast~=0.3.3  # linter\nunidiff==0.7.5 # used at metagpt/tools/libs/cr.py\nqianfan~=0.4.4\ndashscope~=1.19.3\nrank-bm25==0.2.2  # for tool recommendation\njieba==0.42.1  # for tool recommendation\nvolcengine-python-sdk[ark]~=1.0.94 # Solution for installation error in Windows: https://github.com/volcengine/volcengine-python-sdk/issues/5\ngymnasium==0.29.1\nboto3~=1.34.69\nspark_ai_python~=0.3.30\ntree_sitter~=0.23.2\ntree_sitter_python~=0.23.2\nhttpx==0.28.1\n```\n\n----------------------------------------\n\nTITLE: Running Base Data Interpreter\nDESCRIPTION: Command for running the base data interpreter experiment on the Titanic dataset.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode base --task titanic --num_experiments 10\n```\n\n----------------------------------------\n\nTITLE: Dataset Preparation Commands\nDESCRIPTION: Commands to prepare and analyze datasets from scratch using Python scripts\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd data\npython dataset.py --save_analysis_pool\npython hf_data.py --save_analysis_pool\n```\n\n----------------------------------------\n\nTITLE: Daily Planning Template with Variables\nDESCRIPTION: A template structure for daily planning that uses variables to insert personalized information like common settings, lifestyle preferences, current date/time, person name and wake up time. The template provides a framework for describing daily routines and schedules.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/daily_planning_v6.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n!<INPUT 0>!\n\nIn general, !<INPUT 1>!\nToday is !<INPUT 2>!. Here is !<INPUT 3>!'s plan today in broad-strokes (with the time of the day. e.g., have a lunch at 12:00 pm, watch TV from 7 to 8 pm): 1) wake up and complete the morning routine at !<INPUT 4>!, 2)\n```\n\n----------------------------------------\n\nTITLE: Running AutoSklearn Experiment\nDESCRIPTION: Command for running AutoSklearn experiment with the Titanic dataset.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode autosklearn --task titanic\n```\n\n----------------------------------------\n\nTITLE: Translating Input Text to Specified Language\nDESCRIPTION: This template provides instructions for translating the given input text into a specified language. It emphasizes the importance of using only the target language for the translation.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/Translate/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nTranslate the input below into {{$language}}\n\nMAKE SURE YOU ONLY USE {{$language}}.\n\n{{$input}}\n\nTranslation:\n```\n\n----------------------------------------\n\nTITLE: Random Search Experiment Commands\nDESCRIPTION: Commands for running random search experiments with different modes\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode rs --task titanic --rs_mode single\npython run_experiment.py --exp_mode rs --task titanic --rs_mode set\n```\n\n----------------------------------------\n\nTITLE: Web Page Imitation using Selenium and WebDriver in Python\nDESCRIPTION: This task involves using Selenium and WebDriver to render a webpage, convert it to an image, and then use GPT-4V to recreate the webpage as HTML, CSS, and JS. The process is repeated for various websites including Medium, PyTorch, Kaggle, OpenAI, and Google DeepMind.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/README.md#2025-04-22_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# TODO: Implement web page rendering and conversion logic using Selenium and WebDriver\n# Ensure browser window is maximized\n# Convert rendered page to image\n# Use GPT-4V to generate HTML, CSS, and JS\n# Save generated webpage code to a file\n```\n\n----------------------------------------\n\nTITLE: Running Autogluon Experiments\nDESCRIPTION: Commands for running Autogluon experiments for both tabular and multimodal data.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode autogluon --task {task_name}\npython run_experiment.py --exp_mode autogluon --task {task_name} --is_multimodal\n```\n\n----------------------------------------\n\nTITLE: Updating AIDE Agent Query Function\nDESCRIPTION: Modification to AIDE agent.py to handle Deepseek V2.5 compatibility issues with system messages.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nresponse = cast(\n    dict,\n    query(\n        system_message=None,\n        user_message=prompt,\n        func_spec=review_func_spec,\n        model=self.acfg.feedback.model,\n        temperature=self.acfg.feedback.temp,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Displaying MetaGPT Project Timeline in Markdown\nDESCRIPTION: This markdown snippet presents a timeline of MetaGPT project updates, including version releases, paper publications, and notable achievements. It uses emoji and formatted text to highlight key events from the project's inception to recent developments.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/NEWS.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## Earlier news\n\n🚀 Oct. 29, 2024: We introduced three papers: [AFLOW](https://arxiv.org/abs/2410.10762), [FACT](https://arxiv.org/abs/2410.21012), and [SELA](https://arxiv.org/abs/2410.17238), check the [code](examples)!\n\n🚀 Mar. 29, 2024: [v0.8.0](https://github.com/geekan/MetaGPT/releases/tag/v0.8.0) released. Now you can use Data Interpreter ([arxiv](https://arxiv.org/abs/2402.18679), [example](https://docs.deepwisdom.ai/main/en/DataInterpreter/), [code](https://github.com/geekan/MetaGPT/tree/main/examples/di)) via pypi package import. Meanwhile, we integrated the RAG module and supported multiple new LLMs.\n\n🚀 Feb. 08, 2024: [v0.7.0](https://github.com/geekan/MetaGPT/releases/tag/v0.7.0) released, supporting assigning different LLMs to different Roles. We also introduced [Data Interpreter](https://github.com/geekan/MetaGPT/blob/main/examples/di/README.md), a powerful agent capable of solving a wide range of real-world problems.\n\n🚀 Jan. 16, 2024: Our paper [MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework\n](https://openreview.net/forum?id=VtmBAGCN7o) accepted for **oral presentation (top 1.2%)** at ICLR 2024, **ranking #1** in the LLM-based Agent category.\n\n🚀 Jan. 03, 2024: [v0.6.0](https://github.com/geekan/MetaGPT/releases/tag/v0.6.0) released, new features include serialization, upgraded OpenAI package and supported multiple LLM, provided [minimal example for debate](https://github.com/geekan/MetaGPT/blob/main/examples/debate_simple.py) etc.\n\n🚀 Dec. 15, 2023: [v0.5.0](https://github.com/geekan/MetaGPT/releases/tag/v0.5.0) released, introducing some experimental features such as incremental development, multilingual, multiple programming languages, etc.\n\n🔥 Nov. 08, 2023: MetaGPT is selected into [Open100: Top 100 Open Source achievements](https://www.benchcouncil.org/evaluation/opencs/annual.html).\n\n🔥 Sep. 01, 2023: MetaGPT tops GitHub Trending Monthly for the **17th time** in August 2023.\n\n🌟 Jun. 30, 2023: MetaGPT is now open source.\n\n🌟 Apr. 24, 2023: First line of MetaGPT code committed.\n```\n\n----------------------------------------\n\nTITLE: Configuring AFlow Optimization Parameters in Python\nDESCRIPTION: Command line arguments and default parameters for configuring the AFlow optimization process, including dataset selection, sample count, and iteration settings.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/aflow/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--dataset              # (Required) Dataset type (HumanEval/MBPP/GSM8K/MATH/HotpotQA/DROP)\n--sample 4             # Sample count - number of workflows to be resampled\n--optimized_path PATH  # Optimized result save path\n--initial_round 1      # Initial round\n--max_rounds 20        # Max iteration rounds for AFLOW\n--check_convergence    # Whether to enable early stop\n--validation_rounds 5  # Validation rounds for AFLOW\n--if_first_optimize    # Set True for first optimization, False afterwards\n```\n\n----------------------------------------\n\nTITLE: Installing AutoSklearn\nDESCRIPTION: Command for installing AutoSklearn version 0.15.0.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npip install auto-sklearn==0.15.0\n```\n\n----------------------------------------\n\nTITLE: Defining Output Format for Conversation Response in JSON\nDESCRIPTION: This snippet specifies the expected JSON output format for the conversation response, including the persona's utterance and whether the conversation has ended.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/iterative_convo_v1.txt#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n\"!<INPUT 11>!\": \"<!<INPUT 12>!'s utterance>\",\n\"Did the conversation end with !<INPUT 13>!'s utterance?\": \"<json Boolean>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing WritePRD Class for Generating Product Requirement Documents\nDESCRIPTION: Extends the Action class to create a specialized implementation for generating Product Requirement Documents. It formats requirements into a template and uses the language model to generate a complete PRD.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/prompts/generate_skill.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass WritePRD(Action):\n    def __init__(self, name=\"\", context=None, llm=None):\n        super().__init__(name, context, llm)\n\n    async def run(self, requirements, *args, **kwargs):\n        prompt = PROMPT_TEMPLATE.format(requirements=requirements)\n        prd = await self._aask(prompt)\n        return prd\n```\n\n----------------------------------------\n\nTITLE: Installing Streamlit for SPO Web Interface\nDESCRIPTION: This bash command installs Streamlit, which is required to run the user-friendly web interface for SPO configuration and execution.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/spo/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install \"streamlit~=1.42.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key via Environment Variable\nDESCRIPTION: Bash command to set the OpenAI API key as an environment variable. This is one method for configuring API access for MetaGPT.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"sk-...\"\n```\n\n----------------------------------------\n\nTITLE: Specifying platform or tool preference in MetaGPT requirements\nDESCRIPTION: Shows how to direct MetaGPT to use a specific platform or tool when generating a project by including it in the idea description.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/tutorial/usage.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmetagpt \"Write a cli snake game based on pygame\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Mermaid Path in YAML\nDESCRIPTION: YAML configuration for specifying the path to the locally installed mermaid-cli and puppeteer configuration, which is necessary when using a local installation instead of global.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nmermaid:\n  puppeteer_config: \"./config/puppeteer-config.json\"\n  path: \"./node_modules/.bin/mmdc\"\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT Dependencies via Pip\nDESCRIPTION: Command to install MetaGPT core dependencies using pip. This includes the basic requirements for running MetaGPT applications.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install metagpt\n```\n\n----------------------------------------\n\nTITLE: Input Template\nDESCRIPTION: Template showing where new input should be placed\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailGen/skprompt.txt#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n{{$input}}\n```\n\n----------------------------------------\n\nTITLE: Processing Object State from Persona Interaction\nDESCRIPTION: This template takes 5 inputs to generate a description of an object's state based on how a persona is interacting with it. It follows a step-by-step approach to create a logical state description.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/generate_obj_event_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngenerate_obj_event_v1.txt\n\nVariables: \n!<INPUT 0>! -- Object name \n!<INPUT 1>! -- Persona name\n!<INPUT 2>! -- Persona action event description \n!<INPUT 3>! -- Object name \n!<INPUT 4>! -- Object name \n\n<commentblockmarker>###</commentblockmarker>\nTask: We want to understand the state of an object that is being used by someone. \n\nLet's think step by step. \nWe want to know about !<INPUT 0>!'s state. \nStep 1. !<INPUT 1>! is at/using the !<INPUT 2>!.\nStep 2. Describe the !<INPUT 3>!'s state: !<INPUT 4>! is\n```\n\n----------------------------------------\n\nTITLE: Class Diagram for 2048 Game Components\nDESCRIPTION: Mermaid class diagram showing the relationship between Game and UI classes, including their methods and attributes. The Game class handles core game logic while the UI class manages the display and input handling.\nSOURCE: https://github.com/geekan/metagpt/blob/main/tests/data/output_parser/1.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nclassDiagram\n    class Game {\n        -grid: List[List[int]]\n        -score: int\n        -game_over: bool\n        +__init__()\n        +reset_game()\n        +move(direction: str)\n        +is_game_over() bool\n        +get_empty_cells() List[Tuple[int, int]]\n        +add_new_tile()\n        +get_score() int\n    }\n    class UI {\n        -game: Game\n        +__init__(game: Game)\n        +draw_grid()\n        +draw_score()\n        +draw_game_over()\n        +handle_input()\n    }\n    Game --> UI\n```\n\n----------------------------------------\n\nTITLE: Running AFlow Optimization Commands\nDESCRIPTION: Bash commands for running the AFlow optimization process with either default or custom parameters.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/aflow/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Using default parameters\npython -m examples.aflow.optimize --dataset MATH\n\n# Or with custom parameters\npython -m examples.aflow.optimize --dataset MATH --sample n --optimized_path xxx ...\n```\n\n----------------------------------------\n\nTITLE: Determining Persona Movement Based on Activity and Available Areas\nDESCRIPTION: This snippet provides a template for determining where a persona should move based on their current location, intended activity, and available areas. It includes logic for staying in the current area if possible and avoiding unnecessary entry into others' spaces.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/action_location_object_vMar11.txt#2025-04-22_snippet_0\n\nLANGUAGE: plain text\nCODE:\n```\n!<INPUT 0>! is going to !<INPUT 1>! that has the following areas: {!<INPUT 2>!}\n* Stay in the current area if the activity can be done there. \n* NEVER go into other people's rooms unless necessary.\n!<INPUT 3>! is !<INPUT 4>!. For !<INPUT 5>!, !<INPUT 6>! should go to the following area in !<INPUT 7>! (MUST pick one of {!<INPUT 8>!}):\nAnswer: {\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram for Game Flow\nDESCRIPTION: Mermaid sequence diagram depicting the program flow between Main, Game, and UI components, showing method calls and interactions during gameplay.\nSOURCE: https://github.com/geekan/metagpt/blob/main/tests/data/output_parser/1.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant M as Main\n    participant G as Game\n    participant U as UI\n    M->>G: reset_game()\n    M->>U: draw_grid()\n    M->>U: draw_score()\n    M->>U: handle_input()\n    U->>G: move(direction)\n    G->>G: add_new_tile()\n    G->>U: draw_grid()\n    G->>U: draw_score()\n    G->>U: draw_game_over()\n    G->>G: is_game_over()\n    G->>G: get_empty_cells()\n    G->>G: get_score()\n```\n\n----------------------------------------\n\nTITLE: Prompt Template for Generating Funny Poems\nDESCRIPTION: A template prompt that requests the creation of humorous poems or limericks based on a provided event input. The prompt emphasizes creativity, humor and encourages imaginative responses.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/ShortPoem/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nGenerate a short funny poem or limerick to explain the given event. Be creative and be funny. Let your imagination run wild.\nEvent:{{$input}}\n```\n\n----------------------------------------\n\nTITLE: Extracting Key Topics with JSON Response Format\nDESCRIPTION: This snippet shows the expected JSON output format for topic extraction from a text passage. It demonstrates how to structure the response as a JSON object with an array of concise topic phrases.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/SummarizeSkill/Topics/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"topics\": [\n    \"Macbeth\",\n    \"King of Scotland\",\n    \"Lady Macbeth\",\n    \"Dog\",\n    \"Toby McDuff\",\n    \"Shakespeare\",\n    \"Play\",\n    \"Tragedy\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining TODOs for 2048 Game Implementation in Python\nDESCRIPTION: This Python dictionary defines TODO items for the game implementation, specifying required changes in game.py and main.py files. It includes handling edge cases and improving game loop logic.\nSOURCE: https://github.com/geekan/metagpt/blob/main/tests/data/output_parser/3.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{\n    \"game.py\": \"Add handling for no empty cells in add_new_tile function, Update score in move function\",\n    \"main.py\": \"Handle game over condition in the game loop\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running SPO Streamlit Web Interface\nDESCRIPTION: This bash command launches the Streamlit web interface for a more user-friendly experience in configuring and running the SPO optimizer.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/spo/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m streamlit run metagpt/ext/spo/app.py\n```\n\n----------------------------------------\n\nTITLE: Installing MetaGPT with Additional Dependencies\nDESCRIPTION: Command to install MetaGPT with additional dependencies using pip. The 'all' option includes extra packages for enhanced functionality beyond the core requirements.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/stanford_town/requirements.txt#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install \"metagpt[all]\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Action Abstract Base Class with LLM Integration\nDESCRIPTION: Defines an abstract Action class that provides a foundation for operations requiring language model interaction. It includes methods for setting prefixes, asking the language model questions, and a required run method to be implemented by subclasses.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/prompts/generate_skill.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\nfrom abc import ABC\nfrom metagpt.llm import LLM # Large language model, similar to GPT\n\nclass Action(ABC):\n    def __init__(self, name='', context=None, llm: LLM = LLM()):\n        self.name = name\n        self.llm = llm\n        self.context = context\n        self.prefix = \"\"\n        self.desc = \"\"\n\n    def set_prefix(self, prefix):\n        \"\"\"Set prefix for subsequent use\"\"\"\n        self.prefix = prefix\n\n    async def _aask(self, prompt: str, system_msgs: Optional[list[str]] = None):\n        \"\"\"Use prompt with the default prefix\"\"\"\n        if not system_msgs:\n            system_msgs = []\n        system_msgs.append(self.prefix)\n        return await self.llm.aask(prompt, system_msgs)\n\n    async def run(self, *args, **kwargs):\n        \"\"\"Execute action\"\"\"\n        raise NotImplementedError(\"The run method should be implemented in a subclass.\")\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies with Version Constraints\nDESCRIPTION: This snippet defines the required Python packages with specific version pinning for the project. It includes pyshine version 0.0.9 and opencv-python version 4.6.0.66, ensuring compatibility and consistent behavior across different environments.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/android_assistant/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npyshine==0.0.9\nopencv-python==4.6.0.66\n```\n\n----------------------------------------\n\nTITLE: Style-Based Text Rewriting Prompt Format\nDESCRIPTION: A prompt template that takes a style parameter and input text, requesting the text be rewritten in the specified style while maintaining factual accuracy.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/Rewrite/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nRewrite the given text like it was written in this style or by: {{$style}}. \nMUST RETAIN THE MEANING AND FACTUAL CONTENT AS THE ORIGINAL.\n\n{{$input}}\n```\n\n----------------------------------------\n\nTITLE: Specifying ExecuteNbCode File Path\nDESCRIPTION: The file path for the ExecuteNbCode class that needs to be modified.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/InfiAgent-DABench/README.md#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nmetagpt.actions.di.execute_nb_code\n```\n\n----------------------------------------\n\nTITLE: SELA Setup Commands\nDESCRIPTION: Installation commands for setting up SELA environment and dependencies\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -e .\n\ncd metagpt/ext/sela\n\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Insight Analysis Template with Variable Inputs\nDESCRIPTION: A template format that takes two inputs: a numbered list of statements and a target persona/conversation name. The template requests high-level insights with causal relationships following a specific format pattern (insight because of evidence numbers).\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/insight_and_evidence_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n!<INPUT 0>! -- Numbered list of event/thought statements\n!<INPUT 1>! -- target persona name or \"the conversation\"\n\nWhat !<INPUT 1>! high-level insights can you infer from the above statements? Please ensure it includes 'because of' and generates according to the example format.(example format: insight (because of 1, 5, 3)) .\n1.\n```\n\n----------------------------------------\n\nTITLE: Configuring Mermaid in YAML Configuration File for MetaGPT\nDESCRIPTION: YAML configuration snippet for setting up mermaid-js in MetaGPT. Specifies the paths for puppeteer configuration and the mermaid command line tool.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install_cn.md#2025-04-22_snippet_1\n\nLANGUAGE: yml\nCODE:\n```\nmermaid:\n  puppeteer_config: \"./config/puppeteer-config.json\"\n  path: \"./node_modules/.bin/mmdc\"\n```\n\n----------------------------------------\n\nTITLE: Modifying ExecuteNbCode Class Initialization for DABench Testing\nDESCRIPTION: Python code to modify the ExecuteNbCode class initialization for DABench testing. This change is necessary when performing DABench tests.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/InfiAgent-DABench/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass ExecuteNbCode(Action):\n    \"\"\"execute notebook code block, return result to llm, and display it.\"\"\"\n\n    nb: NotebookNode\n    nb_client: NotebookClient\n    console: Console\n    interaction: str\n    timeout: int = 600\n\n    def __init__(\n        self,\n        nb=nbformat.v4.new_notebook(),\n        timeout=600,\n    ):\n        super().__init__(\n            nb=nbformat.v4.new_notebook(),#nb,\n            nb_client=NotebookClient(nb, timeout=timeout),\n            timeout=timeout,\n            console=Console(),\n            interaction=(\"ipython\" if self.is_ipython() else \"terminal\"),\n        )\n```\n\n----------------------------------------\n\nTITLE: SELA Resume Experiment Commands\nDESCRIPTION: Commands demonstrating how to start and resume an interrupted MCTS experiment\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython run_experiment.py --exp_mode mcts --task titanic --rollouts 10\npython run_experiment.py --exp_mode mcts --task titanic --rollouts 7 --load_tree\n```\n\n----------------------------------------\n\nTITLE: Creating a Structured Conversation Memo Template in MetaGPT\nDESCRIPTION: A template that takes a conversation transcript and persona names as inputs to generate a memo highlighting interesting points from one persona's perspective about another. It uses placeholders (!<INPUT X>!) to be replaced with actual content when processed.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/memo_on_convo_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nmemo_on_convo_v1.txt\n\nVariables: \n!<INPUT 0>! -- All convo utterances\n!<INPUT 1>! -- persona name\n!<INPUT 2>! -- persona name\n!<INPUT 3>! -- persona name\n\n<commentblockmarker>###</commentblockmarker>\n[Conversation]\n!<INPUT 0>!\n\nWrite down if there is anything from the conversation that !<INPUT 1>! might have found interesting from !<INPUT 2>!'s perspective, in a full sentence. \n\n\"!<INPUT 3>!\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for AFlow Automating Agentic Workflow\nDESCRIPTION: BibTeX entry for 'AFlow: Automating Agentic Workflow Generation', to be presented at ICLR 2025. This paper introduces AFlow, a system for automatically generating workflows for AI agents.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_5\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{zhang2025aflow,\n      title={{AF}low: Automating Agentic Workflow Generation},\n      author={Jiayi Zhang and Jinyu Xiang and Zhaoyang Yu and Fengwei Teng and Xiong-Hui Chen and Jiaqi Chen and Mingchen Zhuge and Xin Cheng and Sirui Hong and Jinlin Wang and Bingnan Zheng and Bang Liu and Yuyu Luo and Chenglin Wu},\n      booktitle={The Thirteenth International Conference on Learning Representations},\n      year={2025},\n      url={https://openreview.net/forum?id=z5uVAKwmjf}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Credentials\nDESCRIPTION: Environment variable configuration for OpenAI API authentication.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=\"your api key\"\nexport OPENAI_BASE_URL=\"your own url\"\n```\n\n----------------------------------------\n\nTITLE: Conversation Planning Template Structure\nDESCRIPTION: Template structure for analyzing conversations and generating planning thoughts. Uses input placeholders for conversation content (!<INPUT 0>!) and three persona name references (!<INPUT 1>!, !<INPUT 2>!, !<INPUT 3>!).\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/planning_thought_on_convo_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n[Conversation]\n!<INPUT 0>!\n\nWrite down if there is anything from the conversation that !<INPUT 1>! need to remember for her planning, from !<INPUT 2>!'s perspective, in a full sentence.\n\n\"!<INPUT 3>!\n```\n\n----------------------------------------\n\nTITLE: Defining Task Decomposition Template with Variable Placeholders\nDESCRIPTION: This template provides a structure for breaking down a persona's activities into 5-minute increments. It uses numbered placeholders (!<INPUT X>!) to allow dynamic insertion of persona details, scheduling information, and activity context.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/task_decomp_v3.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nVariables: \n!<INPUT 0>! -- Commonset\n!<INPUT 1>! -- Surrounding schedule description\n!<INPUT 2>! -- Persona first name\n!<INPUT 3>! -- Persona first name\n!<INPUT 4>! -- Current action\n!<INPUT 5>! -- curr time range\n!<INPUT 6>! -- Current action duration in min\n!<INPUT 7>! -- Persona first names\n\n<commentblockmarker>###</commentblockmarker>\nDescribe subtasks in 5 min increments. \n---\nName: Kelly Bronson\nAge: 35\nBackstory: Kelly always wanted to be a teacher, and now she teaches kindergarten. During the week, she dedicates herself to her students, but on the weekends, she likes to try out new restaurants and hang out with friends. She is very warm and friendly, and loves caring for others.\nPersonality: sweet, gentle, meticulous\nLocation: Kelly is in an older condo that has the following areas: {kitchen, bedroom, dining, porch, office, bathroom, living room, hallway}.\nCurrently: Kelly is a teacher during the school year. She teaches at the school but works on lesson plans at home. She is currently living alone in a single bedroom condo.\nDaily plan requirement: Kelly is planning to teach during the morning and work from home in the afternoon.s\n\nToday is Saturday May 10. From 08:00am ~09:00am, Kelly is planning on having breakfast, from 09:00am ~ 12:00pm, Kelly is planning on working on the next day's kindergarten lesson plan, and from 12:00 ~ 13pm, Kelly is planning on taking a break. \nIn 5 min increments, list the subtasks Kelly does when Kelly is working on the next day's kindergarten lesson plan from 09:00am ~ 12:00pm (total duration in minutes: 180):\n1) Kelly is reviewing the kindergarten curriculum standards. (duration in minutes: 15, minutes left: 165)\n2) Kelly is brainstorming ideas for the lesson. (duration in minutes: 30, minutes left: 135)\n3) Kelly is creating the lesson plan. (duration in minutes: 30, minutes left: 105)\n4) Kelly is creating materials for the lesson. (duration in minutes: 30, minutes left: 75)\n5) Kelly is taking a break. (duration in minutes: 15, minutes left: 60)\n6) Kelly is reviewing the lesson plan. (duration in minutes: 30, minutes left: 30)\n7) Kelly is making final changes to the lesson plan. (duration in minutes: 15, minutes left: 15)\n8) Kelly is printing the lesson plan. (duration in minutes: 10, minutes left: 5)\n9) Kelly is putting the lesson plan in her bag. (duration in minutes: 5, minutes left: 0)\n---\n!<INPUT 0>!\n!<INPUT 1>!\nIn 5 min increments, list the subtasks !<INPUT 2>! does when !<INPUT 3>! is !<INPUT 4>! from !<INPUT 5>! (total duration in minutes !<INPUT 6>!): \n1) !<INPUT 7>! is\n```\n\n----------------------------------------\n\nTITLE: LLM Configuration Settings\nDESCRIPTION: YAML configuration for the Large Language Model settings including API type, model selection, and parameters\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nllm:\n  api_type: 'openai'\n  model: deepseek-coder\n  base_url: \"https://your_base_url\"\n  api_key: sk-xxx\n  temperature: 0.5\n```\n\n----------------------------------------\n\nTITLE: Installing Autogluon\nDESCRIPTION: Commands for installing Autogluon and its dependencies.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install -U pip\npip install -U setuptools wheel\npip install autogluon==1.1.1\n```\n\n----------------------------------------\n\nTITLE: Defining Schedule Revision Variables in Plaintext\nDESCRIPTION: This snippet defines variables used in the schedule revision template. It includes placeholders for persona name, time ranges, original plan, new event details, and the revised schedule.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/new_decomp_schedule_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nVariables: \n!<INPUT 0>! -- persona name \n!<INPUT 1>! -- start hour\n!<INPUT 2>! -- end hour \n!<INPUT 3>! -- original plan\n!<INPUT 4>! -- persona name\n!<INPUT 5>! -- new event\n!<INPUT 6>! -- new event duration\n!<INPUT 7>! -- persona name \n!<INPUT 8>! -- start hour\n!<INPUT 9>! -- end hour \n!<INPUT 10>! -- end hour \n!<INPUT 11>! -- new schedule init \n```\n\n----------------------------------------\n\nTITLE: Installing AIDE Package\nDESCRIPTION: Commands for installing AIDE in development mode.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd aideml\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Configuring Mermaid.ink for Diagram Rendering in YAML\nDESCRIPTION: YAML configuration to use mermaid.ink as the rendering engine for Mermaid diagrams in MetaGPT. This is an online service that does not support PDF export but requires no local dependencies.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nmermaid:\n  engine: ink\n```\n\n----------------------------------------\n\nTITLE: Converting Action Descriptions to Emojis with ChatGPT Prompt\nDESCRIPTION: A prompt template that instructs ChatGPT to convert a given action description into a representative emoji. The prompt specifies that a maximum of two emojis should be used for the conversion, ensuring concise representation.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/generate_pronunciatio_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nConvert an action description to an emoji (important: use two or less emojis).\n\nAction description: !<INPUT 0>!\nEmoji:\n```\n\n----------------------------------------\n\nTITLE: Running AIDE Runner Script\nDESCRIPTION: Command to execute the AIDE runner script for generating results.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython runner/aide.py\n```\n\n----------------------------------------\n\nTITLE: Creating Memory Points from Input Text\nDESCRIPTION: Example showing how to convert a narrative text into structured memory points, demonstrating the format for summarizing key information in broken English style\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/SummarizeSkill/Notegen/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nFamily History\n- Macbeth, King Scotland\n- Wife Lady Macbeth, No Kids\n- Dog Toby McDuff. Hunter, dead. \n- Shakespeare play\n```\n\n----------------------------------------\n\nTITLE: Instructions for Reversing User-Provided Acronym\nDESCRIPTION: This snippet contains instructions for reversing a user-provided acronym into funny sentences. It asks for three example sentences to be generated that match the given acronym.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/AcronymReverse/skprompt.txt#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nReverse the following acronym back to a funny sentence. Provide 3 examples.\n# acronym: {{$INPUT}}\nSentences matching the acronym:\n```\n\n----------------------------------------\n\nTITLE: Downloading InfiAgent-DABench Dataset\nDESCRIPTION: Commands to clone the InfiAgent repository and move the dataset to the appropriate directory.\nSOURCE: https://github.com/geekan/metagpt/blob/main/examples/di/InfiAgent-DABench/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd /examples/di/InfiAgent-DABench\ngit clone https://github.com/InfiAgent/InfiAgent.git\nmv InfiAgent/examples/DA-Agent/data ./\n```\n\n----------------------------------------\n\nTITLE: Defining Variables for Persona Conversation in Plaintext\nDESCRIPTION: This snippet defines variables used throughout the conversation template, including persona names, retrieved memory, context, and conversation history.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/iterative_convo_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nVariables: \n!<INPUT 0>! -- persona ISS\n!<INPUT 1>! -- persona name\n!<INPUT 2>! -- retrieved memory\n!<INPUT 3>! -- past context\n!<INPUT 4>! -- current location\n!<INPUT 5>! -- current context\n!<INPUT 6>! -- persona name\n!<INPUT 7>! -- target persona name\n!<INPUT 8>! -- curr convo\n!<INPUT 9>! -- persona name\n!<INPUT 10>! -- target persona name\n!<INPUT 11>! -- persona name\n!<INPUT 12>! -- persona name\n!<INPUT 13>! -- persona name\n```\n\n----------------------------------------\n\nTITLE: Email Bullet Points to Complete Sentences Input Example\nDESCRIPTION: An example of input bullet points for an email rewriting service. The input contains brief bullet points about Macbeth that need to be transformed into complete sentences.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailTo/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plain text\nCODE:\n```\nToby,\n\n- Macbeth, King Scotland\n- Married, Wife Lady Macbeth, No Kids\n- Dog Toby McDuff. Hunter, dead. \n- Shakespeare play\n\nThanks,\nDexter\n```\n\n----------------------------------------\n\nTITLE: Configuring Storage Paths in Python\nDESCRIPTION: Code snippet showing how to configure storage paths for the Stanford Town Game by modifying constants in const.py\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSTORAGE_PATH = EXAMPLE_PATH.joinpath(\"storage\")\nTEMP_STORAGE_PATH = EXAMPLE_PATH.joinpath(\"temp_storage\")\n# updated\nSTORAGE_PATH = Path(\"{path/to/ga/storage}\")\nTEMP_STORAGE_PATH = Path(\"{path/to/ga/temp_storage}\")\n```\n\n----------------------------------------\n\nTITLE: Installing Mermaid-CLI Locally\nDESCRIPTION: Alternative command for installing mermaid-cli locally instead of globally, which can help resolve permission issues that some users encounter.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/install/cli_install.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @mermaid-js/mermaid-cli\n```\n\n----------------------------------------\n\nTITLE: Email Bullet Points Rewritten with Complete Sentences\nDESCRIPTION: The transformed email with bullet points converted to complete sentences in a polite and inclusive tone. The rewrite expands the bullet points into a coherent narrative.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailTo/skprompt.txt#2025-04-22_snippet_1\n\nLANGUAGE: plain text\nCODE:\n```\nHi Toby,\n\nThe story of Macbeth\nMy name is Macbeth. I used to be King of Scotland, but I died. My wife's name is Lady Macbeth and we were married for 15 years. We had no children. Our beloved dog Toby McDuff was a famous hunter of rats in the forest.\nMy story was immortalized by Shakespeare in a play.\n\nThanks,\nDexter\n```\n\n----------------------------------------\n\nTITLE: Defining ML Package Requirements\nDESCRIPTION: Lists required machine learning library dependencies including OpenML for experiment tracking and popular gradient boosting frameworks (XGBoost, CatBoost, LightGBM).\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# expo\nopenml==0.14.2\n# ml module to run in DI\nxgboost\ncatboost\nlightgbm\n```\n\n----------------------------------------\n\nTITLE: Narrative Output Format\nDESCRIPTION: Transformed narrative text with complete sentences\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/EmailGen/skprompt.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nThe story of Macbeth\nMy name is Macbeth. I used to be King of Scotland, but I died. My wife's name is Lady Macbeth and we were married for 15 years. We had no children. Our beloved dog Toby McDuff was a famous hunter of rats in the forest.\nMy story was immortalized by Shakespeare in a play.\n```\n\n----------------------------------------\n\nTITLE: Brainstorming Template Requirements\nDESCRIPTION: Template format for brainstorming tasks that requires a numbered list with specific constraints: between 3-10 items, must be a single list, and must end with ##END## marker.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/Brainstorm/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nMust: brainstorm ideas and create a list.\nMust: use a numbered list.\nMust: only one list.\nMust: end list with ##END##\nShould: no more than 10 items.\nShould: at least 3 items.\nTopic: {{$INPUT}}\nStart.\n```\n\n----------------------------------------\n\nTITLE: Installing Mineflayer Collect Block Plugin with NPM\nDESCRIPTION: Command to install the mineflayer-collectblock plugin using NPM package manager.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/environment/minecraft/mineflayer/mineflayer-collectblock/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install --save mineflayer-collectblock\n```\n\n----------------------------------------\n\nTITLE: Structuring Schedule Revision Template in Plaintext\nDESCRIPTION: This snippet provides the structure for the schedule revision template. It includes sections for the original schedule, the unexpected event, and the revised schedule, using the defined variables as placeholders.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/new_decomp_schedule_v1.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nHere was !<INPUT 0>!'s originally planned schedule from !<INPUT 1>! to !<INPUT 2>!. \n!<INPUT 3>!\n\nBut !<INPUT 4>! unexpectedly ended up !<INPUT 5>! for !<INPUT 6>! minutes. Revise !<INPUT 7>!'s schedule from !<INPUT 8>! to !<INPUT 9>! accordingly (it has to end by !<INPUT 10>!). \nThe revised schedule:\n!<INPUT 11>!\n```\n\n----------------------------------------\n\nTITLE: Defining XML Tag List Format\nDESCRIPTION: Defines two allowable XML tags: 'list' for surrounding list content and 'synopsis' for chapter outlines. Specifies that all XML must be well-formed and code sections must use CDATA.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/StoryGen/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n[XML TAG LIST]\nlist: Surround any lists with this tag\nsynopsis: An outline of the chapter to write\n[END LIST]\n```\n\n----------------------------------------\n\nTITLE: Displaying Version Support Status in Markdown Table\nDESCRIPTION: A markdown table showing which versions of MetaGPT are currently supported for security updates. All listed versions (0.7.x, 0.6.x, and versions below 0.6.x) are marked as unsupported.\nSOURCE: https://github.com/geekan/metagpt/blob/main/SECURITY.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Version | Supported          |\n|---------|--------------------|\\n | 0.7.x   | :x:                |\\n | 0.6.x   | :x:                |\\n| < 0.6.x | :x:                |\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for MetaGPT Multi-Agent Collaborative Framework\nDESCRIPTION: BibTeX entry for the paper 'MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework' published at ICLR 2024. This paper introduces MetaGPT, a framework for collaborative multi-agent systems.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{hong2024metagpt,\n      title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},\n      author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\\\"u}rgen Schmidhuber},\n      booktitle={The Twelfth International Conference on Learning Representations},\n      year={2024},\n      url={https://openreview.net/forum?id=VtmBAGCN7o}\n}\n```\n\n----------------------------------------\n\nTITLE: Modifying AIDE Backend Configuration\nDESCRIPTION: Python code modification for AIDE backend initialization to handle different model types.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel_kwargs = model_kwargs | {\n        \"model\": model,\n        \"temperature\": temperature,\n        \"max_tokens\": max_tokens,\n    }\nif \"claude-\" in model:\n  query_func = backend_anthropic.query\nelse:\n  query_func = backend_openai.query\n```\n\n----------------------------------------\n\nTITLE: Common Acronym Examples\nDESCRIPTION: A set of widely recognized acronyms and their full expansions, demonstrating proper acronym construction where the capital letters in the expansion match the acronym letters.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/Acronym/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nRADAR: RAdio Detection And Ranging\nTASER: Thomas A. Swift's Electric Rifle\nSCUBA: Self Contained Underwater Breathing Apparatus\nKISS: Keep It Simple Stupid\nNASA: National Aeronautics Space Administration\nNAFTA: North American Free Trade Agreement\nNATO: North Atlantic Treaty Organization\n```\n\n----------------------------------------\n\nTITLE: Citation Information\nDESCRIPTION: BibTeX citation format for the SELA research paper\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{chi2024selatreesearchenhancedllm,\n      title={SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning}, \n      author={Yizhou Chi and Yizhang Lin and Sirui Hong and Duyi Pan and Yaying Fei and Guanghao Mei and Bangbang Liu and Tianqi Pang and Jacky Kwok and Ceyao Zhang and Bang Liu and Chenglin Wu},\n      year={2024},\n      eprint={2410.17238},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2410.17238}, \n}\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for SELA Tree-Search Enhanced LLM Agents\nDESCRIPTION: BibTeX entry for 'SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning', an arXiv preprint from 2024. This paper presents SELA, a system using tree search to enhance LLM agents for automated machine learning tasks.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_4\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{chi2024sela,\n      title={SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning}, \n      author={Yizhou Chi and Yizhang Lin and Sirui Hong and Duyi Pan and Yaying Fei and Guanghao Mei and Bangbang Liu and Tianqi Pang and Jacky Kwok and Ceyao Zhang and Bang Liu and Chenglin Wu},\n      year={2024},\n      eprint={2410.17238},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2410.17238}, \n}\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for Atom of Thoughts Paper\nDESCRIPTION: BibTeX entry for 'Atom of Thoughts for Markov LLM Test-Time Scaling', an arXiv preprint from 2025. This paper explores test-time scaling techniques for large language models.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{teng2025atom,\n      title={Atom of Thoughts for Markov LLM Test-Time Scaling}, \n      author={Fengwei Teng and Zhaoyang Yu and Quan Shi and Jiayi Zhang and Chenglin Wu and Yuyu Luo},\n      year={2025},\n      eprint={2502.12018},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2502.12018}, \n}\n```\n\n----------------------------------------\n\nTITLE: Academic Citation for MetaGPT in BibTeX Format\nDESCRIPTION: BibTeX citation entries for referencing MetaGPT and Data Interpreter in research papers. This provides the proper format for academic citations of the MetaGPT framework.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/README_CN.md#2025-04-22_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{hong2024metagpt,\n      title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},\n      author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\\\"u}rgen Schmidhuber},\n      booktitle={The Twelfth International Conference on Learning Representations},\n      year={2024},\n      url={https://openreview.net/forum?id=VtmBAGCN7o}\n}\n@misc{hong2024data,\n      title={Data Interpreter: An LLM Agent For Data Science}, \n      author={Sirui Hong and Yizhang Lin and Bang Liu and Bangbang Liu and Binhao Wu and Danyang Li and Jiaqi Chen and Jiayi Zhang and Jinlin Wang and Li Zhang and Lingyao Zhang and Min Yang and Mingchen Zhuge and Taicheng Guo and Tuo Zhou and Wei Tao and Wenyi Wang and Xiangru Tang and Xiangtao Lu and Xiawu Zheng and Xinbing Liang and Yaying Fei and Yuheng Cheng and Zongze Xu and Chenglin Wu},\n      year={2024},\n      eprint={2402.18679},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI}\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Sentences for 'Christmas' Acronym\nDESCRIPTION: This snippet provides three example sentences that match the acronym 'Christmas'. Each sentence is carefully crafted to have words starting with the letters C, H, R, I, S, T, M, A, S in order.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/AcronymReverse/skprompt.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n# acronym: Christmas\nSentences matching the acronym:\n1. Celebrating Harmony and Respect in a Season of Togetherness, Merriment, and True joy\n2. Children Have Real Interest Since The Mystery And Surprise Thrills\n3. Christmas Helps Reduce Inner Stress Through Mistletoe And Sleigh excursions\n#END#\n```\n\n----------------------------------------\n\nTITLE: Generating Sentences for 'Devis' Acronym\nDESCRIPTION: This snippet shows three example sentences that match the acronym 'Devis'. Each sentence is constructed so that its words' initial letters spell out the acronym.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/AcronymReverse/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# acronym: Devis\nSentences matching the acronym:\n1. Dragons Eat Very Interesting Snacks\n2. Develop Empathy and Vision to Increase Success\n3. Don't Expect Vampires In Supermarkets\n#END#\n```\n\n----------------------------------------\n\nTITLE: Generating Sentences for 'noWare' Acronym\nDESCRIPTION: This snippet demonstrates three example sentences that match the acronym 'noWare'. Each sentence is constructed with words whose initial letters spell out 'noWare' in sequence.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/WriterSkill/AcronymReverse/skprompt.txt#2025-04-22_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n# acronym: noWare\nSentences matching the acronym:\n1. No One Wants an App that Randomly Erases everything\n2. Nourishing Oatmeal With Almond, Raisin, and Egg toppings\n3. Notice Opportunity When Available and React Enthusiastically\n#END#\n```\n\n----------------------------------------\n\nTITLE: Academic Citation in BibTeX\nDESCRIPTION: BibTeX citation for the Generative Agents research paper referenced in the project\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{Park2023GenerativeAgents,  \nauthor = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S.},  \ntitle = {Generative Agents: Interactive Simulacra of Human Behavior},  \nyear = {2023},  \npublisher = {Association for Computing Machinery},  \naddress = {New York, NY, USA},  \nbooktitle = {In the 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23)},  \nkeywords = {Human-AI interaction, agents, generative AI, large language models},  \nlocation = {San Francisco, CA, USA},  \nseries = {UIST '23}\n}\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for Self-Supervised Prompt Optimization\nDESCRIPTION: BibTeX entry for 'Self-Supervised Prompt Optimization', an arXiv preprint from 2025. This paper discusses techniques for optimizing prompts in a self-supervised manner.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_2\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{xiang2025self,\n      title={Self-Supervised Prompt Optimization}, \n      author={Jinyu Xiang and Jiayi Zhang and Zhaoyang Yu and Fengwei Teng and Jinhao Tu and Xinbing Liang and Sirui Hong and Chenglin Wu and Yuyu Luo},\n      year={2025},\n      eprint={2502.06855},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL},\n      url={https://arxiv.org/abs/2502.06855}, \n}\n```\n\n----------------------------------------\n\nTITLE: Sharing Document Links in Markdown\nDESCRIPTION: Markdown links to MetaGPT's FAQ documents in English and Chinese for easy sharing and reference.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/FAQ-EN.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- MetaGPT-Index/FAQ-EN https://github.com/geekan/MetaGPT/blob/main/docs/FAQ-EN.md\n- MetaGPT-Index/FAQ-CN https://deepwisdom.feishu.cn/wiki/MsGnwQBjiif9c3koSJNcYaoSnu4\n```\n\n----------------------------------------\n\nTITLE: Installing AIDE Repository\nDESCRIPTION: Clones the AIDE repository and checks out a specific commit version from September 30, 2024.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/sela/runner/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/WecoAI/aideml.git\ngit checkout 77953247ea0a5dc1bd502dd10939dd6d7fdcc5cc\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for Data Interpreter LLM Agent\nDESCRIPTION: BibTeX entry for 'Data Interpreter: An LLM Agent For Data Science', an arXiv preprint from 2024. This paper presents an LLM-based agent specifically designed for data science applications.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_6\n\nLANGUAGE: bibtex\nCODE:\n```\n@misc{hong2024data,\n      title={Data Interpreter: An LLM Agent For Data Science}, \n      author={Sirui Hong and Yizhang Lin and Bang Liu and Bangbang Liu and Binhao Wu and Danyang Li and Jiaqi Chen and Jiayi Zhang and Jinlin Wang and Li Zhang and Lingyao Zhang and Min Yang and Mingchen Zhuge and Taicheng Guo and Tuo Zhou and Wei Tao and Wenyi Wang and Xiangru Tang and Xiangtao Lu and Xiawu Zheng and Xinbing Liang and Yaying Fei and Yuheng Cheng and Zongze Xu and Chenglin Wu},\n      year={2024},\n      eprint={2402.18679},\n      archivePrefix={arXiv},\n      primaryClass={cs.AI},\n      url={https://arxiv.org/abs/2402.18679}, \n}\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for FACT Context Rewriting Paper\nDESCRIPTION: BibTeX entry for 'FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval', a conference paper for ACL 2025. This research examines techniques for iterative context rewriting in multi-fact retrieval systems.\nSOURCE: https://github.com/geekan/metagpt/blob/main/docs/ACADEMIC_WORK.md#2025-04-22_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@inproceedings{wang2025fact,\n      title={FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval}, \n      author={Jinlin Wang and Suyuchen Wang and Ziwen Xia and Sirui Hong and Yun Zhu and Bang Liu and Chenglin Wu},\n      booktitle={The 2025 Annual Conference of the Nations of the Americas Chapter of the ACL},\n      year={2025},\n      url={https://openreview.net/forum?id=VXOircx5h3}\n}\n```\n\n----------------------------------------\n\nTITLE: Thought to Statement Translation Template\nDESCRIPTION: Template that takes a persona name and their inner thought as inputs to formulate a third-person statement about that persona. Uses placeholder variables INPUT 0 (persona name) and INPUT 1 (whisper/thought content).\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/ext/stanford_town/prompts/whisper_inner_thought_v1.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nTranslate the following thought into a statement about !<INPUT 0>!. \n\nThought: \"!<INPUT 1>!\"\nStatement: \"\n```\n\n----------------------------------------\n\nTITLE: Defining Android UI Tap Action\nDESCRIPTION: Specifies a tap action targeting a TextView component within the Apps view hierarchy. The identifier includes the component path and coordinates (1067_236 and 183_204).\nSOURCE: https://github.com/geekan/metagpt/blob/main/tests/data/andriod_assistant/demo_Contacts/record.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ntap(9):::android.view.ViewGroup_1067_236_android.widget.TextView_183_204_Apps_2\n```\n\n----------------------------------------\n\nTITLE: Processing Input for Summarization in Plaintext\nDESCRIPTION: This snippet demonstrates a template for processing input text for summarization. It includes a greeting and a placeholder for the actual input to be summarized.\nSOURCE: https://github.com/geekan/metagpt/blob/main/metagpt/skills/SummarizeSkill/Summarize/skprompt.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nHello how are you?\n+++++\nHello\n\nSummarize this\n{{$input}}\n+++++\n```"
  }
]