[
  {
    "owner": "ultralytics",
    "repo": "yolov5",
    "content": "TITLE: Setting up YOLOv5 environment in Python\nDESCRIPTION: This snippet clones the YOLOv5 repository, installs required dependencies, and initializes the environment for YOLOv5 usage. It also checks PyTorch and GPU availability.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt comet_ml  # install\n\nimport torch\n\nimport utils\n\ndisplay = utils.notebook_init()  # checks\n```\n\n----------------------------------------\n\nTITLE: Performing Inference with PyTorch Hub\nDESCRIPTION: Python code demonstrating how to load a YOLOv5 model using PyTorch Hub and perform inference on an image.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\n# Load a YOLOv5 model (options: yolov5n, yolov5s, yolov5m, yolov5l, yolov5x)\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")  # Default: yolov5s\n\n# Define the input image source (URL, local file, PIL image, OpenCV frame, numpy array, or list)\nimg = \"https://ultralytics.com/images/zidane.jpg\"  # Example image\n\n# Perform inference (handles batching, resizing, normalization automatically)\nresults = model(img)\n\n# Process the results (options: .print(), .show(), .save(), .crop(), .pandas())\nresults.print()  # Print results to console\nresults.show()  # Display results in a window\nresults.save()  # Save results to runs/detect/exp\n```\n\n----------------------------------------\n\nTITLE: Installing Ultralytics Package\nDESCRIPTION: Command to install the Ultralytics package using pip for YOLO11 functionality.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Install the ultralytics package\npip install ultralytics\n```\n\n----------------------------------------\n\nTITLE: Running Inference with detect.py Script\nDESCRIPTION: Bash commands showing various ways to use the detect.py script for object detection on different input sources.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Run inference using a webcam\npython detect.py --weights yolov5s.pt --source 0\n\n# Run inference on a local image file\npython detect.py --weights yolov5s.pt --source img.jpg\n\n# Run inference on a local video file\npython detect.py --weights yolov5s.pt --source vid.mp4\n\n# Run inference on a screen capture\npython detect.py --weights yolov5s.pt --source screen\n\n# Run inference on a directory of images\npython detect.py --weights yolov5s.pt --source path/to/images/\n\n# Run inference on a text file listing image paths\npython detect.py --weights yolov5s.pt --source list.txt\n\n# Run inference on a text file listing stream URLs\npython detect.py --weights yolov5s.pt --source list.streams\n\n# Run inference using a glob pattern for images\npython detect.py --weights yolov5s.pt --source 'path/to/*.jpg'\n\n# Run inference on a YouTube video URL\npython detect.py --weights yolov5s.pt --source 'https://youtu.be/LNwODJXcvt4'\n```\n\n----------------------------------------\n\nTITLE: Setting up YOLOv5 Environment in Python\nDESCRIPTION: Clones the YOLOv5 repository, installs required dependencies, and performs initial setup checks including PyTorch and GPU verification.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt comet_ml  # install\n\nimport torch\nimport utils\ndisplay = utils.notebook_init()  # checks\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Detection\nDESCRIPTION: Executes YOLOv5 detection with specific weights, image size, and confidence threshold on sample images.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5s on COCO Dataset in Bash\nDESCRIPTION: Trains YOLOv5s model on COCO dataset for 300 epochs with a batch size of 64.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5s.yaml --batch-size 64\n```\n\n----------------------------------------\n\nTITLE: YOLOv5 PyTorch HUB Inference for Detection Models\nDESCRIPTION: This Python code snippet demonstrates how to load a YOLOv5 model using PyTorch Hub, perform inference on an image, and display or process the results. It supports various YOLOv5 models and can handle different input types.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n\nmodel = torch.hub.load(\n    \"ultralytics/yolov5\", \"yolov5s-seg\", force_reload=True, trust_repo=True\n)  # or yolov5n - yolov5x6 or custom\nim = \"https://ultralytics.com/images/zidane.jpg\"  # file, Path, PIL.Image, OpenCV, nparray, list\nresults = model(im)  # inference\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Model\nDESCRIPTION: Trains YOLOv5s model on COCO128 dataset for 3 epochs with specified image size, batch size, and caching enabled.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5l on COCO Dataset in Bash\nDESCRIPTION: Trains YOLOv5l model on COCO dataset for 300 epochs with a batch size of 24.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5l.yaml --batch-size 24\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5x on COCO Dataset in Bash\nDESCRIPTION: Trains YOLOv5x model on COCO dataset for 300 epochs with a batch size of 16.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5x.yaml --batch-size 16\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Segmentation prediction in Python\nDESCRIPTION: This snippet runs YOLOv5 segmentation prediction on sample images using specific weights, image size, and confidence threshold.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!python segment/predict.py --weights yolov5s-seg.pt --img 640 --conf 0.25 --source data/images\n# display.Image(filename='runs/predict-seg/exp/zidane.jpg', width=600)\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Segmentation Model on Single GPU\nDESCRIPTION: Command to train a YOLOv5 segmentation model on a single GPU using the COCO128-seg dataset and YOLOv5s-seg weights.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\npython segment/train.py --data coco128-seg.yaml --weights yolov5s-seg.pt --img 640\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5m on COCO Dataset in Bash\nDESCRIPTION: Trains YOLOv5m model on COCO dataset for 300 epochs with a batch size of 40.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5m.yaml --batch-size 40\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Segmentation Model with Multi-GPU DDP\nDESCRIPTION: Command to train a YOLOv5 segmentation model using Multi-GPU Distributed Data Parallel (DDP) with 4 GPUs.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npython -m torch.distributed.run --nproc_per_node 4 --master_port 1 segment/train.py --data coco128-seg.yaml --weights yolov5s-seg.pt --img 640 --device 0,1,2,3\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5n on COCO Dataset in Bash\nDESCRIPTION: Trains YOLOv5n model on COCO dataset for 300 epochs with a batch size of 128.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5n.yaml --batch-size 128\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Segmentation model in Python\nDESCRIPTION: This snippet trains a YOLOv5s segmentation model on the COCO128 dataset for 3 epochs, using specific image size, batch size, and pretrained weights.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n!python segment/train.py --img 640 --batch 16 --epochs 3 --data coco128-seg.yaml --weights yolov5s-seg.pt --cache\n```\n\n----------------------------------------\n\nTITLE: Loading YOLOv5 Segmentation Model from PyTorch Hub\nDESCRIPTION: Python code to load a custom YOLOv5m-seg model from PyTorch Hub for inference.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"custom\", \"yolov5m-seg.pt\")\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Classification Model on Imagenette Dataset\nDESCRIPTION: Trains a YOLOv5s classification model on the Imagenette160 dataset for 5 epochs with 224Ã—224 input size and caching enabled for faster training.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Train YOLOv5s Classification on Imagenette160 for 3 epochs\n!python classify/train.py --model yolov5s-cls.pt --data imagenette160 --epochs 5 --img 224 --cache\n```\n\n----------------------------------------\n\nTITLE: Running the YOLOv5 API Server\nDESCRIPTION: This command starts the Flask API server on the specified port (default 5000). It allows you to send inference requests to the API endpoint.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/flask_rest_api/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython restapi.py --port 5000\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 Classification Models\nDESCRIPTION: Commands for training YOLOv5 classification models on single and multi-GPU setups using CIFAR-100 and ImageNet datasets. Supports various datasets including MNIST, Fashion-MNIST, CIFAR10, and others.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\n# Train on a single GPU using CIFAR-100 dataset\npython classify/train.py --model yolov5s-cls.pt --data cifar100 --epochs 5 --img 224 --batch 128\n\n# Train using Multi-GPU DDP on ImageNet dataset\npython -m torch.distributed.run --nproc_per_node 4 --master_port 1 classify/train.py --model yolov5s-cls.pt --data imagenet --epochs 5 --img 224 --device 0,1,2,3\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Segmentation prediction in Shell\nDESCRIPTION: This snippet demonstrates how to run YOLOv5 instance segmentation inference on various sources using the segment/predict.py script. It includes examples for different input types like webcam, image, video, and online streams.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython segment/predict.py --source 0  # webcam\n                             img.jpg  # image \n                             vid.mp4  # video\n                             screen  # screenshot\n                             path/  # directory\n                             'path/*.jpg'  # glob\n                             'https://youtu.be/LNwODJXcvt4'  # YouTube\n                             'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n```\n\n----------------------------------------\n\nTITLE: Validating YOLOv5 Classification Models\nDESCRIPTION: Commands for validating YOLOv5 classification models on the ImageNet-1k validation dataset, including dataset download and model validation steps.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\n# Download ImageNet validation split (6.3GB, 50,000 images)\nbash data/scripts/get_imagenet.sh --val\n\n# Validate the model\npython classify/val.py --weights yolov5m-cls.pt --data ../datasets/imagenet --img 224\n```\n\n----------------------------------------\n\nTITLE: Validating YOLOv5 Segmentation Model\nDESCRIPTION: Command to validate the YOLOv5s-seg model on the COCO dataset, evaluating mask mean Average Precision (mAP).\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\npython segment/val.py --weights yolov5s-seg.pt --data coco.yaml --img 640\n```\n\n----------------------------------------\n\nTITLE: Predicting with YOLOv5 Classification Models\nDESCRIPTION: Examples of using YOLOv5 classification models for prediction, including both command-line interface and PyTorch Hub loading methods.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\n# Run prediction\npython classify/predict.py --weights yolov5s-cls.pt --source data/images/bus.jpg\n```\n\nLANGUAGE: python\nCODE:\n```\n# Load model from PyTorch Hub\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"custom\", \"yolov5s-cls.pt\")\n```\n\n----------------------------------------\n\nTITLE: Exporting YOLOv5 Classification Models\nDESCRIPTION: Command for exporting trained YOLOv5 classification models to ONNX and TensorRT formats, supporting multiple model architectures in a single export command.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\n# Export models\npython export.py --weights yolov5s-cls.pt resnet50.pt efficientnet_b0.pt --include onnx engine --img 224\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Inference on Video Stream in Python\nDESCRIPTION: Demonstrates how to run inference on an RTSP, RTMP, or HTTP video stream using a pre-trained YOLOv5s model.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npython detect.py --weights yolov5s.pt --source 'rtsp://example.com/media.mp4'\n```\n\n----------------------------------------\n\nTITLE: Validating YOLOv5 Segmentation model in Python\nDESCRIPTION: This snippet validates the YOLOv5s-seg model on the COCO validation dataset, using specific weights, data configuration, and image size.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!python segment/val.py --weights yolov5s-seg.pt --data coco.yaml --img 640 --half\n```\n\n----------------------------------------\n\nTITLE: Predicting with YOLOv5 Segmentation Model\nDESCRIPTION: Command to perform segmentation prediction on an image using the pretrained YOLOv5m-seg model.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\npython segment/predict.py --weights yolov5m-seg.pt --source data/images/bus.jpg\n```\n\n----------------------------------------\n\nTITLE: Validating YOLOv5 Model\nDESCRIPTION: Performs validation of YOLOv5s model on COCO validation dataset with specified parameters.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half\n```\n\n----------------------------------------\n\nTITLE: Exporting YOLOv5 Segmentation Model\nDESCRIPTION: Command to export the YOLOv5s-seg model to ONNX and TensorRT formats with specified image size and device.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\npython export.py --weights yolov5s-seg.pt --include onnx engine --img 640 --device 0\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 with Test Time Augmentation\nDESCRIPTION: Command to run YOLOv5 with Test Time Augmentation (TTA) for improved accuracy on the COCO dataset.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\npython val.py --data coco.yaml --img 1536 --iou 0.7 --augment\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Classification Inference on Images\nDESCRIPTION: Execute the classify/predict.py script to run YOLOv5 classification inference on sample images. This uses a pre-trained classification model with 224Ã—224 image size.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!python classify/predict.py --weights yolov5s-cls.pt --img 224 --source data/images\n# display.Image(filename='runs/predict-cls/exp/zidane.jpg', width=600)\n```\n\n----------------------------------------\n\nTITLE: Measuring YOLOv5 Inference Speed\nDESCRIPTION: Command to measure YOLOv5 inference speed on the COCO dataset using specific parameters.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython val.py --data coco.yaml --img 640 --task speed --batch 1\n```\n\n----------------------------------------\n\nTITLE: Validating YOLOv5 Classification Model on ImageNet\nDESCRIPTION: Runs validation of the YOLOv5s classification model on the ImageNet validation dataset with half-precision inference for faster processing.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Validate YOLOv5s on Imagenet val\n!python classify/val.py --weights yolov5s-cls.pt --data ../datasets/imagenet --img 224 --half\n```\n\n----------------------------------------\n\nTITLE: Reproducing YOLOv5 Performance Study Results\nDESCRIPTION: Command to reproduce the YOLOv5 performance study results using different model sizes on the COCO dataset.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\npython val.py --task study --data coco.yaml --iou 0.7 --weights yolov5n6.pt yolov5s6.pt yolov5m6.pt yolov5l6.pt yolov5x6.pt\n```\n\n----------------------------------------\n\nTITLE: YOLOv5 PyTorch HUB Inference for Detection Models\nDESCRIPTION: This Python code demonstrates how to use YOLOv5 for inference using PyTorch HUB. It loads a pre-trained model, performs inference on an image, and shows how to access the results. The example uses the 'yolov5s' model, but other variants can be specified.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# YOLOv5 PyTorch HUB Inference (DetectionModels only)\nimport torch\n\nmodel = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, trust_repo=True)  # or yolov5n - yolov5x6 or custom\nim = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\nresults = model(im)  # inference\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\n\n----------------------------------------\n\nTITLE: YOLOv5 Classification Inference Command Examples\nDESCRIPTION: Shell command examples showing different source options for the YOLOv5 classification prediction script, including webcam, image files, videos, and streams.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\npython classify/predict.py --source 0  # webcam\n                              img.jpg  # image \n                              vid.mp4  # video\n                              screen  # screenshot\n                              path/  # directory\n                              'path/*.jpg'  # glob\n                              'https://youtu.be/LNwODJXcvt4'  # YouTube\n                              'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n```\n\n----------------------------------------\n\nTITLE: Performing Inference with YOLOv5 using PyTorch Hub\nDESCRIPTION: Demonstrates how to load a YOLOv5 model from PyTorch Hub and perform inference on an image. The code shows model loading, image processing, and accessing results through various methods like print, show, save, crop, or pandas conversion.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n\nmodel = torch.hub.load(\n    \"ultralytics/yolov5\", \"yolov5s\", force_reload=True, trust_repo=True\n)  # or yolov5n - yolov5x6 or custom\nim = \"https://ultralytics.com/images/zidane.jpg\"  # file, Path, PIL.Image, OpenCV, nparray, list\nresults = model(im)  # inference\nresults.print()  # or .show(), .save(), .crop(), .pandas(), etc.\n```\n\n----------------------------------------\n\nTITLE: YOLOv5 API JSON Response Format\nDESCRIPTION: This JSON snippet shows the format of the API response, including detected objects with their class ID, confidence score, bounding box coordinates, and class name.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/flask_rest_api/README.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n[\n  {\n    \"class\": 0,\n    \"confidence\": 0.8900438547,\n    \"height\": 0.9318675399,\n    \"name\": \"person\",\n    \"width\": 0.3264600933,\n    \"xcenter\": 0.7438579798,\n    \"ycenter\": 0.5207948685\n  },\n  {\n    \"class\": 0,\n    \"confidence\": 0.8440024257,\n    \"height\": 0.7155083418,\n    \"name\": \"person\",\n    \"width\": 0.6546785235,\n    \"xcenter\": 0.427829951,\n    \"ycenter\": 0.6334488392\n  },\n  {\n    \"class\": 27,\n    \"confidence\": 0.3771208823,\n    \"height\": 0.3902671337,\n    \"name\": \"tie\",\n    \"width\": 0.0696444362,\n    \"xcenter\": 0.3675483763,\n    \"ycenter\": 0.7991207838\n  },\n  {\n    \"class\": 27,\n    \"confidence\": 0.3527112305,\n    \"height\": 0.1540903747,\n    \"name\": \"tie\",\n    \"width\": 0.0336618312,\n    \"xcenter\": 0.7814827561,\n    \"ycenter\": 0.5065554976\n  }\n]\n```\n\n----------------------------------------\n\nTITLE: Reproducing YOLOv5 mAP Validation Results\nDESCRIPTION: Command to reproduce YOLOv5 mAP validation results on the COCO dataset with specific parameters.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\npython val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65\n```\n\n----------------------------------------\n\nTITLE: Installing Flask for YOLOv5 API\nDESCRIPTION: This command installs the Flask web framework, which is the primary requirement for running the YOLOv5 REST API.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/flask_rest_api/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install Flask\n```\n\n----------------------------------------\n\nTITLE: YOLOv5 Detection Command Options\nDESCRIPTION: Shows various command line options for running object detection using YOLOv5 on different input sources like webcam, images, videos, and streams.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython detect.py --source 0  # webcam\n                      img.jpg  # image\n                      vid.mp4  # video\n                      screen  # screenshot\n                      path/  # directory\n                     'path/*.jpg'  # glob\n                     'https://youtu.be/LNwODJXcvt4'  # YouTube\n                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n```\n\n----------------------------------------\n\nTITLE: Running YOLOv5 Hyperparameter Optimization with Comet\nDESCRIPTION: This command initiates a hyperparameter optimization sweep for YOLOv5 using Comet Optimizer. It specifies the optimizer configuration file and additional fixed arguments for the sweep.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\npython utils/loggers/comet/hpo.py \\\n  --comet_optimizer_config \"utils/loggers/comet/optimizer_config.json\" \\\n  --save-period 1 \\\n  --bbox_interval 1\n```\n\n----------------------------------------\n\nTITLE: Uploading Dataset for YOLOv5 Training with Comet\nDESCRIPTION: This command demonstrates how to upload a dataset to Comet while training a YOLOv5 model. It specifies image size, batch size, number of epochs, dataset configuration, pre-trained weights, and enables dataset upload.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\npython train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data coco128.yaml \\\n  --weights yolov5s.pt \\\n  --upload_dataset # Upload the dataset specified in coco128.yaml\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution of YOLOv5 Hyperparameter Sweep with Comet\nDESCRIPTION: This command demonstrates how to run multiple YOLOv5 hyperparameter sweep trials concurrently using the Comet Optimizer. It specifies the number of parallel workers and the optimizer configuration file.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncomet optimizer -j \\\n  utils/loggers/comet/hpo.py NUM_WORKERS utils/loggers/comet/optimizer_config.json\n```\n\n----------------------------------------\n\nTITLE: Training YOLOv5 with Comet Artifact Dataset\nDESCRIPTION: This command demonstrates how to train a YOLOv5 model using a dataset stored in Comet Artifacts. It specifies image size, batch size, number of epochs, the Artifact dataset configuration, and pre-trained weights.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\npython train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data artifact.yaml \\\n  --weights yolov5s.pt\n```\n\n----------------------------------------\n\nTITLE: Running Hyperparameter Optimization\nDESCRIPTION: Commands to install Optuna and run the hyperparameter optimization script for YOLO training.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# pip install optuna\n\npython utils/loggers/clearml/hpo.py\n```\n\n----------------------------------------\n\nTITLE: Resuming YOLOv5 Training with Comet Run Path\nDESCRIPTION: This command shows how to resume an interrupted YOLOv5 training run using the Comet Run Path. It restores the model state, hyperparameters, and arguments, continuing logging to the existing Comet Experiment.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\npython train.py \\\n  --resume \"comet://YOUR_WORKSPACE/YOUR_PROJECT/EXPERIMENT_ID\"\n```\n\n----------------------------------------\n\nTITLE: Basic YOLO Training with ClearML\nDESCRIPTION: Command to train YOLO on COCO128 dataset for 3 epochs with default ClearML tracking enabled.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache\n```\n\n----------------------------------------\n\nTITLE: Installing and Running YOLOv5 with Comet Integration\nDESCRIPTION: This code snippet demonstrates how to install Comet, set the API key, and run YOLOv5 training with Comet logging enabled. It includes steps for installation, API key configuration, and initiating the training process.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\npip install comet_ml  # 1. install\nexport COMET_API_KEY=<Your API Key>  # 2. paste API key\npython train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Comet ML with YOLOv5\nDESCRIPTION: This snippet demonstrates how to install Comet ML, set the API key, and run YOLOv5 training with Comet logging enabled. It requires a Comet API key and the YOLOv5 repository.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\npip install comet_ml  # 1. install\nexport COMET_API_KEY=<Your API Key>  # 2. paste API key\npython train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train\n```\n\n----------------------------------------\n\nTITLE: Comet ML Integration with YOLOv5 Training\nDESCRIPTION: Shell commands showing how to integrate Comet ML for experiment tracking with YOLOv5. This includes installing Comet, setting the API key, and running training with automatic logging.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\npip install comet_ml  # 1. install\nexport COMET_API_KEY=<Your API Key>  # 2. paste API key\npython train.py --img 640 --epochs 3 --data coco128.yaml --weights yolov5s.pt  # 3. train\n```\n\n----------------------------------------\n\nTITLE: Running YOLO Training with Custom Prediction Logging\nDESCRIPTION: Command to run YOLO training with custom interval for logging model predictions.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\npython train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data coco128.yaml \\\n  --weights yolov5s.pt \\\n  --bbox_interval 2 # Log predictions every 2nd validation batch per epoch\n```\n\n----------------------------------------\n\nTITLE: Running YOLO Training with Checkpoint Logging\nDESCRIPTION: Command to run YOLO training with checkpoint saving enabled for Comet logging.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npython train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data coco128.yaml \\\n  --weights yolov5s.pt \\\n  --save-period 1 # Save checkpoint every epoch\n```\n\n----------------------------------------\n\nTITLE: Running YOLO Training with Custom Image Upload Limit\nDESCRIPTION: Command to run YOLO training with a custom limit on the number of validation images logged to Comet.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nenv COMET_MAX_IMAGE_UPLOADS=200 python train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data coco128.yaml \\\n  --weights yolov5s.pt \\\n  --bbox_interval 1 # Log every batch\n```\n\n----------------------------------------\n\nTITLE: Running YOLO Training with Per-Class Metric Logging\nDESCRIPTION: Command to run YOLO training with logging of per-class metrics enabled in Comet.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\nenv COMET_LOG_PER_CLASS_METRICS=true python train.py \\\n  --img 640 \\\n  --batch 16 \\\n  --epochs 5 \\\n  --data coco128.yaml \\\n  --weights yolov5s.pt\n```\n\n----------------------------------------\n\nTITLE: Starting ClearML Agent\nDESCRIPTION: Command to start a ClearML agent for remote execution with optional Docker support.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nclearml-agent daemon --queue QUEUES_TO_LISTEN_TO [--docker]\n```\n\n----------------------------------------\n\nTITLE: Custom Project YOLO Training\nDESCRIPTION: Training command with custom project and experiment names specified for ClearML tracking.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --project my_yolo_project --name experiment_001 --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache\n```\n\n----------------------------------------\n\nTITLE: ClearML Dataset Upload Commands\nDESCRIPTION: Commands to create and upload a dataset version to ClearML using the clearml-data CLI tool.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd ../datasets/coco128\nclearml-data sync --project YOLO_Datasets --name coco128 --folder .\n```\n\nLANGUAGE: bash\nCODE:\n```\nclearml-data create --project YOLO_Datasets --name coco128\nclearml-data add --files .\nclearml-data close\n```\n\n----------------------------------------\n\nTITLE: Training with ClearML Dataset\nDESCRIPTION: Command to train YOLO using a versioned dataset from ClearML, referenced by its dataset ID.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --img 640 --batch 16 --epochs 3 --data clearml://YOUR_DATASET_ID --weights yolov5s.pt --cache\n```\n\n----------------------------------------\n\nTITLE: Setting Advanced Comet Configuration via Environment Variables\nDESCRIPTION: Shell commands to set various Comet configuration options using environment variables.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nexport COMET_MODE=online\nexport COMET_MODEL_NAME=YOUR_MODEL_NAME\nexport COMET_LOG_CONFUSION_MATRIX=false\nexport COMET_MAX_IMAGE_UPLOADS=NUMBER\nexport COMET_LOG_PER_CLASS_METRICS=true\nexport COMET_DEFAULT_CHECKPOINT_FILENAME=checkpoint_file.pt\nexport COMET_LOG_BATCH_LEVEL_METRICS=true\nexport COMET_LOG_PREDICTIONS=true\n```\n\n----------------------------------------\n\nTITLE: Running YOLO Training Script with Comet Integration\nDESCRIPTION: Command to run the YOLO training script, which will automatically log to Comet.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython train.py --img 640 --batch 16 --epochs 5 --data coco128.yaml --weights yolov5s.pt\n```\n\n----------------------------------------\n\nTITLE: Configuring Comet via Configuration File\nDESCRIPTION: Content of a .comet.config file for setting Comet API key and project name.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\n[comet]\napi_key=YOUR_COMET_API_KEY\nproject_name=YOUR_COMET_PROJECT_NAME # Defaults to 'yolov5' if not set\n```\n\n----------------------------------------\n\nTITLE: Setting up YOLOv5 Training Logger\nDESCRIPTION: Configures logging options for training with support for Comet, ClearML, or TensorBoard.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlogger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n\nif logger == 'Comet':\n  %pip install -q comet_ml\n  import comet_ml; comet_ml.init()\nelif logger == 'ClearML':\n  %pip install -q clearml\n  import clearml; clearml.browser_login()\nelif logger == 'TensorBoard':\n  %load_ext tensorboard\n  %tensorboard --logdir runs/train\n```\n\n----------------------------------------\n\nTITLE: Installing Comet ML Package with pip\nDESCRIPTION: Command to install the comet_ml Python package using pip.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install comet_ml\n```\n\n----------------------------------------\n\nTITLE: Setting up Experiment Tracking for YOLOv5 Training\nDESCRIPTION: Configures experiment tracking with options for Comet, ClearML, or TensorBoard. This code installs the selected logger and initializes it for tracking model metrics during training.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# @title Select YOLOv5 ðŸš€ logger {run: 'auto'}\nlogger = \"Comet\"  # @param ['Comet', 'ClearML', 'TensorBoard']\n\nif logger == \"Comet\":\n    %pip install -q comet_ml\n    import comet_ml\n\n    comet_ml.init()\nelif logger == \"ClearML\":\n    %pip install -q clearml\n    import clearml\n\n    clearml.browser_login()\nelif logger == \"TensorBoard\":\n    %load_ext tensorboard\n    %tensorboard --logdir runs/train\n```\n\n----------------------------------------\n\nTITLE: Configuring logger for YOLOv5 training in Python\nDESCRIPTION: This snippet sets up a logger for YOLOv5 training, allowing the user to choose between Comet, ClearML, or TensorBoard for logging training progress and results.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# @title Select YOLOv5 ðŸš€ logger {run: 'auto'}\nlogger = \"Comet\"  # @param ['Comet', 'ClearML', 'TensorBoard']\n\nif logger == \"Comet\":\n    %pip install -q comet_ml\n    import comet_ml\n\n    comet_ml.init()\nelif logger == \"ClearML\":\n    %pip install -q clearml\n    import clearml\n\n    clearml.browser_login()\nelif logger == \"TensorBoard\":\n    %load_ext tensorboard\n    %tensorboard --logdir runs/train\n```\n\n----------------------------------------\n\nTITLE: Modifying YOLOv5 Training Script for Remote Execution with ClearML\nDESCRIPTION: This code snippet shows how to modify the YOLOv5 train.py script to enable remote execution using ClearML. It adds a line to enqueue the task to a specified remote queue after initializing the ClearML logger.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Inside train.py, after logger initialization...\nif RANK in {-1, 0}:\n    # Initialize loggers\n    loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)\n\n    # Check if ClearML logger is active and enqueue the task\n    if loggers.clearml:\n        # Specify the queue name for the remote agent\n        loggers.clearml.task.execute_remotely(queue_name=\"my_remote_queue\")  # <------ ADD THIS LINE\n        # data_dict might be populated by ClearML if using a ClearML dataset\n        data_dict = loggers.clearml.data_dict\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset YAML for Comet Artifact Usage\nDESCRIPTION: This YAML configuration shows how to reference a dataset stored in Comet Artifacts. It specifies the Artifact resource URL and the subdirectories for training and validation data.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n# contents of artifact.yaml\npath: \"comet://WORKSPACE_NAME/ARTIFACT_NAME:ARTIFACT_VERSION_OR_ALIAS\"\ntrain: images/train # Adjust subdirectory if needed\nval: images/val # Adjust subdirectory if needed\n\n# Other dataset configurations...\n```\n\n----------------------------------------\n\nTITLE: Downloading COCO Validation Dataset\nDESCRIPTION: Downloads and extracts the COCO validation dataset for model evaluation.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntorch.hub.download_url_to_file('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017val.zip', 'tmp.zip')\n!unzip -q tmp.zip -d ../datasets && rm tmp.zip\n```\n\n----------------------------------------\n\nTITLE: Downloading ImageNet Validation Dataset\nDESCRIPTION: Downloads the ImageNet validation dataset (6.3GB, 50,000 images) for model validation using a provided shell script.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Download Imagenet val (6.3G, 50000 images)\n!bash data/scripts/get_imagenet.sh --val\n```\n\n----------------------------------------\n\nTITLE: Downloading COCO validation dataset in Python\nDESCRIPTION: This snippet downloads the COCO validation dataset for segmentation tasks using a shell script.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/segment/tutorial.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!bash data/scripts/get_coco.sh --val --segments  # download (780M - 5000 images)\n```\n\n----------------------------------------\n\nTITLE: Downloading COCO Validation Segments\nDESCRIPTION: Bash command to download the COCO validation segments dataset (780MB, 5000 images).\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nbash data/scripts/get_coco.sh --val --segments\n```\n\n----------------------------------------\n\nTITLE: Testing YOLOv5 API with curl\nDESCRIPTION: This curl command sends a POST request to the API endpoint with a local image file for object detection using the YOLOv5s model.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/flask_rest_api/README.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -F image=@../data/images/zidane.jpg 'http://localhost:5000/v1/object-detection/yolov5s'\n```\n\n----------------------------------------\n\nTITLE: Setting up YOLOv5 Environment in Python\nDESCRIPTION: Clone the YOLOv5 repository, install required dependencies, and initialize necessary utilities. This setup code checks PyTorch installation and GPU availability.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!git clone https://github.com/ultralytics/yolov5  # clone\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nimport torch\n\nimport utils\n\ndisplay = utils.notebook_init()  # checks\n```\n\n----------------------------------------\n\nTITLE: Installing YOLOv5 Dependencies\nDESCRIPTION: Commands to clone the YOLOv5 repository and install required packages using pip.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Clone the YOLOv5 repository\ngit clone https://github.com/ultralytics/yolov5\n\n# Navigate to the cloned directory\ncd yolov5\n\n# Install required packages\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Defining YOLOv5 Dependencies in requirements.txt\nDESCRIPTION: This snippet lists all the required Python packages and their minimum versions for the YOLOv5 project. It includes base dependencies, optional logging and plotting libraries, and packages for various export formats and deployment scenarios.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\n# YOLOv5 requirements\n# Usage: pip install -r requirements.txt\n\n# Base ------------------------------------------------------------------------\ngitpython>=3.1.30\nmatplotlib>=3.3\nnumpy>=1.23.5\nopencv-python>=4.1.1\npillow>=10.3.0\npsutil  # system resources\nPyYAML>=5.3.1\nrequests>=2.32.2\nscipy>=1.4.1\nthop>=0.1.1  # FLOPs computation\ntorch>=1.8.0  # see https://pytorch.org/get-started/locally (recommended)\ntorchvision>=0.9.0\ntqdm>=4.66.3\nultralytics>=8.2.34  # https://ultralytics.com\n# protobuf<=3.20.1  # https://github.com/ultralytics/yolov5/issues/8012\n\n# Logging ---------------------------------------------------------------------\n# tensorboard>=2.4.1\n# clearml>=1.2.0\n# comet\n\n# Plotting --------------------------------------------------------------------\npandas>=1.1.4\nseaborn>=0.11.0\n\n# Export ----------------------------------------------------------------------\n# coremltools>=6.0  # CoreML export\n# onnx>=1.10.0  # ONNX export\n# onnx-simplifier>=0.4.1  # ONNX simplifier\n# nvidia-pyindex  # TensorRT export\n# nvidia-tensorrt  # TensorRT export\n# scikit-learn<=1.1.2  # CoreML quantization\n# tensorflow>=2.4.0,<=2.13.1  # TF exports (-cpu, -aarch64, -macos)\n# tensorflowjs>=3.9.0  # TF.js export\n# openvino-dev>=2023.0  # OpenVINO export\n\n# Deploy ----------------------------------------------------------------------\nsetuptools>=70.0.0 # Snyk vulnerability fix\n# tritonclient[all]~=2.24.0\n\n# Extras ----------------------------------------------------------------------\n# ipython  # interactive notebook\n# mss  # screenshots\n# albumentations>=1.0.3\n# pycocotools>=2.0.6  # COCO mAP\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for YOLOv5 Flask Application\nDESCRIPTION: This code snippet lists the Python package dependencies required for a Flask application in the YOLOv5 project. It specifies versions for pip, Flask, and gunicorn, along with minimum versions for werkzeug and zipp to address potential vulnerabilities.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/google_app_engine/additional_requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# add these requirements in your app on top of the existing ones\npip==23.3\nFlask==2.3.2\ngunicorn==23.0.0\nwerkzeug>=3.0.1 # not directly required, pinned by Snyk to avoid a vulnerability\nzipp>=3.19.1 # not directly required, pinned by Snyk to avoid a vulnerability\n```\n\n----------------------------------------\n\nTITLE: Installing ClearML Package\nDESCRIPTION: Command to install the ClearML Python package via pip. This package is included in YOLO requirements.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/clearml/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install clearml\n```\n\n----------------------------------------\n\nTITLE: Setting Comet Credentials via Environment Variables\nDESCRIPTION: Shell commands to set Comet API key and project name as environment variables.\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/utils/loggers/comet/README.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport COMET_API_KEY=YOUR_COMET_API_KEY\nexport COMET_PROJECT_NAME=YOUR_COMET_PROJECT_NAME # Defaults to 'yolov5' if not set\n```\n\n----------------------------------------\n\nTITLE: Git Update Branch Commands\nDESCRIPTION: Commands to update a local branch with the latest changes from the master branch\nSOURCE: https://github.com/ultralytics/yolov5/blob/master/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit pull\ngit merge master\n```"
  }
]