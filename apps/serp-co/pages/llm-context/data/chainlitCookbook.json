[
  {
    "owner": "chainlit",
    "repo": "cookbook",
    "content": "TITLE: Setting up Environment Variables for Azure OpenAI and Pinecone Integration\nDESCRIPTION: A template for the .env file containing all required environment variables for connecting to Azure OpenAI services and Pinecone vector database. Includes API keys, endpoints, model deployment names, and version specifications.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nAZURE_OPENAI_API_KEY=d49e7825c734484b86c6803d4452ce68 \n# replace with your Azure OpenAI API Key\n\nAZURE_OPENAI_ENDPOINT=https://pineconellmdemoopenai.openai.azure.com/ \n# replace with your Azure OpenAI Endpoint\n\nAZURE_OPENAI_CHAT_DEPLOYMENT_NAME=gpt-35-turbo-16k\n#Create a deployment for the gpt-35-turbo-16k model and place the deployment name here. You can name the deployment as per your choice and put the name here. #In my case, I have named it as `gpt-35-turbo-16k`.\n\nAZURE_OPENAI_CHAT_DEPLOYMENT_VERSION=2023-07-01-preview \n#You don't need to change this unless you are willing to try other versions.\n\nPINECONE_API_KEY=a592424f-ba4e-4c66-a0d2-deda1dcd1de9 \n#Change this to your Pinecone API Key\n\nAZURE_OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002 \n#Create a new deployment in the Azure Open AI Studio using the text-embedding-ada-002 #model and place the deployment name here. You can name the deployment #as per your #choice and put the name here. In my case, I have named it as `text-embedding-ada-002`.\n\nAZURE_OPENAI_ADA_EMBEDDING_MODEL_NAME=text-embedding-ada-002 \n#This is the model name of the text-embedding-ada-002 deployment model from above. You don't need to change it as it will be the same in your case.\n\nAZURE_OPENAI_ADA_DEPLOYMENT_VERSION=2024-02-15-preview\n#You don't need to change this unless you are willing to try earlier versions.\n```\n\n----------------------------------------\n\nTITLE: Initializing Llama2 Chat Session with ChainLit\nDESCRIPTION: Defines the main function decorated with @cl.on_chat_start that initializes an LLM chain with a prompt for answering questions using Llama2. This function is triggered when a new chat session begins.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\ndef main(): Initializes the LLM chain with a prompt for answering questions.\n```\n\n----------------------------------------\n\nTITLE: Processing Messages with Llama2 in ChainLit\nDESCRIPTION: Defines the run function that processes incoming messages and provides responses using the Llama2 LLM chain. This function handles the interaction between user inputs and model outputs.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef run(): Processes incoming messages and provides responses using the LLM chain.\n```\n\n----------------------------------------\n\nTITLE: Loading Llama2 Model from HuggingFace in ChainLit\nDESCRIPTION: Defines the load_llama function that loads a Llama2 model from HuggingFace with specific tokenizer and streamer configurations. This function prepares the model for chat interactions.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef load_llama(): Loads the Llama2 model from HuggingFace with the specified tokenizer and streamer.\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Function for OpenAI Functions in Python\nDESCRIPTION: A sample function that returns weather information for a specified location. This function demonstrates how to structure data for OpenAI function calls, including parameters like location and temperature unit, and returns the weather data as a JSON string.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-functions/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location, unit=\"Fahrenheit\"):\n\"\"\"Get the current weather in a given location\"\"\"\nweather_info = {\n\"location\": location,\n\"temperature\": \"72\",\n\"unit\": unit,\n\"forecast\": [\"sunny\", \"windy\"],\n}\nreturn json.dumps(weather_info)\n```\n\n----------------------------------------\n\nTITLE: Initializing LlamaCpp Chat Session with ChainLit\nDESCRIPTION: Defines the main function decorated with @cl.on_chat_start that sets up a conversation chain with a system prompt for code generation. This function is triggered when a new chat session begins.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\ndef main(): Sets up the conversation chain with a system prompt for code generation.\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Element and Callback in Chainlit\nDESCRIPTION: This code snippet demonstrates how to create a CustomElement in Chainlit, display it to the user, and handle user interactions through a callback function. It uses the Chainlit library to create a simple button element and process clicks.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-element/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_chat_start\nasync def start():\n    custom_element = cl.CustomElement(name=\"custom-element\")\n    await cl.Message(content=\"Click on the button!\", elements=[custom_element]).send()\n\n@cl.on_element_update\nasync def on_element_update(element: cl.CustomElement):\n    await cl.Message(f\"You clicked the button!\").send()\n```\n\n----------------------------------------\n\nTITLE: Creating Conversational Retrieval Chain for RAG\nDESCRIPTION: Sets up a conversational retrieval chain combining the language model, memory, and retriever. This enables context-aware responses that incorporate both conversation history and retrieved document information.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.chains import ConversationalRetrievalChain\n\nchain = ConversationalRetrievalChain.from_llm(\n    llm,\n    retriever=retriever,\n    memory=memory\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Chatbot with Memory and Prompt Template in Python\nDESCRIPTION: This function sets up the chatbot's runnable pipeline with a conversation buffer memory and a structured prompt template. It uses the ChatOpenAI model for generating responses.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/resume-chat/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef setup_runnable():\n    llm = ChatOpenAI(temperature=0, streaming=True)\n    memory = ConversationBufferMemory(\n        return_messages=True, output_key=\"output\", input_key=\"input\"\n    )\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"You are a helpful AI assistant.\"),\n            MessagesPlaceholder(variable_name=\"history\"),\n            (\"human\", \"{input}\"),\n        ]\n    )\n    runnable = prompt | llm | StrOutputParser()\n    return runnable.with_memory(memory)\n```\n\n----------------------------------------\n\nTITLE: Setting up Conversational Agent with Haystack and OpenAI in Python\nDESCRIPTION: This function configures the conversational agent with necessary tools and a prompt template for user interaction.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/haystack/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef get_agent(retriever):\n```\n\n----------------------------------------\n\nTITLE: Implementing Chainlit Chat Interface with RAG\nDESCRIPTION: Creates a Chainlit chat application that integrates the RAG system. This handles user messages, processes them through the retrieval chain, and displays responses in the chat interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport chainlit as cl\n\n@cl.on_message\nasync def main(message: cl.Message):\n    # Your chatbot logic\n    response = await chain.ainvoke({\"question\": message.content})\n    \n    # Send a response back to the user\n    await cl.Message(\n        content=response[\"answer\"],\n    ).send()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom OAuth Injection Logic in Python\nDESCRIPTION: This code sets up the logic for injecting a custom OAuth provider into Chainlit. It includes functions for generating random secrets, checking if custom OAuth is enabled, and adding the custom provider to the list of available providers.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/auth/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport secrets\nimport string\nfrom chainlit.oauth_providers import providers\n\nchars = string.ascii_letters + string.digits + \"$%*,-./:=>?@^_~\"\n\n\ndef random_secret(length: int = 64):\n    return \"\".join((secrets.choice(chars) for i in range(length)))\n\n\ndef custom_oauth_enabled():\n    if (os.environ.get('YOUR_ENV_VARS') is not None):\n        print(\"Custom OAuth configured.\")\n        return True\n    else:\n        print(\"Custom OAuth not configured. Skipping...\")\n        return False\n\n\ndef provider_id_in_instance_list(provider_id: str):\n    if providers is None:\n        print(\"No providers found\")\n        return False\n    if not any(provider.id == provider_id for provider in providers):\n        print(f\"Provider {provider_id} not found\")\n        return False\n    else:\n        print(f\"Provider {provider_id} found\")\n        return True\n\n\ndef add_custom_oauth_provider(provider_id: str, custom_provider_instance):\n    if custom_oauth_enabled() and not provider_id_in_instance_list(provider_id):\n        providers.append(custom_provider_instance)\n        print(f\"Added provider: {provider_id}\")\n    else:\n        print(f\"Custom OAuth is not enabled or provider {provider_id} already exists\")\n```\n\n----------------------------------------\n\nTITLE: Defining Custom OAuth Provider Class in Python\nDESCRIPTION: This code defines a custom OAuth provider class 'FooBarProvider' that inherits from Chainlit's OAuthProvider. It includes methods for initializing the provider, getting tokens, and retrieving user information.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/auth/README.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass FooBarProvider(OAuthProvider):\n    id=\"your-id\"\n    env=[\"YOUR_ENV_VAR_NAMES\"]\n\n    authorize_url=f\"https://get.your/auth_url\"\n    token_url=f\"https://get.your/token_url\"\n    \n    def __init__(self):\n        self.client_id = os.environ.get(\"YOUR_ENV_VAR_NAMES\")\n    \n    async def get_token(self, code: str, url: str) -> str:\n        payload = { \"foo\": self.client_id }\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                self.token_url,\n                data=payload\n            )\n            # do stuff, return a token\n\n    async def get_user_info(self, token: str):\n        async with httpx.AsyncClient() as client:\n            # do stuff with the token and return a user, User tuple\n```\n\n----------------------------------------\n\nTITLE: Processing Messages with LlamaCpp in ChainLit\nDESCRIPTION: Defines the main function decorated with @cl.on_message that handles incoming messages and generates responses using the conversation chain with LlamaCpp. This function processes user inputs and returns model outputs.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_message\ndef main(): Handles incoming messages and generates responses using the conversation chain.\n```\n\n----------------------------------------\n\nTITLE: Processing Chat Messages in Python with Chainlit and LangChain\nDESCRIPTION: This asynchronous function handles incoming chat messages. It retrieves the runnable from the session, processes the message, and streams the response back to the user.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/resume-chat/readme.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_message\nasync def on_message(message: cl.Message):\n    runnable = cl.user_session.get(\"runnable\")\n    msg = cl.Message(content=\"\")\n    async for chunk in runnable.astream(\n        {\"input\": message.content},\n        config=RunnableConfig(callbacks=[cl.LangchainCallbackHandler()]),\n    ):\n        await msg.stream_token(chunk)\n\n    await msg.send()\n```\n\n----------------------------------------\n\nTITLE: Handling Chat Start Event in Python with Chainlit\nDESCRIPTION: This asynchronous function is called when a new chat session starts. It sets up the memory and runnable for the session and stores them as user session variables.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/resume-chat/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_start\nasync def on_chat_start():\n    cl.user_session.set(\"memory\", ConversationBufferMemory(return_messages=True))\n    runnable = setup_runnable()\n    cl.user_session.set(\"runnable\", runnable)\n```\n\n----------------------------------------\n\nTITLE: Handling User Messages and Agent Responses with Chainlit in Python\nDESCRIPTION: This function processes incoming user messages and returns responses from the conversational agent.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/haystack/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef answer(message: cl.Message):\n```\n\n----------------------------------------\n\nTITLE: Loading LlamaCpp Model in ChainLit\nDESCRIPTION: Defines the instantiate_llm function that loads and configures a LlamaCpp model with specific parameters. This function is used to initialize the LLM before starting the conversation chain.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef instantiate_llm(): Loads the LlamaCpp model with the specified configuration.\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI Chat Model with Temperature Configuration\nDESCRIPTION: Initializes the OpenAI chat model with specific temperature settings. Lower temperature values produce more deterministic responses, while higher values increase creativity and variation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(temperature=0)\n```\n\n----------------------------------------\n\nTITLE: Initializing Document Store and Retriever in Python with Haystack\nDESCRIPTION: This function sets up the document store, loads the Seven Wonders dataset, and initializes a BM25Retriever for document searching.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/haystack/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_retriever():\n```\n\n----------------------------------------\n\nTITLE: Processing Messages with Ollama in ChainLit\nDESCRIPTION: Defines the on_message function that handles streaming user messages to the Ollama model and returning responses. This function is called whenever a user sends a message in the ChainLit interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef on_message(): Streams the user's message to the model and sends back the model's response.\n```\n\n----------------------------------------\n\nTITLE: Resuming Chat Session in Python with Chainlit\nDESCRIPTION: This asynchronous function handles resuming a chat session from a previous thread. It repopulates the conversation memory with the thread's history.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/resume-chat/readme.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@cl.on_chat_resume\nasync def on_chat_resume(thread: ThreadDict):\n    memory = ConversationBufferMemory(return_messages=True)\n    root_messages = [m for m in thread[\"steps\"] if m[\"parentId\"] == None]\n    for message in root_messages:\n        if message[\"type\"] == \"HUMAN\":\n            memory.chat_memory.add_user_message(message[\"output\"])\n        else:\n            memory.chat_memory.add_ai_message(message[\"output\"])\n\n    cl.user_session.set(\"memory\", memory)\n    runnable = setup_runnable()\n    cl.user_session.set(\"runnable\", runnable)\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for Custom OAuth Provider in Python\nDESCRIPTION: This snippet shows the necessary imports for creating a custom OAuth provider class in Python. It includes modules for handling HTTP requests, environment variables, and Chainlit-specific classes.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/auth/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport httpx\nfrom fastapi import HTTPException\nfrom chainlit.user import User\nfrom chainlit.oauth_providers import OAuthProvider\nimport json\n```\n\n----------------------------------------\n\nTITLE: Integrating Custom OAuth Provider in Chainlit App.py\nDESCRIPTION: This snippet shows how to integrate the custom OAuth provider into a Chainlit application's app.py file. It includes importing the necessary components, adding the custom provider, and setting up the OAuth callback function.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/auth/README.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom cookbook.auth.foobar_oauthprovider import FooBarProvider\nfrom cookbook.auth.inject_custom_auth import add_custom_oauth_provider\n\nadd_custom_oauth_provider(\"foobar\", FooBarProvider())\n\n@cl.oauth_callback\ndef oauth_callback(\n  provider_id: str,\n  token: str,\n  raw_user_data: Dict[str, str],\n  default_user: cl.User,\n) -> Optional[cl.User]:\n  return default_user\n```\n\n----------------------------------------\n\nTITLE: Implementing User Authentication in Python\nDESCRIPTION: This function handles user authentication by checking a provided password. It returns a test user object if authentication is successful.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/resume-chat/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef auth(password: str):\n    if password == \"test\":\n        return cl.User(identifier=\"test\")\n    else:\n        return None\n```\n\n----------------------------------------\n\nTITLE: Initializing Ollama Integration with ChainLit\nDESCRIPTION: Defines the on_chat_start function that initializes a chat session with Ollama using a historical context prompt. This function is triggered when a new chat session begins in the ChainLit interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/local-llm/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef on_chat_start(): Initializes the chat session with a historical context prompt.\n```\n\n----------------------------------------\n\nTITLE: Creating Retriever from Vector Store for Document Search\nDESCRIPTION: Configures a retriever from the vector store to search for relevant documents. This component is responsible for finding contextual information in the document collection based on user queries.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nretriever = vectorstore.as_retriever()\n```\n\n----------------------------------------\n\nTITLE: Splitting Documents into Chunks for Vector Store\nDESCRIPTION: Processes the loaded documents by splitting them into smaller chunks using the text splitter. This prepares the text for more efficient storage and retrieval in the vector database.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nall_splits = text_splitter.split_documents(docs)\n```\n\n----------------------------------------\n\nTITLE: Setting up FAISS Vector Store for Document Retrieval\nDESCRIPTION: Configures a FAISS vector store for efficient document retrieval based on semantic similarity. FAISS is an efficient library for similarity search and clustering of dense vectors.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_community.vectorstores import FAISS\n\nvectorstore = FAISS.from_texts([\"foo\", \"bar\", \"baz\"], embeddings)\n```\n\n----------------------------------------\n\nTITLE: Creating Plugin Configuration JSON\nDESCRIPTION: JSON configuration file structure for enabling/disabling Chainlit plugins. Each plugin requires this config.json file with an 'enabled' field to control whether the plugin's functions are imported and available for use.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-functions-codeinterpreter/README.md#2025-04-21_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"enabled\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Creating FAISS Vector Store from Document Chunks\nDESCRIPTION: Builds a FAISS vector store from the processed document chunks using the OpenAI embeddings. This enables efficient semantic search capabilities for the RAG application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nvectorstore = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Embeddings for Vector Search\nDESCRIPTION: Initializes the OpenAI embeddings model for vector representation of text. This creates embeddings that capture semantic meaning for effective similarity search in the vector store.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings = OpenAIEmbeddings()\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for LLM Project\nDESCRIPTION: This requirements file lists all necessary Python packages with pinned versions for an LLM project. It includes LLama Index for data indexing, Groq for LLM integration, Chainlit for building conversational AI interfaces, and supporting packages like dotenv for environment variable management and HuggingFace embeddings.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/groq-llama3-llamaindex-hf/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nllama-index==0.10.18\nllama-index-llms-groq==0.1.3\nchainlit==1.0.401\ngroq==0.4.2\npython-dotenv==1.0.1\nllama-index-embeddings-huggingface==0.2.0\n```\n\n----------------------------------------\n\nTITLE: Creating Memory Buffer for Chat History\nDESCRIPTION: Sets up a conversation buffer memory to maintain chat history. This allows the chat application to remember previous interactions and maintain context throughout the conversation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    return_messages=True\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Information Function in Python\nDESCRIPTION: A sample function that simulates fetching current weather data for a specified location. It takes location and unit parameters and returns a JSON string containing temperature and forecast information. This function serves as a demonstration of how custom functions can be called by OpenAI models.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-functions-streaming/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location, unit):\nunit = unit or \"Fahrenheit\"\nweather_info = {\n\"location\": location,\n\"temperature\": \"60\", # Placeholder value\n\"unit\": unit,\n\"forecast\": [\"windy\"], # Placeholder forecast\n}\nreturn json.dumps(weather_info)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Specifies the required Python packages needed to run the Chainlit cookbook project. The dependencies include OpenAI for AI capabilities, Plotly for data visualization, and Chainlit for the chatbot interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-data-analyst/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nopenai\nplotly\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Loading Documents from a Directory for RAG\nDESCRIPTION: Loads documents from a specified directory using a directory loader. This prepares the documents for processing and embedding in the vector store for retrieval.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_community.document_loaders import DirectoryLoader\n\nloader = DirectoryLoader('./documents/')\ndocs = loader.load()\n```\n\n----------------------------------------\n\nTITLE: Creating Text Splitter for Document Chunking\nDESCRIPTION: Configures a text splitter to break documents into manageable chunks. This allows for more precise retrieval and prevents context window limitations during processing.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for OpenAI RAG\nDESCRIPTION: This snippet shows the dependencies required for installing and running the RAG application with OpenAI and vector stores. It includes packages for OpenAI integration, document handling, and various vector stores.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npip install python-dotenv langchain langchain-openai langchain-community chainlit openai tiktoken faiss-cpu\n```\n\n----------------------------------------\n\nTITLE: Building and Running Chroma Q&A Docker Container\nDESCRIPTION: Docker commands to build the application image and run it as a container with port forwarding. The application will be accessible at http://localhost:7860.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/chroma-qa-chat/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker build -t chroma-qa-chat .\ndocker run -p 7860:7860 chroma-qa-chat\n```\n\n----------------------------------------\n\nTITLE: Setting up Environment Variables for OpenAI Integration\nDESCRIPTION: Configuration of environment variables by loading values from a .env file. This is necessary to securely store and access the OpenAI API key for authentication.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/map-canvas/requirements.txt#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# Access your API key\napi_key = os.environ[\"OPENAI_API_KEY\"]\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Requirements for Chainlit Project\nDESCRIPTION: This requirements file lists the necessary Python packages for a Chainlit project. It includes PDF processing capabilities (pypdf), vector database integration (pinecone-client), token counting functionality (tiktoken), and the LangChain framework along with Chainlit itself.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pdf-qa/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npypdf==3.8.1\npinecone-client==2.2.1\ntiktoken==0.3.3\nlangchain\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Building and Testing Chainlit Docker Container Locally\nDESCRIPTION: Shell commands to build a Docker image for the Chainlit application and run it locally for testing. The commands build the image with the tag 'chainlit-app:latest' and run it with port 8080 mapped from the container to the host.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/aws-ecs-deployment/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker build -t chainlit-app:latest .\ndocker run -p 8080:8080 chainlit-app:latest\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit for Tool Calling in TOML\nDESCRIPTION: This snippet shows the configuration required in the .chainlit/config.toml file to enable the 'tool_call' Chain of Thought (CoT) mode for the chat application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langchain-azure-agent/README.md#2025-04-21_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\ncot = \"tool_call\"\n```\n\n----------------------------------------\n\nTITLE: Defining Python Dependencies for Pinecone and LangChain Application\nDESCRIPTION: Requirements file specifying the necessary Python packages for a project that uses Pinecone for vector database operations, Tiktoken for tokenization, and LangChain with Chainlit for building LLM-powered applications. These dependencies indicate the project likely involves vector embeddings and retrieval augmented generation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pinecone/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npinecone-client==2.2.1\ntiktoken==0.3.3\nlangchain\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit Server in Headless Mode\nDESCRIPTION: Commands to navigate to the backend directory and start the Chainlit server using uvicorn, making it accessible on all network interfaces on port 80.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-frontend/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd ./backend\nuvicorn app:app --host 0.0.0.0 --port 80\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies Specification for Chainlit Project\nDESCRIPTION: A comprehensive list of Python package dependencies with specific version requirements. The file includes Chainlit, LangChain components, Azure services integration packages, and HTTP client libraries needed for the project.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langchain-azure-agent/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nazure-core==1.29.7\nazure-search-documents==11.6.0b4\nchainlit==1.2.0\nlangchain==0.3.1\nlangchain-community==0.3.1\nlangchain-openai==0.2.1\nlangchain-unstructured==0.1.5\nrequests==2.31.0\naiofiles==23.2.1\naiohttp==3.9.3\naiohttp_retry==2.8.3\nasync-timeout==4.0.3\nazure-identity==1.17.1\nazure-ai-documentintelligence==1.0.0b1\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Chainlit Project\nDESCRIPTION: A requirements file listing the necessary Python packages for a Chainlit project that uses OpenAI, Yahoo Finance data, Plotly for visualization, and WebSockets for real-time communication. The file pins the WebSockets version to 14.1 while leaving other packages unpinned.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/realtime-assistant/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plain\nCODE:\n```\nchainlit\nopenai\nyfinance\nplotly\nwebsockets==14.1\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Running the React Frontend\nDESCRIPTION: Commands to navigate to the frontend directory, install dependencies, and start the development server for the React application that will connect to the Chainlit backend.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-frontend/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncd ./frontend\nnpm i\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Initializing Conversation with Chainlit in Python\nDESCRIPTION: This function starts the conversation by asking an initial question about the Rhodes Statue.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/haystack/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef init():\n```\n\n----------------------------------------\n\nTITLE: Setting Up Custom OAuth Environment Variables in Python\nDESCRIPTION: This snippet demonstrates the setup of environment variables for a custom OAuth provider, specifically for Azure AD B2C. It includes variables for client ID, secret, tenant information, and redirect URL.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/auth/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nOAUTH_AZURE_AD_B2C_CLIENT_ID=your b2c application/client ID\nOAUTH_AZURE_AD_B2C_CLIENT_SECRET=your b2c client secret\nOAUTH_AZURE_AD_B2C_TENANT_ID=your b2c tenant id\nOAUTH_AZURE_AD_B2C_TENANT_NAME=your b2c tenant name\nOAUTH_AZURE_AD_B2C_REDIRECT_URL=your specified redirect url\nOAUTH_AZURE_AD_B2C_POLICY=your policy\n```\n\n----------------------------------------\n\nTITLE: Installation and Setup Instructions\nDESCRIPTION: Steps to configure and run the React Native client with Chainlit backend integration. Includes instructions for installing dependencies and starting the development server.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- change your backend address of `./react-native-app/chainlit.config.ts`\n- `cd ./react-native-client`\n- Install with `yarn` or `npm install`.\n- Run `yarn start` or `npm run start` to try it out.\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for Chainlit Cookbook\nDESCRIPTION: A requirements file listing three Python packages needed for the Chainlit cookbook project: farm-haystack with inference capabilities, datasets package for data handling and processing, and the chainlit package for building chat interfaces.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/haystack/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nfarm-haystack[inference]\ndatasets\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Dockerizing a Chainlit Application for AWS ECS\nDESCRIPTION: A Dockerfile configuration for containerizing a Chainlit application. It uses Python 3.10-slim as the base image, sets up the working environment, installs dependencies, copies application code, exposes port 8080, and configures the command to run the Chainlit app.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/aws-ecs-deployment/README.md#2025-04-21_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Use an appropriate base image, e.g., python:3.10-slim\nFROM python:3.10-slim\n# Set environment variables\nENV PYTHONUNBUFFERED=1\n# Set the working directory\nWORKDIR /app\n# Install dependencies\nCOPY requirements.txt /app/\nRUN pip install -r /app/requirements.txt\n# Copy application code\nCOPY . /app/\n# Expose the port the app runs on\nEXPOSE 8080\n# Command to run the app\nCMD [\"python\", \"-m\", \"chainlit\", \"run\", \"app.py\", \"-h\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies List for an LLM Application\nDESCRIPTION: A list of Python package dependencies required for a project. The dependencies include chainlit (likely for building LLM UIs), tokeniser (for text tokenization), litellm (for language model interaction), and linkup-sdk (for connectivity).\nSOURCE: https://github.com/chainlit/cookbook/blob/main/ai-web-search-linkup/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit\ntokeniser\nlitellm\nlinkup-sdk\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Specifies the required Python packages for a project using LangChain, LangGraph, LangChain-OpenAI, and Chainlit frameworks. These dependencies enable building conversational AI applications with LLM integration.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langgraph-memory/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nlangchain\nlanggraph\nlangchain-openai\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Defining Python Dependencies with Version Constraints\nDESCRIPTION: Lists required Python packages and their versions. Specifies Chainlit version 2.4.0 and includes the Anthropic package for AI capabilities.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/mcp/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit==2.4.0\nanthropic\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for a Chainlit Application\nDESCRIPTION: A requirements.txt file listing the Python package dependencies needed for a Chainlit application. It includes baseten for model deployment, requests for HTTP communication, and chainlit itself for building the chat interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nbaseten\nrequests\nchainlit\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Baseten API and Model Version\nDESCRIPTION: These environment variables set the Baseten API key and the version ID of the deployed model. The API key should be created in the Baseten UI, and the version ID corresponds to the deployed model.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/chainlit.md#2025-04-21_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nBASETEN_API_KEY=abcd.abcd1234\nVERSION_ID=abcd123\n```\n\n----------------------------------------\n\nTITLE: Defining Python Dependencies in Requirements File\nDESCRIPTION: This snippet lists the required Python packages for the project. It includes Chainlit for building UI interfaces, LangChain for LLM application integration, and Stability SDK version 0.8.0 for accessing Stability AI's services.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/image-gen/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit\nlangchain\nstability_sdk==0.8.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Chainlit Dependencies in Requirements File\nDESCRIPTION: This requirements file specifies Chainlit version 1.6.0 or higher as a dependency for the project. It also includes a comment noting that asyncio is already included in Python versions 3.7 and above, so it doesn't need to be explicitly installed.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/loader-animation/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit>=1.6.0  # Framework\n# asyncio already included in Python 3.7+ \n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements for Chainlit Project\nDESCRIPTION: A simple list of Python package dependencies required for a Chainlit project that integrates with OpenAI and uses Uvicorn as a server. This would typically be used in a requirements.txt file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit\nopenai\nuvicorn\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: List of required Python packages for the project including chainlit and anthropic APIs\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-chat/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit\nanthropic\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Chainlit Project\nDESCRIPTION: This snippet lists the required Python packages and their versions for a Chainlit project. It includes Chainlit itself, Loguru for logging, TikToken for tokenization, and Prompt Toolkit for command-line interfaces.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-functions-codeinterpreter/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit==0.5.2\nloguru==0.5.3\ntiktoken==0.4.0\nprompt_toolkit==3.0.39\n```\n\n----------------------------------------\n\nTITLE: Importing Chainlit Step Class for DeepSeek R1 Integration\nDESCRIPTION: This snippet shows the import statement for the Chainlit Step class, which is used to expose the reasoning process of DeepSeek R1 to users.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/deepseek-r1/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom chainlit import Step\n```\n\n----------------------------------------\n\nTITLE: Installing LangGraph Dependencies\nDESCRIPTION: Command to install the required dependencies for LangGraph using pip package manager.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langgraph-tavily/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Function Documentation\nDESCRIPTION: Documentation of the main functions in the application including load_context(), start(), and main().\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index-googledocs-qa/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### Function Definitions\n\n- `load_context()`: Loads the index from storage or creates a new one if storage is not found. It initializes necessary components like `LLMPredictor`, `PromptHelper`, and `ServiceContext`.\n- `start()`: An asynchronous function that is triggered when a chat starts. It loads the context and sets up the query engine.\n- `main(message: cl.Message)`: The main asynchronous function that handles incoming messages and uses the query engine to generate and send responses.\n```\n\n----------------------------------------\n\nTITLE: Specifying Dependencies for Chainlit with Claude\nDESCRIPTION: This requirements.txt file lists the necessary packages for building Chainlit applications that use Anthropic's Claude model. It includes Chainlit version 2.4.0 and the Anthropic Python client library.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/mcp-linear/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nchainlit==2.4.0\nanthropic\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit Server in Headless Mode\nDESCRIPTION: Navigates to the backend directory, installs requirements and uvicorn, then starts the server on port 8080 accessible from any host.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd ./backend\npip install -r requirement.txt\npip install uvicorn\nuvicorn app:app --host 0.0.0.0 --port 8080\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Running Chainlit Application\nDESCRIPTION: This snippet shows how to install the required dependencies from a requirements file and run the Chainlit application locally. It uses pip for package installation and the chainlit command to run the app.py file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/groq-llama3-llamaindex-hf/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install requirements.txt\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies for Chainlit/Cookbook Project\nDESCRIPTION: This list specifies the required Python packages for the chainlit/cookbook project. It includes python-dotenv for environment variable management, chainlit for UI components, various langchain packages for LLM integration, and langgraph for workflow management.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langgraph-tavily/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npython-dotenv\nchainlit\nlangchain-community\nlanggraph\nlangchain-openai\nlangchain-core\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Chainlit and OpenAI\nDESCRIPTION: Creates a .env file in the backend directory with necessary configuration values for OpenAI API key and base URL.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/README.md#2025-04-21_snippet_1\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=YOUR_KEY\nBASE_URL=YOUR_SITE\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to launch the Chainlit application using the Chainlit CLI, which will start the web interface for the chatbot.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-functions-streaming/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for LangChain and Chainlit Integration\nDESCRIPTION: A requirements list showing the necessary Python packages for a project that uses LangChain with Chainlit, integrates with OpenAI, uses Pinecone for vector database functionality, and includes PDF processing with PyMuPDF.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/requirements.txt#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nlangchain\nchainlit\nlangchain_openai\nopenai\ntiktoken\npymupdf\npinecone-client\nlangchain_pinecone\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Virtual Environment for Chainlit\nDESCRIPTION: Creates a Python virtual environment, activates it, and installs dependencies before starting the Chainlit server in isolation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython -m venv .venv\nsource .venv/bin/activate\n.venv/bin/pip install -r requirements.txt\n.venv/bin/uvicorn app:app --host 0.0.0.0 --port 8080\n```\n\n----------------------------------------\n\nTITLE: Running a Chainlit Application\nDESCRIPTION: Command to execute a Chainlit application from the command line. This specifically runs the app.py file which contains the confirmation dialog implementation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/confirm-action/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Setting Up LangSmith Environment Variables\nDESCRIPTION: Environment variables required to enable LangSmith for tracing, monitoring, and debugging LangChain applications.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport LANGCHAIN_TRACING_V2=true\nexport LANGCHAIN_API_KEY=<your-api-key>\nexport LANGCHAIN_PROJECT=<your-project>  # if not specified, defaults to \"default\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Requirements File\nDESCRIPTION: Installs the required Python packages for the Chainlit application using pip and a requirements.txt file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to launch the Chainlit application. This should be executed from the directory containing the app.py file that implements the OpenInterpreter x Chainlit integration.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/chainlit.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to launch the Chainlit application. This runs the app.py file which contains the implementation of the extended thinking functionality using Claude 3.7.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain CLI\nDESCRIPTION: Installs or updates the LangChain Command Line Interface which is required to manage LangServe applications.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U langchain-cli\n```\n\n----------------------------------------\n\nTITLE: Running the OSS ChatGPT Application with Chainlit\nDESCRIPTION: This command runs the ChatGPT-like application using Chainlit. The '-w' flag enables watch mode for automatic reloading on file changes.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/chainlit.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Running LangGraph Application\nDESCRIPTION: Command to start the LangGraph application using Chainlit.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langgraph-tavily/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for LangServe\nDESCRIPTION: Command to build a Docker image for the LangServe application using the provided Dockerfile.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker build . -t my-langserve-app\n```\n\n----------------------------------------\n\nTITLE: Starting the React Web Client\nDESCRIPTION: Navigates to the React web client directory, installs Node.js dependencies, and starts the development server.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/backend/README.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncd ./react-web-client\nnpm i\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to start the Chainlit server with the app.py implementation, making the chat interface accessible via web browser.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/ai-web-search-linkup/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Launching LangServe Application\nDESCRIPTION: Command to start the LangServe server and run the application locally.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nlangchain serve\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration File for Chainlit Backend\nDESCRIPTION: Environment configuration for the Chainlit backend that sets the OpenAI API key.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-frontend/README.md#2025-04-21_snippet_1\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY=YOUR_KEY\n```\n\n----------------------------------------\n\nTITLE: Example Prompt for Modifying Generated Image\nDESCRIPTION: An example prompt demonstrating how to modify a previously generated image by requesting a change from clear night sky to starry sky. This shows the image editing capability of the application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/image-gen/chainlit.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nchange the clear night sky with a starry sky\n```\n\n----------------------------------------\n\nTITLE: Removing Packages from LangServe Application\nDESCRIPTION: Command to remove packages from a LangServe application by specifying their API path.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nlangchain app remove my/custom/path/rag\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key in Environment File\nDESCRIPTION: Example of how to set up the Anthropic API key in a .env file, which is required for authenticating with the Anthropic API service.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-functions-streaming/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nANTHROPIC_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Command to set the OpenAI API key as an environment variable. This is required for the application to authenticate with OpenAI's services.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/chainlit.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport OPENAI_API_KEY='your_api_key_here'\n```\n\n----------------------------------------\n\nTITLE: Example Prompt for Generating Anime Style Mountain Image\nDESCRIPTION: An example prompt that can be used to generate an anime-style image of snowy Swiss mountains at night. This demonstrates the basic image generation capability of the application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/image-gen/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nAnime style snowy swiss mountains lit by the moon. Clear night sky. HD.\n```\n\n----------------------------------------\n\nTITLE: Configuring Procfile for Chainlit on Fly.io\nDESCRIPTION: Example Procfile configuration that tells Fly.io how to start the Chainlit application, specifying the host and port settings.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nweb: python -m chainlit run app.py -h --port 8080\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Baseten Llama 2 Chat Interface\nDESCRIPTION: Example of environment variables to be set in the .env file. These include the Baseten API key and the deployed model version ID.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nBASETEN_API_KEY=your_baseten_api_key\nVERSION_ID=your_deployed_model_version_id\n```\n\n----------------------------------------\n\nTITLE: Accessing Local Chainlit Application\nDESCRIPTION: HTTP URL to access the locally running Chainlit application for testing PDF uploading and question answering functionality.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://localhost:8000/\n```\n\n----------------------------------------\n\nTITLE: Setting Instance Count for WebSocket Support\nDESCRIPTION: Command to set the app instance count to 1, which is necessary for WebSocket support as Fly.io doesn't support sticky sessions by default.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nflyctl scale count 1\n```\n\n----------------------------------------\n\nTITLE: Starting React Native Chainlit Client\nDESCRIPTION: Commands to start the React Native Chainlit client project using either yarn or npm.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/react-native-client/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nyarn start\n```\n\nLANGUAGE: shell\nCODE:\n```\nnpm run start\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for React Native Chainlit Client\nDESCRIPTION: Commands to install project dependencies using either yarn or npm package managers.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/react-native-chat/react-native-client/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nyarn\n```\n\nLANGUAGE: shell\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Building and Running Docker Image Commands\nDESCRIPTION: Shell commands to build and run the Docker image for the Chainlit application, with instructions for selecting the appropriate architecture based on local machine.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n./build-docker-image.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\n./run-docker-image.sh\n```\n\n----------------------------------------\n\nTITLE: Pushing Docker Image to Azure Container Registry\nDESCRIPTION: Commands for authenticating with Azure and pushing the built Docker image to an Azure Container Registry for cloud deployment.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\naz login\n```\n\nLANGUAGE: bash\nCODE:\n```\n./push-docker-image.sh\n```\n\n----------------------------------------\n\nTITLE: Configuring ESLint Parser Options for TypeScript in React Vite Project\nDESCRIPTION: This code snippet demonstrates how to configure the parserOptions property in ESLint configuration for a React TypeScript project. It sets up the ECMAScript version, source type, and specifies TypeScript configuration files for type-aware linting.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-frontend/frontend/README.md#2025-04-21_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n   parserOptions: {\n    ecmaVersion: 'latest',\n    sourceType: 'module',\n    project: ['./tsconfig.json', './tsconfig.node.json'],\n    tsconfigRootDir: __dirname,\n   },\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Chainlit Anthropic Integration\nDESCRIPTION: Command to install the required dependencies for the Chainlit Anthropic example project using pip package manager.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-functions-streaming/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Setting up and Running Chainlit Application with LangGraph\nDESCRIPTION: These commands copy the example environment file, install required dependencies, and run the Chainlit application. The application uses authentication and persistence from the official data layer.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langgraph-memory/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\npip install -r requirements.txt\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit Server for Window Communication\nDESCRIPTION: Command to run a Chainlit application with specific parameters to enable window message communication. The command starts the server on port 8000 with host and certificate options enabled.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/window-message/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py -h -c --port 8000\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Claude Chatbot\nDESCRIPTION: Command to install the required Python packages from requirements.txt file for running the Claude chatbot application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-chat/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Llama Index Chat Application\nDESCRIPTION: Command to install the required dependencies for the chat application using pip. This should be run in the root directory of the project after cloning the repository.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Cloning the Chainlit Cookbook Repository for AWS ECS Deployment\nDESCRIPTION: Shell commands to clone the Chainlit cookbook repository and navigate to the AWS ECS deployment directory.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/aws-ecs-deployment/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/Chainlit/cookbook.git chainlit-cookbook\ncd chainlit-cookbook/aws-ecs-deployment\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Baseten Llama 2 Chat Interface\nDESCRIPTION: Command to install the required Python libraries using pip. This installs the latest versions of baseten and chainlit packages.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install --upgrade baseten chainlit\n```\n\n----------------------------------------\n\nTITLE: Running the Llama Index Chat Application\nDESCRIPTION: Command to start the chat application. This assumes that the OPENAI_API_KEY environment variable has been set and all dependencies have been installed.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npython chainlit-cookbook/llama-index/app.py\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application for Baseten Llama 2 Chat Interface\nDESCRIPTION: Command to start the Chainlit application. The -w flag enables hot-reloading for development purposes.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Creating a Fly.io Project\nDESCRIPTION: Command to initialize a new Fly.io project for the Chainlit application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nflyctl launch\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Command to install the necessary Python packages for the demo project using pip and the requirements.txt file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Setup and Usage Instructions\nDESCRIPTION: Instructions for setting up and running the application, including environment configuration and Google Docs setup.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index-googledocs-qa/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## Quickstart\n\n1. Set your OpenAI API key in your environment variables.\n2. Define the Google Docs IDs you want to index in the `load_context()` function.\n3. Run the application to start interacting with the chatbot.\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application Locally with Hot Reload\nDESCRIPTION: Command to start the Chainlit application locally with the watch flag enabled for hot reloading during development.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Command to install all required packages for the project using pip package manager.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/ai-web-search-linkup/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Creating Environment Configuration File\nDESCRIPTION: Command to create a .env file by copying the example file, which will contain necessary API keys and configuration settings for the demo.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/README.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Chainlit Application\nDESCRIPTION: Command to install all required Python packages listed in the requirements.txt file for the PDF processing and question answering application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/azure-openai-pinecone-pdf-qa/src/readme.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit App in Watch Mode\nDESCRIPTION: Command to start the Chainlit application in watch mode, which will run the app.py file and automatically reload on changes.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/README.md#2025-04-21_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py -w\n```\n\n----------------------------------------\n\nTITLE: Starting the Chainlit Server\nDESCRIPTION: Command to launch the Chainlit server by running the app.py script that contains the Claude chatbot implementation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/anthropic-chat/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit and OpenAI Dependencies\nDESCRIPTION: Command to install the required Python packages for the Chainlit backend implementation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-frontend/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -U chainlit openai\n```\n\n----------------------------------------\n\nTITLE: Navigating to a Demo Project Directory\nDESCRIPTION: Command to change the current working directory to a specific demo project folder within the cloned repository.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd chainlit-cookbook/demo-folder-name\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application for AutoGen Integration\nDESCRIPTION: Executes the Chainlit application using the app.py file, which contains the main logic for the chat application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pyautogen/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Command to install the required Python dependencies listed in the requirements.txt file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/chainlit.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Fly.io\nDESCRIPTION: Commands to sign up for a Fly.io account and log in using the CLI.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nflyctl auth signup\nflyctl auth login\n```\n\n----------------------------------------\n\nTITLE: Cloning the Chainlit Cookbook Repository\nDESCRIPTION: Command to clone the Chainlit Cookbook repository from GitHub to a local directory named 'chainlit-cookbook'.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/Chainlit/cookbook.git chainlit-cookbook\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to start the Chainlit application by running the app.py file using the chainlit CLI tool. This launches the web interface for interacting with OpenInterpreter.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Fly CLI on macOS\nDESCRIPTION: Command to install the Fly CLI tool on macOS using Homebrew.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew install flyctl\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Virtual Environment for AutoGen-Chainlit Project\nDESCRIPTION: Creates and activates a Python virtual environment for isolating project dependencies.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pyautogen/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npython3 -m venv venv\nsource venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit App Locally\nDESCRIPTION: Command to run the Chainlit application locally for testing before deployment.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Cloning the Chainlit Cookbook Repository\nDESCRIPTION: Git commands to clone the example repository and navigate to the Fly.io deployment directory.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/Chainlit/cookbook.git chainlit-cookbook\ncd chainlit-cookbook/fly-io-deployment\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Command to set the OpenAI API key as an environment variable, which is required for authenticating with OpenAI's services to use their language models.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport OPENAI_API_KEY='your_api_key_here'\n```\n\n----------------------------------------\n\nTITLE: Deploying to Fly.io\nDESCRIPTION: Command to deploy the Chainlit application to Fly.io.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/fly-io-deployment/README.md#2025-04-21_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nflyctl deploy\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Configuration Template\nDESCRIPTION: Shell command to create a .env file from the provided example. This file will contain necessary environment variables for the application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncp .env.example .env\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory\nDESCRIPTION: Command to change directory to the cloned repository. Replace <cloned-directory> with the actual path to the directory where you cloned the cookbook example.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd <cloned-directory>\n```\n\n----------------------------------------\n\nTITLE: Running OpenAI Assistant Application\nDESCRIPTION: Command to run the Chainlit application locally\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-data-analyst/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit via pip\nDESCRIPTION: Command to install the Chainlit framework using pip package manager. This is required to run the web application interface for OpenInterpreter.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install chainlit\n```\n\n----------------------------------------\n\nTITLE: Markdown Content Description\nDESCRIPTION: Front matter and markdown content describing the application's purpose, components, and setup instructions.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index-googledocs-qa/readme.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: 'Llama Index Google Docs QA'\ntags: ['llama', 'index', 'google', 'docs', 'qa']\n---\n\n# Llama Index Google Docs QA\n\nThis Python application integrates a question-answering system using the Llama Index with Google Docs as the data source. It leverages OpenAI's GPT models for generating responses and ChainLit for creating interactive chat applications.\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Application\nDESCRIPTION: Command to start the Chainlit application by running the app.py file.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/chainlit.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI Assistant\nDESCRIPTION: Command to create a new OpenAI assistant instance\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-data-analyst/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython create_assistant.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Welcome Screen with Markdown\nDESCRIPTION: Instructions for modifying the welcome screen by editing the chainlit.md file. The file can be left empty to disable the welcome screen.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/custom-logo/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables in .env File\nDESCRIPTION: Example structure for the .env file needed to configure API keys for Anthropic and Linkup services.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/ai-web-search-linkup/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nANTHROPIC_API_KEY=your_api_key_here\nLINKUP_API_KEY=your_api_key_here\n```\n\n----------------------------------------\n\nTITLE: Running Uvicorn and Caddy Server\nDESCRIPTION: Command for accessing Chainlit through a reverse proxy at a specific URL path prefix\nSOURCE: https://github.com/chainlit/cookbook/blob/main/reverse_proxy/README.md#2025-04-21_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttp://127.0.0.1:8080/proxy/chainlit\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Welcome Screen with Markdown\nDESCRIPTION: Instructions for modifying the default welcome screen by editing the chainlit.md file. The file can be left empty to disable the welcome screen.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/mcp/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for OSS ChatGPT\nDESCRIPTION: This command installs the necessary Python libraries, Baseten and Chainlit, for running the open-source ChatGPT interface.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/baseten-llama-2-chat/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install --upgrade baseten chainlit\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for AutoGen-Chainlit Project\nDESCRIPTION: Installs the necessary Python packages (chainlit and pyautogen) using pip.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pyautogen/README.md#2025-04-21_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install chainlit pyautogen\n```\n\n----------------------------------------\n\nTITLE: Modifying Welcome Screen in Markdown\nDESCRIPTION: Instructions for customizing the Chainlit welcome screen by editing the chainlit.md file. The welcome screen can be disabled by leaving the file empty.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/copilot/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Application\nDESCRIPTION: Command to execute the Chainlit application from the command line after saving the code as app.py.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/loader-animation/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Chroma Q&A Application\nDESCRIPTION: Command to install the required Python packages specified in the requirements.txt file using pip.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/chroma-qa-chat/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Modifying Chainlit Welcome Screen Configuration\nDESCRIPTION: Instructions for customizing the Chainlit welcome screen by editing the chainlit.md file. The file can be left empty to disable the welcome screen.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/llama-index/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nchainlit.md\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Chainlit Animation\nDESCRIPTION: Command to install the necessary Python packages (chainlit and asyncio) for running the animated waiting indicator application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/loader-animation/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install chainlit asyncio\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Welcome Screen\nDESCRIPTION: Instructions for customizing the Chainlit welcome screen through the chainlit.md file, which can be modified or left empty to disable the welcome screen.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openai-whisper/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Extended Thinking Chainlit App\nDESCRIPTION: Command to install the required Python dependencies for running the extended thinking Chainlit application. This must be executed after cloning the repository and navigating to the project directory.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Welcome Screen\nDESCRIPTION: Instructions for modifying the welcome screen by editing the chainlit.md file at the project root. The file can be left empty to disable the welcome screen.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/suggestions/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit via pip\nDESCRIPTION: Command to install the Chainlit library using pip. This is a prerequisite for running the OpenInterpreter x Chainlit integration.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/openinterpreter/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install chainlit\n```\n\n----------------------------------------\n\nTITLE: Configuring Chainlit Welcome Screen - Markdown\nDESCRIPTION: Instructions for modifying the Chainlit welcome screen by editing the chainlit.md file. The welcome screen can be customized or disabled by leaving the file empty.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/pyautogen/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to Chainlit! 🚀🤖\n\nHi there, Developer! 👋 We're excited to have you on board. Chainlit is a powerful tool designed to help you prototype, debug and share applications built on top of LLMs.\n\n## Useful Links 🔗\n\n- **Documentation:** Get started with our comprehensive [Chainlit Documentation](https://docs.chainlit.io) 📚\n- **Discord Community:** Join our friendly [Chainlit Discord](https://discord.gg/k73SQ3FyUh) to ask questions, share your projects, and connect with other developers! 💬\n\nWe can't wait to see what you create with Chainlit! Happy coding! 💻😊\n```\n\n----------------------------------------\n\nTITLE: Markdown Welcome Message for HumanLayer x Chainlit Project\nDESCRIPTION: A welcome message in Markdown format introducing the HumanLayer x Chainlit project. It briefly mentions an example of an OpenAI agent that can call for human confirmation.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/humanlayer-openai/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Welcome to HumanLayer x Chainlit! 🚀🤖\n\nGet started with an example of an OpenAI agent that can call a human for confirmation.\n```\n\n----------------------------------------\n\nTITLE: Defining HumanInputChainlit Class for Human-In-The-Loop Interaction in Python\nDESCRIPTION: This code snippet defines the HumanInputChainlit class, which inherits from BaseTool. It implements methods for both synchronous and asynchronous execution to request and process human input during automated workflows. The class uses cl.AskUserMessage() to pause execution and prompt the user for input.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/langchain-ask-human/README.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass HumanInputChainlit(BaseTool):\n    \"\"\"Tool that adds the capability to ask user for input.\"\"\"\n\n    name = \"human\"\n    description = (\n        \"You can ask a human for guidance when you think you \"\n        \"got stuck or you are not sure what to do next. \"\n        \"The input should be a question for the human.\"\n    )\n\n    def run(self, query: str, run_manager=None) -> str:\n        \"\"\"Use the Human input tool.\"\"\"\n        res = run_sync(cl.AskUserMessage(content=query).send())\n        return res[\"content\"]\n\n    async def _arun(self, query: str, run_manager=None) -> str:\n        \"\"\"Use the Human input tool.\"\"\"\n        res = await cl.AskUserMessage(content=query).send()\n        return res[\"output\"]\n```\n\n----------------------------------------\n\nTITLE: Installing Chainlit via pip\nDESCRIPTION: Command to install the Chainlit library using pip package manager. This is a prerequisite before running the example application.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/confirm-action/README.md#2025-04-21_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install chainlit\n```\n\n----------------------------------------\n\nTITLE: Adding Packages to LangServe Application\nDESCRIPTION: Commands for adding packages to a LangServe application from various sources including official LangChain templates and custom GitHub repositories.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# adding packages from \n# https://github.com/langchain-ai/langchain/tree/master/templates\nlangchain app add $PROJECT_NAME\n\n# adding custom GitHub repo packages\nlangchain app add --repo $OWNER/$REPO\n# or with whole git string (supports other git providers):\n# langchain app add git+https://github.com/hwchase17/chain-of-verification\n\n# with a custom api mount point (defaults to `/{package_name}`)\nlangchain app add $PROJECT_NAME --api_path=/my/custom/path/rag\n```\n\n----------------------------------------\n\nTITLE: Navigating to Cloned Directory in Bash\nDESCRIPTION: Command to change directory to the cloned project folder. Replace <cloned-directory> with the actual directory name.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/extended-thinking-in-the-ui/chainlit.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd <cloned-directory>\n```\n\n----------------------------------------\n\nTITLE: Running LangServe in Docker Container\nDESCRIPTION: Command to run the LangServe application in a Docker container with necessary environment variables and port mapping.\nSOURCE: https://github.com/chainlit/cookbook/blob/main/literal-langserve/langserve-app/README.md#2025-04-21_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker run -e OPENAI_API_KEY=$OPENAI_API_KEY -p 8080:8080 my-langserve-app\n```"
  }
]