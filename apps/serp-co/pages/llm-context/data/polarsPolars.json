[
  {
    "owner": "pola-rs",
    "repo": "polars",
    "content": "TITLE: Executing SQL Queries from Multiple Sources\nDESCRIPTION: This example demonstrates executing SQL queries across multiple data sources including CSV, NDJSON, and Pandas DataFrames. It registers different data sources to the SQLContext and then joins them using SQL. This illustrates how to query data from diverse sources within Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/intro.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclean_tmp_file(csv_path)\nclean_tmp_file(ndjson_path)\n```\n\n----------------------------------------\n\nTITLE: Calculating Annual Average using group_by_dynamic in Python with Polars\nDESCRIPTION: This code snippet shows how to use group_by_dynamic to calculate the annual average closing price of a stock. It groups by the 'Date' column on an annual basis and takes the mean of the 'Close' column for each year.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/rolling.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nannual_avg = df.group_by_dynamic(\n    \"Date\",\n    every=\"1y\",\n).agg(\n    pl.col(\"Close\").mean().alias(\"Annual average\"),\n)\nprint(annual_avg)\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Queries with SQLContext\nDESCRIPTION: This code snippet demonstrates how to execute a SQL query using the SQLContext. It registers a DataFrame, executes a SELECT query, and prints the result. It showcases how to query data registered with the SQLContext.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/intro.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing import assert_frame_equal\n\n\ndf = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"foo\", \"bar\", \"baz\"]\n})\n\nctx = pl.SQLContext(register_globals=True)\nresult = ctx.execute(\"SELECT * FROM df WHERE id > 1\").collect()\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Adding columns with with_columns context\nDESCRIPTION: This snippet demonstrates how to add new columns to a Polars DataFrame using the `with_columns` context.  It shows how to specify new column names using named expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:with_columns\"\n```\n\n----------------------------------------\n\nTITLE: Polars Expression-Based Pattern\nDESCRIPTION: Shows the preferred Polars pattern using expression-based functions that can run in parallel within a single context, improving performance over the sequential pipe pattern.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef get_foo(input_column: str) -> pl.Expr:\n    return pl.col(input_column).some_computation().alias(\"foo\")\n\ndef get_bar(input_column: str) -> pl.Expr:\n    return pl.col(input_column).some_computation().alias(\"bar\")\n\ndef get_ham(input_column: str) -> pl.Expr:\n    return pl.col(input_column).some_computation().alias(\"ham\")\n\n# This single context will run all 3 expressions in parallel\ndf.with_columns(\n    get_ham(\"col_a\"),\n    get_bar(\"col_b\"),\n    get_foo(\"col_c\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning CSV with Polars Lazy API\nDESCRIPTION: Demonstrates how to create a lazy query from a CSV file using pl.scan_csv(), including column transformations and filtering. Shows how to load data, convert column case, and apply filtering conditions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/using.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n(pl.scan_csv(\"reddit.csv\")\n    .with_columns(pl.col(\"name\").str.to_uppercase())\n    .filter(pl.col(\"comment_karma\") > 0))\n```\n\n----------------------------------------\n\nTITLE: Streaming Execution for Large Datasets in Polars (Python)\nDESCRIPTION: This code snippet shows how to use streaming mode in Polars to process larger-than-memory datasets. It uses the engine=\"streaming\" argument with the .collect() method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/execution.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n(df.filter(pl.col(\"comment_karma\") > 100)\n   .select([\"id\", \"name\", \"created_utc\", \"updated_on\", \"comment_karma\", \"link_karma\"])\n   .collect(engine=\"streaming\"))\n```\n\n----------------------------------------\n\nTITLE: Group By Context with Aggregations\nDESCRIPTION: Demonstrates grouping data and applying aggregations across groups using multiple expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/expressions-and-contexts.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf.group_by(\n    [\n        (pl.col(\"birth\") // 10 * 10).alias(\"decade\"),\n        (pl.col(\"height\") < 1.7).alias(\"is_short\")\n    ]\n).agg([\n    pl.col(\"weight\", \"height\").mean().name.prefix(\"avg_\"),\n    pl.col(\"name\").len().alias(\"group_size\")\n])\n```\n\n----------------------------------------\n\nTITLE: Conditional Aggregation in Polars using group_by\nDESCRIPTION: This snippet demonstrates conditional aggregation in Polars. It groups data by 'state' and counts the number of 'Pro' and 'Anti' administration delegates for each state.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nout = df.group_by(\"state\").agg(\n    pl.col(\"type\").filter(pl.col(\"party\") == \"Anti-Administration\").count().alias(\"anti\"),\n    pl.col(\"type\").filter(pl.col(\"party\") == \"Pro-Administration\").count().alias(\"pro\"),\n).sort(\"pro\", descending=True)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Element-wise Casting in Lists with Polars\nDESCRIPTION: This snippet shows how to use the eval function with pl.element to perform element-wise operations on list values. It demonstrates casting string measurements to floats and counting null values to identify error counts.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:element-wise-casting\"\n```\n\n----------------------------------------\n\nTITLE: Creating a DataFrame\nDESCRIPTION: This python snippet shows how to create a polars DataFrame. This piece is from the getting-started guide to Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Unpivoting a DataFrame in Polars\nDESCRIPTION: This code snippet shows how to use the unpivot method in Polars to transform a DataFrame from wide format to long format. It demonstrates both eager and lazy execution, highlighting that they have the same API.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/unpivot.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Eager\ndf_unpivoted = df.melt(id_vars=[\"id\", \"date\"], variable_name=\"variable\", value_name=\"value\")\nprint(df_unpivoted)\n\n# Lazy\ndf_lazy = df.lazy()\ndf_unpivoted_lazy = df_lazy.melt(\n    id_vars=[\"id\", \"date\"], variable_name=\"variable\", value_name=\"value\"\n)\nprint(df_unpivoted_lazy.collect())\n```\n\n----------------------------------------\n\nTITLE: Selecting All Columns with the `all` Function\nDESCRIPTION: Shows how to use the `all` function as a shorthand to refer to all columns in a DataFrame for expression expansion.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:all\"\n```\n\n----------------------------------------\n\nTITLE: Column Assignment in Pandas vs Polars (Python)\nDESCRIPTION: Comparison of adding new columns based on existing ones. Pandas uses assign with lambda functions, while Polars uses with_columns and can execute in parallel.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Pandas\ndf.assign(\n    tenXValue=lambda df_: df_.value * 10,\n    hundredXValue=lambda df_: df_.value * 100\n)\n\n# Polars\ndf.with_columns(\n    tenXValue=pl.col(\"value\") * 10,\n    hundredXValue=pl.col(\"value\") * 100,\n)\n```\n\n----------------------------------------\n\nTITLE: Counting Missing Values in Polars\nDESCRIPTION: Shows how to use the null_count function to determine how many values are missing from a column. This is an efficient operation as Polars maintains metadata about missing values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Count the nulls in each column\ndf.null_count()\n\n# Count the nulls in one column\ndf[\"a\"].null_count()\n```\n\n----------------------------------------\n\nTITLE: Filtering Data in Pandas vs Polars (Python)\nDESCRIPTION: Comparison of filtering operations. Pandas uses query method or boolean indexing, while Polars uses the filter method with expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Pandas\ndf.query(\"m2_living > 2500 and price < 300000\")\n# or\ndf[(df[\"m2_living\"] > 2500) & (df[\"price\"] < 300000)]\n\n# Polars\ndf.filter(\n    (pl.col(\"m2_living\") > 2500) & (pl.col(\"price\") < 300000)\n)\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Common Table Expressions in Polars SQL\nDESCRIPTION: This snippet demonstrates how to create and use a Common Table Expression in Polars SQL. It defines a CTE named 'older_people' that filters rows where age is greater than 30, then queries this CTE to select names starting with 'C'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/cte.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/cte.py:setup\"\n--8<-- \"python/user-guide/sql/cte.py:cte\"\n```\n\n----------------------------------------\n\nTITLE: Distributed Query Example with Polars Cloud in Python\nDESCRIPTION: Comprehensive example showing how to perform a distributed query on Parquet files in S3, including filtering, grouping, aggregation, and writing results back to S3.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/distributed-engine.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars_cloud as pc\nfrom datetime import date\n\nquery = (\n    pl.scan_parquet(\"s3://dataset/\")\n    .filter(pl.col(\"l_shipdate\") <= date(1998, 9, 2))\n    .group_by(\"l_returnflag\", \"l_linestatus\")\n    .agg(\n        avg_price=pl.mean(\"l_extendedprice\"),\n        avg_disc=pl.mean(\"l_discount\"),\n        count_order=pl.len(),\n    )\n)\n\nresult = (\n    query.remote(pc.ComputeContext(cpus=16, memory=64, cluster_size=32))\n    .distributed()\n    .sink_parquet(\"s3://output/result.parquet\")\n)\n```\n\n----------------------------------------\n\nTITLE: Performing a Left Join in Python\nDESCRIPTION: This snippet shows how to perform a left join operation on two DataFrames containing property information, keeping all rows from the left DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\njoined = props_groups.join(props_prices, on=\"property\", how=\"left\")\nprint(joined)\n```\n\n----------------------------------------\n\nTITLE: Filling Missing Values with Interpolation in Polars\nDESCRIPTION: Demonstrates how to use interpolate to fill intermediate missing values through linear interpolation. Note that nulls at the beginning and end of the series remain null.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Interpolate between the non-null values\ndf2.with_columns(pl.col(\"b\").interpolate())\n```\n\n----------------------------------------\n\nTITLE: Element-wise Regex Matching in Lists with Polars\nDESCRIPTION: This snippet demonstrates using regular expressions with pl.element to check if measurements start with a letter (indicating an error code). It shows how to filter and count error codes within lists.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:element-wise-regex\"\n```\n\n----------------------------------------\n\nTITLE: Unique Values and Counts Operations\nDESCRIPTION: Shows how to obtain series of unique values and their counts separately.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:unique_counts\"\n```\n\n----------------------------------------\n\nTITLE: Using the custom expression in Polars\nDESCRIPTION: This Python code demonstrates how to use the registered `pig_latinnify` function within a Polars DataFrame. It creates a DataFrame, then uses the `with_columns` method and the imported `pig_latinnify` function to add a new column containing the pig latin conversion of the 'convert' column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom expression_lib import pig_latinnify\n\ndf = pl.DataFrame(\n    {\n        \"convert\": [\"pig\", \"latin\", \"is\", \"silly\"],\n    }\n)\nout = df.with_columns(pig_latin=pig_latinnify(\"convert\"))\n```\n\n----------------------------------------\n\nTITLE: Creating a Polars Lazy Query Plan\nDESCRIPTION: This snippet creates a lazy query plan in Polars. It reads a CSV file, selects all columns, converts the 'name' column to uppercase, and filters rows where 'comment_karma' is greater than 0.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/query-plan.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nq = (\n    pl.scan_csv(\"data/reddit.csv\")\n    .select(pl.col(\"*\"))\n    .with_columns(pl.col(\"name\").str.to_uppercase())\n    .filter(pl.col(\"comment_karma\") > 0)\n)\n```\n\n----------------------------------------\n\nTITLE: Complex Pokémon Data Analysis Using Window Functions in Polars\nDESCRIPTION: Demonstrates multiple window function operations on Pokémon data, including sorting by type, selecting top 3 per type, and ranking by speed, attack, and name within types.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npokemon.select(\n    pl.all(),\n    pl.col(\"Name\").sort_by(\"Type 1\").over(\"Type 1\").head(3).alias(\"Type 1\"),\n    pl.col(\"Name\").sort_by(\"Speed\").over(\"Type 1\").head(3).alias(\"fastest/group\"),\n    pl.col(\"Name\").sort_by(\"Attack\").over(\"Type 1\").head(3).alias(\"strongest/group\"),\n    pl.col(\"Name\").sort().over(\"Type 1\").head(3).alias(\"sorted_by_alphabet\")\n).show()\n```\n\n----------------------------------------\n\nTITLE: Ranking Pokémon Speed by Multiple Types in Polars\nDESCRIPTION: Demonstrates ranking Pokémon speed using multiple type columns as grouping criteria. This example uses both 'Type 1' and 'Type 2' for more granular ranking.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf_ranked = pokemon.select(\n    pl.col(\"*\"),\n    pl.col(\"Speed\").rank().over([\"Type 1\", \"Type 2\"]).alias(\"Speed rank in type\")\n)\nprint(df_ranked)\n```\n\n----------------------------------------\n\nTITLE: Explaining Query Execution Plan in Polars SQL\nDESCRIPTION: Displays the execution plan that Polars will use to execute the specified query, useful for query optimization.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nEXPLAIN SELECT * FROM some_table\n```\n\n----------------------------------------\n\nTITLE: Basic SELECT Statement Syntax\nDESCRIPTION: Demonstrates the basic syntax for SELECT statements in Polars SQL to retrieve data from tables into DataFrames.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nSELECT column1, column2, ...\nFROM table_name;\n```\n\n----------------------------------------\n\nTITLE: Converting USD to EUR Using Column Name Expansion\nDESCRIPTION: Demonstrates explicit expansion by column name using the `col` function to convert multiple price columns from USD to EUR simultaneously.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:col-with-names\"\n```\n\n----------------------------------------\n\nTITLE: Semi Join Implementation\nDESCRIPTION: Demonstrates semi join that returns left dataframe rows with matches in right dataframe without joining.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:semi-join\"\n```\n\n----------------------------------------\n\nTITLE: Slicing Lists in Polars\nDESCRIPTION: This snippet demonstrates various list slicing operations using the list namespace functions head, tail, and slice. It shows how to extract portions of lists without exploding them.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:list-slicing\"\n```\n\n----------------------------------------\n\nTITLE: Writing Hive Partitioned Parquet Dataset using Polars in Python\nDESCRIPTION: This code demonstrates how to write a DataFrame to a hive-partitioned parquet dataset, partitioned by specified columns 'a' and 'b'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:write_parquet_partitioned\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating INTERSECT Operation in Polars SQL\nDESCRIPTION: This snippet demonstrates the use of the INTERSECT operation to combine two SELECT statements, returning only the rows that appear in both result sets. It uses Polars LazyFrames and the SQL interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/set_operations.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npl.sql(\"\"\"\n    SELECT id, name FROM lf1\n    INTERSECT\n    SELECT id, name FROM lf2\n\"\"\").sort(by=\"id\").collect()\n# shape: (2, 2)\n# ┌─────┬─────────┐\n# │ id  ┆ name    │\n# │ --- ┆ ---     │\n# │ i64 ┆ str     │\n# ╞═════╪═════════╡\n# │ 2   ┆ Bob     │\n# │ 3   ┆ Charlie │\n# └─────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Reading Database with URI Connection - Python\nDESCRIPTION: Example showing how to read all columns from a 'foo' table in a Postgres database using a URI connection string.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npl.read_database_uri(\"postgresql://username:password@host:port/database\", \"SELECT * FROM foo\")\n```\n\n----------------------------------------\n\nTITLE: Converting Time Zones in Polars Dataframes (Python)\nDESCRIPTION: This snippet shows how to convert between different time zones in Polars dataframes using the dt.convert_time_zone method. It also demonstrates replacing time zones and handling daylight saving time transitions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/timezones.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = df.with_columns([\n    pl.col(\"utc\").dt.convert_time_zone(\"America/New_York\").alias(\"new_york\"),\n])\n\nprint(df)\n\n# Replacing time zone (this does not convert the time)\ndf = df.with_columns([\n    pl.col(\"utc\").dt.replace_time_zone(\"America/New_York\").alias(\"unconverted\"),\n])\n\nprint(df)\n\n# Daylight saving time transitions\ndf = pl.DataFrame(\n    {\n        \"date\": [\n            \"2023-03-12 01:59:59\",\n            \"2023-03-12 02:00:00\",\n            \"2023-03-12 02:00:01\",\n            \"2023-03-12 02:59:59\",\n            \"2023-03-12 03:00:00\",\n            \"2023-03-12 03:00:01\",\n        ]\n    }\n).with_columns(pl.col(\"date\").str.to_datetime())\n\ndf = df.with_columns(\n    pl.col(\"date\")\n    .dt.replace_time_zone(\"America/New_York\")\n    .dt.convert_time_zone(\"UTC\")\n    .alias(\"utc\")\n)\n\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Extracting Date Features in Polars\nDESCRIPTION: Demonstrates extracting date components like year or day from a date column using the .dt namespace.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/parsing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/time-series/parsing.py:extract\"\n```\n\n----------------------------------------\n\nTITLE: Converting DataFrame to LazyFrame\nDESCRIPTION: Shows how to convert an existing DataFrame to a LazyFrame using the .lazy() method, enabling lazy evaluation and query optimization on in-memory data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/using.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.lazy()\n```\n\n----------------------------------------\n\nTITLE: Calculating Continuous Quantiles with QUANTILE_CONT in Polars SQL\nDESCRIPTION: Demonstrates how to use the QUANTILE_CONT function to calculate continuous quantiles for a column in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [5, 20, 10, 30, 70, 40, 10, 90]})\ndf.sql(\"\"\"\n  SELECT\n    QUANTILE_CONT(foo, 0.25) AS foo_q25,\n    QUANTILE_CONT(foo, 0.50) AS foo_q50,\n    QUANTILE_CONT(foo, 0.75) AS foo_q75,\n  FROM self\n\"\"\")\n# shape: (1, 3)\n# ┌─────────┬─────────┬─────────┐\n# │ foo_q25 ┆ foo_q50 ┆ foo_q75 │\n# │ ---     ┆ ---     ┆ ---     │\n# │ f64     ┆ f64     ┆ f64     │\n# ╞═════════╪═════════╪═════════╡\n# │ 10.0    ┆ 25.0    ┆ 47.5    │\n# └─────────┴─────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Scanning Parquet Files with Polars in Python\nDESCRIPTION: Illustrates how to scan a Parquet file using Polars, which creates a LazyFrame for delayed computation. This approach allows for query optimization before actually reading the data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/parquet.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlf = pl.scan_parquet(\"path/to/file.parquet\")\n```\n\n----------------------------------------\n\nTITLE: Performing an Equi Join on Property DataFrames in Python\nDESCRIPTION: This snippet demonstrates how to perform an equi join on two DataFrames containing property information, combining color groups and prices based on property names.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\njoined = props_groups.join(props_prices, on=\"property\")\nprint(joined)\n```\n\n----------------------------------------\n\nTITLE: Executing Lazy Pivot Operation\nDESCRIPTION: Shows how to perform pivot operations using lazy evaluation in Polars LazyFrame. Requires schema determination before query execution.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/pivot.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/pivot.py:lazy\"\n```\n\n----------------------------------------\n\nTITLE: Scanning Parquet Data from Hugging Face with Polars\nDESCRIPTION: Illustrates scanning Parquet files from a Hugging Face repository, specifically accessing a Hive-partitioned dataset using the scan_parquet function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hugging-face.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.scan_parquet(\"hf://datasets/nameexhaustion/polars-docs/hive_dates/\")\n```\n\n----------------------------------------\n\nTITLE: String Character Stripping\nDESCRIPTION: Shows various methods for stripping characters from strings including strip_chars, strip_prefix, and strip_suffix functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:strip\"\n```\n\n----------------------------------------\n\nTITLE: Asof Join Implementation\nDESCRIPTION: Shows asof join matching trades with their most recent quotes based on timestamp.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:asof\"\n```\n\n----------------------------------------\n\nTITLE: Installing Python Cloud Storage Dependencies\nDESCRIPTION: Command to install required Python packages for cloud storage integration including fsspec, s3fs, adlfs, and gcsfs.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install fsspec s3fs adlfs gcsfs\n```\n\n----------------------------------------\n\nTITLE: Creating List Examples in Polars\nDESCRIPTION: This snippet demonstrates creating columns with List data type in Polars. The example shows how to create lists of different lengths within a dataframe.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:list-example\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Table with SQL in Polars\nDESCRIPTION: This snippet demonstrates how to use the CREATE TABLE SQL statement within Polars' SQLContext to create a new table based on a SELECT query from an existing DataFrame. It filters data from 'my_table' to create a new table 'older_people' with rows where age is greater than 30.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/create.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/create.py:setup\"\n--8<-- \"python/user-guide/sql/create.py:create\"\n```\n\n----------------------------------------\n\nTITLE: Handling NaN Values with fill_nan in Polars\nDESCRIPTION: Shows how to use fill_nan to replace NaN values with null, which allows aggregation functions like mean to skip these values rather than propagate NaN to the result.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf3.with_columns(\n    b_as_null=pl.col(\"b\").fill_nan(None)\n).select([\n    pl.col(\"b\").mean(),\n    pl.col(\"b_as_null\").mean(),\n])\n```\n\n----------------------------------------\n\nTITLE: Calculating Discrete Quantiles with QUANTILE_DISC in Polars SQL\nDESCRIPTION: Shows how to use the QUANTILE_DISC function to calculate discrete quantiles for a column in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [5, 20, 10, 30, 70, 40, 10, 90]})\ndf.sql(\"\"\"\n  SELECT\n    QUANTILE_DISC(foo, 0.25) AS foo_q25,\n    QUANTILE_DISC(foo, 0.50) AS foo_q50,\n    QUANTILE_DISC(foo, 0.75) AS foo_q75,\n  FROM self\n\"\"\")\n# shape: (1, 3)\n# ┌─────────┬─────────┬─────────┐\n# │ foo_q25 ┆ foo_q50 ┆ foo_q75 │\n# │ ---     ┆ ---     ┆ ---     │\n# │ f64     ┆ f64     ┆ f64     │\n# ╞═════════╪═════════╪═════════╡\n# │ 10.0    ┆ 20.0    ┆ 40.0    │\n# └─────────┴─────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Filtering with Multiple Predicates\nDESCRIPTION: This snippet filters a Polars DataFrame using multiple predicate expressions passed as separate parameters to the `filter` method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:filter-multiple\"\n```\n\n----------------------------------------\n\nTITLE: Handling Negative Dates in Polars\nDESCRIPTION: Illustrates how to work with negative dates (BCE) using Polars' dt namespace, since Python's datetime library doesn't support negative dates.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/filter.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\"dates\": [\"-0050-01-01\", \"0001-01-01\", \"0050-01-01\"]}\n).with_columns(pl.col(\"dates\").str.to_date())\n\ndf.filter(pl.col(\"dates\").dt.year() < 0)\n```\n\n----------------------------------------\n\nTITLE: Counting Unique Values in Polars\nDESCRIPTION: Shows exact and approximate counting of unique values using n_unique and approx_n_unique functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:count\"\n```\n\n----------------------------------------\n\nTITLE: Using WHERE Clause in Polars SQL\nDESCRIPTION: Demonstrates filtering rows based on conditions using the WHERE clause\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [30, 40, 50],\n    \"ham\": [\"a\", \"b\", \"c\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT * FROM self WHERE foo > 42\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: DataFrame Statistical Description\nDESCRIPTION: Demonstrates how to generate summary statistics for all columns in a DataFrame using the describe() method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprint(df.describe())\n```\n\n----------------------------------------\n\nTITLE: Nested Grouping in Polars for Filtered Aggregation\nDESCRIPTION: This code snippet shows nested grouping for filtered aggregation in Polars. It groups data by 'state' and 'gender' to compute the average age of delegates, filtering out invalid age values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nout = df.group_by([\"state\", \"gender\"]).agg(\n    filter_age(compute_age(\"born_date\", \"died_date\")).mean().alias(\"avg_age\")\n).sort(\"avg_age\", descending=True)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Select Context Example\nDESCRIPTION: Shows how to use select context to create new columns through aggregations and combinations of existing columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/expressions-and-contexts.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.select([\n    pl.col(\"name\"),\n    (pl.col(\"weight\") / (pl.col(\"height\") ** 2)).alias(\"bmi\"),\n    pl.lit(1).alias(\"constant\")\n])\n```\n\n----------------------------------------\n\nTITLE: Applying a Custom Function to Multiple Columns Using Struct in Polars\nDESCRIPTION: Demonstrates how to use Struct columns with map_elements() to apply a custom function (Ackermann) to multiple input columns simultaneously, enabling complex computations on multiple fields.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:struct-ack\"\n```\n\n----------------------------------------\n\nTITLE: Conditional Column Assignment in Pandas vs Polars (Python)\nDESCRIPTION: Example of reassigning column values based on a condition. Pandas uses mask, while Polars uses a when-then-otherwise expression that can be computed in parallel.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Pandas\ndf.assign(a=lambda df_: df_[\"a\"].mask(df_[\"c\"] == 2, df_[\"b\"]))\n\n# Polars\ndf.with_columns(\n    pl.when(pl.col(\"c\") == 2)\n    .then(pl.col(\"b\"))\n    .otherwise(pl.col(\"a\")).alias(\"a\")\n)\n```\n\n----------------------------------------\n\nTITLE: Generating NaN Values from Computations in Polars\nDESCRIPTION: Demonstrates how NaN values can arise from mathematical operations like division by zero in floating point calculations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\npl.DataFrame({\"a\": [0.0, 1.0]}).with_columns(b=pl.lit(0.0) / pl.col(\"a\"))\n```\n\n----------------------------------------\n\nTITLE: Reading Parquet Files with Polars in Python\nDESCRIPTION: Demonstrates how to read a Parquet file into a Polars DataFrame using the read_parquet function. This operation loads the entire file into memory.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/parquet.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.read_parquet(\"path/to/file.parquet\")\n```\n\n----------------------------------------\n\nTITLE: Custom Numba Function Implementation\nDESCRIPTION: Shows how to create a fast custom function using Numba's @guvectorize decorator for compiled performance.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:diff_from_mean_numba\"\n```\n\n----------------------------------------\n\nTITLE: Executing Frame-level SQL Query on Polars DataFrame\nDESCRIPTION: Shows how to use the DataFrame.sql method to execute a SQL query directly on a Polars DataFrame. The query selects columns, applies type casting, and filters rows based on a condition.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/python_api.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\ndf.sql(\"\"\"\n  SELECT a::uint4, (b * b) AS bb\n  FROM self WHERE a != 2\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Scanning CSV Files with Polars LazyFrame\nDESCRIPTION: Demonstrates lazy loading of CSV files using scan_csv function, which creates a LazyFrame for optimized processing without loading the entire file into memory.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/csv.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/csv','scan',['scan_csv'])}}\n```\n\n----------------------------------------\n\nTITLE: String Slicing Operations\nDESCRIPTION: Demonstrates string slicing operations using slice, head, and tail functions to extract substrings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:slice\"\n```\n\n----------------------------------------\n\nTITLE: Writing to a Sheet with Location and Clear Options in Google Colab\nDESCRIPTION: This snippet demonstrates how to write a Polars DataFrame to a specific location within a Google Sheet using the `update` method. It uses the `location` parameter to specify the starting cell and the `clear` parameter to control whether the worksheet is cleared before writing. It requires `google.colab` and `polars` libraries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Anti Join Operation\nDESCRIPTION: Shows anti join returning left dataframe rows that don't have matches in right dataframe.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:anti-join\"\n```\n\n----------------------------------------\n\nTITLE: Lazy Evaluation in Polars vs Eager Evaluation in Pandas (Python)\nDESCRIPTION: Comparison of CSV reading and grouping operations in Pandas (eager) and Polars (lazy). Polars optimizes the query by only reading necessary columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Pandas (eager)\ndf = pd.read_csv(csv_file, usecols=[\"id1\",\"v1\"])\ngrouped_df = df.loc[:,[\"id1\",\"v1\"]].groupby(\"id1\").sum(\"v1\")\n\n# Polars (lazy)\ndf = pl.scan_csv(csv_file)\ngrouped_df = df.group_by(\"id1\").agg(pl.col(\"v1\").sum()).collect()\n```\n\n----------------------------------------\n\nTITLE: Converting Data Types with CAST in Polars SQL\nDESCRIPTION: This example demonstrates the use of CAST to convert integer and string columns to float and date types respectively. It also shows the compact PostgreSQL-style casting syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/types.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [20, 10, 30],\n    \"bar\": [\"1999-12-31\", \"2012-07-05\", \"2024-01-01\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    foo::float4,\n    bar::date\n  FROM self\n\"\"\")\n# shape: (3, 2)\n# ┌──────┬────────────┐\n# │ foo  ┆ bar        │\n# │ ---  ┆ ---        │\n# │ f32  ┆ date       │\n# ╞══════╪════════════╡\n# │ 20.0 ┆ 1999-12-31 │\n# │ 10.0 ┆ 2012-07-05 │\n# │ 30.0 ┆ 2024-01-01 │\n# └──────┴────────────┘\n```\n\n----------------------------------------\n\nTITLE: ORDER BY Operation\nDESCRIPTION: Shows how to sort query results using ORDER BY clause in ascending or descending order.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:orderby\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Mean Speed per Pokémon Type Using Window Functions in Polars\nDESCRIPTION: Shows how to calculate the mean speed for each Pokémon type using window functions. The result is broadcast across rows of the same group.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf_mean = pokemon.select(\n    pl.col(\"*\"),\n    pl.col(\"Speed\").mean().over(\"Type 1\").alias(\"Mean Speed in Type\")\n)\nprint(df_mean)\n```\n\n----------------------------------------\n\nTITLE: Ranking Pokémon Speed by Type Using Window Functions in Polars\nDESCRIPTION: Shows how to use window functions to rank Pokémon speed within each type group. The code uses the rank and over functions to perform the operation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf_ranked = pokemon.select(\n    pl.col(\"*\"),\n    pl.col(\"Speed\").rank().over(\"Type 1\").alias(\"Speed rank in type\")\n)\nprint(df_ranked)\n```\n\n----------------------------------------\n\nTITLE: Creating Polars Expressions from SQL using sql_expr\nDESCRIPTION: Demonstrates the use of pl.sql_expr function to create native Polars expressions from SQL fragments. These expressions are then used to add new columns to a DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/python_api.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\ndf.with_columns(\n    pl.sql_expr(\"(a * a) + (b::float / 2) AS expr1\"),\n    pl.sql_expr(\"CONCAT_WS(':',a,b) AS expr2\")\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning File Paths with Hive Partitioning Enabled in Polars using Python\nDESCRIPTION: This code shows how to enable hive partition parsing when scanning file paths by setting hive_partitioning=True in the scan_parquet function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:scan_file_hive\"\n```\n\n----------------------------------------\n\nTITLE: Loading Time Series Data from CSV in Python using Polars\nDESCRIPTION: This snippet demonstrates how to load time series data from a CSV file using Polars. It creates a DataFrame with a 'Date' column parsed as datetime and other columns as floats.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/rolling.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.read_csv(\n    \"AAPL.csv\",\n    parse_dates=[\"Date\"],\n    columns=[\n        \"Date\",\n        \"Open\",\n        \"High\",\n        \"Low\",\n        \"Close\",\n        \"Adj Close\",\n        \"Volume\",\n    ],\n).select([\n    pl.col(\"Date\"),\n    pl.col(\"^.*$\").exclude(\"Date\", \"Volume\").cast(pl.Float64),\n    pl.col(\"Volume\").cast(pl.Int64),\n])\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Fixing multiplication with correct accumulator in Polars (Python)\nDESCRIPTION: This snippet corrects the multiplication example by initializing the accumulator with 1, which is the identity element for multiplication. This ensures the correct product is calculated across the columns. The initial value chosen for the accumulator `acc` is typically the identity element of the operation you want to apply.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\n\nout = df.select(\n    pl.fold(acc=1, function=lambda acc, x: acc * x, exprs=pl.all()).alias(\"product\"),\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Joining DataFrames\nDESCRIPTION: This snippet illustrates how to join two Polars DataFrames using a left outer join based on a common column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:join\"\n```\n\n----------------------------------------\n\nTITLE: Scanning Hive Partitioned Directory in Polars using Python\nDESCRIPTION: This snippet demonstrates how to scan a hive partitioned directory using Polars' scan_parquet function. It loads all files in the directory and includes the hive parts from the path in the output.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:scan_dir\"\n```\n\n----------------------------------------\n\nTITLE: Sorting within Group_by Context in Polars\nDESCRIPTION: This code snippet shows how to sort within the group_by context in Polars without changing the underlying DataFrame. It finds the oldest and youngest politicians per state with names sorted alphabetically.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nout = (\n    df.with_columns(pl.struct([\"born_date\", \"died_date\"])\n                   .apply(lambda x: compute_age(x[\"born_date\"], x[\"died_date\"]))\n                   .alias(\"age\"))\n    .group_by(\"state\")\n    .agg(\n        pl.col(\"first_name\").sort_by(\"age\").first().alias(\"youngest\"),\n        pl.col(\"first_name\").sort_by(\"age\").last().alias(\"oldest\"),\n        pl.col(\"first_name\").sort().first().alias(\"alphabetically_first\"),\n    )\n)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Aggregating Athlete Names Using Join Mapping Strategy in Polars\nDESCRIPTION: Demonstrates the use of the 'join' mapping strategy to aggregate athlete names into lists for each country. This approach repeats the list for all rows in the same group.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf_aggregated = df.select(\n    pl.col(\"*\"),\n    pl.col(\"Name\").sort_by(\"Rank\").over(\"Country\", mapping_strategy=\"join\").alias(\"Names\")\n)\nprint(df_aggregated)\n```\n\n----------------------------------------\n\nTITLE: Reading an Excel File with Polars in Python\nDESCRIPTION: This code snippet demonstrates how to read an Excel file using Polars' read_excel function. It uses the default fastexcel engine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/excel','read',['read_excel'])}}\n```\n\n----------------------------------------\n\nTITLE: Series Processing with map_batches()\nDESCRIPTION: Shows how to process an entire Series using map_batches() to calculate differences from mean.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:diff_from_mean\"\n```\n\n----------------------------------------\n\nTITLE: Conditional Operations Using when-then-otherwise\nDESCRIPTION: Demonstrates conditional operations using Polars' when-then-otherwise syntax, illustrated with the Collatz conjecture example.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:collatz\"\n```\n\n----------------------------------------\n\nTITLE: JOIN Operation\nDESCRIPTION: Illustrates how to perform JOIN operations between multiple tables in Polars SQL.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:join\"\n```\n\n----------------------------------------\n\nTITLE: Basic Aggregation in Polars using group_by\nDESCRIPTION: This code snippet shows how to perform basic aggregations using Polars' group_by context. It groups data by 'first_name', counts rows, collects 'gender' values, and gets the first 'last_name' for each group.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nout = df.group_by(\"first_name\").agg(\n    pl.count(),\n    pl.col(\"gender\"),\n    pl.col(\"last_name\").first(),\n).sort(\"count\", descending=True).limit(5)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Implementing Lazy API in Polars\nDESCRIPTION: A demonstration of the lazy API approach that defers execution until the collect() method is called, allowing optimizations like predicate and projection pushdown to be applied.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/lazy-api.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nscan_csv\n```\n\n----------------------------------------\n\nTITLE: With Columns Context Usage\nDESCRIPTION: Demonstrates using with_columns to add new calculated columns while preserving existing ones in the dataframe.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/expressions-and-contexts.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf.with_columns([\n    (pl.col(\"weight\") / (pl.col(\"height\") ** 2)).alias(\"bmi\")\n])\n```\n\n----------------------------------------\n\nTITLE: Complex Sorting within Group_by Context in Polars\nDESCRIPTION: This snippet demonstrates complex sorting within the group_by context in Polars. It finds the oldest and youngest politicians per state, sorts names alphabetically, and includes gender information for the alphabetically first name.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nout = (\n    df.with_columns(pl.struct([\"born_date\", \"died_date\"])\n                   .apply(lambda x: compute_age(x[\"born_date\"], x[\"died_date\"]))\n                   .alias(\"age\"))\n    .group_by(\"state\")\n    .agg(\n        pl.col(\"first_name\").sort_by(\"age\").first().alias(\"youngest\"),\n        pl.col(\"first_name\").sort_by(\"age\").last().alias(\"oldest\"),\n        pl.col(\"first_name\").sort().first().alias(\"alphabetically_first\"),\n        pl.col(\"gender\").sort_by(\"first_name\").first().alias(\"gender_of_alpha_first\"),\n    )\n)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Polars Selector Set Operations Examples\nDESCRIPTION: Comprehensive examples demonstrating various set operations with Polars selectors including union, intersection, difference, symmetric difference, and complement operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/selectors.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars.selectors as cs\nimport polars as pl\n\n# set up an empty dataframe with plenty of columns of various dtypes\ndf = pl.DataFrame(\n    schema={\n        \"abc\": pl.UInt16,\n        \"bbb\": pl.UInt32,\n        \"cde\": pl.Float64,\n        \"def\": pl.Float32,\n        \"eee\": pl.Boolean,\n        \"fgg\": pl.Boolean,\n        \"ghi\": pl.Time,\n        \"JJK\": pl.Date,\n        \"Lmn\": pl.Duration,\n        \"opp\": pl.Datetime(\"ms\"),\n        \"qqR\": pl.String,\n    },\n)\n\n# Select the UNION of temporal, strings and columns that start with \"e\"\nassert df.select(cs.temporal() | cs.string() | cs.starts_with(\"e\")).schema == {\n    \"eee\": pl.Boolean,\n    \"ghi\": pl.Time,\n    \"JJK\": pl.Date,\n    \"Lmn\": pl.Duration,\n    \"opp\": pl.Datetime(\"ms\"),\n    \"qqR\": pl.String,\n}\n\n# Select the INTERSECTION of temporal and column names that match \"opp\" OR \"JJK\"\nassert df.select(cs.temporal() & cs.matches(\"opp|JJK\")).schema == {\n    \"JJK\": pl.Date,\n    \"opp\": pl.Datetime(\"ms\"),\n}\n\n# Select the DIFFERENCE of temporal columns and columns that contain the name \"opp\" OR \"JJK\"\nassert df.select(cs.temporal() - cs.matches(\"opp|JJK\")).schema == {\n    \"ghi\": pl.Time,\n    \"Lmn\": pl.Duration,\n}\n\n# Select the SYMMETRIC DIFFERENCE of numeric columns and columns that contain an \"e\"\nassert df.select(cs.contains(\"e\") ^ cs.numeric()).schema == {\n    \"abc\": UInt16,\n    \"bbb\": UInt32,\n    \"eee\": Boolean,\n}\n\n# Select the COMPLEMENT of all columns of dtypes Duration and Time\nassert df.select(~cs.by_dtype([pl.Duration, pl.Time])).schema == {\n    \"abc\": pl.UInt16,\n    \"bbb\": pl.UInt32,\n    \"cde\": pl.Float64,\n    \"def\": pl.Float32,\n    \"eee\": pl.Boolean,\n    \"fgg\": pl.Boolean,\n    \"JJK\": pl.Date,\n    \"opp\": pl.Datetime(\"ms\"),\n    \"qqR\": pl.String,\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-column Ranking with Struct Columns in Polars\nDESCRIPTION: Demonstrates using Struct columns for complex multi-column ranking, where records are ranked first by Count and then by Avg_Rating in case of ties, using the over() window function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:struct_ranking\"\n```\n\n----------------------------------------\n\nTITLE: String concatenation with concat_str in Polars (Python)\nDESCRIPTION: This snippet shows how to concatenate strings across columns using `concat_str`.  It's recommended over using `fold` for string concatenation due to performance considerations. The function `concat_str` is more performant for string concatenation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [\"foo\", \"bar\", \"ham\"],\n    \"b\": [\"spam\", \"eggs\", \"toast\"],\n})\n\nout = df.select(\n    pl.concat_str(pl.all(), separator=\"_\").alias(\"str\")\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Creating Date Range and Using group_by_dynamic with Expressions in Python\nDESCRIPTION: This snippet demonstrates creating a date range for every day in 2021 and using group_by_dynamic with expressions to compute the number of days until the end of the month and the number of days in a month.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/rolling.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"date\": pl.date_range(\n    start=pl.date(2021, 1, 1),\n    end=pl.date(2021, 12, 31),\n    interval=\"1d\",\n)})\n\nout = df.group_by_dynamic(\n    \"date\",\n    every=\"1mo\",\n    period=\"1mo\",\n    include_boundaries=True,\n    closed=\"right\",\n).agg(\n    [\n        pl.col(\"date\").count().alias(\"days_in_month\"),\n        (pl.col(\"_upper_boundary\") - pl.col(\"date\").max()).dt.days().alias(\"days_to_end\"),\n    ]\n).select(\n    [\n        pl.col(\"date\").dt.strftime(\"%B\").alias(\"month\"),\n        pl.all().exclude(\"date\"),\n    ]\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Queries on Polars DataFrames in Python\nDESCRIPTION: This example shows how to run SQL queries on Polars DataFrames in Python, including joining data from multiple sources and performing aggregations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> df = pl.scan_csv(\"docs/assets/data/iris.csv\")\n>>> ## OPTION 1\n>>> # run SQL queries on frame-level\n>>> df.sql(\"\"\"\n...\tSELECT species,\n...\t  AVG(sepal_length) AS avg_sepal_length\n...\tFROM self\n...\tGROUP BY species\n...\t\"\"\").collect()\nshape: (3, 2)\n┌────────────┬──────────────────┐\n│ species    ┆ avg_sepal_length │\n│ ---        ┆ ---              │\n│ str        ┆ f64              │\n╞════════════╪══════════════════╡\n│ Virginica  ┆ 6.588            │\n│ Versicolor ┆ 5.936            │\n│ Setosa     ┆ 5.006            │\n└────────────┴──────────────────┘\n>>> ## OPTION 2\n>>> # use pl.sql() to operate on the global context\n>>> df2 = pl.LazyFrame({\n...    \"species\": [\"Setosa\", \"Versicolor\", \"Virginica\"],\n...    \"blooming_season\": [\"Spring\", \"Summer\", \"Fall\"]\n...})\n>>> pl.sql(\"\"\"\n... SELECT df.species,\n...     AVG(df.sepal_length) AS avg_sepal_length,\n...     df2.blooming_season\n... FROM df\n... LEFT JOIN df2 ON df.species = df2.species\n... GROUP BY df.species, df2.blooming_season\n... \"\"\").collect()\n```\n\n----------------------------------------\n\nTITLE: Aggregating and Manipulating Arrays with ARRAY_AGG in Polars SQL\nDESCRIPTION: Demonstrates the use of ARRAY_AGG function to aggregate column values into arrays, with optional ORDER BY and LIMIT clauses.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]})\ndf.sql(\"\"\"\n  SELECT\n    ARRAY_AGG(foo ORDER BY foo DESC) AS arr_foo,\n    ARRAY_AGG(bar LIMIT 2) AS arr_bar\n  FROM self\n\"\"\")\n# shape: (1, 2)\n# ┌───────────┬───────────┐\n# │ arr_foo   ┆ arr_bar   │\n# │ ---       ┆ ---       │\n# │ list[i64] ┆ list[i64] │\n# ╞═══════════╪═══════════╡\n# │ [3, 2, 1] ┆ [4, 5]    │\n# └───────────┴───────────┘\n```\n\n----------------------------------------\n\nTITLE: Boolean Operations in Polars\nDESCRIPTION: Shows usage of boolean operations using both operators (&, |, ~) and named functions (and_, or_, not_).\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:boolean\"\n```\n\n----------------------------------------\n\nTITLE: Full Outer Join in Polars\nDESCRIPTION: Demonstrates full outer join that keeps all rows from both dataframes regardless of matches.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:full-join\"\n```\n\n----------------------------------------\n\nTITLE: AWS S3 Authentication Using Storage Options\nDESCRIPTION: Example showing how to authenticate with AWS S3 using storage_options parameter when scanning a Parquet file.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nstorage_options = {\n    \"key\": \"your-access-key\",\n    \"secret\": \"your-secret-key\",\n    \"session_token\": \"your-session-token\",  # optional\n    \"region\": \"us-east-1\"  # optional\n}\ndf = pl.scan_parquet(\"s3://bucket/file.parquet\", storage_options=storage_options)\n```\n\n----------------------------------------\n\nTITLE: Multi-column Processing with Structs\nDESCRIPTION: Demonstrates how to combine multiple columns into a Struct for processing with user-defined functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:combine\"\n```\n\n----------------------------------------\n\nTITLE: Upsampling Time Series Data with Linear Interpolation in Python using Polars\nDESCRIPTION: This example demonstrates upsampling time series data from 30-minute to 15-minute intervals using Polars' upsample function, followed by linear interpolation to fill null values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/resampling.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf.upsample(\n    time_column=\"dt\",\n    every=\"15m\",\n).interpolate().fill_null(strategy=\"backward\")\n```\n\n----------------------------------------\n\nTITLE: Performing a Join with Key Expressions in Python\nDESCRIPTION: This snippet shows how to perform a join operation using key expressions to handle differently named columns and case-insensitive matching.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\njoined = props_groups2.join(\n    props_prices2,\n    left_on=pl.col(\"property_name\"),\n    right_on=pl.col(\"name\").str.to_lowercase(),\n)\nprint(joined)\n```\n\n----------------------------------------\n\nTITLE: Multiplying across columns with fold in Polars (Python)\nDESCRIPTION: This snippet demonstrates multiplying across columns 'a' and 'b' using the `fold` function. It initializes the accumulator with zero, which results in an incorrect product.  It shows the importance of initializing the accumulator with the correct identity element.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\n\nout = df.select(\n    pl.fold(acc=0, function=lambda acc, x: acc * x, exprs=pl.all()).alias(\"product\"),\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Performing Eager Pivot Operation\nDESCRIPTION: Demonstrates pivot operation using eager evaluation in Polars DataFrame. Performs immediate computation of the pivot transformation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/pivot.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/pivot.py:eager\"\n```\n\n----------------------------------------\n\nTITLE: Reading JSON File with Polars\nDESCRIPTION: Demonstrates how to read a standard JSON file into a Polars DataFrame using the read_json function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/json.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.read_json(\"path/to/file.json\")\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple CSV Files in Polars\nDESCRIPTION: Demonstrates creation of sample CSV files using write_csv method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/multiple.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/multiple.py:create\"\n```\n\n----------------------------------------\n\nTITLE: Writing CSV Files with Polars\nDESCRIPTION: Shows how to write DataFrame content to a CSV file using Polars' write_csv function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/csv.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/csv','write',['write_csv'])}}\n```\n\n----------------------------------------\n\nTITLE: Extracting Individual Fields from a Struct Column in Polars\nDESCRIPTION: Demonstrates how to use the field() function to extract a specific field from a Struct column, returning a new Series containing only the values from that field.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:series_struct_extract\"\n```\n\n----------------------------------------\n\nTITLE: Handling Inconsistent Dictionaries in Struct Columns in Polars\nDESCRIPTION: Shows what happens when trying to create a Series with Struct data type from dictionaries with inconsistent structures, resulting in null values or errors.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:series_struct_error\"\n```\n\n----------------------------------------\n\nTITLE: Reading and Writing CSV files\nDESCRIPTION: This python snippet shows how to write a polars DataFrame to a csv and read a csv. This piece is from the getting-started guide to Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:csv\"\n```\n\n----------------------------------------\n\nTITLE: Handling Diverging Queries in Polars (Python)\nDESCRIPTION: This code snippet illustrates how to efficiently handle diverging queries in Polars using collect_all(). It ensures that expensive LazyFrame computations are executed only once for multiple derived queries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/execution.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Some expensive LazyFrame\nlf: LazyFrame\n\nlf_1 = LazyFrame.select(pl.all().sum())\n\nlf_2 = lf.some_other_computation()\n\npl.collect_all([lf_1, lf_2]) # this will execute lf only once!\n```\n\n----------------------------------------\n\nTITLE: Implementing sum_horizontal with fold in Polars (Python)\nDESCRIPTION: This snippet demonstrates how to reimplement the `sum_horizontal` function using the `fold` function in Polars. It initializes the accumulator with zero and adds the values from columns 'a' and 'b'. The function `fold` expects a function `f` as the parameter `function` and `f` should accept two arguments.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\n\nout = df.select(\n    pl.fold(acc=0, function=lambda acc, x: acc + x, exprs=pl.all()).alias(\"sum\"),\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Concatenating DataFrames with Categorical Columns in Polars\nDESCRIPTION: Demonstrates how to concatenate DataFrames with Categorical columns using the string cache to avoid reencoding warnings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Enable string cache\npl.enable_string_cache()\n\n# Create two DataFrames with Categorical columns\ndf1 = pl.DataFrame(\n    {\"category\": [\"A\", \"B\", \"C\"]},\n    schema={\"category\": pl.Categorical},\n)\ndf2 = pl.DataFrame(\n    {\"category\": [\"B\", \"C\", \"D\"]},\n    schema={\"category\": pl.Categorical},\n)\n\n# Concatenate DataFrames\nconcatenated_df = pl.concat([df1, df2])\nprint(concatenated_df)\n\n# Disable string cache\npl.disable_string_cache()\n```\n\n----------------------------------------\n\nTITLE: Filling Missing Values with Neighbor-Based Strategies in Polars\nDESCRIPTION: Shows fill_null strategies based on neighboring values, such as 'forward' (using previous non-null values) and 'backward' (using next non-null values) to replace missing data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Use values from same column to fill nulls\ndf2.with_columns(\n    forwards=pl.col(\"b\").fill_null(strategy=\"forward\"),\n    backwards=pl.col(\"b\").fill_null(strategy=\"backward\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning NDJSON File with Polars\nDESCRIPTION: Illustrates how to scan a newline-delimited JSON (NDJSON) file using Polars, which returns a LazyFrame for delayed parsing and lazy computation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/json.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlf = pl.scan_ndjson(\"path/to/file.ndjson\")\n```\n\n----------------------------------------\n\nTITLE: Reading Multiple Files into Single DataFrame\nDESCRIPTION: Shows how to use globbing patterns to read multiple CSV files into a single Polars DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/multiple.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/multiple.py:read\"\n```\n\n----------------------------------------\n\nTITLE: Convert pyarrow ChunkedArray/Array to Polars Series\nDESCRIPTION: Illustrates converting a pyarrow ChunkedArray or Array to a Polars Series using the `polars.Series` constructor. This allows importing Arrow-formatted series data into Polars for manipulation. It utilizes the Arrow PyCapsule interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport pyarrow as pa\n\nca = pa.chunked_array([[1, 2, 3]])\n\ns = pl.Series(ca)\n```\n\n----------------------------------------\n\nTITLE: String to Numeric Type Conversion\nDESCRIPTION: Demonstrates conversion between strings and numeric types, including handling of invalid string formats.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [\"1\", \"2\", \"3\"]})\ndf.with_columns([\n    pl.col(\"a\").cast(pl.Int64).alias(\"int\"),\n    pl.col(\"a\").cast(pl.Float64).alias(\"float\"),\n])\n```\n\n----------------------------------------\n\nTITLE: Using SQLContext for DataFrame Queries and Table Management\nDESCRIPTION: Illustrates the use of SQLContext as a context manager to execute SQL queries on registered DataFrames. It demonstrates table registration, query execution, and result retrieval within the context.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/python_api.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf1 = pl.DataFrame({\"id\": [1, 2, 3], \"value\": [0.1, 0.2, 0.3]})\ndf2 = pl.DataFrame({\"id\": [3, 2, 1], \"value\": [25.6, 53.4, 12.7]})\n\nwith pl.SQLContext(df_a=df1, df_b=df2, eager=True) as ctx:\n    df = ctx.execute(\"\"\"\n      SELECT\n        a.id,\n        a.value AS value_a,\n        b.value AS value_b\n      FROM df_a AS a INNER JOIN df_b AS b USING (id)\n      ORDER BY id\n    \"\"\")\n```\n\n----------------------------------------\n\nTITLE: Exploding Lists into Separate Rows in Polars\nDESCRIPTION: This snippet shows how to use the explode function to transform list elements into separate rows. Each temperature measurement is expanded into its own row while preserving the station information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:explode\"\n```\n\n----------------------------------------\n\nTITLE: Multiple Window Functions in Polars\nDESCRIPTION: Shows how to combine multiple window operations efficiently in a single expression, demonstrating Polars' ability to cache and optimize window expressions over the same groups.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf.with_columns(\n    pl.col(\"c\").count().over(\"c\").alias(\"size\"),\n    pl.col(\"c\").sum().over(\"type\").alias(\"sum\"),\n    pl.col(\"type\").reverse().over(\"c\").alias(\"reverse_type\")\n)\n```\n\n----------------------------------------\n\nTITLE: Writing JSON and NDJSON Files with Polars\nDESCRIPTION: Demonstrates how to write Polars DataFrames to both standard JSON and newline-delimited JSON (NDJSON) files using write_json and write_ndjson functions respectively.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/json.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf.write_json(\"path/to/file.json\")\ndf.write_ndjson(\"path/to/file.ndjson\")\n```\n\n----------------------------------------\n\nTITLE: Reading Database with SQLAlchemy Engine - Python\nDESCRIPTION: Demonstrates reading from a database using a SQLAlchemy connection engine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npl.read_database(engine.connect(), \"SELECT * FROM foo\")\n```\n\n----------------------------------------\n\nTITLE: Inspecting DataFrame Schema\nDESCRIPTION: Shows how to view the schema (column names and data types) of a DataFrame using the schema property.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(df.schema)\n```\n\n----------------------------------------\n\nTITLE: Expression Expansion in Polars\nDESCRIPTION: This python snippet shows how to use expression expansion to manipulate columns with a single expression. It uses `.name.suffix` to add a suffix to the names of the original columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:expression-expansion\"\n```\n\n----------------------------------------\n\nTITLE: Split Replace Functionality in Python\nDESCRIPTION: Shows how the replace method has been split into two methods: replace and replace_strict. The replace method now always maintains the existing data type, while replace_strict is for creating a new column with mapped values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1, 2, 3])\ns.replace(1, \"a\")\nshape: (3,)\nSeries: '' [str]\n[\n        \"a\"\n        \"2\"\n        \"3\"\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns.replace(1, \"a\")\nTraceback (most recent call last):\n...\npolars.exceptions.InvalidOperationError: conversion from `str` to `i64` failed in column 'literal' for 1 out of 1 values: [\"a\"]\ns.replace_strict(1, \"a\", default=s)\nshape: (3,)\nSeries: '' [str]\n[\n        \"a\"\n        \"2\"\n        \"3\"\n]\n```\n\n----------------------------------------\n\nTITLE: Grouping rows with group_by context\nDESCRIPTION: This snippet demonstrates how to group rows in a Polars DataFrame based on shared values using the `group_by` context. It also uses `maintain_order` for reproducibility.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:group_by\"\n```\n\n----------------------------------------\n\nTITLE: Filtering rows with the filter context\nDESCRIPTION: This snippet demonstrates how to filter rows in a Polars DataFrame based on a condition using the `filter` context. Uses a datetime expression.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:filter\"\n```\n\n----------------------------------------\n\nTITLE: Prefixing and Suffixing Column Names\nDESCRIPTION: Demonstrates how to add prefixes or suffixes to multiple column names using the `name.prefix` and `name.suffix` functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:prefix-suffix\"\n```\n\n----------------------------------------\n\nTITLE: Safe Type Conversion with TRY_CAST in Polars SQL\nDESCRIPTION: This example shows the use of TRY_CAST to safely convert integer and string columns to unsigned 16-bit integer and date types. TRY_CAST returns NULL for values that cannot be converted.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/types.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [65432, 10101, -33333],\n    \"bar\": [\"1999-12-31\", \"N/A\", \"2024-01-01\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    TRY_CAST(foo AS uint2),\n    TRY_CAST(bar AS date)\n  FROM self\n\"\"\")\n# shape: (3, 2)\n# ┌───────┬────────────┐\n# │ foo   ┆ bar        │\n# │ ---   ┆ ---        │\n# │ u16   ┆ date       │\n# ╞═══════╪════════════╡\n# │ 65432 ┆ 1999-12-31 │\n# │ 10101 ┆ null       │\n# │ null  ┆ 2024-01-01 │\n# └───────┴────────────┘\n```\n\n----------------------------------------\n\nTITLE: Using Regular Expressions for Column Selection\nDESCRIPTION: Demonstrates column selection using regular expressions, which can match multiple columns based on pattern matching rules.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:col-with-regex\"\n```\n\n----------------------------------------\n\nTITLE: Array Type Inference with NumPy in Polars\nDESCRIPTION: This snippet demonstrates how Polars automatically infers the Array data type when using NumPy arrays. It shows how an n+1 dimensional NumPy array generates a column of n dimensional arrays.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:numpy-array-inference\"\n```\n\n----------------------------------------\n\nTITLE: Setting Global ComputeContext in Polars Cloud\nDESCRIPTION: Shows how to set a global ComputeContext using pc.set_compute_context(). This applies the context to all subsequent remote queries without explicit specification.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npc.set_compute_context(ctx)\n\nquery.remote().sink_parquet(...)\n```\n\n----------------------------------------\n\nTITLE: Creating and Querying a DataFrame in Python using Polars\nDESCRIPTION: This snippet demonstrates creating a DataFrame with Polars in Python and performing various operations like sorting, filtering, and aggregating data using Polars' expressive query language.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import polars as pl\n>>> df = pl.DataFrame(\n...     {\n...         \"A\": [1, 2, 3, 4, 5],\n...         \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n...         \"B\": [5, 4, 3, 2, 1],\n...         \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n...     }\n... )\n\n# embarrassingly parallel execution & very expressive query language\n>>> df.sort(\"fruits\").select(\n...     \"fruits\",\n...     \"cars\",\n...     pl.lit(\"fruits\").alias(\"literal_string_fruits\"),\n...     pl.col(\"B\").filter(pl.col(\"cars\") == \"beetle\").sum(),\n...     pl.col(\"A\").filter(pl.col(\"B\") > 2).sum().over(\"cars\").alias(\"sum_A_by_cars\"),\n...     pl.col(\"A\").sum().over(\"fruits\").alias(\"sum_A_by_fruits\"),\n...     pl.col(\"A\").reverse().over(\"fruits\").alias(\"rev_A_by_fruits\"),\n...     pl.col(\"A\").sort_by(\"B\").over(\"fruits\").alias(\"sort_A_by_B_by_fruits\"),\n... )\n```\n\n----------------------------------------\n\nTITLE: Conditional filtering with fold in Polars (Python)\nDESCRIPTION: This snippet demonstrates how to use `fold` to filter rows where all columns ('a' and 'b') are greater than 1.  It returns the boolean results of the comparisons and then ANDs them together.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\n\nout = df.filter(\n    pl.fold(acc=True, function=lambda acc, x: acc & (x > 1), exprs=pl.all())\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Value Counts Analysis in Polars\nDESCRIPTION: Demonstrates how to get detailed information about unique values and their counts.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:value_counts\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Categorical Data Type in Polars\nDESCRIPTION: Demonstrates how to create Categorical columns by casting or specifying the data type directly. Shows lexical comparisons with strings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Create a DataFrame with Categorical column\ndf = pl.DataFrame(\n    {\n        \"id\": [1, 2, 3, 4],\n        \"category\": [\"A\", \"B\", \"A\", \"C\"],\n    },\n    schema={\"id\": pl.Int32, \"category\": pl.Categorical},\n)\n\n# Lexical comparison with string\nprint(df.filter(pl.col(\"category\") > \"B\"))\n\n# Comparison with string column\ndf_with_string = df.with_columns(pl.lit(\"B\").alias(\"compare_value\"))\nprint(df_with_string.filter(pl.col(\"category\") > pl.col(\"compare_value\")))\n```\n\n----------------------------------------\n\nTITLE: Performing an Explicit Inner Join in Python\nDESCRIPTION: This snippet demonstrates how to perform an explicit inner join operation on two DataFrames containing property information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\njoined = props_groups.join(props_prices, on=\"property\", how=\"inner\")\nprint(joined)\n```\n\n----------------------------------------\n\nTITLE: Running SQL Queries with Polars in Python\nDESCRIPTION: This snippet demonstrates how to use SQL syntax with Polars in Python. It shows two approaches: running SQL directly on a DataFrame and using the global SQL context to operate on multiple DataFrames.\nSOURCE: https://github.com/pola-rs/polars/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> df = pl.scan_csv(\"docs/assets/data/iris.csv\")\n>>> ## OPTION 1\n>>> # run SQL queries on frame-level\n>>> df.sql(\"\"\"\n...     SELECT species,\n...       AVG(sepal_length) AS avg_sepal_length\n...     FROM self\n...     GROUP BY species\n...     \"\"\").collect()\nshape: (3, 2)\n┌────────────┬──────────────────┐\n│ species    ┆ avg_sepal_length │\n│ ---        ┆ ---              │\n│ str        ┆ f64              │\n╞════════════╪══════════════════╡\n│ Virginica  ┆ 6.588            │\n│ Versicolor ┆ 5.936            │\n│ Setosa     ┆ 5.006            │\n└────────────┴──────────────────┘\n>>> ## OPTION 2\n>>> # use pl.sql() to operate on the global context\n>>> df2 = pl.LazyFrame({\n...    \"species\": [\"Setosa\", \"Versicolor\", \"Virginica\"],\n...    \"blooming_season\": [\"Spring\", \"Summer\", \"Fall\"]\n...})\n>>> pl.sql(\"\"\"\n... SELECT df.species,\n...     AVG(df.sepal_length) AS avg_sepal_length,\n...     df2.blooming_season\n... FROM df\n... LEFT JOIN df2 ON df.species = df2.species\n... GROUP BY df.species, df2.blooming_season\n... \"\"\").collect()\n```\n\n----------------------------------------\n\nTITLE: Sinking Parquet Data with Partitioning - Polars - Python\nDESCRIPTION: This code snippet demonstrates how to sink data to parquet files using a partitioning strategy based on maximum file size. It first scans CSV files, filters out rows with missing data, and then sinks the data into parquet files. The `PartitionMaxSize` strategy ensures that each parquet file contains a maximum number of rows before creating a new file.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/sources_sinks.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlf = scan_csv(\"my_dataset/*.csv\").filter(pl.all().is_not_null())\nlf.sink_parquet(\n    pl.PartitionMaxSize(\n        \"my_table_{part}.parquet\"\n        max_size=512_000\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Selecting columns using Polars Expressions\nDESCRIPTION: This python snippet shows how to select columns from a polars DataFrame and use alias to name the new columns. This piece is from the getting-started guide to Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:select\"\n```\n\n----------------------------------------\n\nTITLE: Excluding Columns from Selection\nDESCRIPTION: Demonstrates how to exclude specific columns using the `exclude` function while selecting all other columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:all-exclude\"\n```\n\n----------------------------------------\n\nTITLE: Downcasting Numeric Types for Memory Optimization\nDESCRIPTION: Demonstrates how to reduce memory usage by downcasting numeric types from higher to lower precision, showing size estimation before and after casting.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [1.0, 2.0, 3.0]})\nprint(f\"Original dtypes:\\n{df.dtypes}\")\nprint(f\"Estimated size: {df.estimated_size()}\")\n\ndf_small = df.with_columns([\n    pl.col(\"a\").cast(pl.Int16),\n    pl.col(\"b\").cast(pl.Float32),\n])\nprint(f\"\\nNew dtypes:\\n{df_small.dtypes}\")\nprint(f\"Estimated size: {df_small.estimated_size()}\")\n```\n\n----------------------------------------\n\nTITLE: Filling Missing Values with Expressions in Polars\nDESCRIPTION: Demonstrates how to use fill_null with a Polars expression to replace missing values with computed values from other columns. This example replaces nulls with double the value from column 'a'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Fill the nulls with an expression\ndf2.with_columns(pl.col(\"b\").fill_null(pl.col(\"a\") * 2))\n```\n\n----------------------------------------\n\nTITLE: Horizontal Concatenation with Different Lengths in Polars\nDESCRIPTION: Illustrates horizontal concatenation of DataFrames with different row counts, where shorter DataFrames are padded with null values to match the length of the longest DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/concatenation.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/concatenation.py:horizontal_different_lengths\"\n```\n\n----------------------------------------\n\nTITLE: Setting up DataFrame for Pivot Operations\nDESCRIPTION: Creates a sample DataFrame with fruit sales data to demonstrate pivot operations\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/pivot.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/pivot.py:setup\"\n--8<-- \"python/user-guide/transformations/pivot.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Comprehensive Styling of Polars DataFrame with Great Tables\nDESCRIPTION: Provides a full example of styling a Polars DataFrame using various features of Great Tables. This snippet combines multiple styling techniques to create a well-formatted and visually appealing table.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n(\n    gt.tab_header(title=\"Iris Dataset\")\n    .tab_stub(col=\"species\")\n    .tab_spanner(label=\"Sepal\", columns=[\"sepal_length\", \"sepal_width\"])\n    .tab_spanner(label=\"Petal\", columns=[\"petal_length\", \"petal_width\"])\n    .fmt_number(columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], decimals=1)\n    .highlight_max(column=\"sepal_length\", color=\"yellow\")\n    .tab_style(style=\"font-weight: bold;\", locations=gt.cells_stub())\n    .tab_style(style=\"color: red;\", locations=gt.cells_body(columns=\"sepal_length\", rows=gt.where(lambda x: x[\"sepal_length\"] > 6.5)))\n    .tab_style(style=\"background-color: #f8f8f8;\", locations=gt.cells_body(rows=gt.even()))\n)\n```\n\n----------------------------------------\n\nTITLE: Converting USD to EUR Using Data Type Expansion\nDESCRIPTION: Demonstrates expansion by data type, where the expression is applied to all columns of a specified data type (Float64).\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:col-with-dtype\"\n```\n\n----------------------------------------\n\nTITLE: Using DataFrame Tail Method\nDESCRIPTION: Demonstrates how to view the last rows of a DataFrame using the tail() method, with an optional parameter to specify the number of rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(df.tail(2))\n```\n\n----------------------------------------\n\nTITLE: Using IFNULL function in Polars SQL\nDESCRIPTION: Shows how to use the IFNULL function to return an alternative value if an expression is NULL. It creates a DataFrame with null values and applies the IFNULL function using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"a\", None, None, \"d\"],\n    \"bar\": [1, 2, 3, 4],\n  }\n)\ndf.sql(\"\"\"\n  SELECT IFNULL(foo, 'n/a') AS baz FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌─────┐\n# │ baz │\n# │ --- │\n# │ str │\n# ╞═════╡\n# │ a   │\n# │ n/a │\n# │ n/a │\n# │ d   │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Table Functions\nDESCRIPTION: Shows how to use table functions to directly read from various file formats like CSV, Parquet, JSON, and IPC in SQL queries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:tablefunctions\"\n```\n\n----------------------------------------\n\nTITLE: Pattern Matching in Strings\nDESCRIPTION: Shows how to check for patterns in strings using contains, starts_with, and ends_with functions. Includes examples of both regex and literal pattern matching.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:existence\"\n```\n\n----------------------------------------\n\nTITLE: Implementing pandas transform in Polars\nDESCRIPTION: Demonstrates how to convert a pandas groupby transform operation to Polars using window functions. Shows creation of a new column containing group sizes.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.DataFrame({\n    \"c\": [1, 1, 1, 2, 2, 2, 2],\n    \"type\": [\"m\", \"n\", \"o\", \"m\", \"m\", \"n\", \"n\"],\n})\n\ndf[\"size\"] = df.groupby(\"c\")[\"type\"].transform(len)\n```\n\nLANGUAGE: python\nCODE:\n```\ndf.with_columns(\n    pl.col(\"type\").count().over(\"c\").alias(\"size\")\n)\n```\n\n----------------------------------------\n\nTITLE: Computing hash values for DataFrame rows in Python\nDESCRIPTION: The hash_rows method computes hash values for each row in the DataFrame. This can be useful for data integrity checks or creating unique identifiers for rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/computation.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nDataFrame.hash_rows\n```\n\n----------------------------------------\n\nTITLE: Pattern Extraction from Strings\nDESCRIPTION: Demonstrates using the extract function to capture specific patterns from strings using regex with capture groups.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:extract\"\n```\n\n----------------------------------------\n\nTITLE: Polars Expression Namespace Functions\nDESCRIPTION: List of functions available in the Polars expression namespace, accessible through the Expr class.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/functions.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nExpr.all\nExpr.any\nExpr.approx_n_unique\nExpr.count\nExpr.first\nExpr.head\nExpr.implode\nExpr.map_batches\nExpr.map_elements\nExpr.max\nExpr.mean\nExpr.median\nExpr.min\nExpr.n_unique\nExpr.quantile\nExpr.std\nExpr.sum\nExpr.tail\nExpr.var\n```\n\n----------------------------------------\n\nTITLE: Executing Polars Lazy Query with GPU Engine in Python\nDESCRIPTION: This snippet demonstrates how to trigger GPU-based execution for a Polars lazy query using the 'gpu' engine parameter in the collect() method. It sets up a query and collects the result using GPU acceleration.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/gpu.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/lazy/gpu.py:setup\"\n\nresult = q.collect(engine=\"gpu\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Converting String to Date in Polars SQL\nDESCRIPTION: Shows how to use the DATE function to convert string representations of dates into actual Date types. It demonstrates conversion with both default ISO-8601 format and a custom format string.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"s_dt1\": [\"1969-10-30\", \"2024-07-05\", \"2077-02-28\"],\n    \"s_dt2\": [\"10 February 1920\", \"5 July 2077\", \"28 April 2000\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    DATE(s_dt1) AS dt1,\n    DATE(s_dt2, '%d %B %Y') AS dt2\n  FROM self\n\"\"\")\n# shape: (3, 2)\n# ┌────────────┬────────────┐\n# │ dt1        ┆ dt2        │\n# │ ---        ┆ ---        │\n# │ date       ┆ date       │\n# ╞════════════╪════════════╡\n# │ 1969-10-30 ┆ 1920-02-10 │\n# │ 2024-07-05 ┆ 2077-07-05 │\n# │ 2077-02-28 ┆ 2000-04-28 │\n# └────────────┴────────────┘\n```\n\n----------------------------------------\n\nTITLE: Vertical Concatenation of DataFrames in Polars\nDESCRIPTION: Demonstrates vertical concatenation of DataFrames with identical columns to create a longer DataFrame. This operation combines all rows from multiple DataFrames into a single DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/concatenation.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/concatenation.py:setup\"\n--8<-- \"python/user-guide/transformations/concatenation.py:vertical\"\n```\n\n----------------------------------------\n\nTITLE: Using GPUEngine for Detailed Control in Polars\nDESCRIPTION: Example of using a GPUEngine object to specify which GPU to use on a multi-GPU node when collecting results.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/gpu-support.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nresult = q.collect(engine=pl.GPUEngine(device=1))\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Calculating Average with AVG in Polars SQL\nDESCRIPTION: Demonstrates how to use the AVG function to calculate the mean of a column in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [20, 10, 30, 40]})\ndf.sql(\"\"\"\n  SELECT AVG(bar) AS bar_avg FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌─────────┐\n# │ bar_avg │\n# │ ---     │\n# │ f64     │\n# ╞═════════╡\n# │ 25.0    │\n# └─────────┘\n```\n\n----------------------------------------\n\nTITLE: Creating a Series with Struct Data Type from Dictionaries in Polars\nDESCRIPTION: Demonstrates how Polars automatically converts a list of dictionaries into a Series with Struct data type, inferring the field names and types from the first dictionary.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:series_struct\"\n```\n\n----------------------------------------\n\nTITLE: Executing Parallel DataFrame Operations in Python with Polars\nDESCRIPTION: This example demonstrates Polars' expressive query language for DataFrame operations in Python. It creates a DataFrame with sample data and performs complex operations including filtering, sorting, and window functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import polars as pl\n>>> df = pl.DataFrame(\n...     {\n...         \"A\": [1, 2, 3, 4, 5],\n...         \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n...         \"B\": [5, 4, 3, 2, 1],\n...         \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n...     }\n... )\n\n# embarrassingly parallel execution & very expressive query language\n>>> df.sort(\"fruits\").select(\n...     \"fruits\",\n...     \"cars\",\n...     pl.lit(\"fruits\").alias(\"literal_string_fruits\"),\n...     pl.col(\"B\").filter(pl.col(\"cars\") == \"beetle\").sum(),\n...     pl.col(\"A\").filter(pl.col(\"B\") > 2).sum().over(\"cars\").alias(\"sum_A_by_cars\"),\n...     pl.col(\"A\").sum().over(\"fruits\").alias(\"sum_A_by_fruits\"),\n...     pl.col(\"A\").reverse().over(\"fruits\").alias(\"rev_A_by_fruits\"),\n...     pl.col(\"A\").sort_by(\"B\").over(\"fruits\").alias(\"sort_A_by_B_by_fruits\"),\n... )\n```\n\n----------------------------------------\n\nTITLE: Right Join Operation in Polars\nDESCRIPTION: Demonstrates right outer join between two dataframes, showing equivalence with left join when arguments are swapped.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:right-join\"\n```\n\n----------------------------------------\n\nTITLE: Splitting Strings into Lists in Polars\nDESCRIPTION: This snippet demonstrates using the str.split function to convert comma-separated temperature readings into lists. It shows how to transform string data into lists for further processing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:split\"\n```\n\n----------------------------------------\n\nTITLE: Executing Global SQL Query with Polars and Pandas DataFrames\nDESCRIPTION: Demonstrates how to use the global pl.sql function to execute a SQL query on Polars and Pandas DataFrames, as well as PyArrow tables. The query combines data from multiple sources, performs a join, and aggregates results.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/python_api.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport pandas as pd\n\npolars_df = pl.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [4, 5, 6, 7]})\npandas_df = pd.DataFrame({\"a\": [3, 4, 5, 6], \"b\": [6, 7, 8, 9]})\npolars_series = (polars_df[\"a\"] * 2).rename(\"c\")\npyarrow_table = polars_df.to_arrow()\n\npl.sql(\n    \"\"\"\n    SELECT a, b, SUM(c) AS c_total FROM (\n      SELECT * FROM polars_df                  -- polars frame\n        UNION ALL SELECT * FROM pandas_df      -- pandas frame\n        UNION ALL SELECT * FROM pyarrow_table  -- pyarrow table\n    ) all_data\n    INNER JOIN polars_series\n      ON polars_series.c = all_data.b          -- polars series\n    GROUP BY \"a\", \"b\"\n    ORDER BY \"a\", \"b\"\n    \"\"\"\n).collect()\n```\n\n----------------------------------------\n\nTITLE: Writing Parquet Files with Polars in Python\nDESCRIPTION: Shows how to write a Polars DataFrame to a Parquet file using the write_parquet method. This operation saves the DataFrame's data to disk in Parquet format.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/parquet.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.write_parquet(\"path/to/file.parquet\")\n```\n\n----------------------------------------\n\nTITLE: Upsampling Time Series Data with Forward Fill in Python using Polars\nDESCRIPTION: This code snippet shows how to upsample time series data from 30-minute to 15-minute intervals using Polars' upsample function with a forward fill strategy.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/resampling.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.upsample(\n    time_column=\"dt\",\n    every=\"15m\",\n).fill_null(strategy=\"forward\")\n```\n\n----------------------------------------\n\nTITLE: Basic Arithmetic Operations in Polars\nDESCRIPTION: Demonstrates basic arithmetic operations between series and literals. Shows how null values propagate through calculations and illustrates operator overloading functionality.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:arithmetic\"\n```\n\n----------------------------------------\n\nTITLE: Convert Polars DataFrame to pyarrow Table\nDESCRIPTION: This code snippet demonstrates how to convert a Polars DataFrame to a pyarrow Table using the `to_arrow` method. The resulting pyarrow Table provides a representation of the data that can be used with other Arrow-compatible libraries. This method may involve data copying.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\n    \"foo\": [1, 2, 3],\n    \"bar\": [\"ham\", \"spam\", \"jam\"]\n})\n\npa_table = df.to_arrow()\n```\n\n----------------------------------------\n\nTITLE: Loading and Preprocessing US Congress Dataset in Python using Polars\nDESCRIPTION: This snippet demonstrates how to load a US congress dataset into a Polars DataFrame and preprocess it by converting certain columns to categorical data type.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.read_csv(\"https://raw.githubusercontent.com/pola-rs/polars-static/master/datasets/legislators.csv\")\n\ndf = df.with_columns(\n    pl.col([\"first_name\", \"gender\", \"type\", \"state\", \"party\"]).cast(pl.Categorical)\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Query on Partial Dataset in Polars (Python)\nDESCRIPTION: This snippet demonstrates how to execute a query on a partial dataset in Polars for development or testing purposes. It uses .head() to limit the input and .collect() to execute the query.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/execution.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n(df.head(1_000_000)\n   .filter(pl.col(\"comment_karma\") > 100)\n   .select([\"id\", \"name\", \"created_utc\", \"updated_on\", \"comment_karma\", \"link_karma\"])\n   .collect()\n   .head(1))\n```\n\n----------------------------------------\n\nTITLE: Calculating Variance with VARIANCE in Polars SQL\nDESCRIPTION: Shows how to use the VARIANCE function to calculate the variance of columns in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"foo\": [10, 20, 8],\n        \"bar\": [10, 7, 18],\n    }\n)\ndf.sql(\"\"\"\n  SELECT VARIANCE(foo) AS foo_var, VARIANCE(bar) AS bar_var FROM self\n\"\"\")\n# shape: (1, 2)\n# ┌───────────┬───────────┐\n# │ foo_var   ┆ bar_var   │\n# │ ---       ┆ ---       │\n# │ f64       ┆ f64       │\n# ╞═══════════╪═══════════╡\n# │ 41.333333 ┆ 32.333333 │\n# └───────────┴───────────┘\n```\n\n----------------------------------------\n\nTITLE: Writing DataFrame to Cloud Storage\nDESCRIPTION: Example demonstrating how to write a DataFrame to AWS S3 storage in Parquet format.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf.write_parquet(\"s3://bucket/file.parquet\", storage_options=storage_options)\n```\n\n----------------------------------------\n\nTITLE: Reading Database with ADBC Engine - Python\nDESCRIPTION: Example showing how to read from a database using the ADBC engine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npl.read_database_uri(\"sqlite:///some.db\", \"SELECT * FROM foo\", engine=\"adbc\")\n```\n\n----------------------------------------\n\nTITLE: Creating New Table from Query in Polars SQL\nDESCRIPTION: Creates a new table by executing a SELECT query against an existing table. The new table inherits the column structure from the query result.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE new_table AS\nSELECT * FROM existing_table WHERE value > 42\n```\n\n----------------------------------------\n\nTITLE: Using SPLIT_PART Function in Polars SQL\nDESCRIPTION: Shows how to split strings by a delimiter and extract specific parts using SPLIT_PART. Both positive (1-indexed) and negative indexing for accessing parts are demonstrated.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"s\": [\"xx,yy,zz\", \"abc,,xyz,???,hmm\", None, \"\"]})\ndf.sql(\"\"\"\n  SELECT\n    s,\n    SPLIT_PART(s,',',1) AS \"s+1\",\n    SPLIT_PART(s,',',3) AS \"s+3\",\n    SPLIT_PART(s,',',-2) AS \"s-2\",\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Previewing Polars Query Plan with explain()\nDESCRIPTION: Shows how to use the explain() function to view the optimized query plan before execution, revealing optimizations like predicate and projection pushdown.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/lazy-api.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nexplain\n```\n\n----------------------------------------\n\nTITLE: Reading NDJSON File with Polars\nDESCRIPTION: Shows how to read a newline-delimited JSON (NDJSON) file into a Polars DataFrame using the read_ndjson function, which is more performant than standard JSON reading.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/json.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.read_ndjson(\"path/to/file.ndjson\")\n```\n\n----------------------------------------\n\nTITLE: Parallel Processing of Multiple Files\nDESCRIPTION: Demonstrates parallel file processing using scan_csv for efficient handling of multiple files.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/multiple.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/multiple.py:glob\"\n```\n\n----------------------------------------\n\nTITLE: Listing LazyFrame Manipulation and Selection Methods in Python\nDESCRIPTION: This code snippet provides an autosummary of LazyFrame methods for manipulation and selection in the Polars library. It includes methods for data filtering, transformation, joining, and various other operations on lazy dataframes.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/modify_select.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    LazyFrame.approx_n_unique\n    LazyFrame.bottom_k\n    LazyFrame.cast\n    LazyFrame.clear\n    LazyFrame.clone\n    LazyFrame.drop\n    LazyFrame.drop_nans\n    LazyFrame.drop_nulls\n    LazyFrame.explode\n    LazyFrame.fill_nan\n    LazyFrame.fill_null\n    LazyFrame.filter\n    LazyFrame.first\n    LazyFrame.gather_every\n    LazyFrame.group_by\n    LazyFrame.group_by_dynamic\n    LazyFrame.head\n    LazyFrame.inspect\n    LazyFrame.interpolate\n    LazyFrame.join\n    LazyFrame.join_asof\n    LazyFrame.join_where\n    LazyFrame.last\n    LazyFrame.limit\n    LazyFrame.melt\n    LazyFrame.merge_sorted\n    LazyFrame.remove\n    LazyFrame.rename\n    LazyFrame.reverse\n    LazyFrame.rolling\n    LazyFrame.select\n    LazyFrame.select_seq\n    LazyFrame.set_sorted\n    LazyFrame.shift\n    LazyFrame.slice\n    LazyFrame.sort\n    LazyFrame.sql\n    LazyFrame.tail\n    LazyFrame.top_k\n    LazyFrame.unique\n    LazyFrame.unnest\n    LazyFrame.unpivot\n    LazyFrame.update\n    LazyFrame.with_columns\n    LazyFrame.with_columns_seq\n    LazyFrame.with_context\n    LazyFrame.with_row_count\n    LazyFrame.with_row_index\n```\n\n----------------------------------------\n\nTITLE: Cartesian Product Join\nDESCRIPTION: Shows how to compute cartesian product between two dataframes using cross join strategy.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:cartesian-product\"\n```\n\n----------------------------------------\n\nTITLE: Combining Column Selection with Exclusion\nDESCRIPTION: Shows how to use `col` with `exclude` to select columns matching certain criteria while excluding others.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:col-exclude\"\n```\n\n----------------------------------------\n\nTITLE: Registering Pandas DataFrames with SQLContext\nDESCRIPTION: This example illustrates how to register a Pandas DataFrame with the SQLContext by first converting it to a Polars DataFrame. This allows users to use SQL queries on existing Pandas DataFrames. It converts a Pandas DataFrame to a Polars DataFrame before registering.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/intro.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing import assert_frame_equal\nimport pandas as pd\n\n\ndf = pd.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"foo\", \"bar\", \"baz\"]\n})\n\n\nctx = pl.SQLContext(data={\"my_table\": pl.from_pandas(df)})\n```\n\n----------------------------------------\n\nTITLE: Selecting nth Element from DataFrame Column in Python\nDESCRIPTION: Demonstrates how to select the nth element from a DataFrame column using pl.col().get() instead of the deprecated pl.nth() function with columns parameter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2], \"b\": [3, 4], \"c\": [5, 6]})\ndf.select(pl.col(\"a\").get(1))\n```\n\n----------------------------------------\n\nTITLE: Using as_expr to Resolve Selector Ambiguity in Polars\nDESCRIPTION: Demonstrates the correct use of 'as_expr' to resolve operator ambiguity when negating Boolean values in selected columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"has_partner\": [True, False, True],\n        \"has_kids\": [False, True, True],\n        \"has_tattoos\": [True, True, False],\n        \"age\": [25, 30, 35],\n    }\n)\n\nprint(df.select(~cs.starts_with(\"has_\").as_expr()))\n```\n\n----------------------------------------\n\nTITLE: Null Preservation in EWM Methods in Python\nDESCRIPTION: Demonstrates how EWM methods (ewm_mean, ewm_std, ewm_var) no longer forward-fill null values, requiring users to explicitly call .forward_fill() if needed.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1, 4, None, 3])\ns.ewm_mean(alpha=.9, ignore_nulls=False)\nshape: (4,)\nSeries: '' [f64]\n[\n        1.0\n        3.727273\n        3.727273\n        3.007913\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns.ewm_mean(alpha=.9, ignore_nulls=False)\nshape: (4,)\nSeries: '' [f64]\n[\n        1.0\n        3.727273\n        null\n        3.007913\n]\n```\n\n----------------------------------------\n\nTITLE: Unnesting a Struct Column in Polars\nDESCRIPTION: Shows how to use the unnest() function to transform a Struct column into multiple separate columns, with each field of the Struct becoming its own column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:struct_unnest\"\n```\n\n----------------------------------------\n\nTITLE: Efficient Expression Generation with List Comprehension\nDESCRIPTION: Demonstrates a better approach by generating all expressions programmatically before applying them in a single operation for better optimization.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:yield-expressions\"\n```\n\n----------------------------------------\n\nTITLE: Concatenating Strings in Polars SQL\nDESCRIPTION: Shows how to use the CONCAT function to combine multiple string columns into a single string. This example concatenates two columns without any separator.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"aa\", \"b\", \"c\", \"dd\"],\n    \"bar\": [\"zz\", \"yy\", \"xx\", \"ww\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT CONCAT(foo, bar) AS foobar FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌────────┐\n# │ foobar │\n# │ ---    │\n# │ str    │\n# ╞════════╡\n# │ aazz   │\n# │ byy    │\n# │ cxx    │\n# │ ddww   │\n# └────────┘\n```\n\n----------------------------------------\n\nTITLE: Creating Time Series DataFrame in Python using Polars\nDESCRIPTION: This snippet demonstrates how to create a DataFrame with time series data at 30-minute intervals using Polars' date_range function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/resampling.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"dt\": pl.date_range(\n            start=datetime(2022, 1, 1),\n            end=datetime(2022, 1, 2),\n            interval=\"30m\",\n            eager=True,\n        ),\n        \"val\": range(49),\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Using NumPy Functions with Polars DataFrames\nDESCRIPTION: Example demonstrating how to use NumPy's logarithm function with Polars expressions to perform fast columnar operations. This shows how NumPy functionality can be used when a specific function is not provided by Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/numpy-functions.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/numpy-example.py\"\n```\n\n----------------------------------------\n\nTITLE: Checking String Endings in Polars SQL\nDESCRIPTION: Demonstrates the ENDS_WITH function, which checks if a string ends with a specified substring. This example checks if strings end with the letter 'a'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"aa\", \"bb\", \"cc\", \"dd\"],\n    \"bar\": [\"zz\", \"yy\", \"xx\", \"ww\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT foo, ENDS_WITH(foo, 'a') AS ends_a FROM self\n\"\"\")\n# shape: (4, 2)\n# ┌─────┬────────┐\n# │ foo ┆ ends_a │\n# │ --- ┆ ---    │\n# │ str ┆ bool   │\n# ╞═════╪════════╡\n# │ aa  ┆ true   │\n# │ bb  ┆ false  │\n# │ cc  ┆ false  │\n# │ dd  ┆ false  │\n# └─────┴────────┘\n```\n\n----------------------------------------\n\nTITLE: Multiple Pattern Extraction\nDESCRIPTION: Shows how to extract all occurrences of a pattern within strings using extract_all function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:extract_all\"\n```\n\n----------------------------------------\n\nTITLE: Using COALESCE function in Polars SQL\nDESCRIPTION: Demonstrates the usage of COALESCE function to return the first non-null value in the provided columns. It creates a DataFrame with two columns and applies the COALESCE function using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [1, None, 3, None],\n    \"bar\": [1, 2, None, 4],\n  }\n)\ndf.sql(\"\"\"\n  SELECT foo, bar, COALESCE(foo, bar) AS baz FROM self\n\"\"\")\n# shape: (4, 3)\n# ┌──────┬──────┬─────┐\n# │ foo  ┆ bar  ┆ baz │\n# │ ---  ┆ ---  ┆ --- │\n# │ i64  ┆ i64  ┆ i64 │\n# ╞══════╪══════╪═════╡\n# │ 1    ┆ 1    ┆ 1   │\n# │ null ┆ 2    ┆ 2   │\n# │ 3    ┆ null ┆ 3   │\n# │ null ┆ 4    ┆ 4   │\n# └──────┴──────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Polars Cloud Python Client\nDESCRIPTION: This code snippet demonstrates how to authenticate with Polars Cloud using the Python client. The actual implementation is not provided in the text, but it's referenced as a code block to be inserted.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/explain/authentication.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('polars-cloud/authentication','login',['login'])}}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Array Operations with Polars arr Namespace\nDESCRIPTION: This snippet shows examples of using the arr namespace functions with Array data type in Polars. It demonstrates operations like min, max, and sum on array elements.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:array-overview\"\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with GPU Support\nDESCRIPTION: Commands to install Polars with GPU support using pip. Includes separate instructions for CUDA 11 systems.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/gpu-support.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install polars[gpu]\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install --extra-index-url=https://pypi.nvidia.com polars cudf-polars-cu11\n```\n\n----------------------------------------\n\nTITLE: Exporting Polars Series to Various Formats in Python\nDESCRIPTION: This code snippet demonstrates the available methods for exporting Polars Series data to different formats. It includes methods for converting to NumPy arrays, Arrow format, Pandas Series, PyTorch tensors, and more.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/export.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nSeries.__array__\nSeries.__arrow_c_stream__\nSeries.to_arrow\nSeries.to_frame\nSeries.to_init_repr\nSeries.to_jax\nSeries.to_list\nSeries.to_numpy\nSeries.to_pandas\nSeries.to_torch\n```\n\n----------------------------------------\n\nTITLE: Checking Array Contents with ARRAY_CONTAINS in Polars SQL\nDESCRIPTION: Shows how to use the ARRAY_CONTAINS function to check if an array contains a specific value.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[1, 2], [4, 3]]})\ndf.sql(\"\"\"\n  SELECT foo, ARRAY_CONTAINS(foo, 2) AS has_two FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌───────────┬─────────┐\n# │ foo       ┆ has_two │\n# │ ---       ┆ ---     │\n# │ list[i64] ┆ bool    │\n# ╞═══════════╪═════════╡\n# │ [1, 2]    ┆ true    │\n# │ [4, 3]    ┆ false   │\n# └───────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: GROUP BY Operation\nDESCRIPTION: Demonstrates how to use GROUP BY statement to aggregate data by specified columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:group_by\"\n```\n\n----------------------------------------\n\nTITLE: Sorting and Grouping in Polars for Oldest and Youngest Politicians\nDESCRIPTION: This snippet demonstrates sorting and grouping in Polars to find the oldest and youngest politicians per state. It sorts the data by age before grouping and aggregation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nout = (\n    df.with_columns(pl.struct([\"born_date\", \"died_date\"])\n                   .apply(lambda x: compute_age(x[\"born_date\"], x[\"died_date\"]))\n                   .alias(\"age\"))\n    .sort(\"age\")\n    .group_by(\"state\")\n    .agg(\n        pl.col(\"first_name\").first().alias(\"youngest\"),\n        pl.col(\"first_name\").last().alias(\"oldest\"),\n    )\n)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Transforming Data with Fire Risk Calculation\nDESCRIPTION: Performs data transformation to calculate fire risk based on temperature, humidity, and vegetation density, then filters and sorts the results.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n(\n    lf.with_columns(\n            (\n                (pl.col(\"temperature\") / 10)\n                * (1 - pl.col(\"humidity\") / 100)\n                * pl.col(\"vegetation_density\")\n            ).alias(\"fire_risk\"),\n    ).filter(pl.col(\"humidity\") < 70)\n    .sort(by=\"fire_risk\", descending=True)\n .collect()\n)\n```\n\n----------------------------------------\n\nTITLE: Passing kwargs to the Polars expression in Python\nDESCRIPTION: This Python code defines a function `append_args` that registers the `append_kwargs` Polars expression plugin with keyword arguments. It uses the `register_plugin_function` function and passes a dictionary containing the keyword arguments in the `kwargs` parameter. These kwargs get serialized on the Python side, and deserialized on the Rust side to the defined `MyKwargs` struct.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef append_args(\n    expr: IntoExpr,\n    float_arg: float,\n    integer_arg: int,\n    string_arg: str,\n    boolean_arg: bool,\n) -> pl.Expr:\n    \"\"\"\n    This example shows how arguments other than `Series` can be used.\n    \"\"\"\n    return register_plugin_function(\n        plugin_path=PLUGIN_PATH,\n        function_name=\"append_kwargs\",\n        args=expr,\n        kwargs={\n            \"float_arg\": float_arg,\n            \"integer_arg\": integer_arg,\n            \"string_arg\": string_arg,\n            \"boolean_arg\": boolean_arg,\n        },\n        is_elementwise=True,\n    )\n```\n\n----------------------------------------\n\nTITLE: Listing Polars Expression List Methods\nDESCRIPTION: This code snippet enumerates all available methods under the expr.list attribute in Polars. It includes operations for aggregation, manipulation, and analysis of list-type data within Polars expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/list.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nExpr.list.all\nExpr.list.any\nExpr.list.arg_max\nExpr.list.arg_min\nExpr.list.concat\nExpr.list.contains\nExpr.list.count_matches\nExpr.list.diff\nExpr.list.drop_nulls\nExpr.list.eval\nExpr.list.explode\nExpr.list.first\nExpr.list.gather\nExpr.list.gather_every\nExpr.list.get\nExpr.list.head\nExpr.list.join\nExpr.list.last\nExpr.list.len\nExpr.list.max\nExpr.list.mean\nExpr.list.median\nExpr.list.min\nExpr.list.n_unique\nExpr.list.reverse\nExpr.list.sample\nExpr.list.set_difference\nExpr.list.set_intersection\nExpr.list.set_symmetric_difference\nExpr.list.set_union\nExpr.list.shift\nExpr.list.slice\nExpr.list.sort\nExpr.list.std\nExpr.list.sum\nExpr.list.tail\nExpr.list.to_array\nExpr.list.to_struct\nExpr.list.unique\nExpr.list.var\n```\n\n----------------------------------------\n\nTITLE: Convert Polars DataFrame to pyarrow Table via PyCapsule\nDESCRIPTION: Demonstrates how to convert a Polars DataFrame to a pyarrow Table using the `pyarrow.table` constructor, leveraging the Arrow PyCapsule Interface. This zero-copy mechanism enables efficient data sharing between Polars and pyarrow (v15 or higher) without direct data copying.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport pyarrow as pa\n\ndf = pl.DataFrame({\n    \"foo\": [1, 2, 3],\n    \"bar\": [\"ham\", \"spam\", \"jam\"]\n})\n\npa_table = pa.table(df)\n```\n\n----------------------------------------\n\nTITLE: Boolean Type Casting Operations\nDESCRIPTION: Shows conversion between numeric types and booleans, demonstrating how different numeric values are interpreted as boolean values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [-1, 0, 1]})\ndf.with_columns([pl.col(\"a\").cast(pl.Boolean).alias(\"bool\")])\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Executing Polars Lazy Query with GPU Engine in Python\nDESCRIPTION: This snippet includes both the setup and execution of a Polars lazy query using GPU acceleration. It demonstrates the complete process from query setup to result collection using the GPU engine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/gpu.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/lazy/gpu.py:setup\"\n--8<-- \"python/user-guide/lazy/gpu.py:simple-result\"\n```\n\n----------------------------------------\n\nTITLE: Unnesting Arrays into Table Columns in Polars SQL\nDESCRIPTION: Converts multiple arrays into table columns, allowing specification of column names for the resulting table.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT * FROM\n  UNNEST(\n    [1, 2, 3, 4],\n    ['ww','xx','yy','zz'],\n    [23.0, 24.5, 28.0, 27.5]\n  ) AS tbl (x,y,z)\n```\n\n----------------------------------------\n\nTITLE: Alternative Arithmetic Function Syntax\nDESCRIPTION: Shows alternative syntax using named functions instead of operators for arithmetic operations in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:operator-overloading\"\n```\n\n----------------------------------------\n\nTITLE: Executing Query on Full Dataset in Polars (Python)\nDESCRIPTION: This snippet demonstrates how to execute a query on the full dataset using the .collect() method in Polars. It filters rows where the 'comment_karma' is greater than 100 and selects specific columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/execution.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n(df.filter(pl.col(\"comment_karma\") > 100)\n   .select([\"id\", \"name\", \"created_utc\", \"updated_on\", \"comment_karma\", \"link_karma\"])\n   .collect())\n```\n\n----------------------------------------\n\nTITLE: Time Zone Conversion in Series Constructor in Python\nDESCRIPTION: Illustrates the update to time zone handling in Series constructor, which now consistently converts datetime values to the specified time zone rather than just replacing the time zone information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Before:\nfrom datetime import datetime\npl.Series([datetime(2020, 1, 1)], dtype=pl.Datetime('us', 'Europe/Amsterdam'))\nshape: (1,)\nSeries: '' [datetime[μs, Europe/Amsterdam]]\n[\n        2020-01-01 00:00:00 CET\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\nfrom datetime import datetime\npl.Series([datetime(2020, 1, 1)], dtype=pl.Datetime('us', 'Europe/Amsterdam'))\nshape: (1,)\nSeries: '' [datetime[μs, Europe/Amsterdam]]\n[\n        2020-01-01 01:00:00 CET\n]\n```\n\n----------------------------------------\n\nTITLE: Using GREATEST function in Polars SQL\nDESCRIPTION: Shows how to use the GREATEST function to return the greatest value from a list of expressions. It creates a DataFrame with two columns and applies the GREATEST function using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [100, 200, 300, 400],\n    \"bar\": [20, 10, 30, 40]\n  }\n)\ndf.sql(\"\"\"\n  SELECT GREATEST(foo, bar) AS baz FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌─────┐\n# │ baz │\n# │ --- │\n# │ i64 │\n# ╞═════╡\n# │ 100 │\n# │ 200 │\n# │ 300 │\n# │ 400 │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Casting String Columns to Dates in Polars\nDESCRIPTION: Shows how to convert string columns containing datetime information to proper datetime types using str.to_date method with format specification.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/parsing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/time-series/parsing.py:cast\"\n```\n\n----------------------------------------\n\nTITLE: Using FROM Clause in Polars SQL\nDESCRIPTION: Demonstrates the basic usage of FROM clause to specify the source DataFrame\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"a\": [1, 2, 3],\n    \"b\": [\"zz\", \"yy\", \"xx\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT * FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Capitalizing Words in Polars SQL\nDESCRIPTION: Shows the usage of the INITCAP function, which capitalizes the first letter of each word in a string. This is useful for standardizing text formatting.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [\"hello world\", \"HELLO\", \"wOrLd\"]})\ndf.sql(\"\"\"\n  SELECT bar, INITCAP(bar) AS baz FROM self\n\"\"\")\n# shape: (3, 2)\n# ┌─────────────┬─────────────┐\n# │ bar         ┆ baz         │\n# │ ---         ┆ ---         │\n# │ str         ┆ str         │\n# ╞═════════════╪═════════════╡\n# │ hello world ┆ Hello World │\n# │ HELLO       ┆ Hello       │\n# │ wOrLd       ┆ World       │\n# └─────────────┴─────────────┘\n```\n\n----------------------------------------\n\nTITLE: Reading CSV Files with Polars\nDESCRIPTION: Demonstrates how to read CSV files using Polars' read_csv function. This operation loads the entire CSV file into memory as a DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/csv.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/csv','read',['read_csv'])}}\n```\n\n----------------------------------------\n\nTITLE: Creating a DataFrame with Movie Ratings Data in Python\nDESCRIPTION: Creates a sample DataFrame containing movie ratings data across different states, with columns for State, Movie, Theatre, Count, and Avg_Rating to demonstrate Struct operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:ratings_df\"\n```\n\n----------------------------------------\n\nTITLE: Filtering Date Ranges in Polars DataFrame\nDESCRIPTION: Shows how to filter a DataFrame for a date range using the is_between method. Defines start and end dates for the range filter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/filter.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.filter(\n    pl.col(\"Date\").is_between(\n        datetime(2022, 1, 3),\n        datetime(2022, 1, 7)\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Convert pyarrow Table to Polars DataFrame\nDESCRIPTION: Demonstrates converting a pyarrow Table back to a Polars DataFrame using the `polars.DataFrame` constructor. This allows importing Arrow-formatted data into Polars for further processing and analysis. This leverages the Arrow PyCapsule interface for potential zero-copy transfer.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport pyarrow as pa\n\npa_table = pa.table({\n    \"foo\": [1, 2, 3],\n    \"bar\": [\"ham\", \"spam\", \"jam\"]\n})\n\ndf = pl.DataFrame(pa_table)\n```\n\n----------------------------------------\n\nTITLE: LazyFrame Methods - Miscellaneous Operations\nDESCRIPTION: Core utility methods for LazyFrame including caching, collection, async operations, schema management, lazy evaluation, batch processing, piping, profiling and remote operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/miscellaneous.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nLazyFrame.cache\nLazyFrame.collect\nLazyFrame.collect_async\nLazyFrame.collect_schema\nLazyFrame.lazy\nLazyFrame.map_batches\nLazyFrame.pipe\nLazyFrame.profile\nLazyFrame.remote\n```\n\n----------------------------------------\n\nTITLE: Counting Elements with COUNT in Polars SQL\nDESCRIPTION: Shows how to use the COUNT function to count elements and unique values in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"b\", \"a\", \"b\", \"c\"],\n    \"bar\": [20, 10, 30, 40]\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    COUNT(bar) AS n_bar,\n    COUNT(DISTINCT foo) AS n_foo_unique\n  FROM self\n\"\"\")\n\n# shape: (1, 2)\n# ┌───────┬──────────────┐\n# │ n_bar ┆ n_foo_unique │\n# │ ---   ┆ ---          │\n# │ u32   ┆ u32          │\n# ╞═══════╪══════════════╡\n# │ 4     ┆ 3            │\n# └───────┴──────────────┘\n```\n\n----------------------------------------\n\nTITLE: Handling Mixed Time Zone Offsets in Polars\nDESCRIPTION: Shows how to handle mixed time offsets by using UTC and converting to specific time zones, useful for dealing with daylight saving time.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/parsing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/time-series/parsing.py:mixed\"\n```\n\n----------------------------------------\n\nTITLE: Using HAVING Clause in Polars SQL\nDESCRIPTION: Demonstrates filtering grouped data using the HAVING clause\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n      {\n      \"foo\": [\"a\", \"b\", \"b\", \"c\"],\n      \"bar\": [10, 20, 30, 40],\n    }\n  )\ndf.sql(\"\"\"\n  SELECT foo, SUM(bar) FROM self GROUP BY foo HAVING bar >= 40\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Using DATE_PART Function in Polars SQL\nDESCRIPTION: Demonstrates how to extract year, month, and day components from date values using the DATE_PART function. Creates a DataFrame with date values and uses SQL to extract specific temporal parts.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/temporal.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n      \"dt\": [\n          date(1969, 12, 31),\n          date(2026, 8, 22),\n          date(2077, 2, 10),\n      ]\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    dt,\n    DATE_PART('year', dt) AS year,\n    DATE_PART('month', dt) AS month,\n    DATE_PART('day', dt) AS day\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: NumPy Integration for Fast Operations\nDESCRIPTION: Demonstrates using NumPy's optimized ufuncs with Polars for better performance.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:np_log\"\n```\n\n----------------------------------------\n\nTITLE: Aggregation after group_by context\nDESCRIPTION: This snippet shows how to perform aggregations on grouped data after using the `group_by` context with the `agg` method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:group_by-agg\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating UNION Operation in Polars SQL\nDESCRIPTION: This snippet shows how to use the UNION operation to combine the distinct result sets of two SELECT statements. The final result set has no duplicate rows. It uses Polars LazyFrames and the SQL interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/set_operations.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npl.sql(\"\"\"\n    SELECT id, name FROM lf1\n    UNION\n    SELECT id, name FROM lf2\n\"\"\").sort(by=\"id\").collect()\n# shape: (4, 2)\n# ┌─────┬─────────┐\n# │ id  ┆ name    │\n# │ --- ┆ ---     │\n# │ i64 ┆ str     │\n# ╞═════╪═════════╡\n# │ 1   ┆ Alice   │\n# │ 2   ┆ Bob     │\n# │ 3   ┆ Charlie │\n# │ 4   ┆ David   │\n# └─────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Comparison Operations in Polars\nDESCRIPTION: Demonstrates comparison operations using both overloaded operators and named functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:comparison\"\n```\n\n----------------------------------------\n\nTITLE: Using ORDER BY Clause in Polars SQL\nDESCRIPTION: Shows how to sort query results using ORDER BY clause with sort direction\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"b\", \"a\", \"c\", \"b\"],\n    \"bar\": [20, 10, 40, 30],\n  }\n)\ndf.sql(\"\"\"\n  SELECT foo, bar FROM self ORDER BY bar DESC\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Multiplexing Sinks - Polars - Python\nDESCRIPTION: This code snippet demonstrates how to multiplex sinks in Polars, writing data to multiple destinations (Parquet and IPC) in a single query. It defines two sink operations, `q1` and `q2`, and then uses `lf.collect_all([q1, q2])` to execute both sink operations concurrently.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/sources_sinks.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Some expensive computation\nlf: LazyFrame \n\nq1 = lf.sink_parquet(.., lazy=True)\nq2 = lf.sink_ipc(.., lazy=True)\n\nlf.collect_all([q1, q2])\n```\n\n----------------------------------------\n\nTITLE: Equivalent operation in Spark using separate computations (Python)\nDESCRIPTION: Shows how to achieve a similar result in Spark by computing the sum separately and then adding it as a literal to the main query. This demonstrates the additional steps required in Spark for operations that are more straightforward in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pyspark.sql.functions import col, sum, lit\n\nbar_sum = (\n    dfs\n    .where(col(\"foo\") == \"d\")\n    .groupBy()\n    .agg(sum(col(\"bar\")))\n    .take(1)[0][0]\n)\n\n(\n    dfs\n    .orderBy(\"foo\")\n    .limit(2)\n    .withColumn(\"bar\", lit(bar_sum))\n    .show()\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning NDJSON Data from Hugging Face with Polars\nDESCRIPTION: Shows how to scan NDJSON (JSON Lines) formatted data from a Hugging Face repository using the scan_ndjson function. Accesses the iris dataset in JSONL format.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hugging-face.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.scan_ndjson(\"hf://datasets/nameexhaustion/polars-docs/iris.jsonl\")\n```\n\n----------------------------------------\n\nTITLE: Highlighting Maximum Row in Styled Polars DataFrame\nDESCRIPTION: Shows how to highlight the row with the maximum value in a specific column of a styled Polars DataFrame using Great Tables. This technique emphasizes important data points.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n(\n    gt.tab_header(title=\"Iris Dataset\")\n    .tab_stub(col=\"species\")\n    .fmt_number(columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], decimals=1)\n    .highlight_max(column=\"sepal_length\", color=\"yellow\")\n)\n```\n\n----------------------------------------\n\nTITLE: Base-10 Logarithm Function (LOG10) in Polars SQL\nDESCRIPTION: Shows LOG10 function usage for calculating common logarithms.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, LOG10(a) AS log10_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Eager API in Polars\nDESCRIPTION: An example showing the eager API approach to read the iris dataset, filter by sepal length, and calculate the mean sepal width per species. Each operation is executed immediately.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/lazy-api.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nread_csv\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules\nDESCRIPTION: This code snippet imports necessary modules for creating an IO plugin for Polars. It includes the `csv` module for parsing CSV data, `polars` as `pl` for DataFrame manipulation, `register_io_source` for registering the IO source, `Iterator` for type hinting of the generator, and `io` to work with in-memory text streams.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/io_plugins.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Use python for csv parsing.\nimport csv\nimport polars as pl\n# Used to register a new generator on every instantiation.\nfrom polars.io.plugins import register_io_source\nfrom typing import Iterator\nimport io\n```\n\n----------------------------------------\n\nTITLE: Further Data Processing and Storage\nDESCRIPTION: Demonstrates additional filtering of results and storing the final output to S3 in an interactive workflow.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nres2 = (\n    result\n    .filter(pl.col(\"fire_risk\") > 1)\n    .sink_parquet(\"s3://bucket/output-interactive.parquet\")\n)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Changed Join Behavior for Null Values in Polars 0.20\nDESCRIPTION: Shows how the default behavior of join operations has changed to ignore null values in join keys. The previous behavior treated nulls as matchable values, while the new default behavior ignores them. The old behavior can be restored using the nulls_equal=True parameter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ndf1 = pl.DataFrame({\"a\": [1, 2, None], \"b\": [4, 4, 4]})\ndf2 = pl.DataFrame({\"a\": [None, 2, 3], \"c\": [5, 5, 5]})\ndf1.join(df2, on=\"a\", how=\"inner\")\n# Result includes null match\n\n# After:\ndf1.join(df2, on=\"a\", how=\"inner\")\n# Result excludes null match\ndf1.join(df2, on=\"a\", how=\"inner\", nulls_equal=True)  # Keeps previous behavior\n```\n\n----------------------------------------\n\nTITLE: Computing String Lengths in Polars\nDESCRIPTION: Demonstrates how to compute string lengths in terms of bytes and characters using Polars str namespace functions len_bytes and len_chars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Defining a custom Polars expression in Rust\nDESCRIPTION: This Rust code defines a custom Polars expression `pig_latinnify` that converts a string to pig latin. It utilizes the `polars_expr` macro to register the function with Polars. The function accepts a slice of `Series` as input, extracts the string data, and applies the `pig_latin_str` helper function to each string.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n// src/expressions.rs\nuse polars::prelude::*;\nuse pyo3_polars::derive::polars_expr;\nuse std::fmt::Write;\n\nfn pig_latin_str(value: &str, output: &mut String) {\n    if let Some(first_char) = value.chars().next() {\n        write!(output, \"{}{{}}ay\", &value[1..], first_char).unwrap()\n    }\n}\n\n#[polars_expr(output_type=String)]\nfn pig_latinnify(inputs: &[Series]) -> PolarsResult<Series> {\n    let ca = inputs[0].str()?;\n    let out: StringChunked = ca.apply_into_string_amortized(pig_latin_str);\n    Ok(out.into_series())\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting Decimal Places in Styled Polars DataFrame\nDESCRIPTION: Demonstrates how to format decimal places for numeric columns in a styled Polars DataFrame using Great Tables. This enhances the presentation of numerical data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n(\n    gt.tab_header(title=\"Iris Dataset\")\n    .tab_stub(col=\"species\")\n    .fmt_number(columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], decimals=1)\n)\n```\n\n----------------------------------------\n\nTITLE: Calculating Median with MEDIAN in Polars SQL\nDESCRIPTION: Shows how to use the MEDIAN function to find the median value in a column of a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [20, 10, 30, 40]})\ndf.sql(\"\"\"\n  SELECT MEDIAN(bar) AS bar_median FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌────────────┐\n# │ bar_median │\n# │ ---        │\n# │ f64        │\n# ╞════════════╡\n# │ 25.0       │\n# └────────────┘\n```\n\n----------------------------------------\n\nTITLE: Writing to Database with SQLAlchemy - Python\nDESCRIPTION: Example showing how to write a DataFrame to a database table named 'records' using SQLAlchemy.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf.write_database(\"records\", connection=engine)\n```\n\n----------------------------------------\n\nTITLE: Parsing Dates from CSV in Polars\nDESCRIPTION: Demonstrates loading dates from a CSV file using try_parse_dates flag for automatic date parsing during schema inference.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/parsing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/time-series/parsing.py:setup\"\n--8<-- \"python/user-guide/transformations/time-series/parsing.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Polars Shuffle/Sample - Random Seed (After)\nDESCRIPTION: Illustrates the new method of setting the random seed for Polars expressions using the `pl.set_random_seed` function. This is the correct way to control randomness in Polars expressions after the change.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\npl.set_random_seed(1)\n```\n\n----------------------------------------\n\nTITLE: Concatenating Strings with Separator in Polars SQL\nDESCRIPTION: Demonstrates the CONCAT_WS function, which concatenates multiple string columns with a specified separator. This example uses a colon as the separator between two columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"aa\", \"b\", \"c\", \"dd\"],\n    \"bar\": [\"zz\", \"yy\", \"xx\", \"ww\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT CONCAT_WS(':', foo, bar) AS foobar FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌────────┐\n# │ foobar │\n# │ ---    │\n# │ str    │\n# ╞════════╡\n# │ aa:zz  │\n# │ b:yy   │\n# │ c:xx   │\n# │ dd:ww  │\n# └────────┘\n```\n\n----------------------------------------\n\nTITLE: Exponential Function (EXP) in Polars SQL\nDESCRIPTION: Demonstrates EXP function for calculating e raised to the power of input values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, EXP(a) AS exp_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Polars Cloud CLI\nDESCRIPTION: This command uses the Polars Cloud command line interface to initiate the login process. It will redirect the user to a browser for credential input.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/explain/authentication.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npc login\n```\n\n----------------------------------------\n\nTITLE: Computing Sine in Radians using SIN\nDESCRIPTION: Demonstrates SIN function to compute sine in radians for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport math\n\ndf = pl.DataFrame({\"rads\": [0.0, 1/4 * math.pi, 1/2 * math.pi, 3/4 * math.pi]})\ndf.sql(\"SELECT rads, SIN(rads) AS sin FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Calculating String Byte Length in Polars SQL\nDESCRIPTION: Shows how to use the OCTET_LENGTH function to calculate the length of strings in bytes. This is particularly useful when dealing with multi-byte character encodings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"iso_lang\":[\"de\", \"ru\", \"es\"],\n    \"color\": [\"weiß\", \"синий\", \"amarillo\"],\n\n```\n\n----------------------------------------\n\nTITLE: Dynamic Column Name Replacement\nDESCRIPTION: Shows how to dynamically rename columns using a function that transforms old names into new ones with the `name.map` function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:name-map\"\n```\n\n----------------------------------------\n\nTITLE: Using custom namespace to call the expression\nDESCRIPTION: This snippet shows how to call the custom expression using a custom namespace registered with Polars, providing a more natural syntax.  The namespace allows calling the function as a method on a Polars column expression, enhancing readability.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nout = df.with_columns(\n    pig_latin=pl.col(\"convert\").language.pig_latinnify(),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Rust Cloud Storage Dependencies\nDESCRIPTION: Command to install required Rust crates for AWS S3 integration including aws_sdk_s3, aws_config, and tokio.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ cargo add aws_sdk_s3 aws_config tokio --features tokio/full\n```\n\n----------------------------------------\n\nTITLE: Creating Array Examples in Polars\nDESCRIPTION: This snippet shows how to create columns with the Array data type in Polars. The example demonstrates specifying Arrays with fixed shapes for bit flags and tic-tac-toe data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:array-example\"\n```\n\n----------------------------------------\n\nTITLE: Initializing DataFrames in Polars and Spark (Python)\nDESCRIPTION: Creates sample DataFrames in both Polars and Spark for comparison. The DataFrames contain 'foo' and 'bar' columns with string and integer data respectively.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"foo\": [\"a\", \"b\", \"c\", \"d\", \"d\"],\n    \"bar\": [1, 2, 3, 4, 5],\n})\n\ndfs = spark.createDataFrame(\n    [\n        (\"a\", 1),\n        (\"b\", 2),\n        (\"c\", 3),\n        (\"d\", 4),\n        (\"d\", 5),\n    ],\n    schema=[\"foo\", \"bar\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Creating DataFrame from Dictionary\nDESCRIPTION: Illustrates how to create a 2-dimensional DataFrame structure from a dictionary of lists, where each list becomes a column in the DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3, 4, 5],\n        \"b\": [6, 7, 8, 9, 10],\n        \"c\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n    }\n)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Filtered Aggregation in Polars using group_by\nDESCRIPTION: This code snippet shows how to perform filtered aggregation in Polars. It defines custom functions for age calculation and filtering, then uses them in a group_by operation to compute average ages.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef compute_age(born, died):\n    return (\n        pl.when(pl.col(died).is_null())\n        .then(2023 - pl.col(born).dt.year())\n        .otherwise(pl.col(died).dt.year() - pl.col(born).dt.year())\n    )\n\ndef filter_age(age):\n    return pl.col(age).filter((pl.col(age) > 0) & (pl.col(age) < 100))\n\nout = df.group_by(\"state\").agg(\n    pl.len().alias(\"count\"),\n    filter_age(compute_age(\"born_date\", \"died_date\")).mean().alias(\"avg_age\"),\n).sort(\"count\", descending=True)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Natural Logarithm Function (LN) in Polars SQL\nDESCRIPTION: Demonstrates natural logarithm calculation using LN function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, LN(a) AS ln_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Listing Comparison Operators for Polars Series in Python\nDESCRIPTION: This code snippet lists the comparison operators available as methods on the Polars Series class. These methods provide functionality for equality, greater than/less than comparisons, and handling missing values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/operators.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nSeries.eq\nSeries.eq_missing\nSeries.ge\nSeries.gt\nSeries.le\nSeries.lt\nSeries.ne\nSeries.ne_missing\n```\n\n----------------------------------------\n\nTITLE: Scanning Specific Files in Hive Directory using Glob Pattern in Polars with Python\nDESCRIPTION: This code shows how to use a glob pattern with scan_parquet to load specific files from a directory with mixed file types, explicitly enabling hive partitioning.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:scan_glob\"\n```\n\n----------------------------------------\n\nTITLE: Computing Two-argument Inverse Tangent in Radians using ATAN2\nDESCRIPTION: Demonstrates ATAN2 function to compute inverse tangent of two columns in radians.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"a\": [-2.0, -1.0, 1.0, 2.0],\n        \"b\": [1.5, 1.0, 0.5, 0.0],\n    }\n)\ndf.sql(\"SELECT a, b, ATAN2(a, b) AS atan2_ab FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Identifying Duplicate Rows Using Struct Columns in Polars\nDESCRIPTION: Shows how to use Struct columns with is_duplicated() to identify duplicate records based on multiple columns (Movie and Theatre) simultaneously.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:struct_duplicates\"\n```\n\n----------------------------------------\n\nTITLE: Combining Group By Operations in Python using Polars\nDESCRIPTION: This example shows how to combine dynamic group by operations with normal group by operations. It creates a DataFrame with multiple groups and performs a dynamic grouping on a date column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/rolling.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"date\": [\n            \"2020-01-01 13:45:48\",\n            \"2020-01-01 16:42:13\",\n            \"2020-01-01 16:45:09\",\n            \"2020-01-02 18:12:48\",\n            \"2020-01-03 19:45:32\",\n            \"2020-01-08 23:16:43\",\n        ],\n        \"groups\": [\"A\", \"A\", \"A\", \"B\", \"C\", \"C\"],\n        \"values\": [1, 2, 3, 4, 5, 6],\n    }\n)\ndf = df.with_columns(pl.col(\"date\").str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\"))\nprint(df)\n\nout = df.group_by([\"groups\"]).group_by_dynamic(\n    \"date\",\n    every=\"2d\",\n    period=\"2d\",\n    closed=\"right\",\n).agg(\n    [\n        pl.col(\"values\").sum().alias(\"values_sum\"),\n        pl.col(\"values\").count().alias(\"values_count\"),\n    ]\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Using STRFTIME Function in Polars SQL\nDESCRIPTION: Illustrates formatting datetime and time values as strings using the STRFTIME function with chrono-compatible format strings. Creates a DataFrame with date and time values and formats them using specific patterns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/temporal.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"dt\": [date(1978, 7, 5), None, date(2020, 4, 10)],\n    \"tm\": [time(10, 10, 10), time(22, 33, 55), None],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    STRFTIME(dt, '%B %d, %Y') AS s_dt,\n    STRFTIME(tm, '%H.%M.%S') AS s_tm,\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Asof Join with Tolerance\nDESCRIPTION: Demonstrates asof join with time tolerance to limit matches to within specific time range.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:asof-tolerance\"\n```\n\n----------------------------------------\n\nTITLE: Available Polars String Methods Reference\nDESCRIPTION: Complete listing of string manipulation methods available under Series.str attribute in Polars. Includes methods for text operations, pattern matching, case conversion, and type conversion.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/string.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSeries.str.concat\nSeries.str.contains\nSeries.str.contains_any\nSeries.str.count_matches\nSeries.str.decode\nSeries.str.encode\nSeries.str.ends_with\nSeries.str.escape_regex\nSeries.str.explode\nSeries.str.extract\nSeries.str.extract_all\nSeries.str.extract_groups\nSeries.str.extract_many\nSeries.str.find\nSeries.str.find_many\nSeries.str.head\nSeries.str.join\nSeries.str.json_decode\nSeries.str.json_path_match\nSeries.str.len_bytes\nSeries.str.len_chars\nSeries.str.normalize\nSeries.str.pad_end\nSeries.str.pad_start\nSeries.str.replace\nSeries.str.replace_all\nSeries.str.replace_many\nSeries.str.reverse\nSeries.str.slice\nSeries.str.split\nSeries.str.split_exact\nSeries.str.splitn\nSeries.str.starts_with\nSeries.str.strip_chars\nSeries.str.strip_chars_start\nSeries.str.strip_chars_end\nSeries.str.strip_prefix\nSeries.str.strip_suffix\nSeries.str.strptime\nSeries.str.tail\nSeries.str.to_date\nSeries.str.to_datetime\nSeries.str.to_decimal\nSeries.str.to_integer\nSeries.str.to_lowercase\nSeries.str.to_time\nSeries.str.to_titlecase\nSeries.str.to_uppercase\nSeries.str.zfill\n```\n\n----------------------------------------\n\nTITLE: Creating Modified Property Groups DataFrame in Python\nDESCRIPTION: This snippet shows how to create a modified version of the property groups DataFrame with a different column name and lowercase property names.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprops_groups2 = pl.DataFrame(\n    {\n        \"property_name\": [\"Mediterranean Avenue\", \"Baltic Avenue\", \"Reading Railroad\", \"Oriental Avenue\", \"The Shire\"],\n        \"group\": [\"Brown\", \"Brown\", \"Railroad\", \"Light Blue\", \"Magical Land\"],\n    }\n).with_columns(pl.col(\"property_name\").str.to_lowercase().alias(\"property_name\"))\n```\n\n----------------------------------------\n\nTITLE: Parquet Reading with Hive Partitioning in Python\nDESCRIPTION: Demonstrates the updated behavior of read_parquet and scan_parquet functions, where Hive partitioning is now disabled by default for file inputs but enabled for directory inputs.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Before:\npl.read_parquet(\"dataset/a=1/foo.parquet\")\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ x   │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 1.0 │\n│ 1   ┆ 2.0 │\n└─────┴─────┘\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\npl.read_parquet(\"dataset/a=1/foo.parquet\")\nshape: (2, 1)\n┌─────┐\n│ x   │\n│ --- │\n│ f64 │\n╞═════╡\n│ 1.0 │\n│ 2.0 │\n└─────┘\npl.read_parquet(\"dataset/a=1/foo.parquet\", hive_partitioning=True)\nshape: (2, 2)\n┌─────┬─────┐\n│ a   ┆ x   │\n│ --- ┆ --- │\n│ i64 ┆ f64 │\n╞═════╪═════╡\n│ 1   ┆ 1.0 │\n│ 1   ┆ 2.0 │\n└─────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Combining two head operations in Polars (Python)\nDESCRIPTION: Illustrates how Polars can combine two different head expressions on the same DataFrame, provided they return the same number of values. This showcases Polars' ability to perform independent column operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf.select(\n    pl.col(\"foo\").sort().head(2),\n    pl.col(\"bar\").sort(descending=True).head(2),\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up LazyFrame Schema Example\nDESCRIPTION: Demonstrates how to view the schema of a LazyFrame using the collect_schema method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/schemas.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/lazy/schema.py:setup\"\n--8<-- \"python/user-guide/lazy/schema.py:schema\"\n```\n\n----------------------------------------\n\nTITLE: Using LEAST function in Polars SQL\nDESCRIPTION: Demonstrates the usage of LEAST function to return the smallest value from a list of expressions. It creates a DataFrame with two columns and applies the LEAST function using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [100, 200, 300, 400],\n    \"bar\": [20, 10, 30, 40]\n  }\n)\ndf.sql(\"\"\"\n  SELECT LEAST(foo, bar) AS baz FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌─────┐\n# │ baz │\n# │ --- │\n# │ i64 │\n# ╞═════╡\n# │ 20  │\n# │ 10  │\n# │ 30  │\n# │ 40  │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Window Functions\nDESCRIPTION: This snippet shows how to import the 'over' and 'rolling' window functions from the Polars library. These functions are used for performing operations on sliding windows of data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/window.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom polars import Expr\n\nExpr.over\nExpr.rolling\n```\n\n----------------------------------------\n\nTITLE: Accessing DataFrame Properties in Polars Python\nDESCRIPTION: Core attributes for accessing DataFrame metadata and structure in Polars. These attributes provide read-only access to DataFrame properties like column names (columns), data types (dtypes), flags, dimensions (height, width, shape) and schema information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/attributes.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nDataFrame.columns   # List of column names\nDataFrame.dtypes    # Data types of columns\nDataFrame.flags     # DataFrame flags\nDataFrame.height    # Number of rows\nDataFrame.schema    # DataFrame schema\nDataFrame.shape     # (height, width) tuple\nDataFrame.width     # Number of columns\n```\n\n----------------------------------------\n\nTITLE: SQL Functions Usage\nDESCRIPTION: Demonstrates the usage of built-in SQL functions including mathematical, string, and aggregation functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:functions\"\n```\n\n----------------------------------------\n\nTITLE: Bitwise Operations in Polars\nDESCRIPTION: Demonstrates bitwise operations including AND, OR, NOT, and XOR operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/basic-operations.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/operations.py:bitwise\"\n```\n\n----------------------------------------\n\nTITLE: Installing ADBC SQLite Driver - Shell\nDESCRIPTION: Command to install the ADBC driver for SQLite database.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install adbc-driver-sqlite\n```\n\n----------------------------------------\n\nTITLE: Displaying Paths of Written Hive Partitioned Parquet Dataset in Python\nDESCRIPTION: This snippet shows the resulting file paths after writing a hive partitioned parquet dataset, demonstrating the directory structure created by the partitioning.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:write_parquet_partitioned_show_paths\"\n```\n\n----------------------------------------\n\nTITLE: Horizontal Concatenation of DataFrames in Polars\nDESCRIPTION: Shows horizontal concatenation of DataFrames with non-overlapping columns to create a wider DataFrame. This operation combines all columns from multiple DataFrames side by side.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/concatenation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/concatenation.py:horizontal\"\n```\n\n----------------------------------------\n\nTITLE: Pattern Replacement in Strings\nDESCRIPTION: Examples of using replace and replace_all functions for single and multiple pattern replacements in strings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:replace\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating DataType.is_nested Change from Property to Method in Polars 0.20\nDESCRIPTION: Shows how the is_nested property has been changed to a method, requiring code updates to call it properly. Failure to update this can result in incorrect logic since the method itself evaluates to True in conditionals.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Before:\npl.List(pl.Int8).is_nested  # True\n\n# After:\npl.List(pl.Int8).is_nested()  # True\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Polars DataFrame Example\nDESCRIPTION: Creates a sample DataFrame with id, score, and year columns to demonstrate proper Polars syntax for data manipulation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/polars_llms.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\n    \"id\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n    \"score\": [1, 2, 1, 3, 3],\n    \"year\": [2020, 2020, 2021, 2021, 2021],\n})\n# Compute average of score by id\n```\n\n----------------------------------------\n\nTITLE: Polars DataFrame Group By Example\nDESCRIPTION: Demonstrates the correct syntax for grouping and aggregation operations in Polars, showing both the DataFrame creation and the group_by operation with mean aggregation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/polars_llms.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\n    \"id\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n    \"score\": [1, 2, 1, 3, 3],\n    \"year\": [2020, 2020, 2021, 2021, 2021],\n})\n# Compute average of score by id\n# Examples of Polars code:\n\n# df.group_by(\"a\").agg(pl.col(\"b\").mean())\n```\n\n----------------------------------------\n\nTITLE: Using RIGHT Function in Polars SQL\nDESCRIPTION: Shows how to extract the rightmost n characters from strings using the RIGHT function. This is useful for getting suffixes or endings of text.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"ab\", \"cde\", \"fghi\", \"jklmn\"]})\ndf.sql(\"\"\"\n  SELECT foo, RIGHT(foo, 2) AS bar FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Creating ComputeContext for Polars Cloud\nDESCRIPTION: Code to define the hardware specifications for the compute cluster in Polars Cloud, specifying memory, CPUs, and cluster size.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/quickstart.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nctx = pc.ComputeContext(memory=8, cpus=2 , cluster_size=1)\n```\n\n----------------------------------------\n\nTITLE: Listing Available Tables in Polars SQL\nDESCRIPTION: Displays all tables currently registered in the given context.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES\n```\n\n----------------------------------------\n\nTITLE: Using REVERSE Function in Polars SQL\nDESCRIPTION: Demonstrates using the REVERSE function to flip the character order of strings, creating mirror images of the original text.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"apple\", \"banana\", \"orange\", \"grape\"]})\ndf.sql(\"\"\"\n  SELECT foo, REVERSE(foo) AS oof FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Parsing CSV Schema\nDESCRIPTION: This function `parse_schema` takes a CSV string as input and returns a Polars schema. It splits the string by newline characters, extracts the first line as the header, and creates a schema where all columns are of type `pl.String`. This schema is required by Polars to understand the structure of the data being read.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/io_plugins.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef parse_schema(csv_str: str) -> pl.Schema:\n    first_line = csv_str.split(\"\\n\")[0]\n\n    return pl.Schema({k: pl.String for k in first_line.split(\",\")})\n```\n\n----------------------------------------\n\nTITLE: Concatenating DataFrames\nDESCRIPTION: This snippet shows how to vertically concatenate two Polars DataFrames to create a taller DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:concat\"\n```\n\n----------------------------------------\n\nTITLE: Using STRING_TO_ARRAY Function in Polars SQL\nDESCRIPTION: Shows how to split strings by a delimiter and convert them into arrays of strings using the STRING_TO_ARRAY function. This converts a delimited string into a structured list.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"aa,bb,cc\", \"x,y\"]})\ndf.sql(\"\"\"\n  SELECT foo, STRING_TO_ARRAY(foo, ',') AS arr FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Full Join with Column Coalescing\nDESCRIPTION: Shows full join with coalesce parameter to combine matching columns into a single column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:full-join-coalesce\"\n```\n\n----------------------------------------\n\nTITLE: Temporal Data Type Casting\nDESCRIPTION: Demonstrates casting between numerical types and temporal data types, showing how temporal values are stored internally.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndates = pl.date_range(low=date(2022, 1, 1), high=date(2022, 1, 3), interval=\"1d\")\ndf = pl.DataFrame({\"dates\": dates})\ndf.with_columns([pl.col(\"dates\").cast(pl.Int32).alias(\"days_since_epoch\")])\n```\n\n----------------------------------------\n\nTITLE: Polars Series Descriptive Methods Reference\nDESCRIPTION: Comprehensive list of methods available for describing and analyzing Polars Series objects. These methods provide information about series properties like length, null counts, uniqueness, and value distributions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/descriptive.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSeries.chunk_lengths\nSeries.describe\nSeries.estimated_size\nSeries.has_nulls\nSeries.has_validity\nSeries.is_duplicated\nSeries.is_empty\nSeries.is_finite\nSeries.is_first_distinct\nSeries.is_in\nSeries.is_infinite\nSeries.is_last_distinct\nSeries.is_nan\nSeries.is_not_nan\nSeries.is_not_null\nSeries.is_null\nSeries.is_sorted\nSeries.is_unique\nSeries.len\nSeries.lower_bound\nSeries.n_chunks\nSeries.n_unique\nSeries.null_count\nSeries.unique_counts\nSeries.upper_bound\nSeries.value_counts\n```\n\n----------------------------------------\n\nTITLE: Unity Catalog Class and Method Definitions in Python\nDESCRIPTION: This snippet lists the main Catalog class and its methods for interacting with Unity catalogs. It includes methods for listing catalogs, namespaces, tables, and retrieving table information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/catalog/unity.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :toctree: api/\n\n   Catalog\n   Catalog.list_catalogs\n   Catalog.list_namespaces\n   Catalog.list_tables\n   Catalog.get_table_info\n   Catalog.scan_table\n```\n\n----------------------------------------\n\nTITLE: Demonstrating UNION ALL Operation in Polars SQL\nDESCRIPTION: This snippet demonstrates the UNION ALL operation to combine the complete result sets of two SELECT statements. The final result set includes all rows from each query, including duplicates. It uses Polars LazyFrames and the SQL interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/set_operations.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npl.sql(\"\"\"\n    SELECT id, name FROM lf1\n    UNION ALL\n    SELECT id, name FROM lf2\n\"\"\").sort(by=\"id\").collect()\n# shape: (6, 2)\n# ┌─────┬─────────┐\n# │ id  ┆ name    │\n# │ --- ┆ ---     │\n# │ i64 ┆ str     │\n# ╞═════╪═════════╡\n# │ 1   ┆ Alice   │\n# │ 2   ┆ Bob     │\n# │ 2   ┆ Bob     │\n# │ 3   ┆ Charlie │\n# │ 3   ┆ Charlie │\n# │ 4   ┆ David   │\n# └─────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Smaller Integer Types for Datetime Components in Polars 0.20\nDESCRIPTION: Shows how datetime components like month and week now return smaller integer types to reduce memory consumption. For example, month now returns i8 (Int8) instead of u32 (UInt32).\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Before:\nfrom datetime import date\ns = pl.Series([date(2023, 12, 31), date(2024, 1, 1)])\ns.dt.month()\n# Returns u32 type\n\n# After:\ns.dt.month()\n# Returns u8 type\n```\n\n----------------------------------------\n\nTITLE: Joining Array Elements with ARRAY_TO_STRING in Polars SQL\nDESCRIPTION: Illustrates the usage of ARRAY_TO_STRING function to join array elements into a single string with a specified delimiter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"foo\": [[\"a\", \"b\"], [\"c\", \"d\", \"e\"]],\n        \"bar\": [[8, None, 8], [3, 2, 1, 0]],\n    }\n)\ndf.sql(\"\"\"\n  SELECT\n    ARRAY_TO_STRING(foo,':') AS s_foo,\n    ARRAY_TO_STRING(bar,':') AS s_bar\n  FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌───────┬─────────┐\n# │ s_foo ┆ s_bar   │\n# │ ---   ┆ ---     │\n# │ str   ┆ str     │\n# ╞═══════╪═════════╡\n# │ a:b   ┆ 8:8     │\n# │ c:d:e ┆ 3:2:1:0 │\n# └───────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Using BIT_COUNT function in Polars SQL\nDESCRIPTION: This example demonstrates the usage of the BIT_COUNT function to count the number of bits set to 1 in the binary representation of integers in a Polars DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/bitwise.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"i\": [16, 10, 55, 127]})\ndf.sql(\"\"\"\n  SELECT\n    i,\n    BIT_COUNT(i) AS i_bitcount\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Polars LazyFrame Query\nDESCRIPTION: Example of creating a LazyFrame with sample data and defining a query that computes the maximum of column 'a' over column 'b'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/quickstart.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.LazyFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 4, 5]\n})\nlf = df.with_columns(\n    c = pl.col(\"a\").max().over(\"b\")\n)\n```\n\n----------------------------------------\n\nTITLE: Registering DataFrames with SQLContext\nDESCRIPTION: This code shows how to register DataFrames explicitly with the SQLContext using a dictionary. This allows them to be queried using SQL. It demonstrates registering a Polars DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/intro.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing import assert_frame_equal\n\n\ndf = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"foo\", \"bar\", \"baz\"]\n})\n\n\nctx = pl.SQLContext(data={\"my_table\": df})\n```\n\n----------------------------------------\n\nTITLE: String Case Conversion\nDESCRIPTION: Demonstrates string case conversion functions including to_lowercase, to_titlecase, and to_uppercase.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/strings.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/strings.py:casing\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating BIT_AND operation in Polars SQL\nDESCRIPTION: This snippet shows how to use the BIT_AND function and the '&' operator to perform bitwise AND operations on DataFrame columns using Polars SQL.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/bitwise.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n      \"i\": [3, 10, 4, 8],\n      \"j\": [4, 7, 9, 10],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    i,\n    j,\n    i & j AS i_bitand_op_j,\n    BIT_AND(i, j) AS i_bitand_j\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Multiprocessing Recommendation\nDESCRIPTION: This code snippet demonstrates the recommended approach for using multiprocessing with Polars. It involves setting the multiprocessing start method to 'spawn' to avoid potential issues with the 'fork' method, such as deadlocks caused by inherited mutexes.  This ensures that child processes are created with a fresh Python interpreter, preventing them from inheriting the locked state of file access from the parent process.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/multiprocessing.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport multiprocessing as mp\n\nmp.set_start_method('spawn')\n\n```\n\n----------------------------------------\n\nTITLE: Identifying Missing Values with is_null in Polars\nDESCRIPTION: Demonstrates how to use the is_null function to efficiently detect which values are null in a dataframe or series. This operation uses Polars' validity bitmap for performance.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create boolean mask of positions containing nulls\ndf.select(pl.col(\"a\").is_null())\n```\n\n----------------------------------------\n\nTITLE: Setting and Replacing Time Zones in Polars Dataframes (Python)\nDESCRIPTION: This snippet demonstrates how to parse datetime strings, set time zones, and replace time zones in Polars dataframes. It uses the str.to_datetime and dt.replace_time_zone methods.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/timezones.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"date\": [\"2020-01-01\", \"2020-01-02\", \"2020-01-03\"]})\n\ndf = df.with_columns([\n    pl.col(\"date\").str.to_datetime().dt.replace_time_zone(\"UTC\").alias(\"utc\"),\n    pl.col(\"date\").str.to_datetime().dt.replace_time_zone(\"Europe/London\").alias(\"london\"),\n    pl.col(\"date\").str.to_datetime().dt.replace_time_zone(\"Australia/Sydney\").alias(\"sydney\"),\n])\n\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Unnesting Arrays with UNNEST in Polars SQL\nDESCRIPTION: Illustrates how to use the UNNEST function to explode array columns into multiple rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [[\"a\", \"b\"], [\"c\", \"d\", \"e\"]],\n    \"bar\": [[6, 7, 8], [9, 10]]\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    UNNEST(foo) AS f,\n    UNNEST(bar) AS b\n  FROM self\n\"\"\")\n# shape: (5, 2)\n# ┌─────┬─────┐\n# │ f   ┆ b   │\n# │ --- ┆ --- │\n# │ str ┆ i64 │\n# ╞═════╪═════╡\n# │ a   ┆ 6   │\n# │ b   ┆ 7   │\n# │ c   ┆ 8   │\n# │ d   ┆ 9   │\n# │ e   ┆ 10  │\n# └─────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Plotnine with Polars DataFrame\nDESCRIPTION: This snippet demonstrates plotting with Plotnine using a Polars DataFrame. Plotnine internally converts the Polars DataFrame to a pandas DataFrame.  It showcases the use of the Grammar of Graphics in Python via Plotnine for creating visualizations from Polars data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:plotnine_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Miscellaneous Polars Series Methods in Python\nDESCRIPTION: This code snippet demonstrates how to import and access various miscellaneous methods available for Polars Series objects. These methods include equality comparison, chunk retrieval, element mapping, data reinterpretation, sorted flag setting, and physical representation conversion.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/miscellaneous.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom polars import Series\n\n# Example usage of miscellaneous methods\nseries = Series([1, 2, 3, 4, 5])\n\nseries.equals(Series([1, 2, 3, 4, 5]))  # Check equality\nchunks = series.get_chunks()  # Get underlying chunks\nmapped_series = series.map_elements(lambda x: x * 2)  # Apply function to each element\nreinterpreted_series = series.reinterpret()  # Reinterpret underlying data\nseries.set_sorted()  # Set sorted flag\nphysical_series = series.to_physical()  # Convert to physical representation\n```\n\n----------------------------------------\n\nTITLE: Retrieving First Element with FIRST in Polars SQL\nDESCRIPTION: Illustrates the usage of the FIRST function to get the first element of a column in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"b\", \"a\", \"b\", \"c\"]})\ndf.sql(\"\"\"\n  SELECT FIRST(foo) AS ff FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌─────┐\n# │ ff  │\n# │ --- │\n# │ str │\n# ╞═════╡\n# │ b   │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Combining head and sum operations in Polars (Python)\nDESCRIPTION: Demonstrates how Polars can combine independent column operations like sorting, head, filtering, and sum in a single select statement. This showcases Polars' flexibility in column manipulation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf.select(\n    pl.col(\"foo\").sort().head(2),\n    pl.col(\"bar\").filter(pl.col(\"foo\") == \"d\").sum()\n)\n```\n\n----------------------------------------\n\nTITLE: Scanning File Paths without Hive Partitioning in Polars using Python\nDESCRIPTION: This snippet demonstrates scanning file paths without enabling hive partitioning, which is the default behavior for file paths in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:scan_file_no_hive\"\n```\n\n----------------------------------------\n\nTITLE: Registering Custom Series Namespace in Polars\nDESCRIPTION: Shows how to create a 'math' namespace for Series that adds mathematical operations like square and cube calculations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/api.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@pl.api.register_series_namespace(\"math\")\nclass MathShortcuts:\n    def __init__(self, s: pl.Series) -> None:\n        self._s = s\n\n    def square(self) -> pl.Series:\n        return self._s * self._s\n\n    def cube(self) -> pl.Series:\n        return self._s * self._s * self._s\n\n\ns = pl.Series(\"n\", [1, 2, 3, 4, 5])\n\ns2 = s.math.square().rename(\"n2\")\ns3 = s.math.cube().rename(\"n3\")\n```\n\n----------------------------------------\n\nTITLE: Custom Authentication Function for AWS\nDESCRIPTION: Example showing how to implement a custom credential provider function for AWS authentication with role-chaining.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef my_credential_provider():\n    return {\n        \"key\": \"access-key\",\n        \"secret\": \"secret-key\",\n        \"session_token\": \"session-token\",  # optional\n        \"region\": \"us-east-1\"  # optional\n    }\n\ndf = pl.scan_parquet(\"s3://bucket/file.parquet\", credential_provider=my_credential_provider)\n```\n\n----------------------------------------\n\nTITLE: Convert Polars DataFrame to pyarrow Table Zero-Copy\nDESCRIPTION: This code shows how to convert a Polars DataFrame to a pyarrow Table using the `to_arrow` method with `rechunk=False` to ensure a zero-copy conversion.  This creates a view of the data and avoids unnecessary data duplication, improving performance. Requires appropriate data layout for zero-copy.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\n    \"foo\": [1, 2, 3],\n    \"bar\": [\"ham\", \"spam\", \"jam\"]\n})\n\npa_table = df.to_arrow(rechunk=False)\n```\n\n----------------------------------------\n\nTITLE: Ranking Pokémon Speed Using Group By and Explode in Polars\nDESCRIPTION: Shows an alternative method to rank Pokémon speed within types using group_by and explode functions. This approach achieves similar results to window functions but with different row ordering.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf_ranked = pokemon.group_by(\"Type 1\").agg(\n    pl.col(\"Name\"),\n    pl.col(\"Speed\").rank().alias(\"Speed rank in type\")\n).explode([\"Name\", \"Speed rank in type\"])\nprint(df_ranked)\n```\n\n----------------------------------------\n\nTITLE: Polars Optimization Table in Markdown\nDESCRIPTION: A markdown table detailing different optimization strategies in Polars, including predicate pushdown, projection pushdown, slice pushdown, common subplan elimination, expression simplification, join ordering, type coercion, and cardinality estimation. Each optimization is described with its explanation and execution frequency.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/optimizations.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Optimization               | Explanation                                                                                                  | runs                          |\n| -------------------------- | ------------------------------------------------------------------------------------------------------------ | ----------------------------- |\n| Predicate pushdown         | Applies filters as early as possible/ at scan level.                                                         | 1 time                        |\n| Projection pushdown        | Select only the columns that are needed at the scan level.                                                   | 1 time                        |\n| Slice pushdown             | Only load the required slice from the scan level. Don't materialize sliced outputs (e.g. join.head(10)).     | 1 time                        |\n| Common subplan elimination | Cache subtrees/file scans that are used by multiple subtrees in the query plan.                              | 1 time                        |\n| Simplify expressions       | Various optimizations, such as constant folding and replacing expensive operations with faster alternatives. | until fixed point             |\n| Join ordering              | Estimates the branches of joins that should be executed first in order to reduce memory pressure.            | 1 time                        |\n| Type coercion              | Coerce types such that operations succeed and run on minimal required memory.                                | until fixed point             |\n| Cardinality estimation     | Estimates cardinality in order to determine optimal group by strategy.                                       | 0/n times; dependent on query |\n```\n\n----------------------------------------\n\nTITLE: hvPlot Integration with Polars\nDESCRIPTION: This code utilizes hvPlot with Polars to generate interactive plots.  It demonstrates how to register the hvplot method using `hvplot.polars`. hvPlot allows for the creation of interactive visualizations from Polars DataFrames.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:hvplot_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Using STARTS_WITH Function in Polars SQL\nDESCRIPTION: Demonstrates checking if strings begin with a specific substring using the STARTS_WITH function, which returns a boolean result for each row.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"apple\", \"banana\", \"avocado\", \"grape\"]})\ndf.sql(\"\"\"\n  SELECT foo, STARTS_WITH(foo, 'a') AS starts_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Scanning IPC/Feather Data from Hugging Face with Polars\nDESCRIPTION: Demonstrates scanning an IPC/Feather format file from a Hugging Face space using the scan_ipc function. Shows how to access data from the spaces bucket.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hugging-face.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.scan_ipc(\"hf://spaces/nameexhaustion/polars-docs/orders.feather\")\n```\n\n----------------------------------------\n\nTITLE: Matplotlib Visualization with Polars\nDESCRIPTION: This snippet showcases how to create a scatter plot using Matplotlib with Polars DataFrames. It highlights the conversion of Polars Series to NumPy arrays to be compatible with Matplotlib.  The column 'species' is converted to numeric values before being used for plotting.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:matplotlib_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Using SUBSTR Function in Polars SQL\nDESCRIPTION: Demonstrates extracting substrings using the SUBSTR function, which takes a start position (1-indexed) and length. This is useful for extracting specific portions of text.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"apple\", \"banana\", \"orange\", \"grape\"]})\ndf.sql(\"\"\"\n  SELECT foo, SUBSTR(foo, 3, 4) AS foo_3_4 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Aggregating DataFrame using fold method in Python\nDESCRIPTION: The fold method allows for custom aggregation of DataFrame data. It applies a function to accumulate values across rows or columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/computation.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nDataFrame.fold\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Tangent in Radians using ATAN\nDESCRIPTION: Demonstrates ATAN function to compute inverse tangent in radians for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"rads\": [-1.0, 0.0, 1.0, 2.0]})\ndf.sql(\"SELECT rads, ATAN(rads) AS atan FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Random Sampling from DataFrame\nDESCRIPTION: Shows how to randomly sample rows from a DataFrame using the sample() method, useful for inspecting representative data subsets.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(df.sample(2))\n```\n\n----------------------------------------\n\nTITLE: Explaining Expression Expansion in Polars\nDESCRIPTION: An example showing how to use the explain() function to see how an expression like (pl.col(pl.Float64) * 1.1).name.suffix(\"*1.1\") would be evaluated against a schema.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/lazy-api.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/concepts/lazy-vs-eager.py:explain-expression-expansion\"\n```\n\n----------------------------------------\n\nTITLE: Registering Custom DataFrame Namespace in Polars\nDESCRIPTION: Shows how to add a 'split' namespace to DataFrame that implements functionality to split dataframes by alternate rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/api.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@pl.api.register_dataframe_namespace(\"split\")\nclass SplitFrame:\n    def __init__(self, df: pl.DataFrame) -> None:\n        self._df = df\n\n    def by_alternate_rows(self) -> list[pl.DataFrame]:\n        df = self._df.with_row_index(name=\"n\")\n        return [\n            df.filter((pl.col(\"n\") % 2) == 0).drop(\"n\"),\n            df.filter((pl.col(\"n\") % 2) != 0).drop(\"n\"),\n        ]\n\n\npl.DataFrame(\n    data=[\"aaa\", \"bbb\", \"ccc\", \"ddd\", \"eee\", \"fff\"],\n    schema=[(\"txt\", pl.String)],\n).split.by_alternate_rows()\n```\n\n----------------------------------------\n\nTITLE: Explicit sum implementation with fold in Polars (Python)\nDESCRIPTION: This snippet shows an explicit implementation of the sum operation performed by the `fold` function. It demonstrates the equivalent calculation done by the fold function. A third explicit expression represents what the function `fold` is doing above.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/folds.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"a\": [1, 2, 3],\n    \"b\": [4, 5, 6],\n})\n\nout = df.select(\n    (pl.col(\"a\") + pl.col(\"b\")).alias(\"sum\"),\n)\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Absolute Value Function (ABS) in Polars SQL\nDESCRIPTION: Demonstrates the ABS function which returns the absolute value of numbers in a column. Works with floating point numbers and returns the same type.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [-1.0, 0.0, 1.0, -2.0]})\ndf.sql(\"\"\"\n  SELECT a, ABS(a) AS abs_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Polars Cloud\nDESCRIPTION: Command to authenticate with Polars Cloud services. This command refreshes the access token and saves it to disk.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/cli.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npc login\n```\n\n----------------------------------------\n\nTITLE: Using DataFrame Head Method\nDESCRIPTION: Shows how to inspect the first rows of a DataFrame using the head() method, with an optional parameter to specify the number of rows to display.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(df.head(3))\n```\n\n----------------------------------------\n\nTITLE: Creating Weather Data Example in Polars\nDESCRIPTION: This snippet creates a sample weather dataframe with temperature readings from different stations. The data includes error codes when readings are unavailable.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:weather\"\n```\n\n----------------------------------------\n\nTITLE: Equivalent operation in Spark using separate window functions (Python)\nDESCRIPTION: Illustrates how to achieve a similar result in Spark, which requires separate window functions for lag and mean operations. This showcases the limitations in Spark's expression composition compared to Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pyspark.sql import Window\nfrom pyspark.sql import functions as F\n\nwindow = Window().partitionBy(\"store\").orderBy(\"date\")\nrolling_window = window.rowsBetween(-6, 0)\n(\n    df.withColumn(\"lagged_price\", F.lag(\"price\", 7).over(window)).withColumn(\n        \"feature\",\n        F.when(\n            F.count(\"lagged_price\").over(rolling_window) >= 7,\n            F.mean(\"lagged_price\").over(rolling_window),\n        ),\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Filtering by Single Date in Polars DataFrame\nDESCRIPTION: Demonstrates how to filter a DataFrame for a specific date using equality comparison. Uses the datetime method for comparison with a pl.Datetime column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/time-series/filter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf.filter(pl.col(\"Date\") == datetime(2022, 1, 3))\n```\n\n----------------------------------------\n\nTITLE: Deserializing JSON to DataFrame in Python\nDESCRIPTION: Demonstrates how to deserialize JSON data to a DataFrame using pl.DataFrame.deserialize() instead of the deprecated pl.read_json() method for serialized data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport io\ndf_ser = '{\"columns\":[{\"name\":\"a\",\"datatype\":\"Int64\",\"bit_settings\":\"\",\"values\":[1,2]},{\"name\":\"b\",\"datatype\":\"Float64\",\"bit_settings\":\"\",\"values\":[3.0,4.0]}]}'\npl.DataFrame.deserialize(io.StringIO(df_ser))\n```\n\n----------------------------------------\n\nTITLE: Using DISTINCT Clause in Polars SQL\nDESCRIPTION: Shows how to retrieve unique combinations of values from a Polars DataFrame\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"a\": [1, 2, 2, 1],\n    \"b\": [\"xx\", \"yy\", \"yy\", \"xx\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT DISTINCT * FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Finding Minimum Array Value with ARRAY_LOWER in Polars SQL\nDESCRIPTION: Shows the usage of ARRAY_LOWER function to find the minimum value in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[1, 2], [4, -2, 8]]})\ndf.sql(\"\"\"\n  SELECT foo, ARRAY_LOWER(foo) AS min_elem FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌────────────┬──────────┐\n# │ foo        ┆ min_elem │\n# │ ---        ┆ ---      │\n# │ list[i64]  ┆ i64      │\n# ╞════════════╪══════════╡\n# │ [1, 2]     ┆ 1        │\n# │ [4, -2, 8] ┆ -2       │\n# └────────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Writing a DataFrame to a Specific Sheet in an Excel File with Polars in Python\nDESCRIPTION: This example shows how to write a Polars DataFrame to a specific sheet in an Excel file using the write_excel method with the worksheet parameter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/excel','write_sheet_name',['write_excel'])}}\n```\n\n----------------------------------------\n\nTITLE: Using REGEXP_LIKE for Pattern Matching in Polars SQL\nDESCRIPTION: Demonstrates how to use REGEXP_LIKE to check if strings match a regular expression pattern. In this example, it checks if strings end with a digit.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"abc123\", \"4ab4a\", \"abc456\", \"321cba\"]})\ndf.sql(r\"\"\"\n  SELECT foo, REGEXP_LIKE(foo, '\\d$') AS ends_in_digit FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Creating a New Sheet with Initial Data in Google Colab\nDESCRIPTION: This snippet demonstrates how to create a new Google Sheet and immediately populate it with data from a Polars DataFrame. It passes the DataFrame as the `df` parameter to the `InteractiveSheet` constructor. It requires the `google.colab` and `polars` libraries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Using IF function in Polars SQL\nDESCRIPTION: Demonstrates the usage of IF function to return one of two expressions based on a boolean condition. It creates a DataFrame and applies the IF function using SQL syntax to compare values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [100, 200, 300, 400],\n    \"bar\": [10, 20, 30, 40]\n  }\n)\ndf.sql(\"\"\"\n  SELECT IF(foo < 250, 111, 999) AS baz FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌─────┐\n# │ baz │\n# │ --- │\n# │ i32 │\n# ╞═════╡\n# │ 111 │\n# │ 111 │\n# │ 999 │\n# │ 999 │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Using NULLIF function in Polars SQL\nDESCRIPTION: Shows how to use the NULLIF function to return NULL if two expressions are equal, otherwise returning the first expression. It creates a DataFrame and applies the NULLIF function using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/conditional.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [100, 200, 300, 400],\n    \"bar\": [20, 10, 30, 40]\n  }\n)\ndf.sql(\"\"\"\n  SELECT NULLIF(foo, bar) AS baz FROM self\n\"\"\")\n# shape: (4, 1)\n# ┌─────┐\n# │ baz │\n# │ --- │\n# │ i64 │\n# ╞═════╡\n# │ 100 │\n# │ 200 │\n# │ 300 │\n# │ 400 │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Reading a Specific Sheet from an Excel File with Polars in Python\nDESCRIPTION: This example shows how to read a specific sheet from an Excel file using Polars' read_excel function with the sheet_name parameter.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/excel','read_sheet_name',['read_excel'])}}\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample DataFrame in Polars\nDESCRIPTION: Creates a sample DataFrame with stock price data for demonstration of expression expansion techniques.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing Optimized Polars Query Plan\nDESCRIPTION: This code visualizes the optimized query plan using Graphviz. It creates a graph representation of the optimized plan and saves it as an SVG file.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/query-plan.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nq.show_graph(output_path=\"optimized_plan.svg\")\n```\n\n----------------------------------------\n\nTITLE: Accessing Polars Expression Methods\nDESCRIPTION: Code demonstrating the module and class import pattern for accessing Polars expression methods. Shows the three miscellaneous methods available on Expr objects.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/miscellaneous.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n   Expr.deserialize\n   Expr.from_json\n   Expr.set_sorted\n```\n\n----------------------------------------\n\nTITLE: Round Function in Polars SQL\nDESCRIPTION: Demonstrates ROUND function for rounding numbers to specified decimal places.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"x\": [-0.45, -1.81, 2.25, 3.99]})\ndf.sql(\"\"\"\n  SELECT x, ROUND(x) AS x_round, ROUND(x, 1) AS x_round_1 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Detecting GPU Fallback in Polars\nDESCRIPTION: Example of running a query in verbose mode to detect when a query falls back to CPU execution.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/gpu-support.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith pl.Config() as cfg:\n    cfg.set_verbose(True)\n    result = q.collect(engine=\"gpu\")\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Using STRPOS Function in Polars SQL\nDESCRIPTION: Demonstrates finding the position of a substring within a string using STRPOS. The function returns the 1-indexed position of the first occurrence of the substring.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"apple\", \"banana\", \"orange\", \"grape\"]})\ndf.sql(\"\"\"\n  SELECT foo, STRPOS(foo, 'a') AS pos_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Calculating Array Length with ARRAY_LENGTH in Polars SQL\nDESCRIPTION: Demonstrates how to use the ARRAY_LENGTH function to determine the number of elements in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[1, 2], [4, 3, 2]]})\ndf.sql(\"\"\"\n  SELECT foo, ARRAY_LENGTH(foo) AS n_elems FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌───────────┬─────────┐\n# │ foo       ┆ n_elems │\n# │ ---       ┆ ---     │\n# │ list[i64] ┆ u32     │\n# ╞═══════════╪═════════╡\n# │ [1, 2]    ┆ 2       │\n# │ [4, 3, 2] ┆ 3       │\n# └───────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Summing Array Elements with ARRAY_SUM in Polars SQL\nDESCRIPTION: Shows how to use the ARRAY_SUM function to calculate the sum of all values in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[1, -2], [10, 3, -2]]})\ndf.sql(\"\"\"\n  SELECT\n    foo,\n    ARRAY_SUM(foo) AS foo_sum\n  FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌─────────────┬─────────┐\n# │ foo         ┆ foo_sum │\n# │ ---         ┆ ---     │\n# │ list[i64]   ┆ i64     │\n# ╞═════════════╪═════════╡\n# │ [1, -2]     ┆ -1      │\n# │ [10, 3, -2] ┆ 11      │\n# └─────────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Accessing Array Elements with ARRAY_GET in Polars SQL\nDESCRIPTION: Illustrates the usage of ARRAY_GET function to retrieve values at specific indices from array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [[1, 2], [4, 3, 2]],\n    \"bar\": [[6, 7], [8, 9, 10]]\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    foo, bar,\n    ARRAY_GET(foo, 1) AS foo_at_1,\n    ARRAY_GET(bar, 3) AS bar_at_2\n  FROM self\n\"\"\")\n# shape: (2, 4)\n# ┌───────────┬────────────┬──────────┬──────────┐\n# │ foo       ┆ bar        ┆ foo_at_1 ┆ bar_at_2 │\n# │ ---       ┆ ---        ┆ ---      ┆ ---      │\n# │ list[i64] ┆ list[i64]  ┆ i64      ┆ i64      │\n# ╞═══════════╪════════════╪══════════╪══════════╡\n# │ [1, 2]    ┆ [6, 7]     ┆ 1        ┆ null     │\n# │ [4, 3, 2] ┆ [8, 9, 10] ┆ 4        ┆ 10       │\n# └───────────┴────────────┴──────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Selecting Data in Pandas vs Polars (Python)\nDESCRIPTION: Comparison of data selection methods in Pandas and Polars. Pandas uses indexing or column selection, while Polars uses the select method with expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Pandas\ndf[\"a\"]\ndf.loc[:,\"a\"]\n\n# Polars\ndf.select(\"a\")\n```\n\n----------------------------------------\n\nTITLE: Loading Property Prices DataFrame in Python\nDESCRIPTION: This snippet shows how to create a Polars DataFrame containing property names and their prices for a Monopoly-like game.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprops_prices = pl.DataFrame(\n    {\n        \"property\": [\"Mediterranean Avenue\", \"Baltic Avenue\", \"Reading Railroad\", \"Oriental Avenue\", \"Sesame Street\"],\n        \"price\": [60, 60, 200, 100, 250],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Using GPU-Enabled Execution in Polars\nDESCRIPTION: Example of using GPU-enabled execution in Polars by calling .collect(engine=\"gpu\") on a lazy query.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/gpu-support.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nresult = q.collect(engine=\"gpu\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Registering Custom LazyFrame Namespace in Polars\nDESCRIPTION: Demonstrates adding a 'types' namespace to LazyFrame for handling data type operations, specifically upcasting integer types.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/api.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@pl.api.register_lazyframe_namespace(\"types\")\nclass DTypeOperations:\n    def __init__(self, ldf: pl.LazyFrame) -> None:\n        self._ldf = ldf\n\n    def upcast_integer_types(self) -> pl.LazyFrame:\n        return self._ldf.with_columns(\n            pl.col(tp).cast(pl.Int64)\n            for tp in (pl.Int8, pl.Int16, pl.Int32)\n        )\n\n\nldf = pl.DataFrame(\n    data={\"a\": [1, 2], \"b\": [3, 4], \"c\": [5.6, 6.7]},\n    schema=[(\"a\", pl.Int16), (\"b\", pl.Int32), (\"c\", pl.Float32)],\n).lazy()\n\nldf.types.upcast_integer_types()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Non-Optimized Polars Query Plan\nDESCRIPTION: This code visualizes the non-optimized query plan using Graphviz. It creates a graph representation of the plan and saves it as an SVG file.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/query-plan.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nq.show_graph(optimized=False, output_path=\"non_optimized_plan.svg\")\n```\n\n----------------------------------------\n\nTITLE: Listing Series.list Methods in Polars\nDESCRIPTION: This code snippet uses reStructuredText to generate an autosummary of all methods available under the Series.list attribute in Polars. It includes directives for generating API documentation pages for each method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/list.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Series.list.all\n    Series.list.any\n    Series.list.arg_max\n    Series.list.arg_min\n    Series.list.concat\n    Series.list.contains\n    Series.list.count_matches\n    Series.list.diff\n    Series.list.drop_nulls\n    Series.list.eval\n    Series.list.explode\n    Series.list.first\n    Series.list.gather\n    Series.list.gather_every\n    Series.list.get\n    Series.list.head\n    Series.list.join\n    Series.list.last\n    Series.list.len\n    Series.list.max\n    Series.list.mean\n    Series.list.median\n    Series.list.min\n    Series.list.n_unique\n    Series.list.reverse\n    Series.list.sample\n    Series.list.set_difference\n    Series.list.set_intersection\n    Series.list.set_symmetric_difference\n    Series.list.set_union\n    Series.list.shift\n    Series.list.slice\n    Series.list.sort\n    Series.list.std\n    Series.list.sum\n    Series.list.tail\n    Series.list.to_array\n    Series.list.to_struct\n    Series.list.unique\n    Series.list.var\n```\n\n----------------------------------------\n\nTITLE: Nested Grouping in Polars for Conditional Aggregation\nDESCRIPTION: This snippet demonstrates nested grouping in Polars. It groups data by 'state' and 'party' to count the number of 'Pro' and 'Anti' administration delegates for each state and party combination.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/aggregation.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nout = df.group_by([\"state\", \"party\"]).agg(pl.count()).filter(\n    pl.col(\"party\").is_in([\"Pro-Administration\", \"Anti-Administration\"])\n).sort(\"count\", descending=True)\n\nprint(out)\n```\n\n----------------------------------------\n\nTITLE: Intermediate Parametric Testing with Polars LazyFrames in Python\nDESCRIPTION: Demonstrates how to integrate hypothesis-native strategies into specifically-named columns, generating a series of LazyFrames with a minimum size of five rows and values that conform to the given strategies.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/testing.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing.parametric import column, dataframes\n\nimport hypothesis.strategies as st\nfrom hypothesis import given\nfrom string import ascii_letters, digits\n\nid_chars = ascii_letters + digits\n\n@given(\n    dataframes(\n        cols=[\n            column(\"id\", strategy=st.text(min_size=4, max_size=4, alphabet=id_chars)),\n            column(\"ccy\", strategy=st.sampled_from([\"GBP\", \"EUR\", \"JPY\", \"USD\"])),\n            column(\"price\", strategy=st.floats(min_value=0.0, max_value=1000.0)),\n        ],\n        min_size=5,\n        lazy=True,\n    )\n)\ndef test_price_calculations(lf: pl.LazyFrame):\n    ...\n    print(lf.collect())\n\n    # Example frame:\n    # ┌──────┬─────┬─────────┐\n    # │ id   ┆ ccy ┆ price   │\n    # │ ---  ┆ --- ┆ ---     │\n    # │ str  ┆ str ┆ f64     │\n    # ╞══════╪═════╪═════════╡\n    # │ A101 ┆ GBP ┆ 1.1     │\n    # │ 8nIn ┆ JPY ┆ 1.5     │\n    # │ QHoO ┆ EUR ┆ 714.544 │\n    # │ i0e0 ┆ GBP ┆ 0.0     │\n    # │ 0000 ┆ USD ┆ 999.0   │\n    # └──────┴─────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Demonstrating OCTET_LENGTH and LENGTH Functions in Polars SQL\nDESCRIPTION: Shows using OCTET_LENGTH to count bytes and LENGTH to count characters in strings, highlighting the difference with multi-byte UTF-8 characters.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndf.sql(\"\"\"\n  SELECT\n    iso_lang,\n    color,\n    OCTET_LENGTH(color) AS n_bytes,\n    LENGTH(color) AS n_chars\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Custom Authentication Function for Azure\nDESCRIPTION: Example showing how to implement Azure authentication using a custom credential provider function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef azure_credential_provider():\n    return {\n        \"account_key\": \"your-account-key\"\n    }\n\ndf = pl.scan_parquet(\"abfs://container/file.parquet\", credential_provider=azure_credential_provider)\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Aggregation Functions\nDESCRIPTION: This code snippet shows how to import the Polars library and access its aggregation functions. These functions are methods of the Expr class in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/aggregation.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom polars import Expr\n\n# Example usage:\n# df.groupby('column').agg([\n#     Expr('value').sum(),\n#     Expr('value').mean(),\n#     Expr('value').max()\n# ])\n```\n\n----------------------------------------\n\nTITLE: Retrieving Unique Array Elements with ARRAY_UNIQUE in Polars SQL\nDESCRIPTION: Demonstrates how to use the ARRAY_UNIQUE function to get unique elements from array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[\"a\", \"b\"], [\"b\", \"b\", \"e\"]]})\ndf.sql(\"\"\"\n  SELECT ARRAY_UNIQUE(foo) AS foo_unique FROM self\n\"\"\")\n# shape: (2, 1)\n# ┌────────────┐\n# │ foo_unique │\n# │ ---        │\n# │ list[str]  │\n# ╞════════════╡\n# │ [\"a\", \"b\"] │\n# │ [\"e\", \"b\"] │\n# └────────────┘\n```\n\n----------------------------------------\n\nTITLE: Writing to a Sheet in Google Colab\nDESCRIPTION: This snippet demonstrates writing a Polars DataFrame to an existing Google Sheet. It uses the `update` method to clear the worksheet and write the DataFrame starting from the top-left corner. It requires `google.colab` and `polars` libraries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Finding Minimum Value with MIN in Polars SQL\nDESCRIPTION: Illustrates the usage of the MIN function to find the smallest value in a column of a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [20, 10, 30, 40]})\ndf.sql(\"\"\"\n  SELECT MIN(bar) AS bar_min FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌─────────┐\n# │ bar_min │\n# │ ---     │\n# │ i64     │\n# ╞═════════╡\n# │ 10      │\n# └─────────┘\n```\n\n----------------------------------------\n\nTITLE: Polars Schema-Aware Expressions\nDESCRIPTION: Demonstrates how to create schema-aware expression functions in Polars while maintaining parallel execution benefits, using a single pipe to access schema information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom collections import OrderedDict\n\ndef get_foo(input_column: str, schema: OrderedDict) -> pl.Expr:\n    if \"some_col\" in schema:\n        # branch_a\n        ...\n    else:\n        # branch b\n        ...\n\ndef get_bar(input_column: str, schema: OrderedDict) -> pl.Expr:\n    if \"some_col\" in schema:\n        # branch_a\n        ...\n    else:\n        # branch b\n        ...\n\ndef get_ham(input_column: str) -> pl.Expr:\n    return pl.col(input_column).some_computation().alias(\"ham\")\n\n# Use pipe (just once) to get hold of the schema of the LazyFrame.\nlf.pipe(lambda lf: lf.with_columns(\n    get_ham(\"col_a\"),\n    get_bar(\"col_b\", lf.schema),\n    get_foo(\"col_c\", lf.schema),\n)\n```\n\n----------------------------------------\n\nTITLE: Cloud-Scale Query Definition\nDESCRIPTION: Defines a query for cloud execution using S3-stored parquet files, implementing the same fire risk calculation logic as the local version.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nlf = pl.scan_parquet(\"s3://climate-data/global/*.parquet\")\n\nquery = (\n    lf.with_columns(\n        [\n            (\n                (pl.col(\"temperature\") / 10)\n                * (1 - pl.col(\"humidity\") / 100)\n                * pl.col(\"vegetation_density\")\n            ).alias(\"fire_risk\"),\n        ]\n    )\n    .filter(pl.col(\"humidity\") < 70)\n    .sort(by=\"fire_risk\", descending=True)\n)\n```\n\n----------------------------------------\n\nTITLE: Composing expressions in Polars (Python)\nDESCRIPTION: Shows how Polars allows for liberal composition of expressions, such as finding the rolling mean of a lagged variable in a single over expression. This demonstrates Polars' flexibility in combining complex operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf.with_columns(\n    feature=pl.col('price').shift(7).rolling_mean(7).over('store', order_by='date')\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Polars DataFrame and Applying Basic Styling\nDESCRIPTION: Creates a Polars DataFrame with sample data and applies basic styling using the Great Tables library. This snippet demonstrates how to access the style property of a DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame(\n    {\n        \"species\": [\"setosa\", \"versicolor\", \"virginica\"],\n        \"sepal_length\": [5.1, 7.0, 6.3],\n        \"sepal_width\": [3.5, 3.2, 3.3],\n        \"petal_length\": [1.4, 4.7, 6.0],\n        \"petal_width\": [0.2, 1.4, 2.5],\n    }\n)\n\ngt = df.style()\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Input/Output Modules\nDESCRIPTION: This snippet shows the import statement for the Polars library, specifically focusing on the input/output functionality.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/io.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Tangent in Degrees using ATAND\nDESCRIPTION: Shows ATAND function usage to compute inverse tangent in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [-1.0, 0.0, 1.0]})\ndf.sql(\"SELECT degs, ATAND(degs) AS atand FROM self\")\n```\n\n----------------------------------------\n\nTITLE: AWS S3 Authentication Using CredentialProvider\nDESCRIPTION: Example demonstrating AWS S3 authentication using the CredentialProviderAWS utility class for profile selection and IAM role assumption.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/cloud-storage.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncredential_provider = pl.CredentialProviderAWS(\n    profile_name=\"my-aws-profile\",  # optional\n    assume_role_arn=\"arn:aws:iam::123456789012:role/my-role\"  # optional\n)\ndf = pl.scan_parquet(\"s3://bucket/file.parquet\", credential_provider=credential_provider)\n```\n\n----------------------------------------\n\nTITLE: Interactive Cloud Analysis Setup\nDESCRIPTION: Sets up an interactive cloud analysis session with Polars Cloud, enabling real-time data exploration of large datasets.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nctx = pc.ComputeContext(\n    workspace=\"environmental-analysis\",\n    memory=32,\n    cpus=8,\n    interactive=True,  # set interactive to True\n)\n\nresult = query.remote(context=ctx).collect()\n\nprint(result.collect())\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with Optional Dependencies (After)\nDESCRIPTION: Example showing how to install Polars with optional dependencies using the new streamlined extras names like calamine, async, and graph.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_34\n\nLANGUAGE: bash\nCODE:\n```\npip install 'polars[calamine,async,graph]'\n```\n\n----------------------------------------\n\nTITLE: Using OFFSET Clause in Polars SQL\nDESCRIPTION: Shows how to skip rows before returning results using OFFSET clause\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"b\", \"a\", \"c\", \"b\"],\n    \"bar\": [20, 10, 40, 30],\n  }\n)\ndf.sql(\"\"\"\n  SELECT foo, bar FROM self LIMIT 2 OFFSET 2\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Sorting Athletes Using Explode Mapping Strategy in Polars\nDESCRIPTION: Shows how to sort athletes within countries using the 'explode' mapping strategy. This approach is typically faster but reorders rows, grouping athletes by country.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf_sorted = df.select(\n    pl.col(\"*\"),\n    pl.col(\"Name\").sort_by(\"Rank\").over(\"Country\", mapping_strategy=\"explode\").alias(\"Sorted Name\")\n)\nprint(df_sorted)\n```\n\n----------------------------------------\n\nTITLE: Export Methods for Polars DataFrame\nDESCRIPTION: List of available export methods for converting Polars DataFrame objects to other formats including: array representation, Arrow C stream, DataFrame protocol, Arrow table, dictionary, list of dictionaries, initialization representation, JAX array, NumPy array, Pandas DataFrame, struct, and PyTorch tensor.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/export.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nDataFrame.__array__\nDataFrame.__arrow_c_stream__\nDataFrame.__dataframe__\nDataFrame.to_arrow\nDataFrame.to_dict\nDataFrame.to_dicts\nDataFrame.to_init_repr\nDataFrame.to_jax\nDataFrame.to_numpy\nDataFrame.to_pandas\nDataFrame.to_struct\nDataFrame.to_torch\n```\n\n----------------------------------------\n\nTITLE: Executing SHOW TABLES Statement in Polars SQL using Python\nDESCRIPTION: This snippet demonstrates how to create DataFrames, register them with SQLContext, and execute the SHOW TABLES statement to list registered tables. It uses the SQLContext's execute() method to run the SQL query and display the results.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/show.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/show.py:setup\"\n--8<-- \"python/user-guide/sql/show.py:show\"\n```\n\n----------------------------------------\n\nTITLE: Adding polars-sql Dependency in Cargo.toml\nDESCRIPTION: Shows how to add the polars-sql crate as a dependency in a Rust project's Cargo.toml file. This is the first step to use the SQL transpiler functionality in a Rust project.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-sql/README.md#2025-04-22_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[dependencies]\npolars-sql = \"0.30.0\"\n```\n\n----------------------------------------\n\nTITLE: Diagonal Concatenation of DataFrames in Polars\nDESCRIPTION: Demonstrates diagonal concatenation which combines both rows and columns from multiple DataFrames, handling overlapping columns and generating null values for non-overlapping columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/concatenation.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/concatenation.py:cross\"\n```\n\n----------------------------------------\n\nTITLE: Adding Column Spanner to Styled Polars DataFrame\nDESCRIPTION: Illustrates the addition of a column spanner to group related columns in a styled Polars DataFrame using Great Tables. This improves the table's structure and readability.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n(\n    gt.tab_header(title=\"Iris Dataset\")\n    .tab_stub(col=\"species\")\n    .tab_spanner(label=\"Sepal\", columns=[\"sepal_length\", \"sepal_width\"])\n    .tab_spanner(label=\"Petal\", columns=[\"petal_length\", \"petal_width\"])\n)\n```\n\n----------------------------------------\n\nTITLE: Deleting Rows from Table in Polars SQL\nDESCRIPTION: Removes specific rows from a table based on a WHERE condition. If no condition is specified, all rows are deleted.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nDELETE FROM some_table WHERE value < 0\n```\n\n----------------------------------------\n\nTITLE: Testing the Custom IO Source\nDESCRIPTION: This code demonstrates how to use the custom CSV IO source defined by `my_scan_csv`. It creates two sample CSV strings, `csv_str1` and `csv_str2`, and then uses `my_scan_csv` to create `LazyFrame` objects from these strings. The first `LazyFrame` is collected into a `DataFrame` and printed, while the second `LazyFrame` has its first two rows selected using `head(2)`, then collected and printed. This validates the basic functionality of the custom IO source.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/io_plugins.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncsv_str1 = \"\"\"a,b,c,d\n1,2,3,4\n9,10,11,2\n1,2,3,4\n1,122,3,4\"\"\"\n\nprint(my_scan_csv(csv_str1).collect())\n\n\ncsv_str2 = \"\"\"a,b\n1,2\n9,10\n1,2\n1,122\"\"\"\n\nprint(my_scan_csv(csv_str2).head(2).collect())\n```\n\n----------------------------------------\n\nTITLE: Altair Plotting with Polars\nDESCRIPTION: This snippet creates a plot using Altair with data from a Polars DataFrame. The snippet focuses on utilizing Polars DataFrames with Altair for creating visualizations.  Altair is used directly for chart creation and can be configured to adjust various visual properties.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:altair_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Installing Polars for Legacy CPUs using pip\nDESCRIPTION: Command to install a version of Polars compiled without AVX target features, suitable for older CPUs or specific hardware configurations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install polars-lts-cpu\n```\n\n----------------------------------------\n\nTITLE: Polars Series Aggregation Methods Index in RST\nDESCRIPTION: ReStructuredText directive defining the module and listing available Series aggregation methods in Polars library. Lists methods for statistical calculations, numerical operations, and data transformations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/aggregation.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    Series.arg_max\n    Series.arg_min\n    Series.count\n    Series.implode\n    Series.max\n    Series.mean\n    Series.median\n    Series.min\n    Series.mode\n    Series.nan_max\n    Series.nan_min\n    Series.product\n    Series.quantile\n    Series.std\n    Series.sum\n    Series.var\n```\n\n----------------------------------------\n\nTITLE: Interactive Mode Result Display\nDESCRIPTION: Demonstrates how to view results in interactive mode by collecting and printing the LazyFrame data\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/interactive-batch.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(res1.collect())\n```\n\n----------------------------------------\n\nTITLE: DataFrame Plotting Example\nDESCRIPTION: This snippet demonstrates a basic DataFrame plotting example using Polars.  It likely involves reading data from a CSV file and creating a plot based on column data.  The specific plotting library used is not defined in this snippet's description.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:dataframe\"\n```\n\n----------------------------------------\n\nTITLE: Using STRPTIME Function in Polars SQL\nDESCRIPTION: Shows how to convert strings to datetime objects using the STRPTIME function with a format string. This example concatenates date and time strings before parsing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"s_dt\": [\"1969 Oct 30\", \"2024 Jul 05\", \"2077 Feb 28\"],\n    \"s_tm\": [\"00.30.55\", \"12.40.15\", \"10.45.00\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    s_dt,\n    s_tm,\n    STRPTIME(s_dt || ' ' || s_tm, '%Y %b %d %H.%M.%S') AS dtm\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Trimming Whitespace from Left Side of Strings in Polars SQL\nDESCRIPTION: Shows the usage of the LTRIM function, which removes whitespace characters from the left side of a string. This is useful for cleaning up user input or standardizing text data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"   AA\", \" BB\", \"CC\", \"  DD\"]})\ndf.sql(\"\"\"\n  SELECT foo, LTRIM(foo) AS trimmed FROM self\n\"\"\")\n# shape: (4, 2)\n# ┌───────┬─────────┐\n# │ foo   ┆ trimmed │\n# │ ---   ┆ ---     │\n# │ str   ┆ str     │\n# ╞═══════╪═════════╡\n# │    AA ┆ AA      │\n# │  BB   ┆ BB      │\n# │ CC    ┆ CC      │\n# │   DD  ┆ DD      │\n# └───────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Accessing GroupBy Namespace in Polars LazyFrame\nDESCRIPTION: This code snippet demonstrates how to access the GroupBy namespace in Polars. It is achieved by calling the group_by method on a LazyFrame object.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/group_by.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nLazyFrame.group_by(...)\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with cargo\nDESCRIPTION: This command adds the Polars library as a dependency to your Rust project using cargo, the Rust package manager. The `-F lazy` flag enables lazy features. The subsequent Cargo.toml example shows adding polars with a specified version and features.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ncargo add polars -F lazy\n```\n\nLANGUAGE: TOML\nCODE:\n```\n[dependencies]\npolars = { version = \"x\", features = [\"lazy\", ...]}\n```\n\n----------------------------------------\n\nTITLE: Writing to Database with ADBC - Python\nDESCRIPTION: Example demonstrating how to write a DataFrame to a database using the ADBC engine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf.write_database(\"records\", connection=\"sqlite:///some.db\", engine=\"adbc\")\n```\n\n----------------------------------------\n\nTITLE: Bolding Specific Column in Styled Polars DataFrame\nDESCRIPTION: Illustrates how to apply bold formatting to a specific column in a styled Polars DataFrame using Great Tables. This technique can be used to emphasize certain data categories.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n(\n    gt.tab_header(title=\"Iris Dataset\")\n    .tab_stub(col=\"species\")\n    .fmt_number(columns=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], decimals=1)\n    .highlight_max(column=\"sepal_length\", color=\"yellow\")\n    .tab_style(style=\"font-weight: bold;\", locations=gt.cells_stub())\n)\n```\n\n----------------------------------------\n\nTITLE: Multiprocessing Working Example\nDESCRIPTION: This code snippet demonstrates a scenario where the 'fork' multiprocessing start method works without issues because it doesn't involve operations that acquire file locks.  The absence of `pl.read_parquet` prevents the deadlock, showcasing how seemingly unrelated changes can affect multiprocessing code. This example highlights the difficulty of debugging multiprocessing issues when using 'fork'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/multiprocessing.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport multiprocessing as mp\nimport os\nimport time\n\n\ndef run(i: int) -> None:\n    print(f'{i=}: {os.getpid()=}')\n    print(f'{i=}')\n\n\nif __name__ == '__main__':\n    mp.set_start_method('fork')\n\n    t0 = time.time()\n    processes = []\n    for i in range(4):\n        p = mp.Process(target=run, args=(i,))\n        processes.append(p)\n\n    for p in processes:\n        p.start()\n\n    for p in processes:\n        p.join()\n\n    print(f'Duration: {time.time() - t0}')\n\n```\n\n----------------------------------------\n\nTITLE: Sign Function in Polars SQL\nDESCRIPTION: Shows SIGN function usage for determining the sign (-1, 0, or +1) of numbers.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"x\": [0.4, -1, 0, -2, 4]})\ndf.sql(\"\"\"\n  SELECT x, SIGN(x) AS sign_x FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Creating Test DataFrame for Fill Operations in Polars\nDESCRIPTION: Creates a simple dataframe with two missing values in the second column for demonstrating various fill methods.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf2 = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3, 4, 5],\n        \"b\": [5.0, None, 6.0, None, 8.0],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Struct Methods in Polars\nDESCRIPTION: Reference documentation showing the available struct-related methods in Polars' expression system. These methods are accessed through the expr.struct attribute and provide functionality for working with structured data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/struct.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Expr.struct.field\n    Expr.struct.unnest\n    Expr.struct.json_encode\n    Expr.struct.rename_fields\n    Expr.struct.with_fields\n```\n\n----------------------------------------\n\nTITLE: Polars Series Array Methods Reference\nDESCRIPTION: Sphinx documentation directive listing all available array methods under Series.arr attribute. Includes methods for array operations like aggregation (sum, max, min), searching (contains, count_matches), sorting, and data transformation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/array.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Series.arr.all\n    Series.arr.any\n    Series.arr.arg_max\n    Series.arr.arg_min\n    Series.arr.contains\n    Series.arr.count_matches\n    Series.arr.explode\n    Series.arr.first\n    Series.arr.get\n    Series.arr.join\n    Series.arr.last\n    Series.arr.max\n    Series.arr.median\n    Series.arr.min\n    Series.arr.n_unique\n    Series.arr.reverse\n    Series.arr.shift\n    Series.arr.sort\n    Series.arr.std\n    Series.arr.sum\n    Series.arr.to_list\n    Series.arr.to_struct\n    Series.arr.unique\n    Series.arr.var\n```\n\n----------------------------------------\n\nTITLE: Complex queries using Polars\nDESCRIPTION: This snippet demonstrates how to chain multiple contexts and expressions in Polars to create a more complex query.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n--8<-- \"python/user-guide/getting-started.py:complex\"\n```\n\n----------------------------------------\n\nTITLE: Individual Value Processing with map_elements()\nDESCRIPTION: Demonstrates using map_elements() to apply math.log() function to individual values in a Series.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:individual_log\"\n```\n\n----------------------------------------\n\nTITLE: Scanning CSV Data from Hugging Face with Polars\nDESCRIPTION: Demonstrates scanning an iris dataset in CSV format from a Hugging Face repository using the scan_csv function. Shows how to specify the dataset path using the hf:// protocol.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hugging-face.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.scan_csv(\"hf://datasets/nameexhaustion/polars-docs/iris.csv\")\n```\n\n----------------------------------------\n\nTITLE: SQL CREATE TABLE Syntax in Polars\nDESCRIPTION: This snippet shows the general syntax for creating a table using SQL within Polars' SQLContext. It demonstrates the structure of a CREATE TABLE statement, which includes specifying the table name and a SELECT statement to define the data for the new table.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/create.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE table_name\nAS\nSELECT ...\n```\n\n----------------------------------------\n\nTITLE: Setting Compute Context with Labels in Python\nDESCRIPTION: Demonstrates how to initialize a ComputeContext object with workspace name and labels for organizing queries and compute resources. Labels are used for better organization and usage insights.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/workspace/settings.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nctx= plc.ComputeContext(\n    workspace=\"PolarsCloudDemo\",\n    labels=[\"marketing\", \"cltv\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Header Title to Styled Polars DataFrame\nDESCRIPTION: Demonstrates how to add a header title to a styled Polars DataFrame using the Great Tables library. This enhances the structure of the table for presentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngt.tab_header(title=\"Iris Dataset\")\n```\n\n----------------------------------------\n\nTITLE: Installing Polars Cloud with pip\nDESCRIPTION: Command to install both the Polars library and the Polars Cloud extension using pip package manager. This enables the distributed computing capabilities alongside the standard Polars functionality.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install polars polars_cloud\n```\n\n----------------------------------------\n\nTITLE: Renaming a Single Column with `alias`\nDESCRIPTION: Shows how to rename a single column using the `alias` function after applying an expression to it.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:alias\"\n```\n\n----------------------------------------\n\nTITLE: Opening and Reading from a Sheet in Google Colab\nDESCRIPTION: This snippet demonstrates how to open and read data from an existing Google Sheet using the `InteractiveSheet` class in Google Colab. It shows how to initialize the class with either the URL or the sheet ID of the Google Sheet and optionally specify a worksheet by ID or name. It requires the `google.colab` library to be installed.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Accessing Binary Methods in Polars Series\nDESCRIPTION: This code snippet demonstrates how to access binary methods on a Polars Series object. These methods are used for operations on binary data within a Series.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/binary.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nSeries.bin.contains\nSeries.bin.decode\nSeries.bin.encode\nSeries.bin.ends_with\nSeries.bin.reinterpret\nSeries.bin.size\nSeries.bin.starts_with\n```\n\n----------------------------------------\n\nTITLE: Floor Function in Polars SQL\nDESCRIPTION: Shows FLOOR function usage for rounding numbers down to nearest integer.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [0.1, 2.8, 4.30]})\ndf.sql(\"\"\"\n  SELECT a, FLOOR(a) AS floor_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Accessing InProcessQuery Namespace in Polars LazyFrame (Python)\nDESCRIPTION: This code snippet demonstrates how to access the InProcessQuery namespace in Polars. It is made available by calling the collect method on a LazyFrame instance with the background parameter set to True.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/in_process.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nLazyFrame.collect(background=True)\n```\n\n----------------------------------------\n\nTITLE: Python DataFrame Setup\nDESCRIPTION: Shows Python code for setting up a DataFrame with SQLContext for executing SQL queries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/select.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/sql/select.py:setup\"\n--8<-- \"python/user-guide/sql/select.py:df\"\n```\n\n----------------------------------------\n\nTITLE: Chaining Expression Functions on Selectors in Polars\nDESCRIPTION: Demonstrates how expression functions can be chained on top of selectors to perform operations on selected columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3],\n        \"b\": [\"a\", \"b\", \"c\"],\n        \"c\": [4.0, 5.0, 6.0],\n        \"d_high\": [1, 2, 3],\n        \"e_high\": [4, 5, 6],\n    }\n)\n\nprint(df.select(cs.numeric().sum()))\n```\n\n----------------------------------------\n\nTITLE: Using EXTRACT Function in Polars SQL\nDESCRIPTION: Shows how to extract decade, year, and quarter components from date values using the EXTRACT function. Creates a DataFrame with date values and demonstrates the EXTRACT syntax for temporal extraction.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/temporal.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"dt\": [\n      date(1969, 12, 31),\n      date(2026, 8, 22),\n      date(2077, 2, 10),\n    ],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    dt,\n    EXTRACT(decade FROM dt) AS decade,\n    EXTRACT(year FROM dt) AS year,\n    EXTRACT(quarter FROM dt) AS quarter,\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Calculating Standard Deviation with STDDEV in Polars SQL\nDESCRIPTION: Illustrates the usage of the STDDEV function to calculate the sample standard deviation of columns in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"foo\": [10, 20, 8],\n        \"bar\": [10, 7, 18],\n    }\n)\ndf.sql(\"\"\"\n  SELECT STDDEV(foo) AS foo_std, STDDEV(bar) AS bar_std FROM self\n\"\"\")\n# shape: (1, 2)\n# ┌──────────┬──────────┐\n# │ foo_std  ┆ bar_std  │\n# │ ---      ┆ ---      │\n# │ f64      ┆ f64      │\n# ╞══════════╪══════════╡\n# │ 6.429101 ┆ 5.686241 │\n# └──────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Computing Cotangent in Radians using COT\nDESCRIPTION: Demonstrates COT function to compute cotangent in radians for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"rads\": [-2.0, -1.0, 0.0, 1.0, 2.0]})\ndf.sql(\"SELECT rads, COT(rads) AS cot FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Basic Expression Creation in Polars\nDESCRIPTION: Creates a BMI calculation expression by dividing weight by height squared. Demonstrates how expressions are lazy and can be stored in variables.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/expressions-and-contexts.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npl.col(\"weight\") / (pl.col(\"height\") ** 2)\n```\n\n----------------------------------------\n\nTITLE: Importing GroupBy namespace in Polars\nDESCRIPTION: This code snippet shows how to access the GroupBy namespace in Polars. It becomes available after calling the group_by method on a DataFrame object.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/group_by.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nDataFrame.group_by(...)\n```\n\n----------------------------------------\n\nTITLE: Defining ComputeContext with Hardware Specifications in Polars Cloud\nDESCRIPTION: Creates a ComputeContext object with specific CPU and memory requirements. Polars Cloud will select an instance type that meets or exceeds these specifications.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nctx = ComputeContext(cpus=8, memory=\"32GB\")\n```\n\n----------------------------------------\n\nTITLE: Writing JSON with DataFrame in Python\nDESCRIPTION: Illustrates the updated behavior of DataFrame.write_json(), which now only writes row-oriented JSON and no longer supports serialization.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2], \"b\": [3.0, 4.0]})\ndf.write_json()\n```\n\n----------------------------------------\n\nTITLE: Executing Distributed Queries with LazyFrame in Python\nDESCRIPTION: Demonstrates how to use the distributed() method to execute queries using the distributed engine in Polars Cloud.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/distributed-engine.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlf: LazyFrame\n\nresult = (\n      lf.remote()\n      .distributed()\n      .collect()\n)\n```\n\n----------------------------------------\n\nTITLE: DataFrame Aggregation Method List in RST\nDESCRIPTION: Documentation structure for Polars DataFrame aggregation methods using reStructuredText format. Lists all available aggregation functions including count, max, mean, median, min, product, quantile, standard deviation, sum, and variance.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/aggregation.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    DataFrame.count\n    DataFrame.max\n    DataFrame.max_horizontal\n    DataFrame.mean\n    DataFrame.mean_horizontal\n    DataFrame.median\n    DataFrame.min\n    DataFrame.min_horizontal\n    DataFrame.product\n    DataFrame.quantile\n    DataFrame.std\n    DataFrame.sum\n    DataFrame.sum_horizontal\n    DataFrame.var\n```\n\n----------------------------------------\n\nTITLE: Using GROUP BY Clause in Polars SQL\nDESCRIPTION: Shows how to aggregate data using GROUP BY clause with aggregate functions\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n      \"foo\": [\"a\", \"b\", \"b\"],\n      \"bar\": [10, 20, 30],\n    }\n  )\ndf.sql(\"\"\"\n  SELECT foo, SUM(bar) FROM self GROUP BY foo\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Converting Radians to Degrees using DEGREES\nDESCRIPTION: Demonstrates conversion from radians to degrees using the DEGREES function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport math\n\ndf = pl.DataFrame({\"rads\": [0.0, math.pi/2, math.pi, 3*math.pi/2]})\ndf.sql(\"SELECT rads, DEGREES(rads) AS degs FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Specifying Organization for Workspace in Polars Cloud (Python)\nDESCRIPTION: Code example showing how to select a specific workspace by specifying the organization name when creating a Workspace object. This is useful when you have multiple workspaces with the same name across different organizations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/release-notes.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nworkspace = Workspace(\"my_workspace\", organization=\"my_organization\")\ncontext = ComputeContext(workspace=workspace)\n```\n\n----------------------------------------\n\nTITLE: Using Polars Config as a Function Decorator (Python)\nDESCRIPTION: Demonstrates how to use a Polars Config instance as a function decorator to temporarily set options for the duration of the function call. This example sets ASCII tables configuration.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/config.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ncfg_ascii_frames = pl.Config(ascii_tables=True, apply_on_context_enter=True)\n\n@cfg_ascii_frames\ndef write_markdown_frame_to_stdout(df: pl.DataFrame) -> None:\n    sys.stdout.write(str(df))\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with Optional Dependencies in Python\nDESCRIPTION: Example command to install Polars with optional dependencies using pip.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n# For example\npip install 'polars[numpy,fsspec]'\n```\n\n----------------------------------------\n\nTITLE: Listing Temporal Methods in Polars\nDESCRIPTION: This code snippet presents an autosummary of all available temporal methods under the expr.dt attribute in Polars. It includes methods for date and time manipulation, extraction of components, and various time-related calculations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/temporal.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Expr.dt.add_business_days\n    Expr.dt.base_utc_offset\n    Expr.dt.cast_time_unit\n    Expr.dt.century\n    Expr.dt.combine\n    Expr.dt.convert_time_zone\n    Expr.dt.date\n    Expr.dt.datetime\n    Expr.dt.day\n    Expr.dt.dst_offset\n    Expr.dt.epoch\n    Expr.dt.hour\n    Expr.dt.is_business_day\n    Expr.dt.is_leap_year\n    Expr.dt.iso_year\n    Expr.dt.microsecond\n    Expr.dt.millennium\n    Expr.dt.millisecond\n    Expr.dt.minute\n    Expr.dt.month\n    Expr.dt.month_end\n    Expr.dt.month_start\n    Expr.dt.nanosecond\n    Expr.dt.offset_by\n    Expr.dt.ordinal_day\n    Expr.dt.quarter\n    Expr.dt.replace\n    Expr.dt.replace_time_zone\n    Expr.dt.round\n    Expr.dt.second\n    Expr.dt.strftime\n    Expr.dt.time\n    Expr.dt.timestamp\n    Expr.dt.to_string\n    Expr.dt.total_days\n    Expr.dt.total_hours\n    Expr.dt.total_microseconds\n    Expr.dt.total_milliseconds\n    Expr.dt.total_minutes\n    Expr.dt.total_nanoseconds\n    Expr.dt.total_seconds\n    Expr.dt.truncate\n    Expr.dt.week\n    Expr.dt.weekday\n    Expr.dt.with_time_unit\n    Expr.dt.year\n```\n\n----------------------------------------\n\nTITLE: Defining dynamic output types for Polars expressions\nDESCRIPTION: This Rust code shows how to define dynamic output types for Polars expression plugins. It uses the `output_type_func` argument in the `polars_expr` macro to specify a function that maps input fields to an output field.  The `haversine_output` function uses `FieldsMapper` to determine the output data type based on the input.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nuse polars_plan::dsl::FieldsMapper;\n\nfn haversine_output(input_fields: &[Field]) -> PolarsResult<Field> {\n    FieldsMapper::new(input_fields).map_to_float_dtype()\n}\n\n#[polars_expr(output_type_func=haversine_output)]\nfn haversine(inputs: &[Series]) -> PolarsResult<Series> {\n    let out = match inputs[0].dtype() {\n        DataType::Float32 => {\n            let start_lat = inputs[0].f32().unwrap();\n            let start_long = inputs[1].f32().unwrap();\n            let end_lat = inputs[2].f32().unwrap();\n            let end_long = inputs[3].f32().unwrap();\n            crate::distances::naive_haversine(start_lat, start_long, end_lat, end_long)?\n                .into_series()\n        }\n        DataType::Float64 => {\n            let start_lat = inputs[0].f64().unwrap();\n            let start_long = inputs[1].f64().unwrap();\n            let end_lat = inputs[2].f64().unwrap();\n            let end_long = inputs[3].f64().unwrap();\n            crate::distances::naive_haversine(start_lat, start_long, end_lat, end_long)?\n                .into_series()\n        }\n        _ => polars_bail!(InvalidOperation: \"only supported for float types\"),\n    };\n    Ok(out)\n}\n```\n\n----------------------------------------\n\nTITLE: Using UPPER Function in Polars SQL\nDESCRIPTION: Demonstrates converting strings to uppercase using the UPPER function. This creates a new column with all characters in capital letters.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"apple\", \"banana\", \"orange\", \"grape\"]})\ndf.sql(\"\"\"\n  SELECT foo, UPPER(foo) AS foo_upper FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Listing Polars Computation Methods\nDESCRIPTION: This code snippet provides an autosummary of various computation methods available in the Polars library under the Expr class. These methods include mathematical functions, statistical operations, and data manipulation techniques.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/computation.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    Expr.abs\n    Expr.approx_n_unique\n    Expr.arccos\n    Expr.arccosh\n    Expr.arcsin\n    Expr.arcsinh\n    Expr.arctan\n    Expr.arctanh\n    Expr.arg_unique\n    Expr.bitwise_count_ones\n    Expr.bitwise_count_zeros\n    Expr.bitwise_leading_ones\n    Expr.bitwise_leading_zeros\n    Expr.bitwise_trailing_ones\n    Expr.bitwise_trailing_zeros\n    Expr.cbrt\n    Expr.cos\n    Expr.cosh\n    Expr.cot\n    Expr.cum_count\n    Expr.cum_max\n    Expr.cum_min\n    Expr.cum_prod\n    Expr.cum_sum\n    Expr.cumulative_eval\n    Expr.degrees\n    Expr.diff\n    Expr.dot\n    Expr.entropy\n    Expr.ewm_mean\n    Expr.ewm_mean_by\n    Expr.ewm_std\n    Expr.ewm_var\n    Expr.exp\n    Expr.hash\n    Expr.hist\n    Expr.index_of\n    Expr.kurtosis\n    Expr.log\n    Expr.log10\n    Expr.log1p\n    Expr.mode\n    Expr.n_unique\n    Expr.pct_change\n    Expr.peak_max\n    Expr.peak_min\n    Expr.radians\n    Expr.rank\n    Expr.rolling_kurtosis\n    Expr.rolling_map\n    Expr.rolling_max\n    Expr.rolling_max_by\n    Expr.rolling_mean\n    Expr.rolling_mean_by\n    Expr.rolling_median\n    Expr.rolling_median_by\n    Expr.rolling_min\n    Expr.rolling_min_by\n    Expr.rolling_quantile\n    Expr.rolling_quantile_by\n    Expr.rolling_skew\n    Expr.rolling_std\n    Expr.rolling_std_by\n    Expr.rolling_sum\n    Expr.rolling_sum_by\n    Expr.rolling_var\n    Expr.rolling_var_by\n    Expr.search_sorted\n    Expr.sign\n    Expr.sin\n    Expr.sinh\n    Expr.skew\n    Expr.sqrt\n    Expr.tan\n    Expr.tanh\n    Expr.unique\n    Expr.unique_counts\n    Expr.value_counts\n```\n\n----------------------------------------\n\nTITLE: Calculating String Length in Polars SQL\nDESCRIPTION: Shows how to use the LENGTH function to count the number of characters in a string. It also demonstrates the OCTET_LENGTH function to count the number of bytes, which can differ for non-ASCII characters.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"iso_lang\":[\"de\", \"ru\", \"es\"],\n    \"color\": [\"weiß\", \"синий\", \"amarillo\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    iso_lang,\n    color,\n    LENGTH(color) AS n_chars,\n    OCTET_LENGTH(color) AS n_bytes\n  FROM self\n\"\"\")\n\n# shape: (3, 4)\n# ┌──────────┬──────────┬─────────┬─────────┐\n# │ iso_lang ┆ color    ┆ n_chars ┆ n_bytes │\n# │ ---      ┆ ---      ┆ ---     ┆ ---     │\n# │ str      ┆ str      ┆ u32     ┆ u32     │\n# ╞══════════╪══════════╪═════════╪═════════╡\n# │ de       ┆ weiß     ┆ 4       ┆ 5       │\n# │ ru       ┆ синий    ┆ 5       ┆ 10      │\n# │ es       ┆ amarillo ┆ 8       ┆ 8       │\n# └──────────┴──────────┴─────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Performing BIT_OR operation in Polars SQL\nDESCRIPTION: This code snippet illustrates how to use the BIT_OR function and the '|' operator to perform bitwise OR operations on DataFrame columns using Polars SQL.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/bitwise.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n      \"i\": [3, 10, 4, 8],\n      \"j\": [4, 7, 9, 10],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    i,\n    j,\n    i | j AS i_bitor_op_j,\n    BIT_OR(i, j) AS i_bitor_j\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Listing Boolean Methods in Polars Expr Class\nDESCRIPTION: This code snippet lists the available boolean methods in the Polars Expr class. These methods include checks for null values, uniqueness, finiteness, and various other boolean operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/boolean.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nExpr.all\nExpr.any\nExpr.has_nulls\nExpr.is_between\nExpr.is_duplicated\nExpr.is_finite\nExpr.is_first_distinct\nExpr.is_in\nExpr.is_infinite\nExpr.is_last_distinct\nExpr.is_nan\nExpr.is_not_nan\nExpr.is_not_null\nExpr.is_null\nExpr.is_unique\nExpr.not_\n```\n\n----------------------------------------\n\nTITLE: PI Constant Function in Polars SQL\nDESCRIPTION: Demonstrates PI function that returns an approximation of π.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndf.sql(\"\"\"\n  SELECT PI() AS pi FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Printing the Schema\nDESCRIPTION: This snippet demonstrates how to use the `parse_schema` function and print the resulting schema. The `parse_schema` function is called with a sample CSV string, and the returned schema is then printed to the console. This helps visualize the structure inferred from the CSV data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/io_plugins.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> print(parse_schema(\"a,b,c\\n1,2,3\"))\nSchema([('a', String), ('b', String), ('c', String)])\n```\n\n----------------------------------------\n\nTITLE: Natural Logarithm Plus One Function (LOG1P) in Polars SQL\nDESCRIPTION: Demonstrates LOG1P function for calculating natural logarithm of value plus one.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, LOG1P(a) AS log1p_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Setting Polars Cloud Service Account Environment Variables\nDESCRIPTION: Configuration of environment variables required for service account authentication in Polars Cloud. Sets the client ID and client secret credentials obtained during service account creation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/service-accounts.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport POLARS_CLOUD_CLIENT_ID=\"CLIENT_ID_HERE\"\nexport POLARS_CLOUD_CLIENT_SECRET=\"CLIENT_SECRET_HERE\"\n```\n\n----------------------------------------\n\nTITLE: Setting Specific Instance Type for ComputeContext in Polars Cloud\nDESCRIPTION: Creates a ComputeContext object with a specific instance type. This provides precise control over the hardware used for query execution.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nctx = ComputeContext(instance_type=\"c5.4xlarge\")\n```\n\n----------------------------------------\n\nTITLE: Normalizing Unicode Strings in Polars SQL\nDESCRIPTION: Demonstrates the NORMALIZE function, which converts strings to a specified Unicode normalization form. This is useful for standardizing text representation, especially when dealing with international characters or special symbols.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\n    \"txt\": [\n        \"Ｔｅｓｔ\",\n        \"Ⓣⓔⓢⓣ\",\n        \"𝕿𝖊𝖘𝖙\",\n        \"𝕋𝕖𝕤𝕥\",\n        \"𝗧𝗲𝘀𝘁\",\n    ],\n})\ndf.sql(\"\"\"\n  SELECT NORMALIZE(txt, NFKC) FROM self\n\"\"\").to_series()\n# shape: (5,)\n# Series: 'txt' [str]\n# [\n#   \"Test\"\n#   \"Test\"\n#   \"Test\"\n#   \"Test\"\n#   \"Test\"\n# ]\n```\n\n----------------------------------------\n\nTITLE: Using LIMIT Clause in Polars SQL\nDESCRIPTION: Demonstrates limiting the number of returned rows using LIMIT clause\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"b\", \"a\", \"c\", \"b\"],\n    \"bar\": [20, 10, 40, 30],\n  }\n)\ndf.sql(\"\"\"\n  SELECT foo, bar FROM self LIMIT 2\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Writing a DataFrame to an Excel File with Polars in Python\nDESCRIPTION: This code snippet demonstrates how to write a Polars DataFrame to an Excel file using the write_excel method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n{{code_block('user-guide/io/excel','write',['write_excel'])}}\n```\n\n----------------------------------------\n\nTITLE: Creating a New Sheet in Google Colab\nDESCRIPTION: This snippet showcases creating a new Google Sheet when no source is provided to `InteractiveSheet`. This will result in the creation of a new, empty Google Sheet. Requires the `google.colab` library.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Listing Array Methods in Polars RST Documentation\nDESCRIPTION: This RST code snippet enumerates the array methods available under the expr.arr attribute in Polars. It uses autosummary to generate links to detailed API documentation for each method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/array.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Expr.arr.all\n    Expr.arr.any\n    Expr.arr.arg_max\n    Expr.arr.arg_min\n    Expr.arr.contains\n    Expr.arr.count_matches\n    Expr.arr.explode\n    Expr.arr.first\n    Expr.arr.get\n    Expr.arr.join\n    Expr.arr.last\n    Expr.arr.max\n    Expr.arr.median\n    Expr.arr.min\n    Expr.arr.n_unique\n    Expr.arr.reverse\n    Expr.arr.shift\n    Expr.arr.sort\n    Expr.arr.std\n    Expr.arr.sum\n    Expr.arr.to_list\n    Expr.arr.to_struct\n    Expr.arr.unique\n    Expr.arr.var\n```\n\n----------------------------------------\n\nTITLE: Unity Catalog Additional Classes and Methods in Python\nDESCRIPTION: This snippet lists additional classes and methods related to Unity catalogs, including CatalogInfo, ColumnInfo, DataSourceFormat, NamespaceInfo, and TableInfo with its associated method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/catalog/unity.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n   catalog.unity.CatalogInfo\n   catalog.unity.ColumnInfo\n   catalog.unity.DataSourceFormat\n   catalog.unity.NamespaceInfo\n   catalog.unity.TableInfo\n   catalog.unity.TableInfo.get_polars_schema\n   catalog.unity.TableType\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Enum Data Type in Polars\nDESCRIPTION: Demonstrates how to create an Enum data type, specify categories, and use it in a DataFrame. Shows error handling for invalid values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Create an Enum data type\nOperatingSystem = pl.Enum([\"Windows\", \"MacOS\", \"Linux\"])\n\n# Use the Enum in a DataFrame\ndf = pl.DataFrame(\n    {\n        \"user\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"os\": [\"Windows\", \"MacOS\", \"Linux\"],\n    },\n    schema={\"user\": pl.Utf8, \"os\": OperatingSystem},\n)\nprint(df)\n\n# This will raise an error due to invalid value\ntry:\n    df_invalid = pl.DataFrame(\n        {\n            \"user\": [\"Dave\"],\n            \"os\": [\"Android\"],  # Android is not in the Enum\n        },\n        schema={\"user\": pl.Utf8, \"os\": OperatingSystem},\n    )\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Selectors\nDESCRIPTION: Basic setup showing how to import Polars selectors and create a sample DataFrame for column selection operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/selectors.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars.selectors as cs\nimport polars as pl\n\ndf = pl.DataFrame(\n    {\n        \"w\": [\"xx\", \"yy\", \"xx\", \"yy\", \"xx\"],\n        \"x\": [1, 2, 1, 4, -2],\n        \"y\": [3.0, 4.5, 1.0, 2.5, -2.0],\n        \"z\": [\"a\", \"b\", \"a\", \"b\", \"b\"],\n    },\n)\ndf.group_by(cs.string()).agg(cs.numeric().sum())\n```\n\n----------------------------------------\n\nTITLE: Polars Module Root Functions\nDESCRIPTION: List of functions available in the Polars module root namespace. These functions can be used both as expressions and in eager contexts.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/functions.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nall\nall_horizontal\nany\nany_horizontal\napprox_n_unique\narange\narctan2\narctan2d\narg_sort_by\narg_where\nbusiness_day_count\ncoalesce\nconcat_arr\nconcat_list\nconcat_str\ncorr\ncount\ncov\ncum_count\ncum_fold\ncum_reduce\ncum_sum\ncum_sum_horizontal\ndate\ndate_range\ndate_ranges\ndatetime\ndatetime_range\ndatetime_ranges\nduration\nelement\nexclude\nfirst\nfold\nformat\nfrom_epoch\ngroups\nhead\nimplode\nint_range\nint_ranges\nlast\nlen\nlinear_space\nlinear_spaces\nlit\nmap_batches\nmap_groups\nmax\nmax_horizontal\nmean\nmean_horizontal\nmedian\nmin\nmin_horizontal\nn_unique\nnth\nones\nquantile\nreduce\nrepeat\nrolling_corr\nrolling_cov\nselect\nsql\nsql_expr\nstd\nstruct\nsum\nsum_horizontal\ntail\ntime\ntime_range\ntime_ranges\nvar\nwhen\nzeros\n```\n\n----------------------------------------\n\nTITLE: Creating Sample DataFrame in Polars\nDESCRIPTION: Creates a sample DataFrame with a numeric values column for demonstration purposes.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/user-defined-python-functions.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:setup\"\n--8<-- \"python/user-guide/expressions/user-defined-functions.py:dataframe\"\n```\n\n----------------------------------------\n\nTITLE: Updating DataFrame Pivot Operation in Python\nDESCRIPTION: Demonstrates the updated behavior of DataFrame.pivot() method, which now excludes redundant column names when pivoting by multiple values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"name\": [\"Cady\", \"Cady\", \"Karen\", \"Karen\"],\n        \"subject\": [\"maths\", \"physics\", \"maths\", \"physics\"],\n        \"test_1\": [98, 99, 61, 58],\n        \"test_2\": [100, 100, 60, 60],\n    }\n)\ndf.pivot('subject', index='name')\n```\n\n----------------------------------------\n\nTITLE: Loading Property Groups DataFrame in Python\nDESCRIPTION: This snippet demonstrates how to create a Polars DataFrame containing property names and their color groups for a Monopoly-like game.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nprops_groups = pl.DataFrame(\n    {\n        \"property\": [\"Mediterranean Avenue\", \"Baltic Avenue\", \"Reading Railroad\", \"Oriental Avenue\", \"The Shire\"],\n        \"group\": [\"Brown\", \"Brown\", \"Railroad\", \"Light Blue\", \"Magical Land\"],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Series with Explicit Data Type\nDESCRIPTION: Shows how to create a Series with an explicitly specified data type, overriding Polars' automatic type inference system.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ns = pl.Series(name=\"a\", values=[1, 2, 3, 4, 5], dtype=pl.Float32)\nprint(s)\n```\n\n----------------------------------------\n\nTITLE: Monopoly Players Data Setup\nDESCRIPTION: Creates sample dataframe of Monopoly players with their cash amounts for non-equi join example.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:players\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Polars in Rust with Cargo\nDESCRIPTION: This snippet shows how to reference Polars in a Rust project's Cargo.toml file. It demonstrates how to use the latest version from the main branch with an optional git tag.\nSOURCE: https://github.com/pola-rs/polars/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\npolars = { git = \"https://github.com/pola-rs/polars\", rev = \"<optional git tag>\" }\n```\n\n----------------------------------------\n\nTITLE: Interactive Mode Extended Query Results\nDESCRIPTION: Shows how to print results from a follow-up query in interactive mode\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/interactive-batch.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprint(res2.collect())\n```\n\n----------------------------------------\n\nTITLE: Generated Parquet Files - Polars - Text\nDESCRIPTION: This text snippet shows the file names generated by the `sink_parquet` method with the `PartitionMaxSize` partitioning strategy.  It demonstrates the naming convention where each file is named `my_table_{part}.parquet`, with `{part}` being an incremental index.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/sources_sinks.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nmy_table_0.parquet\nmy_table_1.parquet\n...\nmy_table_n.parquet\n```\n\n----------------------------------------\n\nTITLE: Power Function (POW) in Polars SQL\nDESCRIPTION: Shows POW function usage for calculating power of numbers. Also aliased as POWER.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"x\": [0, 1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT x, POW(x, 8) AS x_pow_8 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Stock Quotes Data Setup\nDESCRIPTION: Creates sample dataframe of stock quotes for asof join example.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:df_quotes\"\n```\n\n----------------------------------------\n\nTITLE: Calculating Sum with SUM in Polars SQL\nDESCRIPTION: Demonstrates how to use the SUM function to calculate the sum of columns in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"foo\": [1, 2, 3],\n        \"bar\": [6, 7, 8],\n        \"ham\": [\"a\", \"b\", \"c\"],\n    }\n)\ndf.sql(\"\"\"\n  SELECT SUM(foo) AS foo_sum, SUM(bar) AS bar_sum FROM self\n\"\"\")\n# shape: (1, 2)\n# ┌─────────┬─────────┐\n# │ foo_sum ┆ bar_sum │\n# │ ---     ┆ ---     │\n# │ i64     ┆ i64     │\n# ╞═════════╪═════════╡\n# │ 6       ┆ 21      │\n# └─────────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Registering Custom Expr Namespace in Polars\nDESCRIPTION: Demonstrates how to create a custom 'greetings' namespace for Polars expressions that adds hello and goodbye greeting functionality to strings.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/api.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@pl.api.register_expr_namespace(\"greetings\")\nclass Greetings:\n    def __init__(self, expr: pl.Expr) -> None:\n        self._expr = expr\n\n    def hello(self) -> pl.Expr:\n        return (pl.lit(\"Hello \") + self._expr).alias(\"hi there\")\n\n    def goodbye(self) -> pl.Expr:\n        return (pl.lit(\"Sayōnara \") + self._expr).alias(\"bye\")\n\n\npl.DataFrame(data=[\"world\", \"world!\", \"world!!\"]).select(\n    [\n        pl.all().greetings.hello(),\n        pl.all().greetings.goodbye(),\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Updated Error Types in Polars Python API\nDESCRIPTION: Shows how error types have been updated to more accurately represent the underlying issues, particularly changing ComputeError types to more specific error types like InvalidOperationError or SchemaError.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series(\"a\", [100, 200, 300])\ns.cast(pl.UInt8)\nTraceback (most recent call last):\n...\npolars.exceptions.ComputeError: conversion from `i64` to `u8` failed in column 'a' for 1 out of 3 values: [300]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns.cast(pl.UInt8)\nTraceback (most recent call last):\n...\npolars.exceptions.InvalidOperationError: conversion from `i64` to `u8` failed in column 'a' for 1 out of 3 values: [300]\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with pip\nDESCRIPTION: This command installs the Polars library using pip, the Python package installer. It is the standard way to install Polars in a Python environment.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/getting-started.md#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\npip install polars\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Data Types for Column Selection\nDESCRIPTION: Shows how to specify multiple data types for column selection, expanding the expression to columns matching any of the given types.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:col-with-dtypes\"\n```\n\n----------------------------------------\n\nTITLE: Printing Non-Optimized Polars Query Plan\nDESCRIPTION: This snippet prints the non-optimized query plan as text. It provides a detailed explanation of each step in the query execution process.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/query-plan.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(q.explain(optimized=False))\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Value with MAX in Polars SQL\nDESCRIPTION: Demonstrates the use of the MAX function to find the greatest value in a column of a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [20, 10, 30, 40]})\ndf.sql(\"\"\"\n  SELECT MAX(bar) AS bar_max FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌─────────┐\n# │ bar_max │\n# │ ---     │\n# │ i64     │\n# ╞═════════╡\n# │ 40      │\n# └─────────┘\n```\n\n----------------------------------------\n\nTITLE: Demonstrating EXCEPT Operation in Polars SQL\nDESCRIPTION: This snippet shows how to use the EXCEPT operation to combine two SELECT statements, returning only the rows that appear in the first result set but not in the second. It uses Polars LazyFrames and the SQL interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/set_operations.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlf1 = pl.LazyFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n})\nlf2 = pl.LazyFrame({\n    \"id\": [2, 3, 4],\n    \"age\": [30, 25, 45],\n    \"name\": [\"Bob\", \"Charlie\", \"David\"],\n})\npl.sql(\"\"\"\n    SELECT id, name FROM lf1\n    EXCEPT\n    SELECT id, name FROM lf2\n\"\"\").sort(by=\"id\").collect()\n# shape: (1, 2)\n# ┌─────┬───────┐\n# │ id  ┆ name  │\n# │ --- ┆ ---   │\n# │ i64 ┆ str   │\n# ╞═════╪═══════╡\n# │ 1   ┆ Alice │\n# └─────┴───────┘\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests with Pytest in Polars\nDESCRIPTION: Commands for running unit tests in Polars. Shows how to run tests with different markers and in parallel using pytest.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/test.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npytest -m slow\n```\n\nLANGUAGE: bash\nCODE:\n```\npytest -m ci_only\n```\n\nLANGUAGE: bash\nCODE:\n```\npytest -m slow ci_only\n```\n\nLANGUAGE: bash\nCODE:\n```\npytest -m \"\"\n```\n\nLANGUAGE: bash\nCODE:\n```\npytest -n auto\n```\n\n----------------------------------------\n\nTITLE: Multiprocessing Deadlock Example\nDESCRIPTION: This code snippet demonstrates a potential deadlock situation when using the 'fork' multiprocessing start method with Polars. The `pl.read_parquet` function acquires a file lock, and when `os.fork()` is called, the child processes inherit the acquired file lock, causing them to hang indefinitely waiting for the lock to be released.  Using 'spawn' instead of 'fork' would resolve this issue.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/multiprocessing.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport multiprocessing as mp\nimport os\nimport time\n\nimport polars as pl\n\n\ndef run(i: int) -> None:\n    print(f'{i=}: {os.getpid()=}')\n    df = pl.read_parquet('filename.parquet')\n    print(f'{i=}: {df.shape=}')\n\n\nif __name__ == '__main__':\n    mp.set_start_method('fork')\n\n    t0 = time.time()\n    processes = []\n    for i in range(4):\n        p = mp.Process(target=run, args=(i,))\n        processes.append(p)\n\n    for p in processes:\n        p.start()\n\n    for p in processes:\n        p.join()\n\n    print(f'Duration: {time.time() - t0}')\n\n```\n\n----------------------------------------\n\nTITLE: Documenting LazyFrame.describe Method in Python\nDESCRIPTION: This snippet documents the 'describe' method of the LazyFrame class in Polars. It is likely used to generate summary statistics for the LazyFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/descriptive.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nLazyFrame.describe\n```\n\n----------------------------------------\n\nTITLE: Applying ComputeContext to Remote Query in Polars Cloud\nDESCRIPTION: Demonstrates how to apply a ComputeContext directly to a remote query execution. This method allows for per-query context specification.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nquery.remote(context=ctx).sink_parquet(...)\n```\n\n----------------------------------------\n\nTITLE: Computing Cosine in Radians using COS\nDESCRIPTION: Demonstrates COS function to compute cosine in radians for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"rads\": [-2.0, -1.0, 0.0, 1.0, 2.0]})\ndf.sql(\"SELECT rads, COS(rads) AS cos FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Running Polars Pre-commit Checks in Bash\nDESCRIPTION: Command to run pre-commit checks for formatting and linting using Make.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake pre-commit\n```\n\n----------------------------------------\n\nTITLE: Listing Polars DataFrame Descriptive Methods\nDESCRIPTION: This code snippet lists various descriptive methods available for Polars DataFrames. These methods include functionality for approximating unique values, describing the DataFrame, estimating size, checking for duplicates and uniqueness, counting null values, and more.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/descriptive.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    DataFrame.approx_n_unique\n    DataFrame.describe\n    DataFrame.estimated_size\n    DataFrame.glimpse\n    DataFrame.is_duplicated\n    DataFrame.is_empty\n    DataFrame.is_unique\n    DataFrame.n_chunks\n    DataFrame.n_unique\n    DataFrame.null_count\n```\n\n----------------------------------------\n\nTITLE: Using GPUEngine with LazyFrame.collect()\nDESCRIPTION: Code example showing how to reference the GPUEngine configuration object in the polars.lazyframe.engine_config module. This object allows fine-grained control over GPU processing behavior when executing lazy computations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/gpu_engine.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom polars.lazyframe.engine_config import GPUEngine\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Changed Count Behavior for Null Values in Polars 0.20\nDESCRIPTION: Shows how the count method now ignores null values, consistent with SQL standards. To maintain the previous behavior of counting all values including nulls, use the len method instead.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ndf = pl.DataFrame({\"a\": [1, 2, None]})\ndf.select(pl.col(\"a\").count())\n# Counted nulls\n\n# After:\ndf.select(pl.col(\"a\").count())\n# Ignores nulls\ndf.select(pl.col(\"a\").len())  # Mirrors previous behavior\n```\n\n----------------------------------------\n\nTITLE: Setting Up Cloud Execution Context\nDESCRIPTION: Configures and executes the query in the cloud environment using Polars Cloud ComputeContext with specified resource allocations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars_cloud as pc\n\nctx = pc.ComputeContext(\n    workspace=\"environmental-analysis\",\n    memory=32,\n    cpus=8\n)\n\nquery.remote(context=ctx).sink_parquet(\"s3://bucket/result.parquet\")\n```\n\n----------------------------------------\n\nTITLE: Listing String Manipulation Methods in Polars\nDESCRIPTION: This code snippet lists all the available string manipulation methods in Polars under the expr.str attribute. These methods cover various operations such as concatenation, pattern matching, extraction, transformation, and formatting of string data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/string.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nExpr.str.concat\nExpr.str.contains\nExpr.str.contains_any\nExpr.str.count_matches\nExpr.str.decode\nExpr.str.encode\nExpr.str.ends_with\nExpr.str.escape_regex\nExpr.str.explode\nExpr.str.extract\nExpr.str.extract_all\nExpr.str.extract_groups\nExpr.str.extract_many\nExpr.str.find\nExpr.str.find_many\nExpr.str.head\nExpr.str.join\nExpr.str.json_decode\nExpr.str.json_path_match\nExpr.str.len_bytes\nExpr.str.len_chars\nExpr.str.normalize\nExpr.str.pad_end\nExpr.str.pad_start\nExpr.str.replace\nExpr.str.replace_all\nExpr.str.replace_many\nExpr.str.reverse\nExpr.str.slice\nExpr.str.split\nExpr.str.split_exact\nExpr.str.splitn\nExpr.str.starts_with\nExpr.str.strip_chars\nExpr.str.strip_chars_start\nExpr.str.strip_chars_end\nExpr.str.strip_prefix\nExpr.str.strip_suffix\nExpr.str.strptime\nExpr.str.tail\nExpr.str.to_date\nExpr.str.to_datetime\nExpr.str.to_decimal\nExpr.str.to_integer\nExpr.str.to_lowercase\nExpr.str.to_time\nExpr.str.to_titlecase\nExpr.str.to_uppercase\nExpr.str.zfill\n```\n\n----------------------------------------\n\nTITLE: Example Release Commit Message in Markdown\nDESCRIPTION: Provides a specific example of a commit message for releasing Python Polars version 0.16.1.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n`release(python): Python Polars 0.16.1`\n```\n\n----------------------------------------\n\nTITLE: Using Polars Config as a Context Manager with Direct Initialization (Python)\nDESCRIPTION: Shows a cleaner way to use the Polars Config class as a context manager by setting options directly in the Config initialization, omitting the 'set_' prefix for brevity.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/config.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith pl.Config(verbose=True):\n    do_various_things()\n```\n\n----------------------------------------\n\nTITLE: Documenting LazyFrame.show_graph Method in Python\nDESCRIPTION: This snippet documents the 'show_graph' method of the LazyFrame class in Polars. It likely generates a visual representation of the LazyFrame's execution plan or structure.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/descriptive.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nLazyFrame.show_graph\n```\n\n----------------------------------------\n\nTITLE: Generating Query Plan Graph\nDESCRIPTION: Creates a visualization of the query plan showing how files are read and concatenated.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/multiple.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/multiple.py:creategraph\"\n```\n\n----------------------------------------\n\nTITLE: Ordered Enum Example with Log Levels in Polars\nDESCRIPTION: Shows how to create an ordered Enum for log levels and perform comparisons based on the specified order.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Create an ordered Enum for log levels\nLogLevel = pl.Enum([\"debug\", \"info\", \"warning\", \"error\"])\n\n# Create a DataFrame with log levels\ndf = pl.DataFrame(\n    {\n        \"message\": [\"System started\", \"User login\", \"Connection lost\", \"Data corrupted\"],\n        \"level\": [\"info\", \"debug\", \"warning\", \"error\"],\n    },\n    schema={\"message\": pl.Utf8, \"level\": LogLevel},\n)\n\n# Filter based on log level\nprint(df.filter(pl.col(\"level\") >= \"warning\"))\n```\n\n----------------------------------------\n\nTITLE: Type Annotation with Re-exported Type Alias (Before)\nDESCRIPTION: Example showing how type annotations previously could use re-exported type aliases from the top-level polars namespace.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_31\n\nLANGUAGE: python\nCODE:\n```\ndef foo(dtype: pl.PolarsDataType) -> None: ...\n```\n\n----------------------------------------\n\nTITLE: SHOW TABLES SQL Syntax in Polars\nDESCRIPTION: This snippet shows the simple syntax for the SHOW TABLES statement in Polars SQL. It is used to list all tables registered in the current SQLContext.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/show.md#2025-04-22_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSHOW TABLES\n```\n\n----------------------------------------\n\nTITLE: Installing SQLAlchemy Dependencies - Shell\nDESCRIPTION: Command to install SQLAlchemy and Pandas packages for database operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install SQLAlchemy pandas\n```\n\n----------------------------------------\n\nTITLE: Pandas Pipe Pattern Example\nDESCRIPTION: Demonstrates the traditional pandas pipe pattern which applies sequential transformations to a DataFrame, showing a pattern that should be avoided in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef add_foo(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"foo\"] = ...\n    return df\n\ndef add_bar(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"bar\"] = ...\n    return df\n\n\ndef add_ham(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"ham\"] = ...\n    return df\n\n(df\n .pipe(add_foo)\n .pipe(add_bar)\n .pipe(add_ham)\n)\n```\n\n----------------------------------------\n\nTITLE: Using RTRIM Function in Polars SQL\nDESCRIPTION: Demonstrates how to remove whitespace from the right side of strings using the RTRIM function, which is useful for cleaning up data with trailing spaces.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"bar\": [\"zz    \", \"yy  \", \"xx \", \"ww   \"]})\ndf.sql(\"\"\"\n  SELECT bar, RTRIM(bar) AS baz FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Custom Base Logarithm Function (LOG) in Polars SQL\nDESCRIPTION: Shows LOG function usage for calculating logarithms with custom bases.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, LOG(a, 16) AS log16_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Converting Strings to Lowercase in Polars SQL\nDESCRIPTION: Demonstrates the LOWER function, which converts all characters in a string to lowercase. This is useful for case-insensitive comparisons or standardization.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"AA\", \"BB\", \"CC\", \"DD\"]})\ndf.sql(\"\"\"\n  SELECT foo, LOWER(foo) AS foo_lower FROM self\n\"\"\")\n# shape: (4, 2)\n# ┌─────┬───────────┐\n# │ foo ┆ foo_lower │\n# │ --- ┆ ---       │\n# │ str ┆ str       │\n# ╞═════╪═══════════╡\n# │ AA  ┆ aa        │\n# │ BB  ┆ bb        │\n# │ CC  ┆ cc        │\n# │ DD  ┆ dd        │\n# └─────┴───────────┘\n```\n\n----------------------------------------\n\nTITLE: Renaming Fields in a Struct Column in Polars\nDESCRIPTION: Shows how to use the rename_fields() function to change the names of specific fields within a Struct column while preserving the data structure.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:series_struct_rename\"\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Array Value with ARRAY_UPPER in Polars SQL\nDESCRIPTION: Shows the usage of ARRAY_UPPER function to find the maximum value in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[5, 0], [4, 8, -2]]})\ndf.sql(\"\"\"\n  SELECT foo, ARRAY_UPPER(foo) AS max_elem FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌────────────┬──────────┐\n# │ foo        ┆ max_elem │\n# │ ---        ┆ ---      │\n# │ list[i64]  ┆ i64      │\n# ╞════════════╪══════════╡\n# │ [5, 0]     ┆ 5        │\n# │ [4, 8, -2] ┆ 8        │\n# └────────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Setting up a Polars expression library with Cargo\nDESCRIPTION: This `Cargo.toml` file defines the dependencies and build configuration for a Polars expression plugin library. It specifies the library name, version, edition, and crate type as `cdylib`, which is required for dynamic linking. Dependencies include `polars`, `pyo3`, `pyo3-polars`, and `serde`.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[package]\nname = \"expression_lib\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\nname = \"expression_lib\"\ncrate-type = [\"cdylib\"]\n\n[dependencies]\npolars = { version = \"*\" }\npyo3 = { version = \"*\", features = [\"extension-module\", \"abi3-py38\"] }\npyo3-polars = { version = \"*\", features = [\"derive\"] }\nserde = { version = \"*\", features = [\"derive\"] }\n```\n\n----------------------------------------\n\nTITLE: Package Name Reference in Markdown\nDESCRIPTION: Reference to the polars-compute package name within markdown documentation, highlighting its internal nature and relationship to the main Polars library.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-compute/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\npolars-compute\n```\n\n----------------------------------------\n\nTITLE: Polars Panic Exception List\nDESCRIPTION: ReStructuredText documentation listing the panic exception class in the polars.exceptions module\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/exceptions.rst#2025-04-22_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    PanicException\n```\n\n----------------------------------------\n\nTITLE: Updating Polars Fork in Bash\nDESCRIPTION: Commands to update the local fork with changes from the upstream Polars repository.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout main\ngit fetch upstream\ngit rebase upstream/main\ngit push origin main\n```\n\n----------------------------------------\n\nTITLE: Polars Sum Aggregation - Vertical Computation (After)\nDESCRIPTION: Illustrates the new default behavior of `pl.sum` in Polars version 0.19, which performs vertical computation. The function now sums the columns individually. This example shows how to achieve vertical aggregation after the change.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n>>> df = pl.DataFrame({'a': [1, 2], 'b': [11, 12]})\n>>> df.select(pl.sum('a', 'b'))  # vertical computation\nshape: (1, 2)\n┌─────┬─────┐\n│ a   ┆ b   │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 3   ┆ 23  │\n└─────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with Big Index Support for Python\nDESCRIPTION: Command to install Polars with big index support, allowing for up to 2^64 rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install polars-u64-idx\n```\n\n----------------------------------------\n\nTITLE: Accessing Polars Metadata Functions in Python\nDESCRIPTION: This code snippet demonstrates how to import and use various metadata functions from the Polars library. These functions provide information about the library's build, index types, versions, and thread pool configuration.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/metadata.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n\n.. autosummary::\n   :toctree: api/\n\n    build_info\n    get_index_type\n    show_versions\n    thread_pool_size\n    threadpool_size\n```\n\n----------------------------------------\n\nTITLE: Cube Root Function (CBRT) in Polars SQL\nDESCRIPTION: Shows usage of CBRT function for calculating the cube root of numbers. Returns floating point results.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1.0, 2.0, 4.0]})\ndf.sql(\"\"\"\n  SELECT a, CBRT(a) AS cbrt_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Referencing Polars Core Package\nDESCRIPTION: Code reference showing the internal package name polars-core within backticks, used in the documentation to identify the core package.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-core/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`polars-core`\n```\n\n----------------------------------------\n\nTITLE: Reading Excel Files with Specific Engine in Python\nDESCRIPTION: Demonstrates how to use the xlsx2csv engine when reading Excel files to maintain previous behavior, as the default engine has changed to calamine.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\npl.read_excel(\"data.xlsx\", engine=\"xlsx2csv\", engine_options={\"skip_empty_lines\": True})\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Fundamental Difference Between Polars and Pandas in Python\nDESCRIPTION: A simple code snippet showing that Polars and Pandas are not interchangeable, emphasizing the need for different coding approaches.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npolars != pandas\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Ackermann Function in Python\nDESCRIPTION: Implements the Ackermann mathematical function in Python, which will be used to demonstrate applying custom functions to Struct columns in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:ack\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Hidden HTML Div for Polars Documentation Index\nDESCRIPTION: Creates a hidden HTML div containing the 'Index' title for the Polars documentation. This div is likely used for formatting or structural purposes in the rendered documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div style=\"visibility: hidden;\">\n\n=====\nIndex\n=====\n</div>\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Development Dependencies\nDESCRIPTION: Specifies exact versions of Python development tools including mypy with faster-cache option, ruff linter, and typos checker.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/requirements-lint.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nmypy[faster-cache]==1.14.1\nruff==0.9.4\ntypos==1.29.0\n```\n\n----------------------------------------\n\nTITLE: Defining Category Methods in Polars Documentation\nDESCRIPTION: RestructuredText documentation snippet listing the available categorical expression methods under expr.cat in Polars, including string operations like ends_with, starts_with, and category management functions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/categories.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Expr.cat.ends_with\n    Expr.cat.get_categories\n    Expr.cat.len_bytes\n    Expr.cat.len_chars\n    Expr.cat.starts_with\n```\n\n----------------------------------------\n\nTITLE: Importing Polars in Python\nDESCRIPTION: Python code to import the Polars library.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n```\n\n----------------------------------------\n\nTITLE: Type Checking in Lazy API\nDESCRIPTION: Shows how type checking works in lazy API by attempting to round a string column, which will raise an InvalidOperationError.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/schemas.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/lazy/schema.py:lazyround\"\n--8<-- \"python/user-guide/lazy/schema.py:typecheck\"\n```\n\n----------------------------------------\n\nTITLE: Ceiling Function (CEIL) in Polars SQL\nDESCRIPTION: Demonstrates the CEIL function which rounds numbers up to the nearest integer. Also aliased as CEILING.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [0.1, 2.8, 4.30]})\ndf.sql(\"\"\"\n  SELECT a, CEIL(a) AS ceil_a FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Handling Overflow in Numeric Type Casting\nDESCRIPTION: Shows how Polars handles numeric overflow during downcasting operations when strict mode is enabled vs disabled.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1000]})\ndf.with_columns([pl.col(\"a\").cast(pl.Int8)])\n```\n\n----------------------------------------\n\nTITLE: Creating DataFrame with Missing Data in Polars\nDESCRIPTION: Demonstrates how to create a DataFrame with null values in Polars. This example shows how missing data is represented using null for all data types.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, None, 4, 5],\n        \"b\": [\"a\", \"b\", \"c\", None, \"e\"],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Integer Division Function (DIV) in Polars SQL\nDESCRIPTION: Shows DIV function usage for integer division operations returning the quotient.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [-10.0, 6.5, 25.0]})\ndf.sql(\"\"\"\n  SELECT a, DIV(a, 2) AS a_div_2, DIV(a, 5) AS a_div_5 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Polars Errors Class List\nDESCRIPTION: ReStructuredText documentation listing all error classes in the polars.exceptions module\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/exceptions.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    PolarsError\n    ColumnNotFoundError\n    ComputeError\n    DuplicateError\n    InvalidOperationError\n    ModuleUpgradeRequiredError\n    NoDataError\n    NoRowsReturnedError\n    OutOfBoundsError\n    ParameterCollisionError\n    RowsError\n    SQLInterfaceError\n    SQLSyntaxError\n    SchemaError\n    SchemaFieldNotFoundError\n    ShapeError\n    StringCacheMismatchError\n    StructFieldNotFoundError\n    TooManyRowsReturnedError\n    UnsuitableSQLError\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Array Operations and Parquet Writing in Rust with polars_arrow\nDESCRIPTION: This code snippet showcases the creation of Int32Arrays, performing computations, declaring a schema, creating a chunk, and writing data to a Parquet file using the polars_arrow library. It demonstrates the library's efficiency in handling nullable operations and writing to Parquet format.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/doc/lib.md#2025-04-22_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nuse std::sync::Arc;\n\nuse polars_arrow::array::*;\nuse polars_arrow::datatypes::{Field, DataType, Schema};\nuse polars_arrow::compute::arithmetics;\nuse polars_arrow::error::Result;\nuse polars_arrow::io::parquet::write::*;\nuse polars_arrow::chunk::Chunk;\n\nfn main() -> Result<()> {\n    // declare arrays\n    let a = Int32Array::from(&[Some(1), None, Some(3)]);\n    let b = Int32Array::from(&[Some(2), None, Some(6)]);\n\n    // compute (probably the fastest implementation of a nullable op you can find out there)\n    let c = arithmetics::basic::mul_scalar(&a, &2);\n    assert_eq!(c, b);\n\n    // declare a schema with fields\n    let schema = Schema::from(vec![\n        Field::new(\"c1\", DataType::Int32, true),\n        Field::new(\"c2\", DataType::Int32, true),\n    ]);\n\n    // declare chunk\n    let chunk = Chunk::new(vec![a.arced(), b.arced()]);\n\n    // write to parquet (probably the fastest implementation of writing to parquet out there)\n\n    let options = WriteOptions {\n        write_statistics: true,\n        compression: CompressionOptions::Snappy,\n        version: Version::V1,\n        data_page_size: None,\n    };\n\n    let row_groups = RowGroupIterator::try_new(\n        vec![Ok(chunk)].into_iter(),\n        &schema,\n        options,\n        vec![vec![Encoding::Plain], vec![Encoding::Plain]],\n    )?;\n\n    // anything implementing `std::io::Write` works\n    let mut file = vec![];\n\n    let mut writer = FileWriter::try_new(file, schema, options)?;\n\n    // Write the file.\n    for group in row_groups {\n        writer.write(group?)?;\n    }\n    let _ = writer.end(None)?;\n    Ok(())\n}\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Structure for LazyFrame\nDESCRIPTION: ReStructuredText documentation layout defining the structure and organization of LazyFrame documentation including table of contents and class autodoc directives.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=========\nLazyFrame\n=========\n\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   aggregation\n   attributes\n   descriptive\n   group_by\n   modify_select\n   miscellaneous\n   in_process\n   gpu_engine\n\n.. _lazyframe:\n\n.. currentmodule:: polars\n\n.. autoclass:: LazyFrame\n    :members:\n    :noindex:\n    :autosummary:\n    :autosummary-nosignatures:\n```\n\n----------------------------------------\n\nTITLE: Executing BIT_XOR operation in Polars SQL\nDESCRIPTION: This example shows how to use the BIT_XOR function and the 'XOR' operator to perform bitwise XOR operations on DataFrame columns using Polars SQL.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/bitwise.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n      \"i\": [3, 10, 4, 8],\n      \"j\": [4, 7, 9, 10],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    i,\n    j,\n    i XOR j AS i_bitxor_op_j,\n    BIT_XOR(i, j) AS i_bitxor_j\n  FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: RST Documentation for Polars Data Types\nDESCRIPTION: ReStructuredText documentation defining the data type categories and their implementations in Polars. Includes numeric types (like Float32, Int64), temporal types (Date, Datetime), nested types (Array, Struct), string types (String, Categorical), and other fundamental types (Boolean, Null).\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/datatypes.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n==========\nData types\n==========\n.. currentmodule:: polars.datatypes\n\nDataType\n~~~~~~~~\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    DataType\n\nNumeric\n~~~~~~~\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    Decimal\n    Float32\n    Float64\n    Int8\n    Int16\n    Int32\n    Int64\n    Int128\n    UInt8\n    UInt16\n    UInt32\n    UInt64\n\nTemporal\n~~~~~~~~~~~\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    Date\n    Datetime\n    Duration\n    Time\n\nNested\n~~~~~~\n.. autosummary::\n    :toctree: api/\n\n    Array\n    List\n    Field\n    Struct\n\nString\n~~~~~~\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    String\n    Categorical\n    Enum\n    Utf8\n\nOther\n~~~~~\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    Binary\n    Boolean\n    Null\n    Object\n    Unknown\n```\n\n----------------------------------------\n\nTITLE: Installing ConnectorX Package - Shell\nDESCRIPTION: Command to install the ConnectorX package for database connectivity.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/database.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install connectorx\n```\n\n----------------------------------------\n\nTITLE: Installing Google BigQuery Dependencies for Polars\nDESCRIPTION: Command to install the required Google BigQuery Python package for Polars integration using pip package manager.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/bigquery.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install google-cloud-bigquery\n```\n\n----------------------------------------\n\nTITLE: Base-2 Logarithm Function (LOG2) in Polars SQL\nDESCRIPTION: Demonstrates LOG2 function for calculating logarithms in base 2.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 4]})\ndf.sql(\"\"\"\n  SELECT a, LOG2(a) AS a_log2 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Expression List After Expansion\nDESCRIPTION: Shows how a single expression with multiple column names expands into a list of individual expressions, one per column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:expression-list\"\n```\n\n----------------------------------------\n\nTITLE: Basic Numeric Type Casting in Polars\nDESCRIPTION: Shows casting between float and integer data types in a Polars DataFrame. Demonstrates how floating point numbers are truncated when cast to integers.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/casting.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"ints\": [1, 2, 3], \"floats\": [1.0, 2.5, 3.7]})\ndf.with_columns([\n    pl.col(\"floats\").cast(pl.Int64).alias(\"floats_as_ints\"),\n    pl.col(\"ints\").cast(pl.Float64).alias(\"ints_as_floats\"),\n])\n```\n\n----------------------------------------\n\nTITLE: Demonstrating DataType Instantiation Changes in Polars 0.20\nDESCRIPTION: Shows how DataType objects are now consistently instantiated, making their behavior more predictable. This affects type checking and type hints in code that uses Polars data types.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1, 2, 3], dtype=pl.Int8)\ns.dtype == pl.Int8  # True\ns.dtype is pl.Int8  # True\nisinstance(s.dtype, pl.Int8)  # False\n\n# After:\ns.dtype == pl.Int8  # True\ns.dtype is pl.Int8  # False\nisinstance(s.dtype, pl.Int8)  # True\n```\n\n----------------------------------------\n\nTITLE: DataFrame.sql with Restricted Access (After)\nDESCRIPTION: Example showing how DataFrame.sql now throws an error when attempting to access global variables, enforcing the principle that DataFrame.sql should only operate on the frame itself.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_29\n\nLANGUAGE: python\nCODE:\n```\n>>> df1.sql(\"SELECT * FROM df1 CROSS JOIN df2\")\nTraceback (most recent call last):\n...\npolars.exceptions.SQLInterfaceError: relation 'df1' was not found\n```\n\n----------------------------------------\n\nTITLE: Styling RST Documentation for SQL Functions in Polars\nDESCRIPTION: This HTML snippet applies custom styling to hide the first child of list items with the class 'toctree-l1' within the documentation structure.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<style>\n  div.sd-card-body.docutils li.toctree-l1 > :first-child {display: none;}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Defining LazyFrame Documentation Structure in RST\nDESCRIPTION: ReStructuredText documentation defining the available attributes for LazyFrame objects in Polars library, including the module reference and autosummary directive\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/attributes.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    LazyFrame.columns\n    LazyFrame.dtypes\n    LazyFrame.schema\n    LazyFrame.width\n```\n\n----------------------------------------\n\nTITLE: Importing polars-sql in Rust Code\nDESCRIPTION: Demonstrates how to import the polars-sql crate in Rust code. This allows access to the SQL transpiler functionality provided by the crate.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-sql/README.md#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse polars_sql::*;\n```\n\n----------------------------------------\n\nTITLE: Using SELECT Clause in Polars SQL\nDESCRIPTION: Demonstrates how to select specific columns from a Polars DataFrame using SQL syntax\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"a\": [1, 2, 3],\n    \"b\": [\"zz\", \"yy\", \"xx\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT a, b FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Filling Missing Values with Literals in Polars\nDESCRIPTION: Shows how to use fill_null to replace missing values with a specified literal value. The literal value replaces all occurrences of null in the selected column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Fill the nulls with a single value\ndf2.with_columns(pl.col(\"b\").fill_null(0))\n```\n\n----------------------------------------\n\nTITLE: Combining Selectors with Set Operations in Polars\nDESCRIPTION: Shows how to combine multiple selectors using set operations to match all non-string columns that contain an underscore in the name.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3],\n        \"b\": [\"a\", \"b\", \"c\"],\n        \"c\": [4.0, 5.0, 6.0],\n        \"d_high\": [1, 2, 3],\n        \"e_high\": [4, 5, 6],\n    }\n)\n\nprint(df.select((~cs.string()) & cs.contains(\"_\")))\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Sine in Degrees using ASIND\nDESCRIPTION: Shows the use of ASIND function to compute inverse sine in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [-0.5, 0.0, 0.5]})\ndf.sql(\"SELECT degs, ASIND(degs) AS asind FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Using String and Ends_with Selectors in Polars\nDESCRIPTION: Demonstrates how to use the 'string' and 'ends_with' selectors to select all string columns and columns whose names end with '_high'.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3],\n        \"b\": [\"a\", \"b\", \"c\"],\n        \"c\": [4.0, 5.0, 6.0],\n        \"d_high\": [1, 2, 3],\n        \"e_high\": [4, 5, 6],\n    }\n)\n\nprint(df.select(cs.string() | cs.ends_with(\"_high\")))\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Sine in Radians using ASIN\nDESCRIPTION: Demonstrates ASIN function usage to compute inverse sine in radians for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"rads\": [-1.0, -0.75, -0.0, 0.5]})\ndf.sql(\"SELECT rads, ASIN(rads) AS asin FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Defining Series Documentation Structure in RST\nDESCRIPTION: ReStructuredText directives defining the documentation structure for the Polars Series class, including table of contents, module references and autoclass generation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   aggregation\n   array\n   attributes\n   binary\n   boolean\n   categories\n   computation\n   descriptive\n   export\n   list\n   modify_select\n   miscellaneous\n   operators\n   plot\n   string\n   struct\n   temporal\n\n.. _series:\n\n.. currentmodule:: polars\n\n.. autoclass:: Series\n    :members:\n    :noindex:\n    :autosummary:\n    :autosummary-nosignatures:\n```\n\n----------------------------------------\n\nTITLE: Displaying Mixed File Paths in Hive Partitioned Directory using Python\nDESCRIPTION: This code shows the directory structure with mixed file types, including parquet files and a text file, to demonstrate handling of mixed files in hive partitioned data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:show_mixed_paths\"\n```\n\n----------------------------------------\n\nTITLE: Handling Non-Lazy Operations\nDESCRIPTION: Demonstrates how to handle operations not available in lazy API by switching between lazy and eager modes, specifically showing a pivot operation example.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/schemas.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/lazy/schema.py:lazyeager\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Name Methods in Polars Expressions\nDESCRIPTION: List of available methods under the expr.name attribute for manipulating expression names. Includes methods for case conversion, prefix/suffix addition, and name mapping.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/name.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nExpr.name.keep\nExpr.name.map\nExpr.name.map_fields\nExpr.name.prefix\nExpr.name.prefix_fields\nExpr.name.suffix\nExpr.name.suffix_fields\nExpr.name.to_lowercase\nExpr.name.to_uppercase\n```\n\n----------------------------------------\n\nTITLE: Creating Modified Property Prices DataFrame in Python\nDESCRIPTION: This snippet demonstrates how to create a modified version of the property prices DataFrame with a different column name for property names.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprops_prices2 = pl.DataFrame(\n    {\n        \"name\": [\"Mediterranean Avenue\", \"Baltic Avenue\", \"Reading Railroad\", \"Oriental Avenue\", \"Sesame Street\"],\n        \"price\": [60, 60, 200, 100, 250],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Referencing Array Equality Module in Rust\nDESCRIPTION: Specifies the location of the array equality operators, which serve as the single source of truth for array equality in the crate.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/README.md#2025-04-22_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n[`array/equal`](array/equal/mod.rs)\n```\n\n----------------------------------------\n\nTITLE: Equivalent operation in Spark using artificial keys (Python)\nDESCRIPTION: Demonstrates how to achieve a similar result in Spark by generating artificial keys to join the values. This shows the more complex approach required in Spark for operations that are simpler in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/spark.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pyspark.sql import Window\nfrom pyspark.sql.functions import row_number\n\nfoo_dfs = (\n    dfs\n    .withColumn(\n        \"rownum\",\n        row_number().over(Window.orderBy(\"foo\"))\n    )\n)\n\nbar_dfs = (\n    dfs\n    .withColumn(\n        \"rownum\",\n        row_number().over(Window.orderBy(col(\"bar\").desc()))\n    )\n)\n\n(\n    foo_dfs.alias(\"foo\")\n    .join(bar_dfs.alias(\"bar\"), on=\"rownum\")\n    .select(\"foo.foo\", \"bar.bar\")\n    .limit(2)\n    .show()\n)\n```\n\n----------------------------------------\n\nTITLE: Reversing Arrays with ARRAY_REVERSE in Polars SQL\nDESCRIPTION: Demonstrates the use of ARRAY_REVERSE function to reverse the order of elements in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [[1, 2], [4, 3, 2]],\n    \"bar\": [[6, 7], [8, 9, 10]]\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    foo,\n    ARRAY_REVERSE(foo) AS oof,\n    ARRAY_REVERSE(bar) AS rab\n  FROM self\n\"\"\")\n# shape: (2, 3)\n# ┌───────────┬───────────┬────────────┐\n# │ foo       ┆ oof       ┆ rab        │\n# │ ---       ┆ ---       ┆ ---        │\n# │ list[i64] ┆ list[i64] ┆ list[i64]  │\n# ╞═══════════╪═══════════╪════════════╡\n# │ [1, 2]    ┆ [2, 1]    ┆ [7, 6]     │\n# │ [4, 3, 2] ┆ [2, 3, 4] ┆ [10, 9, 8] │\n# └───────────┴───────────┴────────────┘\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Cosine in Degrees using ACOSD\nDESCRIPTION: Shows usage of ACOSD function to compute inverse cosine in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [-0.5, 0.0, 0.5]})\ndf.sql(\"SELECT degs, ACOSD(degs) AS acosd FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies List\nDESCRIPTION: List of required Python packages and their versions for documentation generation and testing. Includes core data libraries, Sphinx documentation system with version 8.1.3, and various Sphinx extensions for enhanced documentation features.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/requirements-docs.txt#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nhypothesis\nnumpy\npandas\npyarrow\n\nsphinx==8.1.3\n\n# Third-party Sphinx extensions\nautodocsumm==0.2.14\nnumpydoc==1.8.0\npydata-sphinx-theme==0.16.0\nsphinx-autosummary-accessors==2023.4.0\nsphinx-copybutton==0.5.2\nsphinx-design==0.6.1\nsphinx-favicon==1.0.1\nsphinx-reredirects==0.1.5\nsphinx-toolbox==3.8.1\n\nlivereload==2.7.0\n```\n\n----------------------------------------\n\nTITLE: Converting Arrow Decimal Types to Polars in Python\nDESCRIPTION: Shows how Arrow Decimal types are now automatically converted to Polars Decimal types when using pl.from_arrow(), without the need for Config.activate_decimals.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom decimal import Decimal as D\nimport pyarrow as pa\narr = pa.array([D(\"1.01\"), D(\"2.25\")])\npl.from_arrow(arr)\n```\n\n----------------------------------------\n\nTITLE: Arithmetic Operation with Range\nDESCRIPTION: Adds columns 'a' and 'b', squares the result, and adds an integer range starting from 0 to 3.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/tests/unit/operations/namespaces/files/test_tree_fmt.txt#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n(pl.col(\"a\") + pl.col(\"b\"))**2 + pl.int_range(3)\n```\n\n----------------------------------------\n\nTITLE: Type Annotation with Custom Type Alias (After)\nDESCRIPTION: Example showing how type annotations should now define their own type aliases, as re-exports have been removed in preparation for a future polars.typing module.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nPolarsDataType = pl.DataType | type[pl.DataType]\n\ndef foo(dtype: PolarsDataType) -> None: ...\n```\n\n----------------------------------------\n\nTITLE: DataFrame.sql with Global Access (Before)\nDESCRIPTION: Example showing how DataFrame.sql previously allowed access to global variables, enabling queries that referenced other dataframes in the global scope.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n>>> df1 = pl.DataFrame({\"id1\": [1, 2]})\n>>> df2 = pl.DataFrame({\"id2\": [3, 4]})\n>>> df1.sql(\"SELECT * FROM df1 CROSS JOIN df2\")\nshape: (4, 2)\n┌─────┬─────┐\n│ id1 ┆ id2 │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 3   │\n│ 1   ┆ 4   │\n│ 2   ┆ 3   │\n│ 2   ┆ 4   │\n└─────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Computing Tangent Values from Degrees using TAND in Polars SQL\nDESCRIPTION: Shows how to use the TAND function in Polars SQL to calculate tangent values from degree inputs. Creates a DataFrame with degree values and applies the TAND function through SQL expression.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [0, 45, 135, 225]})\ndf.sql(\"SELECT degs, TAND(degs) AS tand FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Interactive Mode Output Type Demonstration\nDESCRIPTION: Shows the return type of an interactive mode query in Polars Cloud\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/interactive-batch.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(type(res1))\n```\n\n----------------------------------------\n\nTITLE: Creating a Sample DataFrame in Polars\nDESCRIPTION: This code snippet demonstrates how to create a sample DataFrame in Polars with multiple columns, including a date column and several numeric columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/unpivot.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ndf = pl.DataFrame(\n    {\n        \"id\": [\"A\", \"B\", \"C\"],\n        \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n        \"x\": [1, 3, 5],\n        \"y\": [2, 4, 6],\n        \"z\": [3, 6, 9],\n    }\n)\nprint(df)\n```\n\n----------------------------------------\n\nTITLE: Initializing Sample Dataset with Polars LazyFrame\nDESCRIPTION: Creates a mock dataset using Polars LazyFrame with climate-related data including region, temperature, humidity, burn area, and vegetation density metrics.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/workflow.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\nlf = pl.LazyFrame(\n    {\n        \"region\": [\n            \"Australia\",\n            \"California\",\n            \"Benelux\",\n            \"Siberia\",\n            \"Mediterranean\",\n            \"Congo\",\n            \"Borneo\",\n        ],\n        \"temperature\": [32.1, 28.5, 30.2, 22.7, 29.3, 31.8, 33.2],\n        \"humidity\": [40, 35, 75, 30, 45, 80, 70],\n        \"burn_area\": [120, 85, 30, 65, 95, 25, 40],\n        \"vegetation_density\": [0.6, 0.7, 0.9, 0.4, 0.5, 0.9, 0.8],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Page State Processing for Nested Types\nDESCRIPTION: Details the implementation of nested type processing using multiple iterators for repetition levels, definition levels, and non-null values. Explains how nested structures are built recursively from Parquet pages.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-parquet/src/arrow/read/deserialize/README.md#2025-04-22_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Template Extension Declaration\nDESCRIPTION: Extends the base Sphinx autosummary class template\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/class.rst#2025-04-22_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{% extends \"!autosummary/class.rst\" %}\n```\n\n----------------------------------------\n\nTITLE: Iterator Design for Non-nested Arrays\nDESCRIPTION: Describes the implementation of simple::page_iter_to_arrays which processes non-nested arrays by converting Parquet pages into Arrow arrays using a streaming iterator pattern. Handles page state management and chunk sizing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-parquet/src/arrow/read/deserialize/README.md#2025-04-22_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Importing Polars in Rust\nDESCRIPTION: Rust code to import the Polars prelude.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\nuse polars::prelude::*;\n```\n\n----------------------------------------\n\nTITLE: Using pl.sql for Global Variable Access\nDESCRIPTION: Example showing the recommended way to execute SQL queries with access to global variables by using the top-level pl.sql function instead of DataFrame.sql.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_30\n\nLANGUAGE: python\nCODE:\n```\n>>> pl.sql(\"SELECT * FROM df1 CROSS JOIN df2\", eager=True)\nshape: (4, 2)\n┌─────┬─────┐\n│ id1 ┆ id2 │\n│ --- ┆ --- │\n│ i64 ┆ i64 │\n╞═════╪═════╡\n│ 1   ┆ 3   │\n│ 1   ┆ 4   │\n│ 2   ┆ 3   │\n│ 2   ┆ 4   │\n└─────┴─────┘\n```\n\n----------------------------------------\n\nTITLE: Rust Naming Conventions for Polars Variables\nDESCRIPTION: Standard naming conventions for common variable types in Polars Rust code, including Series, ChunkedArray, ArrayRef, PrimitiveArray, and DataType.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/code-style.md#2025-04-22_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nlet s: Series = ...\nlet ca: ChunkedArray = ...\nlet arr: ArrayRef = ...\nlet arr: PrimitiveArray = ...\nlet dtype: DataType = ...\nlet dtype: ArrowDataType = ...\n```\n\n----------------------------------------\n\nTITLE: String to Datetime Precision in Python\nDESCRIPTION: Illustrates how str.to_datetime now defaults to microsecond precision for format specifiers \"%f\" and \"%.f\" instead of nanosecond precision.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([\"2022-08-31 00:00:00.123456789\"])\ns.str.to_datetime(format=\"%Y-%m-%d %H:%M:%S%.f\")\nshape: (1,)\nSeries: '' [datetime[ns]]\n[\n        2022-08-31 00:00:00.123456789\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns.str.to_datetime(format=\"%Y-%m-%d %H:%M:%S%.f\")\nshape: (1,)\nSeries: '' [datetime[us]]\n[\n        2022-08-31 00:00:00.123456\n]\n```\n\n----------------------------------------\n\nTITLE: Convert Polars Series to pyarrow Array via PyCapsule\nDESCRIPTION: Shows how to convert a Polars Series to a pyarrow Array using the `pyarrow.array` constructor. If the underlying Polars Series has multiple chunks, this operation might involve data copying to create a contiguous array.  Otherwise it can be zero-copy.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pyarrow as pa\n\ns = pl.Series(\"foo\", [1, 2, 3])\n\narr = pa.array(s)\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Series Struct Methods\nDESCRIPTION: This code snippet shows how to import and use the struct-related methods and attributes for Polars Series objects. It sets up the current module and provides an autosummary of available methods.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/struct.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Series.struct.field\n    Series.struct.json_encode\n    Series.struct.rename_fields\n    Series.struct.unnest\n```\n\n----------------------------------------\n\nTITLE: Recommended Way to Access DataType Attributes\nDESCRIPTION: Example showing the recommended method to check for DataType attributes using getattr with a default value, which works safely with both class and instance variables.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\n>>> getattr(dtype, \"time_unit\", None) is None\nTrue\n```\n\n----------------------------------------\n\nTITLE: Templating Polars Method Documentation with Jinja2/RST\nDESCRIPTION: A template for generating Sphinx documentation for Polars accessor methods. Uses Jinja2 templating to insert the full method name, underline, module name and object name into RST format documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/accessor_method.rst#2025-04-22_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module.split('.')[0] }}\n\n.. autoaccessormethod:: {{ (module.split('.')[1:] + [objname]) | join('.') }}\n```\n\n----------------------------------------\n\nTITLE: Importing Polars DataFrame Serialization Methods\nDESCRIPTION: This code snippet demonstrates the import of serialization-related methods for Polars DataFrame objects. It includes the deserialize and serialize methods for data persistence and transfer.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/miscellaneous.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. autosummary::\n   :toctree: api/\n\n    DataFrame.deserialize\n    DataFrame.serialize\n```\n\n----------------------------------------\n\nTITLE: Configuring Polars Project Dependencies\nDESCRIPTION: This configuration specifies the build tools, runtime dependencies, and development tooling for the Polars project. It includes conditional dependencies based on the platform and Python version, and covers various categories such as interoperability, databases, cloud services, I/O operations, and testing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/requirements-dev.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# We're pinning our tooling, because it's an environment we can strictly control.\n# We're not pinning package dependencies, because our tests need to pass with the\n# latest version of the packages.\n\n# -----\n# BUILD\n# -----\n\nmaturin\n# extra dependency for maturin (linux-only)\npatchelf; platform_system == 'Linux'\npip\n\n# ------------\n# DEPENDENCIES\n# ------------\n\npolars-cloud\n# Interop\nnumpy\nnumba >= 0.54; python_version < '3.13'  # Numba can lag Python releases\npandas\npyarrow\npydantic>=2.0.0\n# Datetime / time zones\ntzdata; platform_system == 'Windows'\n# Database\nsqlalchemy\nadbc-driver-manager; platform_system != 'Windows'\nadbc-driver-sqlite; platform_system != 'Windows'\naiosqlite\nconnectorx\nkuzu\n# Cloud\ncloudpickle\nfsspec\ns3fs[boto3]\n# Spreadsheet\nfastexcel>=0.11.5\nopenpyxl\nxlsx2csv\nxlsxwriter\n# Other I/O\ndeltalake>=0.15.0\n# Csv\nzstandard\n# Plotting\naltair>=5.4.0\n# Styling\ngreat-tables>=0.8.0\n# Async\ngevent\n# Graph\nmatplotlib\n# Testing\nhypothesis\n# Miscellaneous\norjson\n\n# -------\n# TOOLING\n# -------\n\npytest==8.3.2\npytest-codspeed==3.2.0\npytest-cov==6.0.0\npytest-xdist==3.6.1\n\n# Need moto.server to mock s3fs - see: https://github.com/aio-libs/aiobotocore/issues/755\nmoto[s3]==5.0.9\nflask\nflask-cors\n\n# Stub files\npandas-stubs\nboto3-stubs\ngoogle-auth-stubs\n```\n\n----------------------------------------\n\nTITLE: Cloning Polars Repository in Bash\nDESCRIPTION: Commands to clone the forked Polars repository and set up the upstream remote for syncing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/<username>/polars.git\ncd polars\ngit remote add upstream https://github.com/pola-rs/polars.git\ngit fetch upstream\n```\n\n----------------------------------------\n\nTITLE: Listing Numeric Operators for Polars Series in Python\nDESCRIPTION: This code snippet lists the numeric operators available as methods on the Polars Series class. Currently, it only shows the power operation method.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/operators.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nSeries.pow\n```\n\n----------------------------------------\n\nTITLE: Retrieving Last Element with LAST in Polars SQL\nDESCRIPTION: Shows how to use the LAST function to get the last element of a column in a Polars DataFrame using SQL syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/aggregate.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"b\", \"a\", \"b\", \"c\"]})\ndf.sql(\"\"\"\n  SELECT LAST(foo) AS lf FROM self\n\"\"\")\n# shape: (1, 1)\n# ┌─────┐\n# │ lf  │\n# │ --- │\n# │ str │\n# ╞═════╡\n# │ c   │\n# └─────┘\n```\n\n----------------------------------------\n\nTITLE: Computing Tangent Values from Radians using TAN in Polars SQL\nDESCRIPTION: Demonstrates using the TAN function in Polars SQL to calculate tangent values from radian inputs. Creates a DataFrame with radian values and applies the TAN function through SQL expression.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport math\n\ndf = pl.DataFrame({\"rads\": [0.0, 1/4 * math.pi, 3/4 * math.pi]})\ndf.sql(\"SELECT rads, TAN(rads) AS tan FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Stock Trades Data Setup\nDESCRIPTION: Creates sample dataframe of stock trades for asof join example.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:df_trades\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Datetime DataType Class Variables (Before)\nDESCRIPTION: Example showing how Datetime class variables could be accessed directly before the change. This demonstrates the unintended behavior where time_unit was a class variable.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\n>>> dtype = pl.Datetime\n>>> dtype.time_unit is None\nTrue\n```\n\n----------------------------------------\n\nTITLE: Generating Sphinx Documentation for Polars Accessor Callable\nDESCRIPTION: This RST code snippet sets up the documentation structure for a Polars accessor callable method. It uses Sphinx directives to specify the current module and automatically document the __call__ method of the accessor.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/accessor_callable.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module.split('.')[0] }}\n\n.. autoaccessorcallable:: {{ (module.split('.')[1:] + [objname]) | join('.') }}.__call__\n```\n\n----------------------------------------\n\nTITLE: Displaying Polars Cloud CLI Help\nDESCRIPTION: Shows the main help menu of the Polars Cloud CLI, displaying available commands and options including login, workspace, and compute management features.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/cli.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npc --help\n```\n\nLANGUAGE: text\nCODE:\n```\nusage: pc [-h] [-v] [-V] {login,workspace,compute} ...\n\npositional arguments:\n{login,workspace,compute}\nlogin               Authenticate with Polars Cloud by logging in through the browser\nworkspace           Manage Polars Cloud workspaces.\ncompute             Manage Polars Cloud compute clusters.\n\noptions:\n-h, --help            show this help message and exit\n-v, --verbose         Output debug logging messages.\n-V, --version         Display the version of the Polars Cloud client.\n```\n\n----------------------------------------\n\nTITLE: Demonstrating NaN Equality Changes in Polars 0.20\nDESCRIPTION: Illustrates how NaN values are now considered equal to themselves in comparisons, which aligns with user expectations and standards. This is a significant change for workflows that contain NaN values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1.0, float(\"nan\"), float(\"inf\")])\ns == s\n# NaN compared to itself returns false\n\n# After:\ns == s\n# NaN compared to itself returns true\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Series Struct Attributes\nDESCRIPTION: This code snippet demonstrates how to import and use the struct-related attributes for Polars Series objects. It provides an autosummary of available attributes.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/struct.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_attribute.rst\n\n    Series.struct.fields\n    Series.struct.schema\n```\n\n----------------------------------------\n\nTITLE: Importing IO Plugins in Python\nDESCRIPTION: Demonstrates how to import the register_io_source function from the polars.io.plugins module. This is necessary because the io.plugins module is not imported by default to optimize import speed of the primary polars module.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/plugins.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom polars.io.plugins import register_io_source\n```\n\n----------------------------------------\n\nTITLE: Setting Dynamic Linking Preferences in Cargo Config\nDESCRIPTION: Configuration for Cargo build settings that tells the Rust compiler to prefer dynamic linking over static linking. This is necessary when using the polars-dylib package.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-dylib/README.md#2025-04-22_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n# .cargo/config.toml\n[build]\nrustflags = [\n  \"-C\",\n  \"prefer-dynamic\",\n]\n```\n\n----------------------------------------\n\nTITLE: Using expand_selector for Debugging in Polars\nDESCRIPTION: Demonstrates how to use the 'expand_selector' function to check which columns a given selector will expand to in a specific frame or schema.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3],\n        \"b\": [\"a\", \"b\", \"c\"],\n        \"c\": [4.0, 5.0, 6.0],\n        \"d_high\": [1, 2, 3],\n        \"e_high\": [4, 5, 6],\n    }\n)\n\nprint(cs.expand_selector(cs.numeric() & cs.ends_with(\"_high\"), df))\n```\n\n----------------------------------------\n\nTITLE: Polars Sum Aggregation - Horizontal Computation (Before)\nDESCRIPTION: Demonstrates how `pl.sum` was previously used for horizontal computation in Polars before version 0.19. This behavior is now deprecated and requires using `sum_horizontal` instead. The code creates a DataFrame and calculates the sum across rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n>>> df = pl.DataFrame({'a': [1, 2], 'b': [11, 12]})\n>>> df.select(pl.sum('a', 'b'))  # horizontal computation\nshape: (2, 1)\n┌─────┐\n│ sum │\n│ --- │\n│ i64 │\n╞═════╡\n│ 12  │\n│ 14  │\n└─────┘\n```\n\n----------------------------------------\n\nTITLE: Polars Series All - Null Handling (Before)\nDESCRIPTION: Shows the previous behavior of the `all` function in Polars, where null values were treated as `False`. This behavior has changed to ignore null values by default.  Demonstrates how the `all` function previously evaluated a Series containing a null value.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.Series([True, None]).all()\nFalse\n```\n\n----------------------------------------\n\nTITLE: Boolean Series Methods Documentation in reStructuredText\nDESCRIPTION: Documentation structure for boolean operations on Polars Series, including all(), any(), and not_() methods. Uses reStructuredText format for API documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/boolean.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredText\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    Series.all\n    Series.any\n    Series.not_\n```\n\n----------------------------------------\n\nTITLE: Polars Warnings Class List\nDESCRIPTION: ReStructuredText documentation listing all warning classes in the polars.exceptions module\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/exceptions.rst#2025-04-22_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n    :toctree: api/\n    :nosignatures:\n\n    PolarsWarning\n    CategoricalRemappingWarning\n    ChronoFormatWarning\n    CustomUFuncWarning\n    DataOrientationWarning\n    MapWithoutReturnDtypeWarning\n    PerformanceWarning\n    PolarsInefficientMapWarning\n    UnstableWarning\n```\n\n----------------------------------------\n\nTITLE: Displaying Info Box for Inviting Existing Users in Markdown\nDESCRIPTION: This snippet shows how to create an info box in Markdown to provide additional information about inviting users who are already part of another workspace. It uses HTML comments to ignore formatting and creates a styled info box.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/workspace/team.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- dprint-ignore-start -->\n\n!!! info \"Inviting existing users\"\n    Users that are already part of another workspace will get a prompt to join the workspace they are invited for.\n\n<!-- dprint-ignore-end -->\n```\n\n----------------------------------------\n\nTITLE: Configuring Polars Dynamic Library Dependency in Cargo.toml\nDESCRIPTION: Workspace configuration in Cargo.toml that sets up the polars-dylib package as a dependency. This enables using Polars as a dynamic library rather than statically linking it.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-dylib/README.md#2025-04-22_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n# Cargo.toml\n[workspace.dependencies.polars]\npackage = \"polars-dylib\"\n```\n\n----------------------------------------\n\nTITLE: Writing Multiple DataFrames in a Loop in Google Colab\nDESCRIPTION: This snippet showcases writing multiple Polars DataFrames to a Google Sheet in a loop. It clears the worksheet initially and then writes each DataFrame next to the previous one, with a spacing of five columns.  It requires `google.colab` and `polars` libraries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/sheets_colab.md#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# TODO\n```\n\n----------------------------------------\n\nTITLE: Calculating Array Mean with ARRAY_MEAN in Polars SQL\nDESCRIPTION: Illustrates how to use the ARRAY_MEAN function to compute the average of values in array columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/array.rst#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [[1, 2], [4, 3, -1]]})\ndf.sql(\"\"\"\n  SELECT foo, ARRAY_MEAN(foo) AS foo_mean FROM self\n\"\"\")\n# shape: (2, 2)\n# ┌────────────┬──────────┐\n# │ foo        ┆ foo_mean │\n# │ ---        ┆ ---      │\n# │ list[i64]  ┆ f64      │\n# ╞════════════╪══════════╡\n# │ [1, 2]     ┆ 1.5      │\n# │ [4, 3, -1] ┆ 2.0      │\n# └────────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Efficient Binary Computation Pattern for Polars Arrays\nDESCRIPTION: A comprehensive example showing the recommended approach for implementing binary operations on Polars arrays. The code demonstrates handling null values, direct computation on arrow arrays, and propagation through the Polars type system.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/code-style.md#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse std::ops::Add;\n\nuse polars::export::arrow::array::*;\nuse polars::export::arrow::compute::arity::binary;\nuse polars::export::arrow::types::NativeType;\nuse polars::prelude::*;\nuse polars_core::utils::{align_chunks_binary, combine_validities_and};\nuse polars_core::with_match_physical_numeric_polars_type;\n\n// Prefer to do the compute closest to the arrow arrays.\n// this will tend to be faster as iterators can work directly on slices and don't have\n// to go through boxed traits\nfn compute_kernel<T>(arr_1: &PrimitiveArray<T>, arr_2: &PrimitiveArray<T>) -> PrimitiveArray<T>\nwhere\n    T: Add<Output = T> + NativeType,\n{\n    // process the null data separately\n    // this saves an expensive branch and bitoperation when iterating\n    let validity_1 = arr_1.validity();\n    let validity_2 = arr_2.validity();\n\n    let validity = combine_validities_and(validity_1, validity_2);\n\n    // process the numerical data as if there were no validities\n    let values_1: &[T] = arr_1.values().as_slice();\n    let values_2: &[T] = arr_2.values().as_slice();\n\n    let values = values_1\n        .iter()\n        .zip(values_2)\n        .map(|(a, b)| *a + *b)\n        .collect::<Vec<_>>();\n\n    PrimitiveArray::from_data_default(values.into(), validity)\n}\n\n// Same kernel as above, but uses the `binary` abstraction. Prefer this,\n#[allow(dead_code)]\nfn compute_kernel2<T>(arr_1: &PrimitiveArray<T>, arr_2: &PrimitiveArray<T>) -> PrimitiveArray<T>\nwhere\n    T: Add<Output = T> + NativeType,\n{\n    binary(arr_1, arr_2, arr_1.dtype().clone(), |a, b| a + b)\n}\n\nfn compute_chunked_array_2_args<T: PolarsNumericType>(\n    ca_1: &ChunkedArray<T>,\n    ca_2: &ChunkedArray<T>,\n) -> ChunkedArray<T> {\n    // This ensures both ChunkedArrays have the same number of chunks with the\n    // same offset and the same length.\n    let (ca_1, ca_2) = align_chunks_binary(ca_1, ca_2);\n    let chunks = ca_1\n        .downcast_iter()\n        .zip(ca_2.downcast_iter())\n        .map(|(arr_1, arr_2)| compute_kernel(arr_1, arr_2));\n    ChunkedArray::from_chunk_iter(ca_1.name(), chunks)\n}\n\npub fn compute_expr_2_args(arg_1: &Series, arg_2: &Series) -> Series {\n    // Dispatch the numerical series to `compute_chunked_array_2_args`.\n    with_match_physical_numeric_polars_type!(arg_1.dtype(), |$T| {\n        let ca_1: &ChunkedArray<$T> = arg_1.as_ref().as_ref().as_ref();\n        let ca_2: &ChunkedArray<$T> = arg_2.as_ref().as_ref().as_ref();\n        compute_chunked_array_2_args(ca_1, ca_2).into_series()\n    })\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Table of Contents for Polars Documentation\nDESCRIPTION: Configures a table of contents for the Polars documentation using Sphinx. It sets the maximum depth to 2 and includes the 'reference/index' page.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/index.rst#2025-04-22_snippet_1\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n\n   reference/index\n```\n\n----------------------------------------\n\nTITLE: Comparing Series Equality in Python\nDESCRIPTION: Shows the updated behavior of Series.equals(), which now ignores Series names by default. The check_names parameter can be used to retain the previous behavior.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ns1 = pl.Series(\"foo\", [1, 2, 3])\ns2 = pl.Series(\"bar\", [1, 2, 3])\ns1.equals(s2)\ns1.equals(s2, check_names=True)\n```\n\n----------------------------------------\n\nTITLE: Accessing Plot Property in Polars Series (Python)\nDESCRIPTION: This snippet demonstrates how to access the plot property of a Polars Series object. The plot property likely provides methods for creating various types of plots using the Series data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/plot.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nSeries.plot\n```\n\n----------------------------------------\n\nTITLE: Importing polars-testing in Rust code\nDESCRIPTION: This snippet demonstrates how to import all functionality from the polars-testing crate in Rust source code using the wildcard import syntax.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-testing/README.md#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse polars_testing::*;\n```\n\n----------------------------------------\n\nTITLE: Extracting Leftmost Characters in Polars SQL\nDESCRIPTION: Demonstrates the LEFT function, which returns the specified number of characters from the left side of a string. This example extracts both 1 and 2 characters from different columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"foo\": [\"abcd\", \"efgh\", \"ijkl\", \"mnop\"],\n    \"bar\": [\"zz\", \"yy\", \"xx\", \"ww\"],\n  }\n)\ndf.sql(\"\"\"\n  SELECT\n    LEFT(foo, 1) AS foo1,\n    LEFT(bar, 2) AS bar2\n  FROM self\n\"\"\")\n\n# shape: (4, 2)\n# ┌──────┬──────┐\n# │ foo1 ┆ bar2 │\n# │ ---  ┆ ---  │\n# │ str  ┆ str  │\n# ╞══════╪══════╡\n# │ a    ┆ zz   │\n# │ e    ┆ yy   │\n# │ i    ┆ xx   │\n# │ m    ┆ ww   │\n# └──────┴──────┘\n```\n\n----------------------------------------\n\nTITLE: Python Code Block Template for Documentation\nDESCRIPTION: Template showing how to format code snippets in Python documentation with proper delimiters for the documentation build system.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# --8<-- [start:read_parquet]\nimport polars as pl\n\ndf = pl.read_parquet(\"file.parquet\")\n# --8<-- [end:read_parquet]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Preserved Join Keys in Outer Joins in Polars 0.20\nDESCRIPTION: Illustrates how outer joins now preserve both left and right join keys instead of coalescing them. This change brings Polars closer to standard SQL behavior. The previous coalescing behavior can be maintained by using how=\"outer_coalesce\".\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ndf1 = pl.DataFrame({\"L1\": [\"a\", \"b\", \"c\"], \"L2\": [1, 2, 3]})\ndf2 = pl.DataFrame({\"L1\": [\"a\", \"c\", \"d\"], \"R2\": [7, 8, 9]})\ndf1.join(df2, on=\"L1\", how=\"outer\")\n# Result has coalesced keys\n\n# After:\ndf1.join(df2, on=\"L1\", how=\"outer\")\n# Result preserves both join keys\ndf1.join(df2, on=\"a\", how=\"outer_coalesce\")  # Keeps previous behavior\n```\n\n----------------------------------------\n\nTITLE: Specifying Documentation Dependencies for Polars Project\nDESCRIPTION: This snippet lists the dependencies required for generating documentation for the Polars project. It includes specific versions for mkdocs-related packages and other documentation tools.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/requirements.txt#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nmkdocs-material==9.6.1\nmkdocs-macros-plugin==1.3.7\nmkdocs-redirects==1.2.1\nmaterial-plausible-plugin==0.3.0\nmarkdown-exec[ansi]==1.10.0\npygithub==2.6.1\n```\n\n----------------------------------------\n\nTITLE: Implementing Array Trait in Rust\nDESCRIPTION: Demonstrates the required method implementations for structs implementing the Array trait, including try_new, new_empty, and new_null methods.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/array/README.md#2025-04-22_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nimpl Array for SomeArray {\n    fn try_new(...) -> Self {\n        // Implementation\n    }\n\n    fn new_empty() -> Self {\n        // or new_empty(DataType)\n    }\n\n    fn new_null(length: usize) -> Self {\n        // or new_null(DataType, length: usize)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining kwargs for Polars expressions in Rust\nDESCRIPTION: This Rust code defines a struct `MyKwargs` that represents the keyword arguments accepted by a Polars expression plugin.  It derives `serde::Deserialize` to enable deserialization from Python. The `append_kwargs` function demonstrates how to access these keyword arguments within the expression logic.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\n/// Provide your own kwargs struct with the proper schema and accept that type\n/// in your plugin expression.\n#[derive(Deserialize)]\npub struct MyKwargs {\n    float_arg: f64,\n    integer_arg: i64,\n    string_arg: String,\n    boolean_arg: bool,\n}\n\n/// If you want to accept `kwargs`. You define a `kwargs` argument\n/// on the second position in you plugin. You can provide any custom struct that is deserializable\n/// with the pickle protocol (on the Rust side).\n#[polars_expr(output_type=String)]\nfn append_kwargs(input: &[Series], kwargs: MyKwargs) -> PolarsResult<Series> {\n    let input = &input[0];\n    let input = input.cast(&DataType::String)?;\n    let ca = input.str().unwrap();\n\n    Ok(ca\n        .apply_into_string_amortized(|val, buf| {\n            write!(\n                buf,\n                \"{}-{}-{}-{}-{}\",\n                val, kwargs.float_arg, kwargs.integer_arg, kwargs.string_arg, kwargs.boolean_arg\n            )\n                .unwrap()\n        })\n        .into_series())\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating UNION BY NAME Operation in Polars SQL\nDESCRIPTION: This snippet shows the UNION BY NAME operation to combine result sets of two SELECT statements, aligning columns by name instead of ordinal position. It combines columns from both datasets and includes all rows. It uses Polars LazyFrames and the SQL interface.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/set_operations.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npl.sql(\"\"\"\n    SELECT * FROM lf1\n    UNION BY NAME\n    SELECT * FROM lf2\n\"\"\").sort(by=\"id\").collect()\n# shape: (6, 3)\n# ┌─────┬─────────┬──────┐\n# │ id  ┆ name    ┆ age  │\n# │ --- ┆ ---     ┆ ---  │\n# │ i64 ┆ str     ┆ i64  │\n# ╞═════╪═════════╪══════╡\n# │ 1   ┆ Alice   ┆ null │\n# │ 2   ┆ Bob     ┆ null │\n# │ 2   ┆ Bob     ┆ 30   │\n# │ 3   ┆ Charlie ┆ 25   │\n# │ 3   ┆ Charlie ┆ null │\n# │ 4   ┆ David   ┆ 45   │\n# └─────┴─────────┴──────┘\n```\n\n----------------------------------------\n\nTITLE: Convert Polars Series to pyarrow ChunkedArray via PyCapsule\nDESCRIPTION: Illustrates converting a Polars Series to a pyarrow ChunkedArray using the `pyarrow.chunked_array` constructor and the Arrow PyCapsule Interface. This facilitates zero-copy data transfer between Polars and pyarrow for Series data, improving performance and reducing memory usage.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/arrow.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport pyarrow as pa\n\ns = pl.Series(\"foo\", [1, 2, 3])\n\nca = pa.chunked_array(s)\n```\n\n----------------------------------------\n\nTITLE: group_by_dynamic with Previous Default Offset (Before)\nDESCRIPTION: Example showing how group_by_dynamic previously used a negative offset value by default, causing the first window to start one period before the earliest data point.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n>>> from datetime import date\n>>> df = pl.DataFrame({\n...     \"ts\": [date(2020, 1, 1), date(2020, 1, 2), date(2020, 1, 3)],\n...     \"value\": [1, 2, 3],\n... })\n>>> df.group_by_dynamic(\"ts\", every=\"1d\", period=\"2d\").agg(\"value\")\nshape: (4, 2)\n┌────────────┬───────────┐\n│ ts         ┆ value     │\n│ ---        ┆ ---       │\n│ date       ┆ list[i64] │\n╞════════════╪═══════════╡\n│ 2019-12-31 ┆ [1]       │\n│ 2020-01-01 ┆ [1, 2]    │\n│ 2020-01-02 ┆ [2, 3]    │\n│ 2020-01-03 ┆ [3]       │\n└────────────┴───────────┘\n```\n\n----------------------------------------\n\nTITLE: Logging into Polars Cloud\nDESCRIPTION: Command to login to Polars Cloud account.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/quickstart.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pc login\n```\n\n----------------------------------------\n\nTITLE: Window Operation with Multiple Grouping Keys\nDESCRIPTION: Performs multiplication of two columns 'foo' and 'bar', calculates their sum over window groups 'ham' and 'ham2', then divides the result by 2.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/tests/unit/operations/namespaces/files/test_tree_fmt.txt#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n(pl.col(\"foo\") * pl.col(\"bar\")).sum().over(\"ham\", \"ham2\") / 2\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for polars-json\nDESCRIPTION: Markdown documentation explaining the purpose and scope of the polars-json sub-crate, emphasizing its internal nature and directing users to the main Polars crate.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-json/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# polars-json\n\n`polars-json` is an **internal sub-crate** of the [Polars](https://crates.io/crates/polars) library,\nprovides functionalities to handle JSON objects.\n\n**Important Note**: This crate is **not intended for external usage**. Please refer to the main\n[Polars crate](https://crates.io/crates/polars) for intended usage.\n```\n\n----------------------------------------\n\nTITLE: Computing Inverse Cosine in Radians using ACOS\nDESCRIPTION: Demonstrates using ACOS function to compute inverse cosine in radians for DataFrame column values between -1.0 and 1.0.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"rads\": [-1.0, -0.5, 0.5, 1.0]})\ndf.sql(\"SELECT rads, ACOS(rads) AS acos FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents in ReStructuredText for Polars API Documentation\nDESCRIPTION: This code snippet defines the structure of the documentation using ReStructuredText directives. It creates a grid layout with multiple sections, each containing links to different parts of the Polars API documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. grid::\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           dataframe/index\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           lazyframe/index\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           series/index\n\n\n.. grid::\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           expressions/index\n           selectors\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           functions\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           datatypes\n           schema/index\n\n\n.. grid::\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           io\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           catalog/index\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           config\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           api\n\n        .. toctree::\n           :maxdepth: 1\n\n           plugins\n\n\n.. grid::\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 2\n\n           sql/index\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 1\n\n           exceptions\n\n        .. toctree::\n           :maxdepth: 2\n\n           testing\n\n    .. grid-item-card::\n\n        .. toctree::\n           :maxdepth: 1\n\n           metadata\n```\n\n----------------------------------------\n\nTITLE: Configuring Ruff Extension in Visual Studio Code for Polars\nDESCRIPTION: JSON configuration for the Ruff extension in VSCode, setting the import strategy to use the Ruff version installed in the project's environment.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/ide.md#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"ruff.importStrategy\": \"fromEnvironment\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using TIMESTAMP Function in Polars SQL\nDESCRIPTION: Shows how to convert string date representations to datetime objects using the TIMESTAMP function with a format string. This allows custom date format parsing.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n  {\n    \"str_timestamp\": [\n      \"1969 July 30, 00:30:55\",\n      \"2030-October-08, 12:40:15\",\n      \"2077 February 28, 10:45:00\",\n    ]\n  }\n)\ndf.sql(\"\"\"\n  SELECT str_timestamp, TIMESTAMP(str_date, '%Y.%m.%d') AS date FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Demonstrating New 'replace' Behavior in Polars DataFrame\nDESCRIPTION: Shows how the 'replace' method now handles column references and return data types differently compared to the previous version.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> df = pl.DataFrame({\"a\": [1, 2, 2, 3], \"b\": [1.5, 2.5, 5.0, 1.0]}, schema={\"a\": pl.Int8, \"b\": pl.Float64})\n>>> df.select(pl.col(\"a\").replace({2: 100}))\nshape: (4, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 100 │\n│ 100 │\n│ 3   │\n└─────┘\n>>> df.select(pl.col(\"a\").replace({2: 100}, default=pl.col(\"b\")))  # No struct needed\nshape: (4, 1)\n┌───────┐\n│ a     │\n│ ---   │\n│ f64   │\n╞═══════╡\n│ 1.5   │\n│ 100.0 │\n│ 100.0 │\n│ 1.0   │\n└───────┘\n```\n\n----------------------------------------\n\nTITLE: Importing Unity Catalog Module in Python\nDESCRIPTION: This snippet shows how to import the Unity Catalog module in Polars. It sets up the current module context for the subsequent class and method definitions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/catalog/unity.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n```\n\n----------------------------------------\n\nTITLE: Registering the custom expression in Python\nDESCRIPTION: This Python code registers the `pig_latinnify` function as a Polars expression plugin. It uses the `register_plugin_function` function from `polars.plugins` to specify the plugin path, function name, arguments, and whether the function is elementwise. The `is_elementwise=True` argument allows Polars to run the expression in batches.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/expr_plugins.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# expression_lib/__init__.py\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nimport polars as pl\nfrom polars.plugins import register_plugin_function\nfrom polars._typing import IntoExpr\n\nPLUGIN_PATH = Path(__file__).parent\n\ndef pig_latinnify(expr: IntoExpr) -> pl.Expr:\n    \"\"\"Pig-latinnify expression.\"\"\"\n    return register_plugin_function(\n        plugin_path=PLUGIN_PATH,\n        function_name=\"pig_latinnify\",\n        args=expr,\n        is_elementwise=True,\n    )\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Columns as Sorted in DataFrame in Python\nDESCRIPTION: Demonstrates how to set multiple columns as sorted using multiple calls to set_sorted() instead of passing multiple columns in a single call.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4.0, 5.0, 6.0], \"c\": [9, 7, 8]})\ndf.set_sorted(\"a\").set_sorted(\"b\")\n```\n\n----------------------------------------\n\nTITLE: Plotly Visualization with Polars\nDESCRIPTION: This snippet demonstrates using Plotly with Polars DataFrames to create interactive visualizations. It leverages the dataframe interchange protocol for zero-copy conversion between Polars and Plotly when possible. Not all Polars data types are supported by the interchange protocol.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:plotly_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Debugging Selectors with is_selector in Polars\nDESCRIPTION: Shows how to use the 'is_selector' function to check whether an object is a Polars selector or not.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\nprint(cs.is_selector(cs.numeric()))\nprint(cs.is_selector(pl.col(\"a\")))\n```\n\n----------------------------------------\n\nTITLE: Suppress Deprecation Warnings - Python\nDESCRIPTION: Shows how to suppress deprecation warnings in Python using the `warnings` module. This can be useful when upgrading to a new version of Polars and wanting to avoid deprecation warnings temporarily. It imports the warnings module and uses filterwarnings to ignore DeprecationWarning.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n```\n\n----------------------------------------\n\nTITLE: Enabling Streaming Mode in Polars\nDESCRIPTION: Shows how to enable streaming mode in Polars by passing the engine=\"streaming\" argument to the collect() method when executing a lazy query.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/_streaming.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/concepts/streaming.py:import\"\n--8<-- \"python/user-guide/concepts/streaming.py:streaming\"\n```\n\n----------------------------------------\n\nTITLE: Computing Cotangent in Degrees using COTD\nDESCRIPTION: Shows COTD function usage to compute cotangent in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [0, 90, 180, 270, 360]})\ndf.sql(\"SELECT degs, COTD(degs) AS cotd FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Running SQL Queries with Polars CLI\nDESCRIPTION: This example shows how to use the Polars CLI to execute SQL queries directly from the terminal. It demonstrates both inline query execution and interactive mode.\nSOURCE: https://github.com/pola-rs/polars/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# run an inline SQL query\n> polars -c \"SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;\"\n\n# run interactively\n> polars\nPolars CLI v0.3.0\nType .help for help.\n\n> SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Constructor Changes for Decimal and Array in Polars 0.20\nDESCRIPTION: Shows how the parameter order for Decimal and Array data types has been changed to better match user expectations. The precision and scale parameters for Decimal have been swapped, and Array now takes the element type first.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Before:\npl.Array(2, pl.Int16)  # Array(Int16, 2)\npl.Decimal(5, 10)  # Decimal(precision=10, scale=5)\n\n# After:\npl.Array(pl.Int16, 2)  # Array(Int16, width=2)\npl.Decimal(10, 5)  # Decimal(precision=10, scale=5)\n```\n\n----------------------------------------\n\nTITLE: Square Root Function (SQRT) in Polars SQL\nDESCRIPTION: Demonstrates SQRT function for calculating square roots of numbers.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"x\": [2, 16, 4096, 65536]})\ndf.sql(\"\"\"\n  SELECT x, SQRT(x) AS sqrt_x FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Basic Parametric Testing with Polars DataFrames in Python\nDESCRIPTION: Creates a parametric unit test that generates DataFrames with 5 numeric columns and a 10% chance of null values. It demonstrates the use of the dataframes strategy from polars.testing.parametric.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/testing.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing.parametric import dataframes\nfrom polars import NUMERIC_DTYPES\n\nfrom hypothesis import given\n\n@given(\n    dataframes(\n        cols=5,\n        allow_null=True,\n        allowed_dtypes=NUMERIC_DTYPES,\n    )\n)\ndef test_numeric(df: pl.DataFrame):\n    assert all(df[col].dtype.is_numeric() for col in df.columns)\n\n    # Example frame:\n    # ┌──────┬────────┬───────┬────────────┬────────────┐\n    # │ col0 ┆ col1   ┆ col2  ┆ col3       ┆ col4       │\n    # │ ---  ┆ ---    ┆ ---   ┆ ---        ┆ ---        │\n    # │ u8   ┆ i16    ┆ u16   ┆ i32        ┆ f64        │\n    # ╞══════╪════════╪═══════╪════════════╪════════════╡\n    # │ 54   ┆ -29096 ┆ 485   ┆ 2147483647 ┆ -2.8257e14 │\n    # │ null ┆ 7508   ┆ 37338 ┆ 7264       ┆ 1.5        │\n    # │ 0    ┆ 321    ┆ null  ┆ 16996      ┆ NaN        │\n    # │ 121  ┆ -361   ┆ 63204 ┆ 1          ┆ 1.1443e235 │\n    # └──────┴────────┴───────┴────────────┴────────────┘\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Polars Column Expression\nDESCRIPTION: Shows how to use polars.col in DataFrame operations. The Col class provides methods for column selection and manipulation through __call__ and __getattr__ interfaces.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/col.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npolars.col\n```\n\n----------------------------------------\n\nTITLE: Checking Streaming Execution with Non-Streaming Operations\nDESCRIPTION: Shows how to use the explain() method to identify parts of a query that won't execute in streaming mode due to unsupported operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/_streaming.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/concepts/streaming.py:import\"\n--8<-- \"python/user-guide/concepts/streaming.py:example2\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Series Default Data Type Change in Polars 0.20\nDESCRIPTION: Shows how Series now defaults to Null data type when no data is present, instead of the previous behavior of initializing as a Float32 type.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Before:\npl.Series(\"a\", [None])\n# Series with f32 dtype\n\n# After:\npl.Series(\"a\", [None])\n# Series with null dtype\n```\n\n----------------------------------------\n\nTITLE: Creating Sample DataFrame for Hive Partitioned Data Writing in Python\nDESCRIPTION: This snippet creates a sample DataFrame to be used for demonstrating how to write hive partitioned parquet datasets using Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:write_parquet_partitioned_show_data\"\n```\n\n----------------------------------------\n\nTITLE: Handling Out-of-Bounds Indices in List Operations in Python\nDESCRIPTION: Shows how get operations now raise an error by default for out-of-bounds indices. The null_on_oob parameter can be used to restore previous behavior.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ns = pl.Series([[0, 1, 2], [0]])\ns.list.get(1, null_on_oob=True)\n```\n\n----------------------------------------\n\nTITLE: LazyFrame Methods - Serialization Operations\nDESCRIPTION: Methods for serializing and deserializing LazyFrame objects to enable data persistence and transfer.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/miscellaneous.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nLazyFrame.deserialize\nLazyFrame.serialize\n```\n\n----------------------------------------\n\nTITLE: Creating Weather by Day Example in Polars\nDESCRIPTION: This snippet creates a sample weather dataframe with daily temperature readings across multiple stations. The data is structured for demonstrating row-wise list computations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:weather_by_day\"\n```\n\n----------------------------------------\n\nTITLE: LazyFrame Serialization in Binary Format (After)\nDESCRIPTION: Example showing how LazyFrame objects are now serialized to an optimized binary format by default, requiring BytesIO for deserialization of the binary data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n>>> lf = pl.LazyFrame({\"a\": [1, 2, 3]}).sum()\n>>> serialized = lf.serialize()\n>>> serialized\nb'\\xa1kMapFunction\\xa2einput\\xa1mDataFrameScan\\xa4bdf...'\n>>> from io import BytesIO  # Note: using BytesIO instead of StringIO\n>>> pl.LazyFrame.deserialize(BytesIO(serialized)).collect()\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 6   │\n└─────┘\n```\n\n----------------------------------------\n\nTITLE: Configuring Polars Dependencies in Rust\nDESCRIPTION: This Rust code snippet shows how to configure Polars dependencies in a Cargo.toml file, including using the latest version from the main branch on GitHub.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/README.md#2025-04-22_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\npolars = { git = \"https://github.com/pola-rs/polars\", rev = \"<optional git tag>\" }\n```\n\n----------------------------------------\n\nTITLE: Using Default ComputeContext in Polars Cloud\nDESCRIPTION: Demonstrates a remote query execution without explicitly defining a ComputeContext. This uses the default context set in the Polars Cloud dashboard.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nquery.remote().sink_parquet(...)\n```\n\n----------------------------------------\n\nTITLE: Installing Polars Cloud Package\nDESCRIPTION: Command to install the Polars and Polars Cloud Python packages using pip.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/quickstart.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install polars polars-cloud\n```\n\n----------------------------------------\n\nTITLE: Shell Package Installation Commands for Python and Rust\nDESCRIPTION: Example shell commands showing how to install required packages for both Python and Rust implementations of Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install fsspec\n$ cargo add aws_sdk_s3\n```\n\n----------------------------------------\n\nTITLE: Running SQL Queries with Polars CLI\nDESCRIPTION: This snippet demonstrates how to use the Polars CLI to execute SQL queries directly from the terminal, both inline and interactively.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# run an inline SQL query\n> polars -c \"SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;\"\n\n# run interactively\n> polars\nPolars CLI v0.3.0\nType .help for help.\n\n> SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;\n```\n\n----------------------------------------\n\nTITLE: Computing Sine in Degrees using SIND\nDESCRIPTION: Shows SIND function usage to compute sine in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [0, 90, 225, 270]})\ndf.sql(\"SELECT degs, SIND(degs) AS sind FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Workspace in Polars Cloud\nDESCRIPTION: Command to set up a workspace in Polars Cloud, connecting it to your AWS environment.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/quickstart.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ pc setup workspace -n <YOUR_WORKSPACE_NAME>\n```\n\n----------------------------------------\n\nTITLE: Using JOIN Clauses in Polars SQL\nDESCRIPTION: Shows different types of JOIN operations between two DataFrames including FULL JOIN and NATURAL INNER JOIN\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/clauses.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf1 = pl.DataFrame(\n  {\n    \"foo\": [1, 2, 3],\n    \"ham\": [\"a\", \"b\", \"c\"],\n  }\n)\ndf2 = pl.DataFrame(\n  {\n    \"apple\": [\"x\", \"y\", \"z\"],\n    \"ham\": [\"a\", \"b\", \"d\"],\n  }\n)\npl.sql(\"\"\"\n  SELECT foo, apple, COALESCE(df1.ham, df2.ham) AS ham\n  FROM df1 FULL JOIN df2\n  USING (ham)\n\"\"\").collect()\n\npl.sql(\"\"\"\n  SELECT COLUMNS('^\\w+$')\n  FROM df1 NATURAL INNER JOIN df2\n\"\"\").collect()\n```\n\n----------------------------------------\n\nTITLE: Running Polars Test Suite in Bash\nDESCRIPTION: Commands to navigate to the py-polars directory and run the test suite using Make.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd py-polars\nmake test\n```\n\n----------------------------------------\n\nTITLE: Comparing Categorical Columns with Different Ordering in Polars\nDESCRIPTION: Shows how to create Categorical columns with lexical and physical ordering, and demonstrates the difference in comparisons.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Enable string cache\npl.enable_string_cache()\n\n# Create DataFrame with lexically ordered Categorical column\ndf_lexical = pl.DataFrame(\n    {\"category\": [\"C\", \"A\", \"B\"]},\n    schema={\"category\": pl.Categorical(ordering=\"lexical\")},\n)\n\n# Create DataFrame with physically ordered Categorical column\ndf_physical = pl.DataFrame(\n    {\"category\": [\"C\", \"A\", \"B\"]},\n    schema={\"category\": pl.Categorical},\n)\n\n# Compare lexical ordering\nprint(\"Lexical ordering:\")\nprint(df_lexical.sort(\"category\"))\n\n# Compare physical ordering\nprint(\"\\nPhysical ordering:\")\nprint(df_physical.sort(\"category\"))\n\n# Disable string cache\npl.disable_string_cache()\n```\n\n----------------------------------------\n\nTITLE: Polars DataFrame With Columns - Input Parsing (Before)\nDESCRIPTION: Shows how passing `None` to `with_columns` was previously handled in Polars. The `None` input was ignored, and no new column was added to the DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.DataFrame({'a': [1, 2]}).with_columns(None)\nshape: (2, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 1   │\n│ 2   │\n└─────┘\n```\n\n----------------------------------------\n\nTITLE: Illustrating 'value_counts' Column Renaming in Polars Series\nDESCRIPTION: Demonstrates the change in the resulting column name from 'counts' to 'count' when using the 'value_counts' method on a Polars Series.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n>>> s = pl.Series(\"a\", [\"x\", \"x\", \"y\"])\n>>> s.value_counts()\nshape: (2, 2)\n┌─────┬───────┐\n│ a   ┆ count │\n│ --- ┆ ---   │\n│ str ┆ u32   │\n╞═════╪═══════╡\n│ x   ┆ 2     │\n│ y   ┆ 1     │\n└─────┴───────┘\n```\n\n----------------------------------------\n\nTITLE: Defining the IO Source\nDESCRIPTION: This code defines the `my_scan_csv` function, which creates and registers a custom CSV IO source for Polars. It takes a CSV string as input, parses the schema, and defines an inner `source_generator` function that yields `pl.DataFrame` objects. The `source_generator` handles projection pushdown, predicate pushdown, and limiting the number of rows read. Finally, it uses `register_io_source` to register the generator with the schema, returning a `pl.LazyFrame`.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/plugins/io_plugins.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef my_scan_csv(csv_str: str) -> pl.LazyFrame:\n    schema = parse_schema(csv_str)\n\n    def source_generator(\n        with_columns: list[str] | None,\n        predicate: pl.Expr | None,\n        n_rows: int | None,\n        batch_size: int | None,\n    ) -> Iterator[pl.DataFrame]:\n        \"\"\"\n        Generator function that creates the source.\n        This function will be registered as IO source.\n        \"\"\"\n        if batch_size is None:\n            batch_size = 100\n\n        # Initialize the reader.\n        reader = csv.reader(io.StringIO(csv_str), delimiter=',')\n        # Skip the header.\n        _ = next(reader)\n\n        # Ensure we don't read more rows than requested from the engine\n        while n_rows is None or n_rows > 0:\n            if n_rows is not None:\n                batch_size = min(batch_size, n_rows)\n\n            rows = []\n\n            for _ in range(batch_size):\n                try:\n                    row = next(reader)\n                except StopIteration:\n                    n_rows = 0\n                    break\n                rows.append(row)\n\n            df = pl.from_records(rows, schema=schema, orient=\"row\")\n            n_rows -= df.height\n\n            # If we would make a performant reader, we would not read these\n            # columns at all.\n            if with_columns is not None:\n                df = df.select(with_columns)\n\n            # If the source supports predicate pushdown, the expression can be parsed\n            # to skip rows/groups.\n            if predicate is not None:\n                df = df.filter(predicate)\n\n            yield df\n\n    return register_io_source(io_source=source_generator, schema=schema)\n```\n\n----------------------------------------\n\nTITLE: Installing Rust Nightly Toolchain in Bash\nDESCRIPTION: Command to install the Rust nightly toolchain with the Miri component.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nrustup toolchain install nightly --component miri\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with Optional Dependencies (Before)\nDESCRIPTION: Example showing how to install Polars with optional dependencies using the previous extras names like fastexcel, gevent, and matplotlib.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_33\n\nLANGUAGE: bash\nCODE:\n```\npip install 'polars[fastexcel,gevent,matplotlib]'\n```\n\n----------------------------------------\n\nTITLE: Setting up ComputeContext for Batch Processing in Polars Cloud\nDESCRIPTION: Example showing how to configure batch mode processing in Polars Cloud by setting up a compute context. The code demonstrates using remote execution to write results to S3.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/interactive-batch.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nlf.remote(context=ctx).sink_parquet(\"s3://bucket/output.parquet\")\n```\n\n----------------------------------------\n\nTITLE: Adding Row Stub to Styled Polars DataFrame\nDESCRIPTION: Shows how to add a row stub to a styled Polars DataFrame using Great Tables. This technique helps in structuring the table by designating a column as row labels.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/styling.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ngt.tab_header(title=\"Iris Dataset\").tab_stub(col=\"species\")\n```\n\n----------------------------------------\n\nTITLE: Creating Release Commit Message in Markdown\nDESCRIPTION: Demonstrates the format for creating a commit message when releasing a new version of Polars. The commit message should include the language and version number.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n`release(<language>): <Language> Polars <version-number>`\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Reusable Polars Config Instances (Python)\nDESCRIPTION: Shows how to create multiple reusable Config instances with deferred option application, allowing for centralized configuration management and flexible application throughout the codebase.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/config.rst#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ncfg_verbose = pl.Config(verbose=True, apply_on_context_enter=True)\ncfg_markdown = pl.Config(tbl_formatting=\"MARKDOWN\", apply_on_context_enter=True)\n\n@cfg_markdown\ndef write_markdown_frame_to_stdout(df: pl.DataFrame) -> None:\n    sys.stdout.write(str(df))\n\n@cfg_verbose\ndef do_various_things():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Defining Polars Dependencies in Cargo.toml\nDESCRIPTION: Specifies the Polars dependency with version 0.26.1 and enables several features including lazy evaluation, temporal operations, data description, JSON and Parquet support, and datetime data type.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[dependencies]\npolars = { version = \"0.26.1\", features = [\"lazy\", \"temporal\", \"describe\", \"json\", \"parquet\", \"dtype-datetime\"] }\n```\n\n----------------------------------------\n\nTITLE: group_by_dynamic with New Default Offset (After)\nDESCRIPTION: Example showing how group_by_dynamic now uses a zero offset by default, causing the first window to start at the earliest data point, which aligns better with user expectations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n>>> df.group_by_dynamic(\"ts\", every=\"1d\", period=\"2d\").agg(\"value\")\nshape: (3, 2)\n┌────────────┬───────────┐\n│ ts         ┆ value     │\n│ ---        ┆ ---       │\n│ date       ┆ list[i64] │\n╞════════════╪═══════════╡\n│ 2020-01-01 ┆ [1, 2]    │\n│ 2020-01-02 ┆ [2, 3]    │\n│ 2020-01-03 ┆ [3]       │\n└────────────┴───────────┘\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Assertion Utilities Changes in Polars 0.20\nDESCRIPTION: Shows how assertion utilities now perform exact checking for integer values and always treat NaN values as equal. The nans_compare_equal parameter has been removed.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.20.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Before:\nfrom polars.testing import assert_frame_equal\ndf1 = pl.DataFrame({\"id\": [123456]})\ndf2 = pl.DataFrame({\"id\": [123457]})\nassert_frame_equal(df1, df2)  # Passes with approximate checking\n\n# After:\nassert_frame_equal(df1, df2)\n# Fails because integers are checked exactly\n```\n\n----------------------------------------\n\nTITLE: Installing Polars for Legacy CPUs in Python\nDESCRIPTION: Command to install Polars for Python on old CPUs without AVX support.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install polars-lts-cpu\n```\n\n----------------------------------------\n\nTITLE: Creating DataFrame with NaN Values in Polars\nDESCRIPTION: Shows how to create a DataFrame with NaN (Not a Number) values, which are different from null values and only applicable to floating point columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/missing-data.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport math\n\ndf3 = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3, 4, 5],\n        \"b\": [5.0, math.nan, 6.0, math.nan, 8.0],\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Schema Documentation in Polars using reStructuredText\nDESCRIPTION: This RST code snippet sets up the documentation for the Schema class in Polars. It uses autoclass to automatically generate documentation for all members of the Schema class, without including method signatures in the autosummary.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/schema/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n======\nSchema\n======\n\n.. currentmodule:: polars\n\n.. autoclass:: Schema\n    :members:\n    :noindex:\n    :autosummary:\n    :autosummary-nosignatures:\n```\n\n----------------------------------------\n\nTITLE: Initializing SQLContext in Polars\nDESCRIPTION: This code snippet demonstrates how to initialize a SQLContext in Polars. It creates a DataFrame, and then initializes the SQLContext. No dependencies are required beyond Polars itself.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/sql/intro.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing import assert_frame_equal\n\n\ndf = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"foo\", \"bar\", \"baz\"]\n})\n\n\nctx = pl.SQLContext(register_globals=True)\n```\n\n----------------------------------------\n\nTITLE: Comparing Categorical Columns with String Cache in Polars\nDESCRIPTION: Shows how to enable the string cache to compare Categorical columns efficiently and avoid encoding issues.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\n# Enable string cache\npl.enable_string_cache()\n\n# Create DataFrame with Categorical columns\ndf = pl.DataFrame(\n    {\n        \"category1\": [\"A\", \"B\", \"C\"],\n        \"category2\": [\"B\", \"C\", \"A\"],\n    },\n    schema={\"category1\": pl.Categorical, \"category2\": pl.Categorical},\n)\n\n# Compare Categorical columns\nprint(df.filter(pl.col(\"category1\") == pl.col(\"category2\")))\n\n# Disable string cache\npl.disable_string_cache()\n```\n\n----------------------------------------\n\nTITLE: Computing Two-argument Inverse Tangent in Degrees using ATAN2D\nDESCRIPTION: Shows ATAN2D function usage to compute inverse tangent of two columns in degrees.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame(\n    {\n        \"a\": [-1.0, 0.0, 1.0, 1.0],\n        \"b\": [1.0, 1.0, 0.0, -1.0],\n    }\n)\ndf.sql(\"SELECT a, b, ATAN2D(a, b) AS atan2d_ab FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Initializing ComputeContext in Polars Cloud\nDESCRIPTION: Creates a basic ComputeContext object without specifying any parameters. This will use the workspace default settings for compute resources.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/run/compute-context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nctx = ComputeContext()\n```\n\n----------------------------------------\n\nTITLE: Non-Equi Join Example\nDESCRIPTION: Demonstrates non-equi join using join_where to match players with properties they can afford.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:non-equi\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Field Renaming in a Struct Column with Unnest in Polars\nDESCRIPTION: Demonstrates how to confirm that field names were changed in a Struct column by creating a DataFrame and unnesting the Struct, showing the renamed fields as separate columns.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:struct-rename-check\"\n```\n\n----------------------------------------\n\nTITLE: Checking Streaming Execution with Supported Operations\nDESCRIPTION: Demonstrates how to use the explain() method to determine which parts of a query will execute in streaming mode, showing an example with operations that support streaming.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/_streaming.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/concepts/streaming.py:import\"\n--8<-- \"python/user-guide/concepts/streaming.py:streaming\"\n--8<-- \"python/user-guide/concepts/streaming.py:example\"\n```\n\n----------------------------------------\n\nTITLE: Sorting Athletes by Rank Within Countries Using Window Functions in Polars\nDESCRIPTION: Demonstrates sorting athletes by their rank within their respective countries using window functions. This example uses the 'group_to_rows' mapping strategy to maintain original row positions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndf_sorted = df.select(\n    pl.col(\"*\"),\n    pl.col(\"Name\").sort_by(\"Rank\").over(\"Country\").alias(\"Sorted Name\")\n)\nprint(df_sorted)\n```\n\n----------------------------------------\n\nTITLE: Polars Shuffle/Sample - Random Seed (Before)\nDESCRIPTION: Demonstrates the previous method of setting the random seed for Polars expressions using the built-in Python `random.seed` function. This approach no longer works in newer versions of Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\nrandom.seed(1)\n```\n\n----------------------------------------\n\nTITLE: Clip Method Null Handling in Python\nDESCRIPTION: Shows how the clip method no longer propagates nulls in the bounds, instead retaining the original value when a bound is null.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ndf = pl.DataFrame({\"a\": [0, 1, 2], \"min\": [1, None, 1]})\ndf.select(pl.col(\"a\").clip(\"min\"))\nshape: (3, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ 1    │\n│ null │\n│ 2    │\n└──────┘\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ndf.select(pl.col(\"a\").clip(\"min\"))\nshape: (3, 1)\n┌──────┐\n│ a    │\n│ ---  │\n│ i64  │\n╞══════╡\n│ 1    │\n│ 1    │\n│ 2    │\n└──────┘\n```\n\n----------------------------------------\n\nTITLE: Documenting DataFrame.plot Property in Polars\nDESCRIPTION: This code snippet uses Sphinx directives to document the plot property of the Polars DataFrame class. It sets the current module to polars and uses the autoproperty directive to automatically generate documentation for the DataFrame.plot attribute.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/plot.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: polars\n\n.. autoproperty:: DataFrame.plot\n```\n\n----------------------------------------\n\nTITLE: Resolving Operator Ambiguity with Selectors in Polars\nDESCRIPTION: Illustrates the incorrect use of the '~' operator with selectors, which can lead to unintended column selection.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nimport polars.selectors as cs\n\ndf = pl.DataFrame(\n    {\n        \"has_partner\": [True, False, True],\n        \"has_kids\": [False, True, True],\n        \"has_tattoos\": [True, True, False],\n        \"age\": [25, 30, 35],\n    }\n)\n\nprint(df.select(~cs.starts_with(\"has_\")))\n```\n\n----------------------------------------\n\nTITLE: Converting Degrees to Radians using RADIANS\nDESCRIPTION: Shows conversion from degrees to radians using the RADIANS function.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [0, 90, 180, 270]})\ndf.sql(\"SELECT degs, RADIANS(degs) AS rads FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Documenting LazyFrame.explain Method in Python\nDESCRIPTION: This snippet documents the 'explain' method of the LazyFrame class in Polars. It is probably used to provide a detailed explanation of the LazyFrame's query plan or structure.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/lazyframe/descriptive.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nLazyFrame.explain\n```\n\n----------------------------------------\n\nTITLE: Left-Right Join Equivalence\nDESCRIPTION: Shows that right join is computationally equivalent to left join with swapped arguments.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/joins.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/transformations/joins.py:left-right-join-equals\"\n```\n\n----------------------------------------\n\nTITLE: Using REPLACE Function in Polars SQL\nDESCRIPTION: Shows how to replace substrings within strings using the REPLACE function. Here, it replaces all occurrences of 'b' with '?' in each string.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"abc123\", \"11aabb\", \"bcbc45\"]})\ndf.sql(\"\"\"\n  SELECT foo, REPLACE(foo, 'b', '?') AS bar FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Using value_counts to Create a Struct Column in Polars\nDESCRIPTION: Demonstrates how using value_counts() on a column returns a result with Struct data type, which contains both the values and their counts in a composite column.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/structs.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/structs.py:state_value_counts\"\n```\n\n----------------------------------------\n\nTITLE: Defining DataFrame Style Property in Polars using reStructuredText\nDESCRIPTION: This snippet uses Sphinx documentation directives to set the current module to 'polars' and automatically document the 'style' property of the DataFrame class.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/style.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n.. currentmodule:: polars\n\n.. autoproperty:: DataFrame.style\n```\n\n----------------------------------------\n\nTITLE: Loading Pokémon Dataset with Polars in Python\nDESCRIPTION: Demonstrates how to load a CSV file containing Pokémon data into a Polars DataFrame. The code uses the read_csv function to import the data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/window-functions.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\npokemon = pl.read_csv(\"pokemon.csv\")\nprint(pokemon)\n```\n\n----------------------------------------\n\nTITLE: Run Length Encoding with Renamed Fields in Python\nDESCRIPTION: Shows the updated output of the rle() method, where struct fields have been renamed from 'lengths/values' to 'len/value', and the data type of 'len' is now UInt32.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ns = pl.Series([\"a\", \"a\", \"b\", \"c\", \"c\", \"c\"])\ns.rle().struct.unnest()\n```\n\n----------------------------------------\n\nTITLE: Filtering Data in Polars (Python)\nDESCRIPTION: Example of using the filter method in Polars to select rows based on column values, which is different from Pandas' indexing approach.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/migration/pandas.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndf.filter(pl.col(\"a\") < 10)\n```\n\n----------------------------------------\n\nTITLE: Initializing Paths for Hive Partitioned Data Example in Python\nDESCRIPTION: This code snippet sets up the directory structure for demonstrating hive partitioned data scanning in Polars. It creates paths for different date and category combinations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:init_paths\"\n```\n\n----------------------------------------\n\nTITLE: Generating Sphinx Accessor Documentation\nDESCRIPTION: Template for generating documentation using Sphinx's autoaccessor directive with variable substitution. Handles module splitting and name joining for proper path generation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/accessor.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module.split('.')[0] }}\n\n.. autoaccessor:: {{ (module.split('.')[1:] + [objname]) | join('.') }}\n```\n\n----------------------------------------\n\nTITLE: Series Constructor Strict Parameter Example in Python\nDESCRIPTION: Demonstrates how the Series constructor's 'strict' parameter behavior has changed in version 1, where strict mode is now more rigorously enforced by default and prevents mixed type data unless explicitly disabled.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1, 2, 3.5])\nshape: (3,)\nSeries: '' [f64]\n[\n        1.0\n        2.0\n        3.5\n]\ns = pl.Series([1, 2, 3.5], strict=False)\nshape: (3,)\nSeries: '' [i64]\n[\n        1\n        2\n        null\n]\ns = pl.Series([1, 2, 3.5], strict=False, dtype=pl.Int8)\nSeries: '' [i8]\n[\n        1\n        2\n        null\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns = pl.Series([1, 2, 3.5])\nTraceback (most recent call last):\n...\nTypeError: unexpected value while building Series of type Int64; found value of type Float64: 3.5\n\nHint: Try setting `strict=False` to allow passing data with mixed types.\ns = pl.Series([1, 2, 3.5], strict=False)\nshape: (3,)\nSeries: '' [f64]\n[\n        1.0\n        2.0\n        3.5\n]\ns = pl.Series([1, 2, 3.5], strict=False, dtype=pl.Int8)\nSeries: '' [i8]\n[\n        1\n        2\n        3\n]\n```\n\n----------------------------------------\n\nTITLE: Resetting Individual Configuration Options in Polars (Python)\nDESCRIPTION: Demonstrates how to reset individual configuration options in Polars by setting the related value to None. This example shows resetting the table rows option.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/config.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npl.Config.set_tbl_rows(None)\n```\n\n----------------------------------------\n\nTITLE: Truncating Table in Polars SQL\nDESCRIPTION: Removes all rows from a table while maintaining the table structure and schema.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nTRUNCATE TABLE some_table\n```\n\n----------------------------------------\n\nTITLE: Appending Categorical Series in Polars\nDESCRIPTION: Demonstrates appending two categorical series in Polars, showing how different encodings can lead to compatibility issues.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/categorical-data-and-enums.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncat_series = pl.Series([\"Polar\", \"Panda\", \"Brown\", \"Brown\", \"Polar\"]).cast(pl.Categorical)\ncat2_series = pl.Series([\"Panda\", \"Brown\", \"Brown\", \"Polar\", \"Polar\"]).cast(pl.Categorical)\n\nprint(cat_series.append(cat2_series))\n```\n\n----------------------------------------\n\nTITLE: Printing Optimized Polars Query Plan\nDESCRIPTION: This snippet prints the optimized query plan as text. It shows how the query optimizer has rearranged and potentially simplified the execution steps for better performance.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/lazy/query-plan.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(q.explain())\n```\n\n----------------------------------------\n\nTITLE: Feature Usage Example in Rust\nDESCRIPTION: Example showing the required re-export pattern for external dependencies in IO modules, ensuring cargo.toml dependency is sufficient for usage.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/io/README.md#2025-04-22_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub use csv::Writer;\n```\n\n----------------------------------------\n\nTITLE: Polars DataFrame With Columns - Input Parsing (After)\nDESCRIPTION: Illustrates the updated behavior of `with_columns` when passed `None` in Polars. The `None` input is now treated as a literal null value, and a new column filled with nulls is added to the DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.DataFrame({'a': [1, 2]}).with_columns(None)\nshape: (2, 2)\n┌─────┬─────────┐\n│ a   ┆ literal │\n│ --- ┆ ---     │\n│ i64 ┆ null    │\n╞═════╪═════════╡\n│ 1   ┆ null    │\n│ 2   ┆ null    │\n└─────┴─────────┘\n```\n\n----------------------------------------\n\nTITLE: Installing Polars with Big Index Support for Rust\nDESCRIPTION: Commands to add Polars with big index support in Rust using Cargo. Includes both command-line and Cargo.toml options.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncargo add polars -F bigidx\n\n# Or Cargo.toml\n[dependencies]\npolars = { version = \"x\", features = [\"bigidx\", ...] }\n```\n\n----------------------------------------\n\nTITLE: Handling Duplicate Column Names Error\nDESCRIPTION: Demonstrates the error that occurs when an operation would result in duplicate column names, highlighting the need for column renaming.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:duplicate-error\"\n```\n\n----------------------------------------\n\nTITLE: Polars Series Constructor - Error Type (After)\nDESCRIPTION: Illustrates the updated error type returned when passing an unsupported type to the Polars Series constructor in version 0.19.  The code demonstrates that a `TypeError` is now raised instead of a `ValueError`.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.Series(values=15)\n...\nTypeError: Series constructor called with unsupported type 'int' for the `values` parameter\n```\n\n----------------------------------------\n\nTITLE: Reshape Method Returns Array Type in Python\nDESCRIPTION: Shows how the reshape method now returns an Array type instead of a List type, requiring users to call .arr.to_list() to restore the old functionality if needed.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ns = pl.Series([1, 2, 3, 4, 5, 6])\ns.reshape((2, 3))\nshape: (2,)\nSeries: '' [list[i64]]\n[\n        [1, 2, 3]\n        [4, 5, 6]\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\ns.reshape((2, 3))\nshape: (2,)\nSeries: '' [array[i64, 3]]\n[\n        [1, 2, 3]\n        [4, 5, 6]\n]\n```\n\n----------------------------------------\n\nTITLE: Computing Cosine in Degrees using COSD\nDESCRIPTION: Shows COSD function usage to compute cosine in degrees for DataFrame column values.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/trigonometry.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"degs\": [0, 45, 180, 225]})\ndf.sql(\"SELECT degs, COSD(degs) AS cosd FROM self\")\n```\n\n----------------------------------------\n\nTITLE: Installing Excel-related Dependencies for Polars in Python\nDESCRIPTION: This command installs the necessary Python packages for reading Excel files with Polars using different engines.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install fastexcel xlsx2csv openpyxl\n```\n\n----------------------------------------\n\nTITLE: Adding polars-testing dependency in Cargo.toml\nDESCRIPTION: This snippet shows how to add the polars-testing crate as a dependency in a Rust project's Cargo.toml file. It specifies version 0.46.0 of the crate.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-testing/README.md#2025-04-22_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[dependencies]\npolars-testing = \"0.46.0\"\n```\n\n----------------------------------------\n\nTITLE: 2D NumPy Array Parsing as Array Type in Python\nDESCRIPTION: Demonstrates how 2D NumPy arrays are now parsed as an Array type rather than a List type when passed to the Series constructor.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Before:\nimport numpy as np\narr = np.array([[1, 2], [3, 4]])\npl.Series(arr)\nshape: (2,)\nSeries: '' [list[i64]]\n[\n        [1, 2]\n        [3, 4]\n]\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\nimport numpy as np\narr = np.array([[1, 2], [3, 4]])\npl.Series(arr)\nshape: (2,)\nSeries: '' [array[i64, 2]]\n[\n        [1, 2]\n        [3, 4]\n]\n```\n\n----------------------------------------\n\nTITLE: Creating Doctest with IGNORE_RESULT Directive in Polars\nDESCRIPTION: Example of using the IGNORE_RESULT directive in doctests when the output may be random or not interesting to verify.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/test.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> df.sample(n=2)  # doctest: +IGNORE_RESULT\n```\n\n----------------------------------------\n\nTITLE: Installing Polars for Rust\nDESCRIPTION: Commands to add Polars as a dependency in Rust using Cargo. Includes both command-line and Cargo.toml options.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncargo add polars -F lazy\n\n# Or Cargo.toml\n[dependencies]\npolars = { version = \"x\", features = [\"lazy\", ...]}\n```\n\n----------------------------------------\n\nTITLE: Installing xlsxwriter for Writing Excel Files with Polars in Python\nDESCRIPTION: This command installs the xlsxwriter library, which is required for writing Excel files using Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/excel.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install xlsxwriter\n```\n\n----------------------------------------\n\nTITLE: Calculating Percentage Rank within Lists in Polars\nDESCRIPTION: This snippet demonstrates using eval with pl.element and pl.all() to calculate the percentage rank of temperatures by day across stations. It shows how to create custom ranking expressions for list elements.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/lists-and-arrays.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/lists.py:rank_pct\"\n```\n\n----------------------------------------\n\nTITLE: Handling Error when Scanning Mixed Files in Hive Directory using Polars in Python\nDESCRIPTION: This snippet demonstrates the error that occurs when trying to scan a directory with mixed file types using scan_parquet without specifying a file pattern.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/io/hive.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/io/hive.py:scan_dir_err\"\n```\n\n----------------------------------------\n\nTITLE: Importing Polars CSV Batched Reader Module\nDESCRIPTION: This snippet shows the import statement for the Polars CSV batched reader module, which is used for reading CSV files in batches.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/io.rst#2025-04-22_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars.io.csv.batched_reader\n```\n\n----------------------------------------\n\nTITLE: Installing Polars for Python\nDESCRIPTION: Commands to install Polars using pip. Includes an option for legacy CPUs without AVX2 support.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/installation.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install polars\n\n# Or for legacy CPUs without AVX2 support\npip install polars-lts-cpu\n```\n\n----------------------------------------\n\nTITLE: Inefficient Column Generation with For Loop\nDESCRIPTION: Shows an inefficient approach using a for loop to apply different calculations to multiple columns sequentially.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/expressions/expression-expansion.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/expressions/expression-expansion.py:for-with_columns\"\n```\n\n----------------------------------------\n\nTITLE: Generating Accessor Attribute Documentation in RST\nDESCRIPTION: A reStructuredText template that configures documentation for a Polars accessor attribute. Uses Jinja templating variables to dynamically insert the full name, module path, and object name. The template sets up proper module context and uses the autoaccessorattribute directive.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/accessor_attribute.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module.split('.')[0] }}\n\n.. autoaccessorattribute:: {{ (module.split('.')[1:] + [objname]) | join('.') }}\n```\n\n----------------------------------------\n\nTITLE: Polars Series All - Null Handling (After)\nDESCRIPTION: Illustrates the updated behavior of the `all` function in Polars, where null values are now ignored by default and not treated as `False`. The code example demonstrates how `all` now evaluates a Series containing a null value.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.Series([True, None]).all()\nTrue\n```\n\n----------------------------------------\n\nTITLE: Filter Context Implementation\nDESCRIPTION: Shows how to filter rows using boolean expressions to select specific data points.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/expressions-and-contexts.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndf.filter(pl.col(\"height\") >= 1.7)\n```\n\n----------------------------------------\n\nTITLE: Disabling GPU Fallback in Polars\nDESCRIPTION: Example of disabling fallback to CPU execution by configuring the GPUEngine to raise an exception on unsupported queries.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/gpu-support.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nq.collect(engine=pl.GPUEngine(raise_on_fail=True))\n```\n\n----------------------------------------\n\nTITLE: Advanced Parametric Testing with Custom Strategies in Python\nDESCRIPTION: Creates and uses a List[UInt8] dtype strategy as a hypothesis composite that generates pairs of pairs of small integer values in which the first value in each nested pair is always less than or equal to the second value.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/testing.rst#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\nfrom polars.testing.parametric import column, dataframes, lists\n\nimport hypothesis.strategies as st\nfrom hypothesis import given\n\n@st.composite\ndef uint8_pairs(draw: st.DrawFn):\n    uints = lists(pl.UInt8, size=2)\n    pairs = list(zip(draw(uints), draw(uints)))\n    return [sorted(ints) for ints in pairs]\n\n@given(\n    dataframes(\n        cols=[\n            column(\"colx\", strategy=uint8_pairs()),\n            column(\"coly\", strategy=uint8_pairs()),\n            column(\"colz\", strategy=uint8_pairs()),\n        ],\n        min_size=3,\n        max_size=3,\n    )\n)\ndef test_miscellaneous(df: pl.DataFrame): ...\n\n    # Example frame:\n    # ┌─────────────────────────┬─────────────────────────┬──────────────────────────┐\n    # │ colx                    ┆ coly                    ┆ colz                     │\n    # │ ---                     ┆ ---                     ┆ ---                      │\n    # │ list[list[i64]]         ┆ list[list[i64]]         ┆ list[list[i64]]          │\n    # ╞═════════════════════════╪═════════════════════════╪══════════════════════════╡\n    # │ [[143, 235], [75, 101]] ┆ [[143, 235], [75, 101]] ┆ [[31, 41], [57, 250]]    │\n    # │ [[87, 186], [174, 179]] ┆ [[87, 186], [174, 179]] ┆ [[112, 213], [149, 221]] │\n    # │ [[23, 85], [7, 86]]     ┆ [[23, 85], [7, 86]]     ┆ [[22, 255], [27, 28]]    │\n    # └─────────────────────────┴─────────────────────────┴──────────────────────────┘\n```\n\n----------------------------------------\n\nTITLE: DataFrame Construction Data Orientation Inference in Python\nDESCRIPTION: Shows the updated DataFrame constructor behavior where data orientation is now inferred based on dimensions rather than inspecting data types, requiring explicit orientation specification for row-based data.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Before:\ndata = [[1, \"a\"], [2, \"b\"]]\npl.DataFrame(data)\nshape: (2, 2)\n┌──────────┬──────────┐\n│ column_0 ┆ column_1 │\n│ ---      ┆ ---      │\n│ i64      ┆ str      │\n╞══════════╪══════════╡\n│ 1        ┆ a        │\n│ 2        ┆ b        │\n└──────────┴──────────┘\n```\n\nLANGUAGE: python\nCODE:\n```\n# After:\npl.DataFrame(data)\nTraceback (most recent call last):\n...\nTypeError: unexpected value while building Series of type Int64; found value of type String: \"a\"\n\nHint: Try setting `strict=False` to allow passing data with mixed types.\n```\n\nLANGUAGE: python\nCODE:\n```\n# Use instead:\npl.DataFrame(data, orient=\"row\")\nshape: (2, 2)\n┌──────────┬──────────┐\n│ column_0 ┆ column_1 │\n│ ---      ┆ ---      │\n│ i64      ┆ str      │\n╞══════════╪══════════╡\n│ 1        ┆ a        │\n│ 2        ┆ b        │\n└──────────┴──────────┘\n```\n\n----------------------------------------\n\nTITLE: Dropping Tables in Polars SQL\nDESCRIPTION: Completely removes a table from the database and unregisters it from the context.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/table_operations.rst#2025-04-22_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nDROP TABLE old_table\n```\n\n----------------------------------------\n\nTITLE: LazyFrame Serialization in JSON Format (Before)\nDESCRIPTION: Example showing how LazyFrame objects were previously serialized to JSON format by default, using StringIO for deserialization of the text-based format.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n>>> lf = pl.LazyFrame({\"a\": [1, 2, 3]}).sum()\n>>> serialized = lf.serialize()\n>>> serialized\n'{\"MapFunction\":{\"input\":{\"DataFrameScan\":{\"df\":{\"columns\":[{\"name\":...'\n>>> from io import StringIO\n>>> pl.LazyFrame.deserialize(StringIO(serialized)).collect()\nshape: (1, 1)\n┌─────┐\n│ a   │\n│ --- │\n│ i64 │\n╞═════╡\n│ 6   │\n└─────┘\n```\n\n----------------------------------------\n\nTITLE: Configuring launch.json for Rust/Python Debugging in Visual Studio Code\nDESCRIPTION: Comprehensive launch configuration for VSCode to enable debugging of both Rust and Python code in the Polars project. It sets up a Python debugger and attaches a Rust LLDB debugger for seamless debugging across languages.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/ide.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"configurations\": [\n    {\n      \"name\": \"Debug Rust/Python\",\n      \"type\": \"debugpy\",\n      \"request\": \"launch\",\n      \"program\": \"${workspaceFolder}/py-polars/debug/launch.py\",\n      \"args\": [\n        \"${file}\"\n      ],\n      \"console\": \"internalConsole\",\n      \"justMyCode\": true,\n      \"serverReadyAction\": {\n        \"pattern\": \"pID = ([0-9]+)\",\n        \"action\": \"startDebugging\",\n        \"name\": \"Rust LLDB\"\n      }\n    },\n    {\n      \"name\": \"Rust LLDB\",\n      \"pid\": \"0\",\n      \"type\": \"lldb\",\n      \"request\": \"attach\",\n      \"program\": \"${workspaceFolder}/py-polars/.venv/bin/python\",\n      \"stopOnEntry\": false,\n      \"sourceLanguages\": [\n        \"rust\"\n      ],\n      \"presentation\": {\n        \"hidden\": true\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Polars DataFrame Miscellaneous Methods\nDESCRIPTION: This code snippet shows the import statement for the Polars library and lists the miscellaneous methods available for DataFrame objects. These methods include collect_schema, corr, equals, lazy, and map_rows.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/miscellaneous.rst#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    DataFrame.collect_schema\n    DataFrame.corr\n    DataFrame.equals\n    DataFrame.lazy\n    DataFrame.map_rows\n```\n\n----------------------------------------\n\nTITLE: Markdown Code Block Template for Documentation\nDESCRIPTION: Template showing how to reference code snippets in markdown documentation using the code_block macro.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n{{code_block('user-guide/io/cloud-storage','read_parquet',['read_parquet','read_csv'])}}\n```\n\n----------------------------------------\n\nTITLE: Creating Arrays from Rust Native Types\nDESCRIPTION: Illustrates the naming conventions for methods that create new arrays from native Rust types, including from, from_slice, and various iterator-based methods.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/array/README.md#2025-04-22_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nimpl SomeArray {\n    fn from(values: impl AsRef<[Option<T>]>) -> Self { /* ... */ }\n    fn from_slice(values: impl AsRef<[T]>) -> Self { /* ... */ }\n    fn from_trusted_len_iter(iter: impl TrustedLen<Item = Option<T>>) -> Self { /* ... */ }\n    fn from_trusted_len_values_iter(iter: impl TrustedLen<Item = T>) -> Self { /* ... */ }\n    fn try_from_trusted_len_iter(iter: impl TrustedLen<Item = Result<Option<T>, E>>) -> Result<Self, E> { /* ... */ }\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Datetime DataType Class Variables (After)\nDESCRIPTION: Example showing how attempting to access time_unit as a class variable now raises an AttributeError, as these have been correctly changed to instance variables.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/1.md#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\n>>> dtype.time_unit is None\nTraceback (most recent call last):\n...\nAttributeError: type object 'Datetime' has no attribute 'time_unit'\n```\n\n----------------------------------------\n\nTITLE: Using Polars Config as a Context Manager with Explicit Method Calls (Python)\nDESCRIPTION: Illustrates how to use the Polars Config class as a context manager by initializing a Config instance and explicitly calling configuration methods within the context.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/config.rst#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith pl.Config() as cfg:\n    cfg.set_verbose(True)\n    do_various_things()\n\n# on scope exit any modified settings are restored to their previous state\n```\n\n----------------------------------------\n\nTITLE: Accessing Polars Meta Expression Methods\nDESCRIPTION: Example of available meta methods that can be accessed through the expr.meta attribute in Polars. These methods provide metadata operations and information about expressions.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/meta.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nExpr.meta.eq\nExpr.meta.has_multiple_outputs\nExpr.meta.is_column\nExpr.meta.is_column_selection\nExpr.meta.is_literal\nExpr.meta.is_regex_projection\nExpr.meta.ne\nExpr.meta.output_name\nExpr.meta.pop\nExpr.meta.root_names\nExpr.meta.serialize\nExpr.meta.show_graph\nExpr.meta.tree_format\nExpr.meta.undo_aliases\nExpr.meta.write_json\n```\n\n----------------------------------------\n\nTITLE: Series Categorical Methods Reference\nDESCRIPTION: List of available categorical methods accessible through the Series.cat attribute in Polars. Includes methods for string manipulation, category management, and property inspection.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/categories.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\nSeries.cat.ends_with\nSeries.cat.get_categories\nSeries.cat.is_local\nSeries.cat.len_bytes\nSeries.cat.len_chars\nSeries.cat.starts_with\nSeries.cat.to_local\nSeries.cat.uses_lexical_ordering\n```\n\n----------------------------------------\n\nTITLE: Modulo Function (MOD) in Polars SQL\nDESCRIPTION: Shows MOD function usage for calculating remainder of division.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/math.rst#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"x\": [0, 1, 2, 3, 4]})\ndf.sql(\"\"\"\n  SELECT x, MOD(x, 2) AS a_mod_2 FROM self\n\"\"\")\n```\n\n----------------------------------------\n\nTITLE: Markdown Navigation Links for Polars Transformations\nDESCRIPTION: Navigation links to different transformation operation documentation pages including joins, concatenation, pivot, and unpivot operations.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/transformations/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [Joins](joins.md)\n- [Concatenation](concatenation.md)\n- [Pivot](pivot.md)\n- [Unpivot](unpivot.md)\n```\n\n----------------------------------------\n\nTITLE: Binary Methods Reference List in RST\nDESCRIPTION: List of available binary methods under the expr.bin attribute, formatted as restructured text documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/binary.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n   :template: autosummary/accessor_method.rst\n\n    Expr.bin.contains\n    Expr.bin.decode\n    Expr.bin.encode\n    Expr.bin.ends_with\n    Expr.bin.reinterpret\n    Expr.bin.size\n    Expr.bin.starts_with\n```\n\n----------------------------------------\n\nTITLE: Updating Polars Dependencies in Bash\nDESCRIPTION: Commands to update Python dependencies and the Rust toolchain for Polars development.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/index.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake requirements\nrustup update\ncargo clean\n```\n\n----------------------------------------\n\nTITLE: Calculating String Bit Length in Polars SQL\nDESCRIPTION: Demonstrates using the BIT_LENGTH function to calculate the length of strings in bits. This function returns the number of bits needed to represent each string.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/functions/string.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndf = pl.DataFrame({\"foo\": [\"a\", \"bb\", \"ccc\", \"dddd\"]})\ndf.sql(\"\"\"\n  SELECT foo, BIT_LENGTH(foo) AS n_bits FROM self\n\"\"\")\n# shape: (4, 2)\n# ┌──────┬────────┐\n# │ foo  ┆ n_bits │\n# │ ---  ┆ ---    │\n# │ str  ┆ u32    │\n# ╞══════╪════════╡\n# │ a    ┆ 8      │\n# │ bb   ┆ 16     │\n# │ ccc  ┆ 24     │\n# │ dddd ┆ 32     │\n# └──────┴────────┘\n```\n\n----------------------------------------\n\nTITLE: Configuring rust-analyzer Settings in Visual Studio Code for Polars\nDESCRIPTION: JSON configuration for the rust-analyzer extension in VSCode, enabling all Cargo features and setting the target directory for better compatibility with the Polars codebase.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/ide.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"rust-analyzer.cargo.features\": \"all\",\n  \"rust-analyzer.cargo.targetDir\": true\n}\n```\n\n----------------------------------------\n\nTITLE: ReStructuredText Documentation Directives for Polars Columns\nDESCRIPTION: ReStructuredText directives defining documentation structure for Polars column operations, including module reference and API documentation generation commands.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/expressions/columns.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n    Expr.alias\n    Expr.exclude\n\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   col\n```\n\n----------------------------------------\n\nTITLE: Running Parametric Tests with Hypothesis in Polars\nDESCRIPTION: Command for running parametric tests using the Hypothesis framework in Polars.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/test.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npytest -m hypothesis\n```\n\n----------------------------------------\n\nTITLE: Window Operation with Single Column\nDESCRIPTION: Multiplies columns 'foo' and 'bar', computes their sum over a window grouped by 'ham' column, and divides the result by 2.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/tests/unit/operations/namespaces/files/test_tree_fmt.txt#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n(pl.col(\"foo\") * pl.col(\"bar\")).sum().over(pl.col(\"ham\")) / 2\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Unimplemented Functionality in Rust\nDESCRIPTION: Shows how the crate may handle unimplemented functionality, either by returning a specific error or using a panic macro.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/README.md#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nunimplemented!\n```\n\n----------------------------------------\n\nTITLE: Polars Series Constructor - Error Type (Before)\nDESCRIPTION: Demonstrates the error type returned when passing an unsupported type to the Polars Series constructor before version 0.19.  The code shows that a `ValueError` was raised.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/upgrade/0.19.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n>>> pl.Series(values=15)\n...\nValueError: Series constructor called with unsupported type; got 'int'\n```\n\n----------------------------------------\n\nTITLE: Creating Named Series in Polars\nDESCRIPTION: Demonstrates how to create a basic named Series object in Polars. A Series is a 1-dimensional homogeneous data structure where all elements share the same data type.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/concepts/data-types-and-structures.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport polars as pl\n\ns = pl.Series(name=\"a\", values=[1, 2, 3, 4, 5])\nprint(s)\n```\n\n----------------------------------------\n\nTITLE: Implementing Slice Method for Arrays in Rust\nDESCRIPTION: Shows the required slice method implementation for arrays, which returns an offsetted and/or truncated clone of the array.\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-arrow/src/array/README.md#2025-04-22_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nimpl SomeArray {\n    fn slice(&self, offset: usize, length: usize) -> Self {\n        // Implementation that increases the array's offset if it exists\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Partition Module\nDESCRIPTION: This snippet shows the import statement for the Polars partition module, which is used for various partitioning strategies when writing data to disk.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/io.rst#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n.. currentmodule:: polars.io.partition\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation for Polars DataFrame\nDESCRIPTION: This RST code snippet sets up the Sphinx documentation structure for the Polars DataFrame class. It defines the table of contents, links to subpages, and configures the autoclass directive for the DataFrame.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/dataframe/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n=========\nDataFrame\n=========\n\nThis page gives an overview of all public DataFrame methods.\n\n.. toctree::\n   :maxdepth: 2\n   :hidden:\n\n   aggregation\n   attributes\n   computation\n   descriptive\n   export\n   group_by\n   modify_select\n   miscellaneous\n   plot\n   style\n\n.. _dataframe:\n\n.. currentmodule:: polars\n\n.. autoclass:: DataFrame\n    :members:\n    :noindex:\n    :autosummary:\n    :autosummary-nosignatures:\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Autodoc for Polars DataFrame Class\nDESCRIPTION: This snippet sets up the Sphinx autodoc configuration for documenting the Polars DataFrame class. It specifies the current module and autoclass directive for the DataFrame object.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/class_without_autosummary.rst#2025-04-22_snippet_0\n\nLANGUAGE: reStructuredText\nCODE:\n```\n{{ fullname }}\n{{ underline }}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n```\n\n----------------------------------------\n\nTITLE: Importing Polars Testing Module in Python\nDESCRIPTION: Demonstrates how to import specific functions from the Polars testing module, which is not imported by default to optimize import speed of the primary polars module.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/testing.rst#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom polars.testing import assert_frame_equal, assert_series_equal\n```\n\n----------------------------------------\n\nTITLE: Seaborn Integration with Polars\nDESCRIPTION: This snippet integrates Seaborn with Polars DataFrames for visualization.  It leverages the dataframe interchange protocol for zero-copy conversion between Polars and Seaborn where possible. Not all Polars data types are supported by the interchange protocol.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/user-guide/misc/visualization.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n--8<-- \"python/user-guide/misc/visualization.py:seaborn_make_plot\"\n```\n\n----------------------------------------\n\nTITLE: Managing Polars Cloud Workspaces\nDESCRIPTION: Commands for managing Polars Cloud workspaces, including setup and listing all available workspaces.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/polars-cloud/cli.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npc workspace setup\n```\n\nLANGUAGE: bash\nCODE:\n```\npc workspace list\n```\n\nLANGUAGE: text\nCODE:\n```\nNAME           \tID                                    STATUS\ntest-workspace \t0194ac0e-5122-7a90-af5e-b1f60b1989f4  Active\npolars-ci-2025…\t0194287a-e0a5-7642-8058-0f79a39f5b98  Uninitialized\n```\n\n----------------------------------------\n\nTITLE: Running Benchmark Tests in Polars\nDESCRIPTION: Command for running benchmark tests in Polars with duration reporting and verbose output.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/development/contributing/test.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npytest -m benchmark --durations 0 -v\n```\n\n----------------------------------------\n\nTITLE: Displaying Polars Changelog Information in Markdown\nDESCRIPTION: This snippet contains the content of the changelog file, explaining that Polars uses GitHub to manage releases for both Python and Rust versions, and directs users to the GitHub releases page for detailed changelog information.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/releases/changelog.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Changelog\n\nPolars uses GitHub to manage both Python and Rust releases.\n\nRefer to our [GitHub releases page](https://github.com/pola-rs/polars/releases) for the changelog\nassociated with each new release.\n```\n\n----------------------------------------\n\nTITLE: Defining Series Attributes in Sphinx RST Documentation\nDESCRIPTION: Sphinx RST documentation defining the module and autosummary for Polars Series attributes. Lists core Series properties that can be accessed.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/series/attributes.rst#2025-04-22_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: polars\n.. autosummary::\n   :toctree: api/\n\n   Series.dtype\n   Series.flags\n   Series.name\n   Series.shape\n```\n\n----------------------------------------\n\nTITLE: Defining CI Test Requirements for Polars in pip\nDESCRIPTION: This snippet specifies the package requirements for running Polars unit tests on CI. It includes torch (with version and platform constraints), jax[cpu], and pyiceberg (version 0.7.1 or higher). An additional PyTorch index URL is also specified.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/requirements-ci.txt#2025-04-22_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\n--extra-index-url https://download.pytorch.org/whl/cpu\ntorch; python_version < '3.13' or platform_system != 'Windows'  # torch provides no wheel for Python 3.13 on Windows\njax[cpu]\npyiceberg>=0.7.1\n```\n\n----------------------------------------\n\nTITLE: Installing Polars for Legacy CPUs with pip\nDESCRIPTION: Command to install a version of Polars compiled without AVX (Advanced Vector Extensions) target features for compatibility with older CPUs dating from before 2011 or for x86-64 builds of Python on Apple Silicon under Rosetta.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip install polars-lts-cpu\n```\n\n----------------------------------------\n\nTITLE: Listing Core Dependencies for Polars Project\nDESCRIPTION: This snippet lists the main dependencies required for the Polars project, including data visualization libraries and data processing tools. It includes a conditional requirement for numba based on the Python version.\nSOURCE: https://github.com/pola-rs/polars/blob/main/docs/source/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\naltair\npandas\npyarrow\ngraphviz\nhvplot\nmatplotlib\nplotnine\nseaborn\nplotly\nnumba >= 0.54; python_version < '3.13'  # numba does not support Python 3.13\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Styling Documentation TOC Elements with CSS\nDESCRIPTION: CSS style definition to hide first child elements of toctree list items within documentation cards\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/catalog/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: css\nCODE:\n```\ndiv.sd-card-body.docutils li.toctree-l1 > :first-child {display: none;}\n```\n\n----------------------------------------\n\nTITLE: Methods Block Override\nDESCRIPTION: Custom block for handling method documentation that hides the autosummary from output while still generating pages for non-private methods and __call__\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/class.rst#2025-04-22_snippet_1\n\nLANGUAGE: jinja2\nCODE:\n```\n{% block methods %}\n{% if methods %}\n\n..\n   HACK -- the point here is that we don't want this to appear in the output, but the autosummary should still generate the pages.\n   .. autosummary::\n      :toctree:\n      {% for item in all_methods %}\n      {%- if not item.startswith('_') or item in ['__call__'] %}\n      {{ name }}.{{ item }}\n      {%- endif -%}\n      {%- endfor %}\n\n{% endif %}\n{% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Attributes Block Override\nDESCRIPTION: Custom block for handling attribute documentation that hides the autosummary from output while still generating pages for non-private attributes\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/_templates/autosummary/class.rst#2025-04-22_snippet_2\n\nLANGUAGE: jinja2\nCODE:\n```\n{% block attributes %}\n{% if attributes %}\n\n..\n   HACK -- the point here is that we don't want this to appear in the output, but the autosummary should still generate the pages.\n   .. autosummary::\n      :toctree:\n      {% for item in all_attributes %}\n      {%- if not item.startswith('_') %}\n      {{ name }}.{{ item }}\n      {%- endif -%}\n      {%- endfor %}\n\n{% endif %}\n{% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Styling HTML for RST Documentation\nDESCRIPTION: This HTML snippet applies custom styling to hide the first child of list items with the class 'toctree-l1' within a 'sd-card-body' div. It's used to customize the appearance of the documentation.\nSOURCE: https://github.com/pola-rs/polars/blob/main/py-polars/docs/source/reference/sql/index.rst#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<style>\n  div.sd-card-body.docutils li.toctree-l1 > :first-child {display: none;}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Referencing Polars-Ops Package Name\nDESCRIPTION: Shows the package name reference for the internal operations sub-crate of Polars\nSOURCE: https://github.com/pola-rs/polars/blob/main/crates/polars-ops/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\npolars-ops\n```"
  }
]