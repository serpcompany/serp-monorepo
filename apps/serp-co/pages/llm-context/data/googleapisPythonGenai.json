[
  {
    "owner": "googleapis",
    "repo": "python-genai",
    "content": "TITLE: Generating Text Content\nDESCRIPTION: Generates content using the Gemini model with a simple text prompt.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Text Input\nDESCRIPTION: Example of generating content using the Gemini model with a text prompt\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Chat Session with Python GenAI Client\nDESCRIPTION: This snippet shows how to create a chat session and send a message using the 'gemini-2.0-flash-001' model. It demonstrates both synchronous and streaming message sending.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(model='gemini-2.0-flash-001')\nresponse = chat.send_message('tell me a story')\nprint(response.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(model='gemini-2.0-flash-001')\nfor chunk in chat.send_message_stream('tell me a story'):\n    print(chunk.text)\n```\n\n----------------------------------------\n\nTITLE: Initializing Vertex AI Client\nDESCRIPTION: Creates a client instance for Vertex AI with project and location settings.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(\n    vertexai=True, project='your-project-id', location='us-central1'\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Text Content from Gemini Models\nDESCRIPTION: Demonstrates how to stream text responses from Gemini models for incremental content delivery. This is useful for providing real-time feedback to users as the response is generated.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Streaming Text Content from Gemini Models\nDESCRIPTION: Shows how to stream text responses from a Gemini model incrementally instead of waiting for the complete response. This is useful for displaying results to users as they are generated.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Using Async Content Generation with Gemini\nDESCRIPTION: Demonstrates asynchronous content generation with Gemini models using Python's asyncio. This allows for non-blocking operations in asynchronous applications.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nresponse = await client.aio.models.generate_content(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Token Counting with Python GenAI Client\nDESCRIPTION: This snippet demonstrates how to count tokens for a given text using the 'gemini-2.0-flash-001' model. It's useful for understanding the token usage of your prompts.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.count_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Creating Gemini API Client\nDESCRIPTION: Initialize client for Gemini Developer API using an API key\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(api_key='GEMINI_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gen AI SDK\nDESCRIPTION: Command to install the Google Gen AI Python package using pip.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install google-genai\n```\n\n----------------------------------------\n\nTITLE: Installing Google GenAI Package\nDESCRIPTION: Command to install the google-genai package using pip\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install google-genai\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini API Environment Variables\nDESCRIPTION: Configures environment variables for Gemini Developer API authentication.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport GOOGLE_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Creating Default Client\nDESCRIPTION: Creates a client instance using environment variables.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client()\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini API Client\nDESCRIPTION: Creates a client instance for the Gemini Developer API using an API key.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(api_key='GEMINI_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Importing Google GenAI Modules\nDESCRIPTION: Basic imports required for using the Google GenAI SDK\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample File\nDESCRIPTION: Downloads a sample text file for content generation.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\n!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring Safety Settings for Content Generation in Python\nDESCRIPTION: Shows how to set up safety settings when generating content using the Google AI Python client. This example blocks high-level hate speech in the generated content.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Say something bad.',\n    config=types.GenerateContentConfig(\n        safety_settings=[\n            types.SafetySetting(\n                category='HARM_CATEGORY_HATE_SPEECH',\n                threshold='BLOCK_ONLY_HIGH',\n            )\n        ]\n    ),\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Manually Declaring and Using Function Calling with Gemini\nDESCRIPTION: Demonstrates how to manually declare a function and pass it as a tool to the model without using the automatic function support. This approach gives more control over function definitions.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfunction = types.FunctionDeclaration(\n    name='get_current_weather',\n    description='Get the current weather in a given location',\n    parameters=types.Schema(\n        type='OBJECT',\n        properties={\n            'location': types.Schema(\n                type='STRING',\n                description='The city and state, e.g. San Francisco, CA',\n            ),\n        },\n        required=['location'],\n    ),\n)\n\ntool = types.Tool(function_declarations=[function])\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What is the weather like in Boston?',\n    config=types.GenerateContentConfig(tools=[tool]),\n)\n\nprint(response.function_calls[0])\n```\n\n----------------------------------------\n\nTITLE: Importing Gen AI Modules\nDESCRIPTION: Basic imports required for using the Gen AI SDK.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Accessing Function Calls from Gemini Response\nDESCRIPTION: Shows how to retrieve function calls recommended by the model from the response when automatic function calling is disabled.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfunction_calls: Optional[List[types.FunctionCall]] = response.function_calls\n```\n\n----------------------------------------\n\nTITLE: Using Pydantic Models for Response Schema in Gemini\nDESCRIPTION: Demonstrates how to use Pydantic models to define the structure of JSON responses from the Gemini model. This provides type validation and structured output.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\n\nclass CountryInfo(BaseModel):\n    name: str\n    population: int\n    capital: str\n    continent: str\n    gdp: int\n    official_language: str\n    total_area_sq_mi: int\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Give me information for the United States.',\n    config=types.GenerateContentConfig(\n        response_mime_type='application/json',\n        response_schema=CountryInfo,\n    ),\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Setting Vertex AI Environment Variables\nDESCRIPTION: Configures environment variables for Vertex AI authentication and settings.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='your-project-id'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n```\n\n----------------------------------------\n\nTITLE: Using Manual Schema Definition for JSON Responses in Gemini\nDESCRIPTION: Shows how to manually define a schema for JSON responses from the Gemini model without using Pydantic. This approach provides more flexibility in schema definition.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Give me information for the United States.',\n    config=types.GenerateContentConfig(\n        response_mime_type='application/json',\n        response_schema={\n            'required': [\n                'name',\n                'population',\n                'capital',\n                'continent',\n                'gdp',\n                'official_language',\n                'total_area_sq_mi',\n            ],\n            'properties': {\n                'name': {'type': 'STRING'},\n                'population': {'type': 'INTEGER'},\n                'capital': {'type': 'STRING'},\n                'continent': {'type': 'STRING'},\n                'gdp': {'type': 'INTEGER'},\n                'official_language': {'type': 'STRING'},\n                'total_area_sq_mi': {'type': 'INTEGER'},\n            },\n            'type': 'OBJECT',\n        },\n    ),\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Streaming Content Generation with Python GenAI Client\nDESCRIPTION: This code shows how to use the streaming functionality of the generate_content method. It generates a 300-word story and prints the chunks of text as they are received.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\nasync for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Async Token Counting with Python GenAI Client\nDESCRIPTION: This snippet demonstrates the async version of token counting using the 'gemini-2.0-flash-001' model. It's useful for integrating token counting into asynchronous workflows.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nresponse = await client.aio.models.count_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens Asynchronously with Gemini\nDESCRIPTION: Demonstrates how to count tokens asynchronously in Gemini models. This allows for non-blocking token counting operations in async applications.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nresponse = await client.aio.models.count_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Configuring Function Calling with ANY Mode and Disabled Auto Calling\nDESCRIPTION: Demonstrates how to configure function calling to use ANY mode with disabled automatic function calling. In ANY mode, the model will always return function call parts regardless of confidence.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location: str) -> str:\n    \"\"\"Returns the current weather.\n\n    Args:\n      location: The city and state, e.g. San Francisco, CA\n    \"\"\"\n    return \"sunny\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash-001\",\n    contents=\"What is the weather like in Boston?\",\n    config=types.GenerateContentConfig(\n        tools=[get_current_weather],\n        automatic_function_calling=types.AutomaticFunctionCallingConfig(\n            disable=True\n        ),\n        tool_config=types.ToolConfig(\n            function_calling_config=types.FunctionCallingConfig(mode='ANY')\n        ),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Content from File\nDESCRIPTION: Generates content by analyzing an uploaded file using the Gemini model.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfile = client.files.upload(file='a11.txt')\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents=['Could you summarize this file?', file]\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Listing Tuning Jobs with Python GenAI Client\nDESCRIPTION: This code shows how to list tuning jobs using the Python GenAI client. It demonstrates both iterating through all jobs and using pagination.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_43\n\nLANGUAGE: python\nCODE:\n```\nfor job in client.tunings.list(config={'page_size': 10}):\n    print(job)\n```\n\nLANGUAGE: python\nCODE:\n```\npager = client.tunings.list(config={'page_size': 10})\nprint(pager.page_size)\nprint(pager[0])\npager.next_page()\nprint(pager[0])\n```\n\n----------------------------------------\n\nTITLE: Async Chat Session with Python GenAI Client\nDESCRIPTION: This code demonstrates how to use async chat sessions with the 'gemini-2.0-flash-001' model. It includes examples for both regular and streaming async message sending.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_37\n\nLANGUAGE: python\nCODE:\n```\nchat = client.aio.chats.create(model='gemini-2.0-flash-001')\nresponse = await chat.send_message('tell me a story')\nprint(response.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nchat = client.aio.chats.create(model='gemini-2.0-flash-001')\nasync for chunk in await chat.send_message_stream('tell me a story'):\n    print(chunk.text)\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Chat Sessions with Gemini\nDESCRIPTION: Shows how to create a chat session for multi-turn conversations with Gemini models. This enables maintaining context across multiple interactions.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(model='gemini-2.0-flash-001')\nresponse = chat.send_message('tell me a story')\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Gemini API\nDESCRIPTION: Configure environment variables for Gemini Developer API authentication\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport GOOGLE_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: File Operations with Gemini Developer API\nDESCRIPTION: This snippet shows how to perform file operations using the Gemini Developer API. It includes examples for uploading, retrieving, and deleting files.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_38\n\nLANGUAGE: python\nCODE:\n```\nfile1 = client.files.upload(file='2312.11805v3.pdf')\nfile2 = client.files.upload(file='2403.05530.pdf')\n\nprint(file1)\nprint(file2)\n```\n\nLANGUAGE: python\nCODE:\n```\nfile1 = client.files.upload(file='2312.11805v3.pdf')\nfile_info = client.files.get(name=file1.name)\n```\n\nLANGUAGE: python\nCODE:\n```\nfile3 = client.files.upload(file='2312.11805v3.pdf')\n\nclient.files.delete(name=file3.name)\n```\n\n----------------------------------------\n\nTITLE: Creating Vertex AI Client\nDESCRIPTION: Initialize client for Vertex AI API with project and location configuration\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(\n    vertexai=True, project='your-project-id', location='us-central1'\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Image Content Analysis from Local Files\nDESCRIPTION: Demonstrates how to stream responses for image analysis when the image is stored locally. This approach reads the image as bytes and passes it to the model.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nYOUR_IMAGE_PATH = 'your_image_path'\nYOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'\nwith open(YOUR_IMAGE_PATH, 'rb') as f:\n    image_bytes = f.read()\n\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001',\n    contents=[\n        'What is this image about?',\n        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),\n    ],\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Automatic Python Function Calling with Gemini\nDESCRIPTION: Demonstrates how to pass a Python function directly to the Gemini model for automatic function calling. The function will be automatically called based on the model's determination of when to use it.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location: str) -> str:\n    \"\"\"Returns the current weather.\n\n    Args:\n      location: The city and state, e.g. San Francisco, CA\n    \"\"\"\n    return 'sunny'\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What is the weather like in Boston?',\n    config=types.GenerateContentConfig(tools=[get_current_weather]),\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Image Editing with Vertex AI in Python GenAI Client\nDESCRIPTION: This snippet demonstrates image editing using Vertex AI. It uses the 'imagen-3.0-capability-001' model and includes configuration for edit mode, mask reference, and output options.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\n# Edit the generated image from above\nfrom google.genai.types import RawReferenceImage, MaskReferenceImage\n\nraw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=response1.generated_images[0].image,\n)\n\n# Model computes a mask of the background\nmask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_BACKGROUND',\n        mask_dilation=0,\n    ),\n)\n\nresponse3 = client.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='Sunlight and clear sky',\n    reference_images=[raw_ref_image, mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode='EDIT_MODE_INPAINT_INSERTION',\n        number_of_images=1,\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse3.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Generating Content with File Input\nDESCRIPTION: Example of generating content using the Gemini model with an uploaded file\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfile = client.files.upload(file='a11.txt')\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents=['Could you summarize this file?', file]\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Streaming Image Analysis from Local Files with Gemini\nDESCRIPTION: Shows how to stream content generation for image analysis when the image is stored locally. This code reads image bytes from a local file and passes them to the Gemini model.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nYOUR_IMAGE_PATH = 'your_image_path'\nYOUR_IMAGE_MIME_TYPE = 'your_image_mime_type'\nwith open(YOUR_IMAGE_PATH, 'rb') as f:\n    image_bytes = f.read()\n\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001',\n    contents=[\n        'What is this image about?',\n        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),\n    ],\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Setting API Version for Gemini\nDESCRIPTION: Initializes Gemini API client with specific API version settings.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(\n    api_key='GEMINI_API_KEY',\n    http_options=types.HttpOptions(api_version='v1alpha')\n)\n```\n\n----------------------------------------\n\nTITLE: Setting API Version for Vertex AI\nDESCRIPTION: Initializes Vertex AI client with specific API version settings.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(\n    vertexai=True,\n    project='your-project-id',\n    location='us-central1',\n    http_options=types.HttpOptions(api_version='v1')\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Batch Prediction Jobs List with Pagination\nDESCRIPTION: Shows how to list batch prediction jobs, access pagination properties, retrieve specific items by index, and navigate between pages in a manual fashion.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_50\n\nLANGUAGE: python\nCODE:\n```\npager = client.batches.list(config=types.ListBatchJobsConfig(page_size=10))\nprint(pager.page_size)\nprint(pager[0])\npager.next_page()\nprint(pager[0])\n```\n\n----------------------------------------\n\nTITLE: Image Generation with Imagen in Python GenAI Client\nDESCRIPTION: This snippet demonstrates how to generate images using the Imagen model. It includes configuration options for number of images, RAI reason, and output MIME type.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\n# Generate Image\nresponse1 = client.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='An umbrella in the foreground, and a rainy night sky in the background',\n    config=types.GenerateImagesConfig(\n        number_of_images=1,\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse1.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Creating a Batch Prediction Job in Vertex AI\nDESCRIPTION: Shows how to create a batch prediction job in Vertex AI by specifying the model and source data location. The job display name and destination will be auto-populated by the system.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_46\n\nLANGUAGE: python\nCODE:\n```\n# Specify model and source file only, destination and job display name will be auto-populated\njob = client.batches.create(\n    model='gemini-1.5-flash-002',\n    src='bq://my-project.my-dataset.my-table',\n)\n\njob\n```\n\n----------------------------------------\n\nTITLE: Polling Batch Prediction Job Status until Completion\nDESCRIPTION: Shows how to implement a polling loop that checks the status of a batch prediction job until it reaches a completed state, with a 30-second delay between status checks.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_48\n\nLANGUAGE: python\nCODE:\n```\ncompleted_states = set(\n    [\n        'JOB_STATE_SUCCEEDED',\n        'JOB_STATE_FAILED',\n        'JOB_STATE_CANCELLED',\n        'JOB_STATE_PAUSED',\n    ]\n)\n\nwhile job.state not in completed_states:\n    print(job.state)\n    job = client.batches.get(name=job.name)\n    time.sleep(30)\n\njob\n```\n\n----------------------------------------\n\nTITLE: Retrieving a Batch Prediction Job by Name\nDESCRIPTION: Demonstrates how to retrieve an existing batch prediction job using its name and check the current state of the job.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_47\n\nLANGUAGE: python\nCODE:\n```\n# Get a job by name\njob = client.batches.get(name=job.name)\n\njob.state\n```\n\n----------------------------------------\n\nTITLE: Embedding Content with Gemini Models\nDESCRIPTION: Shows how to generate text embeddings using Gemini models. Embeddings are vector representations of text that capture semantic meaning for use in machine learning applications.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.embed_content(\n    model='text-embedding-004',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Accessing Tunings List with Pagination Asynchronously\nDESCRIPTION: Shows how to asynchronously list tuning jobs, access pagination properties, retrieve specific items by index, and navigate between pages.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_45\n\nLANGUAGE: python\nCODE:\n```\nasync_pager = await client.aio.tunings.list(config={'page_size': 10})\nprint(async_pager.page_size)\nprint(async_pager[0])\nawait async_pager.next_page()\nprint(async_pager[0])\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Calling with Google AI Python Client\nDESCRIPTION: Demonstrates various ways to implement function calling using the Google AI Python client. It covers automatic Python function support, disabling automatic function calling, and manually declaring and invoking functions.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location: str) -> str:\n    \"\"\"Returns the current weather.\n\n    Args:\n      location: The city and state, e.g. San Francisco, CA\n    \"\"\"\n    return 'sunny'\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What is the weather like in Boston?',\n    config=types.GenerateContentConfig(\n        tools=[get_current_weather],\n    ),\n)\n\nprint(response.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What is the weather like in Boston?',\n    config=types.GenerateContentConfig(\n        tools=[get_current_weather],\n        automatic_function_calling=types.AutomaticFunctionCallingConfig(\n            disable=True\n        ),\n    ),\n)\n```\n\nLANGUAGE: python\nCODE:\n```\nfunction = types.FunctionDeclaration(\n    name='get_current_weather',\n    description='Get the current weather in a given location',\n    parameters=types.Schema(\n        type='OBJECT',\n        properties={\n            'location': types.Schema(\n                type='STRING',\n                description='The city and state, e.g. San Francisco, CA',\n            ),\n        },\n        required=['location'],\n    ),\n)\n\ntool = types.Tool(function_declarations=[function])\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What is the weather like in Boston?',\n    config=types.GenerateContentConfig(\n        tools=[tool],\n    ),\n)\nprint(response.function_calls[0])\n```\n\n----------------------------------------\n\nTITLE: Listing Tunings Asynchronously in Google Python Generative AI SDK\nDESCRIPTION: Demonstrates how to asynchronously iterate through tuning jobs using the async for loop pattern with a specified page size configuration of 10 items per page.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_44\n\nLANGUAGE: python\nCODE:\n```\nasync for job in await client.aio.tunings.list(config={'page_size': 10}):\n    print(job)\n```\n\n----------------------------------------\n\nTITLE: Using Enum Response Schema with Google AI Python Client\nDESCRIPTION: Shows how to use an enum response schema to get a specific enum value as the model's response. This example uses an InstrumentEnum to categorize musical instruments.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\n\nclass InstrumentEnum(Enum):\n    PERCUSSION = 'Percussion'\n    STRING = 'String'\n    WOODWIND = 'Woodwind'\n    BRASS = 'Brass'\n    KEYBOARD = 'Keyboard'\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n```\n\n----------------------------------------\n\nTITLE: Handling Function Responses and Multi-turn Conversations with Gemini\nDESCRIPTION: Shows the complete flow of receiving a function call from the model, executing the function, and passing the result back to the model to continue the conversation with the context of the function result.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nuser_prompt_content = types.Content(\n    role='user',\n    parts=[types.Part.from_text(text='What is the weather like in Boston?')],\n)\nfunction_call_part = response.function_calls[0]\nfunction_call_content = response.candidates[0].content\n\n\ntry:\n    function_result = get_current_weather(\n        **function_call_part.function_call.args\n    )\n    function_response = {'result': function_result}\nexcept (\n    Exception\n) as e:  # instead of raising the exception, you can let the model handle it\n    function_response = {'error': str(e)}\n\n\nfunction_response_part = types.Part.from_function_response(\n    name=function_call_part.name,\n    response=function_response,\n)\nfunction_response_content = types.Content(\n    role='tool', parts=[function_response_part]\n)\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents=[\n        user_prompt_content,\n        function_call_content,\n        function_response_content,\n    ],\n    config=types.GenerateContentConfig(\n        tools=[tool],\n    ),\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Computing Tokens with Vertex AI Gemini\nDESCRIPTION: Shows how to compute tokens for Gemini models in Vertex AI. Note that this functionality is only available in Vertex AI and not in the standard Gemini API.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.compute_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Responses with Gemini\nDESCRIPTION: Demonstrates how to stream chat responses incrementally for multi-turn conversations. This provides a more interactive experience by showing responses as they are generated.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_30\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(model='gemini-2.0-flash-001')\nfor chunk in chat.send_message_stream('tell me a story'):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Generating Images with Imagen in Gemini\nDESCRIPTION: Shows how to generate images using the Imagen model in Gemini. This feature requires allowlist access and demonstrates setting image generation parameters.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_25\n\nLANGUAGE: python\nCODE:\n```\n# Generate Image\nresponse1 = client.models.generate_images(\n    model='imagen-3.0-generate-002',\n    prompt='An umbrella in the foreground, and a rainy night sky in the background',\n    config=types.GenerateImagesConfig(\n        number_of_images=1,\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse1.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Async Content Generation with Python GenAI Client\nDESCRIPTION: This snippet demonstrates how to use the async version of the generate_content method. It uses the 'gemini-2.0-flash-001' model to generate a 300-word story asynchronously.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\nresponse = await client.aio.models.generate_content(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Videos with Veo in Gemini\nDESCRIPTION: Demonstrates how to generate videos using the Veo model in Gemini. This feature requires allowlist access and shows how to create an operation and poll for results.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_28\n\nLANGUAGE: python\nCODE:\n```\n# Create operation\noperation = client.models.generate_videos(\n    model='veo-2.0-generate-001',\n    prompt='A neon hologram of a cat driving at top speed',\n    config=types.GenerateVideosConfig(\n        number_of_videos=1,\n        fps=24,\n        duration_seconds=5,\n        enhance_prompt=True,\n    ),\n)\n\n# Poll operation\nwhile not operation.done:\n    time.sleep(20)\n    operation = client.operations.get(operation)\n\nvideo = operation.result.generated_videos[0].video\nvideo.show()\n```\n\n----------------------------------------\n\nTITLE: Using Async Chat Sessions with Gemini\nDESCRIPTION: Shows how to use chat sessions asynchronously with Gemini models. This allows for non-blocking chat operations in asynchronous applications.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nchat = client.aio.chats.create(model='gemini-2.0-flash-001')\nresponse = await chat.send_message('tell me a story')\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Working with JSON Response Schemas in Google AI Python Client\nDESCRIPTION: Illustrates how to use JSON response schemas with the Google AI Python client. It includes examples of using Pydantic models and manually defined schemas to structure the model's output.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\n\nclass CountryInfo(BaseModel):\n    name: str\n    population: int\n    capital: str\n    continent: str\n    gdp: int\n    official_language: str\n    total_area_sq_mi: int\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Give me information for the United States.',\n    config=types.GenerateContentConfig(\n        response_mime_type='application/json',\n        response_schema=CountryInfo,\n    ),\n)\nprint(response.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='Give me information for the United States.',\n    config=types.GenerateContentConfig(\n        response_mime_type='application/json',\n        response_schema={\n            'required': [\n                'name',\n                'population',\n                'capital',\n                'continent',\n                'gdp',\n                'official_language',\n                'total_area_sq_mi',\n            ],\n            'properties': {\n                'name': {'type': 'STRING'},\n                'population': {'type': 'INTEGER'},\n                'capital': {'type': 'STRING'},\n                'continent': {'type': 'STRING'},\n                'gdp': {'type': 'INTEGER'},\n                'official_language': {'type': 'STRING'},\n                'total_area_sq_mi': {'type': 'INTEGER'},\n            },\n            'type': 'OBJECT',\n        },\n    ),\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Information from Gemini Developer API\nDESCRIPTION: Demonstrates how to retrieve information about files uploaded to the Gemini Developer API. This shows how to access metadata for previously uploaded files.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_34\n\nLANGUAGE: python\nCODE:\n```\nfile1 = client.files.upload(file='2312.11805v3.pdf')\nfile_info = client.files.get(name=file1.name)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Vertex AI\nDESCRIPTION: Configure environment variables for Vertex AI authentication and settings\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport GOOGLE_GENAI_USE_VERTEXAI=true\nexport GOOGLE_CLOUD_PROJECT='your-project-id'\nexport GOOGLE_CLOUD_LOCATION='us-central1'\n```\n\n----------------------------------------\n\nTITLE: Embedding Multiple Contents with Configuration\nDESCRIPTION: Demonstrates how to embed multiple text contents with custom configuration settings. This example specifies the output dimensionality of the embeddings.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\n# multiple contents with config\nresponse = client.models.embed_content(\n    model='text-embedding-004',\n    contents=['why is the sky blue?', 'What is your age?'],\n    config=types.EmbedContentConfig(output_dimensionality=10),\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Deleting a Batch Prediction Job\nDESCRIPTION: Demonstrates how to delete a batch prediction job resource using the job name and print the result of the delete operation.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_53\n\nLANGUAGE: python\nCODE:\n```\n# Delete the job resource\ndelete_job = client.batches.delete(name=job.name)\n\ndelete_job\n```\n\n----------------------------------------\n\nTITLE: Content Embedding with Python GenAI Client\nDESCRIPTION: This code shows how to embed content using the 'text-embedding-004' model. It demonstrates both single and multiple content embedding with configuration options.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_31\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.embed_content(\n    model='text-embedding-004',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\nLANGUAGE: python\nCODE:\n```\n# multiple contents with config\nresponse = client.models.embed_content(\n    model='text-embedding-004',\n    contents=['why is the sky blue?', 'What is your age?'],\n    config=types.EmbedContentConfig(output_dimensionality=10),\n)\n\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Streaming Image Content Analysis from Cloud Storage\nDESCRIPTION: Shows how to stream responses for image analysis when the image is stored in Google Cloud Storage. This approach avoids loading the entire image into memory.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001',\n    contents=[\n        'What is this image about?',\n        types.Part.from_uri(\n            file_uri='gs://generativeai-downloads/images/scones.jpg',\n            mime_type='image/jpeg',\n        ),\n    ],\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Retrieving Cached Content from Gemini\nDESCRIPTION: Shows how to retrieve previously created cached content from Gemini. This demonstrates accessing cached content for reuse in content generation.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_37\n\nLANGUAGE: python\nCODE:\n```\ncached_content = client.caches.get(name=cached_content.name)\n```\n\n----------------------------------------\n\nTITLE: Image Upscaling with Vertex AI in Python GenAI Client\nDESCRIPTION: This code shows how to upscale an image using Vertex AI. It uses the 'imagen-3.0-generate-001' model and includes configuration for RAI reason and output MIME type.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\n# Upscale the generated image from above\nresponse2 = client.models.upscale_image(\n    model='imagen-3.0-generate-001',\n    image=response1.generated_images[0].image,\n    upscale_factor='x2',\n    config=types.UpscaleImageConfig(\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse2.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Streaming Image Analysis from Cloud Storage with Gemini\nDESCRIPTION: Demonstrates how to stream content generation for image analysis when the image is stored in Google Cloud Storage. This shows how to reference cloud-stored images for content generation.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfor chunk in client.models.generate_content_stream(\n    model='gemini-2.0-flash-001',\n    contents=[\n        'What is this image about?',\n        types.Part.from_uri(\n            file_uri='gs://generativeai-downloads/images/scones.jpg',\n            mime_type='image/jpeg',\n        ),\n    ],\n):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Using Enum Response Schema with Text Output in Gemini\nDESCRIPTION: Demonstrates how to configure the model to return responses from a predefined set of enum values using the text/x.enum response MIME type. This ensures responses are limited to specific values.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nclass InstrumentEnum(Enum):\n  PERCUSSION = 'Percussion'\n  STRING = 'String'\n  WOODWIND = 'Woodwind'\n  BRASS = 'Brass'\n  KEYBOARD = 'Keyboard'\n\nresponse = client.models.generate_content(\n      model='gemini-2.0-flash-001',\n      contents='What instrument plays multiple notes at once?',\n      config={\n          'response_mime_type': 'text/x.enum',\n          'response_schema': InstrumentEnum,\n      },\n  )\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Using Enum Response Schema with JSON Output in Gemini\nDESCRIPTION: Shows how to configure the model to return enum values as JSON responses using the application/json response MIME type. This provides the same validation as text/x.enum but with JSON formatting.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\n\nclass InstrumentEnum(Enum):\n  PERCUSSION = 'Percussion'\n  STRING = 'String'\n  WOODWIND = 'Woodwind'\n  BRASS = 'Brass'\n  KEYBOARD = 'Keyboard'\n\nresponse = client.models.generate_content(\n      model='gemini-2.0-flash-001',\n      contents='What instrument plays multiple notes at once?',\n      config={\n          'response_mime_type': 'application/json',\n          'response_schema': InstrumentEnum,\n      },\n  )\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Using Enum Response Schema with JSON in Gemini\nDESCRIPTION: Demonstrates how to set up an Enum response schema with JSON mime type to get structured responses from the Gemini model. This enables the model to return values from a predefined enumeration type.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nclass InstrumentEnum(Enum):\n    PERCUSSION = 'Percussion'\n    STRING = 'String'\n    WOODWIND = 'Woodwind'\n    BRASS = 'Brass'\n    KEYBOARD = 'Keyboard'\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash-001',\n    contents='What instrument plays multiple notes at once?',\n    config={\n        'response_mime_type': 'application/json',\n        'response_schema': InstrumentEnum,\n    },\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Listing Base Models in Python using Google AI Client\nDESCRIPTION: Demonstrates how to list available base models using the Google AI Python client. It includes both synchronous and asynchronous methods for listing models and paginating through results.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfor model in client.models.list():\n    print(model)\n```\n\nLANGUAGE: python\nCODE:\n```\npager = client.models.list(config={'page_size': 10})\nprint(pager.page_size)\nprint(pager[0])\npager.next_page()\nprint(pager[0])\n```\n\nLANGUAGE: python\nCODE:\n```\nasync for job in await client.aio.models.list():\n    print(job)\n```\n\nLANGUAGE: python\nCODE:\n```\nasync_pager = await client.aio.models.list(config={'page_size': 10})\nprint(async_pager.page_size)\nprint(async_pager[0])\nawait async_pager.next_page()\nprint(async_pager[0])\n```\n\n----------------------------------------\n\nTITLE: Disabling Automatic Function Calling in Gemini\nDESCRIPTION: Shows how to disable automatic function calling for a Python function passed as a tool. With this configuration, the model will suggest function calls but will not execute them automatically.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n  model='gemini-2.0-flash-001',\n  contents='What is the weather like in Boston?',\n  config=types.GenerateContentConfig(\n    tools=[get_current_weather],\n    automatic_function_calling=types.AutomaticFunctionCallingConfig(\n      disable=True\n    ),\n  ),\n)\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens in Gemini Content\nDESCRIPTION: Demonstrates how to count tokens in text for Gemini models. This is useful for staying within model context limits and estimating API usage costs.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.count_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Computing Tokens with Vertex AI in Python GenAI Client\nDESCRIPTION: This code shows how to compute tokens using Vertex AI. This functionality is specific to Vertex AI and uses the 'gemini-2.0-flash-001' model.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_29\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.compute_tokens(\n    model='gemini-2.0-flash-001',\n    contents='why is the sky blue?',\n)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Model Tuning with Python GenAI Client\nDESCRIPTION: This code demonstrates how to perform model tuning using either Vertex AI or Gemini Developer API. It includes examples for creating a tuning job, retrieving job status, and using the tuned model.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_41\n\nLANGUAGE: python\nCODE:\n```\nif client.vertexai:\n    model = 'gemini-1.5-pro-002'\n    training_dataset = types.TuningDataset(\n        gcs_uri='gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl',\n    )\nelse:\n    model = 'models/gemini-1.0-pro-001'\n    training_dataset = types.TuningDataset(\n        examples=[\n            types.TuningExample(\n                text_input=f'Input text {i}',\n                output=f'Output text {i}',\n            )\n            for i in range(5)\n        ],\n    )\n```\n\nLANGUAGE: python\nCODE:\n```\ntuning_job = client.tunings.tune(\n    base_model=model,\n    training_dataset=training_dataset,\n    config=types.CreateTuningJobConfig(\n        epoch_count=1, tuned_model_display_name='test_dataset_examples model'\n    ),\n)\nprint(tuning_job)\n```\n\nLANGUAGE: python\nCODE:\n```\ntuning_job = client.tunings.get(name=tuning_job.name)\nprint(tuning_job)\n```\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nrunning_states = set(\n    [\n        'JOB_STATE_PENDING',\n        'JOB_STATE_RUNNING',\n    ]\n)\n\nwhile tuning_job.state in running_states:\n    print(tuning_job.state)\n    tuning_job = client.tunings.get(name=tuning_job.name)\n    time.sleep(10)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=tuning_job.tuned_model.endpoint,\n    contents='why is the sky blue?',\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Handling API Errors in Google Python Generative AI SDK\nDESCRIPTION: Shows how to properly catch and handle API errors when using the SDK, including accessing error codes and messages when an invalid model name is provided.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_54\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import errors\n\ntry:\n  client.models.generate_content(\n      model=\"invalid-model-name\",\n      contents=\"What is your name?\",\n  )\nexcept errors.APIError as e:\n  print(e.code) # 404\n  print(e.message)\n```\n\n----------------------------------------\n\nTITLE: Editing Images with Imagen in Vertex AI\nDESCRIPTION: Shows how to edit images using Imagen in Vertex AI. This example demonstrates background masking and inpainting with new content, a feature only available in Vertex AI.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_27\n\nLANGUAGE: python\nCODE:\n```\n# Edit the generated image from above\nfrom google.genai.types import RawReferenceImage, MaskReferenceImage\n\nraw_ref_image = RawReferenceImage(\n    reference_id=1,\n    reference_image=response1.generated_images[0].image,\n)\n\n# Model computes a mask of the background\nmask_ref_image = MaskReferenceImage(\n    reference_id=2,\n    config=types.MaskReferenceConfig(\n        mask_mode='MASK_MODE_BACKGROUND',\n        mask_dilation=0,\n    ),\n)\n\nresponse3 = client.models.edit_image(\n    model='imagen-3.0-capability-001',\n    prompt='Sunlight and clear sky',\n    reference_images=[raw_ref_image, mask_ref_image],\n    config=types.EditImageConfig(\n        edit_mode='EDIT_MODE_INPAINT_INSERTION',\n        number_of_images=1,\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse3.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Upscaling Images with Imagen in Vertex AI\nDESCRIPTION: Demonstrates how to upscale generated images using Imagen in Vertex AI. This feature is only available in Vertex AI and not in the standard Gemini API.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_26\n\nLANGUAGE: python\nCODE:\n```\n# Upscale the generated image from above\nresponse2 = client.models.upscale_image(\n    model='imagen-3.0-generate-002',\n    image=response1.generated_images[0].image,\n    upscale_factor='x2',\n    config=types.UpscaleImageConfig(\n        include_rai_reason=True,\n        output_mime_type='image/jpeg',\n    ),\n)\nresponse2.generated_images[0].image.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Structure for Google GenAI\nDESCRIPTION: Sphinx documentation configuration using toctree directive to organize documentation hierarchy. Sets maximum depth to 4 levels and includes the genai module documentation.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/modules.rst.txt#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 4\n\n   genai\n```\n\n----------------------------------------\n\nTITLE: Video Generation with Veo in Python GenAI Client\nDESCRIPTION: This code demonstrates how to generate videos using the Veo model. It includes configuration for FPS, duration, and prompt enhancement. The operation is polled until completion.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\n# Create operation\noperation = client.models.generate_videos(\n    model='veo-2.0-generate-001',\n    prompt='A neon hologram of a cat driving at top speed',\n    config=types.GenerateVideosConfig(\n        number_of_videos=1,\n        fps=24,\n        duration_seconds=5,\n        enhance_prompt=True,\n    ),\n)\n\n# Poll operation\nwhile not operation.done:\n    time.sleep(20)\n    operation = client.operations.get(operation)\n\nvideo = operation.result.generated_videos[0].video\nvideo.show()\n```\n\n----------------------------------------\n\nTITLE: Configuring Limited Automatic Function Calling in ANY Mode\nDESCRIPTION: Shows how to configure the maximum number of automatic function calls by setting the maximum_remote_calls parameter. This limits how many back-and-forth function calls will occur automatically.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\ndef get_current_weather(location: str) -> str:\n    \"\"\"Returns the current weather.\n\n    Args:\n      location: The city and state, e.g. San Francisco, CA\n    \"\"\"\n    return \"sunny\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash-001\",\n    contents=\"What is the weather like in Boston?\",\n    config=types.GenerateContentConfig(\n        tools=[get_current_weather],\n        automatic_function_calling=types.AutomaticFunctionCallingConfig(\n            maximum_remote_calls=2\n        ),\n        tool_config=types.ToolConfig(\n            function_calling_config=types.FunctionCallingConfig(mode='ANY')\n        ),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Responses Asynchronously with Gemini\nDESCRIPTION: Demonstrates how to stream chat responses asynchronously. This combines the benefits of streaming and asynchronous programming for efficient chat applications.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_32\n\nLANGUAGE: python\nCODE:\n```\nchat = client.aio.chats.create(model='gemini-2.0-flash-001')\nasync for chunk in await chat.send_message_stream('tell me a story'):\n    print(chunk.text, end='')\n```\n\n----------------------------------------\n\nTITLE: Uploading Files to Gemini Developer API\nDESCRIPTION: Shows how to upload files to the Gemini Developer API. This functionality is only supported in the Gemini Developer API and not in Vertex AI.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_33\n\nLANGUAGE: python\nCODE:\n```\nfile1 = client.files.upload(file='2312.11805v3.pdf')\nfile2 = client.files.upload(file='2403.05530.pdf')\n\nprint(file1)\nprint(file2)\n```\n\n----------------------------------------\n\nTITLE: Cached Content Creation with Python GenAI Client\nDESCRIPTION: This code demonstrates how to create cached content using the 'gemini-1.5-pro-002' model. It includes configuration for content, system instruction, and TTL.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_39\n\nLANGUAGE: python\nCODE:\n```\nif client.vertexai:\n    file_uris = [\n        'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',\n        'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',\n    ]\nelse:\n    file_uris = [file1.uri, file2.uri]\n\ncached_content = client.caches.create(\n    model='gemini-1.5-pro-002',\n    config=types.CreateCachedContentConfig(\n        contents=[\n            types.Content(\n                role='user',\n                parts=[\n                    types.Part.from_uri(\n                        file_uri=file_uris[0], mime_type='application/pdf'\n                    ),\n                    types.Part.from_uri(\n                        file_uri=file_uris[1],\n                        mime_type='application/pdf',\n                    ),\n                ],\n            )\n        ],\n        system_instruction='What is the sum of the two pdfs?',\n        display_name='test cache',\n        ttl='3600s',\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Content Generation with Cached Content in Python GenAI Client\nDESCRIPTION: This snippet shows how to generate content using cached content with the 'gemini-1.5-pro-002' model. It demonstrates the use of cached content in content generation requests.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_40\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model='gemini-1.5-pro-002',\n    contents='Summarize the pdfs',\n    config=types.GenerateContentConfig(\n        cached_content=cached_content.name,\n    ),\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Listing and Updating Tuned Models with Python GenAI Client\nDESCRIPTION: This snippet demonstrates how to list tuned models, retrieve model information, and update model metadata using the Python GenAI client.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_42\n\nLANGUAGE: python\nCODE:\n```\nfor model in client.models.list(config={'page_size': 10, 'query_base': False}):\n    print(model)\n```\n\nLANGUAGE: python\nCODE:\n```\npager = client.models.list(config={'page_size': 10, 'query_base': False})\nprint(pager.page_size)\nprint(pager[0])\npager.next_page()\nprint(pager[0])\n```\n\nLANGUAGE: python\nCODE:\n```\nasync for job in await client.aio.models.list(config={'page_size': 10, 'query_base': False}):\n    print(job)\n```\n\nLANGUAGE: python\nCODE:\n```\nasync_pager = await client.aio.models.list(config={'page_size': 10, 'query_base': False})\nprint(async_pager.page_size)\nprint(async_pager[0])\nawait async_pager.next_page()\nprint(async_pager[0])\n```\n\nLANGUAGE: python\nCODE:\n```\nmodel = pager[0]\n\nmodel = client.models.update(\n    model=model.name,\n    config=types.UpdateModelConfig(\n        display_name='my tuned model', description='my tuned model description'\n    ),\n)\n\nprint(model)\n```\n\n----------------------------------------\n\nTITLE: Listing Batch Prediction Jobs with Iteration\nDESCRIPTION: Demonstrates how to list batch prediction jobs with a specified page size configuration and iterate through the results.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_49\n\nLANGUAGE: python\nCODE:\n```\nfor job in client.batches.list(config=types.ListBatchJobsConfig(page_size=10)):\n    print(job)\n```\n\n----------------------------------------\n\nTITLE: Deleting Files from Gemini Developer API\nDESCRIPTION: Shows how to delete files from the Gemini Developer API. This demonstrates the cleanup process for files that are no longer needed.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_35\n\nLANGUAGE: python\nCODE:\n```\nfile3 = client.files.upload(file='2312.11805v3.pdf')\n\nclient.files.delete(name=file3.name)\n```\n\n----------------------------------------\n\nTITLE: Listing Batch Prediction Jobs Asynchronously\nDESCRIPTION: Demonstrates how to asynchronously iterate through batch prediction jobs using the async for loop pattern with a specified page size configuration.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_51\n\nLANGUAGE: python\nCODE:\n```\nasync for job in await client.aio.batches.list(\n    config=types.ListBatchJobsConfig(page_size=10)\n):\n    print(job)\n```\n\n----------------------------------------\n\nTITLE: Accessing Batch Prediction Jobs List with Pagination Asynchronously\nDESCRIPTION: Shows how to asynchronously list batch prediction jobs, access pagination properties, retrieve specific items by index, and navigate between pages.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/README.md#2025-04-23_snippet_52\n\nLANGUAGE: python\nCODE:\n```\nasync_pager = await client.aio.batches.list(\n    config=types.ListBatchJobsConfig(page_size=10)\n)\nprint(async_pager.page_size)\nprint(async_pager[0])\nawait async_pager.next_page()\nprint(async_pager[0])\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample File\nDESCRIPTION: Console command to download a sample file for content generation\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n```\n\n----------------------------------------\n\nTITLE: Creating Cached Content with Gemini\nDESCRIPTION: Demonstrates how to create cached content for Gemini models. This shows setting up cached content with files from either Vertex AI or the Gemini Developer API.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_36\n\nLANGUAGE: python\nCODE:\n```\nif client.vertexai:\n    file_uris = [\n        'gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',\n        'gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf',\n    ]\nelse:\n    file_uris = [file1.uri, file2.uri]\n\ncached_content = client.caches.create(\n    model='gemini-1.5-pro-002',\n    config=types.CreateCachedContentConfig(\n        contents=[\n            types.Content(\n                role='user',\n                parts=[\n                    types.Part.from_uri(\n                        file_uri=file_uris[0], mime_type='application/pdf'\n                    ),\n                    types.Part.from_uri(\n                        file_uri=file_uris[1],\n                        mime_type='application/pdf',\n                    ),\n                ],\n            )\n        ],\n        system_instruction='What is the sum of the two pdfs?',\n        display_name='test cache',\n        ttl='3600s',\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Content Asynchronously with Gemini\nDESCRIPTION: Shows how to stream content generation asynchronously from Gemini models. This combines the benefits of streaming and asynchronous programming for efficient processing.\nSOURCE: https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt#2025-04-23_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nasync for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n):\n    print(chunk.text, end='')\n```"
  }
]