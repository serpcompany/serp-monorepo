[
  {
    "owner": "the-pocket",
    "repo": "tutorial-codebase-knowledge",
    "content": "TITLE: Example JSON Data with Type Issues\nDESCRIPTION: An example of incoming user data in JSON format that demonstrates potential validation issues, particularly with the age field being a string instead of a number.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n// Example user data from an API\n{\n  \"username\": \"cool_cat_123\",\n  \"age\": \"28\", // Oops, age is a string!\n  \"email\": \"cat@example.com\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining DeepCrawlStrategy Abstract Base Class in Python\nDESCRIPTION: This abstract base class defines the structure for deep crawl strategies. It includes abstract methods for batch and stream crawling, URL processing, link discovery, and cleanup. Concrete strategies must implement these methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/08_deepcrawlstrategy.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from deep_crawling/base_strategy.py\nfrom abc import ABC, abstractmethod\n# ... other imports\n\nclass DeepCrawlStrategy(ABC):\n\n    @abstractmethod\n    async def _arun_batch(self, start_url, crawler, config) -> List[CrawlResult]:\n        # Implementation for non-streaming mode\n        pass\n\n    @abstractmethod\n    async def _arun_stream(self, start_url, crawler, config) -> AsyncGenerator[CrawlResult, None]:\n        # Implementation for streaming mode\n        pass\n\n    async def arun(self, start_url, crawler, config) -> RunManyReturn:\n        # Decides whether to call _arun_batch or _arun_stream\n        if config.stream:\n            return self._arun_stream(start_url, crawler, config)\n        else:\n            return await self._arun_batch(start_url, crawler, config)\n\n    @abstractmethod\n    async def can_process_url(self, url: str, depth: int) -> bool:\n        # Applies filters to decide if a URL is valid to crawl\n        pass\n\n    @abstractmethod\n    async def link_discovery(self, result, source_url, current_depth, visited, next_level, depths):\n        # Extracts, validates, and prepares links for the next step\n        pass\n\n    @abstractmethod\n    async def shutdown(self):\n        # Cleanup logic\n        pass\n```\n\n----------------------------------------\n\nTITLE: Creating Model Instances with Valid Data\nDESCRIPTION: Example of instantiating a Pydantic model with valid data. The data is passed as a dictionary and automatically validated against the model's field types.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Input data (e.g., from a dictionary)\nuser_data = {'name': 'Alice', 'age': 30}\n\n# Create a User instance\nuser_alice = User(**user_data) # The ** unpacks the dictionary\n\n# Pydantic checked that 'name' is a string and 'age' is an integer.\n# It worked! Let's see the created object.\nprint(user_alice)\n# Expected Output: name='Alice' age=30\n```\n\n----------------------------------------\n\nTITLE: Implementing LookupKey for Seeking in LevelDB\nDESCRIPTION: LookupKey creates a specially formatted key for seeking in MemTables and internal iterators, ensuring proper handling of sequence numbers during lookups.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_4\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/dbformat.h ---\n\n// A helper class useful for DBImpl::Get() and Iterator::Seek()\nclass LookupKey {\n public:\n  // Create a key for looking up user_key at snapshot 'sequence'.\n  LookupKey(const Slice& user_key, SequenceNumber sequence);\n  ~LookupKey();\n\n  // Key for MemTable lookup (includes length prefix for internal key)\n  Slice memtable_key() const;\n  // Key for Internal Iterator lookup (user_key + seq/type tag)\n  Slice internal_key() const;\n  // User key part\n  Slice user_key() const;\n\n private:\n  const char* start_; // Beginning of allocated buffer\n  const char* kstart_; // Beginning of user_key portion\n  const char* end_;   // End of allocated buffer\n  char space_[200]; // Avoid heap allocation for short keys\n};\n\n// --- File: db/dbformat.cc --- (Simplified Constructor Logic)\n\nLookupKey::LookupKey(const Slice& user_key, SequenceNumber s) {\n  size_t usize = user_key.size();\n  // Need space for: internal key length, user key, 8-byte tag\n  size_t needed = VarintLength(usize + 8) + usize + 8;\n  char* dst = /* ... allocate space_ or new char[] ... */ ;\n\n  start_ = dst;\n  // Encode length of internal key (user_key size + 8)\n  dst = EncodeVarint32(dst, usize + 8);\n  kstart_ = dst; // Mark start of internal key part\n  // Copy user key data\n  std::memcpy(dst, user_key.data(), usize);\n  dst += usize;\n  // Encode the 8-byte tag: Use the target sequence 's' BUT use\n  // kValueTypeForSeek (which is kTypeValue, the highest type value).\n  EncodeFixed64(dst, PackSequenceAndType(s, kValueTypeForSeek));\n  dst += 8;\n  end_ = dst; // Mark end of buffer\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Worker Task Processing Flow with Mermaid\nDESCRIPTION: A sequence diagram illustrating the interactions between the command line, main worker process, Celery app, message broker, execution pool, and task code during the processing of a single Celery task. It visualizes the steps from worker startup and connection to message delivery, execution, result handling, and final acknowledgement.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/05_worker.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant CLI as Terminal (celery worker)\n    participant WorkerMain as Worker Main Process\n    participant App as Celery App Instance\n    participant Broker as Message Broker\n    participant Pool as Execution Pool (e.g., Prefork Child)\n    participant TaskCode as Your Task Function (add)\n\n    CLI->>WorkerMain: Start celery -A celery_app worker\n    WorkerMain->>App: Load App & Config (broker_url, tasks)\n    WorkerMain->>Broker: Connect & Listen on 'celery' queue\n\n    Broker-->>WorkerMain: Deliver Message ('tasks.add', (5, 7), task_id)\n    WorkerMain->>WorkerMain: Decode Message\n    WorkerMain->>Pool: Request Execute add(5, 7) with task_id\n    Pool->>TaskCode: Run add(5, 7)\n    TaskCode-->>Pool: Return 12\n    Pool-->>WorkerMain: Result=12 for task_id\n    Note over WorkerMain: (Optionally) Store 12 in Result Backend\n    WorkerMain->>Broker: Acknowledge task_id is complete\n```\n\n----------------------------------------\n\nTITLE: Implementing a Simple RAG Program with DSPy Modules in Python\nDESCRIPTION: Defines a Python class `SimpleRAG` inheriting from `dspy.Module` for a basic Retrieval-Augmented Generation pipeline. It initializes `dspy.Retrieve` to fetch context and `dspy.Predict` to generate an answer. The `forward` method retrieves context using the configured RM based on the input `question` and then uses the context and question to generate an answer via the configured LM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Assume RM is already configured (e.g., colbertv2_wiki from before)\n# dspy.settings.configure(rm=colbertv2_wiki)\n\nclass SimpleRAG(dspy.Module):\n    def __init__(self, num_passages=3):\n        super().__init__()\n        # Initialize the Retrieve module, asking for top 3 passages\n        self.retrieve = dspy.Retrieve(k=num_passages)\n        # Initialize a Predict module to generate the answer\n        self.generate_answer = dspy.Predict('context, question -> answer')\n\n    def forward(self, question):\n        # 1. Retrieve relevant context using the configured RM\n        context = self.retrieve(query=question).passages # Note: Pass query=...\n\n        # 2. Generate the answer using the LM, providing context\n        prediction = self.generate_answer(context=context, question=question)\n        return prediction\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic MCP Client Using ClientSession\nDESCRIPTION: Example demonstrating how to create a client application that connects to an MCP server, performs initialization handshake, and executes a tool call. Shows core session lifecycle management and error handling patterns.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/08_client_server_sessions___clientsession____serversession__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- Conceptual Client Code ---\nimport anyio\nfrom mcp.client.session import ClientSession\n# Assume we have transport streams (read_stream, write_stream)\n# connected to the CalculatorServer (more in Chapter 9)\n\nasync def run_client():\n    # 1. Create a ClientSession using the transport streams\n    async with ClientSession(read_stream, write_stream) as session:\n        try:\n            # 2. Perform the initialization handshake\n            init_result = await session.initialize()\n            print(f\"Connected to: {init_result.serverInfo.name}\")\n\n            # 3. Send a 'callTool' request using the session\n            tool_result = await session.call_tool(\n                name=\"add\",\n                arguments={\"num1\": 15, \"num2\": 27}\n            )\n\n            # 4. Process the result (session handled matching response)\n            # Assuming the result is simple text content\n            if tool_result.content and tool_result.content[0].type == 'text':\n               print(f\"Server calculated: {tool_result.content[0].text}\") # Expected: 42\n\n        except Exception as e:\n            print(f\"An error occurred: {e}\")\n\n# In a real script, you'd set up the transport and run this async function\n# anyio.run(run_client)\n```\n\n----------------------------------------\n\nTITLE: Running the FastAPI Application with Uvicorn in Bash\nDESCRIPTION: This command starts the Uvicorn ASGI server to run the FastAPI application. `main:app` tells Uvicorn to find the `app` object (the FastAPI instance) within the `main.py` file. The `--reload` flag enables automatic server restarts when code changes are detected, which is useful during development.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nuvicorn main:app --reload\n```\n\n----------------------------------------\n\nTITLE: Defining BaseTool Class for CrewAI Python Tools\nDESCRIPTION: This Python code defines the abstract BaseTool class, which serves as the foundation for all CrewAI tools. The class requires subclasses to specify a unique name and description, and optionally an argument schema via Pydantic. The run method is the entry point called by the CrewAI framework, executing internal logic in the _run method. It includes helper methods and logging capabilities. Dependencies include abc, pydantic, and typing, and classes inheriting from BaseTool must implement the _run method. Input arguments are validated using args_schema if provided, with results returned as generic Python objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/04_tool.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from crewai/tools/base_tool.py\\nfrom abc import ABC, abstractmethod\\nfrom typing import Type, Optional, Any\\nfrom pydantic import BaseModel, Field\\n\\nclass BaseTool(BaseModel, ABC):\\n    # Configuration for the tool\\n    name: str = Field(description=\\\"The unique name of the tool.\\\")\\n    description: str = Field(description=\\\"What the tool does, how/when to use it.\\\")\\n    args_schema: Optional[Type[BaseModel]] = Field(\\n        default=None, description=\\\"Pydantic schema for the tool's arguments.\\\"\\n    )\\n    # ... other options like caching ...\\n\\n    # This method contains the actual logic\\n    @abstractmethod\\n    def _run(self, *args: Any, **kwargs: Any) -> Any:\\n        \\\"\\\"\\\"The core implementation of the tool's action.\\\"\\\"\\\"\\n        pass\\n\\n    # This method is called by the agent execution framework\\n    def run(self, *args: Any, **kwargs: Any) -> Any:\\n        \\\"\\\"\\\"Executes the tool's core logic.\\\"\\\"\\\"\\n        # Could add logging, error handling, caching calls here\\n        print(f\\\"----- Executing Tool: {self.name} -----\\\") # Example logging\\n        result = self._run(*args, **kwargs)\\n        print(f\\\"----- Tool {self.name} Finished -----\\\")\\n        return result\\n\\n    # Helper method to generate a structured description for the LLM\\n    def _generate_description(self):\\n        # Creates a detailed description including name, args, and description\\n        # This is what the LLM sees to decide if it should use the tool\\n        pass\\n\\n    # ... other helper methods ...\\n\\n# You can create a simple tool using the 'Tool' class directly\\n# or inherit from BaseTool for more complex logic.\\nfrom typing import Type\\n\\nclass SimpleTool(BaseTool):\\n    name: str = \\\"MySimpleTool\\\"\\n    description: str = \\\"A very simple example tool.\\\"\\n    # No args_schema needed if it takes no arguments\\n\\n    def _run(self) -> str:\\n        return \\\"This simple tool was executed successfully!\\\"\\n\n```\n\n----------------------------------------\n\nTITLE: API Key Header Authentication Scheme Setup and Validation - FastAPI - Python\nDESCRIPTION: This snippet demonstrates setting up an APIKeyHeader security scheme in FastAPI, then defining a verifier dependency that checks for a specific API key in the 'X-API-KEY' header, raising HTTP 403 when missing or invalid. It showcases both direct usage in an endpoint and the refactored pattern where verification logic is separated, aligning with best practices. Dependencies include fastapi.security.APIKeyHeader, Security, HTTPException, and status; expects the X-API-KEY header and returns the validated key or raises an HTTP error.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- Imports ---\nfrom fastapi.security import APIKeyHeader\n\n# --- Scheme Instance ---\napi_key_header_scheme = APIKeyHeader(name=\"X-API-KEY\") # Expect key in X-API-KEY header\n\n# --- Verifier Dependency (Example) ---\nasync def get_api_key(\n    api_key: Annotated[str, Security(api_key_header_scheme)] # Use Security() with the SCHEME instance here\n):\n    if api_key == \"SECRET_API_KEY\": # Check the key (use a secure way in real apps!)\n        return api_key\n    else:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN, detail=\"Could not validate API KEY\"\n        )\n\n# --- Path Operation ---\n@app.get(\"/secure-data\")\nasync def get_secure_data(\n    # Inject the VALIDATED key using Depends() - no need for Security() again\n    # if the get_api_key dependency already uses Security() internally.\n    # Alternatively, if get_api_key just returned the key without raising errors,\n    # you could use Security(get_api_key) here. Let's stick to the pattern:\n    # the verifier dependency uses Security(scheme), the endpoint uses Depends(verifier)\n    # or directly uses Security(verifier) if the verifier handles errors.\n    # Let's adjust get_api_key to make it cleaner:\n    api_key: Annotated[str, Security(api_key_header_scheme)] # Scheme extracts the key\n):\n    # Now, a separate check or use the key\n    if api_key == \"SECRET_API_KEY\": # Re-checking here for simplicity, ideally done in a dependent function\n         return {\"data\": \"sensitive data\", \"api_key_used\": api_key}\n    else:\n         # This path might not be reachable if auto_error=True in APIKeyHeader\n         raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid API Key provided\")\n\n```\n\nLANGUAGE: python\nCODE:\n```\n# Let's refine the API Key example pattern to match the Basic Auth pattern:\n# Scheme Instance\napi_key_header_scheme = APIKeyHeader(name=\"X-API-KEY\", auto_error=False) # auto_error=False lets verifier handle missing key\n\n# Verifier Dependency\nasync def verify_api_key(api_key: Annotated[str | None, Security(api_key_header_scheme)]):\n    if api_key is None:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"X-API-KEY header missing\")\n    if api_key == \"SECRET_API_KEY\":\n        return api_key # Return key or user info associated with the key\n    else:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Invalid API Key\")\n\n# Path Operation using the verifier\n@app.get(\"/secure-data\")\nasync def get_secure_data_v2(\n    # Use Security() with the VERIFIER function\n    verified_key: Annotated[str, Security(verify_api_key)]\n):\n    # verified_key holds the result from verify_api_key (the validated key)\n    return {\"data\": \"sensitive data\", \"key\": verified_key}\n\n```\n\n----------------------------------------\n\nTITLE: Creating Items with FastAPI POST Endpoint\nDESCRIPTION: Demonstrates handling POST requests with request body validation using Pydantic models in FastAPI. The endpoint creates items with optional tax calculation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@app.post(\"/items/\")\nasync def create_item(item: Item):\n    print(f\"Received item: {item.name}, Price: {item.price}\")\n    item_dict = item.model_dump()\n    if item.tax:\n        price_with_tax = item.price + item.tax\n        item_dict[\"price_with_tax\"] = price_with_tax\n    return item_dict\n```\n\n----------------------------------------\n\nTITLE: Initializing a Basic A2A Server with TaskManager Class in Python\nDESCRIPTION: Shows how to set up a simple Python A2A server using the `A2AServer` class from a common library (`common.server`). Agent logic handling is encapsulated within an `EchoTaskManager` class that inherits from `TaskManager` and implements the `on_send_task` method to process requests. An `AgentCard` defines the agent's metadata, and the server is configured and started on localhost:5000.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/04_a2a_server_implementation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: simple_agent/main.py (Conceptual Example)\nfrom common.server import A2AServer, TaskManager  # Simplified import\nfrom common.types import (\n    AgentCard, AgentCapabilities, AgentSkill,\n    Task, TaskSendParams, TaskStatus, TaskState, Message, TextPart, SendTaskResponse\n)\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# 1. Define the Agent's Logic Handler (Task Manager)\n# This class bridges the server and the agent's actual logic.\nclass EchoTaskManager(TaskManager): # Inherit from the base TaskManager\n    async def on_send_task(self, params: TaskSendParams) -> SendTaskResponse:\n        # Simulate processing the task\n        input_text = params.message.parts[0].text if params.message.parts else \"No text\"\n        logger.info(f\"Echo Agent received: {input_text}\")\n\n        # Create the final Task object (simplified for non-streaming)\n        final_task = Task(\n            id=params.id,\n            status=TaskStatus(\n                state=TaskState.COMPLETED,\n                message=Message(role=\"agent\", parts=[TextPart(text=f\"You said: {input_text}\")])\n            ),\n            # ... other Task fields ...\n        )\n        # In a real scenario, you'd store/update the task state\n        # self.tasks[params.id] = final_task # Example storage\n        return SendTaskResponse(id=params.id, result=final_task)\n\n    # Implement other abstract methods from TaskManager (get, cancel, etc.)\n    # (Skipped for brevity in this example)\n    async def on_get_task(self, request): raise NotImplementedError()\n    async def on_cancel_task(self, request): raise NotImplementedError()\n    # ... and so on for streaming, push notifications etc.\n\n# 2. Define the Agent Card\necho_agent_card = AgentCard(\n    name=\"Echo Agent\",\n    description=\"Replies with the text it receives.\",\n    url=\"http://localhost:5000/\", # Where this server will run\n    version=\"1.0\",\n    capabilities=AgentCapabilities(streaming=False), # Simplified non-streaming Python example\n    skills=[AgentSkill(id=\"echo\", name=\"Echo Text\")],\n    # ... other card details\n)\n\n# 3. Create and Start the Server\nserver = A2AServer(\n    agent_card=echo_agent_card,\n    task_manager=EchoTaskManager(), # Pass our task handler\n    host=\"localhost\",\n    port=5000,\n)\n\nlogger.info(\"Starting Echo Agent server on http://localhost:5000\")\nserver.start()\n```\n\n----------------------------------------\n\nTITLE: Defining a Pydantic Data Model in Python\nDESCRIPTION: Defines an `Item` Pydantic model with required and optional fields for use as a data contract in FastAPI applications. Requires the `pydantic` Python package. Each key (name, description, price, tax) specifies its type and optional/default status. Expected input is Python object instantiations or validated JSON parsed by FastAPI. Output is a structured Pydantic object or validation errors if constraints are violated.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# models.py (or within your main.py/routers/items.py)\nfrom pydantic import BaseModel\n\nclass Item(BaseModel):\n    name: str\n    description: str | None = None  # Optional field with a default of None\n    price: float\n    tax: float | None = None        # Optional field with a default of None\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic FastAPI Application in Python\nDESCRIPTION: This snippet demonstrates the minimal code required for a FastAPI application. It imports the `FastAPI` class, creates an instance named `app`, and defines a route for the root path ('/') using the `@app.get` decorator. The associated asynchronous function `read_root` returns a Python dictionary, which FastAPI automatically converts to JSON.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py\nfrom fastapi import FastAPI\n\n# Create the main FastAPI application object\n# Think of this as initializing the 'control tower'\napp = FastAPI()\n\n# Define a 'route'\n# This tells FastAPI: If someone sends a GET request to '/', run the function below\n@app.get(\"/\")\nasync def read_root():\n  # This function will be executed for requests to '/'\n  # It returns a simple Python dictionary\n  return {\"message\": \"Hello World\"}\n\n```\n\n----------------------------------------\n\nTITLE: Simplified Session Class Logic in Requests (Python)\nDESCRIPTION: This Python snippet presents a condensed version of the requests.Session class, emphasizing its persistent state, request preparation, adapter management, and cookie extraction. It contains class and method definitions with detailed comments showing the orchestration of an HTTP request through preparation, sending, adapter selection, and connection closure. Dependencies include supporting modules such as requests, http adapters, cookies utilities, and data structures like OrderedDict. Inputs are HTTP method, URL, and optional keyword arguments; outputs are HTTP Response-like objects. Not all edge cases or session features (like redirects and hooks) are implemented in this simplified demonstration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/03_session.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/sessions.py (Simplified View)\\n\\n# [...] imports and helper functions\\n\\nclass Session(SessionRedirectMixin):\\n    def __init__(self):\\n        # Stores persistent headers, cookies, auth, etc.\\n        self.headers = default_headers()\\n        self.cookies = cookiejar_from_dict({})\\n        self.auth = None\\n        self.params = {}\\n        # [...] other defaults like verify, proxies, max_redirects\\n        self.adapters = OrderedDict() # Holds Transport Adapters\\n        self.mount('https://', HTTPAdapter()) # Default adapter for HTTPS\\n        self.mount('http://', HTTPAdapter())  # Default adapter for HTTP\\n\\n    def prepare_request(self, request):\\n        \"\"\"Prepares a Request object with Session settings.\"\"\"\\n        p = PreparedRequest()\\n\\n        # MERGE session settings with request settings\\n        merged_cookies = merge_cookies(RequestsCookieJar(), self.cookies)\\n        if request.cookies:\\n            merged_cookies = merge_cookies(merged_cookies, cookiejar_from_dict(request.cookies))\\n\\n        merged_headers = merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict)\\n        merged_params = merge_setting(request.params, self.params)\\n        merged_auth = merge_setting(request.auth, self.auth)\\n        # [...] merge other settings like hooks\\n\\n        p.prepare(\\n            method=request.method.upper(),\\n            url=request.url,\\n            headers=merged_headers,\\n            files=request.files,\\n            data=request.data,\\n            json=request.json,\\n            params=merged_params,\\n            auth=merged_auth,\\n            cookies=merged_cookies, # Pass merged cookies to PreparedRequest\\n            hooks=merge_hooks(request.hooks, self.hooks),\\n        )\\n        return p\\n\\n    def request(self, method, url, **kwargs):\\n        \"\"\"Constructs a Request, prepares it, sends it.\"\"\"\\n        # Create the initial Request object from user args\\n        req = Request(method=method.upper(), url=url, **kwargs) # Simplified\\n\\n        # Prepare the request, merging session state\\n        prep = self.prepare_request(req)\\n\\n        # Get environment settings (proxies, verify, cert) merged with session settings\\n        proxies = kwargs.get('proxies') or {}\\n        settings = self.merge_environment_settings(prep.url, proxies,\\n                                                  kwargs.get('stream'),\\n                                                  kwargs.get('verify'),\\n                                                  kwargs.get('cert'))\\n        send_kwargs = {'timeout': kwargs.get('timeout'),\\n                       'allow_redirects': kwargs.get('allow_redirects', True)}\\n        send_kwargs.update(settings)\\n\\n        # Send the prepared request using the appropriate adapter\\n        resp = self.send(prep, **send_kwargs)\\n\\n        return resp\\n\\n    def send(self, request, **kwargs):\\n        \"\"\"Sends a PreparedRequest object.\"\"\"\\n        # [...] set default kwargs if needed\\n\\n        # Get the right adapter (e.g., HTTPAdapter) based on URL\\n        adapter = self.get_adapter(url=request.url)\\n\\n        # The adapter sends the request (using connection pooling)\\n        r = adapter.send(request, **kwargs)\\n\\n        # [...] response hook processing\\n\\n        # IMPORTANT: Extract cookies from the response and store them in the session's cookie jar\\n        extract_cookies_to_jar(self.cookies, request, r.raw)\\n\\n        # [...] redirect handling (which also extracts cookies)\\n\\n        return r\\n\\n    def get_adapter(self, url):\\n        \"\"\"Finds the Transport Adapter for the URL (e.g., HTTPAdapter).\"\"\"\\n        # ... loops through self.adapters ...\\n        # Simplified: return self.adapters['http://'] or self.adapters['https://']\\n        for prefix, adapter in self.adapters.items():\\n            if url.lower().startswith(prefix.lower()):\\n                return adapter\\n        raise InvalidSchema(f\\\"No connection adapters were found for {url!r}\\\")\\n\\n    def mount(self, prefix, adapter):\\n        \"\"\"Attaches a Transport Adapter to handle URLs starting with 'prefix'.\"\"\"\\n        self.adapters[prefix] = adapter\\n        # [...] sort adapters by prefix length\\n\\n    def close(self):\\n        \"\"\"Closes the session and all its adapters (and connections).\"\"\"\\n        for adapter in self.adapters.values():\\n            adapter.close()\\n\\n    # [...] other methods like get(), post(), put(), delete() which call self.request()\\n    # [...] redirect handling logic in SessionRedirectMixin\n```\n\n----------------------------------------\n\nTITLE: Advanced Parameter Validation in FastAPI Routes\nDESCRIPTION: Illustrates advanced parameter validation using Path and Query validators with type annotations. Includes examples of path parameters, query parameters, and various validation rules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\nfrom fastapi import FastAPI, Path, Query\n\napp = FastAPI()\n\nfake_items_db = [{\"item_name\": \"Foo\"}, {\"item_name\": \"Bar\"}, {\"item_name\": \"Baz\"}]\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(\n    item_id: Annotated[int, Path(\n        title=\"The ID of the item to get\",\n        description=\"The item ID must be a positive integer.\",\n        gt=0,\n        le=1000\n    )]\n):\n    return {\"item_id\": item_id, \"name\": f\"Item {item_id} Name\"}\n\n@app.get(\"/items/\")\nasync def read_items(\n    q: Annotated[str | None, Query(\n        title=\"Query string\",\n        description=\"Optional query string to search items.\",\n        min_length=3,\n        max_length=50\n    )] = None,\n    skip: Annotated[int, Query(ge=0)] = 0,\n    limit: Annotated[int, Query(gt=0, le=100)] = 10\n):\n    results = fake_items_db[skip : skip + limit]\n    if q:\n        results = [item for item in results if q.lower() in item[\"item_name\"].lower()]\n    return results\n\n@app.post(\"/items/\")\nasync def create_item(item: Item):\n    return item\n```\n\n----------------------------------------\n\nTITLE: Defining Static and Dynamic Routes in Flask (Python)\nDESCRIPTION: This code sets up a Flask application with three types of routes: a homepage ('/'), an 'About' page ('/about'), and a dynamic user profile page ('/user/<username>'). It shows how to use the `@app.route()` decorator to link URL paths to view functions, and demonstrates how to capture a variable from the URL using angle brackets. Required dependencies are Flask (installable via pip). The key parameters are the URL path and, for dynamic routes, the variable name in angle brackets, which is then passed as an argument to the handler function. Inputs are HTTP GET requests to each route; outputs are simple text responses. The code must be saved as `hello.py` and run using `python hello.py`; visit the specified URLs in a browser to test.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/02_routing_system.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\n\nfrom flask import Flask\n\n# Create the application object from Chapter 1\napp = Flask(__name__)\n\n# Route for the homepage\n@app.route('/')\ndef index():\n  return 'Welcome to the Homepage!'\n\n# NEW: Route for the about page\n@app.route('/about')\ndef about():\n  return 'This is the About Us page.'\n\n# Code to run the app (from Chapter 1)\nif __name__ == '__main__':\n  app.run(debug=True)\n\n```\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n# ... (keep Flask import, app creation, index, and about routes) ...\n\n# NEW: Dynamic route for user profiles\n@app.route('/user/<username>')\ndef show_user_profile(username):\n  # The 'username' variable from the URL is passed to the function!\n  return f'Hello, {username}!'\n\n# ... (keep the if __name__ == '__main__': block) ...\n\n```\n\n----------------------------------------\n\nTITLE: Exploring Response Object in Python Requests\nDESCRIPTION: This code snippet demonstrates how to use the Response object returned by requests.get(). It shows how to access the status code, headers, and content of the response, as well as how to handle JSON responses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/02_request___response_models.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\nurl = 'https://httpbin.org/get'\nprint(f\"Fetching data from: {url}\")\nresponse = requests.get(url)\n\n# --- Exploring the Response Object ---\n\n# 1. Status Code: Was it successful?\nprint(f\"\\nStatus Code: {response.status_code}\") # A number like 200 (OK) or 404 (Not Found)\nprint(f\"Was it successful (status < 400)? {response.ok}\") # A boolean True/False\n\n# 2. Response Headers: Information *about* the response\nprint(f\"\\nResponse Headers (Content-Type): {response.headers['Content-Type']}\")\n# Headers are like a dictionary (Case-Insensitive)\nprint(\"All Headers:\")\nfor key, value in response.headers.items():\n    print(f\"  {key}: {value}\")\n\n# 3. Response Content (Body): The actual data!\n#    - As text (decoded using guessed encoding):\nprint(\"\\nResponse Text (first 100 chars):\")\nprint(response.text[:100])\n\n#    - As raw bytes (useful for non-text like images):\nprint(\"\\nResponse Content (bytes, first 20):\")\nprint(response.content[:20])\n\n# 4. JSON Helper: If the content is JSON\njson_url = 'https://httpbin.org/json'\nprint(f\"\\nFetching JSON from: {json_url}\")\njson_response = requests.get(json_url)\nif json_response.ok and 'application/json' in json_response.headers.get('Content-Type', ''):\n    try:\n        data = json_response.json() # Decodes JSON into a Python dict/list\n        print(\"Decoded JSON data:\")\n        print(data)\n        print(f\"Value of 'title': {data['slideshow']['title']}\")\n    except requests.exceptions.JSONDecodeError:\n        print(\"Response was not valid JSON.\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Pydantic Model with Field Annotations for FastAPI Documentation\nDESCRIPTION: This Python snippet defines a Pydantic `BaseModel` named `Item`. It uses `Field` from Pydantic to add detailed metadata (title, description, example) and validation constraints (required fields indicated by `...`, `gt`, `ge`, `max_length`) to each attribute (`name`, `description`, `price`, `tax`). FastAPI leverages this information to generate richer OpenAPI schemas for request/response bodies, significantly improving the detail and usefulness of the automatic API documentation generated at endpoints like `/docs`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/04_openapi___automatic_docs.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# ... other imports ...\n\nfrom pydantic import BaseModel, Field\n\nclass Item(BaseModel):\n    name: str = Field(..., # ... means required\n                      title=\"Item Name\",\n                      description=\"The name of the item.\",\n                      example=\"Super Gadget\")\n    description: str | None = Field(default=None,\n                                   title=\"Item Description\",\n                                   max_length=300,\n                                   example=\"A very useful gadget.\")\n    price: float = Field(...,\n                       gt=0, # Price must be greater than 0\n                       title=\"Price\",\n                       description=\"The price of the item in USD.\",\n                       example=19.99)\n    tax: float | None = Field(default=None,\n                             ge=0, # Tax >= 0 if provided\n                             title=\"Tax\",\n                             description=\"Optional sales tax.\",\n                             example=1.60)\n\n# ... rest of your FastAPI app ...\n```\n\n----------------------------------------\n\nTITLE: Including an APIRouter in the Main FastAPI App (Python)\nDESCRIPTION: This code shows how to integrate routes defined using `APIRouter` (in a separate module, `routers.items`) into the main FastAPI application. The `app.include_router(items.router)` call merges all routes from the `items` router into the main `app`, making them accessible.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# main.py\nfrom fastapi import FastAPI\nfrom routers import items  # Import the items router\n\n# Create the main FastAPI application\napp = FastAPI()\n\n# Include the router from the items module\n# All routes defined in items.router will now be part of the main app\napp.include_router(items.router)\n\n# You can still define routes directly on the app if needed\n@app.get(\"/\")\nasync def read_root():\n  return {\"message\": \"Hello Main App!\"}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Node Addition in StateGraph\nDESCRIPTION: Implementation of the add_node method in StateGraph class that handles node registration. Takes a node name and action (function/Runnable) as input, validates the node name, converts the action to a Runnable, and stores it as a StateNodeSpec.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass StateGraph(Graph):\n    def add_node(\n        self,\n        node: str,            # The name you give the node (e.g., \"adder\")\n        action: RunnableLike, # The function or Runnable (e.g., add_one)\n        *,\n        # ... other optional parameters ...\n        input: Optional[Type[Any]] = None, # Optional: specific input type for this node\n    ) -> Self:\n        # ... (checks for valid name, etc.) ...\n        if node in self.channels: # Can't use a state key name as a node name\n            raise ValueError(...)\n\n        # Converts your function into a standard LangChain Runnable if needed\n        runnable = coerce_to_runnable(action, ...)\n\n        # Stores the node's details, including the runnable and input schema\n        self.nodes[node] = StateNodeSpec(\n            runnable=runnable,\n            metadata=None, # Optional metadata\n            input=input or self.schema, # Default to graph's main state schema\n            # ... other details ...\n        )\n        return self\n```\n\n----------------------------------------\n\nTITLE: Example 422 Validation Error Response - JSON\nDESCRIPTION: Shows the typical JSON error structure FastAPI returns when incoming data does not meet the required schema. Requires no dependencies and is sent automatically by FastAPI as a response. The key parameter is invalid input, and output is a JSON object describing the errors, including location, message, and relevant context. Limitations are that the format may vary depending on Pydantic/FastAPI versions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"detail\": [\n    {\n      \"type\": \"missing\",\n      \"loc\": [\n        \"body\",\n        \"price\"\n      ],\n      \"msg\": \"Field required\",\n      \"input\": { // The invalid data received\n        \"name\": \"Gadget\"\n      },\n      \"url\": \"...\" // Pydantic v2 URL to error details\n    }\n  ]\n}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing DeepCrawlDecorator for AsyncWebCrawler in Python\nDESCRIPTION: This class decorates the AsyncWebCrawler's arun method to handle deep crawling. It checks for a deep crawl strategy in the config and delegates crawling to the strategy if present, otherwise falls back to single-page crawling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/08_deepcrawlstrategy.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from deep_crawling/base_strategy.py\nfrom contextvars import ContextVar\nfrom functools import wraps\n# ... other imports\n\nclass DeepCrawlDecorator:\n    deep_crawl_active = ContextVar(\"deep_crawl_active\", default=False)\n\n    def __init__(self, crawler: AsyncWebCrawler):\n        self.crawler = crawler\n\n    def __call__(self, original_arun):\n        @wraps(original_arun)\n        async def wrapped_arun(url: str, config: CrawlerRunConfig = None, **kwargs):\n            # Is a strategy present AND not already inside a deep crawl?\n            if config and config.deep_crawl_strategy and not self.deep_crawl_active.get():\n                # Mark that we are starting a deep crawl\n                token = self.deep_crawl_active.set(True)\n                try:\n                    # Call the STRATEGY's arun method instead of the original\n                    strategy_result = await config.deep_crawl_strategy.arun(\n                        crawler=self.crawler,\n                        start_url=url,\n                        config=config\n                    )\n                    # Handle streaming if needed\n                    if config.stream:\n                        # Return an async generator that resets the context var on exit\n                        async def result_wrapper():\n                            try:\n                                async for result in strategy_result: yield result\n                            finally: self.deep_crawl_active.reset(token)\n                        return result_wrapper()\n                    else:\n                        return strategy_result # Return the list of results directly\n                finally:\n                    # Reset the context var if not streaming (or handled in wrapper)\n                    if not config.stream: self.deep_crawl_active.reset(token)\n            else:\n                # No strategy or already deep crawling, call the original single-page arun\n                return await original_arun(url, config=config, **kwargs)\n        return wrapped_arun\n```\n\n----------------------------------------\n\nTITLE: Comprehensive Array Printing Options Management\nDESCRIPTION: Demonstrates different ways to manage NumPy's print options: global settings, temporary context managers, and direct string conversion with custom options. Also shows how to retrieve and restore default settings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport sys # Needed for sys.maxsize\n\narr = np.random.rand(10, 10) * 1000\n\n# --- Global Setting ---\nprint(\"--- Setting threshold globally ---\")\noriginal_options = np.get_printoptions() # Store original settings\nnp.set_printoptions(threshold=50)\nprint(arr)\nnp.set_printoptions(**original_options) # Restore original settings\n\n# --- Temporary Setting (Context Manager) ---\nprint(\"\\n--- Setting precision temporarily ---\")\nwith np.printoptions(precision=2, suppress=True):\n    print(arr)\nprint(\"\\n--- Back to default precision ---\")\nprint(arr) # Options are automatically restored outside the 'with' block\n\n# --- Direct Call with Overrides ---\nprint(\"\\n--- Using array2string with summarization off ---\")\n# Use sys.maxsize to effectively disable summarization\narr_string = np.array2string(arr, threshold=sys.maxsize, precision=1)\n```\n\n----------------------------------------\n\nTITLE: Implementing Options in Click Python CLI\nDESCRIPTION: Demonstrates how to create a CLI command with a --name option using Click. The option has a default value and help text, and the command function receives the option value as a parameter.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/03_parameter__option___argument_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport click\n\n@click.group()\ndef cli():\n  \"\"\"A simple tool with a greeting command.\"\"\"\n  pass\n\n@cli.command()\n@click.option('--name', default='World', help='Who to greet.')\ndef hello(name): # <-- The 'name' parameter matches the option\n  \"\"\"Greets the person specified by the --name option.\"\"\"\n  print(f\"Hello {name}!\")\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI GPT-3.5 Turbo as the LM Client in DSPy\nDESCRIPTION: Demonstrates how to configure DSPy to use OpenAI's `gpt-3.5-turbo` model. It initializes an LM client instance using `dspy.LM`, specifying the model name (using the `litellm` convention 'provider/model_name') and optionally setting default parameters like `max_tokens`. It also shows the alternative, functionally similar approach using the dedicated `dspy.models.openai.OpenAI` client. The API key is typically expected to be set in the `OPENAI_API_KEY` environment variable.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Use the generic dspy.LM for LiteLLM integration\n# Model name follows 'provider/model_name' format for many models\nturbo = dspy.LM(model='openai/gpt-3.5-turbo', max_tokens=100)\n\n# Or, if you prefer the dedicated OpenAI client wrapper (functionally similar for basic use)\n# from dspy.models.openai import OpenAI\n# turbo = OpenAI(model='gpt-3.5-turbo', max_tokens=100)\n```\n\n----------------------------------------\n\nTITLE: Initializing a Minimal Flask Application in Python\nDESCRIPTION: Imports the Flask class and creates a basic Flask application instance named 'app'. It uses the special Python variable `__name__` to help Flask determine the application's root path, which is crucial for finding templates and static files. This is the fundamental first step in building any Flask web application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/01_application_object___flask__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\n\nfrom flask import Flask\n\n# Create the application object\napp = Flask(__name__)\n\n# We'll add more here soon!\n```\n\n----------------------------------------\n\nTITLE: Checking Task Status and Retrieving Results from Result Backend\nDESCRIPTION: Comprehensive example showing how to check task state, determine if tasks are ready, retrieve results with timeouts, and handle both successful and failed task executions. Demonstrates error handling and traceback retrieval.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# continue in run_tasks.py or a new Python session\nfrom celery_app import app # Need app for AsyncResult if creating from ID\n\n# Use the AsyncResult objects we got earlier\n# Or, if you only have the ID, you can recreate the AsyncResult:\n# result_add = app.AsyncResult('the-task-id-you-saved-earlier')\n\nprint(f\"\\nChecking results for add task ({result_add.id})...\")\n\n# Check if the task is finished (returns True/False immediately)\nprint(f\"Is add ready? {result_add.ready()}\")\n\n# Check the state (returns 'PENDING', 'STARTED', 'SUCCESS', 'FAILURE', etc.)\nprint(f\"State of add: {result_add.state}\")\n\n# Get the result. IMPORTANT: This call will BLOCK until the task is finished!\n# If the task failed, this will raise the exception that occurred in the worker.\ntry:\n    # Set a timeout (in seconds) to avoid waiting forever\n    final_result = result_add.get(timeout=10)\n    print(f\"Result of add: {final_result}\")\n    print(f\"Did add succeed? {result_add.successful()}\")\n    print(f\"Final state of add: {result_add.state}\")\nexcept Exception as e:\n    print(f\"Could not get result for add: {type(e).__name__} - {e}\")\n    print(f\"Final state of add: {result_add.state}\")\n    print(f\"Did add fail? {result_add.failed()}\")\n    # Get the traceback if it failed\n    print(f\"Traceback: {result_add.traceback}\")\n\n\nprint(f\"\\nChecking results for fail_sometimes task ({result_fail.id})...\")\ntry:\n    # Wait up to 10 seconds for this task\n    fail_result = result_fail.get(timeout=10)\n    print(f\"Result of fail_sometimes: {fail_result}\")\n    print(f\"Did fail_sometimes succeed? {result_fail.successful()}\")\n    print(f\"Final state of fail_sometimes: {result_fail.state}\")\nexcept Exception as e:\n    print(f\"Could not get result for fail_sometimes: {type(e).__name__} - {e}\")\n    print(f\"Final state of fail_sometimes: {result_fail.state}\")\n    print(f\"Did fail_sometimes fail? {result_fail.failed()}\")\n    print(f\"Traceback:\\n{result_fail.traceback}\")\n```\n\n----------------------------------------\n\nTITLE: Adding Short Names and Flags to Click Options\nDESCRIPTION: Expands on the previous example by adding a short name (-n) for the --name option and introducing a --shout flag. The flag is implemented as a boolean option that doesn't require a value.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/03_parameter__option___argument_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport click\n\n@click.group()\ndef cli():\n  \"\"\"A simple tool with a greeting command.\"\"\"\n  pass\n\n@cli.command()\n@click.option('--name', '-n', default='World', help='Who to greet.') # Added '-n'\n@click.option('--shout', is_flag=True, help='Greet loudly.')        # Added '--shout' flag\ndef hello(name, shout): # <-- Function now accepts 'shout' too\n  \"\"\"Greets the person, optionally shouting.\"\"\"\n  greeting = f\"Hello {name}!\"\n  if shout:\n    greeting = greeting.upper()\n  print(greeting)\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Implementing the LiteLLMModel Interface in Python\nDESCRIPTION: A simplified Python code snippet from `models.py` showing the `LiteLLMModel` class, inheriting from the base `Model`. This class provides a concrete implementation for interacting with LLMs supported by the `litellm` library. Its `__init__` method stores the specific `model_id`. The core logic resides in the `__call__` method, which first prepares arguments using `_prepare_completion_kwargs`, then invokes `litellm.completion` to make the actual API call to the specified LLM backend, and finally parses the received response into the standard `ChatMessage` object before returning it. It depends on the `litellm` library and implicitly on environment variables for API keys.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- File: models.py (Simplified LiteLLMModel __call__) ---\nimport litellm # The library that talks to many LLMs\nfrom typing import List, Dict, Optional # Added imports based on usage\nfrom .tools import Tool # Reference to Tool concept\n\n# Assume Model and ChatMessage classes are defined above or imported\n\nclass LiteLLMModel(Model):\n    def __init__(self, model_id: str, **kwargs):\n        super().__init__(**kwargs)\n        self.model_id = model_id\n        # LiteLLM typically uses environment variables for API keys\n\n    def __call__(\n        self,\n        messages: List[Dict[str, str]],\n        stop_sequences: Optional[List[str]] = None,\n        tools_to_call_from: Optional[List[Tool]] = None,\n        **kwargs,\n    ) -> ChatMessage:\n        # 1. Prepare arguments using the helper\n        completion_kwargs = self._prepare_completion_kwargs(\n            messages=messages,\n            stop_sequences=stop_sequences,\n            tools_to_call_from=tools_to_call_from,\n            model=self.model_id, # Tell litellm which model\n            # ... other parameters ...\n            **kwargs,\n        )\n\n        # 2. Call the actual backend via litellm\n        # This hides the complexity of different API calls!\n        response = litellm.completion(**completion_kwargs)\n\n        # 3. Parse the response into our standard ChatMessage\n        # (Simplified - actual parsing involves more details)\n        raw_message = response.choices[0].message\n        chat_message = ChatMessage(\n            role=raw_message.role,\n            content=raw_message.content,\n            tool_calls=raw_message.tool_calls # If the LLM requested a tool\n        )\n        # ... store token counts, raw response etc. ...\n        return chat_message\n```\n\n----------------------------------------\n\nTITLE: Using Pydantic Model for Request Body Validation in FastAPI - Python\nDESCRIPTION: Implements an API endpoint that accepts data validated by a Pydantic model. Demonstrates dependency on FastAPI and a pre-defined `Item` model. Key parameter is a POSTed JSON object matching the Item schema. Automatically validates data and returns the cleaned object as a dict, raising a 422 error if validation fails. Output is either a dictionary matching the Item schema or a validation error response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# main.py (or routers/items.py)\nfrom fastapi import FastAPI\n# Assume 'Item' model is defined above or imported: from models import Item\n\napp = FastAPI() # Or use your APIRouter\n\n@app.post(\"/items/\")\n# Declare 'item' parameter with type hint 'Item'\nasync def create_item(item: Item):\n    # If the code reaches here, FastAPI + Pydantic already did:\n    # 1. Read the request body (as JSON bytes).\n    # 2. Parsed the JSON into a Python dict.\n    # 3. Validated the dict against the 'Item' model.\n    #    - Checked required fields ('name', 'price').\n    #    - Checked types (name is str, price is float, etc.).\n    #    - Assigned default values for optional fields if missing.\n    # 4. Created an 'Item' instance from the valid data.\n\n    # 'item' is now a Pydantic 'Item' object with validated data!\n    print(f\"Received item name: {item.name}\")\n    print(f\"Received item price: {item.price}\")\n    if item.description:\n        print(f\"Received item description: {item.description}\")\n    if item.tax:\n        print(f\"Received item tax: {item.tax}\")\n\n    # You can easily convert the Pydantic model back to a dict if needed\n    item_dict = item.model_dump() # Pydantic v2 method\n\n    # ... here you would typically save the item to a database ...\n\n    # Return the created item's data\n    return item_dict\n\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Path Parameters in FastAPI (Python)\nDESCRIPTION: Shows how to define a path parameter (`item_id`) within the URL path string (`/items/{item_id}`) using curly braces. It demonstrates how FastAPI automatically extracts the value from the URL, converts it to the specified type hint (`int`), validates it, and passes it as an argument to the path operation function (`read_item`).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# main.py or routers/items.py\nfrom fastapi import FastAPI\n\napp = FastAPI() # Or use your APIRouter\n\n@app.get(\"/items/{item_id}\")  # Path parameter defined here\nasync def read_item(item_id: int): # Parameter name MUST match! Type hint is key!\n    # FastAPI automatically converts the 'item_id' from the path (which is a string)\n    # into an integer because of the 'int' type hint.\n    # It also validates if it *can* be converted to an int.\n    return {\"item_id\": item_id, \"name\": f\"Item {item_id} Name\"}\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Route in a Flask Application (Python)\nDESCRIPTION: Demonstrates adding a route to the Flask application instance 'app'. The `@app.route('/')` decorator associates the URL path '/' (the homepage) with the `index` function. When a request is made to the root URL, the `index` function is called, and its return value ('Hello, World!') is sent back as the HTTP response. This snippet builds upon the initial app creation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/01_application_object___flask__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n# Define what happens when someone visits the homepage (\"/\")\n@app.route('/')\ndef index():\n  return 'Hello, World!'\n\n# More code to run the app below...\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatCompletionContext Base Class in Python\nDESCRIPTION: The abstract base class that defines the structure and common methods for context management. It includes the basic functionality to store messages in an internal list, with subclasses implementing specific retrieval strategies.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# From: model_context/_chat_completion_context.py (Simplified)\nfrom abc import ABC, abstractmethod\nfrom typing import List\nfrom ..models import LLMMessage\n\nclass ChatCompletionContext(ABC):\n    component_type = \"chat_completion_context\" # Identifies this as a component type\n\n    def __init__(self, initial_messages: List[LLMMessage] | None = None) -> None:\n        # Holds the COMPLETE history\n        self._messages: List[LLMMessage] = initial_messages or []\n\n    async def add_message(self, message: LLMMessage) -> None:\n        \"\"\"Add a message to the full context.\"\"\"\n        self._messages.append(message)\n\n    @abstractmethod\n    async def get_messages(self) -> List[LLMMessage]:\n        \"\"\"Get the subset of messages based on the strategy.\"\"\"\n        # Each subclass MUST implement this logic\n        ...\n\n    # Other methods like clear(), save_state(), load_state() exist too\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Pydantic Model in Python\nDESCRIPTION: Creates a simple Product model using Pydantic's BaseModel class. This model has three fields: item_id, name, and price.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nclass Product(BaseModel):\n    item_id: int\n    name: str\n    price: float | None = None\n```\n\n----------------------------------------\n\nTITLE: Defining AgentType Base Class for Custom Data Types in Python\nDESCRIPTION: This snippet establishes an abstract AgentType base class to serve as the foundation for all specialized agent data container types (such as text, image, or audio wrappers). It includes initialization logic, string conversion, and two core methods: to_raw for accessing the underlying data and to_string for a readable representation. This class is intended for subclassing and expects proper overrides. Dependencies include the Python standard logging module. It accepts a generic value on construction (string, PIL image, etc.) and provides stub implementations for subclass methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/07_agenttype.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent_types.py (Simplified AgentType) ---\\nimport logging\\nlogger = logging.getLogger(__name__)\\n\\nclass AgentType:\\n    \"\"\"Abstract base class for custom agent data types.\"\"\"\\n    def __init__(self, value):\\n        # Stores the actual data (string, PIL Image, etc.)\\n        self._value = value\\n\\n    def __str__(self):\\n        # Default string conversion uses the to_string method\\n        return self.to_string()\\n\\n    def to_raw(self):\\n        \"\"\"Returns the underlying raw Python object.\"\"\"\\n        logger.error(\"to_raw() called on base AgentType!\")\\n        return self._value\\n\\n    def to_string(self) -> str:\\n        \"\"\"Returns a string representation suitable for logging/memory.\"\"\"\\n        logger.error(\"to_string() called on base AgentType!\")\\n        return str(self._value)\\n\\n    # Other potential common methods...\\n\n```\n\n----------------------------------------\n\nTITLE: Defining and Executing a CrewAI Crew Sequentially in Python\nDESCRIPTION: This snippet showcases a simplified `Crew` class definition using Pydantic's `BaseModel`. It includes lists for `tasks` and `agents`, and specifies the execution `process` (defaulting to sequential). The `kickoff` method acts as the entry point, delegating execution to specific methods like `_run_sequential_process` based on the `process` type. The `_run_sequential_process` method iterates through the tasks, assigning each to its corresponding agent, providing context from previous tasks, executing the task, and collecting the outputs to form the final `CrewOutput`. Dependencies include `BaseModel` from Pydantic, and `Task`, `BaseAgent`, `Process`, and `CrewOutput` from the CrewAI library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/01_crew.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from crewai/crew.py\nclass Crew(BaseModel):\n    tasks: List[Task] = Field(default_factory=list)\n    agents: List[BaseAgent] = Field(default_factory=list)\n    process: Process = Field(default=Process.sequential)\n    # ... other configurations like memory, cache, etc.\n\n    def kickoff(self, inputs: Optional[Dict[str, Any]] = None) -> CrewOutput:\n        # ... setup steps ...\n\n        # Decides which execution path based on the process\n        if self.process == Process.sequential:\n            result = self._run_sequential_process()\n        elif self.process == Process.hierarchical:\n            result = self._run_hierarchical_process()\n        else:\n            # Handle other processes or errors\n            raise NotImplementedError(...)\n\n        # ... cleanup and formatting steps ...\n        return result # Returns a CrewOutput object\n\n    def _run_sequential_process(self) -> CrewOutput:\n        # Simplified loop logic\n        task_outputs = []\n        for task in self.tasks:\n            agent = task.agent # Find the agent for this task\n            context = self._get_context(task, task_outputs) # Get outputs from previous tasks\n            # Execute the task (sync or async)\n            output = task.execute_sync(agent=agent, context=context)\n            task_outputs.append(output)\n            # ... logging/callbacks ...\n        return self._create_crew_output(task_outputs) # Package final result\n```\n\n----------------------------------------\n\nTITLE: Using Persistent Sessions with Requests in Python\nDESCRIPTION: This snippet shows how to use a requests.Session object in Python to persist cookies, reuse TCP connections, and compare session-based requests versus stateless functional API calls. Dependencies are the requests library and access to example endpoints like httpbin.org. The example demonstrates: initializing a session, maintaining cookies across requests, checking cookie storage, and highlights how the functional API does not remember cookies between calls. Inputs include request URLs; outputs are JSON-printed responses from httpbin endpoints. It requires network access and the requests module.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/03_session.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\\n\\n# 1. Create a Session object\\ns = requests.Session()\\n\\n# Let's try accessing a page that requires a login (we're not logged in yet)\\nlogin_required_url = 'https://httpbin.org/cookies' # This page shows cookies sent to it\\nprint(\"Trying to access protected page without login...\")\\nresponse1 = s.get(login_required_url)\\nprint(\"Cookies sent (should be none):\", response1.json()) # httpbin returns JSON\\n\\n# Now, let's simulate 'logging in' by visiting a page that sets a cookie\\ncookie_setter_url = 'https://httpbin.org/cookies/set/sessioncookie/123456789'\\nprint(\"\\nSimulating login by getting a cookie...\")\\nresponse2 = s.get(cookie_setter_url)\\n# The session automatically stored the cookie! Check the session's cookie jar:\\nprint(\"Session cookies after setting:\", s.cookies.get_dict())\\n\\n# Now, try accessing the 'protected' page again using the SAME session\\nprint(\"\\nTrying to access protected page AGAIN with the session...\")\\nresponse3 = s.get(login_required_url)\\nprint(\"Cookies sent (should have sessioncookie):\", response3.json())\\n\\n# Compare with using the functional API (which forgets cookies)\\nprint(\"\\nTrying the same with functional API (will fail)...\")\\nresponse4 = requests.get(cookie_setter_url) # Gets cookie, but immediately forgets\\nresponse5 = requests.get(login_required_url)\\nprint(\"Cookies sent via functional API (should be none):\", response5.json())\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing a Multiline Unicode-Safe TextBuffer for Terminal Editing in TypeScript\nDESCRIPTION: This class provides a feature-rich, line-based text buffer with full support for multi-line editing, cursor movement, insertion, deletion, and external editing integration for the Codex CLI. It uses helper functions to safely operate on Unicode/multi-byte text, ensures all internal indices remain valid, and can synchronize buffer contents with system editors using Node.js process commands. Key dependencies include the 'cpLen' and 'cpSlice' helpers, and Node APIs for external editor integration. Key parameters include constructor text input, editing methods (insert, backspace, newline, move), and key event maps. Output includes updated text buffer state and a 'version' counter for change tracking.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/02_input_handling__textbuffer_editor_.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport default class TextBuffer {\n  // --- Core State ---\n  private lines: string[] = [\"\"]; // The text, line by line\n  private cursorRow = 0;          // Cursor's current line number\n  private cursorCol = 0;          // Cursor's column (character index) on the line\n  // ... scrollRow, scrollCol for viewport management ...\n  private version = 0;            // Increments on each change\n\n  constructor(text = \"\") {\n    this.lines = text.split(\"\\n\");\n    if (this.lines.length === 0) this.lines = [\"\"];\n    // Start cursor at the end\n    this.cursorRow = this.lines.length - 1;\n    this.cursorCol = this.lineLen(this.cursorRow);\n  }\n\n  // --- Internal Helpers ---\n  private line(r: number): string { return this.lines[r] ?? \"\"; }\n  private lineLen(r: number): number { return cpLen(this.line(r)); }\n  private ensureCursorInRange(): void { /* Makes sure row/col are valid */ }\n\n  // --- Public Accessors ---\n  getCursor(): [number, number] { return [this.cursorRow, this.cursorCol]; }\n  getText(): string { return this.lines.join(\"\\n\"); }\n  getVisibleLines(/* viewport */): string[] {\n    // ... calculate visible lines based on scrollRow/Col ...\n    return this.lines; // Simplified: return all lines\n  }\n\n  // --- Editing Operations ---\n  insert(ch: string): void {\n    // ... handle potential newlines by calling insertStr ...\n    const line = this.line(this.cursorRow);\n    // Use cpSlice for multi-byte character safety\n    this.lines[this.cursorRow] =\n      cpSlice(line, 0, this.cursorCol) + ch + cpSlice(line, this.cursorCol);\n    this.cursorCol += cpLen(ch); // Use cpLen\n    this.version++;\n  }\n\n  newline(): void {\n    const line = this.line(this.cursorRow);\n    const before = cpSlice(line, 0, this.cursorCol);\n    const after = cpSlice(line, this.cursorCol);\n\n    this.lines[this.cursorRow] = before; // Keep text before cursor on current line\n    this.lines.splice(this.cursorRow + 1, 0, after); // Insert text after cursor as new line\n\n    this.cursorRow++; // Move cursor down\n    this.cursorCol = 0;  // Move cursor to start of new line\n    this.version++;\n  }\n\n  backspace(): void {\n    if (this.cursorCol > 0) { // If not at start of line\n      const line = this.line(this.cursorRow);\n      this.lines[this.cursorRow] =\n        cpSlice(line, 0, this.cursorCol - 1) + cpSlice(line, this.cursorCol);\n      this.cursorCol--;\n      this.version++;\n    } else if (this.cursorRow > 0) { // If at start of line (but not first line)\n      // Merge with previous line\n      const prevLine = this.line(this.cursorRow - 1);\n      const currentLine = this.line(this.cursorRow);\n      const newCol = this.lineLen(this.cursorRow - 1); // Cursor goes to end of merged line\n\n      this.lines[this.cursorRow - 1] = prevLine + currentLine; // Combine lines\n      this.lines.splice(this.cursorRow, 1); // Remove the now-empty current line\n\n      this.cursorRow--;\n      this.cursorCol = newCol;\n      this.version++;\n    }\n    // Do nothing if at row 0, col 0\n  }\n\n  move(dir: 'left' | 'right' | 'up' | 'down' | 'wordLeft' | 'wordRight' | 'home' | 'end'): void {\n    switch (dir) {\n      case 'left':\n        if (this.cursorCol > 0) this.cursorCol--;\n        else if (this.cursorRow > 0) { /* Move to end of prev line */ }\n        break;\n      case 'right':\n        if (this.cursorCol < this.lineLen(this.cursorRow)) this.cursorCol++;\n        else if (this.cursorRow < this.lines.length - 1) { /* Move to start of next line */ }\n        break;\n      case 'up':\n        if (this.cursorRow > 0) {\n          this.cursorRow--;\n          // Try to maintain horizontal position (handle preferredCol logic)\n          this.cursorCol = Math.min(this.cursorCol, this.lineLen(this.cursorRow));\n        }\n        break;\n      // ... other cases (down, home, end) ...\n      case 'wordLeft': {\n        // Scan backwards from cursorCol, skip whitespace, then skip word chars\n        // Update this.cursorCol to the start of the word/whitespace run\n        // ... implementation details ...\n        break;\n      }\n      // ... wordRight ...\n    }\n    this.ensureCursorInRange();\n  }\n\n  // --- High-Level Input Handler ---\n  handleInput(input: string | undefined, key: Record<string, boolean>, /* viewport */): boolean {\n    const beforeVersion = this.version;\n    // Check key flags (key.leftArrow, key.backspace, key.ctrl, etc.)\n    // and the `input` character itself.\n    if (key.leftArrow && !key.ctrl && !key.meta) this.move('left');\n    else if (key.rightArrow && !key.ctrl && !key.meta) this.move('right');\n    else if (key.upArrow) this.move('up');\n    else if (key.downArrow) this.move('down');\n    else if ((key.ctrl || key.meta) && key.leftArrow) this.move('wordLeft');\n    // ... handle wordRight, home, end ...\n    else if (key.backspace || input === '\\x7f' /* DEL char */) this.backspace();\n    // ... handle delete, newline (Enter) ...\n    else if (input && !key.ctrl && !key.meta) {\n      // If it's a printable character (and not a special key combo)\n      this.insert(input);\n    }\n\n    // ... ensure cursor visible based on viewport ...\n    return this.version !== beforeVersion; // Return true if text changed\n  }\n\n  // --- External Editor ---\n  async openInExternalEditor(): Promise<void> {\n    // 1. Get editor from $VISUAL or $EDITOR env var (fallback to vi/notepad)\n    // 2. Write this.getText() to a temporary file\n    // 3. Use Node's `spawnSync` to run the editor command with the temp file path\n    //    (This blocks until the editor is closed)\n    // 4. Read the content back from the temp file\n    // 5. Update this.lines, this.cursorRow, this.cursorCol\n    // 6. Clean up the temp file\n    this.version++;\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Executing Tool Calls and Step Logic with MultiStepAgent (Python)\nDESCRIPTION: This Python code demonstrates a simplified implementation of the execute_tool_call method in an agent class (inheriting from MultiStepAgent) along with a partial step method, reflecting how the agent handles LLM-suggested tool calls. It covers finding tools by name, argument unpacking, exception handling, and managing the special case of the 'final_answer' tool. Dependencies: smolagents, tool classes, LLM model. Key parameters: tool_name (str), arguments (dict), memory_step (object). Inputs: LLM response, tool registry, action parameters. Outputs: Tool execution results, updated agent memory. Limitations include its reliance on tool existence and lack of full agent orchestration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- Simplified concept from agents.py ---\nclass SomeAgentType(MultiStepAgent):\n    # ... other methods ...\n\n    def execute_tool_call(self, tool_name: str, arguments: dict) -> Any:\n        # Find the tool in the agent's toolbox\n        if tool_name in self.tools:\n            tool_instance = self.tools[tool_name]\n            try:\n                # Call the tool's forward method with the arguments!\n                # This is where GreetingTool.forward(name=\"Bob\") happens.\n                result = tool_instance(**arguments) # Uses ** to unpack the dict\n                return result\n            except Exception as e:\n                # Handle errors if the tool fails\n                print(f\"Error executing tool {tool_name}: {e}\")\n                return f\"Error: Tool {tool_name} failed.\"\n        # ... handle case where tool_name is not found ...\n        elif tool_name == \"final_answer\":\n             # Special handling for the final answer\n             return arguments.get(\"answer\", arguments) # Return the final answer content\n        else:\n            return f\"Error: Unknown tool {tool_name}.\"\n\n    def step(self, memory_step: ActionStep):\n        # ... (Agent thinks and gets LLM response) ...\n        llm_response = # ... result from self.model(...) ...\n\n        if llm_response suggests a tool call:\n             tool_name = # ... parse tool name from response ...\n             arguments = # ... parse arguments from response ...\n\n             # === ACT ===\n             observation = self.execute_tool_call(tool_name, arguments)\n             memory_step.observations = str(observation) # Store observation\n\n             if tool_name == \"final_answer\":\n                 return observation # Signal that this is the final answer\n        # ... (handle cases where LLM gives text instead of tool call) ...\n        return None # Not the final answer yet\n\n```\n\n----------------------------------------\n\nTITLE: Example Uvicorn Server Startup Output in Bash\nDESCRIPTION: This snippet shows typical output in the terminal when Uvicorn successfully starts the FastAPI application. It indicates the server is running, the address (defaulting to http://127.0.0.1:8000), and that the reloader process is active.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [xxxxx] using StatReload\nINFO:     Started server process [xxxxx]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n```\n\n----------------------------------------\n\nTITLE: Defining a Conceptual RAG Program with DSPy Modules in Python\nDESCRIPTION: Demonstrates how to build a DSPy `Program` (which is also a `Module`) by composing smaller, specialized modules. It defines conceptual modules (`GenerateSearchQuery`, `RetrieveContext`, `GenerateAnswer`) and a `RAG` class that initializes these modules in `__init__` and orchestrates their execution in a specific sequence within its `forward` method to implement a Retrieval-Augmented Generation workflow. This illustrates data flow management between modules. Dependencies include the `dspy` library. The `RAG` program takes a `question` as input and returns a final `answer` string.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/01_module___program.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Assume we have these pre-built or custom Modules (simplified)\nclass GenerateSearchQuery(dspy.Module):\n    def forward(self, question):\n        # Logic to create search queries from the question\n        print(f\"Generating query for: {question}\")\n        return f\"search query for '{question}'\"\n\nclass RetrieveContext(dspy.Module):\n    def forward(self, query):\n        # Logic to find documents using the query\n        print(f\"Retrieving context for: {query}\")\n        return f\"Relevant context document about '{query}'\"\n\nclass GenerateAnswer(dspy.Module):\n    def forward(self, question, context):\n        # Logic to generate answer using question and context\n        print(f\"Generating answer for: {question} using context: {context}\")\n        return f\"Final answer about '{question}' based on context.\"\n\n# Now, let's build the Program (which is also a Module!)\nclass RAG(dspy.Module): # RAG = Retrieval-Augmented Generation\n    def __init__(self):\n        super().__init__()\n        # Initialize the sub-modules it will use\n        self.generate_query = GenerateSearchQuery()\n        self.retrieve = RetrieveContext()\n        self.generate_answer = GenerateAnswer()\n\n    def forward(self, question):\n        # Define the flow of data through the sub-modules\n        print(\"\\n--- RAG Program Start ---\")\n        search_query = self.generate_query(question=question)\n        context = self.retrieve(query=search_query)\n        answer = self.generate_answer(question=question, context=context)\n        print(\"--- RAG Program End ---\")\n        return answer\n\n# How to use the Program\nrag_program = RAG()\nfinal_answer = rag_program(question=\"What is DSPy?\")\nprint(f\"\\nFinal Output: {final_answer}\")\n```\n\n----------------------------------------\n\nTITLE: Initializing CodeAgent and Generating System Prompt in Python\nDESCRIPTION: This Python snippet shows the `__init__` method of the `CodeAgent` class, which inherits from `MultiStepAgent`. It handles loading default prompt templates from a YAML file (`code_agent.yaml`) if none are provided, using `importlib.resources`. It then calls the parent class initializer. The `initialize_system_prompt` method demonstrates how the final system prompt is generated by fetching dynamic data (tools, managed agents, imports) and using the `populate_template` helper function to insert this data into the loaded `system_prompt` template.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/05_prompttemplates.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport yaml\nimport importlib.resources\nfrom .tools import Tool # From Chapter 3\nfrom .agents import MultiStepAgent, populate_template, PromptTemplates # Helper function\n\nclass CodeAgent(MultiStepAgent):\n    def __init__(\n        self,\n        tools: list[Tool],\n        model: callable,\n        prompt_templates: PromptTemplates | None = None, # Allow custom templates\n        # ... other parameters ...\n    ):\n        # 1. Load default templates if none provided\n        if prompt_templates is None:\n            # Find the default 'code_agent.yaml' file\n            default_yaml_path = importlib.resources.files(\"smolagents.prompts\").joinpath(\"code_agent.yaml\")\n            # Load the templates from the YAML file\n            prompt_templates = yaml.safe_load(default_yaml_path.read_text())\n\n        # 2. Call the parent class init, passing the templates along\n        super().__init__(\n            tools=tools,\n            model=model,\n            prompt_templates=prompt_templates, # Use loaded or provided templates\n            # ... other parameters ...\n        )\n        # ... rest of CodeAgent setup ...\n        # self.system_prompt is set later using initialize_system_prompt\n\n    def initialize_system_prompt(self) -> str:\n        \"\"\"Creates the final system prompt string by filling the template.\"\"\"\n        # 3. Get necessary data (tools, managed agents, authorized imports)\n        formatted_tools = # ... format self.tools for the template ...\n        formatted_managed_agents = # ... format self.managed_agents ...\n        authorized_imports = # ... get list of allowed imports for CodeAgent ...\n\n        # 4. Use the populate_template helper to fill in the blanks\n        system_prompt_string = populate_template(\n            template=self.prompt_templates[\"system_prompt\"], # Get the template string\n            variables={ # Provide the data for the placeholders\n                \"tools\": formatted_tools,\n                \"managed_agents\": formatted_managed_agents,\n                \"authorized_imports\": authorized_imports,\n                # ... other potential variables ...\n            }\n        )\n        return system_prompt_string\n\n    # ... other CodeAgent methods ...\n```\n\n----------------------------------------\n\nTITLE: Initializing PromptTemplates for CodeAgent in Python\nDESCRIPTION: This code snippet demonstrates how the CodeAgent class initializes its PromptTemplates. It loads default templates from a YAML file, allows for custom template overrides, and uses Jinja2 for rendering the system prompt with tool descriptions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/05_prompttemplates.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass CodeAgent(MultiStepAgent):\n    def __init__(self, model_interface, tools=None, prompt_templates=None, **kwargs):\n        # Load default templates\n        default_templates = load_yaml('prompts/code_agent.yaml')\n        \n        # Override with custom templates if provided\n        if prompt_templates:\n            default_templates.update(prompt_templates)\n        \n        # Initialize Jinja2 environment\n        env = jinja2.Environment()\n        \n        # Render system prompt with tool descriptions\n        tool_descriptions = [t.get_description() for t in tools]\n        system_prompt = env.from_string(default_templates['system_prompt']).render(\n            tools=tool_descriptions\n        )\n        \n        super().__init__(model_interface, tools, system_prompt=system_prompt, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: DSPy LM Client Implementation\nDESCRIPTION: Core implementation of DSPy's base LM client and the LiteLLM-based client, showing the class structure, initialization, and request handling logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Simplified structure from dspy/clients/base_lm.py\nclass BaseLM:\n    def __init__(self, model, **kwargs):\n        self.model = model\n        self.kwargs = kwargs # Default params like temp, max_tokens\n        self.history = [] # Stores records of calls\n\n    @with_callbacks # Handles logging, potential custom hooks\n    def __call__(self, prompt=None, messages=None, **kwargs):\n        # 1. Call the actual request logic (implemented by subclasses)\n        response = self.forward(prompt=prompt, messages=messages, **kwargs)\n\n        # 2. Extract the output text(s)\n        outputs = [choice.message.content for choice in response.choices] # Simplified\n\n        # 3. Log the interaction (prompt, response, cost, etc.)\n        #    (self.history.append(...))\n\n        # 4. Return the list of generated texts\n        return outputs\n\n    def forward(self, prompt=None, messages=None, **kwargs):\n        # Subclasses MUST implement this method to make the actual API call\n        # It should return an object similar to OpenAI's API response structure\n        raise NotImplementedError\n\n# Simplified structure from dspy/clients/lm.py\nimport litellm\n\nclass LM(BaseLM): # Inherits from BaseLM\n    def __init__(self, model, model_type=\"chat\", ..., num_retries=8, **kwargs):\n        super().__init__(model=model, **kwargs)\n        self.model_type = model_type\n        self.num_retries = num_retries\n        # ... other setup ...\n\n    def forward(self, prompt=None, messages=None, **kwargs):\n        # Combine default and call-specific kwargs\n        request_kwargs = {**self.kwargs, **kwargs}\n        messages = messages or [{\"role\": \"user\", \"content\": prompt}]\n\n        # Use litellm to make the call, handles different providers\n        # Simplified - handles caching, retries, model types under the hood\n        if self.model_type == \"chat\":\n            response = litellm.completion(\n                model=self.model,\n                messages=messages,\n                # Pass combined parameters\n                **request_kwargs,\n                # Configure retries and caching via litellm\n                num_retries=self.num_retries,\n                # cache=...\n            )\n        else: # Text completion model type\n             response = litellm.text_completion(...) # Simplified\n\n        # LiteLLM returns an object compatible with BaseLM's expectations\n        return response\n\n# Simplified Usage in a Module (like Predict)\n# from dspy.dsp.utils import settings\n\n# Inside Predict's forward method:\n# lm_client = settings.lm # Get the globally configured client\n# prompt_text = self._generate_prompt(...) # Format the prompt\n# parameters = self.config # Get parameters specific to this Predict instance\n# generated_texts = lm_client(prompt_text, **parameters) # Call the LM Client!\n# output_text = generated_texts[0]\n# parsed_result = self._parse_output(output_text) # Parse based on signature\n# return Prediction(**parsed_result)\n```\n\n----------------------------------------\n\nTITLE: Controlling Response Data with response_model in FastAPI - Python\nDESCRIPTION: Demonstrates adding an extra internal field to an Item model, then using FastAPI's response_model parameter to filter and control which model fields appear in API responses. Requires FastAPI and Pydantic. Input is an Item object with possible internal-only fields; output is a JSON object matching the response_model definition, excluding fields as needed. Limitations depend on the structure of the response_model and returned object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# main.py (or routers/items.py, modified version)\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel # Assuming Item is defined here or imported\n\n# Let's add an internal field to our model for demonstration\nclass Item(BaseModel):\n    name: str\n    description: str | None = None\n    price: float\n    tax: float | None = None\n    internal_cost: float = 0.0 # Field we DON'T want in the response\n\napp = FastAPI() # Or use your APIRouter\n\n# Add response_model=Item to the decorator\n@app.post(\"/items/\", response_model=Item)\nasync def create_item(item: Item):\n    # item is the validated input Item object\n    print(f\"Processing item: {item.name} with internal cost {item.internal_cost}\")\n\n    # ... save item to database ...\n\n    # Let's imagine we return the same item object we received\n    # (in reality, you might return an object fetched from the DB)\n    return item # FastAPI will handle serialization based on response_model\n\n```\n\n----------------------------------------\n\nTITLE: Adding Elements in Standard Python Lists vs. NumPy Arrays\nDESCRIPTION: This snippet compares the implementation of element-wise addition using standard Python lists with loops versus the vectorized approach using NumPy arrays. It demonstrates the syntax simplicity and efficiency gains from using NumPy arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Using standard Python lists\nlist1 = [1, 2, 3, 4]\nlist2 = [5, 6, 7, 8]\nresult = []\nfor i in range(len(list1)):\n  result.append(list1[i] + list2[i])\n\nprint(result)\n# Output: [6, 8, 10, 12]\n```\n\n----------------------------------------\n\nTITLE: Runtime Setup and Execution with Agent Communication\nDESCRIPTION: Sets up and runs the SingleThreadedAgentRuntime, registers agent factories, adds a subscription for communication, and initiates the workflow by sending the first message. It demonstrates the complete lifecycle of runtime operation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# 3. Setup and Run the Runtime\n\nasync def main():\n    # Create the runtime (the office manager)\n    runtime = SingleThreadedAgentRuntime()\n\n    # Register the factories (tell the manager how to hire)\n    await runtime.register_factory(\"researcher\", researcher_factory)\n    await runtime.register_factory(\"writer\", writer_factory)\n    print(\"Registered agent factories.\")\n\n    # Add the subscription (tell manager who listens to which announcements)\n    # Rule: Messages to topics of type \"research.facts.available\"\n    # should go to a \"writer\" agent whose key matches the topic source.\n    writer_sub = TypeSubscription(topic_type=\"research.facts.available\", agent_type=\"writer\")\n    await runtime.add_subscription(writer_sub)\n    print(f\"Added subscription: {writer_sub.id}\")\n\n    # Start the runtime (open the office)\n    runtime.start()\n    print(\"Runtime started.\")\n\n    # Send the initial message to kick things off\n    research_task_topic = \"AutoGen Agents\"\n    researcher_instance_id = AgentId(type=\"researcher\", key=research_task_topic)\n    print(f\"Sending initial topic '{research_task_topic}' to {researcher_instance_id}\")\n    await runtime.send_message(\n        message=ResearchTopic(topic=research_task_topic),\n        recipient=researcher_instance_id,\n    )\n\n    # Wait until all messages are processed (wait for work day to end)\n    print(\"Waiting for runtime to become idle...\")\n    await runtime.stop_when_idle()\n    print(\"Runtime stopped.\")\n```\n\n----------------------------------------\n\nTITLE: Converting Models to JSON with model_dump_json()\nDESCRIPTION: Example showing how to convert a Pydantic model directly to a JSON string using the model_dump_json() method. This is useful for API responses and data storage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from the user_alice example:\nuser_json = user_alice.model_dump_json(indent=2) # indent for pretty printing\n\nprint(user_json)\n# Expected Output:\n# {\n#   \"name\": \"Alice\",\n#   \"age\": 30\n# }\nprint(type(user_json))\n# Expected Output: <class 'str'>\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Summarization Prompt Template in Python\nDESCRIPTION: Creates a FastMCP server with a prompt template for text summarization. Demonstrates basic prompt creation using @server.prompt decorator and message construction.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import UserMessage\n\nserver = FastMCP(name=\"SummarizerServer\")\n\n@server.prompt(name=\"summarize_text\", description=\"Generates messages to ask an LLM to summarize text.\")\ndef create_summary_prompt(text_to_summarize: str) -> list[UserMessage]:\n  print(f\"Rendering prompt 'summarize_text' with text: {text_to_summarize[:30]}...\")\n  prompt_content = f\"Please summarize the following text concisely:\\n\\n{text_to_summarize}\"\n  return [UserMessage(content=prompt_content)]\n\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Command Execution Flow Diagram\nDESCRIPTION: Mermaid sequence diagram visualizing the flow of command execution in Codex, showing both raw execution and sandboxed execution paths. It illustrates how different components interact when executing commands with varying security requirements.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant HEC as handleExecCommand\n    participant EC as execCommand (Helper)\n    participant Exec as exec (exec.ts)\n    participant Raw as rawExec (raw-exec.ts)\n    participant SB as execWithSeatbelt (macos-seatbelt.ts)\n\n    HEC->>EC: Run `git status`, sandboxType=NONE\n    EC->>Exec: Calls exec({cmd: [\"git\", \"status\"], ...}, SandboxType.NONE)\n    Exec->>Exec: Selects rawExec based on sandboxType\n    Exec->>Raw: Calls rawExec([\"git\", \"status\"], ...)\n    Raw->>NodeJS: Uses child_process.spawn(\"git\", [\"status\"], ...)\n    NodeJS-->>Raw: Command finishes (stdout, stderr, code)\n    Raw-->>Exec: Returns result\n    Exec-->>EC: Returns result\n    EC-->>HEC: Returns final summary\n\n    %% Example with Sandbox %%\n    HEC->>EC: Run `dangerous_script.sh`, sandboxType=MACOS_SEATBELT\n    EC->>Exec: Calls exec({cmd: [\"dangerous...\"], ...}, SandboxType.MACOS_SEATBELT)\n    Exec->>Exec: Selects execWithSeatbelt based on sandboxType\n    Exec->>SB: Calls execWithSeatbelt([\"dangerous...\"], ...)\n    SB->>SB: Constructs `sandbox-exec` command with policy\n    SB->>Raw: Calls rawExec([\"sandbox-exec\", \"-p\", policy, \"--\", \"dangerous...\"], ...)\n    Raw->>NodeJS: Uses child_process.spawn(\"sandbox-exec\", [...])\n    NodeJS-->>Raw: Sandboxed command finishes (stdout, stderr, code)\n    Raw-->>SB: Returns result\n    SB-->>Exec: Returns result\n    Exec-->>EC: Returns result\n    EC-->>HEC: Returns final summary\n```\n\n----------------------------------------\n\nTITLE: Defining Documented API Endpoints with FastAPI and Pydantic - Python\nDESCRIPTION: This Python snippet defines a FastAPI application with documented endpoints relying on Pydantic models for request validation and response serialization. It showcases three API routes: creating an item, reading a single item, and reading items with pagination; each demonstrates how metadata, type hints, and docstrings contribute to OpenAPI schema generation automatically. Dependencies are fastapi, pydantic, and Python 3.10+ for type hint syntax; expected parameters include structured JSON bodies, URL/path params, and query params. Inputs are validated per model and annotations; outputs are serialized items or error responses; endpoints demonstrate grouping via tags, model-based schemas, and docstring-based descriptions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/04_openapi___automatic_docs.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py\nfrom fastapi import FastAPI, Path, Query\nfrom pydantic import BaseModel\nfrom typing import Annotated\n\n# Define a Pydantic model (like in Chapter 3)\nclass Item(BaseModel):\n    name: str\n    description: str | None = None\n    price: float\n    tax: float | None = None\n\napp = FastAPI(\n    title=\"My Super API\",\n    description=\"This is a very fancy API built with FastAPI\",\n    version=\"1.0.0\",\n)\n\n# Simple in-memory storage\nfake_items_db = {}\n\n@app.post(\"/items/\", response_model=Item, tags=[\"Items\"])\nasync def create_item(item: Item):\n    \"\"\"\n    Create a new item and store it.\n\n    - **name**: Each item must have a name.\n    - **description**: A long description.\n    - **price**: Price must be positive.\n    \"\"\"\n    item_id = len(fake_items_db) + 1\n    fake_items_db[item_id] = item\n    return item # Return the created item\n\n@app.get(\"/items/{item_id}\", response_model=Item, tags=[\"Items\"])\nasync def read_item(\n    item_id: Annotated[int, Path(\n        title=\"The ID of the item to get\",\n        description=\"The ID of the item you want to retrieve.\",\n        gt=0\n    )]\n):\n    \"\"\"\n    Retrieve a single item by its ID.\n    \"\"\"\n    if item_id not in fake_items_db:\n        # We'll cover proper error handling in Chapter 6\n        from fastapi import HTTPException\n        raise HTTPException(status_code=404, detail=\"Item not found\")\n    return fake_items_db[item_id]\n\n@app.get(\"/items/\", tags=[\"Items\"])\nasync def read_items(\n    skip: Annotated[int, Query(description=\"Number of items to skip\")] = 0,\n    limit: Annotated[int, Query(description=\"Maximum number of items to return\")] = 10\n):\n    \"\"\"\n    Retrieve a list of items with pagination.\n    \"\"\"\n    items = list(fake_items_db.values())\n    return items[skip : skip + limit]\n\n```\n\n----------------------------------------\n\nTITLE: Creating Progress Bars with click.progressbar()\nDESCRIPTION: Demonstrates how to display an animated progress bar for long-running operations using Click's progressbar() function, providing users with visual feedback during time-consuming tasks.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# progress_example.py\nimport click\nimport time\n\nitems_to_process = range(100) # Simulate 100 items\n\n@click.command()\ndef cli():\n  \"\"\"Shows a progress bar.\"\"\"\n  # 'items_to_process' is the iterable\n  # 'label' is the text shown before the bar\n  with click.progressbar(items_to_process, label=\"Processing items\") as bar:\n    for item in bar:\n      # Simulate work for each item\n      time.sleep(0.05)\n      # The 'bar' automatically updates with each iteration\n\n  click.echo(\"Finished processing!\")\n\nif __name__ == '__main__':\n  cli()\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ python progress_example.py\nProcessing items  [####################################]  100%  00:00:05\nFinished processing!\n# (The bar animates in place while running)\n```\n\n----------------------------------------\n\nTITLE: Initializing the HTTP Basic Security Scheme for FastAPI (Python)\nDESCRIPTION: This code snippet creates an instance of the HTTPBasic security class and initializes a FastAPI app (or router). The security object configures how the API expects HTTP Basic credentials from clients, and 'app = FastAPI()' sets up the application instance. This step is a necessary predecessor to defining endpoint dependencies and requires the objects imported previously (especially HTTPBasic and FastAPI). No user data is checked here; it simply prepares for credential processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Right after imports\nsecurity = HTTPBasic()\n\napp = FastAPI() # Or use your APIRouter\n```\n\n----------------------------------------\n\nTITLE: Defining Optional Query Parameters in FastAPI (Python)\nDESCRIPTION: Illustrates how to declare optional query parameters (`skip`, `limit`) in a FastAPI path operation function. By providing default values (`= 0`, `= 10`) and type hints (`int`), FastAPI automatically extracts these parameters from the URL query string (e.g., `/items/?skip=0&limit=10`), uses defaults if they are missing, and performs type conversion and validation. The example uses these parameters for basic pagination on a fake database.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# main.py or routers/items.py\nfrom fastapi import FastAPI\n\napp = FastAPI() # Or use your APIRouter\n\n# A simple fake database of items\nfake_items_db = [{\"item_name\": \"Foo\"}, {\"item_name\": \"Bar\"}, {\"item_name\": \"Baz\"}]\n\n@app.get(\"/items/\")\n# 'skip' and 'limit' are NOT in the path \"/items/\"\n# They have default values, making them optional query parameters\nasync def read_items(skip: int = 0, limit: int = 10):\n    # FastAPI automatically gets 'skip' and 'limit' from the query string.\n    # If they are not provided in the URL, it uses the defaults (0 and 10).\n    # It also converts them to integers and validates them!\n    return fake_items_db[skip : skip + limit]\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Graph with LangGraph - Python\nDESCRIPTION: Demonstrates explicit node and edge definition in a basic LangGraph Graph. Nodes perform arithmetic operations and are registered using the 'add_node' method; the data flow is specified via 'add_edge'. This example requires the 'langgraph' package. You define node functions that accept and process input, then create and connect nodes in a graph. The input and output are controlled using node connections, but there is no shared state object. Start and finish points govern execution. Suitable for illustrating fundamental control flow with explicit transitions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# This is a conceptual example - we usually use StateGraph\nfrom langgraph.graph import Graph\n\n# Define simple functions or Runnables as nodes\ndef step_one(input_data):\n    print(\"Running Step 1\")\n    return input_data * 2\n\ndef step_two(processed_data):\n    print(\"Running Step 2\")\n    return processed_data + 5\n\n# Create a basic graph\nbasic_graph_builder = Graph()\n\n# Add nodes\nbasic_graph_builder.add_node(\"A\", step_one)\nbasic_graph_builder.add_node(\"B\", step_two)\n\n# Add edges (connections)\nbasic_graph_builder.add_edge(\"A\", \"B\") # Run B after A\nbasic_graph_builder.set_entry_point(\"A\") # Start at A\n# basic_graph_builder.set_finish_point(\"B\") # Not needed for this simple Graph type\n```\n\n----------------------------------------\n\nTITLE: Defining a Shared Query Parameters Dependency with FastAPI - Python\nDESCRIPTION: This snippet defines an asynchronous function, 'common_parameters', used as a FastAPI dependency to obtain and validate common query parameters for multiple endpoints (q, skip, limit) via Annotated and Query. It demonstrates return of a dictionary of parsed values for reuse. Requires FastAPI and Python 3.9+ (for Annotated type hints). Parameters: 'q' (optional string for filtering), 'skip' (int >= 0), 'limit' (int <= 100). Outputs a dictionary of these parameters, allowing endpoints to avoid duplicating validation logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# common_dependencies.py (or within your router file)\nfrom typing import Annotated\nfrom fastapi import Query\n\n# This is our dependency function\n# It takes the common query parameters\nasync def common_parameters(\n    q: Annotated[str | None, Query(description=\"Optional query string\")] = None,\n    skip: Annotated[int, Query(description=\"Items to skip\", ge=0)] = 0,\n    limit: Annotated[int, Query(description=\"Max items to return\", le=100)] = 100,\n):\n    # It simply returns a dictionary containing these parameters\n    return {\"q\": q, \"skip\": skip, \"limit\": limit}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Graph Nodes for Chatbot Logic in Python\nDESCRIPTION: Defines three Python functions that serve as nodes in the LangGraph. `determine_action` decides whether to use a tool or respond directly based on the query. `run_search_tool` simulates calling an external search tool. `generate_response` creates the final chatbot response, potentially using search results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Node that decides the next step\ndef determine_action(state: ChatState) -> dict:\n    print(\"--- Determining Action ---\")\n    query = state['user_query']\n    if \"weather\" in query.lower():\n        print(\"Decision: Need to use search tool for weather.\")\n        return {\"next_action\": \"USE_TOOL\"}\n    else:\n        print(\"Decision: Can respond directly.\")\n        return {\"next_action\": \"RESPOND\"}\n\n# Node representing the search tool\ndef run_search_tool(state: ChatState) -> dict:\n    print(\"--- Using Search Tool ---\")\n    query = state['user_query']\n    # Simulate finding a result\n    result = f\"Search result for '{query}': It's sunny!\"\n    # We return the result to be ADDED to the state list\n    return {\"search_result\": [result]} # Return as list for operator.add\n\n# Node that generates a final response\ndef generate_response(state: ChatState) -> dict:\n    print(\"--- Generating Response ---\")\n    if state.get(\"search_result\"):\n        response = f\"Based on my search: {state['search_result'][-1]}\"\n    else:\n        response = f\"Responding directly to: {state['user_query']}\"\n    return {\"final_response\": response}\n```\n\n----------------------------------------\n\nTITLE: Defining Word Character and Multi-Byte Safe String Helpers in TypeScript\nDESCRIPTION: These helper functions determine if a character counts as a 'word' character and provide Unicode-safe string length and slicing. 'isWordChar' checks for whitespace and basic punctuation, 'cpLen' measures string length with proper support for multi-byte characters, and 'cpSlice' slices strings by codepoints, not bytes. These utilities are critical for text editing operations that need to handle emojis and other Unicode symbols reliably.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/02_input_handling__textbuffer_editor_.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// Helper to check if a character is part of a \"word\"\nfunction isWordChar(ch: string | undefined): boolean {\n  // Simplified: returns true if not whitespace or basic punctuation\n  return ch !== undefined && !/[\\s,.;!?]/.test(ch);\n}\n\n// Helper to get the length respecting multi-byte characters (like emoji)\nfunction cpLen(str: string): number { return Array.from(str).length; }\n// Helper to slice respecting multi-byte characters\nfunction cpSlice(str: string, start: number, end?: number): string {\n  return Array.from(str).slice(start, end).join('');\n}\n\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram Showing Pydantic Annotated Helper Integration\nDESCRIPTION: This Mermaid sequence diagram illustrates how Pydantic handles fields using `typing.Annotated` with functional helpers like `AfterValidator`. It depicts the core schema generator encountering the Annotated type, calling the helper's `__get_pydantic_core_schema__` method, which in turn requests the base type's schema and then modifies it to include the custom logic (`check_no_spaces`) before returning the final field schema.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Dev as Developer\n    participant Py as Python Interpreter\n    participant Meta as BaseModel Metaclass\n    participant SchemaGen as Core Schema Generator\n    participant Helper as AfterValidator Instance\n    participant Core as Pydantic Core Engine\n\n    Dev->>Py: Define `class User(BaseModel): username: Annotated[str, AfterValidator(check_no_spaces)]`\n    Py->>Meta: Ask to create the `User` class\n    Meta->>SchemaGen: Start building schema for `User`\n    SchemaGen->>SchemaGen: Process 'username' field, see `Annotated[str, AfterValidator(...)]`\n    SchemaGen->>Helper: Call `__get_pydantic_core_schema__` on `AfterValidator` instance\n    Helper->>SchemaGen: Generate schema for base type (`str`)\n    SchemaGen-->>Helper: Return base `str` schema\n    Helper->>Helper: Modify schema, adding 'after_validator' pointing to `check_no_spaces`\n    Helper-->>SchemaGen: Return modified schema for 'username'\n    SchemaGen->>Core: Finalize schema for `User` model incorporating custom logic\n    Core-->>SchemaGen: Provide completed Core Schema\n    SchemaGen-->>Meta: Return Core Schema\n    Meta->>Core: Request validator/serializer from final schema\n    Core-->>Meta: Provide optimized functions\n    Meta-->>Py: Return the fully prepared `User` class\n    Py-->>Dev: `User` class is ready\n```\n\n----------------------------------------\n\nTITLE: Checking CrawlResult Success and Handling Errors in Python\nDESCRIPTION: This example shows how to properly check if a crawl operation was successful using the 'success' attribute of CrawlResult. It demonstrates error handling and accessing basic metadata when the crawl succeeds.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlResult # Import CrawlResult for type hint\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url = \"https://httpbin.org/html\" # A working URL\n        # url = \"https://httpbin.org/status/404\" # Try this URL to see failure\n        result: CrawlResult = await crawler.arun(url=url)\n\n        # --- ALWAYS CHECK 'success' FIRST! ---\n        if result.success:\n            print(f\"✅ Successfully crawled: {result.url}\")\n            # Now it's safe to access other attributes\n            print(f\"   Page Title: {result.metadata.get('title', 'N/A')}\")\n        else:\n            print(f\"❌ Failed to crawl: {result.url}\")\n            print(f\"   Error: {result.error_message}\")\n            print(f\"   Status Code: {result.status_code}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Celery App Initialization in Python\nDESCRIPTION: Internal code snippet showing how the Celery class is initialized. This includes setting up the task registry, storing initial configuration, and registering the app instance globally.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from celery/app/base.py\nfrom .registry import TaskRegistry\nfrom .utils import Settings\n\nclass Celery:\n    def __init__(self, main=None, broker=None, backend=None,\n                 include=None, config_source=None, task_cls=None,\n                 autofinalize=True, **kwargs):\n\n        self.main = main # Store the app name ('tasks' in our example)\n        self._tasks = TaskRegistry({}) # Create an empty dictionary for tasks\n\n        # Store broker/backend/include settings temporarily\n        self._preconf = {}\n        self.__autoset('broker_url', broker)\n        self.__autoset('result_backend', backend)\n        self.__autoset('include', include)\n        # ... other kwargs ...\n\n        # Configuration object - initially pending, loaded later\n        self._conf = Settings(...)\n\n        # ... other setup ...\n\n        _register_app(self) # Register this app instance globally (sometimes useful)\n\n    # Helper to store initial settings before full configuration load\n    def __autoset(self, key, value):\n        if value is not None:\n            self._preconf[key] = value\n```\n\n----------------------------------------\n\nTITLE: Using ChatCompletionClient to Request Text Summarization from an LLM\nDESCRIPTION: This code demonstrates how to use a ChatCompletionClient to send messages to an LLM and process the response. It includes a mock implementation of the client for demonstration, shows how to call the create() method asynchronously, and how to extract and display the summary and token usage information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: call_llm_client.py\nimport asyncio\nfrom autogen_core.models import CreateResult, RequestUsage\n# Assume 'messages_to_send' is from the previous step\n# Assume 'llm_client' is a pre-configured ChatCompletionClient instance\n# (e.g., llm_client = OpenAIChatCompletionClient(config=...))\n\nasync def get_summary(client, messages):\n    print(\"\\nSending messages to LLM via ChatCompletionClient...\")\n    try:\n        # The core call: send messages, get structured result\n        response: CreateResult = await client.create(\n            messages=messages,\n            # We aren't providing tools in this simple example\n            tools=[]\n        )\n        print(\"Received response:\")\n        print(f\"- Finish Reason: {response.finish_reason}\")\n        print(f\"- Content: {response.content}\") # This should be the summary\n        print(f\"- Usage (Tokens): Prompt={response.usage.prompt_tokens}, Completion={response.usage.completion_tokens}\")\n        print(f\"- Cached: {response.cached}\")\n\n        # Also, check total usage tracked by the client\n        total_usage = client.total_usage()\n        print(f\"\\nClient Total Usage: Prompt={total_usage.prompt_tokens}, Completion={total_usage.completion_tokens}\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# --- Placeholder for actual client ---\nclass MockChatCompletionClient: # Simulate a real client\n    _total_usage = RequestUsage(prompt_tokens=0, completion_tokens=0)\n    async def create(self, messages, tools=[], **kwargs) -> CreateResult:\n        # Simulate API call and response\n        prompt_len = sum(len(str(m.content)) for m in messages) // 4 # Rough token estimate\n        summary = \"AutoGen is a multi-agent framework for developing LLM applications.\"\n        completion_len = len(summary) // 4 # Rough token estimate\n        usage = RequestUsage(prompt_tokens=prompt_len, completion_tokens=completion_len)\n        self._total_usage.prompt_tokens += usage.prompt_tokens\n        self._total_usage.completion_tokens += usage.completion_tokens\n        return CreateResult(\n            finish_reason=\"stop\", content=summary, usage=usage, cached=False\n        )\n    def total_usage(self) -> RequestUsage: return self._total_usage\n    # Other required methods (count_tokens, model_info etc.) omitted for brevity\n\nasync def main():\n    from prepare_messages import messages_to_send # Get messages from previous step\n    mock_client = MockChatCompletionClient()\n    await get_summary(mock_client, messages_to_send)\n\n# asyncio.run(main()) # If you run this, it uses the mock client\n```\n\n----------------------------------------\n\nTITLE: Simplified Session Adapter Internals - Python\nDESCRIPTION: This code illustrates the internal mechanics of requests.Session from the requests library, focusing on adapter mounting, selection, and handoff to the adapter for making HTTP calls. Core methods include mount, get_adapter, and send. Dependencies are Python 3 standard library collections.OrderedDict and requests' HTTPAdapter. Key parameters are URL prefixes and HTTP request objects; outputs are fully formed Response objects as returned by requests' send method. Certain setup and real-world considerations (e.g., sorting adapters, hooks) are noted as simplified.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/sessions.py (Simplified View)\n\nclass Session:\n    def __init__(self):\n        # ... other defaults ...\n        self.adapters = OrderedDict() # The mounted adapters\n        self.mount('https://', HTTPAdapter()) # Mount default HTTPS adapter\n        self.mount('http://', HTTPAdapter())  # Mount default HTTP adapter\n\n    def get_adapter(self, url):\n        \"\"\"Returns the appropriate connection adapter for the given URL.\"\"\"\n        for prefix, adapter in self.adapters.items():\n            # Find the longest prefix that matches the URL\n            if url.lower().startswith(prefix.lower()):\n                return adapter\n        # No match found\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\n\n    def mount(self, prefix, adapter):\n        \"\"\"Registers a connection adapter to a prefix.\"\"\"\n        self.adapters[prefix] = adapter\n        # Sort adapters by prefix length, descending (longest first)\n        # Simplified: Real code sorts keys and rebuilds OrderedDict\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n        for key in keys_to_move:\n             self.adapters[key] = self.adapters.pop(key)\n\n    def send(self, request, **kwargs):\n        # ... setup kwargs (stream, verify, cert, proxies) ...\n\n        # === GET THE ADAPTER ===\n        adapter = self.get_adapter(url=request.url)\n\n        # === DELEGATE TO THE ADAPTER ===\n        # Start timer\n        start = preferred_clock()\n        # Call the adapter's send method\n        r = adapter.send(request, **kwargs)\n        # Stop timer\n        elapsed = preferred_clock() - start\n        r.elapsed = timedelta(seconds=elapsed)\n\n        # ... dispatch response hooks ...\n        # ... persist cookies (extract_cookies_to_jar) ...\n        # ... handle redirects (resolve_redirects, might call send again) ...\n\n        # ... maybe read content if stream=False ...\n        return r\n```\n\n----------------------------------------\n\nTITLE: Testing the Background Task Endpoint using cURL (Bash)\nDESCRIPTION: Shows how to test the `/send-notification/{email}` endpoint using the `curl` command-line tool. It sends a POST request to the specified URL (running on the local machine, port 8000), triggering the API endpoint and its associated background task.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST http://127.0.0.1:8000/send-notification/test@example.com\n```\n\n----------------------------------------\n\nTITLE: Implementing MultiStepAgent Core Loop (`_run`) in Python\nDESCRIPTION: Simplified `_run` generator method from `agents.py`, implementing the core Think-Act-Observe cycle. It iterates up to `max_steps`, calling `_execute_step` in each iteration to perform the agent's action. It manages step preparation (`_create_action_step`), error handling (`AgentError`), step finalization (`_finalize_step`), saving steps to memory, and yields `ActionStep` details for potential streaming. Finally, it yields the `FinalAnswerStep` or handles reaching the maximum step limit.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified _run) ---\nclass MultiStepAgent:\n    def _run(self, task: str, max_steps: int, ...) -> Generator:\n        final_answer = None\n        self.step_number = 1\n        while final_answer is None and self.step_number <= max_steps:\n            action_step = self._create_action_step(...) # Prepare memory for this step\n\n            try:\n                # This is where the agent type decides how to act\n                # (e.g., call LLM, parse, execute tool/code)\n                final_answer = self._execute_step(task, action_step)\n            except AgentError as e:\n                action_step.error = e # Record errors\n            finally:\n                self._finalize_step(action_step, ...) # Record timing, etc.\n                self.memory.steps.append(action_step) # Save step to memory\n                yield action_step # Yield step details (for streaming)\n                self.step_number += 1\n\n        if final_answer is None:\n            # Handle reaching max steps\n            ...\n        yield FinalAnswerStep(handle_agent_output_types(final_answer)) # Yield final answer\n```\n\n----------------------------------------\n\nTITLE: Integrating Model Interface with MultiStepAgent in Python\nDESCRIPTION: This snippet shows how to integrate the previously initialized `Model Interface` (`llm` object) with a `MultiStepAgent`. It requires importing `MultiStepAgent` and potentially defining tools (like `SearchTool`). The `llm` instance is passed as the `model` argument during the `MultiStepAgent` initialization. This allows the agent to interact with the configured LLM through the standardized interface provided by `llm`, without needing direct knowledge of the specific LLM being used.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# --- Continued from choose_model.py ---\n# (Requires imports from Chapter 1: MultiStepAgent, SearchTool, etc.)\nfrom smolagents import MultiStepAgent\nfrom smolagents.tools import SearchTool # Example Tool\n\n# Define some tools (details in Chapter 3)\nsearch_tool = SearchTool()\ntools = [search_tool]\n\n# Create the agent, giving it the model interface instance\nagent = MultiStepAgent(\n    model=llm,  # <= Here's where we plug in our \"universal remote\"!\n    tools=tools\n)\n\nprint(\"MultiStepAgent created and configured with the model!\")\n# Example Output: MultiStepAgent created and configured with the model!\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatCompletionClient Protocol in Python\nDESCRIPTION: The abstract base class that defines the contract all LLM clients must follow. It includes methods for creating completions, streaming results, tracking token usage, and estimating token counts.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# From: models/_model_client.py (Simplified ABC)\nfrom abc import ABC, abstractmethod\nfrom typing import Sequence, Optional, Mapping, Any, AsyncGenerator, Union\nfrom ._types import LLMMessage, CreateResult, RequestUsage\nfrom ..tools import Tool, ToolSchema\nfrom .. import CancellationToken\n\nclass ChatCompletionClient(ABC):\n    @abstractmethod\n    async def create(\n        self, messages: Sequence[LLMMessage], *,\n        tools: Sequence[Tool | ToolSchema] = [],\n        json_output: Optional[bool] = None, # Hint for JSON mode\n        extra_create_args: Mapping[str, Any] = {}, # API-specific args\n        cancellation_token: Optional[CancellationToken] = None,\n    ) -> CreateResult: ... # The core method\n\n    @abstractmethod\n    def create_stream(\n        self, # Similar to create, but yields results incrementally\n        # ... parameters ...\n    ) -> AsyncGenerator[Union[str, CreateResult], None]: ...\n\n    @abstractmethod\n    def total_usage(self) -> RequestUsage: ... # Get total tracked usage\n\n    @abstractmethod\n    def count_tokens(self, messages: Sequence[LLMMessage], *, tools: Sequence[Tool | ToolSchema] = []) -> int: ... # Estimate token count\n\n    # Other methods like close(), actual_usage(), remaining_tokens(), model_info...\n```\n\n----------------------------------------\n\nTITLE: Implementing IntParamType in Python Click Framework\nDESCRIPTION: Defines the IntParamType class which inherits from ParamType and provides integer validation and conversion. It attempts to convert the input value to an integer and raises a formatted error message if the conversion fails.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass IntParamType(ParamType):\n    name = \"integer\"\n\n    def convert(self, value, param, ctx):\n        try:\n            # The core conversion logic!\n            return int(value)\n        except ValueError:\n            # If conversion fails, raise the standard error\n            self.fail(f\"{value!r} is not a valid integer.\", param, ctx)\n```\n\n----------------------------------------\n\nTITLE: Example of OpenAI API Structured Response in JSON\nDESCRIPTION: This snippet illustrates the structure of a response from the OpenAI API, showing how it separates regular conversation text from tool call requests. It demonstrates the JSON format with message and function_call components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n// Simplified idea of an AI response\n{\n  \"id\": \"response_123\",\n  \"output\": [\n    {\n      \"type\": \"message\", // A regular text message\n      \"role\": \"assistant\",\n      \"content\": [{ \"type\": \"output_text\", \"text\": \"Okay, checking the status...\" }]\n    },\n    {\n      \"type\": \"function_call\", // A request to use a tool!\n      \"name\": \"shell\",\n      \"arguments\": \"{\\\"command\\\": [\\\"git\\\", \\\"status\\\"]}\", // Details for the tool\n      \"call_id\": \"call_abc\"\n    }\n  ]\n  // ... other info ...\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Decorator in Celery (Python)\nDESCRIPTION: This snippet shows how the Celery task decorator creates and registers task classes. It handles decorator arguments, generates task names, and adds tasks to the app's registry.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef task(self, *args, **opts):\n    # ... logic to handle decorator arguments ...\n    def _create_task_cls(fun):\n        # If app isn't finalized, might return a proxy object first\n        # Eventually calls _task_from_fun to create/register the task\n        ret = self._task_from_fun(fun, **opts)\n        return ret\n    return _create_task_cls\n\ndef _task_from_fun(self, fun, name=None, base=None, bind=False, **options):\n    # Generate task name if not provided (e.g., 'celery_app.add')\n    name = name or self.gen_task_name(fun.__name__, fun.__module__)\n    base = base or self.Task # Default base Task class\n\n    # Check if task already registered\n    if name not in self._tasks:\n        # Create a Task class dynamically based on the function\n        task = type(fun.__name__, (base,), {\n            'app': self, # Link task back to this app instance!\n            'name': name,\n            'run': staticmethod(fun), # The actual function to run\n            # ... other attributes and options ...\n        })() # Instantiate the new task class\n        self._tasks[task.name] = task # Add to app's task registry\n        task.bind(self) # Perform any binding steps\n    else:\n        task = self._tasks[name] # Task already exists\n    return task\n```\n\n----------------------------------------\n\nTITLE: Defining Request Validation with Pydantic Models in FastAPI (Python)\nDESCRIPTION: This code demonstrates how to define a POST endpoint with request data validation using a Pydantic model. FastAPI automatically checks incoming JSON against the model, and on failure, returns a 422 error response with details. Dependencies: fastapi, pydantic. Parameters: item (validated request body). Input: JSON matching Item schema. Output: Success message with item data or validation error.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# main.py or your router file\\nfrom fastapi import FastAPI\\nfrom pydantic import BaseModel\\n\\napp = FastAPI()\\n\\n# Pydantic model requiring name and price\\nclass Item(BaseModel):\\n    name: str\\n    price: float\\n    description: str | None = None\\n\\n@app.post(\\\"/items/\\\")\\n# Expects request body matching the Item model\\nasync def create_item(item: Item):\\n    # If execution reaches here, validation PASSED automatically.\\n    return {\\\"message\\\": \\\"Item received!\\\", \\\"item_data\\\": item.model_dump()}\n```\n\n----------------------------------------\n\nTITLE: Implementing SemaphoreDispatcher for Concurrency Control in Python\nDESCRIPTION: This snippet provides a simplified implementation of the `SemaphoreDispatcher` class, inheriting from `BaseDispatcher`. It uses an `asyncio.Semaphore` to control the number of concurrent crawl tasks. The `__init__` method sets up the semaphore count. The `crawl_url` method acquires the semaphore (`async with semaphore`) before calling the main crawler's `arun` method and handles timing, memory tracking (`psutil`), rate limiting, and monitoring updates. The `run_urls` method creates an `asyncio.Semaphore`, spawns tasks for each URL using `asyncio.create_task` (passing the semaphore), and uses `asyncio.gather` to run them concurrently while respecting the semaphore limit. Dependencies include `asyncio`, `uuid`, `psutil`, `time`, and `crawl4ai` components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/10_basedispatcher.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/async_dispatcher.py\nimport asyncio\nimport uuid\nimport psutil # For memory tracking in crawl_url\nimport time   # For timing in crawl_url\n# ... other imports ...\n\nclass SemaphoreDispatcher(BaseDispatcher):\n    def __init__(\n        self,\n        semaphore_count: int = 5,\n        # ... other params like rate_limiter, monitor ...\n    ):\n        super().__init__(...) # Pass rate_limiter, monitor to base\n        self.semaphore_count = semaphore_count\n\n    async def crawl_url(\n        self,\n        url: str,\n        config: CrawlerRunConfig,\n        task_id: str,\n        semaphore: asyncio.Semaphore = None, # Takes the semaphore\n    ) -> CrawlerTaskResult:\n        # ... (Code to track start time, memory usage - similar to MemoryAdaptiveDispatcher's version)\n        start_time = time.time()\n        error_message = \"\"\n        memory_usage = peak_memory = 0.0\n        result = None\n\n        try:\n            # Update monitor state if used\n            if self.monitor: self.monitor.update_task(task_id, status=CrawlStatus.IN_PROGRESS)\n\n            # Wait for rate limiter if used\n            if self.rate_limiter: await self.rate_limiter.wait_if_needed(url)\n\n            # --- Core Semaphore Logic ---\n            async with semaphore: # Acquire a spot from the semaphore\n                # Now that we have a spot, run the actual crawl\n                process = psutil.Process()\n                start_memory = process.memory_info().rss / (1024 * 1024)\n\n                # Call the single-page crawl method of the main crawler\n                result = await self.crawler.arun(url, config=config, session_id=task_id)\n\n                end_memory = process.memory_info().rss / (1024 * 1024)\n                memory_usage = peak_memory = end_memory - start_memory\n            # --- Semaphore spot is released automatically on exiting 'async with' ---\n\n            # Update rate limiter based on result status if used\n            if self.rate_limiter and result.status_code:\n                 if not self.rate_limiter.update_delay(url, result.status_code):\n                    # Handle retry limit exceeded\n                    error_message = \"Rate limit retry count exceeded\"\n                    # ... update monitor, prepare error result ...\n\n            # Update monitor status (success/fail)\n            if result and not result.success: error_message = result.error_message\n            if self.monitor: self.monitor.update_task(task_id, status=CrawlStatus.COMPLETED if result.success else CrawlStatus.FAILED)\n\n        except Exception as e:\n            # Handle unexpected errors during the crawl\n            error_message = str(e)\n            if self.monitor: self.monitor.update_task(task_id, status=CrawlStatus.FAILED)\n            # Create a failed CrawlResult if needed\n            if not result: result = CrawlResult(url=url, html=\"\", success=False, error_message=error_message)\n\n        finally:\n            # Final monitor update with timing, memory etc.\n             end_time = time.time()\n             if self.monitor: self.monitor.update_task(...)\n\n        # Package everything into CrawlerTaskResult\n        return CrawlerTaskResult(...)\n\n\n    async def run_urls(\n        self,\n        crawler: \"AsyncWebCrawler\",\n        urls: List[str],\n        config: CrawlerRunConfig,\n    ) -> List[CrawlerTaskResult]:\n        self.crawler = crawler # Store the crawler instance\n        if self.monitor: self.monitor.start()\n\n        try:\n            # Create the semaphore with the specified count\n            semaphore = asyncio.Semaphore(self.semaphore_count)\n            tasks = []\n\n            # Create a crawl task for each URL, passing the semaphore\n            for url in urls:\n                task_id = str(uuid.uuid4())\n                if self.monitor: self.monitor.add_task(task_id, url)\n                # Create an asyncio task to run crawl_url\n                task = asyncio.create_task(\n                    self.crawl_url(url, config, task_id, semaphore=semaphore)\n                )\n                tasks.append(task)\n\n            # Wait for all created tasks to complete\n            # asyncio.gather runs them concurrently, respecting the semaphore limit\n            results = await asyncio.gather(*tasks, return_exceptions=True)\n\n            # Process results (handle potential exceptions returned by gather)\n            final_results = []\n            for res in results:\n                if isinstance(res, Exception):\n                    # Handle case where gather caught an exception from a task\n                    # You might create a failed CrawlerTaskResult here\n                    pass\n                elif isinstance(res, CrawlerTaskResult):\n                    final_results.append(res)\n            return final_results\n        finally:\n            if self.monitor: self.monitor.stop()\n\n    # run_urls_stream would have similar logic but use asyncio.as_completed\n    # or manage tasks manually to yield results as they finish.\n```\n\n----------------------------------------\n\nTITLE: Customizing Field Serialization with @field_serializer in Python\nDESCRIPTION: Illustrates the use of the @field_serializer decorator to control how a specific field is serialized when converting a Pydantic model to a dictionary or JSON. The example formats a date field as a 'YYYY-MM-DD' string.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\nfrom pydantic import BaseModel, field_serializer\n\nclass Event(BaseModel):\n    name: str\n    event_date: date\n\n    # Customize serialization for the 'event_date' field\n    @field_serializer('event_date')\n    def serialize_date(self, dt: date) -> str:\n        # Return the custom formatted string\n        return dt.strftime('%Y-%m-%d')\n\n# --- Try it out ---\nevent = Event(name='Party', event_date=date(2024, 12, 25))\n\n# Default dump (dictionary)\nprint(f\"Model object: {event}\")\n# Expected Output: Model object: name='Party' event_date=datetime.date(2024, 12, 25)\n\ndumped_dict = event.model_dump()\nprint(f\"Dumped dict: {dumped_dict}\")\n# Expected Output: Dumped dict: {'name': 'Party', 'event_date': '2024-12-25'}\n\ndumped_json = event.model_dump_json(indent=2)\nprint(f\"Dumped JSON:\\n{dumped_json}\")\n# Expected Output:\n# Dumped JSON:\n# {\n#   \"name\": \"Party\",\n#   \"event_date\": \"2024-12-25\"\n# }\n```\n\n----------------------------------------\n\nTITLE: Write Application Logic in Pregel Engine\nDESCRIPTION: Function that applies task outputs to channels, managing state updates according to each channel's rules and versioning. Handles write collection, channel updates, and version management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/05_pregel_execution_engine.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef apply_writes(checkpoint, channels, tasks: list[PregelExecutableTask], get_next_version):\n    # ... (sort tasks for determinism, update seen versions) ...\n    pending_writes_by_channel = defaultdict(list)\n    for task in tasks:\n        for chan, val in task.writes: # task.writes is the dict returned by the node\n            if chan in channels:\n                pending_writes_by_channel[chan].append(val)\n            # ... (handle TASKS, PUSH, managed values etc.) ...\n\n    updated_channels = set()\n    # Apply writes to channels\n    for chan_name, values_to_update in pending_writes_by_channel.items():\n        channel_obj = channels[chan_name]\n        if channel_obj.update(values_to_update): # Channel applies its logic here!\n            # If updated, bump the version in the checkpoint\n            checkpoint[\"channel_versions\"][chan_name] = get_next_version(...)\n            updated_channels.add(chan_name)\n\n    # ... (handle channels that weren't written to but need bumping) ...\n    return updated_channels\n```\n\n----------------------------------------\n\nTITLE: Basic Celery App Configuration with Direct Parameters\nDESCRIPTION: Creating a Celery app instance with broker and backend parameters passed directly to the constructor. This is the simplest approach for basic configurations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# From Chapter 1\nfrom celery import Celery\n\napp = Celery('tasks',\n             broker='redis://localhost:6379/0',\n             backend='redis://localhost:6379/0')\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Pydantic Model\nDESCRIPTION: Creating a simple User model by inheriting from BaseModel and defining fields with type annotations. This demonstrates the core pattern for creating data models in Pydantic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import BaseModel from Pydantic\nfrom pydantic import BaseModel\n\n# Define your data blueprint (Model)\nclass User(BaseModel):\n    name: str  # The user's name must be a string\n    age: int   # The user's age must be an integer\n```\n\n----------------------------------------\n\nTITLE: Implementing BrowserState Model with Pydantic\nDESCRIPTION: Defines the BrowserState Pydantic model that represents a complete snapshot of the browser's state, including URL, title, element tree, selector map, screenshot, and tabs information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import Optional, List, Dict\n\nclass BrowserState(BaseModel):\n    url: str\n    title: str\n    element_tree: Optional[object]\n    selector_map: Optional[Dict[int, object]]\n    screenshot: Optional[str] = None\n    tabs: List[object] = []\n```\n\n----------------------------------------\n\nTITLE: Running a Click Command in Bash\nDESCRIPTION: Shows how to execute the Hello World Click command from the terminal. It demonstrates running the script directly and using the automatically generated --help option.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/01_command___group.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ python hello_app.py\nHello World!\n\n$ python hello_app.py --help\nUsage: hello_app.py [OPTIONS]\n\n  A simple command that says Hello World\n\nOptions:\n  --help  Show this message and exit.\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response from FastAPI Root Endpoint\nDESCRIPTION: This shows the JSON data returned by the basic FastAPI application when a GET request is made to the root path (`/`). FastAPI automatically converted the Python dictionary `{\"message\": \"Hello World\"}` returned by the `read_root` function into this JSON format.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\"message\":\"Hello World\"}\n```\n\n----------------------------------------\n\nTITLE: Compiling the StateGraph for Execution - Python\nDESCRIPTION: Compiles the StateGraph object into an executable application. This step finalizes the graph's structure and prepares it for invocation with concrete input. Requires a constructed StateGraph instance (here named 'workflow'). The resulting 'app' can be repeatedly invoked with compatible state dictionaries. This step is mandatory before deploying or testing the graph.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Compile the workflow into an executable object\napp = workflow.compile()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Basic Agent for Browser Automation in Python\nDESCRIPTION: A simplified example demonstrating how to set up and use an Agent to perform an automated web task. The code initializes all necessary components (Browser, Controller, BrowserContext), creates an Agent instance, and runs it to execute a search task, with proper error handling and cleanup.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/01_agent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- Simplified Example ---\n# We need to import the necessary parts from the browser_use library\nfrom browser_use import Agent, Browser, Controller, BrowserConfig, BrowserContextConfig\n# Assume 'my_llm' is your configured Large Language Model (e.g., from OpenAI, Anthropic)\nfrom my_llm_setup import my_llm # Placeholder for your specific LLM setup\n\n# 1. Define the task for the Agent\nmy_task = \"Go to google.com, search for 'cute cat pictures', and click the first image result.\"\n\n# 2. Basic browser configuration (we'll learn more later)\nbrowser_config = BrowserConfig() # Default settings\ncontext_config = BrowserContextConfig() # Default settings\n\n# 3. Initialize the components the Agent needs\n# The Browser manages the underlying browser application\nbrowser = Browser(config=browser_config)\n# The Controller knows *how* to perform actions like 'click' or 'type'\ncontroller = Controller()\n\nasync def main():\n    # The BrowserContext represents a single browser tab/window environment\n    # It uses the Browser and its configuration\n    async with BrowserContext(browser=browser, config=context_config) as browser_context:\n\n        # 4. Create the Agent instance!\n        agent = Agent(\n            task=my_task,\n            llm=my_llm,                # The \"brain\" - the Language Model\n            browser_context=browser_context, # The \"eyes\" - interacts with the browser tab\n            controller=controller          # The \"hands\" - executes actions\n            # Many other settings can be configured here!\n        )\n\n        print(f\"Agent created. Starting task: {my_task}\")\n\n        # 5. Run the Agent! This starts the loop.\n        # It will keep taking steps until the task is done or it hits the limit.\n        history = await agent.run(max_steps=15) # Limit steps for safety\n\n        # 6. Check the result\n        if history.is_done() and history.is_successful():\n            print(\"✅ Agent finished the task successfully!\")\n            print(f\"Final message from agent: {history.final_result()}\")\n        else:\n            print(\"⚠️ Agent stopped. Maybe max_steps reached or task wasn't completed successfully.\")\n\n    # The 'async with' block automatically cleans up the browser_context\n    await browser.close() # Close the browser application\n\n# Run the asynchronous function\nimport asyncio\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining an English-to-French Translation Signature with DSPy in Python\nDESCRIPTION: Defines a custom Signature by subclassing dspy.Signature for translating English text to French. The signature includes an input field (english_sentence) and an output field (french_sentence), both described with the desc parameter. The docstring serves as instructions for the Language Model. Dependencies: dspy, dspy.signatures.field, and Python 3. Expected inputs are English sentences, and outputs are the corresponding French translations. This class is intended for use with DSPy modules, like dspy.Predict.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/02_signature.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\nfrom dspy.signatures.field import InputField, OutputField\n\nclass TranslateToFrench(dspy.Signature):\n    \"\"\"Translates English text to French.\"\"\" # <-- These are the Instructions!\n\n    # Define the Input Field the module expects\n    english_sentence = dspy.InputField(desc=\"The original sentence in English\")\n\n    # Define the Output Field the module should produce\n    french_sentence = dspy.OutputField(desc=\"The translated sentence in French\")\n\n```\n\n----------------------------------------\n\nTITLE: Importing BackgroundTasks in FastAPI (Python)\nDESCRIPTION: Imports the necessary `BackgroundTasks` class from the `fastapi` library alongside the main `FastAPI` application class. This is the first step required to use background tasks in a FastAPI application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py (or your router file)\nfrom fastapi import BackgroundTasks, FastAPI\n\napp = FastAPI()\n```\n\n----------------------------------------\n\nTITLE: PregelNode Implementation Structure\nDESCRIPTION: Definition of the PregelNode class that represents the operational node in the execution engine. Manages state access, triggers, and execution of the bound function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass PregelNode(Runnable):\n    channels: Union[list[str], Mapping[str, str]] # State keys to read as input\n    triggers: list[str]                          # Channel updates that activate this node\n    mapper: Optional[Callable[[Any], Any]]       # Function to format input state\n    writers: list[Runnable]                      # Runnables to write output back to Channels\n    bound: Runnable[Any, Any]                    # << THE ACTUAL FUNCTION/RUNNABLE YOU PROVIDED >>\n    # ... other attributes like retry policy, tags, etc. ...\n\n    def __init__(self, *, channels, triggers, writers, bound, ...) -> None:\n        self.channels = channels\n        self.triggers = list(triggers)\n        self.writers = writers or []\n        self.bound = bound # Your code lives here!\n        # ... initialize other attributes ...\n```\n\n----------------------------------------\n\nTITLE: Defining a Function with List[int] Input in Python\nDESCRIPTION: Demonstrates a function that expects a list of positive integer user IDs, highlighting the need for validation of raw input data.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Our expected data structure: a list of positive integers\n# Example: [101, 205, 300]\n\n# Incoming data might be messy:\nraw_data_ok = '[101, \"205\", 300]' # Comes as JSON string, contains string number\nraw_data_bad = '[101, -5, \"abc\"]' # Contains negative number and non-number string\n\ndef process_user_ids(user_ids: list[int]):\n    # How do we easily validate 'raw_data' conforms to list[int]\n    # AND ensure all IDs are positive *before* this function runs?\n    # And how do we handle the string \"205\"?\n    for user_id in user_ids:\n        print(f\"Processing user ID: {user_id}\")\n        # We assume user_ids is already clean list[int] here\n```\n\n----------------------------------------\n\nTITLE: Sending Tasks in Celery (Python)\nDESCRIPTION: This snippet demonstrates how Celery sends tasks to the broker. It handles task options, generates task IDs, creates messages, and uses the app's producer pool to send the task to the broker.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef send_task(self, name, args=None, kwargs=None, task_id=None,\n              producer=None, connection=None, router=None, **options):\n    # ... lots of logic to prepare options, task_id, routing ...\n\n    # Get the routing info (exchange, routing_key, queue)\n    # Uses app.conf for defaults if not specified\n    options = self.amqp.router.route(options, name, args, kwargs)\n\n    # Create the message body\n    message = self.amqp.create_task_message(\n        task_id or uuid(), # Generate task ID if needed\n        name, args, kwargs, # Task details\n        # ... other arguments like countdown, eta, expires ...\n    )\n\n    # Get a producer (handles connection/channel to broker)\n    # Uses the app's producer pool (app.producer_pool)\n    with self.producer_or_acquire(producer) as P:\n        # Tell the backend we're about to send (if tracking results)\n        if not options.get('ignore_result', False):\n             self.backend.on_task_call(P, task_id)\n\n        # Actually send the message via the producer\n        self.amqp.send_task_message(P, name, message, **options)\n\n    # Create the AsyncResult object to return to the caller\n    result = self.AsyncResult(task_id)\n    # ... set result properties ...\n    return result\n```\n\n----------------------------------------\n\nTITLE: Extracting structured data using JsonCssExtractionStrategy in Crawl4AI\nDESCRIPTION: This code demonstrates how to extract specific data (page title and main heading) from a webpage using the CSS selector-based extraction strategy. The example defines a schema mapping field names to CSS selectors, creates an extraction strategy instance, configures the crawler, and processes the extraction results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/06_extractionstrategy.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter6_example_1.py\nimport asyncio\nimport json\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    JsonCssExtractionStrategy # Import the CSS strategy\n)\n\nasync def main():\n    # 1. Define the extraction schema (Field Name -> CSS Selector)\n    extraction_schema = {\n        \"baseSelector\": \"body\", # Operate within the body tag\n        \"fields\": [\n            {\"name\": \"page_title\", \"selector\": \"title\", \"type\": \"text\"},\n            {\"name\": \"main_heading\", \"selector\": \"h1\", \"type\": \"text\"}\n        ]\n    }\n    print(\"Extraction Schema defined using CSS selectors.\")\n\n    # 2. Create an instance of the strategy with the schema\n    css_extractor = JsonCssExtractionStrategy(schema=extraction_schema)\n    print(f\"Using strategy: {css_extractor.__class__.__name__}\")\n\n    # 3. Create CrawlerRunConfig and set the extraction_strategy\n    run_config = CrawlerRunConfig(\n        extraction_strategy=css_extractor\n    )\n\n    # 4. Run the crawl\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n        print(f\"\\nCrawling {url_to_crawl} to extract structured data...\")\n\n        result = await crawler.arun(url=url_to_crawl, config=run_config)\n\n        if result.success and result.extracted_content:\n            print(\"\\nExtraction successful!\")\n            # The extracted data is stored as a JSON string in result.extracted_content\n            # Parse the JSON string to work with the data as a Python object\n            extracted_data = json.loads(result.extracted_content)\n            print(\"Extracted Data:\")\n            # Print the extracted data nicely formatted\n            print(json.dumps(extracted_data, indent=2))\n        elif result.success:\n            print(\"\\nCrawl successful, but no structured data extracted.\")\n        else:\n            print(f\"\\nCrawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Handling Validation Errors in Pydantic\nDESCRIPTION: Example showing how Pydantic handles invalid data by raising ValidationError. This demonstrates Pydantic's error reporting when data doesn't match the model definition.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ValidationError\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n# Input data with age as a string that isn't a number\ninvalid_data = {'name': 'Bob', 'age': 'twenty-eight'}\n\ntry:\n    user_bob = User(**invalid_data)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    Expected Output (simplified):\n    1 validation error for User\n    age\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='twenty-eight', input_type=str]\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Crafting Custom HTTP Responses with Headers and Cookies in Flask - Python\nDESCRIPTION: This snippet demonstrates explicit creation and customization of a Flask HTTP response using the make_response helper. It shows how to set custom HTTP headers, cookies, and specific status codes on the response object. Required dependencies are Flask and its make_response method. Key parameters include the response body, a custom header, and a cookie; output is a fully configured Response object sent to the client.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\nfrom flask import Flask, make_response # Import make_response\n\napp = Flask(__name__)\n\n@app.route('/custom')\ndef custom_response():\n  # Create a response object from a string\n  response = make_response(\"This response has custom headers!\")\n\n  # Set a custom header\n  response.headers['X-My-Custom-Header'] = 'Flask is Fun!'\n\n  # Set a cookie (we'll learn more about sessions/cookies later)\n  response.set_cookie('mycookie', 'some_value')\n\n  # Set a specific status code (optional, defaults to 200)\n  response.status_code = 201 # 201 means \"Created\"\n\n  return response # Return the fully configured response object\n\n# ... (rest of the app)\n```\n\n----------------------------------------\n\nTITLE: Simplified Task Class Definition in Python\nDESCRIPTION: This code snippet shows a simplified version of the Task class definition from the CrewAI library. It demonstrates the basic structure and key attributes of a Task object using Pydantic for data validation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/03_task.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from crewai/task.py\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Type, Any\n```\n\n----------------------------------------\n\nTITLE: Defining Routes with APIRouter in FastAPI (Python)\nDESCRIPTION: This snippet demonstrates using `APIRouter` to group related API endpoints. It creates a router instance and defines two GET routes (`/items/` and `/items/{item_id}`) using `@router.get`. This approach helps organize routes in larger applications by separating them into modules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# routers/items.py\nfrom fastapi import APIRouter\n\n# Create an APIRouter instance\n# This is like a mini-FastAPI app for item-related routes\nrouter = APIRouter()\n\n# Define a route on the router, not the main app\n@router.get(\"/items/\")\nasync def read_items():\n  # A simple example returning a list of items\n  return [{\"name\": \"Item Foo\"}, {\"name\": \"Item Bar\"}]\n\n@router.get(\"/items/{item_id}\")\nasync def read_item(item_id: str):\n  # We'll learn about path parameters like {item_id} later!\n  # See [Path Operations & Parameter Declaration](02_path_operations___parameter_declaration.md)\n  return {\"item_id\": item_id, \"name\": f\"Item {item_id}\"}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing the Simplified dspy.Predict Module in Python\nDESCRIPTION: This Python code defines a simplified `Predict` class inheriting from `dspy.Module`. It initializes with a `Signature` and optional `config`. The `forward` method orchestrates the process of generating a prediction: it formats a prompt using the signature, input arguments, and optional demos; calls a configured Language Model (LM); parses the LM's response according to the signature's output fields; and returns the results encapsulated in a `Prediction` object. Dependencies include various `dspy` primitives (`Module`, `Prediction`, `ensure_signature`, `settings`) and a configured LM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/04_predict.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Simplified view from dspy/predict/predict.py\n\nfrom dspy.primitives.program import Module\nfrom dspy.primitives.prediction import Prediction\nfrom dspy.signatures.signature import ensure_signature\nfrom dspy.dsp.utils import settings # To get the configured LM\n\nclass Predict(Module):\n    def __init__(self, signature, **config):\n        super().__init__()\n        # Store the signature and any extra configuration\n        self.signature = ensure_signature(signature)\n        self.config = config\n        # Other initializations (demos, etc.)\n        self.demos = []\n        self.lm = None # LM will be set later or taken from settings\n\n    def forward(self, **kwargs):\n        # Get signature, demos, and LM (either passed in or from settings)\n        signature = self.signature # Use the stored signature\n        demos = kwargs.pop(\"demos\", self.demos) # Get demos if provided\n        lm = kwargs.pop(\"lm\", self.lm) or settings.lm # Find the LM to use\n\n        # Prepare inputs for the LM call\n        inputs = kwargs # Remaining kwargs are the inputs\n\n        # --- This is where the magic happens ---\n        # 1. Format the prompt using signature, demos, inputs\n        #    (Simplified - actual formatting is more complex)\n        prompt = format_prompt(signature, demos, inputs)\n\n        # 2. Call the Language Model\n        #    (Simplified - handles retries, multiple generations etc.)\n        lm_output_text = lm(prompt, **self.config)\n\n        # 3. Parse the LM's output text based on the signature's output fields\n        #    (Simplified - extracts fields like 'french_sentence')\n        parsed_output = parse_output(signature, lm_output_text)\n        # --- End Magic ---\n\n        # 4. Create and return a Prediction object\n        prediction = Prediction(signature=signature, **parsed_output)\n        # (Optionally trace the call)\n        # settings.trace.append(...)\n\n        return prediction\n\n# (Helper functions format_prompt and parse_output would exist elsewhere)\n```\n```\n\n----------------------------------------\n\nTITLE: Visualizing Flask Request Routing Sequence\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of an incoming HTTP request (GET /user/Alice) within a Flask application. It shows the interaction between the browser, the Flask application's WSGI entry point (`app.wsgi_app`), the Werkzeug URL map matching mechanism (`url_map.bind(...).match()`), and the target view function (`show_user_profile()`), demonstrating how a request is matched to a route, variables are extracted, and the appropriate handler is called.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/02_routing_system.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Browser\n    participant FlaskApp as app.wsgi_app\n    participant URLMap as url_map.bind(...).match()\n    participant ViewFunc as show_user_profile()\n\n    Browser->>+FlaskApp: GET /user/Alice\n    FlaskApp->>+URLMap: Match path '/user/Alice' and method 'GET'?\n    URLMap-->>-FlaskApp: Match found! Endpoint='show_user_profile', Args={'username': 'Alice'}\n    FlaskApp->>+ViewFunc: Call show_user_profile(username='Alice')\n    ViewFunc-->>-FlaskApp: Return 'Hello, Alice!'\n    FlaskApp-->>-Browser: Send response 'Hello, Alice!'\n```\n\n----------------------------------------\n\nTITLE: Rendering Jinja2 Templates in Python\nDESCRIPTION: This Python helper function, `populate_template`, takes a Jinja2 template string and a dictionary of variables. It uses the `jinja2` library (`Template`, `StrictUndefined`) to compile and render the template, replacing placeholders (like `{{ variable }}`) with the corresponding values from the `variables` dictionary. It includes basic error handling for the rendering process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/05_prompttemplates.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom jinja2 import Template, StrictUndefined\n\ndef populate_template(template: str, variables: dict) -> str:\n    \"\"\"Renders a Jinja2 template string with given variables.\"\"\"\n    compiled_template = Template(template, undefined=StrictUndefined)\n    try:\n        # This does the magic of replacing {{ placeholder }} with actual values\n        return compiled_template.render(**variables)\n    except Exception as e:\n        raise Exception(f\"Error rendering Jinja template: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Tasks in Python\nDESCRIPTION: This snippet shows how to define Celery tasks, including a simple addition task and a report sending task. It demonstrates task decoration and basic task structure.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# tasks.py (add this new task)\nfrom celery_app import app\nimport time\n\n@app.task\ndef add(x, y):\n    \"\"\"A simple task that adds two numbers.\"\"\"\n    print(f\"Task 'add' starting with ({x}, {y})\")\n    time.sleep(2) # Simulate short work\n    result = x + y\n    print(f\"Task 'add' finished with result: {result}\")\n    return result\n\n@app.task\ndef send_report(name):\n    \"\"\"A task simulating sending a report.\"\"\"\n    print(f\"Task 'send_report' starting for report: {name}\")\n    time.sleep(5) # Simulate longer work\n    print(f\"Report '{name}' supposedly sent.\")\n    return f\"Report {name} sent.\"\n```\n\n----------------------------------------\n\nTITLE: Creating and Using BrowserContext in Python\nDESCRIPTION: This example demonstrates how to set up a Browser instance, create a BrowserContext (isolated browser session), navigate to a webpage, and retrieve information from the current state. It uses asynchronous Python code with proper resource management using 'async with'.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/03_browsercontext.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n# Import necessary classes\nfrom browser_use import Browser, BrowserConfig, BrowserContext, BrowserContextConfig\n\nasync def main():\n    # 1. Configure the main browser application (optional, defaults are usually fine)\n    browser_config = BrowserConfig(headless=False) # Show the browser window\n\n    # 2. Create the main Browser instance\n    # This might launch a browser application in the background (or connect to one)\n    browser = Browser(config=browser_config)\n    print(\"Browser application instance created.\")\n\n    # 3. Configure the specific session/window (optional)\n    context_config = BrowserContextConfig(\n        user_agent=\"MyCoolAgent/1.0\", # Example: Set a custom user agent\n        cookies_file=\"my_session_cookies.json\" # Example: Save/load cookies\n    )\n\n    # 4. Create the isolated BrowserContext (like opening an incognito window)\n    # We use 'async with' to ensure it cleans up automatically afterwards\n    async with browser.new_context(config=context_config) as browser_context:\n        print(f\"BrowserContext created (ID: {browser_context.context_id}).\")\n\n        # 5. Use the context to interact with the browser session\n        start_url = \"https://example.com\"\n        print(f\"Navigating to: {start_url}\")\n        await browser_context.navigate_to(start_url)\n\n        # 6. Get information *from* the context\n        current_state = await browser_context.get_state() # Get current page info\n        print(f\"Current page title: {current_state.title}\")\n        print(f\"Current page URL: {current_state.url}\")\n\n        # The Agent would use this 'browser_context' object to see the page\n        # and tell the Controller to perform actions within it.\n\n    print(\"BrowserContext closed automatically.\")\n\n    # 7. Close the main browser application when done\n    await browser.close()\n    print(\"Browser application closed.\")\n\n# Run the asynchronous code\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Globally Setting the Configured LM in DSPy\nDESCRIPTION: Shows how to apply the created LM client instance (`turbo` in this case) globally within DSPy using `dspy.settings.configure`. Once configured, all subsequent calls from DSPy modules requiring an LM will use this specified client.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndspy.settings.configure(lm=turbo)\n```\n\n----------------------------------------\n\nTITLE: Implementing LevelDB Compaction Scheduling in C++\nDESCRIPTION: Core implementation of LevelDB's compaction scheduling logic, showing how the database determines when to trigger background compaction tasks. The code demonstrates the conditions checked before scheduling compaction and the version management system's role in determining compaction necessity.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/08_compaction.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\nvoid DBImpl::MaybeScheduleCompaction() {\n  mutex_.AssertHeld(); // Must hold lock to check/change state\n\n  if (background_compaction_scheduled_) {\n    // Already scheduled\n  } else if (shutting_down_.load(std::memory_order_acquire)) {\n    // DB is closing\n  } else if (!bg_error_.ok()) {\n    // Background error stopped activity\n  } else if (imm_ == nullptr && // No MemTable flush needed AND\n             manual_compaction_ == nullptr && // No manual request AND\n             !versions_->NeedsCompaction()) { // <<-- VersionSet check!\n    // No work to be done: VersionSet says size/seek limits are okay.\n  } else {\n    // Work needs to be done! Schedule it.\n    background_compaction_scheduled_ = true;\n    env_->Schedule(&DBImpl::BGWork, this); // Ask Env to run BGWork later\n  }\n}\n```\n\nLANGUAGE: c++\nCODE:\n```\nbool NeedsCompaction() const {\n  Version* v = current_;\n  // Check score (size trigger) OR if a file needs compaction due to seeks\n  return (v->compaction_score_ >= 1) || (v->file_to_compact_ != nullptr);\n}\n```\n\n----------------------------------------\n\nTITLE: Using `session` Global for Cross-Request User Data Storage\nDESCRIPTION: Shows how to use the `session` context global to store and retrieve user-specific data across multiple requests. This example implements a simple page view counter: it gets the current count from the session (defaulting to 0), increments it, stores the new value back in the session, logs the session data, and displays the count. Requires `SECRET_KEY` to be set on the app config for secure session cookie signing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n@app.route('/counter')\ndef counter():\n  # Get the current count from the session, default to 0 if not found\n  count = session.get('view_count', 0)\n\n  # Increment the count\n  count += 1\n\n  # Store the new count back in the session\n  session['view_count'] = count\n\n  # Log the session content (for demonstration)\n  current_app.logger.info(f\"Session data: {session}\")\n\n  return f'You have visited this page {count} times during this session.'\n```\n\n----------------------------------------\n\nTITLE: Rendering Prompt Sequence Diagram (Mermaid)\nDESCRIPTION: A sequence diagram illustrating the process of rendering a prompt named 'summarize_text' when a client sends a getPrompt request to the FastMCP server.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastMCP_Server as FastMCP (server.py)\n    participant PromptMgr as PromptManager (_prompt_manager)\n    participant SummaryPrompt as Prompt (wraps create_summary_prompt)\n    participant PromptFunc as create_summary_prompt()\n\n    Client->>+FastMCP_Server: Send MCP Request: getPrompt(name=\"summarize_text\", args={\"text\": \"...\"})\n    FastMCP_Server->>+PromptMgr: render_prompt(name=\"summarize_text\", args={...})\n    PromptMgr->>PromptMgr: Find Prompt object for \"summarize_text\"\n    PromptMgr->>+SummaryPrompt: prompt.render(arguments={...})\n    SummaryPrompt->>+PromptFunc: Call create_summary_prompt(text_to_summarize=\"...\")\n    PromptFunc-->>-SummaryPrompt: Return [UserMessage(content=\"Summarize: ...\")]\n    SummaryPrompt->>SummaryPrompt: Validate & format message list\n    SummaryPrompt-->>-PromptMgr: Return validated [UserMessage(...)]\n    PromptMgr-->>-FastMCP_Server: Return [UserMessage(...)]\n    FastMCP_Server->>-Client: Send MCP Response: result={messages: [{...}]}\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Tasks in Python\nDESCRIPTION: This snippet demonstrates how to define Celery tasks using the @app.task decorator. It includes two example tasks: one for adding numbers and another for simulating sending a welcome email.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/03_task.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# tasks.py\nimport time\nfrom celery_app import app # Import the app instance we created\n\n@app.task\ndef add(x, y):\n    \"\"\"A simple task that adds two numbers.\"\"\"\n    print(f\"Task 'add' starting with ({x}, {y})\")\n    # Simulate some work taking time\n    time.sleep(5)\n    result = x + y\n    print(f\"Task 'add' finished with result: {result}\")\n    return result\n\n@app.task\ndef send_welcome_email(user_id):\n    \"\"\"A task simulating sending a welcome email.\"\"\"\n    print(f\"Task 'send_welcome_email' starting for user {user_id}\")\n    # Simulate email sending process\n    time.sleep(3)\n    print(f\"Welcome email supposedly sent to user {user_id}\")\n    return f\"Email sent to {user_id}\"\n\n# You can have many tasks in one file!\n```\n\n----------------------------------------\n\nTITLE: Creating NumPy Arrays from Python Lists\nDESCRIPTION: This snippet demonstrates how to create NumPy arrays from Python lists using the np.array() function. It shows examples of creating both 1-dimensional (vector) and 2-dimensional (matrix) arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Implementing Write Operations in LevelDB DBImpl\nDESCRIPTION: Core implementation of the Write method in DBImpl that handles write operations by coordinating WAL writes and MemTable updates. Includes error handling and ensures proper sequencing of operations for data consistency.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\nStatus DBImpl::Write(const WriteOptions& options, WriteBatch* updates) {\n  // ... acquire mutex, manage writer queue (omitted) ...\n\n  // Step 4: Make sure there's space. This might trigger a MemTable switch\n  // and schedule background work. May wait if MemTable is full or\n  // too many L0 files exist.\n  Status status = MakeRoomForWrite(updates == nullptr /* force compact? */);\n\n  if (status.ok() && updates != nullptr) {\n    // ... potentially group multiple concurrent writes (BuildBatchGroup) ...\n\n    // Step 5: Add the batch to the Write-Ahead Log\n    status = log_->AddRecord(WriteBatchInternal::Contents(updates));\n    if (status.ok() && options.sync) {\n      // Ensure log entry is on disk if requested\n      status = logfile_->Sync();\n      // ... handle sync error by recording background error ...\n    }\n\n    // Step 6: Insert the batch into the active MemTable (only if WAL ok)\n    if (status.ok()) {\n      status = WriteBatchInternal::InsertInto(updates, mem_);\n    }\n  }\n\n  // ... update sequence number, manage writer queue, release mutex ...\n  return status; // Step 7: Return status to caller\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing BaseAgent Class in Python\nDESCRIPTION: This code snippet defines the BaseAgent class, which inherits from Pydantic's BaseModel and ABC (Abstract Base Class). It includes core attributes, a run method for executing the agent's main loop, and an abstract step method to be implemented by subclasses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/03_baseagent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom abc import ABC, abstractmethod\nfrom pydantic import BaseModel, Field\nfrom app.llm import LLM\nfrom app.schema import AgentState, Memory, Message\n\nclass BaseAgent(BaseModel, ABC):\n    \"\"\"Abstract base class for managing agent state and execution.\"\"\"\n\n    name: str = Field(..., description=\"Unique name\")\n    description: Optional[str] = Field(None)\n    state: AgentState = Field(default=AgentState.IDLE)\n    memory: Memory = Field(default_factory=Memory)\n    llm: LLM = Field(default_factory=LLM)\n    max_steps: int = Field(default=10)\n    current_step: int = Field(default=0)\n\n    async def run(self, request: Optional[str] = None) -> str:\n        \"\"\"Execute the agent's main loop asynchronously.\"\"\"\n        if self.state != AgentState.IDLE:\n            raise RuntimeError(\"Agent not IDLE\")\n\n        if request:\n            self.update_memory(\"user\", request)\n\n        results = []\n        self.state = AgentState.RUNNING\n        try:\n            while (self.current_step < self.max_steps and self.state == AgentState.RUNNING):\n                self.current_step += 1\n                step_result = await self.step()\n                results.append(f\"Step {self.current_step}: {step_result}\")\n        finally:\n            if self.state != AgentState.ERROR:\n                self.state = AgentState.IDLE\n\n        return \"\\n\".join(results)\n\n    @abstractmethod\n    async def step(self) -> str:\n        \"\"\"Execute a single step in the agent's workflow. Must be implemented by subclasses.\"\"\"\n        pass\n\n    def update_memory(self, role: str, content: str, ...) -> None:\n        \"\"\"Helper to add messages to self.memory easily.\"\"\"\n        self.memory.add_message(...)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Jinja2 HTML Template\nDESCRIPTION: This snippet shows a basic HTML file (`hello.html`) intended for use as a Jinja2 template within a Flask application. It includes standard HTML structure and a Jinja2 expression `{{ name_in_template }}` which acts as a placeholder to be replaced by data passed from the Flask application during rendering.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<!-- templates/hello.html -->\n{% raw %}\n<!doctype html>\n<html>\n  <head>\n    <title>Hello Flask!</title>\n  </head>\n  <body>\n    <h1>Hello, {{ name_in_template }}!</h1>\n    <p>Welcome to our templated page.</p>\n  </body>\n</html>\n{% endraw %}\n```\n\n----------------------------------------\n\nTITLE: Creating a Celery App Instance in Python\nDESCRIPTION: Demonstrates how to create a Celery app instance with Redis as both the broker and backend. This sets up the core configuration for task distribution and result storage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\n\n# Create a Celery app instance\n# 'tasks' is just a name for this app instance, often the module name.\n# 'broker' tells Celery where to send task messages.\n# We'll use Redis here for simplicity (you need Redis running).\napp = Celery('tasks',\n             broker='redis://localhost:6379/0',\n             backend='redis://localhost:6379/0') # Added backend for results\n\nprint(f\"Celery app created: {app}\")\n```\n\n----------------------------------------\n\nTITLE: Explicitly Specifying Data Types in NumPy Arrays\nDESCRIPTION: This snippet shows how to explicitly specify the data type when creating NumPy arrays using both type objects (np.int32, np.float32) and string codes ('float64'). It also demonstrates how to check the memory usage of different data types using the itemsize attribute.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/02_dtype__data_type_object_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Create an array, specifying 32-bit integers\narr_i32 = np.array([1, 2, 3], dtype=np.int32)\nprint(f\"Array: {arr_i32}\")\nprint(f\"Data type: {arr_i32.dtype}\")\nprint(f\"Bytes per element: {arr_i32.itemsize}\") # itemsize shows bytes\n\n# Create an array, specifying 32-bit floats\narr_f32 = np.array([1, 2, 3], dtype=np.float32)\nprint(f\"\\nArray: {arr_f32}\") # Notice the decimal points now!\nprint(f\"Data type: {arr_f32.dtype}\")\nprint(f\"Bytes per element: {arr_f32.itemsize}\")\n\n# Create an array using string codes for dtype\narr_f64_str = np.array([4, 5, 6], dtype='float64') # Equivalent to np.float64\nprint(f\"\\nArray: {arr_f64_str}\")\nprint(f\"Data type: {arr_f64_str.dtype}\")\nprint(f\"Bytes per element: {arr_f64_str.itemsize}\")\n```\n\n----------------------------------------\n\nTITLE: FastAPI Dependency Resolution Sequence Diagram\nDESCRIPTION: A sequence diagram showing the complete flow of a request through FastAPI's dependency injection system, from initial client request to final response, including all dependency resolution steps and caching.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastAPIApp as FastAPI App\n    participant DepSolver as Dependency Solver\n    participant GetItemFunc as get_item_from_db\n    participant GetDBFunc as get_db_session\n    participant PathOpFunc as read_db_item\n\n    Client->>+FastAPIApp: GET /db_items/2\n    FastAPIApp->>+DepSolver: Solve dependencies for read_db_item(item_id, Depends(get_item_from_db))\n    DepSolver->>DepSolver: Need path param 'item_id' (value=2)\n    DepSolver->>DepSolver: Need result of get_item_from_db\n    DepSolver->>+DepSolver: Solve dependencies for get_item_from_db(item_id, Depends(get_db_session))\n    DepSolver->>DepSolver: Need 'item_id' (value=2, from path)\n    DepSolver->>DepSolver: Need result of get_db_session\n    DepSolver->>DepSolver: Check cache for get_db_session: Miss\n    DepSolver->>+GetDBFunc: Call get_db_session()\n    GetDBFunc-->>-DepSolver: Return \"fake_db_session_123\"\n    DepSolver->>DepSolver: Cache: get_db_session -> \"fake_db_session_123\"\n    DepSolver-->>-DepSolver: Dependencies for get_item_from_db ready\n    DepSolver->>+GetItemFunc: Call get_item_from_db(item_id=2, db=\"fake_db_session_123\")\n    GetItemFunc-->>-DepSolver: Return \"Item Two\"\n    DepSolver->>DepSolver: Cache: get_item_from_db -> \"Item Two\"\n    DepSolver-->>-FastAPIApp: Dependencies for read_db_item ready\n    FastAPIApp->>+PathOpFunc: Call read_db_item(item_id=2, item_name=\"Item Two\")\n    PathOpFunc-->>-FastAPIApp: Return {\"item_id\": 2, \"name_from_db\": \"Item Two\"}\n    FastAPIApp-->>-Client: Send JSON Response\n```\n\n----------------------------------------\n\nTITLE: Initializing MultiStepAgent Components in Python\nDESCRIPTION: Simplified `__init__` method for the `MultiStepAgent` class in `agents.py`. It demonstrates how the agent stores essential dependencies like a list of tools (converted to a dictionary keyed by name), the language model function (`Callable`), and the maximum allowed steps (`max_steps`). It also initializes the agent's memory (`AgentMemory`) and ensures the presence of a default `FinalAnswerTool`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified __init__) ---\nclass MultiStepAgent:\n    def __init__(\n        self,\n        tools: List[Tool], # List of available tools\n        model: Callable,    # The language model function\n        max_steps: int = 20, # Max cycles allowed\n        # ... other parameters like memory, prompts, etc.\n    ):\n        self.model = model\n        self.tools = {tool.name: tool for tool in tools}\n        # Add the essential final_answer tool\n        self.tools.setdefault(\"final_answer\", FinalAnswerTool())\n        self.max_steps = max_steps\n        self.memory = AgentMemory(...) # Initialize memory\n        # ... setup logging, etc.\n```\n\n----------------------------------------\n\nTITLE: Implementing ListMemory in Python\nDESCRIPTION: A concrete implementation of the Memory protocol that stores items in a simple list. It demonstrates how memory content is stored, retrieved, and injected into chat context as a formatted system message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# From: memory/_list_memory.py (Simplified)\nfrom typing import List\n# ... other imports: Memory, MemoryContent, ..., SystemMessage, ChatCompletionContext\n\nclass ListMemory(Memory):\n    def __init__(self, ..., memory_contents: List[MemoryContent] | None = None):\n        # Stores memory items in a simple list\n        self._contents: List[MemoryContent] = memory_contents or []\n\n    async def add(self, content: MemoryContent, ...) -> None:\n        \"\"\"Add new content to the internal list.\"\"\"\n        self._contents.append(content)\n\n    async def query(self, query: str | MemoryContent = \"\", ...) -> MemoryQueryResult:\n        \"\"\"Return all memories, ignoring the query.\"\"\"\n        # Simple implementation: just return everything\n        return MemoryQueryResult(results=self._contents)\n\n    async def update_context(self, model_context: ChatCompletionContext) -> UpdateContextResult:\n        \"\"\"Add all memories as a SystemMessage to the chat context.\"\"\"\n        if not self._contents: # Do nothing if memory is empty\n            return UpdateContextResult(memories=MemoryQueryResult(results=[]))\n\n        # Format all memories into a numbered list string\n        memory_strings = [f\"{i}. {str(mem.content)}\" for i, mem in enumerate(self._contents, 1)]\n        memory_context_str = \"Relevant memory content...\\n\" + \"\\n\".join(memory_strings) + \"\\n\"\n\n        # Add this string as a SystemMessage to the provided chat context\n        await model_context.add_message(SystemMessage(content=memory_context_str))\n\n        # Return info about which memories were added\n        return UpdateContextResult(memories=MemoryQueryResult(results=self._contents))\n\n    # ... clear(), close(), config methods ...\n```\n\n----------------------------------------\n\nTITLE: Defining Action Parameter Models for Browser Automation in Python\nDESCRIPTION: This snippet defines Pydantic models for various browser actions, including clicking elements, inputting text, and task completion. These models ensure proper parameter validation for each action.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/05_action_controller___registry.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import Optional\n\n# Example parameter model for the 'click_element' action\nclass ClickElementAction(BaseModel):\n    index: int              # The highlight_index of the element to click\n    xpath: Optional[str] = None # Optional hint (usually index is enough)\n\n# Example parameter model for the 'input_text' action\nclass InputTextAction(BaseModel):\n    index: int              # The highlight_index of the input field\n    text: str               # The text to type\n    xpath: Optional[str] = None # Optional hint\n\n# Example parameter model for the 'done' action (task completion)\nclass DoneAction(BaseModel):\n    text: str               # A final message or result\n    success: bool           # Was the overall task successful?\n\n# ... other action models like GoToUrlAction, ScrollAction etc. ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Pydantic Core Components and Relationships with Mermaid\nDESCRIPTION: This Mermaid flowchart illustrates the key components of Pydantic Core and their relationships. It shows how BaseModel interacts with Fields, Configuration, and Custom Logic, and how these elements feed into the Core Schema for validation and serialization. The chart also includes TypeAdapter and its relationship to the core engine.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"BaseModel\"]\n    A1[\"Fields (FieldInfo / Field function)\"]\n    A2[\"Core Schema & Validation/Serialization\"]\n    A3[\"Configuration (ConfigDict / ConfigWrapper)\"]\n    A4[\"Custom Logic (Decorators & Annotated Helpers)\"]\n    A5[\"TypeAdapter\"]\n    A0 -- \"Contains and defines\" --> A1\n    A0 -- \"Is configured by\" --> A3\n    A0 -- \"Applies custom logic via\" --> A4\n    A1 -- \"Is converted into\" --> A2\n    A3 -- \"Configures core engine for\" --> A2\n    A4 -- \"Modifies validation/seriali...\" --> A2\n    A5 -- \"Uses core engine for\" --> A2\n    A5 -- \"Can be configured by\" --> A3\n```\n\n----------------------------------------\n\nTITLE: Defining a Mesop Chat Conversation Component - Python\nDESCRIPTION: This Python snippet implements a Mesop UI component to render a chat interface. It accesses global and local state to load messages, renders either form components or chat bubbles depending on the message type, and provides an input area for user messages. When Enter is pressed, a background task indicator is shown and the user's message is sent to the backend via the send_message coroutine. Requires the Mesop framework, and definitions for PageState, AppState, is_form, render_form, and send_message. Inputs are user messages; outputs are UI updates and background requests.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/components/conversation.py (Simplified Snippet)\n# ... imports ...\n\n@me.component\ndef conversation():\n    \"\"\"Conversation component\"\"\"\n    page_state = me.state(PageState) # Local page state\n    app_state = me.state(AppState)   # Global application state\n\n    # ... loop to display existing messages using chat_bubble component ...\n    for message in app_state.messages:\n        if is_form(message):\n          render_form(message, app_state) # Special handling for forms\n        # ... other message types ...\n        else:\n          chat_bubble(message, message.message_id) # Display regular chat message\n\n    # --- Input area ---\n    with me.box(style=me.Style(display=\"flex\", flex_direction=\"row\", ...)):\n        me.input(\n            label=\"How can I help you?\",\n            on_enter=send_message_enter, # Function to call when user presses Enter\n            # ... other attributes ...\n        )\n        with me.content_button(on_click=send_message_button): # Button handler\n            me.icon(icon=\"send\")\n\nasync def send_message_enter(e: me.InputEnterEvent):\n    # ... (get state) ...\n    message_content = e.value\n    message_id = str(uuid.uuid4())\n    # Store something to indicate a background task is running\n    app_state = me.state(AppState)\n    app_state.background_tasks[message_id] = \"Processing...\"\n    yield # Update UI to show indicator\n    # Call the backend service to actually send the message\n    await send_message(message_content, message_id)\n    yield # Allow UI to potentially update again\n```\n\n----------------------------------------\n\nTITLE: Running the Main Async Application Entry Point in Python\nDESCRIPTION: This Python snippet executes the primary asynchronous `main()` function using `asyncio.run()`. It acts as the main entry point to start the agent runtime application, initiating the setup, registration of agents/subscriptions, message processing, and eventual shutdown described in the surrounding text. It requires the `asyncio` library and a defined `main` asynchronous function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Run the main function\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Keyword-Based Content Filtering with BM25 in Python\nDESCRIPTION: This example implements a BM25-based content filter as a subclass of `RelevantContentFilter`, showcasing how to compute relevance scores for HTML fragments against a user query. The `BM25ContentFilter` initializes with threshold and leverages BM25Okapi for ranking. The `filter_content` method describes parsing HTML, extracting candidate fragments, calculating BM25 scores, and filtering by a configurable threshold. The snippet illustrates the overall workflow with placeholder logic and emphasizes dependencies on BeautifulSoup and BM25Okapi. Inputs include cleaned HTML and a user query; outputs are lists of relevant HTML fragments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nclass BM25ContentFilter(RelevantContentFilter):\\n    def __init__(self, user_query: str = None, bm25_threshold: float = 1.0, ...):\\n        super().__init__(user_query)\\n        self.bm25_threshold = bm25_threshold\\n        # ... BM25 specific setup ...\\n\\n    def filter_content(self, html: str) -> List[str]:\\n        # 1. Parse HTML (e.g., with BeautifulSoup)\\n        # 2. Extract text chunks (candidates)\\n        # 3. Determine query (user_query or extracted)\\n        # 4. Tokenize query and chunks\\n        # 5. Calculate BM25 scores for chunks vs query\\n        # 6. Filter chunks based on score and threshold\\n        # 7. Return the HTML string of the selected chunks\\n        # ... implementation details ...\\n        relevant_html_fragments = [\\\"<p>Relevant paragraph 1...</p>\\\", \\\"<h2>Relevant Section</h2>...\\\"] # Placeholder\\n        return relevant_html_fragments\n```\n\n----------------------------------------\n\nTITLE: Generating Dynamic URLs in Flask Navigation Template\nDESCRIPTION: HTML template demonstrating how to use url_for to generate dynamic URLs in Flask navigation menu, including conditional rendering based on user login status.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_6\n\nLANGUAGE: html\nCODE:\n```\n<!-- templates/navigation.html -->\n<nav>\n  <ul>\n    <li><a href=\"{{ url_for('index') }}\">Home</a></li>\n    <li><a href=\"{{ url_for('show_items') }}\">Items</a></li>\n    <li><a href=\"{{ url_for('greet_user', username='Admin') }}\">Admin Profile</a></li>\n    <!-- Example link that might require login -->\n    {% if user and user.is_logged_in %}\n      <li><a href=\"{{ url_for('profile') }}\">My Profile</a></li>\n    {% else %}\n      <li><a href=\"#\">Login</a></li> {# Replace # with login URL later #}\n    {% endif %}\n  </ul>\n</nav>\n```\n\n----------------------------------------\n\nTITLE: Using AsyncWebCrawler with Default Settings\nDESCRIPTION: A basic example showing how to use AsyncWebCrawler with default configuration settings to crawl a URL and check if the operation was successful.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter3_example_1.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n        print(f\"Crawling {url_to_crawl} with default settings...\")\n\n        # This uses the default behavior (no specific config)\n        result = await crawler.arun(url=url_to_crawl)\n\n        if result.success:\n            print(\"Success! Got the content.\")\n            print(f\"Screenshot taken? {'Yes' if result.screenshot else 'No'}\") # Likely No\n            # We'll learn about CacheMode later, but it defaults to using the cache\n        else:\n            print(f\"Failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining LLMMessage Types for Communication with LLMs\nDESCRIPTION: Pydantic model definitions for different message types (System, User, Assistant) that can be sent to LLMs. These standardized message structures include content that may contain text, images, or function calls.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# From: models/_types.py (Simplified)\nfrom pydantic import BaseModel\nfrom typing import List, Union, Literal\nfrom .. import FunctionCall # From Chapter 4 context\n\nclass SystemMessage(BaseModel):\n    content: str\n    type: Literal[\"SystemMessage\"] = \"SystemMessage\"\n\nclass UserMessage(BaseModel):\n    content: Union[str, List[Union[str, Image]]] # Can include images!\n    source: str\n    type: Literal[\"UserMessage\"] = \"UserMessage\"\n\nclass AssistantMessage(BaseModel):\n    content: Union[str, List[FunctionCall]] # Can be text or function calls\n    source: str\n    type: Literal[\"AssistantMessage\"] = \"AssistantMessage\"\n\n# FunctionExecutionResultMessage also exists here...\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Decorator in FastMCP Python Class\nDESCRIPTION: This snippet defines the 'tool' decorator method in the FastMCP class. It allows users to easily register functions as tools that can be called by MCP clients. The decorator adds the function to the ToolManager for later use.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass FastMCP:\n    # (...) other methods (...)\n\n    def tool(\n        self, name: str | None = None, description: str | None = None\n    ) -> Callable[[AnyFunction], AnyFunction]:\n        \"\"\"Decorator to register a tool.\"\"\"\n        # (...) error checking (...)\n\n        # This is the actual function that gets applied to your 'echo' function\n        def decorator(fn: AnyFunction) -> AnyFunction:\n            # Tells the tool manager to remember this function 'fn'\n            # associating it with the given name and description.\n            # It also inspects 'fn' to figure out its parameters (like 'message: str')\n            self.add_tool(fn, name=name, description=description)\n            return fn # Returns the original function unchanged\n\n        return decorator # Returns the 'decorator' function\n\n    def add_tool(\n        self,\n        fn: AnyFunction,\n        name: str | None = None,\n        description: str | None = None,\n    ) -> None:\n        \"\"\"Add a tool to the server.\"\"\"\n        # This passes the function and its info to the ToolManager\n        self._tool_manager.add_tool(fn, name=name, description=description)\n```\n\n----------------------------------------\n\nTITLE: DBIter Next and FindNextUserEntry Implementation in LevelDB C++\nDESCRIPTION: Implementation of DBIter::Next and DBIter::FindNextUserEntry functions in LevelDB. These functions handle the core logic for filtering and moving through entries in the iterator.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/07_iterator.md#2025-04-22_snippet_3\n\nLANGUAGE: C++\nCODE:\n```\nvoid DBIter::Next() {\n  assert(valid_);\n\n  if (direction_ == kReverse) {\n    // ... code to switch from moving backward to forward ...\n    // Position iter_ at the first entry >= saved_key_\n    // Fall through to FindNextUserEntry...\n    direction_ = kForward;\n  } else {\n    // We are moving forward. Save the current user key so we can skip\n    // all other entries for it.\n    SaveKey(ExtractUserKey(iter_->key()), &saved_key_);\n    // Advance the internal iterator.\n    iter_->Next();\n  }\n\n  // Find the next user key entry that is visible at our sequence number.\n  FindNextUserEntry(true, &saved_key_);\n}\n\n// Find the next entry for a different user key, skipping deleted\n// or older versions of the key in 'skip'.\nvoid DBIter::FindNextUserEntry(bool skipping, std::string* skip) {\n  // Loop until we hit an acceptable entry\n  assert(iter_->Valid() || !valid_); // iter_ might be invalid if Next() moved past end\n  assert(direction_ == kForward);\n\n  do {\n    if (!iter_->Valid()) { // Reached end of internal iterator\n        valid_ = false;\n        return;\n    }\n\n    ParsedInternalKey ikey;\n    // Parse the internal key (key, sequence, type)\n    if (ParseKey(&ikey)) {\n      // Check if the sequence number is visible in our snapshot\n      if (ikey.sequence <= sequence_) {\n        // Check the type (Put or Deletion)\n        switch (ikey.type) {\n          case kTypeDeletion:\n            // This key is deleted. Save the user key so we skip\n            // any older versions of it we might encounter later.\n            SaveKey(ikey.user_key, skip);\n            skipping = true; // Ensure we skip older versions\n            break;\n          case kTypeValue:\n            // This is a potential result (a Put operation).\n            // Is it for the user key we are trying to skip?\n            if (skipping &&\n                user_comparator_->Compare(ikey.user_key, *skip) <= 0) {\n              // Yes, it's hidden by a newer deletion or is an older version\n              // of the key we just yielded. Skip it.\n            } else {\n              // Found a valid entry!\n              valid_ = true;\n              // Clear skip key since we found a new valid key\n              // saved_key_.clear(); // Done in Next() or Seek()\n              return; // Exit the loop, iterator is now positioned correctly.\n            }\n            break;\n        }\n      }\n    } else {\n      // Corrupted key, mark iterator as invalid\n      valid_ = false;\n      status_ = Status::Corruption(\"corrupted internal key in DBIter\");\n      return;\n    }\n\n    // Current internal key was skipped (too new, deleted, hidden), move to next.\n    iter_->Next();\n  } while (true); // Loop until we return or reach the end\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing OAuth2 Password Bearer Authentication - FastAPI - Python\nDESCRIPTION: This snippet illustrates implementing OAuth2 authentication in FastAPI using the OAuth2PasswordBearer flow. It sets up token acquisition at '/token' using a form, demonstrates a sample login endpoint that fakes a token, and defines a dependency to decode and verify tokens for protected user data endpoints. Required dependencies include fastapi.security.OAuth2PasswordBearer, OAuth2PasswordRequestForm, Security, HTTPException, and status; inputs are form fields or bearer tokens, outputs are either a token or user info dict.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- Imports ---\nfrom fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\n\n# --- Scheme Instance ---\n# The 'tokenUrl' points to the path operation where users get the token\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"token\")\n\n# --- Token Endpoint (Example) ---\n@app.post(\"/token\")\nasync def login_for_access_token(\n    form_data: Annotated[OAuth2PasswordRequestForm, Depends()]\n):\n    # 1. Verify form_data.username and form_data.password (check DB)\n    # 2. If valid, create an access token (e.g., a JWT)\n    # 3. Return the token\n    # (Skipping implementation details for brevity)\n    access_token = f\"token_for_{form_data.username}\" # Fake token\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}\n\n# --- Verifier Dependency (Example: decode token and get user) ---\nasync def get_current_user(token: Annotated[str, Security(oauth2_scheme)]):\n    # In a real app:\n    # 1. Decode the token (e.g., JWT)\n    # 2. Validate the token (check expiry, signature)\n    # 3. Extract user identifier from token payload\n    # 4. Fetch user from database\n    # 5. Raise HTTPException if token is invalid or user doesn't exist\n    if token == \"token_for_stanley\": # Fake check\n        return {\"username\": \"stanley\", \"email\": \"stanley@example.com\"}\n    else:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid authentication credentials\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n\n# --- Protected Path Operation ---\n@app.get(\"/users/me/oauth\")\nasync def read_users_me_oauth(\n    # Use Security() with the user verifier function\n    current_user: Annotated[dict, Security(get_current_user)]\n):\n    # current_user holds the dict returned by get_current_user\n    return current_user\n\n```\n\n----------------------------------------\n\nTITLE: Simplified Pydantic Internals for Custom Logic Handling (Python)\nDESCRIPTION: This Python snippet provides conceptual, simplified code mimicking Pydantic's internal mechanisms for handling custom logic. It includes a basic `AfterValidator` dataclass demonstrating the `__get_pydantic_core_schema__` pattern used by Annotated helpers to integrate validation functions by modifying the core schema. It also shows simplified representations of `FieldValidatorDecoratorInfo` (to store decorator metadata) and `PydanticDescriptorProxy` (to wrap decorated methods), along with a conceptual loop showing how a metaclass might scan attributes, identify proxies, extract decorator info, and store it (e.g., in a `DecoratorInfos` object) for later use during schema generation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept from pydantic.functional_validators.py\n\nimport dataclasses\nfrom typing import Callable, Any, Literal\n\n# Assume existence of these types/functions for conceptual clarity\nclass GetCoreSchemaHandler: pass\nclass core_schema:\n    class CoreSchema: pass\n    @staticmethod\n    def with_info_after_validator_function(func, schema): pass\n    @staticmethod\n    def no_info_after_validator_function(func, schema): pass\n\ndef _inspect_validator(func, mode): return False # Placeholder\n\n@dataclasses.dataclass(frozen=True)\nclass AfterValidator:\n    func: Callable # The user's validation function\n\n    # This method is called by Pydantic during schema building\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: Any, # The base type (e.g., str)\n        handler: GetCoreSchemaHandler # Helper to get schema for base type\n    ) -> core_schema.CoreSchema:\n        # 1. Get the schema for the base type (e.g., str_schema())\n        schema = handler(source_type)\n        # 2. Wrap it with an 'after_validator' step using self.func\n        info_arg = _inspect_validator(self.func, 'after') # Check signature\n        if info_arg:\n            # Use core_schema function for validators with info arg\n            return core_schema.with_info_after_validator_function(\n                self.func, schema=schema\n            )\n        else:\n            # Use core_schema function for validators without info arg\n            return core_schema.no_info_after_validator_function(\n                self.func, schema=schema\n            )\n\n# Simplified concept from pydantic._internal._decorators.py\n\nfrom dataclasses import dataclass # Already imported but showing context\n\n@dataclass\nclass FieldValidatorDecoratorInfo: # Stores info about @field_validator\n    fields: tuple[str, ...]\n    mode: Literal['before', 'after', 'wrap', 'plain']\n    # ... other options\n\n@dataclass\nclass PydanticDescriptorProxy: # Wraps the decorated method\n    wrapped: Callable\n    decorator_info: FieldValidatorDecoratorInfo | ... # Stores the info object\n\n# Simplified concept from ModelMetaclass during class creation\n\n# Assume existence of these types for conceptual clarity\nclass DecoratorInfos:\n    def __init__(self):\n        self.field_validators = {}\nclass Decorator:\n    def __init__(self, func, info): pass\nclass model_cls: pass # Placeholder for the model being created\n\n# ... scan class attributes ...\ndecorators = DecoratorInfos() # Object to hold all found decorators\nfor var_name, var_value in vars(model_cls).items():\n    if isinstance(var_value, PydanticDescriptorProxy):\n        info = var_value.decorator_info\n        # Store the decorator info (function, fields, mode, etc.)\n        # in the appropriate category within 'decorators' object\n        if isinstance(info, FieldValidatorDecoratorInfo):\n            decorators.field_validators[var_name] = Decorator(\n                func=var_value.wrapped, info=info # Simplified\n            )\n        # ... handle other decorator types ...\n\n# ... later, when building the core schema ...\n# schema_generator uses the 'decorators' object to add validation/serialization\n# steps to the core schema based on the stored decorator info.\n```\n\n----------------------------------------\n\nTITLE: Automatically Opening Files with Click's File ParamType\nDESCRIPTION: This example shows how click.File can automatically open a file and pass the file handle to your command function, with Click handling the closing of the file afterward.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# file_example.py\nimport click\n\n@click.command()\n@click.argument('input_file', type=click.File('r')) # Open for reading text\ndef cat(input_file):\n    # input_file is an open file handle!\n    click.echo(input_file.read())\n    # Click will close the file automatically after this function returns\n\nif __name__ == '__main__':\n    cat()\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic CrewAI Agent in Python\nDESCRIPTION: This Python snippet demonstrates how to define a CrewAI Agent. It imports the `Agent` class and instantiates it with key attributes like `role`, `goal`, `backstory`, `verbose`, and `allow_delegation`. The example creates an 'Expert Travel Researcher' agent designed to find European cities for a trip. It requires the `crewai` library to be installed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/02_agent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Make sure you have crewai installed\n# pip install crewai\n\nfrom crewai import Agent\n\n# Define our researcher agent\nresearcher = Agent(\n  role='Expert Travel Researcher',\n  goal='Find the most exciting and sunny European cities for a birthday trip in late May.',\n  backstory=(\n      \"You are a world-class travel researcher with deep knowledge of \"\n      \"European destinations. You excel at finding hidden gems and understanding \"\n      \"weather patterns. Your recommendations are always insightful and tailored.\"\n  ),\n  verbose=True, # We want to see the agent's thinking process\n  allow_delegation=False # This agent focuses on its own research\n  # tools=[...] # We'll add tools later!\n  # llm=your_llm # We'll cover LLMs later!\n)\n\n# (You would typically define other agents, tasks, and a crew here)\n# print(researcher) # Just to see the object\n```\n\n----------------------------------------\n\nTITLE: Handling Agent Input and Output Data Types in SmolaAgents (Python)\nDESCRIPTION: This snippet demonstrates utility functions for automatically wrapping tool outputs and unwrapping inputs as AgentType subclasses within SmolaAgents. 'handle_agent_output_types' wraps Python values (such as strings or PIL images) into the correct AgentType wrapper (e.g., AgentImage) using mapping logic, while 'handle_agent_input_types' recursively replaces AgentType values with their raw representations via to_raw(). The code expects annotated input/output types or infers based on instance checks. Dependencies include Python typing and PIL.Image, and these helpers enable tools to work seamlessly with both wrapped and native data parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/07_agenttype.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent_types.py / agents.py (Simplified Helpers) ---\\n\\n# Mapping from type name string to AgentType class\\n_AGENT_TYPE_MAPPING = {\"string\": AgentText, \"image\": AgentImage, \"audio\": AgentAudio}\\n\\ndef handle_agent_output_types(output: Any, output_type: Optional[str] = None) -> Any:\\n    \"\"\"Wraps raw output into an AgentType if needed.\"\"\"\\n    if output_type in _AGENT_TYPE_MAPPING:\\n        # If the tool explicitly defines output type (e.g., \"image\")\\n        wrapper_class = _AGENT_TYPE_MAPPING[output_type]\\n        return wrapper_class(output)\\n    else:\\n        # If no type defined, try to guess based on Python type (optional)\\n        if isinstance(output, str):\\n            return AgentText(output)\\n        if isinstance(output, PIL.Image.Image):\\n            return AgentImage(output)\\n        # ... add checks for audio tensors etc. ...\\n\\n        # Otherwise, return the output as is\\n        return output\\n\\ndef handle_agent_input_types(*args, **kwargs) -> tuple[list, dict]:\\n    \"\"\"Unwraps AgentType inputs into raw types before passing to a tool.\"\"\"\\n    processed_args = []\\n    for arg in args:\\n        # If it's an AgentType instance, call to_raw(), otherwise keep as is\\n        processed_args.append(arg.to_raw() if isinstance(arg, AgentType) else arg)\\n\\n    processed_kwargs = {}\\n    for key, value in kwargs.items():\\n        processed_kwargs[key] = value.to_raw() if isinstance(value, AgentType) else value\\n\\n    return tuple(processed_args), processed_kwargs\\n\n```\n\n----------------------------------------\n\nTITLE: Chat Adapter Implementation in Python\nDESCRIPTION: Concrete implementation of the Chat Adapter for handling chat-based language models, including message formatting and response parsing logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport re\n\nfield_header_pattern = re.compile(r\"\\[\\[ ## (\\w+) ## \\]\\]\")\n\nclass ChatAdapter(Adapter):\n    def format(self, signature, demos, inputs) -> list[dict[str, Any]]:\n        messages = []\n        prepared_instructions = prepare_instructions(signature)\n        messages.append({\"role\": \"system\", \"content\": prepared_instructions})\n        \n        for demo in demos:\n            messages.append(self.format_turn(signature, demo, role=\"user\"))\n            messages.append(self.format_turn(signature, demo, role=\"assistant\"))\n            \n        messages.append(self.format_turn(signature, inputs, role=\"user\"))\n        messages = try_expand_image_tags(messages)\n        return messages\n\n    def parse(self, signature: Type[Signature], completion: str) -> dict[str, Any]:\n        sections = self._split_completion_by_markers(completion)\n        fields = {}\n        for field_name, field_content in sections:\n            if field_name in signature.output_fields:\n                try:\n                    fields[field_name] = parse_value(field_content, signature.output_fields[field_name].annotation)\n                except Exception as e:\n                    pass\n        return fields\n```\n\n----------------------------------------\n\nTITLE: Initializing a Basic A2A Server with Async Generator Logic in TypeScript\nDESCRIPTION: Demonstrates setting up a simple Node.js A2A server using the `A2AServer` class from the `google-a2a/server` library. It defines the agent's core logic (`echoAgentLogic`) as an async generator function that handles incoming tasks and yields status updates and final results. An `AgentCard` provides metadata, and the server instance is created and started on port 4000.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/04_a2a_server_implementation.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// File: simple-agent/index.ts (Conceptual Example)\nimport { A2AServer, TaskContext, TaskYieldUpdate } from \"google-a2a/server\"; // Simplified import\nimport * as schema from \"google-a2a/schema\";\n\n// 1. Define the Agent's Logic (The \"Expert\")\n// This function handles a single task.\nasync function* echoAgentLogic(\n  context: TaskContext\n): AsyncGenerator<TaskYieldUpdate, schema.Task | void> {\n  const inputText = context.userMessage.parts[0].text ?? \"No text found\";\n\n  // Yield a status update: \"working\"\n  yield { state: \"working\", message: { role: \"agent\", parts: [{ text: \"Echoing...\" }] } };\n\n  // Yield the final result: \"completed\"\n  yield {\n    state: \"completed\",\n    message: { role: \"agent\", parts: [{ text: `You said: ${inputText}` }] }\n  };\n  // (Artifacts could also be yielded here if needed)\n}\n\n// 2. Define the Agent Card\nconst echoAgentCard: schema.AgentCard = {\n  name: \"Echo Agent\",\n  description: \"Replies with the text it receives.\",\n  url: \"http://localhost:4000\", // Where this server will run\n  version: \"1.0\",\n  capabilities: { streaming: true }, // It yields updates\n  skills: [{ id: \"echo\", name: \"Echo Text\" }],\n  // ... other card details\n};\n\n// 3. Create and Start the Server\nconst server = new A2AServer(echoAgentLogic, { card: echoAgentCard });\nserver.start(4000); // Start listening on port 4000\n\nconsole.log(\"Echo Agent server running on http://localhost:4000\");\n```\n\n----------------------------------------\n\nTITLE: Implementing a Rich Console Logger for Agents in Python\nDESCRIPTION: Defines the AgentLogger class for rich-formatted console logging, including error, code, and task-specific output, as well as level-based filtering using the LogLevel enumeration. Depends on the 'rich' Python library and custom IntEnum for log levels. Core parameters include log level and content; outputs vary from plain messages to syntax-highlighted code panels. Useful for tracking agent operations with visually distinctive terminal output. Requires Rich to be installed; methods expect appropriate input type for message content and styling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: monitoring.py (Simplified AgentLogger) ---\\nfrom enum import IntEnum\\nfrom rich.console import Console\\nfrom rich.panel import Panel\\nfrom rich.syntax import Syntax\\nfrom rich.rule import Rule\\n# ... other rich imports ...\\n\\nclass LogLevel(IntEnum):\\n    OFF = -1\\n    ERROR = 0\\n    INFO = 1\\n    DEBUG = 2\\n\\nYELLOW_HEX = \"#d4b702\" # Used for styling\\n\\nclass AgentLogger:\\n    def __init__(self, level: LogLevel = LogLevel.INFO):\\n        self.level = level\\n        # The core object from the 'rich' library for printing\\n        self.console = Console()\\n\\n    def log(self, *args, level: LogLevel = LogLevel.INFO, **kwargs):\\n        \\\"\\\"\\\"Logs a message if the level is sufficient.\\\"\\\"\\\"\\n        if level <= self.level:\\n            self.console.print(*args, **kwargs)\\n\\n    def log_error(self, error_message: str):\\n        \\\"\\\"\\\"Logs an error message.\\\"\\\"\\\"\\n        self.log(error_message, style=\"bold red\", level=LogLevel.ERROR)\\n\\n    def log_code(self, title: str, content: str, level: LogLevel = LogLevel.INFO):\\n        \\\"\\\"\\\"Logs a Python code block with syntax highlighting.\\\"\\\"\\\"\\n        self.log(\\n            Panel(Syntax(content, lexer=\"python\", ...), title=title, ...),\\n            level=level\\n        )\\n\\n    def log_rule(self, title: str, level: LogLevel = LogLevel.INFO):\\n        \\\"\\\"\\\"Logs a horizontal rule separator.\\\"\\\"\\\"\\n        self.log(Rule(\"[bold]\" + title, style=YELLOW_HEX), level=level)\\n\\n    def log_task(self, content: str, subtitle: str, title: Optional[str] = None, level: LogLevel = LogLevel.INFO):\\n         \\\"\\\"\\\"Logs the initial task.\\\"\\\"\\\"\\n         self.log(Panel(f\"\\n[bold]{content}\\n\", title=title, subtitle=subtitle, ...), level=level)\\n\\n    # ... other helper methods for specific formatting ...\n```\n\n----------------------------------------\n\nTITLE: Specifying Data Types in Flask Routes with Converters (Python)\nDESCRIPTION: This code snippet expands the Flask application's routing system by adding a new route that uses a converter to match only integer values in the URL ('/post/<int:post_id>'). The 'post_id' value is automatically converted to an integer and passed to the handler function, ensuring type safety and flexible route matching. It demonstrates the use of converters in Flask URL rules, explains the difference in behavior when matching or failing to match the converter constraint, and outputs the post number and its type. Flask must be installed. Intended inputs are GET requests to '/post/<int>', and the output is a string confirming the integer value and type. Non-integer inputs to the route yield a 404 error.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/02_routing_system.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n# ... (keep previous code) ...\n\n# NEW: Route for displaying a specific blog post by ID\n@app.route('/post/<int:post_id>')\ndef show_post(post_id):\n  # Flask ensures post_id is an integer and passes it here\n  # Note: We are just showing the ID, not actually fetching a post\n  return f'Showing Post Number: {post_id} (Type: {type(post_id).__name__})'\n\n# ... (keep the if __name__ == '__main__': block) ...\n\n```\n\n----------------------------------------\n\nTITLE: Initializing LiteLLMModel for SmolaAgents in Python\nDESCRIPTION: This snippet demonstrates how to import and initialize the `LiteLLMModel` from `smolagents.models`. It requires the `litellm` library (`pip install smolagents[litellm]`) and specifies a model ID recognized by `litellm` (e.g., \"gpt-3.5-turbo\"). Depending on the chosen model, specific environment variables like `OPENAI_API_KEY` might be required for authentication. The resulting `llm` object serves as a standardized interface to the selected LLM, abstracting away the specific API details.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: choose_model.py ---\n# Import the model interface you want to use\nfrom smolagents.models import LiteLLMModel\n# (You might need to install litellm first: pip install smolagents[litellm])\n\n# Choose the specific LLM model ID that litellm supports\n# Example: OpenAI's GPT-3.5 Turbo\n# Requires setting the OPENAI_API_KEY environment variable!\nmodel_id = \"gpt-3.5-turbo\"\n\n# Create an instance of the Model Interface\n# This object is our \"universal remote\" configured for GPT-3.5\nllm = LiteLLMModel(model_id=model_id)\n\nprint(f\"Model Interface created for: {model_id}\")\n# Example Output: Model Interface created for: gpt-3.5-turbo\n```\n\n----------------------------------------\n\nTITLE: Instantiating a ColBERTv2 RM Client in Python\nDESCRIPTION: Creates an instance of the `dspy.ColBERTv2` retrieval model client, configured to connect to a specific ColBERTv2 server endpoint. The `url` parameter specifies the server address. This instance represents the connection to the retrieval system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Assume a ColBERTv2 server is running at this URL indexing Wikipedia\ncolbertv2_wiki = dspy.ColBERTv2(url='http://your-colbertv2-endpoint.com:8893', port=None)\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Beat Schedule in Python\nDESCRIPTION: This snippet demonstrates how to configure Celery Beat schedules in a configuration file. It includes setting up periodic tasks with different intervals and using crontab for more complex scheduling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# celeryconfig.py\nfrom datetime import timedelta\nfrom celery.schedules import crontab\n\n# Basic Broker/Backend settings (replace with your actual URLs)\nbroker_url = 'redis://localhost:6379/0'\nresult_backend = 'redis://localhost:6379/1'\ntimezone = 'UTC' # Or your preferred timezone, e.g., 'America/New_York'\nenable_utc = True\n\n# List of modules to import when the Celery worker starts.\n# Make sure tasks.py is discoverable in your Python path\nimports = ('tasks',)\n\n# Define the Beat schedule\nbeat_schedule = {\n    # Executes tasks.add every 15 seconds with arguments (16, 16)\n    'add-every-15-seconds': {\n        'task': 'tasks.add',          # The task name\n        'schedule': 15.0,             # Run every 15 seconds (float or timedelta)\n        'args': (16, 16),             # Positional arguments for the task\n    },\n    # Executes tasks.send_report every minute\n    'send-report-every-minute': {\n        'task': 'tasks.send_report',\n        'schedule': crontab(),        # Use crontab() for \"every minute\"\n        'args': ('daily-summary',),   # Argument for the report name\n        # Example using crontab for more specific timing:\n        # 'schedule': crontab(hour=8, minute=0, day_of_week='fri'), # Every Friday at 8:00 AM\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Not Found Errors with HTTPException in FastAPI (Python)\nDESCRIPTION: Defines a GET endpoint that checks if an item ID exists in the in-memory database, raising an HTTPException with a 404 status code if not. This code demonstrates expected error handling in FastAPI using exception raising inside a path operation. Dependencies: fastapi. Parameters: item_id (int, from path). Input: item_id. Output: JSON response with item if found or error if not.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@app.get(\\\"/items/{item_id}\\\")\\nasync def read_item(item_id: int):\\n    # Check if the requested item_id exists in our \\\"database\\\"\\n    if item_id not in fake_items_db:\\n        # If not found, raise HTTPException!\\n        raise HTTPException(status_code=404, detail=\\\"Item not found\\\")\\n\\n    # If found, proceed normally\\n    return {\\\"item\\\": fake_items_db[item_id]}\n```\n\n----------------------------------------\n\nTITLE: Creating LevelDB Iterator in C++\nDESCRIPTION: Implementation of DBImpl::NewIterator function in LevelDB. It creates an internal iterator, determines the snapshot sequence number, and wraps the internal iterator with DBIter.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/07_iterator.md#2025-04-22_snippet_1\n\nLANGUAGE: C++\nCODE:\n```\nIterator* DBImpl::NewIterator(const ReadOptions& options) {\n  SequenceNumber latest_snapshot;\n  uint32_t seed; // Used for read sampling randomization\n\n  // (1) Create the internal merging iterator\n  Iterator* internal_iter = NewInternalIterator(options, &latest_snapshot, &seed);\n\n  // (2) Determine the sequence number for the snapshot\n  SequenceNumber snapshot_seq =\n      (options.snapshot != nullptr\n           ? static_cast<const SnapshotImpl*>(options.snapshot)\n                 ->sequence_number()\n           : latest_snapshot);\n\n  // (3) Wrap the internal iterator with DBIter\n  return NewDBIterator(this, // Pass DBImpl pointer for read sampling\n                       user_comparator(),\n                       internal_iter,\n                       snapshot_seq,\n                       seed);\n}\n```\n\n----------------------------------------\n\nTITLE: Parsing Tool Call Arguments in TypeScript\nDESCRIPTION: This function parses the raw JSON string from a tool call's arguments, expecting specific shapes for known tools like 'shell' or 'apply_patch'. It returns a structured object containing validated arguments or undefined if parsing fails.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport function parseToolCallArguments(\n  rawArguments: string,\n): ExecInput | undefined { // ExecInput contains { cmd, workdir, timeoutInMillis }\n  let json: unknown;\n  try {\n    json = JSON.parse(rawArguments); // Basic JSON parsing\n  } catch (err) {\n    // Handle JSON parse errors\n    return undefined;\n  }\n\n  if (typeof json !== \"object\" || json == null) return undefined;\n\n  // Look for 'command' or 'cmd' property, expecting an array of strings\n  const { cmd, command, patch /* other possible args */ } = json as Record<string, unknown>;\n  const commandArray = toStringArray(cmd) ?? toStringArray(command);\n\n  // If it's a shell command, require the command array\n  if (commandArray != null) {\n    return {\n      cmd: commandArray,\n      // Optional: extract workdir and timeout too\n      workdir: typeof (json as any).workdir === \"string\" ? (json as any).workdir : undefined,\n      timeoutInMillis: typeof (json as any).timeout === \"number\" ? (json as any).timeout : undefined,\n    };\n  }\n\n  // If it's an apply_patch command, require the patch string\n  if (typeof patch === 'string') {\n    return { cmd: ['apply_patch'], patch: patch }; // Use a placeholder cmd\n  }\n\n  return undefined; // Unknown or invalid arguments structure\n}\n```\n\n----------------------------------------\n\nTITLE: Registering a Custom Exception Handler in FastAPI (Python)\nDESCRIPTION: Implements and registers an asynchronous exception handler with FastAPI for UnicornNotFound errors using the @app.exception_handler decorator. Whenever UnicornNotFound is raised during request processing, this handler returns a JSONResponse with status code 418 and a tailored message. Requires FastAPI, Request, and JSONResponse; depends on UnicornNotFound being defined.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# main.py\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import JSONResponse\n# Assuming UnicornNotFound is defined above or imported\n\napp = FastAPI()\n\n# Decorator registers this function to handle UnicornNotFound errors\n@app.exception_handler(UnicornNotFound)\nasync def unicorn_exception_handler(request: Request, exc: UnicornNotFound):\n    # This function runs whenever UnicornNotFound is raised\n    return JSONResponse(\n        status_code=418, # I'm a teapot!\n        content={\"message\": f\"Oops! Can't find unicorn named: {exc.name}.\"},\n    )\n\n```\n\n----------------------------------------\n\nTITLE: Handling Cookie Name Conflicts with Domain/Path in Python RequestsCookieJar\nDESCRIPTION: This snippet shows how to handle situations where multiple cookies might have the same name but apply to different domains or paths. It uses the `.set()` method of a `RequestsCookieJar` to explicitly set two cookies named 'pref' with different values for different domains ('example.com' and 'test.com'). It then demonstrates retrieving the specific cookie for 'example.com' using the `.get()` method with the `domain` and `path` arguments, highlighting that simple dictionary access (`jar['pref']`) could be ambiguous or lead to errors in such cases.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\njar.set('pref', 'dark', domain='example.com', path='/')\njar.set('pref', 'compact', domain='test.com', path='/')\n\n# Get the specific cookie for example.com\npref_example = jar.get('pref', domain='example.com', path='/')\nprint(f\"Pref for example.com: {pref_example}\")\n\n# Simple access might be ambiguous or pick one arbitrarily\n# print(jar['pref']) # Could raise CookieConflictError or return one\n```\n\n----------------------------------------\n\nTITLE: Defining Base Execution Flow Class with Multiple Agents in Python\nDESCRIPTION: This Python snippet defines an abstract base class, BaseFlow, for execution flows that orchestrate multiple agents. It supports agent management via a dictionary, includes a property to retrieve the primary agent, and mandates implementation of an asynchronous execute method in subclasses. Requires dependencies on abc, typing, pydantic, and local BaseAgent definitions; expected to serve as a base for further specialized flow classes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/flow/base.py\\nfrom abc import ABC, abstractmethod\\nfrom typing import Dict, List, Optional, Union\\nfrom pydantic import BaseModel\\nfrom app.agent.base import BaseAgent\\n\\nclass BaseFlow(BaseModel, ABC):\\n    \\\"\\\"\\\"Base class for execution flows supporting multiple agents\\\"\\\"\\\"\\n    agents: Dict[str, BaseAgent] # Holds the agents\\n    primary_agent_key: Optional[str] = None # Key for the main agent\\n\\n    # ... __init__ handles setting up the agents dictionary ...\\n\\n    @property\\n    def primary_agent(self) -> Optional[BaseAgent]:\\n        \\\"\\\"\\\"Get the primary agent for the flow\\\"\\\"\\\"\\n        return self.agents.get(self.primary_agent_key)\\n\\n    @abstractmethod # Subclasses MUST implement execute\\n    async def execute(self, input_text: str) -> str:\\n        \\\"\\\"\\\"Execute the flow with given input\\\"\\\"\\\"\\n        pass\\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing DSPy Module Architecture with Mermaid - Markdown\nDESCRIPTION: This Mermaid flowchart visualizes the core abstractions and their relationships in DSPy's architecture. It describes how Modules compose programs, use retrieval and language model clients, employ signatures for I/O structure, rely on adapters for formatting, and optimize behavior using Teleprompters. The chart helps users understand object interactions and provides a technical overview for those integrating or extending DSPy.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\\n    A0[\\\"Module / Program\\\"]\\n    A1[\\\"Signature\\\"]\\n    A2[\\\"Predict\\\"]\\n    A3[\\\"LM (Language Model Client)\\\"]\\n    A4[\\\"RM (Retrieval Model Client)\\\"]\\n    A5[\\\"Teleprompter / Optimizer\\\"]\\n    A6[\\\"Example\\\"]\\n    A7[\\\"Evaluate\\\"]\\n    A8[\\\"Adapter\\\"]\\n    A9[\\\"Settings\\\"]\\n    A0 -- \\\"Contains / Composes\\\" --> A0\\n    A0 -- \\\"Uses (via Retrieve)\\\" --> A4\\n    A1 -- \\\"Defines structure for\\\" --> A6\\n    A2 -- \\\"Implements\\\" --> A1\\n    A2 -- \\\"Calls\\\" --> A3\\n    A2 -- \\\"Uses demos from\\\" --> A6\\n    A2 -- \\\"Formats prompts using\\\" --> A8\\n    A5 -- \\\"Optimizes\\\" --> A0\\n    A5 -- \\\"Fine-tunes\\\" --> A3\\n    A5 -- \\\"Uses training data from\\\" --> A6\\n    A5 -- \\\"Uses metric from\\\" --> A7\\n    A7 -- \\\"Tests\\\" --> A0\\n    A7 -- \\\"Evaluates on dataset of\\\" --> A6\\n    A8 -- \\\"Translates\\\" --> A1\\n    A8 -- \\\"Formats demos from\\\" --> A6\\n    A9 -- \\\"Configures default\\\" --> A3\\n    A9 -- \\\"Configures default\\\" --> A4\\n    A9 -- \\\"Configures default\\\" --> A8\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using TypeAdapter - Pydantic - Python\nDESCRIPTION: This conceptual Python code illustrates key components and workflow of the TypeAdapter class from Pydantic V2, demonstrating how type-specific schemas are generated and how validation and serialization methods delegate to underlying pydantic-core objects. It highlights the orchestration in the constructor, internal schema handling, and thin method wrappers. You must have Pydantic V2 (and its Rust-based pydantic-core) installed to use this pattern. The TypeAdapter can be instantiated for any supported type and called with validate/dump methods; errors are handled internally during schema initialization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Simplified conceptual view from pydantic/type_adapter.py\\n\\nfrom pydantic_core import SchemaValidator, SchemaSerializer, CoreSchema\\n# ... other imports\\n\\nclass TypeAdapter(Generic[T]):\\n    core_schema: CoreSchema\\n    validator: SchemaValidator | PluggableSchemaValidator # Actually uses PluggableSchemaValidator internally\\n    serializer: SchemaSerializer\\n\\n    def __init__(self, type: Any, *, config: ConfigDict | None = None, ...):\\n        self._type = type\\n        self._config = config\\n        # ... (fetch parent frame namespaces) ...\\n        ns_resolver = _namespace_utils.NsResolver(...)\\n\\n        # ... Call internal _init_core_attrs ...\\n        self._init_core_attrs(ns_resolver=ns_resolver, force=True)\\n\\n    def _init_core_attrs(self, ns_resolver, force, raise_errors=False):\\n        # ... Simplified schema generation ...\\n        config_wrapper = _config.ConfigWrapper(self._config)\\n        schema_generator = _generate_schema.GenerateSchema(config_wrapper, ns_resolver)\\n        try:\\n            core_schema = schema_generator.generate_schema(self._type)\\n            self.core_schema = schema_generator.clean_schema(core_schema)\\n            core_config = config_wrapper.core_config(None)\\n\\n            # Create and store validator and serializer\\n            # Note: Actual code uses create_schema_validator for plugin support\\n            self.validator = SchemaValidator(self.core_schema, core_config)\\n            self.serializer = SchemaSerializer(self.core_schema, core_config)\\n            self.pydantic_complete = True\\n\\n        except Exception:\\n            # Handle errors, potentially set mocks if build fails\\n            # ...\\n            pass\\n\\n    def validate_python(self, object: Any, /, **kwargs) -> T:\\n        # Directly delegates to the stored validator\\n        return self.validator.validate_python(object, **kwargs)\\n\\n    def validate_json(self, data: str | bytes | bytearray, /, **kwargs) -> T:\\n        # Directly delegates to the stored validator\\n        return self.validator.validate_json(data, **kwargs)\\n\\n    def dump_python(self, instance: T, /, **kwargs) -> Any:\\n        # Directly delegates to the stored serializer\\n        return self.serializer.to_python(instance, **kwargs)\\n\\n    def dump_json(self, instance: T, /, **kwargs) -> bytes:\\n        # Directly delegates to the stored serializer\\n        return self.serializer.to_json(instance, **kwargs)\\n\\n    def json_schema(self, **kwargs) -> dict[str, Any]:\\n        # Generates schema based on self.core_schema\\n        schema_generator_instance = GenerateJsonSchema(**kwargs)\\n        return schema_generator_instance.generate(self.core_schema, mode=kwargs.get('mode', 'validation'))\\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Dependency that Uses a Chained (Database) Dependency in FastAPI - Python\nDESCRIPTION: Defines the 'get_item_from_db' async dependency, which requires both a path parameter ('item_id') and a chained dependency 'db' (from 'get_db_session'). Demonstrates how FastAPI passes parameters and results from one dependency into another and handles error raising (HTTP 404) if a requested item isn't found in a fake database dictionary. Dependencies: FastAPI, Typing.Annotated, a prior definition of get_db_session, and HTTPException import.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# common_dependencies.py\nfrom typing import Annotated\nfrom fastapi import Depends, HTTPException\n\n# Import the DB session dependency\nfrom .common_dependencies import get_db_session\n\nasync def get_item_from_db(\n    item_id: int, # Takes a regular path parameter\n    db: Annotated[str, Depends(get_db_session)] # Depends on get_db_session!\n):\n    print(f\"Getting item {item_id} using DB session: {db}\")\n    # Fake database interaction\n    fake_db = {1: \"Item One\", 2: \"Item Two\"}\n    if item_id not in fake_db:\n        raise HTTPException(status_code=404, detail=\"Item not found in DB\")\n    return fake_db[item_id]\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Beat Schedule in Python\nDESCRIPTION: Example structure of the beat_schedule configuration in celeryconfig.py, showing how to define scheduled tasks with timing intervals, arguments, and execution options.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Example structure from celeryconfig.py\n\nbeat_schedule = {\n    'schedule-name-1': {              # Unique name for this entry\n        'task': 'my_app.tasks.task1',  # Task to run (module.task_name)\n        'schedule': 30.0,             # When to run (e.g., seconds, timedelta, crontab)\n        'args': (arg1, arg2),         # Optional: Positional arguments\n        'kwargs': {'key': 'value'},   # Optional: Keyword arguments\n        'options': {'queue': 'hipri'},# Optional: Execution options\n    },\n    'schedule-name-2': {\n        'task': 'my_app.tasks.task2',\n        'schedule': crontab(minute=0, hour=0), # e.g., Run at midnight\n        # ... other options ...\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Modeling HTTP Responses and Accessing Content with Requests (Python)\nDESCRIPTION: This snippet introduces the Response class, modeling the data returned by a server after making an HTTP request via the Requests library. It provides both internal attributes (for content, status, headers, raw stream, etc.) and user-facing properties and methods like .content, .text, and .json(), allowing access to the response in bytes, decoded text, or parsed JSON. Dependencies include a CaseInsensitiveDict for header management, a cookie jar factory, and the datetime module. Inputs are automatically set from the network transaction; outputs include response data accessible via properties and methods. The implementation assumes content decoding logic is provided.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/02_request___response_models.md#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nclass Response:\n    \"\"\"Contains a server's response to an HTTP request.\"\"\"\n    def __init__(self):\n        self._content = False # Content hasn't been read yet\n        self.status_code = None\n        self.headers = CaseInsensitiveDict() # Special dictionary for headers\n        self.raw = None # The raw stream from the network connection\n        self.url = None\n        self.encoding = None\n        self.history = [] # List of redirects\n        self.reason = None # Text reason, e.g., \"OK\"\n        self.cookies = cookiejar_from_dict({})\n        self.elapsed = datetime.timedelta(0) # Time taken\n        self.request = None # The PreparedRequest that led to this response\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n        # ... logic to read from self.raw if not already read ...\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\"\"\"\n        # ... logic to decode self.content using self.encoding or guessed encoding ...\n        return decoded_string\n\n    def json(self, **kwargs):\n        \"\"\"Returns the json-encoded content of a response, if any.\"\"\"\n        # ... logic to parse self.text as JSON ...\n        return python_object\n\n    # ... other properties like .ok, .is_redirect, and methods like .raise_for_status() ...\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing Flask Request Lifecycle with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram showing the interaction between Browser, Flask App, Context Management, View Function, and request Proxy during a typical request lifecycle. It demonstrates context pushing/popping and how request proxies resolve to the correct objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/07_application_and_request_contexts.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Browser\n    participant FlaskApp as Flask App (WSGI)\n    participant Contexts as Context Management\n    participant YourView as Your View Function\n    participant Globals as request Proxy\n\n    Browser->>+FlaskApp: Sends GET /user/alice\n    FlaskApp->>+Contexts: Request arrives, create RequestContext (incl. AppContext)\n    Contexts->>Contexts: Push RequestContext (sets _cv_request)\n    Contexts->>Contexts: Push AppContext (sets _cv_app)\n    Note over Contexts: request, session, current_app, g are now active\n    FlaskApp->>+YourView: Calls view_func(username='alice')\n    YourView->>+Globals: Access request.method\n    Globals->>Contexts: Lookup _cv_request -> finds current RequestContext\n    Globals-->>YourView: Returns 'GET' (from real request object)\n    YourView-->>-FlaskApp: Returns Response(\"Hello Alice\")\n    FlaskApp->>+Contexts: Response sent, Pop RequestContext (resets _cv_request)\n    Contexts->>Contexts: Pop AppContext (resets _cv_app)\n    Note over Contexts: Context globals are now unbound for this request\n    FlaskApp-->>-Browser: Sends HTTP Response\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Language Model Client for DSPy in Python\nDESCRIPTION: This snippet sets up DSPy to use OpenAI's 'gpt-3.5-turbo' language model client, configuring it for any subsequent LM calls. Dependencies: Valid OpenAI API key and dspy package. This step is prerequisite for any prediction, ensuring language model calls are properly routed. The configuration must occur before invoking Predict modules. No explicit input/output, but it affects all LM operations downstream.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/04_predict.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Assume you have an OpenAI API key configured\n# We'll explain this properly in the next chapter!\ngpt3_turbo = dspy.OpenAI(model='gpt-3.5-turbo')\ndspy.settings.configure(lm=gpt3_turbo)\n```\n\n----------------------------------------\n\nTITLE: Implementing PromptManager.render_prompt in Python\nDESCRIPTION: A simplified implementation of the PromptManager.render_prompt method, which handles the process of finding and rendering a specific prompt by name with given arguments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass PromptManager:\n    # ... (other methods) ...\n\n    async def render_prompt(self, name, arguments=None):\n        # 1. Find the prompt object by name\n        prompt = self.get_prompt(name)\n        if not prompt:\n            raise ValueError(f\"Unknown prompt: {name}\")\n\n        # 2. Tell the Prompt object to render itself\n        return await prompt.render(arguments)\n```\n\n----------------------------------------\n\nTITLE: Selecting Files for Compaction in LevelDB (C++)\nDESCRIPTION: Implementation of VersionSet::PickCompaction method that selects files for compaction based on either seek triggers or size thresholds. It creates a Compaction object, identifies initial files to compact, and expands the selection as needed for Level-0 files due to their potential overlaps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/08_compaction.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/version_set.cc ---\n\nCompaction* VersionSet::PickCompaction() {\n  Compaction* c = nullptr;\n  int level;\n\n  // Check for seek-triggered compaction first\n  const bool seek_compaction = (current_->file_to_compact_ != nullptr);\n  if (seek_compaction) {\n    level = current_->file_to_compact_level_;\n    c = new Compaction(options_, level);\n    c->inputs_[0].push_back(current_->file_to_compact_); // Add the specific file\n  } else {\n    // Check for size-triggered compaction\n    const bool size_compaction = (current_->compaction_score_ >= 1);\n    if (!size_compaction) {\n      return nullptr; // No compaction needed\n    }\n    level = current_->compaction_level_;\n    c = new Compaction(options_, level);\n\n    // Pick starting file in chosen level (often based on compact_pointer_)\n    // ... logic to select initial file(s) ...\n    // c->inputs_[0].push_back(chosen_file);\n  }\n\n  c->input_version_ = current_; // Remember which Version we are compacting\n  c->input_version_->Ref();\n\n  // Expand Level-0 inputs if necessary due to overlap\n  if (level == 0) {\n    InternalKey smallest, largest;\n    GetRange(c->inputs_[0], &smallest, &largest); // Find range of initial file(s)\n    // Find ALL L0 files overlapping that range\n    current_->GetOverlappingInputs(0, &smallest, &largest, &c->inputs_[0]);\n    assert(!c->inputs_[0].empty());\n  }\n\n  // Now figure out the overlapping files in the next level (Level+1)\n  SetupOtherInputs(c);\n  return c;\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Path and Query Parameters in FastAPI (Python)\nDESCRIPTION: Shows an example of a FastAPI path operation function that accepts both a required path parameter (`user_id: int`) and multiple optional query parameters (`show_details: bool = False`, `category: str | None = None`). This demonstrates how FastAPI distinguishes between path and query parameters based on their presence in the path string and function signature, handling type hints (including `bool` and optional `str`) and default values accordingly.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@app.get(\"/users/{user_id}/items\")\nasync def read_user_items(\n    user_id: int,                 # Path parameter\n    show_details: bool = False,   # Optional query parameter (e.g., ?show_details=true)\n    category: str | None = None # Optional query parameter (e.g., ?category=books)\n):\n    # ... function logic ...\n    return {\"user_id\": user_id, \"show_details\": show_details, \"category\": category}\n```\n\n----------------------------------------\n\nTITLE: Using Jinja2 If/Else Statements in HTML Template\nDESCRIPTION: This HTML snippet (`profile.html`) demonstrates the use of Jinja2 conditional statements (`{% if %}`, `{% else %}`, `{% endif %}`). It checks if a `user` variable exists and if its `is_logged_in` attribute is true. Based on this condition, it renders different welcome messages, accessing the user's name via `{{ user.name }}` if logged in.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_3\n\nLANGUAGE: html\nCODE:\n```\n<!-- templates/profile.html -->\n{% raw %}\n<!doctype html>\n<html>\n<head><title>User Profile</title></head>\n<body>\n  {% if user and user.is_logged_in %}\n    <h1>Welcome back, {{ user.name }}!</h1>\n    <p>You are logged in.</p>\n  {% else %}\n    <h1>Welcome, Guest!</h1>\n    <p>Please log in.</p>\n  {% endif %}\n</body>\n</html>\n{% endraw %}\n```\n\n----------------------------------------\n\nTITLE: Defining and Validating the Crew Process - Python\nDESCRIPTION: This snippet defines the Crew class with attributes for process type, manager LLM, and agent, and includes a Pydantic validator to ensure that either a manager LLM or agent is present for hierarchical processes. Dependencies include the Process enum, Field, Optional typing, the BaseModel from Pydantic, and supporting agent classes. The main input is the 'process' type, and validation enforces configuration correctness for hierarchical collaboration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass Crew(BaseModel):\n    # ... other fields like agents, tasks ...\n    process: Process = Field(default=Process.sequential)\n    manager_llm: Optional[Any] = Field(default=None)\n    manager_agent: Optional[BaseAgent] = Field(default=None)\n    # ... other fields ...\n\n    @model_validator(mode=\"after\")\n    def check_manager_llm(self):\n        # Ensures manager_llm or manager_agent is set for hierarchical process\n        if self.process == Process.hierarchical:\n            if not self.manager_llm and not self.manager_agent:\n                raise PydanticCustomError(\n                    \"missing_manager_llm_or_manager_agent\",\n                    \"Attribute `manager_llm` or `manager_agent` is required when using hierarchical process.\",\n                    {},\n                )\n        return self\n```\n\n----------------------------------------\n\nTITLE: Implementing Stdio Transport Server in Python\nDESCRIPTION: Demonstrates how to set up a server using stdio transport to communicate via standard input/output streams. Uses the stdio_server context manager to handle stream creation and management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/09_communication_transports__stdio__sse__websocket__memory_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual code showing how stdio_server might be used\nimport anyio\nfrom mcp.server.stdio import stdio_server # Import the stdio transport\nfrom mcp.server.mcp_server import MCPServer # Low-level server\n\n# Assume 'my_actual_server' is your MCPServer instance\nmy_actual_server = MCPServer(name=\"MyStdioServer\")\n\nasync def main():\n    print(\"Server: Waiting for client over stdio...\")\n    # 1. Use the stdio_server context manager\n    async with stdio_server() as (read_stream, write_stream):\n        # 2. It yields streams connected to stdin/stdout\n        print(\"Server: Stdio streams acquired. Running server logic.\")\n        # 3. Pass streams to the server's run method\n        await my_actual_server.run(\n            read_stream,\n            write_stream,\n            my_actual_server.create_initialization_options()\n        )\n    print(\"Server: Stdio streams closed.\")\n\nif __name__ == \"__main__\":\n    try:\n        anyio.run(main)\n    except KeyboardInterrupt:\n        print(\"Server: Exiting.\")\n```\n\n----------------------------------------\n\nTITLE: Simulating Flask Request Context for Testing (Python)\nDESCRIPTION: This Python script shows how to simulate a Flask request context using `app.test_request_context()`. This method pushes both request and application contexts, making context globals like `request` available within the `with` block. It's primarily used for testing functions or components that normally run within a request lifecycle but need to be tested in isolation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/07_application_and_request_contexts.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# example_test_context.py\nfrom hello import app # Assuming hello.py defines app = Flask(__name__)\n\n# A helper function that might be used inside a view\ndef get_user_agent_info():\n    # This function relies on the 'request' context global\n    from flask import request\n    user_agent = request.headers.get('User-Agent', 'Unknown')\n    return f\"Request came from: {user_agent}\"\n\n# --- Simulate calling the function outside a real request ---\nif __name__ == \"__main__\":\n    # Create a test request context for a fake GET request to '/'\n    # This pushes both Request and App contexts\n    with app.test_request_context('/', method='GET'):\n        # Now, inside this block, 'request' is available!\n        print(\"Inside test request context...\")\n        agent_info = get_user_agent_info()\n        print(agent_info)\n\n    print(\"Outside context.\")\n    # Trying to call get_user_agent_info() here would fail because\n    # the request context has been popped.\n\n```\n\n----------------------------------------\n\nTITLE: Instantiating PlanningFlow via Factory Pattern in Python\nDESCRIPTION: This Python snippet uses the factory pattern to instantiate specific execution flows (e.g., PlanningFlow) based on an enumeration type. The FlowFactory class maps flow types to their corresponding classes and creates them with supplied agents and kwargs. This design supports easy extension of new flow types; requires the Enum class and appropriate flow and agent modules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/flow/flow_factory.py\\nfrom enum import Enum\\nfrom app.agent.base import BaseAgent\\nfrom app.flow.base import BaseFlow\\nfrom app.flow.planning import PlanningFlow # Import specific flows\\n\\nclass FlowType(str, Enum):\\n    PLANNING = \\\"planning\\\" # Add other flow types here\\n\\nclass FlowFactory:\\n    @staticmethod\\n    def create_flow(flow_type: FlowType, agents, **kwargs) -> BaseFlow:\\n        flows = { # Maps type enum to the actual class\\n            FlowType.PLANNING: PlanningFlow,\\n        }\\n        flow_class = flows.get(flow_type)\\n        if not flow_class:\\n            raise ValueError(f\\\"Unknown flow type: {flow_type}\\\")\\n        # Creates an instance of PlanningFlow(agents, **kwargs)\\n        return flow_class(agents, **kwargs)\\n\n```\n\n----------------------------------------\n\nTITLE: Manually Pushing Flask Application Context for Script Access (Python)\nDESCRIPTION: This Python script demonstrates manually pushing a Flask application context using `with app.app_context()`. This allows access to application-specific resources like `current_app.config` outside the normal request-response cycle, typically needed for utility scripts like database initialization or background tasks. It imports the Flask `app` object and uses the context manager to safely access configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/07_application_and_request_contexts.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# init_db.py (Example script to run from command line)\n\nfrom flask import Flask\n\n# Assume your main Flask app object is defined in hello.py\n# We need to import it here.\n# In a real project, you'd structure this better, maybe using a factory function.\ntry:\n    # Let's assume hello.py has app = Flask(__name__)\n    from hello import app\nexcept ImportError:\n    print(\"Could not import 'app' from hello.py\")\n    print(\"Make sure hello.py exists and defines the Flask app.\")\n    exit(1)\n\n# Define a function that needs app access\ndef setup_database():\n    # We need an application context to access current_app.config\n    # Without the 'with' block, current_app would not be available here.\n    with app.app_context():\n        # Now we can safely access app configuration via current_app\n        db_uri = app.config.get('DATABASE_URI', 'No DB URI Set!')\n        print(f\"Inside app context: Accessing config...\")\n        print(f\"Database URI found: {db_uri}\")\n        # Imagine database setup code here that uses the URI\n        print(\"Database initialization logic would run here.\")\n\n# ---- Main execution part of the script ----\nif __name__ == \"__main__\":\n    print(\"Running database setup script...\")\n    setup_database()\n    print(\"Script finished.\")\n\n```\n\n----------------------------------------\n\nTITLE: Building a LangGraph Workflow with Checkpointer - Python\nDESCRIPTION: Shows construction of a LangGraph state graph involving planning, approval, and execution nodes, with memory checkpointing enabled for interrupt handling. Dependencies: langgraph.graph.StateGraph, langgraph.checkpoint.memory.MemorySaver, node functions (create_plan, request_approval, execute_plan), and an ApprovalState class. It demonstrates adding nodes, setting the entry point, linking nodes via directed edges, attaching a checkpointer, and compiling to produce an executable app.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.graph import StateGraph, END, START\n# Need a checkpointer for interrupts!\nfrom langgraph.checkpoint.memory import MemorySaver\n\nworkflow = StateGraph(ApprovalState)\n\nworkflow.add_node(\"planner\", create_plan)\nworkflow.add_node(\"approval_gate\", request_approval)\nworkflow.add_node(\"executor\", execute_plan)\n\nworkflow.set_entry_point(\"planner\")\nworkflow.add_edge(\"planner\", \"approval_gate\")\nworkflow.add_edge(\"approval_gate\", \"executor\") # Runs after interrupt is resolved\nworkflow.add_edge(\"executor\", END)\n\n# Create checkpointer and compile\nmemory_saver = MemorySaver()\napp = workflow.compile(checkpointer=memory_saver)\n```\n\n----------------------------------------\n\nTITLE: Injecting and Scheduling Background Tasks in FastAPI (Python)\nDESCRIPTION: Demonstrates a FastAPI path operation function (`send_notification`) that uses dependency injection to receive a `BackgroundTasks` instance. It then schedules the previously defined `write_log` function to run in the background using `background_tasks.add_task()`, passing the required `log_message`. The API response is returned immediately without waiting for the background task.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.post(\"/send-notification/{email}\")\nasync def send_notification(\n    email: str,\n    background_tasks: BackgroundTasks # Inject BackgroundTasks\n):\n    # The message we want to log in the background\n    log_message = f\"Notification sent to: {email}\"\n\n    # Add the task to run after the response\n    background_tasks.add_task(write_log, log_message) # Schedule write_log\n\n    # Return the response immediately\n    return {\"message\": \"Notification sent successfully!\"}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Prompt.render in Python\nDESCRIPTION: A simplified implementation of the Prompt.render method, which validates arguments, calls the stored function, and processes the function's return value into a list of Message objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass Prompt:\n    # ... (init, from_function, PromptArgument) ...\n\n    async def render(self, arguments=None):\n        # Validate required arguments...\n        # ...\n\n        try:\n            # Call the original decorated function\n            result = self.fn(**(arguments or {}))\n            if inspect.iscoroutine(result): # Handle async functions\n                result = await result\n\n            # Convert result to list of Message objects\n            # (Handles strings, dicts, Message objects, lists)\n            messages: list[Message] = []\n            # ... (conversion logic using message_validator) ...\n            return messages\n        except Exception as e:\n            raise ValueError(f\"Error rendering prompt {self.name}: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Converting Models to Dictionaries with model_dump()\nDESCRIPTION: Example showing how to convert a Pydantic model back to a Python dictionary using the model_dump() method. This is useful for serialization and data interchange.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from the user_alice example:\nuser_dict = user_alice.model_dump()\n\nprint(user_dict)\n# Expected Output: {'name': 'Alice', 'age': 30}\nprint(type(user_dict))\n# Expected Output: <class 'dict'>\n```\n\n----------------------------------------\n\nTITLE: HTTPException Handling Flow in FastAPI (Mermaid Sequence Diagram)\nDESCRIPTION: Visualizes how FastAPI handles HTTPException errors using a sequence diagram. The process demonstrates the interaction between the route handler, FastAPI's exception handling system, and the client, including steps for catching and formatting the error into a JSON response. Best viewed with a Mermaid-compatible renderer.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_8\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastAPIApp as FastAPI App\n    participant RouteHandler as Route Handler (read_item)\n    participant DefaultHTTPExceptionHandler as Default HTTPException Handler\n\n    Client->>+FastAPIApp: GET /items/99\n    FastAPIApp->>+RouteHandler: Call read_item(item_id=99)\n    RouteHandler->>RouteHandler: Check DB: item 99 not found\n    RouteHandler-->>-FastAPIApp: raise HTTPException(404, \"Item not found\")\n    Note over FastAPIApp: Catches HTTPException\n    FastAPIApp->>+DefaultHTTPExceptionHandler: Handle the exception instance\n    DefaultHTTPExceptionHandler->>DefaultHTTPExceptionHandler: Extract status_code=404, detail=\"Item not found\"\n    DefaultHTTPExceptionHandler-->>-FastAPIApp: Return JSONResponse(status=404, content={\"detail\": \"...\"})\n    FastAPIApp-->>-Client: Send 404 JSON Response\n\n```\n\n----------------------------------------\n\nTITLE: Defining BFS Deep Crawl Strategy in Crawl4AI (Python)\nDESCRIPTION: This snippet provides the Python class BFSDeepCrawlStrategy, extending DeepCrawlStrategy to implement a breadth-first search website crawler for the Crawl4AI framework. It initializes with crawling depth, a filter chain, and a URL scorer, then defines asynchronous methods for validating URLs, discovering new links from crawled results, and running the crawler in either batch or streaming mode. Dependencies include DeepCrawlStrategy, FilterChain, crawler instance, runtime config objects, and optionally URL scoring logic. Inputs like start_url, max_depth, and configuration objects are used to orchestrate level-wise crawling; methods emit a list of CrawlResult instances or async generator streams. Constraints include enforcement of max_depth and deduplication of visited URLs to avoid redundant crawling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/08_deepcrawlstrategy.md#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom .base_strategy import DeepCrawlStrategy # Import the base class\n\nclass BFSDeepCrawlStrategy(DeepCrawlStrategy):\n    def __init__(self, max_depth, filter_chain=None, url_scorer=None, ...):\n        self.max_depth = max_depth\n        self.filter_chain = filter_chain or FilterChain() # Use default if none\n        self.url_scorer = url_scorer\n        # ... other init ...\n        self._pages_crawled = 0\n\n    async def can_process_url(self, url: str, depth: int) -> bool:\n        # ... (validation logic using self.filter_chain) ...\n        is_valid = True # Placeholder\n        if depth != 0 and not await self.filter_chain.apply(url):\n            is_valid = False\n        return is_valid\n\n    async def link_discovery(self, result, source_url, current_depth, visited, next_level, depths):\n        # ... (logic to get links from result.links) ...\n        links = result.links.get(\"internal\", []) # Example: only internal\n        for link_data in links:\n            url = link_data.get(\"href\")\n            if url and url not in visited:\n                if await self.can_process_url(url, current_depth + 1):\n                    # Check scoring, max_pages limit etc.\n                    depths[url] = current_depth + 1\n                    next_level.append((url, source_url)) # Add (url, parent) tuple\n\n    async def _arun_batch(self, start_url, crawler, config) -> List[CrawlResult]:\n        visited = set()\n        current_level = [(start_url, None)] # List of (url, parent_url)\n        depths = {start_url: 0}\n        all_results = []\n\n        while current_level: # While there are pages in the current level\n            next_level = []\n            urls_in_level = [url for url, parent in current_level]\n            visited.update(urls_in_level)\n\n            # Create config for this batch (no deep crawl recursion)\n            batch_config = config.clone(deep_crawl_strategy=None, stream=False)\n            # Crawl all URLs in the current level\n            batch_results = await crawler.arun_many(urls=urls_in_level, config=batch_config)\n\n            for result in batch_results:\n                # Add metadata (depth, parent)\n                depth = depths.get(result.url, 0)\n                result.metadata = result.metadata or {}\n                result.metadata[\"depth\"] = depth\n                # ... find parent ...\n                all_results.append(result)\n                # Discover links for the *next* level\n                if result.success:\n                     await self.link_discovery(result, result.url, depth, visited, next_level, depths)\n\n            current_level = next_level # Move to the next level\n\n        return all_results\n\n    async def _arun_stream(self, start_url, crawler, config) -> AsyncGenerator[CrawlResult, None]:\n        # Similar logic to _arun_batch, but uses 'yield result'\n        # and processes results as they come from arun_many stream\n        visited = set()\n        current_level = [(start_url, None)] # List of (url, parent_url)\n        depths = {start_url: 0}\n\n        while current_level:\n             next_level = []\n             urls_in_level = [url for url, parent in current_level]\n             visited.update(urls_in_level)\n\n             # Use stream=True for arun_many\n             batch_config = config.clone(deep_crawl_strategy=None, stream=True)\n             batch_results_gen = await crawler.arun_many(urls=urls_in_level, config=batch_config)\n\n             async for result in batch_results_gen:\n                  # Add metadata\n                  depth = depths.get(result.url, 0)\n                  result.metadata = result.metadata or {}\n                  result.metadata[\"depth\"] = depth\n                  # ... find parent ...\n                  yield result # Yield result immediately\n                  # Discover links for the next level\n                  if result.success:\n                      await self.link_discovery(result, result.url, depth, visited, next_level, depths)\n\n             current_level = next_level\n    # ... shutdown method ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent State Management in Python for AutoGen Core\nDESCRIPTION: This code extends the Agent Protocol with state management capabilities, allowing agents to save and load their internal memory. The save_state method serializes the agent's memory into a mapping, while load_state restores the agent's state from a previously saved mapping.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# From: _agent.py (Simplified Agent Protocol)\nclass Agent(Protocol):\n    # ... other methods\n\n    async def save_state(self) -> Mapping[str, Any]:\n        \"\"\"Save the agent's internal memory.\"\"\"\n        # Return a dictionary representing the state\n        ...\n\n    async def load_state(self, state: Mapping[str, Any]) -> None:\n        \"\"\"Load the agent's internal memory.\"\"\"\n        # Restore state from the dictionary\n        ...\n```\n\n----------------------------------------\n\nTITLE: Conceptual Celery Worker Message Handling Loop in Python\nDESCRIPTION: A simplified Python code snippet representing the core logic within a Celery worker's consumer. It demonstrates the fundamental cycle of receiving a message, decoding it to find the task and arguments, dispatching it to an execution pool, handling the result (including optional storage in a backend), and acknowledging the message to the broker upon success or rejecting it on failure. Note this is conceptual and omits many details of the actual implementation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/05_worker.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual loop inside the Consumer (highly simplified)\n\ndef message_handler(message):\n    try:\n        # 1. Decode message (task name, args, kwargs, id, etc.)\n        task_name, args, kwargs, task_id = decode_message(message.body, message.headers)\n\n        # 2. Find the registered task function\n        task_func = app.tasks[task_name]\n\n        # 3. Prepare execution request for the pool\n        request = TaskRequest(task_id, task_name, task_func, args, kwargs)\n\n        # 4. Send request to the pool for execution\n        #    (Pool runs request.execute() which calls task_func(*args, **kwargs))\n        pool.apply_async(request.execute, accept_callback=task_succeeded, ...)\n\n    except Exception as e:\n        # Handle errors (e.g., unknown task, decoding error)\n        log_error(e)\n        message.reject() # Tell broker it failed\n\ndef task_succeeded(task_id, retval):\n    # Called by the pool when task finishes successfully\n    # 5. Store result (optional)\n    if app.backend:\n        app.backend.store_result(task_id, retval, status='SUCCESS')\n\n    # 6. Acknowledge message to broker\n    message.ack()\n\n# --- Setup ---\n# Worker connects to broker and registers message_handler\n# for incoming messages on the subscribed queue(s)\nconnection.consume(queue_name, callback=message_handler)\n\n# Start the event loop to wait for messages\nconnection.drain_events()\n```\n\n----------------------------------------\n\nTITLE: User Profile Jinja Template for Flask Blueprint - HTML\nDESCRIPTION: This is a Jinja2 HTML template for rendering a user's profile in the Flask user blueprint context. It expects a variable 'user' with at least 'name' and 'email' fields. The template includes navigation using url_for to generate links to the user list and home routes. To function, it should be placed in 'templates/user/profile.html', and Flask must be set up with Jinja2 templating enabled. Expected input is a user dictionary, output is a rendered HTML profile page. Navigation depends on endpoint naming conventions established in the blueprint and app.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<!-- templates/user/profile.html -->\n<!doctype html>\n<html>\n<head><title>User Profile</title></head>\n<body>\n  <h1>Profile for {{ user.name }}</h1>\n  <p>Email: {{ user.email }}</p>\n  <p><a href=\"{{ url_for('user.user_list') }}\">Back to User List</a></p>\n  <p><a href=\"{{ url_for('home') }}\">Back to Home</a></p>\n</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Starting MultiStepAgent Execution with `run` in Python\nDESCRIPTION: Simplified `run` method for the `MultiStepAgent` class in `agents.py`. It serves as the entry point for executing a task. The method takes the `task` string, resets the agent's memory, records the initial task in memory, and then calls the internal `_run` method (which implements the core loop). It uses `deque` with `maxlen=1` to efficiently retrieve the final answer yielded by the `_run` generator.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified run) ---\nclass MultiStepAgent:\n    def run(self, task: str, ...):\n        self.task = task\n        # ... maybe handle additional arguments ...\n\n        # Reset memory if needed\n        self.memory.reset()\n        self.memory.steps.append(TaskStep(task=self.task)) # Record the task\n\n        # Start the internal execution loop\n        # The deque gets the *last* item yielded, which is the final answer\n        return deque(self._run(task=self.task, max_steps=self.max_steps), maxlen=1)[0].final_answer\n```\n\n----------------------------------------\n\nTITLE: Implementing __array_function__ for Custom Array Overrides (Python)\nDESCRIPTION: This code defines a basic Python class `MySimpleArray` that demonstrates how to implement the `__array_function__` protocol. The implementation intercepts calls to NumPy functions involving `MySimpleArray` instances. It specifically overrides `np.sum` to compute the sum using the internal data, while returning `NotImplemented` for other functions like `np.mean`, leading to a `TypeError` for unhandled functions. The example requires the `numpy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/08___array_function___protocol___overrides___overrides__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nclass MySimpleArray:\n    def __init__(self, data):\n        # Store data internally, maybe as a NumPy array for simplicity here\n        self._data = np.asarray(data)\n\n    # This is the magic method!\n    def __array_function__(self, func, types, args, kwargs):\n        print(f\"MySimpleArray.__array_function__ got called for {func.__name__}\")\n\n        if func is np.sum:\n            # Handle np.sum ourselves!\n            print(\"-> Handling np.sum internally!\")\n            # Convert args to NumPy arrays if they are MySimpleArray\n            np_args = [a._data if isinstance(a, MySimpleArray) else a for a in args]\n            np_kwargs = {k: v._data if isinstance(v, MySimpleArray) else v for k, v in kwargs.items()}\n            # Perform the actual sum using NumPy on the internal data\n            return np.sum(*np_args, **np_kwargs)\n        else:\n            # For any other function, say we don't handle it\n            print(f\"-> Don't know how to handle {func.__name__}, returning NotImplemented.\")\n            return NotImplemented\n\n    # Make it look a bit like an array for printing\n    def __repr__(self):\n        return f\"MySimpleArray({self._data})\"\n\n# --- Try it out ---\nmy_arr = MySimpleArray([1, 2, 3, 4])\nprint(\"Array:\", my_arr)\n\n# Call np.sum\nprint(\"\\nCalling np.sum(my_arr):\")\ntotal = np.sum(my_arr)\nprint(\"Result:\", total)\n\n# Call np.mean (which our class doesn't handle)\nprint(\"\\nCalling np.mean(my_arr):\")\ntry:\n    mean_val = np.mean(my_arr)\n    print(\"Result:\", mean_val)\nexcept TypeError as e:\n    print(\"Caught expected TypeError:\", e)\n```\n\nLANGUAGE: output\nCODE:\n```\nArray: MySimpleArray([1 2 3 4])\n\nCalling np.sum(my_arr):\nMySimpleArray.__array_function__ got called for sum\n-> Handling np.sum internally!\nResult: 10\n\nCalling np.mean(my_arr):\nMySimpleArray.__array_function__ got called for mean\n-> Don't know how to handle mean, returning NotImplemented.\nCaught expected TypeError: no implementation found for 'numpy.mean' on types that implement __array_function__: [<class '__main__.MySimpleArray'>]\n```\n\n----------------------------------------\n\nTITLE: Supplying Few-Shot Examples to dspy.Predict in Python\nDESCRIPTION: This snippet illustrates few-shot learning by constructing dspy.Example objects and passing them as demos to the Predict module. Dependencies: dspy and the earlier TranslateToFrench signature. Each example provides paired inputs/outputs to guide the LM. The code invokes the predictor with both the target input and the demos list, encouraging better LM response formatting. Inputs: input sentence, list of examples; Output: prediction object with the translated text.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/04_predict.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create some example translations (from Chapter 3)\ndemo1 = dspy.Example(english_sentence=\"Good morning!\", french_sentence=\"Bonjour!\")\ndemo2 = dspy.Example(english_sentence=\"Thank you.\", french_sentence=\"Merci.\")\n\n# Our translator module (same as before)\ntranslator = dspy.Predict(TranslateToFrench)\n\n# Input we want to translate\nenglish_input = \"See you later.\"\n\n# Call the predictor, this time providing demos\nresult_with_demos = translator(\n    english_sentence=english_input,\n    demos=[demo1, demo2] # Pass our examples here!\n)\n\nprint(f\"English: {english_input}\")\nprint(f\"French (with demos): {result_with_demos.french_sentence}\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom EchoTool in Python\nDESCRIPTION: This snippet demonstrates how to create a custom EchoTool by inheriting from BaseTool. It defines the tool's name, description, parameters, and implements the execute method to echo the input message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/04_tool___toolcollection.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom app.tool.base import BaseTool, ToolResult\n\nclass EchoTool(BaseTool):\n    \"\"\"A simple tool that echoes the input text.\"\"\"\n\n    name: str = \"echo_message\"\n    description: str = \"Repeats back the text provided in the 'message' parameter.\"\n    parameters: dict = {\n        \"type\": \"object\",\n        \"properties\": {\n            \"message\": {\n                \"type\": \"string\",\n                \"description\": \"The text to be echoed back.\",\n            },\n        },\n        \"required\": [\"message\"],\n    }\n\n    async def execute(self, message: str) -> ToolResult:\n        \"\"\"Takes a message and returns it.\"\"\"\n        print(f\"EchoTool executing with message: '{message}'\")\n        return ToolResult(output=f\"You said: {message}\")\n\necho_tool_instance = EchoTool()\n\nprint(f\"Tool Name: {echo_tool_instance.name}\")\nprint(f\"Tool Description: {echo_tool_instance.description}\")\n```\n\n----------------------------------------\n\nTITLE: Protecting Endpoint with HTTP Basic Auth using Security() - FastAPI - Python\nDESCRIPTION: This snippet shows how to secure a FastAPI route using HTTP Basic authentication with the Security dependency system. By applying Security(get_current_username), requests to '/users/me' require valid basic credentials; upon success, the username is returned in a JSON response. Dependencies are FastAPI, the verifier dependency function from earlier, and typing.Annotated; no additional parameters other than the injected username, output is a dict containing the username.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@app.get(\"/users/me\")\nasync def read_current_user(\n    # Use Security() with the verifier function\n    username: Annotated[str, Security(get_current_username)]\n):\n    # If the code reaches here, get_current_username ran successfully\n    # and returned the validated username.\n    # 'username' variable now holds the result from get_current_username.\n    return {\"username\": username}\n\n```\n\n----------------------------------------\n\nTITLE: Storing Messages in Memory using OpenManus\nDESCRIPTION: This code snippet shows how to create a Memory instance and add Message objects to it using the Memory class from app/schema.py in OpenManus.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import Memory and Message\nfrom app.schema import Message, Memory\n\n# Create a Memory instance\nconversation_memory = Memory()\n\n# Add messages to the memory\nconversation_memory.add_message(\n    Message.system_message(\"You are a helpful geography expert.\")\n)\nconversation_memory.add_message(\n    Message.user_message(\"What's the capital of France?\")\n)\nconversation_memory.add_message(\n    Message.assistant_message(\"The capital of France is Paris.\")\n)\nconversation_memory.add_message(\n    Message.user_message(\"What about Spain?\")\n)\n\n\n# See the messages stored\nprint(f\"Number of messages in memory: {len(conversation_memory.messages)}\")\n# Print the last message\nprint(f\"Last message: {conversation_memory.messages[-1].to_dict()}\")\n```\n\n----------------------------------------\n\nTITLE: Defining an Image Generation Tool in Python using SmolaAgents\nDESCRIPTION: This snippet demonstrates how to create an ImageGeneratorTool class that generates an image based on a text prompt. It shows the crucial step of setting the output_type to 'image' and how the framework automatically wraps the output in an AgentImage container.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/07_agenttype.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: image_tool.py ---\nfrom smolagents import Tool\nfrom PIL import Image\n# Assume 'diffusion_pipeline' is a pre-loaded image generation model\n# from diffusers import DiffusionPipeline\n# diffusion_pipeline = DiffusionPipeline.from_pretrained(...)\n\nclass ImageGeneratorTool(Tool):\n    name: str = \"image_generator\"\n    description: str = \"Generates an image based on a text prompt.\"\n    inputs: dict = {\n        \"prompt\": {\n            \"type\": \"string\",\n            \"description\": \"The text description for the image.\"\n        }\n    }\n    # Tell the framework this tool outputs an image!\n    output_type: str = \"image\" # <--- Crucial Hint!\n\n    def forward(self, prompt: str) -> Image.Image:\n        \"\"\"Generates the image using a diffusion model.\"\"\"\n        print(f\"--- ImageGeneratorTool generating image for: '{prompt}' ---\")\n        # image = diffusion_pipeline(prompt).images[0] # Actual generation\n        # For simplicity, let's create a dummy blank image\n        image = Image.new('RGB', (60, 30), color = 'red')\n        print(f\"--- Tool returning a PIL Image object ---\")\n        return image\n\n# --- How the framework uses it (conceptual) ---\nimage_tool = ImageGeneratorTool()\nprompt = \"A red rectangle\"\nraw_output = image_tool(prompt=prompt) # Calls forward(), gets a PIL.Image object\n\n# Framework automatically wraps the output because output_type=\"image\"\n# Uses handle_agent_output_types(raw_output, output_type=\"image\")\nfrom smolagents.agent_types import handle_agent_output_types\nwrapped_output = handle_agent_output_types(raw_output, output_type=\"image\")\n\nprint(f\"Raw output type: {type(raw_output)}\")\nprint(f\"Wrapped output type: {type(wrapped_output)}\")\n\n# When storing in memory or logging, the framework calls to_string()\noutput_string = wrapped_output.to_string()\nprint(f\"String representation for logs: {output_string}\")\n\n# Expected Output (path will vary):\n# --- ImageGeneratorTool generating image for: 'A red rectangle' ---\n# --- Tool returning a PIL Image object ---\n# Raw output type: <class 'PIL.Image.Image'>\n# Wrapped output type: <class 'smolagents.agent_types.AgentImage'>\n# String representation for logs: /tmp/tmpxxxxxx/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.png\n```\n\n----------------------------------------\n\nTITLE: Writing to WAL in LevelDB DBImpl\nDESCRIPTION: Example showing how LevelDB writes to the WAL before updating MemTable, ensuring durability of writes even in case of crashes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/03_write_ahead_log__wal____logwriter_logreader.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\nStatus status = log_->AddRecord(WriteBatchInternal::Contents(write_batch));\n// ... check status ...\nif (status.ok() && options.sync) {\n  // Optionally ensure the data hits the physical disk\n  status = logfile_->Sync();\n}\nif (status.ok()) {\n  // Only if WAL write succeeded, apply to MemTable\n  status = WriteBatchInternal::InsertInto(write_batch, mem_);\n}\n// ... handle status ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing CrewAI Memory Context Gathering Flow - Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the end-to-end flow of how Crew, Agent, and various memory modules (ShortTermMemory, EntityMemory) interact to augment task context before calling the agent's LLM. The visualization highlights the sequence of context gathering, prompt assembly, LLM response, and memory updates in the lifecycle of a CrewAI task. There are no software dependencies; render with a Mermaid-compatible viewer.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/07_memory.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant C as Crew\\n    participant A as Agent\\n    participant CtxMem as ContextualMemory\\n    participant STM as ShortTermMemory\\n    participant EM as EntityMemory\\n    participant LLM as Agent\\'s LLM\\n\\n    C->>A: Execute Task(description, current_context)\\n    Note over A: Need to build full prompt context.\\n    A->>CtxMem: Get memory context for task query\\n    CtxMem->>STM: Search(task_query)\\n    STM-->>CtxMem: Recent memories (e.g., \\\"Found Lisbon earlier\\\")\\n    CtxMem->>EM: Search(task_query)\\n    EM-->>CtxMem: Entity details (e.g., \\\"Lisbon: Capital of Portugal\\\")\\n    CtxMem-->>A: Combined Memory Snippets\\n    A->>A: Assemble Final Prompt (Task Desc + Current Context + Memory Snippets)\\n    A->>LLM: Process Augmented Prompt\\n    LLM-->>A: Generate Response\\n    A-->>C: Task Result\\n    Note over C: Crew updates memories (STM, EM) with task results.\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing AsyncPlaywrightCrawlerStrategy for Browser-Based Web Crawling in Python\nDESCRIPTION: A class that implements the AsyncCrawlerStrategy interface using Playwright to perform browser-based web crawling. It manages browser instances, navigates to URLs, waits for content to load, executes JavaScript, and returns the processed HTML content along with optional screenshots.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass AsyncPlaywrightCrawlerStrategy(AsyncCrawlerStrategy):\n    # ... (Initialization code to manage browsers)\n\n    async def crawl(self, url: str, config: CrawlerRunConfig, **kwargs) -> AsyncCrawlResponse:\n        # Uses Playwright to:\n        # 1. Get a browser page\n        # 2. Navigate to the url (page.goto(url))\n        # 3. Wait for content, run JS, etc.\n        # 4. Get the final HTML (page.content())\n        # 5. Optionally take screenshots, etc.\n        # 6. Return an AsyncCrawlResponse\n        # ... implementation details ...\n        pass\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry from Python Code\nDESCRIPTION: Demonstrates how to disable telemetry programmatically in Python by setting the ANONYMIZED_TELEMETRY environment variable to False before importing the browser_use module.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ['ANONYMIZED_TELEMETRY'] = 'False'\n\n# Now import and use browser_use\nfrom browser_use import Agent # ... other imports\n# ... rest of your script ...\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom API Key Authentication Handler in Python Requests\nDESCRIPTION: This Python snippet defines a class `MyCustomApiKeyAuth` that inherits from `requests.auth.AuthBase`. It implements a custom authentication mechanism by overriding the `__call__` method to add a custom 'X-API-Key' header to the outgoing `PreparedRequest` object. This allows for flexible authentication schemes beyond the built-in ones.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom requests.auth import AuthBase\n\nclass MyCustomApiKeyAuth(AuthBase):\n    \"\"\"Attaches a custom API Key header to the request.\"\"\"\n    def __init__(self, api_key):\n        self.api_key = api_key\n\n    def __call__(self, r):\n        # 'r' is the PreparedRequest object\n        # Modify the request 'r' here. We'll add a header.\n        r.headers['X-API-Key'] = self.api_key\n        # We MUST return the modified request object\n        return r\n\n# Usage:\n# api_key = \"YOUR_SECRET_API_KEY\"\n# response = requests.get(some_url, auth=MyCustomApiKeyAuth(api_key))\n```\n\n----------------------------------------\n\nTITLE: AsyncWebCrawler Class Implementation in Python\nDESCRIPTION: A simplified version of the AsyncWebCrawler class, showing its structure, initialization, and key methods like arun and arun_many. It demonstrates how the class coordinates different components of the crawling process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/02_asyncwebcrawler.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from async_webcrawler.py\n\n# ... imports ...\nfrom .async_crawler_strategy import AsyncCrawlerStrategy, AsyncPlaywrightCrawlerStrategy\nfrom .async_configs import BrowserConfig, CrawlerRunConfig\nfrom .models import CrawlResult\nfrom .cache_context import CacheContext, CacheMode\n# ... other strategy imports ...\n\nclass AsyncWebCrawler:\n    def __init__(\n        self,\n        crawler_strategy: AsyncCrawlerStrategy = None, # You can provide a strategy...\n        config: BrowserConfig = None, # Configuration for the browser\n        # ... other parameters like logger, base_directory ...\n    ):\n        # If no strategy is given, it defaults to Playwright (the 'truck')\n        self.crawler_strategy = crawler_strategy or AsyncPlaywrightCrawlerStrategy(...)\n        self.browser_config = config or BrowserConfig()\n        # ... setup logger, directories, etc. ...\n        self.ready = False # Flag to track if setup is complete\n\n    async def __aenter__(self):\n        # This is called when you use 'async with'. It starts the strategy.\n        await self.crawler_strategy.__aenter__()\n        await self.awarmup() # Perform internal setup\n        self.ready = True\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        # This is called when exiting 'async with'. It cleans up.\n        await self.crawler_strategy.__aexit__(exc_type, exc_val, exc_tb)\n        self.ready = False\n\n    async def arun(self, url: str, config: CrawlerRunConfig = None) -> CrawlResult:\n        # 1. Ensure config exists, set defaults (like CacheMode.ENABLED)\n        crawler_config = config or CrawlerRunConfig()\n        if crawler_config.cache_mode is None:\n            crawler_config.cache_mode = CacheMode.ENABLED\n\n        # 2. Create CacheContext to manage caching logic\n        cache_context = CacheContext(url, crawler_config.cache_mode)\n\n        # 3. Try reading from cache if allowed\n        cached_result = None\n        if cache_context.should_read():\n            cached_result = await async_db_manager.aget_cached_url(url)\n\n        # 4. If cache hit and valid, return cached result\n        if cached_result and self._is_cache_valid(cached_result, crawler_config):\n             # ... log cache hit ...\n             return cached_result\n\n        # 5. If no cache hit or cache invalid/bypassed: Fetch fresh content\n        #    Delegate to the configured AsyncCrawlerStrategy\n        async_response = await self.crawler_strategy.crawl(url, config=crawler_config)\n\n        # 6. Process the HTML (scrape, filter, extract)\n        #    This involves calling other strategies based on config\n        crawl_result = await self.aprocess_html(\n            url=url,\n            html=async_response.html,\n            config=crawler_config,\n            # ... other details from async_response ...\n        )\n\n        # 7. Write to cache if allowed\n        if cache_context.should_write():\n            await async_db_manager.acache_url(crawl_result)\n\n        # 8. Return the final CrawlResult\n        return crawl_result\n\n    async def aprocess_html(self, url: str, html: str, config: CrawlerRunConfig, ...) -> CrawlResult:\n        # This internal method handles:\n        # - Getting the configured ContentScrapingStrategy\n        # - Calling its 'scrap' method\n        # - Getting the configured MarkdownGenerationStrategy\n        # - Calling its 'generate_markdown' method\n        # - Getting the configured ExtractionStrategy (if any)\n        # - Calling its 'run' method\n        # - Packaging everything into a CrawlResult\n        # ... implementation details ...\n        pass # Simplified\n\n    async def arun_many(self, urls: List[str], config: Optional[CrawlerRunConfig] = None, ...) -> List[CrawlResult]:\n        # Uses a Dispatcher (like MemoryAdaptiveDispatcher)\n        # to run self.arun for each URL concurrently.\n        # ... implementation details using a dispatcher ...\n        pass # Simplified\n\n    # ... other methods like awarmup, close, caching helpers ...\n```\n\n----------------------------------------\n\nTITLE: LevelDB Component Relationship Diagram\nDESCRIPTION: A flowchart showing the relationships and interactions between key LevelDB components including DBImpl, MemTable, SSTables, Version management, Write-Ahead Log, Iterator, WriteBatch, Compaction, and Internal Key formatting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"DBImpl\"]\n    A1[\"MemTable\"]\n    A2[\"Table / SSTable & TableCache\"]\n    A3[\"Version & VersionSet\"]\n    A4[\"Write-Ahead Log (WAL) & LogWriter/LogReader\"]\n    A5[\"Iterator\"]\n    A6[\"WriteBatch\"]\n    A7[\"Compaction\"]\n    A8[\"InternalKey & DBFormat\"]\n    A0 -- \"Manages active/immutable\" --> A1\n    A0 -- \"Uses Cache for reads\" --> A2\n    A0 -- \"Manages DB state\" --> A3\n    A0 -- \"Writes to Log\" --> A4\n    A0 -- \"Applies Batches\" --> A6\n    A0 -- \"Triggers/Runs Compaction\" --> A7\n    A1 -- \"Provides Iterator\" --> A5\n    A1 -- \"Stores Keys Using\" --> A8\n    A2 -- \"Provides Iterator via Cache\" --> A5\n    A3 -- \"References SSTables\" --> A2\n    A3 -- \"Picks Files For\" --> A7\n    A4 -- \"Recovers MemTable From\" --> A1\n    A4 -- \"Contains Batch Data\" --> A6\n    A5 -- \"Parses/Hides InternalKey\" --> A8\n    A6 -- \"Inserts Into\" --> A1\n    A7 -- \"Builds SSTables\" --> A2\n    A7 -- \"Updates Versions Via Edit\" --> A3\n    A7 -- \"Uses Iterator for Merging\" --> A5\n```\n\n----------------------------------------\n\nTITLE: Creating FunctionTool for Date Function\nDESCRIPTION: Demonstrates how to wrap a Python function as a FunctionTool with proper schema and description for LLM use.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom autogen_core.tools import FunctionTool\nfrom get_date_function import get_current_date\n\ndate_tool = FunctionTool(\n    func=get_current_date,\n    description=\"Use this tool to get the current date in YYYY-MM-DD format.\"\n)\n\nprint(f\"Tool Name: {date_tool.name}\")\nprint(f\"Tool Description: {date_tool.description}\")\n```\n\n----------------------------------------\n\nTITLE: Defining ComponentModel Structure in Python\nDESCRIPTION: This snippet shows the conceptual structure of the ComponentModel class, which is used as the standard package format for saving and loading components in AutoGen Core.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# From: _component_config.py (Conceptual Structure)\nfrom pydantic import BaseModel\nfrom typing import Dict, Any\n\nclass ComponentModel(BaseModel):\n    provider: str # Path to the class (e.g., \"autogen_core.memory.ListMemory\")\n    config: Dict[str, Any] # The specific settings for this instance\n    component_type: str | None = None # Role (e.g., \"memory\")\n    # ... other fields like version, description, label ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Tool Execution Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram illustrating the typical flow when an LLM agent decides to use a tool managed by a ToolAgent. It shows the interaction between the LLM Agent, Caller Agent, ToolAgent, and Tool Function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant LLMA as LLM Agent (Decides)\n    participant Caller as Caller Agent (Orchestrates)\n    participant ToolA as ToolAgent (Executes)\n    participant ToolFunc as Tool Function (e.g., get_current_date)\n\n    Note over LLMA: Analyzes conversation, decides tool needed.\n    LLMA->>Caller: Sends AssistantMessage containing FunctionCall(name='get_current_date', args='{}')\n    Note over Caller: Receives LLM response, sees FunctionCall.\n    Caller->>+ToolA: Uses runtime.send_message(message=FunctionCall, recipient=ToolAgent_ID)\n    Note over ToolA: Receives FunctionCall via on_message.\n    ToolA->>ToolA: Looks up 'get_current_date' in its internal list of Tools.\n    ToolA->>+ToolFunc: Calls tool.run_json(args={}) -> triggers get_current_date()\n    ToolFunc-->>-ToolA: Returns the result (e.g., \"2023-10-27\")\n    ToolA->>ToolA: Creates FunctionExecutionResult message with the content.\n    ToolA-->>-Caller: Returns FunctionExecutionResult via runtime messaging.\n    Note over Caller: Receives the tool result.\n    Caller->>LLMA: Sends FunctionExecutionResultMessage to LLM for next step.\n    Note over LLMA: Now knows the current date.\n```\n\n----------------------------------------\n\nTITLE: Adding Defined Functions as Nodes to a LangGraph StateGraph in Python\nDESCRIPTION: Demonstrates the process of incorporating defined functions as nodes into a LangGraph workflow. It first imports `StateGraph` and instantiates it, linking it to the previously defined `MyState` structure. Then, it uses the `workflow.add_node` method twice to register the `add_one` function under the name \"adder\" and the `multiply_by_two` function under the name \"multiplier\". This step assigns the functions as computational units within the graph, identifiable by their names for later edge connections.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n```python\nfrom langgraph.graph import StateGraph\n\n# Create the graph builder linked to our state\nworkflow = StateGraph(MyState)\n\n# Add the first node:\n# Give it the name \"adder\" and tell it to use the 'add_one' function\nworkflow.add_node(\"adder\", add_one)\n\n# Add the second node:\n# Give it the name \"multiplier\" and tell it to use the 'multiply_by_two' function\nworkflow.add_node(\"multiplier\", multiply_by_two)\n\n# (Edges like set_entry_point, add_edge, etc. define the flow *between* nodes)\n# ... add edges and compile ...\n```\n```\n\n----------------------------------------\n\nTITLE: Creating and Configuring ListMemory in Python\nDESCRIPTION: This code demonstrates how to create an instance of ListMemory, which is designed as a Component in AutoGen Core, and add some content to it.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: create_memory_component.py\nimport asyncio\nfrom autogen_core.memory import ListMemory, MemoryContent\n\n# Create an instance of ListMemory\nmy_memory = ListMemory(name=\"user_prefs_v1\")\n\n# Add some content (from Chapter 7 example)\nasync def add_content():\n    pref = MemoryContent(content=\"Use formal style\", mime_type=\"text/plain\")\n    await my_memory.add(pref)\n    print(f\"Created memory '{my_memory.name}' with content: {my_memory.content}\")\n\nasyncio.run(add_content())\n# Output: Created memory 'user_prefs_v1' with content: [MemoryContent(content='Use formal style', mime_type='text/plain', metadata=None)]\n```\n\n----------------------------------------\n\nTITLE: Implementing ReadRecord Method in LevelDB LogReader\nDESCRIPTION: This code shows the implementation of the ReadRecord method in log::Reader, which reads and reassembles logical records from physical records in the WAL file. It handles different record types (full, first, middle, last) and manages the reassembly of fragmented records.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/03_write_ahead_log__wal____logwriter_logreader.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/log_reader.cc ---\n\n// Reads the next complete logical record. Returns true if successful.\nbool Reader::ReadRecord(Slice* record, std::string* scratch) {\n  // ... skip records before initial_offset if necessary ...\n\n  scratch->clear();\n  record->clear();\n  bool in_fragmented_record = false;\n\n  Slice fragment; // To hold data from one physical record\n  while (true) {\n    // Reads the next physical record (header + data fragment) from the file blocks.\n    // Handles reading across block boundaries internally.\n    const unsigned int record_type = ReadPhysicalRecord(&fragment);\n\n    // ... handle resyncing logic after seeking ...\n\n    switch (record_type) {\n      case kFullType:\n        // ... sanity check for unexpected fragments ...\n        *record = fragment; // Got a complete record in one piece\n        return true;\n\n      case kFirstType:\n        // ... sanity check for unexpected fragments ...\n        scratch->assign(fragment.data(), fragment.size()); // Start of a new fragmented record\n        in_fragmented_record = true;\n        break;\n\n      case kMiddleType:\n        if (!in_fragmented_record) { /* Report corruption */ }\n        else { scratch->append(fragment.data(), fragment.size()); } // Append middle piece\n        break;\n\n      case kLastType:\n        if (!in_fragmented_record) { /* Report corruption */ }\n        else {\n          scratch->append(fragment.data(), fragment.size()); // Append final piece\n          *record = Slice(*scratch); // Reassembled record is complete\n          return true;\n        }\n        break;\n\n      case kEof:\n        return false; // End of log file\n\n      case kBadRecord:\n        // ... report corruption, clear state ...\n        in_fragmented_record = false;\n        scratch->clear();\n        break; // Try to find the next valid record\n\n      default:\n        // ... report corruption ...\n        in_fragmented_record = false;\n        scratch->clear();\n        break; // Try to find the next valid record\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Memory in CrewAI Trip Planning Crew\nDESCRIPTION: This code snippet demonstrates how to create a Crew with memory enabled for a trip planning scenario. It sets up a Crew with researcher and planner agents, defines tasks, and activates memory features using the memory=True parameter.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/07_memory.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process\n\n# researcher = Agent(...)\n# planner = Agent(...)\n# task1 = Task(...)\n# task2 = Task(...)\n\n# Define the crew WITH memory enabled\ntrip_crew_with_memory = Crew(\n  agents=[researcher, planner],\n  tasks=[task1, task2],\n  process=Process.sequential,\n  memory=True  # <-- Enable memory features!\n  # verbose=2\n)\n\n# Start the work. Agents will now leverage memory.\n# result = trip_crew_with_memory.kickoff()\n# print(result)\n```\n\n----------------------------------------\n\nTITLE: Validating Directory Paths with Click's Path ParamType\nDESCRIPTION: This example demonstrates how to use click.Path to validate that a provided directory exists, is actually a directory (not a file), and is writable before processing begins.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# path_example.py\nimport click\n\n@click.command()\n@click.argument('output_dir', type=click.Path(exists=True, file_okay=False, dir_okay=True, writable=True))\ndef process(output_dir):\n    click.echo(f\"Processing data into directory: {output_dir}\")\n    # We know output_dir exists, is a directory, and is writable!\n\nif __name__ == '__main__':\n    process()\n```\n\n----------------------------------------\n\nTITLE: Implementing MCPServer in Python\nDESCRIPTION: This code snippet shows the MCPServer class, which registers tools with the FastMCP library and handles tool execution requests. It demonstrates how server-side tools are wrapped and exposed through the MCP protocol.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom app.tool.base import BaseTool\nfrom app.tool.bash import Bash # Import the tool to offer\nfrom app.logger import logger\nimport json\n\nclass MCPServer:\n    def __init__(self, name: str = \"openmanus\"):\n        self.server = FastMCP(name) # The underlying MCP server library\n        self.tools: Dict[str, BaseTool] = {}\n        # Add tools to offer\n        self.tools[\"bash\"] = Bash()\n        # ... add other tools like Browser, Editor ...\n\n    def register_tool(self, tool: BaseTool) -> None:\n        \"\"\"Registers a tool's execute method with the FastMCP server.\"\"\"\n        tool_name = tool.name\n        tool_param = tool.to_param() # Get schema for the LLM\n        tool_function = tool_param[\"function\"]\n\n        # Define the function that the MCP server will expose\n        async def tool_method(**kwargs):\n            logger.info(f\"Executing {tool_name} via MCP: {kwargs}\")\n            # Call the actual tool's execute method\n            result = await tool.execute(**kwargs)\n            logger.info(f\"Result of {tool_name}: {result}\")\n            # Return result (often needs conversion, e.g., to JSON)\n            return json.dumps(result.model_dump()) if hasattr(result, \"model_dump\") else str(result)\n\n        # Attach metadata (name, description, parameters) for discovery\n        tool_method.__name__ = tool_name\n        tool_method.__doc__ = self._build_docstring(tool_function)\n        tool_method.__signature__ = self._build_signature(tool_function)\n\n        # Register with the FastMCP library instance\n        self.server.tool()(tool_method)\n        logger.info(f\"Registered tool for MCP: {tool_name}\")\n\n    def register_all_tools(self):\n        for tool in self.tools.values():\n            self.register_tool(tool)\n\n    def run(self, transport: str = \"stdio\"):\n        self.register_all_tools()\n        logger.info(f\"Starting MCP server ({transport} mode)\")\n        self.server.run(transport=transport) # Start listening\n```\n\n----------------------------------------\n\nTITLE: Implementing Tool Calling in FastMCP Python Class\nDESCRIPTION: This snippet shows the implementation of the 'call_tool' method in the FastMCP class. It handles incoming 'callTool' requests by finding the appropriate tool in the ToolManager, executing it with the provided arguments, and converting the result to the expected MCP format.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass FastMCP:\n    # (...) other methods (...)\n\n    async def call_tool(\n        self, name: str, arguments: dict[str, Any]\n    ) -> Sequence[TextContent | ImageContent | EmbeddedResource]:\n        \"\"\"Call a tool by name with arguments.\"\"\"\n        # Gets a 'Context' object (more on this later!)\n        context = self.get_context()\n        # Asks the ToolManager to find and execute the tool\n        # The ToolManager handles finding your 'echo' function,\n        # validating arguments, and calling it.\n        result = await self._tool_manager.call_tool(name, arguments, context=context)\n        # Converts the function's return value (e.g., \"You said: Test\")\n        # into the format MCP expects for the response.\n        converted_result = _convert_to_content(result)\n        return converted_result\n\n    def _setup_handlers(self) -> None:\n        \"\"\"Set up core MCP protocol handlers.\"\"\"\n        # This line connects the low-level 'callTool' message\n        # to the 'self.call_tool' method shown above.\n        self._mcp_server.call_tool()(self.call_tool)\n        # (...) other handlers for listTools, readResource etc. (...)\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks for a Trip Planning Crew in Python\nDESCRIPTION: This code creates two Task instances for the trip planning Crew. Each task is assigned to a specific agent and includes a description and expected output.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/01_crew.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Define the tasks\ntask1 = Task(\n  description='Identify the top 3 European cities suitable for a sunny birthday trip in May.',\n  expected_output='A list of 3 cities with brief reasons.',\n  agent=researcher # Assign task1 to the researcher agent\n)\n\ntask2 = Task(\n  description='Based on the chosen city from task 1, create a 3-day activity plan.',\n  expected_output='A detailed itinerary for 3 days.',\n  agent=planner # Assign task2 to the planner agent\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing CrewAI LLM Interaction Logic in Python\nDESCRIPTION: Simplified Python code showing the structure of the `LLM` class in `crewai/llm.py`. It demonstrates how the class initializes with model parameters, prepares parameters for `litellm.completion` using `_prepare_completion_params` (including provider-specific formatting via `_format_messages_for_provider`), makes the core call to `litellm` within `_handle_non_streaming_response`, and handles potential tool calls returned by the LLM response using `_handle_tool_call`. This class acts as an abstraction layer over `litellm`, simplifying interaction with various LLMs for the CrewAI framework.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n```python\n# Simplified view from crewai/llm.py\n\n# Import litellm and other necessary modules\nimport litellm\nfrom typing import List, Dict, Optional, Union, Any\n\nclass LLM:\n    def __init__(self, model: str, temperature: Optional[float] = 0.7, **kwargs):\n        self.model = model\n        self.temperature = temperature\n        # ... store other parameters like max_tokens, api_key, base_url ...\n        self.additional_params = kwargs\n        self.stream = False # Default to non-streaming\n\n    def _prepare_completion_params(self, messages, tools=None) -> Dict[str, Any]:\n        # Formats messages based on provider (e.g., Anthropic)\n        formatted_messages = self._format_messages_for_provider(messages)\n\n        params = {\n            \"model\": self.model,\n            \"messages\": formatted_messages,\n            \"temperature\": self.temperature,\n            \"tools\": tools,\n            \"stream\": self.stream,\n            # ... add other stored parameters (max_tokens, api_key etc.) ...\n            **self.additional_params,\n        }\n        # Remove None values\n        return {k: v for k, v in params.items() if v is not None}\n\n    def call(self, messages, tools=None, callbacks=None, available_functions=None) -> Union[str, Any]:\n        # ... (emit start event, validate params) ...\n\n        try:\n            # Prepare the parameters for litellm\n            params = self._prepare_completion_params(messages, tools)\n\n            # Decide whether to stream or not (simplified here)\n            if self.stream:\n                 # Handles chunk processing, tool calls from stream end\n                return self._handle_streaming_response(params, callbacks, available_functions)\n            else:\n                 # Makes single call, handles tool calls from response\n                return self._handle_non_streaming_response(params, callbacks, available_functions)\n\n        except Exception as e:\n            # ... (emit failure event, handle exceptions like context window exceeded) ...\n            raise e\n\n    def _handle_non_streaming_response(self, params, callbacks, available_functions):\n         # THE CORE CALL TO LITELLM\n        response = litellm.completion(**params)\n\n        # Extract text content\n        text_response = response.choices[0].message.content or \"\"\n\n        # Check for tool calls in the response\n        tool_calls = getattr(response.choices[0].message, \"tool_calls\", [])\n\n        if not tool_calls or not available_functions:\n            # ... (emit success event) ...\n            return text_response # Return plain text\n        else:\n            # Handle the tool call (runs the actual function)\n            tool_result = self._handle_tool_call(tool_calls, available_functions)\n            if tool_result is not None:\n                return tool_result # Return tool output\n            else:\n                 # ... (emit success event for text if tool failed?) ...\n                return text_response # Fallback to text if tool fails\n\n    def _handle_tool_call(self, tool_calls, available_functions):\n        # Extracts function name and args from tool_calls[0]\n        # Looks up function in available_functions\n        # Executes the function with args\n        # Returns the result\n        # ... (error handling) ...\n        pass\n\n    def _format_messages_for_provider(self, messages):\n        # Handles provider-specific message formatting rules\n        # (e.g., ensuring Anthropic starts with 'user' role)\n        pass\n\n    # ... other methods like _handle_streaming_response ...\n```\n```\n\n----------------------------------------\n\nTITLE: MCP CLI Implementation\nDESCRIPTION: Core implementation of the MCP CLI using Typer, showing command handling and server execution logic\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/01_cli___mcp__command_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Import the Typer library for creating CLIs\nimport typer\n# Import helpers to find/load the server code\nfrom .helpers import _parse_file_path, _import_server # Fictional helper import\n\n# Create the main CLI application object\napp = typer.Typer(name=\"mcp\", help=\"MCP development tools\")\n\n# Decorator tells Typer this function handles the 'run' command\n@app.command()\ndef run(\n    file_spec: str = typer.Argument(...), # Expects the file path argument\n    # ... other options like --transport ...\n) -> None:\n    \"\"\"Run a MCP server.\"\"\"\n    # 1. Find the file and specific server object (if any)\n    file_path, server_object_name = _parse_file_path(file_spec)\n\n    # 2. Load the code and get the server instance\n    server = _import_server(file_path, server_object_name)\n\n    # 3. Tell the server instance to start running\n    server.run() # Additional args like transport might be passed here\n\n# ... other commands like dev, install, version defined similarly ...\n\n# Standard Python entry point\nif __name__ == \"__main__\":\n    app() # Start the Typer application\n```\n\n----------------------------------------\n\nTITLE: Component Base Class Definition (Python)\nDESCRIPTION: Simplified concept of the Component base class, showing required class variables and methods for concrete components, including _to_config and _from_config methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import Type, TypeVar, Generic, ClassVar\n# ... other imports\n\nConfigT = TypeVar(\"ConfigT\", bound=BaseModel)\n\nclass Component(Generic[ConfigT]): # Generic over its config type\n    # Required Class Variables for Concrete Components\n    component_type: ClassVar[str]\n    component_config_schema: Type[ConfigT]\n\n    # Required Instance Method for Saving\n    def _to_config(self) -> ConfigT:\n        raise NotImplementedError\n\n    # Required Class Method for Loading\n    @classmethod\n    def _from_config(cls, config: ConfigT) -> Self:\n         raise NotImplementedError\n\n    # dump_component and load_component are also part of the system\n    # (often inherited from base classes like ComponentBase)\n    def dump_component(self) -> ComponentModel: ...\n    @classmethod\n    def load_component(cls, model: ComponentModel | Dict[str, Any]) -> Self: ...\n```\n\n----------------------------------------\n\nTITLE: Configuring a Pydantic Model with ConfigDict in Python\nDESCRIPTION: Demonstrates how to use ConfigDict to set model-wide configurations for a Pydantic model. This example sets the model to be frozen, forbid extra fields, and validate assignments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict\n\nclass Product(BaseModel):\n    # Define model-wide settings here\n    model_config = ConfigDict(\n        frozen=True,             # Setting 1: Make instances immutable\n        extra='forbid',          # Setting 2: Forbid extra fields during input validation\n        validate_assignment=True # Setting 3: Re-validate fields when they are assigned a new value\n    )\n\n    item_id: int\n    name: str\n    price: float | None = None\n\n# --- How these settings affect behavior ---\n\n# 1. Forbid Extra Fields ('extra=forbid')\ntry:\n    # Input data has an extra 'color' field\n    product_data_extra = {'item_id': 123, 'name': 'Thingy', 'color': 'blue'}\n    Product(**product_data_extra)\nexcept Exception as e:\n    print(f\"Error on extra field:\\n{e}\")\n    # Expected Output (simplified):\n    # Error on extra field:\n    # 1 validation error for Product\n    # color\n    #   Extra inputs are not permitted [type=extra_forbidden, ...]\n\n# 2. Immutability ('frozen=True')\nproduct = Product(item_id=456, name=\"Gadget\")\nprint(f\"Initial product: {product}\")\n# Expected Output: Initial product: item_id=456 name='Gadget' price=None\n\ntry:\n    # Attempt to change a field on the frozen instance\n    product.name = \"New Gadget\"\nexcept Exception as e:\n    print(f\"\\nError on assignment to frozen model:\\n{e}\")\n    # Expected Output (simplified):\n    # Error on assignment to frozen model:\n    # 1 validation error for Product\n    # name\n    #   Instance is frozen [type=frozen_instance, ...]\n\n# 3. Validate Assignment ('validate_assignment=True')\nproduct_mutable = Product.model_construct(item_id=789, name=\"Widget\") # Use model_construct to bypass initial __init__ validation for demo\ntry:\n    # Attempt to assign an invalid type (int instead of str)\n    product_mutable.name = 999\nexcept Exception as e:\n    print(f\"\\nError on invalid assignment:\\n{e}\")\n    # Expected Output (simplified):\n    # Error on invalid assignment:\n    # 1 validation error for Product\n    # name\n    #  Input should be a valid string [type=string_type, input_value=999, input_type=int]\n```\n\n----------------------------------------\n\nTITLE: Custom Error Response Example from Exception Handler (JSON)\nDESCRIPTION: Illustrates the JSON response format sent to the client when the UnicornNotFound exception is raised and handled. The response includes a custom message and is associated with HTTP status code 418.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\"message\": \"Oops! Can't find unicorn named: yolo.\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing __array_function__ Dispatch in NumPy (Python)\nDESCRIPTION: This snippet demonstrates how NumPy functions are decorated to enable __array_function__ dispatching. It shows the use of the @array_function_dispatch decorator and the creation of a dispatcher function for the linspace function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/08___array_function___protocol___overrides___overrides__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example from numpy/core/function_base.py (simplified)\nfrom numpy._core import overrides\n\narray_function_dispatch = functools.partial(\n    overrides.array_function_dispatch, module='numpy')\n\ndef _linspace_dispatcher(start, stop, num=None, ...):\n    # This helper identifies arguments relevant for dispatch\n    return (start, stop)\n\n@array_function_dispatch(_linspace_dispatcher) # Decorator applied!\ndef linspace(start, stop, num=50, ...):\n    # ... Actual implementation for NumPy arrays ...\n    pass\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Retries with Requests HTTPAdapter in Python\nDESCRIPTION: This code demonstrates configuring custom retry logic for HTTP requests using `requests`. It involves creating a `Retry` object from `urllib3` with specific parameters (total retries, backoff factor, status codes to retry on), initializing an `HTTPAdapter` with this `Retry` object via the `max_retries` argument, and mounting the adapter to a `requests.Session` for a target URL prefix. Requests made through this session to the specified prefix will automatically use the defined retry strategy. Dependencies include `requests` and `urllib3`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry # Import the Retry class\n\n# 1. Configure the retry strategy\n#    - total=5: Try up to 5 times in total\n#    - backoff_factor=0.5: Wait 0.5s, 1s, 2s, 4s between retries\n#    - status_forcelist=[500, 502, 503, 504]: Only retry on these HTTP status codes\n#    - allowed_methods=False: Retry for all methods (GET, POST, etc.) by default. Use [\"GET\", \"POST\"] to restrict.\nretry_strategy = Retry(\n    total=5,\n    backoff_factor=0.5,\n    status_forcelist=[500, 502, 503, 504],\n    # allowed_methods=False # Default includes most common methods\n)\n\n# 2. Create an HTTPAdapter with this retry strategy\n#    The 'max_retries' argument accepts a Retry object\nadapter_with_retries = HTTPAdapter(max_retries=retry_strategy)\n\n# 3. Create a Session\nsession = requests.Session()\n\n# 4. Mount the adapter for the specific API prefix\napi_base_url = 'https://flaky-api.example.com/' # Use the base URL prefix\nsession.mount(api_base_url, adapter_with_retries)\n\n# 5. Now, use the session to make requests to the flaky API\napi_endpoint = f\"{api_base_url}data\"\nprint(f\"Making request to {api_endpoint} with custom retries...\")\n\ntry:\n    # Imagine this API sometimes returns 503 Service Unavailable\n    response = session.get(api_endpoint)\n    response.raise_for_status() # Check for HTTP errors\n    print(\"Success!\")\n    # print(response.json()) # Process the successful response\nexcept requests.exceptions.RequestException as e:\n    print(f\"Request failed after retries: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Executing Shell Commands Using Child Process Spawn in Node.js (TypeScript)\nDESCRIPTION: This TypeScript function provides a Promise-based API for executing shell commands with Node.js's child_process.spawn. It captures stdout and stderr, enforcing a 100 KB buffer, and manages process lifecycle including error events. The function never rejects: errors are mapped to an ExecResult with a nonzero exit code. Optional support for AbortSignal allows calling code to cancel the command, and all output is returned in the ExecResult object. Dependencies include 'child_process', local logging, and an ExecResult interface.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/sandbox/raw-exec.ts (Simplified)\nimport type { ExecResult } from \"./interface\";\nimport { spawn, type SpawnOptions } from \"child_process\";\nimport { log, isLoggingEnabled } from \"../log.js\";\n\nconst MAX_BUFFER = 1024 * 100; // 100 KB limit for stdout/stderr\n\n// Never rejects, maps errors to non-zero exit code / stderr\nexport function exec(\n  command: Array<string>, // e.g., [\"git\", \"status\"]\n  options: SpawnOptions,\n  _writableRoots: Array<string>, // Not used in raw exec\n  abortSignal?: AbortSignal,\n): Promise<ExecResult> {\n  const prog = command[0];\n  const args = command.slice(1);\n\n  return new Promise<ExecResult>((resolve) => {\n    // Spawn the child process\n    const child = spawn(prog, args, {\n      ...options,\n      stdio: [\"ignore\", \"pipe\", \"pipe\"], // Don't wait for stdin, capture stdout/err\n      detached: true, // Allows killing process group on abort\n    });\n\n    // Handle abort signal if provided\n    if (abortSignal) {\n       // Add listener to kill child process if aborted\n       // ... abort handling logic ...\n    }\n\n    let stdout = \"\";\n    let stderr = \"\";\n    // Capture stdout/stderr, respecting MAX_BUFFER limit\n    child.stdout?.on(\"data\", (data) => { /* append to stdout if under limit */ });\n    child.stderr?.on(\"data\", (data) => { /* append to stderr if under limit */ });\n\n    // Handle process exit\n    child.on(\"exit\", (code, signal) => {\n      resolve({ stdout, stderr, exitCode: code ?? 1 });\n    });\n\n    // Handle errors like \"command not found\"\n    child.on(\"error\", (err) => {\n      resolve({ stdout: \"\", stderr: String(err), exitCode: 1 });\n    });\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Codex Terminal Chat Workflow with Mermaid SequenceDiagram\nDESCRIPTION: This mermaid diagram illustrates the complete workflow of user interaction with the Codex terminal chat application, detailing the progression of messages and events between the user, the Ink/React-powered CLI UI, and the backend Agent Loop. It visualizes components, data flow, and callbacks, showing how user input is processed and how responses are rendered back to the terminal interface. The diagram serves to help developers and users understand operational context and integration points.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Terminal\n    participant CodexCLI\n    participant InkReactApp as Ink/React UI\n    participant AgentLoop as Agent Loop\n\n    User->>Terminal: Runs `codex \"prompt\"`\n    Terminal->>CodexCLI: Starts the process\n    CodexCLI->>InkReactApp: Renders initial UI (`App` -> `TerminalChat`)\n    InkReactApp->>Terminal: Displays UI (header, empty chat, input box)\n    User->>Terminal: Types message, presses Enter\n    Terminal->>InkReactApp: Captures input (`TerminalChatInput`)\n    InkReactApp->>AgentLoop: Sends user input via `submitInput` prop (in `TerminalChat`)\n    Note over AgentLoop: Processes input, calls LLM...\n    AgentLoop->>InkReactApp: Sends back AI response via `onItem` prop (in `TerminalChat`)\n    InkReactApp->>InkReactApp: Updates state (`items`), triggers re-render\n    InkReactApp->>Terminal: Re-renders UI with new message (`MessageHistory`)\n```\n\n----------------------------------------\n\nTITLE: Internal Task Execution Loop for Crew Processes - Python\nDESCRIPTION: Outlines the internal '_execute_tasks' method, leveraged by both sequential and hierarchical processes for iterating and executing tasks with the assigned or delegated agents. The method is designed for extensibility and may contain additional logic for context management or dynamic assignment in more advanced workflows. Although the implementation is not shown, dependencies are implied to include the Task class, assigned agents, and contextual handlers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef _execute_tasks(self, tasks: List[Task], ...) -> CrewOutput:\n  \"\"\"Internal method used by both sequential and hierarchical processes\n     to iterate through tasks. In hierarchical, the manager agent influences\n     which agent runs which task via delegation tools.\"\"\"\n  # ... loops through tasks, gets agent (directly for seq, via manager for hier), executes ...\n  pass\n```\n\n----------------------------------------\n\nTITLE: Importing Flask Globals and Initializing App with Secret Key\nDESCRIPTION: Imports necessary components from Flask (`Flask`, `request`, `session`, `current_app`, `g`, `render_template`) and the `os` module. Initializes a Flask application instance and sets a `SECRET_KEY` configuration variable using `os.urandom(24)`, which is crucial for enabling session functionality. Emphasizes that hardcoding the secret key is not recommended for production.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom flask import Flask, request, session, current_app, g, render_template\nimport os # For generating a secret key\n\n# Create the application object\napp = Flask(__name__)\n\n# !! IMPORTANT !! Sessions require a secret key for security.\n# In a real app, set this from an environment variable or config file!\n# Never hardcode it like this in production.\napp.config['SECRET_KEY'] = os.urandom(24)\n# We'll learn more about config in Chapter 6: Configuration (Config)\n```\n\n----------------------------------------\n\nTITLE: Configuration Loading Implementation in config.ts (TypeScript)\nDESCRIPTION: Implements the core configuration loading logic in the config.ts file. This code handles reading configuration from YAML/JSON files, loading instructions from multiple sources (global instructions.md and project-specific codex.md), and combining them into a unified AppConfig object with sensible defaults.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/config.ts (Simplified)\n\nimport { existsSync, readFileSync } from \"fs\";\nimport { load as loadYaml } from \"js-yaml\";\nimport { homedir } from \"os\";\nimport { join, dirname, resolve as resolvePath } from \"path\";\n\nexport const CONFIG_DIR = join(homedir(), \".codex\");\nexport const CONFIG_YAML_FILEPATH = join(CONFIG_DIR, \"config.yaml\");\n// ... other paths: .json, .yml, instructions.md ...\nexport const DEFAULT_AGENTIC_MODEL = \"o4-mini\";\n\n// Represents full runtime config\nexport type AppConfig = {\n  apiKey?: string;\n  model: string;\n  instructions: string;\n  // ... other settings ...\n};\n\n// Options for loading\nexport type LoadConfigOptions = {\n  cwd?: string;\n  disableProjectDoc?: boolean;\n  projectDocPath?: string;\n  isFullContext?: boolean; // Affects default model choice\n};\n\nexport const loadConfig = (\n  configPath: string | undefined = CONFIG_YAML_FILEPATH, // Default path\n  instructionsPath: string | undefined = join(CONFIG_DIR, \"instructions.md\"),\n  options: LoadConfigOptions = {},\n): AppConfig => {\n  let storedConfig: Record<string, any> = {}; // Holds data from config.yaml\n\n  // 1. Find and read config.yaml/.json/.yml\n  let actualConfigPath = /* ... logic to find existing config file ... */ ;\n  if (existsSync(actualConfigPath)) {\n    try {\n      const raw = readFileSync(actualConfigPath, \"utf-8\");\n      // Parse based on file extension (.yaml, .yml, .json)\n      storedConfig = /* ... parse YAML or JSON ... */ raw;\n    } catch { /* ignore parse errors */ }\n  }\n\n  // 2. Read global instructions.md\n  const userInstructions = existsSync(instructionsPath)\n    ? readFileSync(instructionsPath, \"utf-8\")\n    : \"\";\n\n  // 3. Read project codex.md (if enabled)\n  let projectDoc = \"\";\n  if (!options.disableProjectDoc /* ... and env var check ... */) {\n     const cwd = options.cwd ?? process.cwd();\n     // loadProjectDoc handles discovery and reading the file\n     projectDoc = loadProjectDoc(cwd, options.projectDocPath);\n  }\n\n  // 4. Combine instructions\n  const combinedInstructions = [userInstructions, projectDoc]\n    .filter((s) => s?.trim()) // Remove empty strings\n    .join(\"\\n\\n--- project-doc ---\\n\\n\"); // Join with separator\n\n  // 5. Determine final model (use stored, else default)\n  const model = storedConfig.model?.trim()\n      ? storedConfig.model.trim()\n      : (options.isFullContext ? /* full ctx default */ : DEFAULT_AGENTIC_MODEL);\n\n  // 6. Assemble the final config object\n  const config: AppConfig = {\n    model: model,\n    instructions: combinedInstructions,\n    // ... merge other settings from storedConfig ...\n  };\n\n  // ... First-run bootstrap logic to create default files if missing ...\n\n  return config;\n};\n\n// Helper to find and read project doc\nfunction loadProjectDoc(cwd: string, explicitPath?: string): string {\n  const filepath = explicitPath\n      ? resolvePath(cwd, explicitPath)\n      : discoverProjectDocPath(cwd); // Search logic\n\n  if (!filepath || !existsSync(filepath)) return \"\";\n\n  try {\n    const buf = readFileSync(filepath);\n    // Limit size, return content\n    return buf.slice(0, /* MAX_BYTES */).toString(\"utf-8\");\n  } catch { return \"\"; }\n}\n\n// Helper to find codex.md by walking up directories\nfunction discoverProjectDocPath(startDir: string): string | null {\n  // ... logic to check current dir, then walk up to git root ...\n  // ... checks for codex.md, .codex.md etc. ...\n  return /* path or null */;\n}\n```\n\n----------------------------------------\n\nTITLE: Managing Anonymous User IDs in Python\nDESCRIPTION: This snippet defines the user_id property of the ProductTelemetry class. It handles getting or creating an anonymous user ID, storing it in a file, and providing fallback behavior if file access fails.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@property\ndef user_id(self) -> str:\n    \"\"\"Gets or creates the anonymous user ID.\"\"\"\n    if self._curr_user_id:\n        return self._curr_user_id\n\n    try:\n        # Check if the ID file exists\n        id_file = Path(self.USER_ID_PATH)\n        if not id_file.exists():\n            # Create directory and generate a new UUID if it doesn't exist\n            id_file.parent.mkdir(parents=True, exist_ok=True)\n            new_user_id = str(uuid.uuid4())\n            id_file.write_text(new_user_id)\n            self._curr_user_id = new_user_id\n        else:\n            # Read the existing UUID from the file\n            self._curr_user_id = id_file.read_text().strip()\n    except Exception:\n        # Fallback if file access fails\n        self._curr_user_id = 'UNKNOWN_USER_ID'\n    return self._curr_user_id\n```\n\n----------------------------------------\n\nTITLE: Visualizing Keystroke Propagation with Mermaid Sequence Diagram - Mermaid\nDESCRIPTION: This Mermaid code snippet creates a sequence diagram to visualize the processing of a single keystroke ('h') in an Ink/React multiline terminal editor. It shows each step as messages between the User, Terminal, InkUI, TextBuffer, and an Agent Loop (not involved), detailing how input flows, internal methods are called, and state updates are managed. The diagram depends on Mermaid.js for rendering and is purely declarative—no parameters or dynamic behavior beyond the described static flow. Inputs and outputs are user actions and state transitions; limitations are the static nature of the depiction and the need for compatible Mermaid viewers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/02_input_handling__textbuffer_editor_.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant User\\n    participant Terminal\\n    participant InkUI as Ink/React (MultilineTextEditor)\\n    participant TextBuffer\\n    participant AgentLoop as Agent Loop (Not involved)\\n\\n    User->>Terminal: Presses 'h' key\\n    Terminal->>InkUI: Terminal sends key event to Ink\\n    InkUI->>InkUI: `useInput` hook captures 'h'\\n    InkUI->>TextBuffer: Calls `handleInput('h', { ... }, viewport)`\\n    TextBuffer->>TextBuffer: Finds current line (\"\") and cursor (0,0)\\n    TextBuffer->>TextBuffer: Calls `insert('h')`\\n    TextBuffer->>TextBuffer: Updates `lines` to `[\"h\"]`\\n    TextBuffer->>TextBuffer: Updates `cursorCol` to 1\\n    TextBuffer->>TextBuffer: Increments internal `version`\\n    TextBuffer-->>InkUI: Returns `true` (buffer was modified)\\n    InkUI->>InkUI: Triggers a React re-render because internal state changed\\n    InkUI->>TextBuffer: Calls `getVisibleLines(viewport)` -> returns `[\"h\"]`\\n    InkUI->>TextBuffer: Calls `getCursor()` -> returns `[0, 1]`\\n    InkUI->>Terminal: Renders the updated text (\"h\") with cursor highlight\n```\n\n----------------------------------------\n\nTITLE: Simplified Agent Step Method Using MessageManager in Python\nDESCRIPTION: A simplified version of the Agent.step method that demonstrates how the MessageManager is used to manage conversation flow between the Browser, Agent, and LLM. This method shows the cycle of adding state, getting messages, calling the LLM, adding responses, and executing actions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent/service.py (Simplified step method - Highlighting MessageManager) ---\nclass Agent:\n    # ... (init, run) ...\n    async def step(self, step_info: Optional[AgentStepInfo] = None) -> None:\n        logger.info(f\"📍 Step {self.state.n_steps}\")\n        state = None\n        model_output = None\n        result: list[ActionResult] = []\n\n        try:\n            # 1. Get current state from the browser\n            state = await self.browser_context.get_state() # Uses BrowserContext\n\n            # 2. Add state + PREVIOUS result to message history via MessageManager\n            #    'self.state.last_result' holds the outcome of the *previous* step's action\n            self._message_manager.add_state_message(\n                state,\n                self.state.last_result, # Result from previous action\n                step_info,\n                self.settings.use_vision # Tell it whether to include image\n            )\n\n            # 3. Get the complete, formatted message history for the LLM\n            input_messages = self._message_manager.get_messages()\n\n            # 4. Get LLM's decision on the next action(s)\n            model_output = await self.get_next_action(input_messages) # Calls the LLM\n\n            # --- Agent increments step counter ---\n            self.state.n_steps += 1\n\n            # 5. Remove the potentially large state message before adding the compact AI response\n            #    (This is an optimization mentioned in the provided code)\n            self._message_manager._remove_last_state_message()\n\n            # 6. Add the LLM's response (the plan) to the history\n            self._message_manager.add_model_output(model_output)\n\n            # 7. Execute the action(s) using the Controller\n            result = await self.multi_act(model_output.action) # Uses Controller\n\n            # 8. Store the result of THIS action. It will be used in the *next* step's\n            #    call to self._message_manager.add_state_message()\n            self.state.last_result = result\n\n            # ... (Record step details, handle success/failure) ...\n\n        except Exception as e:\n            # Handle errors...\n            result = await self._handle_step_error(e)\n            self.state.last_result = result\n        # ... (finally block) ...\n```\n\n----------------------------------------\n\nTITLE: Defining BaseDispatcher Abstract Class in Python\nDESCRIPTION: This snippet shows a simplified definition of the `BaseDispatcher` abstract base class from `crawl4ai.async_dispatcher`. It outlines the core structure for dispatcher implementations, including initialization with optional rate limiters and monitors, and abstract methods `crawl_url` (for single URL crawling) and `run_urls` (for managing concurrent crawls). It also includes a default implementation for `run_urls_stream`. This class serves as a blueprint for concrete dispatchers like `SemaphoreDispatcher`. Dependencies include `abc`, `typing`, and potentially other `crawl4ai` components (like `RateLimiter`, `CrawlerMonitor`, `CrawlerRunConfig`, `CrawlerTaskResult`, `AsyncWebCrawler`).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/10_basedispatcher.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/async_dispatcher.py\nfrom abc import ABC, abstractmethod\nfrom typing import List, Optional\n# ... other imports like CrawlerRunConfig, CrawlerTaskResult, AsyncWebCrawler ...\n\nclass BaseDispatcher(ABC):\n    def __init__(\n        self,\n        rate_limiter: Optional[RateLimiter] = None,\n        monitor: Optional[CrawlerMonitor] = None,\n    ):\n        self.crawler = None # Will be set by arun_many\n        self.rate_limiter = rate_limiter\n        self.monitor = monitor\n        # ... other common state ...\n\n    @abstractmethod\n    async def crawl_url(\n        self,\n        url: str,\n        config: CrawlerRunConfig,\n        task_id: str,\n        # ... maybe other internal params ...\n    ) -> CrawlerTaskResult:\n        \"\"\"Crawls a single URL, potentially handling concurrency primitives.\"\"\"\n        # This is often the core worker method called by run_urls\n        pass\n\n    @abstractmethod\n    async def run_urls(\n        self,\n        urls: List[str],\n        crawler: \"AsyncWebCrawler\",\n        config: CrawlerRunConfig,\n    ) -> List[CrawlerTaskResult]:\n        \"\"\"Manages the concurrent execution of crawl_url for multiple URLs.\"\"\"\n        # This is the main entry point called by arun_many\n        pass\n\n    async def run_urls_stream(\n        self,\n        urls: List[str],\n        crawler: \"AsyncWebCrawler\",\n        config: CrawlerRunConfig,\n    ) -> AsyncGenerator[CrawlerTaskResult, None]:\n         \"\"\" Streaming version of run_urls (might be implemented in base or subclasses) \"\"\"\n         # Example default implementation (subclasses might override)\n         results = await self.run_urls(urls, crawler, config)\n         for res in results: yield res # Naive stream, real one is more complex\n\n    # ... other potential helper methods ...\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Models for Input/Output\nDESCRIPTION: Creates two Pydantic models - ItemCreate for accepting input data including internal fields, and ItemPublic for filtering response data to exclude sensitive information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass ItemCreate(BaseModel):\n    name: str\n    description: str | None = None\n    price: float\n    tax: float | None = None\n    internal_cost: float # Required input, but we won't return it\n\nclass ItemPublic(BaseModel):\n    name: str\n    description: str | None = None\n    price: float\n    tax: float | None = None\n    # Note: internal_cost is NOT defined here\n```\n\n----------------------------------------\n\nTITLE: Simplified Internal Logic of dspy.Predict LM Lookup (Python)\nDESCRIPTION: Provides a simplified conceptual view of how the `forward` method within `dspy.Predict` might prioritize Language Model (LM) selection. It checks for an LM passed in `kwargs`, then the instance's own `self.lm`, and finally falls back to the global `dspy.settings.lm`. Asserts that an LM must be found.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified internal logic of dspy.Predict.forward()\ndef forward(self, **kwargs):\n  # ... get signature, demos, config ...\n\n  # Get the LM: Use 'lm' passed in kwargs, OR self.lm (if set), OR dspy.settings.lm\n  lm_to_use = kwargs.pop(\"lm\", self.lm) or dspy.settings.lm\n  assert lm_to_use is not None, \"No LM configured!\"\n\n  # ... format prompt using signature/demos/inputs ...\n  # ... call lm_to_use(prompt, ...) ...\n  # ... parse output ...\n  # ... return Prediction ...\n```\n\n----------------------------------------\n\nTITLE: Simulating AgentLogger Console Output in Python\nDESCRIPTION: This snippet demonstrates a simulated console output from AgentLogger, showing how it logs different stages of an AI agent's execution including thoughts, tool calls, and observations. It uses rich formatting for better readability.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_0\n\nLANGUAGE: console\nCODE:\n```\n╭─[bold] New run ─ ToolCallingAgent [/bold]────────────────────────────────╮\n│                                                                       │\n│ [bold]What is the capital of France, and what is its current weather?[/bold] │\n│                                                                       │\n╰────────────────────────── LiteLLMModel - gpt-3.5-turbo ─╯\n\n━━━[bold] Step 1 [/bold]━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nINFO     ╭─ Thinking... ───────────────────────────────────────────────────╮\nINFO     │ Thought: The user wants the capital of France and its weather.│\nINFO     │ First, I need to find the capital. I can use the search tool. │\nINFO     ╰─────────────────────────────────────────────────────────────────╯\nINFO     Panel(Text(\"Calling tool: 'search' with arguments: {'query': 'Capital of France'}\"))\nINFO     Observations: Paris\nDEBUG    [Step 1: Duration 1.52 seconds| Input tokens: 150 | Output tokens: 50]\n\n━━━[bold] Step 2 [/bold]━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nINFO     ╭─ Thinking... ───────────────────────────────────────────────────╮\nINFO     │ Thought: I have the capital, which is Paris. Now I need the   │\nINFO     │ weather for Paris. I can use the weather tool.                │\nINFO     ╰─────────────────────────────────────────────────────────────────╯\nINFO     Panel(Text(\"Calling tool: 'weather' with arguments: {'location': 'Paris'}\"))\nINFO     Observations: Sunny, 25°C\nDEBUG    [Step 2: Duration 1.81 seconds| Input tokens: 210 | Output tokens: 105]\n\n━━━[bold] Step 3 [/bold]━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nINFO     ╭─ Thinking... ───────────────────────────────────────────────────╮\nINFO     │ Thought: I have both the capital (Paris) and the weather      │\nINFO     │ (Sunny, 25°C). I have fulfilled the user's request. I should  │\nINFO     │ use the final_answer tool.                                    │\nINFO     ╰─────────────────────────────────────────────────────────────────╯\nINFO     Panel(Text(\"Calling tool: 'final_answer' with arguments: {'answer': 'The capital of France is Paris, and the current weather there is Sunny, 25°C.'}\"))\nINFO     [bold #d4b702]Final answer:[/bold #d4b702] The capital of France is Paris, and the current weather there is Sunny, 25°C.\nDEBUG    [Step 3: Duration 1.25 seconds| Input tokens: 280 | Output tokens: 170]\n```\n\n----------------------------------------\n\nTITLE: Implementing a Greeter Agent Handler using Async Generators (Google A2A, TypeScript)\nDESCRIPTION: This code defines a conceptual async generator function acting as the task handler or 'agent brain' for the Google A2A platform in TypeScript. It imports type definitions for Task and Message objects, and demonstrates stepwise task processing where each yield signals an update in the task's state. The handler receives a TaskContext, extracts the user's name from the message, emits a working status, simulates AI work using a delay, and then yields a final completed status with the generated greeting. Intended for integration with A2AServer; dependencies include the relevant schema/type definition files.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/06_task_handling_logic__server_side_.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// File: samples/js/src/server/handler.ts (Conceptual Example of a Handler)\nimport * as schema from \"../schema.js\"; // For types like Task, Message, etc.\nimport { TaskContext, TaskYieldUpdate } from \"./handler.js\"; // Handler types\n\n// The Task Handling Logic for our 'Greeter Agent'\nasync function* greeterAgentHandler(\n  context: TaskContext\n): AsyncGenerator<TaskYieldUpdate> { // It yields updates\n\n  // 1. Get the user's name from the input message\n  const userMessageText = context.userMessage.parts[0].text ?? \"there\";\n  const userName = userMessageText.split(\" \").pop(); // Simple extraction\n\n  // 2. Signal that work is starting\n  console.log(`[GreeterAgent] Task ${context.task.id}: Starting`);\n  yield {\n    state: \"working\", // Update status to 'working'\n    message: { role: \"agent\", parts: [{ text: \"Thinking...\" }] }\n  };\n\n  // 3. Simulate calling an AI (the \"chef\" uses an \"ingredient\")\n  await new Promise(resolve => setTimeout(resolve, 500)); // Pretend work\n  const greeting = `Hello, ${userName}! Welcome.`;\n\n  // 4. Signal completion and provide the final message\n  console.log(`[GreeterAgent] Task ${context.task.id}: Completing`);\n  yield {\n    state: \"completed\", // Update status to 'completed'\n    message: { role: \"agent\", parts: [{ text: greeting }] }\n  };\n  // For more complex results, we could yield Artifacts here too.\n}\n\n// This handler function (`greeterAgentHandler`) would be passed\n// to the A2AServer constructor, like in Chapter 4.\n// const server = new A2AServer(greeterAgentHandler, { card: greeterAgentCard });\n```\n\n----------------------------------------\n\nTITLE: Visualizing AsyncCrawlerStrategy Flow with Mermaid\nDESCRIPTION: A sequence diagram showing how AsyncWebCrawler delegates the crawling task to AsyncCrawlerStrategy, which then fetches content from a website and returns the results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as AsyncWebCrawler\n    participant S as AsyncCrawlerStrategy\n    participant W as Website\n\n    C->>S: Please crawl(\"https://example.com\")\n    Note over S: I'm using my method (e.g., Browser or HTTP)\n    S->>W: Request Page Content\n    W-->>S: Return Raw Content (HTML, etc.)\n    S-->>C: Here's the result (AsyncCrawlResponse)\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolAgent Execution\nDESCRIPTION: Complete example showing how to create and use a ToolAgent to execute tool requests and handle results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom autogen_core.tool_agent import ToolAgent\nfrom autogen_core.models import FunctionExecutionResult\nfrom create_date_tool import date_tool\nfrom tool_call_request import date_call_request\n\ntool_executor = ToolAgent(\n    description=\"I can execute tools like getting the date.\",\n    tools=[date_tool]\n)\n\nasync def simulate_execution():\n    class MockContext: cancellation_token = None\n    ctx = MockContext()\n\n    print(f\"ToolAgent received request: {date_call_request.name}\")\n    result: FunctionExecutionResult = await tool_executor.handle_function_call(\n        message=date_call_request,\n        ctx=ctx\n    )\n    print(f\"ToolAgent produced result: {result}\")\n\nasyncio.run(simulate_execution())\n```\n\n----------------------------------------\n\nTITLE: Creating CodeAgents with Docker and E2B Executors in Python\nDESCRIPTION: This snippet shows how to create CodeAgents using alternative executor types: DockerExecutor and E2BExecutor. It demonstrates the syntax for specifying different executor types when initializing a CodeAgent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/06_pythonexecutor.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Example: Using a Docker executor (if Docker is installed and running)\ndocker_agent = CodeAgent(\n    model=llm,\n    tools=[search_tool],\n    executor_type=\"docker\" # Tell the agent to use Docker\n    # You might need to pass executor_kwargs for specific configurations\n)\n\n# Example: Using E2B (requires E2B setup and API key in environment)\n# pip install 'smolagents[e2b]'\ne2b_agent = CodeAgent(\n    model=llm,\n    tools=[search_tool],\n    executor_type=\"e2b\" # Tell the agent to use E2B\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Writer Agent Logic in Python for AutoGen Core\nDESCRIPTION: This code implements the writer agent logic that receives research facts and converts them into a blog post draft. It shows how an agent processes received messages and performs its specialized task (in this case, content generation).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept - requires AgentRuntime (Chapter 3) to actually run\n\nasync def writer_logic(agent_context, message: ResearchFacts, msg_context):\n    print(f\"Writer received facts for topic: {message.topic}\")\n    # In a real scenario, this would involve LLM prompting\n    draft = f\"Blog Post about {message.topic}:\\n\"\n    for fact in message.facts:\n        draft += f\"- {fact}\\n\"\n    print(f\"Writer drafted post:\\n{draft}\")\n\n    # Perhaps save the draft or send it somewhere else\n    # For now, we just print it. We don't send another message.\n    return None # Or maybe return a confirmation/result\n```\n\n----------------------------------------\n\nTITLE: Applying WriteBatch Operations to MemTable in LevelDB (C++)\nDESCRIPTION: Shows how the WriteBatch operations are applied to the MemTable. The code demonstrates the MemTableInserter handler that processes each operation during batch iteration, applying it to the MemTable with the appropriate sequence numbers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/05_writebatch.md#2025-04-22_snippet_4\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: leveldb/write_batch.cc ---\n// Helper class used by InsertInto\nnamespace {\nclass MemTableInserter : public WriteBatch::Handler {\n public:\n  SequenceNumber sequence_; // Starting sequence number for the batch\n  MemTable* mem_;           // MemTable to insert into\n\n  void Put(const Slice& key, const Slice& value) override {\n    // Add the Put operation to the MemTable\n    mem_->Add(sequence_, kTypeValue, key, value);\n    sequence_++; // Increment sequence number for the next operation\n  }\n  void Delete(const Slice& key) override {\n    // Add the Delete operation (as a deletion marker) to the MemTable\n    mem_->Add(sequence_, kTypeDeletion, key, Slice()); // Value is ignored\n    sequence_++; // Increment sequence number for the next operation\n  }\n};\n} // namespace\n\n// Applies the batch operations to the MemTable\nStatus WriteBatchInternal::InsertInto(const WriteBatch* b, MemTable* memtable) {\n  MemTableInserter inserter;\n  // Get the starting sequence number assigned by DBImpl::Write\n  inserter.sequence_ = WriteBatchInternal::Sequence(b);\n  inserter.mem_ = memtable;\n  // Iterate() parses rep_ and calls handler.Put/handler.Delete\n  return b->Iterate(&inserter);\n}\n\n// Helper to get/set the 8-byte sequence number from header (bytes 0-7)\nSequenceNumber WriteBatchInternal::Sequence(const WriteBatch* b) {\n  return SequenceNumber(DecodeFixed64(b->rep_.data()));\n}\nvoid WriteBatchInternal::SetSequence(WriteBatch* b, SequenceNumber seq) {\n  EncodeFixed64(&b->rep_[0], seq);\n}\n```\n\n----------------------------------------\n\nTITLE: Using UnboundedChatCompletionContext in AutoGen Core with Python\nDESCRIPTION: This code demonstrates the usage of UnboundedChatCompletionContext, which keeps the entire conversation history. It adds all messages to the context and then retrieves them, showing that all messages are preserved.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: use_unbounded_context.py\nimport asyncio\nfrom define_chat_messages import full_history\nfrom autogen_core.model_context import UnboundedChatCompletionContext\n\nasync def main():\n    # Create context and add all messages\n    context = UnboundedChatCompletionContext()\n    for msg in full_history:\n        await context.add_message(msg)\n\n    # Get the messages to send to the LLM\n    messages_for_llm = await context.get_messages()\n\n    print(f\"--- Unbounded Context ({len(messages_for_llm)} messages) ---\")\n    for i, msg in enumerate(messages_for_llm):\n        print(f\"{i+1}. [{msg.type}]: {msg.content[:30]}...\")\n\n# asyncio.run(main()) # If run\n```\n\n----------------------------------------\n\nTITLE: Configuring Weaviate RM Client in DSPy (Conceptual Python)\nDESCRIPTION: Presents a conceptual Python example demonstrating how to configure DSPy with a Weaviate vector database as the Retrieval Model. It involves connecting to Weaviate, importing and instantiating `WeaviateRM` with collection details and the client object, and configuring it globally. This snippet assumes a working Weaviate instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Example: Configuring Weaviate (Conceptual - requires setup)\n# import weaviate\n# from dspy.retrieve.weaviate_rm import WeaviateRM\n# weaviate_client = weaviate.connect_to_local() # Or connect_to_wcs, etc.\n# weaviate_retriever = WeaviateRM(\n#     weaviate_collection_name='my_manuals',\n#     weaviate_client=weaviate_client\n# )\n# dspy.settings.configure(rm=weaviate_retriever)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom CalculatorTool for Mathematical Evaluation in Python\nDESCRIPTION: This Python snippet demonstrates how to define a custom calculator tool for CrewAI by subclassing BaseTool. It introduces a Pydantic input schema (CalculatorInput) that enforces expression syntax, and a CalculatorTool class that handles expression evaluation with safety checks to avoid malicious input. The tool can be registered to an agent and is suitable for evaluating basic arithmetic expressions. Dependencies are crewai.tools.BaseTool, pydantic, typing, math, and careful use of eval, which is restricted for security. Input is a string expression, and output is the result as a string or an error message if invalid input is detected.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/04_tool.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai.tools import BaseTool\\nfrom pydantic import BaseModel, Field\\nfrom typing import Type\\nimport math # Using math module for safety\\n\\n# 1. Define the input schema using Pydantic\\nclass CalculatorInput(BaseModel):\\n    expression: str = Field(description=\\\"The mathematical expression to evaluate (e.g., '2 + 2 * 4').\\\")\\n\\n# 2. Create the Tool class, inheriting from BaseTool\\nclass CalculatorTool(BaseTool):\\n    name: str = \\\"Calculator\\\"\\n    description: str = \\\"Useful for evaluating simple mathematical expressions involving numbers, +, -, *, /, and parentheses.\\\"\\n    args_schema: Type[BaseModel] = CalculatorInput # Link the input schema\\n\\n    def _run(self, expression: str) -> str:\\n        \\\"\\\"\\\"Evaluates the mathematical expression.\\\"\\\"\\\"\\n        allowed_chars = \\\"0123456789+-*/(). \\\"\\n        if not all(c in allowed_chars for c in expression):\\n             return \\\"Error: Expression contains invalid characters.\\\"\\n\\n        try:\\n            # VERY IMPORTANT: eval() is dangerous with arbitrary user input.\\n            # In a real application, use a safer parsing library like 'numexpr' or build your own parser.\\n            # This is a simplified example ONLY.\\n            result = eval(expression, {\\\"__builtins__\\\": None}, {\\\"math\\\": math}) # Safer eval\\n            return f\\\"The result of '{expression}' is {result}\\\"\\n        except Exception as e:\\n            return f\\\"Error evaluating expression '{expression}': {e}\\\"\\n\\n# 3. Instantiate and use it in an agent\\ncalculator = CalculatorTool()\\n\\nmath_agent = Agent(\\n    role='Math Whiz',\\n    goal='Calculate the results of mathematical expressions accurately.',\\n    backstory='You are an expert mathematician agent.',\\n    tools=[calculator], # Give the agent the calculator\\n    verbose=True\\n)\\n\\n# Example Task for this agent:\\n# math_task = Task(description=\\\"What is the result of (5 + 3) * 6 / 2?\\\", agent=math_agent)\\n\n```\n\n----------------------------------------\n\nTITLE: Injecting a Chained Item Retrieval Dependency into a FastAPI Path Operation - Python\nDESCRIPTION: This snippet shows how to use a higher-level dependency ('get_item_from_db') in a FastAPI route handler, injecting both parameter values and results of chained dependencies in one step. Handles retrieval of an item by ID via the dependency chain and returns a JSON response. Assumes router and 'get_item_from_db' are configured as described in prior snippets.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# routers/items.py\n# ... other imports ...\nfrom ..common_dependencies import get_item_from_db\n\n@router.get(\"/db_items/{item_id}\")\n# This endpoint depends on get_item_from_db\nasync def read_db_item(\n    item_id: int, # Path parameter for get_item_from_db\n    item_name: Annotated[str, Depends(get_item_from_db)] # Inject result here!\n):\n    # 'item_name' will be the string returned by get_item_from_db\n    # after it used the result from get_db_session.\n    return {\"item_id\": item_id, \"name_from_db\": item_name}\n```\n\n----------------------------------------\n\nTITLE: Using the Sandbox Client to Execute Python Code in Docker Container\nDESCRIPTION: This example shows how to use the SANDBOX_CLIENT to execute Python code safely within a Docker container. It demonstrates writing a file to the sandbox, executing a command, and handling the response, all within an isolated environment.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Example of using the sandbox client (simplified)\nfrom app.sandbox.client import SANDBOX_CLIENT\nimport asyncio\n\n# Assume sandbox is enabled based on the config check above\n\n# The Python code our agent wants to run\npython_code = \"print(2 + 2)\"\n\n# Create a temporary script file content\n# We wrap the code to make it executable via 'python script.py'\nscript_content = f\"{python_code}\"\nscript_name = \"temp_script.py\"\n\n# Define the command to run inside the sandbox\ncommand_to_run = f\"python {script_name}\"\n\nasync def run_in_sandbox():\n    try:\n        print(f\"Asking sandbox to run: {command_to_run}\")\n\n        # 1. Create the sandbox container (if not already running)\n        # The client handles this automatically based on config\n        # (Simplified: Actual creation might be handled by a manager)\n        # await SANDBOX_CLIENT.create(config=config.sandbox) # Often implicit\n\n        # 2. Write the script file into the sandbox\n        await SANDBOX_CLIENT.write_file(script_name, script_content)\n        print(f\"Wrote '{script_name}' to sandbox.\")\n\n        # 3. Execute the command inside the sandbox\n        output = await SANDBOX_CLIENT.run_command(command_to_run)\n        print(f\"Sandbox execution output: {output}\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n    # finally:\n        # 4. Cleanup (often handled automatically by a manager or context)\n        # await SANDBOX_CLIENT.cleanup()\n        # print(\"Sandbox cleaned up.\")\n\n# Run the async function\n# asyncio.run(run_in_sandbox()) # Uncomment to run\n```\n\n----------------------------------------\n\nTITLE: MCP Command Flow Diagram\nDESCRIPTION: Sequence diagram illustrating the internal flow of the MCP run command execution\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/01_cli___mcp__command_.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Terminal\n    participant OS\n    participant MCP_CLI as mcp (cli/cli.py)\n    participant ServerCode as my_first_server.py\n\n    User->>Terminal: mcp run my_first_server.py\n    Terminal->>OS: Execute 'mcp' script\n    OS->>MCP_CLI: Start script with args ['run', 'my_first_server.py']\n    MCP_CLI->>MCP_CLI: Parse args (Typer finds 'run' command)\n    MCP_CLI->>MCP_CLI: _parse_file_path('my_first_server.py')\n    MCP_CLI->>MCP_CLI: _import_server(filepath, object_name)\n    MCP_CLI->>ServerCode: Import module & find 'server' object\n    ServerCode-->>MCP_CLI: Return server object\n    MCP_CLI->>ServerCode: server.run()\n    ServerCode->>ServerCode: Start listening/processing...\n```\n\n----------------------------------------\n\nTITLE: Implementing MCPAgent Class in Python\nDESCRIPTION: Defines an MCPAgent class that manages connections to MCP servers, handles tool discovery and execution, and maintains tool state. The agent can connect via stdio, refreshes tools periodically, and cleanly disconnects when finished.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom app.agent.toolcall import ToolCallAgent\nfrom app.tool.mcp import MCPClients\n\nclass MCPAgent(ToolCallAgent):\n    # Use MCPClients as the tool collection\n    mcp_clients: MCPClients = Field(default_factory=MCPClients)\n    available_tools: MCPClients = None # Will point to mcp_clients\n\n    connection_type: str = \"stdio\"\n    # ... other fields ...\n\n    async def initialize(\n        self, command: Optional[str] = None, args: Optional[List[str]] = None, ...\n    ):\n        \"\"\"Initialize by connecting the MCPClients instance.\"\"\"\n        if self.connection_type == \"stdio\":\n            # Tell mcp_clients to connect\n            await self.mcp_clients.connect_stdio(command=command, args=args or [])\n        # elif self.connection_type == \"sse\": ...\n\n        # The agent's tools are now the tools provided by the server\n        self.available_tools = self.mcp_clients\n\n        # Store initial tool schemas for detecting changes later\n        self.tool_schemas = {t.name: t.parameters for t in self.available_tools}\n\n        # Add system message about tools...\n\n    async def _refresh_tools(self):\n        \"\"\"Periodically check the server for tool updates.\"\"\"\n        if not self.mcp_clients.session: return\n\n        # Ask the server for its current list of tools\n        response = await self.mcp_clients.session.list_tools()\n        current_tools = {t.name: t.inputSchema for t in response.tools}\n\n        # Compare with stored schemas (self.tool_schemas)\n        # Detect added/removed tools and update self.tool_schemas\n        # Add system messages to memory if tools change\n        # ... logic to detect and log changes ...\n\n    async def think(self) -> bool:\n        \"\"\"Agent's thinking step.\"\"\"\n        # Refresh tools periodically\n        if self.current_step % self._refresh_tools_interval == 0:\n            await self._refresh_tools()\n            # Stop if server seems gone (no tools left)\n            if not self.mcp_clients.tool_map: return False\n\n        # Use parent class's think method, which uses self.available_tools\n        # (which points to self.mcp_clients) for tool decisions/calls\n        return await super().think()\n\n    async def cleanup(self):\n        \"\"\"Disconnect the MCP session when the agent finishes.\"\"\"\n        if self.mcp_clients.session:\n            await self.mcp_clients.disconnect()\n```\n\n----------------------------------------\n\nTITLE: Importing FastAPI Security Utilities and Dependencies (Python)\nDESCRIPTION: This code imports essential FastAPI objects for setting up security in an API: Annotated for typing with dependencies, FastAPI app and routing core, HTTPException for error handling, and the HTTPBasic/HTTPBasicCredentials classes which provide ready-made classes for HTTP Basic Authentication. This import block is foundational for all subsequent security setup and relies on the fastapi and typing libraries. No parameters or logic are defined; it fulfills dependency prerequisites and establishes the environment for secure endpoint development.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py (or your router file)\nfrom typing import Annotated\n\nfrom fastapi import Depends, FastAPI, HTTPException, status\nfrom fastapi.security import HTTPBasic, HTTPBasicCredentials\n```\n\n----------------------------------------\n\nTITLE: Defining AgentMetadata TypedDict in Python for AutoGen Core\nDESCRIPTION: This code defines the AgentMetadata class as a TypedDict, which stores descriptive information about an agent. It includes the agent's type, key (matching those in AgentId), and a human-readable description of the agent's purpose.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# From: _agent_metadata.py\nfrom typing import TypedDict\n\nclass AgentMetadata(TypedDict):\n    type: str\n    key: str\n    description: str\n```\n\n----------------------------------------\n\nTITLE: Defining and Accessing Model Configuration with ConfigDict and ConfigWrapper (Python, Pydantic)\nDESCRIPTION: These Python snippets illustrate key Pydantic internals for configuration management. ConfigDict is a TypedDict listing valid config options and their types. ConfigWrapper initializes and merges these config options from various sources, exposing defaults via attribute access and translating them for use in the core schema. ModelMetaclass then uses these to assemble classes with proper validation and serialization. Dependencies: Python >=3.9, Pydantic internals (for actual default logic, error handling, and external class references like core_schema). You can pass config via model_config, inheritance, or keyword arguments. Actual implementation is more complex; functions like prepare_config are placeholders. Inputs: class/namespace/bases/kwargs. Outputs: Properly configured model classes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from pydantic/config.py\n# ConfigDict is a TypedDict listing allowed keys and their types\nclass ConfigDict(TypedDict, total=False):\n    frozen: bool\n    extra: Literal['allow', 'ignore', 'forbid'] | None\n    alias_generator: Callable[[str], str] | None\n    # ... many more options\n\n# Simplified view from pydantic._internal._config.py\nclass ConfigWrapper:\n    config_dict: ConfigDict # Stores the actual config values\n\n    def __init__(self, config: ConfigDict | dict[str, Any] | type[Any] | None, *, check: bool = True):\n        # Simplification: Stores the input config, potentially validating keys\n        self.config_dict = prepare_config(config) # prepare_config handles defaults/deprecation\n\n    # Provides attribute access like wrapper.frozen, falling back to defaults\n    def __getattr__(self, name: str) -> Any:\n        try:\n            return self.config_dict[name]\n        except KeyError:\n            # Fallback to default values defined in config_defaults\n            # return config_defaults[name] # Simplified\n            pass # Actual implementation is more complex\n\n    # Used during model creation to gather config from all sources\n    @classmethod\n    def for_model(cls, bases: tuple[type[Any], ...], namespace: dict[str, Any], kwargs: dict[str, Any]) -> Self:\n        config_new = ConfigDict()\n        # 1. Inherit config from base classes\n        # 2. Get config from 'model_config' in the current class namespace\n        # 3. Get config from kwargs passed during class definition (e.g., class Model(BaseModel, frozen=True): ...)\n        # ... logic to merge these sources ...\n        return cls(config_new) # Return a wrapper with the final merged config\n\n    # Creates the config dictionary specifically for pydantic-core\n    def core_config(self, title: str | None) -> core_schema.CoreConfig:\n         # Extracts relevant keys from self.config_dict and maps them\n         # to the names expected by pydantic_core.CoreConfig\n         # e.g., {'extra': 'forbid'} becomes {'extra_fields_behavior': 'forbid'}\n         core_options = { ... }\n         return core_schema.CoreConfig(**core_options)\n\n# Simplified view from pydantic._internal._model_construction.py (ModelMetaclass.__new__)\ndef __new__(mcs, name, bases, namespace, **kwargs):\n    # ... lots of setup ...\n\n    # Step 1: Gather configuration\n    config_wrapper = ConfigWrapper.for_model(bases, namespace, kwargs) # Merges config from bases, class def, kwargs\n\n    # Step 2: Prepare schema generator using the config\n    schema_generator = build_schema_generator(\n        cls, # The class being built\n        config_wrapper,\n        # ... other args ...\n    )\n\n    # Step 3: Build core schema, validator, serializer (using schema_generator which uses config_wrapper)\n    # core_schema = schema_generator.generate_schema(cls) # Simplified\n    # validator = SchemaValidator(core_schema, config_wrapper.core_config()) # Simplified\n    # serializer = SchemaSerializer(core_schema, config_wrapper.core_config()) # Simplified\n\n    # ... attach schema, validator, serializer to the class ...\n    cls = super().__new__(mcs, name, bases, namespace, **kwargs)\n    # cls.__pydantic_validator__ = validator\n    # ...\n\n    return cls\n```\n\n----------------------------------------\n\nTITLE: Automatic Type Coercion in Pydantic\nDESCRIPTION: Example demonstrating Pydantic's automatic type conversion. It shows how Pydantic intelligently converts compatible types, like numeric strings to integers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n# Input data with age as a numeric string\ndata_with_string_age = {'name': 'Charlie', 'age': '35'}\n\n# Create a User instance\nuser_charlie = User(**data_with_string_age)\n\n# Pydantic converted the string '35' into the integer 35!\nprint(user_charlie)\n# Expected Output: name='Charlie' age=35\nprint(type(user_charlie.age))\n# Expected Output: <class 'int'>\n```\n\n----------------------------------------\n\nTITLE: Defining a Data Structure with Pydantic BaseModel (Python)\nDESCRIPTION: Introduces the use of Pydantic's `BaseModel` to define the structure for expected request body data. This `Item` model specifies fields like `name` (required string), `description` (optional string), `price` (required float), and `tax` (optional float). This model is intended to be used in a path operation (like POST or PUT) to parse, validate, and document JSON request bodies, although the consuming path operation is not shown in this specific snippet.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# main.py or a new models.py file\nfrom pydantic import BaseModel\n\n# Define the structure of an Item using Pydantic\nclass Item(BaseModel):\n    name: str\n    description: str | None = None # Optional field\n    price: float\n    tax: float | None = None       # Optional field\n\n# Now use it in a path operation\n# main.py or routers/items.py\nfrom fastapi import FastAPI\n```\n\n----------------------------------------\n\nTITLE: Functional API Implementation Wrappers - Requests - Python\nDESCRIPTION: This simplified source code from requests/api.py shows the internal implementation of the Requests functional API methods in Python. It defines each of the top-level helper functions (get, post, etc.) as wrappers around a core 'request' function, which creates and manages a temporary Session for a single HTTP operation. Dependencies include the requests library and its internal sessions module. Key parameters include HTTP method, url, and **kwargs for request arguments. This design abstracts session management for casual usage but is not suited for repeated or persistent connections.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/01_functional_api.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/api.py (Simplified view)\n\nfrom . import sessions # Where the Session logic lives\n\ndef request(method, url, **kwargs):\n    \"\"\"Internal function that handles all functional API calls.\"\"\"\n\n    # Creates a temporary Session just for this one call.\n    # The 'with' statement ensures it's properly closed afterwards.\n    with sessions.Session() as session:\n        # The temporary session makes the actual request.\n        return session.request(method=method, url=url, **kwargs)\n\ndef get(url, params=None, **kwargs):\n    \"\"\"Sends a GET request (functional API).\"\"\"\n    # This is just a convenient shortcut that calls the main 'request' function.\n    return request(\"get\", url, params=params, **kwargs)\n\ndef post(url, data=None, json=None, **kwargs):\n    \"\"\"Sends a POST request (functional API).\"\"\"\n    # Another shortcut calling the main 'request' function.\n    return request(\"post\", url, data=data, json=json, **kwargs)\n\n# ... similar functions for put, delete, head, patch, options ...\n```\n\n----------------------------------------\n\nTITLE: Implementing AgentImage Data Container for Images in SmolaAgents (Python)\nDESCRIPTION: This snippet illustrates the AgentImage subclass, which builds on AgentType to provide robust handling of images (PIL.Image.Image, paths, or bytes) as agent data. Key features include a flexible constructor, to_raw for always returning a PIL image (with lazy on-disk loading if needed), to_string for serializing to temp PNG files and path-based references, and an _ipython_display_ method for Jupyter integration. It also exposes and delegates image methods like size and save. Required dependencies are PIL.Image, os, tempfile, uuid, and io.BytesIO. Inputs can be image objects, strings/paths, or raw bytes, and output is either a PIL image or a temporary file path.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/07_agenttype.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent_types.py (Simplified AgentImage) ---\\nimport PIL.Image\\nimport os\\nimport tempfile\\nimport uuid\\nfrom io import BytesIO\\n\\nclass AgentImage(AgentType): # Doesn't inherit from PIL.Image directly in reality, but conceptually similar\\n    \"\"\"Handles image data, behaving like a PIL.Image.\"\"\"\\n\\n    def __init__(self, value):\\n        # value can be PIL.Image, path string, bytes, etc.\\n        AgentType.__init__(self, value) # Store original value form\\n        self._raw_image = None # To store the loaded PIL Image\\n        self._path = None # To store the path if saved to temp file\\n\\n        # Logic to load image from different input types (simplified)\\n        if isinstance(value, PIL.Image.Image):\\n            self._raw_image = value\\n        elif isinstance(value, (str, os.PathLike)):\\n             # We might load it lazily later in to_raw()\\n             self._path = str(value) # Assume it's already a path\\n             # In reality, it loads here if path exists\\n        elif isinstance(value, bytes):\\n             self._raw_image = PIL.Image.open(BytesIO(value))\\n        # ... (handle tensors, etc.) ...\\n        else:\\n             raise TypeError(f\"Unsupported type for AgentImage: {type(value)}\")\\n\\n\\n    def to_raw(self) -> PIL.Image.Image:\\n        \"\"\"Returns the raw PIL.Image.Image object.\"\"\"\\n        if self._raw_image is None:\\n            # Lazy loading if initialized with a path\\n            if self._path and os.path.exists(self._path):\\n                self._raw_image = PIL.Image.open(self._path)\\n            else:\\n                 # Handle error or create placeholder\\n                 raise ValueError(\"Cannot get raw image data.\")\\n        return self._raw_image\\n\\n    def to_string(self) -> str:\\n        \"\"\"Saves image to temp file (if needed) and returns the path.\"\"\"\\n        if self._path and os.path.exists(self._path):\\n            # Already have a path (e.g., loaded from file initially)\\n            return self._path\\n\\n        # Need to save the raw image data to a temp file\\n        raw_img = self.to_raw() # Ensure image is loaded\\n        directory = tempfile.mkdtemp()\\n        # Generate a unique filename\\n        self._path = os.path.join(directory, str(uuid.uuid4()) + \".png\")\\n        raw_img.save(self._path, format=\"png\")\\n        print(f\"--- AgentImage saved to temp file: {self._path} ---\")\\n        return self._path\\n\\n    def _ipython_display_(self):\\n        \"\"\"Special method for display in Jupyter/IPython.\"\"\"\\n        from IPython.display import display\\n        display(self.to_raw()) # Display the raw PIL image\\n\\n    # We can also make AgentImage behave like PIL.Image by delegating methods\\n    # (e.g., using __getattr__ or explicit wrappers)\\n    @property\\n    def size(self):\\n         return self.to_raw().size\\n\\n    def save(self, *args, **kwargs):\\n         self.to_raw().save(*args, **kwargs)\\n\\n    # ... other PIL.Image methods ...\\n\n```\n\n----------------------------------------\n\nTITLE: Creating and Accessing dspy.Example Instances in Python\nDESCRIPTION: Demonstrates how to instantiate a `dspy.Example` using keyword arguments that correspond to signature fields (`english_sentence`, `french_sentence`). It also shows accessing the stored values using attribute notation. This requires the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Create an example for our translation task\nexample1 = dspy.Example(\n    english_sentence=\"Hello, world!\",\n    french_sentence=\"Bonjour le monde!\"\n)\n\n# You can access the values like attributes\nprint(f\"English: {example1.english_sentence}\")\nprint(f\"French: {example1.french_sentence}\")\n```\n\n----------------------------------------\n\nTITLE: Passing User Data for Conditional Rendering in Flask Python\nDESCRIPTION: This Python snippet adds a new route `/profile` to a Flask application. It demonstrates passing a dictionary (`current_user`) containing user information (name and login status) to a template named `profile.html`. This data is intended to be used for conditional rendering within the template.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (add this route)\n\n@app.route('/profile')\ndef profile():\n  # Simulate a logged-in user for demonstration\n  current_user = {'name': 'Charlie', 'is_logged_in': True}\n  # Simulate no user logged in\n  # current_user = None\n  return render_template('profile.html', user=current_user)\n\n# ... (keep other routes and run code)\n```\n\n----------------------------------------\n\nTITLE: Flask Configuration Loading Order Implementation\nDESCRIPTION: Shows a complete implementation of Flask configuration loading with defaults and overrides. Includes error handling and environment variable configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom flask import Flask\nimport os\n\napp = Flask(__name__)\n\n# 1. Set built-in defaults maybe? Or load from a base config object.\napp.config['DEBUG'] = False # Default to False for safety\napp.config['SECRET_KEY'] = 'default-insecure-key' # Default bad key\n\n# You could load more defaults from an object here:\n# app.config.from_object('yourapp.default_config')\n\n# 2. Try to load from an environment variable pointing to a deployment-specific file\nconfig_file_path = os.environ.get('YOURAPP_SETTINGS')\nif config_file_path:\n    try:\n        app.config.from_pyfile(config_file_path)\n        print(f\"Loaded overrides from {config_file_path}\")\n    except OSError as e:\n        print(f\"Warning: Could not load config file {config_file_path}: {e}\")\nelse:\n    print(\"Info: YOURAPP_SETTINGS environment variable not set, using defaults.\")\n\n\nprint(f\"Final Debug value: {app.config['DEBUG']}\")\nprint(f\"Final Secret Key: {app.config['SECRET_KEY']}\")\n\n# ... rest of your app ...\nif __name__ == '__main__':\n  app.run()\n```\n\n----------------------------------------\n\nTITLE: Translating urllib3 Exceptions in HTTPAdapter.send - Python\nDESCRIPTION: Provides a simplified excerpt from requests.adapters.py, showing how the HTTPAdapter.send method catches specific urllib3 exceptions and raises corresponding requests exceptions. Relies on both requests and urllib3; it's core to requests' internal operation to allow user code to only handle requests exceptions. Inputs are HTTP requests, outputs are either successful responses or appropriate exceptions. Useful for understanding requests' internal exception mapping.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/adapters.py (Simplified View in HTTPAdapter.send method)\\n\\nfrom urllib3.exceptions import (\\n    MaxRetryError, ConnectTimeoutError, NewConnectionError, ResponseError,\\n    ProxyError as _ProxyError, SSLError as _SSLError, ReadTimeoutError,\\n    ProtocolError, ClosedPoolError, InvalidHeader as _InvalidHeader\\n)\\nfrom ..exceptions import (\\n    ConnectionError, ConnectTimeout, ReadTimeout, SSLError, ProxyError,\\n    RetryError, InvalidHeader, RequestException # And others\\n)\\n\\nclass HTTPAdapter(BaseAdapter):\\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\\n        # ... (prepare connection using self.get_connection_with_tls_context) ...\\n        conn = self.get_connection_with_tls_context(...)\\n        # ... (verify certs, prepare URL, add headers) ...\\n\\n        try:\\n            # === Make the actual request using urllib3 ===\\n            resp = conn.urlopen(\\n                method=request.method,\\n                url=url,\\n                # ... other args like body, headers ...\\n                retries=self.max_retries,\\n                timeout=timeout,\\n            )\\n\\n        # === Catch specific urllib3 errors and raise corresponding requests errors ===\\n\\n        except (ProtocolError, OSError) as err: # General network/protocol errors\\n            raise ConnectionError(err, request=request)\\n\\n        except MaxRetryError as e: # urllib3 retried but failed\\n            if isinstance(e.reason, ConnectTimeoutError):\\n                raise ConnectTimeout(e, request=request)\\n            if isinstance(e.reason, ResponseError): # Errors related to retry logic\\n                raise RetryError(e, request=request)\\n            if isinstance(e.reason, _ProxyError):\\n                raise ProxyError(e, request=request)\\n            if isinstance(e.reason, _SSLError):\\n                raise SSLError(e, request=request)\\n            # Fallback for other retry errors\\n            raise ConnectionError(e, request=request)\\n\\n        except ClosedPoolError as e: # Connection pool was closed\\n            raise ConnectionError(e, request=request)\\n\\n        except _ProxyError as e: # Direct proxy error\\n            raise ProxyError(e)\\n\\n        except (_SSLError, ReadTimeoutError, _InvalidHeader) as e: # Other specific errors\\n            if isinstance(e, _SSLError):\\n                raise SSLError(e, request=request)\\n            elif isinstance(e, ReadTimeoutError):\\n                raise ReadTimeout(e, request=request)\\n            elif isinstance(e, _InvalidHeader):\\n                raise InvalidHeader(e, request=request)\\n            else:\\n                # Should not happen, but raise generic RequestException if needed\\n                raise RequestException(e, request=request)\\n\\n        # ... (build and return the Response object if successful) ...\\n        return self.build_response(request, resp)\n```\n\n----------------------------------------\n\nTITLE: Defining State Schema with TypedDict in Python\nDESCRIPTION: Defines the structure of the shared state for the chatbot graph using Python's `TypedDict`. The `ChatState` includes fields for the user query, the next action decision, accumulated search results (using `Annotated` and `operator.add`), and the final response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict, Annotated, List\nimport operator\n\nclass ChatState(TypedDict):\n    user_query: str\n    # We'll store the decision here\n    next_action: str\n    # Keep track of intermediate results\n    search_result: Annotated[List[str], operator.add] # Use Topic or add if accumulating\n    final_response: str\n```\n\n----------------------------------------\n\nTITLE: Exploring Basic Attributes of NumPy Arrays\nDESCRIPTION: This snippet shows how to access and examine the key attributes of a NumPy ndarray object, including shape (dimensions), number of dimensions (ndim), total size (number of elements), and data type (dtype). These attributes provide essential information about the structure and contents of the array.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\narr = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n\n# 1. Shape: The size of each dimension\nprint(f\"Shape: {arr.shape}\")\n# Output: Shape: (2, 3)  (2 rows, 3 columns)\n\n# 2. Number of Dimensions (ndim): How many axes it has\nprint(f\"Dimensions: {arr.ndim}\")\n# Output: Dimensions: 2\n\n# 3. Size: Total number of elements\nprint(f\"Size: {arr.size}\")\n# Output: Size: 6\n\n# 4. Data Type (dtype): The type of elements in the array\nprint(f\"Data Type: {arr.dtype}\")\n# Output: Data Type: float64\n```\n\n----------------------------------------\n\nTITLE: Implementing Celery Chain Execution Logic in Python\nDESCRIPTION: A simplified Python code snippet conceptualizing the `_chain` class from `celery/canvas.py`. It demonstrates how `apply_async` delegates to `run`, which prepares the task steps, determines the linking mechanism (protocol 1 'link' vs. protocol 2 embedded 'chain' in options), sends the first task, and returns the `AsyncResult` for the final task in the original chain.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept from celery/canvas.py (chain execution)\nclass _chain(Signature):\n    # ... __init__, __or__ ...\n\n    def apply_async(self, args=None, kwargs=None, **options):\n        # ... handle always_eager ...\n        return self.run(args, kwargs, app=self.app, **options)\n\n    def run(self, args=None, kwargs=None, app=None, **options):\n        # ... setup ...\n        tasks, results = self.prepare_steps(...) # Unroll and freeze tasks\n\n        if results: # If there are tasks to run\n            first_task = tasks.pop() # Get the first task (list is reversed)\n            remaining_chain = tasks if tasks else None\n\n            # Determine how to pass the chain info (link vs. message field)\n            use_link = self._use_link # ... logic to decide ...\n\n            if use_link:\n                # Protocol 1: Link first task to the second task\n                if remaining_chain:\n                     first_task.link(remaining_chain.pop())\n                     # (Worker handles subsequent links)\n                options_to_apply = options # Pass original options\n            else:\n                # Protocol 2: Embed the rest of the reversed chain in options\n                options_to_apply = ChainMap({'chain': remaining_chain}, options)\n\n            # Send the *first* task only\n            result_from_apply = first_task.apply_async(**options_to_apply)\n            # Return AsyncResult of the *last* task in the original chain\n            return results[0]\n```\n\n----------------------------------------\n\nTITLE: Conceptual Output of ChatAdapter Formatting for Chat Models\nDESCRIPTION: Illustrates the conceptual list of messages produced by the `ChatAdapter.format()` method when given a Signature, a demo example, and an input. It shows how instructions become the system message, the demo is split into user and assistant turns, and the final input forms another user turn. Note the use of specific field markers like `[[ ## field_name ## ]]` (mentioned in text) within the content to aid parsing later. This structure is sent to the chat LM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual Output of ChatAdapter.format()\n[\n  # 1. System message from Signature instructions\n  {\"role\": \"system\", \"content\": \"Summarize the given text.\\n\\n---\\n\\nFollow the following format.\\n\\nText: ${text}\\nSummary: ${summary}\\n\\n---\\n\\n\"},\n\n  # 2. User turn for the demo input\n  {\"role\": \"user\", \"content\": \"Text: Long article about cats.\\nSummary:\"},\n\n  # 3. Assistant turn for the demo output\n  {\"role\": \"assistant\", \"content\": \"Summary: Cats are popular pets.\"}, # (Might use special markers like [[ ## Summary ## ]])\n\n  # 4. User turn for the actual input\n  {\"role\": \"user\", \"content\": \"Text: DSPy is a framework for programming foundation models...\\nSummary:\"}\n]\n```\n\n----------------------------------------\n\nTITLE: Delegating Hierarchical Task Processing - Python\nDESCRIPTION: Describes the '_run_hierarchical_process' method, in which execution is delegated to a manager agent that orchestrates the flow using LLM and agent tools. This structure enables dynamic assignment and ordering of tasks, allowing for flexible or parallel workflows. The method assumes a properly configured manager agent, either supplied or created via the Crew's configuration, and outputs are handled through internal meta-task delegation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef _run_hierarchical_process(self) -> CrewOutput:\n    # This actually delegates the orchestration to the manager agent.\n    # The manager agent uses its LLM and tools (AgentTools)\n    # to call the worker agents sequentially or in parallel as it sees fit.\n    manager = self.manager_agent\n    # Simplified concept: Manager executes a \"meta-task\"\n    # whose goal is to complete the crew's tasks using available agents.\n    # The actual implementation involves the manager agent's execution loop.\n    return self._execute_tasks(self.tasks) # The manager guides this execution internally\n```\n\n----------------------------------------\n\nTITLE: Implementing a Streaming Greeter TaskManager (Google A2A, Python)\nDESCRIPTION: This code defines a subclass of InMemoryTaskManager that handles streaming task updates for the Google A2A agent in Python. The relevant method, on_send_task_subscribe, is implemented as an async generator that processes incoming task requests by emitting stepwise status updates using yield, handling possible errors, and updating the internal task store. It uses type definitions for tasks, status, and messages, and is designed for integration with server infrastructure supporting async streaming. Dependencies include the common.server.task_manager base class and related type modules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/06_task_handling_logic__server_side_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: my_agent/task_manager.py (Conceptual Example)\nimport asyncio\nfrom typing import Union, AsyncIterable\nfrom common.server.task_manager import InMemoryTaskManager # Base class\nfrom common.types import (\n    Task, TaskSendParams, TaskStatus, TaskState, Message, TextPart,\n    SendTaskStreamingRequest, SendTaskStreamingResponse, TaskStatusUpdateEvent,\n    JSONRPCResponse\n)\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass GreeterTaskManager(InMemoryTaskManager): # Inherit from base\n\n    # Handle non-streaming requests (optional)\n    async def on_send_task(self, request):\n        # ... implementation for non-streaming ...\n        raise NotImplementedError()\n\n    # Handle STREAMING requests using an async generator\n    async def on_send_task_subscribe(\n        self, request: SendTaskStreamingRequest\n    ) -> Union[AsyncIterable[SendTaskStreamingResponse], JSONRPCResponse]:\n\n        task_params: TaskSendParams = request.params\n        task_id = task_params.id\n        logger.info(f\"[GreeterAgent] Task {task_id}: Received\")\n\n        # 0. Set up internal queue for SSE events\n        # (Handled by library/base class, conceptually)\n\n        # 1. Update store & get initial Task object\n        await self.upsert_task(task_params) # Store the task initially\n\n        # --- Start the async generator part ---\n        async def _process_task() -> AsyncIterable[SendTaskStreamingResponse]:\n            try:\n                # 2. Get user name from input\n                user_message_text = task_params.message.parts[0].text if task_params.message.parts else \"there\"\n                user_name = user_message_text.split(\" \").pop()\n\n                # 3. Signal working (Yield a status update event)\n                working_status = TaskStatus(state=TaskState.WORKING, message=Message(role=\"agent\", parts=[TextPart(text=\"Thinking...\")]))\n                working_event = TaskStatusUpdateEvent(id=task_id, status=working_status, final=False)\n                yield SendTaskStreamingResponse(id=request.id, result=working_event)\n                # Update internal store (optional, depending on base class)\n                await self.update_store(task_id, working_status, artifacts=None)\n\n                # 4. Simulate AI call\n                await asyncio.sleep(0.5)\n                greeting = f\"Hello, {user_name}! Welcome from Python.\"\n\n                # 5. Signal completion (Yield final status update event)\n                completed_status = TaskStatus(state=TaskState.COMPLETED, message=Message(role=\"agent\", parts=[TextPart(text=greeting)]))\n                completed_event = TaskStatusUpdateEvent(id=task_id, status=completed_status, final=True) # final=True\n                yield SendTaskStreamingResponse(id=request.id, result=completed_event)\n                # Update internal store\n                await self.update_store(task_id, completed_status, artifacts=None)\n\n                logger.info(f\"[GreeterAgent] Task {task_id}: Completed\")\n\n            except Exception as e:\n                logger.error(f\"[GreeterAgent] Task {task_id}: Error - {e}\")\n                # Signal failure\n                failed_status = TaskStatus(state=TaskState.FAILED, message=Message(role=\"agent\", parts=[TextPart(text=f\"Error: {e}\")]))\n                failed_event = TaskStatusUpdateEvent(id=task_id, status=failed_status, final=True)\n                yield SendTaskStreamingResponse(id=request.id, result=failed_event)\n                await self.update_store(task_id, failed_status, artifacts=None)\n\n        # Return the async generator\n        return _process_task()\n\n# This GreeterTaskManager class would be passed to the A2AServer\n```\n\n----------------------------------------\n\nTITLE: Implementing Buffered Chat Completion Context in Python\nDESCRIPTION: A ChatCompletionContext implementation that keeps only the most recent N messages, where N is defined by buffer_size. This strategy handles special cases such as avoiding starting with function result messages.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# From: model_context/_buffered_chat_completion_context.py (Simplified)\nfrom typing import List\nfrom ._chat_completion_context import ChatCompletionContext\nfrom ..models import LLMMessage, FunctionExecutionResultMessage\n\nclass BufferedChatCompletionContext(ChatCompletionContext):\n    def __init__(self, buffer_size: int, ...):\n        super().__init__(...)\n        self._buffer_size = buffer_size\n\n    async def get_messages(self) -> List[LLMMessage]:\n        \"\"\"Get at most `buffer_size` recent messages.\"\"\"\n        # Slice the list to get the last 'buffer_size' items\n        messages = self._messages[-self._buffer_size :]\n        # Special case: Avoid starting with a function result message\n        if messages and isinstance(messages[0], FunctionExecutionResultMessage):\n            messages = messages[1:]\n        return messages\n```\n\n----------------------------------------\n\nTITLE: Evaluating the Compiled DSPy Program After Optimization\nDESCRIPTION: Evaluates the performance of the `compiled_program`, which has been optimized by the `BootstrapFewShot` teleprompter. It uses the same `evaluator` (configured with the training set and metric) as the initial evaluation. The resulting score is printed, expected to be higher than the initial score if the optimization successfully added helpful few-shot examples.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Evaluate the compiled program\ncompiled_score = evaluator(compiled_program)\nprint(f\"Compiled Score (on trainset): {compiled_score}%\")\n\n# If the optimization worked, the score should be higher!\n# Might output: Compiled Score (on trainset): 100.0%\n```\n\n----------------------------------------\n\nTITLE: Creating and Linking the Manager Agent - Python\nDESCRIPTION: Demonstrates the '_create_manager_agent' helper, establishing a default manager agent if not provided, using a specified LLM and agent tools for delegation. It configures the manager to enable delegation and links it back to the Crew instance, ensuring readiness for hierarchical workflows. The method depends on the presence of agents, an LLM, and required agent tool classes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef _create_manager_agent(self):\n    # Logic to setup the self.manager_agent instance, either using\n    # the provided self.manager_agent or creating a default one\n    # using self.manager_llm and AgentTools(agents=self.agents).\n    if self.manager_agent is None and self.manager_llm:\n         # Simplified: Create a default manager agent here\n         # It gets tools to delegate work to self.agents\n         self.manager_agent = Agent(\n            role=\"Crew Manager\",\n            goal=\"Coordinate the crew to achieve their goals.\",\n            backstory=\"An expert project manager.\",\n            llm=self.manager_llm,\n            tools=AgentTools(agents=self.agents).tools(), # Gives it delegation capability\n            allow_delegation=True, # Must be true for manager\n            verbose=self.verbose\n         )\n         self.manager_agent.crew = self # Link back to crew\n    # Ensure manager has necessary setup...\n    pass\n```\n\n----------------------------------------\n\nTITLE: Defining Message Data Classes in Python for AutoGen Core\nDESCRIPTION: This code defines dataclasses for structured messages that agents can exchange. ResearchTopic represents a request for research, ResearchFacts contains research results, and DraftPost represents a generated blog post draft based on research.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\n@dataclass\nclass ResearchTopic:\n    topic: str\n\n@dataclass\nclass ResearchFacts:\n    topic: str\n    facts: list[str]\n\n@dataclass\nclass DraftPost:\n    topic: str\n    draft: str\n```\n\n----------------------------------------\n\nTITLE: Initializing Knowledge Logic - CrewAI Knowledge Class (Python)\nDESCRIPTION: This Python snippet from crewai/knowledge/knowledge.py shows the structure and initialization of the Knowledge class, which manages sources and a storage backend. It includes setup of the storage engine (defaulting to ChromaDB), loading sources, and a query interface that delegates semantic search to the underlying storage. Dependencies include BaseModel, typing annotations, and KnowledgeStorage. Inputs are source lists and queries; outputs are relevant knowledge chunks. Requires correct storage config and proper chunking by sources.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/08_knowledge.md#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Simplified view from crewai/knowledge/knowledge.py\\nclass Knowledge(BaseModel):\\n    sources: List[BaseKnowledgeSource] = Field(default_factory=list)\\n    storage: Optional[KnowledgeStorage] = Field(default=None)\\n    embedder: Optional[Dict[str, Any]] = None\\n    collection_name: Optional[str] = None\\n\\n    def __init__(self, collection_name: str, sources: List[BaseKnowledgeSource], ...):\\n        # ... setup storage (e.g., KnowledgeStorage(...)) ...\\n        self.sources = sources\\n        self.storage.initialize_knowledge_storage()\\n        self._add_sources() # Tell sources to load/chunk/embed/save\\n\\n    def query(self, query: List[str], limit: int = 3) -> List[Dict[str, Any]]:\\n        if self.storage is None: raise ValueError(\"Storage not initialized.\")\\n        # Delegate search to the storage object\\n        return self.storage.search(query, limit)\\n\\n    def _add_sources(self):\\n        for source in self.sources:\\n            source.storage = self.storage # Give source access to storage\\n            source.add() # Source loads, chunks, embeds, and saves\n```\n\n----------------------------------------\n\nTITLE: Defining Memory Step Dataclasses in Python\nDESCRIPTION: Simplified Python code from `memory.py` defining the structure for memory log entries using dataclasses. It includes `ToolCall` to represent tool invocations, a base `MemoryStep` class with an abstract `to_messages` method, and specific step types like `TaskStep` and `ActionStep`. `ActionStep` captures details of a Think-Act-Observe cycle, including LLM interactions, tool calls, and observations. The `to_messages` method in each step formats its content appropriately for input to the LLM. Dependencies include Python's `dataclasses` and `typing` modules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/04_agentmemory.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# --- File: memory.py (Simplified Step Structures) ---\nfrom dataclasses import dataclass\nfrom typing import List, Any, Dict\n\n@dataclass\nclass ToolCall: # Represents a tool invocation request\n    name: str\n    arguments: Any\n    id: str # Unique ID for matching responses\n\n@dataclass\nclass MemoryStep: # Base class for all memory entries\n    def to_messages(self, **kwargs) -> List[Dict[str, Any]]:\n        # Each step type knows how to format itself for the LLM\n        raise NotImplementedError\n\n@dataclass\nclass TaskStep(MemoryStep):\n    task: str\n    # ... (potentially images)\n    def to_messages(self, **kwargs) -> List[Dict[str, Any]]:\n        # Format: {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"New task: ...\"}]}\n        # ... simplified ...\n        return [{\"role\": \"user\", \"content\": f\"New task:\\n{self.task}\"}]\n\n@dataclass\nclass ActionStep(MemoryStep):\n    step_number: int\n    # model_input_messages: List = None # What was sent to LLM\n    model_output: str | None = None # LLM's thought/action text\n    tool_calls: List[ToolCall] | None = None # Parsed tool calls\n    observations: str | None = None # Tool results or code output\n    error: Any | None = None # Any error encountered\n    # ... other fields like timing ...\n\n    def to_messages(self, **kwargs) -> List[Dict[str, Any]]:\n        # Formats the LLM output, tool calls, observations/errors\n        # into messages for the next LLM call.\n        messages = []\n        if self.model_output:\n             messages.append({\"role\": \"assistant\", \"content\": self.model_output})\n        if self.tool_calls:\n             # Simplified representation\n             messages.append({\"role\": \"tool_call\", \"content\": f\"Calling: {self.tool_calls[0].name}(...)\"})\n        if self.observations:\n             messages.append({\"role\": \"tool_response\", \"content\": f\"Observation:\\n{self.observations}\"})\n        if self.error:\n             messages.append({\"role\": \"tool_response\", \"content\": f\"Error:\\n{self.error}\"})\n        return messages\n\n# ... potentially other step types like SystemPromptStep, PlanningStep ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing AsyncWebCrawler Flow with Mermaid\nDESCRIPTION: A sequence diagram showing the interaction between User, AsyncWebCrawler, CrawlerRunConfig, AsyncCrawlerStrategy, and Scraping/Extraction components during the crawling process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant AWC as AsyncWebCrawler\n    participant Config as CrawlerRunConfig\n    participant Fetcher as AsyncCrawlerStrategy\n    participant Processor as Scraping/Extraction\n\n    User->>AWC: arun(url, config=my_config)\n    AWC->>Config: Check my_config.cache_mode\n    alt Need to Fetch\n        AWC->>Fetcher: crawl(url, config=my_config)\n        Note over Fetcher: Uses my_config settings (timeout, wait_for, screenshot...)\n        Fetcher-->>AWC: Raw Response (HTML, screenshot?)\n        AWC->>Processor: Process HTML (using my_config.css_selector, my_config.extraction_strategy...)\n        Processor-->>AWC: Processed Data\n    else Use Cache\n        AWC->>AWC: Retrieve from Cache\n    end\n    AWC-->>User: Return CrawlResult\n```\n\n----------------------------------------\n\nTITLE: Integrating Checkpointing in Pregel Execution Engine\nDESCRIPTION: Code showing how the Pregel execution engine (PregelLoop) integrates with checkpointers. It demonstrates the checkpoint saving and loading processes during execution cycle.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# pregel/loop.py (Conceptual Snippets)\n\nclass PregelLoop: # Base class for Sync/Async loops\n    def __init__(self, ..., checkpointer: Optional[BaseCheckpointSaver], ...):\n        self.checkpointer = checkpointer\n        # ... other init ...\n\n    def _put_checkpoint(self, metadata: CheckpointMetadata) -> None:\n        # Called by the loop after a step or input processing\n        if self.checkpointer:\n            # 1. Create the Checkpoint object from current channels/state\n            checkpoint_data = create_checkpoint(self.checkpoint, self.channels, ...)\n\n            # 2. Call the checkpointer's put method (sync or async)\n            #    (Uses self.submit to potentially run in background)\n            self.submit(self.checkpointer.put, self.checkpoint_config, checkpoint_data, metadata)\n\n            # 3. Update internal config with the new checkpoint ID\n            self.checkpoint_config = {\"configurable\": {\"thread_id\": ..., \"checkpoint_id\": checkpoint_data[\"id\"]}}\n\n    def __enter__(self): # Or __aenter__ for async\n        # Called when the loop starts\n        if self.checkpointer:\n            # 1. Try to load an existing checkpoint tuple\n            saved = self.checkpointer.get_tuple(self.checkpoint_config)\n        else:\n            saved = None\n\n        if saved:\n            # 2. Restore state from the loaded checkpoint\n            self.checkpoint = saved.checkpoint\n            self.checkpoint_config = saved.config\n            # ... restore channels from saved.checkpoint['channel_values'] ...\n        else:\n            # Initialize with an empty checkpoint\n            self.checkpoint = empty_checkpoint()\n\n        # ... setup channels based on restored or empty checkpoint ...\n        return self\n```\n\n----------------------------------------\n\nTITLE: Sending an A2A Task Request in Python\nDESCRIPTION: Python code demonstrating how a client sends a 'tasks/send' request to an A2A agent. It uses the 'requests' library to make an HTTP POST call with a JSON-RPC payload containing the task details (ID, message). The code also handles the agent's response, checking for success or errors and printing the initial Task state. Requires 'requests', 'uuid', and custom types from 'common.types'.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/02_task.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# File: samples/python/hosts/cli/cli_host.py (Conceptual Snippet)\nimport requests\nimport json\nimport uuid # To generate unique IDs\nfrom common.types import TaskSendParams, Message, TextPart, Task\n\n# Agent's communication endpoint (from Agent Card)\nagent_a2a_url = \"http://translator-agent.com/a2a\"\n\n# 1. Prepare the Task request details\ntask_id = str(uuid.uuid4()) # Generate a unique ID for this job\nuser_message = Message(\n    role=\"user\",\n    parts=[TextPart(text=\"Translate 'hello' to French\")]\n)\ntask_params = TaskSendParams(id=task_id, message=user_message)\n\n# 2. Create the JSON-RPC request structure\nrequest_payload = {\n    \"jsonrpc\": \"2.0\",\n    \"method\": \"tasks/send\", # The command to send a task\n    \"params\": task_params.model_dump(exclude_none=True), # Our task details\n    \"id\": \"req-1\" # An ID for *this specific web request*\n}\n\n# 3. Send the request to the agent's URL\nprint(f\"Sending task {task_id} to {agent_a2a_url}\")\nresponse = requests.post(agent_a2a_url, json=request_payload)\nresponse.raise_for_status() # Check for HTTP errors\n\n# 4. Process the response\nresponse_data = response.json()\nif response_data.get(\"result\"):\n  # Agent accepted the task! It returns the initial Task object.\n  initial_task = Task(**response_data[\"result\"])\n  print(f\"Task created! ID: {initial_task.id}, State: {initial_task.status.state}\")\nelif response_data.get(\"error\"):\n  print(f\"Error creating task: {response_data['error']}\")\n\n```\n\n----------------------------------------\n\nTITLE: Defining Message and Memory Structures with Pydantic in Python\nDESCRIPTION: Implements `Message` and `Memory` classes using Pydantic's `BaseModel` for type validation and structured chat history management. `Message` encapsulates a single conversational turn, offering class methods to conveniently create user or assistant messages, and a `to_dict` method for serialization. `Memory` stores and truncates message lists, and supports conversion of all messages to dicts for downstream LLM or API use. Requires Python, the `pydantic` library, and relies on standard typing (`Optional`, `List`). Input and output are Python objects and dictionaries representing structured chat messages.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass Message(BaseModel):\n    role: str # Simplified: In reality uses ROLE_TYPE Literal\n    content: Optional[str] = None\n    # ... other optional fields like tool_calls, name, etc.\n\n    def to_dict(self) -> dict:\n        # Creates a dictionary representation, skipping None values\n        message_dict = {\"role\": self.role}\n        if self.content is not None:\n            message_dict[\"content\"] = self.content\n        # ... add other fields if they exist ...\n        return message_dict\n\n    @classmethod\n    def user_message(cls, content: str) -> \"Message\":\n        return cls(role=\"user\", content=content)\n\n    @classmethod\n    def assistant_message(cls, content: Optional[str]) -> \"Message\":\n        return cls(role=\"assistant\", content=content)\n\n    # ... other classmethods like system_message, tool_message ...\n\nclass Memory(BaseModel):\n    messages: List[Message] = Field(default_factory=list)\n    max_messages: int = 100 # Example limit\n\n    def add_message(self, message: Message) -> None:\n        \"\"\"Add a single message to the list.\"\"\"\n        self.messages.append(message)\n        # Optional: Trim old messages if limit exceeded\n        if len(self.messages) > self.max_messages:\n            self.messages = self.messages[-self.max_messages :]\n\n    def to_dict_list(self) -> List[dict]:\n        \"\"\"Convert all stored messages to dictionaries.\"\"\"\n        return [msg.to_dict() for msg in self.messages]\n\n    # ... other methods like clear(), get_recent_messages() ...\n```\n\n----------------------------------------\n\nTITLE: Implementing BFS Deep Crawl with Domain Filtering in Python\nDESCRIPTION: This code demonstrates how to create a breadth-first search crawler that explores a website one level deep using BFSDeepCrawlStrategy with a DomainFilter to stay within the same domain. It processes and displays crawl results as they are generated using asynchronous streaming.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/08_deepcrawlstrategy.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter8_example_1.py\nimport asyncio\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    BFSDeepCrawlStrategy, # 1. Import the desired strategy\n    DomainFilter          # Import a filter to stay on the same site\n)\n\nasync def main():\n    # 2. Create an instance of the strategy\n    #    - max_depth=1: Crawl start URL (depth 0) + links found (depth 1)\n    #    - filter_chain: Use DomainFilter to only follow links on the same website\n    bfs_explorer = BFSDeepCrawlStrategy(\n        max_depth=1,\n        filter_chain=[DomainFilter()] # Stay within the initial domain\n    )\n    print(f\"Strategy: BFS, Max Depth: {bfs_explorer.max_depth}\")\n\n    # 3. Create CrawlerRunConfig and set the deep_crawl_strategy\n    #    Also set stream=True to get results as they come in.\n    run_config = CrawlerRunConfig(\n        deep_crawl_strategy=bfs_explorer,\n        stream=True # Get results one by one using async for\n    )\n\n    # 4. Run the crawl - arun now handles the deep crawl!\n    async with AsyncWebCrawler() as crawler:\n        start_url = \"https://httpbin.org/links/10/0\" # A page with 10 internal links\n        print(f\"\\nStarting deep crawl from: {start_url}...\")\n\n        crawl_results_generator = await crawler.arun(url=start_url, config=run_config)\n\n        crawled_count = 0\n        # Iterate over the results as they are yielded\n        async for result in crawl_results_generator:\n            crawled_count += 1\n            status = \"✅\" if result.success else \"❌\"\n            depth = result.metadata.get(\"depth\", \"N/A\")\n            parent = result.metadata.get(\"parent_url\", \"Start\")\n            url_short = result.url.split('/')[-1] # Show last part of URL\n            print(f\"  {status} Crawled: {url_short:<6} (Depth: {depth})\")\n\n        print(f\"\\nFinished deep crawl. Total pages processed: {crawled_count}\")\n        # Expecting 1 (start URL) + 10 (links) = 11 results\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n```\n\n----------------------------------------\n\nTITLE: Adding Nodes to StateGraph in Python\nDESCRIPTION: Implementation of the add_node method in StateGraph that wraps the provided action function, validates node names against reserved keywords, and stores node specifications for later execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view\ndef add_node(self, node: str, action: RunnableLike, ...):\n    # ... basic checks for name conflicts, reserved names (START, END) ...\n    if node in self.channels: # Cannot use a state key name as a node name\n         raise ValueError(...)\n    # ... wrap the provided action (function/runnable) ...\n    runnable = coerce_to_runnable(action, ...)\n    # ... store the node details (runnable, input type etc.) ...\n    self.nodes[node] = StateNodeSpec(runnable, ..., input=input or self.schema, ...)\n    return self\n```\n\n----------------------------------------\n\nTITLE: Customizing Fields with Field() Function\nDESCRIPTION: Example of a User model with fields customized using the Field() function to add defaults, aliases, and validation constraints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Import Field along with BaseModel\nfrom pydantic import BaseModel, Field\n\n# Our User model, now with customizations using Field()\nclass User(BaseModel):\n    name: str = Field(\n        default='Guest',       # Note 1: Default name is 'Guest'\n        alias='userName',      # Note 2: Expect 'userName' in input data\n        min_length=3           # Note 3: Name must be at least 3 characters\n    )\n    age: int = Field(\n        default=18,            # Note 1: Default age is 18\n        gt=0                   # Note 2: Age must be greater than 0\n    )\n    email: str | None = Field(\n        default=None,          # Note 3: Email is optional (defaults to None)\n        description='The user email address' # Note 4: Add a description\n    )\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Worker Startup Flow with Mermaid\nDESCRIPTION: A sequence diagram that illustrates the startup process of a Celery worker, showing how the Bootsteps framework manages the initialization sequence from command execution through loading blueprints, resolving dependencies, and starting individual components in the correct order.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/10_bootsteps.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant CLI as `celery worker ...`\n    participant WorkerMain as Worker Main Process\n    participant Blueprint as Main Worker Blueprint\n    participant DepGraph as Dependency Graph Builder\n    participant Step1 as Connection Step\n    participant Step2 as Pool Step\n    participant Step3 as Consumer Step\n\n    CLI->>WorkerMain: Start worker command\n    WorkerMain->>Blueprint: Load blueprint definition (steps & requires)\n    Blueprint->>DepGraph: Define steps and dependencies\n    DepGraph->>Blueprint: Return sorted startup order [Step1, Step2, Step3]\n    WorkerMain->>Blueprint: Iterate through sorted steps\n    Blueprint->>Step1: Call start()\n    Step1-->>Blueprint: Connection established\n    Blueprint->>Step2: Call start()\n    Step2-->>Blueprint: Pool initialized\n    Blueprint->>Step3: Call start()\n    Step3-->>Blueprint: Consumer loop started\n    Blueprint-->>WorkerMain: Startup complete\n    WorkerMain->>WorkerMain: Worker is Ready\n```\n\n----------------------------------------\n\nTITLE: Sending Events with EventDispatcher in Celery (Python)\nDESCRIPTION: Handles the creation and publishing of event messages using Celery's EventDispatcher class. The send() method constructs the event payload and enforces group-based filtering; it calls publish(), which formats the event dictionary and delegates message publication to Kombu via the _publish method. The implementation manages exchange declarations, routing, and serialization via Kombu's producer, supporting features like event buffering and error handling. Dependencies include Kombu, the parent Celery app (for fields like hostname/pid), and proper exchange setup. Main parameters are event type, fields, producer, and whether the event is blinded; outputs include the synchronous sending or buffering (on failure) of event metrics. Proper serializer selection and error handling are essential constraints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from events/dispatcher.py\nclass EventDispatcher:\n    # ... __init__ setup ...\n\n    def send(self, type, blind=False, ..., **fields):\n        if self.enabled:\n            groups, group = self.groups, group_from(type)\n            if groups and group not in groups:\n                 return # Don't send if this group isn't enabled\n\n            # ... potential buffering logic (omitted) ...\n\n            # Call publish to actually send\n            return self.publish(type, fields, self.producer, blind=blind,\n                                Event=Event, ...)\n\n    def publish(self, type, fields, producer, blind=False, Event=Event, **kwargs):\n        # Create the event dictionary\n        clock = None if blind else self.clock.forward()\n        event = Event(type, hostname=self.hostname, utcoffset=utcoffset(),\n                      pid=self.pid, clock=clock, **fields)\n\n        # Publish using the underlying Kombu producer\n        with self.mutex:\n            return self._publish(event, producer,\n                                 routing_key=type.replace('-', '.'), **kwargs)\n\n    def _publish(self, event, producer, routing_key, **kwargs):\n        exchange = self.exchange # The dedicated event exchange\n        try:\n            # Kombu's publish method sends the message\n            producer.publish(\n                event, # The dictionary payload\n                routing_key=routing_key,\n                exchange=exchange.name,\n                declare=[exchange], # Ensure exchange exists\n                serializer=self.serializer, # e.g., 'json'\n                headers=self.headers,\n                delivery_mode=self.delivery_mode, # e.g., transient\n                **kwargs\n            )\n        except Exception as exc:\n            # ... error handling / buffering ...\n            raise\n\n```\n\n----------------------------------------\n\nTITLE: Invoking Single-Pass Mode via Bash Command\nDESCRIPTION: Example of how to use the single-pass mode in Codex to rename a function across a project.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/08_single_pass_mode.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd ~/my-sales-app/\ncodex --single-pass \"Rename the function 'calculate_total' to 'compute_grand_total' in all project files.\"\n```\n\n----------------------------------------\n\nTITLE: Comparing Response Cookies vs. Session Cookies in Python requests\nDESCRIPTION: This snippet illustrates the difference between the cookies contained in a specific response object (`response.cookies`) and the cookies accumulated within the session's cookie jar (`session.cookies`). It creates a session, makes two separate requests to different URLs that each set a distinct cookie ('cookieA' and 'cookieB'). After each request, it prints both `response.cookies` (showing only the cookie set by *that* response) and `s.cookies` (showing *all* cookies collected by the session so far), demonstrating how the session accumulates cookies over multiple requests.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\ns = requests.Session()\n\nurl_set_a = 'https://httpbin.org/cookies/set/cookieA/valueA'\nurl_set_b = 'https://httpbin.org/cookies/set/cookieB/valueB'\n\nprint(f\"Visiting {url_set_a}\")\nresponse_a = s.get(url_set_a)\nprint(f\"Cookies SET by response A: {response_a.cookies.get_dict()}\")\nprint(f\"ALL session cookies after A: {s.cookies.get_dict()}\")\n\nprint(f\"\\nVisiting {url_set_b}\")\nresponse_b = s.get(url_set_b)\nprint(f\"Cookies SET by response B: {response_b.cookies.get_dict()}\")\nprint(f\"ALL session cookies after B: {s.cookies.get_dict()}\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Background Task Function in FastAPI (Python)\nDESCRIPTION: Defines a simple synchronous Python function `write_log` that takes a string message and appends it to a file named 'log.txt'. This function simulates a task intended to be run in the background after an API response is sent. It depends on standard Python file I/O.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# A function to simulate writing to a log\n# In a real app, this might send an email, process data, etc.\ndef write_log(message: str):\n    # Simulate writing to a file\n    with open(\"log.txt\", mode=\"a\") as log_file:\n        log_file.write(message + \"\\n\")\n    print(f\"Log written: {message}\") # Also print to console for demo\n\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic Question Answering DSPy Program in Python\nDESCRIPTION: This snippet defines a simple DSPy program `BasicQA` using `dspy.Module` and `dspy.Predict`. It takes a question as input and predicts an answer. It assumes a Language Model (LM) client has already been configured via `dspy.settings.configure`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Assume we have configured an LM client (Chapter 5)\n# gpt3_turbo = dspy.LM(model='openai/gpt-3.5-turbo')\n# dspy.settings.configure(lm=gpt3_turbo)\n\n# A simple program using dspy.Predict (Chapter 4)\nclass BasicQA(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        # Use a simple signature: question -> answer\n        self.predictor = dspy.Predict('question -> answer')\n\n    def forward(self, question):\n        return self.predictor(question=question)\n\n# Create an instance of our program\nqa_program = BasicQA()\n```\n\n----------------------------------------\n\nTITLE: LLM Retry Mechanism Implementation in Python\nDESCRIPTION: A code snippet showing how the LLM class implements retry logic using the tenacity library. This mechanism automatically retries API requests when temporary errors occur, making the agent more resilient to network issues.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/01_llm.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/llm.py\n\nfrom tenacity import retry, wait_random_exponential, stop_after_attempt, retry_if_exception_type\nfrom openai import OpenAIError\n```\n\n----------------------------------------\n\nTITLE: Creating CodeAgent with Debug Logging in Python\nDESCRIPTION: This code snippet demonstrates how to create a CodeAgent instance with debug-level logging. It imports necessary components from SmolaAgents, sets up a language model, and configures the agent with a specific verbosity level for detailed logging.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom smolagents import CodeAgent\nfrom smolagents.models import LiteLLMModel\nfrom smolagents.monitoring import LogLevel # Import LogLevel\n\nllm = LiteLLMModel(model_id=\"gpt-3.5-turbo\")\n\n# Create an agent with DEBUG level logging\nagent_debug = CodeAgent(\n    model=llm,\n    tools=[],\n    verbosity_level=LogLevel.DEBUG # Set the level here\n)\n\n# This agent will print more detailed logs when run\n```\n\n----------------------------------------\n\nTITLE: Implementing TopicId Class in Python\nDESCRIPTION: Defines the TopicId dataclass that represents message topics with type and source components. Used to create unique identifiers for message channels.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@dataclass(frozen=True)\nclass TopicId:\n    type: str\n    source: str\n\n    def __str__(self) -> str:\n        return f\"{self.type}/{self.source}\"\n```\n\n----------------------------------------\n\nTITLE: Initializing BrowserContext with UUID in Python\nDESCRIPTION: Simplified code snippet showing the beginning of a BrowserContext class implementation that uses UUID for context identification. This is part of the internal implementation details showing how each browser context gets a unique identifier.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/03_browsercontext.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: browser/context.py (Simplified __init__) ---\nimport uuid\n```\n\n----------------------------------------\n\nTITLE: Defining and Using a User Blueprint in Flask - Python\nDESCRIPTION: This snippet defines a Flask Blueprint for user-related routes in a separate module. It demonstrates creating a Blueprint object, specifying a dedicated template folder, defining routes on the blueprint, and using sample in-memory user data. This code requires Flask to be installed and expects templates to reside in '../templates/user/'. The blueprint expects the username as a URL parameter and will render a template if the user exists, or abort with a 404 otherwise. The snippet does not include authentication logic and assumes only two static users. Outputs include HTML pages rendered via Jinja2 templates and simple responses for user lists.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# blueprints/user.py\nfrom flask import Blueprint, render_template, abort\n\n# 1. Create the Blueprint object\n# 'user' is the name of the blueprint. Used internally by Flask.\n# __name__ helps locate the blueprint's resources (like templates).\n# template_folder specifies where to look for this blueprint's templates.\nuser_bp = Blueprint('user', __name__, template_folder='../templates/user')\n\n# Sample user data (replace with database logic in a real app)\nusers = {\n    \"alice\": {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n    \"bob\": {\"name\": \"Bob\", \"email\": \"bob@example.com\"},\n}\n\n# 2. Define routes ON THE BLUEPRINT using @user_bp.route()\n@user_bp.route('/profile/<username>')\ndef profile(username):\n  user_info = users.get(username)\n  if not user_info:\n    abort(404) # User not found\n  # Note: render_template will now look in 'templates/user/' first\n  # because of template_folder='../templates/user' in Blueprint()\n  return render_template('profile.html', user=user_info)\n\n@user_bp.route('/')\ndef user_list():\n    # A simple view within the user blueprint\n    return f\"List of users: {', '.join(users.keys())}\"\n```\n\n----------------------------------------\n\nTITLE: Writing Tutorial Chapters in Batch with Contextualized LLM - Python\nDESCRIPTION: This batch node generates full chapter Markdown documents for each chapter abstraction, possibly in a translated language, by invoking an LLM with extensive context including project structure, previously written chapters, related file contents, and navigation parameters. It maintains in-memory tracking of chapters for continuity, supports translation requirements, and outputs a complete, ordered list of chapter Markdown strings. Batch design enables iteration over abstractions; dependencies include the LLM, shared store, and chapter sequencing data.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `chapter_order` (indices), `abstractions`, `files`, `project_name`, and `language` from shared store. Initialize an empty instance variable `self.chapters_written_so_far`. Return an iterable list where each item corresponds to an *abstraction index* from `chapter_order`. Each item should contain chapter number, potentially translated abstraction details, a map of related file content (`{ \"idx # path\": content }`), full chapter listing (potentially translated names), chapter filename map, previous/next chapter info (potentially translated names), and language.\n        *   `exec(item)`: Construct a prompt for `call_llm`. If language is not English, add detailed instructions to write the *entire* chapter in the target language, translating explanations, examples, etc., while noting which input context might already be translated. Ask LLM to write a beginner-friendly Markdown chapter. Provide potentially translated concept details. Include a summary of previously written chapters (potentially translated). Provide relevant code snippets. Add the generated (potentially translated) chapter content to `self.chapters_written_so_far` for the next iteration's context. Return the chapter content.\n        *   `post(shared, prep_res, exec_res_list)`: `exec_res_list` contains the generated chapter Markdown content strings (potentially translated), ordered correctly. Assign this list directly to `shared[\"chapters\"]`. Clean up `self.chapters_written_so_far`.\n```\n\n----------------------------------------\n\nTITLE: Receiving Celery Events with EventReceiver (Python)\nDESCRIPTION: Configures event listening via the EventReceiver class, which leverages Kombu's ConsumerMixin to create an event queue and attach handler callbacks. __init__ prepares a unique, auto-deleting queue for event traffic; get_consumers configures consumer objects to invoke the _receive method upon message arrival. The _receive method handles both single-event and list batching (as per newer Celery versions), decoding each event and dispatching it to the custom handler in process. The snippet demonstrates dynamic, handler-based processing of a real-time event stream. It depends on Kombu, the main Celery app, and correct queue/exchange configuration; parameters include the channel, custom event handlers, and routing keys. Outputs are event data processed by supplied handlers, limited by handler completeness and queue configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from events/receiver.py\nclass EventReceiver(ConsumerMixin): # Uses Kombu's ConsumerMixin\n\n    def __init__(self, channel, handlers=None, routing_key='#', ...):\n        # ... setup app, channel, handlers ...\n        self.exchange = get_exchange(..., name=self.app.conf.event_exchange)\n        self.queue = Queue( # Create a unique, auto-deleting queue\n            '.'.join([self.queue_prefix, self.node_id]),\n            exchange=self.exchange,\n            routing_key=routing_key, # Often '#' to get all events\n            auto_delete=True, durable=False,\n            # ... other queue options ...\n        )\n        # ...\n\n    def get_consumers(self, Consumer, channel):\n        # Tell ConsumerMixin to consume from our event queue\n        return [Consumer(queues=[self.queue],\n                         callbacks=[self._receive], # Method to call on message\n                         no_ack=True, # Events usually don't need explicit ack\n                         accept=self.accept)]\n\n    # This method is registered as the callback for new messages\n    def _receive(self, body, message):\n        # Decode message body (can be single event or list in newer Celery)\n        if isinstance(body, list):\n            process, from_message = self.process, self.event_from_message\n            [process(*from_message(event)) for event in body]\n        else:\n            self.process(*self.event_from_message(body))\n\n    # process() calls the appropriate handler from self.handlers\n    def process(self, type, event):\n        \"\"\"Process event by dispatching to configured handler.\"\"\"\n        handler = self.handlers.get(type) or self.handlers.get('*')\n        handler and handler(event) # Call the handler function\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing Conditional Graph Flow with Mermaid\nDESCRIPTION: Provides a Mermaid diagram illustrating the structure and conditional flow of the example LangGraph. It shows the 'Decider' node leading to a routing logic step, which branches to either the 'Search' node or the 'Respond' node based on the outcome of the routing function. Both paths eventually converge at the 'Respond' node before reaching the end.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    Start[START] --> Decider(decider);\n    Decider -- route_based_on_action --> Route{Routing Logic};\n    Route -- \"route_to_tool\" --> Search(search_tool);\n    Route -- \"route_to_respond\" --> Respond(responder);\n    Search --> Respond;\n    Respond --> End(END);\n```\n\n----------------------------------------\n\nTITLE: Initializing Single-Pass Mode in TypeScript\nDESCRIPTION: Entry point function for single-pass mode in Codex, rendering the main React component for the single-pass UI.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/08_single_pass_mode.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/cli_singlepass.tsx (Simplified)\nimport type { AppConfig } from \"./utils/config\";\nimport { SinglePassApp } from \"./components/singlepass-cli-app\";\nimport { render } from \"ink\";\nimport React from \"react\";\n\n// This function is called by the main CLI logic\nexport async function runSinglePass({\n  originalPrompt, // The user's request string\n  config,         // Loaded configuration (model, instructions)\n  rootPath,       // The project directory\n}: { /* ... */ }): Promise<void> {\n  return new Promise((resolve) => {\n    // Render the dedicated Ink UI for single-pass mode\n    render(\n      <SinglePassApp\n        originalPrompt={originalPrompt}\n        config={config}\n        rootPath={rootPath}\n        onExit={() => resolve()} // Callback when the app is done\n      />,\n    );\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Defining ContentScrapingStrategy Abstract Base Class (Python)\nDESCRIPTION: This snippet shows the blueprint for content scraping strategies in Crawl4AI. It defines an abstract base class with synchronous and asynchronous methods for scraping content.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/content_scraping_strategy.py\nfrom abc import ABC, abstractmethod\nfrom .models import ScrapingResult # Defines the structure of the result\n\nclass ContentScrapingStrategy(ABC):\n    \"\"\"Abstract base class for content scraping strategies.\"\"\"\n\n    @abstractmethod\n    def scrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n        \"\"\"\n        Synchronous method to scrape content.\n        Takes raw HTML, returns structured ScrapingResult.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    async def ascrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n        \"\"\"\n        Asynchronous method to scrape content.\n        Takes raw HTML, returns structured ScrapingResult.\n        \"\"\"\n        pass\n```\n\n----------------------------------------\n\nTITLE: Evaluation Process Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram showing the flow of evaluation from user initialization through parallel execution to final result aggregation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_8\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Evaluator as dspy.Evaluate\n    participant Executor as ParallelExecutor\n    participant Program as Your DSPy Program\n    participant Metric as Your Metric Function\n\n    User->>Evaluator: __call__(program)\n    Evaluator->>Executor: Create (manages threads)\n    loop For each example in devset\n        Executor->>Executor: Assign task to a thread\n        Note over Executor, Program: In parallel thread:\n        Executor->>Program: Call program(**example.inputs())\n        Program-->>Executor: Return prediction\n        Executor->>Metric: Call metric(example, prediction)\n        Metric-->>Executor: Return score\n    end\n    Executor->>Evaluator: Collect all results (predictions, scores)\n    Evaluator->>Evaluator: Calculate average score\n    Evaluator-->>User: Return average score (and other requested data)\n```\n\n----------------------------------------\n\nTITLE: Executing Sequential Task Processing - Python\nDESCRIPTION: Implements the '_run_sequential_process' private method for executing tasks in a strict sequence, each time passing context from previous outputs. It depends on the availability of tasks and agent assignments, and returns a CrewOutput by aggregating individual task results. This approach provides predictable and linear execution suitable for simple pipelines.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef _run_sequential_process(self) -> CrewOutput:\n    task_outputs = []\n    for task_index, task in enumerate(self.tasks):\n        agent = task.agent # Get assigned agent\n        # ... handle conditional tasks, async tasks ...\n        context = self._get_context(task, task_outputs) # Get previous output\n        output = task.execute_sync(agent=agent, context=context) # Run task\n        task_outputs.append(output)\n        # ... logging/callbacks ...\n    return self._create_crew_output(task_outputs)\n```\n\n----------------------------------------\n\nTITLE: Implementing Researcher Agent Logic in Python for AutoGen Core\nDESCRIPTION: This code demonstrates the implementation of researcher agent logic that processes a research topic, generates facts, and sends them to a writer agent. It shows how an agent receives messages, processes them, and communicates with other agents in the system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept - requires AgentRuntime (Chapter 3) to actually run\n\nasync def researcher_logic(agent_context, message: ResearchTopic, msg_context):\n    print(f\"Researcher received topic: {message.topic}\")\n    # In a real scenario, this would involve searching, calling an LLM, etc.\n    # For now, we just make up facts.\n    facts = [f\"Fact 1 about {message.topic}\", f\"Fact 2 about {message.topic}\"]\n    print(f\"Researcher found facts: {facts}\")\n\n    # Find the Writer agent's ID (we assume we know it)\n    writer_id = AgentId(type=\"writer\", key=\"blog_writer_1\")\n\n    # Send the facts to the Writer\n    await agent_context.send_message(\n        message=ResearchFacts(topic=message.topic, facts=facts),\n        recipient=writer_id,\n    )\n    print(\"Researcher sent facts to Writer.\")\n    # This agent doesn't return a direct reply\n    return None\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Celery Configuration Loading and Usage\nDESCRIPTION: This code snippet illustrates two key aspects of Celery's configuration system: how configuration is loaded from objects via the BaseLoader class, and how configuration settings are accessed when sending tasks. It shows the relationship between configuration loading and usage in the codebase.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept from loaders/base.py\nclass BaseLoader:\n    # ...\n    def config_from_object(self, obj, silent=False):\n        if isinstance(obj, str):\n            # Import the module (e.g., 'celeryconfig')\n            obj = self._smart_import(obj, imp=self.import_from_cwd)\n            # ... error handling ...\n        # Store the configuration (simplified - actual process merges)\n        self._conf = force_mapping(obj) # Treat obj like a dictionary\n        # ...\n        return True\n\n# Simplified concept from app/base.py (where settings are used)\nclass Celery:\n    # ...\n    def send_task(self, name, args=None, kwargs=None, **options):\n        # ... other setup ...\n\n        # Access configuration to know where the broker is\n        broker_connection_url = self.conf.broker_url # Reads from app.conf\n\n        # Use the broker URL to get a connection/producer\n        with self.producer_or_acquire(producer) as P:\n             # ... create message ...\n             # Send message using the connection derived from broker_url\n             self.amqp.send_task_message(P, name, message, **options)\n\n        # ... return result object ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Tool Invocation Flow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram models the end-to-end interaction flow between CrewAI agents, their LLMs, and a Search Tool during task execution. It graphically illustrates each message, internal decision, and result exchange required to fulfill a research query using tool assistance. There are no code dependencies, but familiarity with Mermaid syntax is required to render the diagram.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/04_tool.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant A as Agent\\n    participant LLM as Agent's Brain\\n    participant ST as Search Tool\\n\\n    A->>LLM: Task: \\\"Find sunny cities...\\\" Plan?\\n    LLM-->>A: Plan: Need current info. Search web for \\\"sunny European cities May\\\".\\n    A->>A: Check tools: Found 'Search' tool (description matches).\\n    A->>LLM: Format request for 'Search' tool. Query?\\n    LLM-->>A: Output: Use Tool 'Search' with args {\\\"query\\\": \\\"sunny European cities May\\\"}\\n    A->>ST: run(query=\\\"sunny European cities May\\\")\\n    Note right of ST: ST._run() calls Serper API...\\n    ST-->>A: Return results: \\\"Lisbon (Sunny...), Seville (Hot...), Malta (Warm...)\\\"\\n    A->>LLM: Observation: Got results \\\"Lisbon...\\\", \\\"Seville...\\\", \\\"Malta...\\\"\\n    LLM-->>A: Thought: Use these results to formulate the final list.\\n    LLM-->>A: Final Answer: \\\"Based on recent web search, the top cities are...\\\"\n```\n\n----------------------------------------\n\nTITLE: Building LangGraph with Conditional Edges in Python\nDESCRIPTION: Constructs the LangGraph `StateGraph` using the defined state and nodes. It sets the entry point to the 'decider' node. Critically, it uses `add_conditional_edges` to connect the 'decider' node to the `route_based_on_action` function, mapping the function's output strings ('route_to_tool', 'route_to_respond') to the corresponding next nodes ('search_tool', 'responder'). Regular edges define the flow after the conditional paths, and the graph is compiled.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.graph import StateGraph, END, START\n\nworkflow = StateGraph(ChatState)\n\nworkflow.add_node(\"decider\", determine_action)\nworkflow.add_node(\"search_tool\", run_search_tool)\nworkflow.add_node(\"responder\", generate_response)\n\nworkflow.set_entry_point(\"decider\")\n\n# After 'decider', call 'route_based_on_action' to choose the next step\nworkflow.add_conditional_edges(\n    \"decider\", # Start node\n    route_based_on_action, # The routing function\n    {\n        # Map the routing function's output to actual node names\n        \"route_to_tool\": \"search_tool\",\n        \"route_to_respond\": \"responder\"\n    }\n)\n\n# Define what happens *after* the conditional paths\nworkflow.add_edge(\"search_tool\", \"responder\") # After searching, generate response\nworkflow.add_edge(\"responder\", END) # After responding, end\n\n# Compile\napp = workflow.compile()\n```\n\n----------------------------------------\n\nTITLE: Defining Telemetry Event Structures with Pydantic in Python\nDESCRIPTION: This snippet demonstrates the use of Pydantic models to define the structure of telemetry events. It includes a base class for all events and a specific event for agent runs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass, asdict\nfrom typing import Any, Dict, Sequence\n\n# Base class for all telemetry events (conceptual)\n@dataclass\nclass BaseTelemetryEvent:\n    @property\n    def name(self) -> str:\n        raise NotImplementedError\n    @property\n    def properties(self) -> Dict[str, Any]:\n        # Helper to convert the dataclass fields to a dictionary\n        return {k: v for k, v in asdict(self).items() if k != 'name'}\n\n# Specific event for when an agent run starts\n@dataclass\nclass AgentRunTelemetryEvent(BaseTelemetryEvent):\n    agent_id: str        # Anonymous ID for the specific agent instance\n    use_vision: bool     # Was vision enabled?\n    task: str            # The task description (anonymized/hashed in practice)\n    model_name: str      # Name of the LLM used\n    chat_model_library: str # Library used for the LLM (e.g., ChatOpenAI)\n    version: str         # browser-use version\n    source: str          # How browser-use was installed (e.g., pip, git)\n    name: str = 'agent_run' # The event name sent to PostHog\n```\n\n----------------------------------------\n\nTITLE: Simple Python Decorator Example\nDESCRIPTION: This snippet demonstrates a basic Python decorator implementation, showing how decorators modify function behavior by wrapping the original function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# A simple Python decorator\ndef simple_decorator(func):\n  def wrapper():\n    print(\"Something is happening before the function is called.\")\n    func() # Call the original function\n    print(\"Something is happening after the function is called.\")\n  return wrapper # Return the modified function\n\n@simple_decorator # Apply the decorator\ndef say_whee():\n  print(\"Whee!\")\n\n# Now, when we call say_whee...\nsay_whee()\n```\n\n----------------------------------------\n\nTITLE: Saving Flow Sequence Diagram (Mermaid)\nDESCRIPTION: A sequence diagram illustrating the flow of the dump_component method, showing interactions between User, MyMemory (ListMemory instance), ListMemoryConfig, and ComponentModel.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MyMemory as my_memory (ListMemory instance)\n    participant ListMemConfig as ListMemoryConfig (Pydantic Model)\n    participant CompModel as ComponentModel\n\n    User->>+MyMemory: dump_component()\n    MyMemory->>MyMemory: Calls internal self._to_config()\n    MyMemory->>+ListMemConfig: Creates Config object (name=\"...\", contents=[...])\n    ListMemConfig-->>-MyMemory: Returns Config object\n    MyMemory->>MyMemory: Gets provider string (\"autogen_core.memory.ListMemory\")\n    MyMemory->>MyMemory: Gets component_type (\"memory\"), version, etc.\n    MyMemory->>+CompModel: Creates ComponentModel(provider=..., config=config_dict, ...)\n    CompModel-->>-MyMemory: Returns ComponentModel instance\n    MyMemory-->>-User: Returns ComponentModel instance\n```\n\n----------------------------------------\n\nTITLE: Implementing Database Recovery Using LogReader in LevelDB\nDESCRIPTION: This code demonstrates how LevelDB uses the log::Reader to recover data from a Write-Ahead Log file. It shows the process of reading records from the log, parsing them into WriteBatch objects, and applying them to a MemTable to rebuild the database state after a crash.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/03_write_ahead_log__wal____logwriter_logreader.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/db_impl.cc ---\n// Inside DBImpl::RecoverLogFile(...)\n\n// Create the log reader for the specific log file number\nstd::string fname = LogFileName(dbname_, log_number);\nSequentialFile* file;\nStatus status = env_->NewSequentialFile(fname, &file);\n// ... check status ...\n\n// Set up reporter for corruption errors\nlog::Reader::Reporter reporter;\n// ... initialize reporter ...\nlog::Reader reader(file, &reporter, true /*checksum*/, 0 /*initial_offset*/);\n\n// Read records one by one and apply them to a temporary MemTable\nstd::string scratch;\nSlice record;\nWriteBatch batch;\nMemTable* mem = new MemTable(internal_comparator_);\nmem->Ref();\n\nwhile (reader.ReadRecord(&record, &scratch) && status.ok()) {\n  // record now holds a complete record originally passed to AddRecord\n\n  // Parse the record back into a WriteBatch\n  WriteBatchInternal::SetContents(&batch, record);\n\n  // Apply the operations from the batch to the MemTable\n  status = WriteBatchInternal::InsertInto(&batch, mem);\n  // ... check status ...\n\n  // Update the max sequence number seen\n  const SequenceNumber last_seq = /* ... get from batch ... */;\n  if (last_seq > *max_sequence) {\n    *max_sequence = last_seq;\n  }\n\n  // Optional: If MemTable gets too big during recovery, flush it\n  if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n    status = WriteLevel0Table(mem, edit, nullptr); // Flush to SSTable\n    mem->Unref();\n    mem = new MemTable(internal_comparator_);\n    mem->Ref();\n    // ... check status ...\n  }\n}\n\ndelete file; // Close the log file\n// ... handle final MemTable (mem) if not null ...\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Built-in Tools in SmolaAgents (Python)\nDESCRIPTION: This Python example shows how to import built-in tools from the smolagents.tools module and integrate them into a MultiStepAgent instance. It demonstrates initializing the DuckDuckGoSearchTool, optionally the PythonInterpreterTool, and supplying these as utilities for the agent to execute LLM-suggested operations. Dependencies: smolagents, an LLM instance (llm). Inputs: agent configuration, tool selection. Outputs: an agent instance ready to use built-in tools.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom smolagents.tools import DuckDuckGoSearchTool, FinalAnswerTool # FinalAnswerTool is usually added automatically\n\nsearch_tool = DuckDuckGoSearchTool()\n# calculator_tool = PythonInterpreterTool() # Often used internally by CodeAgent\n\nagent = MultiStepAgent(\n    model=llm,\n    tools=[search_tool] # Agent can now search!\n)\n\n```\n\n----------------------------------------\n\nTITLE: Setting Persistent Headers, Auth, and Params in Requests Session (Python)\nDESCRIPTION: This Python snippet demonstrates setting default headers, authentication credentials, and query parameters on a requests.Session object. Required dependencies: requests and os, with possible use of environment variables for authentication. The code shows how to update session-wide headers and parameters, assign authentication, and confirms their presence by inspecting responses from httpbin.org. Inputs are headers, auth details, and params; outputs are echoed request data received from the server. Limitations include network connectivity and that /get endpoint does not authenticate users directly.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/03_session.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\\nimport os # To get environment variables for auth example\\n\\ns = requests.Session()\\n\\n# Set a default header for all requests made by this session\\ns.headers.update({'X-My-Custom-Header': 'HelloSession'})\\n\\n# Set default authentication (using basic auth from environment variables for example)\\n# NOTE: Replace with actual username/password or use httpbin's basic-auth endpoint\\n# For httpbin, the user/pass is 'user'/'pass'\\n# s.auth = ('user', 'passwd') # Set directly if needed\\nhttpbin_user = os.environ.get(\"HTTPBIN_USER\", \"testuser\") # Fake user if not set\\nhttpbin_pass = os.environ.get(\"HTTPBIN_PASS\", \"testpass\") # Fake pass if not set\\ns.auth = (httpbin_user, httpbin_pass)\\n\\n# Set default query parameters\\ns.params.update({'session_param': 'persistent'})\\n\\n# Now make a request\\nurl = 'https://httpbin.org/get' # Changed endpoint to see params\\nprint(f\"Making request with persistent session settings to: {url}\")\\nresponse = s.get(url)\\n\\nprint(f\"\\nStatus Code: {response.status_code}\")\\n# Check the response (httpbin.org/get echoes back request details)\\nresponse_data = response.json()\\nprint(\"\\nHeaders sent (look for X-My-Custom-Header):\")\\nprint(response_data['headers'])\\n# print(\"\\nAuth info sent (if using httpbin basic-auth):\")\\n# print(response_data.get('authenticated'), response_data.get('user')) # Won't show here for /get\\nprint(\"\\nQuery parameters sent (look for session_param):\")\\nprint(response_data['args'])\\n\\n# Make another request to a different endpoint using the same session\\nheaders_url = 'https://httpbin.org/headers'\\nprint(f\"\\nMaking request to {headers_url}...\")\\nresponse_headers = s.get(headers_url)\\nprint(\"Headers received by second request (still has custom header):\")\\nprint(response_headers.json()['headers'])\\n\n```\n\n----------------------------------------\n\nTITLE: Preparing LLM Messages for Text Summarization in Python\nDESCRIPTION: This code demonstrates how to prepare structured input messages for an LLM using SystemMessage and UserMessage objects. It creates a system prompt that instructs the LLM to summarize text, and a user message containing the text to be summarized.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# File: prepare_messages.py\nfrom autogen_core.models import SystemMessage, UserMessage\n\n# Instructions for the LLM\nsystem_prompt = SystemMessage(\n    content=\"You are a helpful assistant designed to summarize text concisely.\"\n)\n\n# The text we want to summarize\narticle_text = \"\"\"\nAutoGen is a framework that enables the development of LLM applications using multiple agents\nthat can converse with each other to solve tasks. AutoGen agents are customizable,\nconversable, and can seamlessly allow human participation. They can operate in various modes\nthat employ combinations of LLMs, human inputs, and tools.\n\"\"\"\nuser_request = UserMessage(\n    content=f\"Please summarize the following text in one sentence:\\n\\n{article_text}\",\n    source=\"User\" # Indicate who provided this input\n)\n\n# Combine into a list for the client\nmessages_to_send = [system_prompt, user_request]\n\nprint(\"Messages prepared:\")\nfor msg in messages_to_send:\n    print(f\"- {msg.type}: {msg.content[:50]}...\") # Print first 50 chars\n```\n\n----------------------------------------\n\nTITLE: Implementing DockerSandbox for Container Management in Python\nDESCRIPTION: This class directly interacts with the Docker engine to create, manage, and remove containers. It handles container creation, command execution, file writing, and cleanup operations using the Docker Python library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/sandbox/core/sandbox.py\nimport docker\nimport asyncio\nfrom app.config import SandboxSettings\nfrom app.sandbox.core.terminal import AsyncDockerizedTerminal # For running commands\n\nclass DockerSandbox:\n    def __init__(self, config: Optional[SandboxSettings] = None, ...):\n        self.config = config or SandboxSettings()\n        self.client = docker.from_env() # Connect to Docker engine\n        self.container: Optional[docker.models.containers.Container] = None\n        self.terminal: Optional[AsyncDockerizedTerminal] = None\n\n    async def create(self) -> \"DockerSandbox\":\n        \"\"\"Creates and starts the Docker container.\"\"\"\n        try:\n            # 1. Prepare container settings (image, limits, etc.) from self.config\n            container_config = {...} # Simplified\n\n            # 2. Use Docker client to create the container\n            container_data = await asyncio.to_thread(\n                self.client.api.create_container, **container_config\n            )\n            self.container = self.client.containers.get(container_data[\"Id\"])\n\n            # 3. Start the container\n            await asyncio.to_thread(self.container.start)\n\n            # 4. Initialize a terminal interface to run commands inside\n            self.terminal = AsyncDockerizedTerminal(container_data[\"Id\"], ...)\n            await self.terminal.init()\n            return self\n        except Exception as e:\n            await self.cleanup() # Cleanup on failure\n            raise RuntimeError(f\"Failed to create sandbox: {e}\")\n\n    async def run_command(self, cmd: str, timeout: Optional[int] = None) -> str:\n        \"\"\"Runs a command using the container's terminal.\"\"\"\n        if not self.terminal: raise RuntimeError(\"Sandbox not initialized\")\n        # Use the terminal helper to execute the command and get output\n        return await self.terminal.run_command(\n            cmd, timeout=timeout or self.config.timeout\n        )\n\n    async def write_file(self, path: str, content: str) -> None:\n        \"\"\"Writes content to a file inside the container.\"\"\"\n        if not self.container: raise RuntimeError(\"Sandbox not initialized\")\n        try:\n            # Simplified: Creates a temporary tar archive with the file\n            # and uses Docker's put_archive to copy it into the container\n            tar_stream = await self._create_tar_stream(...) # Helper method\n            await asyncio.to_thread(\n                self.container.put_archive, \"/\", tar_stream\n            )\n        except Exception as e:\n            raise RuntimeError(f\"Failed to write file: {e}\")\n\n    async def cleanup(self) -> None:\n        \"\"\"Stops and removes the Docker container.\"\"\"\n        if self.terminal: await self.terminal.close()\n        if self.container:\n            try:\n                await asyncio.to_thread(self.container.stop, timeout=5)\n            except Exception: pass # Ignore errors on stop\n            try:\n                await asyncio.to_thread(self.container.remove, force=True)\n            except Exception: pass # Ignore errors on remove\n            self.container = None\n```\n\n----------------------------------------\n\nTITLE: Implementing Async Web Crawler with LLM Integration in Python\nDESCRIPTION: Demonstrates a complete workflow for using an LLM-based extraction strategy with a web crawler. The code defines an output schema, creates the LLM strategy, configures the crawler, runs it against a URL, and processes the extracted results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/06_extractionstrategy.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync def main():\n    # 1. Define the desired output schema (what fields we want)\n    #    This helps guide the LLM.\n    output_schema = {\n        \"page_title\": \"string\",\n        \"main_heading\": \"string\"\n    }\n    print(\"Extraction Schema defined for LLM.\")\n\n    # 2. Create an instance of the LLM strategy\n    #    We pass the schema and the LLM configuration.\n    #    We also specify input_format='markdown' (common for LLMs).\n    llm_extractor = LLMExtractionStrategy(\n        schema=output_schema,\n        llmConfig=llm_config, # Pass the LLM provider details\n        input_format=\"markdown\" # Tell it to read the Markdown content\n    )\n    print(f\"Using strategy: {llm_extractor.__class__.__name__}\")\n    print(f\"LLM Provider (mocked): {llm_config.provider}\")\n\n    # 3. Create CrawlerRunConfig with the strategy\n    run_config = CrawlerRunConfig(\n        extraction_strategy=llm_extractor\n    )\n\n    # 4. Run the crawl\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n        print(f\"\\nCrawling {url_to_crawl} using LLM to extract...\")\n\n        # This would make calls to the configured LLM API\n        result = await crawler.arun(url=url_to_crawl, config=run_config)\n\n        if result.success and result.extracted_content:\n            print(\"\\nExtraction successful (using LLM)!\")\n            # Extracted data is a JSON string\n            try:\n                extracted_data = json.loads(result.extracted_content)\n                print(\"Extracted Data:\")\n                print(json.dumps(extracted_data, indent=2))\n            except json.JSONDecodeError:\n                print(\"Could not parse LLM output as JSON:\")\n                print(result.extracted_content)\n        elif result.success:\n            print(\"\\nCrawl successful, but no structured data extracted by LLM.\")\n            # This might happen if the mock LLM doesn't return valid JSON\n            # or if the content was too small/irrelevant for extraction.\n        else:\n            print(f\"\\nCrawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: HITL Interrupt-and-Resume with Checkpointer in LangGraph (Python)\nDESCRIPTION: This example demonstrates the integration of a checkpointer with a graph that uses human-in-the-loop (HITL) interrupts. After a node triggers an interrupt, the workflow persists its exact state using MemorySaver. Execution can then be resumed by invoking the graph again (via stream) with the same config and a human response command. This approach is essential for workflows with manual intervention steps. Dependencies include langgraph.types.Command, proper node definitions, and a compiled workflow. Key inputs are the initial state and human feedback; outputs are seamless paused/resumed workflow processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# (Simplified HITL example from Chapter 4)\\nfrom langgraph.types import interrupt, Command\\n# ... (State, Nodes: create_plan, request_approval, execute_plan) ...\\n\\n# Compile WITH checkpointer (REQUIRED for interrupt)\\nmemory_saver_hitl = MemorySaver()\\napp_hitl = workflow.compile(checkpointer=memory_saver_hitl)\\n\\n# Run, get interrupted\\nconfig_hitl = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\\nfor chunk in app_hitl.stream({\"plan\": \"\"}, config=config_hitl):\\n    # ... (detect interrupt) ...\\n    print(\"Graph interrupted!\")\\n    break\\n\\n# Resume after human decision\\nhuman_decision = \"Approved\"\\nfor chunk in app_hitl.stream(Command(resume=human_decision), config=config_hitl):\\n     # ... (process remaining steps) ...\\n     print(\"Graph resumed and finished!\")\n```\n\n----------------------------------------\n\nTITLE: Context Injection in Tool Class (Python)\nDESCRIPTION: This code demonstrates how the Tool class inspects a function's signature to detect a Context parameter and later injects it when running the tool.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Inside server/fastmcp/tools/base.py (Simplified Tool.from_function)\nclass Tool(BaseModel):\n    # ... fields ...\n    context_kwarg: str | None = Field(...)\n\n    @classmethod\n    def from_function(cls, fn, ...) -> Tool:\n        # ... other inspection ...\n        context_param_name = None\n        sig = inspect.signature(fn)\n        for param_name, param in sig.parameters.items():\n            # Check if the type hint is Context\n            if param.annotation is Context:\n                context_param_name = param_name\n                break\n        # ... create FuncMetadata, skipping context arg ...\n        return cls(\n            # ...,\n            context_kwarg=context_param_name,\n            # ...\n        )\n\n# Inside Tool.run (simplified concept)\nasync def run(self, arguments, context=None):\n    # ... validate args ...\n    kwargs_for_fn = validated_args\n    if self.context_kwarg and context:\n         # Add the context object to the arguments passed to the function\n        kwargs_for_fn[self.context_kwarg] = context\n\n    # Call the original function (self.fn)\n    result = await self.fn(**kwargs_for_fn) # Or sync call\n    return result\n```\n\n----------------------------------------\n\nTITLE: Handling Command Execution in Codex Agent\nDESCRIPTION: Core function for handling command execution, demonstrating how Codex determines whether to run commands directly or in a sandbox based on approval policies. It shows the workflow from approval checking to command execution and result handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/handle-exec-command.ts (Simplified Snippet)\n\nimport { execCommand } from \"./exec-command-helper\"; // (Conceptual helper name)\nimport { getSandbox } from \"./sandbox-selector\"; // (Conceptual helper name)\n// ... other imports: canAutoApprove, config, policy types ...\n\nasync function handleExecCommand(\n  args: ExecInput, // Contains { cmd: [\"git\", \"status\"], ... }\n  config: AppConfig,\n  policy: ApprovalPolicy,\n  getCommandConfirmation: (/*...*/) => Promise<CommandConfirmation>,\n  // ... abortSignal ...\n): Promise<HandleExecCommandResult> {\n\n  // 1. Check policy (calls canAutoApprove)\n  const safety = canAutoApprove(command, policy, [process.cwd()]);\n  let runInSandbox: boolean;\n\n  // 2. Determine if approved and if sandbox needed\n  switch (safety.type) {\n    case \"ask-user\":\n      // Ask user via getCommandConfirmation...\n      // If approved, runInSandbox = false;\n      break;\n    case \"auto-approve\":\n      runInSandbox = safety.runInSandbox; // Get sandbox flag from policy check\n      break;\n    // ... handle reject ...\n  }\n\n  // 3. *** Execute the command! ***\n  // Determine the actual sandbox mechanism (Seatbelt, Docker, None)\n  const sandboxType = await getSandbox(runInSandbox);\n  // Call the function that handles execution\n  const summary = await execCommand(\n    args,\n    applyPatch, // (if it was an apply_patch command)\n    sandboxType,\n    abortSignal,\n  );\n\n  // 4. Format and return results\n  return convertSummaryToResult(summary);\n}\n```\n\n----------------------------------------\n\nTITLE: Example Output of SimpleRAG Program Execution\nDESCRIPTION: Shows the expected standard output format when the `SimpleRAG` Python program is successfully executed. It displays the input question followed by the answer generated by the RAG pipeline.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_7\n\nLANGUAGE: text\nCODE:\n```\nQuestion: What is the largest rodent?\nAnswer: The largest rodent is the capybara.\n```\n\n----------------------------------------\n\nTITLE: Conceptualizing a Basic DSPy Module in Python\nDESCRIPTION: Defines a simplified Python class `BasicPredict` inheriting from `dspy.Module` to illustrate the basic structure. It includes an `__init__` method to store instructions and a `forward` method that conceptually combines instructions with input data to produce an output, mimicking a language model call. This example demonstrates the core components (`__init__`, `forward`) and inheritance pattern of DSPy modules. Dependencies include the `dspy` library. Input is `input_data`, output is `lm_output` (a dummy string in this example).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/01_module___program.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Conceptual structure of a simple Module like dspy.Predict\nclass BasicPredict(dspy.Module): # Inherits from dspy.Module\n    def __init__(self, instructions):\n        super().__init__() # Important initialization\n        self.instructions = instructions\n        # In a real DSPy module, we'd set up LM connection here\n        # self.lm = ... (connect to language model)\n\n    def forward(self, input_data):\n        # 1. Combine instructions and input_data\n        prompt = self.instructions + \"\\nInput: \" + input_data + \"\\nOutput:\"\n\n        # 2. Call the Language Model (LM) with the prompt\n        # lm_output = self.lm(prompt) # Simplified call\n        lm_output = f\"Generated answer for '{input_data}' based on instructions.\" # Dummy output\n\n        # 3. Return the result\n        return lm_output\n\n# How you might use it (conceptual)\n# predictor = BasicPredict(instructions=\"Translate the input to French.\")\n# french_text = predictor(input_data=\"Hello\")\n# print(french_text) # Might output: \"Generated answer for 'Hello' based on instructions.\"\n```\n\n----------------------------------------\n\nTITLE: Using the out parameter with NumPy ufuncs\nDESCRIPTION: Demonstration of the out parameter in NumPy ufuncs, which allows results to be stored in a pre-allocated array instead of creating a new one, improving memory efficiency for large arrays or operations in loops.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\na = np.arange(5)       # [0 1 2 3 4]\nb = np.arange(5, 10)   # [5 6 7 8 9]\n\n# Create an empty array with the same shape and type\nresult = np.empty_like(a)\n\n# Perform addition, storing the result in the 'result' array\nnp.add(a, b, out=result)\n\nprint(f\"a = {a}\")\nprint(f\"b = {b}\")\nprint(f\"result (after np.add(a, b, out=result)) = {result}\")\n# Output:\n# a = [0 1 2 3 4]\n# b = [5 6 7 8 9]\n# result (after np.add(a, b, out=result)) = [ 5  7  9 11 13]\n```\n\n----------------------------------------\n\nTITLE: Implementing ServerSession for MCP Communication in Python\nDESCRIPTION: This code snippet defines the ServerSession class, which inherits from BaseSession. It manages the initialization state, handles incoming requests and notifications, and provides methods for sending log messages and other notifications. The class specifically handles the 'initialize' request and 'initialized' notification to manage the connection state before passing other messages to the main server logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/08_client_server_sessions___clientsession____serversession__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from server/session.py\nfrom mcp.types import InitializeRequest, InitializeResult, InitializedNotification\n\nclass ServerSession(BaseSession):\n    # ... (init with server info, capabilities) ...\n    _initialization_state = InitializationState.NotInitialized\n    _client_params = None # Stores client info after initialization\n\n    async def _handle_incoming_request(self, request: JSONRPCRequest):\n        # Server specifically handles 'initialize' request first\n        if request.method == \"initialize\":\n            # ... (validate request, store client capabilities in self._client_params) ...\n            self._initialization_state = InitializationState.Initializing\n            init_result = InitializeResult(...) # Build result with server info\n            # Respond directly using the base class's internal send method\n            await self._send_response(request.id, ServerResult(init_result))\n        elif self._initialization_state == InitializationState.Initialized:\n            # For other requests, pass them to the main server logic\n            # (e.g., to FastMCP's request router) via an internal queue\n            await self._pass_request_to_server_handler(request)\n        else:\n            # Error: Request received before initialization complete\n            error = ErrorData(code=..., message=\"Server not initialized\")\n            await self._send_response(request.id, error)\n\n    async def _handle_incoming_notification(self, notification: JSONRPCNotification):\n        if notification.method == \"initialized\":\n             self._initialization_state = InitializationState.Initialized\n             print(\"ServerSession: Client initialization complete.\")\n        elif self._initialization_state == InitializationState.Initialized:\n            # Pass other notifications to server logic if needed\n            pass\n        else:\n             # Ignore notifications before initialized, or log warning\n             pass\n\n    async def send_log_message(self, level, data, logger=None):\n        # Helper method to send a specific notification type\n        log_notification = LoggingMessageNotification(...)\n        await self.send_notification(ServerNotification(log_notification))\n\n    # ... other methods like send_progress_notification, send_resource_updated ...\n```\n\n----------------------------------------\n\nTITLE: Configuring Pinecone RM Client in DSPy (Conceptual Python)\nDESCRIPTION: Provides a conceptual Python code example for configuring DSPy to use Pinecone as the Retrieval Model. It shows importing `PineconeRM`, instantiating it with necessary parameters like the index name and embedding model, and setting it globally. This requires prior Pinecone setup and environment variable configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Example: Configuring Pinecone (Conceptual - requires setup)\n# from dspy.retrieve.pinecone_rm import PineconeRM\n# Assumes PINECONE_API_KEY and PINECONE_ENVIRONMENT are set in environment\n# pinecone_retriever = PineconeRM(\n#     pinecone_index_name='my-company-docs-index',\n#     # Assuming embeddings are done via OpenAI's model\n#     openai_embed_model='text-embedding-ada-002'\n# )\n# dspy.settings.configure(rm=pinecone_retriever)\n```\n\n----------------------------------------\n\nTITLE: Compiling StateGraph into Executable Form in Python\nDESCRIPTION: Implementation of the compile method that transforms the defined nodes and edges into an executable CompiledStateGraph, setting up the internal Pregel execution engine and Channels for state management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view\ndef compile(self, ...):\n    # ... validation checks ...\n    self.validate(...)\n    # ... create the CompiledStateGraph instance ...\n    compiled = CompiledStateGraph(builder=self, ...)\n    # ... add nodes, edges, branches to the compiled version ...\n    for key, node in self.nodes.items():\n        compiled.attach_node(key, node)\n    for start, end in self.edges:\n        compiled.attach_edge(start, end)\n    # ... more setup for branches, entry/exit points ...\n    # ... finalize and return the compiled graph ...\n    return compiled.validate()\n```\n\n----------------------------------------\n\nTITLE: Defining Result Data Structure with Pydantic in Python\nDESCRIPTION: This Python snippet defines an ActionResult class using Pydantic's BaseModel to standardize output from actions. The model includes the fields 'is_done', 'success', 'extracted_content', 'error', and 'include_in_memory' with optional or default values, ensuring every response conforms to a consistent schema. This structure supports robust runtime validation of expected outputs without requiring complex business logic, and depends on the 'pydantic' library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\\nfrom typing import Optional\\n\\nclass ActionResult(BaseModel):\\n    is_done: Optional[bool] = False\\n    success: Optional[bool] = None\\n    extracted_content: Optional[str] = None\\n    error: Optional[str] = None\\n    include_in_memory: bool = False # Default to False\\n\n```\n\n----------------------------------------\n\nTITLE: Defining a Connection Helper for Downstream A2A Agents in Python\nDESCRIPTION: This conceptual Python class, `RemoteAgentConnection`, manages the connection to a single downstream A2A agent. It stores the agent's `AgentCard`, initializes an `A2AClient` specifically for that agent's endpoint, and provides an asynchronous method `send_task_to_remote` to delegate tasks to the downstream agent using the A2A protocol. It depends on `A2AClient` from `common.client` and types like `AgentCard`, `TaskSendParams`, and `Task` from `common.types`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/08_multi_agent_orchestration__host_agent_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual Helper Class (Manages client for one downstream agent)\nfrom common.client import A2AClient\nfrom common.types import AgentCard, TaskSendParams, Task\n\nclass RemoteAgentConnection:\n    def __init__(self, agent_card: AgentCard):\n        # Store the downstream agent's card\n        self.card = agent_card\n        # Create an A2A client specifically for this agent\n        self.client = A2AClient(agent_card=agent_card)\n        print(f\"Connection ready for agent: {self.card.name}\")\n\n    async def send_task_to_remote(self, params: TaskSendParams) -> Task:\n        print(f\"Host sending task {params.id} to {self.card.name}...\")\n        # Use the internal A2A client to send the task\n        # (Simplified: assumes non-streaming for clarity)\n        response = await self.client.send_task(params.model_dump())\n        print(f\"Host received response for task {params.id} from {self.card.name}\")\n        return response.result # Return the final Task object\n```\n\n----------------------------------------\n\nTITLE: Creating NumPy Arrays Using np.arange\nDESCRIPTION: This snippet demonstrates how to create sequential NumPy arrays using the np.arange() function, which works similarly to Python's built-in range() function but returns a NumPy array instead of a range object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Create an array with numbers from 0 up to (but not including) 5\nrange_arr = np.arange(5)\nprint(range_arr)\n# Output: [0 1 2 3 4]\n```\n\n----------------------------------------\n\nTITLE: Defining Flask Configuration Variables in a Python Module (Python)\nDESCRIPTION: Illustrates creating a separate Python file (`config.py`) to store configuration settings as variables. Only variables with all uppercase names (like `DEBUG`, `SECRET_KEY`, `DATABASE_URI`) will be loaded into the Flask app's configuration when using `app.config.from_object()`. Lowercase variables (`internal_value`) are ignored.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# config.py\n# Note: Only uppercase variables will be loaded by from_object\n\nDEBUG = True # Set debug mode\nSECRET_KEY = 'a-very-secret-and-complex-key-loaded-from-object' # KEEP SECRET IN REAL APPS\nDATABASE_URI = 'sqlite:///mydatabase.db'\n\n# This lowercase variable will NOT be loaded into app.config\ninternal_value = 'ignore me'\n```\n\n----------------------------------------\n\nTITLE: Running and Resuming a LangGraph Workflow with thread_id Checkpointing in Python\nDESCRIPTION: This snippet illustrates running a compiled LangGraph app with checkpointing enabled by providing a unique thread_id via the config dictionary. uuid.uuid4() is used to set a unique identifier for this run. The workflow is invoked twice: first with an initial state and then with None (to resume from checkpoint). Outputs demonstrate persistence across runs. Dependencies include uuid for thread_id generation. Initial input is a state dictionary; outputs include printed results and final state restoration behaviors.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport uuid\\n\\n# Create a unique ID for this run\\nthread_id = str(uuid.uuid4())\\nconfig = {\"configurable\": {\"thread_id\": thread_id}}\\n\\n# Define the initial state\\ninitial_state = {\"value\": 5}\\n\\nprint(\"--- Running Graph (First Time) ---\")\\n# Run the graph with the config\\nfinal_state = app.invoke(initial_state, config=config)\\n\\nprint(\"\\n--- Final State (First Run) ---\")\\nprint(final_state)\n```\n\n----------------------------------------\n\nTITLE: Using CacheMode.BYPASS for Fresh Content in Crawl4AI\nDESCRIPTION: This example shows CacheMode.BYPASS, which always fetches fresh content from the web while still updating the cache. Both runs take similar time as they both perform network fetches, making it useful when you need the latest webpage versions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# chapter9_example_2.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nimport time\n\nasync def main():\n    url = \"https://httpbin.org/html\"\n    async with AsyncWebCrawler() as crawler:\n        # Set the mode to BYPASS\n        config_bypass = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n        print(f\"Running with CacheMode: {config_bypass.cache_mode.name}\")\n\n        # First run: Fetches, caches, and returns result\n        print(\"First run (BYPASS)...\")\n        start_time = time.perf_counter()\n        result1 = await crawler.arun(url=url, config=config_bypass)\n        duration1 = time.perf_counter() - start_time\n        print(f\"Got result 1? {'Yes' if result1.success else 'No'} (took {duration1:.2f}s)\")\n\n        # Second run: Ignores cache, fetches again, updates cache, returns result\n        print(\"Second run (BYPASS)...\")\n        start_time = time.perf_counter()\n        result2 = await crawler.arun(url=url, config=config_bypass)\n        duration2 = time.perf_counter() - start_time\n        print(f\"Got result 2? {'Yes' if result2.success else 'No'} (took {duration2:.2f}s)\")\n        # Both runs should take a similar amount of time (fetching time)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing BaseCheckpointSaver Abstract Class in Python\nDESCRIPTION: The abstract base class that defines the interface for all checkpoint savers. It specifies methods for saving and loading checkpoints with both synchronous and asynchronous variants.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# checkpoint/base.py (Highly Simplified)\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Mapping, Optional, Sequence, Tuple, TypedDict\n\n# Represents a saved checkpoint\nclass Checkpoint(TypedDict):\n    channel_values: Mapping[str, Any] # Saved state of channels\n    channel_versions: Mapping[str, int] # Internal versions\n    versions_seen: Mapping[str, Mapping[str, int]] # Tracking for node execution\n    # ... other metadata like v, ts, id, pending_sends ...\n\n# Represents the checkpoint tuple retrieved from storage\nclass CheckpointTuple(NamedTuple):\n    config: dict # The config used (includes thread_id)\n    checkpoint: Checkpoint\n    metadata: dict\n    # ... other fields like parent_config, pending_writes ...\n\nclass BaseCheckpointSaver(ABC):\n    # --- Sync Methods ---\n    @abstractmethod\n    def get_tuple(self, config: dict) -> Optional[CheckpointTuple]:\n        \"\"\"Load the checkpoint tuple for the given config.\"\"\"\n        ...\n\n    @abstractmethod\n    def put(self, config: dict, checkpoint: Checkpoint, metadata: dict) -> dict:\n        \"\"\"Save a checkpoint.\"\"\"\n        ...\n\n    # --- Async Methods (similar structure) ---\n    @abstractmethod\n    async def aget_tuple(self, config: dict) -> Optional[CheckpointTuple]:\n        \"\"\"Async load the checkpoint tuple.\"\"\"\n        ...\n\n    @abstractmethod\n    async def aput(self, config: dict, checkpoint: Checkpoint, metadata: dict) -> dict:\n        \"\"\"Async save a checkpoint.\"\"\"\n        ...\n\n    # --- Other methods (list, put_writes) omitted for brevity ---\n```\n\n----------------------------------------\n\nTITLE: Retrieving Detailed Results from dspy.Evaluate in Python\nDESCRIPTION: This snippet demonstrates how to retrieve more detailed information from `dspy.Evaluate`. By setting `return_all_scores=True`, the evaluator returns both the average score and a list of individual scores for each example. By setting `return_outputs=True`, it returns the average score and a list containing tuples of (example, prediction, score) for each item in the development set.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Re-run evaluation asking for more details\nevaluator_detailed = Evaluate(devset=devset, metric=simple_exact_match_metric)\n\n# Get individual scores\navg_score, individual_scores = evaluator_detailed(qa_program, return_all_scores=True)\nprint(f\"Individual Scores: {individual_scores}\") # Output: [True, True, True, False]\n\n# Get full outputs\navg_score, outputs_list = evaluator_detailed(qa_program, return_outputs=True)\n# outputs_list[0] would be roughly: (dev_example1, Prediction(answer='blue'), True)\n```\n\n----------------------------------------\n\nTITLE: Running Celery Beat and Worker in Bash\nDESCRIPTION: These commands demonstrate how to start Celery Beat and a Celery Worker from the command line. Beat is responsible for scheduling tasks, while the Worker executes them.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# In your terminal\ncelery -A celery_app beat --loglevel=info\n\n# In a SECOND terminal\ncelery -A celery_app worker --loglevel=info\n```\n\n----------------------------------------\n\nTITLE: Implementing State-Transformer Nodes - Python\nDESCRIPTION: Provides two node functions for a StateGraph, each transforming the state. 'add_one' increments 'value' by 1, and 'multiply_by_two' doubles it. Both accept the current state (conforming to MyState) and return a dictionary with updated \"value\". Print statements trace execution for debugging or illustration. These are designed to be registered as nodes in a StateGraph. There are no external dependencies for these functions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Node 1: Adds 1 to the value\ndef add_one(state: MyState) -> dict:\n    print(\"--- Running Adder Node ---\")\n    current_value = state['value']\n    new_value = current_value + 1\n    print(f\"Input value: {current_value}, Output value: {new_value}\")\n    # Return *only* the key we want to update\n    return {\"value\": new_value}\n\n# Node 2: Multiplies the value by 2\ndef multiply_by_two(state: MyState) -> dict:\n    print(\"--- Running Multiplier Node ---\")\n    current_value = state['value']\n    new_value = current_value * 2\n    print(f\"Input value: {current_value}, Output value: {new_value}\")\n    # Return the update\n    return {\"value\": new_value}\n```\n\n----------------------------------------\n\nTITLE: Creating Flask Blueprint with Static and Template Configuration\nDESCRIPTION: Demonstrates how to create a Flask Blueprint with custom static folder and template configurations. Shows setup of static URL paths and folder locations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# blueprints/admin.py\nadmin_bp = Blueprint('admin', __name__,\n                     static_folder='static', # Look in blueprints/admin/static/\n                     static_url_path='/admin-static', # URL like /admin-static/style.css\n                     template_folder='templates') # Look in blueprints/admin/templates/\n\n# Then register with the app:\n# app.register_blueprint(admin_bp, url_prefix='/admin')\n```\n\n----------------------------------------\n\nTITLE: Browser DOM State Access Implementation\nDESCRIPTION: Complete implementation example showing how to access and use DOM representation through BrowserContext\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom browser_use import Browser, BrowserConfig, BrowserContext, BrowserContextConfig\n\nasync def main():\n    browser_config = BrowserConfig(headless=False)\n    browser = Browser(config=browser_config)\n    context_config = BrowserContextConfig()\n\n    async with browser.new_context(config=context_config) as browser_context:\n        await browser_context.navigate_to(\"https://www.google.com\")\n\n        print(\"Getting current page state...\")\n        current_state = await browser_context.get_state()\n\n        print(f\"\\nCurrent Page URL: {current_state.url}\")\n        print(f\"Current Page Title: {current_state.title}\")\n\n        print(\"\\n--- DOM Representation Details ---\")\n        if current_state.element_tree:\n            print(f\"Root element tag of simplified tree: <{current_state.element_tree.tag_name}>\")\n        else:\n            print(\"Element tree is empty.\")\n\n        if current_state.selector_map:\n            print(f\"Number of interactive elements found: {len(current_state.selector_map)}\")\n\n            example_index = 5\n            if example_index in current_state.selector_map:\n                element_node = current_state.selector_map[example_index]\n                print(f\"Element [{example_index}]: Tag=<{element_node.tag_name}>, Attributes={element_node.attributes}\")\n            else:\n                print(f\"Element [{example_index}] not found in the selector map for this page state.\")\n        else:\n            print(\"No interactive elements found (selector map is empty).\")\n\n    print(\"\\nBrowserContext closed.\")\n    await browser.close()\n    print(\"Browser closed.\")\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram: FastAPI Request-Response Flow\nDESCRIPTION: A sequence diagram showing the complete flow of an HTTP request from browser through Uvicorn and FastAPI, including the conversion of Python dictionaries to JSON responses. Illustrates the interaction between Browser, Uvicorn ASGI server, FastAPI application, and route handler.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User Browser\n    participant ASGI Server (Uvicorn)\n    participant FastAPI App\n    participant Route Handler (read_root)\n\n    User Browser->>+ASGI Server (Uvicorn): GET / HTTP/1.1\n    ASGI Server (Uvicorn)->>+FastAPI App: Pass Request (method='GET', path='/')\n    FastAPI App->>FastAPI App: Lookup route for GET /\n    FastAPI App->>+Route Handler (read_root): Call async def read_root()\n    Route Handler (read_root)-->>-FastAPI App: Return {\"message\": \"Hello World\"}\n    FastAPI App->>FastAPI App: Convert dict to JSON Response (status 200)\n    FastAPI App-->>-ASGI Server (Uvicorn): Send HTTP Response\n    ASGI Server (Uvicorn)-->>-User Browser: HTTP/1.1 200 OK\\nContent-Type: application/json\\n\\n{\"message\":\"Hello World\"}\n```\n\n----------------------------------------\n\nTITLE: Requesting Human Approval and Executing Plans - LangGraph Node Functions - Python\nDESCRIPTION: Defines two node functions for a LangGraph workflow: one to request human approval by interrupting execution, and another to execute a plan contingent on receipt of approval/feedback. These nodes utilize state input/output and are intended to be hooked into a stateful LangGraph pipeline. Dependency: requires an interrupt function (defined in LangGraph), and ApprovalState objects. Key parameters include the plan fetched from state and the feedback received upon resumption. Outputs are dictionary-formatted state updates.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Node that requests human approval using interrupt\ndef request_approval(state: ApprovalState) -> dict:\n    print(\"--- Requesting Human Approval ---\")\n    plan = state['plan']\n    print(f\"Proposed Plan: {plan}\")\n    # Call interrupt, passing the plan to the client\n    # Execution STOPS here on the first run.\n    feedback_or_approval = interrupt(plan)\n    # --- Execution RESUMES here on the second run ---\n    print(f\"--- Resumed with feedback: {feedback_or_approval} ---\")\n    # Store the feedback received from the resume command\n    return {\"feedback\": str(feedback_or_approval)} # Ensure it's a string\n\n# Node that executes the plan (only if approved implicitly by resuming)\ndef execute_plan(state: ApprovalState) -> dict:\n    print(\"--- Executing Plan ---\")\n    if state.get(\"feedback\"): # Check if we got feedback (meaning we resumed)\n        print(f\"Executing '{state['plan']}' based on feedback: {state['feedback']}\")\n        return {} # No state change needed\n    else:\n        # This path shouldn't be hit if interrupt works correctly\n        print(\"Execution skipped (no feedback received).\")\n        return{}\n```\n\n----------------------------------------\n\nTITLE: Mounting Basic HTTP Adapters to a Requests Session in Python\nDESCRIPTION: This snippet shows how to create a `requests.Session` and mount different instances of `HTTPAdapter` to handle requests for specific URL prefixes. It demonstrates inspecting the default adapters, creating new `HTTPAdapter` instances, mounting them for a specific host (`https://httpbin.org`) and a general scheme (`http://`), inspecting the updated adapter dictionary, and using `session.get_adapter()` to illustrate how the session selects the appropriate adapter based on the longest matching prefix. Requires the `requests` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom requests.adapters import HTTPAdapter\n\n# Create a session\ns = requests.Session()\n\n# See the default adapters that are already mounted\nprint(\"Default Adapters:\")\nprint(s.adapters)\n\n# Create a *new* instance of the default HTTPAdapter\n# (Maybe we'll configure it later)\ncustom_adapter = HTTPAdapter()\n\n# Mount this adapter for a specific website\n# Now, any request to this specific host via HTTPS will use our custom_adapter\nprint(\"\\nMounting custom adapter for https://httpbin.org\")\ns.mount('https://httpbin.org', custom_adapter)\n\n# Let's mount another one for all HTTP traffic\nplain_http_adapter = HTTPAdapter()\nprint(\"Mounting another adapter for all http://\")\ns.mount('http://', plain_http_adapter)\n\n# Check the adapters again (they are ordered by prefix length, longest first)\nprint(\"\\nAdapters after mounting:\")\nprint(s.adapters)\n\n# When we make a request, the session finds the best matching prefix\nprint(f\"\\nAdapter for 'https://httpbin.org/get': {s.get_adapter('https://httpbin.org/get')}\")\nprint(f\"Adapter for 'http://example.com': {s.get_adapter('http://example.com')}\")\nprint(f\"Adapter for 'https://google.com': {s.get_adapter('https://google.com')}\") # Uses default https://\n```\n\n----------------------------------------\n\nTITLE: Implementing MCPClients and MCPClientTool in Python\nDESCRIPTION: This code snippet shows the MCPClients class, which manages the connection to the MCP server and creates proxy tool objects. It also includes the MCPClientTool class, which represents a server-side tool on the client side and handles remote execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp import ClientSession # MCP library for client-side communication\nfrom mcp.client.stdio import stdio_client # Specific transport handler\nfrom mcp.types import TextContent\nfrom app.tool.base import BaseTool, ToolResult\nfrom app.tool.tool_collection import ToolCollection\nfrom contextlib import AsyncExitStack\n\n# Represents a single tool on the server, callable from the client\nclass MCPClientTool(BaseTool):\n    session: Optional[ClientSession] = None # Holds the connection\n\n    async def execute(self, **kwargs) -> ToolResult:\n        \"\"\"Execute by calling the remote tool via the MCP session.\"\"\"\n        if not self.session: return ToolResult(error=\"Not connected\")\n        try:\n            # Make the actual remote call\n            result = await self.session.call_tool(self.name, kwargs)\n            # Extract text output from the response\n            content = \", \".join(\n                item.text for item in result.content if isinstance(item, TextContent)\n            )\n            return ToolResult(output=content or \"No output.\")\n        except Exception as e:\n            return ToolResult(error=f\"MCP tool error: {e}\")\n\n# The collection holding the proxy tools\nclass MCPClients(ToolCollection):\n    session: Optional[ClientSession] = None\n    exit_stack: AsyncExitStack = None # Manages connection resources\n\n    async def connect_stdio(self, command: str, args: List[str]):\n        \"\"\"Connect using stdio.\"\"\"\n        if self.session: await self.disconnect()\n        self.exit_stack = AsyncExitStack()\n\n        # Set up stdio connection using MCP library helper\n        server_params = {\"command\": command, \"args\": args} # Simplified\n        streams = await self.exit_stack.enter_async_context(\n            stdio_client(server_params)\n        )\n        # Establish the MCP session over the connection\n        self.session = await self.exit_stack.enter_async_context(\n            ClientSession(*streams)\n        )\n        await self._initialize_and_list_tools() # Get tool list from server\n\n    async def _initialize_and_list_tools(self):\n        \"\"\"Fetch tools from server and create proxy objects.\"\"\"\n        await self.session.initialize()\n        response = await self.session.list_tools() # Ask server for tools\n\n        self.tool_map = {}\n        for tool_info in response.tools:\n            # Create an MCPClientTool instance for each server tool\n            proxy_tool = MCPClientTool(\n                name=tool_info.name,\n                description=tool_info.description,\n                parameters=tool_info.inputSchema, # Use schema from server\n                session=self.session, # Pass the active session\n            )\n            self.tool_map[tool_info.name] = proxy_tool\n        self.tools = tuple(self.tool_map.values())\n        logger.info(f\"MCP Client found tools: {list(self.tool_map.keys())}\")\n\n    async def disconnect(self):\n        if self.session and self.exit_stack:\n            await self.exit_stack.aclose() # Clean up connection\n            # ... reset state ...\n```\n\n----------------------------------------\n\nTITLE: Equipping an AI Agent with a Web Search Tool in CrewAI\nDESCRIPTION: This code snippet demonstrates how to import a SerperDevTool for web searching, instantiate it, and equip an AI Agent (Expert Travel Researcher) with this tool. It includes setting up the necessary environment and defining the Agent with specific parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/04_tool.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Make sure you have crewai and crewai_tools installed\n# pip install crewai crewai_tools\n\nimport os\nfrom crewai import Agent\nfrom crewai_tools import SerperDevTool\n\n# Set up your API key (replace with your actual key or environment variable setup)\n# IMPORTANT: Do NOT hardcode keys in production code! Use environment variables.\n# os.environ[\"SERPER_API_KEY\"] = \"YOUR_SERPER_API_KEY\"\n\n# 1. Instantiate the tool\n#    (It automatically gets a name and description)\nsearch_tool = SerperDevTool()\n\n# 2. Define the agent and provide the tool in the 'tools' list\nresearcher = Agent(\n  role='Expert Travel Researcher',\n  goal='Find the three most exciting and sunny European cities for a birthday trip in late May.',\n  backstory=(\n      \"You are a world-class travel researcher with deep knowledge of \"\n      \"European destinations. You excel at finding hidden gems and understanding \"\n      \"weather patterns. Your recommendations are always insightful and tailored. \"\n      \"You MUST use the web search tool to find the most up-to-date information.\" # Added instruction\n  ),\n  verbose=True,\n  allow_delegation=False,\n  tools=[search_tool] # <-- Give the agent access to the tool!\n  # llm=your_llm # Assumes an LLM is configured (see Chapter 6)\n)\n\n# (You would then create a Task and a Crew as shown in previous chapters)\n# task1 = Task(description=\"Find 3 sunny European cities for May...\", agent=researcher, ...)\n# trip_crew = Crew(agents=[researcher], tasks=[task1], ...)\n# result = trip_crew.kickoff()\n# print(result)\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Task Class in Python\nDESCRIPTION: This code snippet shows how Celery creates a task class from a decorated function. It demonstrates the internal process of task registration and binding to the Celery app instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/03_task.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from celery/app/base.py\nclass Celery:\n    # ...\n    def task(self, *args, **opts):\n        # ... handles decorator arguments ...\n        def _create_task_cls(fun):\n            # Returns a Task instance or a Proxy that creates one later\n            ret = self._task_from_fun(fun, **opts)\n            return ret\n        return _create_task_cls\n\n    def _task_from_fun(self, fun, name=None, base=None, bind=False, **options):\n        # Generate name like 'tasks.add' if not given\n        name = name or self.gen_task_name(fun.__name__, fun.__module__)\n        base = base or self.Task # The base Task class (from celery.app.task)\n\n        if name not in self._tasks: # If not already registered...\n            # Dynamically create a Task class wrapping the function\n            task = type(fun.__name__, (base,), {\n                'app': self, # Link task back to this app instance!\n                'name': name,\n                'run': staticmethod(fun), # The actual function to run\n                '__doc__': fun.__doc__,\n                '__module__': fun.__module__,\n                # ... other options ...\n            })() # Instantiate the new Task class\n            self._tasks[task.name] = task # Add to app's registry!\n            task.bind(self) # Perform binding steps\n        else:\n            task = self._tasks[name] # Task already exists\n        return task\n```\n\n----------------------------------------\n\nTITLE: Defining a Data Example Wrapper with Input/Label Partitioning - Python\nDESCRIPTION: Defines the Example class, which wraps a dictionary-like structure for data points, allowing both attribute and key-based access to fields. The class includes methods for copying itself, designating input fields using with_inputs, and extracting only input or label fields. Dependencies include only Python standard data structures, and key parameters are the base dictionary and dynamic keyword arguments, as well as the input field identifiers. Inputs and outputs are Example instances or dictionaries as appropriate; input/label partitioning relies on explicit calls to with_inputs. Not all dictionary-like methods (keys(), values(), items()) are implemented here, but are suggested for extension.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nclass Example:\n    def __init__(self, base=None, **kwargs):\n        self._store = {}  # The internal dictionary\n        self._input_keys = None # Stores the input keys after with_inputs()\n\n        # Simplified: Copy from base or dictionary if provided\n        if base and isinstance(base, dict): self._store = base.copy()\n        # Simplified: Update with keyword arguments\n        self._store.update(kwargs)\n\n    # Allows accessing self.key like dictionary lookup self._store[key]\n    def __getattr__(self, key):\n        if key in self._store: return self._store[key]\n        raise AttributeError(f\"No attribute '{key}'\")\n\n    # Allows setting self.key like dictionary assignment self._store[key] = value\n    def __setattr__(self, key, value):\n        if key.startswith(\"_\"): super().__setattr__(key, value) # Handle internal attributes\n        else: self._store[key] = value\n\n    # Allows dictionary-style access example[key]\n    def __getitem__(self, key): return self._store[key]\n\n    # Creates a *copy* and marks input keys on the copy.\n    def with_inputs(self, *keys):\n        copied = self.copy() # Make a shallow copy\n        copied._input_keys = set(keys) # Store the input keys on the copy\n        return copied\n\n    # Returns a new Example containing only input fields.\n    def inputs(self):\n        if self._input_keys is None: raise ValueError(\"Inputs not set.\")\n        # Create a dict with only input keys\n        input_dict = {k: v for k, v in self._store.items() if k in self._input_keys}\n        # Return a new Example wrapping this dict\n        return type(self)(base=input_dict).with_inputs(*self._input_keys)\n\n    # Returns a new Example containing only non-input fields (labels).\n    def labels(self):\n        input_keys = self.inputs().keys() if self._input_keys else set()\n        # Create a dict with only non-input keys\n        label_dict = {k: v for k, v in self._store.items() if k not in input_keys}\n        # Return a new Example wrapping this dict\n        return type(self)(base=label_dict)\n\n    # Helper to create a copy\n    def copy(self, **kwargs):\n        return type(self)(base=self, **kwargs)\n\n    # ... other helpful methods like keys(), values(), items(), etc. ...\n```\n\n----------------------------------------\n\nTITLE: Monitoring Celery Events via Command Line\nDESCRIPTION: Command to watch the Celery event stream using the built-in events monitor\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncelery -A celery_app events\n```\n\n----------------------------------------\n\nTITLE: Defining Task and TaskOutput Classes in CrewAI (Python)\nDESCRIPTION: Defines the core classes used in CrewAI for representing tasks (`Task`) and their outputs (`TaskOutput`). The Task class includes attributes for description, expected output, assigned agent, tools, and callback functionality. It manages internal state and facilitates task delegation, context handling, and output configuration using Pydantic models for structured data. Dependencies: Pydantic (`BaseModel`, `Field`), typing (`Optional`, `List`, `Any`, `Type`), CrewAI base classes. Inputs include descriptive task configuration fields and optionally agent/tool references, and outputs are encapsulated in structured models. Designed for extensibility, supporting advanced features like file output, custom serialization, and asynchronous execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/03_task.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Import Agent and Tool placeholders for the example\\nfrom crewai import BaseAgent, BaseTool\\n\\nclass TaskOutput(BaseModel): # Simplified representation of the result\\n    description: str\\n    raw: str\\n    agent: str\\n    # ... other fields like pydantic, json_dict\\n\\nclass Task(BaseModel):\\n    # Core attributes\\n    description: str = Field(description=\\\"Description of the actual task.\\\")\\n    expected_output: str = Field(description=\\\"Clear definition of expected output.\\\")\\n    agent: Optional[BaseAgent] = Field(default=None, description=\\\"Agent responsible.\\\")\\n\\n    # Optional attributes\\n    context: Optional[List[\\\"Task\\\"]] = Field(default=None, description=\\\"Context from other tasks.\\\")\\n    tools: Optional[List[BaseTool]] = Field(default_factory=list, description=\\\"Task-specific tools.\\\")\\n    async_execution: Optional[bool] = Field(default=False)\\n    output_json: Optional[Type[BaseModel]] = Field(default=None)\\n    output_pydantic: Optional[Type[BaseModel]] = Field(default=None)\\n    output_file: Optional[str] = Field(default=None)\\n    callback: Optional[Any] = Field(default=None) # Function to call after execution\\n\\n    # Internal state\\n    output: Optional[TaskOutput] = Field(default=None, description=\\\"Task output after execution\\\")\\n\\n    def execute_sync(\\n        self,\\n        agent: Optional[BaseAgent] = None,\\n        context: Optional[str] = None,\\n        tools: Optional[List[BaseTool]] = None,\\n    ) -> TaskOutput:\\n        # 1. Identify the agent to use (passed or self.agent)\\n        agent_to_execute = agent or self.agent\\n        if not agent_to_execute:\\n            raise Exception(\\\"No agent assigned to task.\\\")\\n\\n        # 2. Prepare tools (task tools override agent tools if provided)\\n        execution_tools = tools or self.tools or agent_to_execute.tools\\n\\n        # 3. Call the agent's execute_task method\\n        #    (The agent handles LLM calls, tool use, etc.)\\n        raw_result = agent_to_execute.execute_task(\\n            task=self, # Pass self (the task object)\\n            context=context,\\n            tools=execution_tools,\\n        )\\n\\n        # 4. Format the output\\n        # (Handles JSON/Pydantic conversion if requested)\\n        pydantic_output, json_output = self._export_output(raw_result)\\n\\n        # 5. Create and return TaskOutput object\\n        task_output = TaskOutput(\\n            description=self.description,\\n            raw=raw_result,\\n            pydantic=pydantic_output,\\n            json_dict=json_output,\\n            agent=agent_to_execute.role,\\n            # ... other fields\\n        )\\n        self.output = task_output # Store the output within the task object\\n\\n        # 6. Execute callback if defined\\n        if self.callback:\\n            self.callback(task_output)\\n\\n        # 7. Save to file if output_file is set\\n        if self.output_file:\\n            # ... logic to save file ...\\n            pass\\n\\n        return task_output\\n\\n    def prompt(self) -> str:\\n        # Combines description and expected output for the agent\\n        return f\\\"{self.description}\\\\n\\\\nExpected Output:\\\\n{self.expected_output}\\\"\\n\\n    # ... other methods like execute_async, _export_output, _save_file ...\\n\n```\n\n----------------------------------------\n\nTITLE: Conceptual Task Execution in Celery with Python\nDESCRIPTION: Illustrates how to send a task for background execution using the delay() method. This snippet demonstrates the asynchronous nature of Celery tasks and the use of result promises.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# In a separate Python script or interpreter, after importing 'add' from celery_app.py\nfrom celery_app import add\n\n# Send the task to the broker configured in our 'app'\nresult_promise = add.delay(4, 5)\n\nprint(f\"Task sent! It will run in the background.\")\nprint(f\"We got back a promise object: {result_promise}\")\n# We can later check the result using result_promise.get()\n# (Requires a result backend and a worker running the task)\n```\n\n----------------------------------------\n\nTITLE: Implementing Nodes with Interrupt for Human Approval in Python\nDESCRIPTION: Defines nodes for a workflow that includes human approval. The create_plan node generates a plan, while get_approval uses the interrupt primitive to pause execution and wait for human input.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.types import interrupt, Command # Import interrupt and Command\n\n# Node that creates a plan\ndef create_plan(state: ApprovalState) -> dict:\n    print(\"--- Creating Plan ---\")\n    plan = \"Plan: Execute risky action X.\"\n    return {\"plan\": plan}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Module Usage with Configured LM\nDESCRIPTION: Illustrates how a DSPy module (`dspy.Predict` initialized with a `TranslateToFrench` signature) automatically uses the globally configured LM client. The example defines the signature, configures an LM (commented out, assumes previous configuration), creates the `Predict` module, and then calls it without explicitly passing the LM instance. The module fetches the active LM from `dspy.settings` internally.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define signature (same as before)\nclass TranslateToFrench(dspy.Signature):\n    \"\"\"Translates English text to French.\"\"\"\n    english_sentence = dspy.InputField()\n    french_sentence = dspy.OutputField()\n\n# Configure the LM (e.g., using OpenAI)\n# turbo = dspy.LM(model='openai/gpt-3.5-turbo', max_tokens=100)\n# dspy.settings.configure(lm=turbo)\n\n# Create the Predict module\ntranslator = dspy.Predict(TranslateToFrench)\n\n# Use the module - NO need to pass the LM here!\nresult = translator(english_sentence=\"Hello, how are you?\")\nprint(result.french_sentence)\n```\n\n----------------------------------------\n\nTITLE: Handling SSE Streaming Response in TypeScript\nDESCRIPTION: Implementation of SSE event handling in TypeScript using browser's fetch API and ReadableStream. Processes incoming SSE events, parses JSON-RPC responses, and yields TaskStatusUpdateEvent or TaskArtifactUpdateEvent objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/07_streaming_communication__sse_.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync function* _handleStreamingResponse(response: Response): AsyncIterable<any> {\n  if (!response.ok || !response.body) {\n    // Handle HTTP errors before trying to stream\n    throw new Error(`HTTP error ${response.status}`);\n  }\n\n  // Get a reader for the response body stream (decoded as text)\n  const reader = response.body\n    .pipeThrough(new TextDecoderStream())\n    .getReader();\n  let buffer = \"\"; // To handle partial messages\n\n  try {\n    while (true) {\n      const { done, value } = await reader.read(); // Read next chunk\n\n      if (done) break; // Stream finished\n\n      buffer += value; // Add chunk to buffer\n      const lines = buffer.split(\"\\n\\n\"); // Split into potential messages\n      buffer = lines.pop() || \"\"; // Keep any trailing partial message\n\n      for (const message of lines) {\n        if (message.startsWith(\"data: \")) { // Check for SSE data line\n          const dataLine = message.substring(\"data: \".length);\n          try {\n            // Parse the JSON data from the line\n            const parsedData = JSON.parse(dataLine);\n            // parsedData is expected to be a JSONRPCResponse\n            if (parsedData.result) {\n              // Yield the actual event payload (TaskStatusUpdateEvent, etc.)\n              yield parsedData.result;\n            } else if (parsedData.error) {\n              // Handle errors received in the stream\n              throw new RpcError(parsedData.error.code, parsedData.error.message);\n            }\n          } catch (e) {\n            console.error(\"Failed to parse SSE data:\", dataLine, e);\n          }\n        }\n      }\n    }\n  } finally {\n    reader.releaseLock(); // Clean up the reader\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Messages in Python using OpenManus\nDESCRIPTION: This snippet demonstrates how to create Message objects with different roles (user, assistant, system) using the Message class from app/schema.py in OpenManus.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import the Message class\nfrom app.schema import Message\n\n# Create a message from the user\nuser_q = Message.user_message(\"What's the capital of France?\")\n\n# Create a message from the assistant (agent's response)\nassistant_a = Message.assistant_message(\"The capital of France is Paris.\")\n\n# Create a system instruction\nsystem_instruction = Message.system_message(\"You are a helpful geography expert.\")\n\nprint(f\"User Message: Role='{user_q.role}', Content='{user_q.content}'\")\nprint(f\"Assistant Message: Role='{assistant_a.role}', Content='{assistant_a.content}'\")\n```\n\n----------------------------------------\n\nTITLE: Injecting Shared Dependencies into FastAPI Path Operations - Python\nDESCRIPTION: These snippets show how to import and reuse a shared dependency for query parameters within multiple FastAPI route handlers, using Annotated and Depends to inject parsed query parameters as a dictionary. Demonstrates endpoint handler logic for items and users with optional filtering and slicing of fake data, leveraging the single dependency. Requires previous definition/import of 'common_parameters' dependency and FastAPI router setup.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# routers/items.py (example)\nfrom typing import Annotated\nfrom fastapi import APIRouter, Depends\n# Assume common_parameters is defined in common_dependencies.py\nfrom ..common_dependencies import common_parameters\n\nrouter = APIRouter()\n\n# Fake data for demonstration\nfake_items = [{\"item_name\": \"Foo\"}, {\"item_name\": \"Bar\"}, {\"item_name\": \"Baz\"}]\n\n@router.get(\"/items/\")\n# Here's the magic! Declare 'commons' parameter using Depends\nasync def read_items(\n    commons: Annotated[dict, Depends(common_parameters)] # Dependency Injection!\n):\n    # Inside this function, 'commons' will be the dictionary returned\n    # by common_parameters after FastAPI calls it with the query params.\n    print(f\"Received common parameters: {commons}\")\n\n    # Use the values from the dependency\n    q = commons[\"q\"]\n    skip = commons[\"skip\"]\n    limit = commons[\"limit\"]\n\n    response_items = fake_items[skip : skip + limit]\n    if q:\n        response_items = [item for item in response_items if q in item[\"item_name\"]]\n    return response_items\n\n@router.get(\"/users/\")\n# We can reuse the SAME dependency here!\nasync def read_users(\n    commons: Annotated[dict, Depends(common_parameters)] # Reusing the dependency\n):\n    # 'commons' will again be the dict returned by common_parameters\n    print(f\"Received common parameters for users: {commons}\")\n    # Imagine fetching users using commons['skip'], commons['limit']...\n    return {\"message\": \"Users endpoint\", \"params\": commons}\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing np.issubdtype Function Flow with Mermaid\nDESCRIPTION: This diagram illustrates the sequence of operations when calling np.issubdtype(np.int32, np.integer). It shows how the function interacts with NumPy's type hierarchy and Python's type system to determine subtype relationships.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant P as Your Python Code\n    participant NPFunc as np.issubdtype\n    participant PyTypes as Python Type System\n    participant TypeHier as NumPy Type Hierarchy (in numerictypes.py)\n\n    P->>NPFunc: np.issubdtype(np.int32, np.integer)\n    NPFunc->>TypeHier: Get type object for np.int32\n    NPFunc->>TypeHier: Get type object for np.integer\n    NPFunc->>PyTypes: Ask: issubclass(np.int32_obj, np.integer_obj)?\n    PyTypes-->>NPFunc: Return True (based on class inheritance)\n    NPFunc-->>P: Return True\n```\n\n----------------------------------------\n\nTITLE: Composing a StateGraph with Nodes and Flow - LangGraph Python\nDESCRIPTION: Shows the construction of a StateGraph using predefined state and node functions. Nodes are registered with unique names, entry and exit points are set, and node-to-node transitions are defined with 'add_edge'. The graph is instantiated with the state structure, and the 'END' marker designates completion. Requires the 'langgraph' package and the earlier state and node function definitions. This snippet outlines the compositional logic for building graph workflows.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.graph import StateGraph, END, START\n\n# Create a StateGraph instance linked to our state definition\nworkflow = StateGraph(MyState)\n\n# Add the nodes to the graph\nworkflow.add_node(\"adder\", add_one)\nworkflow.add_node(\"multiplier\", multiply_by_two)\n\n# Set the entry point --> where does the flow start?\nworkflow.set_entry_point(\"adder\")\n\n# Add edges --> how do the nodes connect?\nworkflow.add_edge(\"adder\", \"multiplier\") # After adder, run multiplier\n\n# Set the finish point --> where does the flow end?\n# We use the special identifier END\nworkflow.add_edge(\"multiplier\", END)\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Loop in React Component\nDESCRIPTION: A simplified TypeScript React component demonstrating how the Agent Loop is integrated into the Terminal UI. It shows the creation, configuration, and usage of the AgentLoop class within a React component.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/03_agent_loop.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport React, { useState, useEffect, useRef } from \"react\";\nimport { AgentLoop } from \"../../utils/agent/agent-loop\";\n// ... other imports: UI components, config types ...\n\nexport default function TerminalChat({ config, approvalPolicy, /* ... */ }) {\n  const [items, setItems] = useState([]);\n  const [loading, setLoading] = useState(false);\n  const [confirmationPrompt, setConfirmationPrompt] = useState(null);\n  const agentRef = useRef<AgentLoop | null>(null);\n\n  useEffect(() => {\n    agentRef.current = new AgentLoop({\n      model: config.model,\n      config: config,\n      approvalPolicy: approvalPolicy,\n      onItem: (newItem) => {\n        setItems((prev) => [...prev, newItem]);\n      },\n      onLoading: (isLoading) => {\n        setLoading(isLoading);\n      },\n      getCommandConfirmation: async (command, /*...*/) => {\n        const userDecision = await showConfirmationUI(command);\n        return { review: userDecision /* ... */ };\n      },\n      // ... other callbacks like onLastResponseId ...\n    });\n\n    return () => agentRef.current?.terminate();\n  }, [config, approvalPolicy /* ... */]);\n\n  const submitInputToAgent = (userInput) => {\n    if (agentRef.current) {\n      agentRef.current.run([userInput /* ... */]);\n    }\n  };\n\n  return (\n    <Box>\n      {/* Display 'items' using TerminalMessageHistory */}\n      {/* Display input box (TerminalChatInput) or confirmationPrompt */}\n      {/* Pass `submitInputToAgent` to the input box */}\n      {/* Pass function to handle confirmation decision */}\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Managing Single-Pass Flow in React Ink CLI - TypeScript\nDESCRIPTION: Implements a React Ink component that drives the single-pass workflow, handling state transitions (init, prompt, thinking, confirm, applied, error, skipped), coordinating file context gathering, AI invocation, diff generation, and applying confirmed changes to the filesystem. Requires React, Ink, OpenAI (with zodResponseFormat helper), fs/promises, supporting utilities, and proper schema configuration. Inputs are user prompts; outputs are interactive UI flows culminating in updated files, or error states if issues occur. All code is TypeScript, and dependencies must be available for the code to run.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/08_single_pass_mode.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/components/singlepass-cli-app.tsx (Simplified Snippets)\nimport React, { useEffect, useState } from \"react\";\nimport { Box, Text, useApp } from \"ink\";\nimport OpenAI from \"openai\";\nimport { zodResponseFormat } from \"openai/helpers/zod\";\n// --- Local Utils ---\nimport { getFileContents } from \"../utils/singlepass/context_files\";\nimport { renderTaskContext } from \"../utils/singlepass/context\";\nimport { EditedFilesSchema, FileOperation } from \"../utils/singlepass/file_ops\";\nimport { generateDiffSummary, generateEditSummary } from \"../utils/singlepass/code_diff\";\nimport * as fsPromises from \"fs/promises\";\n// --- UI Components ---\nimport { InputPrompt, ConfirmationPrompt } from \"./prompts\"; // Conceptual grouping\n\nexport function SinglePassApp({ /* ...props: config, rootPath, onExit ... */ }): JSX.Element {\n  const app = useApp();\n  const [state, setState] = useState(\"init\"); // 'init', 'prompt', 'thinking', 'confirm', 'applied', 'error'...\n  const [files, setFiles] = useState([]); // Holds { path, content }\n  const [diffInfo, setDiffInfo] = useState({ summary: \"\", diffs: \"\", ops: [] });\n\n  // 1. Load file context on mount\n  useEffect(() => {\n    (async () => {\n      const fileContents = await getFileContents(rootPath, /* ignorePatterns */);\n      setFiles(fileContents);\n      setState(\"prompt\"); // Ready for user input\n    })();\n  }, [rootPath]);\n\n  // 2. Function to run the AI task\n  async function runSinglePassTask(userPrompt: string) {\n    setState(\"thinking\");\n    try {\n      // Format the context + prompt for the AI\n      const taskContextStr = renderTaskContext({ prompt: userPrompt, files, /*...*/ });\n\n      const openai = new OpenAI({ /* ... config ... */ });\n      // Call OpenAI, specifying the expected structured response format\n      const chatResp = await openai.beta.chat.completions.parse({\n        model: config.model,\n        messages: [{ role: \"user\", content: taskContextStr }],\n        response_format: zodResponseFormat(EditedFilesSchema, \"schema\"), // Ask for this specific structure!\n      });\n\n      const edited = chatResp.choices[0]?.message?.parsed; // The parsed { ops: [...] } object\n\n      if (!edited || !Array.isArray(edited.ops)) { /* Handle no ops */ }\n\n      // Generate diffs from the AI's proposed operations\n      const [combinedDiffs, opsToApply] = generateDiffSummary(edited, /* original files map */);\n      if (!opsToApply.length) { /* Handle no actual changes */ }\n\n      const summary = generateEditSummary(opsToApply, /* original files map */);\n      setDiffInfo({ summary, diffs: combinedDiffs, ops: opsToApply });\n      setState(\"confirm\"); // Move to confirmation state\n\n    } catch (err) { setState(\"error\"); }\n  }\n\n  // 3. Function to apply the changes\n  async function applyFileOps(ops: Array<FileOperation>) {\n    for (const op of ops) {\n      if (op.delete) {\n        await fsPromises.unlink(op.path).catch(() => {});\n      } else { // Create or Update\n        const newContent = op.updated_full_content || \"\";\n        await fsPromises.mkdir(path.dirname(op.path), { recursive: true });\n        await fsPromises.writeFile(op.path, newContent, \"utf-8\");\n      }\n      // Handle move_to separately if needed\n    }\n    setState(\"applied\");\n  }\n\n  // --- Render logic based on `state` ---\n  if (state === \"prompt\") {\n    return <InputPrompt onSubmit={runSinglePassTask} /* ... */ />;\n  }\n  if (state === \"thinking\") { /* Show Spinner */ }\n  if (state === \"confirm\") {\n    return (\n      <Box flexDirection=\"column\">\n        {/* Display diffInfo.summary and diffInfo.diffs */}\n        <ConfirmationPrompt\n          message=\"Apply these changes?\"\n          onResult={(accept) => {\n            if (accept) applyFileOps(diffInfo.ops);\n            else setState(\"skipped\");\n          }}\n        />\n      </Box>\n    );\n  }\n  if (state === \"applied\") { /* Show success, maybe offer another prompt */ }\n  // ... other states: init, error, skipped ...\n\n  return <Text>...</Text>; // Fallback\n}\n\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks for Article Processing Workflow\nDESCRIPTION: Creates a set of Celery tasks that simulate an article processing workflow. Includes tasks for fetching data, processing content in two different ways, and combining the results from parallel processing steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# tasks.py\nfrom celery_app import app\nimport time\nimport random\n\n@app.task\ndef fetch_data(url):\n    print(f\"Fetching data from {url}...\")\n    time.sleep(1)\n    # Simulate fetching some data\n    data = f\"Content from {url} - {random.randint(1, 100)}\"\n    print(f\"Fetched: {data}\")\n    return data\n\n@app.task\ndef process_part_a(data):\n    print(f\"Processing Part A for: {data}\")\n    time.sleep(2)\n    result_a = f\"Keywords for '{data}'\"\n    print(\"Part A finished.\")\n    return result_a\n\n@app.task\ndef process_part_b(data):\n    print(f\"Processing Part B for: {data}\")\n    time.sleep(3) # Simulate slightly longer processing\n    result_b = f\"Language for '{data}'\"\n    print(\"Part B finished.\")\n    return result_b\n\n@app.task\ndef combine_results(results):\n    # 'results' will be a list containing the return values\n    # of process_part_a and process_part_b\n    print(f\"Combining results: {results}\")\n    time.sleep(1)\n    final_output = f\"Combined: {results[0]} | {results[1]}\"\n    print(f\"Final Output: {final_output}\")\n    return final_output\n```\n\n----------------------------------------\n\nTITLE: Base Adapter Implementation in Python\nDESCRIPTION: Abstract base class implementation for DSPy adapters, defining the core interface and orchestration logic for language model interaction.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom abc import ABC, abstractmethod\n\nclass Adapter(ABC):\n    def __call__(\n        self,\n        lm: \"LM\",\n        lm_kwargs: dict[str, Any],\n        signature: Type[Signature],\n        demos: list[dict[str, Any]],\n        inputs: dict[str, Any],\n    ) -> list[dict[str, Any]]:\n        formatted_input = self.format(signature, demos, inputs)\n        lm_call_args = dict(prompt=formatted_input) if isinstance(formatted_input, str) else dict(messages=formatted_input)\n        outputs = lm(**lm_call_args, **lm_kwargs)\n        parsed_values = []\n        for output in outputs:\n            raw_text = output if isinstance(output, str) else output[\"text\"]\n            value = self.parse(signature, raw_text)\n            parsed_values.append(value)\n        return parsed_values\n\n    @abstractmethod\n    def format(self, signature, demos, inputs) -> list[dict[str, Any]] | str:\n        raise NotImplementedError\n\n    @abstractmethod\n    def parse(self, signature: Type[Signature], completion: str) -> dict[str, Any]:\n        raise NotImplementedError\n```\n\n----------------------------------------\n\nTITLE: Asking Questions to an LLM with OpenManus\nDESCRIPTION: Demonstrates how to create an LLM interface, prepare a message containing a question, and asynchronously receive a response from the language model. This example shows the direct use of the LLM class, though usually this is handled by the agent automatically.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/01_llm.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary classes\nfrom app.llm import LLM\nfrom app.schema import Message\nimport asyncio # Needed to run asynchronous code\n\n# Assume configuration is already loaded (API keys, model name, etc.)\n# Create an instance of the LLM class (using default settings)\nllm_interface = LLM()\n\n# Prepare the question as a list of messages\n# (We'll learn more about Messages in Chapter 2)\nconversation = [\n    Message.user_message(\"What is the capital of France?\")\n]\n\n# Define an async function to ask the question\nasync def ask_question():\n    print(\"Asking the LLM...\")\n    # Use the 'ask' method to send the conversation\n    response = await llm_interface.ask(messages=conversation)\n    print(f\"LLM Response: {response}\")\n\n# Run the async function\nasyncio.run(ask_question())\n```\n\n----------------------------------------\n\nTITLE: Implementing ParamType Base Class in Python Click Framework\nDESCRIPTION: Defines the ParamType base class which serves as the foundation for all parameter types in Click. It includes a name attribute for human-readable identification and abstract methods for converting values and reporting failures.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass ParamType:\n    name: str  # Human-readable name like \"integer\" or \"filename\"\n\n    def convert(self, value, param, ctx):\n        # Must be implemented by subclasses\n        # Should return the converted value or call self.fail()\n        raise NotImplementedError\n\n    def fail(self, message, param, ctx):\n        # Raises a BadParameter exception\n        raise BadParameter(message, ctx=ctx, param=param)\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running AsyncWebCrawler in Python\nDESCRIPTION: This snippet demonstrates how to set up and use AsyncWebCrawler from Crawl4AI. It configures an extraction strategy, sets up a crawler run configuration, and processes the crawl result including extracted data, screenshots, and PDFs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport json\nfrom crawl4ai import (\n    AsyncWebCrawler, CrawlResult, CrawlerRunConfig,\n    JsonCssExtractionStrategy # Example extractor\n)\n\nasync def main():\n    # Define a simple extraction strategy (from Chapter 6)\n    schema = {\"baseSelector\": \"body\", \"fields\": [{\"name\": \"heading\", \"selector\": \"h1\", \"type\": \"text\"}]}\n    extractor = JsonCssExtractionStrategy(schema=schema)\n\n    # Configure the run to extract and take a screenshot\n    config = CrawlerRunConfig(\n        extraction_strategy=extractor,\n        screenshot=True\n    )\n\n    async with AsyncWebCrawler() as crawler:\n        url = \"https://httpbin.org/html\"\n        result: CrawlResult = await crawler.arun(url=url, config=config)\n\n        if result.success:\n            print(\"--- Extracted Data & Media ---\")\n            # Check if structured data was extracted\n            if result.extracted_content:\n                print(\"Extracted Data found:\")\n                data = json.loads(result.extracted_content) # Parse the JSON string\n                print(json.dumps(data, indent=2))\n            else:\n                print(\"No structured data extracted.\")\n\n            # Check if a screenshot was taken\n            if result.screenshot:\n                print(f\"Screenshot saved to: {result.screenshot}\")\n            else:\n                print(\"Screenshot not taken.\")\n\n            # Check for PDF (would be bytes if requested and successful)\n            if result.pdf:\n                 print(f\"PDF data captured ({len(result.pdf)} bytes).\")\n            else:\n                 print(\"PDF not generated.\")\n        else:\n            print(f\"Crawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing TypeSubscription for Topic-Based Routing in Python\nDESCRIPTION: A concrete implementation of the Subscription protocol that matches messages based on exact topic type and maps them to agents of a specified type, using the topic source as the agent's unique key.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# From: _type_subscription.py (Simplified)\nclass TypeSubscription(Subscription):\n    def __init__(self, topic_type: str, agent_type: str, ...):\n        self._topic_type = topic_type\n        self._agent_type = agent_type\n        # ... generates a unique self._id ...\n\n    def is_match(self, topic_id: TopicId) -> bool:\n        # Matches if the topic's type is exactly the one we want\n        return topic_id.type == self._topic_type\n\n    def map_to_agent(self, topic_id: TopicId) -> AgentId:\n        # Maps to an agent of the specified type, using the\n        # topic's source as the agent's unique key.\n        if not self.is_match(topic_id):\n             raise CantHandleException(...) # Should not happen if used correctly\n        return AgentId(type=self._agent_type, key=topic_id.source)\n    # ... id property ...\n```\n\n----------------------------------------\n\nTITLE: Automatic Adapter Usage in dspy.Predict Call (Python)\nDESCRIPTION: Reinforces that when using modules like `dspy.Predict` after configuring `dspy.settings`, the appropriate Adapter is used automatically behind the scenes. The call to `summarizer(text=long_text)` implicitly invokes the configured Adapter (e.g., `ChatAdapter`) to format the request for the LM and parse its response, making the process seamless for the user. Requires the `dspy` library and a configured LM/Adapter in `dspy.settings`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# The summarizer automatically uses the configured LM and Adapter\nsummarizer = dspy.Predict(Summarize)\nresult = summarizer(text=long_text) # Adapter works its magic here!\nprint(result.summary)\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Agent by Extending BaseAgent in Python\nDESCRIPTION: This code demonstrates how to create a simple EchoAgent by inheriting from BaseAgent. It implements the required step() method to echo back the last user message, showing the fundamental pattern for creating specialized agents in OpenManus.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/03_baseagent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual Example - Not runnable code, just for illustration\n\n# Import BaseAgent and necessary components\nfrom app.agent.base import BaseAgent\nfrom app.schema import Message\n\nclass EchoAgent(BaseAgent): # Inherits from BaseAgent!\n    \"\"\"A simple agent that echoes the last user message.\"\"\"\n\n    name: str = \"EchoBot\"\n    description: str = \"Repeats the last thing the user said.\"\n\n    # THIS IS THE IMPORTANT PART - We implement the abstract 'step' method\n    async def step(self) -> str:\n        \"\"\"Perform one step: find the last user message and echo it.\"\"\"\n\n        last_user_message = None\n        # Look backwards through memory to find the last user message\n        for msg in reversed(self.memory.messages):\n            if msg.role == \"user\":\n                last_user_message = msg\n                break\n\n        if last_user_message and last_user_message.content:\n            echo_content = f\"You said: {last_user_message.content}\"\n            # Add the echo response to memory as an 'assistant' message\n            self.update_memory(\"assistant\", echo_content)\n            # The state will be set to FINISHED after this step by run()\n            # (Simplified: a real agent might need more complex logic)\n            self.state = AgentState.FINISHED # Indicate task is done\n            return echo_content # Return the result of this step\n        else:\n            self.state = AgentState.FINISHED # Nothing to echo, finish\n            return \"I didn't hear anything from the user to echo.\"\n\n# How you might conceptually use it:\n# echo_bot = EchoAgent()\n# # Add a user message to its memory\n# echo_bot.update_memory(\"user\", \"Hello there!\")\n# # Start the agent's run loop\n# result = await echo_bot.run()\n# print(result) # Output would contain: \"Step 1: You said: Hello there!\"\n```\n\n----------------------------------------\n\nTITLE: Generating Blueprint-Scoped URLs with url_for in Flask - Python\nDESCRIPTION: This snippet shows how to use Flask's url_for within a blueprint to generate URLs for endpoints defined in that blueprint and in the main app. It demonstrates both relative ('.profile') and fully qualified ('user.profile') endpoint references in url_for. The function 'link_example' is defined as a blueprint route and produces links as response strings. Requires Flask, and should reside inside the user blueprint module. Inputs are static; the generated URLs reflect the blueprint's URL prefix and endpoint scoping.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Inside blueprints/user.py\nfrom flask import url_for\n\n@user_bp.route('/link-example')\ndef link_example():\n    # Generate URL for 'profile' endpoint within the *same* blueprint ('user')\n    alice_url = url_for('.profile', username='alice') # Note the leading dot!\n    # alice_url will be '/users/profile/alice'\n\n    # Generate URL for the main app's 'home' endpoint\n    home_url = url_for('home') # No dot needed for app routes\n    # home_url will be '/'\n\n    return f'Alice profile: {alice_url}<br>Homepage: {home_url}'\n```\n\n----------------------------------------\n\nTITLE: Defining a Crew with a Sequential Process in Python\nDESCRIPTION: Demonstrates initializing a CrewAI `Crew` to execute tasks sequentially. It imports `Crew` and `Process`, defines a crew instance with pre-defined agents (`researcher`, `planner`) and tasks (`task1`, `task2`), and explicitly sets the `process` parameter to `Process.sequential`. In this process, the output of the first task automatically becomes context for the second.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Assuming 'researcher' and 'planner' agents are defined (from Chapter 2)\n# Assuming 'task1' (find cities) and 'task2' (create itinerary) are defined (from Chapter 3)\n# task1 assigned to researcher, task2 assigned to planner\n\nfrom crewai import Crew, Process\n\n# Define the crew with a sequential process\ntrip_crew = Crew(\n  agents=[researcher, planner],\n  tasks=[task1, task2],\n  process=Process.sequential # Explicitly setting the sequential process\n  # verbose=2 # Optional verbosity\n)\n\n# Start the work\n# result = trip_crew.kickoff()\n# print(result)\n```\n\n----------------------------------------\n\nTITLE: Using SemaphoreDispatcher for Concurrent Crawling in Python\nDESCRIPTION: This script demonstrates how to use the `SemaphoreDispatcher` from the `crawl4ai` library to limit the number of concurrent web crawls. It imports necessary components, defines a list of URLs, creates a `SemaphoreDispatcher` instance with a concurrency limit of 2, and then uses `AsyncWebCrawler.arun_many` with the custom dispatcher to fetch the URLs asynchronously. The example prints the status of each crawl result after completion. Dependencies include `asyncio` and `crawl4ai`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/10_basedispatcher.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# chapter10_example_2.py\nimport asyncio\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    SemaphoreDispatcher # 1. Import the specific dispatcher\n)\n\nasync def main():\n    urls_to_crawl = [\n        \"https://httpbin.org/delay/1\", # Takes 1 second\n        \"https://httpbin.org/delay/1\",\n        \"https://httpbin.org/delay/1\",\n        \"https://httpbin.org/delay/1\",\n        \"https://httpbin.org/delay/1\",\n    ]\n\n    # 2. Create an instance of the SemaphoreDispatcher\n    #    Allow only 2 crawls to run at the same time.\n    semaphore_controller = SemaphoreDispatcher(semaphore_count=2)\n    print(f\"Using SemaphoreDispatcher with limit: {semaphore_controller.semaphore_count}\")\n\n    async with AsyncWebCrawler() as crawler:\n        print(f\"Crawling {len(urls_to_crawl)} URLs with explicit dispatcher...\")\n        config = CrawlerRunConfig(stream=False)\n\n        # 3. Pass the dispatcher instance to arun_many\n        results = await crawler.arun_many(\n            urls=urls_to_crawl,\n            config=config,\n            dispatcher=semaphore_controller # Pass our controller\n        )\n\n        print(f\"\\nFinished! Got {len(results)} results.\")\n        # This crawl likely took around 3 seconds (5 tasks, 1s each, 2 concurrent = ceil(5/2)*1s)\n        for result in results:\n            status = \"✅\" if result.success else \"❌\"\n            print(f\"  {status} {result.url}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing LastValue Channel in Python\nDESCRIPTION: LastValue channel implementation that keeps only the most recent value it received. This is the default channel type for state keys in TypedDict unless specified otherwise.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass LastValue(Generic[Value], BaseChannel[Value, Value, Value]):\n    value: Any = MISSING\n\n    def update(self, values: Sequence[Value]) -> bool:\n        if len(values) == 0:\n            return False\n        self.value = values[-1]\n        return True\n\n    def get(self) -> Value:\n        if self.value is MISSING:\n            raise EmptyChannelError()\n        return self.value\n```\n\n----------------------------------------\n\nTITLE: Registering and Using a Response Hook in Python Requests\nDESCRIPTION: This snippet demonstrates how to register a custom hook function with a Requests Session and use it for multiple requests. It shows the automatic logging of response details for each request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# (Paste the log_response_details function definition from above here)\ndef log_response_details(response, *args, **kwargs):\n    request_method = response.request.method\n    url = response.url\n    status_code = response.status_code\n    print(f\"HOOK LOG: Received {status_code} for {request_method} request to {url}\")\n\n# Create a Session\ns = requests.Session()\n\n# Register the hook on the session\n# Hooks are stored in a dictionary: session.hooks = {'event_name': [list_of_functions]}\n# We add our function to the list for the 'response' event.\ns.hooks['response'].append(log_response_details)\n\n# Now, make some requests using the session\nprint(\"Making requests...\")\nresponse1 = s.get('https://httpbin.org/get')\nprint(f\"  -> Main code received response 1 with status: {response1.status_code}\")\n\nresponse2 = s.post('https://httpbin.org/post', data={'id': '123'})\nprint(f\"  -> Main code received response 2 with status: {response2.status_code}\")\n\nresponse3 = s.get('https://httpbin.org/status/404') # This will get a 404\nprint(f\"  -> Main code received response 3 with status: {response3.status_code}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Commands with Click Group in Python\nDESCRIPTION: Illustrates how to create a Click application with multiple commands using @click.group() decorator. It defines a main group and two commands (hello and goodbye), then attaches the commands to the group.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/01_command___group.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# multi_app.py\nimport click\n\n@click.group()\ndef cli():\n  \"\"\"A simple tool with multiple commands.\"\"\"\n  pass\n\n@click.command()\ndef hello():\n  \"\"\"Says Hello World\"\"\"\n  print(\"Hello World!\")\n\n@click.command()\ndef goodbye():\n  \"\"\"Says Goodbye World\"\"\"\n  print(\"Goodbye World!\")\n\ncli.add_command(hello)\ncli.add_command(goodbye)\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Defining Celery Task Signatures in Python\nDESCRIPTION: A simplified Python code snippet from `celery/canvas.py` illustrating the structure of the `Signature` class. It shows how signatures are defined (inheriting from `dict`) and key methods like `link`, `link_error` for adding callbacks, and the `__or__` operator used to build chains (`|`). This class encapsulates the information needed to call a task without executing it immediately.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from celery/canvas.py\nclass Signature(dict):\n    # ... methods like __init__, clone, set, apply_async ...\n\n    def link(self, callback):\n        # Appends callback signature to the 'link' list in options\n        return self.append_to_list_option('link', callback)\n\n    def link_error(self, errback):\n        # Appends errback signature to the 'link_error' list in options\n        return self.append_to_list_option('link_error', errback)\n\n    def __or__(self, other):\n        # Called when you use the pipe '|' operator\n        if isinstance(other, Signature):\n            # task | task -> chain\n            return _chain(self, other, app=self._app)\n        # ... other cases for group, chain ...\n        return NotImplemented\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent's Step Execution in Python\nDESCRIPTION: The step method of the Agent class, representing the core of the loop. It gets the current browser state, asks the LLM for the next action, executes the action, and records the outcome.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/01_agent.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass Agent:\n    # ... (init, run) ...\n    async def step(self, step_info: Optional[AgentStepInfo] = None) -> None:\n        logger.info(f\"📍 Step {self.state.n_steps}\")\n        state = None\n        model_output = None\n        result: list[ActionResult] = []\n\n        try:\n            # 1. Get current state from the browser\n            state = await self.browser_context.get_state() # Uses BrowserContext\n\n            # 2. Add state (+ previous result) to message history for LLM context\n            self._message_manager.add_state_message(state, self.state.last_result, ...)\n\n            # 3. Get LLM's decision on the next action(s)\n            input_messages = self._message_manager.get_messages()\n            model_output = await self.get_next_action(input_messages) # Calls the LLM\n\n            self.state.n_steps += 1 # Increment step counter\n\n            # 4. Execute the action(s) using the Controller\n            result = await self.multi_act(model_output.action) # Uses Controller\n            self.state.last_result = result # Store result for next step's context\n\n            # 5. Record step details (actions, results, state snapshot)\n            self._make_history_item(model_output, state, result, ...)\n\n            self.state.consecutive_failures = 0 # Reset failure count on success\n\n        except Exception as e:\n            # Handle errors, increment failure count, maybe retry later\n            result = await self._handle_step_error(e)\n            self.state.last_result = result\n        # ... (finally block for logging/telemetry) ...\n```\n\n----------------------------------------\n\nTITLE: Importing `time` Module for Use with `g` Global\nDESCRIPTION: Imports the standard Python `time` module. This snippet is presented in the context of preparing to demonstrate the `g` context global, which is often used for storing temporary data needed within a single request cycle, such as request timing or user data loaded by a `before_request` handler.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\nimport time\n```\n\n----------------------------------------\n\nTITLE: Implementing LocalSandboxClient in Python\nDESCRIPTION: This class provides an interface to the DockerSandbox. It handles creating the sandbox, running commands, writing files, and cleanup. It uses an instance of DockerSandbox to perform these operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/sandbox/client.py\nfrom app.config import SandboxSettings\nfrom app.sandbox.core.sandbox import DockerSandbox\nfrom typing import Optional\n\nclass LocalSandboxClient: # Implements BaseSandboxClient\n    def __init__(self):\n        self.sandbox: Optional[DockerSandbox] = None\n\n    async def create(self, config: Optional[SandboxSettings] = None, ...):\n        \"\"\"Creates a sandbox if one doesn't exist.\"\"\"\n        if not self.sandbox:\n            # Create the actual DockerSandbox instance\n            self.sandbox = DockerSandbox(config, ...)\n            await self.sandbox.create() # Start the container\n\n    async def run_command(self, command: str, timeout: Optional[int] = None) -> str:\n        \"\"\"Runs command in the sandbox.\"\"\"\n        if not self.sandbox:\n            # Simplified: In reality, might auto-create or raise error\n            await self.create() # Ensure sandbox exists\n\n        # Delegate the command execution to the DockerSandbox instance\n        return await self.sandbox.run_command(command, timeout)\n\n    async def write_file(self, path: str, content: str) -> None:\n        \"\"\"Writes file to the sandbox.\"\"\"\n        if not self.sandbox: await self.create()\n        # Delegate writing to the DockerSandbox instance\n        await self.sandbox.write_file(path, content)\n\n    async def cleanup(self) -> None:\n        \"\"\"Cleans up the sandbox resources.\"\"\"\n        if self.sandbox:\n            await self.sandbox.cleanup() # Tell DockerSandbox to stop/remove container\n            self.sandbox = None\n\n# Create the shared instance used by tools\nSANDBOX_CLIENT = LocalSandboxClient()\n```\n\n----------------------------------------\n\nTITLE: Defining State and Node Functions for LangGraph in Python\nDESCRIPTION: Defines a `TypedDict` named `MyState` to structure the graph's shared state with a single integer field 'value'. It also defines two Python functions, `add_one` and `multiply_by_two`, intended to be used as nodes. Each function accepts the current state (`MyState`), prints informational messages, performs a simple arithmetic operation on the 'value', and returns a dictionary containing only the key 'value' with its updated result, signifying the state change.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\nfrom typing import TypedDict\n\n# Define the state structure (the whiteboard)\nclass MyState(TypedDict):\n    value: int\n\n# Node 1: Adds 1 to the value\ndef add_one(state: MyState) -> dict:\n    print(\"--- Running Adder Node ---\")\n    current_value = state['value']\n    new_value = current_value + 1\n    print(f\"Input value: {current_value}, Output value: {new_value}\")\n    # Return *only* the key we want to update\n    return {\"value\": new_value}\n\n# Node 2: Multiplies the value by 2\ndef multiply_by_two(state: MyState) -> dict:\n    print(\"--- Running Multiplier Node ---\")\n    current_value = state['value']\n    new_value = current_value * 2\n    print(f\"Input value: {current_value}, Output value: {new_value}\")\n    # Return the update\n    return {\"value\": new_value}\n```\n```\n\n----------------------------------------\n\nTITLE: Fetching a Webpage with Requests Functional API - Python\nDESCRIPTION: This snippet demonstrates how to perform a simple HTTP GET request using the Python Requests library's functional API. It imports the requests module, specifies a URL, and retrieves the response, printing both the status code and the first 200 characters of the response content. The script depends on having the requests library installed (pip install requests). The 'url' parameter specifies the target endpoint. Outputs include the HTTP status code and a portion of the returned data. Designed for basic, rapid retrieval tasks without advanced configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/01_functional_api.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests # Import the library\n\n# The URL we want to get data from\nurl = 'https://httpbin.org/get' # A handy website for testing requests\n\n# Use the functional API 'get' function\nprint(f\"Fetching data from: {url}\")\nresponse = requests.get(url)\n\n# Check if the request was successful (Status Code 200 means OK)\nprint(f\"Status Code: {response.status_code}\")\n\n# Print the first 200 characters of the content we received\nprint(\"Response Content (first 200 chars):\")\nprint(response.text[:200])\n```\n\n----------------------------------------\n\nTITLE: Creating an Initial Plan using LLM and PlanningTool in Python\nDESCRIPTION: Implements the `_create_initial_plan` async method within the `PlanningFlow` class. This method takes a user request string, prepares system and user messages using the `Message` schema, and then calls the language model (`self.llm.ask_tool`) to generate a plan. It provides the `PlanningTool`'s specification to the LLM, potentially forcing the LLM to use this tool to structure the plan. The method logs the creation process and assumes subsequent logic handles the LLM's response to execute the planning tool and store the generated steps. Depends on `Message`, an LLM client instance (`self.llm`), and `PlanningTool`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n    async def _create_initial_plan(self, request: str):\n        \"\"\"Uses LLM and PlanningTool to create the plan.\"\"\"\n        logger.info(f\"Creating plan for: {request}\")\n        system_msg = Message.system_message(\"You are a planner...\")\n        user_msg = Message.user_message(f\"Create a plan for: {request}\")\n\n        # Ask LLM to use the planning tool\n        response = await self.llm.ask_tool(\n            messages=[user_msg],\n            system_msgs=[system_msg],\n            tools=[self.planning_tool.to_param()], # Provide the tool spec\n            # Force LLM to use a tool (often planning tool)\n            # tool_choice=ToolChoice.AUTO # Or specify planning tool name\n        )\n\n        # Process LLM response to execute the planning tool call\n        # Simplified: Assume LLM calls planning_tool.execute(...)\n        # to store the plan steps.\n        # ... logic to handle response and tool execution ...\n        logger.info(\"Plan created.\")\n```\n\n----------------------------------------\n\nTITLE: Agent Factory Functions Definition\nDESCRIPTION: Defines factory functions for creating ResearcherAgent and WriterAgent instances. These functions are registered with the runtime so it knows how to instantiate agents when needed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# 2. Define Agent Factories\n\ndef researcher_factory():\n    # Gets runtime/id via AgentInstantiationContext inside BaseAgent.__init__\n    print(\"Runtime is creating a ResearcherAgent...\")\n    return ResearcherAgent(description=\"I research topics.\")\n\ndef writer_factory():\n    print(\"Runtime is creating a WriterAgent...\")\n    return WriterAgent(description=\"I write drafts from facts.\")\n```\n\n----------------------------------------\n\nTITLE: Parsing Apply Patch Operations in TypeScript\nDESCRIPTION: This function parses a multi-line string describing patch changes. It checks for specific markers and extracts operations like create, delete, and update for files. It returns an array of ApplyPatchOp objects or null if parsing fails.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport function parseApplyPatch(patch: string): Array<ApplyPatchOp> | null {\n  // 1. Check for \"*** Begin Patch\" and \"*** End Patch\" markers.\n  if (!patch.startsWith(\"*** Begin Patch\\n\") || !patch.endsWith(\"\\n*** End Patch\")) {\n    return null; // Invalid format\n  }\n\n  // 2. Extract the body between the markers.\n  const patchBody = /* ... extract body ... */;\n  const lines = patchBody.split('\\n');\n\n  const operations: Array<ApplyPatchOp> = [];\n  for (const line of lines) {\n    // 3. Check for operation markers:\n    if (line.startsWith(\"*** Add File: \")) {\n      operations.push({ type: \"create\", path: /* path */, content: \"\" });\n    } else if (line.startsWith(\"*** Delete File: \")) {\n      operations.push({ type: \"delete\", path: /* path */ });\n    } else if (line.startsWith(\"*** Update File: \")) {\n      operations.push({ type: \"update\", path: /* path */, update: \"\", added: 0, deleted: 0 });\n    } else if (operations.length > 0) {\n      // 4. If inside an operation, parse the content/diff lines (+/-)\n      const lastOp = operations[operations.length - 1];\n      // ... add line content to create/update operation ...\n    } else {\n      // Invalid line outside of an operation\n      return null;\n    }\n  }\n\n  return operations; // Return the list of parsed operations\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Celery Configuration in Python\nDESCRIPTION: This snippet shows how to create a Celery application instance and load the configuration from a separate configuration file.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\n\n# Create the app instance\napp = Celery('tasks')\n\n# Load configuration from the 'celeryconfig' module\napp.config_from_object('celeryconfig')\n\n# Tasks might be defined here, but we put them in tasks.py\n# which is loaded via the 'imports' setting in celeryconfig.py\n```\n\n----------------------------------------\n\nTITLE: Printing Truncated NumPy Array Output - Python\nDESCRIPTION: This Python snippet demonstrates how to print only the first few lines of a potentially large array's string representation. It uses string splitting and joining to avoid overwhelming console output when displaying large arrays, making inspection manageable. The code assumes that 'arr_string' is a string obtained from array formatting and only prints its first five lines, ending with an ellipsis to indicate truncation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# print(arr_string) # This might still be very long! Let's just print the first few lines\nprint('\\n'.join(arr_string.splitlines()[:5]) + '\\n...')\n```\n\n----------------------------------------\n\nTITLE: Illustrating JSON-RPC Success Response Structure\nDESCRIPTION: This JSON snippet demonstrates the format of a successful JSON-RPC 2.0 response sent by an agent back to the client. It includes the `jsonrpc` version, a `result` field containing the output of the requested action, and the original `id` from the request to allow the client to match the response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"jsonrpc\": \"2.0\",\n  \"result\": { ... },      // The output/result of the action\n  \"id\": \"request-123\"     // The SAME ID as the request\n}\n```\n\n----------------------------------------\n\nTITLE: Context Class Implementation (Python)\nDESCRIPTION: This snippet shows the implementation of key methods in the Context class, including report_progress, read_resource, and logging functions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Inside server/fastmcp/server.py (Simplified Context methods)\nclass Context(BaseModel, Generic[ServerSessionT, LifespanContextT]):\n    _request_context: RequestContext[...] | None\n    _fastmcp: FastMCP | None\n    # ... (init, properties) ...\n\n    async def report_progress(self, progress, total=None):\n        # Get progress token from low-level context meta if available\n        progress_token = self.request_context.meta.progressToken if self.request_context.meta else None\n        if progress_token:\n            # Use the session object from the low-level context\n            await self.request_context.session.send_progress_notification(...)\n\n    async def read_resource(self, uri):\n        # Use the stored FastMCP instance\n        assert self._fastmcp is not None\n        return await self._fastmcp.read_resource(uri)\n\n    async def log(self, level, message, ...):\n         # Use the session object from the low-level context\n        await self.request_context.session.send_log_message(...)\n\n    async def info(self, message, **extra):\n        await self.log(\"info\", message, **extra)\n    # ... (debug, warning, error methods) ...\n```\n\n----------------------------------------\n\nTITLE: Basic Array Printing with Automatic Summarization\nDESCRIPTION: Demonstrates how NumPy's array printing automatically summarizes large arrays, showing only the beginning and end elements with ellipsis in between to represent omitted values.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nlarge_array = np.arange(2000)\n\n# Let NumPy's array printing handle it\nprint(large_array)\n```\n\n----------------------------------------\n\nTITLE: Session Sending and Hook Handling in Requests - Python\nDESCRIPTION: Demonstrates how the Session object's send method in requests imports hook dispatch functionality and coordinates response flow, including response hook execution, cookie persistence, and redirect handling. The method gets the appropriate adapter, sends the request, invokes dispatch_hook for registered 'response' hooks, and then processes cookies and possible redirects using the modified response. Requires correct hook dictionaries, request/response objects, and adapter interfaces. Returns the finished response object to the caller.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/sessions.py (Simplified view of Session.send)\n\nfrom .hooks import dispatch_hook # Import the dispatcher\n\nclass Session:\n    # ... (other methods: __init__, request, prepare_request, get_adapter) ...\n\n    def send(self, request, **kwargs):\n        # ... (setup: kwargs, get adapter) ...\n\n        adapter = self.get_adapter(url=request.url)\n\n        # === ADAPTER SENDS THE REQUEST ===\n        r = adapter.send(request, **kwargs) # Gets the Response object 'r'\n\n        # ... (calculate elapsed time) ...\n\n        # === DISPATCH THE 'RESPONSE' HOOK ===\n        # request.hooks contains merged hooks from Request and Session\n        r = dispatch_hook(\"response\", request.hooks, r, **kwargs)\n\n        # === CONTINUE PROCESSING ===\n        # Persist cookies from the (potentially modified) response 'r'\n        extract_cookies_to_jar(self.cookies, request, r.raw)\n\n        # Handle redirects if allowed (using the potentially modified 'r')\n        if kwargs.get('allow_redirects', True):\n            # ... redirect logic using self.resolve_redirects ...\n            # This might modify 'r' further if redirects occur\n            pass\n        else:\n            # ... store potential next request for non-redirected responses ...\n            pass\n\n        # ... (maybe consume content if stream=False) ...\n\n        return r # Return the final Response object\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Context Usage in Click Commands\nDESCRIPTION: Demonstrates basic context usage including passing context between group and command, storing shared data in ctx.obj, and accessing command information via context attributes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/05_context.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# context_basics.py\nimport click\n\n@click.group()\n@click.pass_context # Request the context for the group function\ndef cli(ctx):\n  \"\"\"A simple CLI with context.\"\"\"\n  # We can store arbitrary data on the context's 'obj' attribute\n  ctx.obj = {'verbose': False} # Initialize a shared dictionary\n\n@cli.command()\n@click.option('--verbose', is_flag=True, help='Enable verbose mode.')\n@click.pass_context # Request the context for the command function\ndef info(ctx, verbose):\n  \"\"\"Prints info, possibly verbosely.\"\"\"\n  # Access the command name from the context\n  click.echo(f\"Executing command: {ctx.command.name}\")\n\n  # Access parameters passed to *this* command\n  click.echo(f\"Verbose flag (local): {verbose}\")\n\n  # We can modify the shared object from the parent context\n  if verbose:\n    ctx.obj['verbose'] = True\n\n  # Access the shared object from the parent context\n  click.echo(f\"Verbose setting (shared): {ctx.obj['verbose']}\")\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Referencing Request Exceptions in Python\nDESCRIPTION: Code references showing key exception classes in the Requests library including RequestException, ConnectionError, Timeout (ConnectTimeout, ReadTimeout), and HTTPError.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nrequests.exceptions.RequestException\nConnectionError\nTimeout\nConnectTimeout\nReadTimeout\nHTTPError\nresponse.raise_for_status()\n```\n\n----------------------------------------\n\nTITLE: Sending Message via HTTP POST in Python\nDESCRIPTION: This asynchronous Python function `SendMessage` handles sending a user message to the backend server. It initializes a `ConversationClient` with the server URL and uses it to make an HTTP POST request to the `/message/send` endpoint, sending the `Message` object wrapped in a `SendMessageRequest`. It returns the result from the server response (e.g., confirmation IDs) or None if an exception occurs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/state/host_agent_service.py (Simplified Snippet)\nasync def SendMessage(message: Message) -> str | None:\n  client = ConversationClient(server_url) # Backend server URL\n  try:\n    # Make HTTP POST request to backend API\n    response = await client.send_message(SendMessageRequest(params=message))\n    return response.result # Contains confirmation IDs\n  except Exception as e:\n    print(\"Failed to send message: \", e)\n```\n\n----------------------------------------\n\nTITLE: Loading Flask Configuration from a Python Object/Module (Python)\nDESCRIPTION: Shows how to load configuration settings into a Flask app from a separate Python module (`config.py`) using `app.config.from_object('config')`. This method imports the specified module and copies all its uppercase attributes into `app.config`. The example demonstrates accessing the loaded values and confirms that lowercase variables from the config module are not loaded.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\nfrom flask import Flask\n\napp = Flask(__name__)\n\n# Load configuration from the config.py file (using its import path as a string)\napp.config.from_object('config')\n# Alternatively, if you imported the module:\n# import config\n# app.config.from_object(config)\n\nprint(f\"Loaded Debug: {app.config.get('DEBUG')}\")\nprint(f\"Loaded Secret Key: {app.config.get('SECRET_KEY')}\")\nprint(f\"Loaded DB URI: {app.config.get('DATABASE_URI')}\")\nprint(f\"Internal Value (should be None): {app.config.get('internal_value')}\")\n\n# ... rest of your app ...\nif __name__ == '__main__':\n  app.run()\n```\n\n----------------------------------------\n\nTITLE: Building a Complex Workflow with Chain, Group, and Chord\nDESCRIPTION: Creates a complex workflow using Celery Canvas primitives. The workflow fetches article data, processes it in parallel using two different methods, and then combines the results. Demonstrates how to use chain, group, and chord together.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# run_workflow.py\nfrom celery import chain, group, chord\nfrom tasks import fetch_data, process_part_a, process_part_b, combine_results\n\n# The URL we want to process\narticle_url = \"http://example.com/article1\"\n\n# Create the workflow structure\n# 1. Fetch data. The result (data) is passed to the next step.\n# 2. The next step is a chord:\n#    - Header: A group running process_part_a and process_part_b in parallel.\n#              Both tasks receive the 'data' from fetch_data.\n#    - Body: combine_results receives a list of results from the group.\n\nworkflow = chain(\n    fetch_data.s(article_url),              # Step 1: Fetch\n    chord(                                  # Step 2: Chord\n        group(process_part_a.s(), process_part_b.s()), # Header: Parallel processing\n        combine_results.s()                            # Body: Combine results\n    )\n)\n\nprint(f\"Workflow definition:\\n{workflow}\")\n\n# Start the workflow\nprint(\"\\nSending workflow to Celery...\")\nresult_promise = workflow.apply_async()\n\nprint(f\"Workflow sent! Final result ID: {result_promise.id}\")\nprint(\"Run a Celery worker to execute the tasks.\")\n# You can optionally wait for the final result:\n# final_result = result_promise.get()\n# print(f\"\\nWorkflow finished! Final result: {final_result}\")\n```\n\n----------------------------------------\n\nTITLE: Background Compaction Scheduling in DBImpl\nDESCRIPTION: Implementation of MaybeScheduleCompaction method that determines when to schedule background compaction work based on various database conditions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\nvoid DBImpl::MaybeScheduleCompaction() {\n  mutex_.AssertHeld(); // Must hold lock to check/change state\n\n  if (background_compaction_scheduled_) {\n    // Already scheduled\n  } else if (shutting_down_.load(std::memory_order_acquire)) {\n    // DB is closing\n  } else if (!bg_error_.ok()) {\n    // Background error stopped activity\n  } else if (imm_ == nullptr && // No MemTable flush needed AND\n             manual_compaction_ == nullptr && // No manual request AND\n             !versions_->NeedsCompaction()) { // VersionSet says no work needed\n    // No work to be done\n  } else {\n    // Work needs to be done! Schedule it.\n    background_compaction_scheduled_ = true;\n    env_->Schedule(&DBImpl::BGWork, this); // Ask Env to run BGWork later\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sandboxing Command Execution with macOS Seatbelt (TypeScript)\nDESCRIPTION: This TypeScript function executes shell commands in a macOS Seatbelt sandbox using the 'sandbox-exec' tool. It dynamically constructs a policy allowing file reads and selective writes within specified roots for security. The function builds the full 'sandbox-exec' command, logs the policy, and delegates to the rawExec implementation. Requires macOS with sandbox-exec available, and imports from local modules for logging and execution. Inputs include command, options, writable directories array, and abort signal; output is an ExecResult promise with standard command output and code.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/sandbox/macos-seatbelt.ts (Simplified)\nimport type { ExecResult } from \"./interface.js\";\nimport { exec as rawExec } from \"./raw-exec.js\"; // Uses raw exec internally!\nimport { log } from \"../log.js\";\n\nconst READ_ONLY_POLICY_BASE = `\n(version 1)\n(deny default)\n(allow file-read*) ; Allow reading most things\n(allow process-exec process-fork signal) ; Allow running/forking\n(allow sysctl-read) ; Allow reading system info\n; ... more base rules ...\n`;\n\n// Runs command inside macOS Seatbelt sandbox\nexport function execWithSeatbelt(\n  cmd: Array<string>, // The original command e.g., [\"python\", \"script.py\"]\n  opts: SpawnOptions,\n  writableRoots: Array<string>, // Dirs allowed for writing, e.g., project root\n  abortSignal?: AbortSignal,\n): Promise<ExecResult> {\n\n  // 1. Build the sandbox policy string\n  let policy = READ_ONLY_POLICY_BASE;\n  let policyParams: Array<string> = [];\n  if (writableRoots.length > 0) {\n    // Add rules to allow writing ONLY within specified roots\n    const writeRules = writableRoots.map(\n      (root, i) => `(allow file-write* (subpath (param \"WR_${i}\")))`\n    ).join(\"\\n\");\n    policy += `\\n${writeRules}`;\n    // Create parameters for sandbox-exec\n    policyParams = writableRoots.map((root, i) => `-DWR_${i}=${root}`);\n  }\n  log(`Seatbelt Policy: ${policy}`);\n\n  // 2. Construct the actual command to run: sandbox-exec + policy + original command\n  const fullCommand = [\n    \"sandbox-exec\",\n    \"-p\", policy, // Pass the policy string\n    ...policyParams, // Pass parameters like -DWR_0=/path/to/project\n    \"--\", // End of sandbox-exec options\n    ...cmd, // The original command and arguments\n  ];\n\n  // 3. Execute the `sandbox-exec` command using rawExec\n  return rawExec(fullCommand, opts, [], abortSignal); // writableRoots not needed by rawExec here\n}\n```\n\n----------------------------------------\n\nTITLE: Using dspy.Predict with a Signature for Summarization in Python\nDESCRIPTION: Instantiates a `dspy.Predict` module using the previously defined `Summarize` Signature. It then calls the `summarizer` instance with input text to generate a summary. Assumes a Language Model (LM) has been configured in `dspy.settings`. The result object is expected to contain the generated summary in `result.summary`. Requires the `dspy` library and a configured LM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Assume LM is configured (Chapter 5)\nsummarizer = dspy.Predict(Summarize)\nlong_text = \"DSPy is a framework for programming foundation models...\" # (imagine longer text)\nresult = summarizer(text=long_text)\n# We expect result.summary to contain the summary\n```\n\n----------------------------------------\n\nTITLE: Loading Flask Configuration from a Python File using `from_pyfile` (Python)\nDESCRIPTION: Demonstrates loading configuration settings into a Flask app from an external file (e.g., `settings.cfg`) using `app.config.from_pyfile()`. It shows how to construct the absolute path to the configuration file using `os.path.join` and `os.path.dirname(__file__)`. The `silent=False` argument ensures an error is raised if the file doesn't exist, and the code checks the return value to confirm loading.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\nfrom flask import Flask\nimport os\n\napp = Flask(__name__)\n\n# Construct the path to the config file relative to this file\n# __file__ is the path to the current python script (hello.py)\n# os.path.dirname gets the directory containing hello.py\n# os.path.join creates the full path to settings.cfg\nconfig_file_path = os.path.join(os.path.dirname(__file__), 'settings.cfg')\n\n# Load configuration from the file\n# Set silent=True to ignore errors if the file doesn't exist\nloaded = app.config.from_pyfile(config_file_path, silent=False)\n\nif loaded:\n    print(\"Loaded config from settings.cfg\")\n    print(f\"Loaded Secret Key: {app.config.get('SECRET_KEY')}\")\n    print(f\"Loaded Server Name: {app.config.get('SERVER_NAME')}\")\n    print(f\"Calculated APP_ROOT: {app.config.get('APP_ROOT')}\")\nelse:\n    print(\"Could not load settings.cfg\")\n\n# ... rest of your app ...\nif __name__ == '__main__':\n  app.run()\n```\n\n----------------------------------------\n\nTITLE: Complete Graph Implementation Example\nDESCRIPTION: Full example showing a graph implementation using LastValue channel with adder and multiplier nodes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict\nfrom langgraph.graph import StateGraph, END, START\n\nclass MyState(TypedDict):\n    value: int\n\ndef add_one(state: MyState) -> dict:\n    return {\"value\": state['value'] + 1}\n\ndef multiply_by_two(state: MyState) -> dict:\n    return {\"value\": state['value'] * 2}\n\nworkflow = StateGraph(MyState)\nworkflow.add_node(\"adder\", add_one)\nworkflow.add_node(\"multiplier\", multiply_by_two)\nworkflow.set_entry_point(\"adder\")\nworkflow.add_edge(\"adder\", \"multiplier\")\nworkflow.add_edge(\"multiplier\", END)\napp = workflow.compile()\n\ninitial_state = {\"value\": 5}\nfinal_state = app.invoke(initial_state)\n```\n\n----------------------------------------\n\nTITLE: Configuring the Global RM in DSPy (Python)\nDESCRIPTION: Sets the global default Retrieval Model (RM) for the DSPy environment using `dspy.settings.configure`. It takes the previously created RM client instance (`colbertv2_wiki`) and makes it available for use by DSPy modules like `dspy.Retrieve`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndspy.settings.configure(rm=colbertv2_wiki)\n```\n\n----------------------------------------\n\nTITLE: Instantiating a MemorySaver Checkpointer in Python\nDESCRIPTION: This snippet shows how to create an instance of MemorySaver. Instantiating MemorySaver sets up an in-memory (RAM-backed) checkpoint manager for LangGraph. The resulting object will be used as an argument for graph compilation, making persistence available during the workflow's execution. No arguments are necessary for initialization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create an instance of the memory checkpointer\\nmemory_saver = MemorySaver()\n```\n\n----------------------------------------\n\nTITLE: Executing a Single Plan Step via an Agent in Python\nDESCRIPTION: Defines the `_execute_step` async method within `PlanningFlow`. This method is responsible for executing a single step of the plan. It takes the executor agent (`BaseAgent`) and step information (`step_info`) as input. It retrieves the current plan state (`_get_plan_text`), constructs a specific prompt for the agent including the plan context and the task for the current step, and then invokes the agent's `run` method with this prompt. After the agent completes the task and returns a result, this method calls `_mark_step_completed` to update the plan state. Depends on `BaseAgent` and internal helpers like `_get_plan_text` and `_mark_step_completed`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n    async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str:\n        \"\"\"Execute a single step using the executor agent.\"\"\"\n        step_text = step_info.get(\"text\", \"Current step\")\n        plan_status = await self._get_plan_text() # Get current plan state\n\n        # Construct prompt for the agent\n        step_prompt = f\"Current Plan:\\n{plan_status}\\n\\nYour Task:\\nExecute step: {step_text}\"\n\n        # Call the agent's run method!\n        step_result = await executor.run(step_prompt)\n\n        # Mark step completed after execution\n        await self._mark_step_completed()\n\n        return step_result\n```\n\n----------------------------------------\n\nTITLE: Building and Running LangGraph with Send in Python\nDESCRIPTION: Demonstrates how to construct a LangGraph using the defined nodes and the Send primitive. It shows the graph construction, compilation, and execution with sample input data.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.graph import StateGraph, END, START\n\nworkflow = StateGraph(MapReduceState)\n\nworkflow.add_node(\"preparer\", prepare_items)\nworkflow.add_node(\"worker\", process_single_item) # The node targeted by Send\nworkflow.add_node(\"aggregator\", aggregate_results)\n\nworkflow.set_entry_point(\"preparer\")\n\n# After 'preparer', call 'dispatch_work' which returns Send packets\nworkflow.add_conditional_edges(\"preparer\", dispatch_work)\n\nworkflow.add_edge(\"worker\", \"aggregator\")\n\nworkflow.add_edge(\"aggregator\", END)\n\n# Compile\napp = workflow.compile()\n\n# Run\ninput_state = {\"items_to_process\": [\"apple\", \"banana\", \"cherry\"]}\nfinal_state = app.invoke(input_state)\nprint(\"\\nFinal State:\", final_state)\n```\n\n----------------------------------------\n\nTITLE: Validating Entire Models with @model_validator in Python\nDESCRIPTION: Shows how to use the @model_validator decorator to implement validation logic that involves multiple fields in a Pydantic model. The example ensures that an end date is after a start date.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\nfrom pydantic import BaseModel, model_validator, ValidationError\nfrom typing import Self # Used for type hint in Python 3.11+\n\nclass Trip(BaseModel):\n    start_date: date\n    end_date: date\n    destination: str\n\n    # This method runs AFTER the model fields are validated individually\n    @model_validator(mode='after')\n    def check_dates(self) -> Self: # Use 'Self' or 'Trip' as return hint\n        print(f\"Checking dates: start={self.start_date}, end={self.end_date}\")\n        if self.start_date >= self.end_date:\n            raise ValueError('End date must be after start date')\n        # Return the validated model instance\n        return self\n\n# --- Try it out ---\n\n# Valid dates\ntrip_ok = Trip(start_date=date(2024, 7, 1), end_date=date(2024, 7, 10), destination='Beach')\nprint(f\"Valid trip: {trip_ok}\")\n# Expected Output:\n# Checking dates: start=2024-07-01, end=2024-07-10\n# Valid trip: start_date=datetime.date(2024, 7, 1) end_date=datetime.date(2024, 7, 10) destination='Beach'\n\n# Invalid dates\ntry:\n    Trip(start_date=date(2024, 7, 10), end_date=date(2024, 7, 1), destination='Mountains')\nexcept ValidationError as e:\n    print(f\"\\nValidation Error:\\n{e}\")\n    # Expected Output (simplified):\n    # Checking dates: start=2024-07-10, end=2024-07-01\n    # Validation Error:\n    # 1 validation error for Trip\n    #   Value error, End date must be after start date [type=value_error, ...]\n```\n\n----------------------------------------\n\nTITLE: Advanced Alias Control in Pydantic v2.11+ for Python\nDESCRIPTION: Demonstrates the use of newer configuration options in Pydantic v2.11 and above for more granular control over alias behavior, including validate_by_name, validate_by_alias, and serialize_by_alias.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic.alias_generators import to_camel\n\nclass UserV2(BaseModel):\n    user_id: int\n    first_name: str\n\n    model_config = ConfigDict(\n        alias_generator=to_camel,\n        validate_by_name=True,     # Allow input using 'user_id', 'first_name'\n        validate_by_alias=True,    # Allow input using 'userId', 'firstName' (default is True)\n        serialize_by_alias=True    # Use aliases ('userId', 'firstName') when dumping by default\n    )\n\nuser_data_camel = {'userId': 1, 'firstName': 'Zaphod'}\nuser_camel = UserV2(**user_data_camel)\nprint(f\"User from camel: {user_camel}\")\n# > User from camel: user_id=1 first_name='Zaphod'\n\nuser_data_snake = {'user_id': 2, 'first_name': 'Ford'}\nuser_snake = UserV2(**user_data_snake)\nprint(f\"User from snake: {user_snake}\")\n# > User from snake: user_id=2 first_name='Ford'\n\n# serialize_by_alias=True means model_dump() uses aliases by default\nprint(f\"Dumped (default alias): {user_camel.model_dump()}\")\n# > Dumped (default alias): {'userId': 1, 'firstName': 'Zaphod'}\nprint(f\"Dumped (force no alias): {user_camel.model_dump(by_alias=False)}\")\n# > Dumped (force no alias): {'user_id': 1, 'first_name': 'Zaphod'}\n```\n\n----------------------------------------\n\nTITLE: Accessing Application Settings and Logger with `current_app` Global\nDESCRIPTION: Illustrates using the `current_app` context global to interact with the application instance handling the current request. The `app_info` route function accesses the application's logger (`current_app.logger`) to log a message and retrieves configuration values (`MY_SETTING`, `DEBUG`) from `current_app.config`. Includes commented-out code for running the app with debug mode enabled.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n# Add another config value for demonstration\napp.config['MY_SETTING'] = 'Flask is Cool'\n\n@app.route('/app-info')\ndef app_info():\n  # Access the application's logger\n  current_app.logger.info('Someone accessed the app-info page.')\n\n  # Access a configuration value\n  setting = current_app.config.get('MY_SETTING', 'Default Value')\n  debug_mode = current_app.config['DEBUG'] # Accessing debug status\n\n  return f'My Setting: {setting}<br>Debug Mode: {debug_mode}'\n\n# Make sure debug is enabled for the logger example to show easily\n# if __name__ == '__main__':\n#   app.run(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Response Item Component\nDESCRIPTION: Component that handles rendering of individual chat messages with different types (user messages, AI responses, commands). Uses conditional rendering based on message type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_3\n\nLANGUAGE: tsx\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-chat-response-item.tsx (Simplified)\n\n// ... imports ...\nimport { Box, Text } from \"ink\";\nimport React from \"react\";\n\nexport default function TerminalChatResponseItem({ item }: { item: ResponseItem }): React.ReactElement {\n  switch (item.type) {\n    case \"message\":\n      return (\n        <Box flexDirection=\"column\">\n          <Text bold color={/* color based on role */}>\n            {item.role === \"assistant\" ? \"codex\" : item.role}\n          </Text>\n          <Text>{/* ... content ... */}</Text>\n        </Box>\n      );\n    case \"function_call\":\n       return (\n         <Box flexDirection=\"column\">\n           <Text color=\"magentaBright\" bold>command</Text>\n           <Text><Text dimColor>$</Text> {/* Formatted command */}</Text>\n         </Box>\n       );\n    default:\n      return <Text>Unknown message type</Text>;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing TopicId in Python for Message Categorization\nDESCRIPTION: The TopicId dataclass that holds 'type' and 'source' fields to identify message channels. It includes validation and provides a helper method to parse string representations of topic IDs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# From: _topic.py\n@dataclass(eq=True, frozen=True)\nclass TopicId:\n    type: str\n    source: str\n    # ... validation and __str__ ...\n\n    @classmethod\n    def from_str(cls, topic_id: str) -> Self:\n        # Helper to parse \"type/source\" string\n        # ... implementation ...\n```\n\n----------------------------------------\n\nTITLE: NumPy Core Module Imports and Setup\nDESCRIPTION: Simplified example of how NumPy's core module initializes and exposes functionality from the multiarray and umath modules, showing the import hierarchy that makes NumPy functions available.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# From numpy/core/numeric.py - Simplified\nfrom . import multiarray # Imports numpy/core/multiarray.py\n# multiarray.py itself imports from _multiarray_umath\nfrom .multiarray import (\n    array, asarray, zeros, empty, # Functions defined/re-exported\n    # ... many others ...\n)\n```\n\n----------------------------------------\n\nTITLE: Identifying Code Abstractions via LLM with Language Support - Python\nDESCRIPTION: This node analyzes file contents to extract key code abstractions (like classes, components, or modules) using an LLM and prompts constructed with context. It structures the output as a list of abstractions, each containing a translated or original name/description and associated file indices. The node manages YAML parsing, index validation, and supports multilingual scenarios. Dependencies include the shared store, LLM API, and a `create_llm_context` helper.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `files` (list of tuples), `project_name`, and `language` from shared store. Create context using `create_llm_context` helper which adds file indices. Format the list of `index # path` for the prompt.\n        *   `exec`: Construct a prompt for `call_llm`. If language is not English, add instructions to generate `name` and `description` in the target language. Ask LLM to identify ~5-10 core abstractions, provide a simple description for each, and list the relevant *file indices* (e.g., `- 0 # path/to/file.py`). Request YAML list output. Parse and validate the YAML, ensuring indices are within bounds and converting entries like `0 # path...` to just the integer `0`.\n        *   `post`: Write the validated list of `abstractions` (e.g., `[{\"name\": \"Node\", \"description\": \"...\", \"files\": [0, 3, 5]}, ...]`) containing file *indices* and potentially translated `name`/`description` to the shared store.\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pydantic Validation with SimpleMessage Example\nDESCRIPTION: This example illustrates how Pydantic performs automatic data validation. It shows a simple message schema that requires both 'role' and 'content' fields, with the role restricted to specific values, and demonstrates validation behavior for both valid and invalid inputs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Standalone Example (Illustrative)\nfrom pydantic import BaseModel, ValidationError\nfrom typing import Literal\n\nROLE_TYPE = Literal[\"user\", \"assistant\"] # Only allow these roles\n\nclass SimpleMessage(BaseModel):\n    role: ROLE_TYPE\n    content: str\n```\n\n----------------------------------------\n\nTITLE: Background Compaction Flow\nDESCRIPTION: Mermaid flowchart showing the lifecycle of background compaction tasks, from triggering conditions through execution and completion.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A[\"Write/Read/Compact finishes\"] --> B{\"Need Compaction?\"}\n    B -->|Yes| C{\"BG Task Scheduled?\"}\n    B -->|No| Z[\"Idle\"]\n    C -->|Yes| Z\n    C -->|No| D[\"Mark BG Scheduled = true\"]\n    D --> E[\"Schedule BGWork\"]\n    E --> F[\"Background Thread Pool\"]\n    F -->|Runs| G[\"DBImpl::BGWork\"]\n    G --> H[\"DBImpl::BackgroundCall\"]\n    H --> I{\"Compact imm_ OR Pick/Run SSTable Compaction?\"}\n    I --> J[\"Perform Compaction Work\"]\n    J --> K[\"Mark BG Scheduled = false\"]\n    K --> L[\"Signal Waiting Threads\"]\n    L --> B\n```\n\n----------------------------------------\n\nTITLE: Implementing LXMLWebScrapingStrategy in Crawl4AI (Python)\nDESCRIPTION: This snippet demonstrates the implementation of the LXMLWebScrapingStrategy class, which uses lxml to parse and scrape HTML content. It inherits from WebScrapingStrategy and overrides the scrap method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/content_scraping_strategy.py\nfrom lxml import html as lhtml # Library used by LXMLWebScrapingStrategy\n# ... other imports like models ...\n\nclass LXMLWebScrapingStrategy(WebScrapingStrategy): # Often inherits for shared logic\n    def __init__(self, logger=None):\n        super().__init__(logger)\n        # ... potentially LXML specific setup ...\n\n    def scrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n        # 1. Parse HTML using lxml\n        doc = lhtml.document_fromstring(html)\n\n        # 2. Find main content, remove unwanted tags, extract info\n        # ... complex cleaning and extraction logic using lxml's XPath or CSS selectors ...\n\n        # 3. Package results into a ScrapingResult object\n        cleaned_html_content = \"<html><body>Cleaned LXML content...</body></html>\" # Placeholder\n        links_data = Links(...)\n        media_data = Media(...)\n        metadata_dict = {\"title\": \"Page Title LXML\"}\n\n        return ScrapingResult(\n            cleaned_html=cleaned_html_content,\n            links=links_data,\n            media=media_data,\n            metadata=metadata_dict,\n            success=True\n        )\n\n    # ascrap might also delegate or have specific async optimizations\n```\n\n----------------------------------------\n\nTITLE: Implementing Long-Running Task with FastMCP Context\nDESCRIPTION: Demonstrates how to create a long-running task that reports progress and logs messages using the Context object. Shows basic Context usage including info logging, debug messaging, and progress reporting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport anyio\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.server import Context\n\nserver = FastMCP(name=\"LongTaskServer\")\n\n@server.tool(name=\"long_task\", description=\"Simulates a task that takes time.\")\nasync def run_long_task(duration_seconds: int, ctx: Context) -> str:\n  \"\"\"\n  Simulates a task, reporting progress and logging using Context.\n  \"\"\"\n  await ctx.info(f\"Starting long task for {duration_seconds} seconds.\")\n\n  total_steps = 5\n  for i in range(total_steps):\n      step = i + 1\n      await ctx.debug(f\"Working on step {step}/{total_steps}...\")\n      await anyio.sleep(duration_seconds / total_steps)\n      await ctx.report_progress(step, total_steps)\n\n  await ctx.info(\"Long task completed!\")\n  return f\"Finished simulated task of {duration_seconds} seconds.\"\n\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Command with Click in Python\nDESCRIPTION: Demonstrates how to create a basic 'Hello World' command using Click. The code imports Click, defines a command function decorated with @click.command(), and includes a docstring for automatic help text generation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/01_command___group.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# hello_app.py\nimport click\n\n@click.command()\ndef hello():\n  \"\"\"A simple command that says Hello World\"\"\"\n  print(\"Hello World!\")\n\nif __name__ == '__main__':\n  hello()\n```\n\n----------------------------------------\n\nTITLE: Implementing Terminal Chat Container Component\nDESCRIPTION: Core terminal chat component that manages chat state and renders message history and input components. Handles loading states and command confirmation prompts.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-chat.tsx (Simplified)\n\n// ... imports ...\nimport TerminalMessageHistory from \"./terminal-message-history\";\nimport TerminalChatInput from \"./terminal-chat-input\"; // Or TerminalChatNewInput\nimport { Box } from \"ink\";\nimport React, { useState } from \"react\";\n\nexport default function TerminalChat({ /* ...props... */ }): React.ReactElement {\n  const [items, setItems] = useState<Array<ResponseItem>>([]);\n  const [loading, setLoading] = useState<boolean>(false);\n  const [confirmationPrompt, setConfirmationPrompt] = useState<React.ReactNode | null>(null);\n\n  return (\n    <Box flexDirection=\"column\">\n      <TerminalMessageHistory\n        batch={/* ...derived from items... */}\n        loading={loading}\n        /* ...other props... */\n      />\n\n      <TerminalChatInput\n        loading={loading}\n        confirmationPrompt={confirmationPrompt}\n        submitInput={(/*...user input...*/) => { /* Send to Agent Loop */ }}\n        submitConfirmation={(/*...decision...*/) => { /* Send to Agent Loop */ }}\n        /* ...other props... */\n      />\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Message Manager Sequence Diagram in Mermaid\nDESCRIPTION: A sequence diagram written in Mermaid syntax illustrating the key interactions during one step of the Agent loop involving the MessageManager. The diagram shows the flow between Agent, BrowserContext, MessageManager, LLM, and Controller components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant BC as BrowserContext\n    participant MM as MessageManager\n    participant LLM\n    participant Controller\n\n    Note over Agent: Start of step\n    Agent->>BC: get_state()\n    BC-->>Agent: Current BrowserState (DOM map, URL, screenshot?)\n    Note over Agent: Have BrowserState and `last_result` from previous step\n    Agent->>MM: add_state_message(BrowserState, last_result)\n    MM->>MM: Format state/result into HumanMessage (with text/image)\n    MM->>MM: Calculate tokens for new message\n    MM->>MM: Add HumanMessage to internal history list\n    MM->>MM: Update total token count\n    MM->>MM: Check token limit, potentially call cut_messages()\n    Note over Agent: Ready to ask LLM\n    Agent->>MM: get_messages()\n    MM-->>Agent: Return List[BaseMessage] (System, Task, State1, Plan1, State2...)\n    Agent->>LLM: Invoke LLM with message list\n    LLM-->>Agent: LLM Response (AgentOutput containing plan)\n    Note over Agent: Got LLM's plan\n    Agent->>MM: _remove_last_state_message() # Optimization\n    MM->>MM: Remove last (large) HumanMessage from list\n    Agent->>MM: add_model_output(AgentOutput)\n    MM->>MM: Format plan into AIMessage (with tool calls)\n    MM->>MM: Calculate tokens for AIMessage\n    MM->>MM: Add AIMessage to internal history list\n    MM->>MM: Update total token count\n    Note over Agent: Ready to execute plan\n    Agent->>Controller: multi_act(AgentOutput.action)\n    Controller-->>Agent: List[ActionResult] (Result of this step's actions)\n    Agent->>Agent: Store ActionResult in `self.state.last_result` (for next step)\n    Note over Agent: End of step\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolAgent for Managing and Executing Tools\nDESCRIPTION: A simplified concept of the ToolAgent class, which inherits from RoutedAgent. It shows how the agent handles function calls, including tool lookup, argument parsing, tool execution, and result handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass ToolAgent(RoutedAgent):\n    def __init__(self, ..., tools: List[Tool]):\n        super().__init__(...)\n        self._tools = {tool.name: tool for tool in tools} # Store tools by name\n\n    @message_handler # Registers this for FunctionCall messages\n    async def handle_function_call(self, message: FunctionCall, ctx: MessageContext):\n        # Find the tool by name\n        tool = self._tools.get(message.name)\n        if tool is None:\n            # Handle error: Tool not found\n            raise ToolNotFoundException(...)\n        try:\n            # Parse arguments string into a dictionary\n            arguments = json.loads(message.arguments)\n            # Execute the tool's run_json method\n            result_obj = await tool.run_json(args=arguments, ...)\n            # Convert result object back to string if needed\n            result_str = tool.return_value_as_string(result_obj)\n            # Create the success result message\n            return FunctionExecutionResult(content=result_str, ...)\n        except Exception as e:\n            # Handle execution errors\n            return FunctionExecutionResult(content=f\"Error: {e}\", is_error=True, ...)\n```\n\n----------------------------------------\n\nTITLE: Defining a Translation Signature with DSPy in Python\nDESCRIPTION: This snippet defines a custom dspy.Signature class for translating English text to French, specifying both the input (english_sentence) and the expected output (french_sentence) with field descriptions. Requires the dspy package and its field submodule. Input: English sentence string; Output: French translation string. The class structure provides task instructions to the Predict module and underpins prompt formatting for the LM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/04_predict.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\nfrom dspy.signatures.field import InputField, OutputField\n\nclass TranslateToFrench(dspy.Signature):\n    \"\"\"Translates English text to French.\"\"\"\n    english_sentence = dspy.InputField(desc=\"The original sentence in English\")\n    french_sentence = dspy.OutputField(desc=\"The translated sentence in French\")\n```\n\n----------------------------------------\n\nTITLE: Executing Code via PythonExecutor in CodeAgent Step in Python\nDESCRIPTION: This snippet illustrates the `step` method within the `CodeAgent`. It first parses Python code blocks from a language model's output using helper functions (`parse_code_blobs`, `fix_final_answer_code`). Then, it delegates the execution of this parsed code (`code_action`) to the agent's `python_executor` instance by calling it directly (`self.python_executor(code_action)`). The method captures the execution output, logs, and a flag indicating if the result is the final answer, storing them in the `memory_step` and handling potential execution errors. Dependencies include helper functions (`parse_code_blobs`, `fix_final_answer_code`), the `PythonExecutor` instance, and error types like `AgentParsingError` and `AgentExecutionError`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/06_pythonexecutor.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified CodeAgent step) ---\nfrom .utils import parse_code_blobs # Helper to extract code\nfrom .local_python_executor import fix_final_answer_code # Helper\n\nclass CodeAgent(MultiStepAgent):\n    def step(self, memory_step: ActionStep) -> Union[None, Any]:\n        # ... (Agent thinks, gets LLM response with code) ...\n        model_output = chat_message.content\n\n        # Parse the code from the LLM response\n        try:\n            # parse_code_blobs finds ```python ... ``` blocks\n            # fix_final_answer ensures `final_answer = x` becomes `final_answer(x)`\n            code_action = fix_final_answer_code(parse_code_blobs(model_output))\n        except Exception as e:\n            # Handle parsing errors\n            raise AgentParsingError(...)\n\n        # === Execute the code using the PythonExecutor ===\n        self.logger.log_code(title=\"Executing parsed code:\", content=code_action, ...)\n        try:\n            # THE CORE CALL to the executor\n            output, execution_logs, is_final_answer = self.python_executor(code_action)\n\n            # Store results in memory step\n            memory_step.observations = f\"Execution logs:\\n{execution_logs}\\nLast output:\\n{output}\"\n            memory_step.action_output = output\n\n        except Exception as e:\n            # Handle execution errors reported by the executor\n            raise AgentExecutionError(...)\n\n        # Return the output if it's the final answer, otherwise None\n        return output if is_final_answer else None\n        # ...\n```\n\n----------------------------------------\n\nTITLE: Enabling the Event Dispatcher in Celery Worker (Python)\nDESCRIPTION: Initializes the event dispatching subsystem in a Celery worker, controlling its activation through configuration or flags (such as -E). Relies on the bootsteps pattern for worker startup and uses dependencies like 'Connection' and the main Celery app. The start() method creates and assigns an EventDispatcher instance to the app, passing connection, hostname, and enablement flags for downstream event transmission. Key parameters include task_events for dispatcher activation and the worker connection; outputs include the initialized dispatcher instance (or a no-op if not enabled); limitations may include the requirement for proper configuration and the dependency on correct Kombu setup.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from worker/consumer/events.py\nclass Events(bootsteps.StartStopStep):\n    requires = (Connection,)\n\n    def __init__(self, c, task_events=True, # Controlled by config/flags\n                 # ... other flags ...\n                 **kwargs):\n        self.send_events = task_events # or other flags\n        self.enabled = self.send_events\n        # ...\n        super().__init__(c, **kwargs)\n\n    def start(self, c):\n        # ... gets connection ...\n        # Creates the actual dispatcher instance\n        dis = c.event_dispatcher = c.app.events.Dispatcher(\n            c.connection_for_write(),\n            hostname=c.hostname,\n            enabled=self.send_events, # Only sends if enabled\n            # ... other options ...\n        )\n        # ... flush buffer ...\n\n```\n\n----------------------------------------\n\nTITLE: Defining a DSPy Signature for Text Summarization in Python\nDESCRIPTION: Defines a `Summarize` class inheriting from `dspy.Signature` to specify a text summarization task. It declares an input field `text` and an output field `summary`, both with descriptive help text. This Signature acts as a structured template for interacting with LMs via DSPy modules. Requires the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\nclass Summarize(dspy.Signature):\n  \"\"\"Summarize the given text.\"\"\"\n  text = dspy.InputField(desc=\"The text to summarize.\")\n  summary = dspy.OutputField(desc=\"A concise summary.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing WebSocket Transport Server in Python\nDESCRIPTION: Shows how to implement a WebSocket-based server using the Starlette web framework. Uses websocket_server context manager to handle WebSocket connections and stream management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/09_communication_transports__stdio__sse__websocket__memory_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual code using Starlette web framework\nfrom starlette.applications import Starlette\nfrom starlette.routing import WebSocketRoute\nfrom starlette.websockets import WebSocket\nfrom mcp.server.websocket import websocket_server # Import WS transport\nfrom mcp.server.mcp_server import MCPServer # Low-level server\n\nmy_actual_server = MCPServer(name=\"MyWebSocketServer\")\n\n# Define the WebSocket endpoint handler\nasync def websocket_endpoint(websocket: WebSocket):\n    # 1. Use the websocket_server context manager\n    async with websocket_server(\n        websocket.scope, websocket.receive, websocket.send\n    ) as (read_stream, write_stream):\n        # 2. It yields streams connected to this specific WebSocket\n        print(f\"Server: WebSocket client connected. Running server logic.\")\n        # 3. Pass streams to the server's run method\n        await my_actual_server.run(\n            read_stream,\n            write_stream,\n            my_actual_server.create_initialization_options()\n        )\n    print(\"Server: WebSocket client disconnected.\")\n\n# Set up the web application routes\nroutes = [\n    WebSocketRoute(\"/mcp\", endpoint=websocket_endpoint)\n]\napp = Starlette(routes=routes)\n\n# To run this, you'd use an ASGI server like uvicorn:\n# uvicorn your_module:app --host 0.0.0.0 --port 8000\n```\n\n----------------------------------------\n\nTITLE: Basic ufunc operations with NumPy arrays\nDESCRIPTION: Examples of using NumPy ufuncs both directly (via function calls) and indirectly (via operators). Shows how functions like np.add, np.maximum, and np.sin perform element-wise operations on arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\na = np.array([1, 2, 3, 4])\nb = np.array([5, 0, 7, 2])\n\n# Using the ufunc directly\nc = np.add(a, b)\nprint(f\"np.add(a, b)  = {c}\")\n# Output: np.add(a, b)  = [ 6  2 10  6]\n\n# Using the corresponding operator (which calls np.add internally)\nd = a + b\nprint(f\"a + b         = {d}\")\n# Output: a + b         = [ 6  2 10  6]\n\n# Other examples\nprint(f\"np.maximum(a, b) = {np.maximum(a, b)}\") # Element-wise maximum\n# Output: np.maximum(a, b) = [5 2 7 4]\n\nprint(f\"np.sin(a)      = {np.sin(a)}\") # Element-wise sine\n# Output: np.sin(a)      = [ 0.84147098  0.90929743  0.14112001 -0.7568025 ]\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Signatures in Celery\nDESCRIPTION: Demonstrates how to create a signature for a Celery task using the .s() shortcut. The example creates a signature for an addition task and shows how to access signature properties like task name and arguments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# tasks.py\nfrom celery_app import app # Assuming app is defined in celery_app.py\n\n@app.task\ndef add(x, y):\n    return x + y\n\n# Create a signature for add(2, 3)\nadd_sig = add.s(2, 3)\n\n# add_sig now holds the 'plan' to run add(2, 3)\nprint(f\"Signature: {add_sig}\")\nprint(f\"Task name: {add_sig.task}\")\nprint(f\"Arguments: {add_sig.args}\")\n\n# To actually run it, you call .delay() or .apply_async() ON the signature\n# result_promise = add_sig.delay()\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Field() and FieldInfo Internals in Python\nDESCRIPTION: This Python code provides a simplified view of Pydantic's internal mechanisms for handling field definitions. It shows the `Field()` function, which captures configuration arguments (like default, alias, constraints) and returns a `FieldInfo` instance. The `FieldInfo` class stores this configuration. The `collect_model_fields` function demonstrates how Pydantic iterates through class type hints, checks for assigned values (potentially `Field()` results or defaults), and creates the final `FieldInfo` object for each field, handling different definition styles.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from pydantic/fields.py\n\n# The user-facing function\ndef Field(\n    default: Any = PydanticUndefined,\n    *,\n    alias: str | None = _Unset,\n    description: str | None = _Unset,\n    gt: float | None = _Unset,\n    # ... many other arguments\n) -> Any: # Returns Any for type checker convenience\n    # It captures all arguments and passes them to create a FieldInfo instance\n    field_info = FieldInfo.from_field(\n        default,\n        alias=alias,\n        description=description,\n        gt=gt,\n        # ... passing all arguments through\n    )\n    return field_info # Actually returns a FieldInfo instance at runtime\n\n# The internal storage class\nclass FieldInfo:\n    # Attributes to store all the configuration\n    annotation: type[Any] | None\n    default: Any\n    alias: str | None\n    description: str | None\n    metadata: list[Any] # Stores constraints like Gt, MinLen, etc.\n    # ... other attributes\n\n    def __init__(self, **kwargs) -> None:\n        # Simplified: Assigns kwargs to attributes\n        self.annotation = kwargs.get('annotation')\n        self.default = kwargs.get('default', PydanticUndefined)\n        self.alias = kwargs.get('alias')\n        self.description = kwargs.get('description')\n        # ... and collects constraints into self.metadata\n        self.metadata = self._collect_metadata(kwargs)\n\n    @staticmethod\n    def from_field(default: Any = PydanticUndefined, **kwargs) -> 'FieldInfo':\n        # Creates an instance, handling the default value logic\n        # ... implementation ...\n        return FieldInfo(default=default, **kwargs)\n\n    def _collect_metadata(self, kwargs: dict[str, Any]) -> list[Any]:\n        # Simplified: Takes kwargs like 'gt=0' and converts them\n        # to internal metadata objects like 'annotated_types.Gt(0)'\n        metadata = []\n        if 'gt' in kwargs:\n             # metadata.append(annotated_types.Gt(kwargs.pop('gt'))) # Real code is more complex\n             pass # Simplified\n        # ... handles other constraint kwargs ...\n        return metadata\n\n# --- Simplified view from pydantic._internal._fields.py ---\n\ndef collect_model_fields(cls, config_wrapper, ns_resolver, *, typevars_map=None):\n    fields: dict[str, FieldInfo] = {}\n    type_hints = get_model_type_hints(cls, ns_resolver=ns_resolver) # Get {'name': str, 'age': int, ...}\n\n    for ann_name, (ann_type, evaluated) in type_hints.items():\n        if is_valid_field_name(ann_name):\n            assigned_value = getattr(cls, ann_name, PydanticUndefined) # Check if Field() was used\n\n            if isinstance(assigned_value, FieldInfo): # If name = Field(...) was used\n                # Create FieldInfo using the type hint AND the assigned FieldInfo object\n                field_info = FieldInfo.from_annotated_attribute(ann_type, assigned_value)\n            elif assigned_value is PydanticUndefined: # If only name: str was used\n                # Create FieldInfo just from the type hint\n                field_info = FieldInfo.from_annotation(ann_type)\n            else: # If name: str = 'some_default' was used\n                # Create FieldInfo from type hint and simple default\n                field_info = FieldInfo.from_annotated_attribute(ann_type, assigned_value)\n\n            fields[ann_name] = field_info\n            # ... more logic for inheritance, docstrings, etc. ...\n\n    return fields, set() # Returns dict of field names to FieldInfo objects\n```\n\n----------------------------------------\n\nTITLE: Visualizing Sandbox Execution Flow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of a sandbox execution, from the tool's command to the Docker container and back. It shows the interactions between the Tool, SANDBOX_CLIENT, DockerSandbox, Docker Engine, and Docker Container.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Tool as Tool (e.g., PythonExecute)\n    participant Client as SANDBOX_CLIENT\n    participant Sandbox as DockerSandbox\n    participant Docker as Docker Engine (Host)\n    participant Container as Docker Container\n\n    Tool->>+Client: run_command(\"python script.py\")\n    Client->>+Sandbox: run_command(\"python script.py\")\n    Note over Sandbox: Checks if container exists. Assume No.\n    Sandbox->>+Docker: Create Container Request (using config: image, limits)\n    Docker->>+Container: Creates & Starts Container\n    Container-->>-Docker: Container Ready\n    Docker-->>-Sandbox: Container Created (ID: abc)\n    Sandbox->>+Docker: Execute Command Request (in Container abc: \"python script.py\")\n    Docker->>+Container: Runs \"python script.py\"\n    Note over Container: script prints \"4\"\n    Container-->>-Docker: Command Output (\"4\\n\")\n    Docker-->>-Sandbox: Command Result (\"4\\n\")\n    Sandbox-->>-Client: Returns \"4\\n\"\n    Client-->>-Tool: Returns \"4\\n\"\n\n    Note over Tool, Container: ... Later (idle timeout or explicit cleanup) ...\n    Client->>+Sandbox: cleanup() (or Manager does it)\n    Sandbox->>+Docker: Stop Container Request (ID: abc)\n    Docker->>Container: Stops Container\n    Container-->>Docker: Stopped\n    Sandbox->>+Docker: Remove Container Request (ID: abc)\n    Docker->>Docker: Removes Container abc\n    Docker-->>-Sandbox: Container Removed\n    Sandbox-->>-Client: Cleanup Done\n```\n\n----------------------------------------\n\nTITLE: Running the Compiled StateGraph Application - Python\nDESCRIPTION: Demonstrates how to execute a compiled StateGraph workflow. The initial state ('initial_state') is passed to 'app.invoke', returning a final state after all nodes execute in sequence. Sample print statements illustrate how to inspect results. The expected I/O is a dictionary mapping the state's keys to updated values. Requires a compiled 'app' object from previous steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Define the initial state\ninitial_state = {\"value\": 5}\n\n# Run the graph\nfinal_state = app.invoke(initial_state)\n\n# Print the final result\nprint(\"\\n--- Final State ---\")\nprint(final_state)\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent Class with Custom SystemPrompt in Python\nDESCRIPTION: This code snippet defines an Agent class that initializes with a task, language model, browser context, and controller. It sets up a SystemPrompt instance and uses it to create a MessageManager, which governs the LLM's behavior in the browser automation framework.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/02_system_prompt.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Agent:\n    def __init__(\n        self,\n        task: str,\n        llm: BaseChatModel,\n        browser_context: BrowserContext,\n        controller: Controller,\n        system_prompt_class: Type[SystemPrompt] = SystemPrompt, # Allows customizing the prompt class\n        max_actions_per_step: int = 10,\n         # ... other parameters ...\n        **kwargs\n    ):\n        self.task = task\n        self.llm = llm\n        # ... store other components ...\n\n        # Get the list of available actions from the controller\n        self.available_actions = controller.registry.get_prompt_description()\n\n        # 1. Create the SystemPrompt instance using the provided class\n        system_prompt_instance = system_prompt_class(\n            action_description=self.available_actions,\n            max_actions_per_step=max_actions_per_step,\n        )\n\n        # 2. Get the formatted SystemMessage (the rules)\n        system_message = system_prompt_instance.get_system_message()\n\n        # 3. Initialize the Message Manager with the task and the rules\n        self._message_manager = MessageManager(\n            task=self.task,\n            system_message=system_message, # <--- Pass the rules here!\n            settings=MessageManagerSettings(...)\n            # ... other message manager setup ...\n        )\n        # ... rest of initialization ...\n        logger.info(\"Agent initialized with System Prompt.\")\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram: A2A Client-Server Communication Flow\nDESCRIPTION: Detailed sequence diagram showing the complete flow of communication between an application using the A2AClient library and an A2A Agent Server, including request formatting, HTTP communication, SSE handling, and event processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/05_a2a_client_implementation.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant App as Your Application (e.g., CLI)\n    participant Lib as A2AClient Library\n    participant Net as Network (HTTP)\n    participant Srv as A2A Agent Server\n\n    App->>Lib: Call client.sendTaskSubscribe(params)\n    Note right of Lib: Generates JSON-RPC ID, Method='tasks/sendSubscribe'\n    Lib->>Lib: Format JSON-RPC Request Body (using params)\n    Note right of Lib: {jsonrpc:\"2.0\", id:\"req-1\", method:\"...\", params:{...}}\n\n    Lib->>Net: Send HTTP POST Request to Agent URL\n    Note over Net,Srv: Request travels over the internet\n\n    Net->>Srv: Delivers HTTP POST Request\n    Note right of Srv: Server receives request, parses JSON-RPC\n\n    Srv->>Srv: Processes Task (Starts internal logic)\n    Note right of Srv: Switches to streaming mode (SSE)\n\n    Srv-->>Net: Send HTTP Response (Status 200 OK, Content-Type: text/event-stream)\n    Srv-->>Net: Send SSE Event 1 (e.g., 'working' status)\n    Srv-->>Net: Send SSE Event 2 (e.g., 'completed' status)\n    Note right of Srv: Stream ends\n\n    Net-->>Lib: Delivers HTTP Response & SSE Events\n    Note right of Lib: Receives streaming response\n\n    Lib->>Lib: Parse SSE Events (Extract JSON data from 'data:' lines)\n    Lib-->>App: Yield Parsed Event 1 (as object)\n    Lib-->>App: Yield Parsed Event 2 (as object)\n    Note left of App: Application processes each event in the loop\n\n    App->>App: Loop finishes when stream ends\n```\n\n----------------------------------------\n\nTITLE: Integrating Monitor Step Metrics with Agent Step Lifecycle (Python)\nDESCRIPTION: Shows how the Monitor's update_metrics method is registered as a callback within MultiStepAgent, ensuring that after every agent step, duration and token statistics are recorded. The agent also resets both memory and monitor on new runs. Expects proper instantiation of the Monitor class and agent components supporting hooks/callbacks for step completion. Relies on ActionStep to provide step metrics and supports arbitrary additional callbacks.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified Agent setup for Monitor) ---\\nfrom .monitoring import Monitor\\nfrom .memory import ActionStep\\n\\nclass MultiStepAgent:\\n    def __init__(self, ..., model: Model, step_callbacks: Optional[List[Callable]] = None):\\n        # ... setup logger ...\\n        self.model = model # Store the model\\n        self.monitor = Monitor(self.model, self.logger) # Create Monitor\\n\\n        # Add monitor's update method to callbacks\\n        self.step_callbacks = step_callbacks if step_callbacks is not None else []\\n        self.step_callbacks.append(self.monitor.update_metrics)\\n        # ...\\n\\n    def _finalize_step(self, memory_step: ActionStep, step_start_time: float):\\n        \\\"\\\"\\\"Called at the very end of each step.\\\"\\\"\\\"\\n        memory_step.end_time = time.time()\\n        memory_step.duration = memory_step.end_time - step_start_time\\n\\n        # Call all registered callbacks, including monitor.update_metrics\\n        for callback in self.step_callbacks:\\n             # Pass the completed step data to the callback\\n             callback(memory_step)\\n        # ...\\n\\n    def run(self, ..., reset: bool = True):\\n         # ...\\n         if reset:\\n             self.memory.reset()\\n             self.monitor.reset() # Reset monitor metrics on new run\\n         # ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving Metadata and Links from CrawlResult in Python\nDESCRIPTION: This example shows how to access metadata, internal links, and external links from a CrawlResult object. It demonstrates safe dictionary access for metadata and how to iterate through the links collections.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlResult\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url = \"https://httpbin.org/links/10/0\" # A page with links\n        result: CrawlResult = await crawler.arun(url=url)\n\n        if result.success:\n            print(\"--- Metadata & Links ---\")\n            print(f\"Title: {result.metadata.get('title', 'N/A')}\")\n            print(f\"Found {len(result.links.internal)} internal links.\")\n            print(f\"Found {len(result.links.external)} external links.\")\n            if result.links.internal:\n                print(f\"  First internal link text: '{result.links.internal[0].text}'\")\n            # Similarly access result.media.images etc.\n        else:\n            print(f\"Crawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Adding Content to Memory in AutoGen Core\nDESCRIPTION: Shows how to create a MemoryContent object with user preference information and add it to a ListMemory instance using the asynchronous add method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# File: add_preference.py\nimport asyncio\nfrom autogen_core.memory import MemoryContent\n# Assume user_prefs_memory exists from the previous step\n\n# Define the preference as MemoryContent\npreference = MemoryContent(\n    content=\"User prefers all communication to be written in a formal style.\",\n    mime_type=\"text/plain\", # It's just text\n    metadata={\"source\": \"user_instruction_conversation_1\"} # Optional info\n)\n\nasync def add_to_memory():\n    # Add the content to our memory instance\n    await user_prefs_memory.add(preference)\n    print(f\"Memory content after adding: {user_prefs_memory.content}\")\n\nasyncio.run(add_to_memory())\n# Output (will show the MemoryContent object):\n# Memory content after adding: [MemoryContent(content='User prefers...', mime_type='text/plain', metadata={'source': '...'})]\n```\n\n----------------------------------------\n\nTITLE: Visualizing NumPy Core Relationships with Mermaid - Mermaid\nDESCRIPTION: This mermaid flowchart code visually represents the interdependencies among major NumPy core components: ndarray, dtype, ufunc, and core modules such as multiarray and umath. It shows how ndarrays are typed, how ufuncs operate, and how supporting modules provide implementations and formatting. No external dependencies beyond Mermaid are required. The chart is intended for documentation or interactive visualization platforms that render Mermaid diagrams.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\\n    A0[\\\"ndarray (N-dimensional array)\\\"]\\n    A1[\\\"dtype (Data Type Object)\\\"]\\n    A2[\\\"ufunc (Universal Function)\\\"]\\n    A3[\\\"multiarray Module\\\"]\\n    A4[\\\"umath Module\\\"]\\n    A5[\\\"Numeric Types\\\"]\\n    A6[\\\"Array Printing\\\"]\\n    A7[\\\"__array_function__ Protocol / Overrides\\\"]\\n    A0 -- \\\"Has data type\\\" --> A1\\n    A2 -- \\\"Operates element-wise on\\\" --> A0\\n    A3 -- \\\"Provides implementation for\\\" --> A0\\n    A4 -- \\\"Provides implementation for\\\" --> A2\\n    A5 -- \\\"Defines scalar types for\\\" --> A1\\n    A6 -- \\\"Formats for display\\\" --> A0\\n    A6 -- \\\"Uses for formatting info\\\" --> A1\\n    A7 -- \\\"Overrides functions from\\\" --> A3\\n    A7 -- \\\"Overrides functions from\\\" --> A4\\n    A1 -- \\\"References type hierarchy\\\" --> A5\n```\n\n----------------------------------------\n\nTITLE: Defining GET and POST Path Operations in FastAPI (Python)\nDESCRIPTION: Demonstrates how to define different HTTP methods (GET, POST) for the same URL path (`/items/`) using FastAPI decorators (`@app.get`, `@app.post`). It shows separate functions handling data retrieval (GET) and data creation (POST), illustrating how FastAPI routes requests based on the HTTP method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py (continuing from Chapter 1, maybe add this to routers/items.py)\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n# A GET operation (read)\n@app.get(\"/items/\")\nasync def read_items():\n    return [{\"item_id\": 1, \"name\": \"Thingamajig\"}]\n\n# A POST operation (create)\n@app.post(\"/items/\")\nasync def create_item():\n    # We'll see how to get data *into* here later\n    return {\"message\": \"Item received!\"} # Placeholder\n\n# We'll focus on GET for now, but others work similarly!\n```\n\n----------------------------------------\n\nTITLE: Automatic Usage of dspy.settings by dspy.Retrieve (Python)\nDESCRIPTION: Illustrates how a `dspy.Retrieve` module, when instantiated without an explicit `rm` argument, automatically utilizes the Retrieval Model (RM) configured globally in `dspy.settings`. Assumes `dspy.settings.configure` has been previously called to set `dspy.settings.rm`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n# Assume settings were configured as above\n\n# Create a Retrieve module WITHOUT passing 'rm' explicitly\nretriever = dspy.Retrieve() # Uses default k=3 from DummyRM initialization\n\n# When called, it uses dspy.settings.rm\nresults = retriever(query=\"DSPy benefits\")\nprint(results.passages)\n```\n\n----------------------------------------\n\nTITLE: Implementing Arguments in Click Python CLI\nDESCRIPTION: Shows how to create a CLI command that accepts two required positional arguments using @click.argument(). The command function receives the argument values as parameters in the order they are defined.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/03_parameter__option___argument_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport click\n\n@click.command()\n@click.argument('src')  # Defines the first argument\n@click.argument('dst')  # Defines the second argument\ndef copy(src, dst):     # Function parameters match argument names\n  \"\"\"Copies SRC file to DST.\"\"\"\n  print(f\"Pretending to copy '{src}' to '{dst}'\")\n\nif __name__ == '__main__':\n  copy()\n```\n\n----------------------------------------\n\nTITLE: Implementing Map-Reduce Nodes for Send Example in Python\nDESCRIPTION: Defines three nodes for a map-reduce workflow: prepare_items to set up the process, process_single_item to handle individual items, and aggregate_results to combine processed items.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_items(state: MapReduceState) -> dict:\n    print(\"--- Preparing Items (No change) ---\")\n    # In a real scenario, this might fetch or generate the items\n    return {}\n\ndef process_single_item(state: dict) -> dict:\n    # Note: This node receives the dict passed via Send, NOT the full MapReduceState\n    item = state['item']\n    print(f\"--- Processing Item: {item} ---\")\n    processed = f\"Processed_{item.upper()}\"\n    # Return the processed item to be ADDED to the list in the main state\n    return {\"processed_items\": [processed]} # Return list for operator.add\n\ndef aggregate_results(state: MapReduceState) -> dict:\n    print(\"--- Aggregating Results ---\")\n    all_processed = state['processed_items']\n    final = \", \".join(all_processed)\n    return {\"final_result\": final}\n```\n\n----------------------------------------\n\nTITLE: FastMCP Context with Resource Access Integration\nDESCRIPTION: Shows how to combine Context functionality with resource access, demonstrating both outward communication (logs, progress) and inward interaction (reading resources) within a single request scope.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport anyio\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.server import Context\n\nserver = FastMCP(name=\"LongTaskServer\")\n\n@server.resource(uri=\"config://task_settings\", description=\"Settings for the long task.\")\ndef get_task_settings() -> str:\n  \"\"\"Returns task settings as a simple string.\"\"\"\n  print(\"Resource 'config://task_settings' was read!\")\n  return \"Default speed: Normal\"\n\n@server.tool(name=\"long_task\", description=\"Simulates a task using config resource.\")\nasync def run_long_task(duration_seconds: int, ctx: Context) -> str:\n  \"\"\"Simulates a task, reads config via Context, reports progress.\"\"\"\n  await ctx.info(f\"Starting long task for {duration_seconds} seconds.\")\n\n  try:\n      resource_contents = await ctx.read_resource(\"config://task_settings\")\n      settings = \"\"\n      for content_part in resource_contents:\n          if hasattr(content_part, 'content') and isinstance(content_part.content, str):\n              settings = content_part.content\n              break\n      await ctx.info(f\"Loaded settings: {settings}\")\n  except Exception as e:\n      await ctx.warning(f\"Could not read task settings: {e}\")\n\n  total_steps = 5\n  for i in range(total_steps):\n      step = i + 1\n      await ctx.debug(f\"Working on step {step}/{total_steps}...\")\n      await anyio.sleep(duration_seconds / total_steps)\n      await ctx.report_progress(step, total_steps)\n\n  await ctx.info(\"Long task completed!\")\n  return f\"Finished simulated task of {duration_seconds} seconds using settings.\"\n\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Conceptual Output of ChatAdapter Parsing\nDESCRIPTION: Shows the conceptual dictionary returned by the `ChatAdapter.parse()` method after processing the raw LM response string. The method extracts the text associated with the output field markers (like `[[ ## summary ## ]]`) and maps it to the corresponding field name from the Signature (e.g., `\"summary\"`). This structured dictionary is then used by the DSPy module.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual Output of ChatAdapter.parse()\n{\n  \"summary\": \"DSPy helps build and optimize language model pipelines.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ListToolsResult with Pydantic in Python\nDESCRIPTION: Example showing how to create a ListToolsResult object using Pydantic models to structure tool information. This demonstrates the creation of a standardized response containing tool metadata including name, description, and input schema.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/07_mcp_protocol_types.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Simplified example of creating a ListToolsResult object\n# (FastMCP does this automatically for you!)\nfrom mcp.types import ListToolsResult, Tool\n\n# ToolManager gathered this info from your @server.tool decorator\nadd_tool_info = Tool(\n    name=\"add\",\n    description=\"Adds two numbers together.\",\n    inputSchema={ # JSON Schema describing expected input\n        \"type\": \"object\",\n        \"properties\": {\n            \"num1\": {\"type\": \"integer\"},\n            \"num2\": {\"type\": \"integer\"}\n        },\n        \"required\": [\"num1\", \"num2\"]\n    }\n)\n\n# FastMCP creates the result object\nresult_data = ListToolsResult(\n    tools=[add_tool_info]\n    # nextCursor would be set if paginating\n)\n\n# This result_data object is then packaged into a\n# standard JSONRPCResponse and sent to the client.\nprint(result_data.model_dump_json(indent=2)) # See its JSON form\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"_meta\": null,\n  \"nextCursor\": null,\n  \"tools\": [\n    {\n      \"name\": \"add\",\n      \"description\": \"Adds two numbers together.\",\n      \"inputSchema\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"num1\": {\n            \"type\": \"integer\"\n          },\n          \"num2\": {\n            \"type\": \"integer\"\n          }\n        },\n        \"required\": [\n          \"num1\",\n          \"num2\"\n        ]\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing FastAPI Endpoint with Model Filtering\nDESCRIPTION: Creates a FastAPI endpoint that uses ItemCreate for input validation and ItemPublic for response filtering. Demonstrates automatic removal of sensitive fields from API responses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/03_data_validation___serialization__pydantic_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom models import ItemCreate, ItemPublic # Import both models\n\napp = FastAPI()\n\nitems_db = [] # Simple in-memory \"database\"\n\n@app.post(\"/items/\", response_model=ItemPublic) # Use ItemPublic for response\nasync def create_item(item_input: ItemCreate): # Use ItemCreate for input\n    print(f\"Received internal cost: {item_input.internal_cost}\")\n\n    # Convert input model to a dict (or create DB model instance)\n    item_data = item_input.model_dump()\n\n    # Simulate saving to DB and getting back the saved data\n    # In a real app, the DB might assign an ID, etc.\n    saved_item_data = item_data.copy()\n    saved_item_data[\"id\"] = len(items_db) + 1 # Add a simulated ID\n    items_db.append(saved_item_data)\n\n    # Return the *dictionary* of saved data. FastAPI will use response_model\n    # ItemPublic to filter and serialize this dictionary.\n    return saved_item_data\n```\n\n----------------------------------------\n\nTITLE: Setting up Memory Transport for Testing in Python\nDESCRIPTION: Code snippet demonstrating the setup of memory transport, which is primarily used for testing purposes. Shows the import of necessary components for memory transport testing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/09_communication_transports__stdio__sse__websocket__memory_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport anyio\nimport pytest # Using pytest testing framework\nfrom mcp.client.session import ClientSession\nfrom mcp.server.fastmcp import FastMCP # Using FastMCP for the server part\nfrom mcp.shared.memory import create_client_server_memory_streams\n```\n\n----------------------------------------\n\nTITLE: Importing and Using FastAPI BackgroundTasks\nDESCRIPTION: FastAPI's BackgroundTasks class inherits from starlette.background.BackgroundTasks to provide type hints and FastAPI-specific documentation. Tasks are stored as tuples containing the callable, args, and kwargs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfastapi.BackgroundTasks.add_task(func, *args, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Implementing FunctionTool for Wrapping Python Functions\nDESCRIPTION: A simplified concept of the FunctionTool class, which inherits from BaseTool. It demonstrates how Python functions are wrapped, including automatic creation of Pydantic models for arguments and handling of function execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass FunctionTool(BaseTool[BaseModel, BaseModel]):\n    def __init__(self, func, description, ...):\n        self._func = func\n        self._signature = get_typed_signature(func)\n        # Automatically create Pydantic model for arguments\n        args_model = args_base_model_from_signature(...)\n        # Get return type from signature\n        return_type = self._signature.return_annotation\n        super().__init__(args_model, return_type, ...)\n\n    async def run(self, args: BaseModel, ...):\n        # Extract arguments from the 'args' model\n        kwargs = args.model_dump()\n        # Call the original Python function (sync or async)\n        result = await self._call_underlying_func(**kwargs)\n        return result # Must match the expected return_type\n```\n\n----------------------------------------\n\nTITLE: Persisting Authentication Across Requests Using Session Object (Python Requests)\nDESCRIPTION: Explains how to persist authentication for multiple requests via a requests.Session object and its auth property. The example sets up a Session with either an HTTPBasicAuth object or a tuple and shows that all subsequent requests (even to different endpoints) automatically include the Authorization header. Demonstrates responses for both an authenticated and a header-inspection endpoint. Requires the 'requests' library and HTTPBasicAuth. The output reveals the headers sent, confirming persistent authentication behavior.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom requests.auth import HTTPBasicAuth\n\nbasic_auth_url = 'https://httpbin.org/basic-auth/testuser/testpass'\nheaders_url = 'https://httpbin.org/headers' # Just to see headers sent\n\n# Create a session\nwith requests.Session() as s:\n    # Set the authentication ONCE on the session\n    s.auth = HTTPBasicAuth('testuser', 'testpass')\n    # Or: s.auth = ('testuser', 'testpass')\n\n    # Make the first request (auth will be added automatically)\n    print(\"Making first request using session auth...\")\n    response1 = s.get(basic_auth_url)\n    print(f\"Status Code 1: {response1.status_code}\")\n\n    # Make a second request to a different endpoint (auth will also be added)\n    # We use /headers to see the Authorization header being sent\n    print(\"\\nMaking second request using session auth...\")\n    response2 = s.get(headers_url)\n    print(f\"Status Code 2: {response2.status_code}\")\n    print(\"Headers sent in second request:\")\n    # Look for the 'Authorization' header in the output\n    print(response2.json()['headers'])\n\n```\n\n----------------------------------------\n\nTITLE: Initializing BrowserContext for Playwright Session Management in Python\nDESCRIPTION: Defines the `BrowserContext` class responsible for managing an isolated browser session. The `__init__` method sets up initial configuration and references, assigning a unique ID. The `__aenter__` method makes the class usable with `async with`, triggering `_initialize_session` to lazily create the actual Playwright browser context (`PlaywrightBrowserContext`) and wrap it in a `BrowserSession` when the context is entered. Dependencies include the main `Browser` instance, `BrowserContextConfig` for settings, and Playwright's browser context.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/03_browsercontext.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# ... other imports ...\nif TYPE_CHECKING:\n    from browser_use.browser.browser import Browser # Link to the Browser class\n\n@dataclass\nclass BrowserContextConfig: # Configuration settings\n    # ... various settings like user_agent, cookies_file, window_size ...\n    pass\n\n@dataclass\nclass BrowserSession: # Holds the actual Playwright context\n    context: PlaywrightBrowserContext # The underlying Playwright object\n    cached_state: Optional[BrowserState] = None # Stores the last known state\n\nclass BrowserContext:\n    def __init__(\n        self,\n        browser: 'Browser', # Reference to the main Browser instance\n        config: BrowserContextConfig = BrowserContextConfig(),\n        # ... other optional state ...\n    ):\n        self.context_id = str(uuid.uuid4()) # Unique ID for this session\n        self.config = config # Store the configuration\n        self.browser = browser # Store the reference to the parent Browser\n\n        # The actual Playwright session is created later, when needed\n        self.session: BrowserSession | None = None\n        logger.debug(f\"BrowserContext object created (ID: {self.context_id}). Session not yet initialized.\")\n\n    # The 'async with' statement calls __aenter__ which initializes the session\n    async def __aenter__(self):\n        await self._initialize_session() # Creates the actual browser window/tab\n        return self\n\n    async def _initialize_session(self):\n        # ... (complex setup code happens here) ...\n        # Gets the main Playwright browser from self.browser\n        playwright_browser = await self.browser.get_playwright_browser()\n        # Creates the isolated Playwright context (like the incognito window)\n        context = await self._create_context(playwright_browser)\n        # Creates the BrowserSession to hold the context and state\n        self.session = BrowserSession(context=context, cached_state=None)\n        logger.debug(f\"BrowserContext session initialized (ID: {self.context_id}).\")\n        # ... (sets up the initial page) ...\n        return self.session\n\n    # ... other methods like navigate_to, close, etc. ...\n```\n\n----------------------------------------\n\nTITLE: Defining the State Structure with TypedDict - Python\nDESCRIPTION: Defines the schema for the shared state used in a StateGraph by subclassing Python's TypedDict. This sets a clear contract for what data the graph nodes can access and update. The state here consists of a single integer entry ('value'). There are no dependencies aside from the 'typing' module. Nodes will later read and write to this state.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict\n\nclass MyState(TypedDict):\n    # Our state will hold a single number called 'value'\n    value: int\n```\n\n----------------------------------------\n\nTITLE: Scanning Keys Using LevelDB Iterator (C++)\nDESCRIPTION: This C++ code demonstrates how to create and use a LevelDB Iterator to efficiently scan a range of key-value pairs whose keys start with a specified prefix (such as 'user:'). It relies on LevelDB's standard API and assumes that the database object (db) is already open and configured. Key parameters include an optional snapshot for read-consistency, and the start key for seeking. The snippet showcases proper iterator usage patterns: creation, positioning (seek), iteration/looping, validity-checking, optional error handling, and resource cleanup. Slice objects returned by key() and value() must be copied if their data is needed after advancing the iterator. Requires LevelDB headers (db.h, iterator.h) and a linked/open LevelDB database instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/07_iterator.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\n#include \\\"leveldb/db.h\\\"\n#include \\\"leveldb/iterator.h\\\"\n#include <iostream>\n\n// ... assume db is an open LevelDB database ...\n\n// 1. Create an iterator\nleveldb::ReadOptions options;\n// options.snapshot = db->GetSnapshot(); // Optional: Use a specific snapshot\nleveldb::Iterator* it = db->NewIterator(options);\n\n// 2. Position the iterator (e.g., seek to the first key >= \\\"start_key\\\")\nstd::string start_key = \\\"user:\\\";\nit->Seek(start_key);\n\n// 3. Loop through the keys\nstd::cout << \\\"Keys starting with '\\\" << start_key << \\\"':\\\" << std::endl;\nfor (; it->Valid(); it->Next()) {\n  leveldb::Slice key = it->key();\n  leveldb::Slice value = it->value();\n\n  // Optional: Stop if we go past the desired range\n  if (!key.starts_with(start_key)) {\n     break;\n  }\n\n  std::cout << key.ToString() << \\\" => \\\" << value.ToString() << std::endl;\n}\n\n// 4. Check for errors (optional but recommended)\nif (!it->status().ok()) {\n  std::cerr << \\\"Iterator error: \\\" << it->status().ToString() << std::endl;\n}\n\n// 5. Clean up the iterator and snapshot (if used)\ndelete it;\n// if (options.snapshot != nullptr) {\n//   db->ReleaseSnapshot(options.snapshot);\n// }\n\n```\n\n----------------------------------------\n\nTITLE: Multi-Message Prompt Template Example in Python\nDESCRIPTION: Demonstrates creating a prompt template that returns multiple message types including UserMessage, AssistantMessage, and string conversions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import UserMessage, AssistantMessage\n\nserver = FastMCP(name=\"MultiMessageServer\")\n\n@server.prompt(name=\"greet_user\", description=\"Starts a simple conversation.\")\ndef greeting_prompt(user_name: str):\n  return [\n      UserMessage(f\"Hello {user_name}, tell me about your day.\"),\n      {\"role\": \"assistant\", \"content\": \"I'm ready to listen!\"},\n      \"Start whenever you're ready.\",\n  ]\n```\n\n----------------------------------------\n\nTITLE: Processing Authentication in Python Requests PreparedRequest (Simplified)\nDESCRIPTION: This Python snippet shows a simplified view of the `prepare_auth` method within the `requests.models.PreparedRequest` class. It illustrates how `requests` handles the `auth` parameter: it checks for authentication info in the URL, automatically wraps `(username, password)` tuples into an `HTTPBasicAuth` object, and crucially, calls the `__call__` method of the provided authentication object (`auth(self)`), allowing the auth handler to modify the `PreparedRequest` instance (typically by adding headers).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/models.py (Simplified View)\n\nfrom .auth import HTTPBasicAuth\nfrom .utils import get_auth_from_url\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    # ... (other prepare methods like prepare_url, prepare_headers) ...\n\n    def prepare_auth(self, auth, url=\"\"):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth provided, maybe get it from the URL (e.g., http://user:pass@host)\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            # If auth is a ('user', 'pass') tuple, wrap it in HTTPBasicAuth\n            if isinstance(auth, tuple) and len(auth) == 2:\n                auth = HTTPBasicAuth(*auth)\n\n            # --- The Core Step ---\n            # Call the auth object (which must be callable, like AuthBase subclasses)\n            # Pass 'self' (the PreparedRequest instance) to the auth object's __call__\n            r = auth(self)\n\n            # Update self to reflect any changes made by the auth object\n            # (Auth objects typically just modify headers, but could do more)\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length in case auth modified the body (unlikely for Basic/Digest)\n            self.prepare_content_length(self.body)\n\n    # ... (rest of PreparedRequest) ...\n```\n\n----------------------------------------\n\nTITLE: Creating and Executing StateGraph Workflow in Python\nDESCRIPTION: This snippet demonstrates the creation of a StateGraph, adding nodes and edges, compiling it into an app, and invoking the graph. It uses two adder functions to modify the state value, resulting in a final sum of 15.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Create graph\nworkflow = StateGraph(SummingState)\nworkflow.add_node(\"adder1\", add_five)\nworkflow.add_node(\"adder2\", add_ten)\nworkflow.set_entry_point(\"adder1\")\nworkflow.add_edge(\"adder1\", \"adder2\")\nworkflow.add_edge(\"adder2\", END)\n\napp = workflow.compile()\n\n# Run with initial state value = 0 (BinaryOperatorAggregate defaults int to 0)\nprint(\"Invoking graph...\")\n# You could also provide an initial value: app.invoke({\"value\": 100})\nfinal_state = app.invoke({})\n\nprint(\"\\n--- Final State ---\")\nprint(final_state)\n```\n\n----------------------------------------\n\nTITLE: Implementing an Image Analysis Tool in Python with SmolaAgents\nDESCRIPTION: This code snippet shows how to create an ImageAnalyzerTool class that accepts an image input and analyzes its dimensions. It demonstrates how the framework automatically unwraps AgentImage objects before passing them to the tool's forward method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/07_agenttype.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# --- File: image_analyzer_tool.py ---\nfrom smolagents import Tool\nfrom PIL import Image\nfrom smolagents.agent_types import AgentImage, handle_agent_input_types\n\nclass ImageAnalyzerTool(Tool):\n    name: str = \"image_analyzer\"\n    description: str = \"Analyzes an image and returns its dimensions.\"\n    inputs: dict = {\n        \"input_image\": {\n            \"type\": \"image\", # Expects an image type\n            \"description\": \"The image to analyze.\"\n        }\n    }\n    output_type: str = \"string\"\n\n    def forward(self, input_image: Image.Image) -> str:\n        \"\"\"Analyzes the image.\"\"\"\n        # IMPORTANT: input_image here is ALREADY the raw PIL.Image object!\n        print(f\"--- ImageAnalyzerTool received image of type: {type(input_image)} ---\")\n        width, height = input_image.size\n        return f\"Image dimensions are {width}x{height}.\"\n\n# --- How the framework uses it (conceptual) ---\nanalyzer_tool = ImageAnalyzerTool()\n\n# Let's pretend 'agent_image_object' is an AgentImage retrieved from memory\n# (It wraps a red PIL.Image.Image object like the one from Scenario 1)\nagent_image_object = AgentImage(Image.new('RGB', (60, 30), color = 'red'))\nprint(f\"Input object type: {type(agent_image_object)}\")\n\n# Framework automatically unwraps the input before calling 'forward'\n# Uses handle_agent_input_types(input_image=agent_image_object)\n# args_tuple, kwargs_dict = handle_agent_input_types(input_image=agent_image_object)\n# result = analyzer_tool.forward(**kwargs_dict) # Simplified conceptual call\n\n# Simulate the unwrapping and call:\nraw_image = agent_image_object.to_raw() # Get the underlying PIL Image\nresult = analyzer_tool.forward(input_image=raw_image)\n\nprint(f\"Analysis result: {result}\")\n\n# Expected Output:\n# Input object type: <class 'smolagents.agent_types.AgentImage'>\n# --- ImageAnalyzerTool received image of type: <class 'PIL.Image.Image'> ---\n```\n\n----------------------------------------\n\nTITLE: Defining a Mock Database Session Dependency for FastAPI - Python\nDESCRIPTION: This snippet defines an async dependency function, 'get_db_session', that mocks the acquisition of a database session by returning a hard-coded string. Intended to illustrate dependency chaining, it simulates what would typically be the creation and teardown of a DB connection. No real database operations occur. Useful as a prerequisite for higher-level dependencies that require DB access in FastAPI.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/05_dependency_injection.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# common_dependencies.py\nasync def get_db_session():\n    print(\"Getting DB Session\")\n    # In reality, this would connect to a DB and yield/return a session object\n    session = \"fake_db_session_123\"\n    # You might use 'yield' here for setup/teardown (see FastAPI docs)\n    return session\n```\n\n----------------------------------------\n\nTITLE: Implementing Controller Class for Browser Automation in Python\nDESCRIPTION: This class ties together the Registry and BrowserContext, registering default actions and providing an 'act' method to execute actions. It handles action execution, error handling, and result formatting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/05_action_controller___registry.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom browser_use.agent.views import ActionModel, ActionResult # Input/Output types\nfrom browser_use.browser.context import BrowserContext # Needed by actions\nfrom browser_use.controller.registry.service import Registry # The toolbox\nfrom browser_use.controller.views import ClickElementAction, InputTextAction, DoneAction # Param models\n\nlogger = logging.getLogger(__name__)\n\nclass Controller:\n    def __init__(self, exclude_actions: list[str] = []):\n        self.registry = Registry(exclude_actions=exclude_actions) # Initialize the toolbox\n\n        # --- Register Default Actions ---\n        # (Registration happens when Controller is created)\n\n        @self.registry.action(\"Click element\", param_model=ClickElementAction)\n        async def click_element(params: ClickElementAction, browser: BrowserContext):\n            logger.info(f\"Attempting to click element index {params.index}\")\n            # --- Actual click logic using browser object ---\n            element_node = await browser.get_dom_element_by_index(params.index)\n            await browser._click_element_node(element_node) # Internal browser method\n            # ---\n            msg = f\"🖱️ Clicked element with index {params.index}\"\n            return ActionResult(extracted_content=msg, include_in_memory=True)\n\n        @self.registry.action(\"Input text into an element\", param_model=InputTextAction)\n        async def input_text(params: InputTextAction, browser: BrowserContext):\n            logger.info(f\"Attempting to type into element index {params.index}\")\n            # --- Actual typing logic using browser object ---\n            element_node = await browser.get_dom_element_by_index(params.index)\n            await browser._input_text_element_node(element_node, params.text) # Internal method\n            # ---\n            msg = f\"⌨️ Input text into index {params.index}\"\n            return ActionResult(extracted_content=msg, include_in_memory=True)\n\n        @self.registry.action(\"Complete task\", param_model=DoneAction)\n        async def done(params: DoneAction):\n             logger.info(f\"Task completion requested. Success: {params.success}\")\n             return ActionResult(is_done=True, success=params.success, extracted_content=params.text)\n\n        # ... registration for scroll_down, go_to_url, etc. ...\n\n    async def act(\n        self,\n        action: ActionModel,        # The ActionModel from the LLM\n        browser_context: BrowserContext, # The context to act within\n        **kwargs # Other potential context (LLMs, etc.)\n    ) -> ActionResult:\n        \"\"\"Execute an action defined in the ActionModel\"\"\"\n        try:\n            # ActionModel might look like: ActionModel(click_element=ClickElementAction(index=5))\n            # model_dump gets {'click_element': {'index': 5}}\n            action_data = action.model_dump(exclude_unset=True)\n\n            for action_name, params in action_data.items():\n                if params is not None:\n                    logger.debug(f\"Executing action: {action_name} with params: {params}\")\n                    # Call the registry's execute method\n                    result = await self.registry.execute_action(\n                        action_name=action_name,\n                        params=params,\n                        browser=browser_context, # Pass the essential context\n                        **kwargs # Pass any other context needed by actions\n                    )\n\n                    # Ensure result is ActionResult or convert it\n                    if isinstance(result, ActionResult): return result\n                    if isinstance(result, str): return ActionResult(extracted_content=result)\n                    return ActionResult() # Default empty result if action returned None\n\n            logger.warning(\"ActionModel had no action to execute.\")\n            return ActionResult(error=\"No action specified in the model\")\n\n        except Exception as e:\n            logger.error(f\"Error during controller.act: {e}\", exc_info=True)\n            return ActionResult(error=str(e)) # Return error in ActionResult\n```\n\n----------------------------------------\n\nTITLE: Implementing a FastAPI Conversation Server Endpoint - Python\nDESCRIPTION: This snippet defines a ConversationServer class that adds REST endpoints to a FastAPI application for an agent-based chat UI. The /message/send endpoint parses UI requests, sanitizes messages, and starts the background agent interaction logic via ADKHostManager. Background processing is done on a separate thread to ensure the API returns a quick acknowledgment. Dependencies are FastAPI, Message model, ADKHostManager, and Python threading/asyncio. Inputs are JSON HTTP requests from the frontend; outputs are SendMessageResponse objects containing message metadata.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/service/server/server.py (Simplified Snippet)\nfrom fastapi import APIRouter, Request\nfrom common.types import Message\nfrom .adk_host_manager import ADKHostManager # Implements agent interaction logic\n# ... other imports ...\n\nclass ConversationServer:\n    def __init__(self, router: APIRouter):\n        # Choose the manager (e.g., ADKHostManager uses the Host Agent)\n        self.manager = ADKHostManager()\n\n        # Define API route for sending messages\n        router.add_api_route(\n            \"/message/send\",\n            self._send_message, # Maps URL to the _send_message method\n            methods=[\"POST\"])\n        # ... other routes (/conversation/list, /task/list, etc.) ...\n\n    async def _send_message(self, request: Request):\n        message_data = await request.json()\n        # Parse the message data sent by the UI client\n        message = Message(**message_data['params'])\n        # Add necessary metadata (IDs, etc.)\n        message = self.manager.sanitize_message(message)\n        # --- Crucial Part: Pass message to the agent logic ---\n        # Run the actual agent processing in a background thread\n        # so the API call returns quickly to the UI.\n        thread = threading.Thread(\n           target=lambda: asyncio.run(self.manager.process_message(message))\n        )\n        thread.start()\n        # Return an immediate confirmation to the UI\n        return SendMessageResponse(result=MessageInfo(\n            message_id=message.metadata['message_id'],\n            # ... other info ...\n        ))\n```\n\n----------------------------------------\n\nTITLE: Sending Data with Requests.post Functional API - Python\nDESCRIPTION: This snippet illustrates how to send data as a form POST using the Python Requests library's functional API. It constructs a dictionary 'payload' with key/value pairs, then calls requests.post() with the data, printing the status code and full response content. Requires the requests library (pip install requests). The 'url' parameter is the endpoint to send data to, and 'payload' is sent as form-encoded data in the request body. Suitable for submitting forms or posting data in simple scripts. Output confirms both response status and returned content.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/01_functional_api.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# The URL we want to send data to\nurl = 'https://httpbin.org/post'\n\n# The data we want to send (like form fields)\n# We'll use a Python dictionary\npayload = {'username': 'tutorial_user', 'action': 'learn_requests'}\n\nprint(f\"Sending data to: {url}\")\n# Use the functional API 'post' function, passing the data\nresponse = requests.post(url, data=payload)\n\n# Check the status code\nprint(f\"Status Code: {response.status_code}\")\n\n# The response often echoes back the data we sent\nprint(\"Response Content:\")\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Defining Tool and Parameter Schemas in Python\nDESCRIPTION: Type definitions for ToolSchema and ParametersSchema that specify how tools and their parameters are structured in AutoGen Core.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict, Dict, Any, Sequence, NotRequired\n\nclass ParametersSchema(TypedDict):\n    type: str # Usually \"object\"\n    properties: Dict[str, Any] # Defines input fields and their types\n    required: NotRequired[Sequence[str]] # List of required field names\n\nclass ToolSchema(TypedDict):\n    name: str\n    description: NotRequired[str]\n    parameters: NotRequired[ParametersSchema]\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Automatic Cookie Handling with requests.Session in Python\nDESCRIPTION: This snippet demonstrates how a `requests.Session` object automatically manages cookies. It creates a session, makes a request to a URL designed to set a cookie ('fruit'='apple'), prints the session's cookie jar to show the cookie has been stored, then makes another request to a different URL on the same domain ('httpbin.org/cookies') to verify that the session automatically sends the stored cookie back to the server. The output confirms the initial empty jar, the jar after the cookie is set, and the server's response showing it received the cookie.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# Create a Session object (which has its own empty Cookie Jar)\ns = requests.Session()\nprint(f\"Initial session cookies: {s.cookies.get_dict()}\")\n\n# Visit a page that sets a cookie\ncookie_setter_url = 'https://httpbin.org/cookies/set/fruit/apple'\nprint(f\"\\nVisiting {cookie_setter_url}...\")\nresponse1 = s.get(cookie_setter_url)\n\n# Check the Session's Cookie Jar - it should have the cookie now!\nprint(f\"Session cookies after setting: {s.cookies.get_dict()}\")\n\n# Visit another page on the same domain (httpbin.org)\ncookie_viewer_url = 'https://httpbin.org/cookies'\nprint(f\"\\nVisiting {cookie_viewer_url}...\")\nresponse2 = s.get(cookie_viewer_url)\n\n# This page shows the cookies it received. Let's see if our 'fruit' cookie was sent.\nprint(\"Cookies received by the server:\")\nprint(response2.text) # httpbin.org/cookies returns JSON showing received cookies\n```\n\n----------------------------------------\n\nTITLE: Creating 1D and 2D NumPy Arrays from Python Lists\nDESCRIPTION: This snippet demonstrates the creation of one-dimensional (vector) and two-dimensional (matrix) NumPy arrays by converting Python lists using np.array(). It shows how NumPy automatically converts nested lists into multi-dimensional arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Create a 1-dimensional array (vector)\nmy_list = [10, 20, 30]\narr1d = np.array(my_list)\nprint(arr1d)\n# Output: [10 20 30]\n\n# Create a 2-dimensional array (matrix/table)\nmy_nested_list = [[1, 2, 3], [4, 5, 6]]\narr2d = np.array(my_nested_list)\nprint(arr2d)\n# Output:\n# [[1 2 3]\n#  [4 5 6]]\n```\n\n----------------------------------------\n\nTITLE: Loading Configuration from a Dedicated Module\nDESCRIPTION: Loading Celery configuration from the dedicated celeryconfig.py module using the config_from_object() method. This demonstrates how to use the recommended configuration approach in your app file.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\n\n# Create the app instance (no need to pass broker/backend here now)\napp = Celery('tasks')\n\n# Load configuration from the 'celeryconfig' module\n# Assumes celeryconfig.py is in the same directory or Python path\napp.config_from_object('celeryconfig')\n\nprint(f\"Loaded Broker URL from config file: {app.conf.broker_url}\")\nprint(f\"Loaded Timezone from config file: {app.conf.timezone}\")\n\n# You might still define tasks in this file or in the modules listed\n# in celeryconfig.imports\n@app.task\ndef multiply(x, y):\n    return x * y\n```\n\n----------------------------------------\n\nTITLE: Creating and Executing a PlanningFlow in Python\nDESCRIPTION: This code snippet demonstrates how to set up a PlanningFlow with a Manus agent, define a goal, and execute the flow. It shows the process of importing necessary classes, creating agents, instantiating the flow, and running it asynchronously.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary classes\nfrom app.agent.manus import Manus # A capable agent\nfrom app.flow.flow_factory import FlowFactory, FlowType\nimport asyncio # Needed for async execution\n\n# 1. Create the agent(s) we want the flow to manage\n# We can give agents specific keys (names) within the flow\nagents_for_flow = {\n    \"research_writer\": Manus() # Use Manus agent for all tasks\n}\n\n# 2. Create the flow using the factory\n# We specify the type (PLANNING) and provide the agents\nplanning_flow_instance = FlowFactory.create_flow(\n    flow_type=FlowType.PLANNING,\n    agents=agents_for_flow,\n    # Optional: specify which agent is primary (if not first)\n    # primary_agent_key=\"research_writer\"\n)\n\nprint(f\"Created a {type(planning_flow_instance).__name__}\")\nprint(f\"Primary agent: {planning_flow_instance.primary_agent.name}\")\n\n# 3. Define the overall goal for the flow\noverall_goal = \"Research the main benefits of solar power and write a short summary.\"\n\n# Define an async function to run the flow\nasync def run_the_flow():\n    print(f\"\\nExecuting flow with goal: '{overall_goal}'\")\n    # 4. Execute the flow with the goal\n    final_result = await planning_flow_instance.execute(overall_goal)\n    print(\"\\n--- Flow Execution Finished ---\")\n    print(f\"Final Result:\\n{final_result}\")\n\n# Run the async function\n# asyncio.run(run_the_flow()) # Uncomment to run\n```\n\n----------------------------------------\n\nTITLE: Internals: Interrupt, Command, and GraphInterrupt Classes - LangGraph - Python\nDESCRIPTION: Simplified internal implementations of core LangGraph constructs that enable interrupt and resume operations in workflows. Includes the interrupt function that raises or resumes using GraphInterrupt, and dataclasses for Interrupt and Command objects used to represent interrupts and resumption commands, as well as the custom exception GraphInterrupt. Dependencies: dataclasses, typing.Any, and internal LangGraph infrastructure. Shows how resume values are tracked and how state changes are managed within the workflow engine.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\n# types.py (Simplified view)\ndef interrupt(value: Any) -> Any:\n    # ... access internal config/scratchpad ...\n    scratchpad = conf[CONFIG_KEY_SCRATCHPAD]\n    idx = scratchpad.interrupt_counter()\n\n    # Check if resume value already exists for this interrupt index\n    if scratchpad.resume and idx < len(scratchpad.resume):\n        return scratchpad.resume[idx] # Return existing resume value\n\n    # Check if a new global resume value was provided\n    v = scratchpad.get_null_resume(consume=True)\n    if v is not None:\n        # Store and return the new resume value\n        scratchpad.resume.append(v)\n        conf[CONFIG_KEY_SEND]([(RESUME, scratchpad.resume)]) # Update state internally\n        return v\n\n    # No resume value - raise the interrupt exception\n    raise GraphInterrupt(\n        (Interrupt(value=value, resumable=True, ns=...),)\n    )\n\n# types.py (Simplified view)\n@dataclasses.dataclass\nclass Interrupt:\n    value: Any # The value passed to interrupt()\n    resumable: bool = True\n    # ... other fields ...\n\n# types.py (Simplified view)\n@dataclasses.dataclass\nclass Command:\n    # ... other fields like update, goto ...\n    resume: Optional[Any] = None # Value to provide to a pending interrupt\n\n# errors.py (Simplified view)\nclass GraphInterrupt(Exception): # Base class for interrupts\n    pass\n```\n\n----------------------------------------\n\nTITLE: Illustrating Agent Class Inheritance in CrewAI (Python)\nDESCRIPTION: This Python code snippet shows the inheritance structure for the `Agent` class within the CrewAI library. It indicates that the main `Agent` class (in `crewai/agent.py`) inherits from `BaseAgent` (located in `crewai/agents/agent_builder/base_agent.py`). This provides context on the underlying code structure mentioned in the 'Diving into the Code (`agent.py`)' section.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/02_agent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from crewai/agent.py\nfrom crewai.agents.agent_builder.base_agent import BaseAgent\n```\n\n----------------------------------------\n\nTITLE: Attaching Field Validators with Annotated and AfterValidator in Pydantic (Python)\nDESCRIPTION: This snippet shows validating a string field in a Pydantic model using Python's 'typing.Annotated' and Pydantic's 'AfterValidator'. The validator, defined as an external function, enforces that the 'username' has no spaces, raising a ValueError otherwise. The field type hint directly includes the validator, promoting reusable validation logic. Dependencies: Python 3.8+, Pydantic v2+, and 'typing'. Inputs are model data for validation; outputs are validated model instances or errors if criteria are not met.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\nfrom pydantic import BaseModel, Field, ValidationError\n# Import the helper\nfrom pydantic.functional_validators import AfterValidator\n\n# Define the validation function (can be outside the class)\ndef check_no_spaces(v: str) -> str:\n    print(f\"Checking username via Annotated: '{v}'\")\n    if ' ' in v:\n        raise ValueError('Username cannot contain spaces')\n    return v\n\nclass UserRegistrationAnnotated(BaseModel):\n    # Attach the validator function directly to the type hint\n    username: Annotated[str, AfterValidator(check_no_spaces)]\n    email: str\n\n# --- Try it out ---\n\n# Valid username\nuser_ok = UserRegistrationAnnotated(username='another_cat', email='cat@meow.com')\nprint(f\"Valid user: {user_ok}\")\n# Expected Output:\n# Checking username via Annotated: 'another_cat'\n# Valid user: username='another_cat' email='cat@meow.com'\n\n# Invalid username\ntry:\n    UserRegistrationAnnotated(username='another cat', email='cat@meow.com')\nexcept ValidationError as e:\n    print(f\"\\nValidation Error:\\n{e}\")\n    # Expected Output (simplified):\n    # Checking username via Annotated: 'another cat'\n    # Validation Error:\n    # 1 validation error for UserRegistrationAnnotated\n    # username\n    #   Value error, Username cannot contain spaces [type=value_error, ...]\n```\n\n----------------------------------------\n\nTITLE: Using click.echo() for Cross-Platform Terminal Output in Python\nDESCRIPTION: Demonstrates how to use click.echo() instead of print() for better cross-platform compatibility, stderr redirection, and Unicode handling in Click applications.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# echo_example.py\nimport click\n\n@click.command()\ndef cli():\n  \"\"\"Demonstrates click.echo\"\"\"\n  click.echo(\"Hello from Click!\")\n  # You can print errors to stderr easily\n  click.echo(\"Oops, something went wrong!\", err=True)\n\nif __name__ == '__main__':\n  cli()\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ python echo_example.py\nHello from Click!\nOops, something went wrong!  # (This line goes to stderr)\n```\n\n----------------------------------------\n\nTITLE: Memory Content Base Structure in AutoGen Core\nDESCRIPTION: Defines the MemoryContent class that represents a single entry in an agent's memory notebook. Each memory content includes the actual data, its MIME type, and optional metadata.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# From: memory/_base_memory.py (Simplified Concept)\nfrom pydantic import BaseModel\nfrom typing import Any, Dict, Union\n\n# Represents one entry in the memory notebook\nclass MemoryContent(BaseModel):\n    content: Union[str, bytes, Dict[str, Any]] # The actual data\n    mime_type: str # What kind of data (e.g., \"text/plain\")\n    metadata: Dict[str, Any] | None = None # Extra info (optional)\n```\n\n----------------------------------------\n\nTITLE: Python Wrapper Import in umath.py\nDESCRIPTION: Shows how the Python-level umath.py module imports ufuncs from the compiled C extension module to make them available through the numpy namespace.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/07_umath_module.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# From numpy/core/umath.py - Simplified\nfrom . import _multiarray_umath\nfrom ._multiarray_umath import * # Imports C-defined ufuncs like 'add'\n\n# Functions like 'add', 'sin', 'log' are now available in this module's\n# namespace, ready to be used via `np.add`, `np.sin`, etc.\n```\n\n----------------------------------------\n\nTITLE: Initializing MessageManager for LLM Agent in Python\nDESCRIPTION: This snippet shows the initialization of the MessageManager class, which sets up the initial context for the LLM agent including system messages and task description. It manages the conversation history and applies settings for token limits and image handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MessageManager:\n    def __init__(\n        self,\n        task: str,\n        system_message: SystemMessage, # Received from Agent\n        settings: MessageManagerSettings = MessageManagerSettings(),\n        state: MessageManagerState = MessageManagerState(), # Stores history\n    ):\n        self.task = task\n        self.settings = settings # Max tokens, image settings, etc.\n        self.state = state # Holds the 'history' object\n        self.system_prompt = system_message\n\n        # Only initialize if history is empty (e.g., not resuming from saved state)\n        if len(self.state.history.messages) == 0:\n            self._init_messages()\n\n    def _init_messages(self) -> None:\n        \"\"\"Add the initial fixed messages to the history.\"\"\"\n        # Add the main system prompt (rules)\n        self._add_message_with_tokens(self.system_prompt)\n\n        # Add the user's task\n        task_message = HumanMessage(\n            content=f'Your ultimate task is: \"\"\"{self.task}\"\"\"...'\n        )\n        self._add_message_with_tokens(task_message)\n\n        # Add other setup messages (context, sensitive data info, examples)\n        # ... (simplified - see full code for details) ...\n\n        # Example: Add a placeholder for where the main history begins\n        placeholder_message = HumanMessage(content='[Your task history memory starts here]')\n        self._add_message_with_tokens(placeholder_message)\n```\n\n----------------------------------------\n\nTITLE: Creating NumPy Arrays of Zeros and Ones\nDESCRIPTION: This snippet demonstrates how to create NumPy arrays filled with zeros or ones using np.zeros() and np.ones() functions. It shows how to specify the shape of the arrays using tuples for multi-dimensional arrays or single integers for one-dimensional arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Create an array of shape (2, 3) filled with zeros\nzeros_arr = np.zeros((2, 3))\nprint(zeros_arr)\n# Output:\n# [[0. 0. 0.]\n#  [0. 0. 0.]]\n\n# Create an array of shape (3,) filled with ones\nones_arr = np.ones(3)\nprint(ones_arr)\n# Output: [1. 1. 1.]\n```\n\n----------------------------------------\n\nTITLE: Batch Crawling with arun_many Method in Python\nDESCRIPTION: Demonstrates how to use the arun_many method of AsyncWebCrawler to efficiently crawl multiple URLs concurrently, showcasing configuration and result handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/02_asyncwebcrawler.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        urls_to_crawl = [\n            \"https://httpbin.org/html\",\n            \"https://httpbin.org/links/10/0\",\n            \"https://httpbin.org/robots.txt\"\n        ]\n        print(f\"Asking crawler to fetch {len(urls_to_crawl)} URLs.\")\n\n        # Use arun_many for multiple URLs\n        # We can still pass a config that applies to all URLs in the batch\n        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n        results = await crawler.arun_many(urls=urls_to_crawl, config=config)\n\n        print(f\"\\nFinished crawling! Got {len(results)} results.\")\n        for result in results:\n            status = \"Success\" if result.success else \"Failed\"\n            url_short = result.url.split('/')[-1] # Get last part of URL\n            print(f\"- URL: {url_short:<10} | Status: {status:<7} | Title: {result.metadata.get('title', 'N/A')}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Calling dspy.Predict for English-to-French Translation in Python\nDESCRIPTION: This example demonstrates creating a Predict module from the previously defined translation signature, supplying an input sentence, invoking the module, and accessing the structured output. Dependencies: dspy installed, working LM configuration, and TranslateToFrench signature. Inputs are provided as keyword arguments matching the signature's input fields; the output is in the returned Prediction object's output field. Used for single-task LM inference.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/04_predict.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create a Predict module using our signature\ntranslator = dspy.Predict(TranslateToFrench)\n\n# Prepare the input data\nenglish_input = \"Hello, how are you?\"\n\n# Call the predictor with the input field name from the signature\nresult = translator(english_sentence=english_input)\n\n# Access the output field name from the signature\nprint(f\"English: {english_input}\")\nprint(f\"French: {result.french_sentence}\")\n```\n\n----------------------------------------\n\nTITLE: Defining SandboxSettings with Pydantic in Python\nDESCRIPTION: This snippet defines a Pydantic model for sandbox configuration settings. It specifies fields like use_sandbox, image, work_dir, memory_limit, cpu_limit, timeout, and network_enabled, each with default values and descriptions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/config.py\nfrom pydantic import BaseModel, Field\n\nclass SandboxSettings(BaseModel):\n    \"\"\"Configuration for the execution sandbox\"\"\"\n    use_sandbox: bool = Field(False, description=\"Whether to use the sandbox\")\n    image: str = Field(\"python:3.12-slim\", description=\"Base image\")\n    work_dir: str = Field(\"/workspace\", description=\"Container working directory\")\n    memory_limit: str = Field(\"512m\", description=\"Memory limit\")\n    cpu_limit: float = Field(1.0, description=\"CPU limit\")\n    timeout: int = Field(300, description=\"Default command timeout (seconds)\")\n    network_enabled: bool = Field(False, description=\"Whether network access is allowed\")\n```\n\n----------------------------------------\n\nTITLE: FastMCP Server with Dynamic Time Resource\nDESCRIPTION: Extends the FastMCP server to include both static and dynamic resources. Adds a time resource that returns the current server time when requested.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport datetime # Need this module to get the current time\nfrom mcp.server.fastmcp import FastMCP\n\nserver = FastMCP(name=\"LibraryServer\")\n\n@server.resource(uri=\"data://greeting\", description=\"A friendly greeting.\")\ndef welcome_message() -> str:\n  print(\"Resource 'data://greeting' was read!\")\n  return \"Welcome to the Library Server! Enjoy your stay.\"\n\n# NEW: Add a dynamic resource for the current time\n@server.resource(uri=\"time://current\", description=\"The current server time.\")\ndef current_time() -> str:\n  \"\"\"Returns the current time as a string.\"\"\"\n  now = datetime.datetime.now()\n  time_str = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n  print(f\"Resource 'time://current' was read! Time is {time_str}\")\n  # The function calculates the time *each time* it's called\n  return f\"The current server time is: {time_str}\"\n\n# Standard run block\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Authentication Handlers in Python Requests (Simplified)\nDESCRIPTION: This Python snippet shows simplified implementations of authentication-related components from `requests/auth.py`. It includes the `_basic_auth_str` helper for generating Basic Auth headers, the `AuthBase` abstract base class requiring subclasses to implement `__call__`, the `HTTPBasicAuth` class which adds the 'Authorization' header, `HTTPProxyAuth` which adds the 'Proxy-Authorization' header, and a structural outline of the more complex `HTTPDigestAuth` class which involves state management and response hooks.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/auth.py (Simplified)\n\nfrom base64 import b64encode\nfrom ._internal_utils import to_native_string\n\ndef _basic_auth_str(username, password):\n    \"\"\"Returns a Basic Auth string.\"\"\"\n    # ... (handle encoding username/password to bytes) ...\n    auth_bytes = b\":\".join((username_bytes, password_bytes))\n    auth_b64 = b64encode(auth_bytes).strip()\n    # Return native string (str in Py3) e.g., \"Basic dXNlcjpwYXNz\"\n    return \"Basic \" + to_native_string(auth_b64)\n\nclass AuthBase:\n    \"\"\"Base class that all auth implementations derive from\"\"\"\n    def __call__(self, r):\n        # This method MUST be overridden by subclasses\n        raise NotImplementedError(\"Auth hooks must be callable.\")\n\nclass HTTPBasicAuth(AuthBase):\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\n    def __init__(self, username, password):\n        self.username = username\n        self.password = password\n\n    def __call__(self, r):\n        # 'r' is the PreparedRequest object passed in by requests\n        # Calculate the Basic auth string\n        auth_header_value = _basic_auth_str(self.username, self.password)\n        # Modify the request's headers\n        r.headers['Authorization'] = auth_header_value\n        # Return the modified request\n        return r\n\nclass HTTPProxyAuth(HTTPBasicAuth):\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\n    def __call__(self, r):\n        # Same as Basic Auth, but sets the Proxy-Authorization header\n        r.headers['Proxy-Authorization'] = _basic_auth_str(self.username, self.password)\n        return r\n\n# HTTPDigestAuth is more complex, involving state and hooks for the 401 challenge\nclass HTTPDigestAuth(AuthBase):\n    def __init__(self, username, password):\n        # ... store username/password ...\n        # ... initialize state (nonce, etc.) ...\n        pass\n\n    def build_digest_header(self, method, url):\n        # ... complex calculation based on nonce, realm, qop, etc. ...\n        return \"Digest ...\" # Calculated digest header\n\n    def handle_401(self, r, **kwargs):\n        # Hook called when a 401 response is received\n        # 1. Parse challenge ('WWW-Authenticate' header)\n        # 2. Store nonce, realm etc.\n        # 3. Prepare a *new* request with the calculated digest header\n        # 4. Send the new request\n        # 5. Return the response to the *new* request\n        pass # Simplified\n\n    def __call__(self, r):\n        # 'r' is the PreparedRequest\n        # If we already have a nonce, add the Authorization header directly\n        if self.has_nonce():\n            r.headers['Authorization'] = self.build_digest_header(r.method, r.url)\n        # Register the handle_401 hook to handle the server challenge if needed\n        r.register_hook('response', self.handle_401)\n        return r\n```\n\n----------------------------------------\n\nTITLE: Defining Required Query Parameters in FastAPI (Python)\nDESCRIPTION: Demonstrates how to define a *required* query parameter (`query_str`) in FastAPI. Unlike optional parameters, this function argument lacks a default value. FastAPI will return an error if the request URL (e.g., `/search/`) does not include the required query parameter (e.g., `/search/?query_str=value`). Type hints (`str`) are still used for validation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/02_path_operations___parameter_declaration.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Example: Required query parameter 'query_str'\n@app.get(\"/search/\")\nasync def search_items(query_str: str): # No default value means it's required\n    return {\"search_query\": query_str}\n\n# Visiting /search/ will cause an error\n# Visiting /search/?query_str=hello will work\n```\n\n----------------------------------------\n\nTITLE: Implementing DSPy Settings Management\nDESCRIPTION: Core implementation of DSPy's settings management system, including global configuration, thread-local storage, and context management for temporary overrides. Features singleton pattern and thread-safe configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from dspy/dsp/utils/settings.py\nimport copy\nimport threading\nfrom contextlib import contextmanager\n# from dspy.dsp.utils.utils import dotdict # Simplified as dict\n\nDEFAULT_CONFIG = dict(lm=None, rm=None, adapter=None, ...) # Default values\n\n# Global state\nmain_thread_config = copy.deepcopy(DEFAULT_CONFIG)\nconfig_owner_thread_id = None\nglobal_lock = threading.Lock()\n\n# Thread-local storage for overrides\nclass ThreadLocalOverrides(threading.local):\n    def __init__(self):\n        self.overrides = {}\nthread_local_overrides = ThreadLocalOverrides()\n\nclass Settings:\n    _instance = None\n    def __new__(cls): # Singleton pattern\n        if cls._instance is None: cls._instance = super().__new__(cls)\n        return cls._instance\n\n    # When you access settings.lm or settings['lm']\n    def __getattr__(self, name):\n        # Check thread-local overrides first\n        overrides = getattr(thread_local_overrides, \"overrides\", {})\n        if name in overrides: return overrides[name]\n        # Fall back to global config\n        elif name in main_thread_config: return main_thread_config[name]\n        else: raise AttributeError(f\"'Settings' object has no attribute '{name}'\")\n\n    def __getitem__(self, key): return self.__getattr__(key)\n\n    # dspy.settings.configure(...)\n    def configure(self, **kwargs):\n        global main_thread_config, config_owner_thread_id\n        current_thread_id = threading.get_ident()\n\n        with global_lock: # Ensure thread safety for configuration\n            if config_owner_thread_id is None: config_owner_thread_id = current_thread_id\n            elif config_owner_thread_id != current_thread_id:\n                raise RuntimeError(\"dspy.settings can only be changed by the thread that initially configured it.\")\n\n        # Update global config\n        for k, v in kwargs.items(): main_thread_config[k] = v\n\n    # with dspy.settings.context(...)\n    @contextmanager\n    def context(self, **kwargs):\n        # Save current overrides\n        original_overrides = getattr(thread_local_overrides, \"overrides\", {}).copy()\n        # Create new overrides for this context (combining global + old local + new)\n        new_overrides = {**main_thread_config, **original_overrides, **kwargs}\n        # Apply new overrides to thread-local storage\n        thread_local_overrides.overrides = new_overrides\n        try:\n            yield # Code inside the 'with' block runs here\n        finally:\n            # Restore original overrides when exiting the block\n            thread_local_overrides.overrides = original_overrides\n\n# The global instance you use\nsettings = Settings()\n```\n\n----------------------------------------\n\nTITLE: Implementing Caching in AsyncWebCrawler (Python)\nDESCRIPTION: This snippet shows the implementation of caching in the AsyncWebCrawler class. It demonstrates how the crawler checks for cached results, fetches new content if necessary, and updates the cache.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/async_webcrawler.py\nfrom .cache_context import CacheContext, CacheMode\nfrom .async_database import async_db_manager\nfrom .models import CrawlResult\n# ... other imports\n\nclass AsyncWebCrawler:\n    # ... (init, other methods) ...\n\n    async def arun(self, url: str, config: CrawlerRunConfig = None) -> CrawlResult:\n        # ... (ensure config exists, set defaults) ...\n        if config.cache_mode is None:\n            config.cache_mode = CacheMode.ENABLED # Example default\n\n        # 1. Create CacheContext\n        cache_context = CacheContext(url, config.cache_mode)\n\n        cached_result = None\n        # 2. Check if cache read is allowed\n        if cache_context.should_read():\n            # 3. Try reading from database\n            cached_result = await async_db_manager.aget_cached_url(url)\n\n        # 4. If cache hit and valid, return it\n        if cached_result and self._is_cache_valid(cached_result, config):\n            self.logger.info(\"Cache hit for: %s\", url) # Example log\n            return cached_result # Return early\n\n        # 5. Fetch fresh content (if no cache hit or read disabled)\n        async_response = await self.crawler_strategy.crawl(url, config=config)\n        html = async_response.html # ... and other data ...\n\n        # 6. Process the HTML to get a new CrawlResult\n        crawl_result = await self.aprocess_html(\n            url=url, html=html, config=config, # ... other params ...\n        )\n\n        # 7. Check if cache write is allowed\n        if cache_context.should_write():\n            # 8. Write the new result to the database\n            await async_db_manager.acache_url(crawl_result)\n\n        # 9. Return the new result\n        return crawl_result\n\n    def _is_cache_valid(self, cached_result: CrawlResult, config: CrawlerRunConfig) -> bool:\n        # Internal logic to check if cached result meets current needs\n        # (e.g., was screenshot requested now but not cached?)\n        if config.screenshot and not cached_result.screenshot: return False\n        if config.pdf and not cached_result.pdf: return False\n        # ... other checks ...\n        return True\n```\n\n----------------------------------------\n\nTITLE: Creating and Using Structured Arrays in NumPy\nDESCRIPTION: A code example demonstrating how to define and use structured dtypes in NumPy for representing complex data structures similar to C structs or database rows. The example creates a structured array of people with name and age fields.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/02_dtype__data_type_object_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Define a structured dtype: a name (up to 10 chars) and an age (4-byte int)\nperson_dtype = np.dtype([('name', 'S10'), ('age', 'i4')])\npeople = np.array([('Alice', 30), ('Bob', 25)], dtype=person_dtype)\n\nprint(people)\nprint(people.dtype)\nprint(people[0]['name']) # Access fields by name\n```\n\n----------------------------------------\n\nTITLE: Implementing AsyncHTTPCrawlerStrategy for Simple HTTP Request-Based Web Crawling in Python\nDESCRIPTION: A class that implements the AsyncCrawlerStrategy interface using aiohttp to perform simple HTTP request-based web crawling. It manages HTTP sessions, makes GET or other method requests, reads response bodies, and returns the raw HTML content along with response headers and status codes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from async_crawler_strategy.py\nimport aiohttp # Library for making HTTP requests asynchronously\n# ... other imports\n\nclass AsyncHTTPCrawlerStrategy(AsyncCrawlerStrategy):\n    # ... (Initialization code to manage HTTP sessions)\n\n    async def crawl(self, url: str, config: CrawlerRunConfig, **kwargs) -> AsyncCrawlResponse:\n        # Uses aiohttp to:\n        # 1. Make an HTTP GET (or other method) request to the url\n        # 2. Read the response body (HTML)\n        # 3. Get response headers and status code\n        # 4. Return an AsyncCrawlResponse\n        # ... implementation details ...\n        pass\n```\n\n----------------------------------------\n\nTITLE: Defining Conditional Routing Function in Python\nDESCRIPTION: Defines the routing function `route_based_on_action` used with `add_conditional_edges`. This function inspects the `next_action` field in the `ChatState` and returns a string key ('route_to_tool' or 'route_to_respond') which determines the next node to execute based on the mapping provided in `add_conditional_edges`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef route_based_on_action(state: ChatState) -> str:\n    print(\"--- Routing ---\")\n    action = state['next_action']\n    print(f\"Routing based on action: {action}\")\n    if action == \"USE_TOOL\":\n        return \"route_to_tool\" # This key must match our path_map\n    else:\n        return \"route_to_respond\" # This key must match our path_map\n```\n\n----------------------------------------\n\nTITLE: Handling SSE Streaming Response in Python\nDESCRIPTION: Python implementation of SSE event handling using httpx-sse library. Manages SSE connections, processes events asynchronously, and validates responses using SendTaskStreamingResponse model.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/07_streaming_communication__sse_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nasync def send_task_streaming(self, payload: dict) -> AsyncIterable[SendTaskStreamingResponse]:\n    request = SendTaskStreamingRequest(params=payload)\n    request_json = request.model_dump(exclude_none=True)\n\n    # Use httpx client and connect_sse context manager\n    async with httpx.AsyncClient(timeout=None) as client:\n      try:\n        async with connect_sse(client, \"POST\", self.url, json=request_json) as event_source:\n            # Iterate through Server-Sent Events provided by the library\n            async for sse in event_source.aiter_sse():\n                if sse.event == \"message\": # Default event type\n                    try:\n                        # Parse the JSON data from the event\n                        response_data = json.loads(sse.data)\n                        # Validate and yield the parsed response object\n                        yield SendTaskStreamingResponse(**response_data)\n                    except json.JSONDecodeError:\n                        print(f\"Warning: Could not decode SSE data: {sse.data}\")\n                    except Exception as e: # Catch validation errors too\n                        print(f\"Warning: Error processing SSE data: {e} - Data: {sse.data}\")\n      except httpx.RequestError as e:\n          raise A2AClientHTTPError(400, str(e)) from e\n      # Handle other potential errors like connection issues\n```\n\n----------------------------------------\n\nTITLE: Hypothetical Example of Multiple Configuration Parameters\nDESCRIPTION: Demonstrates what a crawl configuration might look like with multiple parameters, though this isn't actual code from the document but is used to illustrate the potential complexity.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Imagine doing this every time - it gets long!\n# result = await crawler.arun(\n#     url=\"https://example.com\",\n#     take_screenshot=True,\n#     ignore_cache=True,\n#     only_look_at_this_part=\"#main-content\",\n#     wait_for_this_element=\"#data-table\",\n#     # ... maybe many more settings ...\n# )\n```\n\n----------------------------------------\n\nTITLE: Authenticating Requests Using HTTPDigestAuth Class (Python Requests)\nDESCRIPTION: Illustrates how to use HTTPDigestAuth from requests.auth to perform HTTP Digest Authentication. After constructing an HTTPDigestAuth object with the given username and password, the snippet makes an authenticated request to a Digest-protected endpoint. Requires 'requests' and HTTPDigestAuth. It plots status code 200 and response JSON on success, and shows the request history to demonstrate the multi-step challenge-response inherent in Digest Auth. Handles any RequestException errors.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom requests.auth import HTTPDigestAuth # Import the class\n\n# httpbin has a digest auth endpoint\n# user='testuser', pass='testpass'\nurl = 'https://httpbin.org/digest-auth/auth/testuser/testpass'\n\n# Create an HTTPDigestAuth object\ndigest_auth = HTTPDigestAuth('testuser', 'testpass')\n\n# Pass the auth object to the 'auth' parameter\nprint(\"Attempting with HTTPDigestAuth object...\")\ntry:\n    response = requests.get(url, auth=digest_auth)\n    print(f\"Status Code: {response.status_code}\") # Expect 200\n    print(\"Response JSON:\")\n    print(response.json())\n    # Note: It might take two requests internally for Digest Auth\n    print(f\"Request History (if any): {response.history}\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred: {e}\")\n\n```\n\n----------------------------------------\n\nTITLE: Simplified BaseAgent Initialization\nDESCRIPTION: Shows how a BaseAgent gets its ID and runtime access through the AgentInstantiationContext when created by the AgentRuntime. This demonstrates how agents automatically receive their unique identifiers and reference to the runtime system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Simplified Concept - How a BaseAgent gets its ID and runtime access\n# From: _agent_instantiation.py and _base_agent.py\n\n# Inside the agent's __init__ method (when inheriting from BaseAgent):\nclass MyAgent(BaseAgent):\n    def __init__(self, description: str):\n        # This magic happens *because* the AgentRuntime is creating the agent\n        # inside a special context.\n        self._runtime = AgentInstantiationContext.current_runtime() # Gets the manager\n        self._id = AgentInstantiationContext.current_agent_id()     # Gets its own ID\n        self._description = description\n        # ... rest of initialization ...\n```\n\n----------------------------------------\n\nTITLE: Configuring LLM Client for Gemini Pro 2.5\nDESCRIPTION: Python code snippet showing how to set up an LLM client using the Gemini API. This uses an API key that can be set as an environment variable.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(\n  api_key=os.getenv(\"GEMINI_API_KEY\", \"your-api_key\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Marking Input Fields in dspy.Example using .with_inputs() in Python\nDESCRIPTION: Shows how to use the `.with_inputs()` method on a `dspy.Example` to designate specific fields (e.g., `\"english_sentence\"`) as inputs. It explains that this returns a new Example object and demonstrates using the `.inputs()` and `.labels()` methods to retrieve the input and non-input (label) fields separately. Requires the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Our original example\nexample1 = dspy.Example(\n    english_sentence=\"Hello, world!\",\n    french_sentence=\"Bonjour le monde!\"\n)\n\n# Mark 'english_sentence' as the input field\ninput_marked_example = example1.with_inputs(\"english_sentence\")\n\n# Let's check the inputs and labels (non-inputs)\nprint(f\"Inputs: {input_marked_example.inputs()}\")\nprint(f\"Labels: {input_marked_example.labels()}\")\n```\n\n----------------------------------------\n\nTITLE: Invoking Commands Programmatically with Context\nDESCRIPTION: Demonstrates how to use context.invoke() to call other commands programmatically, passing parameters between commands.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/05_context.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# invoke_example.py\nimport click\n\n@click.group()\ndef cli():\n  pass\n\n@cli.command()\n@click.argument('text')\ndef print_it(text):\n  \"\"\"Prints the given text.\"\"\"\n  click.echo(f\"Printing: {text}\")\n\n@cli.command()\n@click.argument('message')\n@click.pass_context # Need context to call invoke\ndef shout(ctx, message):\n  \"\"\"Shouts the message by calling print_it.\"\"\"\n  click.echo(\"About to invoke print_it...\")\n  # Call the 'print_it' command, passing the uppercased message\n  ctx.invoke(print_it, text=message.upper())\n  click.echo(\"Finished invoking print_it.\")\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Marking a Plan Step as Completed using PlanningTool in Python\nDESCRIPTION: Defines the `_mark_step_completed` async helper method within the `PlanningFlow` class. Its purpose is to update the state of the current plan step to 'completed'. It checks if a `current_step_index` is set and then calls the `execute` method of the `planning_tool` instance. The command \"mark_step\" is passed along with the active plan ID, the index of the step to be marked, and the new status ('completed'). This interaction modifies the plan state managed by the `PlanningTool`. Depends on the `PlanningTool` instance associated with the flow.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n    async def _mark_step_completed(self):\n        \"\"\"Update the planning tool state for the current step.\"\"\"\n        if self.current_step_index is not None:\n            await self.planning_tool.execute(\n                command=\"mark_step\",\n                plan_id=self.active_plan_id,\n                step_index=self.current_step_index,\n                step_status=\"completed\" # Simplified status\n            )\n            logger.info(f\"Step {self.current_step_index} marked complete.\")\n```\n\n----------------------------------------\n\nTITLE: Sending Tasks and Handling Streaming Responses Using A2AClient (Python)\nDESCRIPTION: This Python snippet illustrates how to implement a command-line client for sending tasks to an A2A agent server and handling streaming responses using the A2AClient library. It sets up a client instance (optionally via agent card or URL), prepares the request payload with a unique task ID and user message, and streams event responses asynchronously using async for. Required dependencies include the A2AClient library, Python's asyncio, and uuid. Users must provide the correct agent URL and the message input. Outputs are printed JSON-serialized event objects as they are received. The example assumes the agent supports SSE streaming; for non-streaming agents, send_task would be used instead.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/05_a2a_client_implementation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: samples/python/hosts/cli/__main__.py (Simplified Snippet)\nimport asyncio\nfrom uuid import uuid4\nfrom common.client import A2AClient # The client library\n# Assume 'card' is the AgentCard fetched previously (see Chapter 1)\n# card = A2ACardResolver(\"http://localhost:5000\").get_agent_card()\n\n# 1. Create a client instance using the agent's card or URL\n# client = A2AClient(agent_card=card)\nclient = A2AClient(url=\"http://localhost:5000\") # Or directly use URL\n\n# User input\nuser_input = \"Hi Python Agent!\"\n\n# 2. Prepare the payload (parameters) for the request\ntask_id = uuid4().hex # Generate a unique Task ID\npayload = {\n    \"id\": task_id,\n    \"message\": {\n        \"role\": \"user\",\n        \"parts\": [{\"type\": \"text\", \"text\": user_input}],\n    },\n}\n\n# 3. Send the request and handle the response\nasync def send_message():\n    print(f\"Sending task {task_id} to {client.url}...\")\n    try:\n        # Use send_task_streaming if agent supports it (check card.capabilities.streaming)\n        # Assuming streaming is supported here:\n        response_stream = client.send_task_streaming(payload)\n        async for result in response_stream:\n             # result is already parsed SendTaskStreamingResponse object\n            print(f\"Received Agent Event: {result.model_dump_json(exclude_none=True)}\")\n\n        print(\"Agent stream finished.\");\n\n        # If NOT streaming, you'd use send_task:\n        # task_result = await client.send_task(payload)\n        # print(f\"Received Agent Response: {task_result.model_dump_json(exclude_none=True)}\")\n\n    except Exception as e:\n        print(f\"Error talking to agent: {e}\")\n\nasyncio.run(send_message())\n```\n\n----------------------------------------\n\nTITLE: Implementing TerminalChatInput with MultilineTextEditor in React/Ink\nDESCRIPTION: A simplified implementation of the TerminalChatInput component that uses MultilineTextEditor for text input. The component manages input state, history navigation, and submission handling while delegating actual text editing to the MultilineTextEditor component.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/02_input_handling__textbuffer_editor_.md#2025-04-22_snippet_1\n\nLANGUAGE: tsx\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-chat-new-input.tsx (Simplified)\nimport React, { useState, useCallback } from \"react\";\nimport { Box, Text, useInput } from \"ink\";\nimport MultilineTextEditor from \"./multiline-editor\"; // Our editor component\n// ... other imports\n\nexport default function TerminalChatInput({ submitInput, active, /* ... */ }) {\n  const [input, setInput] = useState(\"\"); // Holds the current text in the editor state\n  const [history, setHistory] = useState<string[]>([]); // Holds past submitted messages\n  const [historyIndex, setHistoryIndex] = useState<number | null>(null);\n  // Used to force re-render editor when history changes text\n  const [editorKey, setEditorKey] = useState(0);\n  const editorRef = React.useRef(/* ... */); // Handle to the editor\n\n  // --- History Handling (Simplified) ---\n  useInput((_input, key) => {\n    // Check if Up/Down arrow pressed AND cursor is at top/bottom line\n    const isAtTop = editorRef.current?.isCursorAtFirstRow();\n    const isAtBottom = editorRef.current?.isCursorAtLastRow();\n\n    if (key.upArrow && isAtTop && history.length > 0) {\n      // Logic to go back in history\n      const newIndex = historyIndex === null ? history.length - 1 : Math.max(0, historyIndex - 1);\n      setHistoryIndex(newIndex);\n      setInput(history[newIndex] ?? \"\"); // Set the text to the historical item\n      setEditorKey(k => k + 1); // Force editor to re-mount with new text\n      // ... save draft if needed ...\n    } else if (key.downArrow && isAtBottom && historyIndex !== null) {\n      // Logic to go forward in history or restore draft\n      // ... similar logic using setInput, setHistoryIndex, setEditorKey ...\n    }\n    // Note: If not handling history, the key press falls through to MultilineTextEditor\n  }, { isActive: active });\n\n\n  // --- Submission Handling ---\n  const onSubmit = useCallback((textFromEditor: string) => {\n    const trimmedText = textFromEditor.trim();\n    if (!trimmedText) return; // Ignore empty submissions\n\n    // Add to history\n    setHistory(prev => [...prev, textFromEditor]);\n    setHistoryIndex(null); // Reset history navigation\n\n    // Send the input to the Agent Loop!\n    submitInput(/* ... create input item from trimmedText ... */);\n\n    // Clear the input for the next message\n    setInput(\"\");\n    setEditorKey(k => k + 1); // Force editor reset\n\n  }, [submitInput, setHistory /* ... */]);\n\n  return (\n    <Box flexDirection=\"column\" borderStyle=\"round\">\n      {/* The actual editor component */}\n      <MultilineTextEditor\n        ref={editorRef} // Connect ref for cursor position checks\n        key={editorKey} // Force re-render on key change\n        initialText={input} // Tell editor what text to display initially\n        focus={active} // Tell editor whether to capture keys\n        onChange={(text) => setInput(text)} // Update React state when text changes internally\n        onSubmit={onSubmit} // Tell editor what to do on Enter\n        height={8} // Example height\n      />\n      <Text dimColor>ctrl+c exit | enter send | ↑↓ history | ctrl+x editor</Text>\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Flask Context Variable Definitions\nDESCRIPTION: Shows how Flask defines context variables and proxies using Python's contextvars module. Demonstrates the setup of request, session, current_app, and g proxies.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nfrom contextvars import ContextVar\nfrom werkzeug.local import LocalProxy\n\n_cv_app: ContextVar[AppContext] = ContextVar(\"flask.app_ctx\")\n_cv_request: ContextVar[RequestContext] = ContextVar(\"flask.request_ctx\")\n\nrequest: Request = LocalProxy(_cv_request, \"request\")\nsession: SessionMixin = LocalProxy(_cv_request, \"session\")\ncurrent_app: Flask = LocalProxy(_cv_app, \"app\")\ng: _AppCtxGlobals = LocalProxy(_cv_app, \"g\")\n```\n\n----------------------------------------\n\nTITLE: Example Success Response for tasks/send\nDESCRIPTION: This JSON snippet illustrates the structure of a successful JSON-RPC 2.0 response from an agent after processing a `tasks/send` request. The `result` field contains the initial `Task` object, including its `id`, initial `status` (with `state` set to 'submitted' and a `timestamp`), potentially null `artifacts` and `history`, and the `id` matching the original client request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n// Agent Sends This Back (HTTP Response body)\n{\n  \"jsonrpc\": \"2.0\",\n  \"result\": {          // The result: a Task object\n    \"id\": \"task-xyz-789\", // The same Task ID\n    \"status\": {        // The initial status\n      \"state\": \"submitted\",\n      \"timestamp\": \"2023-10-27T10:00:00Z\"\n    },\n    \"artifacts\": null, // No results yet\n    \"history\": null    // History might be omitted initially\n    // Other Task fields\n  },\n  \"id\": \"client-req-001\" // Matches the request ID\n}\n```\n\n----------------------------------------\n\nTITLE: Using Jinja2 For Loops in HTML Template\nDESCRIPTION: This HTML snippet (`items.html`) showcases Jinja2's `for` loop (`{% for %}`, `{% endfor %}`). It iterates over the `items` list passed from the Flask application, rendering each item as an `<li>` element. It also includes an optional `{% else %}` block that renders fallback content if the `items` list is empty.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<!-- templates/items.html -->\n{% raw %}\n<!doctype html>\n<html>\n<head><title>Item List</title></head>\n<body>\n  <h2>Available Items:</h2>\n  <ul>\n    {% for fruit in items %}\n      <li>{{ fruit }}</li>\n    {% else %}\n      <li>No items available.</li>\n    {% endfor %}\n  </ul>\n</body>\n</html>\n{% endraw %}\n```\n\n----------------------------------------\n\nTITLE: Using Click's Choice ParamType for Validated Input Selection\nDESCRIPTION: This example shows how to use click.Choice ParamType to restrict user input to a predefined set of options, with case-insensitive matching for better user experience.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# choice_example.py\nimport click\n\n@click.command()\n@click.option('--difficulty', type=click.Choice(['easy', 'medium', 'hard'], case_sensitive=False), default='easy')\ndef setup(difficulty):\n    click.echo(f\"Setting up game with difficulty: {difficulty}\")\n\nif __name__ == '__main__':\n    setup()\n```\n\n----------------------------------------\n\nTITLE: Initializing CrewAI Memory Modules in Python - Crew Class\nDESCRIPTION: This Python class snippet, simplified from crewai/crew.py, demonstrates how the Crew object's memory subsystems (ShortTermMemory, LongTermMemory, EntityMemory) are instantiated conditionally via a Pydantic validator method when memory=True. Dependencies include Pydantic, CrewAI's memory module classes, and Python typing. The class expects memory to be enabled through the constructor for memory initialization; outputs are side effects in object state.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/07_memory.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crewai/crew.py\\nclass Crew(BaseModel):\\n    memory: bool = Field(default=False, ...)\\n    _short_term_memory: Optional[InstanceOf[ShortTermMemory]] = PrivateAttr()\\n    _long_term_memory: Optional[InstanceOf[LongTermMemory]] = PrivateAttr()\\n    _entity_memory: Optional[InstanceOf[EntityMemory]] = PrivateAttr()\\n    # ... other fields ...\\n\\n    @model_validator(mode=\\\"after\\\")\\n    def create_crew_memory(self) -> \\\"Crew\\\":\\n        if self.memory:\\n            # Simplified: Initializes memory objects if memory=True\\n            self._long_term_memory = LongTermMemory(...)\\n            self._short_term_memory = ShortTermMemory(crew=self, ...)\\n            self._entity_memory = EntityMemory(crew=self, ...)\\n        return self\\n\n```\n\n----------------------------------------\n\nTITLE: BootstrapFewShot Implementation in Python\nDESCRIPTION: Core implementation of the BootstrapFewShot class in DSPy, including initialization, compilation, bootstrapping, and demo collection logic. Shows how the teleprompter manages the teacher-student training process and handles successful demonstrations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from dspy/teleprompt/bootstrap.py\n\n# ... imports ...\nfrom .teleprompt import Teleprompter\nfrom .vanilla import LabeledFewShot # Used for teacher setup if labeled demos are needed\nimport dspy\n\nclass BootstrapFewShot(Teleprompter):\n    def __init__(self, metric=None, max_bootstrapped_demos=4, ...):\n        self.metric = metric\n        self.max_bootstrapped_demos = max_bootstrapped_demos\n        # ... other initializations ...\n\n    def compile(self, student, *, teacher=None, trainset):\n        self.trainset = trainset\n        self._prepare_student_and_teacher(student, teacher) # Sets up self.student and self.teacher\n        self._prepare_predictor_mappings() # Links student predictors to teacher predictors\n        self._bootstrap() # Runs the core bootstrapping logic\n\n        self.student = self._train() # Assigns collected demos to the student\n        self.student._compiled = True\n        return self.student\n\n    def _bootstrap(self):\n        # ... setup ...\n        self.name2traces = {name: [] for name in self.name2predictor} # Store successful traces per predictor\n\n        for example_idx, example in enumerate(tqdm.tqdm(self.trainset)):\n            # ... logic to stop early if enough demos found ...\n            success = self._bootstrap_one_example(example, round_idx=0) # Try to get a demo from this example\n            # ... potentially multiple rounds ...\n\n        # ... logging ...\n\n    def _bootstrap_one_example(self, example, round_idx=0):\n        # ... setup teacher context (e.g., temperature) ...\n        try:\n            with dspy.settings.context(trace=[], **self.teacher_settings):\n                # Optionally modify teacher LM settings for exploration\n                # ...\n                # Run the teacher program\n                prediction = self.teacher(**example.inputs())\n                trace = dspy.settings.trace # Get the execution trace\n\n                # Evaluate the prediction using the metric\n                if self.metric:\n                    metric_val = self.metric(example, prediction, trace)\n                    # Determine success based on metric value/threshold\n                    success = bool(metric_val) # Simplified\n                else:\n                    success = True # Assume success if no metric provided\n        except Exception:\n            success = False\n            # ... error handling ...\n\n        if success:\n            # If successful, extract demos from the trace\n            for step in trace:\n                predictor, inputs, outputs = step\n                demo = dspy.Example(augmented=True, **inputs, **outputs)\n                try:\n                    predictor_name = self.predictor2name[id(predictor)]\n                    # Store the successful demo example\n                    self.name2traces[predictor_name].append(demo)\n                except KeyError:\n                    continue # Handle potential issues finding the predictor\n\n        return success\n\n    def _train(self):\n        # Assign the collected demos to the student's predictors\n        for name, predictor in self.student.named_predictors():\n            demos_for_predictor = self.name2traces[name][:self.max_bootstrapped_demos]\n            # Potentially mix with labeled demos if configured\n            # ...\n            predictor.demos = demos_for_predictor # Assign the demos!\n        return self.student\n```\n\n----------------------------------------\n\nTITLE: Accessing Command Parameters via Context\nDESCRIPTION: Shows how to access command parameters through the context.params dictionary after parameter processing and type conversion.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/05_context.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# access_params.py\nimport click\n\n@click.command()\n@click.option('--name', default='Guest')\n@click.pass_context\ndef hello(ctx, name):\n  click.echo(f\"Hello, {name}!\")\n  # Access the parameter value directly via ctx.params\n  click.echo(f\"(Value from ctx.params: {ctx.params['name']})\")  \n\nif __name__ == '__main__':\n  hello()\n```\n\n----------------------------------------\n\nTITLE: Creating Basic FastMCP Resource Server - Initial Version\nDESCRIPTION: Demonstrates setting up a basic FastMCP server with a static welcome message resource. Shows initial implementation with separate getter function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# 1. Import FastMCP\nfrom mcp.server.fastmcp import FastMCP\n\n# 2. Create the server instance\nserver = FastMCP(name=\"LibraryServer\")\n\n# 3. Define a function that returns our static data\ndef get_welcome_message() -> str:\n  \"\"\"Returns a simple welcome string.\"\"\"\n  return \"Welcome to the Library Server!\"\n\n# 4. Use the @server.resource() decorator to register the function's result\n#    The URI \"data://greeting\" will be used by clients to access this.\n@server.resource(uri=\"data://greeting\", description=\"A friendly greeting.\")\ndef welcome_resource():\n    # This function will be called *when a client reads* the resource.\n    # It just returns the static message.\n    return get_welcome_message() # Or simply: return \"Welcome...\"\n\n# Standard run block\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Resuming Execution and Inspecting Checkpoints with MemorySaver in Python\nDESCRIPTION: This snippet further demonstrates how to resume an execution from a previous checkpoint by re-invoking the workflow with the same thread_id but omitting the initial state. It also shows how to enumerate all checkpoints saved by MemorySaver for a given config. Outputs are state restorations and printed checkpoint objects, useful for verifying persistence. Requires a prior MemorySaver object and an executed workflow.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(\"\\n--- Running Graph Again with SAME thread_id ---\")\\n# Use the SAME config (containing the same thread_id)\\n# Provide NO initial state, as it will be loaded from the checkpoint\\nresumed_state = app.invoke(None, config=config)\\n\\nprint(\"\\n--- Final State (Resumed Run) ---\")\\nprint(resumed_state)\\n\\n# Let's check the saved states using the checkpointer directly\\nprint(\"\\n--- Checkpoints Saved ---\")\\nfor checkpoint in memory_saver.list(config):\\n    print(checkpoint)\n```\n\n----------------------------------------\n\nTITLE: Updating Claude Configuration for MCP Server Integration in Python\nDESCRIPTION: This snippet demonstrates how to add or update a FastMCP server in Claude's configuration. It includes functions to find Claude's config path and update the configuration file with server details. The code uses 'uv' to run Python code and constructs the necessary command for server execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/01_cli___mcp__command_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef get_claude_config_path() -> Path | None:\n    # ... platform specific logic to find the path ...\n    # Returns Path object like /Users/You/Library/Application Support/Claude\n    pass # Implementation details skipped\n\ndef update_claude_config(file_spec: str, server_name: str, ...) -> bool:\n    \"\"\"Add or update a FastMCP server in Claude's configuration.\"\"\"\n    config_dir = get_claude_config_path()\n    if not config_dir:\n        print(\"Error: Claude config not found.\")\n        return False\n\n    config_file = config_dir / \"claude_desktop_config.json\"\n\n    try:\n        # Read existing config or create an empty one\n        config = json.loads(config_file.read_text()) if config_file.exists() else {}\n        if \"mcpServers\" not in config:\n            config[\"mcpServers\"] = {}\n\n        # Define how to run the server using 'uv' (a tool for running Python code)\n        # This builds the command: uv run --with mcp mcp run /path/to/server.py\n        run_command = [\"uv\", \"run\", \"--with\", \"mcp\", \"mcp\", \"run\", file_spec]\n        # ... logic to add --with-editable or --with packages ...\n\n        # Add the server entry to the config dictionary\n        config[\"mcpServers\"][server_name] = {\n            \"command\": \"uv\",\n            \"args\": run_command[1:], # Arguments for the uv command\n            # ... potentially add 'env' dictionary here ...\n        }\n\n        # Write the updated configuration back to the file\n        config_file.write_text(json.dumps(config, indent=2))\n        print(f\"Successfully installed {server_name} in Claude.\")\n        return True\n    except Exception as e:\n        print(f\"Error updating Claude config: {e}\")\n        return False\n```\n\n----------------------------------------\n\nTITLE: Temporarily Overriding Settings with dspy.context (Python)\nDESCRIPTION: Demonstrates using the `dspy.settings.context` context manager to temporarily change the default LM (and optionally other settings like RM) within a specific `with` block. A dummy `gpt4_dummy` LM is created for this purpose. Inside the block, modules use the temporary settings. Settings automatically revert to the global defaults upon exiting the block.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Assume global settings have 'turbo' (GPT-3.5 or Dummy) as the LM\n# dspy.settings.configure(lm=turbo, rm=my_rm)\n\nprint(f\"Outside context: {dspy.settings.lm}\")\n\n# Let's create a more powerful (dummy) LM for demonstration\nclass DummyGPT4(dspy.LM):\n    def __init__(self): super().__init__(model=\"dummy-gpt4\")\n    def basic_request(self, prompt, **kwargs): return {\"choices\": [{\"text\": \"GPT-4 Dummy Response\"}]}\n    def __call__(self, prompt, **kwargs): return [\"GPT-4 Dummy Response\"]\ngpt4_dummy = DummyGPT4()\n\n# Use dspy.context to temporarily switch the LM\nwith dspy.settings.context(lm=gpt4_dummy, rm=None): # Temporarily set lm, unset rm\n    print(f\"Inside context: {dspy.settings.lm}\")\n    print(f\"Inside context (RM): {dspy.settings.rm}\")\n\n    # Modules used inside this block will use the temporary settings\n    predictor_in_context = dspy.Predict('input -> output')\n    result_in_context = predictor_in_context(input=\"Complex reasoning task\")\n    print(f\"Prediction in context: {result_in_context.output}\")\n\n    # Trying to use RM here would fail as it's None in this context\n    # retriever_in_context = dspy.Retrieve()\n    # retriever_in_context(query=\"something\") # This would raise an error\n\n# Settings revert back automatically outside the block\nprint(f\"Outside context again: {dspy.settings.lm}\")\nprint(f\"Outside context again (RM): {dspy.settings.rm}\")\n```\n\n----------------------------------------\n\nTITLE: Defining Chat Messages for AutoGen Core in Python\nDESCRIPTION: This snippet demonstrates how to define a set of chat messages using AutoGen Core's message types. It creates a system message and a sequence of user and assistant messages, combining them into a full conversation history.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# File: define_chat_messages.py\nfrom autogen_core.models import (\n    SystemMessage, UserMessage, AssistantMessage, LLMMessage\n)\nfrom typing import List\n\n# The initial instruction for the assistant\nsystem_msg = SystemMessage(content=\"You are a helpful assistant.\")\n\n# A sequence of user/assistant turns\nchat_sequence: List[LLMMessage] = [\n    UserMessage(content=\"What is AutoGen?\", source=\"User\"),\n    AssistantMessage(content=\"AutoGen is a multi-agent framework...\", source=\"Agent\"),\n    UserMessage(content=\"What can it do?\", source=\"User\"),\n    AssistantMessage(content=\"It can build complex LLM apps.\", source=\"Agent\"),\n    UserMessage(content=\"Thanks!\", source=\"User\")\n]\n\n# Combine system message and the chat sequence\nfull_history: List[LLMMessage] = [system_msg] + chat_sequence\n\nprint(f\"Total messages in full history: {len(full_history)}\")\n# Output: Total messages in full history: 6\n```\n\n----------------------------------------\n\nTITLE: Managing Message Tokens and Trimming History in Python\nDESCRIPTION: This snippet shows the core functions for adding messages to the history, counting tokens, and trimming the history when it exceeds the token limit. It includes logic for handling multi-modal messages with text and images, and implements strategies for reducing token count by removing images or trimming text content.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass MessageManager:\n    # ... (other methods) ...\n\n    def _add_message_with_tokens(self, message: BaseMessage, position: int | None = None) -> None:\n        \"\"\"Internal helper to add any message with its token count metadata.\"\"\"\n\n        # 1. Optionally filter sensitive data (replace actual data with placeholders)\n        # if self.settings.sensitive_data:\n        #    message = self._filter_sensitive_data(message) # Simplified\n\n        # 2. Count the tokens in the message\n        token_count = self._count_tokens(message)\n\n        # 3. Create metadata object\n        metadata = MessageMetadata(tokens=token_count)\n\n        # 4. Add the message and its metadata to the history list\n        #    (self.state.history is a MessageHistory object)\n        self.state.history.add_message(message, metadata, position)\n        #    Note: self.state.history.add_message also updates the total token count\n\n        # 5. Check if history exceeds token limit and truncate if needed\n        self.cut_messages() # Check and potentially trim history\n\n    def _count_tokens(self, message: BaseMessage) -> int:\n        \"\"\"Estimate tokens in a message.\"\"\"\n        tokens = 0\n        if isinstance(message.content, list): # Multi-modal (text + image)\n            for item in message.content:\n                if isinstance(item, dict) and 'image_url' in item:\n                    # Add fixed cost for images\n                    tokens += self.settings.image_tokens\n                elif isinstance(item, dict) and 'text' in item:\n                    # Estimate tokens based on text length\n                    tokens += len(item['text']) // self.settings.estimated_characters_per_token\n        elif isinstance(message.content, str): # Text message\n            text = message.content\n            if hasattr(message, 'tool_calls'): # Add tokens for tool call structure\n                 text += str(getattr(message, 'tool_calls', ''))\n            tokens += len(text) // self.settings.estimated_characters_per_token\n\n        return tokens\n\n    def cut_messages(self):\n        \"\"\"Trim messages if total tokens exceed the limit.\"\"\"\n        # Calculate how many tokens we are over the limit\n        diff = self.state.history.current_tokens - self.settings.max_input_tokens\n        if diff <= 0:\n            return # We are within limits\n\n        logger.debug(f\"Token limit exceeded by {diff}. Trimming history.\")\n\n        # Strategy:\n        # 1. Try removing the image from the *last* (most recent) state message if present.\n        #    (Code logic finds the last message, checks content list, removes image item, updates counts)\n        # ... (Simplified - see full code for image removal logic) ...\n\n        # 2. If still over limit after image removal (or no image was present),\n        #    trim text content from the *end* of the last state message.\n        #    Calculate proportion to remove, shorten string, create new message.\n        # ... (Simplified - see full code for text trimming logic) ...\n\n        # Ensure we don't get stuck if trimming isn't enough (raise error)\n        if self.state.history.current_tokens > self.settings.max_input_tokens:\n             raise ValueError(\"Max token limit reached even after trimming.\")\n```\n\n----------------------------------------\n\nTITLE: Using the Default Dispatcher with AsyncWebCrawler.arun_many()\nDESCRIPTION: Python example demonstrating how to use AsyncWebCrawler.arun_many() with the default MemoryAdaptiveDispatcher to crawl multiple URLs concurrently. This code crawls four different URLs and prints their status and titles after completion.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/10_basedispatcher.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# chapter10_example_1.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n\nasync def main():\n    urls_to_crawl = [\n        \"https://httpbin.org/html\",\n        \"https://httpbin.org/links/5/0\", # Page with 5 links\n        \"https://httpbin.org/robots.txt\",\n        \"https://httpbin.org/status/200\",\n    ]\n\n    # We DON'T specify a dispatcher here.\n    # arun_many will use the default MemoryAdaptiveDispatcher.\n    async with AsyncWebCrawler() as crawler:\n        print(f\"Crawling {len(urls_to_crawl)} URLs using the default dispatcher...\")\n        config = CrawlerRunConfig(stream=False) # Get results as a list at the end\n\n        # The MemoryAdaptiveDispatcher manages concurrency behind the scenes.\n        results = await crawler.arun_many(urls=urls_to_crawl, config=config)\n\n        print(f\"\\nFinished! Got {len(results)} results.\")\n        for result in results:\n            status = \"✅\" if result.success else \"❌\"\n            url_short = result.url.split('/')[-1]\n            print(f\"  {status} {url_short:<15} | Title: {result.metadata.get('title', 'N/A')}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing AgentMemory Class in Python\nDESCRIPTION: Simplified Python code from `memory.py` showing the `AgentMemory` class. This class manages the agent's history. It initializes with a `SystemPromptStep` and maintains a list `steps` containing subsequent `MemoryStep` objects (like `TaskStep`, `ActionStep`). It includes a `reset` method to clear history for new runs and a placeholder `replay` method for debugging/logging. Dependencies include the previously defined `MemoryStep` subclasses and `typing`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/04_agentmemory.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: memory.py (Simplified AgentMemory) ---\nfrom typing import List, Union\n\n@dataclass\nclass SystemPromptStep(MemoryStep): # Simplified\n    system_prompt: str\n    def to_messages(self, **kwargs): # Simplified\n         return [{\"role\": \"system\", \"content\": self.system_prompt}]\n\nclass AgentMemory:\n    def __init__(self, system_prompt: str):\n        # Initialize with the system prompt\n        self.system_prompt = SystemPromptStep(system_prompt=system_prompt)\n        # The main logbook - a list of steps taken\n        self.steps: List[Union[TaskStep, ActionStep, PlanningStep]] = []\n\n    def reset(self):\n        \"\"\"Clears the memory for a new run.\"\"\"\n        self.steps = []\n\n    def replay(self, logger, detailed: bool = False):\n         \"\"\"Utility to print the memory steps nicely.\"\"\"\n         # ... implementation uses logger to print each step ...\n         pass\n```\n\n----------------------------------------\n\nTITLE: Verifying HTTP Basic Credentials in FastAPI - Python\nDESCRIPTION: This snippet defines a custom dependency function to verify hardcoded HTTP Basic credentials for demonstration purposes in a FastAPI application. It uses Annotated dependencies, compares against hardcoded credentials (which is insecure and for demo only), and raises HTTPException with HTTP 401 status if authentication fails, returning the username if successful. Dependencies include fastapi, Annotated, HTTPBasicCredentials, Depends, security instance, status, and HTTPException; input is HTTPBasicCredentials, output is the username string, with hardcoded values for illustration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Our \"verifier\" function\ndef get_current_username(credentials: Annotated[HTTPBasicCredentials, Depends(security)]):\n    # NOTE: In a real app, NEVER hardcode credentials like this!\n    #       Always use secure password hashing (e.g., with passlib)\n    #       and check against a database.\n    correct_username = \"stanley\"\n    correct_password = \"password123\" # Don't do this in production!\n\n    # Basic check (insecure comparison for demonstration)\n    is_correct_username = credentials.username == correct_username\n    is_correct_password = credentials.password == correct_password # Insecure!\n\n    if not (is_correct_username and is_correct_password):\n        # If credentials are bad, raise an exception\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect email or password\",\n            headers={\"WWW-Authenticate\": \"Basic\"}, # Required header for 401 Basic Auth\n        )\n    # If credentials are okay, return the username\n    return credentials.username\n\n```\n\n----------------------------------------\n\nTITLE: Rendering Message History Component\nDESCRIPTION: Component that efficiently renders chat message history using Ink's Static component for optimization. Maps message items to individual response components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_2\n\nLANGUAGE: tsx\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-message-history.tsx (Simplified)\n\n// ... imports ...\nimport TerminalChatResponseItem from \"./terminal-chat-response-item\";\nimport { Box, Static } from \"ink\";\nimport React from \"react\";\n\nconst MessageHistory: React.FC<MessageHistoryProps> = ({ batch, /* ... */ }) => {\n  const messages = batch.map(({ item }) => item!);\n\n  return (\n    <Box flexDirection=\"column\">\n      <Static items={messages}>\n        {(message, index) => (\n          <Box key={`${message.id}-${index}`} /* ...styling... */ >\n            <TerminalChatResponseItem item={message} />\n          </Box>\n        )}\n      </Static>\n    </Box>\n  );\n};\n\nexport default React.memo(MessageHistory);\n```\n\n----------------------------------------\n\nTITLE: Catching Specific Requests Errors in Python\nDESCRIPTION: This snippet shows how to catch specific types of errors from the Requests library, such as ConnectionError, Timeout, and HTTPError. It demonstrates different handling for each type of error, allowing for more precise error management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# URL that gives a 404 error\nnot_found_url = 'https://httpbin.org/status/404'\n\ntry:\n    response = requests.get(not_found_url, timeout=5)\n    response.raise_for_status()  # This will raise an HTTPError for 4xx/5xx status codes\n    print(\"Success! Status Code:\", response.status_code)\n\nexcept requests.exceptions.Timeout:\n    print(\"The request timed out. Please try again later.\")\n\nexcept requests.exceptions.ConnectionError:\n    print(\"Network error. Please check your internet connection.\")\n\nexcept requests.exceptions.HTTPError as e:\n    print(f\"HTTP Error occurred: {e}\")\n    print(f\"Response text: {e.response.text}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"An unexpected error occurred: {e}\")\n\nprint(\"\\nScript continues after handling the error.\")\n```\n\n----------------------------------------\n\nTITLE: Content Filter Strategy Base Class Implementation\nDESCRIPTION: This snippet shows the simplified content_filter_strategy.py file with the abstract base class for content filters. It defines the interface that all content filters must implement, including the filter_content method that processes HTML content and returns relevant fragments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from content_filter_strategy.py\nfrom abc import ABC, abstractmethod\nfrom typing import List\n```\n\n----------------------------------------\n\nTITLE: Functional API Workflow Sequence - Requests - Mermaid\nDESCRIPTION: This mermaid diagram visually represents the flow of a functional API call in the Requests Python library. It shows how a call to requests.get() in user code creates a new temporary Session, sends an HTTP request to a server, returns the response, and discards the session. No dependencies beyond mermaid diagram support. Used to conceptually illustrate the short-lived, stateless nature of functional API web requests.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/01_functional_api.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User as Your Code\n    participant FuncAPI as requests.get()\n    participant TempSession as Temporary Session\n    participant Server as Web Server\n\n    User->>FuncAPI: Call requests.get('url')\n    FuncAPI->>TempSession: Create new Session()\n    activate TempSession\n    TempSession->>Server: Make HTTP GET request to 'url'\n    activate Server\n    Server-->>TempSession: Send HTTP Response back\n    deactivate Server\n    TempSession-->>FuncAPI: Return Response object\n    FuncAPI-->>User: Return Response object\n    deactivate TempSession\n    Note right of FuncAPI: Temporary Session is discarded\n```\n\n----------------------------------------\n\nTITLE: Visualizing SmolaAgents Architecture with Mermaid Flowchart\nDESCRIPTION: This Mermaid flowchart illustrates the architecture and relationships between the main components of SmolaAgents. It shows how MultiStepAgent interacts with various tools, interfaces, and modules to create a comprehensive autonomous agent system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"MultiStepAgent\"]\n    A1[\"Tool\"]\n    A2[\"Model Interface\"]\n    A3[\"AgentMemory\"]\n    A4[\"PythonExecutor\"]\n    A5[\"PromptTemplates\"]\n    A6[\"AgentType\"]\n    A7[\"AgentLogger & Monitor\"]\n    A0 -- \"Uses tools\" --> A1\n    A0 -- \"Uses model\" --> A2\n    A0 -- \"Uses memory\" --> A3\n    A0 -- \"Uses templates\" --> A5\n    A0 -- \"Uses logger/monitor\" --> A7\n    A0 -- \"Uses executor (CodeAgent)\" --> A4\n    A1 -- \"Outputs agent types\" --> A6\n    A4 -- \"Executes tool code\" --> A1\n    A2 -- \"Generates/Parses tool calls\" --> A1\n    A3 -- \"Logs tool calls\" --> A1\n    A5 -- \"Includes tool info\" --> A1\n    A6 -- \"Handled by agent\" --> A0\n    A7 -- \"Replays memory\" --> A3\n```\n\n----------------------------------------\n\nTITLE: Implementing LXMLWebScrapingStrategy in Crawl4AI (Python)\nDESCRIPTION: This snippet demonstrates how to use the LXMLWebScrapingStrategy in a Crawl4AI application. It shows the process of importing the strategy, creating an instance, configuring the crawler, and running it with the custom strategy.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# 1. Import the specific strategy you want to use\nfrom crawl4ai import LXMLWebScrapingStrategy\n\nasync def main():\n    # 2. Create an instance of the desired scraping strategy\n    lxml_editor = LXMLWebScrapingStrategy()\n    print(f\"Using scraper: {lxml_editor.__class__.__name__}\")\n\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n\n        # 3. Create a CrawlerRunConfig and pass the strategy instance\n        config = CrawlerRunConfig(\n            cache_mode=CacheMode.BYPASS,\n            scraping_strategy=lxml_editor # Tell the config which strategy to use\n        )\n\n        print(f\"Crawling {url_to_crawl} with explicit LXML scraping strategy...\")\n        result = await crawler.arun(url=url_to_crawl, config=config)\n\n        if result.success:\n            print(\"\\nSuccess! Content fetched and scraped using LXML.\")\n            print(f\"Page Title: {result.metadata.get('title', 'N/A')}\")\n            print(f\"Found {len(result.links.external)} external links.\")\n            # Output should be largely the same as the default strategy for simple pages\n        else:\n            print(f\"\\nFailed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Using alias_generator in Pydantic ConfigDict for Python\nDESCRIPTION: Shows how to use the alias_generator configuration option to automatically generate camelCase aliases for snake_case field names. It also demonstrates the use of populate_by_name for flexible input handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic.alias_generators import to_camel # Import a helper\n\nclass User(BaseModel):\n    user_id: int\n    first_name: str\n\n    model_config = ConfigDict(\n        alias_generator=to_camel, # Use the camelCase generator\n        populate_by_name=True # Allow using EITHER alias or python name for input (see warning below)\n                              # Replaced by validate_by_name=True + validate_by_alias=True\n    )\n\n# Input using camelCase aliases\nuser_data_camel = {'userId': 1, 'firstName': 'Arthur'}\nuser = User(**user_data_camel)\nprint(f\"User created from camelCase: {user}\")\n# Expected Output: User created from camelCase: user_id=1 first_name='Arthur'\n\n# Output (dumping) using aliases requires `by_alias=True`\nprint(f\"Dumped with aliases: {user.model_dump(by_alias=True)}\")\n# Expected Output: Dumped with aliases: {'userId': 1, 'firstName': 'Arthur'}\n\nprint(f\"Dumped without aliases: {user.model_dump()}\")\n# Expected Output: Dumped without aliases: {'user_id': 1, 'first_name': 'Arthur'}\n```\n\n----------------------------------------\n\nTITLE: Using Memory for Context in OpenManus\nDESCRIPTION: This snippet demonstrates how to prepare the stored messages in Memory for use with an LLM, converting them to a format suitable for API calls in OpenManus.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# (Continuing from previous example)\n\n# Agent prepares to ask the LLM\nmessages_for_llm = conversation_memory.to_dict_list()\n\nprint(\"Messages being sent to LLM for context:\")\nfor msg in messages_for_llm:\n    print(f\"- {msg}\")\n\n# Simplified: Agent would now pass 'messages_for_llm' to llm.ask(...)\n# response = await agent.llm.ask(messages=messages_for_llm)\n# print(f\"LLM would likely respond about the capital of Spain, e.g., 'The capital of Spain is Madrid.'\")\n```\n\n----------------------------------------\n\nTITLE: Message and Memory Flow Diagram in OpenManus\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of messages between User, Agent, Memory, LLM Class, and LLM API in OpenManus, showing how memory is updated and used for context.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Agent as BaseAgent (app/agent/base.py)\n    participant Mem as Memory (app/schema.py)\n    participant LLM as LLM Class (app/llm.py)\n    participant LLM_API as Actual LLM API\n\n    User->>+Agent: Sends message (\"What about Spain?\")\n    Agent->>+Mem: update_memory(role=\"user\", content=\"What about Spain?\")\n    Mem->>Mem: Adds Message(role='user', ...) to internal list\n    Mem-->>-Agent: Memory updated\n    Agent->>Agent: Needs to generate response\n    Agent->>+Mem: Get all messages (memory.messages)\n    Mem-->>-Agent: Returns list of Message objects\n    Agent->>Agent: Formats messages to dict list (memory.to_dict_list())\n    Agent->>+LLM: ask(messages=formatted_list)\n    LLM->>LLM_API: Sends request with history\n    LLM_API-->>LLM: Receives response (\"The capital is Madrid.\")\n    LLM-->>-Agent: Returns text response\n    Agent->>+Mem: update_memory(role=\"assistant\", content=\"The capital is Madrid.\")\n    Mem->>Mem: Adds Message(role='assistant', ...) to internal list\n    Mem-->>-Agent: Memory updated\n    Agent->>-User: Sends response (\"The capital is Madrid.\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing AsyncWebCrawler Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram illustrating the flow of operations when calling the arun method of AsyncWebCrawler, including cache checking, content fetching, and processing steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/02_asyncwebcrawler.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant U as User\n    participant AWC as AsyncWebCrawler (Manager)\n    participant CC as Cache Check\n    participant CS as AsyncCrawlerStrategy (Fetcher)\n    participant SP as Scraping/Processing\n    participant CR as CrawlResult (Final Report)\n\n    U->>AWC: arun(\"https://example.com\", config)\n    AWC->>CC: Need content for \"https://example.com\"? (Respect CacheMode in config)\n    alt Cache Hit & Cache Mode allows reading\n        CC-->>AWC: Yes, here's the cached result.\n        AWC-->>CR: Package cached result.\n        AWC-->>U: Here is the CrawlResult\n    else Cache Miss or Cache Mode prevents reading\n        CC-->>AWC: No cached result / Cannot read cache.\n        AWC->>CS: Please fetch \"https://example.com\" (using configured strategy)\n        CS-->>AWC: Here's the raw response (HTML, etc.)\n        AWC->>SP: Process this raw content (Scrape, Filter, Extract based on config)\n        SP-->>AWC: Here's the processed data (Markdown, Metadata, etc.)\n        AWC->>CC: Cache this result? (Respect CacheMode in config)\n        CC-->>AWC: OK, cached.\n        AWC-->>CR: Package new result.\n        AWC-->>U: Here is the CrawlResult\n    end\n```\n\n----------------------------------------\n\nTITLE: Visualizing Knowledge Retrieval Flow - Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram illustrates the high-level steps and message flow in CrewAI's knowledge retrieval process. Participants are depicted as the Agent, Knowledge Object, KnowledgeStorage (vector DB), and LLM. The sequence covers task initiation, prompt preparation, knowledge query and retrieval, prompt augmentation, and receiving the LLM's final answer. This can be rendered with any Mermaid-compatible tool for process visualization. Inputs are general descriptions of actions; the output is the visual sequence chart.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/08_knowledge.md#2025-04-22_snippet_2\n\nLANGUAGE: Mermaid\nCODE:\n```\nsequenceDiagram\\n    participant A as Agent\\n    participant K as Knowledge Object\\n    participant KS as KnowledgeStorage (Vector DB)\\n    participant LLM as Agent's LLM\\n\\n    A->>A: Start Task ('How to reset Widget Pro?')\\n    A->>A: Prepare base prompt (Task, Role, Goal...)\\n    A->>K: Query('How to reset Widget Pro?')\\n    K->>KS: Search(query='How to reset Widget Pro?')\\n    Note right of KS: Finds similar chunks via embeddings\\n    KS-->>K: Return relevant chunks from manual\\n    K-->>A: Provide relevant chunks\\n    A->>A: Augment prompt with retrieved chunks\\n    A->>LLM: Send augmented prompt\\n    LLM-->>A: Generate answer based on task + manual excerpts\\n    A->>A: Final Answer (Steps from manual)\n```\n\n----------------------------------------\n\nTITLE: Sending SSE Events from A2A Server using sse-starlette (Python)\nDESCRIPTION: Conceptual Python code snippet showing how an A2A server uses the `sse-starlette` library to manage SSE streaming. When the task handler (`on_send_task_subscribe`) returns an `AsyncIterable` (async generator), the `_create_response` method wraps this generator in `EventSourceResponse`. An inner async generator formats each yielded item (expected to be a pre-formatted JSONRPCResponse object) into the required SSE `{\"data\": ...}` structure before sending it to the client.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/07_streaming_communication__sse_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: samples/python/common/server/server.py (Simplified Snippet _create_response)\nfrom sse_starlette.sse import EventSourceResponse\nfrom typing import AsyncIterable\n\n# ... inside _process_request ...\nresult = await self.task_manager.on_send_task_subscribe(json_rpc_request)\nreturn self._create_response(result) # Pass the generator to _create_response\n\n# ... inside A2AServer ...\ndef _create_response(self, result: Any) -> JSONResponse | EventSourceResponse:\n    if isinstance(result, AsyncIterable):\n        # If the handler returned an async generator...\n\n        async def event_generator(generator_result) -> AsyncIterable[dict[str, str]]:\n            # Wrap the generator to format SSE messages\n            async for item in generator_result:\n                # item is expected to be a JSONRPCResponse containing the event payload\n                yield {\"data\": item.model_dump_json(exclude_none=True)}\n\n        # Use EventSourceResponse to handle the streaming\n        return EventSourceResponse(event_generator(result))\n    # ... (handle non-streaming JSONResponse) ...\n```\n\n----------------------------------------\n\nTITLE: Testing Pydantic Validation with Valid and Invalid Message Data\nDESCRIPTION: This snippet demonstrates how Pydantic validation works in practice by attempting to create SimpleMessage instances with both valid and invalid data. It shows how Pydantic automatically catches errors like missing required fields before they can cause problems elsewhere in the code.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- Valid Data ---\ntry:\n    msg1 = SimpleMessage(role=\"user\", content=\"Hello there!\")\n    print(\"msg1 created successfully:\", msg1.model_dump()) # .model_dump() shows dict\nexcept ValidationError as e:\n    print(\"Error creating msg1:\", e)\n\n# --- Missing Required Field ('content') ---\ntry:\n    msg2 = SimpleMessage(role=\"assistant\")\n    print(\"msg2 created successfully:\", msg2.model_dump())\nexcept ValidationError as e:\n    print(\"\\nError creating msg2:\")\n    print(e) # Pydantic gives a detailed error\n```\n\n----------------------------------------\n\nTITLE: Basic Click Application with Type Validation\nDESCRIPTION: A simple Click command-line application that demonstrates automatic type validation. This example includes a command with an integer option and a required message argument, showing how Click's built-in type validation works.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# count_app.py (from Chapter 4)\nimport click\n\n@click.command()\n@click.option('--count', default=1, type=click.INT, help='Number of times to print.')\n@click.argument('message')\ndef repeat(count, message):\n  \"\"\"Prints MESSAGE the specified number of times.\"\"\"\n  for _ in range(count):\n    click.echo(message)\n\nif __name__ == '__main__':\n  repeat()\n```\n\n----------------------------------------\n\nTITLE: Using the AsyncHTTPCrawlerStrategy Explicitly\nDESCRIPTION: Example code demonstrating how to explicitly select and use the AsyncHTTPCrawlerStrategy for faster, simpler webpage fetching without JavaScript execution. This is suitable for simple static websites.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# http_strategy_example.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n# Import the specific strategies we want to use\nfrom crawl4ai.async_crawler_strategy import AsyncHTTPCrawlerStrategy\n\nasync def main():\n    # 1. Create an instance of the strategy you want\n    http_strategy = AsyncHTTPCrawlerStrategy()\n\n    # 2. Pass the strategy instance when creating the AsyncWebCrawler\n    async with AsyncWebCrawler(crawler_strategy=http_strategy) as crawler:\n        print(\"Crawler is ready using the explicit HTTP strategy.\")\n\n        # Crawl the same simple page\n        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n        result = await crawler.arun(\n            url=\"https://httpbin.org/html\",\n            config=config\n        )\n\n        if result.success:\n            print(\"\\nSuccessfully fetched content using HTTP strategy!\")\n            print(f\"First 100 chars of fetched HTML: {result.html[:100]}...\")\n        else:\n            print(f\"\\nFailed to fetch content: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Working with Field Aliases in Pydantic\nDESCRIPTION: Shows how to use field aliases to map between different naming conventions in input data and your model, with serialization examples.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from above...\n\n# Input data using the alias 'userName'\ninput_data_2 = {'userName': 'Alice', 'age': 30}\n\n# Pydantic correctly uses the alias to populate 'name'\nuser2 = User(**input_data_2)\nprint(user2)\n# Expected Output: name='Alice' age=30 email=None\n\n# Dumping the model back, using the alias\nprint(user2.model_dump(by_alias=True))\n# Expected Output: {'userName': 'Alice', 'age': 30, 'email': None}\n\n# Dumping without by_alias uses the actual field names\nprint(user2.model_dump())\n# Expected Output: {'name': 'Alice', 'age': 30, 'email': None}\n```\n\n----------------------------------------\n\nTITLE: Defining FastMCP Server with Ping Tool in Python\nDESCRIPTION: This snippet creates a FastMCP server named 'TestServer' with a simple 'ping' tool that returns 'pong'. It demonstrates the basic structure of defining an MCP server and a tool function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/09_communication_transports__stdio__sse__websocket__memory_.md#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ntest_server = FastMCP(name=\"TestServer\")\n@test_server.tool()\ndef ping() -> str:\n    return \"pong\"\n```\n\n----------------------------------------\n\nTITLE: Testing Memory Transport for MCP Client-Server Communication in Python\nDESCRIPTION: This asynchronous test function demonstrates the use of memory streams for client-server communication in an MCP implementation. It creates memory streams, runs the server and client concurrently, and tests the 'ping' tool functionality.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/09_communication_transports__stdio__sse__websocket__memory_.md#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n@pytest.mark.anyio # Mark test to be run with anyio\nasync def test_memory_transport():\n    # 1. Use the memory stream generator\n    async with create_client_server_memory_streams() as (\n        (client_read, client_write), # Client perspective\n        (server_read, server_write)  # Server perspective\n    ):\n        print(\"Test: Memory streams created.\")\n        # Run server and client concurrently\n        async with anyio.create_task_group() as tg:\n            # 2. Start the server using its streams\n            tg.start_soon(\n                test_server.run, server_read, server_write,\n                test_server.create_initialization_options()\n            )\n            print(\"Test: Server started in background task.\")\n\n            # 3. Create and run client using its streams\n            async with ClientSession(client_read, client_write) as client:\n                print(\"Test: Client session created. Initializing...\")\n                await client.initialize()\n                print(\"Test: Client initialized. Calling 'ping' tool...\")\n                result = await client.call_tool(\"ping\")\n                print(f\"Test: Client received result: {result}\")\n                # Assert the result is correct\n                assert result.content[0].text == \"pong\"\n\n            # Cancel server task when client is done (optional)\n            tg.cancel_scope.cancel()\n        print(\"Test: Finished.\")\n```\n\n----------------------------------------\n\nTITLE: Running a FastAPI Application with Uvicorn - Bash\nDESCRIPTION: This Bash snippet demonstrates how to start a FastAPI application using the Uvicorn ASGI server with auto-reload enabled, making development easier. The command expects that FastAPI and Uvicorn are installed in the Python environment and that the Python source file is named `main.py` with an ASGI app called `app`. The command launches the API for local development at http://127.0.0.1:8000/ with live code reload.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/04_openapi___automatic_docs.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuvicorn main:app --reload\n```\n\n----------------------------------------\n\nTITLE: Managing Agent Instantiation Context in Python\nDESCRIPTION: This Python code defines the `AgentInstantiationContext` class using `contextvars`. It provides a mechanism for the `AgentRuntime` to temporarily store and retrieve its own instance and the target `AgentId` during the agent creation process within a factory function. This ensures agents are initialized with the correct runtime context. It depends on the `contextvars` module and assumes `AgentRuntime` and `AgentId` types are defined elsewhere (likely within AutoGen Core).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# From: _agent_instantiation.py (Simplified)\nclass AgentInstantiationContext:\n    _CONTEXT_VAR = ContextVar(\"agent_context\") # Stores (runtime, agent_id)\n\n    @classmethod\n    @contextmanager\n    def populate_context(cls, ctx: tuple[AgentRuntime, AgentId]):\n        token = cls._CONTEXT_VAR.set(ctx) # Store context for this block\n        try:\n            yield # Code inside the 'with' block runs here\n        finally:\n            cls._CONTEXT_VAR.reset(token) # Clean up context\n\n    @classmethod\n    def current_runtime(cls) -> AgentRuntime:\n        return cls._CONTEXT_VAR.get()[0] # Retrieve runtime from context\n\n    @classmethod\n    def current_agent_id(cls) -> AgentId:\n        return cls._CONTEXT_VAR.get()[1] # Retrieve agent_id from context\n```\n\n----------------------------------------\n\nTITLE: Initializing Agent Class in Python\nDESCRIPTION: The __init__ method of the Agent class, setting up internal state, task, LLM, controller, and message manager. It prepares the agent for task execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/01_agent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Agent:\n    def __init__(\n        self,\n        task: str,\n        llm: BaseChatModel,\n        browser_context: BrowserContext,\n        controller: Controller,\n        # ... other settings like use_vision, max_failures, etc.\n        **kwargs\n    ):\n        self.task = task\n        self.llm = llm\n        self.browser_context = browser_context\n        self.controller = controller\n        self.settings = AgentSettings(**kwargs) # Store various settings\n        self.state = AgentState() # Internal state (step count, failures, etc.)\n\n        # Setup message manager for history, using the task and system prompt\n        self._message_manager = MessageManager(\n            task=self.task,\n            system_message=self.settings.system_prompt_class(...).get_system_message(),\n            settings=MessageManagerSettings(...)\n            # ... more setup ...\n        )\n        # ... other initializations ...\n        logger.info(\"Agent initialized.\")\n```\n\n----------------------------------------\n\nTITLE: Simplified Implementation of DSPy Signature and Field Classes in Python\nDESCRIPTION: Shows a simplified internal implementation of DSPy's Signature, SignatureMeta, InputField, and OutputField classes. SignatureMeta is a metaclass that processes fields and the class docstring, enabling extraction of instructions and input/output fields. InputField and OutputField factory functions use pydantic.Field and embed meta-information on the type. Dependencies: pydantic and Python 3. This snippet is illustrative and omits error checking and advanced logic from the actual DSPy source code.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/02_signature.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view inside dspy/signatures/signature.py\nfrom pydantic import BaseModel\nfrom pydantic.fields import FieldInfo\n# ... other imports ...\n\nclass SignatureMeta(type(BaseModel)):\n    # Metaclass magic to handle fields and docstring\n    def __new__(mcs, name, bases, namespace, **kwargs):\n        # ... logic to find fields, handle docstring ...\n        cls = super().__new__(mcs, name, bases, namespace, **kwargs)\n        cls.__doc__ = cls.__doc__ or _default_instructions(cls) # Default instructions if none provided\n        # ... logic to validate fields ...\n        return cls\n\n    @property\n    def instructions(cls) -> str:\n        # Retrieves the docstring as instructions\n        return inspect.cleandoc(getattr(cls, \"__doc__\", \"\"))\n\n    @property\n    def input_fields(cls) -> dict[str, FieldInfo]:\n        # Finds fields marked as input\n        return cls._get_fields_with_type(\"input\")\n\n    @property\n    def output_fields(cls) -> dict[str, FieldInfo]:\n        # Finds fields marked as output\n        return cls._get_fields_with_type(\"output\")\n\nclass Signature(BaseModel, metaclass=SignatureMeta):\n    # The base class you inherit from\n    pass\n\n# Simplified view inside dspy/signatures/field.py\nimport pydantic\n\ndef InputField(**kwargs):\n    # Creates a Pydantic field marked as input for DSPy\n    return pydantic.Field(**move_kwargs(**kwargs, __dspy_field_type=\"input\"))\n\ndef OutputField(**kwargs):\n    # Creates a Pydantic field marked as output for DSPy\n    return pydantic.Field(**move_kwargs(**kwargs, __dspy_field_type=\"output\"))\n\n```\n\n----------------------------------------\n\nTITLE: Validating Individual Fields with @field_validator in Python\nDESCRIPTION: Demonstrates how to use the @field_validator decorator to add custom validation logic for a specific field in a Pydantic model. The example checks if a username contains spaces.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, field_validator, ValidationError\n\nclass UserRegistration(BaseModel):\n    username: str\n    email: str\n\n    # This method will be called automatically for the 'username' field\n    # AFTER Pydantic checks it's a string.\n    @field_validator('username')\n    @classmethod # Field validators should usually be class methods\n    def check_username_spaces(cls, v: str) -> str:\n        print(f\"Checking username: '{v}'\")\n        if ' ' in v:\n            # Raise a ValueError if the rule is broken\n            raise ValueError('Username cannot contain spaces')\n        # Return the valid value (can also modify it here if needed)\n        return v\n\n# --- Try it out ---\n\n# Valid username\nuser_ok = UserRegistration(username='cool_cat123', email='cat@meow.com')\nprint(f\"Valid user created: {user_ok}\")\n# Expected Output:\n# Checking username: 'cool_cat123'\n# Valid user created: username='cool_cat123' email='cat@meow.com'\n\n# Invalid username\ntry:\n    UserRegistration(username='cool cat 123', email='cat@meow.com')\nexcept ValidationError as e:\n    print(f\"\\nValidation Error:\\n{e}\")\n    # Expected Output (simplified):\n    # Checking username: 'cool cat 123'\n    # Validation Error:\n    # 1 validation error for UserRegistration\n    # username\n    #   Value error, Username cannot contain spaces [type=value_error, ...]\n```\n\n----------------------------------------\n\nTITLE: Initializing A2AServer with TaskManager in Python\nDESCRIPTION: Code snippet showing how to initialize an A2AServer by providing a custom GreeterTaskManager. This demonstrates the pattern of connecting task handling logic to the server in Python implementations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/06_task_handling_logic__server_side_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# server = A2AServer(task_manager=GreeterTaskManager(), ...)\n```\n\n----------------------------------------\n\nTITLE: HTTP Request Sending Implementation in Python\nDESCRIPTION: Implements the core send() method that handles the actual HTTP request transmission using urllib3, including timeout configuration, SSL verification, and exception handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \"\"\"Sends PreparedRequest object using urllib3.\"\"\"\n        # ... determine connection pool (conn) based on URL, proxies, SSL context ...\n        conn = self.get_connection_with_tls_context(request, verify, proxies=proxies, cert=cert)\n        # ... determine URL to use (might be different for proxies) ...\n        url = self.request_url(request, proxies)\n        # ... configure timeout object for urllib3 ...\n        timeout_obj = self._build_timeout(timeout)\n\n        try:\n            # === CALL URLIB3 ===\n            # This is the core network call\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False, # Requests handles redirects\n                assert_same_host=False,\n                preload_content=False, # Requests streams content\n                decode_content=False, # Requests handles decoding\n                retries=self.max_retries, # Pass configured retries\n                timeout=timeout_obj,     # Pass configured timeout\n                chunked=... # Determine if chunked encoding is needed\n            )\n\n        except (urllib3_exceptions...) as err:\n            # === WRAP URLIB3 EXCEPTIONS ===\n            # Catch exceptions from urllib3 and raise corresponding\n            # requests.exceptions (ConnectionError, Timeout, SSLError, etc.)\n            # See Chapter 6 for details.\n            raise MappedRequestsException(err, request=request)\n\n        # === BUILD RESPONSE OBJECT ===\n        # Convert the raw urllib3 response into a requests.Response\n        response = self.build_response(request, resp)\n\n        return response\n```\n\n----------------------------------------\n\nTITLE: Visualizing CrewAI Components and Relationships with Mermaid Flowchart\nDESCRIPTION: This Mermaid flowchart diagram illustrates the relationships between key components of CrewAI, including Agents, Tasks, Crews, Tools, Processes, LLMs, Memory, and Knowledge. It shows how Crews manage Agents and orchestrate Tasks, and how Agents execute Tasks using various resources.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Agent\"]\n    A1[\"Task\"]\n    A2[\"Crew\"]\n    A3[\"Tool\"]\n    A4[\"Process\"]\n    A5[\"LLM\"]\n    A6[\"Memory\"]\n    A7[\"Knowledge\"]\n    A2 -- \"Manages\" --> A0\n    A2 -- \"Orchestrates\" --> A1\n    A2 -- \"Defines workflow\" --> A4\n    A2 -- \"Manages shared\" --> A6\n    A0 -- \"Executes\" --> A1\n    A0 -- \"Uses\" --> A3\n    A0 -- \"Uses as brain\" --> A5\n    A0 -- \"Queries\" --> A7\n    A1 -- \"Assigned to\" --> A0\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Architecture with Mermaid Diagram\nDESCRIPTION: A flowchart diagram illustrating the relationships between Celery's core components. It shows how the Celery App connects to Tasks, Workers, Broker Connections, Result Backends, Canvas, Beat Scheduler, Configuration, Events, and Bootsteps, and how these components interact with each other.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Celery App\"]\n    A1[\"Task\"]\n    A2[\"Worker\"]\n    A3[\"Broker Connection (AMQP)\"]\n    A4[\"Result Backend\"]\n    A5[\"Canvas (Signatures & Primitives)\"]\n    A6[\"Beat (Scheduler)\"]\n    A7[\"Configuration\"]\n    A8[\"Events\"]\n    A9[\"Bootsteps\"]\n    A0 -- \"Defines and sends\" --> A1\n    A0 -- \"Uses for messaging\" --> A3\n    A0 -- \"Uses for results\" --> A4\n    A0 -- \"Loads and uses\" --> A7\n    A1 -- \"Updates state in\" --> A4\n    A2 -- \"Executes\" --> A1\n    A2 -- \"Fetches tasks from\" --> A3\n    A2 -- \"Uses for lifecycle\" --> A9\n    A5 -- \"Represents task invocation\" --> A1\n    A6 -- \"Sends scheduled tasks via\" --> A3\n    A8 -- \"Sends events via\" --> A3\n    A9 -- \"Manages connection via\" --> A3\n```\n\n----------------------------------------\n\nTITLE: Assembling and Executing a Trip Planning Crew in Python\nDESCRIPTION: This snippet shows how to create a Crew instance with the defined agents and tasks, set the process to sequential, and kickoff the Crew's work. It also includes code to print the final result.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/01_crew.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Create the Crew\ntrip_crew = Crew(\n  agents=[researcher, planner],\n  tasks=[task1, task2],\n  process=Process.sequential # Tasks will run one after another\n  # verbose=2 # Optional: Sets verbosity level for the crew execution\n)\n\n# Start the Crew's work!\nresult = trip_crew.kickoff()\n\nprint(\"\\n\\n########################\")\nprint(\"## Here is the result\")\nprint(\"########################\\n\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Illustrating Agent-Tool-LLM Workflow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid code snippet visually depicts the agent's operational workflow in the Think-Act-Observe cycle, emphasizing how the MultiStepAgent interacts with an LLM and a tool (e.g., GreetingTool). The sequence covers sending tasks to the LLM, executing tool methods, observing results, and reporting to the user. It is intended to provide process visibility and is formatted for Mermaid-compatible visual renderers. Inputs: Agent's tasks and tool availability. Outputs: Sequence diagram for documentation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent as MultiStepAgent\n    participant LLM as LLM Brain\n    participant GreetTool as GreetingTool\n\n    Agent->>LLM: Task: Greet Bob. Tools: [greet_person]. What next?\n    LLM-->>Agent: Use tool 'greet_person' with name='Bob'\n    Agent->>GreetTool: forward(name=\"Bob\")\n    GreetTool-->>Agent: \"Hello, Bob! Nice to meet you.\" (Observation)\n    Agent->>LLM: Observation: \"Hello, Bob!...\" Task done?\n    LLM-->>Agent: Use tool 'final_answer' with \"Hello, Bob!...\"\n    Agent-->>User: \"Hello, Bob! Nice to meet you.\"\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Broker URL\nDESCRIPTION: Example configuration showing how to set up broker URLs for different message brokers (RabbitMQ and Redis) in celeryconfig.py\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/04_broker_connection__amqp_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nbroker_url = 'amqp://guest:guest@localhost:5672//' # Example for RabbitMQ\n# Or maybe: broker_url = 'redis://localhost:6379/0' # Example for Redis\n```\n\n----------------------------------------\n\nTITLE: Executing the Conditional LangGraph in Python\nDESCRIPTION: Demonstrates how to run the compiled LangGraph application (`app`). It invokes the graph twice with different `user_query` inputs to show the conditional logic in action. The first input triggers the search tool path, while the second triggers the direct response path. The final state for each scenario is printed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Scenario 1: Query needs the tool\nprint(\"--- Scenario 1: Weather Query ---\")\ninput1 = {\"user_query\": \"What's the weather like?\"}\nfinal_state1 = app.invoke(input1)\nprint(\"Final State 1:\", final_state1)\n\nprint(\"\\n--- Scenario 2: Direct Response ---\")\n# Scenario 2: Query doesn't need the tool\ninput2 = {\"user_query\": \"Tell me a joke.\"}\nfinal_state2 = app.invoke(input2)\nprint(\"Final State 2:\", final_state2)\n```\n\n----------------------------------------\n\nTITLE: Focusing on Specific Page Content with CSS Selectors\nDESCRIPTION: Shows how to use CrawlerRunConfig with CSS selectors to extract only specific portions of a webpage and set custom timeouts for the crawling operation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# chapter3_example_3.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\n\nasync def main():\n    # This example site has a heading 'H1' inside a 'body' tag.\n    url_to_crawl = \"https://httpbin.org/html\"\n    async with AsyncWebCrawler() as crawler:\n        print(f\"Crawling {url_to_crawl}, focusing on the H1 tag...\")\n\n        # Instructions: Only get the H1 tag, wait max 10s for it\n        specific_config = CrawlerRunConfig(\n            css_selector=\"h1\", # Only grab content inside <h1> tags\n            page_timeout=10000 # Set page timeout to 10 seconds\n            # We could also add wait_for=\"h1\" if needed for dynamic loading\n        )\n\n        result = await crawler.arun(url=url_to_crawl, config=specific_config)\n\n        if result.success:\n            print(\"\\nSuccess! Focused crawl completed.\")\n            # The markdown should now ONLY contain the H1 content\n            print(f\"Markdown content:\\n---\\n{result.markdown.raw_markdown.strip()}\\n---\")\n        else:\n            print(f\"\\nFailed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining a Task with Celery App Decorator in Python\nDESCRIPTION: Shows how to define a task using the @app.task decorator. This example creates a simple addition task that simulates work with a sleep function and prints debug information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/01_celery_app.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\nimport time\n\n# Create a Celery app instance\napp = Celery('tasks',\n             broker='redis://localhost:6379/0',\n             backend='redis://localhost:6379/0')\n\n# Define a simple task using the app's decorator\n@app.task\ndef add(x, y):\n    print(f\"Task 'add' started with args: ({x}, {y})\")\n    time.sleep(2) # Simulate some work\n    result = x + y\n    print(f\"Task 'add' finished with result: {result}\")\n    return result\n\nprint(f\"Task 'add' is registered: {app.tasks.get('celery_app.add')}\")\n```\n\n----------------------------------------\n\nTITLE: LastValue Channel Usage Example\nDESCRIPTION: Example showing how to implicitly use LastValue channel in a TypedDict state definition.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict\n\nclass MyState(TypedDict):\n     value: int\n     user_query: str\n```\n\n----------------------------------------\n\nTITLE: Visualizing Message Flow with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram showing the conceptual flow of a published message through the AutoGen Core system, from Publisher Agent through the AgentRuntime and Subscription Registry to Subscriber Agent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Publisher as Publisher Agent\n    participant Runtime as AgentRuntime\n    participant SubRegistry as Subscription Registry\n    participant Subscriber as Subscriber Agent\n\n    Publisher->>+Runtime: publish_message(message, topic_id)\n    Runtime->>+SubRegistry: Find subscriptions matching topic_id\n    SubRegistry-->>-Runtime: Return list of matching Subscriptions\n    loop For each matching Subscription\n        Runtime->>Subscription: map_to_agent(topic_id)\n        Subscription-->>Runtime: Return target AgentId\n        Runtime->>+Subscriber: Locate/Create Agent instance by AgentId\n        Runtime->>Subscriber: on_message(message, context)\n        Subscriber-->>-Runtime: Process message (optional return)\n    end\n    Runtime-->>-Publisher: Return (usually None for publish)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Server-Handler Interaction with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram illustrating the interaction flow between an A2A client, server, task handler, optional AI tools, and the task store. Shows the complete lifecycle of a streaming task request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/06_task_handling_logic__server_side_.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as A2A Client\n    participant S as A2A Server\n    participant TH as Task Handler (e.g., greeterAgentHandler)\n    participant AI as AI Model/Tool (Optional)\n    participant TS as Task Store\n\n    C->>S: POST / (JSON-RPC: method=\"tasks/sendSubscribe\", params={...})\n    Note right of S: Receives request, parses JSON-RPC\n\n    S->>TS: Create/Get Task Record (ID: task-123)\n    TS-->>S: Task Object (state: submitted)\n\n    S->>TH: Invoke handler(context) / Call on_send_task_subscribe()\n    Note right of TH: Handler starts executing\n\n    TH->>TS: Update Task (state: working)\n    TH-->>S: yield {state: \"working\", ...} / yield TaskStatusUpdateEvent(working)\n    Note right of S: Receives yielded update\n\n    S-->>C: Send SSE Event (data: TaskStatusUpdateEvent - working)\n    Note left of C: Client receives 'working' status\n\n    alt Handler needs AI/Tool\n        TH->>AI: Request generation(\"greet user\")\n        AI-->>TH: Response (\"Hello there!\")\n    end\n\n    TH->>TS: Update Task (state: completed, message: \"Hello...\")\n    TH-->>S: yield {state: \"completed\", ...} / yield TaskStatusUpdateEvent(completed, final=True)\n    Note right of S: Receives final yielded update\n\n    S-->>C: Send SSE Event (data: TaskStatusUpdateEvent - completed, final=True)\n    Note left of C: Client receives 'completed' status, stream ends\n```\n\n----------------------------------------\n\nTITLE: Visualizing Hierarchical Module Structure using Mermaid\nDESCRIPTION: Provides a Mermaid graph definition to visualize the hierarchical composition of DSPy modules. It shows a top-level `RAG Program` containing several modules (`GenerateSearchQuery`, `RetrieveContext`, `GenerateAnswer`), illustrating how a program coordinates sub-modules. It further depicts `GenerateAnswer` as potentially containing its own sub-modules (`SummarizeContext`, `DraftAnswer`, `RefineAnswer`), demonstrating the concept of nested module structures for building complex systems.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/01_module___program.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    A[RAG Program] --> B(GenerateSearchQuery Module);\n    A --> C(RetrieveContext Module);\n    A --> D(GenerateAnswer Module / Program);\n    D --> D1(SummarizeContext Module);\n    D --> D2(DraftAnswer Module);\n    D --> D3(RefineAnswer Module);\n```\n\n----------------------------------------\n\nTITLE: Executing Tasks with Knowledge Augmentation - CrewAI Agent Class (Python)\nDESCRIPTION: This Python snippet from crewai/agent.py depicts how the Agent class injects knowledge snippets into prompts before invoking the LLM. If the agent has knowledge assigned, it queries the knowledgebase with the current task prompt, formats the retrieved context, and appends it for the model's input. It depends on the Knowledge system, field management via Pydantic, and the agent_executor interface. Inputs include the current Task; outputs are augmented prompt and LLM result. Requires well-configured knowledge and extraction logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/08_knowledge.md#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Simplified view from crewai/agent.py\\nclass Agent(BaseAgent):\\n    knowledge: Optional[Knowledge] = Field(default=None, ...)\\n    # ... other fields ...\\n\\n    def execute_task(self, task: Task, context: Optional[str] = None, ...) -> str:\\n        task_prompt = task.prompt()\\n        # ... add memory context if applicable ...\\n\\n        # === KNOWLEDGE RETRIEVAL ===\\n        if self.knowledge:\\n            # Query the knowledge base using the task prompt\\n            agent_knowledge_snippets = self.knowledge.query([task_prompt]) # Or task.description\\n            if agent_knowledge_snippets:\\n                # Format the snippets into context string\\n                agent_knowledge_context = extract_knowledge_context(agent_knowledge_snippets)\\n                if agent_knowledge_context:\\n                    # Add knowledge context to the prompt\\n                    task_prompt += agent_knowledge_context\\n        # ===========================\\n\\n        # ... add crew knowledge context if applicable ...\\n        # ... prepare tools, create agent_executor ...\\n\\n        # Call the LLM via agent_executor with the augmented task_prompt\\n        result = self.agent_executor.invoke({\"input\": task_prompt, ...})[\"output\"]\\n        return result\n```\n\n----------------------------------------\n\nTITLE: Manipulating requests.cookies.RequestsCookieJar like a Dictionary in Python\nDESCRIPTION: This snippet demonstrates how to interact with a `requests.cookies.RequestsCookieJar` object using dictionary-like syntax. It creates an instance of `RequestsCookieJar`, adds cookies using both the `.set()` method (specifying domain and path) and direct dictionary assignment (`jar['key'] = 'value'`). It then retrieves cookies using dictionary key access (`jar['key']`) and the `.get()` method (with a default value), iterates through the cookies using `.items()`, and removes a cookie using the `del` keyword. This highlights the convenience of the dictionary interface for managing cookies.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\njar = requests.cookies.RequestsCookieJar()\n\n# Set cookies using dictionary-like assignment or set()\njar.set('username', 'Nate', domain='httpbin.org', path='/')\njar['session_id'] = 'abcdef123' # Sets for default domain/path ('')\n\nprint(f\"Jar contents: {jar.get_dict()}\")\n\n# Get cookies using dictionary-like access or get()\nprint(f\"Username: {jar['username']}\")\nprint(f\"Session ID: {jar.get('session_id')}\")\nprint(f\"API Key (default None): {jar.get('api_key', default='NoKey')}\")\n\n# Iterate over cookies\nprint(\"\\nIterating:\")\nfor name, value in jar.items():\n    print(f\" - {name}: {value}\")\n\n# Delete a cookie\ndel jar['session_id']\nprint(f\"\\nJar after deleting session_id: {jar.get_dict()}\")\n```\n\n----------------------------------------\n\nTITLE: Authenticating Requests Using Basic Auth Tuple with Requests (Python)\nDESCRIPTION: Demonstrates how to perform HTTP Basic Authentication by passing a tuple (username, password) to the auth parameter in the requests.get() function. Requires the 'requests' library. This snippet first makes a request without authentication (expecting a 401 response), followed by an authenticated request which includes the credentials and expects a 200 response along with JSON output confirming authentication. Proper exception handling for network errors is included.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# This URL requires Basic Auth with user='testuser', pass='testpass'\nurl = 'https://httpbin.org/basic-auth/testuser/testpass'\n\n# Try without authentication first (should fail with 401 Unauthorized)\nprint(\"Attempting without authentication...\")\nresponse_fail = requests.get(url)\nprint(f\"Status Code (fail): {response_fail.status_code}\") # Expect 401\n\n# Now, provide the username and password tuple to the 'auth' parameter\nprint(\"\\nAttempting with Basic Auth tuple...\")\ntry:\n    response_ok = requests.get(url, auth=('testuser', 'testpass'))\n    print(f\"Status Code (ok): {response_ok.status_code}\") # Expect 200\n    # Check the response content (httpbin echoes auth info)\n    print(\"Response JSON:\")\n    print(response_ok.json())\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred: {e}\")\n\n```\n\n----------------------------------------\n\nTITLE: Content Filtering Implementation in DefaultMarkdownGenerator\nDESCRIPTION: This code snippet shows a simplified version of the DefaultMarkdownGenerator implementation from the crawl4ai library, focusing on how content filters are integrated. It demonstrates the internal logic for generating both raw markdown and filtered (fit) markdown using the provided content filter.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from markdown_generation_strategy.py\nfrom .models import MarkdownGenerationResult\nfrom .html2text import CustomHTML2Text\nfrom .content_filter_strategy import RelevantContentFilter # Import filter base class\n\nclass DefaultMarkdownGenerator(MarkdownGenerationStrategy):\n    # ... __init__ stores self.content_filter ...\n\n    def generate_markdown(\n        self,\n        cleaned_html: str,\n        # ... other params like base_url, options ...\n        content_filter: Optional[RelevantContentFilter] = None,\n        **kwargs,\n    ) -> MarkdownGenerationResult:\n\n        h = CustomHTML2Text(...) # Setup html2text converter\n        # ... apply options ...\n\n        # 1. Generate raw markdown from the full cleaned_html\n        raw_markdown = h.handle(cleaned_html)\n        # ... post-process raw_markdown ...\n\n        # 2. Convert links to citations (if enabled)\n        markdown_with_citations, references_markdown = self.convert_links_to_citations(...)\n\n        # 3. Generate fit markdown IF a filter is available\n        fit_markdown = \"\"\n        filtered_html = \"\"\n        # Use the filter passed directly, or the one stored during initialization\n        active_filter = content_filter or self.content_filter\n        if active_filter:\n            try:\n                # Call the filter's main method\n                filtered_html_fragments = active_filter.filter_content(cleaned_html)\n                # Join fragments (assuming filter returns list of HTML strings)\n                filtered_html = \"\\n\".join(filtered_html_fragments)\n                # Convert ONLY the filtered HTML to markdown\n                fit_markdown = h.handle(filtered_html)\n            except Exception as e:\n                fit_markdown = f\"Error during filtering: {e}\"\n                # Log error...\n\n        return MarkdownGenerationResult(\n            raw_markdown=raw_markdown,\n            markdown_with_citations=markdown_with_citations,\n            references_markdown=references_markdown,\n            fit_markdown=fit_markdown, # Contains the filtered result\n            fit_html=filtered_html,     # The HTML fragments kept by the filter\n        )\n```\n\n----------------------------------------\n\nTITLE: Defining a Crew with a Hierarchical Process in Python\nDESCRIPTION: Shows how to set up a CrewAI `Crew` for hierarchical task execution using Python. It defines worker agents and tasks, sets the `process` to `Process.hierarchical`, and specifies a `manager_llm` (e.g., `ChatOpenAI`) which CrewAI uses to create an internal manager agent. This manager agent then orchestrates the worker agents to complete the given tasks dynamically.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Assuming 'researcher' and 'planner' agents are defined\n# Assuming 'task1' and 'task2' are defined (WITHOUT necessarily assigning agents initially)\n# You need an LLM configured (e.g., from OpenAI, Ollama - see Chapter 6)\n# from langchain_openai import ChatOpenAI # Example LLM\n\nfrom crewai import Crew, Process, Task\n\n# Example tasks (agent assignment might be handled by the manager)\ntask1 = Task(description='Find top 3 European cities for a sunny May birthday trip.', expected_output='List of 3 cities with justifications.')\ntask2 = Task(description='Create a 3-day itinerary for the best city found.', expected_output='Detailed 3-day plan.')\n\n# Define the crew with a hierarchical process and a manager LLM\nhierarchical_crew = Crew(\n  agents=[researcher, planner], # The worker agents\n  tasks=[task1, task2], # The tasks to be managed\n  process=Process.hierarchical, # Set the process to hierarchical\n  manager_llm=ChatOpenAI(model=\"gpt-4\") # Specify the LLM for the manager agent\n  # You could also provide a pre-configured manager_agent instance instead of manager_llm\n)\n\n# Start the work\n# result = hierarchical_crew.kickoff()\n# print(result)\n```\n\n----------------------------------------\n\nTITLE: Collecting User Input with click.prompt()\nDESCRIPTION: Demonstrates how to interactively gather user input with type validation using Click's prompt() function, including examples with default values and type conversion for integers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# prompt_example.py\nimport click\n\n@click.command()\ndef cli():\n  \"\"\"Asks for user input\"\"\"\n  name = click.prompt(\"Please enter your name\")\n  click.echo(f\"Hello, {name}!\")\n\n  # You can specify a default value\n  location = click.prompt(\"Enter location\", default=\"Earth\")\n  click.echo(f\"Location: {location}\")\n\n  # You can also require a specific type (like an integer)\n  age = click.prompt(\"Enter your age\", type=int)\n  click.echo(f\"You are {age} years old.\")\n\nif __name__ == '__main__':\n  cli()\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ python prompt_example.py\nPlease enter your name: Alice\nHello, Alice!\nEnter location [Earth]: # Just press Enter here\nLocation: Earth\nEnter your age: 30\nYou are 30 years old.\n```\n\n----------------------------------------\n\nTITLE: Capturing Multi-line Terminal Chat Input with Ink in TypeScript\nDESCRIPTION: This TypeScript React component, using Ink, provides a multi-line text editor for terminal chat input. It encapsulates state management for user-entered text, exposes callbacks for submission via Enter, and utilizes a ref to control the editor programmatically (e.g., for command history navigation). The input box uses a custom MultilineTextEditor, styled with Ink's Box, and displays helper instructions; dependencies include Ink, react, and ink-text-input or a custom editor. The component accepts props such as 'submitInput' for handling submitted input, and is designed to be swapped out for command review when required.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-chat-new-input.tsx (Simplified)\n\n// ... imports ...\nimport MultilineTextEditor from \"./multiline-editor\"; // Custom multiline input\nimport { Box, Text, useInput } from \"ink\";\nimport React, { useState } from \"react\";\n\nexport default function TerminalChatInput({ submitInput, active, /* ... */ }): React.ReactElement {\n  const [input, setInput] = useState(\"\"); // Current text in the editor\n  const editorRef = React.useRef(/* ... */); // Handle to editor\n\n  // useInput hook from Ink handles key presses (like Up/Down for history)\n  useInput((_input, _key) => {\n     // Handle history navigation (Up/Down arrows)\n     // ... logic using editorRef.current.getRow() ...\n  }, { isActive: active });\n\n  return (\n    <Box flexDirection=\"column\">\n      <Box borderStyle=\"round\">\n        {/* The actual input field */}\n        <MultilineTextEditor\n          ref={editorRef}\n          onChange={(txt: string) => setInput(txt)}\n          initialText={input}\n          focus={active} // Only active when overlay isn't shown\n          onSubmit={(text) => {\n            // When Enter is pressed (and not escaped)\n            submitInput(/* ...create input item from text... */);\n            setInput(\"\"); // Clear the input field\n          }}\n        />\n      </Box>\n      {/* Help text */}\n      <Text dimColor>ctrl+c to exit | enter to send</Text>\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Applying HeadAndTailChatCompletionContext in AutoGen Core using Python\nDESCRIPTION: This snippet illustrates the use of HeadAndTailChatCompletionContext, which keeps the first and last few messages of the conversation. It's configured to keep the first message and the last two messages, skipping the middle part of the conversation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# File: use_head_tail_context.py\nimport asyncio\nfrom define_chat_messages import full_history\nfrom autogen_core.model_context import HeadAndTailChatCompletionContext\n\nasync def main():\n    # Keep first 1 and last 2 messages\n    context = HeadAndTailChatCompletionContext(head_size=1, tail_size=2)\n    for msg in full_history:\n        await context.add_message(msg)\n\n    messages_for_llm = await context.get_messages()\n\n    print(f\"--- Head & Tail Context (h=1, t=2, {len(messages_for_llm)} messages) ---\")\n    for i, msg in enumerate(messages_for_llm):\n        print(f\"{i+1}. [{msg.type}]: {msg.content[:30]}...\")\n\n# asyncio.run(main()) # If run\n```\n\n----------------------------------------\n\nTITLE: Instantiating and Running dspy.Evaluate in Python\nDESCRIPTION: This snippet shows how to use `dspy.Evaluate` to assess a DSPy program. It first imports `Evaluate`, then creates an instance providing the development set (`devset`) and the metric function (`simple_exact_match_metric`). Optional parameters like `num_threads`, `display_progress`, and `display_table` are used for parallelization and output formatting. Finally, it calls the evaluator instance with the program (`qa_program`) to compute and print the average score.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dspy.evaluate import Evaluate\n\n# 1. Create the Evaluator instance\nevaluator = Evaluate(\n    devset=devset,            # The dataset to evaluate on\n    metric=simple_exact_match_metric, # The function to score predictions\n    num_threads=4,            # Run 4 evaluations in parallel (optional)\n    display_progress=True,    # Show a progress bar (optional)\n    display_table=True        # Display results in a table (optional)\n)\n\n# 2. Run the evaluation by calling the evaluator with the program\n# This will run qa_program on each example in devset,\n# score it using simple_exact_match_metric, and return the average score.\naverage_score = evaluator(qa_program)\n\nprint(f\"Average Score: {average_score}%\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Publish/Subscribe Subscription Management in Python\nDESCRIPTION: This Python snippet shows a simplified `SubscriptionManager` class responsible for handling agent subscriptions to message topics within the AutoGen runtime. It maintains a list of `Subscription` objects and implements methods to add new subscriptions and retrieve a list of recipient `AgentId`s for a given `TopicId` based on matching subscriptions. This enables the runtime's publish/subscribe message routing mechanism. It depends on `Subscription`, `TopicId`, and `AgentId` types from AutoGen Core.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# From: _runtime_impl_helpers.py (SubscriptionManager simplified)\nclass SubscriptionManager:\n    def __init__(self):\n        self._subscriptions: List[Subscription] = []\n        # Optimization cache can be added here\n\n    async def add_subscription(self, subscription: Subscription):\n        self._subscriptions.append(subscription)\n        # Clear cache if any\n\n    async def get_subscribed_recipients(self, topic: TopicId) -> List[AgentId]:\n        recipients = []\n        for sub in self._subscriptions:\n            if sub.is_match(topic):\n                recipients.append(sub.map_to_agent(topic))\n        return recipients\n```\n\n----------------------------------------\n\nTITLE: Validating JSON Data with TypeAdapter in Python\nDESCRIPTION: Shows how to use TypeAdapter's validate_json() method to parse and validate JSON data in one step.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Input as a JSON string\nraw_data_ok_json = '[101, \"205\", 300]'\nraw_data_bad_json = '[101, -5, \"abc\"]'\n\n# Validate the good JSON\ntry:\n    validated_list_from_json = user_id_list_adapter.validate_json(raw_data_ok_json)\n    print(f\"\\nValidated from JSON: {validated_list_from_json}\")\n    # Expected Output: Validated from JSON: [101, 205, 300]\nexcept ValidationError as e:\n    print(f\"\\nJSON validation failed: {e}\")\n\n# Validate the bad JSON\ntry:\n    user_id_list_adapter.validate_json(raw_data_bad_json)\nexcept ValidationError as e:\n    print(f\"\\nJSON validation failed as expected:\\n{e}\")\n    # Expected Output (simplified):\n    # JSON validation failed as expected:\n    # 1 validation error for list[PositiveInt]\n    # 1\n    #   Input should be greater than 0 [type=greater_than, context={'gt': 0}, input_value=-5, input_type=int]\n```\n\n----------------------------------------\n\nTITLE: Topic Channel Usage Example\nDESCRIPTION: Example showing how to explicitly use Topic channel with accumulation in a TypedDict state definition.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict, Annotated, List\nfrom langgraph.channels import Topic\n\nclass ChatState(TypedDict):\n    chat_history: Annotated[List[str], Topic(str, accumulate=True)]\n```\n\n----------------------------------------\n\nTITLE: Capturing Telemetry Events in Python\nDESCRIPTION: This snippet shows the capture method of the ProductTelemetry class. It sends telemetry events to PostHog, including the event name and properties. The method handles exceptions to prevent crashes in the main application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef capture(self, event: BaseTelemetryEvent) -> None:\n    # Do nothing if telemetry is disabled\n    if self._posthog_client is None:\n        return\n\n    try:\n        # Get the anonymous user ID (lazy loaded)\n        anon_user_id = self.user_id\n\n        # Send the event name and its properties (as a dictionary)\n        self._posthog_client.capture(\n            distinct_id=anon_user_id,\n            event=event.name, # e.g., \"agent_run\"\n            properties=event.properties # Data from the event model\n        )\n        logger.debug(f'Telemetry event captured: {event.name}')\n    except Exception as e:\n        # Don't crash the main application if telemetry fails\n        logger.error(f'Failed to send telemetry event {event.name}: {e}')\n```\n\n----------------------------------------\n\nTITLE: Visualizing Client-Agent JSON-RPC Interaction\nDESCRIPTION: This Mermaid sequence diagram illustrates the communication flow between a client application and an agent server using the JSON-RPC protocol. It depicts the client sending a request with a specific method and parameters, and the agent responding with either a successful result or an error, emphasizing the use of the `id` field to correlate requests and responses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Client App\n    participant A as Agent Server\n\n    C->>A: JSON-RPC Request (id: \"req-abc\", method: \"tasks/send\", params: {...})\n    Note right of A: Agent parses JSON, finds method 'tasks/send'\n\n    alt Action Successful\n        A-->>C: JSON-RPC Response (id: \"req-abc\", result: {Task Object})\n    else Action Failed\n        A-->>C: JSON-RPC Response (id: \"req-abc\", error: {code:..., message:...})\n    end\n    Note left of C: Client matches response 'id' to original request\n```\n\n----------------------------------------\n\nTITLE: Generating SSTable Filenames in LevelDB\nDESCRIPTION: Creates standardized filenames for SSTable files using a database name and sequence number. The function generates names in the format 'dbname/000005.ldb' to identify table files on disk.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/01_table___sstable___tablecache.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\nstd::string TableFileName(const std::string& dbname, uint64_t number) {\n  assert(number > 0);\n  return MakeFileName(dbname, number, \"ldb\"); // or \"sst\"\n}\n```\n\n----------------------------------------\n\nTITLE: Simplified ModelMetaclass Implementation\nDESCRIPTION: A conceptual, simplified view of how Pydantic's ModelMetaclass works to create model classes with validation and serialization capabilities.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Extremely simplified conceptual view of metaclass action\nclass ModelMetaclass(type):\n    def __new__(mcs, name, bases, namespace, **kwargs):\n        # 1. Find fields and type hints in 'namespace'\n        fields = {} # Simplified: find 'name: str', 'age: int'\n        annotations = {} # Simplified\n\n        # ... collect fields, config, etc. ...\n\n        # 2. Generate Core Schema (pseudo-code)\n        # core_schema = pydantic_core.generate_schema(fields, annotations, config)\n        # (This happens internally, see Chapter 5)\n\n        # 3. Create validator & serializer (pseudo-code)\n        # validator = pydantic_core.SchemaValidator(core_schema)\n        # serializer = pydantic_core.SchemaSerializer(core_schema)\n\n        # Create the actual class object\n        cls = super().__new__(mcs, name, bases, namespace, **kwargs)\n\n        # Attach the generated validator/serializer (simplified)\n        # cls.__pydantic_validator__ = validator\n        # cls.__pydantic_serializer__ = serializer\n        # cls.__pydantic_core_schema__ = core_schema # Store the schema\n\n        return cls\n\n# class BaseModel(metaclass=ModelMetaclass):\n```\n\n----------------------------------------\n\nTITLE: Visualizing MCP Communication Flow with Mermaid\nDESCRIPTION: This diagram illustrates the sequence of interactions between the User, Agent, LLM, Server, and Bash Tool during a file listing operation using MCP.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Agent as MCPAgent\n    participant LLM as Agent's LLM\n    participant Server as MCPServer\n    participant BashTool as Bash Tool (on Server)\n\n    Note over Agent, Server: Initial Connection & list_tools (omitted for brevity)\n\n    User->>+Agent: \"List files using bash\"\n    Agent->>+LLM: ask_tool(\"List files\", tools=[...bash_schema...])\n    LLM-->>-Agent: Decide: call tool 'bash', args={'command':'ls'}\n    Agent->>+Server: call_tool(name='bash', args={'command':'ls'})\n    Server->>+BashTool: execute(command='ls')\n    BashTool->>BashTool: Runs 'ls' command\n    BashTool-->>-Server: Returns file list string\n    Server-->>-Agent: Tool Result (output=file list)\n    Agent->>Agent: Process result, update memory\n    Agent-->>-User: \"OK, the files are: ...\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Flask Configuration Values\nDESCRIPTION: Shows different methods of accessing Flask configuration values both inside and outside request contexts using current_app and direct app access.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom flask import current_app, session\n\n# Inside a view function or other request-context code:\n@app.route('/some-route')\ndef some_view():\n    # Using current_app proxy\n    api_key = current_app.config.get('MY_API_KEY')\n    if not api_key:\n        return \"Error: API Key not configured!\", 500\n\n    # Flask extensions often use app.config too\n    session['user_id'] = 123 # Uses current_app.config['SECRET_KEY'] implicitly\n    \n    # ... use api_key ...\n    return f\"Using API Key starting with: {api_key[:5]}...\"\n\n# Accessing outside a request context (e.g., in setup code)\n# Requires the app object directly or an app context\nwith app.app_context():\n    print(f\"Accessing SECRET_KEY via current_app: {current_app.config['SECRET_KEY']}\")\n\n# Or directly via the app object if available\nprint(f\"Accessing SECRET_KEY via app: {app.config['SECRET_KEY']}\")\n```\n\n----------------------------------------\n\nTITLE: Using BM25ContentFilter in Crawl4AI to Extract Solar Power Content\nDESCRIPTION: This code demonstrates how to use BM25ContentFilter to extract only content related to solar power from a webpage about renewable energy. It creates a filter with the query \"solar power technology\", configures a markdown generator with this filter, and then runs the crawl to obtain both raw and filtered (fit) markdown.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter5_example_1.py\nimport asyncio\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    DefaultMarkdownGenerator, # The standard markdown generator\n    BM25ContentFilter         # The keyword-based filter\n)\n\nasync def main():\n    # 1. Create the BM25 filter with our query\n    solar_filter = BM25ContentFilter(user_query=\"solar power technology\")\n    print(f\"Filter created for query: '{solar_filter.user_query}'\")\n\n    # 2. Create a Markdown generator that USES this filter\n    markdown_generator_with_filter = DefaultMarkdownGenerator(\n        content_filter=solar_filter\n    )\n    print(\"Markdown generator configured with BM25 filter.\")\n\n    # 3. Create CrawlerRunConfig using this specific markdown generator\n    run_config = CrawlerRunConfig(\n        markdown_generator=markdown_generator_with_filter\n    )\n\n    # 4. Run the crawl\n    async with AsyncWebCrawler() as crawler:\n        # Example URL (replace with a real page having relevant content)\n        url_to_crawl = \"https://en.wikipedia.org/wiki/Renewable_energy\"\n        print(f\"\\nCrawling {url_to_crawl}...\")\n\n        result = await crawler.arun(url=url_to_crawl, config=run_config)\n\n        if result.success:\n            print(\"\\nCrawl successful!\")\n            print(f\"Raw Markdown length: {len(result.markdown.raw_markdown)}\")\n            print(f\"Fit Markdown length: {len(result.markdown.fit_markdown)}\")\n\n            # The fit_markdown should be shorter and focused on solar power\n            print(\"\\n--- Start of Fit Markdown (Solar Power Focus) ---\")\n            # Print first 500 chars of the filtered markdown\n            print(result.markdown.fit_markdown[:500] + \"...\")\n            print(\"--- End of Fit Markdown Snippet ---\")\n        else:\n            print(f\"\\nCrawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating Global Instructions for Codex\nDESCRIPTION: Example Markdown file for global instructions that apply to all Codex runs. These instructions provide general guidelines for how the AI should respond, including a preference for step-by-step explanations, Python usage, and emoji inclusion.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n# File: ~/.codex/instructions.md\n\n- Always explain your reasoning step-by-step before suggesting code or commands.\n- Prefer using Python for scripting tasks unless otherwise specified.\n- Use emojis in your responses! 🎉\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt Rules in Markdown\nDESCRIPTION: This snippet shows a simplified version of the system_prompt.md file, which contains the rules for the AI assistant's behavior and response format.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/02_system_prompt.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n# Response Rules\n1. RESPONSE FORMAT: You must ALWAYS respond with valid JSON in this exact format:\n{{\"current_state\": {{\"evaluation_previous_goal\": \"...\",\n\"memory\": \"...\",\n\"next_goal\": \"...\"}},\n\"action\":[{{\"one_action_name\": {{...}}}}, ...]}}\n\n2. ACTIONS: You can specify multiple actions in the list... Use maximum {{max_actions}} actions...\n```\n\n----------------------------------------\n\nTITLE: Inspecting Real Core Schema in Pydantic\nDESCRIPTION: Demonstrates how to access the generated Core Schema for a Pydantic model. This schema is an internal representation and should be treated as an implementation detail.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    id: int\n    username: str = Field(min_length=5, alias='userName')\n\n# Access the generated core schema\n# Warning: Internal structure, subject to change!\nprint(User.__pydantic_core_schema__)\n# Output will be a complex dictionary representing the detailed schema\n# (Output is large and complex, not shown here for brevity)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Error Propagation in requests and urllib3 - Mermaid Diagram\nDESCRIPTION: Illustrates the flow of method calls and error propagation when a network error occurs using the requests library, visualized in a Mermaid sequence diagram. No dependencies required beyond Mermaid for rendering. Shows how errors originating in the underlying network or urllib3 library are caught and remapped into requests exceptions, which the user code can handle. The input is a failed HTTP request; the output is a diagram representing exception translation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant UserCode as Your Code\\n    participant ReqAPI as requests.get()\\n    participant Adapter as HTTPAdapter\\n    participant Urllib3 as urllib3 library\\n    participant Network\\n\\n    UserCode->>ReqAPI: requests.get(bad_url, timeout=1)\\n    ReqAPI->>Adapter: send(prepared_request)\\n    Adapter->>Urllib3: urlopen(method, url, ..., timeout=1)\\n    Urllib3->>Network: Attempt connection...\\n    Network-->>Urllib3: Fails (e.g., DNS lookup fails)\\n    Urllib3->>Urllib3: Raise urllib3.exceptions.NewConnectionError\\n    Urllib3-->>Adapter: Propagate NewConnectionError\\n    Adapter->>Adapter: Catch NewConnectionError\\n    Adapter->>Adapter: Raise requests.exceptions.ConnectionError(original_error)\\n    Adapter-->>ReqAPI: Propagate ConnectionError\\n    ReqAPI-->>UserCode: Propagate ConnectionError\\n    UserCode->>UserCode: Catch requests.exceptions.ConnectionError\n```\n\n----------------------------------------\n\nTITLE: Visualizing LangGraph Architecture with Mermaid in Markdown\nDESCRIPTION: This mermaid diagram presents a high-level overview of main LangGraph components and their interactions, as utilized in stateful AI applications (e.g., chatbots or agents). It requires support for markdown rendering of mermaid diagrams (such as GitHub or compatible markdown engines). The expected input is no external data—this is purely a visualization. Outputs include graphical elements like nodes and directed edges that clarify relationships among the Pregel engine, Graph, State management, and control flow. There are no parameters, and it is not executable code but serves as a schematic reference.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Pregel Execution Engine\"]\n    A1[\"Graph / StateGraph\"]\n    A2[\"Channels\"]\n    A3[\"Nodes (PregelNode)\"]\n    A4[\"Checkpointer (BaseCheckpointSaver)\"]\n    A5[\"Control Flow Primitives (Branch, Send, Interrupt)\"]\n    A0 -- \"Executes\" --> A1\n    A1 -- \"Contains\" --> A3\n    A3 -- \"Updates State Via\" --> A2\n    A0 -- \"Manages State Via\" --> A2\n    A0 -- \"Uses Checkpointer\" --> A4\n    A1 -- \"Defines Control Flow With\" --> A5\n    A5 -- \"Directs Execution Of\" --> A0\n    A4 -- \"Saves State Of\" --> A2\n```\n\n----------------------------------------\n\nTITLE: Using CacheMode.ENABLED for Efficient Crawling in Crawl4AI\nDESCRIPTION: This example demonstrates using CacheMode.ENABLED, where the first run fetches and caches the webpage, while the second run retrieves the result from the cache. This is the default and most balanced approach for caching.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter9_example_1.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\nasync def main():\n    url = \"https://httpbin.org/html\"\n    async with AsyncWebCrawler() as crawler:\n        # Explicitly set the mode to ENABLED\n        config_enabled = CrawlerRunConfig(cache_mode=CacheMode.ENABLED)\n        print(f\"Running with CacheMode: {config_enabled.cache_mode.name}\")\n\n        # First run: Fetches, caches, and returns result\n        print(\"First run (ENABLED)...\")\n        result1 = await crawler.arun(url=url, config=config_enabled)\n        print(f\"Got result 1? {'Yes' if result1.success else 'No'}\")\n\n        # Second run: Finds result in cache and returns it instantly\n        print(\"Second run (ENABLED)...\")\n        result2 = await crawler.arun(url=url, config=config_enabled)\n        print(f\"Got result 2? {'Yes' if result2.success else 'No'}\")\n        # This second run should be much faster!\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Using app.conf.update() Method\nDESCRIPTION: Updating Celery configuration after app creation using the conf.update() method. This approach allows for more detailed configuration and is useful for simple adjustments or quick tests.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\n\n# Create the app (maybe with initial settings)\napp = Celery('tasks', broker='redis://localhost:6379/0')\n\n# Update configuration afterwards\napp.conf.update(\n    result_backend='redis://localhost:6379/1', # Use database 1 for results\n    task_serializer='json',\n    result_serializer='json',\n    accept_content=['json'], # Only accept json formatted tasks\n    timezone='Europe/Oslo',\n    enable_utc=True, # Use UTC timezone internally\n    # Add task modules to import when worker starts\n    include=['my_tasks'] # Assumes you have a file my_tasks.py with tasks\n)\n\nprint(f\"Broker URL set to: {app.conf.broker_url}\")\nprint(f\"Result backend set to: {app.conf.result_backend}\")\nprint(f\"Timezone set to: {app.conf.timezone}\")\n```\n\n----------------------------------------\n\nTITLE: Sending Tasks with Celery Delay\nDESCRIPTION: Demonstration of how to send a task using Celery's delay() method, including comments explaining the internal connection process\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/04_broker_connection__amqp_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# run_tasks.py (simplified)\nfrom tasks import add\nfrom celery_app import app # Assume app is configured with a broker_url\n\n# 1. You call .delay()\nprint(\"Sending task...\")\nresult_promise = add.delay(2, 2)\n# Behind the scenes:\n# a. Celery looks at the 'add' task, finds its associated 'app'.\n# b. It asks 'app' for the broker_url from its configuration.\n# c. It uses the app.amqp component (powered by Kombu) to get a connection\n#    to the broker specified by the URL (e.g., 'amqp://localhost...').\n# d. It packages the task name 'tasks.add' and args (2, 2) into a message.\n# e. It uses the connection to 'publish' (send) the message to the broker.\n\nprint(f\"Task sent! ID: {result_promise.id}\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Anthropic and Local Ollama Models in DSPy\nDESCRIPTION: Provides examples of configuring DSPy to use different language models via the generic `dspy.LM` client, which leverages `litellm`. It shows configuration for Anthropic's Claude 3 Haiku (requiring `ANTHROPIC_API_KEY` environment variable) and a local Llama 3 model served via Ollama (requiring a running Ollama server with the specified model). It highlights setting model-specific parameters like `max_tokens` and `temperature` during client instantiation and applying the configuration using `dspy.settings.configure`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Example: Configure Anthropic's Claude 3 Haiku\n# (Assumes ANTHROPIC_API_KEY environment variable is set)\n# Note: Provider prefix 'anthropic/' is often optional if model name is unique\nclaude_haiku = dspy.LM(model='anthropic/claude-3-haiku-20240307', max_tokens=200)\ndspy.settings.configure(lm=claude_haiku)\n\n# Now DSPy modules will use Claude 3 Haiku\n\n# Example: Configure a local model served via Ollama\n# (Assumes Ollama server is running and has the 'llama3' model)\nlocal_llama = dspy.LM(model='ollama/llama3', max_tokens=500, temperature=0.7)\ndspy.settings.configure(lm=local_llama)\n\n# Now DSPy modules will use the local Llama 3 model via Ollama\n```\n\n----------------------------------------\n\nTITLE: Defining the Base Model Interface in Python\nDESCRIPTION: A simplified Python code snippet from `models.py` defining the abstract `Model` base class. It includes a simplified `ChatMessage` dataclass representing the standard response format, which includes role, content, and optional tool calls. The `Model` class defines the `__call__` method contract, which takes messages and optional parameters like stop sequences and tools, and must be implemented by subclasses. It also includes an `__init__` method for storing configuration and a placeholder `_prepare_completion_kwargs` helper method for backend-specific request formatting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: models.py (Simplified Model base class) ---\nfrom typing import List, Dict, Optional\nfrom .tools import Tool # Reference to Tool concept\nfrom dataclasses import dataclass # Added import based on usage\n\n@dataclass\nclass ChatMessage: # Simplified representation of the standard response\n    role: str\n    content: Optional[str] = None\n    tool_calls: Optional[List[dict]] = None # For tool usage (Chapter 3)\n    # ... other fields ...\n\nclass Model:\n    def __init__(self, **kwargs):\n        self.kwargs = kwargs # Stores model-specific settings\n        # ...\n\n    # The standard \"button\" our agent presses!\n    def __call__(\n        self,\n        messages: List[Dict[str, str]],\n        stop_sequences: Optional[List[str]] = None,\n        tools_to_call_from: Optional[List[Tool]] = None,\n        **kwargs,\n    ) -> ChatMessage:\n        # Each specific model interface implements this method\n        raise NotImplementedError(\"Subclasses must implement the __call__ method.\")\n\n    def _prepare_completion_kwargs(self, messages, **kwargs) -> Dict:\n        # Helper to format messages and parameters for the backend\n        # ... translation logic ...\n        pass\n```\n\n----------------------------------------\n\nTITLE: Defining MCP Protocol Types with Pydantic in mcp/types.py\nDESCRIPTION: An example snippet from the SDK's types.py file showing how Pydantic BaseModel is used to define structured protocol types like ProgressNotification with type hints and validation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/07_mcp_protocol_types.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# This file defines all the standard MCP types using Pydantic\n\nfrom pydantic import BaseModel, Field\nfrom typing import Literal, Any\n\n# Define the base for parameters of progress notifications\nclass ProgressNotificationParams(NotificationParams):\n    \"\"\"Parameters for progress notifications.\"\"\"\n    progressToken: ProgressToken # Defined elsewhere as str | int\n    progress: float\n    total: float | None = None\n    model_config = ConfigDict(extra=\"allow\")\n\n# Define the notification itself, using the params above\nclass ProgressNotification(\n    Notification[ProgressNotificationParams, Literal[\"notifications/progress\"]]\n):\n    \"\"\"\n    An out-of-band notification used to inform the receiver of a progress update...\n    \"\"\"\n    method: Literal[\"notifications/progress\"]\n    params: ProgressNotificationParams\n\n# --- Other definitions like Tool, Resource, CallToolRequest etc. ---\n```\n\n----------------------------------------\n\nTITLE: Raising a Custom Exception in a FastAPI Route (Python)\nDESCRIPTION: Demonstrates raising the custom UnicornNotFound exception within a FastAPI route handler based on path parameter logic. If the supplied unicorn name equals 'yolo', UnicornNotFound is raised and subsequently handled by the registered exception handler; otherwise, a normal success response is returned. Requires FastAPI app instance with the appropriate handler registered.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@app.get(\"/unicorns/{name}\")\nasync def read_unicorn(name: str):\n    if name == \"yolo\":\n        # Raise our custom exception\n        raise UnicornNotFound(name=name)\n    return {\"unicorn_name\": name, \"message\": \"Unicorn exists!\"}\n\n```\n\n----------------------------------------\n\nTITLE: Defining MapReduce State for Send Example in Python\nDESCRIPTION: Defines a TypedDict representing the state for a map-reduce workflow. It includes lists for items to process and processed items, as well as a final result string.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict, List, Annotated\nimport operator\n\nclass MapReduceState(TypedDict):\n    items_to_process: List[str]\n    # Use Topic or operator.add to collect results from worker nodes\n    processed_items: Annotated[List[str], operator.add]\n    final_result: str\n```\n\n----------------------------------------\n\nTITLE: Implementing Head and Tail Chat Completion Context in Python\nDESCRIPTION: A context management strategy that keeps both the first N messages (head) and the last M messages (tail), with an optional placeholder for skipped messages in between. This preserves initial context and recent messages while managing total context size.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# From: model_context/_head_and_tail_chat_completion_context.py (Simplified)\nfrom typing import List\nfrom ._chat_completion_context import ChatCompletionContext\nfrom ..models import LLMMessage, UserMessage\n\nclass HeadAndTailChatCompletionContext(ChatCompletionContext):\n    def __init__(self, head_size: int, tail_size: int, ...):\n        super().__init__(...)\n        self._head_size = head_size\n        self._tail_size = tail_size\n\n    async def get_messages(self) -> List[LLMMessage]:\n        head = self._messages[: self._head_size] # First 'head_size' items\n        tail = self._messages[-self._tail_size :] # Last 'tail_size' items\n        num_skipped = len(self._messages) - len(head) - len(tail)\n\n        if num_skipped <= 0: # If no overlap or gap\n            return self._messages\n        else: # If messages were skipped\n            placeholder = [UserMessage(content=f\"Skipped {num_skipped} messages.\", source=\"System\")]\n            # Combine head + placeholder + tail\n            return head + placeholder + tail\n```\n\n----------------------------------------\n\nTITLE: Creating Echo Server with FastMCP\nDESCRIPTION: Implements a simple echo server using FastMCP's tool decorator. The server accepts a message string and returns it with a prefix. Demonstrates tool registration and type hints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp.server.fastmcp import FastMCP\n\n# 1. Create the server instance\nserver = FastMCP(name=\"EchoServer\")\n\n# 2. Define the tool using the @server.tool decorator\n@server.tool(name=\"echo\", description=\"Repeats the input message back.\")\ndef echo(message: str) -> str:\n  \"\"\"\n  This function is now registered as the 'echo' tool.\n  'message: str' tells FastMCP the tool expects one argument\n  named 'message' which should be a string.\n  '-> str' tells FastMCP the tool will return a string.\n  \"\"\"\n  print(f\"Tool 'echo' called with message: {message}\") # Server-side log\n  # 3. The function's logic directly implements the tool\n  return f\"You said: {message}\"\n\n# 4. Standard run block\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run() # Start listening\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Action Models with Pydantic\nDESCRIPTION: Defines the ActionModel and related models for representing specific browser actions like clicking elements and inputting text, with their required parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import Optional\n\nclass ClickElementAction(BaseModel):\n    index: int\n    xpath: Optional[str] = None\n\nclass InputTextAction(BaseModel):\n    index: int\n    text: str\n    xpath: Optional[str] = None\n\nclass ActionModel(BaseModel):\n    click_element: Optional[ClickElementAction] = None\n    input_text: Optional[InputTextAction] = None\n    pass\n```\n\n----------------------------------------\n\nTITLE: Validating Python Data with TypeAdapter in Python\nDESCRIPTION: Demonstrates how to use TypeAdapter's validate_python() method to validate and coerce Python data against a specified type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import ValidationError, PositiveInt, TypeAdapter\nfrom typing import List\n\nUserIdListType = List[PositiveInt]\nuser_id_list_adapter = TypeAdapter(UserIdListType)\n\n# --- Example 1: Valid data (with coercion needed) ---\npython_data_ok = [101, \"205\", 300] # \"205\" needs converting to int\n\ntry:\n    validated_list = user_id_list_adapter.validate_python(python_data_ok)\n    print(f\"Validation successful: {validated_list}\")\n    # Expected Output: Validation successful: [101, 205, 300]\n    print(f\"Types: {[type(x) for x in validated_list]}\")\n    # Expected Output: Types: [<class 'int'>, <class 'int'>, <class 'int'>]\nexcept ValidationError as e:\n    print(f\"Validation failed: {e}\")\n\n# --- Example 2: Invalid data (negative number) ---\npython_data_bad_value = [101, -5, 300] # -5 is not PositiveInt\n\ntry:\n    user_id_list_adapter.validate_python(python_data_bad_value)\nexcept ValidationError as e:\n    print(f\"\\nValidation failed as expected:\\n{e}\")\n    # Expected Output (simplified):\n    # Validation failed as expected:\n    # 1 validation error for list[PositiveInt]\n    # 1\n    #   Input should be greater than 0 [type=greater_than, context={'gt': 0}, input_value=-5, input_type=int]\n\n# --- Example 3: Invalid data (wrong type) ---\npython_data_bad_type = [101, \"abc\", 300] # \"abc\" cannot be int\n\ntry:\n    user_id_list_adapter.validate_python(python_data_bad_type)\nexcept ValidationError as e:\n    print(f\"\\nValidation failed as expected:\\n{e}\")\n    # Expected Output (simplified):\n    # Validation failed as expected:\n    # 1 validation error for list[PositiveInt]\n    # 1\n    #   Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='abc', input_type=str]\n```\n\n----------------------------------------\n\nTITLE: Initializing Agents for a Trip Planning Crew in Python\nDESCRIPTION: This snippet demonstrates how to create two Agent instances for a trip planning Crew: a researcher and a planner. It shows the basic structure of defining agents with roles, goals, and settings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/01_crew.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process\n\n# Define our agents (don't worry about the details for now)\n# Agent 1: The Researcher\nresearcher = Agent(\n  role='Travel Researcher',\n  goal='Find interesting cities in Europe for a birthday trip',\n  backstory='An expert travel researcher.',\n  # verbose=True, # Optional: Shows agent's thinking process\n  allow_delegation=False # This agent doesn't delegate work\n  # llm=your_llm # We'll cover LLMs later!\n)\n\n# Agent 2: The Planner\nplanner = Agent(\n  role='Activity Planner',\n  goal='Create a fun 3-day itinerary for the chosen city',\n  backstory='An experienced activity planner.',\n  # verbose=True,\n  allow_delegation=False\n  # llm=your_llm\n)\n```\n\n----------------------------------------\n\nTITLE: Making HTTP Requests with Session and Default Retry Logic - Python\nDESCRIPTION: This snippet demonstrates using a requests.Session to make an HTTP GET call to another domain, relying on the default adapter and default retry behavior present in the requests library. It includes exception handling for network errors and prints the HTTP status code or the error encountered. Required dependencies are the requests library and a pre-existing Session object; key parameters are the target URL and standard requests settings. The main output is the HTTP status code or an error message printed to console.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprint(\"\\nMaking request to a different site (default retries)...\")\ntry:\n    response_other = session.get('https://httpbin.org/get')\n    print(f\"Status for httpbin: {response_other.status_code}\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"Httpbin request failed: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Python Prompt Example\nDESCRIPTION: An example of a multi-line Python prompt that demonstrates why Codex needs a sophisticated input handling system. This snippet illustrates the type of complex, structured prompt a user might write.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/02_input_handling__textbuffer_editor_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nWrite a python function that:\n1. Takes a list of numbers.\n2. Returns a new list containing only the even numbers.\nMake sure it handles empty lists gracefully.\n```\n\n----------------------------------------\n\nTITLE: DBImpl Class Definition in LevelDB\nDESCRIPTION: This snippet shows a simplified version of the DBImpl class definition from LevelDB. It includes the public API methods, private helper methods, and key member variables that manage the database state, including MemTables, WAL, VersionSet, and various synchronization primitives.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_6\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/db_impl.h ---\n\nclass DBImpl : public DB {\n public:\n  DBImpl(const Options& options, const std::string& dbname);\n  ~DBImpl() override;\n\n  // Public API methods (implementing DB interface)\n  Status Put(...) override;\n  Status Delete(...) override;\n  Status Write(...) override;\n  Status Get(...) override;\n  Iterator* NewIterator(...) override;\n  const Snapshot* GetSnapshot() override;\n  void ReleaseSnapshot(...) override;\n  // ... other public methods ...\n\n private:\n  // Friend classes allow access to private members\n  friend class DB;\n  struct CompactionState; // Helper struct for compactions\n  struct Writer;          // Helper struct for writer queue\n\n  // Core methods for internal operations\n  Status Recover(VersionEdit* edit, bool* save_manifest);\n  void CompactMemTable();\n  Status RecoverLogFile(...);\n  Status WriteLevel0Table(...);\n  Status MakeRoomForWrite(...);\n  void MaybeScheduleCompaction();\n  static void BGWork(void* db); // Background task entry point\n  void BackgroundCall();\n  void BackgroundCompaction();\n  Status DoCompactionWork(...);\n  // ... other private helpers ...\n\n  // == Key Member Variables ==\n  Env* const env_;                // OS interaction layer\n  const InternalKeyComparator internal_comparator_; // For sorting keys\n  const Options options_;         // Database configuration options\n  const std::string dbname_;      // Database directory path\n\n  TableCache* const table_cache_; // Cache for open SSTable files\n\n  FileLock* db_lock_;             // Lock file handle for DB directory\n\n  port::Mutex mutex_;             // Main mutex protecting shared state\n  std::atomic<bool> shutting_down_; // Flag indicating DB closure\n  port::CondVar background_work_finished_signal_ GUARDED_BY(mutex_); // For waiting\n\n  MemTable* mem_ GUARDED_BY(mutex_); // Active memtable (accepts writes)\n  MemTable* imm_ GUARDED_BY(mutex_); // Immutable memtable (being flushed)\n  std::atomic<bool> has_imm_;        // Fast check if imm_ is non-null\n\n  WritableFile* logfile_;         // Current WAL file handle\n  uint64_t logfile_number_ GUARDED_BY(mutex_); // Current WAL file number\n  log::Writer* log_;              // WAL writer object\n\n  VersionSet* const versions_ GUARDED_BY(mutex_); // Manages SSTables/Versions\n\n  // Queue of writers waiting for their turn\n  std::deque<Writer*> writers_ GUARDED_BY(mutex_);\n  // List of active snapshots\n  SnapshotList snapshots_ GUARDED_BY(mutex_);\n  // Files being generated by compactions\n  std::set<uint64_t> pending_outputs_ GUARDED_BY(mutex_);\n  // Is a background compaction scheduled/running?\n  bool background_compaction_scheduled_ GUARDED_BY(mutex_);\n  // Error status from background threads\n  Status bg_error_ GUARDED_BY(mutex_);\n  // Compaction statistics\n  CompactionStats stats_[config::kNumLevels] GUARDED_BY(mutex_);\n};\n```\n\n----------------------------------------\n\nTITLE: Internal Structure of LangGraph Branch Primitive (Python)\nDESCRIPTION: Presents a simplified, conceptual view of the internal `Branch` class within LangGraph (`graph/branch.py`). It highlights key components like the `path` (containing the user-provided routing function) and `ends` (the mapping from routing results to node names). The description outlines how the `_route` method invokes the routing function and uses the mapping to determine the next node(s) to schedule.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# graph/branch.py (Simplified view)\nclass Branch(NamedTuple):\n    path: Runnable # Your routing function wrapped as a Runnable\n    ends: Optional[dict[Hashable, str]] # Your path_map\n    # ... other fields ...\n\n    def _route(self, input: Any, config: RunnableConfig, ...) -> Runnable:\n        # ... reads current state if needed ...\n        value = ... # Get the state\n        result = self.path.invoke(value, config) # Call your routing function\n        # ... determines destination node(s) using self.ends mapping ...\n        destinations = [self.ends[r] for r in result]\n        # ... tells the engine (via writer) which node(s) to run next ...\n        return writer(destinations, config) or input # writer is a callback to the engine\n```\n\n----------------------------------------\n\nTITLE: AsyncCrawlerStrategy Implementation Snippet\nDESCRIPTION: A partial code snippet showing the beginning of the specific implementations for the crawler strategies. This fragment imports the Playwright library for browser automation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from async_crawler_strategy.py\nfrom playwright.async_api import Page # Playwright library for browser automation\n```\n\n----------------------------------------\n\nTITLE: AsyncCrawlerStrategy Abstract Base Class Implementation\nDESCRIPTION: A simplified code snippet showing the AsyncCrawlerStrategy abstract base class definition. This class defines the interface that all crawler strategies must implement with the crawl method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from async_crawler_strategy.py\nfrom abc import ABC, abstractmethod\nfrom .models import AsyncCrawlResponse # Defines the structure of the result\n\nclass AsyncCrawlerStrategy(ABC):\n    \"\"\"\n    Abstract base class for crawler strategies.\n    \"\"\"\n    @abstractmethod\n    async def crawl(self, url: str, **kwargs) -> AsyncCrawlResponse:\n        \"\"\"Fetch content from the URL.\"\"\"\n        pass # Each specific strategy must implement this\n```\n\n----------------------------------------\n\nTITLE: Automatic Usage of dspy.settings by dspy.Predict (Python)\nDESCRIPTION: Shows how a `dspy.Predict` module, when instantiated without an explicit `lm` argument, automatically uses the Language Model (LM) configured globally in `dspy.settings`. This relies on `dspy.settings.configure` having been called previously to set `dspy.settings.lm`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n# Assume settings were configured as above\n\n# Create a Predict module WITHOUT passing 'lm' explicitly\nsimple_predictor = dspy.Predict('input -> output')\n\n# When we call it, it will automatically use dspy.settings.lm\nresult = simple_predictor(input=\"Tell me a fact.\")\nprint(result.output)\n```\n\n----------------------------------------\n\nTITLE: Directly Calling the Configured RM in DSPy (Python)\nDESCRIPTION: Illustrates how to directly invoke the globally configured Retrieval Model (RM) in DSPy for testing or debugging. It assumes an RM is configured via `dspy.settings.configure`. The code calls `dspy.settings.rm()` with a query string and the desired number of passages (`k`) to fetch results directly.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Assume colbertv2_wiki is configured as the RM\n# dspy.settings.configure(rm=colbertv2_wiki)\n\nquery = \"Stanford University mascot\"\nk = 2 # Ask for top 2 passages\n\n# Call the configured RM directly\nretrieved_passages = dspy.settings.rm(query, k=k)\n```\n\n----------------------------------------\n\nTITLE: Defining a Minimal Sandbox Environment Using Docker (Dockerfile)\nDESCRIPTION: This Dockerfile defines a minimal Node.js container used for sandboxed command execution in Codex, providing Linux-based process and network isolation. It installs essential CLI tools, sets up a non-root 'node' user and workspace, and configures network rules through a startup firewall script invoked via sudo. Additional configuration ensures only required tools and scripts are available, with no unnecessary software included. Inputs are not handled by the Dockerfile itself but are managed at runtime; outputs depend on the 'codex' entrypoint or custom shell invocations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_5\n\nLANGUAGE: dockerfile\nCODE:\n```\n# File: codex-cli/Dockerfile (Simplified Snippets)\n\n# Start from a basic Node.js image\nFROM node:20\n\n# Install only necessary tools (git, jq, rg, maybe python/bash, etc.)\n# Avoid installing powerful tools unless absolutely needed.\nRUN apt update && apt install -y \\\n  git jq ripgrep sudo iproute2 iptables ipset \\\n  # ... other minimal tools ...\n  && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Copy codex itself into the container\nCOPY dist/codex.tgz codex.tgz\nRUN npm install -g codex.tgz\n\n# Setup non-root user\nUSER node\nWORKDIR /home/node/workspace # Work happens here\n\n# Copy and set up firewall script (runs via sudo)\n# This script uses iptables/ipset to block network access by default,\n# potentially allowing only specific domains if configured.\nCOPY scripts/init_firewall.sh /usr/local/bin/\nUSER root\nRUN chmod +x /usr/local/bin/init_firewall.sh && \\\n  # Allow 'node' user to run firewall script via sudo without password\n  echo \"node ALL=(root) NOPASSWD: /usr/local/bin/init_firewall.sh\" > /etc/sudoers.d/node-firewall\nUSER node\n\n# Default command when container starts (might be codex or just a shell)\n# ENTRYPOINT [\"codex\"]\n```\n\n----------------------------------------\n\nTITLE: Importing FastAPI and HTTPException in Python\nDESCRIPTION: This snippet shows how to import FastAPI and HTTPException, as well as defining a simple in-memory database for demo purposes. This setup is required before defining API endpoints that handle errors. Dependencies: fastapi library. Inputs: None. Outputs: Initializes FastAPI instance and a fake items dictionary.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# main.py or your router file\\nfrom fastapi import FastAPI, HTTPException\\n\\napp = FastAPI() # Or use your APIRouter\\n\\n# Simple in-memory storage (like from Chapter 4)\\nfake_items_db = {1: {\\\"name\\\": \\\"Foo\\\"}, 2: {\\\"name\\\": \\\"Bar\\\"}}\n```\n\n----------------------------------------\n\nTITLE: Request Processing Flow Sequence Diagram\nDESCRIPTION: A sequence diagram showing the interaction flow between Client App, A2A Server, Task Manager, Agent Logic, and Task Store components when processing a tasks/send request. Illustrates both streaming and non-streaming response paths.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/04_a2a_server_implementation.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Client App\n    participant S as A2A Server (e.g., Express/Starlette)\n    participant TM as Task Manager/Handler (Your Logic Bridge)\n    participant AL as Agent Logic (e.g., echoAgentLogic, CrewAI)\n    participant TS as Task Store (Memory/DB)\n\n    C->>S: POST / (JSON-RPC: method=\"tasks/send\", params={...})\n    Note right of S: Receives HTTP POST, parses JSON-RPC\n\n    S->>TM: Call on_send_task / Invoke Handler(params)\n    Note right of TM: Validates parameters\n\n    TM->>TS: Load/Create Task Record (ID: task-123)\n    Note right of TS: Creates Task in 'submitted' state\n\n    TM->>AL: Execute Agent Logic (Input: user message)\n    Note right of AL: Performs the core work (e.g., echo)\n\n    AL-->>TM: Returns result/Yields updates (e.g., \"working\", \"completed\")\n\n    loop For each update/result\n        TM->>TS: Update Task Record (ID: task-123, state: working/completed, artifacts: [...])\n        Note right of TS: Saves the latest task state\n        alt Streaming Response (SSE)\n           S-->>C: SSE Event (data: {TaskStatusUpdateEvent/Artifact})\n        end\n    end\n\n    alt Non-Streaming Response\n        TM-->>S: Final Task object\n        S-->>C: 200 OK (JSON-RPC: result={Final Task Object})\n    else Streaming Response (SSE)\n        Note over S,C: Stream ends after final event\n    end\n```\n\n----------------------------------------\n\nTITLE: Initializing a New Chat Context\nDESCRIPTION: Creates a new, empty ChatCompletionContext that represents a fresh conversation, and prepares to add a user message about drafting an email.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# File: start_new_chat.py\nfrom autogen_core.model_context import UnboundedChatCompletionContext\nfrom autogen_core.models import UserMessage\n\n# Start a new, empty chat context for a new task\nnew_chat_context = UnboundedChatCompletionContext()\n\n# Add the user's new request\nnew_request = UserMessage(content=\"Draft an email to the team about the Q3 results.\", source=\"User\")\n# await new_chat_context.add_message(new_request) # In a real app, add the request\n\nprint(\"Created a new, empty chat context.\")\n# Output: Created a new, empty chat context.\n```\n\n----------------------------------------\n\nTITLE: Simple Database Update Operations\nDESCRIPTION: Example showing basic database operations without atomic guarantees, demonstrating the potential consistency issues that can arise.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/05_writebatch.md#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n// Goal: Increase playerA score, decrease playerB score\ndb->Put(options, \"score_playerA\", \"101\");\ndb->Put(options, \"score_playerB\", \"49\");\n```\n\n----------------------------------------\n\nTITLE: Implementing GreetingTool in Python for SmolaAgents\nDESCRIPTION: This code snippet demonstrates how to create a custom GreetingTool by inheriting from the base Tool class in SmolaAgents. It includes the required attributes and the forward method implementation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: simple_tools.py ---\nfrom smolagents import Tool # Import the base class\n\nclass GreetingTool(Tool):\n    \"\"\"A simple tool that generates a greeting.\"\"\"\n\n    # 1. Give it a unique name\n    name: str = \"greet_person\"\n\n    # 2. Describe what it does clearly\n    description: str = \"Greets a person by their name.\"\n\n    # 3. Define the inputs it needs\n    # It needs one input: the 'name' of the person, which should be a string.\n    inputs: dict = {\n        \"name\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the person to greet.\"\n        }\n    }\n\n    # 4. Specify the type of the output\n    # It will return the greeting as a string.\n    output_type: str = \"string\"\n\n    # 5. Implement the action in the 'forward' method\n    def forward(self, name: str) -> str:\n        \"\"\"The actual code that runs when the tool is called.\"\"\"\n        print(f\"--- GreetingTool activated with name: {name} ---\")\n        greeting = f\"Hello, {name}! Nice to meet you.\"\n        return greeting\n\n# Let's test it quickly (outside the agent context)\ngreeter = GreetingTool()\nresult = greeter(name=\"Alice\") # Calling the tool instance\nprint(f\"Tool returned: '{result}'\")\n\n# Expected Output:\n# --- GreetingTool activated with name: Alice ---\n# Tool returned: 'Hello, Alice! Nice to meet you.'\n```\n\n----------------------------------------\n\nTITLE: Preparing a Development Dataset for DSPy Evaluation in Python\nDESCRIPTION: This snippet demonstrates how to create a development dataset (`devset`) for evaluating a DSPy program. It uses `dspy.Example` to store question-answer pairs and applies the `.with_inputs()` method to designate the 'question' field as input, implicitly marking 'answer' as the gold label for comparison during evaluation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create example data points with questions and gold answers\ndev_example1 = dspy.Example(question=\"What color is the sky?\", answer=\"blue\")\ndev_example2 = dspy.Example(question=\"What is 2 + 2?\", answer=\"4\")\ndev_example3 = dspy.Example(question=\"What is the capital of France?\", answer=\"Paris\")\ndev_example_wrong = dspy.Example(question=\"Who wrote Hamlet?\", answer=\"Shakespeare\") # Let's assume our QA program might get this wrong\n\n# Create the development set (list of examples)\ndevset = [dev_example1, dev_example2, dev_example3, dev_example_wrong]\n\n# We need to tell DSPy which fields are inputs vs outputs for evaluation\n# The .with_inputs() method marks the input keys.\n# The remaining keys ('answer' in this case) are treated as labels.\ndevset = [d.with_inputs('question') for d in devset]\n```\n\n----------------------------------------\n\nTITLE: Using the Default AsyncPlaywrightCrawlerStrategy\nDESCRIPTION: Example code showing how to use the default AsyncPlaywrightCrawlerStrategy to crawl a webpage. The strategy is automatically selected when no specific strategy is provided to the AsyncWebCrawler constructor.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/01_asynccrawlerstrategy.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# main_example.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\nasync def main():\n    # When you create AsyncWebCrawler without specifying a strategy,\n    # it automatically uses AsyncPlaywrightCrawlerStrategy!\n    async with AsyncWebCrawler() as crawler:\n        print(\"Crawler is ready using the default strategy (Playwright).\")\n\n        # Let's crawl a simple page that just returns HTML\n        # We use CacheMode.BYPASS to ensure we fetch it fresh each time for this demo.\n        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n        result = await crawler.arun(\n            url=\"https://httpbin.org/html\",\n            config=config\n        )\n\n        if result.success:\n            print(\"\\nSuccessfully fetched content!\")\n            # The strategy fetched the raw HTML.\n            # AsyncWebCrawler then processes it (more on that later).\n            print(f\"First 100 chars of fetched HTML: {result.html[:100]}...\")\n        else:\n            print(f\"\\nFailed to fetch content: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementation of DSPy Retrieve Module and ColBERTv2 Client\nDESCRIPTION: Core implementation of DSPy's Retrieve module and ColBERTv2 client showing how retrieval functionality is implemented and how it interacts with external search systems.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\nfrom dspy.primitives.prediction import Prediction\n\nclass Retrieve(dspy.Module):\n    def __init__(self, k=3):\n        super().__init__()\n        self.k = k\n\n    def forward(self, query: str, k: Optional[int] = None) -> Prediction:\n        k = k if k is not None else self.k\n        rm_client = dspy.settings.rm\n        if not rm_client:\n            raise AssertionError(\"No RM is loaded. Configure with dspy.settings.configure(rm=...).\")\n        passages_or_dotdicts = rm_client(query, k=k)\n        if isinstance(passages_or_dotdicts, list) and hasattr(passages_or_dotdicts[0], 'long_text'):\n            passages = [psg.long_text for psg in passages_or_dotdicts]\n        else:\n             passages = list(passages_or_dotdicts)\n        return Prediction(passages=passages)\n\nclass ColBERTv2:\n    def __init__(self, url: str, port: Optional[int] = None, **kwargs):\n        self.url = f\"{url}:{port}\" if port else url\n\n    def __call__(self, query: str, k: int = 10, **kwargs) -> list[dotdict]:\n        payload = {\"query\": query, \"k\": k}\n        try:\n            res = requests.get(self.url, params=payload, timeout=10)\n            res.raise_for_status()\n            json_response = res.json()\n            topk = json_response.get(\"topk\", [])[:k]\n            passages = [dotdict({**d, \"long_text\": d.get(\"text\", \"\")}) for d in topk]\n            return passages\n        except requests.exceptions.RequestException as e:\n            print(f\"Error calling ColBERTv2 server: {e}\")\n            return []\n```\n\n----------------------------------------\n\nTITLE: Catching HTTP and Network Exceptions with requests - Python\nDESCRIPTION: Demonstrates how to make an HTTP GET request with the requests library in Python, handling various exceptions due to networking or HTTP errors. Requires the requests library. The snippet shows setting a short timeout, and includes multiple except blocks to catch and provide specific feedback for ConnectTimeout, ReadTimeout, ConnectionError, HTTPError, and other RequestException types. Expected input is a URL; outputs are printed error or success messages. Limitations: it does not include retries or recovery beyond printing diagnostics.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# URL that is slow and might time out\\ntimeout_url = 'https://httpbin.org/delay/5' # Delays response by 5 seconds\\n\\nurl_to_try = timeout_url # Change to not_found_url to see HTTPError\\n\\nprint(f\\\"Trying to fetch: {url_to_try}\\\")\\n\\ntry:\\n    # Set a short timeout to demonstrate Timeout exception\\n    response = requests.get(url_to_try, timeout=2)\\n    response.raise_for_status() # Check for 4xx/5xx status codes\\n    print(\\\"Success! Status Code:\\\", response.status_code)\\n    # Process response...\\n\\nexcept requests.exceptions.ConnectTimeout as e:\\n    print(f\\\"\\\\nError: Could not connect to the server in time.\\\")\\n    print(f\\\"Details: {e}\\\")\\n    # Maybe retry later?\\n\\nexcept requests.exceptions.ReadTimeout as e:\\n    print(f\\\"\\\\nError: Server took too long to send data.\\\")\\n    print(f\\\"Details: {e}\\\")\\n    # Maybe the server is slow, could try again?\\n\\nexcept requests.exceptions.ConnectionError as e:\\n    print(f\\\"\\\\nError: Network problem (e.g., DNS error, refused connection).\\\")\\n    print(f\\\"Details: {e}\\\")\\n    # Check internet connection?\\n\\nexcept requests.exceptions.HTTPError as e:\\n    print(f\\\"\\\\nError: Bad HTTP status code received from server.\\\")\\n    print(f\\\"Status Code: {e.response.status_code}\\\")\\n    print(f\\\"Details: {e}\\\")\\n    # Was it a 404 Not Found? 500 Server Error?\\n\\nexcept requests.exceptions.RequestException as e:\\n    # Catch any other requests error that wasn't specifically handled above\\n    print(f\\\"\\\\nAn unexpected requests error occurred:\\\")\\n    print(f\\\"Error Type: {type(e).__name__}\\\")\\n    print(f\\\"Details: {e}\\\")\\n\\nprint(\"\\nScript continues...\")\n```\n\n----------------------------------------\n\nTITLE: Executing Click Application with Invalid Integer Input\nDESCRIPTION: Command-line example showing how Click automatically handles a type conversion error. When a non-integer value is provided for the --count option, Click raises a BadParameter exception and displays a helpful error message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ python count_app.py --count five \"Oh no\"\nUsage: count_app.py [OPTIONS] MESSAGE\nTry 'count_app.py --help' for help.\n\nError: Invalid value for '--count': 'five' is not a valid integer.\n```\n\n----------------------------------------\n\nTITLE: HTTP Adapter Implementation in Python\nDESCRIPTION: Implements the main HTTPAdapter class that handles HTTP connections using urllib3. Includes initialization of connection pools and retry configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass HTTPAdapter(BaseAdapter):\n    def __init__(self, pool_connections=10, pool_maxsize=10, max_retries=0, pool_block=False):\n        # === STORE RETRY CONFIGURATION ===\n        if isinstance(max_retries, Retry):\n            self.max_retries = max_retries\n        else:\n            # Convert integer retries to a basic Retry object\n            self.max_retries = Retry(total=max_retries, read=False, connect=max_retries)\n\n        # ... configure pooling options ...\n\n        # === INITIALIZE URLIB3 POOL MANAGER ===\n        # This object manages connections using urllib3\n        self.poolmanager = PoolManager(num_pools=pool_connections, maxsize=pool_maxsize, block=pool_block)\n        self.proxy_manager = {} # For handling proxies\n```\n\n----------------------------------------\n\nTITLE: Implementing Memory Protocol in Python\nDESCRIPTION: The abstract base class that defines the required interface for any memory implementation in AutoGen Core. It specifies methods for updating context, querying, adding, clearing, and closing memory operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# From: memory/_base_memory.py (Simplified ABC)\nfrom abc import ABC, abstractmethod\n# ... other imports: MemoryContent, MemoryQueryResult, UpdateContextResult, ChatCompletionContext\n\nclass Memory(ABC):\n    component_type = \"memory\"\n\n    @abstractmethod\n    async def update_context(self, model_context: ChatCompletionContext) -> UpdateContextResult: ...\n\n    @abstractmethod\n    async def query(self, query: str | MemoryContent, ...) -> MemoryQueryResult: ...\n\n    @abstractmethod\n    async def add(self, content: MemoryContent, ...) -> None: ...\n\n    @abstractmethod\n    async def clear(self) -> None: ...\n\n    @abstractmethod\n    async def close(self) -> None: ...\n```\n\n----------------------------------------\n\nTITLE: Serializing Data with TypeAdapter in Python\nDESCRIPTION: Demonstrates how to use TypeAdapter's dump_python() and dump_json() methods to serialize Python objects, including handling of complex types like datetime.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import datetime\nfrom typing import List\nfrom pydantic import TypeAdapter\n\ndatetime_list_adapter = TypeAdapter(List[datetime])\n\n# A list of datetime objects\ndt_list = [datetime(2023, 1, 1, 12, 0, 0), datetime(2024, 7, 15, 9, 30, 0)]\n\n# Dump to Python objects (datetimes remain datetimes by default)\ndumped_python = datetime_list_adapter.dump_python(dt_list)\nprint(f\"Dumped Python: {dumped_python}\")\n# Expected Output: Dumped Python: [datetime.datetime(2023, 1, 1, 12, 0), datetime.datetime(2024, 7, 15, 9, 30)]\n\n# To get JSON-compatible types (strings), use mode='json'\ndumped_for_json = datetime_list_adapter.dump_python(dt_list, mode='json')\nprint(f\"Dumped for JSON: {dumped_for_json}\")\n# Expected Output: Dumped for JSON: ['2023-01-01T12:00:00', '2024-07-15T09:30:00']\n\n# Dump directly to a JSON string\ndumped_json_str = datetime_list_adapter.dump_json(dt_list, indent=2)\nprint(f\"\\nDumped JSON:\\n{dumped_json_str.decode()}\") # .decode() to convert bytes to string for printing\n# Expected Output:\n# Dumped JSON:\n# [\n#   \"2023-01-01T12:00:00\",\n#   \"2024-07-15T09:30:00\"\n# ]\n```\n\n----------------------------------------\n\nTITLE: Compiling Nodes in CompiledStateGraph\nDESCRIPTION: Implementation of the attach_node method that transforms StateNodeSpec into PregelNode during graph compilation. Determines state access requirements and creates operational node representation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass CompiledStateGraph(CompiledGraph):\n    def attach_node(self, key: str, node: Optional[StateNodeSpec]) -> None:\n        # ... (handles START node specially) ...\n        if node is not None:\n            # Determine what parts of the state this node needs to read\n            input_schema = node.input\n            input_values = list(self.builder.schemas[input_schema]) # Keys to read\n\n            # Create the internal representation: PregelNode\n            self.nodes[key] = PregelNode(\n                triggers=[f\"branch:to:{key}\"], # When should this node run? (Connected via Channels)\n                channels=input_values, # What state keys does it read?\n                mapper=_pick_mapper(...), # How to format the input state for the function\n                writers=[ChannelWrite(...)], # How to write the output back to state (via Channels)\n                bound=node.runnable, # The actual function/Runnable to execute!\n                # ... other internal details ...\n            )\n```\n\n----------------------------------------\n\nTITLE: Basic Pydantic Model Definition\nDESCRIPTION: A simple Pydantic model declaration that defines a User with name and age fields using type hints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n```\n\n----------------------------------------\n\nTITLE: Visualizing Session to Adapter to urllib3 Workflow - Mermaid\nDESCRIPTION: This sequence diagram visualizes the call flow from user code invoking session.get in the requests library, through preparation, adapter selection, and delegation to the HTTP adapter and urllib3, and ultimately out to the server and back. It helps readers understand the stepwise, layered delegation that enables retries, connection pooling, and request customization. No dependencies beyond Mermaid plugin/renderer are required for interpreting the diagram.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as Your Code\n    participant Session as Session Object\n    participant Adapter as Transport Adapter\n    participant Urllib3 as urllib3 Library\n    participant Server\n\n    UserCode->>Session: session.get(url)\n    Session->>Session: prepare_request(req) -> PreparedRequest (prep)\n    Session->>Session: merge_environment_settings() -> send_kwargs\n    Session->>Session: get_adapter(url) -> adapter_instance\n    Session->>Adapter: adapter_instance.send(prep, **send_kwargs)\n    activate Adapter\n    Adapter->>Urllib3: Get connection from PoolManager\n    Adapter->>Urllib3: urlopen(prep.method, url, ..., retries=..., timeout=...)\n    activate Urllib3\n    Urllib3->>Server: Send HTTP Request Bytes\n    Server-->>Urllib3: Receive HTTP Response Bytes\n    Urllib3-->>Adapter: Return raw urllib3 response\n    deactivate Urllib3\n    Adapter->>Adapter: build_response(prep, raw_response) -> Response (r)\n    Adapter-->>Session: Return Response (r)\n    deactivate Adapter\n    Session->>Session: Extract cookies, handle redirects...\n    Session-->>UserCode: Return final Response\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi-Command Click Application (Version 1)\nDESCRIPTION: This snippet shows how to create a Click application with multiple commands using @click.group() and @click.command() decorators, with manual attachment of commands to the group.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# multi_app_v1.py (from Chapter 1)\nimport click\n\n@click.group()\ndef cli():\n  \"\"\"A simple tool with multiple commands.\"\"\"\n  pass\n\n@click.command()\ndef hello():\n  \"\"\"Says Hello World\"\"\"\n  print(\"Hello World!\")\n\n@click.command()\ndef goodbye():\n  \"\"\"Says Goodbye World\"\"\"\n  print(\"Goodbye World!\")\n\n# Manual attachment\ncli.add_command(hello)\ncli.add_command(goodbye)\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Using AsyncWebCrawler with Custom CrawlerRunConfig\nDESCRIPTION: Demonstrates how to create and use a CrawlerRunConfig object to customize crawling behavior, specifically bypassing the cache and taking a screenshot during crawling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# chapter3_example_2.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai import CrawlerRunConfig # 1. Import the config class\nfrom crawl4ai import CacheMode        # Import cache options\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n        print(f\"Crawling {url_to_crawl} with custom settings...\")\n\n        # 2. Create an instance of CrawlerRunConfig with our desired settings\n        my_instructions = CrawlerRunConfig(\n            cache_mode=CacheMode.BYPASS, # Don't use the cache, fetch fresh\n            screenshot=True              # Take a screenshot\n        )\n        print(\"Instructions: Bypass cache, take screenshot.\")\n\n        # 3. Pass the config object to arun()\n        result = await crawler.arun(\n            url=url_to_crawl,\n            config=my_instructions # Pass our instruction manual\n        )\n\n        if result.success:\n            print(\"\\nSuccess! Got the content with custom config.\")\n            print(f\"Screenshot taken? {'Yes' if result.screenshot else 'No'}\") # Should be Yes\n            # Check if the screenshot file path exists in result.screenshot\n            if result.screenshot:\n                print(f\"Screenshot saved to: {result.screenshot}\")\n        else:\n            print(f\"\\nFailed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Visualizing Click Decorator Sequence with Mermaid\nDESCRIPTION: A sequence diagram illustrating the process of applying Click decorators to a Python function, showing how information is attached and Command objects are created.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant PythonInterpreter\n    participant click_option as @click.option('--name')\n    participant hello_func as hello(name)\n    participant cli_command as @cli.command()\n    participant cli_Group as cli (Group Object)\n    participant hello_Command as hello (New Command Object)\n\n    Note over PythonInterpreter, hello_func: Python processes decorators bottom-up\n    PythonInterpreter->>click_option: Processes @click.option('--name', ...) decorator\n    click_option->>hello_func: Attaches Option info (like in __click_params__)\n    click_option-->>PythonInterpreter: Returns original hello_func (with attached info)\n\n    PythonInterpreter->>cli_command: Processes @cli.command() decorator\n    cli_command->>hello_func: Reads function name, docstring, attached params (__click_params__)\n    cli_command->>hello_Command: Creates new Command object for 'hello'\n    cli_command->>cli_Group: Calls cli.add_command(hello_Command)\n    cli_command-->>PythonInterpreter: Returns the new hello_Command object\n\n    Note over PythonInterpreter: 'hello' in the code now refers to the Command object\n```\n\n----------------------------------------\n\nTITLE: LogWriter Record Addition Implementation\nDESCRIPTION: Detailed implementation of how LogWriter adds records to the WAL file, handling record fragmentation across blocks and managing record types.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/03_write_ahead_log__wal____logwriter_logreader.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\nStatus Writer::AddRecord(const Slice& slice) {\n  const char* ptr = slice.data();\n  size_t left = slice.size(); // How much data is left to write?\n  Status s;\n  bool begin = true; // Is this the first fragment of this record?\n\n  do {\n    const int leftover = kBlockSize - block_offset_; // Space left in current block\n    // ... if leftover < kHeaderSize, fill trailer and start new block ...\n\n    // Calculate how much of the data can fit in this block\n    const size_t avail = kBlockSize - block_offset_ - kHeaderSize;\n    const size_t fragment_length = (left < avail) ? left : avail;\n\n    // Determine the type of this physical record (fragment)\n    RecordType type;\n    const bool end = (left == fragment_length); // Is this the last fragment?\n    if (begin && end) {\n      type = kFullType;     // Fits entirely in one piece\n    } else if (begin) {\n      type = kFirstType;    // First piece of a multi-piece record\n    } else if (end) {\n      type = kLastType;     // Last piece of a multi-piece record\n    } else {\n      type = kMiddleType;   // Middle piece of a multi-piece record\n    }\n\n    // Write this physical record (header + data fragment) to the file\n    s = EmitPhysicalRecord(type, ptr, fragment_length);\n\n    // Advance pointers and update remaining size\n    ptr += fragment_length;\n    left -= fragment_length;\n    begin = false; // Subsequent fragments are not the 'begin' fragment\n\n  } while (s.ok() && left > 0); // Loop until all data is written or error\n  return s;\n}\n\n// Simplified - Writes header (checksum, length, type) and payload\nStatus Writer::EmitPhysicalRecord(RecordType t, const char* ptr, size_t length) {\n  // ... format header (buf) with checksum, length, type ...\n  // ... compute checksum ...\n  // ... Encode checksum into header ...\n\n  // Write header and payload fragment\n  Status s = dest_->Append(Slice(buf, kHeaderSize));\n  if (s.ok()) {\n    s = dest_->Append(Slice(ptr, length));\n    // LevelDB might Flush() here or let the caller Sync() later\n  }\n  block_offset_ += kHeaderSize + length; // Update position in current block\n  return s;\n}\n```\n\n----------------------------------------\n\nTITLE: Illustrating Flask Application Initialization with Mermaid\nDESCRIPTION: A sequence diagram visualizing the internal process when `app = Flask(__name__)` is called. It shows the interaction between the user's code (`hello.py`), the Flask class constructor (`Flask.__init__`), the base App class, the Config object, and the URL Map. This helps understand how Flask sets up the application's core components like configuration and routing upon initialization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/01_application_object___flask__.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as hello.py\n    participant Flask as Flask(__init__)\n    participant App as Base App(__init__)\n    participant Config as Config()\n    participant URLMap as URL Map()\n\n    UserCode->>+Flask: app = Flask(__name__)\n    Flask->>+App: Initialize base features (paths, folders)\n    App-->>-Flask: Base initialized\n    Flask->>+Config: Create config object (self.config)\n    Config-->>-Flask: Config ready\n    Flask->>+URLMap: Create URL map (self.url_map)\n    URLMap-->>-Flask: Map ready\n    Flask-->>-UserCode: Return Flask instance (app)\n```\n\n----------------------------------------\n\nTITLE: Initializing dspy.Example from a Dictionary in Python\nDESCRIPTION: Illustrates creating a `dspy.Example` object by passing a Python dictionary to its constructor. The dictionary keys (`english_sentence`, `french_sentence`) become the fields of the `Example`. Accessing fields via attribute notation is also shown. Depends on the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndata_dict = {\n    \"english_sentence\": \"How are you?\",\n    \"french_sentence\": \"Comment ça va?\"\n}\nexample2 = dspy.Example(data_dict)\n\nprint(f\"Example 2 English: {example2.english_sentence}\")\n```\n\n----------------------------------------\n\nTITLE: Advanced Response Hooks in Python Requests\nDESCRIPTION: This snippet shows two advanced hook functions: one that modifies the response by adding a custom header, and another (commented out) that replaces the response entirely under certain conditions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef add_custom_header_hook(response, *args, **kwargs):\n    \"\"\"Adds a custom header to the received response.\"\"\"\n    print(\"HOOK: Adding X-Hook-Processed header...\")\n    response.headers['X-Hook-Processed'] = 'True'\n    # We modified the response in-place, so we return None\n    # to let requests continue using the modified response.\n    return None\n\n# Or, a hook that returns a *new* response (less common)\n# def replace_response_hook(response, *args, **kwargs):\n#     if response.status_code == 404:\n#         print(\"HOOK: Replacing 404 response with a custom one!\")\n#         new_response = requests.Response()\n#         new_response.status_code = 200\n#         new_response.reason = \"Found via Hook\"\n#         new_response._content = b\"Content generated by hook!\"\n#         new_response.request = response.request # Keep original request link\n#         return new_response # Return the NEW response\n#     return None # Otherwise, keep the original response\n```\n\n----------------------------------------\n\nTITLE: Setting Up Basic QA Program and Initial Evaluation in DSPy\nDESCRIPTION: Defines a simple `BasicQA` program using `dspy.Predict`, an exact match metric (`simple_exact_match_metric`), and a small training dataset (`trainset`) composed of `dspy.Example` objects. It then evaluates the initial, unoptimized program's performance on this dataset using `dspy.evaluate.Evaluate` to establish a baseline score. Requires the `dspy` library and a pre-configured Language Model (LM).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\nfrom dspy.evaluate import Evaluate\n# Assume LM is configured (e.g., dspy.settings.configure(lm=...))\n\n# Our simple program\nclass BasicQA(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        self.predictor = dspy.Predict('question -> answer')\n\n    def forward(self, question):\n        return self.predictor(question=question)\n\n# Our metric from Chapter 7\ndef simple_exact_match_metric(gold, prediction, trace=None):\n    return prediction.answer.lower() == gold.answer.lower()\n\n# Our dataset from Chapter 7 (let's use it as a trainset now)\ndev_example1 = dspy.Example(question=\"What color is the sky?\", answer=\"blue\")\ndev_example2 = dspy.Example(question=\"What is 2 + 2?\", answer=\"4\")\ndev_example3 = dspy.Example(question=\"What is the capital of France?\", answer=\"Paris\")\n# Example our program might struggle with initially\ndev_example_hard = dspy.Example(question=\"Who painted the Mona Lisa?\", answer=\"Leonardo da Vinci\")\n\ntrainset = [dev_example1, dev_example2, dev_example3, dev_example_hard]\ntrainset = [d.with_inputs('question') for d in trainset]\n\n# Let's evaluate the initial program (likely imperfect)\ninitial_program = BasicQA()\nevaluator = Evaluate(devset=trainset, metric=simple_exact_match_metric, display_progress=False)\ninitial_score = evaluator(initial_program)\nprint(f\"Initial Score (on trainset): {initial_score}%\")\n# Might output: Initial Score (on trainset): 75.0% (assuming it fails the last one)\n```\n\n----------------------------------------\n\nTITLE: Request to Response Flow Diagram in Python Requests\nDESCRIPTION: This Mermaid sequence diagram illustrates the internal flow of a request in the Python Requests library, from the initial API call to receiving the Response object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/02_request___response_models.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as Your Code (e.g., requests.get)\n    participant Session as requests Session (Temporary or Explicit)\n    participant PrepReq as PreparedRequest\n    participant Adapter as Transport Adapter\n    participant Server as Web Server\n    participant Resp as Response\n\n    UserCode->>Session: Call get(url) / post(url, data=...)\n    Session->>Session: Create models.Request object\n    Session->>PrepReq: prepare_request(request) -> PreparedRequest\n    Note over PrepReq: Encodes data, adds headers, cookies etc.\n    Session->>Adapter: send(prepared_request)\n    Adapter->>Server: Send HTTP Request bytes\n    Server-->>Adapter: Send HTTP Response bytes\n    Adapter->>Resp: build_response(raw_reply) -> Response\n    Resp-->>Adapter: Return Response\n    Adapter-->>Session: Return Response\n    Session-->>UserCode: Return Response\n```\n\n----------------------------------------\n\nTITLE: Running Click Group Commands in Bash\nDESCRIPTION: Demonstrates how to use the multi-command Click application from the terminal. It shows accessing the main help screen and running individual commands within the group.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/01_command___group.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ python multi_app.py --help\nUsage: multi_app.py [OPTIONS] COMMAND [ARGS]...\n\n  A simple tool with multiple commands.\n\nOptions:\n  --help  Show this message and exit.\n\nCommands:\n  goodbye  Says Goodbye World\n  hello    Says Hello World\n\n$ python multi_app.py hello\nHello World!\n\n$ python multi_app.py goodbye\nGoodbye World!\n```\n\n----------------------------------------\n\nTITLE: Rendering an HTML Login Form via Flask - Python\nDESCRIPTION: This snippet defines a Flask route that returns a raw HTML login form when accessed via a GET request. It uses the Flask app and the request object, with the form method set to POST for subsequent submission. No credentials are processed at this stage; the HTML is sent directly as the response body. Users must later POST to the same URL for form submission handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\nfrom flask import Flask, request, make_response # Import make_response\n\napp = Flask(__name__)\n\n@app.route('/login', methods=['GET']) # Only allow GET for this view\ndef show_login_form():\n  # Just return the raw HTML for the form\n  return '''\n      <form method=\"POST\">\n          Username: <input type=\"text\" name=\"username\"><br>\n          Password: <input type=\"password\" name=\"password\"><br>\n          <input type=\"submit\" value=\"Log In\">\n      </form>\n  '''\n# ... (add the next route below)\n```\n\n----------------------------------------\n\nTITLE: Inspecting FieldInfo Objects in Pydantic Models\nDESCRIPTION: Shows how to access and inspect the internal FieldInfo objects that store all field metadata through the model_fields dictionary.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from the User model above\n\n# Access the internal FieldInfo objects\nprint(User.model_fields['name'])\n# Expected Output (representation may vary slightly):\n# FieldInfo(annotation=str, required=False, default='Guest', alias='userName', alias_priority=2, validation_alias='userName', serialization_alias='userName', metadata=[MinLen(min_length=3)])\n\nprint(User.model_fields['age'])\n# Expected Output:\n# FieldInfo(annotation=int, required=False, default=18, metadata=[Gt(gt=0)])\n\nprint(User.model_fields['email'])\n# Expected Output:\n# FieldInfo(annotation=Union[str, NoneType], required=False, default=None, description='The user email address')\n```\n\n----------------------------------------\n\nTITLE: Adding Browser State to LLM Conversation History in Python\nDESCRIPTION: This method adds the current browser state and previous action results to the conversation history. It formats the state information into a HumanMessage, potentially including multi-modal content with text and images. It also handles the inclusion of previous action results in the history.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclass MessageManager:\n    # ... (init) ...\n\n    def add_state_message(\n        self,\n        state: BrowserState, # The current view of the browser\n        result: Optional[List[ActionResult]] = None, # Result from *previous* action\n        step_info: Optional[AgentStepInfo] = None,\n        use_vision=True, # Flag to include screenshot\n    ) -> None:\n        \"\"\"Add browser state and previous result as a human message.\"\"\"\n\n        # Add any 'memory' messages from the previous result first (if any)\n        if result:\n            for r in result:\n                if r.include_in_memory and (r.extracted_content or r.error):\n                    content = f\"Action result: {r.extracted_content}\" if r.extracted_content else f\"Action error: {r.error}\"\n                    msg = HumanMessage(content=content)\n                    self._add_message_with_tokens(msg)\n                    result = None # Don't include again in the main state message\n\n        # Use a helper class to format the BrowserState (+ optional remaining result)\n        # into the correct message structure (text + optional image)\n        state_prompt = AgentMessagePrompt(\n            state,\n            result, # Pass any remaining result info\n            include_attributes=self.settings.include_attributes,\n            step_info=step_info,\n        )\n        # Get the formatted message (could be complex list for vision)\n        state_message = state_prompt.get_user_message(use_vision)\n\n        # Add the formatted message (with token calculation) to history\n        self._add_message_with_tokens(state_message)\n```\n\n----------------------------------------\n\nTITLE: BinaryOperatorAggregate Usage Example\nDESCRIPTION: Example showing how to explicitly use BinaryOperatorAggregate channel with operator.add in a TypedDict state definition.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport operator\nfrom typing import TypedDict, Annotated\nfrom langgraph.channels import BinaryOperatorAggregate\n\nclass AgentState(TypedDict):\n    total_score: Annotated[int, BinaryOperatorAggregate(int, operator.add)]\n```\n\n----------------------------------------\n\nTITLE: Defining LLMExtractionStrategy Class in Python\nDESCRIPTION: This Python class `LLMExtractionStrategy` implements a data extraction strategy using Large Language Models (LLMs). It takes a schema or instruction, LLM configuration, and input format during initialization. The `extract` method constructs a prompt, calls the LLM API using `perform_completion_with_backoff`, and parses the expected JSON response. The `_build_llm_prompt` method handles the creation of the prompt based on templates and input data. The `run` method (currently simplified) is intended to manage content chunking before extraction. Dependencies include `perform_completion_with_backoff`, `chunk_documents`, `escape_json_string` utilities, and `PROMPT_EXTRACT_SCHEMA_WITH_INSTRUCTION`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/06_extractionstrategy.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Needs imports for LLM interaction (e.g., perform_completion_with_backoff)\nfrom .utils import perform_completion_with_backoff, chunk_documents, escape_json_string\nfrom .prompts import PROMPT_EXTRACT_SCHEMA_WITH_INSTRUCTION # Example prompt\n\nclass LLMExtractionStrategy(ExtractionStrategy):\n    def __init__(self, schema: Dict = None, instruction: str = None, llmConfig=None, input_format=\"markdown\", **kwargs):\n        super().__init__(input_format=input_format, **kwargs)\n        self.schema = schema\n        self.instruction = instruction\n        self.llmConfig = llmConfig # Contains provider, API key, etc.\n        # ... other LLM specific setup ...\n\n    def extract(self, url: str, content_chunk: str, *q, **kwargs) -> List[Dict[str, Any]]:\n        # Prepare the prompt for the LLM\n        prompt = self._build_llm_prompt(url, content_chunk)\n\n        # Call the LLM API\n        response = perform_completion_with_backoff(\n            provider=self.llmConfig.provider,\n            prompt_with_variables=prompt,\n            api_token=self.llmConfig.api_token,\n            base_url=self.llmConfig.base_url,\n            json_response=True # Often expect JSON from LLM for extraction\n            # ... pass other necessary args ...\n        )\n\n        # Parse the LLM's response (which should ideally be JSON)\n        try:\n            extracted_data = json.loads(response.choices[0].message.content)\n            # Ensure it's a list\n            if isinstance(extracted_data, dict):\n                extracted_data = [extracted_data]\n            return extracted_data\n        except Exception as e:\n            # Handle LLM response parsing errors\n            print(f\"Error parsing LLM response: {e}\")\n            return [{\"error\": \"Failed to parse LLM output\", \"raw_output\": response.choices[0].message.content}]\n\n    def _build_llm_prompt(self, url: str, content_chunk: str) -> str:\n        # Logic to construct the prompt using self.schema or self.instruction\n        # and the content_chunk. Example:\n        prompt_template = PROMPT_EXTRACT_SCHEMA_WITH_INSTRUCTION # Choose appropriate prompt\n        variable_values = {\n            \"URL\": url,\n            \"CONTENT\": escape_json_string(content_chunk), # Send Markdown or HTML chunk\n            \"SCHEMA\": json.dumps(self.schema) if self.schema else \"{}\",\n            \"REQUEST\": self.instruction if self.instruction else \"Extract relevant data based on the schema.\"\n        }\n        prompt = prompt_template\n        for var, val in variable_values.items():\n            prompt = prompt.replace(\"{\" + var + \"}\", str(val))\n        return prompt\n\n    # run() method might override the base to handle chunking specifically for LLMs\n    def run(self, url: str, sections: List[str], *q, **kwargs) -> List[Dict[str, Any]]:\n        # Potentially chunk sections based on token limits before calling extract\n        # chunked_content = chunk_documents(sections, ...)\n        # extracted_data = []\n        # for chunk in chunked_content:\n        #    extracted_data.extend(self.extract(url, chunk, **kwargs))\n        # return extracted_data\n        # Simplified for now:\n        return super().run(url, sections, *q, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Manual Logging in Python Requests (Inefficient)\nDESCRIPTION: This snippet demonstrates the inefficient way of manually logging responses after each request. It shows why a hook system is needed for automating such tasks.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Manual logging (Repetitive!)\nresponse1 = s.get('https://api.service1.com/data')\nprint(f\"LOG: Got {response1.status_code} for {response1.url}\")\n# ... process response1 ...\n\nresponse2 = s.post('https://api.service2.com/action', data={'key': 'value'})\nprint(f\"LOG: Got {response2.status_code} for {response2.url}\")\n# ... process response2 ...\n\nresponse3 = s.get('https://api.service1.com/status')\nprint(f\"LOG: Got {response3.status_code} for {response3.url}\")\n# ... process response3 ...\n```\n\n----------------------------------------\n\nTITLE: Invoking Tools with ToolManager in FastMCP (Python)\nDESCRIPTION: This snippet demonstrates the simplified implementation of the ToolManager's call_tool method, which is responsible for executing tools in FastMCP. It finds the requested tool by name and calls its run method with the provided arguments.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/04_fastmcp_tools___tool____toolmanager__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Inside server/fastmcp/tools/tool_manager.py (Simplified ToolManager.call_tool)\nclass ToolManager:\n    # ... (init, add_tool, list_tools) ...\n\n    async def call_tool(self, name, arguments, context=None):\n        # 1. Find the tool by name\n        tool = self.get_tool(name)\n        if not tool:\n            raise ToolError(f\"Unknown tool: {name}\")\n\n        # 2. Tell the Tool object to run with the arguments\n        logger.debug(f\"Calling tool: {name} with args: {arguments}\")\n        result = await tool.run(arguments, context=context)\n        return result\n```\n\n----------------------------------------\n\nTITLE: Adding GreetingTool to MultiStepAgent in Python\nDESCRIPTION: This snippet shows how to create a MultiStepAgent with the custom GreetingTool. It demonstrates initializing the tool, setting up the language model, and creating the agent with the tool in its toolbox.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent_with_greeting.py ---\n# (Assuming GreetingTool is defined as above or imported)\n# from simple_tools import GreetingTool\nfrom smolagents import MultiStepAgent\nfrom smolagents.models import LiteLLMModel # From Chapter 2\n# Potentially other tools like SearchTool etc.\n\n# 1. Create an instance of our new tool\ngreeting_tool = GreetingTool()\n\n# 2. Create instances of any other tools the agent might need\n# search_tool = SearchTool() # Example from Chapter 1\n\n# 3. Choose a language model (the \"brain\")\nllm = LiteLLMModel(model_id=\"gpt-3.5-turbo\") # Needs API key setup\n\n# 4. Create the MultiStepAgent, passing the tool(s) in a list\nagent = MultiStepAgent(\n    model=llm,\n    tools=[greeting_tool] # Add our tool here! Maybe add search_tool too?\n    # tools=[greeting_tool, search_tool]\n)\n\nprint(\"Agent created with GreetingTool!\")\n\n# 5. Give the agent a task that might use the tool\ntask = \"Greet the user named Bob.\"\nprint(f\"Running agent with task: '{task}'\")\n\n# The agent will now start its Think-Act-Observe cycle...\nfinal_answer = agent.run(task)\n\nprint(\"-\" * 20)\nprint(f\"Final Answer received: {final_answer}\")\n\n# --- Expected Interaction (Simplified) ---\n# Agent (thinks): The task is to greet Bob. I have a 'greet_person' tool.\n# Agent (acts): Use tool 'greet_person' with input name=\"Bob\".\n# --- GreetingTool activated with name: Bob --- (Our print statement)\n# Agent (observes): Tool returned \"Hello, Bob! Nice to meet you.\"\n# Agent (thinks): I have the greeting. That completes the task.\n# Agent (acts): Use 'final_answer' tool with \"Hello, Bob! Nice to meet you.\"\n# --------------------\n# Final Answer received: Hello, Bob! Nice to meet you.\n```\n\n----------------------------------------\n\nTITLE: Refreshing UI State via Polling in Python\nDESCRIPTION: This asynchronous Python function `refresh_app_state` is triggered by a Mesop `async_poller` component based on a web event. It accesses the current application state (`AppState`) and calls the `UpdateAppState` function (likely located in `host_agent_service.py`) to fetch the latest state from the backend service. This update triggers a re-render in the Mesop UI.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/components/page_scaffold.py (Simplified Snippet)\nasync def refresh_app_state(e: mel.WebEvent): # Triggered by poller\n    yield\n    app_state = me.state(AppState)\n    # Call backend service to get the latest state\n    await UpdateAppState(app_state, app_state.current_conversation_id)\n    yield\n# ... in page_scaffold component setup ...\nasync_poller(action=..., trigger_event=refresh_app_state)\n```\n\n----------------------------------------\n\nTITLE: Defining a DSPy Signature for Translation in Python\nDESCRIPTION: Shows how to define a `dspy.Signature` subclass `TranslateToFrench` with `InputField` (`english_sentence`) and `OutputField` (`french_sentence`) to specify the structure for a translation task. This signature is reused from a previous chapter and provides context for demonstrating `dspy.Example`. Dependencies include the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# From Chapter 2\nimport dspy\nfrom dspy.signatures.field import InputField, OutputField\n\nclass TranslateToFrench(dspy.Signature):\n    \"\"\"Translates English text to French.\"\"\"\n    english_sentence = dspy.InputField(desc=\"The original sentence in English\")\n    french_sentence = dspy.OutputField(desc=\"The translated sentence in French\")\n```\n\n----------------------------------------\n\nTITLE: Defining JSON Response Format for Browser Automation AI\nDESCRIPTION: This snippet demonstrates the expected JSON structure that the AI assistant should use when responding. It includes the current state evaluation, memory, next goal, and planned actions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/02_system_prompt.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"current_state\": {\n    \"evaluation_previous_goal\": \"Success - Found the search bar.\",\n    \"memory\": \"On google.com main page. Need to search for cats.\",\n    \"next_goal\": \"Type 'cute cat pictures' into the search bar.\"\n  },\n  \"action\": [\n    {\n      \"input_text\": {\n        \"index\": 5,\n        \"text\": \"cute cat pictures\"\n      }\n    },\n    {\n      \"press_keys\": {\n        \"keys\": \"Enter\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Inspecting a NumPy Array in Python\nDESCRIPTION: Demonstrates the basic creation of a NumPy array and accessing its properties, highlighting the operations that are actually implemented in the multiarray C module.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# How does this seemingly simple line actually work?\nmy_array = np.array([1, 2, 3, 4, 5])\n\n# How does NumPy know its shape? How is the data stored?\nprint(my_array)\nprint(my_array.shape)\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram Illustrating Pydantic Decorator Processing\nDESCRIPTION: This Mermaid sequence diagram shows the interaction flow when Pydantic processes a model class with a `@field_validator` decorator. It highlights how the metaclass detects the decorator, stores its information (using internal structures like DecoratorInfos), and requests the Pydantic Core Engine to incorporate this logic into the Core Schema, which is then used to generate validation functions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Dev as Developer\n    participant Py as Python Interpreter\n    participant Meta as BaseModel Metaclass\n    participant DecInfo as DecoratorInfos\n    participant Core as Pydantic Core Engine\n\n    Dev->>Py: Define `class User(BaseModel): ... @field_validator('username') def check_spaces(cls, v): ...`\n    Py->>Meta: Ask to create the `User` class\n    Meta->>Meta: Scan class attributes, find `check_spaces` wrapped by PydanticDescriptorProxy\n    Meta->>DecInfo: Store info: func=check_spaces, applies_to='username', mode='after'\n    Meta->>Core: Request Core Schema, providing field info AND DecoratorInfos\n    Core->>Core: Build schema, incorporating an 'after_validator' step for 'username' linked to `check_spaces`\n    Core-->>Meta: Provide internal Core Schema for User\n    Meta->>Core: Request validator/serializer functions from schema\n    Core-->>Meta: Provide optimized functions incorporating custom logic\n    Meta-->>Py: Return the fully prepared `User` class\n    Py-->>Dev: `User` class is ready\n```\n\n----------------------------------------\n\nTITLE: Managing Sessions with Context Manager Using Requests (Python)\nDESCRIPTION: This snippet illustrates how to use requests.Session as a context manager with the with statement in Python. No additional dependencies besides requests are required. It shows setting cookies within the 'with' block and verifies their presence via a request, while emphasizing that session resources are released automatically after the block. Inputs include endpoints for setting and checking cookies; output is printed JSON from httpbin. Using the Session as a context manager is recommended for resource cleanup and error safety.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/03_session.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\\n\\nurl = 'https://httpbin.org/cookies'\\n\\n# Use the Session as a context manager\\nwith requests.Session() as s:\\n    s.get('https://httpbin.org/cookies/set/contextcookie/abc')\\n    response = s.get(url)\\n    print(\"Cookies sent within 'with' block:\", response.json())\\n\\n# After the 'with' block, the session 's' is automatically closed.\\n# Making a request now might fail or use a new connection pool if s was reused (not recommended)\\n# print(\"\\nTrying to use session after 'with' block (might not work as expected)...\")\\n# try:\\n#    response_after = s.get(url)\\n#    print(response_after.text)\\n# except Exception as e:\\n#    print(f\"Error using session after close: {e}\")\\n\\nprint(\"\\nSession automatically closed after 'with' block.\")\\n\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry in Linux/macOS Terminal\nDESCRIPTION: Demonstrates how to disable telemetry on Linux or macOS by setting the ANONYMIZED_TELEMETRY environment variable to False before running the Python script.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANONYMIZED_TELEMETRY=False\n# Now run your Python script in the same terminal\npython your_agent_script.py\n```\n\n----------------------------------------\n\nTITLE: Defining the Agent Class Structure and Task Execution in Python\nDESCRIPTION: This Python class defines an 'Agent' inheriting from 'BaseAgent' and using Pydantic 'Field' for attribute definitions like 'role', 'goal', 'backstory', 'llm', and 'tools'. The 'execute_task' method takes a 'Task' object and optional 'context' and 'tools', prepares a comprehensive prompt including context and agent details, ensures the internal 'agent_executor' is created via 'create_agent_executor', and then invokes the executor with the prompt and tool information to get the final string output. The 'create_agent_executor' method (implementation omitted) is responsible for initializing the component that handles the LLM interaction loop. Dependencies include BaseAgent, BaseTool, Task, Field, Any, Optional, and List from relevant libraries (likely CrewAI and typing).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/02_agent.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# ... other imports\n\nclass Agent(BaseAgent):\n    role: str = Field(description=\"Role of the agent\")\n    goal: str = Field(description=\"Objective of the agent\")\n    backstory: str = Field(description=\"Backstory of the agent\")\n    llm: Any = Field(default=None, description=\"LLM instance\")\n    tools: Optional[List[BaseTool]] = Field(default_factory=list)\n    allow_delegation: bool = Field(default=False)\n    verbose: bool = Field(default=False)\n    # ... other fields like memory, max_iter, etc.\n\n    def execute_task(\n        self,\n        task: Task,\n        context: Optional[str] = None,\n        tools: Optional[List[BaseTool]] = None,\n    ) -> str:\n        # ... (steps 1 & 2: Prepare task prompt with context, memory, knowledge) ...\n\n        task_prompt = task.prompt() # Get base task description\n        if context:\n            task_prompt = f\"{task_prompt}\\nContext:\\n{context}\"\n        # Add memory, knowledge, tool descriptions etc. to the prompt...\n\n        # ... (Internal setup: Create AgentExecutor if needed) ...\n        self.create_agent_executor(tools=tools or self.tools)\n\n        # ... (Step 3-7: Run the execution loop via AgentExecutor) ...\n        result = self.agent_executor.invoke({\n            \"input\": task_prompt,\n            \"tool_names\": self._get_tool_names(self.agent_executor.tools),\n            \"tools\": self._get_tool_descriptions(self.agent_executor.tools),\n            # ... other inputs for the executor ...\n        })[\"output\"] # Extract the final string output\n\n        return result\n\n    def create_agent_executor(self, tools: Optional[List[BaseTool]] = None) -> None:\n        # Sets up the internal CrewAgentExecutor which handles the actual\n        # interaction loop with the LLM and tools.\n        # It uses the agent's profile (role, goal, backstory) to build the main prompt.\n        pass\n\n    # ... other helper methods ...\n```\n\n----------------------------------------\n\nTITLE: Example Output from Running a Flask Development Server\nDESCRIPTION: Displays typical output generated in the terminal when running a Flask application using `app.run(debug=True)`. It shows the application name ('hello'), debug mode status, the local URL where the server is accessible (http://127.0.0.1:5000), instructions to stop the server, and debugger information. This confirms the development server has started successfully.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/01_application_object___flask__.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n * Serving Flask app 'hello'\n * Debug mode: on\n * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n * Restarting with stat\n * Debugger is active!\n * Debugger PIN: ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving Current Version for Read Operation in LevelDB (C++)\nDESCRIPTION: This simplified C++ snippet from `DBImpl::Get` demonstrates how LevelDB handles a read request when the key is not found in memory. It acquires a mutex, obtains the current `Version` object from the `VersionSet`, increments its reference count, performs the lookup by calling `current->Get()`, decrements the reference count, and releases the mutex. Proper reference counting ensures the `Version` object remains valid during the potentially slow disk I/O operation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/06_version___versionset.md#2025-04-22_snippet_0\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/db_impl.cc Get() ---\n\nStatus DBImpl::Get(const ReadOptions& options, const Slice& key,\n                   std::string* value) {\n  // ... check MemTable, Immutable MemTable first ...\n\n  // If not found in memory, check SSTables:\n  else {\n    MutexLock l(&mutex_); // Need lock to get current Version pointer safely\n    Version* current = versions_->current(); // Ask VersionSet for current Version\n    current->Ref();       // Increment ref count (important!)\n    mutex_.Unlock();      // Unlock for potentially slow disk I/O\n\n    LookupKey lkey(key, snapshot_sequence_number); // Key to search for\n    Version::GetStats stats;\n    // Ask the Version object to perform the lookup in its files\n    Status s = current->Get(options, lkey, value, &stats);\n\n    mutex_.Lock();        // Re-acquire lock for cleanup\n    current->Unref();     // Decrement ref count\n    // ... maybe trigger compaction based on stats ...\n    mutex_.Unlock();\n    return s;\n  }\n  // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Using a DSPy Signature with dspy.Predict in Python\nDESCRIPTION: Shows how to instantiate and use a dspy.Predict module with a custom Signature class (TranslateToFrench). After configuring a Language Model (not shown here), dspy.Predict is constructed with the signature, and called by passing the input field as a keyword argument. The returned object contains the output fields as attributes. This requires a properly configured LM (e.g., dspy.OpenAI) and a valid signature definition.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/02_signature.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Assume 'lm' is a configured Language Model client (more in Chapter 5)\n# lm = dspy.OpenAI(model='gpt-3.5-turbo')\n# dspy.settings.configure(lm=lm)\n\n# Create an instance of dspy.Predict, giving it our Signature\ntranslator = dspy.Predict(TranslateToFrench)\n\n# Call the predictor with the required input field\nenglish = \"Hello, how are you?\"\nresult = translator(english_sentence=english)\n\n# The result object will contain the output field defined in the signature\nprint(f\"English: {english}\")\n# Assuming the LM works correctly, it might print:\n# print(f\"French: {result.french_sentence}\") # => French: Bonjour, comment ça va?\n\n```\n\n----------------------------------------\n\nTITLE: Implicitly Configuring Agent LLM via Environment Variables (Python)\nDESCRIPTION: Shows a simplified CrewAI Agent definition where the `llm` parameter is omitted. If `OPENAI_API_KEY` and optionally `OPENAI_MODEL_NAME` are set in the environment, CrewAI attempts to automatically configure the agent's LLM using these settings. Depends on the `crewai` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# agent.py (simplified)\nfrom crewai import Agent\n\n# If OPENAI_API_KEY and OPENAI_MODEL_NAME are set in the environment,\n# CrewAI might automatically configure an OpenAI LLM for this agent.\nresearcher = Agent(\n    role='Travel Researcher',\n    goal='Find interesting cities in Europe',\n    backstory='Expert researcher.',\n    # No 'llm=' parameter needed here if env vars are set\n)\n```\n\n----------------------------------------\n\nTITLE: Defining and Preparing HTTP Requests with Requests (Python)\nDESCRIPTION: This snippet defines the Request and PreparedRequest classes, which represent user-constructed HTTP requests and their finalized, network-ready forms in the Requests library. The Request class captures initial parameters and offers a method to produce a PreparedRequest; the latter prepares the parameters (URL, headers, data, etc.) for transmission. Key dependencies include proper handling or stubbing of attributes and the assumption that the actual logic for encoding and header management is implemented. Inputs are method, url, headers, files, data, params, auth, cookies, hooks, and json; outputs are finalized PreparedRequest objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/02_request___response_models.md#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nclass Request:\n    \"\"\"A user-created Request object. Used to prepare a PreparedRequest.\"\"\"\n    def __init__(self, method=None, url=None, headers=None, files=None,\n                 data=None, params=None, auth=None, cookies=None, hooks=None, json=None):\n        self.method = method\n        self.url = url\n        # ... other attributes ...\n\n    def prepare(self):\n        \"\"\"Constructs a PreparedRequest for transmission.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            # ... pass other attributes ...\n        )\n        return p\n\nclass PreparedRequest:\n    \"\"\"The fully mutable PreparedRequest object, containing the exact bytes\n    that will be sent to the server.\"\"\"\n    def __init__(self):\n        self.method = None\n        self.url = None\n        self.headers = None\n        self.body = None\n        # ... other attributes ...\n\n    def prepare(self, method=None, url=None, headers=None, files=None, data=None,\n                params=None, auth=None, cookies=None, hooks=None, json=None):\n        \"\"\"Prepares the entire request.\"\"\"\n        # ... Logic to encode data, set headers, handle auth, etc. ...\n        self.method = method\n        self.url = # processed url\n        self.headers = # final headers\n        self.body = # encoded body bytes or stream\n        # ...\n\n```\n\n----------------------------------------\n\nTITLE: Sequence Flow of Hook Dispatch in Requests - Mermaid\nDESCRIPTION: Presents, using the Mermaid sequence diagram syntax, the chronological call sequence for a request in requests: from the user's code, through session and adapter selection, hook dispatching, and eventual response return. Helps visualize how hooks fit into the request/response pipeline. No dependencies are required to understand, but a Mermaid renderer is needed for graphical display. The diagram does not execute but provides a reference for implementation context.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as Your Code\n    participant Session as Session Object\n    participant Adapter as Transport Adapter\n    participant Hooks as dispatch_hook()\n\n    UserCode->>Session: s.get(url) / s.post(url)\n    Session->>Session: Calls prepare_request()\n    Session->>Session: Gets adapter based on URL\n    Session->>Adapter: adapter.send(request)\n    activate Adapter\n    Note over Adapter: Sends request, gets raw response\n    Adapter->>Adapter: build_response() -> Response 'r'\n    Adapter-->>Session: Return Response 'r'\n    deactivate Adapter\n\n    Note over Session: Merges request and session hooks\n    Session->>Hooks: dispatch_hook('response', merged_hooks, r)\n    activate Hooks\n    Note over Hooks: Iterates through registered hook functions\n    Hooks->>Hooks: Call each hook_function(r)\n    Note over Hooks: Hook might modify 'r' or return a new one\n    Hooks-->>Session: Return (potentially modified) Response 'r'\n    deactivate Hooks\n\n    Note over Session: Persist cookies from 'r', handle redirects...\n    Session-->>UserCode: Return final Response 'r'\n\n```\n\n----------------------------------------\n\nTITLE: Flow Chart of Browser Use Architecture using Mermaid\nDESCRIPTION: A mermaid flowchart diagram showing the architecture and component relationships of the Browser Use system. It illustrates how the Agent interacts with various components including BrowserContext, Action Controller, DOM Representation, Message Manager, System Prompt, Data Structures, and Telemetry Service.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Agent\"]\n    A1[\"BrowserContext\"]\n    A2[\"Action Controller & Registry\"]\n    A3[\"DOM Representation\"]\n    A4[\"Message Manager\"]\n    A5[\"System Prompt\"]\n    A6[\"Data Structures (Views)\"]\n    A7[\"Telemetry Service\"]\n    A0 -- \"Gets state from\" --> A1\n    A0 -- \"Uses to execute actions\" --> A2\n    A0 -- \"Uses for LLM communication\" --> A4\n    A0 -- \"Gets instructions from\" --> A5\n    A0 -- \"Uses/Produces data formats\" --> A6\n    A0 -- \"Logs events to\" --> A7\n    A1 -- \"Gets DOM structure via\" --> A3\n    A1 -- \"Provides BrowserState\" --> A6\n    A2 -- \"Executes actions on\" --> A1\n    A2 -- \"Defines/Uses ActionModel/Ac...\" --> A6\n    A2 -- \"Logs registered functions to\" --> A7\n    A3 -- \"Provides structure to\" --> A1\n    A3 -- \"Uses DOM structures\" --> A6\n    A4 -- \"Provides messages to\" --> A0\n    A4 -- \"Initializes with\" --> A5\n    A4 -- \"Formats data using\" --> A6\n    A5 -- \"Defines structure for Agent...\" --> A6\n    A7 -- \"Receives events from\" --> A0\n```\n\n----------------------------------------\n\nTITLE: Fetching Agent Card using Python Requests\nDESCRIPTION: This Python function `get_agent_card` demonstrates how to retrieve an agent's Agent Card (agent.json) from its standard location (`/.well-known/agent.json`). It uses the `requests` library to perform an HTTP GET request to the constructed URL, raises an exception for bad status codes, and parses the received JSON response into a structured `AgentCard` object. An example usage block shows how to call the function and handle potential network errors.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/01_agent_card.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/utils/agent_card.py (simplified)\nimport requests # A library to make web requests\nfrom common.types import AgentCard # A helper to understand the card's structure\n\ndef get_agent_card(remote_agent_address: str) -> AgentCard:\n  \"\"\"Gets the agent card from the agent's address.\"\"\"\n  agent_card_url = f\"{remote_agent_address}/.well-known/agent.json\"\n  print(f\"Fetching card from: {agent_card_url}\")\n  # Make a web request to get the file\n  response = requests.get(agent_card_url)\n  response.raise_for_status() # Check if the request was successful\n  # Parse the JSON file content into an AgentCard object\n  return AgentCard(**response.json())\n\n# Example Usage:\nagent_address = \"http://example-agent.com\" # Assume our agent is here\ntry:\n  card = get_agent_card(agent_address)\n  print(f\"Got card for agent: {card.name}\")\nexcept requests.exceptions.RequestException as e:\n  print(f\"Could not fetch card: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Catching Any Requests Error in Python\nDESCRIPTION: This snippet demonstrates how to use a try-except block to catch any error from the Requests library when making an HTTP GET request. It includes error handling for connection issues, timeouts, and HTTP status errors.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# A URL that might cause a connection error (e.g., non-existent domain)\nbad_url = 'https://this-domain-probably-does-not-exist-asdfghjkl.com'\ngood_url = 'https://httpbin.org/get'\n\nurl_to_try = bad_url # Change to good_url to see success case\n\nprint(f\"Trying to fetch: {url_to_try}\")\n\ntry:\n    response = requests.get(url_to_try, timeout=5) # Add timeout\n    response.raise_for_status() # Check for 4xx/5xx errors\n    print(\"Success! Status Code:\", response.status_code)\n    # Process the response... (e.g., print response.text)\n\nexcept requests.exceptions.RequestException as e:\n    # This will catch ANY error originating from requests\n    print(f\"\\nOh no! A requests-related error occurred:\")\n    print(f\"Error Type: {type(e).__name__}\")\n    print(f\"Error Details: {e}\")\n\nprint(\"\\nScript continues after handling the error.\")\n```\n\n----------------------------------------\n\nTITLE: Defining Knowledge Source and Knowledge Object in Python with CrewAI\nDESCRIPTION: This snippet demonstrates how to create a Knowledge object using a text file as a source. It shows the setup of CrewDoclingSource and the Knowledge object, which will process and store the content of the manual in a vector database.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/08_knowledge.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Agent, Task, Crew, Process, Knowledge\nfrom crewai.knowledge.source.crew_docling_source import CrewDoclingSource\n\nmanual_source = CrewDoclingSource(file_paths=[\"widget_pro_manual.txt\"])\n\nproduct_knowledge = Knowledge(\n    collection_name=\"widget_pro_manual\",\n    sources=[manual_source],\n)\n```\n\n----------------------------------------\n\nTITLE: Example Message List Format for Chat Language Models\nDESCRIPTION: Shows the structured list-of-dictionaries format expected by modern chat-based Language Models (like GPT-4, Claude 3). Each dictionary represents a message with a specific `role` (system, user, assistant) and `content`. This example demonstrates how instructions and input data might be formatted into system and user messages for a summarization task. This structure is typically generated by a DSPy Adapter like `ChatAdapter`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n[\n  {\"role\": \"system\", \"content\": \"Summarize the given text.\\n\\nFollow the following format.\\n\\nText: ${text}\\nSummary: ${summary}\"},\n  {\"role\": \"user\", \"content\": \"Text: DSPy is a framework for programming foundation models...\\nSummary:\"}\n]\n```\n\n----------------------------------------\n\nTITLE: Defining and Extending DSPy.Module Classes in Python\nDESCRIPTION: This Python snippet demonstrates the core inheritance and method-override patterns central to DSPy. It shows how custom user modules are derived from dspy.Module, with an emphasis on the roles of __init__, forward, and __call__ methods. The base Module class enforces that subclasses must implement forward, and the convenient __call__ method invokes forward directly. Dependencies include the dspy.primitives.module BaseModule. Inputs and outputs are flexible, depending on the user's forward implementation; subclasses must provide their own logic inside forward. Limitations: forward must be overridden, or NotImplementedError will be raised.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/01_module___program.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Snippet from dspy/primitives/program.py (Simplified)\\nfrom dspy.primitives.module import BaseModule\\n\\nclass Module(BaseModule): # Inherits from BaseModule\\n    def __init__(self):\\n        super()._base_init()\\n        # ... initialization ...\\n\\n    def forward(self, *args, **kwargs):\\n        # This is where the main logic of the module goes.\\n        # Users override this method in their own modules.\\n        raise NotImplementedError # Needs to be implemented by subclasses\\n\\n    def __call__(self, *args, **kwargs):\\n        # When you call module_instance(), this runs...\\n        # ...and typically calls self.forward()\\n        return self.forward(*args, **kwargs)\\n\\n# You write classes like this:\\nclass MyModule(dspy.Module):\\n    def __init__(self):\\n        super().__init__()\\n        # Your setup\\n\\n    def forward(self, input_data):\\n        # Your logic\\n        result = ...\\n        return result\n```\n\n----------------------------------------\n\nTITLE: Accessing Model Data in Pydantic\nDESCRIPTION: Example showing how to access data from a Pydantic model using standard attribute access. This demonstrates the object-oriented nature of Pydantic models.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from the user_alice example:\nprint(f\"User's Name: {user_alice.name}\")\n# Expected Output: User's Name: Alice\n\nprint(f\"User's Age: {user_alice.age}\")\n# Expected Output: User's Age: 30\n```\n\n----------------------------------------\n\nTITLE: Fetching Browser State with get_state in BrowserContext (Python)\nDESCRIPTION: Implements the `get_state` method within the `BrowserContext` class to capture the current state of the browser session. It first ensures the page is loaded and stable using `_wait_for_page_and_frames_load`. Then, it calls `_update_state` which uses `DomService` to analyze the DOM and interactive elements, takes a screenshot using `take_screenshot` (returning base64), retrieves metadata like URL, title, tabs, and scroll position, and packages all this information into a `BrowserState` object. Optional cookie saving is triggered if configured. Key dependencies include `DomService`, `BrowserState`, `asyncio`, and `base64`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/03_browsercontext.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: browser/context.py (Simplified get_state and helpers) ---\n# ... other imports ...\nfrom browser_use.dom.service import DomService # Imports the DOM analyzer\nfrom browser_use.browser.views import BrowserState # Imports the state structure\n\nclass BrowserContext:\n    # ... (init, aenter, etc.) ...\n\n    async def get_state(self) -> BrowserState:\n        \"\"\"Get the current state of the browser session.\"\"\"\n        logger.debug(f\"Getting state for context {self.context_id}...\")\n        # 1. Make sure the page is loaded and stable\n        await self._wait_for_page_and_frames_load()\n\n        # 2. Get the actual Playwright session object\n        session = await self.get_session()\n\n        # 3. Update the state (this does the heavy lifting)\n        session.cached_state = await self._update_state()\n        logger.debug(f\"State update complete for {self.context_id}.\")\n\n        # 4. Optionally save cookies if configured\n        if self.config.cookies_file:\n            asyncio.create_task(self.save_cookies())\n\n        return session.cached_state\n\n    async def _wait_for_page_and_frames_load(self, timeout_overwrite: float | None = None):\n         \"\"\"Ensures page is fully loaded before continuing.\"\"\"\n         # ... (complex logic to wait for network idle, minimum times) ...\n         page = await self.get_current_page()\n         await page.wait_for_load_state('load', timeout=5000) # Simplified wait\n         logger.debug(\"Page load/network stability checks passed.\")\n         await asyncio.sleep(self.config.minimum_wait_page_load_time) # Ensure minimum wait\n\n    async def _update_state(self) -> BrowserState:\n        \"\"\"Fetches all info and builds the BrowserState.\"\"\"\n        session = await self.get_session()\n        page = await self.get_current_page() # Get the active Playwright page object\n\n        try:\n            # Use DomService to analyze the page content\n            dom_service = DomService(page)\n            # Get the simplified DOM tree and interactive elements map\n            content_info = await dom_service.get_clickable_elements(\n                highlight_elements=self.config.highlight_elements,\n                # ... other DOM options ...\n            )\n\n            # Take a screenshot\n            screenshot_b64 = await self.take_screenshot()\n\n            # Get URL, Title, Tabs, Scroll info etc.\n            url = page.url\n            title = await page.title()\n            tabs = await self.get_tabs_info()\n            pixels_above, pixels_below = await self.get_scroll_info(page)\n\n            # Create the BrowserState object\n            browser_state = BrowserState(\n                element_tree=content_info.element_tree,\n                selector_map=content_info.selector_map,\n                url=url,\n                title=title,\n                tabs=tabs,\n                screenshot=screenshot_b64,\n                pixels_above=pixels_above,\n                pixels_below=pixels_below,\n            )\n            return browser_state\n\n        except Exception as e:\n            logger.error(f'Failed to update state: {str(e)}')\n            # Maybe return old state or raise error\n            raise BrowserError(\"Failed to get browser state\") from e\n\n    async def take_screenshot(self, full_page: bool = False) -> str:\n        \"\"\"Takes a screenshot and returns base64 encoded string.\"\"\"\n        page = await self.get_current_page()\n        screenshot_bytes = await page.screenshot(full_page=full_page, animations='disabled')\n        return base64.b64encode(screenshot_bytes).decode('utf-8')\n\n    # ... many other helper methods (_get_current_page, get_tabs_info, etc.) ...\n```\n\n----------------------------------------\n\nTITLE: Creating Function Call Request\nDESCRIPTION: Shows how to construct a FunctionCall message to request tool execution with appropriate parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom autogen_core import FunctionCall\n\ndate_call_request = FunctionCall(\n    id=\"call_date_001\",\n    name=\"get_current_date\",\n    arguments=\"{}\"\n)\n\nprint(\"FunctionCall message:\", date_call_request)\n```\n\n----------------------------------------\n\nTITLE: LLM Class Initialization Using Config\nDESCRIPTION: A simplified example of how the LLM class in OpenManus uses the Config system to obtain its settings during initialization, demonstrating the practical application of the configuration system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/llm.py __init__ method\n\nfrom app.config import config, LLMSettings # Import config and the schema\nfrom typing import Optional\n\nclass LLM:\n    # ... other methods ...\n    def __init__(self, config_name: str = \"default\", llm_config: Optional[LLMSettings] = None):\n        # If specific llm_config isn't provided, get it from the global config\n        if llm_config is None:\n            # Ask the global 'config' object for the settings\n            # corresponding to 'config_name' (e.g., \"default\")\n            llm_settings = config.llm.get(config_name)\n            if not llm_settings: # Handle case where the name doesn't exist\n                 llm_settings = config.llm.get(\"default\") # Fallback to default\n\n        else: # Use the provided config if given\n            llm_settings = llm_config\n\n\n        # Store the settings read from the config object\n        self.model = llm_settings.model\n        self.api_key = llm_settings.api_key\n        self.base_url = llm_settings.base_url\n        # ... store other settings like max_tokens, temperature ...\n\n        print(f\"LLM initialized with model: {self.model}\")\n        # Initialize the actual API client using these settings\n        # self.client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)\n        # ... rest of initialization ...\n```\n\n----------------------------------------\n\nTITLE: Loading Flask Config from Environment Variable\nDESCRIPTION: Demonstrates loading Flask configuration from an environment variable with error handling. Uses the YOURAPP_SETTINGS environment variable to specify the config file path.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nloaded = app.config.from_envvar('YOURAPP_SETTINGS', silent=True)\n\nif loaded:\n    print(f\"Loaded config from file specified in YOURAPP_SETTINGS: {app.config.get('SECRET_KEY')}\")\nelse:\n    print(\"YOURAPP_SETTINGS environment variable not set or file not found.\")\n    # You might want to set default configs here or raise an error\n\n# ... rest of your app ...\nif __name__ == '__main__':\n  app.run()\n```\n\n----------------------------------------\n\nTITLE: Fetching Repository Code or Files using Crawler Utilities - Python\nDESCRIPTION: This node downloads source files from a GitHub repository or reads them from a local directory using `crawl_github_files` or `crawl_local_files`. It reads and writes parameters and artifacts such as URLs, local directory paths, project names, token credentials, and file patterns to a shared store. The node outputs file contents as (path, content) tuples, and is designed for regular workflow execution, relying on Node's built-in fault tolerance and shared context management. Key parameters include repository URL, authentication token, inclusion/exclusion patterns, and output directory.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `repo_url`, `local_dir`, `project_name`, `github_token`, `output_dir`, `include_patterns`, `exclude_patterns`, `max_file_size` from shared store. Determine `project_name` from `repo_url` or `local_dir` if not present in shared. Set `use_relative_paths` flag.\n        *   `exec`: If `repo_url` is present, call `crawl_github_files(...)`. Otherwise, call `crawl_local_files(...)`. Convert the resulting `files` dictionary into a list of `(path, content)` tuples.\n        *   `post`: Write the list of `files` tuples and the derived `project_name` (if applicable) to the shared store.\n```\n\n----------------------------------------\n\nTITLE: Command Execution Router Implementation\nDESCRIPTION: Implementation of the command execution router that selects the appropriate execution method based on the sandbox type. It demonstrates how Codex routes commands to either raw execution or sandboxed execution, and includes special handling for file patching operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/06_command_execution___sandboxing.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/exec.ts (Simplified)\nimport type { ExecInput, ExecResult, SandboxType } from \"./sandbox/interface.js\";\nimport { execWithSeatbelt } from \"./sandbox/macos-seatbelt.js\";\nimport { exec as rawExec } from \"./sandbox/raw-exec.js\";\n// ... other imports like process_patch for apply_patch ...\n\n// Never rejects, maps errors to non-zero exit code / stderr\nexport function exec(\n  { cmd, workdir, timeoutInMillis }: ExecInput,\n  sandbox: SandboxType, // e.g., NONE, MACOS_SEATBELT\n  abortSignal?: AbortSignal,\n): Promise<ExecResult> {\n\n  // Decide which execution function to use\n  const execFunction =\n    sandbox === SandboxType.MACOS_SEATBELT ? execWithSeatbelt : rawExec;\n\n  const opts: SpawnOptions = { /* ... set timeout, workdir ... */ };\n  const writableRoots = [process.cwd(), os.tmpdir()]; // Basic allowed paths\n\n  // Call the chosen function (either raw or sandboxed)\n  return execFunction(cmd, opts, writableRoots, abortSignal);\n}\n\n// Special handler for apply_patch pseudo-command\nexport function execApplyPatch(patchText: string): ExecResult {\n  try {\n    // Use file system operations directly (fs.writeFileSync etc.)\n    const result = process_patch(/* ... patchText, fs functions ... */);\n    return { stdout: result, stderr: \"\", exitCode: 0 };\n  } catch (error: unknown) {\n    // Handle errors during patching\n    return { stdout: \"\", stderr: String(error), exitCode: 1 };\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Local Ollama LLM for a CrewAI Agent (Python)\nDESCRIPTION: Demonstrates how to configure a CrewAI agent to use a local LLM served by Ollama (e.g., Llama 3). It uses the `Ollama` wrapper from `langchain_community.llms`, specifying the `model` name and the `base_url` of the running Ollama server. Requires `crewai` and `langchain-community` libraries, and a running Ollama instance with the specified model pulled.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Make sure you have langchain_community installed: pip install langchain-community\nfrom langchain_community.llms import Ollama\nfrom crewai import Agent\n\n# Instantiate the Ollama LLM wrapper\n# Make sure Ollama server is running!\nollama_llm = Ollama(model=\"llama3\", base_url=\"http://localhost:11434\")\n# temperature, etc. can also be set if supported by the model/wrapper\n\n# Pass the configured LLM to the Agent\nlocal_researcher = Agent(\n    role='Travel Researcher',\n    goal='Find interesting cities in Europe',\n    backstory='Expert researcher.',\n    llm=ollama_llm # Use the local Llama 3 model\n)\n```\n\n----------------------------------------\n\nTITLE: FastMCP Message Flow Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram showing the interaction flow between Client, FastMCP Server, ToolManager, and Echo Function when processing an echo request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastMCP_Server as FastMCP (echo_server.py)\n    participant ToolManager as _tool_manager\n    participant EchoFunction as echo()\n\n    Client->>+FastMCP_Server: Send MCP Request: callTool(name=\"echo\", args={\"message\": \"Test\"})\n    FastMCP_Server->>+ToolManager: Find tool named \"echo\"\n    ToolManager-->>-FastMCP_Server: Return registered 'echo' function info\n    FastMCP_Server->>+EchoFunction: Call echo(message=\"Test\")\n    EchoFunction-->>-FastMCP_Server: Return \"You said: Test\"\n    FastMCP_Server->>-Client: Send MCP Response: result=\"You said: Test\"\n```\n\n----------------------------------------\n\nTITLE: Defining Configuration Constants for LevelDB\nDESCRIPTION: Key constants that control LevelDB's behavior, particularly related to compaction triggers, level counts, and threshold values for write operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_5\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/dbformat.h ---\n\nnamespace config {\nstatic const int kNumLevels = 7; // Number of levels in the LSM tree\n\n// Level-0 compaction is started when we hit this many files.\nstatic const int kL0_CompactionTrigger = 4;\n\n// Soft limit on number of level-0 files. We slow down writes at this point.\nstatic const int kL0_SlowdownWritesTrigger = 8;\n\n// Maximum number of level-0 files. We stop writes at this point.\nstatic const int kL0_StopWritesTrigger = 12;\n\n// Maximum level to push a new memtable compaction to if it doesn't overlap.\nstatic const int kMaxMemCompactLevel = 2;\n// ... other constants ...\n} // namespace config\n```\n\n----------------------------------------\n\nTITLE: Main Pregel Execution Loop Implementation\nDESCRIPTION: Core execution loop class that manages the step-by-step processing of the graph, coordinating task execution, state updates, and checkpoint management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/05_pregel_execution_engine.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass PregelLoop:\n    def run(self): # Simplified invoke/stream logic\n        with self: # Enters context (loads checkpoint, sets up channels)\n            while self.tick(): # tick executes one step\n                # Start tasks for the current step using PregelRunner\n                runner = PregelRunner(...)\n                for _ in runner.tick(self.tasks):\n                     # Yield control back, allowing writes/outputs to be streamed\n                     pass # (actual stream logic happens via callbacks)\n        return self.output # Return final result\n```\n\n----------------------------------------\n\nTITLE: BinaryOperatorAggregate Example Implementation\nDESCRIPTION: Example implementation showing how to use BinaryOperatorAggregate for summing values in a graph.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport operator\nfrom typing import TypedDict, Annotated\nfrom langgraph.graph import StateGraph, END, START\nfrom langgraph.channels import BinaryOperatorAggregate\n\nclass SummingState(TypedDict):\n    value: Annotated[int, BinaryOperatorAggregate(int, operator.add)]\n\ndef add_five(state: SummingState) -> dict:\n    print(f\"--- Running Adder Node 1 (current value: {state.get('value', 0)}) ---\")\n    return {\"value\": 5}\n\ndef add_ten(state: SummingState) -> dict:\n    print(f\"--- Running Adder Node 2 (current value: {state['value']}) ---\")\n    return {\"value\": 10}\n```\n\n----------------------------------------\n\nTITLE: Version Check Command\nDESCRIPTION: Command to verify MCP SDK installation and display version number\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/01_cli___mcp__command_.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmcp version\n```\n\n----------------------------------------\n\nTITLE: Implementing Confirmations with click.confirm()\nDESCRIPTION: Shows how to use click.confirm() to ask users yes/no questions before performing actions, with support for a --yes flag to bypass confirmation prompts for scripted usage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# confirm_example.py\nimport click\nimport time\n\n@click.command()\n@click.option('--yes', is_flag=True, help='Assume Yes to confirmation.')\ndef cli(yes):\n  \"\"\"Asks for confirmation.\"\"\"\n  click.echo(\"This might take a while or change things.\")\n\n  # If --yes flag is given, `yes` is True, otherwise ask.\n  # abort=True means if user says No, stop the program.\n  if not yes:\n    click.confirm(\"Do you want to continue?\", abort=True)\n\n  click.echo(\"Starting operation...\")\n  time.sleep(2) # Simulate work\n  click.echo(\"Done!\")\n\nif __name__ == '__main__':\n  cli()\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ python confirm_example.py\nThis might take a while or change things.\nDo you want to continue? [y/N]: y # User types 'y'\nStarting operation...\nDone!\n```\n\n----------------------------------------\n\nTITLE: Conceptual: Passing LM/RM Explicitly without dspy.settings (Python)\nDESCRIPTION: Illustrates a conceptual (and discouraged) approach where LM and RM instances are manually passed down through nested DSPy Modules. This highlights the complexity `dspy.settings` aims to solve by avoiding explicit parameter threading for common configurations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- WITHOUT dspy.settings (Conceptual - DON'T DO THIS) ---\nimport dspy\n\n# Assume lm_instance and rm_instance are created somewhere\n\nclass GenerateSearchQuery(dspy.Module):\n    def __init__(self, lm): # Needs LM passed in\n        self.predictor = dspy.Predict('question -> query', lm=lm) # Pass LM to Predict\n    # ... forward ...\n\nclass RetrieveContext(dspy.Module):\n    def __init__(self, rm): # Needs RM passed in\n        self.retriever = dspy.Retrieve(rm=rm, k=3) # Pass RM to Retrieve\n    # ... forward ...\n\n# ... other modules needing lm or rm ...\n\nclass ComplexRAG(dspy.Module):\n    def __init__(self, lm, rm): # Needs LM and RM passed in\n        self.gen_query = GenerateSearchQuery(lm=lm) # Pass LM down\n        self.retrieve = RetrieveContext(rm=rm)    # Pass RM down\n        # ... other sub-modules needing lm or rm ...\n\n    def forward(self, question, lm=None, rm=None): # Maybe pass them here too? Messy!\n        # ... use sub-modules ...\n```\n\n----------------------------------------\n\nTITLE: Installing FastAPI and Uvicorn using pip in Bash\nDESCRIPTION: This command uses the pip package installer to install the necessary libraries for running a FastAPI application. It installs `fastapi` itself and `uvicorn` along with its standard dependencies, which include libraries for parsing and serving web requests.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/01_fastapi_application___routing.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install fastapi uvicorn[standard]\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker from Command Line\nDESCRIPTION: Command to start a Celery worker process with basic configuration. Requires celery_app.py and tasks.py files, plus a running message broker. Sets logging level to info for monitoring task execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/05_worker.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncelery -A celery_app worker --loglevel=info\n```\n\n----------------------------------------\n\nTITLE: Dispatching Hooks in Python Requests - Python\nDESCRIPTION: Defines core hook functionality for the requests library, including registration and execution of hook functions. The primary functions create a dictionary of event keys to lists of hooks, and invoke all registered hooks for a particular event (such as 'response'), possibly allowing those hooks to modify the data passed through. Requires the hooks to be registered properly as callables and expects hook data and optional arguments. Outputs the (potentially modified) data after all hooks have executed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/hooks.py (Simplified)\n\nHOOKS = [\"response\"] # Currently, only 'response' is actively used\n\ndef default_hooks():\n    # Creates the initial empty structure for hooks\n    return {event: [] for event in HOOKS}\n\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\n    \"\"\"Dispatches hooks for a given key event.\"\"\"\n    hooks = hooks or {} # Ensure hooks is a dict\n    hooks = hooks.get(key) # Get the list of functions for this event key\n\n    if hooks:\n        # Allow a single callable or a list\n        if hasattr(hooks, \"__call__\"):\n            hooks = [hooks]\n        # Call each registered hook function\n        for hook in hooks:\n            _hook_data = hook(hook_data, **kwargs) # Call the user's function\n            if _hook_data is not None:\n                # If the hook returned something, update the data\n                hook_data = _hook_data\n    return hook_data # Return the (potentially modified) data\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing CrewAI Agent-LLM Interaction Sequence\nDESCRIPTION: Mermaid sequence diagram illustrating the step-by-step interaction flow between a CrewAI Agent, its LLM Object (like ChatOpenAI), the `litellm` library, and the underlying LLM provider's API (like OpenAI) when the Agent needs to process a task. It shows prompt assembly, function calls through `litellm`, the API request/response cycle, standardization by `litellm`, and final result processing (text output or tool execution) by the Agent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant Agent\n    participant LLM_Object as LLM Object (e.g., ChatOpenAI)\n    participant LiteLLM\n    participant ProviderAPI as Actual LLM API (e.g., OpenAI)\n\n    Agent->>Agent: Assemble Prompt (Role, Goal, Task, Tools...)\n    Agent->>LLM_Object: call(prompt, tools_schema)\n    LLM_Object->>LiteLLM: litellm.completion(model, messages, ...)\n    LiteLLM->>ProviderAPI: Send API Request\n    ProviderAPI-->>LiteLLM: Receive API Response (text or tool_call)\n    LiteLLM-->>LLM_Object: Standardized Response\n    LLM_Object-->>Agent: Result (text or tool_call)\n    Agent->>Agent: Process Result (Output text or Execute tool)\n```\n```\n\n----------------------------------------\n\nTITLE: Running and Resuming a LangGraph Workflow with Interrupts - Python\nDESCRIPTION: Illustrates running a LangGraph app with checkpointing and handling the interrupt/resume flow for human-in-the-loop approval. Generates a unique thread_id, streams execution until an interrupt occurs, then simulates human input and resumes the workflow using Command(resume=...). Dependencies: langgraph app as built above, Python uuid, and a Command class for resumption. Inputs include an initial plan and configuration; outputs are streamed dict status chunks, optionally including interrupt or resume info. Key details include interruption detection and resume mechanics.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nimport uuid\n\n# Unique ID for this conversation thread is needed for the checkpointer\nconfig = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n\nprint(\"--- Initial Invocation ---\")\n# Start the graph. It should interrupt at the approval node.\ninterrupt_info = None\nfor chunk in app.stream({\"plan\": \"\"}, config=config):\n    print(chunk)\n    # Check if the chunk contains interrupt information\n    if \"__interrupt__\" in chunk:\n        interrupt_info = chunk[\"__interrupt__\"]\n        print(\"\\n!! Graph Interrupted !!\")\n        break # Stop processing stream after interrupt\n\n# The client code inspects the interrupt value (the plan)\nif interrupt_info:\n    print(f\"Interrupt Value (Plan): {interrupt_info[0].value}\") # interrupt_info is a tuple\n\n    # --- Simulate human interaction ---\n    human_decision = \"Approved, proceed with caution.\"\n    print(f\"\\n--- Resuming with Decision: '{human_decision}' ---\")\n\n    # Resume execution with the human's feedback/approval\n    # We pass the decision using Command(resume=...)\n    for chunk in app.stream(Command(resume=human_decision), config=config):\n         print(chunk)\n\nelse:\n    print(\"Graph finished without interruption.\")\n```\n\n----------------------------------------\n\nTITLE: Atomic Operations Using WriteBatch in LevelDB\nDESCRIPTION: Complete example demonstrating how to use WriteBatch to perform multiple operations atomically, including error handling and durability options.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/05_writebatch.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\n#include \"leveldb/write_batch.h\"\n#include \"leveldb/db.h\"\n\n// ... assume db is an open LevelDB database ...\nleveldb::WriteOptions write_options;\nwrite_options.sync = true; // Ensure durability\n\n// 1. Create an empty WriteBatch\nleveldb::WriteBatch batch;\n\n// 2. Add changes to the batch (in memory)\nbatch.Put(\"score_playerA\", \"101\"); // Add 'Put playerA' to the list\nbatch.Delete(\"old_temp_key\");       // Add 'Delete old_temp_key' to the list\nbatch.Put(\"score_playerB\", \"49\");  // Add 'Put playerB' to the list\n\n// 3. Apply the entire batch atomically\nleveldb::Status status = db->Write(write_options, &batch);\n\nif (status.ok()) {\n  // Success! Both score_playerA and score_playerB are updated,\n  // and old_temp_key is deleted.\n} else {\n  // Failure! The database state is unchanged. Neither score was updated,\n  // and old_temp_key was not deleted.\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing WebScrapingStrategy in Crawl4AI (Python)\nDESCRIPTION: This snippet shows the implementation of the WebScrapingStrategy class, which uses BeautifulSoup to parse and scrape HTML content. It includes methods for synchronous and asynchronous scraping.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/content_scraping_strategy.py\nfrom bs4 import BeautifulSoup # Library used by WebScrapingStrategy\n# ... other imports like models ...\n\nclass WebScrapingStrategy(ContentScrapingStrategy):\n    def __init__(self, logger=None):\n        self.logger = logger\n        # ... potentially other setup ...\n\n    def scrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n        # 1. Parse HTML using BeautifulSoup\n        soup = BeautifulSoup(html, 'lxml') # Or another parser\n\n        # 2. Find the main content area (maybe using kwargs['css_selector'])\n        # 3. Remove unwanted tags (scripts, styles, nav, footer, ads...)\n        # 4. Extract metadata (title, description...)\n        # 5. Extract all links (<a> tags)\n        # 6. Extract all images (<img> tags) and other media\n        # 7. Get the remaining cleaned HTML text content\n\n        # ... complex cleaning and extraction logic using BeautifulSoup methods ...\n\n        # 8. Package results into a ScrapingResult object\n        cleaned_html_content = \"<html><body>Cleaned content...</body></html>\" # Placeholder\n        links_data = Links(...)\n        media_data = Media(...)\n        metadata_dict = {\"title\": \"Page Title\"}\n\n        return ScrapingResult(\n            cleaned_html=cleaned_html_content,\n            links=links_data,\n            media=media_data,\n            metadata=metadata_dict,\n            success=True\n        )\n\n    async def ascrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n        # Often delegates to the synchronous version for CPU-bound tasks\n        return await asyncio.to_thread(self.scrap, url, html, **kwargs)\n```\n\n----------------------------------------\n\nTITLE: Using CacheMode.DISABLED to Skip Caching in Crawl4AI\nDESCRIPTION: This example demonstrates CacheMode.DISABLED, which completely ignores the cache system. It never reads from or writes to the cache, making both runs fetch fresh content from the web. Useful for debugging or when facing storage constraints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# chapter9_example_3.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nimport time\n\nasync def main():\n    url = \"https://httpbin.org/html\"\n    async with AsyncWebCrawler() as crawler:\n        # Set the mode to DISABLED\n        config_disabled = CrawlerRunConfig(cache_mode=CacheMode.DISABLED)\n        print(f\"Running with CacheMode: {config_disabled.cache_mode.name}\")\n\n        # First run: Fetches, returns result (does NOT cache)\n        print(\"First run (DISABLED)...\")\n        start_time = time.perf_counter()\n        result1 = await crawler.arun(url=url, config=config_disabled)\n        duration1 = time.perf_counter() - start_time\n        print(f\"Got result 1? {'Yes' if result1.success else 'No'} (took {duration1:.2f}s)\")\n\n        # Second run: Fetches again, returns result (does NOT cache)\n        print(\"Second run (DISABLED)...\")\n        start_time = time.perf_counter()\n        result2 = await crawler.arun(url=url, config=config_disabled)\n        duration2 = time.perf_counter() - start_time\n        print(f\"Got result 2? {'Yes' if result2.success else 'No'} (took {duration2:.2f}s)\")\n        # Both runs fetch fresh, and nothing is ever saved to the cache.\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Configuring and Instantiating BootstrapFewShot Teleprompter in DSPy\nDESCRIPTION: Creates an instance of the `BootstrapFewShot` teleprompter. It's configured using a dictionary that specifies the evaluation metric (`simple_exact_match_metric`) to determine successful examples and the maximum number of demonstrations (`max_bootstrapped_demos=4`) to generate for each predictor module within the program.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Configure the BootstrapFewShot optimizer\n# It will use the metric to find successful demonstrations\n# max_bootstrapped_demos=4 means it will try to find up to 4 good examples for EACH predictor\nconfig = dict(max_bootstrapped_demos=4, metric=simple_exact_match_metric)\nteleprompter = BootstrapFewShot(**config)\n```\n\n----------------------------------------\n\nTITLE: Initializing FastMCP Server in Python\nDESCRIPTION: This snippet shows the constructor for the FastMCP class. It initializes various managers (ToolManager, ResourceManager, PromptManager) and sets up the underlying MCP server with provided settings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass FastMCP:\n    def __init__(\n        self, name: str | None = None, instructions: str | None = None, **settings: Any\n    ):\n        # Stores settings like debug mode, log level etc.\n        self.settings = Settings(**settings)\n\n        # Creates the underlying low-level MCP server\n        self._mcp_server = MCPServer(\n            name=name or \"FastMCP\",\n            instructions=instructions,\n            # ... other low-level setup ...\n        )\n        # Creates the managers to keep track of registered items\n        self._tool_manager = ToolManager(\n            warn_on_duplicate_tools=self.settings.warn_on_duplicate_tools\n        )\n        self._resource_manager = ResourceManager(\n            # ...\n        )\n        self._prompt_manager = PromptManager(\n            # ...\n        )\n\n        # Connects MCP requests (like 'callTool') to FastMCP methods\n        self._setup_handlers()\n        # (...)\n```\n\n----------------------------------------\n\nTITLE: Processing Message and Interacting with Agent in Python\nDESCRIPTION: This asynchronous Python function `process_message` within the `ADKHostManager` handles the backend logic for an incoming message. It extracts the conversation context, interacts with the agent system (e.g., Google ADK Runner) via `_host_runner.run_async`, converting the message to the agent's format. It processes events received back from the agent asynchronously, stores them, and potentially updates task statuses before removing the pending indicator for the processed message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# File: demo/ui/service/server/adk_host_manager.py (Simplified Snippet)\nasync def process_message(self, message: Message):\n    # ... (Store message, add event) ...\n    # Get conversation context\n    conversation_id = message.metadata.get('conversation_id')\n    # --- Interact with the actual agent (e.g., Google ADK Runner) ---\n    async for event in self._host_runner.run_async(\n        user_id=self.user_id,\n        session_id=conversation_id,\n        new_message=self.adk_content_from_message(message) # Convert to agent format\n    ):\n        # Process events coming *back* from the agent\n        self.add_event(...) # Store for UI event log\n        # ... potentially update task status via task_callback ...\n    # ... (Store final response message) ...\n    # Remove pending indicator\n    self._pending_message_ids.remove(get_message_id(message))\n```\n\n----------------------------------------\n\nTITLE: Defining Exception Hierarchy in requests.exceptions - Python\nDESCRIPTION: Shows simplified class definitions from requests.exceptions.py, demonstrating inheritance among the various exception types used by the requests library. No runtime dependencies, but conceptually linked to the requests and urllib3 packages. Illustrates how specific exceptions build on base classes to allow precise error handling in user code. Inputs and outputs are conceptual, not practical code: its use is for understanding exception relationships and design.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/06_exception_hierarchy.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/exceptions.py (Simplified View)\\n\\nfrom urllib3.exceptions import HTTPError as BaseHTTPError\\n\\n# The base class for all requests exceptions\\nclass RequestException(IOError):\\n    \\\"\\\"\\\"There was an ambiguous exception that occurred while handling your request.\\\"\\\"\\\"\\n    # ... (stores request/response objects) ...\\n\\n# Specific exceptions inheriting from RequestException or other requests exceptions\\nclass HTTPError(RequestException):\\n    \\\"\\\"\\\"An HTTP error occurred.\\\"\\\"\\\" # Typically raised by response.raise_for_status()\\n\\nclass ConnectionError(RequestException):\\n    \\\"\\\"\\\"A Connection error occurred.\\\"\\\"\\\"\\n\\nclass ProxyError(ConnectionError): # Inherits from ConnectionError\\n    \\\"\\\"\\\"A proxy error occurred.\\\"\\\"\\\"\\n\\nclass SSLError(ConnectionError): # Inherits from ConnectionError\\n    \\\"\\\"\\\"An SSL error occurred.\\\"\\\"\\\"\\n\\nclass Timeout(RequestException): # Inherits directly from RequestException\\n    \\\"\\\"\\\"The request timed out.\\\"\\\"\\\"\\n\\nclass ConnectTimeout(ConnectionError, Timeout): # Inherits from BOTH ConnectionError and Timeout!\\n    \\\"\\\"\\\"The request timed out while trying to connect to the remote server.\\\"\\\"\\\"\\n\\nclass ReadTimeout(Timeout): # Inherits from Timeout\\n    \\\"\\\"\\\"The server did not send any data in the allotted amount of time.\\\"\\\"\\\"\\n\\nclass URLRequired(RequestException):\\n    \\\"\\\"\\\"A valid URL is required to make a request.\\\"\\\"\\\"\\n\\nclass TooManyRedirects(RequestException):\\n    \\\"\\\"\\\"Too many redirects.\\\"\\\"\\\"\\n\\n# ... other specific errors like MissingSchema, InvalidURL, etc. ...\\n\\n# Some exceptions might also inherit from standard Python errors\\nclass JSONDecodeError(RequestException, ValueError): # Inherits from RequestException and ValueError\\n    \\\"\\\"\\\"Couldn't decode the text into json\\\"\\\"\\\"\\n    # Uses Python's built-in JSONDecodeError capabilities\\n\n```\n\n----------------------------------------\n\nTITLE: Validating LLM Output with Pydantic and Handling Errors in Python\nDESCRIPTION: This Python code demonstrates how to validate LLM-generated JSON data against a defined Pydantic model (AgentOutput) and gracefully handle validation errors. It attempts to parse the JSON using AgentOutput.model_validate_json; if schema constraints are violated (such as missing required fields), a ValidationError is caught, allowing the system to prevent downstream errors and provide feedback or request reprocessing. Dependencies include 'pydantic', the defined AgentOutput model, and a valid JSON string response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- Conceptual Agent Code ---\\nimport pydantic\\n# Assume AgentOutput is the Pydantic model defined earlier\\n# Assume 'llm_json_response' contains the bad JSON from above\\n\\ntry:\\n    # Try to create the AgentOutput object from the LLM's response\\n    llm_plan = AgentOutput.model_validate_json(llm_json_response)\\n    # If validation succeeds, proceed...\\n    print(\"LLM Plan Validated:\", llm_plan)\\nexcept pydantic.ValidationError as e:\\n    # Pydantic catches the error!\\n    print(f\"Validation Error: The LLM response didn't match the blueprint!\")\\n    print(e)\\n    # The Agent can now handle this error gracefully,\\n    # maybe asking the LLM to try again, instead of crashing later.\\n\n```\n\n----------------------------------------\n\nTITLE: Creating an Agent with Knowledge and Defining a Task in Python with CrewAI\nDESCRIPTION: This code snippet shows how to create an Agent with a Knowledge object, define a Task for the agent, and set up a Crew. The agent is equipped with specific product knowledge to answer customer questions accurately based on the provided manual.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/08_knowledge.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsupport_agent = Agent(\n    role='Product Support Specialist',\n    goal='Answer customer questions accurately based ONLY on the Widget Pro manual.',\n    backstory='You are an expert support agent with deep knowledge of the Widget Pro, derived exclusively from its official manual.',\n    knowledge=product_knowledge,\n    verbose=True,\n    allow_delegation=False,\n)\n\nsupport_task = Task(\n    description=\"The customer asks: 'How do I reset my Widget Pro?' Use the manual to find the answer.\",\n    expected_output=\"A clear, step-by-step answer based solely on the provided manual content.\",\n    agent=support_agent\n)\n\nsupport_crew = Crew(\n    agents=[support_agent],\n    tasks=[support_task],\n    process=Process.sequential\n)\n```\n\n----------------------------------------\n\nTITLE: Processing POSTed Form Data in Flask - Python\nDESCRIPTION: This code handles POST requests to the /login route, extracting 'username' and 'password' fields from the submitted form using Flask's request.form. If both are provided, it returns a confirmation message; otherwise, it returns an error with status code 400. It depends on a Flask app instance and the request object, and demonstrates validating form data and returning custom response codes. Inputs are form fields sent as POST data; outputs are plain text strings with optional HTTP error codes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n@app.route('/login', methods=['POST']) # Only allow POST for this view\ndef process_login():\n  # Access form data using request.form\n  username = request.form.get('username')\n  password = request.form.get('password') # In a real app, NEVER just display a password!\n\n  if username and password:\n    return f'Attempting login for username: {username}'\n  else:\n    return 'Missing username or password', 400 # Return an error status code\n\n# ... (rest of the app, including if __name__ == '__main__': ...)\n```\n\n----------------------------------------\n\nTITLE: Creating Project-Specific Instructions for Codex\nDESCRIPTION: Sample project-specific instructions file (codex.md) that provides context and guidelines specific to a particular codebase. This example specifies TypeScript usage, Jest testing requirements, and Git workflow guidelines that apply only when working in this project.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n# File: ~/my-cool-project/codex.md\n\n- This project uses TypeScript and adheres to the Prettier style guide.\n- When adding new features, always include unit tests using Jest.\n- Do not run `git push` directly; always suggest creating a pull request.\n```\n\n----------------------------------------\n\nTITLE: Defining CrawlResult Model in Python with Pydantic\nDESCRIPTION: This snippet shows a simplified definition of the CrawlResult class using Pydantic. It includes various fields for storing crawl results such as HTML content, extracted data, screenshots, and PDF data. The model uses type hints and validation provided by Pydantic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/models.py\nfrom pydantic import BaseModel, HttpUrl\nfrom typing import List, Dict, Optional, Any\n\n# Other related models (simplified)\nclass MarkdownGenerationResult(BaseModel):\n    raw_markdown: str\n    fit_markdown: Optional[str] = None\n    # ... other markdown fields ...\n\nclass Links(BaseModel):\n    internal: List[Dict] = []\n    external: List[Dict] = []\n\nclass Media(BaseModel):\n    images: List[Dict] = []\n    videos: List[Dict] = []\n\n# The main CrawlResult model\nclass CrawlResult(BaseModel):\n    url: str\n    html: str\n    success: bool\n    cleaned_html: Optional[str] = None\n    media: Media = Media() # Use the Media model\n    links: Links = Links() # Use the Links model\n    screenshot: Optional[str] = None\n    pdf: Optional[bytes] = None\n    # Uses a private attribute and property for markdown for compatibility\n    _markdown: Optional[MarkdownGenerationResult] = None # Actual storage\n    extracted_content: Optional[str] = None # JSON string\n    metadata: Optional[Dict[str, Any]] = None\n    error_message: Optional[str] = None\n    status_code: Optional[int] = None\n    response_headers: Optional[Dict[str, str]] = None\n    redirected_url: Optional[str] = None\n    # ... other fields like session_id, ssl_certificate ...\n\n    # Custom property to access markdown data\n    @property\n    def markdown(self) -> Optional[MarkdownGenerationResult]:\n        return self._markdown\n\n    # Configuration for Pydantic\n    class Config:\n        arbitrary_types_allowed = True\n\n    # Custom init and model_dump might exist for backward compatibility handling\n    # ... (omitted for simplicity) ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Model Creation and Configuration Flow with Sequence Diagram (Mermaid)\nDESCRIPTION: This Mermaid sequence diagram visualizes the interaction sequence when a Pydantic model class is created and configured. It shows how model_config is detected and converted to a ConfigWrapper, which then influences the subsequent schema and validator/serializer setup. No dependencies beyond Mermaid syntax and sequenceDiagram rendering support. Inputs: Developer code, Python runtime. Outputs: A sequence diagram tracing the flow of config processing across Pydantic internals.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Dev as Developer\n    participant Py as Python\n    participant Meta as ModelMetaclass\n    participant CfgWrap as ConfigWrapper\n    participant Core as Pydantic Core Engine\n\n    Dev->>Py: Define `class Product(BaseModel): model_config = ConfigDict(frozen=True, extra='forbid') ...`\n    Py->>Meta: Ask to create `Product` class\n    Meta->>Meta: Find `model_config` dict in namespace\n    Meta->>CfgWrap: Create `ConfigWrapper` using `model_config` (and defaults)\n    CfgWrap-->>Meta: Return `ConfigWrapper(config_dict={'frozen': True, 'extra': 'forbid', ...other defaults...})`\n    Meta->>Meta: Collect fields (`item_id`, `name`, `price`) and their FieldInfo\n    Meta->>Core: Request Core Schema using FieldInfo AND ConfigWrapper settings (e.g., frozen, extra)\n    Core-->>Meta: Provide Core Schema incorporating model-wide rules\n    Meta->>Core: Request validator/serializer from Core Schema\n    Core-->>Meta: Provide optimized validator/serializer reflecting config\n    Meta-->>Py: Return fully prepared `Product` class\n    Py-->>Dev: `Product` class is ready, respecting the config\n```\n\n----------------------------------------\n\nTITLE: Accessing HTTP Method and User Agent in Flask - Python\nDESCRIPTION: This snippet demonstrates how to use the Flask request object to retrieve the HTTP method and User-Agent header from an incoming request in a Flask route. Dependencies include the Flask library and the created Flask app instance. The view function returns a string indicating the HTTP method used and the user agent string sent by the client. Inputs are the incoming HTTP request; output is a formatted string describing the request. The request object must be imported from flask, and this code is typically run within a Flask web server context.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\nfrom flask import Flask, request # Import request\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n  # Access the HTTP method (GET, POST, etc.)\n  method = request.method\n  # Access the browser's user agent string (an HTTP header)\n  user_agent = request.headers.get('User-Agent')\n  return f'Hello! You used the {method} method. Your browser is: {user_agent}'\n\n# ... (rest of the app, including if __name__ == '__main__': ...)\n```\n\n----------------------------------------\n\nTITLE: Running the Main Script for Local Directory Analysis\nDESCRIPTION: Command to generate a tutorial from a local directory, with options to include only Python files and exclude test files.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython main.py --dir /path/to/your/codebase --include \"*.py\" --exclude \"*test*\"\n```\n\n----------------------------------------\n\nTITLE: Controlling Summarization Thresholds and Edge Items\nDESCRIPTION: Shows how to customize array printing behavior by adjusting the threshold that triggers summarization and the number of edge items (elements shown at the beginning and end of each dimension).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# An array with 10 elements\narr = np.arange(10)\nprint(\"Original:\")\nprint(arr)\n\n# Temporarily set the threshold lower (e.g., 5)\n# We use np.printoptions as a context manager for temporary settings\nwith np.printoptions(threshold=5):\n  print(\"\\nWith threshold=5:\")\n  print(arr)\n\n# Change edgeitems too\nwith np.printoptions(threshold=5, edgeitems=2):\n  print(\"\\nWith threshold=5, edgeitems=2:\")\n  print(arr)\n```\n\n----------------------------------------\n\nTITLE: Adding Styled Text and Colors with click.style() and click.secho()\nDESCRIPTION: Shows how to enhance CLI output with colors, bold text, and underlines using Click's style() and secho() functions, making success and error messages more visually distinguishable.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# style_example.py\nimport click\n\n@click.command()\ndef cli():\n  \"\"\"Demonstrates styled output\"\"\"\n  # Style the text first, then echo it\n  success_message = click.style(\"Operation successful!\", fg='green', bold=True)\n  click.echo(success_message)\n\n  # Or use secho for style + echo in one step\n  click.secho(\"Critical error!\", fg='red', underline=True, err=True)\n\nif __name__ == '__main__':\n  cli()\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ python style_example.py\n# Output will look something like:\n# Operation successful!  (in bold green)\n# Critical error!        (in underlined red, sent to stderr)\n```\n\n----------------------------------------\n\nTITLE: BaseModel Instantiation Sequence Diagram\nDESCRIPTION: A sequence diagram showing the internal flow of how Pydantic's BaseModel works, from class definition to schema generation to validation and serialization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/01_basemodel.md#2025-04-22_snippet_8\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Dev as Developer\n    participant Py as Python Interpreter\n    participant Meta as BaseModel Metaclass\n    participant Core as Pydantic Core Engine\n\n    Dev->>Py: Define `class User(BaseModel): name: str, age: int`\n    Py->>Meta: Ask to create the `User` class\n    Meta->>Meta: Inspect fields (`name: str`, `age: int`)\n    Meta->>Core: Request schema based on fields & types\n    Core-->>Meta: Provide internal Core Schema for User\n    Meta->>Core: Request validator function from schema\n    Core-->>Meta: Provide optimized validator\n    Meta->>Core: Request serializer function from schema\n    Core-->>Meta: Provide optimized serializer\n    Meta-->>Py: Return the fully prepared `User` class (with hidden validator/serializer attached)\n    Py-->>Dev: `User` class is ready to use\n```\n\n----------------------------------------\n\nTITLE: Explicitly Configuring OpenAI LLM for CrewAI Agent and Crew (Python)\nDESCRIPTION: Illustrates the recommended practice of explicitly configuring an LLM using `langchain_openai.ChatOpenAI` and assigning it to a CrewAI `Agent` via the `llm` parameter. It also shows how to assign specific LLMs (`manager_llm`, `function_calling_llm`) at the `Crew` level. Requires `crewai` and `langchain-openai` libraries, and an OpenAI API key (preferably set as an environment variable). Key parameters include `model` (e.g., \"gpt-4o\") and `temperature`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Make sure you have langchain_openai installed: pip install langchain-openai\nimport os\nfrom langchain_openai import ChatOpenAI\nfrom crewai import Agent\n\n# Set the API key (best practice: use environment variables)\n# os.environ[\"OPENAI_API_KEY\"] = \"sk-your_key_here\"\n\n# Instantiate the OpenAI LLM wrapper\nopenai_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n\n# Pass the configured LLM to the Agent\nresearcher = Agent(\n    role='Travel Researcher',\n    goal='Find interesting cities in Europe',\n    backstory='Expert researcher.',\n    llm=openai_llm # Explicitly assign the LLM\n)\n\n# You can also assign a default LLM to the Crew\n# from crewai import Crew\n# trip_crew = Crew(\n#   agents=[researcher],\n#   tasks=[...],\n#   # Manager LLM for hierarchical process\n#   manager_llm=openai_llm\n#   # A function_calling_llm can also be set for tool use reasoning\n#   # function_calling_llm=openai_llm\n# )\n```\n\n----------------------------------------\n\nTITLE: Implementing PromptManager.add_prompt in Python\nDESCRIPTION: A simplified implementation of the PromptManager.add_prompt method, which is responsible for adding a new Prompt object to the PromptManager's internal dictionary.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom .base import Prompt\n\nclass PromptManager:\n    # ... (init, get_prompt, list_prompts) ...\n\n    def add_prompt(self, prompt: Prompt) -> Prompt:\n        # Check for duplicates...\n        if prompt.name in self._prompts:\n             # ... handle duplicate ...\n             pass\n        # Store the Prompt object\n        self._prompts[prompt.name] = prompt\n        return prompt\n\n# Note: Prompt.from_function (in base.py) does the function inspection.\n```\n\n----------------------------------------\n\nTITLE: Using PruningContentFilter for Structural Web Content Filtering in Python\nDESCRIPTION: This example demonstrates how to use PruningContentFilter to extract the main content from web pages by removing structural boilerplate like headers and footers. The code creates and configures a filter, sets up a crawler with the filter, and then crawls a sample URL to demonstrate the pruning effect on the resulting markdown.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    DefaultMarkdownGenerator,\n    PruningContentFilter # The structural filter\n)\n\nasync def main():\n    # 1. Create the Pruning filter (no query needed)\n    pruning_filter = PruningContentFilter()\n    print(\"Filter created: PruningContentFilter (structural)\")\n\n    # 2. Create a Markdown generator that uses this filter\n    markdown_generator_with_filter = DefaultMarkdownGenerator(\n        content_filter=pruning_filter\n    )\n    print(\"Markdown generator configured with Pruning filter.\")\n\n    # 3. Create CrawlerRunConfig using this generator\n    run_config = CrawlerRunConfig(\n        markdown_generator=markdown_generator_with_filter\n    )\n\n    # 4. Run the crawl\n    async with AsyncWebCrawler() as crawler:\n        # Example URL (replace with a real page that has boilerplate)\n        url_to_crawl = \"https://www.python.org/\" # Python homepage likely has headers/footers\n        print(f\"\\nCrawling {url_to_crawl}...\")\n\n        result = await crawler.arun(url=url_to_crawl, config=run_config)\n\n        if result.success:\n            print(\"\\nCrawl successful!\")\n            print(f\"Raw Markdown length: {len(result.markdown.raw_markdown)}\")\n            print(f\"Fit Markdown length: {len(result.markdown.fit_markdown)}\")\n\n            # fit_markdown should have less header/footer/sidebar content\n            print(\"\\n--- Start of Fit Markdown (Pruned) ---\")\n            print(result.markdown.fit_markdown[:500] + \"...\")\n            print(\"--- End of Fit Markdown Snippet ---\")\n        else:\n            print(f\"\\nCrawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Loading ListMemory Configuration in Python\nDESCRIPTION: This code demonstrates how to load a ListMemory instance from a saved ComponentModel, recreating the exact state of the original memory component.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: load_memory_config.py\nfrom autogen_core import ComponentModel\nfrom autogen_core.memory import ListMemory # Need the class for type hint/loading\n\n# Assume 'memory_model' is the ComponentModel we just created\n# (or loaded from a file)\n\nprint(f\"Loading component from ComponentModel (Provider: {memory_model.provider})...\")\n\n# Use the ComponentLoader mechanism (available on Component classes)\n# to load the model. We specify the expected type (ListMemory).\nloaded_memory: ListMemory = ListMemory.load_component(memory_model)\n\nprint(f\"Successfully loaded memory!\")\nprint(f\"- Name: {loaded_memory.name}\")\nprint(f\"- Content: {loaded_memory.content}\")\n```\n\n----------------------------------------\n\nTITLE: Authenticating Requests Using HTTPBasicAuth Class (Python Requests)\nDESCRIPTION: Shows how to use the HTTPBasicAuth class from requests.auth to perform HTTP Basic Authentication. Requires the 'requests' library and the HTTPBasicAuth class. It constructs an HTTPBasicAuth object and supplies it to the auth parameter of requests.get(). The snippet expects a 200 status code and a JSON body confirming successful authentication. Exceptions are handled for network or request issues.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom requests.auth import HTTPBasicAuth # Import the class\n\nurl = 'https://httpbin.org/basic-auth/testuser/testpass'\n\n# Create an HTTPBasicAuth object\nbasic_auth = HTTPBasicAuth('testuser', 'testpass')\n\n# Pass the auth object to the 'auth' parameter\nprint(\"Attempting with HTTPBasicAuth object...\")\ntry:\n    response = requests.get(url, auth=basic_auth)\n    print(f\"Status Code: {response.status_code}\") # Expect 200\n    print(\"Response JSON:\")\n    print(response.json())\nexcept requests.exceptions.RequestException as e:\n    print(f\"An error occurred: {e}\")\n\n```\n\n----------------------------------------\n\nTITLE: Fetching Agent Card using TypeScript Fetch API\nDESCRIPTION: This TypeScript function `fetchAndDisplayAgentCard` demonstrates retrieving an Agent Card using the standard `fetch` API. It constructs the full URL to the `/.well-known/agent.json` endpoint based on a `serverUrl`, makes an asynchronous GET request, checks if the response status is 'ok' (e.g., 200), parses the JSON response body into an `AgentCard` type, and handles potential errors during the fetch operation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/01_agent_card.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// File: samples/js/src/cli.ts (Relevant Snippet)\nasync function fetchAndDisplayAgentCard() {\n  const wellKnownUrl = new URL(\"/.well-known/agent.json\", serverUrl).toString();\n  console.log(`Attempting to fetch agent card from: ${wellKnownUrl}`);\n  try {\n    // Use browser's fetch to get the card\n    const response = await fetch(wellKnownUrl);\n    if (response.ok) {\n      const card: AgentCard = await response.json(); // Parse JSON\n      agentName = card.name || \"Agent\";\n      console.log(`✓ Agent Card Found: ${agentName}`);\n      // ... display other card info ...\n    } else {\n      console.log(`⚠️ Could not fetch agent card (Status: ${response.status})`);\n    }\n  } catch (error: any) {\n    console.log(`⚠️ Error fetching agent card: ${error.message}`);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Expected Output of Conditional Graph Execution\nDESCRIPTION: Shows the expected console output when running the Python script that executes the conditional LangGraph. It illustrates the different execution paths taken based on the input query, including the print statements from each node and the final state dictionary for both scenarios.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n--- Scenario 1: Weather Query ---\n--- Determining Action ---\nDecision: Need to use search tool for weather.\n--- Routing ---\nRouting based on action: USE_TOOL\n--- Using Search Tool ---\n--- Generating Response ---\nFinal State 1: {'user_query': \"What's the weather like?\", 'next_action': 'USE_TOOL', 'search_result': [\"Search result for 'What's the weather like?': It's sunny!\"], 'final_response': \"Based on my search: Search result for 'What's the weather like?': It's sunny!\"}\n\n--- Scenario 2: Direct Response ---\n--- Determining Action ---\nDecision: Can respond directly.\n--- Routing ---\nRouting based on action: RESPOND\n--- Generating Response ---\nFinal State 2: {'user_query': 'Tell me a joke.', 'next_action': 'RESPOND', 'search_result': [], 'final_response': 'Responding directly to: Tell me a joke.'}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Flask Core Component Interactions with Mermaid\nDESCRIPTION: This Mermaid flowchart depicts the relationships between key components within the Flask framework. It shows how the central Application Object interacts with Blueprints, the Routing System, Request/Response objects, Application/Request Contexts, Configuration, and Templating (Jinja2). The chart illustrates the flow and dependencies, such as how Blueprints use Routing, Routing matches URLs from Requests, Requests are bound within Contexts, and Templating accesses Context Globals.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"0: Application Object (Flask)\"]\n    A1[\"1: Blueprints\"]\n    A2[\"2: Routing System\"]\n    A3[\"3: Request and Response Objects\"]\n    A4[\"4: Application and Request Contexts\"]\n    A5[\"5: Context Globals (current_app, request, session, g)\"]\n    A6[\"6: Configuration (Config)\"]\n    A7[\"7: Templating (Jinja2 Integration)\"]\n    A0 -- \"Registers\" --> A1\n    A0 -- \"Uses\" --> A2\n    A0 -- \"Handles\" --> A3\n    A0 -- \"Manages\" --> A4\n    A0 -- \"Holds\" --> A6\n    A0 -- \"Integrates\" --> A7\n    A1 -- \"Defines routes using\" --> A2\n    A2 -- \"Matches URL from\" --> A3\n    A3 -- \"Bound within\" --> A4\n    A4 -- \"Enables access to\" --> A5\n    A7 -- \"Accesses\" --> A5\n```\n\n----------------------------------------\n\nTITLE: FastMCP Server with Parameterized Resource Templates\nDESCRIPTION: Advanced implementation showing parameterized resource templates. Includes static, dynamic, and template-based resources for weather forecasts with city parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport datetime\nimport random # To simulate getting weather data\nfrom mcp.server.fastmcp import FastMCP\n\nserver = FastMCP(name=\"LibraryServer\")\n\n@server.resource(uri=\"data://greeting\", description=\"A friendly greeting.\")\ndef welcome_message() -> str:\n    return \"Welcome to the Library Server! Enjoy your stay.\"\n\n@server.resource(uri=\"time://current\", description=\"The current server time.\")\ndef current_time() -> str:\n    now = datetime.datetime.now()\n    return f\"The current server time is: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n\n# NEW: Add a resource template for weather\n# The URI contains a parameter {city_name}\n@server.resource(uri=\"weather://forecast/{city_name}\",\n                  description=\"Provides a dummy weather forecast.\")\n# The function accepts an argument matching the URI parameter\ndef get_weather_forecast(city_name: str) -> str:\n    \"\"\"Generates a fake weather forecast for the given city.\"\"\"\n    print(f\"Resource template 'weather://forecast/{{city}}' read for city: {city_name}\")\n    # In a real app, you'd fetch actual weather here based on city_name\n    temperature = random.randint(5, 25)\n    conditions = random.choice([\"Sunny\", \"Cloudy\", \"Rainy\"])\n    return f\"Forecast for {city_name.capitalize()}: {temperature}°C, {conditions}\"\n```\n\n----------------------------------------\n\nTITLE: NumPy Vectorized Array Addition\nDESCRIPTION: This snippet demonstrates vectorized operations with NumPy arrays, showing how to add two arrays without explicit loops. It highlights NumPy's ability to perform element-wise operations efficiently through vectorization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np # Standard way to import NumPy\n\narray1 = np.array([1, 2, 3, 4])\narray2 = np.array([5, 6, 7, 8])\n\n# Add the arrays directly!\nresult_array = array1 + array2\n\nprint(result_array)\n# Output: [ 6  8 10 12]\n```\n\n----------------------------------------\n\nTITLE: NumPy C-API Code Generation Script\nDESCRIPTION: Example from NumPy's code generator that creates the C-API function table, which defines the interface for multiarray's core functionality and makes it accessible to other C extensions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Snippet from numpy/core/code_generators/generate_numpy_api.py\n# This script generates C code that defines an array of function pointers\n# making up the C-API.\n\n# Describes API functions, their index in the API table, return type, args...\nmultiarray_funcs = {\n    # ... many functions ...\n    'NewLikeArray': (10, None, 'PyObject *', (('PyArrayObject *', 'prototype'), ...)),\n    'NewFromDescr': (9, None, 'PyObject *', ...),\n    'Empty': (8, None, 'PyObject *', ...),\n    # ...\n}\n\n# ... code to generate C header (.h) and implementation (.c) files ...\n# These generated files help expose the C functions consistently.\n```\n\n----------------------------------------\n\nTITLE: Sequence Flow of TypeAdapter Initialization and Usage - Mermaid\nDESCRIPTION: This mermaid code block diagrams the sequence of operations from creating a TypeAdapter for a Python type, through schema generation, validator/serializer instantiation in the Rust engine, to invoking validation and serialization methods. It visually clarifies the delegation between Python and Rust layers in Pydantic V2.\nNo dependencies are required to interpret the diagram, but rendering requires a markdown/mermaid-capable environment. The focus is to show developer interactions and layer responsibilities.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant Dev as Developer\\n    participant TA as TypeAdapter\\n    participant PydanticPy as Pydantic (Python Layer)\\n    participant CoreSchemaDS as CoreSchema\\n    participant PydanticCore as pydantic-core (Rust Engine)\\n\\n    Dev->>TA: adapter = TypeAdapter(List[PositiveInt])\\n    TA->>PydanticPy: Request schema generation for List[PositiveInt]\\n    PydanticPy->>CoreSchemaDS: Generate CoreSchema for List[PositiveInt]\\n    PydanticPy->>PydanticCore: Pass CoreSchema to Rust engine\\n    PydanticCore->>PydanticCore: Compile SchemaValidator for List[PositiveInt]\\n    PydanticCore->>PydanticCore: Compile SchemaSerializer for List[PositiveInt]\\n    PydanticCore-->>TA: Return compiled Validator & Serializer\\n    TA->>TA: Store validator on self.validator\\n    TA->>TA: Store serializer on self.serializer\\n    TA-->>Dev: Adapter instance is ready\\n\\n    Dev->>TA: adapter.validate_python(data)\\n    TA->>PydanticCore: Call self.validator.validate_python(data)\\n    PydanticCore-->>TA: Return validated data or raise ValidationError\\n    TA-->>Dev: Return result\\n\\n    Dev->>TA: adapter.dump_json(obj)\\n    TA->>PydanticCore: Call self.serializer.to_json(obj)\\n    PydanticCore-->>TA: Return JSON bytes\\n    TA-->>Dev: Return result\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Exact Match Metric Function in Python for DSPy Evaluation\nDESCRIPTION: This snippet defines a Python function `simple_exact_match_metric` suitable for use with `dspy.Evaluate`. The function takes a gold standard `dspy.Example` and a `dspy.Prediction` object, comparing the 'answer' field from the prediction to the gold example's 'answer' field. It returns `True` (1.0) for an exact match and `False` (0.0) otherwise. It also notes that DSPy provides common metrics like `dspy.evaluate.answer_exact_match`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef simple_exact_match_metric(gold_example, prediction, trace=None):\n    # Does the predicted 'answer' EXACTLY match the gold 'answer'?\n    # '.answer' field comes from our Predict signature 'question -> answer'\n    # 'gold_example.answer' is the gold label from the devset example\n    return prediction.answer == gold_example.answer\n\n# Note: DSPy often provides common metrics too, like dspy.evaluate.answer_exact_match\n# import dspy.evaluate\n# metric = dspy.evaluate.answer_exact_match\n```\n\n----------------------------------------\n\nTITLE: Hooks Registration and Preparation in Requests Models - Python\nDESCRIPTION: Shows how hooks are initialized, registered, and merged in the requests library's Request and PreparedRequest classes via a hooks mixin. Hooks are stored as event-to-list dictionaries, set up with default_hooks(), and populated by explicit registration or during preparation (e.g., merging hooks across objects). Dependencies include the default_hooks() utility and properly merged or passed hook dictionaries. Each hook is appended under the appropriate event and can later be triggered by the dispatcher.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/models.py (Simplified view of PreparedRequest)\n# Shows where hooks are stored initially\n\nclass RequestHooksMixin:\n    # Mixin used by Request and PreparedRequest\n    def register_hook(self, event, hook):\n        # ... logic to add hook functions to self.hooks[event] list ...\n        pass\n\nclass Request(RequestHooksMixin):\n    def __init__(self, ..., hooks=None):\n        # ...\n        self.hooks = default_hooks() # Initialize hooks dict\n        if hooks:\n            for k, v in list(hooks.items()):\n                self.register_hook(event=k, hook=v) # Register hooks passed in\n        # ...\n\nclass PreparedRequest(..., RequestHooksMixin):\n    def __init__(self):\n        # ...\n        self.hooks = default_hooks() # Hooks are also on PreparedRequest\n        # ...\n\n    def prepare_hooks(self, hooks):\n        # Called during prepare() to merge hooks from the original Request\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n# Note: Session.prepare_request merges Request hooks and Session hooks\n#       into the PreparedRequest.hooks dictionary.\n\n```\n\n----------------------------------------\n\nTITLE: Setting Line Width for Multi-Dimensional Array Display\nDESCRIPTION: Shows how to control line wrapping by setting the maximum line width for array display, which affects how multi-dimensional arrays are formatted across multiple lines.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# A 2D array\narr2d = np.arange(12).reshape(3, 4) * 0.1\nprint(\"Default linewidth:\")\nprint(arr2d)\n\n# Set a narrow linewidth\nwith np.printoptions(linewidth=30):\n  print(\"\\nWith linewidth=30:\")\n  print(arr2d)\n```\n\n----------------------------------------\n\nTITLE: Building SSTable Files in LevelDB\nDESCRIPTION: Implements the process of creating a new SSTable file from an iterator of key-value pairs. The function handles file creation, writes sorted data using TableBuilder, maintains metadata about key ranges, and ensures proper file synchronization and closure.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/01_table___sstable___tablecache.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\nStatus BuildTable(const std::string& dbname, Env* env, const Options& options,\n                  TableCache* table_cache, Iterator* iter, FileMetaData* meta) {\n  Status s;\n  std::string fname = TableFileName(dbname, meta->number);\n  WritableFile* file;\n  s = env->NewWritableFile(fname, &file);\n\n  TableBuilder* builder = new TableBuilder(options, file);\n\n  iter->SeekToFirst();\n  meta->smallest.DecodeFrom(iter->key());\n\n  Slice key;\n  for (; iter->Valid(); iter->Next()) {\n    key = iter->key();\n    builder->Add(key, iter->value());\n  }\n  if (!key.empty()) {\n    meta->largest.DecodeFrom(key);\n  }\n\n  s = builder->Finish();\n  if (s.ok()) {\n      meta->file_size = builder->FileSize();\n      s = file->Sync();\n  }\n  if (s.ok()) {\n      s = file->Close();\n  }\n\n  return s;\n}\n```\n\n----------------------------------------\n\nTITLE: Example Final Score Output from dspy.Evaluate\nDESCRIPTION: This text block shows the final line of output printed by the example evaluation script, displaying the calculated average score as a percentage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nAverage Score: 75.0%\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram for callTool with Context (Mermaid)\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of a callTool request, showing how Context is created, injected, and used throughout the process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastMCPServer as FastMCP (server.py)\n    participant ToolMgr as ToolManager (_tool_manager)\n    participant ToolRunner as Tool.run / FuncMetadata\n    participant YourToolFunc as run_long_task(ctx: Context)\n    participant ContextObj as Context\n\n    Client->>+FastMCPServer: callTool(name=\"long_task\", args={...})\n    FastMCPServer->>FastMCPServer: Create low-level RequestContext\n    FastMCPServer->>+ContextObj: Create Context (wraps RequestContext, FastMCP)\n    FastMCPServer->>+ToolMgr: call_tool(name=\"long_task\", args={...})\n    ToolMgr->>+ToolRunner: run(arguments={...}, context=ContextObj)\n    ToolRunner->>ToolRunner: Inspect run_long_task, see 'ctx: Context'\n    ToolRunner->>+YourToolFunc: Call run_long_task(duration=..., ctx=ContextObj)\n    YourToolFunc->>ContextObj: ctx.info(\"Starting...\")\n    ContextObj->>FastMCPServer: Use session.send_log_message(...)\n    YourToolFunc->>ContextObj: ctx.report_progress(...)\n    ContextObj->>FastMCPServer: Use session.send_progress_notification(...)\n    YourToolFunc->>ContextObj: ctx.read_resource(\"config://...\")\n    ContextObj->>FastMCPServer: Call fastmcp.read_resource(\"config://...\")\n    FastMCPServer-->>ContextObj: Return resource content\n    ContextObj-->>YourToolFunc: Return resource content\n    YourToolFunc-->>-ToolRunner: Return \"Finished...\"\n    ToolRunner-->>-ToolMgr: Return \"Finished...\"\n    ToolMgr-->>-FastMCPServer: Return \"Finished...\"\n    FastMCPServer->>-Client: Send Response: result=\"Finished...\"\n```\n\n----------------------------------------\n\nTITLE: Executing the SimpleRAG DSPy Program in Python\nDESCRIPTION: Demonstrates how to instantiate and run the `SimpleRAG` DSPy program defined previously. It assumes both LM and RM are configured. An instance of `SimpleRAG` is created and called with a sample question, printing the final generated answer.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# --- Let's try it ---\n# Assume LM is also configured (e.g., gpt3_turbo from Chapter 5)\n# dspy.settings.configure(lm=gpt3_turbo)\n\nrag_program = SimpleRAG()\nquestion = \"What is the largest rodent?\"\nresult = rag_program(question=question)\n\nprint(f\"Question: {question}\")\n# The retrieve module would fetch passages about rodents...\n# print(f\"Context: {context}\") # (Would show passages about capybaras, etc.)\nprint(f\"Answer: {result.answer}\")\n```\n\n----------------------------------------\n\nTITLE: Response Building Implementation in Python\nDESCRIPTION: Implements the build_response() method that converts urllib3 responses into Requests library Response objects, handling status codes, headers, and other response metadata.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n    def build_response(self, req, resp):\n        \"\"\"Builds a requests.Response from a urllib3 response.\"\"\"\n        response = Response()\n        response.status_code = getattr(resp, 'status', None)\n        response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n        response.raw = resp # The raw urllib3 response object\n        response.reason = response.raw.reason\n        response.url = req.url\n        # ... extract cookies, set encoding, link request ...\n        response.request = req\n        response.connection = self # Link back to this adapter\n        return response\n```\n\n----------------------------------------\n\nTITLE: Using the Config Singleton to Access Settings\nDESCRIPTION: Example of how different parts of OpenManus can access configuration settings through the singleton Config instance, demonstrating access to LLM, sandbox, search, and browser settings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Example of how another part of the code might use the config\nfrom app.config import config # Import the singleton instance\n\n# Access LLM settings\ndefault_llm_settings = config.llm.get(\"default\") # Get the 'default' LLM config\nif default_llm_settings:\n    model_name = default_llm_settings.model\n    api_key = default_llm_settings.api_key\n    print(f\"LLM Model: {model_name}\")\n    # Don't print the API key in real code! This is just for illustration.\n    # print(f\"LLM API Key: {api_key[:4]}...{api_key[-4:]}\")\n\n# Access Sandbox settings\nuse_sandbox_flag = config.sandbox.use_sandbox\nsandbox_image = config.sandbox.image\nprint(f\"Use Sandbox: {use_sandbox_flag}\")\nprint(f\"Sandbox Image: {sandbox_image}\")\n\n# Access Search settings (check if it exists)\nif config.search_config:\n    search_engine = config.search_config.engine\n    print(f\"Preferred Search Engine: {search_engine}\")\n\n# Access Browser settings (check if it exists)\nif config.browser_config:\n    run_headless = config.browser_config.headless\n    print(f\"Run Browser Headless: {run_headless}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Topic Channel\nDESCRIPTION: Topic channel implementation that collects updates into a list, with optional accumulation across steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Sequence, List, Union\n\nclass Topic(Generic[Value], BaseChannel[Sequence[Value], Union[Value, list[Value]], list[Value]]):\n    values: list[Value]\n    accumulate: bool\n\n    def update(self, updates: Sequence[Union[Value, list[Value]]]) -> bool:\n        old_len = len(self.values)\n        if not self.accumulate:\n            self.values = []\n        new_values = list(flatten(updates))\n        self.values.extend(new_values)\n        return len(self.values) != old_len\n```\n\n----------------------------------------\n\nTITLE: Serialization Example in Pydantic\nDESCRIPTION: Shows how to serialize a Pydantic model instance to a dictionary or JSON string using the model_dump() and model_dump_json() methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Example: Serialization\nuser = User(id=1, username='validUser')\nuser_dict = user.model_dump()\n# or: user_json = user.model_dump_json()\n```\n\n----------------------------------------\n\nTITLE: Implementing Researcher Publishing Logic\nDESCRIPTION: Shows how a Researcher agent publishes facts to a topic using the messaging system. Includes message definition and publishing logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass ResearchFacts:\n    topic: str\n    facts: list[str]\n\nasync def researcher_publish_logic(agent_context, message: ResearchTopic, msg_context):\n    print(f\"Researcher working on: {message.topic}\")\n    facts_data = ResearchFacts(\n        topic=message.topic,\n        facts=[f\"Fact A about {message.topic}\", f\"Fact B about {message.topic}\"]\n    )\n\n    results_topic = TopicId(type=\"research.facts.available\", source=message.topic)\n\n    await agent_context.publish_message(message=facts_data, topic_id=results_topic)\n    print(f\"Researcher published facts to topic: {results_topic}\")\n    return None\n```\n\n----------------------------------------\n\nTITLE: Checking Sandbox Configuration in OpenManus\nDESCRIPTION: This snippet demonstrates how to check if the sandbox is enabled in the configuration. It accesses the config object to verify if the sandbox feature is turned on before proceeding with sandboxed execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/08_dockersandbox.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Check the configuration loaded in Chapter 7\nfrom app.config import config\n\nif config.sandbox and config.sandbox.use_sandbox:\n    print(\"Sandbox is ENABLED. Code will run inside a container.\")\n    # Proceed with using the sandbox client...\nelse:\n    print(\"Sandbox is DISABLED. Code might run directly on the host (potentially unsafe).\")\n    # Fallback or raise an error...\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery with a Result Backend using Redis\nDESCRIPTION: Sets up a Celery application with both broker and result backend configurations using Redis. Includes two example tasks: a simple addition task and a task that randomly fails to demonstrate error handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# celery_app.py\nfrom celery import Celery\n\n# Configure BOTH broker and result backend\napp = Celery('tasks',\n             broker='redis://localhost:6379/0',\n             backend='redis://localhost:6379/1') # <-- Result Backend URL\n\n# You could also use app.config_from_object('celeryconfig')\n# if result_backend = 'redis://localhost:6379/1' is in celeryconfig.py\n\n# ... your task definitions (@app.task) would go here or be imported ...\n@app.task\ndef add(x, y):\n    import time\n    time.sleep(3) # Simulate work\n    return x + y\n\n@app.task\ndef fail_sometimes(x):\n    import random\n    if random.random() < 0.5:\n        raise ValueError(\"Something went wrong!\")\n    return f\"Processed {x}\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing MCP Communication Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram illustrating how MCP Protocol Types are used in a callTool interaction between a client application and a server tool function, showing the transformation of data through different layers of the system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/07_mcp_protocol_types.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant ClientApp as Client Application\n    participant ClientSDK as MCP Client SDK\n    participant ServerSDK as MCP Server SDK (FastMCP)\n    participant YourTool as Your @server.tool Function\n\n    ClientApp->>+ClientSDK: Request tool \"add\" with {num1: 5, num2: 7}\n    ClientSDK->>ClientSDK: Create CallToolRequest object (Pydantic model)\n    ClientSDK->>+ServerSDK: Send JSON message (based on CallToolRequest)\n    ServerSDK->>ServerSDK: Receive JSON, parse into CallToolRequest object (Pydantic validation)\n    ServerSDK->>+YourTool: Call add_numbers(num1=5, num2=7)\n    YourTool-->>-ServerSDK: Return 12\n    ServerSDK->>ServerSDK: Create CallToolResult object (Pydantic model, content=[TextContent(text=\"12\")])\n    ServerSDK->>-ClientSDK: Send JSON message (based on CallToolResult)\n    ClientSDK->>ClientSDK: Receive JSON, parse into CallToolResult object (Pydantic validation)\n    ClientSDK-->>-ClientApp: Return result \"12\"\n```\n\n----------------------------------------\n\nTITLE: Basic NumPy Sine Function Usage\nDESCRIPTION: Demonstrates using NumPy's sine function on an array of angles, showing how ufuncs operate element-wise on arrays.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/07_umath_module.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nangles = np.array([0, np.pi/2, np.pi])\nsines = np.sin(angles) # How is this sine calculated so fast?\n\nprint(angles)\nprint(sines)\n```\n\n----------------------------------------\n\nTITLE: Agent Logic Implementation Using BaseAgent\nDESCRIPTION: Defines two agent classes (ResearcherAgent and WriterAgent) that inherit from BaseAgent. The ResearcherAgent processes research topics and publishes facts, while the WriterAgent receives facts and creates draft content from them.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# 1. Define Agent Logic (using BaseAgent)\n\nclass ResearcherAgent(BaseAgent):\n    async def on_message_impl(self, message: ResearchTopic, ctx: MessageContext):\n        print(f\"Researcher ({self.id}) got topic: {message.topic}\")\n        facts = [f\"Fact 1 about {message.topic}\", f\"Fact 2\"]\n        results_topic = TopicId(\"research.facts.available\", message.topic)\n        # Use the runtime (via self.publish_message helper) to publish\n        await self.publish_message(\n            ResearchFacts(topic=message.topic, facts=facts), results_topic\n        )\n        print(f\"Researcher ({self.id}) published facts to {results_topic}\")\n\nclass WriterAgent(BaseAgent):\n    async def on_message_impl(self, message: ResearchFacts, ctx: MessageContext):\n        print(f\"Writer ({self.id}) received facts via topic '{ctx.topic_id}': {message.facts}\")\n        draft = f\"Draft for {message.topic}: {'; '.join(message.facts)}\"\n        print(f\"Writer ({self.id}) created draft: '{draft}'\")\n        # This agent doesn't send further messages in this example\n```\n\n----------------------------------------\n\nTITLE: Visualizing Session Workflow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid code block renders a sequence diagram representing the internal communication flow between your code, a Session object, PreparedRequest, Transport Adapter, and a Web Server during two consecutive HTTP requests. It provides a visual summary of the steps explained in the surrounding text. The diagram does not require code dependencies, but rendering it will need a Markdown viewer or tool that supports Mermaid syntax.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/03_session.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant User as Your Code\\n    participant Sess as Session Object\\n    participant PrepReq as PreparedRequest\\n    participant Adapter as Transport Adapter (holds connection pool)\\n    participant Server as Web Server\\n\\n    User->>Sess: Create Session()\\n    User->>Sess: s.get(url1, headers={'User-Header': 'A'})\\n    Sess->>Sess: Merge s.headers, s.cookies, s.auth... with User's headers/data\\n    Sess->>PrepReq: prepare_request(merged_settings)\\n    Sess->>Adapter: send(prepared_request)\\n    Adapter->>Adapter: Get connection from pool (or create new)\\n    Adapter->>Server: Send HTTP Request 1 (with session+user headers, session cookies)\\n    Server-->>Adapter: Send HTTP Response 1 (sets cookie 'C')\\n    Adapter->>Sess: Return Response 1\\n    Sess->>Sess: Extract cookie 'C' into s.cookies\\n    Sess-->>User: Return Response 1\\n\\n    User->>Sess: s.get(url2)\\n    Sess->>Sess: Merge s.headers, s.cookies ('C'), s.auth...\\n    Sess->>PrepReq: prepare_request(merged_settings)\\n    Sess->>Adapter: send(prepared_request)\\n    Adapter->>Adapter: Get REUSED connection from pool\\n    Adapter->>Server: Send HTTP Request 2 (with session headers, cookie 'C')\\n    Server-->>Adapter: Send HTTP Response 2\\n    Adapter->>Sess: Return Response 2\\n    Sess-->>User: Return Response 2\n```\n\n----------------------------------------\n\nTITLE: Visualizing Sequential Process in Trip Planning Crew using Mermaid\nDESCRIPTION: This Mermaid diagram illustrates the sequential process of the Crew executing tasks. It shows the flow of information between the User, Crew, and the two agents (Researcher and Planner).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/01_crew.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MyCrew as Crew\n    participant ResearcherAgent as Researcher\n    participant PlannerAgent as Planner\n\n    User->>MyCrew: kickoff()\n    MyCrew->>ResearcherAgent: Execute Task 1 (\"Find cities...\")\n    Note right of ResearcherAgent: Researcher thinks... generates city list.\n    ResearcherAgent-->>MyCrew: Task 1 Output (\"Barcelona, Lisbon, Rome...\")\n    MyCrew->>PlannerAgent: Execute Task 2 (\"Create itinerary...\") \\nwith Task 1 Output as context\n    Note right of PlannerAgent: Planner thinks... uses city list, creates itinerary.\n    PlannerAgent-->>MyCrew: Task 2 Output (\"Day 1: ..., Day 2: ...\")\n    MyCrew-->>User: Final Result (Task 2 Output)\n```\n\n----------------------------------------\n\nTITLE: Complete Example: Sending a Task via JSON-RPC\nDESCRIPTION: This JSON snippet shows the complete structure of an HTTP POST body for a `tasks/send` request using JSON-RPC 2.0. It includes the `jsonrpc` version, the `method` name ('tasks/send'), the `params` object containing the specific task details (like `id` and the user's `message` structured with `role` and `parts`), and a unique request `id`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n// Client Sends This (HTTP POST body to Agent's URL)\n{\n  \"jsonrpc\": \"2.0\",\n  \"method\": \"tasks/send\", // The action: start/continue a task\n  \"params\": {            // The details (TaskSendParams structure)\n    \"id\": \"task-xyz-789\", // Unique Task ID\n    \"message\": {         // The user's message\n      \"role\": \"user\",\n      \"parts\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"Translate 'hello' to French\"\n        }\n      ]\n    }\n    // Other optional params like sessionId could go here\n  },\n  \"id\": \"client-req-001\" // Unique ID for *this specific request*\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a TypeAdapter for List[PositiveInt] in Python\nDESCRIPTION: Shows how to create a TypeAdapter for a list of positive integers using Pydantic's PositiveInt type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import List\nfrom pydantic import TypeAdapter, PositiveInt\n\n# Define the specific type we want to validate against\n# This can be any Python type hint Pydantic understands\nUserIdListType = List[PositiveInt]\n\n# Create the adapter for this type\nuser_id_list_adapter = TypeAdapter(UserIdListType)\n\nprint(user_id_list_adapter)\n# Expected Output: TypeAdapter(<class 'list[pydantic.types.PositiveInt]'>)\n```\n\n----------------------------------------\n\nTITLE: Saving ListMemory Configuration in Python\nDESCRIPTION: This snippet shows how to save the configuration of a ListMemory instance by creating a ComponentModel using the dump_component method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# File: save_memory_config.py\n# Assume 'my_memory' exists from the previous step\n\n# Dump the component's configuration into a ComponentModel\nmemory_model = my_memory.dump_component()\n\n# Let's print it (converting to dict for readability)\nprint(\"Saved ComponentModel:\")\nprint(memory_model.model_dump_json(indent=2))\n```\n\n----------------------------------------\n\nTITLE: Implementing Session and Cookie Extraction in Requests (Python)\nDESCRIPTION: This Python snippet shows simplified versions of key classes and functions in the Requests library that manage cookies, including the Session class, cookie extraction, and request preparation logic. It covers how cookies are merged and extracted, and demonstrates dictionary-like operations using RequestsCookieJar. Dependencies include Requests modules (cookies, models), and the cookielib or http.cookiejar library. Inputs are request/response objects; outputs are merged cookies or headers set for HTTP traffic. The snippet abstracts many details for clarity and omits unrelated methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# File: requests/sessions.py (Simplified View)\\n\\nfrom .cookies import extract_cookies_to_jar, merge_cookies, RequestsCookieJar, cookiejar_from_dict\\nfrom .models import PreparedRequest\\nfrom .utils import to_key_val_list\\nfrom .structures import CaseInsensitiveDict\\n\\nclass Session:\\n    def __init__(self):\\n        # ... other attributes ...\\n        self.cookies = cookiejar_from_dict({}) # The Session's main Cookie Jar\\n\\n    def prepare_request(self, request):\\n        # ... merge headers, params, auth ...\\n\\n        # Merge session cookies with request-specific cookies\\n        merged_cookies = merge_cookies(\\n            merge_cookies(RequestsCookieJar(), self.cookies),\\n            cookiejar_from_dict(request.cookies or {})\\n        )\\n\\n        p = PreparedRequest()\\n        p.prepare(\\n            # ... other args ...\\n            cookies=merged_cookies, # Pass merged jar to PreparedRequest\\n        )\\n        return p\\n\\n    def send(self, request, **kwargs):\\n        # ... prepare sending ...\\n        adapter = self.get_adapter(url=request.url)\\n        response = adapter.send(request, **kwargs) # Adapter gets raw response\\n\\n        # ... hooks ...\\n\\n        # EXTRACT cookies from the response and put them in the session jar!\\n        extract_cookies_to_jar(self.cookies, request, response.raw)\\n\\n        # ... redirect handling (also extracts cookies) ...\\n\\n        return response\\n\\n# --- File: requests/models.py (Simplified View) ---\\nfrom .cookies import get_cookie_header, _copy_cookie_jar, cookiejar_from_dict\\n\\nclass PreparedRequest:\\n    def prepare_cookies(self, cookies):\\n        # Store the jar potentially passed from Session.prepare_request\\n        if isinstance(cookies, cookielib.CookieJar):\\n            self._cookies = cookies\\n        else:\\n            self._cookies = cookiejar_from_dict(cookies)\\n\\n        # Generate the Cookie header string\\n        cookie_header = get_cookie_header(self._cookies, self)\\n        if cookie_header is not None:\\n            self.headers['Cookie'] = cookie_header\\n\\nclass Response:\\n    def __init__(self):\\n        # ... other attributes ...\\n        # This jar holds cookies SET by *this* response only\\n        self.cookies = cookiejar_from_dict({})\\n\\n# --- File: requests/cookies.py (Simplified View) ---\\nimport cookielib\\n\\nclass MockRequest: # Helper to adapt requests.Request for cookielib\\n    # ... implementation ...\\n\\nclass MockResponse: # Helper to adapt response headers for cookielib\\n    # ... implementation ...\\n\\ndef extract_cookies_to_jar(jar, request, response):\\n    \\\"\\\"\\\"Extract Set-Cookie headers from response into jar.\\\"\\\"\\\"\\n    if not hasattr(response, '_original_response') or not response._original_response:\\n        return # Need the underlying httplib response\\n\\n    req = MockRequest(request) # Adapt request for cookielib\\n    res = MockResponse(response._original_response.msg) # Adapt headers for cookielib\\n    jar.extract_cookies(res, req) # Use cookielib's extraction logic\\n\\ndef get_cookie_header(jar, request):\\n    \\\"\\\"\\\"Generate the Cookie header string for the request.\\\"\\\"\\\"\\n    r = MockRequest(request)\\n    jar.add_cookie_header(r) # Use cookielib to add the header to the mock request\\n    return r.get_new_headers().get('Cookie') # Retrieve the generated header\\n\\nclass RequestsCookieJar(cookielib.CookieJar, MutableMapping):\\n    # Dictionary-like methods (get, set, __getitem__, etc.)\\n    def get(self, name, default=None, domain=None, path=None):\\n       # ... find cookie, handle conflicts ...\\n       pass\\n    def set(self, name, value, **kwargs):\\n       # ... create or update cookie ...\\n       pass\\n    # ... other dict methods ...\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolCall and Function Schemas in OpenManus\nDESCRIPTION: These schemas define the structure for tool call requests when an LLM instructs an agent to use a tool. The Function schema specifies the tool name and arguments, while ToolCall wraps this with additional metadata like a unique ID and call type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simplified Pydantic models from app/schema.py\nfrom pydantic import BaseModel\n\nclass Function(BaseModel):\n    name: str      # The name of the tool/function to call\n    arguments: str # The input arguments as a JSON string\n\nclass ToolCall(BaseModel):\n    id: str              # A unique ID for this specific call\n    type: str = \"function\" # Currently always \"function\"\n    function: Function   # Embeds the Function details above\n```\n\n----------------------------------------\n\nTITLE: OpenManus Configuration File Example in TOML\nDESCRIPTION: A simplified example of the config.toml file which defines settings for different components of the OpenManus application including LLM, sandbox, search, and browser configurations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n# config/config.toml (Simplified Example)\n\n[llm] # Settings for the Large Language Model\nmodel = \"gpt-4o\"\napi_key = \"YOUR_OPENAI_API_KEY_HERE\" # Replace with your actual key\nbase_url = \"https://api.openai.com/v1\"\napi_type = \"openai\"\n\n[sandbox] # Settings for the code execution sandbox\nuse_sandbox = true\nimage = \"python:3.12-slim\"\nmemory_limit = \"256m\"\n\n[search_config] # Settings for web search\nengine = \"DuckDuckGo\"\n\n[browser_config] # Settings for the browser tool\nheadless = false\n```\n\n----------------------------------------\n\nTITLE: Updating BrowserState using DomService in Python\nDESCRIPTION: This snippet shows how BrowserContext._update_state() method uses DomService to get the DOM map and combine it with other page information to create a BrowserState object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom browser_use.dom.service import DomService # Import the service\nfrom browser_use.browser.views import BrowserState\n\nclass BrowserContext:\n    # ... other methods ...\n    async def _update_state(self) -> BrowserState:\n        page = await self.get_current_page() # Get the active Playwright page object\n        # ... error handling ...\n        try:\n            # 1. Create DomService instance for the current page\n            dom_service = DomService(page)\n\n            # 2. Call DomService to get the DOM map (DOMState)\n            content_info = await dom_service.get_clickable_elements(\n                highlight_elements=self.config.highlight_elements,\n                viewport_expansion=self.config.viewport_expansion,\n                # ... other options ...\n            )\n\n            # 3. Get other info (screenshot, URL, title etc.)\n            screenshot_b64 = await self.take_screenshot()\n            url = page.url\n            title = await page.title()\n            # ... gather more state ...\n\n            # 4. Package everything into BrowserState\n            browser_state = BrowserState(\n                element_tree=content_info.element_tree, # <--- From DomService\n                selector_map=content_info.selector_map, # <--- From DomService\n                url=url,\n                title=title,\n                screenshot=screenshot_b64,\n                # ... other state info ...\n            )\n            return browser_state\n        except Exception as e:\n            logger.error(f'Failed to update state: {str(e)}')\n            raise # Or handle error\n```\n\n----------------------------------------\n\nTITLE: Configuring Floating-Point Display Precision\nDESCRIPTION: Demonstrates how to control the display of floating-point numbers in NumPy arrays by adjusting the precision and suppressing scientific notation for small values.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# An array with floating-point numbers\nfloat_arr = np.array([0.123456789, 1.5e-10, 2.987])\nprint(\"Default precision:\")\nprint(float_arr)\n\n# Set precision to 3\nwith np.printoptions(precision=3):\n  print(\"\\nWith precision=3:\")\n  print(float_arr)\n\n# Set precision to 3 and suppress small numbers\nwith np.printoptions(precision=3, suppress=True):\n  print(\"\\nWith precision=3, suppress=True:\")\n  print(float_arr)\n```\n\n----------------------------------------\n\nTITLE: Implementing Config Management in Python\nDESCRIPTION: A simplified snippet from app/config.py showing the implementation of the Config class, including Pydantic models for settings validation, the singleton pattern, and methods for loading and accessing configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/config.py\nimport threading\nimport tomllib\nfrom pathlib import Path\nfrom pydantic import BaseModel, Field\n# ... other imports like typing ...\n\n# --- Pydantic Models for Settings ---\nclass LLMSettings(BaseModel): # Defines structure for [llm] section\n    model: str\n    api_key: str\n    # ... other fields like base_url, max_tokens, api_type ...\n\nclass SandboxSettings(BaseModel): # Defines structure for [sandbox] section\n    use_sandbox: bool\n    image: str\n    # ... other fields like memory_limit, timeout ...\n\n# ... Similar models for BrowserSettings, SearchSettings, MCPSettings ...\n\nclass AppConfig(BaseModel): # Holds all validated settings together\n    llm: Dict[str, LLMSettings]\n    sandbox: Optional[SandboxSettings]\n    browser_config: Optional[BrowserSettings]\n    search_config: Optional[SearchSettings]\n    mcp_config: Optional[MCPSettings]\n\n# --- The Singleton Config Class ---\nclass Config:\n    _instance = None\n    _lock = threading.Lock() # Ensures thread-safety during creation\n    _initialized = False\n\n    def __new__(cls): # Controls instance creation (Singleton part 1)\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = super().__new__(cls)\n        return cls._instance\n\n    def __init__(self): # Initializes the instance (runs only once)\n        if not self._initialized:\n            with self._lock:\n                if not self._initialized:\n                    self._config: Optional[AppConfig] = None # Where settings are stored\n                    self._load_initial_config() # Load from file\n                    self._initialized = True\n\n    def _load_config(self) -> dict: # Reads the TOML file\n        config_path = self._get_config_path() # Finds config.toml or example\n        with config_path.open(\"rb\") as f:\n            return tomllib.load(f) # Parses TOML into a dictionary\n\n    def _load_initial_config(self): # Parses dict and validates with Pydantic\n        raw_config = self._load_config()\n        # ... (logic to handle defaults and structure the raw_config dict) ...\n        # ... (creates LLMSettings, SandboxSettings etc. from raw_config) ...\n\n        # Validate the final structured dict using AppConfig\n        self._config = AppConfig(**structured_config_dict)\n\n    # --- Properties to Access Settings ---\n    @property\n    def llm(self) -> Dict[str, LLMSettings]:\n        # Provides easy access like 'config.llm'\n        return self._config.llm\n\n    @property\n    def sandbox(self) -> SandboxSettings:\n        # Provides easy access like 'config.sandbox'\n        return self._config.sandbox\n\n    # ... Properties for browser_config, search_config, mcp_config ...\n\n# --- Create the Singleton Instance ---\n# This line runs when the module is imported, creating the single instance.\nconfig = Config()\n```\n\n----------------------------------------\n\nTITLE: Implementing Blueprint Class in Python for Celery Bootsteps\nDESCRIPTION: This snippet defines the Blueprint class used in Celery's bootstep system. It manages a collection of steps, handles their dependencies, and controls their lifecycle. The class includes methods for applying steps, starting, stopping, and managing the execution order.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/10_bootsteps.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept from celery/bootsteps.py\nfrom celery.utils.graph import DependencyGraph\n\nclass Blueprint:\n    # Set of default step classes (or string names) included in this blueprint\n    default_steps = set()\n\n    def __init__(self, steps=None, name=None, **kwargs):\n        self.name = name or self.__class__.__name__\n        # Combine default steps with any provided steps\n        self.types = set(steps or []) | set(self.default_steps)\n        self.steps = {} # Will hold step instances\n        self.order = [] # Will hold sorted step instances\n        # ... other callbacks ...\n\n    def apply(self, parent, **kwargs):\n        # 1. Load step classes from self.types\n        step_classes = self.claim_steps() # {name: StepClass, ...}\n\n        # 2. Build the dependency graph\n        self.graph = DependencyGraph(\n            ((Cls, Cls.requires) for Cls in step_classes.values()),\n            # ... formatter options ...\n        )\n\n        # 3. Get the topologically sorted order\n        sorted_classes = self.graph.topsort()\n\n        # 4. Instantiate and include each step\n        self.order = []\n        for S in sorted_classes:\n            step = S(parent, **kwargs) # Call Step.__init__\n            self.steps[step.name] = step\n            self.order.append(step)\n        for step in self.order:\n            step.include(parent) # Call Step.include -> Step.create\n\n        return self\n\n    def start(self, parent):\n        # Called by the parent (e.g., Worker) to start all steps\n        for step in self.order: # Use the sorted order\n            if hasattr(step, 'start'):\n                step.start(parent)\n\n    def stop(self, parent):\n        # Called by the parent to stop all steps (in reverse order)\n        for step in reversed(self.order):\n             if hasattr(step, 'stop'):\n                step.stop(parent)\n    # ... other methods like close, terminate, restart ...\n```\n\n----------------------------------------\n\nTITLE: NumPy Array Print Output Examples - Python\nDESCRIPTION: This snippet shows example outputs when printing a NumPy array under different print option settings. It exemplifies the effects of changing threshold and precision, as well as summarization options, on the multiline string representation of arrays. The arrays illustrated contain random floating-point numbers, and the output demonstrates formatting differences like precision, line breaks, and the presence of ellipses for summarized content.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n--- Setting threshold globally ---\n[[992.84337197 931.73648142 119.68616987 ... 305.61919366 516.97897205\n  707.69140878]\n [507.45895986 253.00740626 739.97091378 ... 755.69943511 813.11931119\n   19.84654589]\n [941.25264871 689.43209981 820.11954711 ... 709.83933545 192.49837505\n  609.30358618]\n ...\n [498.86686503 872.79555956 401.19333028 ... 552.97492858 303.59379464\n  308.61881807]\n [797.51920685 427.86020151 783.2019203  ... 511.63382762 322.52764881\n  778.22766019]\n [ 54.84391309 938.24403397 796.7431406  ... 495.90873227 267.16620292\n  409.51491904]]\n\n--- Setting precision temporarily ---\n[[992.84 931.74 119.69 ... 305.62 516.98 707.69]\n [507.46 253.01 739.97 ... 755.7  813.12  19.85]\n [941.25 689.43 820.12 ... 709.84 192.5  609.3 ]\n ...\n [498.87 872.8  401.19 ... 552.97 303.59 308.62]\n [797.52 427.86 783.2  ... 511.63 322.53 778.23]\n [ 54.84 938.24 796.74 ... 495.91 267.17 409.51]]\n\n--- Back to default precision ---\n[[992.84337197 931.73648142 119.68616987 ... 305.61919366 516.97897205\n  707.69140878]\n [507.45895986 253.00740626 739.97091378 ... 755.69943511 813.11931119\n   19.84654589]\n [941.25264871 689.43209981 820.11954711 ... 709.83933545 192.49837505\n  609.30358618]\n ...\n [498.86686503 872.79555956 401.19333028 ... 552.97492858 303.59379464\n  308.61881807]\n [797.51920685 427.86020151 783.2019203  ... 511.63382762 322.52764881\n  778.22766019]\n [ 54.84391309 938.24403397 796.7431406  ... 495.90873227 267.16620292\n  409.51491904]]\n\n--- Using array2string with summarization off ---\n[[992.8 931.7 119.7 922.  912.2 156.5 459.4 305.6 517.  707.7]\n [507.5 253.  740.  640.3 420.3 652.1 197.  755.7 813.1  19.8]\n [941.3 689.4 820.1 125.8 598.2 219.3 466.7 709.8 192.5 609.3]\n [ 32.  855.2 362.1 434.9 133.5 148.1 522.6 725.1 395.5 377.9]\n [332.7 782.2 587.3 320.3 905.5 412.8 378.  911.9 972.1 400.2]\n...\n```\n\n----------------------------------------\n\nTITLE: DomService JavaScript Execution in Python\nDESCRIPTION: This snippet demonstrates how DomService._build_dom_tree() method executes JavaScript code (stored in buildDomTree.js) within the browser page's context to analyze the DOM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nfrom importlib import resources\n# ... other imports ...\n\nlogger = logging.getLogger(__name__)\n\nclass DomService:\n    def __init__(self, page: 'Page'):\n        self.page = page\n        # Load the JavaScript code from the file when DomService is created\n        self.js_code = resources.read_text('browser_use.dom', 'buildDomTree.js')\n        # ...\n\n    async def _build_dom_tree(\n        self, highlight_elements: bool, focus_element: int, viewport_expansion: int\n    ) -> tuple[DOMElementNode, SelectorMap]:\n\n        # Prepare arguments for the JavaScript function\n        args = {\n            'doHighlightElements': highlight_elements,\n            'focusHighlightIndex': focus_element,\n            'viewportExpansion': viewport_expansion,\n            'debugMode': logger.getEffectiveLevel() == logging.DEBUG,\n        }\n\n        try:\n            # Execute the JavaScript code in the browser page!\n            # The JS code analyzes the live DOM and returns a structured result.\n            eval_page = await self.page.evaluate(self.js_code, args)\n        except Exception as e:\n            logger.error('Error evaluating JavaScript: %s', e)\n            raise\n\n        # ... (optional debug logging) ...\n\n        # Parse the result from JavaScript into Python objects\n        return await self._construct_dom_tree(eval_page)\n\n    async def _construct_dom_tree(self, eval_page: dict) -> tuple[DOMElementNode, SelectorMap]:\n        # ... (logic to parse js_node_map from eval_page) ...\n        # ... (loops through nodes, creates DOMElementNode/DOMTextNode objects) ...\n        # ... (builds the tree structure by linking parents/children) ...\n        # ... (populates the selector_map dictionary) ...\n        # This uses the structures defined in dom/views.py\n        # ...\n        root_node = ... # Parsed root DOMElementNode\n        selector_map = ... # Populated dictionary {index: DOMElementNode}\n        return root_node, selector_map\n    # ... other methods like get_clickable_elements ...\n```\n\n----------------------------------------\n\nTITLE: Executing Main Function with Asyncio in Python\nDESCRIPTION: Demonstrates using asyncio.run to execute the main coroutine function. This is typically used as the entry point for asynchronous applications, allowing the host agent to coordinate concurrent tasks to multiple downstream agents.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/08_multi_agent_orchestration__host_agent_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Telemetry Flow Diagram in Mermaid\nDESCRIPTION: A sequence diagram showing the flow of how telemetry data is captured, processed, and sent from an Agent to PostHog through the ProductTelemetry service.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant TelemetrySvc as ProductTelemetry\n    participant LocalFile as ~/.cache/.../user_id\n    participant PostHog\n\n    Agent->>TelemetrySvc: capture(AgentRunEvent)\n    Note over TelemetrySvc: Telemetry Enabled? Yes.\n    TelemetrySvc->>LocalFile: Read existing User ID (or create new)\n    LocalFile-->>TelemetrySvc: Anonymous User ID (UUID)\n    Note over TelemetrySvc: Package Event + User ID\n    TelemetrySvc->>PostHog: Send(EventData, UserID)\n    PostHog-->>TelemetrySvc: Acknowledgment (Optional)\n```\n\n----------------------------------------\n\nTITLE: Sending Tasks and Handling Streaming Responses Using A2AClient (JavaScript, TypeScript)\nDESCRIPTION: This JavaScript/TypeScript snippet demonstrates how to build a basic command-line client for interacting with an A2A agent server using the A2AClient library. The client constructs and sends task requests with a uniquely generated taskId and user message, subscribes to streaming events (such as TaskStatusUpdateEvent or TaskArtifactUpdateEvent), and prints all received events in real time. Dependencies include the A2AClient package, proper agent endpoint URL, TypeScript support, and Node.js crypto module for random ID generation. Inputs include the agent server URL and user message; outputs are received events printed to the console. The snippet assumes the agent supports streaming via tasks/sendSubscribe and requires the client library to properly process and iterate Server-Sent Events (SSE).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/05_a2a_client_implementation.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// File: samples/js/src/cli.ts (Simplified Snippet)\nimport { A2AClient } from \"./client/client.js\"; // The client library\nimport { TaskSendParams } from \"./schema.js\"; // Types for request parameters\nimport crypto from \"node:crypto\"; // To generate IDs\n\n// Agent's address (replace with your agent's URL)\nconst serverUrl = \"http://localhost:4000\";\n\n// 1. Create a client instance pointing to the agent's server\nconst client = new A2AClient(serverUrl);\n\n// User input from the command line\nconst userInput = \"Hello Echo Agent!\";\n\n// 2. Prepare the parameters for the 'tasks/sendSubscribe' request\nconst taskId = crypto.randomUUID(); // Generate a unique ID for this task\nconst params: TaskSendParams = {\n  id: taskId,\n  message: {\n    role: \"user\",\n    parts: [{ type: \"text\", text: userInput }], // The user's message\n  },\n};\n\n// 3. Send the request and handle the streaming response\nasync function sendMessage() {\n  console.log(`Sending task ${taskId} to ${serverUrl}...`);\n  try {\n    // Use sendTaskSubscribe for agents that support streaming\n    const stream = client.sendTaskSubscribe(params);\n\n    // Loop through the events received from the server\n    for await (const event of stream) {\n      console.log(\"Received Agent Event:\", event);\n      // (In a real app, you'd parse 'event' which could be\n      // TaskStatusUpdateEvent or TaskArtifactUpdateEvent)\n    }\n    console.log(\"Agent stream finished.\");\n\n  } catch (error: any) {\n    console.error(\"Error talking to agent:\", error.message || error);\n  }\n}\n\nsendMessage();\n```\n\n----------------------------------------\n\nTITLE: Adding Edges in Graph Base Class in Python\nDESCRIPTION: Implementation of the add_edge method in the Graph base class that stores connections between nodes as simple pairs, performing validation to prevent invalid edges like those starting from END nodes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from the base Graph class\ndef add_edge(self, start_key: str, end_key: str):\n    # ... checks for invalid edges (e.g., starting from END) ...\n    # ... basic validation ...\n    # Stores the connection as a simple pair\n    self.edges.add((start_key, end_key))\n    return self\n```\n\n----------------------------------------\n\nTITLE: Illustrating JSON-RPC Error Response Structure\nDESCRIPTION: This JSON snippet shows the format of a JSON-RPC 2.0 error response used when an agent encounters a problem processing a request. It contains the `jsonrpc` version, an `error` object detailing the failure with a numeric `code` and a descriptive `message`, and the `id` corresponding to the failed request (or null in severe cases).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"jsonrpc\": \"2.0\",\n  \"error\": {             // Details about what went wrong\n    \"code\": -32601,\n    \"message\": \"Method not found\"\n  },\n  \"id\": \"request-123\"     // The SAME ID as the request (or null if error was severe)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Approval State for Interrupt Example in Python\nDESCRIPTION: Creates a TypedDict to represent the state for a workflow involving human approval. It includes fields for the plan and feedback/approval status.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import TypedDict, Optional\n\nclass ApprovalState(TypedDict):\n    plan: str\n    # We'll use the resume value to implicitly know if approved\n    feedback: Optional[str] # Store feedback/approval status\n```\n\n----------------------------------------\n\nTITLE: Creating Context Object in FastMCP (Python)\nDESCRIPTION: This snippet shows how the FastMCP class creates a Context object, wrapping the low-level RequestContext and including a reference to the FastMCP instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/06_fastmcp_context___context__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Inside server/fastmcp/server.py (Simplified FastMCP.get_context)\nfrom mcp.shared.context import RequestContext # Low-level context\n\nclass FastMCP:\n    # ... (other methods) ...\n\n    def get_context(self) -> Context[ServerSession, object]:\n        \"\"\"Returns a Context object.\"\"\"\n        try:\n            # Get the low-level context for the current request\n            request_context: RequestContext | None = self._mcp_server.request_context\n        except LookupError:\n            request_context = None # Not available outside a request\n\n        # Create our high-level Context, passing the low-level one\n        # and a reference to this FastMCP instance ('self')\n        return Context(request_context=request_context, fastmcp=self)\n```\n\n----------------------------------------\n\nTITLE: Assigning Specific LLMs for Manager and Function Calling in CrewAI (Python)\nDESCRIPTION: Example of setting specific LLMs within a CrewAI `Crew` definition, particularly for hierarchical processes. It assigns `manager_llm` for the managing agent and `function_calling_llm` for tool usage decisions, potentially using different models (e.g., a faster/cheaper one like gpt-3.5-turbo for function calling). Requires the `crewai` library and the relevant LangChain LLM wrappers (e.g., `langchain_openai`). Assumes agents and tasks are already defined.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom crewai import Crew, Process\nfrom langchain_openai import ChatOpenAI\n\n# Assume agents 'researcher', 'planner' and tasks 'task1', 'task2' are defined\n\nopenai_llm = ChatOpenAI(model=\"gpt-4o\")\nfast_llm = ChatOpenAI(model=\"gpt-3.5-turbo\") # Maybe a faster/cheaper model\n\ntrip_crew = Crew(\n    agents=[researcher, planner], # Agents might have their own LLMs assigned too\n    tasks=[task1, task2],\n    process=Process.hierarchical,\n    # The Manager agent will use gpt-4o\n    manager_llm=openai_llm,\n    # Use gpt-3.5-turbo specifically for deciding which tool to use (can save costs)\n    function_calling_llm=fast_llm\n)\n```\n\n----------------------------------------\n\nTITLE: Converting Celsius to Fahrenheit using NumPy vectorization\nDESCRIPTION: Example showing how NumPy's vectorized operations enable temperature conversion without explicit loops. This demonstrates the clean, mathematical syntax and improved efficiency that ufuncs provide.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Celsius temperatures in a NumPy array\ncelsius_array = np.array([0.0, 10.0, 20.0, 30.0, 100.0])\n\n# NumPy vectorized conversion - NO explicit Python loop!\nfahrenheit_array = celsius_array * (9/5) + 32\n\nprint(fahrenheit_array)\n# Output: [ 32.  50.  68.  86. 212.]\n```\n\n----------------------------------------\n\nTITLE: Implementing Writer Subscription System\nDESCRIPTION: Demonstrates how a Writer agent subscribes to research facts topics, including agent implementation and subscription setup using TypeSubscription.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom autogen_core import TypeSubscription, BaseAgent\n\nclass WriterAgent(BaseAgent):\n    async def on_message_impl(self, message: ResearchFacts, ctx):\n        print(f\"Writer ({self.id}) received facts via subscription: {message.facts}\")\n\nwriter_subscription = TypeSubscription(\n    topic_type=\"research.facts.available\",\n    agent_type=\"writer\"\n)\n\nprint(f\"Writer subscription created for topic type: {writer_subscription.topic_type}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolCollection Class in Python\nDESCRIPTION: This code snippet shows the implementation of the ToolCollection class, which manages a set of tools for AI agents. It includes methods for initialization, parameter formatting, and tool execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/04_tool___toolcollection.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/tool/tool_collection.py\nfrom typing import Any, Dict, List, Tuple\nfrom app.tool.base import BaseTool, ToolResult, ToolFailure\nfrom app.exceptions import ToolError\n\nclass ToolCollection:\n    # ... (Config class) ...\n\n    tools: Tuple[BaseTool, ...] # Holds the tool instances\n    tool_map: Dict[str, BaseTool] # Maps name to tool instance for quick lookup\n\n    def __init__(self, *tools: BaseTool):\n        \"\"\"Initializes with a sequence of tools.\"\"\"\n        self.tools = tools\n        # Create the map for easy lookup by name\n        self.tool_map = {tool.name: tool for tool in tools}\n\n    def to_params(self) -> List[Dict[str, Any]]:\n        \"\"\"Formats tools for the LLM API.\"\"\"\n        # Calls the 'to_param()' method on each tool\n        return [tool.to_param() for tool in self.tools]\n\n    async def execute(\n        self, *, name: str, tool_input: Dict[str, Any] = None\n    ) -> ToolResult:\n        \"\"\"Finds a tool by name and executes it.\"\"\"\n        # 1. Find the tool instance using the name\n        tool = self.tool_map.get(name)\n        if not tool:\n            # Return a standard failure result if tool not found\n            return ToolFailure(error=f\"Tool {name} is invalid\")\n\n        # 2. Execute the tool's specific method\n        try:\n            # The 'tool(**tool_input)' calls the tool instance's __call__ method,\n            # which in BaseTool, calls the tool's 'execute' method.\n            # The ** unpacks the dictionary into keyword arguments.\n            result = await tool(**(tool_input or {}))\n            # Ensure the result is a ToolResult (or subclass)\n            return result if isinstance(result, ToolResult) else ToolResult(output=str(result))\n        except ToolError as e:\n             # Handle errors specific to tools\n            return ToolFailure(error=e.message)\n        except Exception as e:\n             # Handle unexpected errors during execution\n            return ToolFailure(error=f\"Unexpected error executing tool {name}: {e}\")\n\n    # ... other methods like add_tool, __iter__ ...\n```\n\n----------------------------------------\n\nTITLE: Using the Controller to Execute an Action in Python\nDESCRIPTION: A simplified code example showing how the Agent calls the Controller to execute an action. The Controller handles looking up the function in the Registry, validating parameters, and executing the action within the browser context.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/05_action_controller___registry.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- Simplified Agent step calling the Controller ---\n# Assume 'llm_response_model' is the ActionModel object parsed from LLM's JSON\n# Assume 'self.controller' is the Controller instance\n# Assume 'self.browser_context' is the current BrowserContext\n\n# ... inside the Agent's step method ...\n\ntry:\n    # Agent tells the Controller: \"Execute this action!\"\n    action_result: ActionResult = await self.controller.act(\n        action=llm_response_model,      # The LLM's chosen action and parameters\n        browser_context=self.browser_context # The browser tab to act within\n        # Other context like LLMs for extraction might be passed too\n    )\n\n    # Agent receives the result from the Controller\n    print(f\"Action executed. Result: {action_result.extracted_content}\")\n    if action_result.is_done:\n        print(\"Task marked as done by the action!\")\n    if action_result.error:\n        print(f\"Action encountered an error: {action_result.error}\")\n\n    # Agent records this result in the history ([Message Manager](06_message_manager.md))\n    # ...\n\nexcept Exception as e:\n    print(f\"Failed to execute action: {e}\")\n    # Handle the error\n```\n\n----------------------------------------\n\nTITLE: Resource Management with Context Callbacks\nDESCRIPTION: Shows how to use context.call_on_close() for automatic resource cleanup when a command completes execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/05_context.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# resource_management.py\nimport click\n\nclass MockResource:\n  def __init__(self, name):\n    self.name = name\n    click.echo(f\"Resource '{self.name}' opened.\")\n  def close(self):\n    click.echo(f\"Resource '{self.name}' closed.\")\n\n@click.command()\n@click.pass_context\ndef process(ctx):\n  \"\"\"Opens and closes a mock resource.\"\"\"\n  res = MockResource(\"DataFile\")\n  # Register the close method to be called when the context ends\n  ctx.call_on_close(res.close)\n  click.echo(\"Processing with resource...\")\n  # Function ends, context tears down, call_on_close triggers\n\nif __name__ == '__main__':\n  process()\n```\n\n----------------------------------------\n\nTITLE: Creating a CodeAgent with Default PythonExecutor in Python\nDESCRIPTION: This snippet demonstrates how to create a CodeAgent with the default LocalPythonExecutor. It imports necessary modules, sets up a search tool, initializes a language model, and creates the CodeAgent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/06_pythonexecutor.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom smolagents import CodeAgent\nfrom smolagents.models import LiteLLMModel\nfrom smolagents.tools import DuckDuckGoSearchTool\n\nsearch_tool = DuckDuckGoSearchTool()\n\nllm = LiteLLMModel(model_id=\"gpt-4-turbo\")\n\nagent = CodeAgent(\n    model=llm,\n    tools=[search_tool],\n    # By default, executor_type=\"local\" is used\n)\n\nprint(\"CodeAgent created with an internal PythonExecutor.\")\n\n# Now, when you run the agent:\n# task = \"Calculate the square root of 1764 and tell me the result.\"\n# result = agent.run(task)\n# print(f\"Result: {result}\")\n```\n\n----------------------------------------\n\nTITLE: Flowchart for 3D Array\nDESCRIPTION: This Mermaid diagram visualizes a 3-dimensional array structure, showing how 2D layers are stacked to form a cube-like structure. It illustrates connections within each 2D layer and between corresponding elements across different layers.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_10\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    subgraph Layer 1\n    L1R1C1[ L1R1C1 ] --> L1R1C2[ L1R1C2 ]\n    L1R2C1[ L1R2C1 ] --> L1R2C2[ L1R2C2 ]\n    L1R1C1 -.-> L1R2C1\n    L1R1C2 -.-> L1R2C2\n    end\n\n    subgraph Layer 2\n    L2R1C1[ L2R1C1 ] --> L2R1C2[ L2R1C2 ]\n    L2R2C1[ L2R2C1 ] --> L2R2C2[ L2R2C2 ]\n    L2R1C1 -.-> L2R2C1\n    L2R1C2 -.-> L2R2C2\n    end\n\n    L1R1C1 --- L2R1C1\n    L1R1C2 --- L2R1C2\n    L1R2C1 --- L2R2C1\n    L1R2C2 --- L2R2C2\n```\n\n----------------------------------------\n\nTITLE: Accessing Blueprint Static Files in Templates\nDESCRIPTION: Shows how to reference static files from within blueprint templates using url_for helper function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<!-- Inside an admin blueprint template -->\n<link rel=\"stylesheet\" href=\"{{ url_for('admin.static', filename='style.css') }}\">\n<!-- Generates a URL like: /admin-static/style.css -->\n```\n\n----------------------------------------\n\nTITLE: Simulating Agent's Model Call in Python\nDESCRIPTION: This simplified snippet illustrates the internal mechanism by which a `MultiStepAgent` uses its configured `Model Interface`. The agent constructs a list of messages representing the conversation history (using `ChatMessage` or dictionaries with `role` and `content`). It then invokes the model interface by calling `agent.model(messages_for_llm)`, where `agent.model` refers to the initialized interface (e.g., the `llm` instance). The interface handles the actual LLM communication and returns a standardized `ChatMessage` object containing the LLM's response, potentially including structured data for tool usage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- Simplified view of what happens inside the agent ---\nfrom smolagents.models import ChatMessage, MessageRole\n\n# Agent prepares messages (example)\nmessages_for_llm = [\n    {\"role\": MessageRole.SYSTEM, \"content\": \"You are a helpful agent. Decide the next step.\"},\n    {\"role\": MessageRole.USER, \"content\": \"Task: What is the capital of France?\"},\n    # ... potentially previous steps ...\n]\n\n# Agent calls the model using the standard interface\n# This is like pressing the main button on the universal remote\nprint(\"Agent asking model: What should I do next?\")\nresponse: ChatMessage = agent.model(messages_for_llm) # agent.model refers to our 'llm' instance\n\n# Agent gets a standard response back\nprint(f\"Model suggested action (simplified): {response.content}\")\n# Example Output (will vary):\n# Agent asking model: What should I do next?\n# Model suggested action (simplified): Thought: I need to find the capital of France. I can use the search tool.\n# Action:\n# ```json\n# {\n#  \"action\": \"search\",\n#  \"action_input\": \"Capital of France\"\n# }\n# ```\n```\n\n----------------------------------------\n\nTITLE: Accessing Incoming Request Data with `request` Global\nDESCRIPTION: Demonstrates using the `request` context global within a Flask route function (`index`) to access details of the incoming HTTP request without needing it passed as an argument. Specifically, it retrieves the 'User-Agent' header and the HTTP method ('GET', 'POST', etc.) from the `request` object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\n\n@app.route('/')\ndef index():\n  user_agent = request.headers.get('User-Agent', 'Unknown')\n  method = request.method\n  return f'Welcome! Method: {method}, Browser: {user_agent}'\n```\n\n----------------------------------------\n\nTITLE: Implementing Task Delay and Apply Async in Python\nDESCRIPTION: This code snippet shows the implementation of the delay() and apply_async() methods in the Celery Task class. It demonstrates how tasks are sent for execution, either locally or via the message broker.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/03_task.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from celery/app/task.py\nclass Task:\n    # ...\n    def delay(self, *args, **kwargs):\n        \"\"\"Shortcut for apply_async(args, kwargs)\"\"\"\n        return self.apply_async(args, kwargs)\n\n    def apply_async(self, args=None, kwargs=None, ..., **options):\n        # ... argument checking, option processing ...\n\n        # Get the app associated with this task instance\n        app = self._get_app()\n\n        # If always_eager is set, run locally instead of sending\n        if app.conf.task_always_eager:\n            return self.apply(args, kwargs, ...) # Runs inline\n\n        # The main path: tell the app to send the task message\n        return app.send_task(\n            self.name, args, kwargs, task_type=self,\n            **options # Includes things like countdown, eta, queue etc.\n        )\n```\n\n----------------------------------------\n\nTITLE: Sending SSE Events from A2A Server (TypeScript/Express)\nDESCRIPTION: Conceptual TypeScript code demonstrating how an A2A server using Express.js handles streaming responses for the `tasks/sendSubscribe` method. It sets appropriate HTTP headers for SSE (`Content-Type: text/event-stream`), iterates through values yielded by an async task handler generator, formats each value as a JSON-RPC response containing an A2A event payload, writes it to the response stream in SSE format (`data: <json string>\\n\\n`), and finally closes the stream upon completion or a final event.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/07_streaming_communication__sse_.md#2025-04-22_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n// File: samples/js/src/server/server.ts (Simplified Snippet inside handleTaskSendSubscribe)\n\n// --- Setup SSE ---\nres.writeHead(200, {\n  \"Content-Type\": \"text/event-stream\", // Tell client it's SSE\n  \"Cache-Control\": \"no-cache\",\n  \"Connection\": \"keep-alive\",\n});\n\n// Function to send a single SSE event\nconst sendEvent = (eventData: schema.JSONRPCResponse) => {\n  // Format: \"data: <json string>\\n\\n\"\n  res.write(`data: ${JSON.stringify(eventData)}\\n\\n`);\n};\n\n// --- Process generator yields ---\nfor await (const yieldValue of generator) {\n  // ... (Apply update, save to store etc. - see Chapter 6) ...\n\n  // Create the JSON payload (TaskStatusUpdateEvent or TaskArtifactUpdateEvent)\n  const eventPayload = createEventFromYield(taskId, yieldValue, isFinal);\n\n  // Wrap payload in a JSON-RPC Response structure\n  const rpcResponse = createSuccessResponse(req.id, eventPayload);\n\n  // Send the formatted event down the stream\n  sendEvent(rpcResponse);\n\n  if (isFinal) break; // Stop if handler yielded a final state\n}\n\n// --- End Stream ---\nif (!res.writableEnded) {\n  res.end(); // Close the connection\n}\n```\n\n----------------------------------------\n\nTITLE: DSPy Evaluate Class Implementation\nDESCRIPTION: Simplified implementation of the DSPy Evaluate class showing initialization, evaluation process, parallel execution handling, and result aggregation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Evaluate:\n    def __init__(self, devset, metric, num_threads=1, ..., failure_score=0.0):\n        self.devset = devset\n        self.metric = metric\n        self.num_threads = num_threads\n        self.display_progress = ...\n        self.display_table = ...\n        # ... store other flags ...\n        self.failure_score = failure_score\n\n    def __call__(self, program, metric=None, devset=None, ...):\n        metric = metric if metric is not None else self.metric\n        devset = devset if devset is not None else self.devset\n        num_threads = ...\n\n        executor = ParallelExecutor(num_threads=num_threads, ...)\n\n        def process_item(example):\n            try:\n                prediction = program(**example.inputs())\n                score = metric(example, prediction)\n                return prediction, score\n            except Exception as e:\n                print(f\"Error processing example: {e}\")\n                return None\n\n        raw_results = executor.execute(process_item, devset)\n\n        results = []\n        for i, r in enumerate(raw_results):\n            example = devset[i]\n            if r is None:\n                prediction, score = dspy.Prediction(), self.failure_score\n            else:\n                prediction, score = r\n            results.append((example, prediction, score))\n\n        total_score = sum(score for *_, score in results)\n        num_examples = len(devset)\n        average_score = round(100 * total_score / num_examples, 2) if num_examples > 0 else 0\n\n        if self.display_table:\n             self._display_result_table(...)\n\n        return average_score\n```\n\n----------------------------------------\n\nTITLE: Running MCPServer with stdio Transport in OpenManus\nDESCRIPTION: Command to start the MCP server using the stdio transport method. This launches a server that registers and provides standard tools like Bash, Browser, and Editor to connected agents.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Make sure you are in the root directory of the OpenManus project\n# Use python to run the server module\npython -m app.mcp.server --transport stdio\n```\n\n----------------------------------------\n\nTITLE: Visualizing MultiStepAgent Run Sequence with Mermaid\nDESCRIPTION: A sequence diagram illustrating the interaction flow between the User, MultiStepAgent (MSA), LLM Brain (Model), Tools, and Memory during the execution of an agent task. It visualizes the Think-Act-Observe cycle, showing task reception, history retrieval, model calls for actions, tool execution, observation storage, and final answer generation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MSA as MultiStepAgent\n    participant Model as LLM Brain\n    participant Tools\n    participant Memory\n\n    User->>MSA: run(\"Task: Capital & Weather?\")\n    MSA->>Memory: Store Task\n    loop Think-Act-Observe Cycle\n        MSA->>Memory: Get history (Task)\n        MSA->>Model: What's next? (based on Task)\n        Model-->>MSA: Think: Need capital. Act: search(\"Capital of France\")\n        MSA->>Memory: Store Thought & Action Plan\n        MSA->>Tools: Execute search(\"Capital of France\")\n        Tools-->>MSA: Observation: \"Paris\"\n        MSA->>Memory: Store Observation (\"Paris\")\n\n        MSA->>Memory: Get history (Task, search result \"Paris\")\n        MSA->>Model: What's next? (based on Task & \"Paris\")\n        Model-->>MSA: Think: Need weather for Paris. Act: weather(\"Paris\")\n        MSA->>Memory: Store Thought & Action Plan\n        MSA->>Tools: Execute weather(\"Paris\")\n        Tools-->>MSA: Observation: \"Sunny, 25°C\"\n        MSA->>Memory: Store Observation (\"Sunny, 25°C\")\n\n        MSA->>Memory: Get history (Task, \"Paris\", \"Sunny, 25°C\")\n        MSA->>Model: What's next? (based on Task & results)\n        Model-->>MSA: Think: Have all info. Act: final_answer(\"Capital: Paris, Weather: Sunny, 25°C\")\n        MSA->>Memory: Store Thought & Action Plan (Final Answer)\n        MSA-->>User: Return \"Capital: Paris, Weather: Sunny, 25°C\"\n        Note right of MSA: Loop completes when final answer is ready\n    end\n```\n\n----------------------------------------\n\nTITLE: Rendering Command Approval Prompts with Selection in Ink in TypeScript\nDESCRIPTION: This snippet defines a TypeScript React component for reviewing and approving commands within a terminal chat UI, using Ink's layout and selection capabilities. The component presents a confirmation prompt, allows the user to select an approval option (such as Yes, No, Edit), and handles keyboard shortcuts and state switching between selection and text input modes. It uses the Select and TextInput custom/vendor Ink components, and manages interaction through callbacks for decision communication to the outer chat handler. Requires Ink, React, and relevant selection/input dependencies; receives props for the prompt and handling user decisions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/components/chat/terminal-chat-command-review.tsx (Simplified)\n\n// ... imports ...\n// @ts-expect-error - Using a vendor component for selection\nimport { Select } from \"../vendor/ink-select/select\";\nimport TextInput from \"../vendor/ink-text-input\"; // For editing feedback\nimport { Box, Text, useInput } from \"ink\";\nimport React from \"react\";\n\nexport function TerminalChatCommandReview({\n  confirmationPrompt, // The command display element\n  onReviewCommand, // Function to call with the decision\n}: { /* ... */ }): React.ReactElement {\n  const [mode, setMode] = React.useState<\"select\" | \"input\">(\"select\"); // Select Yes/No or type feedback\n\n  // Options for the selection list\n  const approvalOptions = [\n    { label: \"Yes (y)\", value: ReviewDecision.YES },\n    // ... other options like Always, Edit, No ...\n  ];\n\n  useInput((input, key) => { /* Handle shortcuts like 'y', 'n', 'e', Esc */ });\n\n  return (\n    <Box flexDirection=\"column\" borderStyle=\"round\" marginTop={1}>\n      {/* Display the command that needs review */}\n      {confirmationPrompt}\n\n      {mode === \"select\" ? (\n        <>\n          <Text>Allow command?</Text>\n          <Select // Ink component for selection lists\n            options={approvalOptions}\n            onChange={(value) => { /* ... call onReviewCommand or setMode('input') ... */ }}\n          />\n        </>\n      ) : (\n        /* UI for typing feedback (TextInput) */\n        // ...\n      )}\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ProgressNotification with Pydantic in Python\nDESCRIPTION: Example demonstrating how to create a ProgressNotification object using Pydantic models to structure progress updates. Shows how progress information is formatted and sent as notifications to clients.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/07_mcp_protocol_types.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simplified example of creating a ProgressNotification\n# (Context object does this for you!)\nfrom mcp.types import ProgressNotification, ProgressNotificationParams\n\n# Context gets these values\ntoken_from_request = \"client_progress_token_123\"\ncurrent_step = 2\ntotal_steps = 5\nprogress_value = current_step / total_steps # 0.4\n\n# Context creates the notification object\nnotification_data = ProgressNotification(\n    method=\"notifications/progress\", # Standard MCP method name\n    params=ProgressNotificationParams(\n        progressToken=token_from_request,\n        progress=progress_value,\n        total=float(total_steps)\n    )\n)\n\n# This notification_data is then packaged into a\n# JSONRPCNotification message and sent to the client.\nprint(notification_data.model_dump_json(indent=2))\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"method\": \"notifications/progress\",\n  \"params\": {\n    \"_meta\": null,\n    \"progressToken\": \"client_progress_token_123\",\n    \"progress\": 0.4,\n    \"total\": 5.0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Events in Python\nDESCRIPTION: Python configuration file showing how to enable various types of Celery events through configuration settings\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# celeryconfig.py (example)\nbroker_url = 'redis://localhost:6379/0'\nresult_backend = 'redis://localhost:6379/1'\nimports = ('tasks',)\n\n# Enable sending task-related events\ntask_send_sent_event = False # Optional: If you want task-sent events too\nworker_send_task_events = True\nworker_send_worker_events = True # Usually True by default\n```\n\n----------------------------------------\n\nTITLE: Processing and Executing Agent Actions in Python\nDESCRIPTION: Implementation of the action execution flow in an agent system. The code parses LLM responses, executes actions through tool calls, records observations, and handles final answers. It demonstrates the core logic for processing agent actions and maintaining memory state.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/04_agentmemory.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntool_name, arguments = self._parse_action(llm_response) # Simplified\nmemory_step.tool_calls = [ToolCall(name=tool_name, arguments=arguments, id=...)]\n\n# === ACT & OBSERVE ===\n# 4. Execute the action (tool call or code)\nobservation = self._execute_action(tool_name, arguments) # Simplified\n\n# 5. Record observation\nmemory_step.observations = str(observation)\n\n# 6. Check if it's the final answer\nif tool_name == \"final_answer\":\n     return observation # Return the final answer to stop the loop\nelse:\n     return None # Continue to the next step\n\n# ... other methods like _create_action_step, _finalize_step ...\n```\n\n----------------------------------------\n\nTITLE: Representing LLM Tool Call Suggestion in JSON\nDESCRIPTION: This JSON snippet demonstrates an LLM's output suggesting a tool call within the agent's think phase. It specifies the 'thought' process, the 'action' to invoke ('greet_person'), and the structured input arguments needed by the tool instance. Intended as the agent's prompt/response format with the model, it relies on the agent's ability to parse and interpret such outputs. Inputs: LLM response content. Outputs: Parsed action instructions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/03_tool.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"thought\": \"The user wants me to greet Bob. I should use the 'greet_person' tool.\",\n  \"action\": \"greet_person\",\n  \"action_input\": {\"name\": \"Bob\"}\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Schema with Pydantic in OpenManus\nDESCRIPTION: This snippet defines the Message schema used for representing chat messages in the conversation. It shows how Pydantic enforces data validation with required fields like 'role' (which must be one of the predefined types) and optional fields like 'content'.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Simplified Pydantic model from app/schema.py\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Literal\n\n# Define allowed roles\nROLE_TYPE = Literal[\"system\", \"user\", \"assistant\", \"tool\"]\n\nclass Message(BaseModel):\n    role: ROLE_TYPE = Field(...) # '...' means this field is required\n    content: Optional[str] = Field(default=None) # Optional text content\n    # ... other optional fields like tool_calls, name, tool_call_id ...\n\n    # Class methods like user_message, assistant_message are here...\n```\n\n----------------------------------------\n\nTITLE: Defining a Content Filtering Framework Using Abstract Base Classes in Python\nDESCRIPTION: This snippet defines an abstract base class, `RelevantContentFilter`, which specifies a standard interface for filtering relevant HTML fragments from cleaned HTML input. It introduces a required `filter_content` method for implementations and demonstrates the use of Python's abstract base class (ABC) mechanism. The class accommodates extensible initialization with a user query and establishes placeholders for common setup and helper methods. Dependencies include `ABC`, `abstractmethod`, and appropriate typing definitions (such as `List`). The expected input is cleaned HTML as a string, and the output is a list of relevant HTML fragments; implementation must handle candidate extraction and strategy-specific selection.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nclass RelevantContentFilter(ABC):\\n    \\\"\\\"\\\"Abstract base class for content filtering strategies\\\"\\\"\\\"\\n    def __init__(self, user_query: str = None, ...):\\n        self.user_query = user_query\\n        # ... common setup ...\\n\\n    @abstractmethod\\n    def filter_content(self, html: str) -> List[str]:\\n        \\\"\\\"\\\"\\n        Takes cleaned HTML, returns a list of HTML fragments\\n        deemed relevant by the specific strategy.\\n        \\\"\\\"\\\"\\n        pass\\n    # ... common helper methods like extract_page_query, is_excluded ...\n```\n\n----------------------------------------\n\nTITLE: BaseAgent Run Method Sequence Diagram in Mermaid\nDESCRIPTION: This Mermaid sequence diagram visualizes the execution flow of the BaseAgent.run() method. It shows the interaction between the user, a specific agent subclass, the BaseAgent.run() method, and the subclass-specific step() method during the agent's execution cycle.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/03_baseagent.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MyAgent as MySpecificAgent (e.g., EchoAgent)\n    participant BaseRun as BaseAgent.run()\n    participant MyStep as MySpecificAgent.step()\n\n    User->>+MyAgent: Calls run(\"Initial Request\")\n    MyAgent->>+BaseRun: run(\"Initial Request\")\n    BaseRun->>BaseRun: Check state (must be IDLE)\n    BaseRun->>MyAgent: Set state = RUNNING\n    BaseRun->>MyAgent: Add \"Initial Request\" to memory\n    Note over BaseRun, MyStep: Loop starts (while step < max_steps AND state == RUNNING)\n    loop Execution Loop\n        BaseRun->>BaseRun: Increment current_step\n        BaseRun->>+MyStep: Calls step()\n        MyStep->>MyStep: Executes specific logic (e.g., reads memory, calls LLM, adds response to memory)\n        MyStep->>MyAgent: Maybe sets state = FINISHED\n        MyStep-->>-BaseRun: Returns step_result (string)\n        BaseRun->>BaseRun: Record step_result\n        BaseRun->>BaseRun: Check loop condition (step < max_steps AND state == RUNNING?)\n    end\n    Note over BaseRun: Loop ends\n    BaseRun->>MyAgent: Set state = IDLE (or keep ERROR)\n    BaseRun-->>-MyAgent: Returns combined results\n    MyAgent-->>-User: Returns final result string\n```\n\n----------------------------------------\n\nTITLE: Formatting Tool Parameters for LLM in Python\nDESCRIPTION: This snippet demonstrates how to get the parameters for an LLM from a ToolCollection and print them as JSON. It shows the use of the to_params() method and JSON formatting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/04_tool___toolcollection.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Get the parameters needed for the LLM\ntool_params_for_llm = my_toolbox.to_params()\nprint(f\"\\nParameters for LLM (showing first tool):\")\nimport json\nprint(json.dumps(tool_params_for_llm[0], indent=2))\n```\n\n----------------------------------------\n\nTITLE: NumPy Type Hierarchy Visualization with Mermaid\nDESCRIPTION: A mermaid diagram showing the hierarchical relationship between NumPy's scalar types, from abstract base classes to concrete implementations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    N[np.number] --> I[np.integer]\n    N --> IX[np.inexact]\n\n    I --> SI[np.signedinteger]\n    I --> UI[np.unsignedinteger]\n\n    IX --> F[np.floating]\n    IX --> C[np.complexfloating]\n\n    SI --> i8[np.int8]\n    SI --> i16[np.int16]\n    SI --> i32[np.int32]\n    SI --> i64[np.int64]\n    SI --> ip[np.intp]\n    SI --> dots_i[...]\n\n    UI --> u8[np.uint8]\n    UI --> u16[np.uint16]\n    UI --> u32[np.uint32]\n    UI --> u64[np.uint64]\n    UI --> up[np.uintp]\n    UI --> dots_u[...]\n\n    F --> f16[np.float16]\n    F --> f32[np.float32]\n    F --> f64[np.float64]\n    F --> fld[np.longdouble]\n    F --> dots_f[...]\n\n    C --> c64[np.complex64]\n    C --> c128[np.complex128]\n    C --> cld[np.clongdouble]\n    C --> dots_c[...]\n\n    %% Styling for clarity\n    classDef abstract fill:#f9f,stroke:#333,stroke-width:2px;\n    class N,I,IX,SI,UI,F,C abstract;\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Chain Execution with Mermaid\nDESCRIPTION: A sequence diagram illustrating the message flow and interactions between components (Client, Canvas, Broker, Worker) when executing a simple two-task Celery chain (`add.s(2, 2) | add.s(4)`). It shows the sending of the first task with a link to the second, execution by a worker, sending of the second task using the result of the first, and final execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/08_canvas__signatures___primitives_.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Your Code\n    participant Canvas as workflow = chain(...)\n    participant Broker as Message Broker\n    participant Worker as Celery Worker\n\n    Client->>Canvas: workflow.apply_async()\n    Note over Canvas: Prepare msg for add(2, 2) with link=add.s(4)\n    Canvas->>Broker: Send Task 1 msg ('add', (2, 2), link=add.s(4), id=T1)\n    Broker-->>Canvas: Ack\n    Canvas-->>Client: Return AsyncResult(id=T2) # ID of the *last* task in chain\n\n    Worker->>Broker: Fetch msg (T1)\n    Broker-->>Worker: Deliver Task 1 msg\n    Worker->>Worker: Execute add(2, 2) -> returns 4\n    Note over Worker: Store result 4 for T1 in Backend\n    Worker->>Worker: Check 'link' option -> add.s(4)\n    Note over Worker: Prepare msg for add(4, 4) using result 4 + linked args\n    Worker->>Broker: Send Task 2 msg ('add', (4, 4), id=T2)\n    Broker-->>Worker: Ack\n    Worker->>Broker: Ack Task 1 msg complete\n\n    Worker->>Broker: Fetch msg (T2)\n    Broker-->>Worker: Deliver Task 2 msg\n    Worker->>Worker: Execute add(4, 4) -> returns 8\n    Note over Worker: Store result 8 for T2 in Backend\n    Worker->>Broker: Ack Task 2 msg complete\n```\n\n----------------------------------------\n\nTITLE: Utilizing AgentMemory within MultiStepAgent in Python\nDESCRIPTION: Simplified Python code from `agents.py` demonstrating how `MultiStepAgent` interacts with `AgentMemory`. The agent initializes an `AgentMemory` instance. In the `run` method, it potentially resets memory and adds the initial `TaskStep`. The core `_run` loop creates an `ActionStep` placeholder, calls `_execute_step` (which uses `write_memory_to_messages` to get history and then calls the LLM/tools), and finally appends the completed `ActionStep` to `memory.steps`. The `write_memory_to_messages` method iterates through memory steps, calling their `to_messages` methods to format the history for the LLM. Dependencies include `AgentMemory`, `TaskStep`, `ActionStep`, `ToolCall`, and `typing` utilities.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/04_agentmemory.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified MultiStepAgent interactions) ---\nfrom .memory import AgentMemory, TaskStep, ActionStep, ToolCall # Import memory components\nfrom typing import Optional, List, Dict, Any, Union, Generator # Added relevant types\n# Assume AgentError, FinalAnswerStep, LogLevel are defined elsewhere\nclass AgentError(Exception): pass\n@dataclass\nclass FinalAnswerStep: final_answer: Any\nclass LogLevel: INFO = 1\n\nclass MultiStepAgent:\n    def __init__(self, ..., memory: Optional[AgentMemory] = None):\n        # ... setup model, tools ...\n        self.system_prompt = self.initialize_system_prompt() # Define system prompt\n        # Create the memory instance\n        self.memory = memory if memory is not None else AgentMemory(self.system_prompt)\n        # ... setup logger, monitor ...\n        self.step_number = 1 # Initialize step number\n        self.logger = MagicMock() # Mock logger for example\n        self.model = MagicMock() # Mock model for example\n        self.task = \"\" # Initialize task\n\n    def initialize_system_prompt(self): # Example implementation\n        return \"You are a helpful assistant.\"\n\n    def run(self, task: str, reset: bool = True, ...):\n        # ... setup ...\n        self.task = task\n        if reset: # Option to clear memory before a new run\n            self.memory.reset()\n            self.step_number = 1\n\n        # Record the initial task in memory\n        self.memory.steps.append(TaskStep(task=self.task))\n\n        # Start the internal execution loop (_run)\n        # ... calls _run ...\n        final_result = None\n        for step_result in self._run(task, max_steps=10): # Example max_steps\n             if isinstance(step_result, FinalAnswerStep):\n                 final_result = step_result.final_answer\n        # ... get result from _run ...\n        return final_result\n\n    def _run(self, task: str, max_steps: int, ...) -> Generator:\n        # ... loop initialization ...\n        final_answer = None\n        while final_answer is None and self.step_number <= max_steps:\n            # ... (handle planning steps if enabled) ...\n\n            # Create a placeholder for the current step's data\n            action_step = self._create_action_step()\n\n            try:\n                # === Execute one step (Think -> Act -> Observe) ===\n                # This method internally calls write_memory_to_messages,\n                # calls the model, executes the tool, and populates\n                # the 'action_step' object with results.\n                final_answer = self._execute_step(task, action_step)\n\n            except AgentError as e:\n                # Record errors in the memory step\n                action_step.error = e\n            finally:\n                # Finalize timing etc. for the step\n                self._finalize_step(action_step)\n                # === Store the completed step in memory ===\n                self.memory.steps.append(action_step)\n                # ... yield step details ...\n                yield action_step # Yield the step itself for potential monitoring\n                self.step_number += 1\n        # ... handle finish ...\n        if final_answer is not None:\n            yield FinalAnswerStep(final_answer)\n        else:\n             # Handle max steps reached or other termination\n             yield FinalAnswerStep(\"Max steps reached or no answer found.\")\n\n    def _create_action_step(self): # Example implementation\n        return ActionStep(step_number=self.step_number)\n\n    def _finalize_step(self, action_step: ActionStep, ...): # Example implementation\n        # Add timing, etc.\n        pass\n\n    def write_memory_to_messages(self, summary_mode: Optional[bool] = False) -> List[Dict[str, Any]]:\n        \"\"\"\n        Reads history from memory and formats it for the LLM.\n        \"\"\"\n        messages = self.memory.system_prompt.to_messages(summary_mode=summary_mode)\n        # Go through each step recorded in memory\n        for memory_step in self.memory.steps:\n            # Ask each step to format itself into messages\n            messages.extend(memory_step.to_messages(summary_mode=summary_mode))\n        return messages\n\n    def _execute_step(self, task: str, memory_step: ActionStep) -> Union[None, Any]:\n        self.logger.log_rule(f\"Step {self.step_number}\", level=LogLevel.INFO)\n        # === THINK ===\n        # 1. Get history from memory\n        messages_for_llm = self.write_memory_to_messages()\n        # memory_step.model_input_messages = messages_for_llm # Record input to LLM - Field commented out in original snippet\n\n        # 2. Call the LLM brain\n        llm_response = self.model(messages_for_llm) # Call Model Interface (simplified)\n        memory_step.model_output = llm_response # Record LLM response (using model_output instead of model_output_message)\n\n        # 3. Parse LLM response for action\n        # (Specific parsing logic depends on AgentType - ToolCallingAgent, CodeAgent)\n        # ... parsing logic ...\n        # Example: Assume parsing yields tool calls\n        # tool_calls = parse_tool_calls(llm_response)\n        # memory_step.tool_calls = tool_calls\n\n        # === ACT ===\n        # ... execute tool calls ...\n        # observations = execute_tools(tool_calls)\n        # memory_step.observations = observations\n\n        # === OBSERVE ===\n        # Determine if this is the final answer\n        # final_answer = check_if_final(observations or llm_response)\n        # return final_answer\n        return None # Placeholder\n\n# Mock class for demonstration purposes\nfrom dataclasses import dataclass\nfrom unittest.mock import MagicMock \n\n```\n\n----------------------------------------\n\nTITLE: Implementing the Agent Loop Orchestration Logic in TypeScript\nDESCRIPTION: This TypeScript code snippet presents a simplified structure of the `AgentLoop` class, responsible for orchestrating interactions between the UI, an AI model (OpenAI), and command execution. It shows the constructor initializing dependencies like the OpenAI client and UI callbacks (`onItem`, `onLoading`, `getCommandConfirmation`), the main `run` method handling the conversation loop with OpenAI via streaming, and the `handleFunctionCall` method processing tool requests like shell commands, including approval checks and result formatting. Dependencies include the `OpenAI` client library and internal modules like `handleExecCommand`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/03_agent_loop.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n// File: codex-cli/src/utils/agent/agent-loop.ts (Simplified)\nimport OpenAI from \"openai\";\n// ... other imports: types for config, responses, approval ...\nimport { handleExecCommand } from \"./handle-exec-command\"; // For tool calls\n\nexport class AgentLoop {\n  private oai: OpenAI; // The OpenAI client instance\n  private model: string;\n  private config: AppConfig;\n  private approvalPolicy: ApprovalPolicy;\n  // Callbacks provided by the UI:\n  private onItem: (item: ResponseItem) => void;\n  private onLoading: (loading: boolean) => void;\n  private getCommandConfirmation: (/*...*/) => Promise<CommandConfirmation>;\n  // ... other state like current stream, cancellation flags ...\n\n  constructor({ model, config, approvalPolicy, onItem, onLoading, getCommandConfirmation, /*...*/ }: AgentLoopParams) {\n    this.model = model;\n    this.config = config;\n    this.approvalPolicy = approvalPolicy;\n    this.onItem = onItem;\n    this.onLoading = onLoading;\n    this.getCommandConfirmation = getCommandConfirmation;\n    this.oai = new OpenAI({ /* ... API key, base URL ... */ });\n    // ... initialize other state ...\n  }\n\n  // The main method called by the UI\n  public async run(input: Array<ResponseInputItem>, previousResponseId: string = \"\"): Promise<void> {\n    this.onLoading(true); // Signal start\n    let turnInput = input; // Input for this step of the loop\n    let lastResponseId = previousResponseId;\n\n    try {\n      // Keep looping as long as there's input (initially user msg, later tool results)\n      while (turnInput.length > 0) {\n        // 1. Send current input history to OpenAI API\n        const stream = await this.oai.responses.create({\n          model: this.model,\n          input: turnInput, // Includes user message or tool results\n          previous_response_id: lastResponseId || undefined,\n          stream: true,\n          // ... other parameters like instructions, tools ...\n        });\n\n        turnInput = []; // Clear input for the next loop iteration\n\n        // 2. Process the stream of events from OpenAI\n        for await (const event of stream) {\n          if (event.type === \"response.output_item.done\") {\n            const item = event.item; // Could be text, function_call, etc.\n            this.onItem(item as ResponseItem); // Send item to UI to display\n          }\n          if (event.type === \"response.completed\") {\n            lastResponseId = event.response.id; // Remember the ID for the next call\n            // Check the final output for tool calls\n            for (const item of event.response.output) {\n              if (item.type === \"function_call\") {\n                 // Handle the tool call (ask for approval, execute)\n                 // This might add a 'function_call_output' to `turnInput`\n                 const toolResults = await this.handleFunctionCall(item);\n                 turnInput.push(...toolResults);\n              }\n            }\n          }\n          // ... handle other event types ...\n        } // End stream processing\n      } // End while loop (no more input for this turn)\n    } catch (error) {\n      // ... Handle errors (network issues, API errors etc.) ...\n      this.onItem(/* Create system error message */);\n    } finally {\n      this.onLoading(false); // Signal end\n    }\n  }\n\n  // Helper to handle tool/function calls\n  private async handleFunctionCall(item: ResponseFunctionToolCall): Promise<Array<ResponseInputItem>> {\n    // ... Parse arguments from 'item' ...\n    const args = /* ... parse item.arguments ... */;\n    let outputText = \"Error: Unknown function\";\n    let metadata = {};\n\n    if (item.name === \"shell\") { // Example: handle shell commands\n       // This uses the approval policy and getCommandConfirmation callback!\n       const result = await handleExecCommand(\n         args,\n         this.config,\n         this.approvalPolicy,\n         this.getCommandConfirmation,\n         /* ... cancellation signal ... */\n       );\n       outputText = result.outputText;\n       metadata = result.metadata;\n    }\n    // ... handle other function names ...\n\n    // Format the result to send back to OpenAI in the next turn\n    const outputItem: ResponseInputItem.FunctionCallOutput = {\n      type: \"function_call_output\",\n      call_id: item.call_id, // Link to the specific function call\n      output: JSON.stringify({ output: outputText, metadata }),\n    };\n    return [outputItem]; // This goes into `turnInput` for the next loop\n  }\n\n  // ... other methods like cancel(), terminate() ...\n}\n```\n```\n\n----------------------------------------\n\nTITLE: MCP Prompt Request/Response Example in JSON\nDESCRIPTION: Shows the JSON structure for client-server communication when requesting and receiving a prompt template render.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/05_fastmcp_prompts___prompt____promptmanager__.md#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"method\": \"getPrompt\",\n  \"params\": {\n    \"name\": \"summarize_text\",\n    \"arguments\": {\n      \"text_to_summarize\": \"The quick brown fox jumps over the lazy dog.\"\n    }\n  }\n}\n\n{\n  \"result\": {\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": {\n          \"type\": \"text\",\n          \"text\": \"Please summarize the following text concisely:\\n\\nThe quick brown fox jumps over the lazy dog.\"\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the FastAPI Documentation Generation Flow with Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the interaction flow when accessing FastAPI's automatically generated documentation at the `/docs` endpoint. It shows the browser requesting the HTML page, the embedded Swagger UI JavaScript subsequently fetching the `/openapi.json` schema from the FastAPI backend, and FastAPI generating this schema based on route inspection before returning it to the browser, which then renders the interactive documentation interface.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/04_openapi___automatic_docs.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Browser\n    participant FastAPIApp as FastAPI App (Python Backend)\n    participant RouteInspector as Route Inspector (Internal)\n    participant OpenAPIGenerator as OpenAPI Generator (Internal - get_openapi)\n    participant SwaggerUIHandler as /docs Handler (Internal)\n    participant OpenAPISchemaHandler as /openapi.json Handler (Internal)\n\n    Note over FastAPIApp: App Starts & Inspects Routes\n    FastAPIApp->>RouteInspector: Analyze @app.post(\"/items/\"), @app.get(\"/items/{id}\") etc.\n    RouteInspector-->>FastAPIApp: Extracted Route Metadata\n\n    Note over Browser: User navigates to /docs\n    Browser->>+FastAPIApp: GET /docs\n    FastAPIApp->>SwaggerUIHandler: Process request for /docs\n    SwaggerUIHandler-->>FastAPIApp: Generate HTML page loading Swagger UI JS/CSS (points JS to /openapi.json)\n    FastAPIApp-->>-Browser: Send Swagger UI HTML page\n\n    Note over Browser: Browser renders HTML, Swagger UI JS executes\n    Browser->>+FastAPIApp: GET /openapi.json (requested by Swagger UI JS)\n    FastAPIApp->>OpenAPISchemaHandler: Process request for /openapi.json\n    OpenAPISchemaHandler->>OpenAPIGenerator: Use stored route metadata to build OpenAPI schema dict\n    OpenAPIGenerator-->>OpenAPISchemaHandler: Return OpenAPI Schema (dict)\n    OpenAPISchemaHandler-->>FastAPIApp: Convert schema dict to JSON\n    FastAPIApp-->>-Browser: Send JSON Response (The OpenAPI Schema)\n\n    Note over Browser: Swagger UI JS receives schema and renders interactive docs\n    Browser->>Browser: Display Interactive API Documentation\n```\n\n----------------------------------------\n\nTITLE: Converting Celsius to Fahrenheit using Python loops\nDESCRIPTION: Example of converting temperature values from Celsius to Fahrenheit using standard Python lists and a for loop, demonstrating the traditional approach before introducing NumPy's vectorized operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Celsius temperatures in a Python list\ncelsius_list = [0.0, 10.0, 20.0, 30.0, 100.0]\nfahrenheit_list = []\n\n# Python loop for conversion\nfor temp_c in celsius_list:\n  temp_f = temp_c * (9/5) + 32\n  fahrenheit_list.append(temp_f)\n\nprint(fahrenheit_list)\n# Output: [32.0, 50.0, 68.0, 86.0, 212.0]\n```\n\n----------------------------------------\n\nTITLE: Python Dictionary Selector Map Example\nDESCRIPTION: Example of a selector map implementation showing how highlight indices map to DOM element nodes\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n{\n    5: <DOMElementNode tag_name='input', attributes={'aria-label':'Search'}, ...>,\n    6: <DOMElementNode tag_name='button', ...>,\n    7: <DOMElementNode tag_name='a', attributes={'href':'/images'}, ...>\n}\n```\n\n----------------------------------------\n\nTITLE: Agent Loop Response Processing in TypeScript\nDESCRIPTION: This code shows how the Agent Loop processes events streamed from the OpenAI API. It demonstrates the handling of different event types, particularly focusing on function_call events that represent tool calls. The code extracts tool names and arguments for further processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/agent-loop.ts (Simplified)\n\n// Inside the loop processing OpenAI stream events...\nfor await (const event of stream) {\n  if (event.type === \"response.output_item.done\") {\n    const item = event.item; // Could be text, function_call, etc.\n    this.onItem(item as ResponseItem); // Send to UI\n\n    // If it's a tool call, mark it for later processing\n    if (item.type === \"function_call\") {\n      // Store item.call_id or item details\n      // to handle after the stream finishes\n    }\n  }\n\n  if (event.type === \"response.completed\") {\n    // Process the full response output once the stream is done\n    for (const item of event.response.output) {\n      if (item.type === \"function_call\") {\n        // *** This is where we handle the tool call! ***\n        // Calls a helper function like handleFunctionCall\n        const toolResults = await this.handleFunctionCall(item);\n        // Prepare results to potentially send back to AI\n        turnInput.push(...toolResults);\n      }\n    }\n    lastResponseId = event.response.id;\n  }\n  // ... other event types ...\n}\n\n// Helper function to process the tool call details\nprivate async handleFunctionCall(item: ResponseFunctionToolCall): Promise<Array<ResponseInputItem>> {\n  const name = item.name; // e.g., \"shell\"\n  const rawArguments = item.arguments; // e.g., \"{\\\"command\\\": [\\\"git\\\", \\\"status\\\"]}\"\n  const callId = item.call_id;\n\n  // *** Use a parser to get structured arguments ***\n  const args = parseToolCallArguments(rawArguments ?? \"{}\"); // From parsers.ts\n\n  if (args == null) {\n    // Handle error: arguments couldn't be parsed\n    return [/* error output item */];\n  }\n\n  let outputText = `Error: Unknown function ${name}`;\n  let metadata = {};\n\n  // Check which tool was called\n  if (name === \"shell\") {\n    // *** Prepare for execution ***\n    // Call handleExecCommand, which checks approval and runs the command\n    const result = await handleExecCommand(\n      args, // Contains { cmd: [\"git\", \"status\"], ... }\n      this.config,\n      this.approvalPolicy,\n      this.getCommandConfirmation, // Function to ask user via UI\n      /* ... cancellation signal ... */\n    );\n    outputText = result.outputText;\n    metadata = result.metadata;\n  } else if (name === \"apply_patch\") {\n    // Similar logic, potentially using execApplyPatch after approval check\n    // It would parse args.patch using logic from parse-apply-patch.ts\n  }\n  // ... other tools ...\n\n  // Create the result message to send back to the AI\n  const outputItem: ResponseInputItem.FunctionCallOutput = {\n    type: \"function_call_output\",\n    call_id: callId,\n    output: JSON.stringify({ output: outputText, metadata }),\n  };\n  return [outputItem];\n}\n```\n\n----------------------------------------\n\nTITLE: Interacting with MCPAgent to Use a Server Tool in OpenManus\nDESCRIPTION: Example of a user request to the MCPAgent that requires using a tool (bash) provided by the connected MCPServer.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n# In the agent's terminal\nEnter your request: Use the bash tool to list the files in the current directory.\n```\n\n----------------------------------------\n\nTITLE: Task Workflow and Context Diagram in Mermaid\nDESCRIPTION: This Mermaid diagram illustrates the flow of information between two tasks in a CrewAI workflow. It shows how the output of the first task (finding cities) becomes the context for the second task (creating an itinerary).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/03_task.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph LR\n    A[\"Task 1: Find Cities (Agent: Researcher)\"] -->|Output: Lisbon, Seville, Malta| B[Context for Task 2]\n    B --> C[\"Task 2: Create Itinerary (Agent: Planner)\"]\n    C -->|Output: Lisbon Itinerary...| D[Final Result]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style C fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#ccf,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5\n    style D fill:#cfc,stroke:#333,stroke-width:2px\n```\n\n----------------------------------------\n\nTITLE: Creating a Multi-Command Click Application with Options (Version 2)\nDESCRIPTION: This snippet demonstrates an improved version of the multi-command Click application, using nested decorators to automatically attach commands to the group and add options to commands.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# multi_app_v2.py (using decorators more effectively)\nimport click\n\n# 1. Create the main group\n@click.group()\ndef cli():\n  \"\"\"A simple tool with multiple commands.\"\"\"\n  pass # Group function still doesn't need to do much\n\n# 2. Define 'hello' and attach it to 'cli' using a decorator\n@cli.command() # <-- Decorator from the 'cli' group object!\n@click.option('--name', default='World', help='Who to greet.')\ndef hello(name): # The 'name' parameter matches the option\n  \"\"\"Says Hello\"\"\"\n  print(f\"Hello {name}!\")\n\n# 3. Define 'goodbye' and attach it to 'cli' using a decorator\n@cli.command() # <-- Decorator from the 'cli' group object!\ndef goodbye():\n  \"\"\"Says Goodbye\"\"\"\n  print(\"Goodbye World!\")\n\n# No need for cli.add_command() anymore!\n\nif __name__ == '__main__':\n  cli()\n```\n\n----------------------------------------\n\nTITLE: Demonstrating NumPy Type Aliases\nDESCRIPTION: This code shows how NumPy provides multiple names (aliases) for the same underlying data types, allowing developers to use either specific names or more general aliases.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Using the specific name\narr_f64 = np.array([1.0, 2.0], dtype=np.float64)\nprint(f\"Type using np.float64: {arr_f64.dtype}\")\n# Output: Type using np.float64: float64\n\n# Using an alias\narr_double = np.array([1.0, 2.0], dtype=np.double)\nprint(f\"Type using np.double: {arr_double.dtype}\")\n# Output: Type using np.double: float64\n\n# They refer to the same underlying type\nprint(f\"Is np.float64 the same as np.double? {np.float64 is np.double}\")\n# Output: Is np.float64 the same as np.double? True\n```\n\n----------------------------------------\n\nTITLE: Agent Run Method with Telemetry Tracking in Python\nDESCRIPTION: Shows how the Agent automatically interacts with the Telemetry service at the beginning and end of an agent run. The Agent captures telemetry events to track when a run starts, completes, and whether it was successful.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent/service.py (Simplified Agent run method) ---\nclass Agent:\n    # ... (other methods) ...\n\n    # Agent has a telemetry object initialized in __init__\n    # self.telemetry = ProductTelemetry()\n\n    async def run(self, max_steps: int = 100) -> AgentHistoryList:\n        # ---> Tell Telemetry: Agent run is starting <---\n        self._log_agent_run() # This includes a telemetry.capture() call\n\n        try:\n            # ... (main agent loop runs here) ...\n            for step_num in range(max_steps):\n                # ... (agent takes steps) ...\n                if self.state.history.is_done():\n                    break\n            # ...\n        finally:\n            # ---> Tell Telemetry: Agent run is ending <---\n            self.telemetry.capture(\n                AgentEndTelemetryEvent( # Uses a specific data structure\n                    agent_id=self.state.agent_id,\n                    is_done=self.state.history.is_done(),\n                    success=self.state.history.is_successful(),\n                    # ... other anonymous stats ...\n                )\n            )\n            # ... (cleanup browser etc.) ...\n\n        return self.state.history\n```\n\n----------------------------------------\n\nTITLE: Kickoff Method for Crew Execution - Python\nDESCRIPTION: Defines the 'kickoff' method, the main entry point for initiating task execution according to the current process mode. It interprets the Crew's configuration to run either sequential or hierarchical processes and returns the aggregated output. The method assumes that task list, agents, and configuration are already in place, and raises errors for unsupported process values.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef kickoff(self, inputs: Optional[Dict[str, Any]] = None) -> CrewOutput:\n    # ... setup, input interpolation, callback setup ...\n\n    # THE CORE DECISION BASED ON PROCESS:\n    if self.process == Process.sequential:\n        result = self._run_sequential_process()\n    elif self.process == Process.hierarchical:\n        # Ensure manager is ready before running\n        self._create_manager_agent() # Creates manager if needed\n        result = self._run_hierarchical_process()\n    else:\n        raise NotImplementedError(f\"Process '{self.process}' not implemented.\")\n\n    # ... calculate usage metrics, final formatting ...\n    return result\n```\n\n----------------------------------------\n\nTITLE: Base Transport Adapter Definition in Python\nDESCRIPTION: Defines the base abstract class for transport adapters with required interface methods send() and close().\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/07_transport_adapters.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        raise NotImplementedError\n    def close(self):\n        raise NotImplementedError\n```\n\n----------------------------------------\n\nTITLE: Defining and Compiling a LangGraph Workflow with MemorySaver in Python\nDESCRIPTION: This code defines a simple LangGraph workflow with two nodes (adder and multiplier), sets up state management with a custom TypedDict, and compiles the workflow with an attached MemorySaver checkpointer. By passing checkpointer=memory_saver to compile(), automatic checkpointing is enabled and state will be persisted after each step. Dependencies are typing.TypedDict and core langgraph.graph classes. Inputs include an initial state and the compiled app; output is an application object with checkpoint support. All node and workflow setup code is preserved.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- Define State and Nodes (same as Chapter 1) ---\\nfrom typing import TypedDict\\nfrom langgraph.graph import StateGraph, END, START\\n\\nclass MyState(TypedDict):\\n    value: int\\n\\ndef add_one(state: MyState) -> dict:\\n    print(f\\\"Adder: Adding 1 to {state['value']}\\\")\\n    return {\"value\": state['value'] + 1}\\n\\ndef multiply_by_two(state: MyState) -> dict:\\n    print(f\\\"Multiplier: Doubling {state['value']}\\\")\\n    return {\"value\": state['value'] * 2}\\n\\n# --- Build the Graph (same as Chapter 1) ---\\nworkflow = StateGraph(MyState)\\nworkflow.add_node(\"adder\", add_one)\\nworkflow.add_node(\"multiplier\", multiply_by_two)\\nworkflow.set_entry_point(\"adder\")\\nworkflow.add_edge(\"adder\", \"multiplier\")\\nworkflow.add_edge(\"multiplier\", END)\\n\\n# --- Compile WITH the checkpointer ---\\n# Pass the checkpointer instance to the compile method\\napp = workflow.compile(checkpointer=memory_saver)\n```\n\n----------------------------------------\n\nTITLE: Defining AgentState Enumeration in OpenManus\nDESCRIPTION: This snippet defines the possible states an agent can be in using Python's Enum class. The enumeration ensures that an agent's state can only be one of the predefined values: IDLE, RUNNING, FINISHED, or ERROR.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified definition from app/schema.py\nfrom enum import Enum\n\nclass AgentState(str, Enum):\n    \"\"\"Agent execution states\"\"\"\n    IDLE = \"IDLE\"\n    RUNNING = \"RUNNING\"\n    FINISHED = \"FINISHED\"\n    ERROR = \"ERROR\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Relationship Between dtype and Scalar Types in NumPy\nDESCRIPTION: This code demonstrates how NumPy's dtype objects describe the data type of an array while the actual element type is one of NumPy's scalar types (part of numerictypes).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Create an array of 32-bit integers\narr = np.array([10, 20, 30], dtype=np.int32)\n\n# The dtype object describes the type\nprint(f\"Array's dtype object: {arr.dtype}\")\n# Output: Array's dtype object: int32\n\n# The actual Python type of elements (if accessed individually)\n# and the type referred to by the dtype object's `.type` attribute\nprint(f\"The element type class: {arr.dtype.type}\")\n# Output: The element type class: <class 'numpy.int32'>\n\n# This <class 'numpy.int32'> is one of NumPy's scalar types\n# managed under the numerictypes concept.\n```\n\n----------------------------------------\n\nTITLE: Running a Simple Flask Development Server in Python\nDESCRIPTION: Shows the complete minimal Flask application including the code to run Flask's built-in development server. The `if __name__ == '__main__':` block ensures the server only runs when the script is executed directly. `app.run(debug=True)` starts the server in debug mode, which provides automatic reloading and detailed error messages during development. This server is intended for development only, not production.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/01_application_object___flask__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (end of the file)\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/')\ndef index():\n  return 'Hello, World!'\n\n# This block runs the app only when the script is executed directly\nif __name__ == '__main__':\n  # Start the built-in development server\n  app.run(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Local Python Execution with AST Evaluation in Python\nDESCRIPTION: This snippet details the `LocalPythonExecutor` class, focusing on its execution logic. The `__call__` method uses the `evaluate_python_code` function to run code safely. This function parses the input code string into an Abstract Syntax Tree (AST) and evaluates it node-by-node using `evaluate_ast`, preventing unsafe operations. The executor maintains internal state (`self.state`), manages available tools (`self.static_tools`, `self.custom_tools`), enforces allowed imports (`self.authorized_imports`), and captures print outputs. The `send_variables` and `send_tools` methods allow external configuration of the executor's state and available functions. Dependencies include `evaluate_python_code`, `evaluate_ast`, `ast` module, `Tool` type, and potentially error types like `FinalAnswerException` and `InterpreterError`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/06_pythonexecutor.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: local_python_executor.py (Simplified LocalPythonExecutor __call__) ---\nfrom .local_python_executor import evaluate_python_code # The safe evaluation function\nfrom .tools import Tool # For type hinting\n\nclass LocalPythonExecutor(PythonExecutor):\n    def __init__(self, additional_authorized_imports, max_print_outputs_length=None):\n        self.custom_tools = {} # Stores functions defined in code\n        self.state = {} # Stores variables\n        self.max_print_outputs_length = max_print_outputs_length or 50000\n        self.additional_authorized_imports = additional_authorized_imports\n        self.authorized_imports = # ... combine base and additional imports ...\n        self.static_tools = None # Will hold agent tools + safe builtins\n\n    def __call__(self, code_action: str) -> Tuple[Any, str, bool]:\n        \"\"\"Runs the code using the safe evaluate_python_code function.\"\"\"\n        output, is_final_answer = evaluate_python_code(\n            code=code_action,\n            static_tools=self.static_tools, # Tools provided by the agent\n            custom_tools=self.custom_tools, # Functions defined during execution\n            state=self.state, # Current variables\n            authorized_imports=self.authorized_imports, # Allowed imports\n            max_print_outputs_length=self.max_print_outputs_length,\n        )\n        # Get captured print logs from the state\n        logs = str(self.state.get(\"_print_outputs\", \"\"))\n        return output, logs, is_final_answer\n\n    def send_variables(self, variables: dict):\n        \"\"\"Adds external variables to the executor's state.\"\"\"\n        self.state.update(variables)\n\n    def send_tools(self, tools: Dict[str, Tool]):\n        \"\"\"Makes agent tools available to the executed code.\"\"\"\n        # Combine agent tools with safe Python builtins (like len, str, math functions)\n        from .local_python_executor import BASE_PYTHON_TOOLS\n        self.static_tools = {**tools, **BASE_PYTHON_TOOLS.copy()}\n\n# --- Also in local_python_executor.py ---\ndef evaluate_python_code(code, static_tools, custom_tools, state, authorized_imports, ...):\n    \"\"\"\n    Safely evaluates code by parsing to AST and walking the tree.\n    - Parses `code` string into an Abstract Syntax Tree (AST).\n    - Initializes `state['_print_outputs']` to capture prints.\n    - Defines a `final_answer` wrapper to signal completion.\n    - Iterates through AST nodes using `evaluate_ast`.\n    - `evaluate_ast` recursively handles different node types (assignments, calls, loops etc.)\n        - It uses `state` to read/write variables.\n        - It checks calls against `static_tools` and `custom_tools`.\n        - It enforces `authorized_imports`.\n        - It blocks dangerous operations (e.g., direct `eval`, certain imports).\n    - Returns the final `result` and `is_final_answer` flag.\n    - Captures print outputs in `state['_print_outputs']`.\n    - Handles errors gracefully.\n    \"\"\"\n    # ... implementation details ...\n    try:\n        expression = ast.parse(code) # Parse code to AST\n        # ... setup state, wrap final_answer ...\n        for node in expression.body:\n             result = evaluate_ast(node, state, static_tools, custom_tools, authorized_imports) # Evaluate node-by-node\n        # ... capture logs, handle exceptions ...\n        return result, is_final_answer\n    except FinalAnswerException as e:\n         # ... capture logs ...\n         return e.value, True # Special exception for final_answer\n    except Exception as e:\n         # ... capture logs, wrap error ...\n         raise InterpreterError(...)\n\ndef evaluate_ast(expression: ast.AST, state, static_tools, custom_tools, authorized_imports):\n    \"\"\"Recursive function to evaluate a single AST node safely.\"\"\"\n    # ... checks node type (ast.Assign, ast.Call, ast.Import, etc.) ...\n    # ... performs the corresponding safe operation using state and tools ...\n    # ... raises InterpreterError for disallowed operations ...\n    pass\n```\n\n----------------------------------------\n\nTITLE: Submitting Tasks and Retrieving Task IDs\nDESCRIPTION: Demonstrates how to send tasks to Celery workers and obtain AsyncResult objects that contain the task IDs needed for result retrieval. Shows submitting both a reliable task and one that might fail.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# run_tasks.py\nfrom celery_app import add, fail_sometimes\n\n# Send the add task\nresult_add = add.delay(10, 20)\nprint(f\"Sent task add(10, 20). Task ID: {result_add.id}\")\n\n# Send the task that might fail\nresult_fail = fail_sometimes.delay(\"my data\")\nprint(f\"Sent task fail_sometimes('my data'). Task ID: {result_fail.id}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing BufferedChatCompletionContext in AutoGen Core with Python\nDESCRIPTION: This example shows how to use BufferedChatCompletionContext to keep only the most recent messages in the conversation history. It sets a buffer size of 3, demonstrating how older messages are discarded.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# File: use_buffered_context.py\nimport asyncio\nfrom define_chat_messages import full_history\nfrom autogen_core.model_context import BufferedChatCompletionContext\n\nasync def main():\n    # Keep only the last 3 messages\n    context = BufferedChatCompletionContext(buffer_size=3)\n    for msg in full_history:\n        await context.add_message(msg)\n\n    messages_for_llm = await context.get_messages()\n\n    print(f\"--- Buffered Context (buffer=3, {len(messages_for_llm)} messages) ---\")\n    for i, msg in enumerate(messages_for_llm):\n        print(f\"{i+1}. [{msg.type}]: {msg.content[:30]}...\")\n\n# asyncio.run(main()) # If run\n```\n\n----------------------------------------\n\nTITLE: Example A2A Protocol Error Response (Method Not Found)\nDESCRIPTION: This JSON snippet demonstrates a specific JSON-RPC error response within the A2A protocol. It shows the agent's response when a client attempts to call an unsupported method (`tasks/make_coffee`). The `error` object contains the standard JSON-RPC code `-32601` ('Method not found') and a descriptive error `message`, along with the `id` of the originating request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"jsonrpc\": \"2.0\",\n  \"error\": {\n    \"code\": -32601, // Standard JSON-RPC code for \"Method not found\"\n    \"message\": \"Method not found: tasks/make_coffee\"\n  },\n  \"id\": \"client-req-002\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Arrays with Different Data Types in NumPy\nDESCRIPTION: This snippet demonstrates how to create NumPy arrays with different data types (integers, floats, and booleans) and how to inspect their dtype attribute to see what data type NumPy has assigned.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/02_dtype__data_type_object_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Create an array of integers\nint_array = np.array([1, 2, 3])\nprint(f\"Integer array: {int_array}\")\nprint(f\"Data type: {int_array.dtype}\")\n\n# Create an array of floating-point numbers (decimals)\nfloat_array = np.array([1.0, 2.5, 3.14])\nprint(f\"\\nFloat array: {float_array}\")\nprint(f\"Data type: {float_array.dtype}\")\n\n# Create an array of booleans (True/False)\nbool_array = np.array([True, False, True])\nprint(f\"\\nBoolean array: {bool_array}\")\nprint(f\"Data type: {bool_array.dtype}\")\n```\n\n----------------------------------------\n\nTITLE: Illustrating JSON-RPC Request Structure\nDESCRIPTION: This JSON snippet shows the basic format of a JSON-RPC 2.0 request message sent from a client to an agent. It highlights the key fields: `jsonrpc` (protocol version), `method` (the action to perform), `params` (input data for the action), and `id` (a unique identifier to correlate request and response).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"jsonrpc\": \"2.0\",        // Specifies the protocol version\n  \"method\": \"some_action\", // What the client wants the agent to DO\n  \"params\": { ... },       // The details needed for the action\n  \"id\": \"request-123\"      // A unique ID to match request and response\n}\n```\n\n----------------------------------------\n\nTITLE: NumPy Core Initialization Example\nDESCRIPTION: Simplified code showing how NumPy's core module is initialized, importing from various submodules and exposing their functionality to create the numpy API.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# From numpy/core/__init__.py - Simplified\nfrom . import multiarray\nfrom . import umath\n# ... other imports ...\nfrom . import numeric\nfrom .numeric import * # Pulls in functions like np.array, np.zeros\n# ... more setup ...\n```\n\n----------------------------------------\n\nTITLE: File Content Written by Background Task (Text)\nDESCRIPTION: Displays the content written to the `log.txt` file by the `write_log` background task. This confirms the side effect (file writing) of the background task's execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nNotification sent to: test@example.com\n```\n\n----------------------------------------\n\nTITLE: Using LLMContentFilter for AI-based Content Extraction in Python\nDESCRIPTION: This conceptual example shows how to use LLMContentFilter to extract specific content from web pages using AI. The code demonstrates setting up an LLM filter with an instruction, configuring a markdown generator with this filter, and using it with the AsyncWebCrawler. This example uses a mock LLM configuration for demonstration purposes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/05_relevantcontentfilter.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# chapter5_example_3_conceptual.py\nimport asyncio\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    DefaultMarkdownGenerator,\n    LLMContentFilter,\n    # Assume LlmConfig is set up correctly (see LLM-specific docs)\n    # from crawl4ai.async_configs import LlmConfig\n)\n\n# Assume llm_config is properly configured with API keys, provider, etc.\n# Example: llm_config = LlmConfig(provider=\"openai\", api_token=\"env:OPENAI_API_KEY\")\n# For this example, we'll pretend it's ready.\nclass MockLlmConfig: # Mock for demonstration\n    provider = \"mock_provider\"\n    api_token = \"mock_token\"\n    base_url = None\nllm_config = MockLlmConfig()\n\n\nasync def main():\n    # 1. Create the LLM filter with an instruction\n    instruction = \"Extract only the main news article content. Remove headers, footers, ads, comments, and related links.\"\n    llm_filter = LLMContentFilter(\n        instruction=instruction,\n        llmConfig=llm_config # Pass the LLM configuration\n    )\n    print(f\"Filter created: LLMContentFilter\")\n    print(f\"Instruction: '{llm_filter.instruction}'\")\n\n    # 2. Create a Markdown generator using this filter\n    markdown_generator_with_filter = DefaultMarkdownGenerator(\n        content_filter=llm_filter\n    )\n    print(\"Markdown generator configured with LLM filter.\")\n\n    # 3. Create CrawlerRunConfig\n    run_config = CrawlerRunConfig(\n        markdown_generator=markdown_generator_with_filter\n    )\n\n    # 4. Run the crawl\n    async with AsyncWebCrawler() as crawler:\n        # Example URL (replace with a real news article)\n        url_to_crawl = \"https://httpbin.org/html\" # Using simple page for demo\n        print(f\"\\nCrawling {url_to_crawl}...\")\n\n        # In a real scenario, this would call the LLM API\n        result = await crawler.arun(url=url_to_crawl, config=run_config)\n\n        if result.success:\n            print(\"\\nCrawl successful!\")\n            # The fit_markdown would contain the AI-filtered content\n            print(\"\\n--- Start of Fit Markdown (AI Filtered - Conceptual) ---\")\n            # Because we used a mock LLM/simple page, fit_markdown might be empty or simple.\n            # On a real page with a real LLM, it would ideally contain just the main article.\n            print(result.markdown.fit_markdown[:500] + \"...\")\n            print(\"--- End of Fit Markdown Snippet ---\")\n        else:\n            print(f\"\\nCrawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Click Command with Decorators\nDESCRIPTION: This snippet shows how to create a simple Click command using the @click.command() decorator, demonstrating the simplicity and cleanliness of the decorator approach.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# The actual Click way\nimport click\n\n@click.command() # <-- The Decorator!\ndef hello():\n  \"\"\"A simple command that says Hello World\"\"\"\n  print(\"Hello World!\")\n\nif __name__ == '__main__':\n  hello()\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry in Windows Command Prompt\nDESCRIPTION: Shows how to disable telemetry in Windows Command Prompt by setting the ANONYMIZED_TELEMETRY environment variable to False before running the Python script.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_2\n\nLANGUAGE: cmd\nCODE:\n```\nset ANONYMIZED_TELEMETRY=False\npython your_agent_script.py\n```\n\n----------------------------------------\n\nTITLE: Using DefaultSubscription Decorator for Simplified Agent Registration\nDESCRIPTION: Example usage of the DefaultSubscription class via the @default_subscription decorator, which provides a convenient way to create TypeSubscription objects with automatic agent type inference from the class being defined.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# From: _default_subscription.py (Conceptual Usage)\nfrom autogen_core import BaseAgent, default_subscription, ResearchFacts\n\n@default_subscription # Uses 'default' topic type, infers agent type 'writer'\nclass WriterAgent(BaseAgent):\n    # Agent logic here...\n    async def on_message_impl(self, message: ResearchFacts, ctx): ...\n\n# Or specify the topic type\n@default_subscription(topic_type=\"research.facts.available\")\nclass SpecificWriterAgent(BaseAgent):\n     # Agent logic here...\n     async def on_message_impl(self, message: ResearchFacts, ctx): ...\n```\n\n----------------------------------------\n\nTITLE: Python Wrapper for NumPy C Extension Module\nDESCRIPTION: Simplified example showing how NumPy's Python layer imports and exposes functionality from the compiled C extension module. This demonstrates the bridge between Python and the C implementation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# numpy/core/multiarray.py - Simplified Example\n# This Python file imports directly from the C extension module\n\nfrom . import _multiarray_umath # Import the compiled C module\nfrom ._multiarray_umath import * # Make C functions available\n\n# Functions like 'array', 'empty', 'dot' that you use via `np.`\n# might be defined or re-exported here, ultimately calling C code.\n# For example, the `array` function here might parse the Python input\n# and then call a C function like `PyArray_NewFromDescr` from _multiarray_umath.\n```\n\n----------------------------------------\n\nTITLE: Accessing HTML and Markdown Content from CrawlResult in Python\nDESCRIPTION: This snippet demonstrates how to access the raw HTML and generated Markdown content from a CrawlResult object. It includes checks to ensure the Markdown object exists before attempting to access its attributes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlResult\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url = \"https://httpbin.org/html\"\n        result: CrawlResult = await crawler.arun(url=url)\n\n        if result.success:\n            print(\"--- Content ---\")\n            # Print the first 150 chars of raw HTML\n            print(f\"Raw HTML snippet: {result.html[:150]}...\")\n\n            # Access the raw markdown\n            if result.markdown: # Check if markdown object exists\n                 print(f\"Markdown snippet: {result.markdown.raw_markdown[:150]}...\")\n            else:\n                 print(\"Markdown not generated.\")\n        else:\n            print(f\"Crawl failed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Field Validation Constraints and Error Handling\nDESCRIPTION: Demonstrates how Field() validation constraints like min_length and gt are enforced, with examples of ValidationError exceptions for invalid data.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Continuing from above...\nfrom pydantic import ValidationError\n\n# Input data with invalid values\ninvalid_data_1 = {'userName': 'Bo', 'age': 30} # Name too short\ninvalid_data_2 = {'userName': 'Charlie', 'age': -5} # Age not > 0\n\ntry:\n    User(**invalid_data_1)\nexcept ValidationError as e:\n    print(f\"Error 1:\\n{e}\")\n    \"\"\"\n    Expected Output (simplified):\n    Error 1:\n    1 validation error for User\n    name\n      String should have at least 3 characters [type=string_too_short, context={'min_length': 3}, ...]\n    \"\"\"\n\ntry:\n    User(**invalid_data_2)\nexcept ValidationError as e:\n    print(f\"Error 2:\\n{e}\")\n    \"\"\"\n    Expected Output (simplified):\n    Error 2:\n    1 validation error for User\n    age\n      Input should be greater than 0 [type=greater_than, context={'gt': 0}, ...]\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Illustrative Usage of dspy.Predict (Recap)\nDESCRIPTION: This snippet demonstrates the basic usage of `dspy.Predict` with a hypothetical `TranslateToFrench` signature, showing how it takes an input field (`english_sentence`) and generates an output field (`french_sentence`). It serves as context for explaining how `dspy.Predict` relies on an underlying LM Client.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# translator = dspy.Predict(TranslateToFrench)\n# result = translator(english_sentence=\"Hello, how are you?\")\n# print(result.french_sentence) # --> Bonjour, comment ça va?\n```\n\n----------------------------------------\n\nTITLE: Integrating AgentLogger in MultiStep Agent Workflow (Python)\nDESCRIPTION: Demonstrates use of the AgentLogger within a MultiStepAgent class to log task initiation, actions, tool calls, code execution, observations, and errors. Requires prior initialization of the AgentLogger with an appropriate verbosity level. The logger's methods are called at various workflow stages to produce formatted output. Expects agent step objects and uses LogLevel to filter logs by importance. Proper operation depends on logging setup and the definitions of code/tool execution functions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified Agent using Logger) ---\\nfrom .monitoring import AgentLogger, LogLevel\\n\\nclass MultiStepAgent:\\n    def __init__(self, ..., verbosity_level: LogLevel = LogLevel.INFO):\\n        # ... other setup ...\\n        self.logger = AgentLogger(level=verbosity_level)\\n        # ...\\n\\n    def run(self, task: str, ...):\\n        # ...\\n        self.logger.log_task(content=self.task, ..., level=LogLevel.INFO)\\n        # ... call _run ...\\n\\n    def _execute_step(self, task: str, memory_step: ActionStep):\\n        self.logger.log_rule(f\"Step {self.step_number}\", level=LogLevel.INFO)\\n        try:\\n            # ... (Think phase: LLM call) ...\\n\\n            # ... (Act phase: Execute tool/code) ...\\n            # Example for CodeAgent:\\n            # self.logger.log_code(\"Executing code:\", code_action, level=LogLevel.INFO)\\n            # observation = self.python_executor(code_action)\\n\\n            # Example for ToolCallingAgent:\\n            # self.logger.log(Panel(f\"Calling tool: '{tool_name}' ...\"), level=LogLevel.INFO)\\n            # observation = self.execute_tool_call(tool_name, arguments)\\n\\n            # ... (Observe phase) ...\\n            self.logger.log(f\"Observations: {observation}\", level=LogLevel.INFO)\\n\\n            # ... (Handle final answer) ...\\n            # if final_answer:\\n            #    self.logger.log(f\"Final answer: {final_answer}\", style=f\"bold {YELLOW_HEX}\", level=LogLevel.INFO)\\n\\n        except AgentError as e:\\n            # Log errors using the logger's error method\\n            action_step.error = e # Store error in memory\\n            self.logger.log_error(f\"Error in step {self.step_number}: {e}\") # Display error\\n\\n        # ...\n```\n\n----------------------------------------\n\nTITLE: Implementing ToolResult Schema for Standardized Tool Outputs\nDESCRIPTION: The ToolResult schema standardizes how tools report their execution results. It includes fields for the output data (which can be of any type) and an optional error message, providing a consistent structure regardless of the specific tool.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified Pydantic model from app/tool/base.py\nfrom pydantic import BaseModel, Field\nfrom typing import Any, Optional\n\nclass ToolResult(BaseModel):\n    \"\"\"Represents the result of a tool execution.\"\"\"\n    output: Any = Field(default=None)          # The main result data\n    error: Optional[str] = Field(default=None) # Error message, if any\n    # ... other optional fields like base64_image, system message ...\n\n    class Config:\n        arbitrary_types_allowed = True # Allows 'Any' type for output\n```\n\n----------------------------------------\n\nTITLE: Configuring AsyncWebCrawler with CrawlerRunConfig in Python\nDESCRIPTION: Shows how to customize the behavior of AsyncWebCrawler for a specific crawl operation using CrawlerRunConfig. This example demonstrates setting the cache mode to bypass for fresh content fetching.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/02_asyncwebcrawler.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# chapter2_example_2.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai import CrawlerRunConfig # Import configuration class\nfrom crawl4ai import CacheMode # Import cache options\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        print(\"Crawler is ready!\")\n        url_to_crawl = \"https://httpbin.org/html\"\n\n        # Create a specific configuration for this run\n        # Tell the crawler to BYPASS the cache (fetch fresh)\n        run_config = CrawlerRunConfig(\n            cache_mode=CacheMode.BYPASS\n        )\n        print(\"Configuration: Bypass cache for this run.\")\n\n        # Pass the config object to the arun method\n        result = await crawler.arun(\n            url=url_to_crawl,\n            config=run_config # Pass the specific instructions\n        )\n\n        if result.success:\n            print(\"\\nSuccess! Crawler got fresh content (cache bypassed).\")\n            print(f\"Page Title: {result.metadata.get('title', 'N/A')}\")\n        else:\n            print(f\"\\nFailed to crawl: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Experimenting with Swapping Language Models in DSPy\nDESCRIPTION: Demonstrates the ease of switching between different language models in DSPy. The code first configures and uses OpenAI's GPT-3.5 Turbo with a `translator` module. Then, it reconfigures DSPy to use Anthropic's Claude 3 Haiku by calling `dspy.settings.configure` with a new LM client instance. The *same* `translator` module instance is then called again, automatically picking up the newly configured Claude model, showcasing the flexibility provided by the LM Client abstraction.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# --- Experiment 1: Using GPT-3.5 Turbo ---\nprint(\"Testing with GPT-3.5 Turbo...\")\nturbo = dspy.LM(model='openai/gpt-3.5-turbo', max_tokens=100)\ndspy.settings.configure(lm=turbo)\n\ntranslator = dspy.Predict(TranslateToFrench)\nresult_turbo = translator(english_sentence=\"Where is the library?\")\nprint(f\"GPT-3.5: {result_turbo.french_sentence}\")\n\n\n# --- Experiment 2: Using Claude 3 Haiku ---\nprint(\"\\nTesting with Claude 3 Haiku...\")\nclaude_haiku = dspy.LM(model='anthropic/claude-3-haiku-20240307', max_tokens=100)\ndspy.settings.configure(lm=claude_haiku)\n\n# We can reuse the SAME translator object, or create a new one\n# It will pick up the NEWLY configured LM from settings\nresult_claude = translator(english_sentence=\"Where is the library?\")\nprint(f\"Claude 3 Haiku: {result_claude.french_sentence}\")\n```\n\n----------------------------------------\n\nTITLE: Compiling a DSPy Program with BootstrapFewShot\nDESCRIPTION: Executes the optimization process by calling the `compile` method of the instantiated `BootstrapFewShot` teleprompter. This method takes the initial `student` program (`initial_program`) and the `trainset` as input. It runs the training examples, identifies successful traces using the provided metric, and uses these traces to create few-shot demonstrations which are then added to a new, optimized version of the program (`compiled_program`).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Compile the program!\n# This runs the optimization process using the trainset.\n# It uses a 'teacher' model (often the student itself or a copy)\n# to generate traces, finds successful ones via the metric,\n# and adds them as demos to the student's predictors.\ncompiled_program = teleprompter.compile(student=initial_program, trainset=trainset)\n\n# The 'compiled_program' is a new instance of BasicQA,\n# but its internal predictor now has few-shot examples added!\n```\n\n----------------------------------------\n\nTITLE: Starting Celery Worker with Events Enabled\nDESCRIPTION: Command to start a Celery worker with event monitoring enabled using the -E flag\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncelery -A celery_app worker --loglevel=info -E\n```\n\n----------------------------------------\n\nTITLE: Implementing Current Date Function Tool\nDESCRIPTION: Basic Python function implementation to get the current date, which will be wrapped as a Tool.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/04_tool.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport datetime\n\ndef get_current_date() -> str:\n    \"\"\"Fetches the current date as a string.\"\"\"\n    today = datetime.date.today()\n    return today.isoformat() # Returns date like \"2023-10-27\"\n\n# Test the function\nprint(f\"Function output: {get_current_date()}\")\n```\n\n----------------------------------------\n\nTITLE: Importing BootstrapFewShot Teleprompter in DSPy\nDESCRIPTION: Imports the `BootstrapFewShot` class from the `dspy.teleprompt` module. This specific Teleprompter is designed to automatically generate and select effective few-shot demonstrations for the predictors within a DSPy program.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dspy.teleprompt import BootstrapFewShot\n```\n\n----------------------------------------\n\nTITLE: Configuring Global LM and RM Defaults using dspy.settings (Python)\nDESCRIPTION: Demonstrates how to set global default Language Model (LM) and Retrieval Model (RM) instances using `dspy.settings.configure`. It includes creating dummy LM and RM classes (as fallbacks or examples) and then registering them as the defaults for subsequent DSPy operations. Prints the configured settings for verification.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# 1. Create your LM and RM instances (as seen in Chapters 5 & 6)\n# Example using OpenAI and a dummy RM\ntry:\n    # Assumes OPENAI_API_KEY is set\n    turbo = dspy.LM(model='openai/gpt-3.5-turbo-instruct', max_tokens=100)\nexcept ImportError:\n    print(\"Note: dspy[openai] not installed. Using dummy LM.\")\n    # Define a dummy LM if OpenAI isn't available\n    class DummyLM(dspy.LM):\n        def __init__(self): super().__init__(model=\"dummy\")\n        def basic_request(self, prompt, **kwargs): return {\"choices\": [{\"text\": \"Dummy LM Response\"}]}\n        def __call__(self, prompt, **kwargs): return [\"Dummy LM Response\"]\n    turbo = DummyLM()\n\n\n# Dummy RM for demonstration\nclass DummyRM(dspy.Retrieve):\n     def __init__(self, k=3): super().__init__(k=k)\n     def forward(self, query, k=None):\n         k = k if k is not None else self.k\n         return dspy.Prediction(passages=[f\"Dummy passage {i+1} for '{query}'\" for i in range(k)])\nmy_rm = DummyRM(k=3)\n\n# 2. Configure dspy.settings with these instances\ndspy.settings.configure(lm=turbo, rm=my_rm)\n\n# That's it! Defaults are now set globally.\nprint(f\"Default LM: {dspy.settings.lm}\")\nprint(f\"Default RM: {dspy.settings.rm}\")\n```\n\n----------------------------------------\n\nTITLE: Example A2A Message with TextPart\nDESCRIPTION: This JSON snippet exemplifies the structure of a `Message` object within the A2A protocol, specifically one containing a simple text instruction. It shows the `role` (indicating the sender, here 'user') and a `parts` array containing a single `TextPart` with the actual content. This structure is typically embedded within the `params` of a `tasks/send` JSON-RPC request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/03_a2a_protocol___core_types.md#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n// This structure would go inside the \"params\" of a tasks/send request\n{\n  \"role\": \"user\", // Who is sending this message\n  \"parts\": [      // List of content parts (here, just one)\n    {\n      \"type\": \"text\", // Specifies this is a TextPart\n      \"text\": \"Translate 'hello' to French\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring LM and Default Adapter in DSPy Settings (Python)\nDESCRIPTION: Demonstrates how to configure the global `dspy.settings`. It shows setting the Language Model (LM) client (commented out, referring to Chapter 5). The comment highlights that configuring an adapter explicitly (like `dspy.adapters.ChatAdapter`) is usually unnecessary, as DSPy typically uses a suitable default (like `ChatAdapter`) automatically based on the configured LM. Requires the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n\n# Configure LM (Chapter 5)\n# turbo = dspy.LM(model='openai/gpt-3.5-turbo')\n# dspy.settings.configure(lm=turbo)\n\n# Default Adapter (ChatAdapter) is usually active automatically!\n# You typically DON'T need to configure it unless you want a different one.\n# dspy.settings.configure(adapter=dspy.adapters.ChatAdapter())\n```\n\n----------------------------------------\n\nTITLE: Defining the Subscription Protocol Interface in Python\nDESCRIPTION: The Subscription Protocol defines the contract that any subscription rule must implement, including methods to check if a topic matches and to map matching topics to target agent IDs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# From: _subscription.py (Simplified Protocol)\nfrom typing import Protocol\n# ... other imports\n\nclass Subscription(Protocol):\n    @property\n    def id(self) -> str: ... # Unique ID for this subscription instance\n\n    def is_match(self, topic_id: TopicId) -> bool:\n        \"\"\"Check if a topic matches this subscription's rule.\"\"\"\n        ...\n\n    def map_to_agent(self, topic_id: TopicId) -> AgentId:\n        \"\"\"Determine the target AgentId if is_match was True.\"\"\"\n        ...\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Protocol in Python for AutoGen Core\nDESCRIPTION: This code defines the Agent Protocol which specifies the required interface for all agent implementations. It includes the id property to get the agent's unique ID and the on_message method which handles incoming messages, representing the agent's main communication capability.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# From: _agent.py (Simplified Agent Protocol)\nfrom typing import Any, Mapping, Protocol\n# ... other imports\n\nclass Agent(Protocol):\n    @property\n    def id(self) -> AgentId: ... # The agent's unique ID\n\n    async def on_message(self, message: Any, ctx: MessageContext) -> Any:\n        \"\"\"Handles an incoming message.\"\"\"\n        # Agent's logic to process the message goes here\n        ...\n```\n\n----------------------------------------\n\nTITLE: Defining CacheContext and CacheMode (Python)\nDESCRIPTION: This snippet defines the CacheContext class and CacheMode enum, which are used to encapsulate cache-related decisions and URL handling in the web crawler.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/cache_context.py\nfrom enum import Enum\n\nclass CacheMode(Enum):\n    \"\"\"Defines the caching behavior for web crawling operations.\"\"\"\n    ENABLED = \"enabled\"     # Read and Write\n    DISABLED = \"disabled\"    # No Read, No Write\n    READ_ONLY = \"read_only\"  # Read Only, No Write\n    WRITE_ONLY = \"write_only\" # Write Only, No Read\n    BYPASS = \"bypass\"      # No Read, Write Only (similar to WRITE_ONLY but explicit intention)\n\nclass CacheContext:\n    \"\"\"Encapsulates cache-related decisions and URL handling.\"\"\"\n    def __init__(self, url: str, cache_mode: CacheMode, always_bypass: bool = False):\n        self.url = url\n        self.cache_mode = cache_mode\n        self.always_bypass = always_bypass # Usually False\n        # Determine if URL type is cacheable (e.g., not 'raw:')\n        self.is_cacheable = url.startswith((\"http://\", \"https://\", \"file://\"))\n        # ... other URL type checks ...\n\n    def should_read(self) -> bool:\n        \"\"\"Determines if cache should be read based on context.\"\"\"\n        if self.always_bypass or not self.is_cacheable:\n            return False\n        # Allow read if mode is ENABLED or READ_ONLY\n        return self.cache_mode in [CacheMode.ENABLED, CacheMode.READ_ONLY]\n\n    def should_write(self) -> bool:\n        \"\"\"Determines if cache should be written based on context.\"\"\"\n        if self.always_bypass or not self.is_cacheable:\n            return False\n        # Allow write if mode is ENABLED, WRITE_ONLY, or BYPASS\n        return self.cache_mode in [CacheMode.ENABLED, CacheMode.WRITE_ONLY, CacheMode.BYPASS]\n\n    @property\n    def display_url(self) -> str:\n        \"\"\"Returns the URL in display format.\"\"\"\n        return self.url if not self.url.startswith(\"raw:\") else \"Raw HTML\"\n\n# Helper for backward compatibility (may be removed later)\ndef _legacy_to_cache_mode(...) -> CacheMode:\n    # ... logic to convert old boolean flags ...\n    pass\n```\n\n----------------------------------------\n\nTITLE: Celery Worker Task Execution Log\nDESCRIPTION: Example log output showing task execution progress including task receipt, execution, and completion with timing information. Demonstrates the worker's logging of task processing steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/05_worker.md#2025-04-22_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n[2023-10-27 10:05:00,100: INFO/ForkPoolWorker-1] Task tasks.add[some-task-id] received\nTask 'add' starting with (5, 7)\nTask 'add' finished with result: 12\n[2023-10-27 10:05:05,150: INFO/ForkPoolWorker-1] Task tasks.add[some-task-id] succeeded in 5.05s: 12\n```\n\n----------------------------------------\n\nTITLE: Visualizing Client-Server Tool Call Flow with Mermaid\nDESCRIPTION: A sequence diagram illustrating the flow of a tool call from client to server and back, showing how request IDs are assigned and matched with responses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/08_client_server_sessions___clientsession____serversession__.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant ClientApp\n    participant ClientSess as ClientSession\n    participant ServerSess as ServerSession\n    participant ServerTool as Tool Function (e.g., add_numbers)\n\n    ClientApp->>+ClientSess: call_tool(\"add\", {num1: 15, num2: 27})\n    ClientSess->>ClientSess: Assign Request ID (e.g., 1)\n    ClientSess->>ClientSess: Store 'waiter' for ID 1\n    ClientSess->>+ServerSess: Send CallToolRequest (ID=1, method=\"tools/call\", params={...})\n    ServerSess->>ServerSess: Receive request ID=1\n    ServerSess->>+ServerTool: Dispatch request to tool handler\n    ServerTool-->>-ServerSess: Return result (e.g., 42)\n    ServerSess->>-ClientSess: Send CallToolResult (ID=1, result={content: [{\"type\": \"text\", \"text\": \"42\"}]})\n    ClientSess->>ClientSess: Receive response ID=1\n    ClientSess->>ClientSess: Match ID=1 to 'waiter'\n    ClientSess-->>-ClientApp: Return result (CallToolResult object)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Client-LLM Communication Flow with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram illustrating the flow of data from agent logic through the ChatCompletionClient, formatter, HTTP client, and LLM API. The diagram shows how requests are formatted, sent to external APIs, and how responses are parsed and returned.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent as Agent Logic\n    participant Client as ChatCompletionClient\n    participant Formatter as API Formatter\n    participant HTTP as HTTP Client\n    participant LLM_API as External LLM API\n\n    Agent->>+Client: create(messages, tools)\n    Client->>+Formatter: Format messages & tools for specific API (e.g., OpenAI JSON format)\n    Formatter-->>-Client: Return formatted request body\n    Client->>+HTTP: Send POST request to LLM API endpoint with formatted body & API Key\n    HTTP->>+LLM_API: Transmit request over network\n    LLM_API->>LLM_API: Process request, generate completion/function call\n    LLM_API-->>-HTTP: Return API response (e.g., JSON)\n    HTTP-->>-Client: Receive HTTP response\n    Client->>+Formatter: Parse API response (extract content, usage, finish_reason)\n    Formatter-->>-Client: Return parsed data\n    Client->>Client: Create standard CreateResult object\n    Client-->>-Agent: Return CreateResult\n```\n\n----------------------------------------\n\nTITLE: Configuring Celery Using Environment Variables\nDESCRIPTION: Setting Celery configuration through environment variables in the terminal. This approach is useful for deployments where you might want to change settings without modifying code.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# In your terminal (Linux/macOS)\nexport CELERY_BROKER_URL='amqp://guest:guest@localhost:5672//'\nexport CELERY_RESULT_BACKEND='redis://localhost:6379/2'\n\n# Now run your Python script or Celery worker\npython your_script.py\n# or\n# celery -A your_app_module worker --loglevel=info\n```\n\n----------------------------------------\n\nTITLE: ComponentModel JSON Output for ListMemory\nDESCRIPTION: This JSON structure represents the saved configuration of a ListMemory instance, including its provider, component type, version, and specific settings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"provider\": \"autogen_core.memory.ListMemory\",\n  \"component_type\": \"memory\",\n  \"version\": 1,\n  \"component_version\": 1,\n  \"description\": \"ListMemory stores memory content in a simple list.\",\n  \"label\": \"ListMemory\",\n  \"config\": {\n    \"name\": \"user_prefs_v1\",\n    \"memory_contents\": [\n      {\n        \"content\": \"Use formal style\",\n        \"mime_type\": \"text/plain\",\n        \"metadata\": null\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Expected API Response for Background Task Endpoint (JSON)\nDESCRIPTION: Illustrates the JSON response returned immediately by the `/send-notification` endpoint after a successful request. The background task execution happens *after* this response is sent to the client.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\"message\":\"Notification sent successfully!\"}\n```\n\n----------------------------------------\n\nTITLE: Orchestrating Context Retrieval in CrewAI - ContextualMemory (Python)\nDESCRIPTION: This snippet is from crewai/memory/contextual/contextual_memory.py and defines the ContextualMemory class, which orchestrates memory lookups from ShortTermMemory, LongTermMemory, and EntityMemory. The build_context_for_task method synthesizes context by querying each memory type and assembling their results as an augmented prompt context. Dependencies include CrewAI memory modules. Inputs are task and context; outputs are context-augmented strings.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/07_memory.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crewai/memory/contextual/contextual_memory.py\\nclass ContextualMemory:\\n    def __init__(self, stm: ShortTermMemory, ltm: LongTermMemory, em: EntityMemory, ...):\\n        self.stm = stm\\n        self.ltm = ltm\\n        self.em = em\\n        # ...\\n\\n    def build_context_for_task(self, task, context) -> str:\\n        query = f\\\"{task.description} {context}\\\".strip()\\n        if not query: return \\\"\\\"\\n\\n        memory_context = []\\n        # Fetch relevant info from Short Term Memory\\n        memory_context.append(self._fetch_stm_context(query))\\n        # Fetch relevant info from Entity Memory\\n        memory_context.append(self._fetch_entity_context(query))\\n        # Fetch relevant info from Long Term Memory (if applicable)\\n        # memory_context.append(self._fetch_ltm_context(task.description))\\n\\n        return \\\"\\\\n\\\".join(filter(None, memory_context))\\n\\n    def _fetch_stm_context(self, query) -> str:\\n        stm_results = self.stm.search(query)\\n        # ... format results ...\\n        return formatted_results if stm_results else \\\"\\\"\\n\\n    def _fetch_entity_context(self, query) -> str:\\n        em_results = self.em.search(query)\\n        # ... format results ...\\n        return formatted_results if em_results else \\\"\\\"\\n\n```\n\n----------------------------------------\n\nTITLE: Demonstration of Passage Retrieval in Python\nDESCRIPTION: Shows how to retrieve and print passages using DSPy's retrieval functionality, including formatting and handling of retrieved passages.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"Query: {query}\")\nprint(f\"Retrieved Passages (Top {k}):\")\nfor i, passage in enumerate(retrieved_passages):\n    print(f\"--- Passage {i+1} ---\")\n    print(passage.long_text)\n```\n\n----------------------------------------\n\nTITLE: Loading and Applying Configuration in CLI Entry Point (TypeScript)\nDESCRIPTION: Shows how the CLI entry point loads configuration using loadConfig and merges it with command-line arguments. The code demonstrates how user settings are combined with runtime flags and environment variables before being passed to the main App component.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/cli.tsx (Simplified)\n\nimport { loadConfig } from \"./utils/config\";\nimport App from \"./app\";\n// ... other imports: React, render, meow ...\n\n// --- Get command line arguments ---\nconst cli = meow(/* ... cli setup ... */);\nconst prompt = cli.input[0];\nconst modelOverride = cli.flags.model; // e.g., --model gpt-4\n\n// --- Load Configuration ---\n// loadConfig handles reading files and combining instructions\nlet config = loadConfig(\n  undefined, // Use default config file paths\n  undefined, // Use default instructions file paths\n  {\n    cwd: process.cwd(), // Where are we running from? (for project docs)\n    disableProjectDoc: Boolean(cli.flags.noProjectDoc), // Did user pass --no-project-doc?\n    projectDocPath: cli.flags.projectDoc as string | undefined, // Explicit project doc?\n  }\n);\n\n// --- Apply Overrides ---\n// Command-line flags take precedence over config file settings\nconfig = {\n  ...config, // Start with loaded config\n  model: modelOverride ?? config.model, // Use flag model if provided, else keep loaded one\n  apiKey: process.env[\"OPENAI_API_KEY\"] || \"\", // Get API key from environment\n};\n\n// --- Check Model Support ---\n// ... check if config.model is valid ...\n\n// --- Render the App ---\n// Pass the final, combined config object to the main UI component\nconst instance = render(\n  <App\n    prompt={prompt}\n    config={config} // Use the loaded and merged configuration\n    // ... other props: approvalPolicy, etc. ...\n  />,\n);\n```\n\n----------------------------------------\n\nTITLE: Ordering Tutorial Chapters Based on Concept Dependency - Python\nDESCRIPTION: This node determines a pedagogically sound order for presenting abstractions as tutorial chapters. It leverages concept indices, relationship descriptions, and project summaries to guide an LLM in establishing foundational and dependent concepts using YAML output. The process ensures that each abstraction appears exactly once and supports translated names and labels. All context and outputs are tracked via the shared store.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `abstractions`, `relationships`, `project_name`, and `language` from the shared store. Prepare context including the list of `index # AbstractionName` (potentially translated) and textual descriptions of relationships referencing indices and using the potentially translated `label`. Note in context if summary/names might be translated.\n        *   `exec`: Construct a prompt for `call_llm` asking it to order the abstractions based on importance, foundational concepts, or dependencies. Request output as an ordered YAML list of `index # AbstractionName`. Parse and validate, extracting only the indices and ensuring all are present exactly once.\n        *   `post`: Write the validated ordered list of indices (`chapter_order`) to the shared store.\n```\n\n----------------------------------------\n\nTITLE: Applying VersionEdits in LevelDB (C++)\nDESCRIPTION: Implementation of VersionSet::LogAndApply method, which applies a VersionEdit to update the database state. It creates a new Version, writes changes to the MANIFEST file, and installs the new version as the current one.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/06_version___versionset.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\nStatus VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n  // 1. Fill in metadata in the edit (log number, sequence number etc.)\n  // ... set edit->log_number_, edit->last_sequence_, etc. ...\n\n  // 2. Create a new Version based on the current one + the edit\n  Version* v = new Version(this);\n  {\n    Builder builder(this, current_); // Builder starts with 'current_' state\n    builder.Apply(edit);             // Apply the changes described by 'edit'\n    builder.SaveTo(v);               // Save the resulting state into 'v'\n  }\n  Finalize(v); // Calculate compaction score/level for the new version\n\n  // 3. Write the edit to the MANIFEST file (for persistence)\n  std::string record;\n  edit->EncodeTo(&record); // Serialize the VersionEdit\n\n  // Unlock mutex while writing to disk (can be slow)\n  mu->Unlock();\n  Status s = descriptor_log_->AddRecord(record); // Append edit to MANIFEST log\n  if (s.ok()) {\n    s = descriptor_file_->Sync(); // Ensure MANIFEST write is durable\n  }\n  // ... handle MANIFEST write errors ...\n  mu->Lock(); // Re-lock mutex\n\n  // 4. Install the new version as the 'current' one\n  if (s.ok()) {\n    AppendVersion(v); // Make 'v' the new current_ version\n    // Update VersionSet's metadata based on the edit\n    log_number_ = edit->log_number_;\n    prev_log_number_ = edit->prev_log_number_;\n  } else {\n    delete v; // Discard the new version if MANIFEST write failed\n  }\n\n  return s;\n}\n```\n\n----------------------------------------\n\nTITLE: Example Prompt Format for Completion Language Models\nDESCRIPTION: Illustrates the typical single-string prompt format expected by older completion-based Language Models (like GPT-3 davinci). This format combines instructions, field definitions, and the specific input instance into one text block, ending where the model should start its generation. The `${text}` and `${summary}` placeholders represent where DSPy would insert the input text and where the model should generate the output, respectively.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nSummarize the given text.\n\n---\n\nFollow the following format.\n\nText: ${text}\nSummary: ${summary}\n\n---\n\nText: DSPy is a framework for programming foundation models...\nSummary: \n```\n\n----------------------------------------\n\nTITLE: Generating JSON Schema with TypeAdapter in Python\nDESCRIPTION: Shows how to use TypeAdapter's json_schema() method to generate a JSON Schema for the handled type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/06_typeadapter.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Using our user_id_list_adapter from before...\n# UserIdListType = List[PositiveInt]\n# user_id_list_adapter = TypeAdapter(UserIdListType)\n\nschema = user_id_list_adapter.json_schema()\n\nimport json\nprint(f\"\\nJSON Schema:\\n{json.dumps(schema, indent=2)}\")\n# Expected Output:\n# JSON Schema:\n# {\n#   \"items\": {\n#     \"exclusiveMinimum\": 0,\n#     \"type\": \"integer\"\n#   },\n#   \"title\": \"List[PositiveInt]\",\n#   \"type\": \"array\"\n# }\n```\n\n----------------------------------------\n\nTITLE: Internal Key Structure Diagram for LevelDB\nDESCRIPTION: A diagram showing how user keys are transformed into internal keys with sequence numbers and types, and how they are stored and sorted in LevelDB.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TB\n    A[User Application] --> |\"Put('key', 'value')\"| B(LevelDB)\n    B --> |\"Assigns Seq=10\"| C{Internal Operation}\n    C --> |\"Creates\"| D[InternalKey String]\n    \n    D --> I{Storage}\n    \n    subgraph \"Key Components\"\n    D --- E[\"InternalKey Structure\"]\n    E --> E1[\"User Key\"]\n    E --> E2[\"8-byte Tag\"]\n    E2 --> G[\"Seq # (56 bits)\"]\n    E2 --> H[\"Type (8 bits)\"]\n    end\n    \n    subgraph \"Sort Order\"\n    I --> J[\"By User Key\"]\n    J --> K[\"By Sequence DESC\"]\n    K --> L[\"By Type DESC\"]\n    end\n```\n\n----------------------------------------\n\nTITLE: Implementing Celery Beat Scheduler's Tick Method in Python\nDESCRIPTION: A simplified conceptual implementation of the Scheduler.tick() method that powers Celery Beat's main loop. It checks which tasks are due to run, sends them to the broker, and calculates sleep time until the next task.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified conceptual logic of Scheduler.tick()\n\ndef tick(self):\n    remaining_times = []\n    due_tasks = []\n\n    # 1. Iterate through schedule entries\n    for entry in self.schedule.values(): # self.schedule reads from PersistentScheduler._store['entries']\n        # 2. Check if entry is due using its schedule object (e.g., crontab)\n        is_due, next_time_to_run = entry.is_due() # Calls schedule.is_due(entry.last_run_at)\n\n        if is_due:\n            due_tasks.append(entry)\n        else:\n            remaining_times.append(next_time_to_run) # Store time until next check\n\n    # 3. Apply due tasks (send message to broker)\n    for entry in due_tasks:\n        self.apply_entry(entry) # Sends task message and updates entry's last_run_at in schedule store\n\n    # 4. Calculate minimum sleep time until next event\n    return min(remaining_times + [self.max_interval])\n```\n\n----------------------------------------\n\nTITLE: Successful Response Example for Existing Unicorn (JSON)\nDESCRIPTION: Shows the structure of a standard success JSON response returned by the FastAPI endpoint when a unicorn is found. This output occurs when no exceptions are raised within the route handler.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\"unicorn_name\": \"sparklehoof\", \"message\": \"Unicorn exists!\"}\n```\n\n----------------------------------------\n\nTITLE: Rendering Jinja2 Templates with Data in Flask Python\nDESCRIPTION: This Python snippet demonstrates how to use Flask's `render_template` function to render an HTML template (`hello.html`). It imports `render_template`, defines two routes (`/` and `/user/<username>`), and in each route, calls `render_template` specifying the template file name and passing data as keyword arguments. The keyword argument name (`name_in_template`) corresponds to the variable placeholder used within the Jinja2 template.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\n\n# Make sure 'request' is imported if you use it elsewhere,\n# otherwise remove it for this example.\nfrom flask import Flask, render_template\n\napp = Flask(__name__)\n\n# Route for the homepage\n@app.route('/')\ndef index():\n  # The name we want to display in the template\n  user_name = \"World\"\n  # Render the template, passing the user_name as a variable\n  # The key on the left ('name_in_template') is how we access it in HTML.\n  # The value on the right (user_name) is the Python variable.\n  return render_template('hello.html', name_in_template=user_name)\n\n# NEW Route to greet a specific user using the same template\n@app.route('/user/<username>')\ndef greet_user(username):\n  # Here, 'username' comes from the URL\n  # We still use 'name_in_template' as the key for the template\n  return render_template('hello.html', name_in_template=username)\n\n# Code to run the app (from Chapter 1)\nif __name__ == '__main__':\n  app.run(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Context Management Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram showing the interaction flow between Agent Logic, ChatCompletionContext, and the Internal Message List. It illustrates how messages are added to the context and how message retrieval works according to different strategies.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent as Agent Logic\n    participant Context as ChatCompletionContext\n    participant FullHistory as Internal Message List\n\n    Agent->>+Context: add_message(newMessage)\n    Context->>+FullHistory: Append newMessage to list\n    FullHistory-->>-Context: List updated\n    Context-->>-Agent: Done\n\n    Agent->>+Context: get_messages()\n    Context->>+FullHistory: Read the full list\n    FullHistory-->>-Context: Return full list\n    Context->>Context: Apply Strategy (e.g., slice list for Buffered/HeadTail)\n    Context-->>-Agent: Return selected list of messages\n```\n\n----------------------------------------\n\nTITLE: Tracking Agent Step Metrics with a Monitor Class in Python\nDESCRIPTION: This code defines a Monitor class to record and report metrics (step durations, input/output tokens) for each agent step. It uses callback hooks to integrate into the agent flow, accessing token usage data from the agent's model and step duration from the step log. Requires references to ActionStep, Model, and AgentLogger objects. Invoked after each step completion, it prints metrics at the specified log level (typically DEBUG). Prerequisites include proper model instrumentation for token counting and agent architecture supporting callback registration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/08_agentlogger___monitor.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# --- File: monitoring.py (Simplified Monitor) ---\\nfrom .memory import ActionStep # Needs access to step data\\nfrom .models import Model # Needs access to model token counts\\nfrom .monitoring import AgentLogger, LogLevel # Uses the logger to print\\n\\nclass Monitor:\\n    def __init__(self, tracked_model: Model, logger: AgentLogger):\\n        self.step_durations = []\\n        self.tracked_model = tracked_model # Reference to the agent's model\\n        self.logger = logger # Uses the logger to output metrics\\n        self.total_input_token_count = 0\\n        self.total_output_token_count = 0\\n        # ... potentially other metrics ...\\n\\n    def reset(self):\\n        \\\"\\\"\\\"Resets metrics for a new run.\\\"\\\"\\\"\\n        self.step_durations = []\\n        self.total_input_token_count = 0\\n        self.total_output_token_count = 0\\n\\n    def update_metrics(self, step_log: ActionStep):\\n        \\\"\\\"\\\"Callback function called after each step.\\\"\\\"\\\"\\n        # 1. Get duration from the step log\\n        step_duration = step_log.duration\\n        self.step_durations.append(step_duration)\\n\\n        console_outputs = f\"[Step {len(self.step_durations)}: Duration {step_duration:.2f} seconds\"\\n\\n        # 2. Get token counts from the model (if available)\\n        input_tokens = getattr(self.tracked_model, \"last_input_token_count\", None)\\n        output_tokens = getattr(self.tracked_model, \"last_output_token_count\", None)\\n\\n        if input_tokens is not None and output_tokens is not None:\\n            self.total_input_token_count += input_tokens\\n            self.total_output_token_count += output_tokens\\n            # 4. Format metrics string\\n            console_outputs += (\\n                f\"| Input tokens: {self.total_input_token_count:,}\"\\n                f\" | Output tokens: {self.total_output_token_count:,}\"\\n            )\\n        console_outputs += \"]\"\\n\\n        # 5. Log metrics using the logger (at DEBUG level)\\n        self.logger.log(console_outputs, level=LogLevel.DEBUG) # Note: logs at DEBUG\\n\\n    # ... methods to get totals, averages etc. ...\n```\n\n----------------------------------------\n\nTITLE: Initializing StateGraph Class in Python\nDESCRIPTION: Implementation of the StateGraph constructor that initializes a graph by storing the state schema, analyzing it to understand state keys, and setting up internal structures for state management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view\nclass StateGraph(Graph):\n    def __init__(self, state_schema: Optional[Type[Any]] = None, ...):\n        super().__init__()\n        # ... stores the state_schema ...\n        self.schema = state_schema\n        # ... analyzes the schema to understand state keys and how to update them ...\n        self._add_schema(state_schema)\n        # ... sets up internal dictionaries for channels, nodes etc. ...\n```\n\n----------------------------------------\n\nTITLE: Passing List Data for Looping in Flask Python\nDESCRIPTION: This Python snippet adds a route `/items` to a Flask application. It defines a list of strings (`item_list`) and passes this list to the `items.html` template using `render_template`. The data is passed under the context variable name `items`, intended for iteration within the template.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (add this route)\n\n@app.route('/items')\ndef show_items():\n  item_list = ['Apple', 'Banana', 'Cherry']\n  return render_template('items.html', items=item_list)\n\n# ... (keep other routes and run code)\n```\n\n----------------------------------------\n\nTITLE: Initializing CodeAgent with a Python Executor in Python\nDESCRIPTION: This snippet shows the `__init__` and `create_python_executor` methods of the `CodeAgent`. It accepts configuration parameters like `executor_type` and `executor_kwargs` to dynamically instantiate the appropriate executor class (`LocalPythonExecutor`, `DockerExecutor`, or `E2BExecutor`). After creation, it sends initial state and tools to the executor instance using `send_variables` and `send_tools`. Dependencies include the executor classes (`LocalPythonExecutor`, `DockerExecutor`, `E2BExecutor`, `PythonExecutor`) and potentially types like `Optional`, `Dict`, `Any`, `List` from `typing`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/06_pythonexecutor.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified CodeAgent __init__) ---\nfrom .local_python_executor import LocalPythonExecutor, PythonExecutor\nfrom .remote_executors import DockerExecutor, E2BExecutor\n\nclass CodeAgent(MultiStepAgent):\n    def __init__(\n        self,\n        # ... model, tools, etc. ...\n        executor_type: str | None = \"local\", # Default is local\n        executor_kwargs: Optional[Dict[str, Any]] = None,\n        additional_authorized_imports: Optional[List[str]] = None,\n        max_print_outputs_length: Optional[int] = None,\n        # ... other kwargs ...\n    ):\n        # ... setup basic agent parts ...\n        self.executor_type = executor_type or \"local\"\n        self.executor_kwargs = executor_kwargs or {}\n        self.additional_authorized_imports = additional_authorized_imports or []\n        self.max_print_outputs_length = max_print_outputs_length\n\n        # Create the appropriate executor instance based on type\n        self.python_executor: PythonExecutor = self.create_python_executor()\n\n        # ... rest of setup ...\n        # Send initial state/tools to executor if needed\n        if getattr(self, \"python_executor\", None):\n            self.python_executor.send_variables(variables=self.state)\n            self.python_executor.send_tools({**self.tools, **self.managed_agents})\n\n\n    def create_python_executor(self) -> PythonExecutor:\n        \"\"\"Helper method to create the executor instance.\"\"\"\n        match self.executor_type:\n            case \"e2b\":\n                return E2BExecutor(self.additional_authorized_imports, self.logger, **self.executor_kwargs)\n            case \"docker\":\n                return DockerExecutor(self.additional_authorized_imports, self.logger, **self.executor_kwargs)\n            case \"local\":\n                return LocalPythonExecutor(\n                    self.additional_authorized_imports,\n                    max_print_outputs_length=self.max_print_outputs_length,\n                )\n            case _:\n                raise ValueError(f\"Unsupported executor type: {self.executor_type}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Default Model in Codex Configuration File\nDESCRIPTION: Sample YAML configuration file (~/.codex/config.yaml) that sets the default AI model to gpt-4o and demonstrates error handling options in full-auto mode. This allows users to avoid repeatedly specifying the model via command-line flags.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# File: ~/.codex/config.yaml\n\n# Use the gpt-4o model by default for all Codex runs\nmodel: gpt-4o\n\n# Optional: How to handle errors when running commands in full-auto\n# fullAutoErrorMode: ask-user # (Default) Ask user what to do\n# fullAutoErrorMode: ignore-and-continue # Don't stop on error\n```\n\n----------------------------------------\n\nTITLE: Flow Visualization with Mermaid Sequence Diagram\nDESCRIPTION: Sequence diagram showing the interaction flow between User, Predict module, Adapter, LM Client, and LM API when executing a summarization request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_10\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant PredictMod as dspy.Predict (summarizer)\n    participant Adapter as Adapter (e.g., ChatAdapter)\n    participant LMClient as LM Client (e.g., turbo)\n    participant LMApi as Actual LM API\n\n    User->>PredictMod: Call summarizer(text=...)\n    PredictMod->>Adapter: __call__(lm=LMClient, signature, demos, inputs)\n    Adapter->>Adapter: format(signature, demos, inputs)\n    Adapter-->>Adapter: Return formatted_messages (list)\n    Adapter->>LMClient: __call__(messages=formatted_messages)\n    LMClient->>LMApi: Send API Request\n    LMApi-->>LMClient: Return raw_completion_text\n    LMClient-->>Adapter: Return raw_completion_text\n    Adapter->>Adapter: parse(signature, raw_completion_text)\n    Adapter-->>Adapter: Return parsed_output (dict)\n    Adapter-->>PredictMod: Return list[parsed_output]\n    PredictMod->>PredictMod: Create Prediction object(s)\n    PredictMod-->>User: Return Prediction object(s)\n```\n\n----------------------------------------\n\nTITLE: Illustrating Execution Flow of a DSPy RAG Program (Mermaid Diagram)\nDESCRIPTION: This Mermaid sequence diagram visualizes the step-by-step execution flow when a user calls a DSPy RAG program with a question. It shows how the user interacts with the main RAG program's forward method, which internally calls sub-modules for query generation, context retrieval, and answer generation. This diagram helps illustrate the orchestration of modules and their data dependencies within a DSPy Program.\nDependencies: Mermaid diagram rendering engine. Inputs include user questions; outputs follow module returns.\nLimitations: No executable code; for documentation and mental modeling only.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/01_module___program.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant User\\n    participant RAGProgram as RAG Program (forward)\\n    participant GenQuery as GenerateQuery (forward)\\n    participant Retrieve as RetrieveContext (forward)\\n    participant GenAnswer as GenerateAnswer (forward)\\n\\n    User->>RAGProgram: Call with \\\"What is DSPy?\\\"\\n    RAGProgram->>GenQuery: Call with question=\\\"What is DSPy?\\\"\\n    GenQuery-->>RAGProgram: Return \\\"search query...\\\"\\n    RAGProgram->>Retrieve: Call with query=\\\"search query...\\\"\\n    Retrieve-->>RAGProgram: Return \\\"Relevant context...\\\"\\n    RAGProgram->>GenAnswer: Call with question, context\\n    GenAnswer-->>RAGProgram: Return \\\"Final answer...\\\"\\n    RAGProgram-->>User: Return \\\"Final answer...\\\"\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of AsyncWebCrawler in Python\nDESCRIPTION: Demonstrates how to use AsyncWebCrawler to crawl a single URL using the arun method within an async context manager. It shows how to handle the result and access basic information from the crawl.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/02_asyncwebcrawler.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# chapter2_example_1.py\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler # Import the General Manager\n\nasync def main():\n    # Create the General Manager instance using 'async with'\n    # This handles setup (like starting a browser if needed)\n    # and cleanup (closing the browser).\n    async with AsyncWebCrawler() as crawler:\n        print(\"Crawler is ready!\")\n\n        # Tell the manager to crawl a specific URL\n        url_to_crawl = \"https://httpbin.org/html\" # A simple example page\n        print(f\"Asking the crawler to fetch: {url_to_crawl}\")\n\n        result = await crawler.arun(url=url_to_crawl)\n\n        # Check if the crawl was successful\n        if result.success:\n            print(\"\\nSuccess! Crawler got the content.\")\n            # The result object contains the processed data\n            # We'll learn more about CrawlResult in Chapter 7\n            print(f\"Page Title: {result.metadata.get('title', 'N/A')}\")\n            print(f\"First 100 chars of Markdown: {result.markdown.raw_markdown[:100]}...\")\n        else:\n            print(f\"\\nFailed to crawl: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing Conceptual Host Agent Orchestration Logic in Python\nDESCRIPTION: This conceptual Python class, `HostAgentLogic`, demonstrates how a Host Agent orchestrates tasks across multiple downstream agents. It initializes `RemoteAgentConnection` instances for known agents (Joke, Summarizer). The `handle_user_request` method analyzes the input text, identifies relevant tasks (joke, summarize), creates `TaskSendParams`, uses `asyncio.gather` to concurrently send tasks via the `RemoteAgentConnection` helpers, awaits their completion, and combines the results into a final response. It relies on `asyncio`, `uuid`, `common.types` (`Message`, `TextPart`, `TaskSendParams`), and the `RemoteAgentConnection` class.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/08_multi_agent_orchestration__host_agent_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual Host Agent Logic\nimport asyncio\nfrom common.types import Message, TextPart, TaskSendParams\nimport uuid\n\nclass HostAgentLogic:\n    def __init__(self):\n        # Assume agent cards are loaded somehow\n        joke_agent_card = AgentCard(name=\"Joke Agent\", url=\"http://joke-agent.com/a2a\", ...)\n        summary_agent_card = AgentCard(name=\"Summarizer Agent\", url=\"http://summary-agent.com/a2a\", ...)\n\n        # Create connections to downstream agents\n        self.remote_connections = {\n            \"Joke Agent\": RemoteAgentConnection(joke_agent_card),\n            \"Summarizer Agent\": RemoteAgentConnection(summary_agent_card),\n        }\n        print(\"Host Agent initialized with remote connections.\")\n\n    async def handle_user_request(self, user_request_text: str):\n        print(f\"Host received user request: {user_request_text}\")\n        # Super simplified logic: If \"joke\" in request, call Joke Agent.\n        # If \"summarize\" in request, call Summarizer Agent.\n\n        tasks_to_run = []\n        if \"joke\" in user_request_text.lower():\n            joke_conn = self.remote_connections[\"Joke Agent\"]\n            joke_params = TaskSendParams(\n                id=str(uuid.uuid4()),\n                message=Message(role=\"user\", parts=[TextPart(text=\"Tell joke\")])\n            )\n            # Add the task-sending coroutine to the list\n            tasks_to_run.append(joke_conn.send_task_to_remote(joke_params))\n\n        if \"summarize\" in user_request_text.lower():\n            # (Assume article_text is extracted from user_request_text)\n            article_text = \"This is the article to summarize...\"\n            summary_conn = self.remote_connections[\"Summarizer Agent\"]\n            summary_params = TaskSendParams(\n                id=str(uuid.uuid4()),\n                message=Message(role=\"user\", parts=[TextPart(text=article_text)])\n            )\n            tasks_to_run.append(summary_conn.send_task_to_remote(summary_params))\n\n        # Run the downstream tasks concurrently\n        print(f\"Host dispatching {len(tasks_to_run)} tasks...\")\n        results = await asyncio.gather(*tasks_to_run)\n        print(\"Host gathered results from downstream agents.\")\n\n        # Combine results (simplified)\n        final_response = \"\"\n        for task_result in results:\n            if task_result.status.message and task_result.status.message.parts:\n                final_response += task_result.status.message.parts[0].text + \"\\n\"\n\n        print(f\"Host final response: {final_response}\")\n        return final_response\n\n# --- Example Usage ---\n# async def main():\n#     host = HostAgentLogic()\n#     await host.handle_user_request(\"Tell me a joke and summarize stuff.\")\n```\n\n----------------------------------------\n\nTITLE: NumPy Array Addition with ufuncs\nDESCRIPTION: Shows two equivalent ways to add NumPy arrays: using the np.add ufunc directly and using the + operator which calls the same underlying C implementation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/07_umath_module.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\na = np.array([1, 2, 3])\nb = np.array([10, 20, 30])\n\n# Calling the ufunc np.add\nresult1 = np.add(a, b) # Triggers the C implementation for addition\n\n# Using the operator '+' which also calls np.add for arrays\nresult2 = a + b        # Also triggers the C implementation\n\nprint(f\"Using np.add: {result1}\")\nprint(f\"Using + operator: {result2}\")\n```\n\n----------------------------------------\n\nTITLE: Creating Topic IDs for Research Results\nDESCRIPTION: Example of creating a TopicId instance for research facts, demonstrating how to structure topic identifiers for specific research tasks.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/02_messaging_system__topic___subscription_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom autogen_core import TopicId\n\nresearch_topic_id = TopicId(type=\"research.facts.available\", source=\"blog-post-autogen\")\n\nprint(f\"Topic ID: {research_topic_id}\")\n```\n\n----------------------------------------\n\nTITLE: Conceptual Representation of Core Schema in Python\nDESCRIPTION: A simplified example showing what a Core Schema might look like for a field and a model. This is a conceptual representation to illustrate the structure, not actual Pydantic code.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual representation - the actual structure is more complex!\nname_field_schema = {\n  'type': 'str',          # The basic type expected\n  'min_length': 3,        # Constraint from Field(min_length=3)\n  'strict': False,        # Default strictness mode from config\n  'strip_whitespace': None # Default string handling from config\n  # ... other settings relevant to strings\n}\n\n# A schema for a whole model wraps field schemas:\nmodel_schema = {\n    'type': 'model',\n    'cls': YourModelClass, # Reference to the Python class\n    'schema': {\n        'type': 'model-fields',\n        'fields': {\n            'name': { 'type': 'model-field', 'schema': name_field_schema },\n            # ... schema for other fields ...\n        },\n        # ... details about custom model validators ...\n    },\n    'config': { # Merged config settings\n        'title': 'YourModelClass',\n        'extra_behavior': 'ignore',\n        'frozen': False,\n        # ...\n    },\n    # ... details about custom serializers ...\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Agent's Main Run Loop in Python\nDESCRIPTION: The run method of the Agent class, orchestrating the main loop. It repeatedly calls the step method until the task is done, an error occurs, or max_steps is reached.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/01_agent.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass Agent:\n    # ... (init) ...\n    async def run(self, max_steps: int = 100) -> AgentHistoryList:\n        self._log_agent_run() # Log start event\n        try:\n            for step_num in range(max_steps):\n                if self.state.stopped or self.state.consecutive_failures >= self.settings.max_failures:\n                    break # Stop conditions\n\n                # Wait if paused\n                while self.state.paused: await asyncio.sleep(0.2)\n\n                step_info = AgentStepInfo(step_number=step_num, max_steps=max_steps)\n                await self.step(step_info) # <<< Execute one step of the loop\n\n                if self.state.history.is_done():\n                    await self.log_completion() # Log success/failure\n                    break # Exit loop if agent signaled 'done'\n            else:\n                logger.info(\"Max steps reached.\") # Ran out of steps\n\n        finally:\n            # ... (cleanup, telemetry, potentially save history/gif) ...\n            pass\n        return self.state.history # Return the recorded history\n```\n\n----------------------------------------\n\nTITLE: Storing Results in Celery's BaseKeyValueStoreBackend\nDESCRIPTION: This code snippet shows the implementation of the _store_result method in BaseKeyValueStoreBackend. It prepares the result metadata, encodes it, and stores it in the backend using a task-specific key.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef _store_result(self, task_id, result, state,\n                  traceback=None, request=None, **kwargs):\n    # 1. Prepare the metadata dictionary\n    meta = self._get_result_meta(result=result, state=state,\n                                 traceback=traceback, request=request)\n    meta['task_id'] = bytes_to_str(task_id) # Ensure task_id is str\n\n    # (Check if already successfully stored to prevent overwrites - omitted for brevity)\n\n    # 2. Encode the metadata (e.g., to JSON or pickle)\n    encoded_meta = self.encode(meta)\n\n    # 3. Get the specific key for this task\n    key = self.get_key_for_task(task_id) # e.g., b'celery-task-meta-<task_id>'\n\n    # 4. Call the specific backend's 'set' method (implemented by RedisBackend etc.)\n    #    It might also set an expiry time (self.expires)\n    try:\n        self._set_with_state(key, encoded_meta, state) # Calls self.set(key, encoded_meta)\n    except Exception as exc:\n         # Handle potential storage errors, maybe retry\n         raise BackendStoreError(...) from exc\n\n    return result # Returns the original (unencoded) result\n```\n\n----------------------------------------\n\nTITLE: Applying Memory to a Chat Context\nDESCRIPTION: Demonstrates how to use the update_context method to inject relevant memories into a chat context before sending it to an LLM, enabling the agent to utilize previously stored information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# File: update_chat_with_memory.py\nimport asyncio\n# Assume user_prefs_memory exists (with the preference added)\n# Assume new_chat_context exists (empty or with just the new request)\n# Assume new_request exists\n\nasync def main():\n    # --- This is where Memory connects to Chat Context ---\n    print(\"Updating chat context with memory...\")\n    update_result = await user_prefs_memory.update_context(new_chat_context)\n    print(f\"Memories injected: {len(update_result.memories.results)}\")\n\n    # Now let's add the actual user request for this task\n    await new_chat_context.add_message(new_request)\n\n    # See what messages are now in the context\n    messages_for_llm = await new_chat_context.get_messages()\n    print(\"\\nMessages to be sent to LLM:\")\n    for msg in messages_for_llm:\n        print(f\"- [{msg.type}]: {msg.content}\")\n\nasyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Retrieving Entries from MemTable in LevelDB (C++)\nDESCRIPTION: This function retrieves a value from the MemTable by using a SkipList iterator to find the target key. It searches for an exact match of the user key, then returns the associated value if found. The function also handles deletion markers by returning NotFound status when a deletion entry is encountered for the requested key.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/02_memtable.md#2025-04-22_snippet_4\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/memtable.cc ---\n\nbool MemTable::Get(const LookupKey& lkey, std::string* value, Status* s) {\n  // Get the specially formatted key to search for in the MemTable.\n  Slice memkey = lkey.memtable_key();\n\n  // Create an iterator for the SkipList.\n  Table::Iterator iter(&table_);\n\n  // Seek to the first entry >= the key we are looking for.\n  iter.Seek(memkey.data());\n\n  if (iter.Valid()) { // Did we find something at or after our key?\n    // Decode the key found in the SkipList\n    const char* entry = iter.key();\n    // ... decode logic to get user_key, sequence, type ...\n    Slice found_user_key = /* decoded user key */;\n    ValueType found_type = /* decoded type */;\n\n    // Check if the user key matches exactly\n    if (comparator_.comparator.user_comparator()->Compare(\n            found_user_key, lkey.user_key()) == 0) {\n      // It's the right key! Check the type.\n      if (found_type == kTypeValue) { // Is it a Put record?\n        // Decode the value and return it\n        Slice v = /* decoded value */;\n        value->assign(v.data(), v.size());\n        return true; // Found the value!\n      } else { // Must be kTypeDeletion\n        // Found a deletion marker for this key. Report \"NotFound\".\n        *s = Status::NotFound(Slice());\n        return true; // Found a deletion!\n      }\n    }\n  }\n  // Key not found in this MemTable\n  return false;\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Query Parameters from URLs in Flask - Python\nDESCRIPTION: This code sample shows how to retrieve query string parameters from the URL using Flask's request.args attribute in a route handler. It safely fetches the 'query' parameter and returns different responses based on its presence. Required dependencies are Flask and an active app instance. This snippet highlights how GET request parameters are accessed and returned to the user; it handles cases where parameters are missing using conditional logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (continued)\nfrom flask import Flask, request\n\napp = Flask(__name__)\n\n@app.route('/search')\ndef search():\n  # Get the value of the 'query' parameter from the URL\n  # request.args.get() is safer than request.args[] as it returns None if the key doesn't exist\n  search_term = request.args.get('query')\n\n  if search_term:\n    return f'You searched for: {search_term}'\n  else:\n    return 'Please provide a search term using ?query=...'\n\n# ... (rest of the app)\n```\n\n----------------------------------------\n\nTITLE: Directly Querying Memory\nDESCRIPTION: Shows how to use the query method to directly retrieve information from memory without going through a chat context, which can be useful for specific lookups by an agent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# File: query_memory.py\nimport asyncio\n# Assume user_prefs_memory exists\n\nasync def main():\n    # Query the memory (ListMemory returns all items regardless of query text)\n    query_result = await user_prefs_memory.query(\"style preference\")\n    print(\"\\nDirect query result:\")\n    for item in query_result.results:\n        print(f\"- Content: {item.content}, Type: {item.mime_type}\")\n\nasyncio.run(main())\n# Output:\n# Direct query result:\n# - Content: User prefers all communication to be written in a formal style., Type: text/plain\n```\n\n----------------------------------------\n\nTITLE: Visualizing Google A2A Component Interactions using Mermaid\nDESCRIPTION: This Mermaid flowchart illustrates the relationships and data flow between key components of the Google A2A protocol. It depicts how the core A2A Protocol defines structures for Tasks and Agent Cards, how Client and Server implementations interact to send and handle tasks, the role of Streaming (SSE) for updates, and how a Demo UI might orchestrate multi-agent interactions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nflowchart TD\n    A0[\"A2A Protocol & Core Types\"]\n    A1[\"Task\"]\n    A2[\"Agent Card\"]\n    A3[\"A2A Server Implementation\"]\n    A4[\"A2A Client Implementation\"]\n    A5[\"Task Handling Logic (Server-side)\"]\n    A6[\"Streaming Communication (SSE)\"]\n    A7[\"Demo UI Application & Service\"]\n    A8[\"Multi-Agent Orchestration (Host Agent)\"]\n    A0 -- \"Defines Structure For\" --> A1\n    A0 -- \"Defines Structure For\" --> A2\n    A4 -- \"Sends Task Requests To\" --> A3\n    A3 -- \"Delegates Task To\" --> A5\n    A5 -- \"Executes\" --> A1\n    A8 -- \"Uses for Discovery\" --> A2\n    A3 -- \"Sends Updates Via\" --> A6\n    A4 -- \"Receives Updates Via\" --> A6\n    A8 -- \"Acts As\" --> A4\n    A7 -- \"Presents/Manages\" --> A8\n    A7 -- \"Communicates With\" --> A5\n```\n```\n\n----------------------------------------\n\nTITLE: Visualizing click.secho Execution Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram showing the step-by-step process of what happens when click.secho() is called. The diagram illustrates how Click processes styled text through various layers including style formatting, compatibility checks, and terminal output.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/06_term_ui__terminal_user_interface_.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as Your Code\n    participant ClickSecho as click.secho()\n    participant ClickStyle as click.style()\n    participant ClickEcho as click.echo()\n    participant CompatLayer as Click Compatibility Layer\n    participant Terminal\n\n    UserCode->>ClickSecho: secho(\"Error!\", fg='red', err=True)\n    ClickSecho->>ClickStyle: style(\"Error!\", fg='red', ...)\n    ClickStyle-->>ClickSecho: Returns \"\\033[31mError!\\033[0m\" (styled text)\n    ClickSecho->>ClickEcho: echo(\"\\033[31mError!\\033[0m\", err=True)\n    ClickEcho->>CompatLayer: Check if output (stderr) is a TTY\n    CompatLayer-->>ClickEcho: Yes, it's a TTY\n    ClickEcho->>CompatLayer: Check if color is enabled\n    CompatLayer-->>ClickEcho: Yes, color is enabled\n    Note over ClickEcho, Terminal: On Windows, may wrap stream with Colorama here\n    ClickEcho->>CompatLayer: Write styled text to stderr\n    CompatLayer->>Terminal: Writes \"\\033[31mError!\\033[0m\\n\"\n    Terminal-->>Terminal: Displays \"Error!\" in red\n```\n\n----------------------------------------\n\nTITLE: Example Output for Sending A2A Task\nDESCRIPTION: Illustrative console output showing the confirmation message after a client successfully sends a task request to an agent using the provided Python script. It displays the generated unique Task ID and its initial 'submitted' state.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/02_task.md#2025-04-22_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nSending task a1b2c3d4-e5f6-7890-abcd-ef1234567890 to http://translator-agent.com/a2a\nTask created! ID: a1b2c3d4-e5f6-7890-abcd-ef1234567890, State: submitted\n```\n\n----------------------------------------\n\nTITLE: Visualizing Pregel Execution Flow for Adder-Multiplier Graph using Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the step-by-step execution of a simple LangGraph (`adder -> multiplier`) invoked with `{'value': 5}`. It shows how the Pregel engine orchestrates the flow, scheduling nodes (`adder`, `multiplier`), reading state from and writing updates to Channels, and finally returning the result (`{'value': 12}`). The diagram clarifies the interaction between different components during graph execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/05_pregel_execution_engine.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant User\n    participant App as CompiledGraph\n    participant PregelEngine as Pregel Engine\n    participant StateChannels as Channels\n    participant AdderNode as adder\n    participant MultiplierNode as multiplier\n\n    User->>App: invoke({\"value\": 5})\n    App->>PregelEngine: Start Execution\n    PregelEngine->>StateChannels: Initialize state {\"value\": 5}\n    Note over PregelEngine: Step 1\n    PregelEngine->>PregelEngine: Schedule 'adder' (from START)\n    PregelEngine->>StateChannels: Read state ({'value': 5})\n    PregelEngine->>AdderNode: Run add_one({'value': 5})\n    AdderNode-->>PregelEngine: Return {\"value\": 6}\n    PregelEngine->>StateChannels: Apply update {\"value\": 6}\n    StateChannels-->>PregelEngine: State is now {'value': 6}\n    Note over PregelEngine: Step 2\n    PregelEngine->>PregelEngine: Schedule 'multiplier' (from 'adder')\n    PregelEngine->>StateChannels: Read state ({'value': 6})\n    PregelEngine->>MultiplierNode: Run multiply_by_two({'value': 6})\n    MultiplierNode-->>PregelEngine: Return {\"value\": 12}\n    PregelEngine->>StateChannels: Apply update {\"value\": 12}\n    StateChannels-->>PregelEngine: State is now {'value': 12}\n    Note over PregelEngine: Step 3\n    PregelEngine->>PregelEngine: Check edges from 'multiplier' (sees END)\n    PregelEngine->>PregelEngine: No more nodes to schedule. Finish.\n    PregelEngine->>StateChannels: Read final state ({'value': 12})\n    PregelEngine->>App: Return final state {'value': 12}\n    App->>User: Return {'value': 12}\n```\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI Environment Variables for CrewAI Auto-Detection (Bash)\nDESCRIPTION: Demonstrates setting `OPENAI_API_KEY` and `OPENAI_MODEL_NAME` environment variables, typically in a `.env` file. CrewAI (via `litellm`) can automatically detect these variables to configure an OpenAI LLM without explicit code configuration. Requires a valid OpenAI API key. `OPENAI_MODEL_NAME` is optional; if not set, a default (like gpt-4o) is used.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/06_llm.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Example .env file\nOPENAI_API_KEY=\"sk-your_openai_api_key_here\"\n# Optional: Specify the model, otherwise it uses a default like gpt-4o\nOPENAI_MODEL_NAME=\"gpt-4o\"\n```\n\n----------------------------------------\n\nTITLE: Visualizing NumPy Array Creation Process with Mermaid\nDESCRIPTION: A sequence diagram showing the internal process that occurs when creating a NumPy array, including dtype parsing, memory allocation, and data copying.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/02_dtype__data_type_object_.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant P as Python Code (Your script)\n    participant NPF as NumPy Python Func (e.g., np.array)\n    participant C_API as NumPy C API\n    participant DTypeC as C Struct (PyArray_Descr)\n    participant Mem as Memory\n\n    P->>NPF: np.array([1, 2], dtype='int32')\n    NPF->>C_API: Parse dtype string 'int32'\n    C_API->>DTypeC: Create/Find PyArray_Descr for int32 (kind='i', itemsize=4, etc.)\n    C_API->>Mem: Allocate memory (2 items * 4 bytes/item = 8 bytes)\n    C_API->>Mem: Copy data [1, 2] into memory as 32-bit ints\n    C_API-->>NPF: Return C ndarray struct (pointing to Mem and DTypeC)\n    NPF-->>P: Return Python ndarray object wrapping the C struct\n```\n\n----------------------------------------\n\nTITLE: Visualizing StateGraph Execution Flow with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram showing the step-by-step flow of execution in a StateGraph, from user invocation to final state return, illustrating how nodes read from and update the shared state.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant App (CompiledGraph)\n    participant State\n    participant AdderNode as adder\n    participant MultiplierNode as multiplier\n\n    User->>App: invoke({\"value\": 5})\n    App->>State: Initialize state = {\"value\": 5}\n    App->>AdderNode: Execute(state)\n    AdderNode->>State: Read value (5)\n    AdderNode-->>App: Return {\"value\": 6}\n    App->>State: Update state = {\"value\": 6}\n    App->>MultiplierNode: Execute(state)\n    MultiplierNode->>State: Read value (6)\n    MultiplierNode-->>App: Return {\"value\": 12}\n    App->>State: Update state = {\"value\": 12}\n    App->>User: Return final state {\"value\": 12}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the Approval Flow with Mermaid Sequence Diagram\nDESCRIPTION: This diagram illustrates the workflow when the Agent Loop receives an action suggestion from the AI. It shows how the Approval Policy evaluates the action against the current policy settings and either automatically approves it, asks for user confirmation, or rejects it based on the policy rules.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/04_approval_policy___security.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant AgentLoop as Agent Loop\n    participant ApprovalCheck as Approval Policy Check\n    participant UserUI as Terminal UI\n    participant CmdExec as Command Execution\n\n    AgentLoop->>AgentLoop: AI suggests action (e.g., run `npm install`)\n    AgentLoop->>ApprovalCheck: Check action against policy (`auto-edit`)\n    ApprovalCheck->>ApprovalCheck: Action is `npm install` (command)\n    ApprovalCheck->>ApprovalCheck: Policy is `auto-edit` (commands need approval)\n    ApprovalCheck-->>AgentLoop: Decision: `ask-user`\n    AgentLoop->>UserUI: Request confirmation for `npm install`\n    UserUI->>UserUI: Display \"Allow command `npm install`? [Y/n]\"\n    UserUI-->>AgentLoop: User response (e.g., Yes)\n    AgentLoop->>CmdExec: Execute `npm install`\n```\n\n----------------------------------------\n\nTITLE: Visualizing Agent Loop Process with Mermaid Diagram\nDESCRIPTION: A sequence diagram illustrating the interaction between User, Agent, LLM, Controller, and BrowserContext during a task execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/01_agent.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Agent\n    participant LLM\n    participant Controller\n    participant BC as BrowserContext\n\n    User->>Agent: Start task(\"Search Google for cats...\")\n    Note over Agent: Agent Loop Starts\n    Agent->>BC: Get current state (e.g., blank page)\n    BC-->>Agent: Current Page State\n    Agent->>LLM: What's next? (Task + State + History)\n    LLM-->>Agent: Plan: [Action: Type 'cute cat pictures', Action: Press Enter]\n    Agent->>Controller: Execute: type_text(...)\n    Controller->>BC: Perform type action\n    Agent->>Controller: Execute: press_keys('Enter')\n    Controller->>BC: Perform press action\n    Agent->>BC: Get new state (search results page)\n    BC-->>Agent: New Page State\n    Agent->>LLM: What's next? (Task + New State + History)\n    LLM-->>Agent: Plan: [Action: click_element(index=5)]\n    Agent->>Controller: Execute: click_element(index=5)\n    Controller->>BC: Perform click action\n    Note over Agent: Loop continues until done...\n    LLM-->>Agent: Plan: [Action: done(success=True, text='Found cat picture!')]\n    Agent->>Controller: Execute: done(...)\n    Controller-->>Agent: ActionResult (is_done=True)\n    Note over Agent: Agent Loop Ends\n    Agent->>User: Return History (Task Complete)\n```\n\n----------------------------------------\n\nTITLE: Implementing MemorySaver for In-Memory Checkpoint Storage in Python\nDESCRIPTION: A concrete implementation of BaseCheckpointSaver that stores checkpoints in RAM using a dictionary. It provides thread-safe operations for saving and retrieving checkpoints by thread_id.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# checkpoint/memory.py (Highly Simplified)\nimport threading\nfrom collections import defaultdict\n\nclass MemorySaver(BaseCheckpointSaver):\n    def __init__(self):\n        # Use a dictionary to store checkpoints in RAM\n        # Key: thread_id, Value: List of CheckpointTuples\n        self._checkpoints: defaultdict[str, list[CheckpointTuple]] = defaultdict(list)\n        self._lock = threading.RLock() # To handle multiple threads safely\n\n    def get_tuple(self, config: dict) -> Optional[CheckpointTuple]:\n        thread_id = config[\"configurable\"][\"thread_id\"]\n        with self._lock:\n            if checkpoints := self._checkpoints.get(thread_id):\n                # Return the latest checkpoint for this thread_id\n                return checkpoints[-1]\n            return None\n\n    def put(self, config: dict, checkpoint: Checkpoint, metadata: dict) -> dict:\n        thread_id = config[\"configurable\"][\"thread_id\"]\n        with self._lock:\n            # Append the new checkpoint to the list for this thread_id\n            self._checkpoints[thread_id].append(\n                CheckpointTuple(config, checkpoint, metadata)\n            )\n        return {\"configurable\": {\"thread_id\": thread_id}}\n\n    # ... async methods (aget_tuple, aput) are similar using the same dict ...\n    # ... list method iterates through the dictionary ...\n```\n\n----------------------------------------\n\nTITLE: Visualizing ListMemory Context Update Flow with Mermaid\nDESCRIPTION: A sequence diagram illustrating the flow of information when ListMemory updates the chat context, showing how stored memory items are formatted and injected as a SystemMessage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant AgentLogic as Agent Logic\n    participant ListMem as ListMemory\n    participant InternalList as Memory's Internal List\n    participant ChatCtx as ChatCompletionContext\n\n    AgentLogic->>+ListMem: update_context(chat_context)\n    ListMem->>+InternalList: Get all stored MemoryContent items\n    InternalList-->>-ListMem: Return list of [pref_content]\n    alt Memory list is NOT empty\n        ListMem->>ListMem: Format memories into a single string (e.g., \"1. pref_content\")\n        ListMem->>ListMem: Create SystemMessage with formatted string\n        ListMem->>+ChatCtx: add_message(SystemMessage)\n        ChatCtx-->>-ListMem: Context updated\n    end\n    ListMem->>ListMem: Create UpdateContextResult(memories=[pref_content])\n    ListMem-->>-AgentLogic: Return UpdateContextResult\n```\n\n----------------------------------------\n\nTITLE: String Manipulation in Pydantic ConfigDict for Python\nDESCRIPTION: Shows how to use str_strip_whitespace and str_to_lower configuration options to automatically clean and transform string inputs in a Pydantic model.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict\n\nclass Comment(BaseModel):\n    text: str\n    author: str\n\n    model_config = ConfigDict(\n        str_strip_whitespace=True, # Remove leading/trailing whitespace\n        str_to_lower=True          # Convert to lowercase\n    )\n\ncomment_data = {'text': '  Hello World!  ', 'author': ' ALICE '}\ncomment = Comment(**comment_data)\nprint(comment)\n# Expected Output: text='hello world!' author='alice'\n```\n\n----------------------------------------\n\nTITLE: Using Default Values with Field()\nDESCRIPTION: Demonstrates how Pydantic fills in missing fields with default values specified in Field() when creating a model instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    name: str = Field(default='Guest', alias='userName', min_length=3)\n    age: int = Field(default=18, gt=0)\n    email: str | None = Field(default=None, description='The user email address')\n\n# Input data missing name and age\ninput_data_1 = {'email': 'new@example.com'}\n\n# Pydantic uses the defaults!\nuser1 = User(**input_data_1)\nprint(user1)\n# Expected Output: name='Guest' age=18 email='new@example.com'\n```\n\n----------------------------------------\n\nTITLE: Defining AI File Operations Response Schema with Zod - TypeScript\nDESCRIPTION: Defines strict schemas for file operations (`FileOperationSchema`) and for batches of edits (`EditedFilesSchema`) using the Zod validation library, enforcing complete content for modifications and supporting delete/move semantics. Essential dependencies are the `zod` package and any runtime compatible with its TypeScript typings. These schemas are critical for validating and shaping both user and AI-generated structured data in Codex workflows. All validations and type inferences are typed via TypeScript.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/08_single_pass_mode.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/singlepass/file_ops.ts (Simplified)\nimport { z } from \"zod\"; // Zod is a schema validation library\n\n// Schema for a single file operation\nexport const FileOperationSchema = z.object({\n  path: z.string().describe(\"Absolute path to the file.\"),\n  updated_full_content: z.string().optional().describe(\n    \"FULL CONTENT of the file after modification. MUST provide COMPLETE content.\"\n  ),\n  delete: z.boolean().optional().describe(\"Set true to delete the file.\"),\n  move_to: z.string().optional().describe(\"New absolute path if file is moved.\"),\n  // Ensure only one action per operation (update, delete, or move)\n}).refine(/* ... validation logic ... */);\n\n// Schema for the overall response containing a list of operations\nexport const EditedFilesSchema = z.object({\n  ops: z.array(FileOperationSchema).describe(\"List of file operations.\"),\n});\n\nexport type FileOperation = z.infer<typeof FileOperationSchema>;\nexport type EditedFiles = z.infer<typeof EditedFilesSchema>;\n\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Invalid LLM Response with Missing Field in JSON\nDESCRIPTION: This JSON snippet illustrates an invalid response from an LLM where a required field ('index') is missing within a 'click_element' action. The incomplete structure highlights the risks of free-form data exchange and demonstrates why schema validation is essential for robust communication between components. No additional dependencies are required, but this JSON would be passed into a Pydantic model for validation and would fail due to the missing field.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\\n  \"current_state\": { ... },\\n  \"action\": [\\n    {\\n      \"click_element\": {\\n         \"xpath\": \"//button[@id='submit']\" // 'index' is missing!\\n      }\\n    }\\n  ]\\n}\\n\n```\n\n----------------------------------------\n\nTITLE: Response Handling Flow Diagram in Mermaid\nDESCRIPTION: A sequence diagram showing the flow of data between different components when processing an AI response. It illustrates how the Agent Loop, Response Parser, Terminal UI, and Approval Check interact to handle both text and tool call parts of a response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant OpenAI\n    participant AgentLoop as Agent Loop\n    participant Parser as Response Parser\n    participant UI as Terminal UI\n    participant Approval as Approval Check\n\n    OpenAI-->>AgentLoop: Sends structured response (Text + Tool Call)\n    AgentLoop->>Parser: Passes raw response data\n    Parser->>Parser: Extracts Text part (\"Okay...\")\n    Parser-->>AgentLoop: Returns extracted Text\n    AgentLoop->>UI: Sends Text to display (\"onItem\" callback)\n    Parser->>Parser: Extracts Tool Call part (shell, [\"git\", \"status\"])\n    Parser-->>AgentLoop: Returns Tool Name (\"shell\") & Arguments ([\"git\", \"status\"])\n    AgentLoop->>Approval: Sends Tool details for policy check\n    Note over Approval: Next step: Chapter 4/6\n```\n\n----------------------------------------\n\nTITLE: Structuring CreateResult for LLM Response Handling\nDESCRIPTION: Definition of the CreateResult class that standardizes responses from different LLM services. It includes fields for completion content, finish reason, token usage, and a flag indicating whether the result was cached.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/05_chatcompletionclient.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# From: models/_types.py (Simplified)\nfrom pydantic import BaseModel\nfrom dataclasses import dataclass\nfrom typing import Union, List, Optional\nfrom .. import FunctionCall\n\n@dataclass\nclass RequestUsage:\n    prompt_tokens: int\n    completion_tokens: int\n\nFinishReasons = Literal[\"stop\", \"length\", \"function_calls\", \"content_filter\", \"unknown\"]\n\nclass CreateResult(BaseModel):\n    finish_reason: FinishReasons\n    content: Union[str, List[FunctionCall]] # LLM output\n    usage: RequestUsage # Token usage for this call\n    cached: bool\n    # Optional fields like logprobs, thought...\n```\n\n----------------------------------------\n\nTITLE: Workflow Visualization with Mermaid Sequence Diagram\nDESCRIPTION: Sequence diagram showing the interaction flow between user code, DSPy Predict module, LM client, and the actual LM API when making a translation request.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant PredictModule as translator (Predict)\n    participant Settings as dspy.settings\n    participant LMClient as LM Client (e.g., dspy.LM instance)\n    participant ActualAPI as Actual LM API (e.g., Anthropic)\n\n    User->>PredictModule: Call translator(english_sentence=\"...\")\n    PredictModule->>Settings: Get configured lm\n    Settings-->>PredictModule: Return LMClient instance\n    PredictModule->>PredictModule: Format prompt for LM\n    PredictModule->>LMClient: __call__(prompt, **params)\n    LMClient->>LMClient: Check Cache (Cache Miss)\n    LMClient->>ActualAPI: Send formatted API request (prompt, key, params)\n    ActualAPI-->>LMClient: Return API response\n    LMClient->>LMClient: Parse response, extract text\n    LMClient-->>PredictModule: Return generated text\n    PredictModule->>PredictModule: Parse text into output fields\n    PredictModule-->>User: Return Prediction object\n```\n\n----------------------------------------\n\nTITLE: Using Default WebScrapingStrategy in Crawl4AI\nDESCRIPTION: Example code demonstrating how to use the default WebScrapingStrategy in Crawl4AI to crawl and process a webpage, including extraction of metadata, links, and media information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url_to_crawl = \"https://httpbin.org/html\"\n\n        config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n\n        print(f\"Crawling {url_to_crawl} using default scraping strategy...\")\n        result = await crawler.arun(url=url_to_crawl, config=config)\n\n        if result.success:\n            print(\"\\nSuccess! Content fetched and scraped.\")\n            print(f\"Page Title: {result.metadata.get('title', 'N/A')}\")\n            print(f\"Found {len(result.links.internal)} internal links and {len(result.links.external)} external links.\")\n            if result.links.external:\n                print(f\"  Example external link: {result.links.external[0].href}\")\n            print(f\"Found {len(result.media.images)} images.\")\n            if result.media.images:\n                print(f\"  Example image alt text: '{result.media.images[0].alt}'\")\n            print(f\"\\nMarkdown snippet:\\n---\\n{result.markdown.raw_markdown[:200]}...\\n---\")\n        else:\n            print(f\"\\nFailed: {result.error_message}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Testing Custom Validation with Invalid Inputs\nDESCRIPTION: Command-line examples demonstrating how the custom validation callback handles invalid inputs. When zero or negative values are provided for the --count option, the application raises a BadParameter exception with the custom error message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ python count_app_validate.py --count 0 \"Zero?\"\nUsage: count_app_validate.py [OPTIONS] MESSAGE\nTry 'count_app_validate.py --help' for help.\n\nError: Invalid value for '--count': Count must be a positive number.\n\n$ python count_app_validate.py --count -5 \"Negative?\"\nUsage: count_app_validate.py [OPTIONS] MESSAGE\nTry 'count_app_validate.py --help' for help.\n\nError: Invalid value for '--count': Count must be a positive number.\n```\n\n----------------------------------------\n\nTITLE: Encoding and Parsing Internal Keys in LevelDB\nDESCRIPTION: Functions for encoding user keys with sequence numbers and value types into internal keys, and for parsing internal keys back into their components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/dbformat.h --- (Inline functions)\n\n// Combine sequence and type into 8 bytes (64 bits)\nstatic uint64_t PackSequenceAndType(uint64_t seq, ValueType t) {\n  // seq uses upper 56 bits, type uses lower 8 bits\n  return (seq << 8) | t;\n}\n\n// Extract the user_key part from an encoded internal key\ninline Slice ExtractUserKey(const Slice& internal_key) {\n  assert(internal_key.size() >= 8);\n  return Slice(internal_key.data(), internal_key.size() - 8); // All bytes EXCEPT the last 8\n}\n\n// --- File: db/dbformat.cc ---\n\n// Append the encoded internal key to a string 'result'\nvoid AppendInternalKey(std::string* result, const ParsedInternalKey& key) {\n  result->append(key.user_key.data(), key.user_key.size()); // Append user key\n  // Append the 8-byte packed sequence and type\n  PutFixed64(result, PackSequenceAndType(key.sequence, key.type));\n}\n\n// Parse an encoded internal key 'internal_key' into 'result'\nbool ParseInternalKey(const Slice& internal_key, ParsedInternalKey* result) {\n  const size_t n = internal_key.size();\n  if (n < 8) return false; // Must have the 8-byte trailer\n  // Decode the 8-byte trailer\n  uint64_t num = DecodeFixed64(internal_key.data() + n - 8);\n  uint8_t c = num & 0xff; // Lower 8 bits are the type\n  result->sequence = num >> 8; // Upper 56 bits are sequence\n  result->type = static_cast<ValueType>(c);\n  result->user_key = Slice(internal_key.data(), n - 8); // The rest is user key\n  return (c <= static_cast<uint8_t>(kTypeValue)); // Basic validation\n}\n```\n\n----------------------------------------\n\nTITLE: Message Manager Import Statement in Python\nDESCRIPTION: Import statement showing the main message types used by the MessageManager from the langchain_core.messages module. These message types are used to structure the conversation between the agent and the LLM.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agent/message_manager/service.py (Simplified __init__) ---\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n```\n\n----------------------------------------\n\nTITLE: Visualizing Authentication Flow with Sequence Diagram in Mermaid (mermaid)\nDESCRIPTION: This snippet provides a Mermaid sequence diagram to visually detail the interaction steps among various FastAPI components, such as the client, FastAPI app, security scheme instance, verifier function, and route handler, during HTTP Basic authentication. No external dependencies are required beyond a Markdown/Mermaid-compatible renderer. The diagram outlines the flow from the client's request through dependency resolution, credentials extraction, verification, and response. It expects FastAPI's HTTP Basic Auth pattern as described and targets readers familiar with sequence diagram syntax.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/07_security_utilities.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant Client\\n    participant FastAPIApp as FastAPI App\\n    participant HTTPBasicInst as security (HTTPBasic Instance)\\n    participant VerifierFunc as get_current_username\\n    participant PathOpFunc as read_current_user\\n\\n    Client->>+FastAPIApp: GET /users/me (Authorization: Basic ...)\\n    FastAPIApp->>FastAPIApp: Match route, see Security(get_current_username)\\n    FastAPIApp->>FastAPIApp: Resolve get_current_username dependencies: Depends(security)\\n    FastAPIApp->>+HTTPBasicInst: Call security(request)\\n    HTTPBasicInst->>HTTPBasicInst: Read header, decode base64, split user/pass\\n    HTTPBasicInst-->>-FastAPIApp: Return HTTPBasicCredentials(user=\\\"stanley\\\", pass=\\\"...\\\")\\n    FastAPIApp->>+VerifierFunc: Call get_current_username(credentials=...)\\n    VerifierFunc->>VerifierFunc: Check credentials -> OK\\n    VerifierFunc-->>-FastAPIApp: Return username \\\"stanley\\\"\\n    FastAPIApp->>+PathOpFunc: Call read_current_user(username=\\\"stanley\\\")\\n    PathOpFunc-->>-FastAPIApp: Return {\\\"username\\\": \\\"stanley\\\"}\\n    FastAPIApp-->>-Client: Send 200 OK JSON Response\n```\n\n----------------------------------------\n\nTITLE: Task Preparation Implementation in Pregel Engine\nDESCRIPTION: Function that determines which tasks are ready to run in the next step by checking Send commands and channel triggers. Handles both PUSH tasks from explicit Send commands and PULL tasks from edge/trigger updates.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/05_pregel_execution_engine.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef prepare_next_tasks(checkpoint, processes, channels, config, step, ...):\n    tasks = {}\n    # Check PUSH tasks (from Send)\n    for packet in checkpoint[\"pending_sends\"]:\n        # ... create task if node exists ...\n        task = create_task_for_send(packet, ...)\n        tasks[task.id] = task\n\n    # Check PULL tasks (from edges/triggers)\n    for name, proc in processes.items():\n        # Check if any trigger channel for 'proc' was updated since last seen\n        if _triggers(channels, checkpoint[\"channel_versions\"], proc):\n            # ... read input for the node ...\n            task = create_task_for_pull(name, proc, ...)\n            tasks[task.id] = task\n    return tasks\n```\n\n----------------------------------------\n\nTITLE: Conceptual load_component Implementation (Python)\nDESCRIPTION: A conceptual implementation of the load_component class method, demonstrating how it imports the correct class, validates the configuration, and creates a new instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Inside ComponentLoader or similar\n@classmethod\ndef load_component(cls, model: ComponentModel | Dict[str, Any]) -> Self:\n    # 1. Ensure we have a ComponentModel object\n    if isinstance(model, dict):\n        loaded_model = ComponentModel(**model)\n    else:\n        loaded_model = model\n\n    # 2. Import the class based on the provider string\n    provider_str = loaded_model.provider\n    # ... (handle WELL_KNOWN_PROVIDERS mapping) ...\n    module_path, class_name = provider_str.rsplit(\".\", 1)\n    module = importlib.import_module(module_path)\n    component_class = getattr(module, class_name)\n\n    # 3. Validate the class and config\n    if not is_component_class(component_class): # Check it's a valid Component\n        raise TypeError(...)\n    schema = component_class.component_config_schema\n    validated_config = schema.model_validate(loaded_model.config)\n\n    # 4. Call the class's factory method to create instance\n    instance = component_class._from_config(validated_config)\n\n    # 5. Return the instance (after type checks)\n    return instance\n```\n\n----------------------------------------\n\nTITLE: Executing a Multi-Step Plan with PlanningFlow in Python\nDESCRIPTION: Defines the `PlanningFlow` class inheriting from `BaseFlow` and its core `execute` method. This async method orchestrates the entire workflow: it optionally creates an initial plan if input text is provided using `_create_initial_plan`, then iteratively retrieves the next step (`_get_current_step_info`), finds the appropriate agent (`get_executor`), executes the step via `_execute_step`, and accumulates results. The loop continues until all steps are completed or the plan is finalized. Dependencies include `BaseFlow`, `PlanningTool`, `BaseAgent`, and `Message`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom app.flow.base import BaseFlow\nfrom app.tool import PlanningTool\nfrom app.agent.base import BaseAgent\nfrom app.schema import Message # Assuming Message is imported\n\nclass PlanningFlow(BaseFlow):\n    planning_tool: PlanningTool = Field(default_factory=PlanningTool)\n    # ... other fields like llm, active_plan_id ...\n\n    async def execute(self, input_text: str) -> str:\n        \"\"\"Execute the planning flow with agents.\"\"\"\n        # 1. Create the plan if input is provided\n        if input_text:\n            await self._create_initial_plan(input_text)\n            # Check if plan exists...\n\n        result_accumulator = \"\"\n        while True:\n            # 2. Get the next step to execute\n            step_index, step_info = await self._get_current_step_info()\n\n            # 3. Exit if no more steps\n            if step_index is None:\n                result_accumulator += await self._finalize_plan()\n                break\n\n            # 4. Get the agent to execute the step\n            executor_agent = self.get_executor(step_info.get(\"type\"))\n\n            # 5. Execute the step using the agent\n            step_result = await self._execute_step(executor_agent, step_info)\n            result_accumulator += step_result + \"\\n\"\n\n            # Mark step as completed (done inside _execute_step or here)\n            # await self._mark_step_completed(step_index) # Simplified\n\n            # Maybe check if agent finished early...\n\n        return result_accumulator\n```\n\n----------------------------------------\n\nTITLE: Sending Celery Tasks for Execution in Python\nDESCRIPTION: This snippet shows how to send Celery tasks for execution using both the .delay() and .apply_async() methods. It demonstrates sending tasks immediately and scheduling them for future execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/03_task.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# run_tasks.py\nfrom tasks import add, send_welcome_email\n\nprint(\"Let's send some tasks!\")\n\n# --- Using .delay() ---\n# Tell Celery to run add(5, 7) in the background\nresult_promise_add = add.delay(5, 7)\nprint(f\"Sent task add(5, 7). Task ID: {result_promise_add.id}\")\n\n# Tell Celery to run send_welcome_email(123) in the background\nresult_promise_email = send_welcome_email.delay(123)\nprint(f\"Sent task send_welcome_email(123). Task ID: {result_promise_email.id}\")\n\n\n# --- Using .apply_async() ---\n# Does the same thing as .delay() but allows more options\nresult_promise_add_later = add.apply_async(args=(10, 20), countdown=10) # Run after 10s\nprint(f\"Sent task add(10, 20) to run in 10s. Task ID: {result_promise_add_later.id}\")\n\nprint(\"Tasks have been sent to the broker!\")\nprint(\"A Celery worker needs to be running to pick them up.\")\n```\n\n----------------------------------------\n\nTITLE: Analyzing Relationships Between Abstractions with LLM Summarization - Python\nDESCRIPTION: This node summarizes how code abstractions interact using contextually formatted indexed labels and descriptions, including multilingual support when required. A prompt is constructed for the LLM requesting a project summary and a list of abstraction-to-abstraction relationships with concise, possibly translated, labels. Outputs are validated and structured as indices and labels, stored for downstream use. Requires helpers for assembling content by abstraction index and LLM interfacing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `abstractions`, `files`, `project_name`, and `language` from shared store. Format context for the LLM, including potentially translated abstraction names *and indices*, potentially translated descriptions, and content snippets from related files (referenced by `index # path` using `get_content_for_indices` helper). Prepare the list of `index # AbstractionName` (potentially translated) for the prompt.\n        *   `exec`: Construct a prompt for `call_llm`. If language is not English, add instructions to generate `summary` and `label` in the target language, and note that input names might be translated. Ask for (1) a high-level summary and (2) a list of relationships, each specifying `from_abstraction` (e.g., `0 # Abstraction1`), `to_abstraction` (e.g., `1 # Abstraction2`), and a concise `label`. Request structured YAML output. Parse and validate, converting referenced abstractions to indices (`from: 0, to: 1`).\n        *   `post`: Parse the LLM response and write the `relationships` dictionary (`{\"summary\": \"...\", \"details\": [{\"from\": 0, \"to\": 1, \"label\": \"...\"}, ...]}`) with indices and potentially translated `summary`/`label` to the shared store.\n```\n\n----------------------------------------\n\nTITLE: Visualizing Sequential Process Flow with Mermaid\nDESCRIPTION: A Mermaid sequence diagram illustrating the workflow of a CrewAI `Crew` using the `Process.sequential` strategy. It shows the user initiating the `kickoff`, tasks being executed in strict order by their assigned agents (Researcher then Planner), and the output of the first task feeding context into the second before the final result is returned.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MyCrew as Crew (Sequential)\n    participant ResearcherAgent as Researcher\n    participant PlannerAgent as Planner\n\n    User->>MyCrew: kickoff()\n    MyCrew->>ResearcherAgent: Execute Task 1 (\"Find cities\")\n    ResearcherAgent-->>MyCrew: Task 1 Output (Cities List)\n    MyCrew->>PlannerAgent: Execute Task 2 (\"Create itinerary\")\\nwith Task 1 Output context\n    PlannerAgent-->>MyCrew: Task 2 Output (Itinerary)\n    MyCrew-->>User: Final Result (Task 2 Output)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Agent Interaction Flow with Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the step-by-step interaction between a User, the Terminal UI (Ink), the AgentLoop, OpenAI, and Command Execution components for processing a \"write & run hello world\" request. It shows the flow of messages, API calls, tool call handling, user confirmation, command execution, and response streaming back to the user.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/03_agent_loop.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant User\n    participant InkUI as Terminal UI (Ink)\n    participant AgentLoop\n    participant OpenAI\n    participant CmdExec as Command Execution\n\n    User->>InkUI: Types \"write & run hello world\", presses Enter\n    InkUI->>AgentLoop: Calls `run([\"write & run...\"])`\n    AgentLoop->>AgentLoop: Sets loading=true (calls `onLoading(true)`)\n    InkUI->>User: Shows loading indicator\n    AgentLoop->>OpenAI: Sends request: [\"write & run...\"]\n    OpenAI-->>AgentLoop: Streams response: [Text: \"Okay, try:\", ToolCall: `shell(...)`]\n    AgentLoop->>InkUI: Calls `onItem(Text: \"Okay, try:\")`\n    InkUI->>User: Displays \"Okay, try:\"\n    AgentLoop->>AgentLoop: Processes ToolCall `shell(...)`\n    Note over AgentLoop: Checks Approval Policy\n    AgentLoop->>InkUI: Calls `getCommandConfirmation([\"python\", \"-c\", \"...\"])`\n    InkUI->>User: Displays \"Allow command: python -c '...'?\" [Yes/No]\n    User->>InkUI: Clicks/Types 'Yes'\n    InkUI-->>AgentLoop: Returns confirmation result ({ review: YES })\n    AgentLoop->>CmdExec: Executes `python -c 'print(\"hello world\")'`\n    CmdExec-->>AgentLoop: Returns result (stdout: \"hello world\", exit code: 0)\n    AgentLoop->>AgentLoop: Creates `function_call_output` item\n    AgentLoop->>OpenAI: Sends request: [..., ToolCall: `shell(...)`, Output: \"hello world\"]\n    OpenAI-->>AgentLoop: Streams response: [Text: \"Command ran successfully!\"]\n    AgentLoop->>InkUI: Calls `onItem(Text: \"Command ran...\")`\n    InkUI->>User: Displays \"Command ran successfully!\"\n    AgentLoop->>AgentLoop: Sets loading=false (calls `onLoading(false)`)\n    InkUI->>User: Hides loading indicator, shows input prompt\n```\n```\n\n----------------------------------------\n\nTITLE: Conceptual example of LLMExtractionStrategy in Crawl4AI\nDESCRIPTION: This code snippet shows a conceptual implementation of the LLM-based extraction strategy, which uses AI to extract structured data from web content based on a provided schema. The example imports the necessary components but is incomplete, serving as a template for implementation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/06_extractionstrategy.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# chapter6_example_2.py\nimport asyncio\nimport json\nfrom crawl4ai import (\n    AsyncWebCrawler,\n    CrawlerRunConfig,\n    LLMExtractionStrategy, # Import the LLM strategy\n    LlmConfig             # Import LLM configuration helper\n)\n\n# Assume llm_config is properly configured with provider, API key, etc.\n# This is just a placeholder - replace with your actual LLM setup\n```\n\n----------------------------------------\n\nTITLE: Explicit LXMLWebScrapingStrategy Configuration\nDESCRIPTION: Example code showing how to explicitly configure and use the LXMLWebScrapingStrategy in Crawl4AI for potentially faster HTML processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n```\n\n----------------------------------------\n\nTITLE: Creating INT Instance of IntParamType in Python Click Framework\nDESCRIPTION: Creates a global instance of IntParamType named INT, which is used throughout the Click framework to validate and convert integer parameters from command line inputs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# click.INT is just an instance of this class\nINT = IntParamType()\n```\n\n----------------------------------------\n\nTITLE: Accessing Pydantic-Core Validator and Serializer\nDESCRIPTION: Shows how to access the compiled pydantic-core validator and serializer objects attached to a Pydantic model. These are internal implementation details and should be used with caution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# You can access these too (again, internal details!)\nprint(User.__pydantic_validator__)\n# Output: <SchemaValidator 'User' ...> (a pydantic-core object)\n\nprint(User.__pydantic_serializer__)\n# Output: <SchemaSerializer 'User' ...> (a pydantic-core object)\n```\n\n----------------------------------------\n\nTITLE: Graph Flow Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram showing the flow of execution through a graph with LastValue channel.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_8\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant App as CompiledGraph\n    participant Engine as Pregel Engine\n    participant ValueChannel as \"value\" (LastValue)\n    participant AdderNode as adder\n    participant MultiplierNode as multiplier\n\n    User->>App: invoke({\"value\": 5})\n    App->>Engine: Start execution\n    Engine->>ValueChannel: Initialize/Set state from input (value = 5)\n    App->>Engine: Entry point is \"adder\"\n    Engine->>ValueChannel: Read current value (5)\n    ValueChannel-->>Engine: Returns 5\n    Engine->>AdderNode: Execute(state={'value': 5})\n    AdderNode-->>Engine: Return {\"value\": 6}\n    Engine->>ValueChannel: Update with [6]\n    Note over ValueChannel: LastValue rule: value becomes 6\n    ValueChannel-->>Engine: Acknowledge update\n    Engine->>Engine: Follow edge \"adder\" -> \"multiplier\"\n    Engine->>ValueChannel: Read current value (6)\n    ValueChannel-->>Engine: Returns 6\n    Engine->>MultiplierNode: Execute(state={'value': 6})\n    MultiplierNode-->>Engine: Return {\"value\": 12}\n    Engine->>ValueChannel: Update with [12]\n    Note over ValueChannel: LastValue rule: value becomes 12\n    ValueChannel-->>Engine: Acknowledge update\n    Engine->>Engine: Follow edge \"multiplier\" -> END\n    Engine->>ValueChannel: Read final value (12)\n    ValueChannel-->>Engine: Returns 12\n    Engine->>App: Execution finished, final state {'value': 12}\n    App->>User: Return final state {'value': 12}\n```\n\n----------------------------------------\n\nTITLE: Flask Template Rendering Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram illustrating the step-by-step process of how Flask's render_template function works internally, from view function call to final browser response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/04_templating__jinja2_integration_.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant ViewFunc as Your View Function\n    participant RenderFunc as flask.render_template()\n    participant JinjaEnv as app.jinja_env\n    participant Loader as DispatchingJinjaLoader\n    participant TemplateObj as Template Object\n    participant Response as Flask Response\n\n    ViewFunc->>+RenderFunc: render_template('hello.html', name_in_template='Alice')\n    RenderFunc->>+JinjaEnv: get_or_select_template('hello.html')\n    JinjaEnv->>+Loader: Find 'hello.html'\n    Loader-->>-JinjaEnv: Found template file content\n    JinjaEnv-->>-RenderFunc: Return compiled TemplateObj\n    Note over RenderFunc, Response: Update context (add request, g, etc.)\n    RenderFunc->>+TemplateObj: render({'name_in_template': 'Alice', 'request': ..., ...})\n    TemplateObj-->>-RenderFunc: Return \"<html>...Hello, Alice!...</html>\"\n    RenderFunc-->>-ViewFunc: Return HTML string\n    ViewFunc->>+Response: Create Response from HTML string\n    Response-->>-ViewFunc: Response object\n    ViewFunc-->>Browser: Return Response\n```\n\n----------------------------------------\n\nTITLE: Implementing BaseAgent Class in Python\nDESCRIPTION: This code snippet shows a simplified implementation of the BaseAgent class, which inherits from ABC and Agent. It provides standard setup for agent creation, including runtime and id assignment, and implements methods like on_message and send_message. Subclasses must implement the on_message_impl method.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass BaseAgent(ABC, Agent):\n    def __init__(self, description: str) -> None:\n        # Gets runtime & id from a special context when created by the runtime\n        # Raises error if you try to create it directly!\n        self._runtime: AgentRuntime = AgentInstantiationContext.current_runtime()\n        self._id: AgentId = AgentInstantiationContext.current_agent_id()\n        self._description = description\n        # ...\n\n    # This is the final version called by the runtime\n    @final\n    async def on_message(self, message: Any, ctx: MessageContext) -> Any:\n        # It calls the implementation method you need to write\n        return await self.on_message_impl(message, ctx)\n\n    # You MUST implement this in your subclass\n    @abstractmethod\n    async def on_message_impl(self, message: Any, ctx: MessageContext) -> Any: ...\n\n    # Helper to send messages easily\n    async def send_message(self, message: Any, recipient: AgentId, ...) -> Any:\n        # It just asks the runtime to do the actual sending\n        return await self._runtime.send_message(\n            message, sender=self.id, recipient=recipient, ...\n        )\n    # ... other methods like publish_message, save_state, load_state\n```\n\n----------------------------------------\n\nTITLE: Visualizing AutoGen Core Components and Their Relationships\nDESCRIPTION: A flowchart diagram illustrating how the core components of AutoGen interact with each other. The diagram shows how AgentRuntime manages Agent lifecycles, how Agents use various components like Tools and ChatCompletionClient, and how data flows between different parts of the system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"0: Agent\"]\n    A1[\"1: AgentRuntime\"]\n    A2[\"2: Messaging System (Topic & Subscription)\"]\n    A3[\"3: Component\"]\n    A4[\"4: Tool\"]\n    A5[\"5: ChatCompletionClient\"]\n    A6[\"6: ChatCompletionContext\"]\n    A7[\"7: Memory\"]\n    A1 -- \"Manages lifecycle\" --> A0\n    A1 -- \"Uses for message routing\" --> A2\n    A0 -- \"Uses LLM client\" --> A5\n    A0 -- \"Executes tools\" --> A4\n    A0 -- \"Accesses memory\" --> A7\n    A5 -- \"Gets history from\" --> A6\n    A5 -- \"Uses tool schema\" --> A4\n    A7 -- \"Updates LLM context\" --> A6\n    A4 -- \"Implemented as\" --> A3\n```\n\n----------------------------------------\n\nTITLE: Mermaid Sequence Diagram for readResource Request Processing\nDESCRIPTION: A Mermaid sequence diagram illustrating how FastMCP processes a readResource request. It shows the interaction flow between the client, FastMCP server, ResourceManager, FunctionResource, and the wrapped welcome_message function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastMCP_Server as FastMCP (library_server.py)\n    participant ResManager as ResourceManager (_resource_manager)\n    participant FuncResource as FunctionResource (wraps welcome_message)\n    participant WelcomeFunc as welcome_message()\n\n    Client->>+FastMCP_Server: Send MCP Request: readResource(uri=\"data://greeting\")\n    FastMCP_Server->>+ResManager: get_resource(\"data://greeting\")\n    ResManager-->>-FastMCP_Server: Return FunctionResource object\n    FastMCP_Server->>+FuncResource: resource.read()\n    FuncResource->>+WelcomeFunc: Call original function welcome_message()\n    WelcomeFunc-->>-FuncResource: Return \"Welcome...\"\n    FuncResource-->>-FastMCP_Server: Return \"Welcome...\"\n    FastMCP_Server->>-Client: Send MCP Response: content=\"Welcome...\"\n```\n\n----------------------------------------\n\nTITLE: Managing Agent Memory and LLM Responses in Python\nDESCRIPTION: Demonstrates how an agent interacts with its memory using the previously defined `Memory` and `Message` models, and consults a language model (`LLM`) to generate responses. The agent encapsulates memory and LLM handling: it adds user messages to memory, serializes message history for LLM input, stores LLM responses as assistant messages, and prints state updates. Requires Python and correct imports from the application's schema and LLM modules. Inputs are user text strings; outputs include printed messages and async LLM-generated responses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified conceptual snippet inspired by app/agent/base.py\n\nfrom app.schema import Memory, Message, ROLE_TYPE # Simplified imports\nfrom app.llm import LLM\n\nclass SimplifiedAgent:\n    def __init__(self):\n        self.memory = Memory() # Agent holds a Memory instance\n        self.llm = LLM() # Agent has access to the LLM\n\n    def add_user_input(self, text: str):\n        \"\"\"Adds user input to memory.\"\"\"\n        user_msg = Message.user_message(text)\n        self.memory.add_message(user_msg)\n        print(f\"Agent Memory Updated with: {user_msg.to_dict()}\")\n\n    async def generate_response(self) -> str:\n        \"\"\"Generates a response based on memory.\"\"\"\n        print(\"Agent consulting memory...\")\n        messages_for_llm = self.memory.to_dict_list()\n\n        print(f\"Sending {len(messages_for_llm)} messages to LLM...\")\n        # The actual call to the LLM\n        response_text = await self.llm.ask(messages=messages_for_llm)\n\n        # Add assistant response to memory\n        assistant_msg = Message.assistant_message(response_text)\n        self.memory.add_message(assistant_msg)\n        print(f\"Agent Memory Updated with: {assistant_msg.to_dict()}\")\n\n        return response_text\n\n# Example Usage (needs async context)\n# agent = SimplifiedAgent()\n# agent.add_user_input(\"What is the capital of France?\")\n# response = await agent.generate_response() # Gets \"Paris\"\n# agent.add_user_input(\"What about Spain?\")\n# response2 = await agent.generate_response() # Gets \"Madrid\"\n```\n\n----------------------------------------\n\nTITLE: Combining Tutorial Artifacts and Mermaid Diagrams into Output Files - Python\nDESCRIPTION: This node aggregates all tutorial artifacts including index, chapter files, and a project diagram (using the Mermaid syntax). It composes index and chapter Markdown files enriched with attribution footers, organizes them into a designated output directory, and logs completion. Input and output context may be fully or partially translated. Dependencies include the shared store for input artifacts, standard file I/O, and directory management.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n    *   Steps*:\n        *   `prep`: Read `project_name`, `relationships` (potentially translated summary/labels), `chapter_order` (indices), `abstractions` (potentially translated name/desc), `chapters` (list of potentially translated content), `repo_url`, and `output_dir` from shared store. Generate a Mermaid `flowchart TD` string based on `relationships[\"details\"]`, using indices to identify nodes (potentially translated names) and the concise `label` (potentially translated) for edges. Construct the content for `index.md` (including potentially translated summary, Mermaid diagram, and ordered links to chapters using potentially translated names derived using `chapter_order` and `abstractions`). Define the output directory path (e.g., `./output_dir/project_name`). Prepare a list of `{ \"filename\": \"01_...\", \"content\": \"...\" }` for chapters, adding the English attribution footer to each chapter's content. Add the English attribution footer to the index content.\n        *   `exec`: Create the output directory. Write the generated `index.md` content. Iterate through the prepared chapter file list and write each chapter's content to its corresponding `.md` file in the output directory.\n        *   `post`: Write the final `output_path` to `shared[\"final_output_dir\"]`. Log completion.\n```\n\n----------------------------------------\n\nTITLE: Implementing Approval Logic for Commands in TypeScript\nDESCRIPTION: This snippet defines the core approval logic for Codex CLI, including types for approval policies and safety assessment outcomes. The canAutoApprove function determines whether commands can be run automatically based on the policy, with special handling for apply_patch commands and known safe read-only operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/04_approval_policy___security.md#2025-04-22_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/approvals.ts (Simplified)\n\n// Represents the different approval modes\nexport type ApprovalPolicy = \"suggest\" | \"auto-edit\" | \"full-auto\";\n\n// Represents the outcome of the safety check\nexport type SafetyAssessment =\n  | { type: \"auto-approve\"; runInSandbox: boolean; reason: string; /*...*/ }\n  | { type: \"ask-user\"; applyPatch?: ApplyPatchCommand }\n  | { type: \"reject\"; reason: string };\n\n// Input for apply_patch commands\nexport type ApplyPatchCommand = { patch: string; };\n\n/**\n * Checks if a command can be run automatically based on the policy.\n */\nexport function canAutoApprove(\n  command: ReadonlyArray<string>, // e.g., [\"git\", \"status\"] or [\"apply_patch\", \"...\"]\n  policy: ApprovalPolicy,\n  writableRoots: ReadonlyArray<string>, // Allowed directories for edits\n  // ... env ...\n): SafetyAssessment {\n  // --- Special case: apply_patch ---\n  if (command[0] === \"apply_patch\") {\n    // Check if policy allows auto-editing and if patch only affects allowed files\n    const applyPatchArg = command[1] as string;\n    const patchDetails = { patch: applyPatchArg };\n\n    if (policy === \"suggest\") return { type: \"ask-user\", applyPatch: patchDetails };\n\n    if (isWritePatchConstrainedToWritablePaths(applyPatchArg, writableRoots)) {\n       return { type: \"auto-approve\", runInSandbox: false, reason: \"Patch affects allowed files\", /*...*/ };\n    }\n    // If policy is auto-edit but patch affects disallowed files, ask user.\n    // If policy is full-auto, still approve but mark for sandbox if paths are weird.\n    return policy === \"full-auto\" ?\n      { type: \"auto-approve\", runInSandbox: true, reason: \"Full auto mode\", /*...*/ } :\n      { type: \"ask-user\", applyPatch: patchDetails };\n  }\n\n  // --- Check for known safe, read-only commands ---\n  const knownSafe = isSafeCommand(command); // Checks things like \"ls\", \"pwd\", \"git status\"\n  if (knownSafe != null) {\n    return { type: \"auto-approve\", runInSandbox: false, reason: knownSafe.reason, /*...*/ };\n  }\n\n  // --- Handle shell commands (like \"bash -lc 'npm install'\") ---\n  // (Simplified: assumes any other command needs policy check)\n\n  // --- Default: Check policy for general commands ---\n  if (policy === \"full-auto\") {\n    return { type: \"auto-approve\", runInSandbox: true, reason: \"Full auto mode\", /*...*/ };\n  } else {\n    // 'suggest' and 'auto-edit' require asking for commands\n    return { type: \"ask-user\" };\n  }\n}\n\n// Helper to check if a command is known to be safe (read-only)\nfunction isSafeCommand(command: ReadonlyArray<string>): { reason: string, group: string } | null {\n  const cmd = command[0];\n  if ([\"ls\", \"pwd\", \"cat\", \"git status\", \"git diff\", /*...*/].includes(cmd)) {\n     return { reason: `Safe read-only command: ${cmd}`, group: \"Reading\" };\n  }\n  return null;\n}\n\n// Helper (simplified) to check if patch affects allowed paths\nfunction isWritePatchConstrainedToWritablePaths(\n  patch: string,\n  writableRoots: ReadonlyArray<string>\n): boolean {\n  // ... logic to parse patch and check affected file paths ...\n  // ... return true if all paths are within writableRoots ...\n  return true; // Simplified for example\n}\n```\n\n----------------------------------------\n\nTITLE: Server Output After Starting MCPServer in OpenManus\nDESCRIPTION: Expected console output when the MCPServer successfully starts. Shows the registered tools and confirmation that the server is running in stdio mode.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nINFO:root:Registered tool: bash\nINFO:root:Registered tool: browser\nINFO:root:Registered tool: editor\nINFO:root:Registered tool: terminate\nINFO:root:Starting OpenManus server (stdio mode)\n# --- The server is now running and waiting for a connection ---\n```\n\n----------------------------------------\n\nTITLE: Defining CrawlerRunConfig Class in Python\nDESCRIPTION: A simplified version of the CrawlerRunConfig class from the crawl4ai library, showing the initialization of various crawling parameters and strategies.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/03_crawlerrunconfig.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from crawl4ai/async_configs.py\n\nfrom .cache_context import CacheMode\nfrom .extraction_strategy import ExtractionStrategy\nfrom .content_scraping_strategy import ContentScrapingStrategy, WebScrapingStrategy\n# ... other imports ...\n\nclass CrawlerRunConfig():\n    \"\"\"\n    Configuration class for controlling how the crawler runs each crawl operation.\n    \"\"\"\n    def __init__(\n        self,\n        # Caching\n        cache_mode: CacheMode = CacheMode.BYPASS, # Default behavior if not specified\n\n        # Content Selection / Waiting\n        css_selector: str = None,\n        wait_for: str = None,\n        page_timeout: int = 60000, # 60 seconds\n\n        # Media\n        screenshot: bool = False,\n        pdf: bool = False,\n\n        # Processing Strategies\n        scraping_strategy: ContentScrapingStrategy = None, # Defaults internally if None\n        extraction_strategy: ExtractionStrategy = None,\n\n        # ... many other parameters omitted for clarity ...\n        **kwargs # Allows for flexibility\n    ):\n        self.cache_mode = cache_mode\n        self.css_selector = css_selector\n        self.wait_for = wait_for\n        self.page_timeout = page_timeout\n        self.screenshot = screenshot\n        self.pdf = pdf\n        # Assign scraping strategy, ensuring a default if None is provided\n        self.scraping_strategy = scraping_strategy or WebScrapingStrategy()\n        self.extraction_strategy = extraction_strategy\n        # ... initialize other attributes ...\n\n    # Helper methods like 'clone', 'to_dict', 'from_kwargs' might exist too\n    # ...\n```\n\n----------------------------------------\n\nTITLE: Defining Key Structures and Value Types in LevelDB\nDESCRIPTION: Core definitions for ValueType enum, SequenceNumber type, and the InternalKey structure that combines user keys with metadata in LevelDB's storage format.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/dbformat.h ---\n\nnamespace leveldb {\n\n// Value types: Deletion or Value\nenum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };\n\n// ValueType used for seeking. (Uses highest type value)\nstatic const ValueType kValueTypeForSeek = kTypeValue;\n\n// Type for sequence numbers. 56 bits available.\ntypedef uint64_t SequenceNumber;\n\n// Max possible sequence number.\nstatic const SequenceNumber kMaxSequenceNumber = ((0x1ull << 56) - 1);\n\n// Structure to hold the parsed parts of an InternalKey\nstruct ParsedInternalKey {\n  Slice user_key;\n  SequenceNumber sequence;\n  ValueType type;\n\n  // Constructors... DebugString()...\n};\n\n// Helper class to manage the encoded string representation\nclass InternalKey {\n private:\n  std::string rep_; // Holds the encoded key: user_key + seq/type tag\n public:\n  // Constructors... DecodeFrom()... Encode()... user_key()...\n  InternalKey(const Slice& user_key, SequenceNumber s, ValueType t);\n};\n\n// ... other definitions like LookupKey, InternalKeyComparator ...\n\n} // namespace leveldb\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Click Command without Decorators (Hypothetical)\nDESCRIPTION: This snippet illustrates a hypothetical way of creating a Click command without using decorators, demonstrating the complexity that decorators help avoid.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/02_decorators.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# NOT how Click works, but imagine...\nimport click\n\ndef hello_logic():\n  \"\"\"My command's help text\"\"\"\n  print(\"Hello World!\")\n\n# Manually create a Command object\nhello_command = click.Command(\n  name='hello',      # Give it a name\n  callback=hello_logic, # Tell it which function to run\n  help=hello_logic.__doc__ # Copy the help text\n)\n\nif __name__ == '__main__':\n  # Manually parse arguments and run\n  # (This part would be complex!)\n  pass\n```\n\n----------------------------------------\n\nTITLE: Visualizing Agent Task Execution Flow with Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the step-by-step process of how a CrewAI Agent handles a task assigned by the Crew. It shows the interaction between the Agent, its LLM (brain), and optional Tools (like a search tool) to process the task, consult its profile, use tools, and return the result to the Crew. It visualizes the flow described in the 'How Agents Work \"Under the Hood\"' section.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/02_agent.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Crew\n    participant MyAgent as Agent (Researcher)\n    participant LLM as Agent's Brain\n    participant SearchTool as Tool\n\n    C->>MyAgent: Execute Task (\"Find sunny cities in May\")\n    MyAgent->>MyAgent: Consult profile (Role, Goal, Backstory)\n    MyAgent->>LLM: Formulate plan & Ask: \"Best way to find sunny cities?\"\n    LLM-->>MyAgent: Suggestion: \"Search web for 'Europe weather May'\"\n    MyAgent->>SearchTool: Use Tool(query=\"Europe weather May sunny cities\")\n    SearchTool-->>MyAgent: Web search results (e.g., Lisbon, Seville, Malta)\n    MyAgent->>LLM: Consolidate results & Ask: \"Format these 3 cities nicely\"\n    LLM-->>MyAgent: Formatted list: \"1. Lisbon...\"\n    MyAgent-->>C: Task Result (\"Here are 3 sunny cities: Lisbon...\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Mock LLM for Web Crawler in Python\nDESCRIPTION: Sets up a mock LLM configuration to be used with the web crawler. This mock configuration simulates the connection to an LLM provider like OpenAI.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/06_extractionstrategy.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# E.g., llm_config = LlmConfig(provider=\"openai\", api_token=\"env:OPENAI_API_KEY\")\nclass MockLlmConfig: provider=\"mock\"; api_token=\"mock\"; base_url=None\nllm_config = MockLlmConfig()\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of __array_function__ Dispatch Process (Mermaid)\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of a NumPy function call (np.sum) when using the __array_function__ protocol. It shows the interaction between the user, NumPy function dispatcher, overrides module, and a custom array object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/08___array_function___protocol___overrides___overrides__.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant NumPyFunc as np.sum (Dispatcher Object)\n    participant Overrides as numpy.core.overrides\n    participant CustomArr as my_arr (MySimpleArray)\n\n    User->>NumPyFunc: np.sum(my_arr)\n    NumPyFunc->>Overrides: Get relevant args (my_arr)\n    Overrides->>Overrides: _get_implementing_args([my_arr])\n    Overrides-->>NumPyFunc: Found [my_arr] implements __array_function__\n    NumPyFunc->>CustomArr: call __array_function__(func=np.sum, ...)\n    CustomArr->>CustomArr: Check if func is np.sum (Yes)\n    CustomArr->>CustomArr: Perform custom sum logic\n    CustomArr-->>NumPyFunc: Return result (e.g., 10)\n    NumPyFunc-->>User: Return result (10)\n```\n\n----------------------------------------\n\nTITLE: Customizing Model Serialization with @model_serializer in Pydantic (Python)\nDESCRIPTION: This snippet illustrates how to customize the entire serialization output of a Pydantic model using the '@model_serializer' decorator. It adds a calculated field 'duration_days' by overriding the serialization method, returning a manually constructed dictionary for use by 'model_dump()' and 'model_dump_json()'. Dependencies include Python 3.8+, Pydantic v2+, and standard modules like 'datetime'. Inputs are model instances; outputs are dicts or JSON with an extra field. This approach replaces the default serialization entirely.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date, timedelta\nfrom pydantic import BaseModel, model_serializer\nfrom typing import Dict, Any\n\nclass Trip(BaseModel):\n    start_date: date\n    end_date: date\n    destination: str\n\n    # Customize the entire model's serialization\n    @model_serializer\n    def serialize_with_duration(self) -> Dict[str, Any]:\n        # Start with the default field values\n        data = {'start_date': self.start_date, 'end_date': self.end_date, 'destination': self.destination}\n        # Calculate and add the custom field\n        duration = self.end_date - self.start_date\n        data['duration_days'] = duration.days\n        return data\n\n# --- Try it out ---\ntrip = Trip(start_date=date(2024, 8, 1), end_date=date(2024, 8, 5), destination='Lake')\n\nprint(f\"Model object: {trip}\")\n# Expected Output: Model object: start_date=datetime.date(2024, 8, 1) end_date=datetime.date(2024, 8, 5) destination='Lake'\n\ndumped_dict = trip.model_dump()\nprint(f\"Dumped dict: {dumped_dict}\")\n# Expected Output: Dumped dict: {'start_date': datetime.date(2024, 8, 1), 'end_date': datetime.date(2024, 8, 5), 'destination': 'Lake', 'duration_days': 4}\n\ndumped_json = trip.model_dump_json(indent=2)\nprint(f\"Dumped JSON:\\n{dumped_json}\")\n# Expected Output:\n# Dumped JSON:\n# {\n#   \"start_date\": \"2024-08-01\",\n#   \"end_date\": \"2024-08-05\",\n#   \"destination\": \"Lake\",\n#   \"duration_days\": 4\n# }\n```\n\n----------------------------------------\n\nTITLE: Executing Agent Step and Defining Abstract `step` in Python\nDESCRIPTION: Simplified `_execute_step` method from `agents.py` within the `MultiStepAgent` class. Its primary role is to delegate the actual work of a single step (thinking, acting) to the `step` method, passing the current `memory_step`. It receives the potential final answer back. It also includes the abstract `step` method signature, which raises `NotImplementedError`, indicating that subclasses (specific agent types like `CodeAgent` or `ToolCallingAgent`) must provide their concrete implementation for how a step is executed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# --- File: agents.py (Simplified _execute_step) ---\nclass MultiStepAgent:\n    def _execute_step(self, task: str, memory_step: ActionStep) -> Union[None, Any]:\n        # Calls the specific logic for the agent type\n        # This method will interact with the model, tools, memory\n        final_answer = self.step(memory_step)\n        # ... (optional checks on final answer) ...\n        return final_answer\n\n    # step() is implemented by subclasses like CodeAgent or ToolCallingAgent\n    def step(self, memory_step: ActionStep) -> Union[None, Any]:\n        raise NotImplementedError(\"Subclasses must implement the step method.\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Logic for LLM API Calls in Python\nDESCRIPTION: This code snippet demonstrates the implementation of the 'ask' method in the LLM class. It uses the @retry decorator from the tenacity library to handle retries for API calls. The method formats messages, checks token limits, makes API calls, and processes responses while handling various error scenarios.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/01_llm.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@retry( # This decorator handles retries!\n    wait=wait_random_exponential(min=1, max=60), # Wait 1-60s between tries\n    stop=stop_after_attempt(6), # Give up after 6 tries\n    retry=retry_if_exception_type((OpenAIError, Exception)) # Retry on these errors\n)\nasync def ask(\n    self,\n    messages: List[Union[dict, Message]],\n    # ... other parameters ...\n) -> str:\n    try:\n        # 1. Format messages (simplified)\n        formatted_msgs = self.format_messages(messages)\n\n        # 2. Count tokens & Check limits (simplified)\n        input_tokens = self.count_message_tokens(formatted_msgs)\n        if not self.check_token_limit(input_tokens):\n            raise TokenLimitExceeded(...) # Special error, not retried\n\n        # 3. Prepare API call parameters (simplified)\n        params = {\"model\": self.model, \"messages\": formatted_msgs, ...}\n\n        # 4. Make the actual API call (simplified)\n        response = await self.client.chat.completions.create(**params)\n\n        # 5. Process response & update tokens (simplified)\n        answer = response.choices[0].message.content\n        self.update_token_count(response.usage.prompt_tokens, ...)\n\n        return answer\n    except TokenLimitExceeded:\n         raise # Don't retry token limits\n    except Exception as e:\n         logger.error(f\"LLM ask failed: {e}\")\n         raise # Let the @retry decorator handle retrying other errors\n```\n\n----------------------------------------\n\nTITLE: Compaction Execution Loop in LevelDB (C++)\nDESCRIPTION: Core compaction loop from DBImpl::DoCompactionWork that iterates through all input keys from Level-N and Level-N+1, determines which entries to keep or drop, and builds new SSTable files in Level-N+1. The algorithm handles obsolete deletion markers, shadowed entries, and manages output file sizes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/08_compaction.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\n// --- Highly simplified loop from db/db_impl.cc DoCompactionWork ---\n\n// Create iterator over Level-N and Level-N+1 input files\nIterator* input = versions_->MakeInputIterator(compact->compaction);\ninput->SeekToFirst();\n\n// ... Release Mutex ...\n\nwhile (input->Valid() && !shutting_down_) {\n  Slice key = input->key();\n  Slice value = input->value();\n\n  // Should we finish the current output file and start a new one?\n  if (compact->compaction->ShouldStopBefore(key) && compact->builder != nullptr) {\n    status = FinishCompactionOutputFile(compact, input);\n    // ... handle status ...\n  }\n\n  // Should we drop this key/value pair?\n  bool drop = false;\n  if (ParseInternalKey(key, &ikey)) {\n      // Logic based on ikey.sequence, ikey.type, smallest_snapshot,\n      // last_sequence_for_key, IsBaseLevelForKey...\n      // drop = true if this entry is deleted, shadowed, or obsolete.\n  } else {\n      // Corrupt key? Maybe keep it? (See actual code for details)\n  }\n\n  if (!drop) {\n    // Open output file if needed\n    if (compact->builder == nullptr) {\n      status = OpenCompactionOutputFile(compact);\n      // ... handle status ...\n    }\n    // Add key/value to the output file being built\n    compact->builder->Add(key, value);\n    // ... update output file metadata (smallest/largest key) ...\n\n    // Close output file if it's big enough\n    if (compact->builder->FileSize() >= compact->compaction->MaxOutputFileSize()) {\n      status = FinishCompactionOutputFile(compact, input);\n      // ... handle status ...\n    }\n  }\n\n  // Advance to the next key in the merged input stream\n  input->Next();\n}\n\n// ... Finish the last output file ...\n// ... Check input iterator status ...\ndelete input;\n\n// ... Re-acquire Mutex ...\n```\n\n----------------------------------------\n\nTITLE: Testing NumPy Type Relationships with issubdtype and issubclass\nDESCRIPTION: This code demonstrates how to check type relationships in NumPy using issubdtype and issubclass functions, showing how the type hierarchy works in practice.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Is np.int32 a kind of integer?\nprint(f\"issubdtype(np.int32, np.integer): {np.issubdtype(np.int32, np.integer)}\")\n# Output: issubdtype(np.int32, np.integer): True\n\n# Is np.float64 a kind of integer?\nprint(f\"issubdtype(np.float64, np.integer): {np.issubdtype(np.float64, np.integer)}\")\n# Output: issubdtype(np.float64, np.integer): False\n\n# Is np.float64 a kind of number?\nprint(f\"issubdtype(np.float64, np.number): {np.issubdtype(np.float64, np.number)}\")\n# Output: issubdtype(np.float64, np.number): True\n\n# Using issubclass directly on the types also works\nprint(f\"issubclass(np.int32, np.integer): {issubclass(np.int32, np.integer)}\")\n# Output: issubclass(np.int32, np.integer): True\n```\n\n----------------------------------------\n\nTITLE: Setting up and Running a MultiStepAgent in Python\nDESCRIPTION: This code snippet demonstrates how to import necessary components, define tools, choose a language model, create a MultiStepAgent instance, and run a task. It showcases the basic setup for using the MultiStepAgent to solve a multi-step problem.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/01_multistepagent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# --- File: basic_agent.py ---\n# Import necessary components (we'll explain these more in later chapters!)\nfrom smolagents import MultiStepAgent\nfrom smolagents.models import LiteLLMModel # A simple way to use various LLMs\nfrom smolagents.tools import SearchTool, WeatherTool # Example Tools\n\n# 1. Define the tools the agent can use\n# These are like specialized workers the agent can call upon.\nsearch_tool = SearchTool()   # A tool to search the web (details in Chapter 3)\nweather_tool = WeatherTool() # A tool to get weather info (details in Chapter 3)\n# Note: Real tools might need API keys or setup!\n\n# 2. Choose a language model (the \"brain\")\n# We'll use LiteLLMModel here, connecting to a capable model.\n# Make sure you have 'litellm' installed: pip install litellm\nllm = LiteLLMModel(model_id=\"gpt-3.5-turbo\") # Needs an API key set up\n# We'll cover models properly in Chapter 2\n\n# 3. Create the MultiStepAgent instance\n# We pass the brain (llm) and the helpers (tools)\nagent = MultiStepAgent(\n    model=llm,\n    tools=[search_tool, weather_tool]\n    # By default, a 'final_answer' tool is always added.\n)\n\nprint(\"Agent created!\")\n\n# 4. Give the agent a task!\ntask = \"What is the capital of France, and what is its current weather?\"\nprint(f\"Running agent with task: '{task}'\")\n\n# The agent will now start its Think-Act-Observe cycle...\nfinal_answer = agent.run(task)\n\n# ... and eventually return the final result.\nprint(\"-\" * 20)\nprint(f\"Final Answer received: {final_answer}\")\n```\n\n----------------------------------------\n\nTITLE: Importing the DSPy Library in Python\nDESCRIPTION: Imports the `dspy` library, which is the primary entry point for using the DSPy framework. This is a necessary first step before utilizing any DSPy components like RM or LM clients.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n```\n\n----------------------------------------\n\nTITLE: Visualizing Click Framework Architecture with Mermaid\nDESCRIPTION: A flowchart diagram showing the relationships between key Click components including Context, Commands, Parameters, ParamType, Decorators, Terminal UI, and Exceptions. It illustrates how decorators configure commands and parameters, how context manages execution, and how components interact for validation and user interaction.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Context\"]\n    A1[\"Command / Group\"]\n    A2[\"Parameter (Option / Argument)\"]\n    A3[\"ParamType\"]\n    A4[\"Decorators\"]\n    A5[\"Term UI (Terminal User Interface)\"]\n    A6[\"Click Exceptions\"]\n    A4 -- \"Creates/Configures\" --> A1\n    A4 -- \"Creates/Configures\" --> A2\n    A0 -- \"Manages execution of\" --> A1\n    A0 -- \"Holds parsed values for\" --> A2\n    A2 -- \"Uses for validation/conversion\" --> A3\n    A3 -- \"Raises on conversion error\" --> A6\n    A1 -- \"Uses for user interaction\" --> A5\n    A0 -- \"Handles/Raises\" --> A6\n    A4 -- \"Injects via @pass_context\" --> A0\n```\n\n----------------------------------------\n\nTITLE: Sequence Flow: DSPy Settings Access\nDESCRIPTION: Mermaid sequence diagram illustrating the flow of how modules access DSPy settings, showing interactions between user code, modules, thread-local storage, and global configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/10_settings.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Module as Your Module (e.g., Predict)\n    participant Settings as dspy.settings\n    participant ThreadLocalStorage as Thread-Local Storage\n    participant GlobalConfig as Global Defaults\n\n    User->>Module: Call module(input=...)\n    Module->>Settings: Get configured lm (`settings.lm`)\n    Settings->>ThreadLocalStorage: Check for 'lm' override?\n    alt Override Exists\n        ThreadLocalStorage-->>Settings: Return thread-local lm\n        Settings-->>Module: Return thread-local lm\n    else No Override\n        ThreadLocalStorage-->>Settings: No override found\n        Settings->>GlobalConfig: Get global 'lm'\n        GlobalConfig-->>Settings: Return global lm\n        Settings-->>Module: Return global lm\n    end\n    Module->>Module: Use the returned lm for processing...\n    Module-->>User: Return result\n```\n\n----------------------------------------\n\nTITLE: Example LLM Tool Parameter Output in JSON\nDESCRIPTION: This JSON snippet shows an example of the formatted output for a tool's parameters as provided to an LLM. It includes the tool's name, description, and required parameters.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/04_tool___toolcollection.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"function\",\n  \"function\": {\n    \"name\": \"echo_message\",\n    \"description\": \"Repeats back the text provided in the 'message' parameter.\",\n    \"parameters\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"message\": {\n          \"type\": \"string\",\n          \"description\": \"The text to be echoed back.\"\n        }\n      },\n      \"required\": [\n        \"message\"\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Demonstrating LevelDB Key Evolution Example\nDESCRIPTION: Example showing how LevelDB transforms and tracks a key through multiple operations using sequence numbers and value types. Demonstrates the internal representation and sorting of keys for a Put/Put/Delete sequence.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nPut(\"mykey\", \"v1\") -> gets Sequence = 5 -> InternalKey: (\"mykey\", 5, kTypeValue)\nPut(\"mykey\", \"v2\") -> gets Sequence = 10 -> InternalKey: (\"mykey\", 10, kTypeValue)\nDelete(\"mykey\") -> gets Sequence = 15 -> InternalKey: (\"mykey\", 15, kTypeDeletion)\n\nSorted order:\n1. (\"mykey\", 15, kTypeDeletion) (Highest sequence)\n2. (\"mykey\", 10, kTypeValue)\n3. (\"mykey\", 5, kTypeValue) (Lowest sequence)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Exception in Python\nDESCRIPTION: Defines a custom exception class (UnicornNotFound) to represent a missing unicorn scenario. The exception captures the name of the unicorn via its constructor. This is a prerequisite for registering a custom FastAPI exception handler and is typically placed in your main file or a dedicated exceptions module.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/06_error_handling.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Can be in your main file or a separate exceptions.py\nclass UnicornNotFound(Exception):\n    def __init__(self, name: str):\n        self.name = name\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing Deep Crawl Process with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram illustrates the interaction between the user, DeepCrawlDecorator, DeepCrawlStrategy (e.g., BFS), and AsyncWebCrawler during a deep crawl operation. It shows the flow of control and data through the crawling process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/08_deepcrawlstrategy.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Decorator as DeepCrawlDecorator\n    participant Strategy as DeepCrawlStrategy (e.g., BFS)\n    participant AWC as AsyncWebCrawler\n\n    User->>Decorator: arun(start_url, config_with_strategy)\n    Decorator->>Strategy: arun(start_url, crawler=AWC, config)\n    Note over Strategy: Initialize queue/level with start_url\n    loop Until Queue Empty or Limits Reached\n        Strategy->>Strategy: Get next batch of URLs from queue\n        Note over Strategy: Create batch_config (deep_crawl=None)\n        Strategy->>AWC: arun_many(batch_urls, config=batch_config)\n        AWC-->>Strategy: batch_results (List/Stream of CrawlResult)\n        loop For each result in batch_results\n            Strategy->>Strategy: Process result (yield if streaming)\n            Strategy->>Strategy: Discover links (apply filters)\n            Strategy->>Strategy: Add valid new links to queue\n        end\n    end\n    Strategy-->>Decorator: Final result (List or Generator)\n    Decorator-->>User: Final result\n```\n\n----------------------------------------\n\nTITLE: Disabling Telemetry in Windows PowerShell\nDESCRIPTION: Illustrates how to disable telemetry in Windows PowerShell by setting the ANONYMIZED_TELEMETRY environment variable to False before running the Python script.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n$env:ANONYMIZED_TELEMETRY=\"False\"\npython your_agent_script.py\n```\n\n----------------------------------------\n\nTITLE: Conceptual Usage of np.sum with Custom Arrays (Python)\nDESCRIPTION: This snippet illustrates the desired, user-friendly syntax for applying a standard NumPy function (`np.sum`) directly to an instance of a custom array type (e.g., from CuPy or Dask). It represents the goal that the `__array_function__` protocol helps achieve, where the custom object handles the execution.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/08___array_function___protocol___overrides___overrides__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Assume 'my_special_array' is an instance of a custom array type\n# (e.g., from CuPy or Dask)\nresult = np.sum(my_special_array)\n```\n\n----------------------------------------\n\nTITLE: Implementing AgentOutput Model with Pydantic\nDESCRIPTION: Defines the AgentOutput model that represents the complete plan received from the LLM, including current state and list of actions to execute.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/07_data_structures__views_.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import List\n\nclass AgentOutput(BaseModel):\n    current_state: object\n    action: List[ActionModel]\n```\n\n----------------------------------------\n\nTITLE: Creating a ToolCollection with Custom and Built-in Tools in Python\nDESCRIPTION: This snippet shows how to create a ToolCollection by combining a custom EchoTool with the built-in WebSearch tool. It demonstrates importing necessary classes, creating tool instances, and organizing them into a ToolCollection.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/04_tool___toolcollection.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom app.tool import ToolCollection, WebSearch\n# Assume EchoTool class is defined as above\n# from your_module import EchoTool\n\necho_tool = EchoTool()\nweb_search_tool = WebSearch()\n\nmy_toolbox = ToolCollection(echo_tool, web_search_tool)\n\ntool_names = [tool.name for tool in my_toolbox]\nprint(f\"Tools in the toolbox: {tool_names}\")\n```\n\n----------------------------------------\n\nTITLE: Serializing Field as String with Annotated and PlainSerializer in Pydantic (Python)\nDESCRIPTION: This snippet demonstrates serializing a 'date' field as a 'YYYY-MM-DD' string in a Pydantic model using 'typing.Annotated' and 'PlainSerializer'. The serialization function is defined outside the class and referenced directly in the type hint, ensuring the field outputs a formatted string during model export. This approach can be reused across models and requires Python 3.8+, Pydantic v2+, and the 'datetime' module. Inputs are model instances; outputs are dicts or JSON with the date serialized in the specified string format.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/04_custom_logic__decorators___annotated_helpers_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\nfrom typing import Annotated\nfrom pydantic import BaseModel\n# Import the helper\nfrom pydantic.functional_serializers import PlainSerializer\n\n# Define the serializer function\ndef format_date_yyyymmdd(dt: date) -> str:\n    return dt.strftime('%Y-%m-%d')\n\nclass EventAnnotated(BaseModel):\n    name: str\n    # Attach the serializer function directly to the type hint\n    event_date: Annotated[date, PlainSerializer(format_date_yyyymmdd)]\n\n# --- Try it out ---\nevent = EventAnnotated(name='Conference', event_date=date(2024, 10, 15))\n\nprint(f\"Model object: {event}\")\n# Expected Output: Model object: name='Conference' event_date=datetime.date(2024, 10, 15)\n\ndumped_dict = event.model_dump()\nprint(f\"Dumped dict: {dumped_dict}\")\n# Expected Output: Dumped dict: {'name': 'Conference', 'event_date': '2024-10-15'}\n\ndumped_json = event.model_dump_json(indent=2)\nprint(f\"Dumped JSON:\\n{dumped_json}\")\n# Expected Output:\n# Dumped JSON:\n# {\n#   \"name\": \"Conference\",\n#   \"event_date\": \"2024-10-15\"\n# }\n```\n\n----------------------------------------\n\nTITLE: Providing a Few-Shot Example to a DSPy Module in Python\nDESCRIPTION: Shows how to create a `dspy.Example` object containing a sample input (`text`) and its corresponding desired output (`summary`) to serve as a few-shot demonstration. The `.with_inputs(\"text\")` method specifies which fields are inputs. This `demo` is then passed along with the actual input `long_text` when calling the `summarizer` module, potentially improving the LM's output quality by providing context. Requires the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Demo example\ndemo = dspy.Example(\n    text=\"Long article about cats.\",\n    summary=\"Cats are popular pets.\"\n).with_inputs(\"text\")\n\n# Call the summarizer with the demo\nresult = summarizer(text=long_text, demos=[demo])\n```\n\n----------------------------------------\n\nTITLE: Multi-Agent Orchestration Flow in Mermaid Diagram\nDESCRIPTION: A sequence diagram visualizing the communication flow between a user, host agent, and specialized downstream agents (Joke and Summarizer). The diagram shows how the host agent acts as both a server to the user and a client to the downstream agents using the A2A protocol.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/08_multi_agent_orchestration__host_agent_.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Host as Host Agent (Server)\n    participant HAClient as Host Agent (Internal A2A Client)\n    participant Joke as Joke Agent (Server)\n    participant Summary as Summarizer Agent (Server)\n\n    User->>Host: Send Task T0: \"Tell joke & summarize...\"\n    Note over Host: Analyzes request, needs Joke & Summarizer\n\n    Host->>HAClient: Initiate A2A Task T1 to Joke Agent (\"Tell joke\")\n    HAClient->>Joke: POST /a2a (tasks/send, id=T1, msg=\"Tell joke\")\n    Note right of Joke: Joke Agent starts processing T1\n\n    Host->>HAClient: Initiate A2A Task T2 to Summarizer Agent (\"Summarize text...\")\n    HAClient->>Summary: POST /a2a (tasks/send, id=T2, msg=\"...\")\n    Note right of Summary: Summarizer Agent starts processing T2\n\n    Joke-->>HAClient: 200 OK (JSON-RPC result: Task T1 object, state=completed, result=\"Why..?\")\n    HAClient-->>Host: Received result for T1\n\n    Summary-->>HAClient: 200 OK (JSON-RPC result: Task T2 object, state=completed, result=\"[Summary...]\")\n    HAClient-->>Host: Received result for T2\n\n    Note over Host: Combines results from T1 and T2\n    Host-->>User: Respond Task T0 (state=completed, result=\"Joke: ... Summary: ...\")\n```\n\n----------------------------------------\n\nTITLE: Read Operation Sequence Flow\nDESCRIPTION: Mermaid sequence diagram showing the flow of a read operation through different storage layers including MemTable, Immutable MemTable, and SSTables via TableCache.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant App as Application\n    participant DBImpl\n    participant MemTable as Active MemTable (RAM)\n    participant ImmMemTable as Immutable MemTable (RAM)\n    participant Version as Current Version\n    participant TableCache as TableCache (SSTables)\n\n    App->>DBImpl: Get(\"key\")\n    DBImpl->>MemTable: Get(lkey)?\n    alt Key Found in MemTable\n        MemTable-->>DBImpl: Return value / deletion\n        DBImpl-->>App: Return value / NotFound\n    else Key Not Found in MemTable\n        MemTable-->>DBImpl: Not Found\n        DBImpl->>ImmMemTable: Get(lkey)?\n        alt Key Found in ImmMemTable\n            ImmMemTable-->>DBImpl: Return value / deletion\n            DBImpl-->>App: Return value / NotFound\n        else Key Not Found in ImmMemTable\n            ImmMemTable-->>DBImpl: Not Found\n            DBImpl->>Version: Get(lkey) from SSTables?\n            Version->>TableCache: Find key in relevant SSTables\n            TableCache-->>Version: Return value / deletion / NotFound\n            Version-->>DBImpl: Return value / deletion / NotFound\n            DBImpl-->>App: Return value / NotFound\n        end\n    end\n```\n\n----------------------------------------\n\nTITLE: Ufunc Sequence Diagram\nDESCRIPTION: A Mermaid sequence diagram illustrating the flow of a ufunc operation from Python call to C implementation and back, showing how data types are resolved and memory is managed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/07_umath_module.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User as Your Python Script\n    participant PyUfunc as np.add (Python Wrapper)\n    participant UfuncObj as Ufunc Object (Metadata)\n    participant C_Core as C Code (_multiarray_umath)\n    participant C_Loop as Specific Add Loop (e.g., int64_add)\n    participant Memory\n\n    User->>PyUfunc: result = np.add(a, b)\n    PyUfunc->>UfuncObj: Access the 'add' ufunc object\n    UfuncObj->>C_Core: Initiate ufunc execution (pass inputs a, b)\n    C_Core->>C_Core: Inspect a.dtype, b.dtype\n    C_Core->>UfuncObj: Find best C loop (e.g., int64_add loop)\n    C_Core->>Memory: Allocate memory for result (if needed)\n    C_Core->>C_Loop: Execute int64_add(a_data, b_data, result_data)\n    C_Loop->>Memory: Read a, b, compute sum, write result\n    C_Loop-->>C_Core: Signal loop completion\n    C_Core->>Memory: Wrap result memory in ndarray object\n    C_Core-->>PyUfunc: Return result ndarray\n    PyUfunc-->>User: Assign result ndarray to 'result'\n```\n\n----------------------------------------\n\nTITLE: Simplified Ufunc Definition in generate_umath.py\nDESCRIPTION: Shows a simplified excerpt from the NumPy code generation system that defines the 'add' ufunc, including its inputs, outputs, identity element, and type dispatch mechanisms.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/07_umath_module.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from generate_umath.py's defdict for 'add'\n'add':\n    Ufunc(2, 1, Zero, # nin=2, nout=1, identity=0\n          docstrings.get('numpy._core.umath.add'), # Docstring reference\n          'PyUFunc_AdditionTypeResolver', # Type resolution logic\n          TD('?', ...), # Loop for booleans\n          TD(no_bool_times_obj, dispatch=[...]), # Loops for numeric types\n          # ... loops for datetime, object ...\n          ),\n```\n\n----------------------------------------\n\nTITLE: Creating a Dedicated Celery Configuration Module\nDESCRIPTION: Defining a separate Python module (celeryconfig.py) for Celery settings. This approach is recommended for larger projects as it keeps configuration separate from application logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/02_configuration.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# celeryconfig.py\n\n# Broker settings\nbroker_url = 'redis://localhost:6379/0'\n\n# Result backend settings\nresult_backend = 'redis://localhost:6379/1'\n\n# Task settings\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\n\n# Timezone settings\ntimezone = 'America/New_York'\nenable_utc = True # Recommended\n\n# List of modules to import when the Celery worker starts.\nimports = ('proj.tasks',) # Example: Assuming tasks are in proj/tasks.py\n```\n\n----------------------------------------\n\nTITLE: Defining BaseChannel Abstract Base Class in Python\nDESCRIPTION: This snippet shows the definition of the BaseChannel abstract base class, which serves as the foundation for all channel types in LangGraph. It defines the common interface for channel operations such as updating, getting values, and handling checkpoints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# channels/base.py (Simplified Abstract Base Class)\nfrom abc import ABC, abstractmethod\nfrom typing import Generic, Sequence, TypeVar\n\nValue = TypeVar(\"Value\") # The type of the stored state\nUpdate = TypeVar(\"Update\") # The type of incoming updates\nCheckpoint = TypeVar(\"Checkpoint\") # The type of saved state\n\nclass BaseChannel(Generic[Value, Update, Checkpoint], ABC):\n    # ... (init, type properties) ...\n\n    @abstractmethod\n    def update(self, values: Sequence[Update]) -> bool:\n        \"\"\"Combines the sequence of updates with the current channel value.\"\"\"\n        # Must be implemented by subclasses (like LastValue, Topic)\n        pass\n\n    @abstractmethod\n    def get(self) -> Value:\n        \"\"\"Returns the current value of the channel.\"\"\"\n        # Must be implemented by subclasses\n        pass\n\n    @abstractmethod\n    def checkpoint(self) -> Checkpoint:\n        \"\"\"Returns a serializable representation of the channel's state.\"\"\"\n        # Used by the Checkpointer\n        pass\n\n    @abstractmethod\n    def from_checkpoint(self, checkpoint: Checkpoint) -> Self:\n        \"\"\"Creates a new channel instance from a saved checkpoint.\"\"\"\n        # Used by the Checkpointer\n        pass\n```\n\n----------------------------------------\n\nTITLE: Implementing Click Exception Classes in Python\nDESCRIPTION: This code snippet shows the simplified structure of Click's exception classes from the click/exceptions.py file. It demonstrates how ClickException serves as the base class, with UsageError and BadParameter inheriting and extending its functionality for more specific error handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Simplified structure from click/exceptions.py\n\nclass ClickException(Exception):\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        # ... (stores message, gets color settings) ...\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def show(self, file=None) -> None:\n        # ... (gets stderr if file is None) ...\n        echo(f\"Error: {self.format_message()}\", file=file, color=self.show_color)\n\nclass UsageError(ClickException):\n    exit_code = 2\n\n    def __init__(self, message: str, ctx=None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        # ...\n\n    def show(self, file=None) -> None:\n        # ... (gets stderr, color) ...\n        hint = \"\"\n        if self.ctx is not None and self.ctx.command.get_help_option(self.ctx):\n            hint = f\"Try '{self.ctx.command_path} {self.ctx.help_option_names[0]}' for help.\\n\"\n        if self.ctx is not None:\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        # Call the base class's logic to print \"Error: ...\"\n        echo(f\"Error: {self.format_message()}\", file=file, color=color)\n\nclass BadParameter(UsageError):\n    def __init__(self, message: str, ctx=None, param=None, param_hint=None) -> None:\n        super().__init__(message, ctx)\n        self.param = param\n        self.param_hint = param_hint\n\n    def format_message(self) -> str:\n        # ... (logic to get parameter name/hint) ...\n        param_hint = self.param.get_error_hint(self.ctx) if self.param else self.param_hint\n        # ...\n        return f\"Invalid value for {param_hint}: {self.message}\"\n\n# Other exceptions like MissingParameter, NoSuchOption follow similar patterns\n```\n\n----------------------------------------\n\nTITLE: Visualizing Cookie Handling Flow with Sequence Diagram (Mermaid)\nDESCRIPTION: This mermaid code snippet provides a visual representation of the sequence in which cookies are managed by the Requests library. It illustrates the flow from sending a request to receiving a response, showing the interaction between user code, the session's cookie jar, the adapter, and the server. No dependencies are needed to read, but rendering requires a mermaid-compatible viewer.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/04_cookie_jar.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant User as Your Code\\n    participant Sess as Session Object\\n    participant Jar as Cookie Jar (s.cookies)\\n    participant Adapter as Transport Adapter\\n    participant Server as Web Server\\n\\n    User->>Sess: s.get(url)\\n    Sess->>Jar: get_cookie_header(url)\\n    Jar-->>Sess: Return matching cookie header string (e.g., \\\"fruit=apple\\\")\\n    Sess->>Adapter: send(request with 'Cookie' header)\\n    Adapter->>Server: Send HTTP Request (with Cookie: fruit=apple)\\n    Server-->>Adapter: Send HTTP Response (e.g., with Set-Cookie: new=cookie)\\n    Adapter->>Sess: Return raw response\\n    Sess->>Jar: extract_cookies_to_jar(raw response)\\n    Jar->>Jar: Add/Update 'new=cookie'\\n    Sess->>User: Return Response object\n```\n\n----------------------------------------\n\nTITLE: Initializing Main App Component with Safety Checks\nDESCRIPTION: Main application component that handles initial safety checks (like git repository verification) before rendering the chat interface. Uses Ink components for terminal rendering and includes conditional UI logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/01_terminal_ui__ink_components_.md#2025-04-22_snippet_0\n\nLANGUAGE: tsx\nCODE:\n```\n// File: codex-cli/src/app.tsx (Simplified)\n\n// ... imports ...\nimport TerminalChat from \"./components/chat/terminal-chat\";\nimport { ConfirmInput } from \"@inkjs/ui\";\nimport { Box, Text, useApp } from \"ink\";\nimport React, { useState } from \"react\";\n\nexport default function App({ /* ...props... */ }): JSX.Element {\n  const app = useApp();\n  const [accepted, setAccepted] = useState(/* ... */);\n  const inGitRepo = /* ... check if in git ... */;\n\n  // If not in a git repo and not yet accepted, show a warning\n  if (!inGitRepo && !accepted) {\n    return (\n      <Box flexDirection=\"column\" /* ...styling... */>\n        <Text color=\"yellow\">Warning! Not in a git repo.</Text>\n        <ConfirmInput // <-- An Ink component for Yes/No!\n          onConfirm={() => setAccepted(true)}\n          onCancel={() => app.exit()}\n        />\n      </Box>\n    );\n  }\n\n  // Otherwise, render the main chat interface\n  return <TerminalChat /* ...props... */ />;\n}\n```\n\n----------------------------------------\n\nTITLE: Expected Output Example for LangGraph Interrupt & Resume Workflow - Output Text\nDESCRIPTION: Presents the expected terminal output of the entire LangGraph workflow, including the steps for planning, approval node interrupt, simulated human resumption, and execution completion. Includes console messages, state transitions, and interrupt/resume feedback for validation and comparison purposes. This is not code to be executed but an example of system output.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_17\n\nLANGUAGE: text\nCODE:\n```\n--- Initial Invocation ---\n{'planner': {'plan': 'Plan: Execute risky action X.'}}\n{'approval_gate': None} # Node starts execution\n--- Requesting Human Approval ---\nProposed Plan: Plan: Execute risky action X.\n{'__interrupt__': (Interrupt(value='Plan: Execute risky action X.', resumable=True, ns=..., when='during'),)} # Interrupt occurs\n\n!! Graph Interrupted !!\nInterrupt Value (Plan): Plan: Execute risky action X.\n\n--- Resuming with Decision: 'Approved, proceed with caution.' ---\n{'approval_gate': {'feedback': 'Approved, proceed with caution.'}} # Node resumes and finishes\n--- Resumed with feedback: Approved, proceed with caution. ---\n{'executor': {}} # Executor node runs\n--- Executing Plan ---\nExecuting 'Plan: Execute risky action X.' based on feedback: Approved, proceed with caution.\n{'__end__': {'plan': 'Plan: Execute risky action X.', 'feedback': 'Approved, proceed with caution.'}} # Graph finishes\n```\n\n----------------------------------------\n\nTITLE: Visualizing OpenManus Architecture with Mermaid Flow Chart\nDESCRIPTION: This mermaid flowchart illustrates the architecture of the OpenManus framework, showing the relationships between core components such as BaseAgent, Tools, LLM, Memory, Flows, and DockerSandbox. It visualizes how different components interact, with the BaseAgent using LLM for thinking and Tools for execution, while Flows orchestrate multiple agents.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"BaseAgent\"]\n    A1[\"Tool / ToolCollection\"]\n    A2[\"LLM\"]\n    A3[\"Message / Memory\"]\n    A4[\"Schema\"]\n    A5[\"BaseFlow\"]\n    A6[\"DockerSandbox\"]\n    A7[\"Configuration (Config)\"]\n    A8[\"MCP (Model Context Protocol)\"]\n    A0 -- \"Uses LLM for thinking\" --> A2\n    A0 -- \"Uses Memory for context\" --> A3\n    A0 -- \"Executes Tools\" --> A1\n    A5 -- \"Orchestrates Agents\" --> A0\n    A1 -- \"Uses Sandbox for execution\" --> A6\n    A2 -- \"Reads LLM Config\" --> A7\n    A6 -- \"Reads Sandbox Config\" --> A7\n    A7 -- \"Provides MCP Config\" --> A8\n    A8 -- \"Provides Dynamic Tools\" --> A1\n    A8 -- \"Extends BaseAgent\" --> A0\n    A4 -- \"Defines Agent Structures\" --> A0\n    A4 -- \"Defines Message Structure\" --> A3\n    A2 -- \"Processes Messages\" --> A3\n    A5 -- \"Uses Tools\" --> A1\n    A4 -- \"Defines Tool Structures\" --> A1\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Protocol in Python\nDESCRIPTION: This code snippet defines the Agent protocol using Python's runtime_checkable and Protocol. It specifies the required properties and methods that any Agent must implement, including metadata, id, on_message, save_state, load_state, and close.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@runtime_checkable\nclass Agent(Protocol):\n    @property\n    def metadata(self) -> AgentMetadata: ...\n\n    @property\n    def id(self) -> AgentId: ...\n\n    async def on_message(self, message: Any, ctx: MessageContext) -> Any: ...\n\n    async def save_state(self) -> Mapping[str, Any]: ...\n\n    async def load_state(self, state: Mapping[str, Any]) -> None: ...\n\n    async def close(self) -> None: ...\n```\n\n----------------------------------------\n\nTITLE: Creating Internal Iterator in LevelDB C++\nDESCRIPTION: Implementation of DBImpl::NewInternalIterator function in LevelDB. It gathers iterators from MemTable, immutable MemTable, and SSTables, then creates a MergingIterator to combine them.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/07_iterator.md#2025-04-22_snippet_2\n\nLANGUAGE: C++\nCODE:\n```\nIterator* DBImpl::NewInternalIterator(const ReadOptions& options,\n                                      SequenceNumber* latest_snapshot,\n                                      uint32_t* seed) {\n  mutex_.Lock(); // Need lock to access shared state (mem_, imm_, versions_)\n  *latest_snapshot = versions_->LastSequence();\n  *seed = ++seed_; // For random sampling\n\n  // Collect together all needed child iterators\n  std::vector<Iterator*> list;\n  // Add iterator for active MemTable\n  list.push_back(mem_->NewIterator());\n  mem_->Ref(); // Manage lifetime with ref counting\n\n  // Add iterator for immutable MemTable (if it exists)\n  if (imm_ != nullptr) {\n    list.push_back(imm_->NewIterator());\n    imm_->Ref();\n  }\n\n  // Add iterators for all SSTable files in the current Version\n  versions_->current()->AddIterators(options, &list);\n  versions_->current()->Ref();\n\n  // Create the MergingIterator\n  Iterator* internal_iter =\n      NewMergingIterator(&internal_comparator_, &list[0], list.size());\n\n  // Register cleanup function to Unref MemTables/Version when iterator is deleted\n  IterState* cleanup = new IterState(&mutex_, mem_, imm_, versions_->current());\n  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, nullptr);\n\n  mutex_.Unlock();\n  return internal_iter;\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Flask Request/Response Flow with Mermaid Sequence Diagram\nDESCRIPTION: A sequence diagram that illustrates the complete HTTP request/response cycle in Flask applications, showing interactions between the browser, WSGI server, Flask app, request context, and view functions. The diagram traces all steps from initial HTTP request to final response generation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/03_request_and_response_objects.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Browser\n    participant WSGIServer as WSGI Server\n    participant FlaskApp as Flask App (wsgi_app)\n    participant RequestCtx as Request Context\n    participant ReqObj as Request Object\n    participant Routing\n    participant ViewFunc as Your View Function\n    participant RespObj as Response Object\n\n    Browser->>+WSGIServer: Sends HTTP Request (e.g., GET /search?query=flask)\n    WSGIServer->>+FlaskApp: Calls app(environ, start_response)\n    FlaskApp->>+RequestCtx: Creates Request Context(environ)\n    RequestCtx->>+ReqObj: Creates Request(environ)\n    RequestCtx-->>-FlaskApp: Request Context ready (request is now available)\n    FlaskApp->>+Routing: Matches request.path, request.method\n    Routing-->>-FlaskApp: Finds view_func=search, args={}\n    FlaskApp->>+ViewFunc: Calls search()\n    ViewFunc->>ReqObj: Accesses request.args.get('query')\n    ViewFunc-->>-FlaskApp: Returns \"You searched for: flask\" (string)\n    FlaskApp->>+RespObj: Calls make_response(\"...\")\n    RespObj-->>-FlaskApp: Response object created (status=200, body=\"...\", headers={...})\n    FlaskApp-->>-WSGIServer: Returns Response (via start_response, iterable body)\n    WSGIServer-->>-Browser: Sends HTTP Response\n    Note right of FlaskApp: Request Context is torn down\n```\n\n----------------------------------------\n\nTITLE: Console Output Confirmation of Background Task Execution (Text)\nDESCRIPTION: Shows the expected output printed to the console by the `write_log` function (defined in a previous snippet) when it runs in the background *after* the API response has been sent. This confirms the task executed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nLog written: Notification sent to: test@example.com\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram Illustrating FastAPI Background Task Flow (Mermaid)\nDESCRIPTION: A Mermaid sequence diagram visualizing the interaction flow when a request triggers a FastAPI endpoint using background tasks. It shows the client request, FastAPI/Starlette processing, path function execution, task scheduling via `add_task`, immediate response to the client, and subsequent background task execution by Starlette.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_7\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastAPIApp as FastAPI App (via Starlette)\n    participant PathFunc as send_notification\n    participant BGTasks as BackgroundTasks Object\n    participant BGExecutor as Background Task Executor (Starlette)\n    participant TaskFunc as write_log\n\n    Client->>+FastAPIApp: POST /send-notification/test@example.com\n    FastAPIApp->>FastAPIApp: Route to send_notification\n    FastAPIApp->>+PathFunc: Call send_notification(email=\"...\", background_tasks=BGTasks)\n    PathFunc->>+BGTasks: background_tasks.add_task(write_log, \"...\")\n    BGTasks-->>-PathFunc: Task added to internal list\n    PathFunc-->>-FastAPIApp: Return response {\"message\": \"...\"}\n    Note over FastAPIApp: FastAPI/Starlette prepares to send response AND notes background tasks\n    FastAPIApp-->>-Client: Send HTTP 200 OK Response\n    Note over FastAPIApp: Response sent, now run background tasks\n    FastAPIApp->>+BGExecutor: Execute tasks from BGTasks object\n    BGExecutor->>+TaskFunc: Call write_log(\"...\")\n    TaskFunc->>TaskFunc: Write to log.txt\n    TaskFunc-->>-BGExecutor: Task finished\n    BGExecutor-->>-FastAPIApp: All tasks finished\n\n```\n\n----------------------------------------\n\nTITLE: Simplified View of NumPy Type Aliases Definition\nDESCRIPTION: This code snippet demonstrates how NumPy defines and manages its type aliases. It shows the structure of dictionaries used to map type names and aliases to actual type objects, which is crucial for resolving dtype specifications.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/04_numeric_types___numerictypes__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Simplified view from numpy/core/_type_aliases.py\n\n# ... (definitions of actual types like np.int8, np.float64) ...\n\nallTypes = {\n    'int8': np.int8,\n    'int16': np.int16,\n    # ...\n    'float64': np.float64,\n    # ...\n    'signedinteger': np.signedinteger, # Abstract type\n    'integer': np.integer,           # Abstract type\n    'number': np.number,             # Abstract type\n    # ... etc\n}\n\n_aliases = {\n    'double': 'float64', # \"double\" maps to the key \"float64\"\n    'int_': 'intp',      # \"int_\" maps to the key \"intp\" (platform dependent type)\n    # ... etc\n}\n\nsctypeDict = {} # Dictionary mapping names/aliases to types\n# Populate sctypeDict using allTypes and _aliases\n# ... (code to merge these dictionaries) ...\n\n# When you do np.dtype('double'), NumPy uses sctypeDict (or similar logic)\n# to find that 'double' means np.float64.\n```\n\n----------------------------------------\n\nTITLE: MemTable Write Flow and Flush Process\nDESCRIPTION: Demonstrates the flow of write operations and the process of flushing a full MemTable to disk, including the creation of new MemTables and background flush operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/02_memtable.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    subgraph Writes\n        A[Incoming Writes: Put/Delete] --> B(Active MemTable mem_);\n    end\n\n    subgraph MemTable Full\n        B -- Reaches Size Limit --> C{Freeze mem_ -> becomes imm_};\n        C --> D(Create New Empty mem_);\n        A --> D;\n        C --> E{Background Flush};\n    end\n\n    subgraph Background Flush\n        E -- Reads Data --> F(Immutable MemTable imm_);\n        F -- Uses BuildTable --> G([Level-0 SSTable on Disk]);\n        G -- Flush Complete --> H{Discard imm_};\n    end\n\n    style G fill:#f9f,stroke:#333,stroke-width:2px\n```\n\n----------------------------------------\n\nTITLE: Visualizing Pydantic Model Processing with Mermaid\nDESCRIPTION: A Mermaid sequence diagram illustrating the lifecycle of a Pydantic model. It shows the interaction between the developer defining the class, the Python layer intercepting class creation, generating the `CoreSchema`, passing it to the `pydantic-core` Rust engine for compilation, attaching the resulting validator/serializer, and their subsequent use in validation (`User(...)`) and serialization (`user.model_dump()`).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant Dev as Developer\n    participant PyClassDef as Python Class Definition\n    participant PydanticPy as Pydantic (Python Layer)\n    participant CoreSchemaDS as CoreSchema (Data Structure)\n    participant PydanticCore as pydantic-core (Rust Engine)\n    participant UserCode as User Code\n\n    Dev->>PyClassDef: Define `class User(BaseModel): ...`\n    PyClassDef->>PydanticPy: Python creates class, Pydantic metaclass intercepts\n    PydanticPy->>PydanticPy: Inspects fields, config, decorators\n    PydanticPy->>CoreSchemaDS: Generates detailed CoreSchema\n    PydanticPy->>PydanticCore: Pass CoreSchema to Rust engine\n    PydanticCore->>PydanticCore: Compile SchemaValidator from CoreSchema\n    PydanticCore->>PydanticCore: Compile SchemaSerializer from CoreSchema\n    PydanticCore-->>PydanticPy: Return compiled Validator & Serializer objects\n    PydanticPy->>PyClassDef: Attach Validator/Serializer to class object (`User`)\n\n    UserCode->>PyClassDef: Instantiate: `User(...)` or `User.model_validate(...)`\n    PyClassDef->>PydanticCore: Use attached SchemaValidator\n    PydanticCore->>PydanticCore: Execute fast validation logic\n    alt Validation OK\n        PydanticCore-->>UserCode: Return validated instance/data\n    else Validation Error\n        PydanticCore-->>UserCode: Raise ValidationError\n    end\n\n    UserCode->>PyClassDef: Serialize: `user.model_dump()`\n    PyClassDef->>PydanticCore: Use attached SchemaSerializer\n    PydanticCore->>PydanticCore: Execute fast serialization logic\n    PydanticCore-->>UserCode: Return dict/JSON string\n```\n```\n\n----------------------------------------\n\nTITLE: Running MCPAgent with stdio Connection in OpenManus\nDESCRIPTION: Command to start an MCPAgent that connects to a running MCPServer via stdio. The --interactive flag enables chat interaction with the agent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# In a NEW terminal, in the root directory of OpenManus\n# Run the MCP agent runner script\npython run_mcp.py --connection stdio --interactive\n```\n\n----------------------------------------\n\nTITLE: Starlette Background Task Execution\nDESCRIPTION: Starlette's middleware stack executes background tasks after the response is sent using anyio's task groups. This happens in the exception middleware and response handling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/08_background_tasks.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nanyio.create_task_group().start_soon()\n```\n\n----------------------------------------\n\nTITLE: Example Agent Card JSON Structure\nDESCRIPTION: This JSON snippet illustrates the structure of a typical `agent.json` file as defined by the Google A2A protocol. It includes essential agent metadata like name, description, version, the communication endpoint URL, supported capabilities (e.g., streaming), default input/output modes, a list of skills the agent offers, and provider information. This file serves as the agent's public profile for discovery.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/01_agent_card.md#2025-04-22_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n// File: /.well-known/agent.json (Example)\n{\n  \"name\": \"Text Summarizer Bot\",\n  \"description\": \"Summarizes long text documents.\",\n  \"version\": \"1.0.0\",\n  \"url\": \"http://example-agent.com/a2a\", // Where to send tasks\n  \"capabilities\": {\n    \"streaming\": false // Doesn't support real-time updates\n  },\n  \"defaultInputModes\": [\"text\"], // Primarily accepts text\n  \"defaultOutputModes\": [\"text\"], // Primarily outputs text\n  \"skills\": [\n    {\n      \"id\": \"summarize\",\n      \"name\": \"Summarize Text\",\n      \"description\": \"Provide text, get a short summary.\"\n    }\n  ],\n  \"provider\": {\n    \"organization\": \"AI Helpers Inc.\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Conceptual Internal Storage of dspy.Example in Python\nDESCRIPTION: Presents a conceptual code comment illustrating how a `dspy.Example` internally uses a dictionary (conceptually `_store`) to hold the key-value pairs provided during initialization. This snippet helps understand the underlying data structure and requires context from the `dspy` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Conceptual internal structure\nexample = dspy.Example(question=\"What is DSPy?\", answer=\"A framework...\")\n# example._store == {'question': 'What is DSPy?', 'answer': 'A framework...'}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Node Execution Flow in LangGraph using Mermaid\nDESCRIPTION: Presents a Mermaid sequence diagram illustrating the internal execution process when a specific node (e.g., \"adder\") is run within LangGraph. The diagram shows the sequence of interactions: the Pregel Engine reads the current state ('value') via Channels, invokes the node's function (`add_one`) with the state, the function executes its logic, returns the update dictionary, and finally, the engine writes the updated value back to the shared state via Channels before determining the next node to execute.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/02_nodes___pregelnode__.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant Engine as Pregel Engine\n    participant State (via Channels)\n    participant AdderNode as adder (add_one func)\n\n    Engine->>State (via Channels): Read 'value' (current state is {'value': 5})\n    State (via Channels)-->>Engine: Returns {'value': 5}\n    Engine->>AdderNode: Invoke add_one({'value': 5})\n    Note over AdderNode: Function executes: 5 + 1 = 6\n    AdderNode-->>Engine: Return {'value': 6}\n    Engine->>State (via Channels): Write update: 'value' = 6\n    State (via Channels)-->>Engine: Acknowledge (state is now {'value': 6})\n    Engine->>Engine: Find next node based on edge from \"adder\"\n```\n```\n\n----------------------------------------\n\nTITLE: Implementing Flask Request Lifecycle Hooks\nDESCRIPTION: Shows how to use Flask's before_request, route handlers, and teardown_request decorators to manage request lifecycle. Demonstrates storing and accessing data in Flask's 'g' object across different phases of request processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/05_context_globals___current_app____request____session____g__.md#2025-04-22_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n@app.before_request\ndef load_request_data():\n  g.request_time = time.time()\n  g.user = 'Guest'\n  current_app.logger.info(f\"Before request: Set g.user to {g.user}\")\n\n@app.route('/show-g')\ndef show_g():\n  req_time = g.get('request_time', 'Not Set')\n  current_user = g.get('user', 'Unknown')\n  return f'Data from g:<br>Request Time: {req_time}<br>User: {current_user}'\n\n@app.teardown_request\ndef teardown_request_data(exception=None):\n    req_time = g.pop('request_time', None)\n    user = g.pop('user', None)\n    if req_time:\n      duration = time.time() - req_time\n      current_app.logger.info(f\"Teardown request: User={user}, Duration={duration:.4f}s\")\n    else:\n      current_app.logger.info(\"Teardown request: g values already popped or not set.\")\n```\n\n----------------------------------------\n\nTITLE: Conceptual DOM Tree Structure Example\nDESCRIPTION: Example showing the hierarchical structure of a simplified DOM tree with highlight indices for interactive elements\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n<body> [no index]\n |-- <div> [no index]\n |    |-- <input aria-label=\"Search\"> [highlight_index: 5]\n |    +-- <button> [highlight_index: 6]\n |         +-- \"Google Search\" (TextNode)\n +-- <a> href=\"/images\"> [highlight_index: 7]\n      +-- \"Images\" (TextNode)\n```\n\n----------------------------------------\n\nTITLE: Execution Flow Diagram with Mermaid\nDESCRIPTION: A sequence diagram showing the journey of an action request from the Agent to the browser click. It illustrates how the Controller orchestrates the process by receiving requests, consulting the Registry, validating parameters, calling action functions, and returning results.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/05_action_controller___registry.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant Controller\n    participant Registry\n    participant ClickFunc as click_element Function\n    participant BC as BrowserContext\n\n    Note over Agent: LLM decided: click_element(index=5)\n    Agent->>Controller: act(action={\"click_element\": {\"index\": 5}}, browser_context=BC)\n    Note over Controller: Identify action and params\n    Controller->>Controller: action_name = \"click_element\", params = {\"index\": 5}\n    Note over Controller: Ask Registry for the tool\n    Controller->>Registry: Get action definition for \"click_element\"\n    Registry-->>Controller: Return RegisteredAction(name=\"click_element\", function=ClickFunc, param_model=ClickElementAction, ...)\n    Note over Controller: Validate params using param_model\n    Controller->>Controller: ClickElementAction(index=5) # Validation OK\n    Note over Controller: Execute the function\n    Controller->>ClickFunc: ClickFunc(params=ClickElementAction(index=5), browser=BC)\n    Note over ClickFunc: Perform the click via BrowserContext\n    ClickFunc->>BC: Find element with index 5\n    BC-->>ClickFunc: Element reference\n    ClickFunc->>BC: Execute click on element\n    BC-->>ClickFunc: Click successful\n    ClickFunc-->>Controller: Return ActionResult(extracted_content=\"Clicked button...\")\n    Controller-->>Agent: Return ActionResult\n```\n\n----------------------------------------\n\nTITLE: Implementing Session Management in Python\nDESCRIPTION: Core implementation of the BaseSession class that handles request/response matching using unique IDs and waiting mechanisms. This is the foundation for both client and server session objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/08_client_server_sessions___clientsession____serversession__.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from shared/session.py\nimport anyio\nfrom mcp.types import JSONRPCRequest, JSONRPCResponse, JSONRPCError, ErrorData\n\nclass BaseSession:\n    def __init__(self, read_stream, write_stream, ...):\n        self._read_stream = read_stream\n        self._write_stream = write_stream\n        self._response_streams = {} # Stores 'waiters' for responses, keyed by request ID\n        self._request_id_counter = 0\n        # ... other setup ...\n\n    async def send_request(self, request, result_type):\n        # 1. Get a new unique ID\n        request_id = self._request_id_counter\n        self._request_id_counter += 1\n\n        # 2. Create a 'waiter' (memory stream) to receive the response\n        response_receiver, response_sender = anyio.create_memory_object_stream(1)\n        self._response_streams[request_id] = response_sender\n\n        # 3. Format the request with the ID\n        jsonrpc_request = JSONRPCRequest(id=request_id, **request.model_dump())\n\n        # 4. Send it over the write stream\n        await self._write_stream.send(JSONRPCMessage(jsonrpc_request))\n\n        # 5. Wait for the response to arrive on the 'waiter' stream\n        response_or_error = await response_receiver.receive() # Timeout logic omitted\n\n        # 6. Process response/error and return result\n        if isinstance(response_or_error, JSONRPCError):\n            raise McpError(response_or_error.error)\n        else:\n            return result_type.model_validate(response_or_error.result)\n\n    async def _receive_loop(self):\n        # Runs in the background, reading from the read_stream\n        async for message in self._read_stream:\n            if isinstance(message.root, (JSONRPCResponse, JSONRPCError)):\n                # It's a response or error for a request we sent\n                request_id = message.root.id\n                # Find the matching 'waiter' stream\n                response_sender = self._response_streams.pop(request_id, None)\n                if response_sender:\n                    # Send the response back to the waiting send_request call\n                    await response_sender.send(message.root)\n                else:\n                    print(f\"Warning: Received response for unknown request ID {request_id}\")\n            elif isinstance(message.root, JSONRPCRequest):\n                # It's a new request *from* the other side\n                # Subclasses (Client/ServerSession) handle this differently\n                await self._handle_incoming_request(message.root)\n            elif isinstance(message.root, JSONRPCNotification):\n                 # It's a notification *from* the other side\n                 await self._handle_incoming_notification(message.root)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Pydantic Validation in Python\nDESCRIPTION: This code snippet shows how Pydantic handles validation for a SimpleMessage model. It includes examples of successful object creation and various validation errors, such as missing required fields, invalid role values, and incorrect data types.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/06_schema.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# --- Invalid Role ---\ntry:\n    msg3 = SimpleMessage(role=\"system\", content=\"System message\") # 'system' is not allowed\n    print(\"msg3 created successfully:\", msg3.model_dump())\nexcept ValidationError as e:\n    print(\"\\nError creating msg3:\")\n    print(e) # Pydantic catches the wrong role\n\n# --- Wrong Data Type for 'content' ---\ntry:\n    msg4 = SimpleMessage(role=\"user\", content=123) # content should be string\n    print(\"msg4 created successfully:\", msg4.model_dump())\nexcept ValidationError as e:\n    print(\"\\nError creating msg4:\")\n    print(e) # Pydantic catches the type error\n```\n\n----------------------------------------\n\nTITLE: WriteBatch Internal Flow Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram showing the internal flow of WriteBatch operations, including interactions between application, DBImpl, WAL, and MemTable.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/05_writebatch.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant App as Application\n    participant DBImpl as DBImpl::Write\n    participant WriteBatch as WriteBatch Object\n    participant WAL as WAL File (Disk)\n    participant MemTable as MemTable (RAM)\n\n    App->>WriteBatch: batch.Put(\"k1\", \"v1\")\n    App->>WriteBatch: batch.Delete(\"k2\")\n    App->>WriteBatch: batch.Put(\"k3\", \"v3\")\n    App->>DBImpl: db->Write(options, &batch)\n    DBImpl->>WriteBatch: Get serialized contents (rep_)\n    WriteBatch-->>DBImpl: Return byte string representing all ops\n    DBImpl->>WAL: AddRecord(entire batch content)\n    Note right of WAL: Single disk write (if sync)\n    WAL-->>DBImpl: WAL Write OK\n    DBImpl->>WriteBatch: Iterate through operations\n    loop Apply each operation from Batch\n        WriteBatch-->>DBImpl: Next Op: Put(\"k1\", \"v1\")\n        DBImpl->>MemTable: Add(\"k1\", \"v1\")\n        WriteBatch-->>DBImpl: Next Op: Delete(\"k2\")\n        DBImpl->>MemTable: Add(\"k2\", deletion_marker)\n        WriteBatch-->>DBImpl: Next Op: Put(\"k3\", \"v3\")\n        DBImpl->>MemTable: Add(\"k3\", \"v3\")\n    end\n    MemTable-->>DBImpl: MemTable Updates Done\n    DBImpl-->>App: Write Successful\n```\n\n----------------------------------------\n\nTITLE: Visualizing Agent Interaction Flow using Mermaid\nDESCRIPTION: A Mermaid sequence diagram illustrating the interaction between a User, MultiStepAgent (MSA), AgentMemory, the LLM Brain, and a Tool. It shows the steps involved in processing a user task, including storing the task, executing Think-Act-Observe cycles (fetching history, querying the LLM, executing a tool, storing results), and updating the AgentMemory at each stage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/04_agentmemory.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MSA as MultiStepAgent\n    participant Memory as AgentMemory\n    participant Model as LLM Brain\n    participant Tool\n\n    User->>MSA: run(\"Task: Capital & Weather?\")\n    MSA->>Memory: Store TaskStep(\"Capital & Weather?\")\n    loop Think-Act-Observe Cycle (Step 1)\n        MSA->>Memory: write_memory_to_messages() --> Get History [Task]\n        MSA->>Model: What's next? (with History)\n        Model-->>MSA: Think: Need capital. Act: search(...) -> LLM Response\n        MSA->>Memory: Store LLM Response in new ActionStep\n        MSA->>Tool: Execute search(...)\n        Tool-->>MSA: Observation: \"Paris\"\n        MSA->>Memory: Store Observation in current ActionStep\n        MSA->>Memory: Append finished ActionStep to steps list\n    end\n    loop Think-Act-Observe Cycle (Step 2)\n        MSA->>Memory: write_memory_to_messages() --> Get History [Task, Step 1]\n        MSA->>Model: What's next? (with History)\n        Model-->>MSA: Think: Need weather. Act: weather(...) -> LLM Response\n        MSA->>Memory: Store LLM Response in new ActionStep\n        MSA->>Tool: Execute weather(...)\n        Tool-->>MSA: Observation: \"Sunny, 25C\"\n        MSA->>Memory: Store Observation in current ActionStep\n        MSA->>Memory: Append finished ActionStep to steps list\n    end\n    MSA-->>User: Final Answer\n```\n\n----------------------------------------\n\nTITLE: Illustrating Pydantic Model Creation Sequence with Mermaid\nDESCRIPTION: This sequence diagram illustrates the steps involved when a Pydantic model using `Field()` is defined. It shows the interaction between the developer defining the class, the Python interpreter, Pydantic's `ModelMetaclass`, and the `FieldInfo` class. Key steps include the metaclass inspecting attributes, calling `FieldInfo` to create configuration objects based on type hints and `Field()` arguments, storing these `FieldInfo` instances, and finally returning the prepared model class.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/02_fields__fieldinfo___field_function_.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Dev as Developer\n    participant Py as Python\n    participant Meta as ModelMetaclass\n    participant FInfo as FieldInfo\n\n    Dev->>Py: Define `class User(BaseModel): name: str = Field(alias='userName')`\n    Py->>Meta: Ask to create the `User` class\n    Meta->>Meta: Inspect `name` attribute: finds `str` and `Field(alias='userName')` assignment\n    Meta->>FInfo: Create `FieldInfo` using `str` and the `Field()` arguments\n    FInfo-->>Meta: Return `FieldInfo(annotation=str, alias='userName', default=PydanticUndefined, ...)`\n    Meta->>Meta: Store this `FieldInfo` instance in `cls.__pydantic_fields__['name']`\n    Meta->>Meta: (Repeat for other fields like 'age', 'email')\n    Meta-->>Py: Return the fully prepared `User` class (with `model_fields` populated)\n    Py-->>Dev: `User` class is ready\n```\n\n----------------------------------------\n\nTITLE: Visualizing Click Exception Handling with Mermaid Sequence Diagram\nDESCRIPTION: This diagram illustrates the sequence of events when a BadParameter exception is raised due to invalid user input. It shows the flow from user command entry through Click's runtime, parameter type conversion, exception handling, and final error display.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant CLI as YourApp.py\n    participant ClickRuntime\n    participant ParamType as ParamType (e.g., click.INT)\n    participant ClickExceptionHandling\n\n    User->>CLI: python YourApp.py --count five\n    CLI->>ClickRuntime: Starts command execution\n    ClickRuntime->>ParamType: Calls convert(value='five', ...) for '--count'\n    ParamType->>ParamType: Tries int('five'), raises ValueError\n    ParamType->>ClickExceptionHandling: Catches ValueError, calls self.fail(...)\n    ClickExceptionHandling->>ClickExceptionHandling: Raises BadParameter(\"...'five' is not...\")\n    ClickExceptionHandling-->>ClickRuntime: BadParameter propagates up\n    ClickRuntime->>ClickExceptionHandling: Catches BadParameter exception\n    ClickExceptionHandling->>ClickExceptionHandling: Calls exception.show()\n    ClickExceptionHandling->>CLI: Prints formatted \"Error: Invalid value...\" to stderr\n    ClickExceptionHandling->>CLI: Calls sys.exit(exception.exit_code)\n    CLI-->>User: Shows error message and exits\n```\n\n----------------------------------------\n\nTITLE: Using use_enum_values in Pydantic ConfigDict for Python\nDESCRIPTION: Illustrates how to use the use_enum_values configuration option to serialize enum members as their values rather than as enum objects.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/03_configuration__configdict___configwrapper_.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\nfrom pydantic import BaseModel, ConfigDict\n\nclass Status(Enum):\n    PENDING = \"pending\"\n    PROCESSING = \"processing\"\n    COMPLETE = \"complete\"\n\nclass Order(BaseModel):\n    order_id: int\n    status: Status\n\n    model_config = ConfigDict(\n        use_enum_values=True # Use the string value of Status\n    )\n\norder = Order(order_id=101, status=Status.PROCESSING)\nprint(f\"Order object status type: {type(order.status)}\")\n# Expected Output: Order object status type: <enum 'Status'>\n\nprint(f\"Order dumped: {order.model_dump()}\")\n# Expected Output: Order dumped: {'order_id': 101, 'status': 'processing'}\n# Note: 'status' is the string \"processing\", not Status.PROCESSING\n```\n\n----------------------------------------\n\nTITLE: Visualizing Codex Architecture with Mermaid Flowchart\nDESCRIPTION: This Mermaid flowchart illustrates the architecture and component interactions of the Codex tool. It shows the relationships between the agent loop, terminal UI, approval policy, command execution, configuration management, response handling, single-pass mode, and input handling components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Agent Loop\"]\n    A1[\"Terminal UI (Ink Components)\"]\n    A2[\"Approval Policy & Security\"]\n    A3[\"Command Execution & Sandboxing\"]\n    A4[\"Configuration Management\"]\n    A5[\"Response & Tool Call Handling\"]\n    A6[\"Single-Pass Mode\"]\n    A7[\"Input Handling (TextBuffer/Editor)\"]\n    A0 -- \"Drives updates for\" --> A1\n    A0 -- \"Processes responses via\" --> A5\n    A0 -- \"Consults policy from\" --> A2\n    A0 -- \"Loads config using\" --> A4\n    A1 -- \"Uses editor for input\" --> A7\n    A2 -- \"Dictates sandboxing for\" --> A3\n    A4 -- \"Provides settings to\" --> A2\n    A5 -- \"Triggers\" --> A3\n    A7 -- \"Provides user input to\" --> A0\n    A0 -- \"Can initiate\" --> A6\n    A6 -- \"Renders via specific UI\" --> A1\n```\n\n----------------------------------------\n\nTITLE: Click Application with Custom Validation Callback\nDESCRIPTION: Enhanced Click application that implements custom validation logic using a callback function. This example validates that the count parameter is positive, raising a BadParameter exception with a custom error message when validation fails.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# count_app_validate.py\nimport click\n\n# 1. Define a validation callback function\ndef validate_count(ctx, param, value):\n  \"\"\"Callback to ensure count is positive.\"\"\"\n  if value <= 0:\n    # 2. Raise BadParameter if validation fails\n    raise click.BadParameter(\"Count must be a positive number.\")\n  # 3. Return the value if it's valid\n  return value\n\n@click.command()\n# 4. Attach the callback to the --count option\n@click.option('--count', default=1, type=click.INT, help='Number of times to print.',\n              callback=validate_count) # <-- Added callback\n@click.argument('message')\ndef repeat(count, message):\n  \"\"\"Prints MESSAGE the specified number of times (must be positive).\"\"\"\n  for _ in range(count):\n    click.echo(message)\n\nif __name__ == '__main__':\n  repeat()\n```\n\n----------------------------------------\n\nTITLE: Illustrating State and Node Updates in LangGraph - Python\nDESCRIPTION: This Python code snippet provides a schematic overview (with comments) of how different nodes, such as an adder and multiplier, interact with a shared state dictionary within a LangGraph pipeline. It outlines the initial state, node purpose, and transformation flow from START through the adder and multiplier to END. It is intended purely for illustration and does not require any dependencies beyond Python syntax. There are no input/output operations in this snippet; it is meant to visually map roles and state updates for Channels.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# State: {'value': int}\\n# Node 1: adder (reads 'value', returns {'value': value + 1})\\n# Node 2: multiplier (reads 'value', returns {'value': value * 2})\\n# Flow: START -> adder -> multiplier -> END\n```\n\n----------------------------------------\n\nTITLE: Defining the Tutorial Generator Shared Store Schema in Python\nDESCRIPTION: This Python snippet declares the shared Store dict holding inputs, intermediate, and output data for the workflow. It establishes all key fields with descriptive comments, including repository info, output settings, tutorial data collections, and a final output directory. Dependencies are standard Python dicts/sets and optional YAML; no external library is required. Inputs include repo paths, patterns, size constraints, and language; outputs include files, abstractions, relationships, chapter ordering, chapters, and output path. Assumes external population and usage; intended as a store schema template for workflow nodes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nshared = {\n    # --- Inputs ---\n    \"repo_url\": None, # Provided by the user/main script if using GitHub\n    \"local_dir\": None, # Provided by the user/main script if using local directory\n    \"project_name\": None, # Optional, derived from repo_url/local_dir if not provided\n    \"github_token\": None, # Optional, from argument or environment variable\n    \"output_dir\": \"output\", # Default or user-specified base directory for output\n    \"include_patterns\": set(), # File patterns to include\n    \"exclude_patterns\": set(), # File patterns to exclude\n    \"max_file_size\": 100000, # Default or user-specified max file size\n    \"language\": \"english\", # Default or user-specified language for the tutorial\n\n    # --- Intermediate/Output Data ---\n    \"files\": [], # Output of FetchRepo: List of tuples (file_path: str, file_content: str)\n    \"abstractions\": [], # Output of IdentifyAbstractions: List of {\"name\": str (potentially translated), \"description\": str (potentially translated), \"files\": [int]} (indices into shared[\"files\"])\n    \"relationships\": { # Output of AnalyzeRelationships\n         \"summary\": None, # Overall project summary (potentially translated)\n         \"details\": [] # List of {\"from\": int, \"to\": int, \"label\": str (potentially translated)} describing relationships between abstraction indices.\n     },\n    \"chapter_order\": [], # Output of OrderChapters: List of indices into shared[\"abstractions\"], determining tutorial order\n    \"chapters\": [], # Output of WriteChapters: List of chapter content strings (Markdown, potentially translated), ordered according to chapter_order\n    \"final_output_dir\": None # Output of CombineTutorial: Path to the final generated tutorial directory (e.g., \"output/my_project\")\n}\n```\n\n----------------------------------------\n\nTITLE: Basic MCP Server Implementation\nDESCRIPTION: Minimal example of a FastMCP server implementation showing basic server setup and execution\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/01_cli___mcp__command_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# We'll learn about FastMCP in the next chapter!\n# For now, just know this creates a basic server.\nfrom mcp.server.fastmcp import FastMCP\n\n# Create an instance of our server\nserver = FastMCP(name=\"MyFirstServer\")\n\n# This is a standard Python check to make sure\n# the script is being run directly\nif __name__ == \"__main__\":\n    # Tell the server to start running\n    print(\"Starting MyFirstServer...\")\n    server.run()\n    print(\"MyFirstServer finished.\") # You might not see this if the server runs forever\n```\n\n----------------------------------------\n\nTITLE: Task Execution Sequence Diagram in Mermaid\nDESCRIPTION: This Mermaid sequence diagram shows the step-by-step process of how tasks are executed within a CrewAI Crew. It illustrates the interaction between the Crew, Tasks, and Agents, including context passing and result storage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/03_task.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Crew\n    participant T1 as Task 1\n    participant R_Agent as Researcher Agent\n    participant T2 as Task 2\n    participant P_Agent as Planner Agent\n\n    C->>T1: Prepare to Execute\n    Note right of T1: Task 1 selected\n    C->>R_Agent: Execute Task(T1.description, T1.expected_output)\n    R_Agent->>R_Agent: Use LLM, Profile, Tools...\n    R_Agent-->>C: Return TaskOutput (Cities List)\n    C->>C: Store TaskOutput from T1\n\n    C->>T2: Prepare to Execute\n    Note right of T2: Task 2 selected\n    Note right of C: Get Context (Output from T1)\n    C->>P_Agent: Execute Task(T2.description, T2.expected_output, context=T1_Output)\n    P_Agent->>P_Agent: Use LLM, Profile, Tools, Context...\n    P_Agent-->>C: Return TaskOutput (Itinerary)\n    C->>C: Store TaskOutput from T2\n```\n\n----------------------------------------\n\nTITLE: MCP Python SDK Architecture Diagram\nDESCRIPTION: A flowchart showing the relationships between different abstraction layers in the MCP Python SDK, from protocol types (A0) to CLI tools (A8), illustrating how components build upon each other.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"MCP Protocol Types\"]\n    A1[\"Client/Server Sessions\"]\n    A2[\"Communication Transports\"]\n    A3[\"FastMCP Server\"]\n    A4[\"FastMCP Resources\"]\n    A5[\"FastMCP Tools\"]\n    A6[\"FastMCP Prompts\"]\n    A7[\"FastMCP Context\"]\n    A8[\"CLI\"]\n    A1 -- \"Uses MCP Types\" --> A0\n    A1 -- \"Operates Over Transport\" --> A2\n    A2 -- \"Serializes/Deserializes MCP...\" --> A0\n    A3 -- \"Uses Session Logic\" --> A1\n    A3 -- \"Manages Resources\" --> A4\n    A3 -- \"Manages Tools\" --> A5\n    A3 -- \"Manages Prompts\" --> A6\n    A8 -- \"Runs/Configures Server\" --> A3\n    A5 -- \"Handlers Can Use Context\" --> A7\n    A4 -- \"Handlers Can Use Context\" --> A7\n    A7 -- \"Provides Access To Session\" --> A1\n    A7 -- \"Provides Access To Server\" --> A3\n```\n\n----------------------------------------\n\nTITLE: NumPy Core Implementation Structure\nDESCRIPTION: This snippet shows a simplified version of how NumPy's Python interface functions are imported from the underlying multiarray module. It illustrates the structure of NumPy's implementation, where Python wrapper functions call optimized C implementations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# From numpy/core/numeric.py - Simplified\nfrom . import multiarray\nfrom .multiarray import (\n    arange, array, asarray, asanyarray, # <-- Python functions defined here\n    empty, empty_like, zeros # <-- More functions\n    # ... many others ...\n)\n\n# The `array` function seen in multiarray.py is often a wrapper\n# that calls the actual C implementation.\n```\n\n----------------------------------------\n\nTITLE: Creating an Iterator for SSTable Access in C++\nDESCRIPTION: This code shows how TableCache provides an iterator for reading a specific SSTable file. It uses FindTable to get the Table object (from cache or disk), creates an iterator from it, and registers a cleanup function to release the cache handle when the iterator is no longer needed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/01_table___sstable___tablecache.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: table_cache.cc ---\n\n// Returns an iterator for reading the specified SSTable file.\nIterator* TableCache::NewIterator(const ReadOptions& options,\n                                  uint64_t file_number, uint64_t file_size,\n                                  Table** tableptr) {\n  // ... setup ...\n  Cache::Handle* handle = nullptr;\n  // Use FindTable to get the Table object (from cache or by opening file)\n  Status s = FindTable(file_number, file_size, &handle);\n  if (!s.ok()) {\n    return NewErrorIterator(s); // Return an iterator that yields the error\n  }\n\n  // Get the Table object from the cache handle\n  Table* table = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;\n  // Ask the Table object to create a new iterator for its data\n  Iterator* result = table->NewIterator(options);\n\n  // Important: Register cleanup to release the cache handle when iterator is done\n  result->RegisterCleanup(&UnrefEntry, cache_, handle);\n\n  // Optionally return the Table object itself\n  if (tableptr != nullptr) {\n    *tableptr = table;\n  }\n  return result;\n}\n```\n\n----------------------------------------\n\nTITLE: LLM Communication Sequence Diagram in Mermaid\nDESCRIPTION: A diagram illustrating the sequence of operations that occur when an agent uses the LLM class to communicate with a language model. It shows the flow from initial request through token counting, API communication, error handling, and response processing.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/01_llm.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant LLMClass as LLM Class (app/llm.py)\n    participant TokenCounter as Token Counter (app/llm.py)\n    participant OpenAIClient as OpenAI/Bedrock Client (app/llm.py, app/bedrock.py)\n    participant LLM_API as Actual LLM API (e.g., OpenAI, AWS Bedrock)\n\n    Agent->>+LLMClass: ask(messages)\n    LLMClass->>LLMClass: format_messages(messages)\n    LLMClass->>+TokenCounter: count_message_tokens(formatted_messages)\n    TokenCounter-->>-LLMClass: input_token_count\n    LLMClass->>LLMClass: check_token_limit(input_token_count)\n    Note over LLMClass: If limit exceeded, raise Error.\n    LLMClass->>+OpenAIClient: create_completion(formatted_messages, model, ...)\n    Note right of OpenAIClient: Handles retries on network errors etc.\n    OpenAIClient->>+LLM_API: Send HTTP Request\n    LLM_API-->>-OpenAIClient: Receive HTTP Response\n    OpenAIClient-->>-LLMClass: completion_response\n    LLMClass->>LLMClass: extract_content(completion_response)\n    LLMClass->>+TokenCounter: update_token_count(input_tokens, completion_tokens)\n    TokenCounter-->>-LLMClass: \n    LLMClass-->>-Agent: llm_answer (string)\n```\n\n----------------------------------------\n\nTITLE: Visualizing Config Loading Sequence with Mermaid\nDESCRIPTION: A sequence diagram illustrating the process of loading and initializing the Config object, including file reading, parsing, and validation steps.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant App as Application Start\n    participant CfgMod as app/config.py\n    participant Config as Config Singleton Object\n    participant TOML as config.toml File\n    participant Parser as TOML Parser & Pydantic\n    participant OtherMod as e.g., app/llm.py\n\n    App->>+CfgMod: import config\n    Note over CfgMod: First time loading module\n    CfgMod->>+Config: Config() called (implicitly via `config = Config()`)\n    Config->>Config: __new__ checks if _instance exists (it doesn't)\n    Config->>Config: Creates new Config instance (_instance)\n    Config->>Config: Calls __init__ (only runs once)\n    Config->>Config: _load_initial_config()\n    Config->>Config: _get_config_path() -> finds path\n    Config->>+TOML: Opens file\n    TOML-->>-Config: Returns file content\n    Config->>+Parser: Parses TOML content into dict\n    Parser-->>-Config: Returns raw_config dict\n    Config->>+Parser: Validates dict using Pydantic models (LLMSettings etc.)\n    Parser-->>-Config: Returns validated AppConfig object\n    Config->>Config: Stores validated config internally\n    Config-->>-CfgMod: Returns the single instance\n    CfgMod-->>-App: Provides `config` instance\n\n    App->>+OtherMod: Code runs (e.g., `LLM()`)\n    OtherMod->>+Config: Accesses property (e.g., `config.llm`)\n    Config-->>-OtherMod: Returns stored settings (e.g., Dict[str, LLMSettings])\n```\n\n----------------------------------------\n\nTITLE: Visualizing FastAPI Component Interactions with Mermaid\nDESCRIPTION: This Mermaid flowchart illustrates the relationships and dependencies between key FastAPI features, including application routing, path operations, Pydantic data validation, dependency injection, automatic documentation generation (OpenAPI), error handling, security utilities, and background tasks. It provides a high-level architectural overview of how these components work together within a FastAPI application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/FastAPI/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"FastAPI Application & Routing\"]\n    A1[\"Path Operations & Parameter Declaration\"]\n    A2[\"Data Validation & Serialization (Pydantic)\"]\n    A3[\"Dependency Injection\"]\n    A4[\"OpenAPI & Automatic Docs\"]\n    A5[\"Error Handling\"]\n    A6[\"Security Utilities\"]\n    A7[\"Background Tasks\"]\n    A0 -- \"Defines Routes for\" --> A1\n    A1 -- \"Uses for parameter/body val...\" --> A2\n    A1 -- \"Uses Depends() for dependen...\" --> A3\n    A0 -- \"Generates API spec for\" --> A4\n    A0 -- \"Manages global\" --> A5\n    A3 -- \"Injects BackgroundTasks object\" --> A7\n    A6 -- \"Uses Depends mechanism (Sec...\" --> A3\n    A6 -- \"Raises HTTPException on fai...\" --> A5\n    A4 -- \"Reads definitions from\" --> A1\n    A4 -- \"Reads Pydantic models for s...\" --> A2\n    A4 -- \"Reads security scheme defin...\" --> A6\n    A5 -- \"Handles RequestValidationEr...\" --> A2\n```\n\n----------------------------------------\n\nTITLE: Channel Detection in StateGraph Initialization in Python\nDESCRIPTION: This code snippet shows how StateGraph detects and creates appropriate channels for state management. It uses type hints and Annotated metadata to determine whether to use LastValue, BinaryOperatorAggregate, or other channel types for each state field.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# graph/state.py (Simplified view of channel detection)\n\ndef _get_channels(schema: Type[dict]) -> tuple[...]:\n    # ... gets type hints including Annotated metadata ...\n    type_hints = get_type_hints(schema, include_extras=True)\n    all_keys = {}\n    for name, typ in type_hints.items():\n         # Checks if the annotation specifies a channel or binop\n        if channel := _is_field_channel(typ) or _is_field_binop(typ):\n             channel.key = name\n             all_keys[name] = channel\n        else:\n             # Default case: Use LastValue\n             fallback = LastValue(typ)\n             fallback.key = name\n             all_keys[name] = fallback\n    # ... separate BaseChannel instances from ManagedValueSpec ...\n    return channels, managed_values, type_hints\n\ndef _is_field_channel(typ: Type[Any]) -> Optional[BaseChannel]:\n    # Checks if Annotated metadata contains a BaseChannel instance or class\n    if hasattr(typ, \"__metadata__\"):\n        meta = typ.__metadata__\n        if len(meta) >= 1 and isinstance(meta[-1], BaseChannel):\n            return meta[-1] # Return the channel instance directly\n        # ... (handle channel classes too) ...\n    return None\n\ndef _is_field_binop(typ: Type[Any]) -> Optional[BinaryOperatorAggregate]:\n    # Checks if Annotated metadata contains a callable (the reducer function)\n    if hasattr(typ, \"__metadata__\"):\n        meta = typ.__metadata__\n        if len(meta) >= 1 and callable(meta[-1]):\n            # ... (validate function signature) ...\n            return BinaryOperatorAggregate(typ, meta[-1]) # Create binop channel\n    return None\n\n# --- In StateGraph.__init__ ---\n# self._add_schema(state_schema) # This calls _get_channels\n```\n\n----------------------------------------\n\nTITLE: Conceptual dump_component Implementation (Python)\nDESCRIPTION: A conceptual implementation of the dump_component method, showing how it creates a ComponentModel from an instance's configuration and metadata.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Inside ComponentBase or similar\ndef dump_component(self) -> ComponentModel:\n    # 1. Get the specific config from the instance\n    obj_config: BaseModel = self._to_config()\n    config_dict = obj_config.model_dump() # Convert to dictionary\n\n    # 2. Determine the provider string (class path)\n    provider_str = _type_to_provider_str(self.__class__)\n    # (Handle overrides like self.component_provider_override)\n\n    # 3. Get other metadata\n    comp_type = self.component_type\n    comp_version = self.component_version\n    # ... description, label ...\n\n    # 4. Create and return the ComponentModel\n    model = ComponentModel(\n        provider=provider_str,\n        config=config_dict,\n        component_type=comp_type,\n        version=comp_version,\n        # ... other metadata ...\n    )\n    return model\n```\n\n----------------------------------------\n\nTITLE: Displaying Tool Calls in React Terminal UI\nDESCRIPTION: This React component renders tool calls differently from regular messages in the terminal UI. It uses the parseToolCall function to get displayable details and shows the command with distinct styling.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/05_response___tool_call_handling.md#2025-04-22_snippet_5\n\nLANGUAGE: tsx\nCODE:\n```\nexport default function TerminalChatResponseItem({ item }: { item: ResponseItem }): React.ReactElement {\n  switch (item.type) {\n    case \"message\":\n      // ... render regular message ...\n      break;\n    case \"function_call\": // <-- Handle tool calls\n      return <TerminalChatResponseToolCall message={item} />;\n    case \"function_call_output\":\n      // ... render tool output ...\n      break;\n    // ... other cases ...\n  }\n  // ... fallback ...\n}\n\nfunction TerminalChatResponseToolCall({ message }: { message: ResponseFunctionToolCallItem }) {\n  // Use the parser to get displayable details\n  const details = parseToolCall(message); // From parsers.ts\n\n  if (!details) return <Text color=\"red\">Invalid tool call</Text>;\n\n  return (\n    <Box flexDirection=\"column\">\n      <Text color=\"magentaBright\" bold>command</Text>\n      {/* Display the nicely formatted command */}\n      <Text><Text dimColor>$</Text> {details.cmdReadableText}</Text>\n    </Box>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing BinaryOperatorAggregate Channel\nDESCRIPTION: BinaryOperatorAggregate channel implementation that combines values using a specified binary operator. Useful for accumulating values or maintaining running totals.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/03_channels.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport operator\nfrom typing import Callable\n\nclass BinaryOperatorAggregate(Generic[Value], BaseChannel[Value, Value, Value]):\n    value: Any = MISSING\n    operator: Callable[[Value, Value], Value]\n\n    def update(self, values: Sequence[Value]) -> bool:\n        if not values:\n            return False\n        if self.value is MISSING:\n            self.value = values[0]\n            values = values[1:]\n        for val in values:\n            self.value = self.operator(self.value, val)\n        return True\n```\n\n----------------------------------------\n\nTITLE: Implementing Dispatch Function with Send in Python\nDESCRIPTION: Defines a function that uses the Send primitive to dispatch work to the process_single_item node for each item in the list. This demonstrates dynamic task routing in LangGraph.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/04_control_flow_primitives___branch____send____interrupt__.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom langgraph.graph import Send # Import Send\n\ndef dispatch_work(state: MapReduceState) -> List[Send]:\n    print(\"--- Dispatching Work ---\")\n    items = state['items_to_process']\n    send_packets = []\n    for item in items:\n        print(f\"Sending item '{item}' to worker node.\")\n        # Create a Send object for each item\n        # Target node: \"worker\"\n        # Data payload: a dictionary {'item': current_item}\n        packet = Send(\"worker\", {\"item\": item})\n        send_packets.append(packet)\n    return send_packets # Return a list of Send objects\n```\n\n----------------------------------------\n\nTITLE: Setting Flask Configuration Directly in Code (Python)\nDESCRIPTION: Demonstrates initializing a Flask application and setting configuration variables like `DEBUG` and `SECRET_KEY` directly on the `app.config` dictionary. It uses `os.urandom` to generate a temporary secret key suitable for development and shows how to access config values using dictionary syntax (`[]`) or the safer `get()` method. An example route `/config-example` accesses a custom setting.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# hello.py (or your main app file)\nfrom flask import Flask\nimport os\n\napp = Flask(__name__)\n\n# Setting configuration directly\napp.config['DEBUG'] = True # Turn on debug mode\napp.config['SECRET_KEY'] = os.urandom(24) # Generate a random key (OK for simple dev)\napp.config['MY_CUSTOM_SETTING'] = 'Hello Config!'\n\nprint(f\"Debug mode is: {app.config['DEBUG']}\")\nprint(f\"My custom setting: {app.config.get('MY_CUSTOM_SETTING')}\")\n# Using .get() is safer if the key might not exist\nprint(f\"Another setting: {app.config.get('NON_EXISTENT_KEY', 'Default Value')}\")\n\n# ... rest of your app (routes, etc.) ...\n\n# Example route accessing config\n@app.route('/config-example')\ndef config_example():\n  custom_val = app.config.get('MY_CUSTOM_SETTING', 'Not set')\n  return f'The custom setting is: {custom_val}'\n\nif __name__ == '__main__':\n  # The app.run(debug=True) argument also sets app.config['DEBUG'] = True\n  # but setting it explicitly ensures it's set even if run differently.\n  app.run()\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of DSPy Retrieval Flow\nDESCRIPTION: Mermaid sequence diagram showing the interaction flow between different components during retrieval operations in DSPy.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/06_rm__retrieval_model_client_.md#2025-04-22_snippet_10\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant RAGProgram as SimpleRAG (forward)\n    participant RetrieveMod as dspy.Retrieve\n    participant Settings as dspy.settings\n    participant RMClient as RM Client (e.g., ColBERTv2)\n    participant ExtSearch as External Search (e.g., ColBERT Server)\n\n    User->>RAGProgram: Call with question=\"...\"\n    RAGProgram->>RetrieveMod: Call retrieve(query=question)\n    RetrieveMod->>Settings: Get configured rm\n    Settings-->>RetrieveMod: Return RMClient instance\n    RetrieveMod->>RMClient: __call__(query, k=3)\n    RMClient->>ExtSearch: Send Search Request (query, k)\n    ExtSearch-->>RMClient: Return Found Passages\n    RMClient->>RMClient: Parse Response into dotdicts\n    RMClient-->>RetrieveMod: Return list[dotdict]\n    RetrieveMod->>RetrieveMod: Extract 'long_text' into list[str]\n    RetrieveMod-->>RAGProgram: Return Prediction(passages=list[str])\n    RAGProgram->>RAGProgram: Use context for LM call...\n    RAGProgram-->>User: Return final answer\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of Model Interface Interaction\nDESCRIPTION: A Mermaid sequence diagram illustrating the interaction flow between an Agent (`MultiStepAgent`), the Model Interface (e.g., `LiteLLMModel`), and the specific backend LLM API (e.g., OpenAI). It depicts the process: the agent calls the interface, the interface translates the message format, sends the request to the backend, receives the raw response, parses it into a standard `ChatMessage`, and returns it to the agent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/02_model_interface.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent as MultiStepAgent\n    participant ModelI as Model Interface (e.g., LiteLLMModel)\n    participant Backend as Specific LLM API/Library (e.g., OpenAI)\n\n    Agent->>ModelI: call(standard_messages)\n    ModelI->>ModelI: Translate messages to backend format\n    ModelI->>Backend: Send API Request (formatted messages, API key)\n    Backend-->>ModelI: Receive API Response (raw JSON/text)\n    ModelI->>ModelI: Parse raw response into ChatMessage\n    ModelI-->>Agent: Return ChatMessage object\n```\n\n----------------------------------------\n\nTITLE: Implementing FindTable Function for TableCache in C++\nDESCRIPTION: This code demonstrates how TableCache finds a Table structure for a given file number. It first checks the cache for the file, and if not found (cache miss), it opens the file from disk, parses the table structure, and inserts it into the cache for future use.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/01_table___sstable___tablecache.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: table_cache.cc ---\n\n// Tries to find the Table structure for a given file number.\n// If not in cache, opens the file and loads it.\nStatus TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n                             Cache::Handle** handle) {\n  Status s;\n  // Create a key for the cache lookup (based on file number)\n  char buf[sizeof(file_number)];\n  EncodeFixed64(buf, file_number);\n  Slice key(buf, sizeof(buf));\n\n  // 1. Try looking up the table in the cache\n  *handle = cache_->Lookup(key);\n\n  if (*handle == nullptr) { // Cache Miss!\n    // 2. If not found, open the actual file from disk\n    std::string fname = TableFileName(dbname_, file_number);\n    RandomAccessFile* file = nullptr;\n    Table* table = nullptr;\n    s = env_->NewRandomAccessFile(fname, &file); // Open the file\n    // ... handle errors, potentially check for old .sst filename ...\n\n    if (s.ok()) {\n      // 3. Parse the Table structure (index etc.) from the file\n      s = Table::Open(options_, file, file_size, &table);\n    }\n\n    if (s.ok()) {\n      // 4. Store the opened file and parsed Table in the cache\n      TableAndFile* tf = new TableAndFile;\n      tf->file = file;\n      tf->table = table;\n      *handle = cache_->Insert(key, tf, 1 /*charge*/, &DeleteEntry);\n    } else {\n      // Error occurred, cleanup\n      delete file;\n      // Note: Errors are NOT cached. We'll retry opening next time.\n    }\n  } // else: Cache Hit! *handle is already valid.\n  return s;\n}\n```\n\n----------------------------------------\n\nTITLE: Importing DSPy Library\nDESCRIPTION: Imports the core `dspy` library, which is the prerequisite for using any DSPy components, including LM clients and settings configuration.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/05_lm__language_model_client_.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport dspy\n```\n\n----------------------------------------\n\nTITLE: Sending Test Task for Event Monitoring\nDESCRIPTION: Python code to send a test task that will generate events for monitoring\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/09_events.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom tasks import add\nresult = add.delay(5, 10)\nprint(f\"Sent task {result.id}\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing NumPy Array Print Call Flow - Mermaid Markdown\nDESCRIPTION: This mermaid sequence diagram illustrates the flow of a print call on a NumPy array, showing interactions among the Python print function, ndarray object, numpy core modules, and the print options manager. It diagrams how a print statement triggers special method calls, module functions, formatting logic, and eventually returns the final string representation for output. The diagram aids in understanding control flow and component responsibilities within the array printing process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n```mermaid\nsequenceDiagram\n    participant User\n    participant Python as print() / REPL\n    participant NDArray as my_array object\n    participant ArrayPrint as numpy.core.arrayprint module\n    participant PrintOpts as numpy.core.printoptions module\n\n    User->>Python: print(my_array) or my_array\n    Python->>NDArray: call __str__ or __repr__\n    NDArray->>ArrayPrint: call array_str or array_repr\n    ArrayPrint->>ArrayPrint: call array2string(my_array, ...)\n    ArrayPrint->>PrintOpts: Get current print options (threshold, precision, etc.)\n    ArrayPrint->>ArrayPrint: Check size vs threshold -> Summarize?\n    ArrayPrint->>ArrayPrint: Select Formatter based on my_array.dtype\n    loop For each element/chunk\n        ArrayPrint->>ArrayPrint: Format element using Formatter\n    end\n    ArrayPrint->>ArrayPrint: Arrange strings, add brackets, wrap lines\n    ArrayPrint-->>NDArray: Return formatted string\n    NDArray-->>Python: Return formatted string\n    Python-->>User: Display formatted string\n```\n```\n\n----------------------------------------\n\nTITLE: Agent Response After Using MCPServer Tool in OpenManus\nDESCRIPTION: Expected output when the agent successfully uses a tool from the MCPServer, showing the execution logs and the formatted response with the tool's output.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n# ... (Potential LLM thinking logs) ...\nINFO:app.agent.mcp:Executing tool: bash with input {'command': 'ls'}\n# ... (Server logs might show execution in its own terminal) ...\n\nAgent: The bash tool executed the 'ls' command and returned the following output:\n[List of files/directories in the project root, e.g.,]\nREADME.md\napp\nconfig\nrun_mcp.py\n... etc ...\n```\n\n----------------------------------------\n\nTITLE: Defining Tasks for Travel Planning in Python using CrewAI\nDESCRIPTION: This code snippet demonstrates how to create Task objects for a travel planning scenario using CrewAI. It defines two tasks: one for researching cities and another for creating an itinerary, assigning them to specific agents and setting expectations for the output.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/03_task.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import necessary classes\nfrom crewai import Task, Agent # Assuming Agent class is defined as in Chapter 2\n\n# Assume 'researcher' and 'planner' agents are already defined\n# researcher = Agent(role='Travel Researcher', ...)\n# planner = Agent(role='Activity Planner', ...)\n\n# Define Task 1 for the Researcher\ntask1 = Task(\n  description=(\n      \"Identify the top 3 European cities known for great sunny weather \"\n      \"around late May. Focus on cities with vibrant culture and good food.\"\n  ),\n  expected_output=(\n      \"A numbered list of 3 cities, each with a brief (1-2 sentence) justification \"\n      \"mentioning weather, culture, and food highlights.\"\n  ),\n  agent=researcher # Assign this task to our researcher agent\n)\n\n# Define Task 2 for the Planner\ntask2 = Task(\n  description=(\n      \"Using the list of cities provided by the researcher, select the best city \"\n      \"and create a detailed 3-day itinerary. Include morning, afternoon, and \"\n      \"evening activities, plus restaurant suggestions.\"\n  ),\n  expected_output=(\n      \"A markdown formatted 3-day itinerary for the chosen city. \"\n      \"Include timings, activity descriptions, and 2-3 restaurant ideas.\"\n  ),\n  agent=planner # Assign this task to our planner agent\n  # context=[task1] # Optionally explicitly define context (often handled automatically)\n)\n\n# (You would then add these tasks to a Crew)\n# print(task1)\n# print(task2)\n```\n\n----------------------------------------\n\nTITLE: Implementing SystemPrompt Class in Python\nDESCRIPTION: This Python class loads the system prompt from a file, formats it, and prepares it for use with the AI model. It includes methods for loading the prompt template and creating a SystemMessage object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/02_system_prompt.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport importlib.resources\nfrom langchain_core.messages import SystemMessage\n\nclass SystemPrompt:\n    def __init__(self, action_description: str, max_actions_per_step: int = 10):\n        self.default_action_description = action_description\n        self.max_actions_per_step = max_actions_per_step\n        self._load_prompt_template()\n\n    def _load_prompt_template(self) -> None:\n        try:\n            filepath = importlib.resources.files('browser_use.agent').joinpath('system_prompt.md')\n            with filepath.open('r') as f:\n                self.prompt_template = f.read()\n            print(\"System Prompt template loaded successfully!\")\n        except Exception as e:\n            print(f\"Error loading system prompt: {e}\")\n            self.prompt_template = \"Error: Could not load prompt.\"\n\n    def get_system_message(self) -> SystemMessage:\n        prompt = self.prompt_template.format(max_actions=self.max_actions_per_step)\n        return SystemMessage(content=prompt)\n```\n\n----------------------------------------\n\nTITLE: Command Execution Handler with Approval Integration in TypeScript\nDESCRIPTION: This snippet demonstrates how the canAutoApprove function is used in the command execution flow. It shows the handling of different approval outcomes (auto-approve, ask-user, or reject) and how user confirmation is requested when required by the approval policy.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/04_approval_policy___security.md#2025-04-22_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// File: codex-cli/src/utils/agent/handle-exec-command.ts (Simplified snippet)\n\nimport { canAutoApprove } from \"../../approvals.js\";\nimport { ReviewDecision } from \"./review.js\";\n// ... other imports ...\n\nexport async function handleExecCommand(\n  args: ExecInput, // Contains the command array `cmd`\n  config: AppConfig,\n  policy: ApprovalPolicy,\n  getCommandConfirmation: (/*...*/) => Promise<CommandConfirmation>, // UI callback\n  // ... abortSignal ...\n): Promise<HandleExecCommandResult> {\n\n  // *** Check the approval policy first! ***\n  const safety = canAutoApprove(args.cmd, policy, [process.cwd()]);\n\n  let runInSandbox: boolean;\n  switch (safety.type) {\n    case \"ask-user\": {\n      // Policy requires asking the user\n      const { review: decision } = await getCommandConfirmation(args.cmd, safety.applyPatch);\n      if (decision !== ReviewDecision.YES && decision !== ReviewDecision.ALWAYS) {\n        // User said No or provided feedback to stop\n        return { outputText: \"aborted\", metadata: { /*...*/ } };\n      }\n      // User approved! Proceed without sandbox (unless policy changes later).\n      runInSandbox = false;\n      break;\n    }\n    case \"auto-approve\": {\n      // Policy allows auto-approval\n      runInSandbox = safety.runInSandbox; // Respect sandbox flag from canAutoApprove\n      break;\n    }\n    case \"reject\": {\n      // Policy outright rejected the command\n      return { outputText: \"aborted\", metadata: { reason: safety.reason } };\n    }\n  }\n\n  // *** If approved (either automatically or by user), execute the command ***\n  const summary = await execCommand(args, safety.applyPatch, runInSandbox, /*...*/);\n  // ... handle results ...\n  return convertSummaryToResult(summary);\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing Checkpointing Process with Mermaid Diagram\nDESCRIPTION: A sequence diagram showing the interaction flow between User, CompiledGraph, Pregel Engine, Checkpointer, and Storage during both saving and loading operations of checkpoints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant App as CompiledGraph\n    participant Engine as Pregel Engine\n    participant Saver as Checkpointer (e.g., MemorySaver)\n    participant Storage as Underlying Storage (RAM, DB)\n\n    %% Saving %%\n    Engine->>Engine: Finishes Step N\n    Engine->>Saver: Save checkpoint for config (thread_id)\n    Saver->>Engine: Request current channel states & versions\n    Engine-->>Saver: Provides states & versions\n    Saver->>Storage: Store Checkpoint(Step N, states, versions) linked to thread_id\n    Storage-->>Saver: Acknowledge Save\n    Saver-->>Engine: Save Complete\n\n    %% Loading %%\n    User->>App: invoke(None, config with thread_id)\n    App->>Engine: Start/Resume Execution\n    Engine->>Saver: Get latest checkpoint for config (thread_id)\n    Saver->>Storage: Retrieve Checkpoint linked to thread_id\n    Storage-->>Saver: Returns Checkpoint(Step N, states, versions)\n    Saver-->>Engine: Provides Checkpoint\n    Engine->>Engine: Restore channel states from checkpoint\n    Engine->>Engine: Prepare tasks for Step N+1\n    Engine->>App: Continue execution...\n```\n\n----------------------------------------\n\nTITLE: Visualizing Click Context Flow with Mermaid\nDESCRIPTION: This sequence diagram illustrates the creation and interaction of Click Context objects during the execution of a command like `python context_basics.py info --verbose`. It shows the initial context creation for the main group (`cli`), the creation of a child context for the `info` subcommand, the inheritance and modification of the shared object (`ctx.obj`), and the final teardown process. This visual representation corresponds to the step-by-step explanation provided in the surrounding text.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/05_context.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant CLI as python context_basics.py\n    participant ClickRuntime\n    participant cli_ctx as cli Context\n    participant info_ctx as info Context\n    participant cli_func as cli(ctx)\n    participant info_func as info(ctx, verbose)\n\n    User->>CLI: info --verbose\n    CLI->>ClickRuntime: Calls cli() entry point\n    ClickRuntime->>cli_ctx: Creates root context for 'cli' group\n    Note over ClickRuntime, cli_func: ClickRuntime calls cli's callback (due to @click.group)\n    ClickRuntime->>cli_func: cli(ctx=cli_ctx)\n    cli_func->>cli_ctx: Sets ctx.obj = {'verbose': False}\n    cli_func-->>ClickRuntime: Returns\n    ClickRuntime->>ClickRuntime: Parses args, finds 'info' subcommand, '--verbose' option\n    ClickRuntime->>info_ctx: Creates child context for 'info' command\n    info_ctx->>cli_ctx: Sets info_ctx.parent = cli_ctx\n    info_ctx->>info_ctx: Inherits ctx.obj from parent (value = {'verbose': False})\n    Note over ClickRuntime, info_func: ClickRuntime prepares to call info's callback\n    ClickRuntime->>ClickRuntime: Uses @pass_context to get info_ctx\n    ClickRuntime->>info_func: info(ctx=info_ctx, verbose=True)\n    info_func->>info_ctx: Accesses ctx.command.name\n    info_func->>info_ctx: Accesses ctx.params['verbose'] (or local 'verbose')\n    info_func->>info_ctx: Modifies ctx.obj['verbose'] = True\n    info_func->>info_ctx: Accesses ctx.obj['verbose'] (now True)\n    info_func-->>ClickRuntime: Returns\n    ClickRuntime->>info_ctx: Tears down info_ctx (runs call_on_close)\n    ClickRuntime->>cli_ctx: Tears down cli_ctx (runs call_on_close)\n    ClickRuntime-->>CLI: Exits\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Project Dependencies in a Requirements File - Python\nDESCRIPTION: This snippet acts as a requirements.txt, listing the necessary Python packages and their minimum versions needed to run the project. To use, install all dependencies with pip (e.g., pip install -r requirements.txt) before running any project code. Each line specifies a library such as pocketflow, pyyaml, requests, gitpython, google-cloud-aiplatform, google-genai, and python-dotenv, which cover functionality from API integration to machine learning workflows; it expects a Python environment with pip available and may require Python 3+ for full compatibility. There are no inputs or outputs directly, but successful installation is necessary for all project code to function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npocketflow>=0.0.1\\npyyaml>=6.0\\nrequests>=2.28.0\\ngitpython>=3.1.0\\ngoogle-cloud-aiplatform>=1.25.0\\ngoogle-genai>=1.9.0\\npython-dotenv>=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Visualizing BootstrapFewShot Sequence Flow\nDESCRIPTION: Mermaid sequence diagram showing the interaction flow between User, Teleprompter, Student Program, Teacher Program, Language Model, Metric Function, and Compiled Program during the bootstrapping process.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/08_teleprompter___optimizer.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Teleprompter as BootstrapFewShot\n    participant StudentProgram as Student Program\n    participant TeacherProgram as Teacher Program\n    participant LM as Language Model\n    participant Metric as Metric Function\n    participant CompiledProgram as Compiled Program (Student with Demos)\n\n    User->>Teleprompter: compile(student=StudentProgram, trainset=...)\n    Teleprompter->>TeacherProgram: Set up (copy of student, potentially modified)\n    loop For each example in trainset\n        Teleprompter->>TeacherProgram: Run example.inputs()\n        TeacherProgram->>LM: Make calls (via Predictors)\n        LM-->>TeacherProgram: Return predictions\n        TeacherProgram-->>Teleprompter: Return final prediction & trace\n        Teleprompter->>Metric: Evaluate(example, prediction, trace)\n        Metric-->>Teleprompter: Return score (success/fail)\n        alt Metric returns success\n            Teleprompter->>Teleprompter: Extract demo from trace\n        end\n    end\n    Teleprompter->>StudentProgram: Assign selected demos to predictors\n    StudentProgram-->>CompiledProgram: Create compiled version\n    Teleprompter-->>User: Return CompiledProgram\n```\n\n----------------------------------------\n\nTITLE: MemTable Class Definition in C++\nDESCRIPTION: Header file definition of the MemTable class showing its core components including the SkipList data structure, memory management through Arena, and primary public methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/02_memtable.md#2025-04-22_snippet_2\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/memtable.h ---\n\n#include \"db/skiplist.h\" // The SkipList data structure\n#include \"util/arena.h\"   // Memory allocator\n\nclass MemTable {\n private:\n  // The core data structure: a SkipList.\n  // The Key is 'const char*' pointing into the Arena.\n  // KeyComparator helps compare keys correctly (we'll see this later).\n  typedef SkipList<const char*, KeyComparator> Table;\n\n  Arena arena_;   // Allocates memory for nodes efficiently\n  Table table_;   // The actual SkipList instance\n  int refs_;      // Reference count for managing lifetime\n  // ... other members like KeyComparator ...\n\n public:\n  // Add an entry (Put or Delete marker)\n  void Add(SequenceNumber seq, ValueType type, const Slice& key,\n           const Slice& value);\n\n  // Look up a key\n  bool Get(const LookupKey& key, std::string* value, Status* s);\n\n  // Create an iterator to scan the MemTable's contents\n  Iterator* NewIterator();\n\n  // Estimate memory usage\n  size_t ApproximateMemoryUsage();\n\n  // Constructor, Ref/Unref omitted for brevity...\n};\n```\n\n----------------------------------------\n\nTITLE: Defining a Response Hook Function in Python Requests\nDESCRIPTION: This snippet defines a custom hook function for logging response details. It captures the request method, URL, and status code from the response object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/08_hook_system.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Our custom hook function for logging\ndef log_response_details(response, *args, **kwargs):\n    \"\"\"\n    This function will be called after each response.\n    It logs the request method, URL, and response status code.\n    \"\"\"\n    # 'response' is the Response object just received\n    request_method = response.request.method # Get the method from the original request\n    url = response.url                     # Get the final URL\n    status_code = response.status_code       # Get the status code\n\n    print(f\"HOOK LOG: Received {status_code} for {request_method} request to {url}\")\n\n    # IMPORTANT: Hooks usually shouldn't return anything (or return None).\n    # If a hook returns a value, it REPLACES the data being processed.\n    # For the 'response' hook, returning a value would replace the Response object!\n    # Since we just want to log, we don't return anything.\n```\n\n----------------------------------------\n\nTITLE: Creating a ListMemory Instance\nDESCRIPTION: Demonstrates how to initialize a ListMemory object, which is a simple implementation of the Memory interface that stores information in a Python list.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/07_memory.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# File: create_list_memory.py\nfrom autogen_core.memory import ListMemory\n\n# Create a simple list-based memory instance\nuser_prefs_memory = ListMemory(name=\"user_preferences\")\n\nprint(f\"Created memory: {user_prefs_memory.name}\")\nprint(f\"Initial content: {user_prefs_memory.content}\")\n# Output:\n# Created memory: user_preferences\n# Initial content: []\n```\n\n----------------------------------------\n\nTITLE: Visualizing Hierarchical Process Flow with Mermaid\nDESCRIPTION: A Mermaid sequence diagram depicting the workflow of a CrewAI `Crew` using the `Process.hierarchical` strategy. It highlights the role of the Manager Agent, which receives the overall goal, decides which worker agent (Researcher or Planner) should perform each task, delegates the tasks, receives the results, and compiles the final output for the user.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/CrewAI/05_process.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant MyCrew as Crew (Hierarchical)\n    participant ManagerAgent as Manager\n    participant ResearcherAgent as Researcher\n    participant PlannerAgent as Planner\n\n    User->>MyCrew: kickoff()\n    MyCrew->>ManagerAgent: Goal: Plan Trip (Tasks: Find Cities, Create Itinerary)\n    ManagerAgent->>ManagerAgent: Decide: Researcher should do Task 1\n    ManagerAgent->>ResearcherAgent: Delegate: Execute Task 1 (\"Find cities\")\n    ResearcherAgent-->>ManagerAgent: Task 1 Output (Cities List)\n    ManagerAgent->>ManagerAgent: Decide: Planner should do Task 2 with context\n    ManagerAgent->>PlannerAgent: Delegate: Execute Task 2 (\"Create itinerary\", Cities List)\n    PlannerAgent-->>ManagerAgent: Task 2 Output (Itinerary)\n    ManagerAgent->>MyCrew: Report Final Result (Itinerary)\n    MyCrew-->>User: Final Result (Itinerary)\n```\n\n----------------------------------------\n\nTITLE: Standard Python Main Entry Point\nDESCRIPTION: The standard Python main block pattern used to start a FastMCP server. This code checks if the script is being run directly, starts the server, and prints status messages.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run()\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Example System Prompt Template for CodeAgent in YAML\nDESCRIPTION: This YAML snippet shows a portion of a `system_prompt` template typically found in `prompts/code_agent.yaml`. It demonstrates the use of Jinja2 templating syntax within YAML. Placeholders like `{{ tool.name }}`, `{{ agent.description }}`, and `{{ authorized_imports }}` indicate where dynamic data will be inserted. Jinja2 control structures like `{%- for ... %}` are used to iterate over lists (e.g., tools, managed agents). This template structures the instructions and available resources provided to the language model for the CodeAgent.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/SmolaAgents/05_prompttemplates.md#2025-04-22_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\n# --- Snippet from prompts/code_agent.yaml ---\nsystem_prompt: |-\n  You are an expert assistant who can solve any task using code blobs.\n  # ... (lots of instructions and examples) ...\n\n  You only have access to these tools:\n  {%- for tool in tools.values() %}\n  - {{ tool.name }}: {{ tool.description }}\n      Takes inputs: {{tool.inputs}}\n      Returns an output of type: {{tool.output_type}}\n  {%- endfor %}\n\n  {%- if managed_agents and managed_agents.values() | list %}\n  You can also give tasks to team members.\n  # ... (instructions for managed agents) ...\n  {%- for agent in managed_agents.values() %}\n  - {{ agent.name }}: {{ agent.description }}\n  {%- endfor %}\n  {%- endif %}\n\n  Here are the rules you should always follow:\n  # ... (more rules) ...\n  You can use imports in your code, but only from the following list of modules: {{authorized_imports}}\n  # ... (rest of the prompt) ...\n```\n\n----------------------------------------\n\nTITLE: Example LLM Response Output\nDESCRIPTION: Shows the expected console output when running the LLM query example. The response is a simple answer to the question about France's capital.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/01_llm.md#2025-04-22_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nAsking the LLM...\nLLM Response: The capital of France is Paris.\n```\n\n----------------------------------------\n\nTITLE: Implementing Registry Class for Managing Browser Actions in Python\nDESCRIPTION: This class manages a registry of browser actions, including methods for registering actions, creating parameter models, and executing actions. It also provides functionality to generate prompt descriptions for registered actions.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/05_action_controller___registry.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Registry:\n    def __init__(self, exclude_actions: list[str] = []):\n        self.registry: dict[str, RegisteredAction] = {}\n        self.exclude_actions = exclude_actions\n        # ... other initializations ...\n\n    def _create_param_model(self, function: Callable) -> Type[BaseModel]:\n        \"\"\"Creates a Pydantic model from function signature (simplified)\"\"\"\n        # ... (Inspects function signature to build a model) ...\n        # Example: for func(index: int, text: str), creates a model\n        # class func_parameters(ActionModel):\n        #      index: int\n        #      text: str\n        # return func_parameters\n        pass # Placeholder for complex logic\n\n    def action(\n        self,\n        description: str,\n        param_model: Type[BaseModel] | None = None,\n    ):\n        \"\"\"Decorator for registering actions\"\"\"\n        def decorator(func: Callable):\n            if func.__name__ in self.exclude_actions: return func # Skip excluded\n\n            # If no specific param_model provided, try to generate one\n            actual_param_model = param_model # Or self._create_param_model(func) if needed\n\n            # Ensure function is awaitable (async)\n            wrapped_func = func # Assume func is already async for simplicity\n\n            action = RegisteredAction(\n                name=func.__name__,\n                description=description,\n                function=wrapped_func,\n                param_model=actual_param_model,\n            )\n            self.registry[func.__name__] = action # Add to the toolbox!\n            print(f\"Action '{func.__name__}' registered.\")\n            return func\n        return decorator\n\n    def get_prompt_description(self) -> str:\n        \"\"\"Get a description of all actions for the prompt (simplified)\"\"\"\n        descriptions = []\n        for action in self.registry.values():\n             # Format description for LLM (e.g., \"click_element: Click element {index: {'type': 'integer'}}\")\n             descriptions.append(f\"{action.name}: {action.description} {action.param_model.schema()}\")\n        return \"\\n\".join(descriptions)\n\n    async def execute_action(self, action_name: str, params: dict, browser, **kwargs) -> Any:\n         \"\"\"Execute a registered action (simplified)\"\"\"\n         if action_name not in self.registry:\n             raise ValueError(f\"Action {action_name} not found\")\n\n         action = self.registry[action_name]\n         try:\n             # Validate params using the registered Pydantic model\n             validated_params = action.param_model(**params)\n\n             # Call the actual action function with validated params and browser context\n             # Assumes function takes validated_params model and browser\n             result = await action.function(validated_params, browser=browser, **kwargs)\n             return result\n         except Exception as e:\n             raise RuntimeError(f\"Error executing {action_name}: {e}\") from e\n```\n\n----------------------------------------\n\nTITLE: Adding LLM Model Output to Conversation History in Python\nDESCRIPTION: This method adds the LLM's plan (AgentOutput) to the conversation history as an AIMessage. It formats the output according to OpenAI's tool calling standard, creating a structured message with tool calls. It also adds a corresponding empty ToolMessage to maintain the expected conversation structure.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/06_message_manager.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass MessageManager:\n    # ... (init, add_state_message) ...\n\n    def add_model_output(self, model_output: AgentOutput) -> None:\n        \"\"\"Add model output (the plan) as an AI message with tool calls.\"\"\"\n        # Format the output according to OpenAI's tool calling standard\n        tool_calls = [\n            {\n                'name': 'AgentOutput', # The 'tool' name\n                'args': model_output.model_dump(mode='json', exclude_unset=True), # The LLM's JSON output\n                'id': str(self.state.tool_id), # Unique ID for the call\n                'type': 'tool_call',\n            }\n        ]\n\n        # Create the AIMessage containing the tool calls\n        msg = AIMessage(\n            content='', # Content is often empty when using tool calls\n            tool_calls=tool_calls,\n        )\n\n        # Add it to history\n        self._add_message_with_tokens(msg)\n\n        # Add a corresponding empty ToolMessage (required by some models)\n        self.add_tool_message(content='') # Content depends on tool execution result\n\n    def add_tool_message(self, content: str) -> None:\n        \"\"\"Add tool message to history (often confirms tool call receipt/result)\"\"\"\n        # ToolMessage links back to the AIMessage's tool_call_id\n        msg = ToolMessage(content=content, tool_call_id=str(self.state.tool_id))\n        self.state.tool_id += 1 # Increment for next potential tool call\n        self._add_message_with_tokens(msg)\n```\n\n----------------------------------------\n\nTITLE: Flowchart for 1D Array\nDESCRIPTION: This Mermaid diagram visualizes a 1-dimensional array structure, showing the sequential nature of elements in a vector. It represents how elements are connected linearly in a 1D array.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_8\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    A[0] --> B[1] --> C[2] --> D[3]\n```\n\n----------------------------------------\n\nTITLE: Visualizing Tutorial Generation Workflow Using Mermaid in Markdown\nDESCRIPTION: This Mermaid code block defines a flowchart illustrating the sequential workflow for generating the tutorial. The diagram visualizes the main nodes of the process: fetching the repo, identifying core abstractions, analyzing their relationships, determining chapter order, batch writing chapters, and finally combining outputs. It requires embedding in a Markdown environment that supports Mermaid rendering and has no parameters. The output is a rendered flowchart showing step-to-step transitions; limited by Mermaid's graph drawing capabilities.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/design.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A[FetchRepo] --> B[IdentifyAbstractions];\n    B --> C[AnalyzeRelationships];\n    C --> D[OrderChapters];\n    D --> E[Batch WriteChapters];\n    E --> F[CombineTutorial];\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram for A2A Task Handling\nDESCRIPTION: A Mermaid sequence diagram illustrating the flow of events when an A2A agent server receives and processes a 'tasks/send' request. It shows interactions between the Client, Agent Server, Task Store, and Task Logic, including request reception, task creation, initial response, asynchronous processing, state updates ('working', 'completed'), and result storage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/02_task.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Client App\n    participant A as Agent Server (A2A Endpoint)\n    participant TS as Task Store (e.g., Memory, DB)\n    participant TL as Task Logic (e.g., Translator)\n\n    C->>A: POST /a2a (JSON-RPC: method=\"tasks/send\", params={id=\"T1\", msg=\"Translate...\"})\n    Note right of A: Receives HTTP request, parses JSON-RPC\n\n    A->>TS: Create/Find Task Record (ID: \"T1\")\n    Note right of TS: Creates a new Task object in 'submitted' state\n    TS-->>A: New Task Object (ID: \"T1\", state: \"submitted\")\n\n    A-->>C: 200 OK (JSON-RPC: result={Task Object with state 'submitted'})\n    Note left of C: Client receives confirmation Task is created\n\n    Note over A,TL: Agent asynchronously starts processing...\n    A->>TL: Start processing Task \"T1\" (Input: \"Translate...\")\n    A->>TS: Update Task \"T1\" status to 'working'\n    Note right of TS: Updates Task record state\n\n    TL->>A: Processing finished (Output: \"Bonjour\")\n    Note over A,TS: Agent updates Task with result and 'completed' state\n    A->>TS: Update Task \"T1\" (state: 'completed', artifacts: [\"Bonjour\"])\n\n```\n\n----------------------------------------\n\nTITLE: Caching Process Sequence Diagram (Mermaid)\nDESCRIPTION: This diagram illustrates the sequence of operations in the caching process, including interactions between the user, AsyncWebCrawler, CacheContext, DatabaseManager, and AsyncCrawlerStrategy.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/09_cachecontext___cachemode.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant AWC as AsyncWebCrawler\n    participant Ctx as CacheContext\n    participant DB as DatabaseManager\n    participant Fetcher as AsyncCrawlerStrategy\n\n    User->>AWC: arun(url, config)\n    AWC->>Ctx: Create CacheContext(url, config.cache_mode)\n    AWC->>Ctx: should_read()?\n    alt Cache Read Allowed\n        Ctx-->>AWC: Yes\n        AWC->>DB: aget_cached_url(url)\n        DB-->>AWC: Cached Result (or None)\n        alt Cache Hit & Valid\n            AWC-->>User: Return Cached CrawlResult\n        else Cache Miss or Invalid\n            AWC->>AWC: Proceed to Fetch\n        end\n    else Cache Read Not Allowed\n        Ctx-->>AWC: No\n        AWC->>AWC: Proceed to Fetch\n    end\n\n    Note over AWC: Fetching Required\n    AWC->>Fetcher: crawl(url, config)\n    Fetcher-->>AWC: Raw Response\n    AWC->>AWC: Process HTML -> New CrawlResult\n    AWC->>Ctx: should_write()?\n    alt Cache Write Allowed\n        Ctx-->>AWC: Yes\n        AWC->>DB: acache_url(New CrawlResult)\n        DB-->>AWC: OK\n    else Cache Write Not Allowed\n        Ctx-->>AWC: No\n    end\n    AWC-->>User: Return New CrawlResult\n```\n\n----------------------------------------\n\nTITLE: Visualizing Agent Loop Workflow with Mermaid Diagram\nDESCRIPTION: A flowchart diagram illustrating the cycle of the Agent Loop, from user input through AI processing, tool execution, and back to user interaction.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/03_agent_loop.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    A[User Input] --> B[Agent Loop]\n    B --> C{Send to AI Model}\n    C --> D[AI Response: Text or Tool Call]\n    D --> B\n    B --> E{Process Response}\n    E -- Text --> F[Show Text in UI]\n    E -- Tool Call --> G{Handle Tool Call}\n    G --> H{Needs Approval?}\n    H -- Yes --> I[Ask User via UI]\n    I --> J{User Approves?}\n    H -- No --> K[Execute Tool]\n    J -- Yes --> K\n    J -- No --> L[Report Denial to AI]\n    K --> M[Get Tool Result]\n    M --> B\n    L --> B\n    F --> N[Update History]\n    M --> N\n    L --> N\n    N --> O[Ready for next Input/Step]\n```\n\n----------------------------------------\n\nTITLE: Implementing Get Operation in DBImpl\nDESCRIPTION: Implementation of the Get method in DBImpl that handles read operations by checking MemTable, Immutable MemTable, and SSTables in sequence. Includes reference counting and lock management for thread safety.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\nStatus DBImpl::Get(const ReadOptions& options, const Slice& key,\n                   std::string* value) {\n  Status s;\n  SequenceNumber snapshot;\n  // ... (Step 3) Determine snapshot sequence number ...\n  mutex_.Lock(); // Need lock to access mem_, imm_, current version\n  MemTable* mem = mem_;\n  MemTable* imm = imm_;\n  Version* current = versions_->current();\n  mem->Ref(); // Increase reference counts\n  if (imm != nullptr) imm->Ref();\n  current->Ref();\n  mutex_.Unlock(); // Unlock for potentially slow lookups\n\n  LookupKey lkey(key, snapshot); // Internal key format for lookup\n\n  // Step 4: Check active MemTable\n  if (mem->Get(lkey, value, &s)) {\n    // Found in mem_ (value or deletion marker)\n  }\n  // Step 5: Check immutable MemTable (if it exists)\n  else if (imm != nullptr && imm->Get(lkey, value, &s)) {\n    // Found in imm_\n  }\n  // Step 6: Check SSTables via current Version\n  else {\n    Version::GetStats stats; // To record file access stats\n    s = current->Get(options, lkey, value, &stats);\n    // Step 7: Maybe update stats and schedule compaction\n    if (current->UpdateStats(stats)) {\n       mutex_.Lock();\n       MaybeScheduleCompaction(); // Needs lock\n       mutex_.Unlock();\n    }\n  }\n\n  // Decrease reference counts\n  mutex_.Lock();\n  mem->Unref();\n  if (imm != nullptr) imm->Unref();\n  current->Unref();\n  mutex_.Unlock();\n\n  return s; // Step 8: Return status\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Click Application with Missing Required Argument\nDESCRIPTION: Command-line example showing how Click handles a missing required argument. When the MESSAGE argument is omitted, Click raises a MissingParameter exception and provides a clear error message to the user.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/07_click_exceptions.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ python count_app.py --count 3\nUsage: count_app.py [OPTIONS] MESSAGE\nTry 'count_app.py --help' for help.\n\nError: Missing argument 'MESSAGE'.\n```\n\n----------------------------------------\n\nTITLE: Agent Output After Connecting to MCPServer in OpenManus\nDESCRIPTION: Expected console output when the MCPAgent successfully connects to the server. Shows the loaded configuration, connection information, and detected tools from the server.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/09_mcp__model_context_protocol_.md#2025-04-22_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nINFO:app.config:Configuration loaded successfully from .../config/config.toml\nINFO:app.agent.mcp:Initializing MCPAgent with stdio connection...\n# ... (potential logs about connecting) ...\nINFO:app.tool.mcp:Connected to server with tools: ['bash', 'browser', 'editor', 'terminate']\nINFO:app.agent.mcp:Connected to MCP server via stdio\n\nMCP Agent Interactive Mode (type 'exit' to quit)\n\nEnter your request:\n```\n\n----------------------------------------\n\nTITLE: Array Creation Process Flow Diagram\nDESCRIPTION: Sequence diagram showing the steps from a Python call to np.array() through to memory allocation and back, illustrating how the C implementation handles array creation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/06_multiarray_module.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User as Your Python Script\n    participant PyFunc as NumPy Python Func (np.array)\n    participant C_API as C Code (_multiarray_umath)\n    participant Memory\n\n    User->>PyFunc: my_array = np.array([1, 2, 3])\n    PyFunc->>C_API: Call C function (e.g., PyArray_NewFromDescr) with list data, inferred dtype, shape\n    C_API->>Memory: Allocate memory block (e.g., 24 bytes for 3x int64)\n    C_API->>Memory: Copy data [1, 2, 3] into block\n    C_API->>C_API: Create internal C ndarray struct (PyArrayObject) pointing to data, storing shape=(3,), dtype=int64, etc.\n    C_API->>PyFunc: Return Python ndarray object wrapping the C struct\n    PyFunc-->>User: Assign returned ndarray object to `my_array`\n```\n\n----------------------------------------\n\nTITLE: ProductTelemetry Initialization in Python\nDESCRIPTION: Shows how the ProductTelemetry service initializes and checks environment variables to determine whether telemetry is enabled or disabled. The service uses the singleton pattern to ensure only one instance exists.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/08_telemetry_service.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# --- File: telemetry/service.py (Simplified __init__) ---\nimport os\nimport uuid\nimport logging\nfrom pathlib import Path\nfrom posthog import Posthog # The library for the external service\nfrom browser_use.utils import singleton\n\nlogger = logging.getLogger(__name__)\n\n@singleton # Ensures only one instance exists\nclass ProductTelemetry:\n    USER_ID_PATH = str(Path.home() / '.cache' / 'browser_use' / 'telemetry_user_id')\n    # ... (API key constants) ...\n    _curr_user_id = None\n\n    def __init__(self) -> None:\n        # Check the environment variable\n        telemetry_disabled = os.getenv('ANONYMIZED_TELEMETRY', 'true').lower() == 'false'\n\n        if telemetry_disabled:\n            self._posthog_client = None # Telemetry is off\n            logger.debug('Telemetry disabled by environment variable.')\n        else:\n            # Initialize the PostHog client if enabled\n            self._posthog_client = Posthog(...)\n            logger.info(\n                'Anonymized telemetry enabled.' # Inform the user\n            )\n            # Optionally silence PostHog's own logs\n            # ...\n\n    # ... (other methods) ...\n```\n\n----------------------------------------\n\nTITLE: Mermaid Sequence Diagram for ContentScrapingStrategy Flow\nDESCRIPTION: Diagram showing the interaction flow between AsyncWebCrawler, AsyncCrawlerStrategy, ContentScrapingStrategy and related components when processing a webpage.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/04_contentscrapingstrategy.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant AWC as AsyncWebCrawler (Manager)\n    participant Fetcher as AsyncCrawlerStrategy\n    participant HTML as Raw HTML\n    participant CSS as ContentScrapingStrategy (Editor)\n    participant SR as ScrapingResult (Cleaned Draft)\n    participant CR as CrawlResult (Final Report)\n\n    AWC->>Fetcher: Fetch(\"https://example.com\")\n    Fetcher-->>AWC: Here's the Raw HTML\n    AWC->>CSS: Please scrap this Raw HTML (using config)\n    Note over CSS: Parsing HTML... Removing scripts, styles, ads... Extracting links, images, title...\n    CSS-->>AWC: Here's the ScrapingResult (Cleaned HTML, Links, Media, Metadata)\n    AWC->>CR: Combine ScrapingResult with other info\n    AWC-->>User: Return final CrawlResult\n```\n\n----------------------------------------\n\nTITLE: Visualizing Click Parameter Processing Flow with Mermaid\nDESCRIPTION: A sequence diagram illustrating how Click processes command-line arguments, from user input to function execution. It shows the steps of parsing, command identification, parameter matching, validation, and function invocation.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/03_parameter__option___argument_.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Terminal\n    participant PythonScript as python greet_app_v2.py\n    participant ClickRuntime\n    participant hello_func as hello(name, shout)\n\n    User->>Terminal: python greet_app_v2.py hello --shout -n Alice\n    Terminal->>PythonScript: Executes script with args [\"hello\", \"--shout\", \"-n\", \"Alice\"]\n    PythonScript->>ClickRuntime: Calls cli() entry point\n    ClickRuntime->>ClickRuntime: Parses args, finds 'hello' command\n    ClickRuntime->>ClickRuntime: Identifies '--shout' as flag for 'shout' parameter (value=True)\n    ClickRuntime->>ClickRuntime: Identifies '-n' as option for 'name' parameter\n    ClickRuntime->>ClickRuntime: Consumes 'Alice' as value for '-n'/'name' parameter (value=\"Alice\")\n    ClickRuntime->>ClickRuntime: Validates parameters, performs type conversion\n    ClickRuntime->>hello_func: Calls callback: hello(name=\"Alice\", shout=True)\n    hello_func-->>PythonScript: Prints \"HELLO ALICE!\"\n    PythonScript-->>Terminal: Shows output\n    Terminal-->>User: Displays \"HELLO ALICE!\"\n```\n\n----------------------------------------\n\nTITLE: Example Raw LM Response with Field Markers\nDESCRIPTION: Represents a typical raw text response received from a Language Model when prompted using the `ChatAdapter`'s format. It includes special markers (e.g., `[[ ## summary ## ]]`) prepended to the generated content for specific output fields defined in the Signature. These markers allow the Adapter's `parse` method to reliably extract the required output values.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/09_adapter.md#2025-04-22_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n[[ ## summary ## ]]\nDSPy helps build and optimize language model pipelines.\n```\n\n----------------------------------------\n\nTITLE: Creating a Repeat Command with Integer Count Parameter in Python Click\nDESCRIPTION: This example demonstrates using click.INT ParamType to validate and convert a count option into an integer that specifies how many times to print a message.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Click/04_paramtype.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# count_app.py\nimport click\n\n@click.command()\n@click.option('--count', default=1, type=click.INT, help='Number of times to print.')\n@click.argument('message')\ndef repeat(count, message):\n  \"\"\"Prints MESSAGE the specified number of times.\"\"\"\n  # 'count' is now guaranteed to be an integer!\n  for _ in range(count):\n    click.echo(message)\n\nif __name__ == '__main__':\n  repeat()\n```\n\n----------------------------------------\n\nTITLE: Example Text Output Table from dspy.Evaluate\nDESCRIPTION: This text block illustrates the expected table format generated by `dspy.Evaluate` when `display_table=True`. It shows the average metric score, followed by each example's input (`question`), gold answer (`answer`), and the result of the metric calculation (represented by ✔️ for True/1.0). Note that this requires the `pandas` library.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nAverage Metric: 3 / 4  (75.0%)\n  question                           answer      simple_exact_match_metric\n0 What color is the sky?           blue        ✔️ [True]\n1 What is 2 + 2?                   4           ✔️ [True]\n2 What is the capital of France?   Paris       ✔️ [True]\n3 Who wrote Hamlet?                Shakespeare \n```\n\n----------------------------------------\n\nTITLE: Blueprint Registration Process Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram illustrating the step-by-step process of registering a Flask Blueprint with the main application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Code as Your Code (e.g., user.py)\n    participant BP as user_bp (Blueprint obj)\n    participant App as Main App (Flask obj)\n    participant State as BlueprintSetupState\n\n    Code->>+BP: @user_bp.route('/profile/<name>')\n    BP->>BP: record(deferred_add_rule_func)\n    BP-->>-Code: Decorator applied\n\n    Note over App: Later, in app.py...\n    App->>App: app.register_blueprint(user_bp, url_prefix='/users')\n    App->>+State: Create BlueprintSetupState(bp=user_bp, app=app, options={...})\n    State-->>-App: Return state object\n    App->>BP: For func in user_bp.deferred_functions:\n    Note right of BP: func = deferred_add_rule_func\n    App->>BP: func(state)\n    BP->>+State: deferred_add_rule_func calls state.add_url_rule('/profile/<name>', ...)\n    State->>App: Calls app.add_url_rule('/users/profile/<name>', endpoint='user.profile', ...)\n    App->>App: Adds rule to app.url_map\n    State-->>-BP: add_url_rule finished\n    BP-->>App: Deferred function finished\n```\n\n----------------------------------------\n\nTITLE: Accessing CrawlResult from AsyncWebCrawler in Python\nDESCRIPTION: This snippet demonstrates how to use AsyncWebCrawler to crawl a URL and obtain a CrawlResult object. It shows the basic setup for an asynchronous crawl operation and how to access the returned result.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/07_crawlresult.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\n\nasync def main():\n    async with AsyncWebCrawler() as crawler:\n        url = \"https://httpbin.org/html\"\n        print(f\"Crawling {url}...\")\n\n        # The 'arun' method returns a CrawlResult object\n        result: CrawlResult = await crawler.arun(url=url) # Type hint optional\n\n        print(\"Crawl finished!\")\n        # Now 'result' holds all the information\n        print(f\"Result object type: {type(result)}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Retrieving Results in Celery's SyncBackendMixin\nDESCRIPTION: This code snippet demonstrates the wait_for method in SyncBackendMixin, which is used to poll the backend for task results. It repeatedly checks the task's metadata until a final state is reached or a timeout occurs.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef wait_for(self, task_id,\n             timeout=None, interval=0.5, no_ack=True, on_interval=None):\n    \"\"\"Wait for task and return its result meta.\"\"\"\n    self._ensure_not_eager() # Check if running in eager mode\n\n    time_elapsed = 0.0\n\n    while True:\n        # 1. Get metadata from backend (calls self._get_task_meta_for)\n        meta = self.get_task_meta(task_id)\n\n        # 2. Check if the task is in a final state\n        if meta['status'] in states.READY_STATES:\n            return meta # Return the full metadata dict\n\n        # 3. Call interval callback if provided\n        if on_interval:\n            on_interval()\n\n        # 4. Sleep to avoid busy-waiting\n        time.sleep(interval)\n        time_elapsed += interval\n\n        # 5. Check for timeout\n        if timeout and time_elapsed >= timeout:\n            raise TimeoutError('The operation timed out.')\n```\n\n----------------------------------------\n\nTITLE: Adding Operations to WriteBatch in LevelDB (C++)\nDESCRIPTION: Shows how Put and Delete operations are serialized and added to WriteBatch's internal representation buffer. The code includes the serialization format, methods for adding key-value pairs or deletion markers, and helper functions for manipulating the batch header.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/05_writebatch.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: leveldb/write_batch.cc ---\n\n// Simplified serialization format:\n// rep_ :=\n//    sequence: fixed64 (8 bytes, initially 0)\n//    count:    fixed32 (4 bytes, number of records)\n//    data:     record[count]\n// record :=\n//    kTypeValue  varstring varstring |\n//    kTypeDeletion varstring\n// varstring :=\n//    len: varint32\n//    data: uint8[len]\n\nvoid WriteBatch::Put(const Slice& key, const Slice& value) {\n  // Increment the record count stored in the header\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n\n  // Append the type marker (kTypeValue)\n  rep_.push_back(static_cast<char>(kTypeValue));\n  // Append the key (length-prefixed)\n  PutLengthPrefixedSlice(&rep_, key);\n  // Append the value (length-prefixed)\n  PutLengthPrefixedSlice(&rep_, value);\n}\n\nvoid WriteBatch::Delete(const Slice& key) {\n  // Increment the record count stored in the header\n  WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1);\n\n  // Append the type marker (kTypeDeletion)\n  rep_.push_back(static_cast<char>(kTypeDeletion));\n  // Append the key (length-prefixed)\n  PutLengthPrefixedSlice(&rep_, key);\n}\n\n// Helper to get/set the 4-byte count from the header (bytes 8-11)\nint WriteBatchInternal::Count(const WriteBatch* b) {\n  return DecodeFixed32(b->rep_.data() + 8); // Read count from header\n}\nvoid WriteBatchInternal::SetCount(WriteBatch* b, int n) {\n  EncodeFixed32(&b->rep_[8], n); // Write count to header\n}\n\n// Helper to get the full serialized content\nSlice WriteBatchInternal::Contents(const WriteBatch* batch) {\n  return Slice(batch->rep_);\n}\n```\n\n----------------------------------------\n\nTITLE: Visualizing the HTTP Basic Authentication Flow in Requests\nDESCRIPTION: This Mermaid sequence diagram illustrates the internal steps taken by the `requests` library when performing HTTP Basic Authentication. It shows the interaction flow starting from the user's function call (`requests.get` or `Session.request`), through the creation and preparation of the `PreparedRequest`, the instantiation and invocation of the `HTTPBasicAuth` object, the modification of request headers, sending the request to the server, and finally returning the response.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/05_authentication_handlers.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant UserCode as Your Code\n    participant ReqFunc as requests.get / Session.request\n    participant PrepReq as PreparedRequest\n    participant AuthObj as HTTPBasicAuth Instance\n    participant Server\n\n    UserCode->>ReqFunc: Call get(url, auth=('user', 'pass'))\n    ReqFunc->>PrepReq: Create PreparedRequest (p)\n    ReqFunc->>PrepReq: Call p.prepare_auth(auth=...)\n    Note over PrepReq: Detects tuple, creates HTTPBasicAuth('user', 'pass')\n    PrepReq->>AuthObj: Call auth_obj(p)\n    activate AuthObj\n    AuthObj->>AuthObj: Calculate 'Basic ...' string\n    AuthObj->>PrepReq: Set p.headers['Authorization'] = 'Basic ...'\n    AuthObj-->>PrepReq: Return modified p\n    deactivate AuthObj\n    PrepReq-->>ReqFunc: Return prepared request p\n    ReqFunc->>Server: Send HTTP Request (with Authorization header)\n    Server-->>ReqFunc: Send HTTP Response\n    ReqFunc-->>UserCode: Return Response\n```\n\n----------------------------------------\n\nTITLE: BrowserContext get_state() Sequence Diagram in Mermaid\nDESCRIPTION: A sequence diagram illustrating the process flow when BrowserContext's get_state() method is called. It shows the interactions between the Agent, BrowserContext, underlying browser page, and DOM Service to gather the complete state information.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/03_browsercontext.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant BC as BrowserContext\n    participant PlaywrightPage as Underlying Browser Page\n    participant DomService as DOM Service\n\n    Agent->>BC: get_state()\n    Note over BC: Wait for page to be ready...\n    BC->>PlaywrightPage: Ensure page/network is stable\n    PlaywrightPage-->>BC: Page is ready\n    Note over BC: Analyze the page content...\n    BC->>DomService: Get simplified DOM structure + interactive elements\n    DomService-->>BC: DOMState (element tree, etc.)\n    Note over BC: Get visuals and metadata...\n    BC->>PlaywrightPage: Take screenshot()\n    PlaywrightPage-->>BC: Screenshot data\n    BC->>PlaywrightPage: Get URL, Title\n    PlaywrightPage-->>BC: URL, Title data\n    Note over BC: Combine everything...\n    BC->>BC: Create BrowserState object\n    BC-->>Agent: Return BrowserState\n```\n\n----------------------------------------\n\nTITLE: Celery AMQP Task Sender Implementation\nDESCRIPTION: Internal implementation of Celery's task sending mechanism in app/amqp.py, showing how messages are created and published to the broker\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/04_broker_connection__amqp_.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Simplified from app/amqp.py within the AMQP class\n\n# This function is configured internally and gets called by app.send_task\ndef _create_task_sender(self):\n    # ... (lots of setup: getting defaults from config, signals) ...\n    default_serializer = self.app.conf.task_serializer\n    default_compressor = self.app.conf.task_compression\n\n    def send_task_message(producer, name, message,\n                          exchange=None, routing_key=None, queue=None,\n                          serializer=None, compression=None, declare=None,\n                          retry=None, retry_policy=None,\n                           **properties):\n        # ... (Determine exchange, routing_key, queue based on config/options) ...\n        # ... (Prepare headers, properties, handle retries) ...\n\n        headers, properties, body, sent_event = message # Unpack the prepared message tuple\n\n        # The core action: Use the producer to publish the message!\n        ret = producer.publish(\n            body, # The actual task payload (args, kwargs, etc.)\n            exchange=exchange,\n            routing_key=routing_key,\n            serializer=serializer or default_serializer, # e.g., 'json'\n            compression=compression or default_compressor,\n            retry=retry,\n            retry_policy=retry_policy,\n            declare=declare, # Maybe declare queues/exchanges if needed\n            headers=headers,\n            **properties # Other message properties (correlation_id, etc.)\n        )\n\n        # ... (Send signals like task_sent, publish events if configured) ...\n        return ret\n    return send_task_message\n```\n\n----------------------------------------\n\nTITLE: Visualizing DSPy Module and Signature Workflow with Mermaid\nDESCRIPTION: Provides a visual sequence diagram (in Mermaid syntax) illustrating the workflow between the user, dspy.Predict module, Signature class, and the Language Model. The diagram shows data flow, prompt formatting, LM invocation, and output parsing. This visual is intended for documentation and requires Mermaid support for rendering.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/02_signature.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant PredictModule as dspy.Predict(TranslateToFrench)\n    participant Signature as TranslateToFrench\n    participant LM as Language Model\n\n    User->>PredictModule: Call with english_sentence=\"Hello\"\n    PredictModule->>Signature: Get Instructions, Input/Output Fields\n    Signature-->>PredictModule: Return structure (\"Translates...\", \"english_sentence\", \"french_sentence\")\n    PredictModule->>LM: Send formatted prompt (e.g., \"Translate...\\nEnglish: Hello\\nFrench:\")\n    LM-->>PredictModule: Return generated text (e.g., \"Bonjour\")\n    PredictModule->>Signature: Parse LM output into 'french_sentence' field\n    Signature-->>PredictModule: Return structured output {french_sentence: \"Bonjour\"}\n    PredictModule-->>User: Return structured output (Prediction object)\n\n```\n\n----------------------------------------\n\nTITLE: Visualizing Crawl4AI Components with Mermaid Flowchart\nDESCRIPTION: This Mermaid flowchart illustrates the relationships between various components of the Crawl4AI library, including AsyncWebCrawler, CrawlerRunConfig, and different strategies for crawling, scraping, and filtering content.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"AsyncWebCrawler\"]\n    A1[\"CrawlerRunConfig\"]\n    A2[\"AsyncCrawlerStrategy\"]\n    A3[\"ContentScrapingStrategy\"]\n    A4[\"ExtractionStrategy\"]\n    A5[\"CrawlResult\"]\n    A6[\"BaseDispatcher\"]\n    A7[\"DeepCrawlStrategy\"]\n    A8[\"CacheContext / CacheMode\"]\n    A9[\"RelevantContentFilter\"]\n    A0 -- \"Configured by\" --> A1\n    A0 -- \"Uses Fetching Strategy\" --> A2\n    A0 -- \"Uses Scraping Strategy\" --> A3\n    A0 -- \"Uses Extraction Strategy\" --> A4\n    A0 -- \"Produces\" --> A5\n    A0 -- \"Uses Dispatcher for `arun_m...\" --> A6\n    A0 -- \"Uses Caching Logic\" --> A8\n    A6 -- \"Calls Crawler's `arun`\" --> A0\n    A1 -- \"Specifies Deep Crawl Strategy\" --> A7\n    A7 -- \"Processes Links from\" --> A5\n    A3 -- \"Provides Cleaned HTML to\" --> A9\n    A1 -- \"Specifies Content Filter\" --> A9\n```\n\n----------------------------------------\n\nTITLE: LLM JSON Response Format Example\nDESCRIPTION: Example of JSON response format showing how the LLM uses highlight indices to specify actions\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Browser Use/04_dom_representation.md#2025-04-22_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"current_state\": {\n    \"evaluation_previous_goal\": \"...\",\n    \"memory\": \"On Google homepage, need to search for cats.\",\n    \"next_goal\": \"Type 'cute cats' into the search bar [5].\"\n  },\n  \"action\": [\n    {\n      \"input_text\": {\n        \"index\": 5,\n        \"text\": \"cute cats\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Core Implementation of Message and Memory in OpenManus\nDESCRIPTION: This snippet shows the simplified core implementation of the Message and Memory classes from app/schema.py in OpenManus, demonstrating their structure and key methods.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/02_message___memory.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Simplified snippet from app/schema.py\n\nfrom typing import List, Optional\nfrom pydantic import BaseModel, Field\n```\n\n----------------------------------------\n\nTITLE: Visualizing Requests Library Architecture with Mermaid\nDESCRIPTION: A flowchart diagram illustrating the relationships between key components of the Requests library, including Request & Response Models, Session, Transport Adapters, Functional API, Authentication Handlers, Cookie Jar, Exception Hierarchy, and Hook System.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Requests/index.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart TD\n    A0[\"Request & Response Models\"]\n    A1[\"Session\"]\n    A2[\"Transport Adapters\"]\n    A3[\"Functional API\"]\n    A4[\"Authentication Handlers\"]\n    A5[\"Cookie Jar\"]\n    A6[\"Exception Hierarchy\"]\n    A7[\"Hook System\"]\n    A3 -- \"Uses temporary\" --> A1\n    A1 -- \"Prepares/Receives\" --> A0\n    A1 -- \"Manages & Uses\" --> A2\n    A1 -- \"Manages\" --> A5\n    A1 -- \"Manages\" --> A4\n    A1 -- \"Manages\" --> A7\n    A2 -- \"Sends/Builds\" --> A0\n    A4 -- \"Modifies (adds headers)\" --> A0\n    A5 -- \"Populates/Reads\" --> A0\n    A7 -- \"Operates on\" --> A0\n    A0 -- \"Can Raise (raise_for_status)\" --> A6\n    A2 -- \"Raises Connection Errors\" --> A6\n```\n\n----------------------------------------\n\nTITLE: Visualizing Codex Configuration Loading Sequence\nDESCRIPTION: Mermaid sequence diagram illustrating how Codex loads configuration at startup. It shows the interaction between the CLI process, ConfigLoader, and FileSystem to read and combine settings from config.yaml and instructions files (both global and project-specific).\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Codex/07_configuration_management.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant CLI as Codex CLI Process\n    participant ConfigLoader as config.ts (loadConfig)\n    participant FileSystem as Your Computer's Files\n\n    CLI->>ConfigLoader: Start: Call loadConfig()\n    ConfigLoader->>FileSystem: Check for ~/.codex/config.yaml (or .json, .yml)?\n    FileSystem-->>ConfigLoader: Found config.yaml\n    ConfigLoader->>FileSystem: Read ~/.codex/config.yaml\n    FileSystem-->>ConfigLoader: YAML content (e.g., model: gpt-4o)\n    ConfigLoader->>ConfigLoader: Parse YAML, store model='gpt-4o'\n    ConfigLoader->>FileSystem: Check for ~/.codex/instructions.md?\n    FileSystem-->>ConfigLoader: Found instructions.md\n    ConfigLoader->>FileSystem: Read ~/.codex/instructions.md\n    FileSystem-->>ConfigLoader: Global instructions text\n    ConfigLoader->>FileSystem: Check for project 'codex.md' (discoverProjectDocPath)?\n    FileSystem-->>ConfigLoader: Found project/codex.md\n    ConfigLoader->>FileSystem: Read project/codex.md\n    FileSystem-->>ConfigLoader: Project instructions text\n    ConfigLoader->>ConfigLoader: Combine global + project instructions\n    ConfigLoader-->>CLI: Return AppConfig object { model, instructions }\n    CLI->>CLI: Use AppConfig for AgentLoop, etc.\n```\n\n----------------------------------------\n\nTITLE: Simplified Recovery Logic in LevelDB\nDESCRIPTION: This snippet demonstrates the conceptual logic for recovering a database from log files in LevelDB. It shows how records are read from log files, parsed into WriteBatch objects, and applied to MemTables. It also handles MemTable flushing if it becomes full during recovery.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/04_dbimpl.md#2025-04-22_snippet_5\n\nLANGUAGE: c++\nCODE:\n```\n// --- Conceptual, simplified from DBImpl::RecoverLogFile ---\n\n// Inside loop processing a single log file during recovery:\nwhile (reader.ReadRecord(&record, &scratch) && status.ok()) {\n  // Check if record looks like a valid WriteBatch\n  if (record.size() < 12) { /* report corruption */ continue; }\n\n  // Parse the raw log record back into a WriteBatch object\n  WriteBatchInternal::SetContents(&batch, record);\n\n  // Create a MemTable if we don't have one yet for this log\n  if (mem == nullptr) {\n    mem = new MemTable(internal_comparator_);\n    mem->Ref();\n  }\n\n  // Apply the operations from the batch TO THE MEMTABLE\n  status = WriteBatchInternal::InsertInto(&batch, mem);\n  // ... handle error ...\n\n  // Keep track of the latest sequence number seen\n  const SequenceNumber last_seq = /* ... get sequence from batch ... */;\n  if (last_seq > *max_sequence) {\n    *max_sequence = last_seq;\n  }\n\n  // If the MemTable gets full *during recovery*, flush it!\n  if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n    status = WriteLevel0Table(mem, edit, nullptr); // Flush to L0 SSTable\n    mem->Unref();\n    mem = nullptr; // Will create a new one if needed\n    // ... handle error ...\n  }\n}\n// After loop, handle the final state of 'mem'\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Beat Process Flow with Mermaid Diagram\nDESCRIPTION: A sequence diagram showing the interaction between the Celery Beat process, configuration, schedule file, message broker, and worker. It illustrates the tick loop that checks for due tasks and the message flow when tasks are executed.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/07_beat__scheduler_.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Beat as Celery Beat Process\n    participant ScheduleCfg as beat_schedule Config\n    participant ScheduleDB as celerybeat-schedule File\n    participant Broker as Message Broker\n    participant Worker as Celery Worker\n\n    Beat->>ScheduleCfg: Load schedule definitions on startup\n    Beat->>ScheduleDB: Load last run times on startup\n\n    loop Tick Loop (e.g., every second or more)\n        Beat->>Beat: Check current time\n        Beat->>ScheduleCfg: Get definition for 'add-every-15'\n        Beat->>ScheduleDB: Get last run time for 'add-every-15'\n        Beat->>Beat: Calculate if 'add-every-15' is due now\n        alt Task 'add-every-15' is due\n            Beat->>Broker: Send task message('tasks.add', (16, 16))\n            Broker-->>Beat: Ack (Message Queued)\n            Beat->>ScheduleDB: Update last run time for 'add-every-15'\n            ScheduleDB-->>Beat: Ack (Saved)\n        end\n        Beat->>Beat: Calculate time until next task is due\n        Beat->>Beat: Sleep until next check\n    end\n\n    Worker->>Broker: Fetch task message ('tasks.add', ...)\n    Broker-->>Worker: Deliver message\n    Worker->>Worker: Execute task add(16, 16)\n    Worker->>Broker: Ack message complete\n```\n\n----------------------------------------\n\nTITLE: Read Flow Sequence Diagram in LevelDB\nDESCRIPTION: Illustrates the sequence of operations during a read (Get) operation in LevelDB, showing how data is searched across MemTable, Immutable MemTable, and SSTable Cache.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/02_memtable.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as App Read (Get)\n    participant LevelDB\n    participant MemTable as Active MemTable (RAM)\n    participant ImMemTable as Immutable MemTable (RAM, if exists)\n    participant TableCache as SSTable Cache (Disk/RAM)\n\n    Client->>LevelDB: Get(\"some_key\")\n    LevelDB->>MemTable: Have \"some_key\"?\n    alt Key found in Active MemTable\n        MemTable-->>LevelDB: Yes, value is \"xyz\"\n        LevelDB-->>Client: Return \"xyz\"\n    else Key Deleted in Active MemTable\n        MemTable-->>LevelDB: Yes, it's deleted\n        LevelDB-->>Client: Return NotFound\n    else Not in Active MemTable\n        MemTable-->>LevelDB: No\n        LevelDB->>ImMemTable: Have \"some_key\"?\n        alt Key found in Immutable MemTable\n             ImMemTable-->>LevelDB: Yes, value is \"abc\"\n             LevelDB-->>Client: Return \"abc\"\n        else Key Deleted in Immutable MemTable\n             ImMemTable-->>LevelDB: Yes, it's deleted\n             LevelDB-->>Client: Return NotFound\n        else Not in Immutable MemTable\n            ImMemTable-->>LevelDB: No\n            LevelDB->>TableCache: Get(\"some_key\") from SSTables\n            TableCache-->>LevelDB: Found \"old_value\" / NotFound\n            LevelDB-->>Client: Return \"old_value\" / NotFound\n        end\n    end\n```\n\n----------------------------------------\n\nTITLE: Demonstrating the Need for Array Printing in NumPy\nDESCRIPTION: This snippet shows why specialized array printing is necessary by creating a large array that would be overwhelming to print in full. It illustrates the problem that NumPy's arrayprint mechanism solves.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/05_array_printing___arrayprint__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\n# Imagine this is a huge array, maybe thousands of numbers\nlarge_array = np.arange(2000)\n\n# If Python just tried to print every single number...\n# it would flood your screen and be impossible to read!\n# print(list(large_array)) # <-- Don't run this! It would be too long.\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Task Execution Flow with Mermaid\nDESCRIPTION: This mermaid sequence diagram illustrates the flow of task execution in Celery, from task definition to message sending and worker execution. It shows the interactions between different components of the Celery system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/03_task.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Your Code (run_tasks.py)\n    participant TaskDef as @app.task def add()\n    participant App as Celery App Instance\n    participant Broker as Message Broker (e.g., Redis)\n    participant Worker as Celery Worker (separate process)\n\n    Note over TaskDef, App: 1. @app.task registers 'add' function with App's task registry\n\n    Client->>TaskDef: 2. Call add.delay(5, 7)\n    TaskDef->>App: 3. Get broker config\n    App-->>TaskDef: Broker URL\n    TaskDef->>Broker: 4. Send message ('tasks.add', (5, 7), task_id, ...)\n    Broker-->>TaskDef: Ack (Message Queued)\n    TaskDef-->>Client: 5. Return AsyncResult(task_id)\n\n    Worker->>Broker: 6. Fetch next message\n    Broker-->>Worker: Message ('tasks.add', (5, 7), task_id)\n    Worker->>App: 7. Lookup 'tasks.add' in registry\n    App-->>Worker: add function code\n    Worker->>Worker: 8. Execute add(5, 7) -> returns 12\n    Note over Worker: (Optionally store result in Backend)\n    Worker->>Broker: 9. Acknowledge message completion\n```\n\n----------------------------------------\n\nTITLE: Visualizing Message Flow with Mermaid Sequence Diagram\nDESCRIPTION: This Mermaid sequence diagram illustrates the high-level interaction flow when a user sends a message. It shows the sequence of calls between the User, the Mesop Frontend (UI), the Backend Client, the Backend Server, the Backend Manager (ADKHostManager), and the Agent Logic. It covers both the initial message sending and the subsequent UI polling mechanism used to retrieve and display agent responses and state updates.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/09_demo_ui_application___service.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant UI as Mesop Frontend\n    participant BClient as Backend Client (host_agent_service)\n    participant BServer as Backend Service (ConversationServer)\n    participant Manager as Backend Manager (ADKHostManager)\n    participant Agent as Agent Logic (Host Agent / ADK)\n\n    User->>UI: Type message, press Enter\n    UI->>BClient: Call SendMessage(msg)\n    BClient->>BServer: POST /message/send (JSON: msg)\n    BServer->>Manager: Call process_message(msg) [async]\n    BServer-->>BClient: 200 OK (Ack)\n    BClient-->>UI: Return (UI shows processing)\n\n    Note over Manager, Agent: Agent processing happens...\n    Manager->>Agent: Run agent with message\n    Agent-->>Manager: Agent produces results/updates\n    Manager->>Manager: Store results/state updates\n\n    loop UI Polling for Updates\n        UI->>BClient: Call UpdateAppState()\n        BClient->>BServer: POST /message/list, /task/list, etc.\n        BServer->>Manager: Get current state data\n        Manager-->>BServer: Return state data\n        BServer-->>BClient: 200 OK (JSON: state)\n        BClient->>UI: Update Mesop AppState\n        Note over UI: Mesop re-renders with new data (agent response)\n    end\n```\n\n----------------------------------------\n\nTITLE: Registering a Flask Blueprint with URL Prefix - Python\nDESCRIPTION: This snippet demonstrates how to register a previously defined Flask Blueprint ('user_bp') to the main Flask application with a URL prefix. It imports the blueprint, configures the Flask app, uses app.register_blueprint() with a custom URL prefix, and defines a simple home route. To function, this code relies on the blueprint being available from blueprints.user, Flask installed, and (optionally) secret key configuration. Outputs are served at the expected endpoints, with blueprint routes under '/users/'.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/08_blueprints.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# app.py\nfrom flask import Flask\nfrom blueprints.user import user_bp # Import the blueprint object\n\napp = Flask(__name__)\n# We might have other config here, like SECRET_KEY from Chapter 6\n# app.config['SECRET_KEY'] = 'your secret key'\n\n# Register the blueprint with the main application\n# We can add a url_prefix here!\napp.register_blueprint(user_bp, url_prefix='/users')\n\n# Maybe add a simple homepage route directly on the app\n@app.route('/')\ndef home():\n  return 'Welcome to the main application!'\n\nif __name__ == '__main__':\n  app.run(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Validation Example in Pydantic\nDESCRIPTION: Demonstrates the validation process in Pydantic, showing how to create a model instance from a dictionary and handle validation errors.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Pydantic Core/05_core_schema___validation_serialization.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Example: Validation\ntry:\n    user_data = {'id': 1, 'userName': 'validUser'}\n    user = User(**user_data) # Calls __init__ -> pydantic validation\n    # or: user = User.model_validate(user_data)\nexcept ValidationError as e:\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Comparing Internal Keys in LevelDB\nDESCRIPTION: Implementation of the InternalKeyComparator which orders keys first by user key, then by descending sequence number, and finally by descending type.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/09_internalkey___dbformat.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/dbformat.cc ---\n\nint InternalKeyComparator::Compare(const Slice& akey, const Slice& bkey) const {\n  // 1. Compare user keys using the user's comparator\n  int r = user_comparator_->Compare(ExtractUserKey(akey), ExtractUserKey(bkey));\n\n  if (r == 0) {\n    // User keys are equal, compare sequence numbers (descending)\n    // Decode the 8-byte tag (seq+type) from the end of each key\n    const uint64_t anum = DecodeFixed64(akey.data() + akey.size() - 8);\n    const uint64_t bnum = DecodeFixed64(bkey.data() + bkey.size() - 8);\n    // Higher sequence number should come first (negative result)\n    if (anum > bnum) {\n      r = -1;\n    } else if (anum < bnum) {\n      r = +1;\n    }\n    // If sequence numbers are also equal, type decides (descending,\n    // but packed value comparison handles this implicitly).\n  }\n  return r;\n}\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of PlanningFlow Execution (Mermaid)\nDESCRIPTION: This Mermaid diagram illustrates the sequence of interactions between the user, PlanningFlow, LLM-based planner, PlanningTool, executor agent, and agent's LLM during a multi-step plan execution. It visually shows how steps are proposed, delegated, executed, marked complete, and results are compiled in the system. No external code dependencies are required to interpret this diagram, but a Mermaid-compatible renderer is necessary for visualization.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/05_baseflow.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\\n    participant User\\n    participant PF as PlanningFlow\\n    participant LLM_Planner as LLM (for Planning)\\n    participant PlanTool as PlanningTool\\n    participant Executor as Executor Agent (e.g., Manus)\\n    participant AgentLLM as Agent's LLM (for Execution)\\n\\n    User->>+PF: execute(\\\"Research & Summarize Solar Power\\\")\\n    PF->>+LLM_Planner: ask_tool(\\\"Create plan...\\\", tools=[PlanTool])\\n    LLM_Planner->>+PlanTool: execute(command='create', steps=['Search', 'Summarize'], ...)\\n    PlanTool-->>-LLM_Planner: Plan created (ID: plan_123)\\n    LLM_Planner-->>-PF: Plan created successfully\\n    Note over PF: Start Execution Loop\\n    loop Plan Steps\\n        PF->>+PlanTool: get_next_step(plan_id='plan_123')\\n        PlanTool-->>-PF: Step 0: \\\"Search\\\"\\n        PF->>PF: Select Executor (Manus)\\n        PF->>+Executor: run(\\\"Execute step 0: 'Search'...\\\")\\n        Executor->>+AgentLLM: ask/ask_tool (e.g., use web search)\\n        AgentLLM-->>-Executor: Search results\\n        Executor-->>-PF: Step 0 result (\\\"Found benefits X, Y, Z...\\\")\\n        PF->>+PlanTool: mark_step(plan_id='plan_123', step=0, status='completed')\\n        PlanTool-->>-PF: Step marked\\n        PF->>+PlanTool: get_next_step(plan_id='plan_123')\\n        PlanTool-->>-PF: Step 1: \\\"Summarize\\\"\\n        PF->>PF: Select Executor (Manus)\\n        PF->>+Executor: run(\\\"Execute step 1: 'Summarize'...\\\")\\n        Executor->>+AgentLLM: ask(\\\"Summarize: X, Y, Z...\\\")\\n        AgentLLM-->>-Executor: Summary text\\n        Executor-->>-PF: Step 1 result (\\\"Solar power benefits include...\\\")\\n        PF->>+PlanTool: mark_step(plan_id='plan_123', step=1, status='completed')\\n        PlanTool-->>-PF: Step marked\\n        PF->>+PlanTool: get_next_step(plan_id='plan_123')\\n        PlanTool-->>-PF: No more steps\\n    end\\n    Note over PF: End Execution Loop\\n    PF->>PF: Finalize (optional summary)\\n    PF-->>-User: Final combined result string\\n\n```\n\n----------------------------------------\n\nTITLE: Defining Task and TaskStatus Interfaces in TypeScript for A2A Protocol\nDESCRIPTION: This code snippet defines the core TypeScript interfaces for the Task and TaskStatus data structures in the A2A protocol. The Task interface includes fields for identification, status tracking, and result storage, while TaskStatus tracks the state, associated messages, and timestamps of a task.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/02_task.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n// File: samples/js/src/schema.ts (Simplified Task Structure)\n\nexport interface Task {\n  // Unique identifier for the task.\n  id: string;\n  // The current status of the task.\n  status: TaskStatus;\n  // Optional list of artifacts (outputs).\n  artifacts?: Artifact[] | null;\n  // (Optional) History of messages for this task\n  // history?: Message[] | null;\n  // ... other fields like sessionId, metadata\n}\n\nexport interface TaskStatus {\n  // The current state (e.g., \"submitted\", \"working\", \"completed\").\n  state: TaskState;\n  // Optional message associated with this status.\n  message?: Message | null;\n  // Timestamp of this status update.\n  timestamp?: string;\n}\n\n// Example Artifact containing translated text\n// artifact = { parts: [ { type: \"text\", text: \"Bonjour le monde\" } ] }\n```\n\n----------------------------------------\n\nTITLE: Imports and Message Definitions for Agent Communication\nDESCRIPTION: Defines the necessary imports from autogen_core and creates dataclasses for the messages (ResearchTopic and ResearchFacts) that will be exchanged between agents in the example system.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/03_agentruntime.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# 0. Imports and Message Definitions (from previous chapters)\nimport asyncio\nfrom dataclasses import dataclass\nfrom autogen_core import (\n    AgentId, BaseAgent, SingleThreadedAgentRuntime, TopicId,\n    MessageContext, TypeSubscription, AgentInstantiationContext\n)\n\n@dataclass\nclass ResearchTopic: topic: str\n@dataclass\nclass ResearchFacts: topic: str; facts: list[str]\n```\n\n----------------------------------------\n\nTITLE: VersionEdit Application Sequence Diagram (Mermaid)\nDESCRIPTION: A sequence diagram illustrating the process of applying a VersionEdit in LevelDB. It shows the interaction between background tasks, VersionEdit, VersionSet, and the MANIFEST file during state changes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/06_version___versionset.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant BG as Background Task (Flush/Compact)\n    participant VE as VersionEdit\n    participant VS as VersionSet\n    participant VSCur as Current Version\n    participant VSBld as VersionSet::Builder\n    participant V as New Version\n    participant Manifest as MANIFEST Log File\n\n    BG ->> VE: Create edit (add file X, remove Y)\n    BG ->> VS: LogAndApply(edit)\n    VS ->> VSCur: Get current state\n    VS ->> VSBld: Create Builder(based on VSCur)\n    VSBld ->> VE: Apply(edit)\n    VSBld ->> V: Save resulting state to New Version\n    VS ->> V: Finalize()\n    VE ->> VE: EncodeTo(record)\n    VS ->> Manifest: AddRecord(record)\n    Manifest -->> VS: Write Status OK\n    VS ->> V: AppendVersion(V)  // Make V the new 'current'\n    VS ->> VS: Update log_number etc.\n    VS -->> BG: Return OK\n```\n\n----------------------------------------\n\nTITLE: Loading Flask Configuration Path from Environment Variable (Python)\nDESCRIPTION: Illustrates the start of using `app.config.from_envvar()` to load a configuration file whose path is specified by an environment variable (e.g., `YOURAPP_SETTINGS`). This method reads the file path from the environment variable and then uses `from_pyfile` internally to load the actual configuration file. It requires the corresponding environment variable to be set before running the application.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# hello.py\nfrom flask import Flask\n\napp = Flask(__name__)\n\n# Attempt to load config specified by environment variable 'YOURAPP_SETTINGS'\n# Needs environment variable set beforehand:\n# export YOURAPP_SETTINGS=/path/to/settings.cfg (Linux/macOS)\n# set YOURAPP_SETTINGS=C:\\path\\to\\settings.cfg (Windows cmd)\n# $env:YOURAPP_SETTINGS=\"C:\\path\\to\\settings.cfg\" (Windows PowerShell)\n# app.config.from_envvar('YOURAPP_SETTINGS', silent=True) # Example usage\n\n```\n\n----------------------------------------\n\nTITLE: Celery Worker Startup Banner Output\nDESCRIPTION: Example console output when starting a Celery worker, showing configuration details including transport settings, concurrency level, and registered tasks. Demonstrates successful worker initialization and broker connection.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/05_worker.md#2025-04-22_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n -------------- celery@yourhostname v5.x.x (stars)\n--- ***** -----\n-- ******* ---- Linux-5.15.0...-generic-x86_64-with-... 2023-10-27 10:00:00\n- *** --- * ---\n- ** ---------- [config]\n- ** ---------- .> app:         tasks:0x7f...\n- ** ---------- .> transport:   redis://localhost:6379/0\n- ** ---------- .> results:     redis://localhost:6379/0\n- *** --- * --- .> concurrency: 8 (prefork)\n-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)\n--- ***** -----\n -------------- [queues]\n                .> celery           exchange=celery(direct) key=celery\n\n\n[tasks]\n  . tasks.add\n  . tasks.send_welcome_email\n\n[2023-10-27 10:00:01,000: INFO/MainProcess] Connected to redis://localhost:6379/0\n[2023-10-27 10:00:01,050: INFO/MainProcess] mingle: searching for neighbors\n[2023-10-27 10:00:02,100: INFO/MainProcess] mingle: all alone\n[2023-10-27 10:00:02,150: INFO/MainProcess] celery@yourhostname ready.\n```\n\n----------------------------------------\n\nTITLE: Searching SSTables Across Levels in LevelDB Version::Get (C++)\nDESCRIPTION: This C++ snippet outlines the `Version::Get` method, responsible for looking up a key within the set of SSTables defined by a specific `Version`. It iterates through levels, searching Level-0 files (which may overlap) newest-first. For higher levels (Levels > 0), where files are sorted and non-overlapping, it uses a binary search (`FindFile`) to efficiently locate the correct file before searching within it via the `TableCache`. The search terminates upon finding the key or exhausting all relevant files.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/06_version___versionset.md#2025-04-22_snippet_1\n\nLANGUAGE: c++\nCODE:\n```\n// --- Simplified from db/version_set.cc ---\n\nStatus Version::Get(const ReadOptions& options, const LookupKey& k,\n                    std::string* value, GetStats* stats) {\n  Slice ikey = k.internal_key();\n  Slice user_key = k.user_key();\n\n  // We search level-by-level\n  for (int level = 0; level < config::kNumLevels; level++) {\n    const std::vector<FileMetaData*>& files = files_[level]; // Get list for this level\n    if (files.empty()) continue; // Skip empty levels\n\n    if (level == 0) {\n      // Level-0 files might overlap, search newest-first\n      std::vector<FileMetaData*> tmp;\n      // Find potentially overlapping files in level 0\n      // ... logic to find relevant files ...\n      // Sort them newest-first\n      std::sort(tmp.begin(), tmp.end(), NewestFirst);\n      // Search each relevant file\n      for (uint32_t i = 0; i < tmp.size(); i++) {\n        FileMetaData* f = tmp[i];\n        // Use TableCache to search the actual SSTable file\n        Status s = vset_->table_cache_->Get(options, f->number, f->file_size,\n                                           ikey, /* saver state */, SaveValue);\n        // ... check if found/deleted/error and update stats ...\n        if (/* found or deleted */) return s;\n      }\n    } else {\n      // Levels > 0 files are sorted and non-overlapping\n      // Binary search to find the single file that might contain the key\n      uint32_t index = FindFile(vset_->icmp_, files, ikey);\n      if (index < files.size()) {\n        FileMetaData* f = files[index];\n        // Check if user_key is within the file's range\n        if (/* user_key is within f->smallest/f->largest range */) {\n          // Use TableCache to search the actual SSTable file\n          Status s = vset_->table_cache_->Get(options, f->number, f->file_size,\n                                             ikey, /* saver state */, SaveValue);\n          // ... check if found/deleted/error and update stats ...\n          if (/* found or deleted */) return s;\n        }\n      }\n    }\n  } // End loop over levels\n\n  return Status::NotFound(Slice()); // Key not found in any SSTable\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Entries to MemTable in LevelDB (C++)\nDESCRIPTION: This function adds a new key-value pair to the MemTable by calculating the required memory size, allocating memory from the Arena, encoding the entry with sequence number and type information, and inserting it into the SkipList. The encoded format includes key size, key bytes, sequence number with type tag, value size, and value bytes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/02_memtable.md#2025-04-22_snippet_3\n\nLANGUAGE: c++\nCODE:\n```\n// --- File: db/memtable.cc ---\n\nvoid MemTable::Add(SequenceNumber s, ValueType type, const Slice& key,\n                   const Slice& value) {\n  // Calculate size needed for the entry in the skiplist.\n  // Format includes key size, key, sequence number + type tag, value size, value.\n  size_t key_size = key.size();\n  size_t val_size = value.size();\n  size_t internal_key_size = key_size + 8; // 8 bytes for seq + type\n  const size_t encoded_len = VarintLength(internal_key_size) +\n                             internal_key_size + VarintLength(val_size) +\n                             val_size;\n\n  // Allocate memory from the Arena\n  char* buf = arena_.Allocate(encoded_len);\n\n  // Encode the entry into the buffer 'buf' (details omitted)\n  // Format: [key_len][key_bytes][seq_num|type][value_len][value_bytes]\n  // ... encoding logic ...\n\n  // Insert the buffer pointer into the SkipList. The SkipList uses the\n  // KeyComparator to know how to sort based on the encoded format.\n  table_.Insert(buf);\n}\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of TableCache Read Operation in Mermaid\nDESCRIPTION: This diagram visualizes the flow of a read operation using TableCache, showing both cache hit and cache miss scenarios. It illustrates how TableCache interacts with the LRUCache, filesystem, and Table objects to efficiently retrieve data.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LevelDB/01_table___sstable___tablecache.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Read Operation\n    participant TableCache\n    participant Cache as LRUCache\n    participant OS/FileSystem as FS\n    participant TableObject as In-Memory Table Rep\n\n    Client->>TableCache: Get(\"some_key\", file_num=5, size=1MB)\n    TableCache->>Cache: Lookup(file_num=5)?\n    alt Cache Hit\n        Cache-->>TableCache: Return handle for Table 5\n        TableCache->>TableObject: Find \"some_key\" within Table 5 data\n        TableObject-->>TableCache: Return value / not found\n        TableCache-->>Client: Return value / not found\n    else Cache Miss\n        Cache-->>TableCache: Not found (nullptr)\n        TableCache->>FS: Open file \"000005.ldb\"\n        FS-->>TableCache: Return file handle\n        TableCache->>TableObject: Create Table 5 representation from file handle + size\n        TableObject-->>TableCache: Return Table 5 object\n        TableCache->>Cache: Insert(file_num=5, Table 5 object)\n        Note right of Cache: Table 5 now cached\n        TableCache->>TableObject: Find \"some_key\" within Table 5 data\n        TableObject-->>TableCache: Return value / not found\n        TableCache-->>Client: Return value / not found\n    end\n```\n\n----------------------------------------\n\nTITLE: Implementing Calculator Server with FastMCP Tools\nDESCRIPTION: Example of creating a FastMCP server that exposes an addition tool. Demonstrates tool registration using @server.tool decorator, type hints for parameter validation, and basic server setup. The tool accepts two integers and returns their sum.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/04_fastmcp_tools___tool____toolmanager__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# 1. Import FastMCP\nfrom mcp.server.fastmcp import FastMCP\n\n# 2. Create the server instance\nserver = FastMCP(name=\"CalculatorServer\")\n\n# 3. Use the @server.tool() decorator to define our tool\n@server.tool(name=\"add\", description=\"Adds two numbers together.\")\ndef add_numbers(num1: int, num2: int) -> int:\n  \"\"\"\n  This function is registered as the 'add' tool.\n  'num1: int' and 'num2: int' tell FastMCP the tool expects\n  two integer arguments named 'num1' and 'num2'.\n  '-> int' tells FastMCP the tool will return an integer.\n  \"\"\"\n  print(f\"Tool 'add' called with {num1} and {num2}\") # Server-side log\n  # 4. The function's logic performs the action\n  result = num1 + num2\n  print(f\"Returning result: {result}\")\n  return result\n\n# 5. Standard run block\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run() # Start listening\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Visualizing Celery Task Execution Flow with Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of a Celery task from client initiation through execution, result storage, and retrieval. It shows interactions between the client, broker, worker, and result backend.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/06_result_backend.md#2025-04-22_snippet_5\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Your Application\n    participant Task as add.delay(10, 20)\n    participant Broker as Message Broker (Redis DB 0)\n    participant Worker as Celery Worker\n    participant ResultBackend as Result Backend (Redis DB 1)\n    participant AsyncResult as result_add = AsyncResult(...)\n\n    Client->>Task: Call add.delay(10, 20)\n    Task->>Broker: Send task message (task_id: 't1')\n    Task-->>Client: Return AsyncResult (id='t1')\n\n    Worker->>Broker: Fetch message (task_id: 't1')\n    Worker->>Worker: Execute add(10, 20) -> returns 30\n    Worker->>ResultBackend: Store result (key='t1', value={'status': 'SUCCESS', 'result': 30, ...})\n    ResultBackend-->>Worker: Ack (Result stored)\n    Worker->>Broker: Ack message complete\n\n    Client->>AsyncResult: Call result_add.get(timeout=10)\n    loop Check Backend Until Ready or Timeout\n        AsyncResult->>ResultBackend: Get result for key='t1'\n        ResultBackend-->>AsyncResult: Return {'status': 'SUCCESS', 'result': 30, ...}\n    end\n    AsyncResult-->>Client: Return 30\n```\n\n----------------------------------------\n\nTITLE: Defining Step and StartStopStep Classes in Python for Celery Bootsteps\nDESCRIPTION: This snippet defines the base Step class and the StartStopStep subclass used in Celery's bootstep system. It includes methods for initialization, creation, inclusion, and lifecycle management (start, stop, terminate) of worker components.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/10_bootsteps.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simplified concept from celery/bootsteps.py\n\n# Base class for all steps\nclass Step:\n    # List of other Step classes needed before this one runs\n    requires = ()\n\n    def __init__(self, parent, **kwargs):\n        # Called when the blueprint is applied to the parent (e.g., Worker)\n        # Can be used to set initial attributes on the parent.\n        pass\n\n    def create(self, parent):\n        # Create the service/component managed by this step.\n        # Often returns an object to be stored.\n        pass\n\n    def include(self, parent):\n        # Logic to add this step to the parent's step list.\n        # Called after __init__.\n        if self.should_include(parent):\n             self.obj = self.create(parent) # Store created object if needed\n             parent.steps.append(self)\n             return True\n        return False\n\n# A common step type with start/stop/terminate methods\nclass StartStopStep(Step):\n    obj = None # Holds the object created by self.create\n\n    def start(self, parent):\n        # Logic to start the component/service\n        if self.obj and hasattr(self.obj, 'start'):\n            self.obj.start()\n\n    def stop(self, parent):\n        # Logic to stop the component/service gracefully\n        if self.obj and hasattr(self.obj, 'stop'):\n            self.obj.stop()\n\n    def terminate(self, parent):\n        # Logic to force shutdown (if different from stop)\n        if self.obj:\n            term_func = getattr(self.obj, 'terminate', None) or getattr(self.obj, 'stop', None)\n            if term_func:\n                term_func()\n\n    # include() method adds self to parent.steps if created\n```\n\n----------------------------------------\n\nTITLE: Visualizing NumPy Ufunc Execution Flow with Mermaid\nDESCRIPTION: A sequence diagram illustrating the step-by-step process of executing a NumPy ufunc, from the initial Python call to returning the result array. It shows interactions between Python code, the ufunc object, NumPy's C core, and memory operations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_4\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant P as Python Code\n    participant UFunc as np.add (Ufunc Object)\n    participant C_API as NumPy C Core (Ufunc Machinery)\n    participant C_Loop as Specific C Loop (e.g., int32_add)\n    participant Mem as Memory\n\n    P->>UFunc: np.add(arr1, arr2)\n    UFunc->>C_API: Request execution\n    C_API->>C_API: Check dtypes (arr1.dtype, arr2.dtype)\n    C_API->>UFunc: Find appropriate C loop (e.g., int32_add)\n    C_API->>C_API: Check broadcasting rules\n    C_API->>Mem: Allocate memory for result (if no 'out')\n    C_API->>C_Loop: Execute C loop(arr1_data, arr2_data, result_data)\n    C_Loop->>Mem: Read inputs, Compute, Write output\n    C_Loop-->>C_API: Signal completion\n    C_API->>Mem: Wrap result memory in ndarray object\n    C_API-->>P: Return result ndarray\n```\n\n----------------------------------------\n\nTITLE: Hardcoded API Key Example (Anti-Pattern)\nDESCRIPTION: An example of the bad practice of hardcoding API keys directly in the code, which exposes sensitive information and makes maintenance difficult.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/OpenManus/07_configuration__config_.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Bad idea! Don't do this!\napi_key = \"MY_SUPER_SECRET_API_KEY_12345\"\n# ... rest of the code uses api_key ...\n```\n\n----------------------------------------\n\nTITLE: Message Flow Sequence Diagram\nDESCRIPTION: Mermaid sequence diagram showing the interaction flow between different components when sending a Celery task\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Celery/04_broker_connection__amqp_.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client as Your App Code\n    participant Task as add.delay()\n    participant App as Celery App\n    participant AppAMQP as app.amqp (Kombu Interface)\n    participant Broker as RabbitMQ / Redis\n\n    Client->>Task: Call add.delay(2, 2)\n    Task->>App: Get broker config (broker_url)\n    App-->>Task: broker_url\n    Task->>App: Ask to send task 'tasks.add'\n    App->>AppAMQP: Send task message('tasks.add', (2, 2), ...)\n    Note over AppAMQP: Gets connection/producer (maybe from pool)\n    AppAMQP->>Broker: publish(message, routing_info) via Connection\n    Broker-->>AppAMQP: Acknowledge message received\n    AppAMQP-->>App: Message sent successfully\n    App-->>Task: Return AsyncResult\n    Task-->>Client: Return AsyncResult\n```\n\n----------------------------------------\n\nTITLE: Loading Flow Sequence Diagram (Mermaid)\nDESCRIPTION: A sequence diagram showing the flow of the load_component method, detailing interactions between User, ComponentLoader, Python Import System, ListMemory class, ListMemoryConfig, and the new ListMemory instance.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/08_component.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant Loader as ComponentLoader (e.g., ListMemory.load_component)\n    participant Importer as Python Import System\n    participant ListMemClass as ListMemory (Class definition)\n    participant ListMemConfig as ListMemoryConfig (Pydantic Model)\n    participant NewMemory as New ListMemory Instance\n\n    User->>+Loader: load_component(component_model)\n    Loader->>Loader: Reads provider (\"autogen_core.memory.ListMemory\") from model\n    Loader->>+Importer: Imports the class `autogen_core.memory.ListMemory`\n    Importer-->>-Loader: Returns ListMemory class object\n    Loader->>+ListMemClass: Checks if it's a valid Component class\n    Loader->>ListMemClass: Gets expected config schema (ListMemoryConfig)\n    Loader->>+ListMemConfig: Validates `config` dict from model against schema\n    ListMemConfig-->>-Loader: Returns validated ListMemoryConfig object\n    Loader->>+ListMemClass: Calls _from_config(validated_config)\n    ListMemClass->>+NewMemory: Creates new ListMemory instance using config\n    NewMemory-->>-ListMemClass: Returns new instance\n    ListMemClass-->>-Loader: Returns new instance\n    Loader-->>-User: Returns the new ListMemory instance\n```\n\n----------------------------------------\n\nTITLE: Agent Card Discovery Sequence Diagram (Mermaid)\nDESCRIPTION: This Mermaid sequence diagram visualizes the interaction flow for discovering an agent's capabilities using the Agent Card. It shows a Client Application initiating an HTTP GET request to the Agent Server's standard `/.well-known/agent.json` path. The Agent Server responds with a '200 OK' status and the content of the `agent.json` file, which the client then parses.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Google A2A/01_agent_card.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant C as Client App\n    participant A as Agent Server\n    C->>A: GET /.well-known/agent.json\n    Note right of A: Agent looks for its agent.json file\n    A-->>C: 200 OK (Returns content of agent.json)\n    Note left of C: Client parses the JSON data\n```\n\n----------------------------------------\n\nTITLE: Defining Flask Configuration in a Separate File for `from_pyfile` (Python)\nDESCRIPTION: Provides an example of a configuration file (`settings.cfg`) intended to be loaded using Flask's `from_pyfile` method. This file contains Python code that defines configuration variables (e.g., `SECRET_KEY`, `SERVER_NAME`). Because the file is executed, it can contain simple Python logic, such as using the `os` module to determine paths, but only uppercase variables are loaded into `app.config`.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Flask/06_configuration___config__.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# settings.cfg\n# This file will be executed by Python\n\nSECRET_KEY = 'secret-key-loaded-from-pyfile'\nSERVER_NAME = '127.0.0.1:5000' # Example setting\n\n# You can even have simple logic if needed\nimport os\nAPP_ROOT = os.path.dirname(__file__)\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram: AsyncWebCrawler and BaseDispatcher Interaction Flow\nDESCRIPTION: A Mermaid sequence diagram illustrating the interaction flow between the user, AsyncWebCrawler, BaseDispatcher, and the Concurrency Manager when executing multiple crawling tasks with arun_many().\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/Crawl4AI/10_basedispatcher.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant User\n    participant AWC as AsyncWebCrawler\n    participant Dispatcher as BaseDispatcher (e.g., MemoryAdaptive)\n    participant TaskPool as Concurrency Manager\n\n    User->>AWC: arun_many(urls, config, dispatcher?)\n    AWC->>Dispatcher: run_urls(crawler=AWC, urls, config)\n    Dispatcher->>TaskPool: Initialize (e.g., set max concurrency)\n    loop For each URL in urls\n        Dispatcher->>TaskPool: Can I start a new task? (Checks limits)\n        alt Yes\n            TaskPool-->>Dispatcher: OK\n            Note over Dispatcher: Create task: call AWC.arun(url, config) internally\n            Dispatcher->>TaskPool: Add new task\n        else No\n            TaskPool-->>Dispatcher: Wait\n            Note over Dispatcher: Waits for a running task to finish\n        end\n    end\n    Note over Dispatcher: Manages running tasks, collects results\n    Dispatcher-->>AWC: List of CrawlResults\n    AWC-->>User: List of CrawlResults\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram: callTool Flow for 'add' Function (Mermaid)\nDESCRIPTION: This Mermaid sequence diagram illustrates the flow of a callTool request for the 'add' function, from the client through FastMCP, ToolManager, and the wrapped add_numbers function.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/04_fastmcp_tools___tool____toolmanager__.md#2025-04-22_snippet_3\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Client\n    participant FastMCP_Server as FastMCP (calculator_server.py)\n    participant ToolMgr as ToolManager (_tool_manager)\n    participant AddTool as Tool (wraps add_numbers)\n    participant AddFunc as add_numbers()\n\n    Client->>+FastMCP_Server: Send MCP Request: callTool(name=\"add\", args={\"num1\": 5, \"num2\": 7})\n    FastMCP_Server->>+ToolMgr: call_tool(name=\"add\", args={...})\n    ToolMgr->>ToolMgr: Find Tool object for \"add\"\n    ToolMgr->>+AddTool: tool.run(arguments={...})\n    AddTool->>AddTool: Validate args against schema\n    AddTool->>+AddFunc: Call add_numbers(num1=5, num2=7)\n    AddFunc-->>-AddTool: Return 12\n    AddTool-->>-ToolMgr: Return 12\n    ToolMgr-->>-FastMCP_Server: Return 12\n    FastMCP_Server->>-Client: Send MCP Response: result=12\n```\n\n----------------------------------------\n\nTITLE: Implementing AgentId Class in Python for AutoGen Core\nDESCRIPTION: This code defines the AgentId class which provides a unique identity for each agent. It consists of a type (representing the agent's role) and a key (unique identifier), together forming an address that allows messages to be directed to specific agents.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/01_agent.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# From: _agent_id.py\nclass AgentId:\n    def __init__(self, type: str, key: str) -> None:\n        # ... (validation checks omitted for brevity)\n        self._type = type\n        self._key = key\n\n    @property\n    def type(self) -> str:\n        return self._type\n\n    @property\n    def key(self) -> str:\n        return self._key\n\n    def __str__(self) -> str:\n        # Creates an id like \"researcher/amy-the-writer\"\n        return f\"{self._type}/{self._key}\"\n```\n\n----------------------------------------\n\nTITLE: Defining Ufunc Properties in Python Generator Script\nDESCRIPTION: A snippet from the NumPy ufunc generation script (generate_umath.py) showing how the 'add' ufunc is defined. It includes the ufunc's properties such as input/output count, identity element, type resolution function, and loops for different data types.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/03_ufunc__universal_function_.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Snippet from generate_umath.py's defdict for 'add'\n'add':\n    Ufunc(2, 1, Zero, # nin=2, nout=1, identity=0\n          docstrings.get('numpy._core.umath.add'),\n          'PyUFunc_AdditionTypeResolver', # Function for type resolution\n          TD('?', cfunc_alias='logical_or', ...), # Loop for bools\n          TD(no_bool_times_obj, dispatch=[...]), # Loops for numeric types\n          # ... loops for datetime, object ...\n          indexed=intfltcmplx # Types supporting indexed access\n          ),\n```\n\n----------------------------------------\n\nTITLE: Registering Tools with ToolManager in FastMCP (Python)\nDESCRIPTION: This snippet shows the simplified implementation of the ToolManager's add_tool method, which is responsible for registering new tools in FastMCP. It creates a Tool object from a function and stores it in an internal dictionary.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/04_fastmcp_tools___tool____toolmanager__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Inside server/fastmcp/tools/tool_manager.py (Simplified ToolManager.add_tool)\nfrom .base import Tool # Tool class definition is in base.py\n\nclass ToolManager:\n    # ... (init, get_tool, list_tools) ...\n\n    def add_tool(self, fn, name=None, description=None) -> Tool:\n        # 1. Create a Tool object from the function\n        tool = Tool.from_function(fn, name=name, description=description)\n        # 2. Check for duplicates (optional warning)\n        if tool.name in self._tools:\n            # ... handle duplicate ...\n            pass\n        # 3. Store the Tool object in the dictionary\n        self._tools[tool.name] = tool\n        logger.debug(f\"Registered tool: {tool.name}\")\n        return tool\n```\n\n----------------------------------------\n\nTITLE: Sequence Diagram of NumPy Array Creation\nDESCRIPTION: This Mermaid sequence diagram illustrates the process of creating a NumPy array, showing the interaction between Python code, NumPy's Python functions, C-level functions, and memory allocation. It demonstrates how NumPy bridges Python and optimized C implementations.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_11\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant P as Python Code (Your script)\n    participant NPF as NumPy Python Function (e.g., np.array)\n    participant CF as C Function (in _multiarray_umath)\n    participant M as Memory\n\n    P->>NPF: np.array([1, 2, 3])\n    NPF->>CF: Call C implementation with list data\n    CF->>M: Allocate contiguous memory block\n    CF->>M: Copy data [1, 2, 3] into block\n    CF-->>NPF: Return C-level ndarray structure pointing to memory\n    NPF-->>P: Return Python ndarray object wrapping the C structure\n```\n\n----------------------------------------\n\nTITLE: Importing MemorySaver Checkpointer in Python\nDESCRIPTION: This snippet demonstrates how to import the MemorySaver class from langgraph.checkpoint.memory. MemorySaver is the simplest in-memory checkpointer implementation available in LangGraph, enabling temporary state persistence during graph execution. There are no additional dependencies beyond langgraph itself for this step, and this import statement is a prerequisite for instantiating the MemorySaver object.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/06_checkpointer___basecheckpointsaver__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Import the simplest checkpointer\\nfrom langgraph.checkpoint.memory import MemorySaver\n```\n\n----------------------------------------\n\nTITLE: Creating Basic FastMCP Resource Server - Simplified Version\nDESCRIPTION: Simplified implementation of the FastMCP server with a single welcome message resource function. Demonstrates basic resource registration and type hints.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/03_fastmcp_resources___resource____resourcemanager__.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# 1. Import FastMCP\nfrom mcp.server.fastmcp import FastMCP\n\n# 2. Create the server instance\nserver = FastMCP(name=\"LibraryServer\")\n\n# 3. Use the @server.resource() decorator directly on the function\n#    that provides the data.\n@server.resource(uri=\"data://greeting\", description=\"A friendly greeting.\")\ndef welcome_message() -> str:\n  \"\"\"\n  This function is registered as the resource 'data://greeting'.\n  It will be called when a client reads this resource URI.\n  '-> str' indicates it returns text. FastMCP sets MIME type to text/plain.\n  \"\"\"\n  print(\"Resource 'data://greeting' was read!\") # Server-side log\n  return \"Welcome to the Library Server! Enjoy your stay.\"\n\n# 4. Standard run block\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    server.run() # Start listening\n    print(f\"{server.name} finished.\")\n```\n\n----------------------------------------\n\nTITLE: Sample Output from LangGraph StateGraph Execution - Text\nDESCRIPTION: Shows expected console output when running the full LangGraph StateGraph workflow. Print statements from the nodes and the final state dictionary display the data as it flows and is transformed by the graph. Useful for confirming correct functional behavior and for debugging purposes.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/LangGraph/01_graph___stategraph.md#2025-04-22_snippet_6\n\nLANGUAGE: text\nCODE:\n```\n--- Running Adder Node ---\nInput value: 5, Output value: 6\n--- Running Multiplier Node ---\nInput value: 6, Output value: 12\n\n--- Final State ---\n{'value': 12}\n```\n\n----------------------------------------\n\nTITLE: Flowchart for 2D Array\nDESCRIPTION: This Mermaid diagram visualizes a 2-dimensional array structure, showing both row-wise connections (horizontal arrows) and column-wise relationships (vertical dotted lines). It illustrates the grid or matrix-like structure of a 2D array.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/NumPy Core/01_ndarray__n_dimensional_array_.md#2025-04-22_snippet_9\n\nLANGUAGE: mermaid\nCODE:\n```\nflowchart LR\n    subgraph Row 1\n    R1C1[ R1C1 ] --> R1C2[ R1C2 ] --> R1C3[ R1C3 ]\n    end\n\n    subgraph Row 2\n    R2C1[ R2C1 ] --> R2C2[ R2C2 ] --> R2C3[ R2C3 ]\n    end\n\n    R1C1 -.-> R2C1\n    R1C2 -.-> R2C2\n    R1C3 -.-> R2C3\n```\n\n----------------------------------------\n\nTITLE: Implementing Unbounded Chat Completion Context in Python\nDESCRIPTION: The simplest implementation of ChatCompletionContext that returns all stored messages without any filtering or truncation. This is suitable when the total context size is guaranteed to be within the model's limits.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/AutoGen Core/06_chatcompletioncontext.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# From: model_context/_unbounded_chat_completion_context.py (Simplified)\nfrom typing import List\nfrom ._chat_completion_context import ChatCompletionContext\nfrom ..models import LLMMessage\n\nclass UnboundedChatCompletionContext(ChatCompletionContext):\n    async def get_messages(self) -> List[LLMMessage]:\n        \"\"\"Returns all messages.\"\"\"\n        return self._messages # Just return the whole internal list\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic FastMCP Server\nDESCRIPTION: Demonstrates the minimum code required to create a FastMCP server. Shows server instantiation, naming, and basic startup logic.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/MCP Python SDK/02_fastmcp_server___fastmcp__.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# 1. Import the FastMCP class\nfrom mcp.server.fastmcp import FastMCP\n\n# 2. Create an instance of the FastMCP server\n#    Give it a name clients might see.\n#    Optionally, provide general instructions.\nserver = FastMCP(\n    name=\"MySimpleServer\",\n    instructions=\"This is a very simple example server.\"\n)\n\n# 3. Add the standard Python block to run the server\n#    when the script is executed directly.\nif __name__ == \"__main__\":\n    print(f\"Starting {server.name}...\")\n    # This tells FastMCP to start listening for connections\n    server.run()\n    print(f\"{server.name} finished.\") # Usually only seen after stopping (Ctrl+C)\n```\n\n----------------------------------------\n\nTITLE: Simplified dspy.Example Source Code Snippet in Python\nDESCRIPTION: Introduces a section intended to show a simplified view of the source code for `dspy.Example` from `dspy/primitives/example.py`, explaining its internal mechanisms. The actual code implementation is not provided in the source text, only the code block marker is present.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/03_example.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n\n```\n\n----------------------------------------\n\nTITLE: Running the Main Script for GitHub Repository Analysis\nDESCRIPTION: Command to generate a tutorial from a GitHub repository, with options to include specific file types and exclude certain directories, with a maximum file size limit.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython main.py --repo https://github.com/username/repo --include \"*.py\" \"*.js\" --exclude \"tests/*\" --max-size 50000\n```\n\n----------------------------------------\n\nTITLE: Evaluator Output Example\nDESCRIPTION: Example showing the structure of outputs returned by the evaluator, demonstrating that outputs_list[3] contains a tuple of example, prediction and boolean flag.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/docs/DSPy/07_evaluate.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"Number of outputs returned: {len(outputs_list)}\")\n```\n\n----------------------------------------\n\nTITLE: Testing LLM Setup\nDESCRIPTION: Command to verify the LLM configuration is correctly set up by running the call_llm.py utility script.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython utils/call_llm.py\n```\n\n----------------------------------------\n\nTITLE: Generating a Tutorial in Chinese\nDESCRIPTION: Command to generate a tutorial in Chinese language from a GitHub repository using the language parameter.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython main.py --repo https://github.com/username/repo --language \"Chinese\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Command to install the required packages for the project using the requirements.txt file.\nSOURCE: https://github.com/the-pocket/tutorial-codebase-knowledge/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```"
  }
]