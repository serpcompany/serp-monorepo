[
  {
    "owner": "microsoftlearning",
    "repo": "ai-102-aiengineer",
    "content": "TITLE: Installing Python Packages for AI Development\nDESCRIPTION: Command line instructions for installing required Python packages using pip. Includes essential libraries for web development (Flask), HTTP requests, environment management, code linting, data visualization, and image processing.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/00-setup.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flask requests python-dotenv pylint matplotlib pillow\npip install --upgrade numpy\n```\n\n----------------------------------------\n\nTITLE: Creating a Service Principal with Azure CLI\nDESCRIPTION: Command to create a service principal with owner role to a specific resource group. This generates authentication credentials that an application can use to access Azure resources.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp create-for-rbac -n \"api://<spName>\" --role owner --scopes subscriptions/<subscriptionId>/resourceGroups/<resourceGroup>\n```\n\n----------------------------------------\n\nTITLE: Detecting and Locating Objects in Images with Azure AI Vision in Python\nDESCRIPTION: This Python code snippet uses Azure AI Vision for object detection in images. It identifies objects, draws bounding boxes, and saves the annotated image using matplotlib and PIL libraries.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_17\n\nLANGUAGE: Python\nCODE:\n```\n# Get objects in the image\nif len(analysis.objects) > 0:\n    print(\"Objects in image:\")\n\n    # Prepare image for drawing\n    fig = plt.figure(figsize=(8, 8))\n    plt.axis('off')\n    image = Image.open(image_file)\n    draw = ImageDraw.Draw(image)\n    color = 'cyan'\n    for detected_object in analysis.objects:\n        # Print object name\n        print(\" -{} (confidence: {:.2f}%)\".format(detected_object.object_property, detected_object.confidence * 100))\n        \n        # Draw object bounding box\n        r = detected_object.rectangle\n        bounding_box = ((r.x, r.y), (r.x + r.w, r.y + r.h))\n        draw.rectangle(bounding_box, outline=color, width=3)\n        plt.annotate(detected_object.object_property,(r.x, r.y), backgroundcolor=color)\n    # Save annotated image\n    plt.imshow(image)\n    outputfile = 'objects.jpg'\n    fig.savefig(outputfile)\n    print('  Results saved in', outputfile)\n```\n\n----------------------------------------\n\nTITLE: Synthesizing Translated Text to Speech in Python\nDESCRIPTION: Code to convert the translated text to speech using Azure AI Speech Synthesis in Python. The code configures appropriate neural voices for different languages and plays the synthesized speech through the default speaker.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Synthesize translation\nvoices = {\n        \"fr\": \"fr-FR-HenriNeural\",\n        \"es\": \"es-ES-ElviraNeural\",\n        \"hi\": \"hi-IN-MadhurNeural\"\n}\nspeech_config.speech_synthesis_voice_name = voices.get(targetLanguage)\nspeech_synthesizer = speech_sdk.SpeechSynthesizer(speech_config)\nspeak = speech_synthesizer.speak_text_async(translation).get()\nif speak.reason != speech_sdk.ResultReason.SynthesizingAudioCompleted:\n    print(speak.reason)\n```\n\n----------------------------------------\n\nTITLE: Detecting and Analyzing Faces using Azure Face API in Python\nDESCRIPTION: This code snippet uses the Azure Face API to detect faces in an image, extract face attributes such as blur, occlusion, and glasses, and visualize the results. It reads an image file, detects faces, draws bounding boxes, and saves the annotated image.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# Get faces\nwith open(image_file, mode=\"rb\") as image_data:\n    detected_faces = face_client.face.detect_with_stream(image=image_data,\n                                                            return_face_attributes=features,                     return_face_id=False)\n\n    if len(detected_faces) > 0:\n        print(len(detected_faces), 'faces detected.')\n\n        # Prepare image for drawing\n        fig = plt.figure(figsize=(8, 6))\n        plt.axis('off')\n        image = Image.open(image_file)\n        draw = ImageDraw.Draw(image)\n        color = 'lightgreen'\n        face_count = 0\n\n        # Draw and annotate each face\n        for face in detected_faces:\n\n            # Get face properties\n            face_count += 1\n            print('\\nFace number {}'.format(face_count))\n\n            detected_attributes = face.face_attributes.as_dict()\n            if 'blur' in detected_attributes:\n                print(' - Blur:')\n                for blur_name in detected_attributes['blur']:\n                    print('   - {}: {}'.format(blur_name, detected_attributes['blur'][blur_name]))\n                    \n            if 'occlusion' in detected_attributes:\n                print(' - Occlusion:')\n                for occlusion_name in detected_attributes['occlusion']:\n                    print('   - {}: {}'.format(occlusion_name, detected_attributes['occlusion'][occlusion_name]))\n\n            if 'glasses' in detected_attributes:\n                print(' - Glasses:{}'.format(detected_attributes['glasses']))\n\n            # Draw and annotate face\n            r = face.face_rectangle\n            bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n            draw = ImageDraw.Draw(image)\n            draw.rectangle(bounding_box, outline=color, width=5)\n            annotation = 'Face ID: {}'.format(face.face_id)\n            plt.annotate(annotation,(r.left, r.top), backgroundcolor=color)\n\n        # Save annotated image\n        plt.imshow(image)\n        outputfile = 'detected_faces.jpg'\n        fig.savefig(outputfile)\n\n        print('\\nResults saved in', outputfile)\n```\n\n----------------------------------------\n\nTITLE: Exporting Language Studio Project as JSON\nDESCRIPTION: The JSON export file contains the complete project definition including the model schema that can be used for portability and reproducibility. This file can be imported into other Azure AI Language instances and retrained as needed.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_9\n\nLANGUAGE: json\nCODE:\n```\nClock.json\n```\n\n----------------------------------------\n\nTITLE: Implementing Sentiment Analysis\nDESCRIPTION: Code to analyze the sentiment of text documents using the Text Analytics client\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\nDocumentSentiment sentimentAnalysis = CogClient.AnalyzeSentiment(text);\nConsole.WriteLine($\"\\nSentiment: {sentimentAnalysis.Sentiment}\");\n```\n\nLANGUAGE: Python\nCODE:\n```\nsentimentAnalysis = cog_client.analyze_sentiment(documents=[text])[0]\nprint(\"\\nSentiment: {}\".format(sentimentAnalysis.sentiment))\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image and Detecting Faces in C#\nDESCRIPTION: Performs image analysis to detect faces, draws bounding boxes around detected faces, and saves the annotated image in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_8\n\nLANGUAGE: C#\nCODE:\n```\n// Get image analysis\nusing (var imageData = File.OpenRead(imageFile))\n{    \n    var analysis = await cvClient.AnalyzeImageInStreamAsync(imageData, features);\n\n    // Get faces\n    if (analysis.Faces.Count > 0)\n    {\n        Console.WriteLine($\"{analysis.Faces.Count} faces detected.\");\n\n        // Prepare image for drawing\n        Image image = Image.FromFile(imageFile);\n        Graphics graphics = Graphics.FromImage(image);\n        Pen pen = new Pen(Color.LightGreen, 3);\n        Font font = new Font(\"Arial\", 3);\n        SolidBrush brush = new SolidBrush(Color.LightGreen);\n\n        // Draw and annotate each face\n        foreach (var face in analysis.Faces)\n        {\n            var r = face.FaceRectangle;\n            Rectangle rect = new Rectangle(r.Left, r.Top, r.Width, r.Height);\n            graphics.DrawRectangle(pen, rect);\n            string annotation = $\"Person at approximately {r.Left}, {r.Top}\";\n            graphics.DrawString(annotation,font,brush,r.Left, r.Top);\n        }\n\n        // Save annotated image\n        String output_file = \"detected_faces.jpg\";\n        image.Save(output_file);\n        Console.WriteLine(\" Results saved in \" + output_file);   \n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision SDK in Python\nDESCRIPTION: Command to install the Azure Cognitive Services Custom Vision package for Python using pip. This package includes both training and prediction functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-cognitiveservices-vision-customvision==3.1.0\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image and Detecting Faces in Python\nDESCRIPTION: Performs image analysis to detect faces, draws bounding boxes around detected faces, and saves the annotated image in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# The Python code snippet for analyzing images and detecting faces was not provided in the input text.\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image Categories and Landmarks with Azure AI Vision in Python\nDESCRIPTION: This Python code snippet uses the Azure AI Vision service to analyze image categories and detect landmarks. It processes categories, prints them with confidence scores, and identifies landmarks if present in the image.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_13\n\nLANGUAGE: Python\nCODE:\n```\n# Get image categories\nif (len(analysis.categories) > 0):\n    print(\"Categories:\")\n    landmarks = []\n    for category in analysis.categories:\n        # Print the category\n        print(\" -'{}' (confidence: {:.2f}%)\".format(category.name, category.score * 100))\n        if category.detail:\n            # Get landmarks in this category\n            if category.detail.landmarks:\n                for landmark in category.detail.landmarks:\n                    if landmark not in landmarks:\n                        landmarks.append(landmark)\n\n    # If there were landmarks, list them\n    if len(landmarks) > 0:\n        print(\"Landmarks:\")\n        for landmark in landmarks:\n            print(\" -'{}' (confidence: {:.2f}%)\".format(landmark.name, landmark.confidence * 100))\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image Categories and Landmarks with Azure AI Vision in C#\nDESCRIPTION: This code snippet demonstrates how to use the Azure AI Vision service to analyze image categories and detect landmarks in C#. It iterates through categories, prints them with confidence scores, and identifies landmarks if present.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_12\n\nLANGUAGE: C#\nCODE:\n```\n// Get image categories\nList<LandmarksModel> landmarks = new List<LandmarksModel> {};\nConsole.WriteLine(\"Categories:\");\nforeach (var category in analysis.Categories)\n{\n    // Print the category\n    Console.WriteLine($\" -{category.Name} (confidence: {category.Score.ToString(\"P\")}\");\n\n    // Get landmarks in this category\n    if (category.Detail?.Landmarks != null)\n    {\n        foreach (LandmarksModel landmark in category.Detail.Landmarks)\n        {\n            if (!landmarks.Any(item => item.Name == landmark.Name))\n            {\n                landmarks.Add(landmark);\n            }\n        }\n    }\n}\n\n// If there were landmarks, list them\nif (landmarks.Count > 0)\n{\n    Console.WriteLine(\"Landmarks:\");\n    foreach(LandmarksModel landmark in landmarks)\n    {\n        Console.WriteLine($\" -{landmark.Name} (confidence: {landmark.Confidence.ToString(\"P\")}\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech Translation with Microphone Input in Python\nDESCRIPTION: Code for creating a TranslationRecognizer that captures audio from the default microphone, recognizes speech, and translates it to the target language in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Translate speech\naudio_config = speech_sdk.AudioConfig(use_default_microphone=True)\ntranslator = speech_sdk.translation.TranslationRecognizer(translation_config, audio_config = audio_config)\nprint(\"Speak now...\")\nresult = translator.recognize_once_async().get()\nprint('Translating \"{}\"'.format(result.text))\ntranslation = result.translations[targetLanguage]\nprint(translation)\n```\n\n----------------------------------------\n\nTITLE: Generating Thumbnail Images with Azure AI Vision in C#\nDESCRIPTION: This C# code snippet demonstrates how to generate a thumbnail image using Azure AI Vision. It creates a 100x100 pixel thumbnail from the input image and saves it as a PNG file.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_20\n\nLANGUAGE: C#\nCODE:\n```\n// Generate a thumbnail\nusing (var imageData = File.OpenRead(imageFile))\n{\n    // Get thumbnail data\n    var thumbnailStream = await cvClient.GenerateThumbnailInStreamAsync(100, 100,imageData, true);\n\n    // Save thumbnail image\n    string thumbnailFileName = \"thumbnail.png\";\n    using (Stream thumbnailFile = File.Create(thumbnailFileName))\n    {\n        thumbnailStream.CopyTo(thumbnailFile);\n    }\n\n    Console.WriteLine($\"Thumbnail saved in {thumbnailFileName}\");\n}\n```\n\n----------------------------------------\n\nTITLE: Linked Entity Recognition with Azure AI Language Service\nDESCRIPTION: Code for identifying entities with known links to external data sources using Azure AI Language client. The implementation detects entities and outputs their names along with corresponding URLs.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_7\n\nLANGUAGE: csharp\nCODE:\n```\n// Get linked entities\nLinkedEntityCollection linkedEntities = CogClient.RecognizeLinkedEntities(text);\nif (linkedEntities.Count > 0)\n{\n    Console.WriteLine(\"\\nLinks:\");\n    foreach(LinkedEntity linkedEntity in linkedEntities)\n    {\n        Console.WriteLine($\"\\t{linkedEntity.Name} ({linkedEntity.Url})\");\n    }\n}\n```\n\nLANGUAGE: python\nCODE:\n```\n# Get linked entities\nentities = cog_client.recognize_linked_entities(documents=[text])[0].entities\nif len(entities) > 0:\n    print(\"\\nLinks\")\n    for linked_entity in entities:\n        print('\\t{} ({})'.format(linked_entity.name, linked_entity.url))\n```\n\n----------------------------------------\n\nTITLE: Implementing a Word Count Azure Function in Node.js for Azure AI Search Custom Skill\nDESCRIPTION: This Node.js Azure Function implements a custom skill for Azure AI Search that counts the frequency of words in text documents. It filters out common stop words, counts the occurrence of each remaining word, and returns the top 9 most frequent words. The function follows the required input/output schema for Azure AI Search skills.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nmodule.exports = async function (context, req) {\n    context.log('JavaScript HTTP trigger function processed a request.');\n\n    if (req.body && req.body.values) {\n\n        vals = req.body.values;\n\n        // Array of stop words to be ignored\n        var stopwords = ['', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n        \"youre\", \"youve\", \"youll\", \"youd\", 'your', 'yours', 'yourself', \n        'yourselves', 'he', 'him', 'his', 'himself', 'she', \"shes\", 'her', \n        'hers', 'herself', 'it', \"its\", 'itself', 'they', 'them', \n        'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', \n        'this', 'that', \"thatll\", 'these', 'those', 'am', 'is', 'are', 'was',\n        'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', \n        'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', \n        'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', \n        'about', 'against', 'between', 'into', 'through', 'during', 'before', \n        'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', \n        'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', \n        'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', \n        'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', \n        'only', 'own', 'same', 'so', 'than', 'too', 'very', 'can', 'will',\n        'just', \"dont\", 'should', \"shouldve\", 'now', \"arent\", \"couldnt\", \n        \"didnt\", \"doesnt\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\",\n        \"neednt\", \"shant\", \"shouldnt\", \"wasnt\", \"werent\", \"wont\", \"wouldnt\"];\n\n        res = {\"values\":[]};\n\n        for (rec in vals)\n        {\n            // Get the record ID and text for this input\n            resVal = {recordId:vals[rec].recordId, data:{}};\n            txt = vals[rec].data.text;\n\n            // remove punctuation and numerals\n            txt = txt.replace(/[^ A-Za-z_]/g,\"\").toLowerCase();\n\n            // Get an array of words\n            words = txt.split(\" \")\n\n            // count instances of non-stopwords\n            wordCounts = {}\n            for(var i = 0; i < words.length; ++i) {\n                word = words[i];\n                if (stopwords.includes(word) == false )\n                {\n                    if (wordCounts[word])\n                    {\n                        wordCounts[word] ++;\n                    }\n                    else\n                    {\n                        wordCounts[word] = 1;\n                    }\n                }\n            }\n\n            // Convert wordcounts to an array\n            var topWords = [];\n            for (var word in wordCounts) {\n                topWords.push([word, wordCounts[word]]);\n            }\n\n            // Sort in descending order of count\n            topWords.sort(function(a, b) {\n                return b[1] - a[1];\n            });\n\n            // Get the first ten words from the first array dimension\n            resVal.data.text = topWords.slice(0,9)\n              .map(function(value,index) { return value[0]; });\n\n            res.values[rec] = resVal;\n        };\n\n        context.res = {\n            body: JSON.stringify(res),\n            headers: {\n            'Content-Type': 'application/json'\n        }\n\n        };\n    }\n    else {\n        context.res = {\n            status: 400,\n            body: {\"errors\":[{\"message\": \"Invalid input\"}]},\n            headers: {\n            'Content-Type': 'application/json'\n        }\n\n        };\n    }\n};\n```\n\n----------------------------------------\n\nTITLE: Detecting and Locating Objects in Images with Azure AI Vision in C#\nDESCRIPTION: This C# code snippet demonstrates object detection using Azure AI Vision. It identifies objects in an image, draws bounding boxes around them, and saves the annotated image. It uses System.Drawing for image manipulation.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_16\n\nLANGUAGE: C#\nCODE:\n```\n// Get objects in the image\nif (analysis.Objects.Count > 0)\n{\n    Console.WriteLine(\"Objects in image:\");\n\n    // Prepare image for drawing\n    Image image = Image.FromFile(imageFile);\n    Graphics graphics = Graphics.FromImage(image);\n    Pen pen = new Pen(Color.Cyan, 3);\n    Font font = new Font(\"Arial\", 16);\n    SolidBrush brush = new SolidBrush(Color.Black);\n\n    foreach (var detectedObject in analysis.Objects)\n    {\n        // Print object name\n        Console.WriteLine($\" -{detectedObject.ObjectProperty} (confidence: {detectedObject.Confidence.ToString(\"P\")}\");\n\n        // Draw object bounding box\n        var r = detectedObject.Rectangle;\n        Rectangle rect = new Rectangle(r.X, r.Y, r.W, r.H);\n        graphics.DrawRectangle(pen, rect);\n        graphics.DrawString(detectedObject.ObjectProperty,font,brush,r.X, r.Y);\n\n    }\n    // Save annotated image\n    String output_file = \"objects.jpg\";\n    image.Save(output_file);\n    Console.WriteLine(\"  Results saved in \" + output_file);   \n}\n```\n\n----------------------------------------\n\nTITLE: Synthesizing Translated Text to Speech in C#\nDESCRIPTION: Code to convert the translated text to speech using Azure AI Speech Synthesis in C#. The code configures appropriate neural voices for different languages and plays the synthesized speech through the default speaker.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_13\n\nLANGUAGE: csharp\nCODE:\n```\n// Synthesize translation\nvar voices = new Dictionary<string, string>\n                {\n                    [\"fr\"] = \"fr-FR-HenriNeural\",\n                    [\"es\"] = \"es-ES-ElviraNeural\",\n                    [\"hi\"] = \"hi-IN-MadhurNeural\"\n                };\nspeechConfig.SpeechSynthesisVoiceName = voices[targetLanguage];\nusing SpeechSynthesizer speechSynthesizer = new SpeechSynthesizer(speechConfig);\nSpeechSynthesisResult speak = await speechSynthesizer.SpeakTextAsync(translation);\nif (speak.Reason != ResultReason.SynthesizingAudioCompleted)\n{\n    Console.WriteLine(speak.Reason);\n}\n```\n\n----------------------------------------\n\nTITLE: Entity Recognition with Azure AI Language Service\nDESCRIPTION: Implementation for detecting and categorizing entities in text documents using Azure AI Language client. The code identifies various categories of entities and outputs them with their respective categories.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_6\n\nLANGUAGE: csharp\nCODE:\n```\n// Get entities\nCategorizedEntityCollection entities = CogClient.RecognizeEntities(text);\nif (entities.Count > 0)\n{\n    Console.WriteLine(\"\\nEntities:\");\n    foreach(CategorizedEntity entity in entities)\n    {\n        Console.WriteLine($\"\\t{entity.Text} ({entity.Category})\");\n    }\n}\n```\n\nLANGUAGE: python\nCODE:\n```\n# Get entities\nentities = cog_client.recognize_entities(documents=[text])[0].entities\nif len(entities) > 0:\n    print(\"\\nEntities\")\n    for entity in entities:\n        print('\\t{} ({})'.format(entity.text, entity.category))\n```\n\n----------------------------------------\n\nTITLE: Using Read API to Extract Text from Image in Python\nDESCRIPTION: This code uses the Read API to asynchronously extract text from an image file in Python. It submits a read operation, checks for completion, and processes the results.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Use Read API to read text in image\nwith open(image_file, mode=\"rb\") as image_data:\n    read_op = cv_client.read_in_stream(image_data, raw=True)\n\n    # Get the async operation ID so we can check for the results\n    operation_location = read_op.headers[\"Operation-Location\"]\n    operation_id = operation_location.split(\"/\")[-1]\n\n    # Wait for the asynchronous operation to complete\n    while True:\n        read_results = cv_client.get_read_result(operation_id)\n        if read_results.status not in [OperationStatusCodes.running, OperationStatusCodes.not_started]:\n            break\n        time.sleep(1)\n\n    # If the operation was successfully, process the text line by line\n    if read_results.status == OperationStatusCodes.succeeded:\n        for page in read_results.analyze_result.read_results:\n            for line in page.lines:\n                print(line.text)\n                # Uncomment the following line if you'd like to see the bounding box \n                #print(line.bounding_box)\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in Python\nDESCRIPTION: Creates and authenticates an Azure AI Vision client object using the endpoint and key in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Authenticate Azure AI Vision client\ncredential = CognitiveServicesCredentials(cog_key) \ncv_client = ComputerVisionClient(cog_endpoint, credential)\n```\n\n----------------------------------------\n\nTITLE: Detecting Brands in Images with Azure AI Vision in Python\nDESCRIPTION: This Python code snippet uses the Azure AI Vision service to detect and identify brands in images. It processes the detected brands and prints their names along with confidence scores.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\n# Get brands in the image\nif (len(analysis.brands) > 0):\n    print(\"Brands: \")\n    for brand in analysis.brands:\n        print(\" -'{}' (confidence: {:.2f}%)\".format(brand.name, brand.confidence * 100))\n```\n\n----------------------------------------\n\nTITLE: Getting Moderation Ratings for Images with Azure AI Vision in C#\nDESCRIPTION: This C# code snippet demonstrates how to obtain content moderation ratings for images using Azure AI Vision. It checks for adult, racy, and gory content in the image.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_18\n\nLANGUAGE: C#\nCODE:\n```\n// Get moderation ratings\nstring ratings = $\"Ratings:\\n -Adult: {analysis.Adult.IsAdultContent}\\n -Racy: {analysis.Adult.IsRacyContent}\\n -Gore: {analysis.Adult.IsGoryContent}\";\nConsole.WriteLine(ratings);\n```\n\n----------------------------------------\n\nTITLE: Implementing Text Translation in C#\nDESCRIPTION: C# code implementation for translating text from its source language to English using Azure AI Translator's REST API. The code specifies source and target languages in the request path.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_9\n\nLANGUAGE: C#\nCODE:\n```\n// Use the Azure AI Translator translate function\nobject[] body = new object[] { new { Text = text } };\nvar requestBody = JsonConvert.SerializeObject(body);\nusing (var client = new HttpClient())\n{\n    using (var request = new HttpRequestMessage())\n    {\n        // Build the request\n        string path = \"/translate?api-version=3.0&from=\" + sourceLanguage + \"&to=en\" ;\n        request.Method = HttpMethod.Post;\n        request.RequestUri = new Uri(translatorEndpoint + path);\n        request.Content = new StringContent(requestBody, Encoding.UTF8, \"application/json\");\n        request.Headers.Add(\"Ocp-Apim-Subscription-Key\", cogSvcKey);\n        request.Headers.Add(\"Ocp-Apim-Subscription-Region\", cogSvcRegion);\n\n        // Send the request and get response\n        HttpResponseMessage response = await client.SendAsync(request).ConfigureAwait(false);\n        // Read response as a string\n        string responseContent = await response.Content.ReadAsStringAsync();\n\n        // Parse JSON array and get translation\n        JArray jsonResponse = JArray.Parse(responseContent);\n        translation = (string)jsonResponse[0][\"translations\"][0][\"text\"];  \n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Weather Card Response in Bot Framework Composer\nDESCRIPTION: This code creates a ThumbnailCard to display weather information, including the city name, weather condition, temperature, and an icon representing the weather condition.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\n[ThumbnailCard\n    title = Weather for ${dialog.city}\n    text = ${dialog.weather} (${dialog.temp}&deg;)\n    image = http://openweathermap.org/img/w/${dialog.icon}.png\n]\n```\n\n----------------------------------------\n\nTITLE: Detecting Brands in Images with Azure AI Vision in C#\nDESCRIPTION: This C# code snippet demonstrates how to use the Azure AI Vision service to detect and identify brands in images. It iterates through detected brands and prints their names along with confidence scores.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_14\n\nLANGUAGE: C#\nCODE:\n```\n// Get brands in the image\nif (analysis.Brands.Count > 0)\n{\n    Console.WriteLine(\"Brands:\");\n    foreach (var brand in analysis.Brands)\n    {\n        Console.WriteLine($\" -{brand.Name} (confidence: {brand.Confidence.ToString(\"P\")}\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Language Detection in Python\nDESCRIPTION: Python code implementation for detecting the language of text using Azure AI Translator's REST API. The code sends a POST request with the text and receives language identification in the response.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n# Use the Azure AI Translator detect function\npath = '/detect'\nurl = translator_endpoint + path\n\n# Build the request\nparams = {\n    'api-version': '3.0'\n}\n\nheaders = {\n'Ocp-Apim-Subscription-Key': cog_key,\n'Ocp-Apim-Subscription-Region': cog_region,\n'Content-type': 'application/json'\n}\n\nbody = [{\n    'text': text\n}]\n\n# Send the request and get response\nrequest = requests.post(url, params=params, headers=headers, json=body)\nresponse = request.json()\n\n# Parse JSON array and get language\nlanguage = response[0][\"language\"]\n```\n\n----------------------------------------\n\nTITLE: Translating Text with Azure AI Translator API in Python\nDESCRIPTION: This snippet demonstrates how to use the Azure AI Translator API to translate text. It sets up the API endpoint, builds the request with necessary parameters and headers, sends the request, and parses the response to extract the translated text.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Use the Azure AI Translator translate function\npath = '/translate'\nurl = translator_endpoint + path\n\n# Build the request\nparams = {\n    'api-version': '3.0',\n    'from': source_language,\n    'to': ['en']\n}\n\nheaders = {\n    'Ocp-Apim-Subscription-Key': cog_key,\n    'Ocp-Apim-Subscription-Region': cog_region,\n    'Content-type': 'application/json'\n}\n\nbody = [{\n    'text': text\n}]\n\n# Send the request and get response\nrequest = requests.post(url, params=params, headers=headers, json=body)\nresponse = request.json()\n\n# Parse JSON array and get translation\ntranslation = response[0][\"translations\"][0][\"text\"]\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision Namespaces in C#\nDESCRIPTION: This code imports the necessary namespaces for using the Azure AI Vision SDK in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\n// import namespaces\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision;\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech Translation with Microphone Input in C#\nDESCRIPTION: Code for creating a TranslationRecognizer that captures audio from the default microphone, recognizes speech, and translates it to the target language in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\n// Translate speech\nusing AudioConfig audioConfig = AudioConfig.FromDefaultMicrophoneInput();\nusing TranslationRecognizer translator = new TranslationRecognizer(translationConfig, audioConfig);\nConsole.WriteLine(\"Speak now...\");\nTranslationRecognitionResult result = await translator.RecognizeOnceAsync();\nConsole.WriteLine($\"Translating '{result.Text}'\");\ntranslation = result.Translations[targetLanguage];\nConsole.OutputEncoding = Encoding.UTF8;\nConsole.WriteLine(translation);\n```\n\n----------------------------------------\n\nTITLE: Making Prediction Request\nDESCRIPTION: Send conversation analysis request to Language Service model to get intent and entities from user input.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_5\n\nLANGUAGE: C#\nCODE:\n```\nvar projectName = \"Clock\";\nvar deploymentName = \"production\";\nvar data = new\n{\n    analysisInput = new\n    {\n        conversationItem = new\n        {\n            text = userText,\n            id = \"1\",\n            participantId = \"1\",\n        }\n    },\n    parameters = new\n    {\n        projectName,\n        deploymentName,\n        stringIndexType = \"Utf16CodeUnit\",\n    },\n    kind = \"Conversation\",\n};\nResponse response = await client.AnalyzeConversationAsync(RequestContent.Create(data));\ndynamic conversationalTaskResult = response.Content.ToDynamicFromJson(JsonPropertyNames.CamelCase);\ndynamic conversationPrediction = conversationalTaskResult.Result.Prediction;   \nvar options = new JsonSerializerOptions { WriteIndented = true };\nConsole.WriteLine(JsonSerializer.Serialize(conversationalTaskResult, options));\nConsole.WriteLine(\"--------------------\\n\");\nConsole.WriteLine(userText);\nvar topIntent = \"\";\nif (conversationPrediction.Intents[0].ConfidenceScore > 0.5)\n{\n    topIntent = conversationPrediction.TopIntent;\n}\n```\n\nLANGUAGE: Python\nCODE:\n```\ncls_project = 'Clock'\ndeployment_slot = 'production'\n\nwith client:\n    query = userText\n    result = client.analyze_conversation(\n        task={\n            \"kind\": \"Conversation\",\n            \"analysisInput\": {\n                \"conversationItem\": {\n                    \"participantId\": \"1\",\n                    \"id\": \"1\",\n                    \"modality\": \"text\",\n                    \"language\": \"en\",\n                    \"text\": query\n                },\n                \"isLoggingEnabled\": False\n            },\n            \"parameters\": {\n                \"projectName\": cls_project,\n                \"deploymentName\": deployment_slot,\n                \"verbose\": True\n            }\n        }\n    )\n```\n\n----------------------------------------\n\nTITLE: Adding Sentiment Analysis Skill to Azure AI Search Skillset\nDESCRIPTION: JSON definition for a sentiment analysis skill that evaluates the sentiment of document content. The skill processes text from the merged_content field, determines whether sentiment is positive, negative, neutral, or mixed, and outputs the result as a sentimentLabel field.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"@odata.type\": \"#Microsoft.Skills.Text.V3.SentimentSkill\",\n    \"defaultLanguageCode\": \"en\",\n    \"name\": \"get-sentiment\",\n    \"description\": \"New skill to evaluate sentiment\",\n    \"context\": \"/document\",\n    \"inputs\": [\n        {\n            \"name\": \"text\",\n            \"source\": \"/document/merged_content\"\n        },\n        {\n            \"name\": \"languageCode\",\n            \"source\": \"/document/language\"\n        }\n    ],\n    \"outputs\": [\n        {\n            \"name\": \"sentiment\",\n            \"targetName\": \"sentimentLabel\"\n        }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Extracting Key Phrases with Azure AI Language Service\nDESCRIPTION: Code to detect and extract key phrases from text documents using Azure AI Language client. The code processes text input and outputs a list of identified key phrases to the console.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_5\n\nLANGUAGE: csharp\nCODE:\n```\n// Get key phrases\nKeyPhraseCollection phrases = CogClient.ExtractKeyPhrases(text);\nif (phrases.Count > 0)\n{\n    Console.WriteLine(\"\\nKey Phrases:\");\n    foreach(string phrase in phrases)\n    {\n        Console.WriteLine($\"\\t{phrase}\");\n    }\n}\n```\n\nLANGUAGE: python\nCODE:\n```\n# Get key phrases\nphrases = cog_client.extract_key_phrases(documents=[text])[0].key_phrases\nif len(phrases) > 0:\n    print(\"\\nKey Phrases:\")\n    for phrase in phrases:\n        print('\\t{}'.format(phrase))\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Training Package - C#\nDESCRIPTION: Command to install the Microsoft Azure Custom Vision Training NuGet package for C# development, version 2.0.0\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0\n```\n\n----------------------------------------\n\nTITLE: Generating Thumbnail Images with Azure AI Vision in Python\nDESCRIPTION: This Python code snippet uses Azure AI Vision to generate a thumbnail image. It creates a 100x100 pixel thumbnail from the input image and saves it as a PNG file.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_21\n\nLANGUAGE: Python\nCODE:\n```\n# Generate a thumbnail\nwith open(image_file, mode=\"rb\") as image_data:\n    # Get thumbnail data\n    thumbnail_stream = cv_client.generate_thumbnail_in_stream(100, 100, image_data, True)\n\n# Save thumbnail image\nthumbnail_file_name = 'thumbnail.png'\nwith open(thumbnail_file_name, \"wb\") as thumbnail_file:\n    for chunk in thumbnail_stream:\n        thumbnail_file.write(chunk)\n\nprint('Thumbnail saved in.', thumbnail_file_name)\n```\n\n----------------------------------------\n\nTITLE: Mapping Storage Path to URL Field in Azure AI Search Indexer\nDESCRIPTION: JSON configuration for mapping the metadata_storage_path from source documents to the url field in the search index without Base-64 encoding, providing a clean URL for client applications to use.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"sourceFieldName\" : \"metadata_storage_path\",\n    \"targetFieldName\" : \"url\"\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Language Detection in C#\nDESCRIPTION: C# code implementation for detecting the language of text using Azure AI Translator's REST API. The code sends a POST request with the text and receives language identification in the response.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_7\n\nLANGUAGE: C#\nCODE:\n```\n// Use the Azure AI Translator detect function\nobject[] body = new object[] { new { Text = text } };\nvar requestBody = JsonConvert.SerializeObject(body);\nusing (var client = new HttpClient())\n{\n    using (var request = new HttpRequestMessage())\n    {\n        // Build the request\n        string path = \"/detect?api-version=3.0\";\n        request.Method = HttpMethod.Post;\n        request.RequestUri = new Uri(translatorEndpoint + path);\n        request.Content = new StringContent(requestBody, Encoding.UTF8, \"application/json\");\n        request.Headers.Add(\"Ocp-Apim-Subscription-Key\", cogSvcKey);\n        request.Headers.Add(\"Ocp-Apim-Subscription-Region\", cogSvcRegion);\n\n        // Send the request and get response\n        HttpResponseMessage response = await client.SendAsync(request).ConfigureAwait(false);\n        // Read response as a string\n        string responseContent = await response.Content.ReadAsStringAsync();\n\n        // Parse JSON array and get language\n        JArray jsonResponse = JArray.Parse(responseContent);\n        language = (string)jsonResponse[0][\"language\"]; \n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Python Image Classifier Client Application\nDESCRIPTION: Command to execute the Python script that tests the deployed image classification model using the Custom Vision SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython test-classifier.py\n```\n\n----------------------------------------\n\nTITLE: Modifying Message Activity Handler in C#\nDESCRIPTION: C# code to modify the OnMessageActivityAsync method to respond with the current time when asked.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_10\n\nLANGUAGE: C#\nCODE:\n```\nprotected override async Task OnMessageActivityAsync(ITurnContext<IMessageActivity> turnContext, CancellationToken cancellationToken)\n{\n    string inputMessage = turnContext.Activity.Text;\n    string responseMessage = \"Ask me what the time is.\";\n    if (inputMessage.ToLower().StartsWith(\"what\") && inputMessage.ToLower().Contains(\"time\"))\n    {\n        var now = DateTime.Now;\n        responseMessage = \"The time is \" + now.Hour.ToString() + \":\" + now.Minute.ToString(\"D2\");\n    }\n    await turnContext.SendActivityAsync(MessageFactory.Text(responseMessage, responseMessage), cancellationToken);\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Speech SDK Namespaces in C#\nDESCRIPTION: Code for importing the necessary Microsoft Cognitive Services Speech namespaces required for speech translation functionality in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_0\n\nLANGUAGE: C#\nCODE:\n```\n// Import namespaces\nusing Microsoft.CognitiveServices.Speech;\nusing Microsoft.CognitiveServices.Speech.Audio;\nusing Microsoft.CognitiveServices.Speech.Translation;\n```\n\n----------------------------------------\n\nTITLE: Querying Azure AI Search for Positive London Reviews\nDESCRIPTION: JSON query that searches for documents mentioning 'London', filters for positive sentiment and reviewer authorship, and returns only the URL, sentiment, and key phrases for each matching document.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_13\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"London\",\n  \"select\": \"url,sentiment,keyphrases\",\n  \"filter\": \"metadata_author eq 'Reviewer' and sentiment eq 'positive'\"\n}\n```\n\n----------------------------------------\n\nTITLE: Curl Request for Azure AI Language Question Answering API\nDESCRIPTION: Bash script that sends a POST request to the Azure AI Language Question Answering endpoint. Uses curl to query the knowledge base with authentication and receives JSON response containing answers.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/12-qna-maker.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nprediction_url=\"https://my-example-resource.cognitiveservices.azure.com/language/:query-knowledgebases?projectName=LearnFAQ&api-version=2021-10-01&deploymentName=production\"\nkey=\"123ca1b012ec4e4456dab367fefdf178\"\n\ncurl -X POST $prediction_url -H \"Ocp-Apim-Subscription-Key: $key\" -H \"Content-Type: application/json\" -d \"{'question': 'What is a learning Path?' }\"\n```\n\n----------------------------------------\n\nTITLE: Adding New Fields to Azure AI Search Index Definition\nDESCRIPTION: JSON definition for adding two additional fields to the search index: a sentiment field to store sentiment analysis results and a URL field to store the unencoded document path for easier retrieval in client applications.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"name\": \"sentiment\",\n    \"type\": \"Edm.String\",\n    \"facetable\": false,\n    \"filterable\": true,\n    \"retrievable\": true,\n    \"sortable\": true\n},\n{\n    \"name\": \"url\",\n    \"type\": \"Edm.String\",\n    \"facetable\": false,\n    \"filterable\": true,\n    \"retrievable\": true,\n    \"searchable\": false,\n    \"sortable\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Text Analytics Client\nDESCRIPTION: Initializing the Text Analytics client using endpoint and authentication key\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\nAzureKeyCredential credentials = new AzureKeyCredential(cogSvcKey);\nUri endpoint = new Uri(cogSvcEndpoint);\nTextAnalyticsClient CogClient = new TextAnalyticsClient(endpoint, credentials);\n```\n\nLANGUAGE: Python\nCODE:\n```\ncredential = AzureKeyCredential(cog_key)\ncog_client = TextAnalyticsClient(endpoint=cog_endpoint, credential=credential)\n```\n\n----------------------------------------\n\nTITLE: Configuring Facial Feature Detection with Azure Face API in Python\nDESCRIPTION: This snippet shows how to specify which facial features to detect when analyzing faces. The code configures the Face API to detect occlusion, blur, and glasses attributes.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\n# Specify facial features to be retrieved\nfeatures = [FaceAttributeType.occlusion,\n            FaceAttributeType.blur,\n            FaceAttributeType.glasses]\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision Namespaces in Python\nDESCRIPTION: This code imports the necessary namespaces for using the Azure AI Vision SDK in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# import namespaces\nfrom azure.cognitiveservices.vision.computervision import ComputerVisionClient\nfrom azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\nfrom msrest.authentication import CognitiveServicesCredentials\n```\n\n----------------------------------------\n\nTITLE: Querying the Azure AI Search Index\nDESCRIPTION: Search query to find positive reviews mentioning London authored by 'Reviewer', returning specific fields including URLs, sentiment, and key phrases.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsearch=London&$select=url,sentiment,keyphrases&$filter=metadata_author eq 'Reviewer' and sentiment eq 'positive'\n```\n\n----------------------------------------\n\nTITLE: Creating User-Friendly Weather Response in Bot Framework Composer\nDESCRIPTION: A bot response template that displays the current weather conditions and temperature for the city specified by the user, using variables stored during the dialog.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_2\n\nLANGUAGE: expression\nCODE:\n```\nThe weather in ${dialog.city} is ${dialog.weather} and the temperature is ${dialog.temp}&deg;.\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech Translation in C#\nDESCRIPTION: Code for setting up a SpeechTranslationConfig object with language parameters for translating from English to French, Spanish, and Hindi using C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\n// Configure translation\ntranslationConfig = SpeechTranslationConfig.FromSubscription(cogSvcKey, cogSvcRegion);\ntranslationConfig.SpeechRecognitionLanguage = \"en-US\";\ntranslationConfig.AddTargetLanguage(\"fr\");\ntranslationConfig.AddTargetLanguage(\"es\");\ntranslationConfig.AddTargetLanguage(\"hi\");\nConsole.WriteLine(\"Ready to translate from \" + translationConfig.SpeechRecognitionLanguage);\n```\n\n----------------------------------------\n\nTITLE: Running Python Flask Application for Margies Travel\nDESCRIPTION: This command runs the Python Flask web application for Margies Travel, which includes search functionality using Azure AI Search.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\nflask run\n```\n\n----------------------------------------\n\nTITLE: Creating Error Response for Failed Weather API Requests\nDESCRIPTION: A bot response template that displays the error message received from the OpenWeather API when a request fails, providing useful feedback to the user.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_3\n\nLANGUAGE: expression\nCODE:\n```\nI got an error: ${dialog.api_response.content.message}.\n```\n\n----------------------------------------\n\nTITLE: Specifying Face Detection Features in C#\nDESCRIPTION: Specifies the visual features to be retrieved (faces) for image analysis in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\n// Specify features to be retrieved (faces)\nList<VisualFeatureTypes?> features = new List<VisualFeatureTypes?>()\n{\n    VisualFeatureTypes.Faces\n};\n```\n\n----------------------------------------\n\nTITLE: Filtering Search Results by Author in JSON Format\nDESCRIPTION: JSON query that demonstrates combining search with filtering, retrieving documents that mention \"New York\" and were authored by 'Reviewer'.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"New York\",\n  \"count\": true,\n  \"select\": \"metadata_storage_name\",\n  \"filter\": \"metadata_author eq 'Reviewer'\"\n}\n```\n\n----------------------------------------\n\nTITLE: Searching for Specific Term with Field Selection in JSON Format\nDESCRIPTION: JSON query that searches for documents containing \"New York\" and returns only the filename and keyphrases fields from matching documents.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"New York\",\n  \"count\": true,\n  \"select\": \"metadata_storage_name,keyphrases\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Property Assignments for Weather Data in Bot Framework Composer\nDESCRIPTION: Property assignments for storing specific weather data from the OpenWeather API response, including weather description, temperature, and icon code.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n| Property | Value |\n| -- | -- |\n| `dialog.weather` | `=dialog.api_response.content.weather[0].description` |\n| `dialog.temp` | `=round(dialog.api_response.content.main.temp)` |\n| `dialog.icon` | `=dialog.api_response.content.weather[0].icon` |\n```\n\n----------------------------------------\n\nTITLE: Retrieving Image Tags in C#\nDESCRIPTION: This code retrieves and displays image tags using the Azure AI Vision SDK in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_10\n\nLANGUAGE: C#\nCODE:\n```\n// Get image tags\nif (analysis.Tags.Count > 0)\n{\n    Console.WriteLine(\"Tags:\");\n    foreach (var tag in analysis.Tags)\n    {\n        Console.WriteLine($\" -{tag.Name} (confidence: {tag.Confidence.ToString(\"P\")})\")\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Language Service Client\nDESCRIPTION: Initialize a ConversationAnalysisClient with endpoint and credentials for Azure Language Service.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\nUri endpoint = new Uri(predictionEndpoint);\nAzureKeyCredential credential = new AzureKeyCredential(predictionKey);\n\nConversationAnalysisClient client = new ConversationAnalysisClient(endpoint, credential);\n```\n\nLANGUAGE: Python\nCODE:\n```\nclient = ConversationAnalysisClient(\n    ls_prediction_endpoint, AzureKeyCredential(ls_prediction_key))\n```\n\n----------------------------------------\n\nTITLE: Retrieving Image Tags in Python\nDESCRIPTION: This code retrieves and displays image tags using the Azure AI Vision SDK in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n# Get image tags\nif (len(analysis.tags) > 0):\n    print(\"Tags: \")\n    for tag in analysis.tags:\n        print(\" -'{}' (confidence: {:.2f}%)\".format(tag.name, tag.confidence * 100))\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in C#\nDESCRIPTION: This code creates and authenticates an Azure AI Vision client object in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\n// Authenticate Azure AI Vision client\nApiKeyServiceClientCredentials credentials = new ApiKeyServiceClientCredentials(cogSvcKey);\ncvClient = new ComputerVisionClient(credentials)\n{\n    Endpoint = cogSvcEndpoint\n};\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in C#\nDESCRIPTION: This code creates and authenticates an Azure AI Vision client object in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\n// Authenticate Azure AI Vision client\nApiKeyServiceClientCredentials credentials = new ApiKeyServiceClientCredentials(cogSvcKey);\ncvClient = new ComputerVisionClient(credentials)\n{\n    Endpoint = cogSvcEndpoint\n};\n```\n\n----------------------------------------\n\nTITLE: Modifying Message Activity Handler in Python\nDESCRIPTION: Python code to modify the on_message_activity method to respond with the current time when asked.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\nasync def on_message_activity(self, turn_context: TurnContext):\n    input_message = turn_context.activity.text\n    response_message = 'Ask me what the time is.'\n    if (input_message.lower().startswith('what') and 'time' in input_message.lower()):\n        now = datetime.now()\n        response_message = 'The time is {}:{:02d}.'.format(now.hour,now.minute)\n    await turn_context.send_activity(response_message)\n```\n\n----------------------------------------\n\nTITLE: Running Search Creation Script\nDESCRIPTION: Command to execute the batch script that submits JSON definitions to the Azure AI Search REST interface to create search components.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncreate-search\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in Python\nDESCRIPTION: This code creates and authenticates an Azure AI Vision client object in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Authenticate Azure AI Vision client\ncredential = CognitiveServicesCredentials(cog_key) \ncv_client = ComputerVisionClient(cog_endpoint, credential)\n```\n\n----------------------------------------\n\nTITLE: Accessing Video Analyzer API with PowerShell\nDESCRIPTION: A PowerShell script that demonstrates the two-step authentication process for Video Analyzer API - first obtaining an access token using an API key, then using that token to list videos in the account. The script requires an account ID and API key to be configured before use.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/16-video-indexer.md#2025-04-23_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\nget-videos.ps1\n```\n\n----------------------------------------\n\nTITLE: Mapping Sentiment Output to Index Field in Azure AI Search\nDESCRIPTION: JSON configuration for mapping the sentimentLabel output from the sentiment analysis skill to the sentiment field in the search index, allowing sentiment-based filtering and sorting in search queries.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"sourceFieldName\": \"/document/sentimentLabel\",\n    \"targetFieldName\": \"sentiment\"\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Text Translation Program in Python\nDESCRIPTION: This command shows how to execute the text translation Python script from the command line.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\npython text-translation.py\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in C#\nDESCRIPTION: Creates and authenticates an Azure AI Vision client object using the endpoint and key.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\n// Authenticate Azure AI Vision client\nApiKeyServiceClientCredentials credentials = new ApiKeyServiceClientCredentials(cogSvcKey);\ncvClient = new ComputerVisionClient(credentials)\n{\n    Endpoint = cogSvcEndpoint\n};\n```\n\n----------------------------------------\n\nTITLE: Sample JSON Response from Azure AI Language Service\nDESCRIPTION: Example JSON response from the language understanding model showing predicted intent and entities for the query 'What's the time in Sydney'.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"kind\": \"ConversationResult\",\n  \"result\": {\n    \"query\": \"What's the time in Sydney\",\n    \"prediction\": {\n      \"topIntent\": \"GetTime\",\n      \"projectKind\": \"Conversation\",\n      \"intents\": [\n        {\n          \"category\": \"GetTime\",\n          \"confidenceScore\": 0.9135122\n        },\n        {\n          \"category\": \"GetDay\",\n          \"confidenceScore\": 0.61633164\n        },\n        {\n          \"category\": \"GetDate\",\n          \"confidenceScore\": 0.601757\n        },\n        {\n          \"category\": \"None\",\n          \"confidenceScore\": 0\n        }\n      ],\n      \"entities\": [\n        {\n          \"category\": \"Location\",\n          \"text\": \"Sydney\",\n          \"offset\": 19,\n          \"length\": 6,\n          \"confidenceScore\": 1\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for C# Application\nDESCRIPTION: Command to install the necessary NuGet packages for a C# application to work with Azure Text Analytics, Azure Identity, and Azure Key Vault Secrets.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Azure.AI.TextAnalytics --version 5.3.0\ndotnet add package Azure.Identity --version 1.5.0\ndotnet add package Azure.Security.KeyVault.Secrets --version 4.2.0-beta.3\n```\n\n----------------------------------------\n\nTITLE: Implementing Language Detection\nDESCRIPTION: Code to detect the language of text documents using the Text Analytics client\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_3\n\nLANGUAGE: C#\nCODE:\n```\nDetectedLanguage detectedLanguage = CogClient.DetectLanguage(text);\nConsole.WriteLine($\"\\nLanguage: {detectedLanguage.Name}\");\n```\n\nLANGUAGE: Python\nCODE:\n```\ndetectedLanguage = cog_client.detect_language(documents=[text])[0]\nprint('\\nLanguage: {}'.format(detectedLanguage.primary_language.name))\n```\n\n----------------------------------------\n\nTITLE: Authenticating Azure AI Vision Client in Python\nDESCRIPTION: This code creates and authenticates an Azure AI Vision client object in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Authenticate Azure AI Vision client\ncredential = CognitiveServicesCredentials(cog_key) \ncv_client = ComputerVisionClient(cog_endpoint, credential)\n```\n\n----------------------------------------\n\nTITLE: Specifying Image Analysis Features in Python\nDESCRIPTION: This code specifies the features to be retrieved during image analysis in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Specify features to be retrieved\nfeatures = [VisualFeatureTypes.description,\n            VisualFeatureTypes.tags,\n            VisualFeatureTypes.categories,\n            VisualFeatureTypes.brands,\n            VisualFeatureTypes.objects,\n            VisualFeatureTypes.adult]\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Text Analytics SDK\nDESCRIPTION: Commands to install the required SDK packages for text analytics in C# and Python\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\ndotnet add package Azure.AI.TextAnalytics --version 5.3.0\n\npip install azure-ai-textanalytics==5.3.0\npip install python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependency\nDESCRIPTION: Command to install the python-dotenv package required by the Python application to load environment variables from the .env file.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\npip install python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech Synthesis in C#\nDESCRIPTION: Code for creating a SpeechConfig object for speech synthesis using the Azure AI Speech service in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\n// Configure speech\nspeechConfig = SpeechConfig.FromSubscription(cogSvcKey, cogSvcRegion);\n```\n\n----------------------------------------\n\nTITLE: Specifying Image Analysis Features in C#\nDESCRIPTION: This code specifies the features to be retrieved during image analysis in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\n// Specify features to be retrieved\nList<VisualFeatureTypes?> features = new List<VisualFeatureTypes?>()\n{\n    VisualFeatureTypes.Description,\n    VisualFeatureTypes.Tags,\n    VisualFeatureTypes.Categories,\n    VisualFeatureTypes.Brands,\n    VisualFeatureTypes.Objects,\n    VisualFeatureTypes.Adult\n};\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK for Python\nDESCRIPTION: This command installs the Azure AI Vision SDK package for Python using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-cognitiveservices-vision-computervision==0.7.0\n```\n\n----------------------------------------\n\nTITLE: Opening Lab Folder in Cloud Shell Editor\nDESCRIPTION: Command to open the lab folder in the Cloud Shell Code editor. This opens the translate-text project folder.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\ncode azure-ai-eng/06-translate-text\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech Synthesis in Python\nDESCRIPTION: Code for creating a SpeechConfig object for speech synthesis using the Azure AI Speech service in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n# Configure speech\nspeech_config = speech_sdk.SpeechConfig(cog_key, cog_region)\n```\n\n----------------------------------------\n\nTITLE: Sample Utterances for GetTime Intent\nDESCRIPTION: Example utterances for the GetTime intent in a clock application conversational language model. These samples help train the model to recognize when users are asking for the current time.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nwhat is the time?\nwhat's the time?\nwhat time is it?\ntell me the time\n```\n\n----------------------------------------\n\nTITLE: Installing Language Service SDK Packages for C#\nDESCRIPTION: Commands to install the required NuGet packages for the Conversational Language Service SDK in a C# project.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Azure.AI.Language.Conversations --version 1.0.0\ndotnet add package Azure.Core\n```\n\n----------------------------------------\n\nTITLE: Installing Tabulate.NET Package for C#\nDESCRIPTION: Command to install the Tabulate.NET package version 1.0.5 using dotnet CLI for C# projects. This package is used to display output in a table format.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_6\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet add package Tabulate.NET --version 1.0.5\n```\n\n----------------------------------------\n\nTITLE: Running C# Object Detection Client Application\nDESCRIPTION: Command to run the C# program for object detection using the published Custom Vision model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_6\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Importing Audio Libraries in C# and Python\nDESCRIPTION: Code to import the necessary libraries for audio playback in C# (System.Media) and Python (playsound).\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_9\n\nLANGUAGE: csharp\nCODE:\n```\nusing System.Media;\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom playsound import playsound\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Training Package - Python\nDESCRIPTION: Command to install the Azure Cognitive Services Custom Vision Training Python package, version 3.1.0\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install azure-cognitiveservices-vision-customvision==3.1.0\n```\n\n----------------------------------------\n\nTITLE: Getting Moderation Ratings for Images with Azure AI Vision in Python\nDESCRIPTION: This Python code snippet uses Azure AI Vision to obtain content moderation ratings for images. It checks for adult, racy, and gory content in the analyzed image.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_19\n\nLANGUAGE: Python\nCODE:\n```\n# Get moderation ratings\nratings = 'Ratings:\\n -Adult: {}\\n -Racy: {}\\n -Gore: {}'.format(analysis.adult.is_adult_content,\n                                                                    analysis.adult.is_racy_content,\n                                                                    analysis.adult.is_gory_content)\nprint(ratings)\n```\n\n----------------------------------------\n\nTITLE: Running Text Recognition in C#\nDESCRIPTION: Command to execute the C# application for reading handwritten text using Azure AI Vision.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Importing Text Analytics Namespaces\nDESCRIPTION: Required namespace imports for using the Text Analytics SDK\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/05-analyze-text.md#2025-04-23_snippet_1\n\nLANGUAGE: C#\nCODE:\n```\nusing Azure;\nusing Azure.AI.TextAnalytics;\n```\n\nLANGUAGE: Python\nCODE:\n```\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.ai.textanalytics import TextAnalyticsClient\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK for C#\nDESCRIPTION: This command installs the Azure AI Vision SDK package for C# using the .NET CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.ComputerVision --version 6.0.0\n```\n\n----------------------------------------\n\nTITLE: Translating Speech from Audio File in C#\nDESCRIPTION: Code to translate speech from a WAV file using Azure AI Speech Translation services in C#. The code plays the audio file, configures a TranslationRecognizer with the audio input, and processes the translation result.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_10\n\nLANGUAGE: csharp\nCODE:\n```\n// Translate speech\nstring audioFile = \"station.wav\";\nSoundPlayer wavPlayer = new SoundPlayer(audioFile);\nwavPlayer.Play();\nusing AudioConfig audioConfig = AudioConfig.FromWavFileInput(audioFile);\nusing TranslationRecognizer translator = new TranslationRecognizer(translationConfig, audioConfig);\nConsole.WriteLine(\"Getting speech from file...\");\nTranslationRecognitionResult result = await translator.RecognizeOnceAsync();\nConsole.WriteLine($\"Translating '{result.Text}'\");\ntranslation = result.Translations[targetLanguage];\nConsole.OutputEncoding = Encoding.UTF8;\nConsole.WriteLine(translation);\n```\n\n----------------------------------------\n\nTITLE: Running C# Custom Vision Training Application\nDESCRIPTION: Command to execute the C# application for training the Custom Vision model\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Selecting Specific Fields in Search Query using JSON Format\nDESCRIPTION: JSON query that retrieves only specific fields (filename, author, and locations) from documents, demonstrating field selection capabilities in Azure AI Search.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"*\",\n  \"count\": true,\n  \"select\": \"metadata_storage_name,metadata_author,locations\"\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Speech SDK Namespaces in Python\nDESCRIPTION: Code for importing the Azure Cognitive Services Speech SDK namespace in Python for speech translation functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# Import namespaces\nimport azure.cognitiveservices.speech as speech_sdk\n```\n\n----------------------------------------\n\nTITLE: Translating Speech from Audio File in Python\nDESCRIPTION: Code to translate speech from a WAV file using Azure AI Speech Translation services in Python. The code plays the audio file, configures a TranslationRecognizer with the audio input, and processes the translation result.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Translate speech\naudioFile = 'station.wav'\nplaysound(audioFile)\naudio_config = speech_sdk.AudioConfig(filename=audioFile)\ntranslator = speech_sdk.translation.TranslationRecognizer(translation_config, audio_config = audio_config)\nprint(\"Getting speech from file...\")\nresult = translator.recognize_once_async().get()\nprint('Translating \"{}\"'.format(result.text))\ntranslation = result.translations[targetLanguage]\nprint(translation)\n```\n\n----------------------------------------\n\nTITLE: Running Python Custom Vision Training Application\nDESCRIPTION: Command to execute the Python script for training the Custom Vision model\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython train-classifier.py\n```\n\n----------------------------------------\n\nTITLE: Adding Count Parameter to Search Query in JSON Format\nDESCRIPTION: JSON query that includes the count parameter to return the total number of documents that match the search criteria along with the search results.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"*\",\n  \"count\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Granting Key Vault Access to Service Principal\nDESCRIPTION: Azure CLI command to set access policy in a Key Vault, giving the service principal permission to get and list secrets. This allows an application using this identity to retrieve secrets from the vault.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\naz keyvault set-policy -n <keyVaultName> --object-id <objectId> --secret-permissions get list\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Document Intelligence SDK for Python\nDESCRIPTION: This command installs the Azure AI Document Intelligence package for Python projects using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install azure-ai-formrecognizer==3.0.0\n```\n\n----------------------------------------\n\nTITLE: Running C# Web Application for Margies Travel\nDESCRIPTION: This command runs the C# ASP.NET Razor web application for Margies Travel, which includes search functionality using Azure AI Search.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Performing a Basic Search Query in JSON Format\nDESCRIPTION: A simple JSON query that returns all documents in the index using the asterisk wildcard. This is the most basic search query in Azure AI Search.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"*\"\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving Service Principal Object ID\nDESCRIPTION: Azure CLI command to get the object ID of a service principal using its appId. This ID is needed to grant the service principal permissions to access Key Vault.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\naz ad sp show --id <appId> --query objectId --out tsv\n```\n\n----------------------------------------\n\nTITLE: Setting up Azure Face API Client in Python\nDESCRIPTION: This snippet demonstrates how to initialize and authenticate a FaceClient using Azure Face API credentials. It imports the necessary namespaces and creates a client with endpoint and authentication key.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_11\n\nLANGUAGE: Python\nCODE:\n```\n# Import namespaces\nfrom azure.cognitiveservices.vision.face import FaceClient\nfrom azure.cognitiveservices.vision.face.models import FaceAttributeType\nfrom msrest.authentication import CognitiveServicesCredentials\n```\n\nLANGUAGE: Python\nCODE:\n```\n# Authenticate Face client\ncredentials = CognitiveServicesCredentials(cog_key)\nface_client = FaceClient(cog_endpoint, credentials)\n```\n\n----------------------------------------\n\nTITLE: Running Python Test Model Script\nDESCRIPTION: Command to run the Python script that tests the custom Document Intelligence model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_9\n\nLANGUAGE: Shell\nCODE:\n```\npython test-model.py\n```\n\n----------------------------------------\n\nTITLE: Installing Azure.AI.FormRecognizer Package for C#\nDESCRIPTION: Command to install the Azure.AI.FormRecognizer package version 3.0.0 using dotnet CLI for C# projects.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet add package Azure.AI.FormRecognizer --version 3.0.0\n```\n\n----------------------------------------\n\nTITLE: Specifying Face Detection Features in Python\nDESCRIPTION: Specifies the visual features to be retrieved (faces) for image analysis in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\n# Specify features to be retrieved (faces)\nfeatures = [VisualFeatureTypes.faces]\n```\n\n----------------------------------------\n\nTITLE: Running Python REST Client Application\nDESCRIPTION: Command to run the Python script that demonstrates using the REST API to access Azure AI Services for language detection.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython rest-client.py\n```\n\n----------------------------------------\n\nTITLE: Creating an EchoBot in Python\nDESCRIPTION: Command to create a new bot based on the EchoBot template in Python using cookiecutter.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\ncookiecutter https://github.com/microsoft/botbuilder-python/releases/download/Templates/echo.zip\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK for Python\nDESCRIPTION: This command installs the Azure AI Vision SDK package for Python using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\npip install azure-cognitiveservices-vision-computervision==0.7.0\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Text Analytics SDK for Python\nDESCRIPTION: Command to install the Azure Text Analytics SDK package for a Python project using pip. This package provides client libraries for interacting with the Azure Text Analytics service.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-ai-textanalytics==5.3.0\n```\n\n----------------------------------------\n\nTITLE: Running the Bot in C#\nDESCRIPTION: Command to run the bot locally in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision Namespaces in C#\nDESCRIPTION: This code imports the necessary namespaces to use the Azure AI Vision SDK in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\n// import namespaces\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision;\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK Package for C#\nDESCRIPTION: Installs the Azure AI Vision SDK NuGet package for C# projects.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.ComputerVision --version 6.0.0\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision SDK Namespaces in C#\nDESCRIPTION: Imports the necessary namespaces to use the Azure AI Vision SDK in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\n// import namespaces\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision;\nusing Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Search SDK for .NET\nDESCRIPTION: NuGet package installation command to add the Azure.Search.Documents package to a C# project, enabling interaction with Azure AI Search services through the .NET SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Azure.Search.Documents --version 11.1.1\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision Namespaces in Python\nDESCRIPTION: This code imports the necessary namespaces to use the Azure AI Vision SDK in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# import namespaces\nfrom azure.cognitiveservices.vision.computervision import ComputerVisionClient\nfrom azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\nfrom msrest.authentication import CognitiveServicesCredentials\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Training Package in C#\nDESCRIPTION: Command to install the Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training package version 2.0.0 using the .NET CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0\n```\n\n----------------------------------------\n\nTITLE: Importing Language Service SDK Namespaces in C#\nDESCRIPTION: C# code to import the necessary namespaces for using the Language service SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_2\n\nLANGUAGE: csharp\nCODE:\n```\n// Import namespaces\nusing Azure;\nusing Azure.AI.Language.Conversations;\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech Translation in Python\nDESCRIPTION: Code for setting up a SpeechTranslationConfig object with language parameters for translating from English to French, Spanish, and Hindi using Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Configure translation\ntranslation_config = speech_sdk.translation.SpeechTranslationConfig(cog_key, cog_region)\ntranslation_config.speech_recognition_language = 'en-US'\ntranslation_config.add_target_language('fr')\ntranslation_config.add_target_language('es')\ntranslation_config.add_target_language('hi')\nprint('Ready to translate from',translation_config.speech_recognition_language)\n```\n\n----------------------------------------\n\nTITLE: Importing Azure AI Vision SDK Modules in Python\nDESCRIPTION: Imports the required modules to use the Azure AI Vision SDK in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# import namespaces\nfrom azure.cognitiveservices.vision.computervision import ComputerVisionClient\nfrom azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\nfrom msrest.authentication import CognitiveServicesCredentials\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Training Package in Python\nDESCRIPTION: Command to install the azure-cognitiveservices-vision-customvision package version 3.1.0 using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-cognitiveservices-vision-customvision==3.1.0\n```\n\n----------------------------------------\n\nTITLE: Installing Audio Library Dependencies in C# and Python\nDESCRIPTION: Commands to install required packages for audio playback in C# (System.Windows.Extensions) and Python (playsound).\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_8\n\nLANGUAGE: csharp\nCODE:\n```\ndotnet add package System.Windows.Extensions --version 4.6.0 \n```\n\nLANGUAGE: python\nCODE:\n```\npip install playsound==1.3.0\n```\n\n----------------------------------------\n\nTITLE: Importing datetime Module in Python\nDESCRIPTION: Code to import the datetime module in Python to access date and time functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nfrom datetime import datetime\n```\n\n----------------------------------------\n\nTITLE: Importing Language Service SDK Modules in Python\nDESCRIPTION: Python code to import the necessary modules for using the Language service SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Import namespaces\nfrom azure.core.credentials import AzureKeyCredential\nfrom azure.ai.language.conversations import ConversationAnalysisClient\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Prediction SDK in C#\nDESCRIPTION: Command to install the Microsoft Azure Cognitive Services Custom Vision Prediction package for C# using the .NET CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0\n```\n\n----------------------------------------\n\nTITLE: Running the C# Image Classifier Client Application\nDESCRIPTION: Command to execute the C# program that tests the deployed image classification model using the Custom Vision Prediction SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/17-image-classification.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Using Read API to Extract Text from Image in C#\nDESCRIPTION: This code uses the Read API to asynchronously extract text from an image file in C#. It submits a read operation, checks for completion, and processes the results.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\n// Use Read API to read text in image\nusing (var imageData = File.OpenRead(imageFile))\n{    \n    var readOp = await cvClient.ReadInStreamAsync(imageData);\n\n    // Get the async operation ID so we can check for the results\n    string operationLocation = readOp.OperationLocation;\n    string operationId = operationLocation.Substring(operationLocation.Length - 36);\n\n    // Wait for the asynchronous operation to complete\n    ReadOperationResult results;\n    do\n    {\n        Thread.Sleep(1000);\n        results = await cvClient.GetReadResultAsync(Guid.Parse(operationId));\n    }\n    while ((results.Status == OperationStatusCodes.Running ||\n            results.Status == OperationStatusCodes.NotStarted));\n\n    // If the operation was successfully, process the text line by line\n    if (results.Status == OperationStatusCodes.Succeeded)\n    {\n        var textUrlFileResults = results.AnalyzeResult.ReadResults;\n        foreach (ReadResult page in textUrlFileResults)\n        {\n            foreach (Line line in page.Lines)\n            {\n                Console.WriteLine(line.Text);\n                \n                // Uncomment the following line if you'd like to see the bounding box \n                //Console.WriteLine(line.BoundingBox);\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK for C#\nDESCRIPTION: This command installs the Azure AI Vision SDK package for C# using the dotnet CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.ComputerVision --version 6.0.0\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Prediction Package for C#\nDESCRIPTION: Command to install the Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction package version 2.0.0 using dotnet CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0\n```\n\n----------------------------------------\n\nTITLE: Running Python Object Detection Client Application\nDESCRIPTION: Command to run the Python script for object detection using the published Custom Vision model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_7\n\nLANGUAGE: Shell\nCODE:\n```\npython test-detector.py\n```\n\n----------------------------------------\n\nTITLE: Sample Utterances for GetDay Intent\nDESCRIPTION: Example utterances for the GetDay intent in a clock application conversational language model. These samples help train the model to recognize when users are asking about the current day.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nwhat day is it?\nwhat's the day?\nwhat is the day today?\nwhat day of the week is it?\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Document Intelligence SDK for C#\nDESCRIPTION: This command installs the Azure AI Document Intelligence package for C# projects using the .NET CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndotnet add package Azure.AI.FormRecognizer --version 3.0.0\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Search SDK for Python\nDESCRIPTION: pip command to install the azure-search-documents package for Python, enabling Python applications to interact with Azure AI Search services through the Python SDK.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-search-documents==11.0.0\n```\n\n----------------------------------------\n\nTITLE: Running Python Object Detection Training Program\nDESCRIPTION: Command to run the Python script for uploading tagged images and training the object detection model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython train-detector.py\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory in Azure Cloud Shell\nDESCRIPTION: Command to change into the language app directory of the cloned repository.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncd azure-ai-eng/09-language-app\n```\n\n----------------------------------------\n\nTITLE: Installing Custom Vision Package for Python\nDESCRIPTION: Command to install the azure-cognitiveservices-vision-customvision package version 3.1.0 using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\npip install azure-cognitiveservices-vision-customvision==3.1.0\n```\n\n----------------------------------------\n\nTITLE: Running Python Application with Key Vault Authentication\nDESCRIPTION: Command to run the Python application that uses a service principal to authenticate to Key Vault and retrieve the Azure AI services key.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython keyvault-client.py\n```\n\n----------------------------------------\n\nTITLE: Running the Text Translation Program in C#\nDESCRIPTION: This command demonstrates how to run the text translation program in a C# environment using the dotnet CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running Azure CLI Login Command\nDESCRIPTION: Command to authenticate and establish a connection to an Azure subscription using Azure CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\naz login --output none\n```\n\n----------------------------------------\n\nTITLE: Installing Language Service SDK Packages for Python\nDESCRIPTION: Commands to install the required pip packages for the Conversational Language Service SDK in a Python project.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-ai-language-conversations --pre\npython -m pip install python-dotenv\npython -m pip install python-dateutil\n```\n\n----------------------------------------\n\nTITLE: Running C# SDK Client Application\nDESCRIPTION: Command to run the C# console application that uses the Azure Text Analytics SDK to access language detection functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Defining Weather Request Activity in Bot Framework Composer\nDESCRIPTION: This code snippet defines an activity that prompts the user for their city and displays a 'Cancel' button as a suggested action.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n[Activity    \n    Text = Enter your city.\n    SuggestedActions = Cancel\n]\n```\n\n----------------------------------------\n\nTITLE: Listing Azure Locations with Azure CLI\nDESCRIPTION: Command to list all available Azure locations in a tabular format using Azure CLI.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naz account list-locations -o table\n```\n\n----------------------------------------\n\nTITLE: Running C# Application with Key Vault Authentication\nDESCRIPTION: Command to run the C# application that uses a service principal to authenticate to Key Vault and retrieve the Azure AI services key.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running C# REST Client Application\nDESCRIPTION: Command to run the C# console application that demonstrates using the REST API to access Azure AI Services for language detection.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the Translation Program in C# and Python\nDESCRIPTION: Commands to run the translation program in C# and Python from the command line.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/08-translate-speech.md#2025-04-23_snippet_12\n\nLANGUAGE: csharp\nCODE:\n```\ndotnet run\n```\n\nLANGUAGE: python\nCODE:\n```\npython translator.py\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image and Retrieving Captions in Python\nDESCRIPTION: This code analyzes an image and retrieves captions using the Azure AI Vision SDK in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Get image analysis\nwith open(image_file, mode=\"rb\") as image_data:\n    analysis = cv_client.analyze_image_in_stream(image_data , features)\n\n# Get image description\nfor caption in analysis.description.captions:\n    print(\"Description: '{}' (confidence: {:.2f}%)\".format(caption.text, caption.confidence * 100))\n\n# Get image tags\n\n\n# Get image categories \n\n\n# Get brands in the image\n\n\n# Get objects in the image\n\n\n# Get moderation ratings\n\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Python Application\nDESCRIPTION: Command to install the necessary Python packages for working with Azure Text Analytics, Azure Identity, and Azure Key Vault Secrets using pip.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install azure-ai-textanalytics==5.3.0\npip install azure-identity==1.5.0\npip install azure-keyvault-secrets==4.2.0\n```\n\n----------------------------------------\n\nTITLE: Running C# Test Model Program\nDESCRIPTION: Command to run the C# program that tests the custom Document Intelligence model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_8\n\nLANGUAGE: Shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the Search Modification Script for Azure AI Search\nDESCRIPTION: Command to execute the modify-search.cmd script which submits the updated JSON definitions to the Azure AI Search REST API and initiates the indexing process with the new sentiment analysis capability.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nmodify-search\n```\n\n----------------------------------------\n\nTITLE: Installing Bot Templates and Packages in C#\nDESCRIPTION: Commands to install the necessary Bot Framework templates in C# including EchoBot, CoreBot, and EmptyBot templates.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_0\n\nLANGUAGE: C#\nCODE:\n```\ndotnet new -i Microsoft.Bot.Framework.CSharp.EchoBot\ndotnet new -i Microsoft.Bot.Framework.CSharp.CoreBot\ndotnet new -i Microsoft.Bot.Framework.CSharp.EmptyBot\n```\n\n----------------------------------------\n\nTITLE: Cloning the AI-102-AIEngineer Repository with Git\nDESCRIPTION: Command to clone the Microsoft Learning AI-102-AIEngineer repository containing the lab files needed for the Azure AI Search exercise.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhttps://github.com/MicrosoftLearning/AI-102-AIEngineer\n```\n\n----------------------------------------\n\nTITLE: Running Text Recognition in Python\nDESCRIPTION: Command to execute the Python script for reading handwritten text using Azure AI Vision.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/20-ocr.md#2025-04-23_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\npython read-text.py\n```\n\n----------------------------------------\n\nTITLE: Sample Utterances with Location Entity for GetTime Intent\nDESCRIPTION: Example utterances that include location entities for the GetTime intent. These samples help train the model to recognize location references when users ask for the time in specific places.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nwhat time is it in London?\nTell me the time in Paris?\nwhat's the time in New York?\n```\n\n----------------------------------------\n\nTITLE: Installing azure-ai-formrecognizer Package for Python\nDESCRIPTION: Command to install the azure-ai-formrecognizer package version 3.0.0 using pip for Python projects.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\npip install azure-ai-formrecognizer==3.0.0\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory in Azure Cloud Shell\nDESCRIPTION: Bash commands to clone the course repository and navigate to the project directory in Azure Cloud Shell. This sets up the environment for the lab.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/12-qna-maker.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nrm -r azure-ai-eng -f\ngit clone https://github.com/MicrosoftLearning/AI-102-AIEngineer azure-ai-eng\ncd azure-ai-eng/12-qna\n```\n\n----------------------------------------\n\nTITLE: Running C# Object Detection Training Program\nDESCRIPTION: Command to run the C# program for uploading tagged images and training the object detection model.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/18-object-detection.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Sample Utterances for GetDate Intent\nDESCRIPTION: Example utterances for the GetDate intent in a clock application conversational language model. These samples help train the model to recognize when users are asking about the current date.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nwhat date is it?\nwhat's the date?\nwhat is the date today?\nwhat's today's date?\n```\n\n----------------------------------------\n\nTITLE: Processing Prediction Response\nDESCRIPTION: Handle the prediction response by processing intents and entities to determine appropriate actions for time, date, and day queries.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/10b-language-understanding-client-(preview).md#2025-04-23_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\nswitch (topIntent)\n{\n    case \"GetTime\":\n        var location = \"local\";           \n        foreach (dynamic entity in conversationPrediction.Entities)\n        {\n            if (entity.Category == \"Location\")\n            {\n                location = entity.Text;\n            }\n        }\n        string timeResponse = GetTime(location);\n        Console.WriteLine(timeResponse);\n        break;\n    case \"GetDay\":\n        var date = DateTime.Today.ToShortDateString();            \n        foreach (dynamic entity in conversationPrediction.Entities)\n        {\n            if (entity.Category == \"Date\")\n            {\n                date = entity.Text;\n            }\n        }            \n        string dayResponse = GetDay(date);\n        Console.WriteLine(dayResponse);\n        break;\n    case \"GetDate\":\n        var day = DateTime.Today.DayOfWeek.ToString();\n        foreach (dynamic entity in conversationPrediction.Entities)\n        {\n            if (entity.Category == \"Weekday\")\n            {\n                day = entity.Text;\n            }\n        }          \n        string dateResponse = GetDate(day);\n        Console.WriteLine(dateResponse);\n        break;\n    default:\n        Console.WriteLine(\"Try asking me for the time, the day, or the date.\");\n        break;\n}\n```\n\nLANGUAGE: Python\nCODE:\n```\nif top_intent == 'GetTime':\n    location = 'local'\n    if len(entities) > 0:\n        for entity in entities:\n            if 'Location' == entity[\"category\"]:\n                location = entity[\"text\"]\n    print(GetTime(location))\n\nelif top_intent == 'GetDay':\n    date_string = date.today().strftime(\"%m/%d/%Y\")\n    if len(entities) > 0:\n        for entity in entities:\n            if 'Date' == entity[\"category\"]:\n                date_string = entity[\"text\"]\n    print(GetDay(date_string))\n\nelif top_intent == 'GetDate':\n    day = 'today'\n    if len(entities) > 0:\n        for entity in entities:\n            if 'Weekday' == entity[\"category\"]:\n                day = entity[\"text\"]\n    print(GetDate(day))\n\nelse:\n    print('Try asking me for the time, the day, or the date.')\n```\n\n----------------------------------------\n\nTITLE: Running Python Document Intelligence Training Application\nDESCRIPTION: This command executes the Python script to train a custom Document Intelligence model using the provided sample forms.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npython train-model.py\n```\n\n----------------------------------------\n\nTITLE: Importing System Namespace in C#\nDESCRIPTION: Code to import the System namespace in C# to access DateTime functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_8\n\nLANGUAGE: C#\nCODE:\n```\nusing System;\n```\n\n----------------------------------------\n\nTITLE: Installing Azure Text Analytics SDK for C#\nDESCRIPTION: Command to install the Azure Text Analytics SDK package for a C# project using the .NET CLI. This package provides client libraries for interacting with the Azure Text Analytics service.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndotnet add package Azure.AI.TextAnalytics --version 5.3.0\n```\n\n----------------------------------------\n\nTITLE: Installing Bot Packages in Python\nDESCRIPTION: Commands to install the required Python packages for bot development including botbuilder-core, asyncio, aiohttp, and cookiecutter.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\npip install botbuilder-core\npip install asyncio\npip install aiohttp\npip install cookiecutter==1.7.0\n```\n\n----------------------------------------\n\nTITLE: Installing tabulate Package for Python\nDESCRIPTION: Command to install the tabulate package using pip for Python projects. This package is used to display output in a table format.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_7\n\nLANGUAGE: Shell\nCODE:\n```\npip install tabulate\n```\n\n----------------------------------------\n\nTITLE: Running C# Application\nDESCRIPTION: Command to run the C# application for text translation. This executes the code that detects language and translates text.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Creating an EchoBot in C#\nDESCRIPTION: Command to create a new bot based on the EchoBot template in C#, named TimeBot.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\ndotnet new echobot -n TimeBot\n```\n\n----------------------------------------\n\nTITLE: Running Document Upload Script\nDESCRIPTION: Command to execute the UploadDocs batch file which creates a blob container and uploads documents to Azure Storage.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nUploadDocs\n```\n\n----------------------------------------\n\nTITLE: Executing Search Query with Custom Skill Results in Azure AI Search\nDESCRIPTION: JSON query that searches for documents containing 'Las Vegas' and returns only the URL and top_words fields. The top_words field is populated by the custom skill that extracts important terms from documents.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"search\": \"Las Vegas\",\n  \"select\": \"url,top_words\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Expression for OpenWeather API Condition in Bot Framework Composer\nDESCRIPTION: An expression that checks if the HTTP response status code from the OpenWeather API call equals 200, indicating a successful request.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/14-bot-composer.md#2025-04-23_snippet_0\n\nLANGUAGE: expression\nCODE:\n```\n=dialog.api_response.statusCode == 200\n```\n\n----------------------------------------\n\nTITLE: Running Python SDK Client Application\nDESCRIPTION: Command to run the Python script that uses the Azure Text Analytics SDK to access language detection functionality.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/01-get-started-cognitive-services.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython sdk-client.py\n```\n\n----------------------------------------\n\nTITLE: Installing Azure AI Vision SDK Package for Python\nDESCRIPTION: Installs the Azure AI Vision SDK pip package for Python projects.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\npip install azure-cognitiveservices-vision-computervision==0.7.0\n```\n\n----------------------------------------\n\nTITLE: Running the API Request Script\nDESCRIPTION: Command to execute the shell script that sends a request to the Azure AI Language service.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nsh send-call.sh\n```\n\n----------------------------------------\n\nTITLE: Running Python Application\nDESCRIPTION: Command to run the Python application for text translation. This executes the code that detects language and translates text.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\npython text-translation.py\n```\n\n----------------------------------------\n\nTITLE: Running C# Document Intelligence Training Application\nDESCRIPTION: This command runs the C# application to train a custom Document Intelligence model using the provided sample forms.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/21-form-recognizer.md#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndotnet run\n```\n\n----------------------------------------\n\nTITLE: Running the Bot in Python\nDESCRIPTION: Command to run the bot locally in Python.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\npython app.py\n```\n\n----------------------------------------\n\nTITLE: Opening the API Request Script in Cloud Shell Editor\nDESCRIPTION: Command to open the script file that contains the API call to the Azure AI Language service.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncode send-call.sh\n```\n\n----------------------------------------\n\nTITLE: Analyzing Image and Retrieving Captions in C#\nDESCRIPTION: This code analyzes an image and retrieves captions using the Azure AI Vision SDK in C#.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/15-computer-vision.md#2025-04-23_snippet_8\n\nLANGUAGE: C#\nCODE:\n```\n// Get image analysis\nusing (var imageData = File.OpenRead(imageFile))\n{    \n    var analysis = await cvClient.AnalyzeImageInStreamAsync(imageData, features);\n\n    // get image captions\n    foreach (var caption in analysis.Description.Captions)\n    {\n        Console.WriteLine($\"Description: {caption.Text} (confidence: {caption.Confidence.ToString(\"P\")})\")\n    }\n\n    // Get image tags\n\n\n    // Get image categories\n\n\n    // Get brands in the image\n\n\n    // Get objects in the image\n\n\n    // Get moderation ratings\n    \n\n}            \n```\n\n----------------------------------------\n\nTITLE: Service Principal Creation Response Format\nDESCRIPTION: Example JSON output from the service principal creation command, showing the appId, displayName, name, password, and tenant values that will be needed for application authentication.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/02-cognitive-services-security.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"appId\": \"abcd12345efghi67890jklmn\",\n    \"displayName\": \"ai-app\",\n    \"name\": \"http://ai-app\",\n    \"password\": \"1a2b3c4d5e6f7g8h9i0j\",\n    \"tenant\": \"1234abcd5678fghi90jklm\"\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Project Repository in Azure Cloud Shell\nDESCRIPTION: Commands to download and navigate to the project files in Azure Cloud Shell. This removes any existing directory and clones the AI-102-AIEngineer repository.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/09b-language-understanding-(preview).md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nrm -r azure-ai-eng -f\ngit clone https://github.com/MicrosoftLearning/AI-102-AIEngineer azure-ai-eng\n```\n\n----------------------------------------\n\nTITLE: Running Setup Script for Azure Resources\nDESCRIPTION: Command to execute the setup script that creates required Azure resources for the search solution.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsetup\n```\n\n----------------------------------------\n\nTITLE: Navigating to C# Project Folder\nDESCRIPTION: Command to change directory to the C# project folder containing the text translation implementation.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\ncd AI-Engineer/06-translate-text/C-Sharp/text-translation\n```\n\n----------------------------------------\n\nTITLE: Opening the C# Project File for Editing\nDESCRIPTION: Command to open the TimeBot project file in Visual Studio Code to modify the target framework.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_3\n\nLANGUAGE: Code\nCODE:\n```\ncode TimeBot\\TimeBot.csproj\n```\n\n----------------------------------------\n\nTITLE: Changing Directory and Listing Files\nDESCRIPTION: Commands to navigate to the TimeBot directory and list its contents.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/13-bot-framework.md#2025-04-23_snippet_5\n\nLANGUAGE: Code\nCODE:\n```\ncd TimeBot\ndir\n```\n\n----------------------------------------\n\nTITLE: Logging into Azure CLI\nDESCRIPTION: Command to authenticate with Azure using the Azure Command Line Interface, which opens a browser for login.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/22-azure-search.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\naz login\n```\n\n----------------------------------------\n\nTITLE: Detecting Faces with Azure AI Vision in Python\nDESCRIPTION: This code snippet demonstrates how to use the Azure AI Vision client to analyze an image and detect faces. It then draws rectangles around the faces and annotates their positions in the image, saving the result as a new image file.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/19-face-service.md#2025-04-23_snippet_10\n\nLANGUAGE: Python\nCODE:\n```\n# Get image analysis\nwith open(image_file, mode=\"rb\") as image_data:\n    analysis = cv_client.analyze_image_in_stream(image_data , features)\n\n    # Get faces\n    if analysis.faces:\n        print(len(analysis.faces), 'faces detected.')\n\n        # Prepare image for drawing\n        fig = plt.figure(figsize=(8, 6))\n        plt.axis('off')\n        image = Image.open(image_file)\n        draw = ImageDraw.Draw(image)\n        color = 'lightgreen'\n\n        # Draw and annotate each face\n        for face in analysis.faces:\n            r = face.face_rectangle\n            bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n            draw = ImageDraw.Draw(image)\n            draw.rectangle(bounding_box, outline=color, width=5)\n            annotation = 'Person at approximately {}, {}'.format(r.left, r.top)\n            plt.annotate(annotation,(r.left, r.top), backgroundcolor=color)\n\n        # Save annotated image\n        plt.imshow(image)\n        outputfile = 'detected_faces.jpg'\n        fig.savefig(outputfile)\n\n        print('Results saved in', outputfile)\n```\n\n----------------------------------------\n\nTITLE: Navigating to Python Project Folder\nDESCRIPTION: Command to change directory to the Python project folder containing the text translation implementation.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\ncd AI-Engineer/06-translate-text/Python/text-translation\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository in Azure Cloud Shell\nDESCRIPTION: Commands to download the lab repository into Azure Cloud Shell environment. The commands remove any existing copy of the repository before cloning a fresh version.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/06-translate-text.md#2025-04-23_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\nrm -r azure-ai-eng -f\ngit clone https://github.com/MicrosoftLearning/AI-102-AIEngineer azure-ai-eng\n```\n\n----------------------------------------\n\nTITLE: Generating Exercise Table in Jekyll/Liquid\nDESCRIPTION: A Liquid template snippet that dynamically generates a table of available lab exercises by filtering pages that contain '/Instructions' in their URL. The template creates a markdown table with links to each exercise.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/index.md#2025-04-23_snippet_0\n\nLANGUAGE: liquid\nCODE:\n```\n{% assign labs = site.pages | where_exp:\"page\", \"page.url contains '/Instructions'\" %}\n| Exercise |\n| --- |\n{% for activity in labs  %}| [{{ activity.lab.title }}{% if activity.lab.type %} - {{ activity.lab.type }}{% endif %}]({{ site.github.url }}{{ activity.url }}) |\n{% endfor %}\n```\n\n----------------------------------------\n\nTITLE: Embedding Video Analyzer Widgets in HTML\nDESCRIPTION: This HTML code snippet demonstrates how to embed Video Analyzer Player and Insights widgets in a web page. It includes a reference to the vb.widgets.mediator.js script for widget interaction.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/16-video-indexer.md#2025-04-23_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<!DOCTYPE html>\n<html>\n<head>\n    <title>Analyze Video</title>\n    <script src=\"https://breakdown.blob.core.windows.net/public/vb.widgets.mediator.js\"></script>\n</head>\n<body>\n    <h1>Video Analysis</h1>\n    <!-- Player widget goes here -->\n    \n    <!-- Insights widget goes here -->\n</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Running Update Script for Azure AI Search Resources\nDESCRIPTION: Command to execute the batch script that updates the search resources with the new custom skill configuration.\nSOURCE: https://github.com/microsoftlearning/ai-102-aiengineer/blob/master/Instructions/23-search-skills.md#2025-04-23_snippet_7\n\nLANGUAGE: cmd\nCODE:\n```\nupdate-search\n```"
  }
]