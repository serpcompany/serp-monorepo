[
  {
    "owner": "nvidia",
    "repo": "physicsnemo",
    "content": "TITLE: Optimized Training Workflow with StaticCaptureTraining\nDESCRIPTION: Shows how to use the StaticCaptureTraining decorator to optimize the training step function with AMP, CUDA Graphs, and JIT optimizations in PhysicsNeMo.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@StaticCaptureTraining(amp=True, cuda_graphs=True, jit=True)\ndef train_step(model, optimizer, batch):\n    optimizer.zero_grad()\n    out = model(batch[\"input\"])\n    loss = torch.mean((out - batch[\"output\"]) ** 2)\n    loss.backward()\n    optimizer.step()\n    return loss\n\n# Training loop\nfor epoch in range(10):\n    for batch in dataset:\n        loss = train_step(model, optimizer, batch)\n    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n```\n\n----------------------------------------\n\nTITLE: Loading Model from Checkpoint in PhysicsNeMo\nDESCRIPTION: Demonstrates loading a pre-trained model from a .mdlus file using the Module.from_checkpoint method. Shows how to instantiate a model without explicitly defining its class or parameters.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo import Module\n>>> fc_model = Module.from_checkpoint(\"model.mdlus\") # Instantiate model from .mdlus file.\n>>> fc_model\n```\n\n----------------------------------------\n\nTITLE: Basic Training Loop with PhysicsNeMo FNO Model\nDESCRIPTION: Demonstrates a simple training loop using PhysicsNeMo's FNO model and Darcy2D dataset. It includes model initialization, data loading, and the training process with loss calculation and optimization.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Initialize the model\nmodel = FNO(modes1=12, modes2=12, width=32)\n\n# Initialize the optimizer\noptimizer = Adam(model.parameters(), lr=1e-3)\n\n# Initialize the data loader\ndataset = Darcy2D(batch_size=32, shuffle=True)\n\n# Training loop\nfor epoch in range(10):\n    for batch in dataset:\n        optimizer.zero_grad()\n        out = model(batch[\"input\"])\n        loss = torch.mean((out - batch[\"output\"]) ** 2)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom PyTorch UNet Model\nDESCRIPTION: Shows the implementation of a custom UNet model using PyTorch's nn.Module. This serves as a base for demonstrating how to convert a PyTorch model to a PhysicsNeMo model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch.nn as nn\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNet, self).__init__()\n\n        self.enc1 = self.conv_block(in_channels, 64)\n        self.enc2 = self.conv_block(64, 128)\n        self.enc3 = self.conv_block(128, 256)\n        self.enc4 = self.conv_block(256, 512)\n\n        self.pool = nn.MaxPool2d(2)\n        self.upconv = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n\n        self.dec1 = self.conv_block(512, 256)\n        self.dec2 = self.conv_block(256, 128)\n        self.dec3 = self.conv_block(128, 64)\n\n        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def conv_block(self, in_c, out_c):\n        return nn.Sequential(\n            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        e1 = self.enc1(x)\n        e2 = self.enc2(self.pool(e1))\n        e3 = self.enc3(self.pool(e2))\n        e4 = self.enc4(self.pool(e3))\n\n        d = self.upconv(e4)\n        d = self.dec1(torch.cat([d, e3], dim=1))\n        d = self.dec2(torch.cat([d, e2], dim=1))\n        d = self.dec3(torch.cat([d, e1], dim=1))\n\n        return self.out(d)\n```\n\n----------------------------------------\n\nTITLE: Running Inference on Trained PhysicsNeMo Models\nDESCRIPTION: Demonstrates how to perform inference using a trained PhysicsNeMo model, including loading the model, preparing input data, and running predictions.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom physicsnemo.models import FNO\nfrom physicsnemo.data import Darcy2D\n\n# Load the trained model\nmodel = FNO(modes1=12, modes2=12, width=32)\nmodel.load_state_dict(torch.load('trained_model.pth'))\nmodel.eval()\n\n# Prepare input data\ndataset = Darcy2D(batch_size=1, shuffle=False)\nbatch = next(iter(dataset))\n\n# Run inference\nwith torch.no_grad():\n    prediction = model(batch[\"input\"])\n\nprint(f\"Input shape: {batch['input'].shape}\")\nprint(f\"Prediction shape: {prediction.shape}\")\nprint(f\"Ground truth shape: {batch['output'].shape}\")\n\n# Calculate error\nerror = torch.mean((prediction - batch[\"output\"]) ** 2)\nprint(f\"Mean squared error: {error.item()}\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed Data Parallel Training with DistributedManager in Python\nDESCRIPTION: This snippet demonstrates how to set up distributed data parallel training using PhysicsNeMo's DistributedManager, which simplifies configuration of PyTorch's DistributedDataParallel. It shows initialization, model setup, DDP configuration, and a basic training loop.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch.nn.parallel import DistributedDataParallel\nfrom physicsnemo.distributed import DistributedManager\nfrom physicsnemo.models.mlp.fully_connected import FullyConnected\n\ndef main():\n    # Initialize the DistributedManager. This will automatically \n    # detect the number of processes the job was launched with and \n    # set those configuration parameters appropriately. Currently \n    # torchrun (or any other pytorch compatible launcher), mpirun (OpenMPI) \n    # and SLURM based launchers are supported.\n    DistributedManager.initialize()\n\n    # Since this is a singleton class, you can just get an instance \n    # of it anytime after initialization and not need to reinitialize\n    # each time.\n    dist = DistributedManager()\n\n    # Set up model on the appropriate device. DistributedManager\n    # figures out what device should be used on this process\n    arch = FullyConnected(in_features=32, out_features=64).to(dist.device)\n\n    # Set up DistributedDataParallel if using more than a single process.\n    # The `distributed` property of DistributedManager can be used to \n    # check this.\n    if dist.distributed:\n        ddps = torch.cuda.Stream()\n        with torch.cuda.stream(ddps):\n            arch = DistributedDataParallel(\n                arch,\n                device_ids=[dist.local_rank],  # Set the device_id to be\n                                               # the local rank of this process on\n                                               # this node\n                output_device=dist.device,\n                broadcast_buffers=dist.broadcast_buffers,\n                find_unused_parameters=dist.find_unused_parameters,\n            )\n        torch.cuda.current_stream().wait_stream(ddps)\n\n    # Set up the optimizer\n    optimizer = torch.optim.Adam(\n        arch.parameters(),\n        lr=0.001,\n    )\n\n    def training_step(input, target):\n        pred = arch(invar)\n        loss = torch.sum(torch.pow(pred - target, 2))\n        loss.backward()\n        optimizer.step()\n        return loss\n\n    # Sample training loop\n    for i in range(20):\n        # Random inputs and targets for simplicity\n        input = torch.randn(128, 32, device=dist.device)\n        target = torch.randn(128, 64, device=dist.device)\n\n        # Training step\n        loss = training_step(input, target)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Model for PhysicsNeMo\nDESCRIPTION: Example implementation of a custom model class that can be registered with PhysicsNeMo, showing the required structure and inheritance pattern.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# mypackage/models.py\n\nimport torch.nn as nn\nfrom physicsnemo.models import Model\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        return self.conv2(x)\n\nMyPhysicsNeMoModel = Model.from_pytorch(MyModel)\n```\n\n----------------------------------------\n\nTITLE: DistributedAFNO Constructor Implementation in Python\nDESCRIPTION: This snippet shows the constructor of the DistributedAFNO class, demonstrating how the DistributedManager enables model-parallel implementations to query distributed configuration without explicitly passing parameters.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# This is from DistributedAFNO.__init__ method\n# The full method implementation is not shown in the snippet\n```\n\n----------------------------------------\n\nTITLE: Installing PhysicsNeMo via PyPi\nDESCRIPTION: Command to install the latest version of PhysicsNeMo using the Python package manager pip.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\npip install nvidia-physicsnemo\n```\n\n----------------------------------------\n\nTITLE: Implementing Weights and Biases Logging with PhysicsNeMo\nDESCRIPTION: Setting up a training loop with PhysicsNeMo's Weights and Biases integration. This example demonstrates how to initialize wandb for experiment tracking, configure project parameters, and log metrics during training that will be visualized in the wandb dashboard.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Initialize wandb Tracking\ninitialize_wandb(\n    project=\"simple-wandb-logging\",\n    name=\"test_run\",\n    job_type=\"training\",\n    tags=[\"test\", \"wandb\", \"logging\"],\n    mode=\"offline\",\n)\n\n# Create a logger instance with wandb enabled\nlogger = LaunchLogger(use_console=True, use_wandb=True)\nlogger.info(\"Starting Training!\")\n\n# Setup a simple diffusion solver\ntrainer, model, solver, domain = setup_1d_diffusion_solver()\n\n# Setup optimizer, scheduler and criterion\noptimizer = Adam(model.parameters(), lr=1e-2)\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\ncriterion = nn.MSELoss()\n\n# Run a simple training loop\nfor epoch in range(20):\n    loss = trainer.train(model, solver, domain, optimizer, criterion)\n    \n    # Log metrics using the train function of the logger\n    logger.train({\n        \"Learning Rate\": scheduler.get_last_lr()[0],\n        \"Loss\": loss.item(),\n    })\n    \n    scheduler.step()\n\nlogger.info(\"Finished Training!\")\n```\n\n----------------------------------------\n\nTITLE: PhysicsNeMo UNet Implementation\nDESCRIPTION: Enhanced UNet implementation using PhysicsNeMo with CUDA Graphs and Automatic Mixed-Precision support through metadata configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nimport physicsnemo\nimport torch.nn as nn\n\n@dataclass\nclass UNetMetaData(physicsnemo.ModelMetaData):\n    name: str = \"UNet\"\n    # Optimization\n    jit: bool = True\n    cuda_graphs: bool = True\n    amp_cpu: bool = True\n    amp_gpu: bool = True\n\nclass UNet(physicsnemo.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNet, self).__init__(meta=UNetMetaData())\n\n        self.enc1 = self.conv_block(in_channels, 64)\n        self.enc2 = self.conv_block(64, 128)\n\n        self.dec1 = self.upconv_block(128, 64)\n        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2)\n        )\n\n    def upconv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(x1)\n        x = self.dec1(x2)\n        return self.final(x)\n```\n\n----------------------------------------\n\nTITLE: Running FNO-based Physics-Informed Darcy Flow Model\nDESCRIPTION: Command to run the Fourier Neural Operator (FNO) approach for the physics-informed Darcy flow model. This script uses numerical differentiation in a PINO-style implementation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_physics_informed/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython darcy_physics_informed_fno.py\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading PhysicsNeMo Models\nDESCRIPTION: Demonstrates saving and loading PhysicsNeMo models using the .mdlus file format, which preserves model metadata.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.models.mlp.fully_connected import FullyConnected\nmodel = FullyConnected(in_features=32, out_features=64)\nmodel.save(\"model.mdlus\") # Save model to .mdlus file\nmodel.load(\"model.mdlus\") # Load model weights from .mdlus file from already instantiated model\n```\n\n----------------------------------------\n\nTITLE: Initializing Fully Connected Model in PhysicsNeMo\nDESCRIPTION: Demonstrates creating and using a basic fully connected neural network model using PhysicsNeMo's FullyConnected class with input and output feature specifications.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom physicsnemo.models.mlp.fully_connected import FullyConnected\nmodel = FullyConnected(in_features=32, out_features=64)\ninput = torch.randn(128, 32)\noutput = model(input)\noutput.shape\n```\n\n----------------------------------------\n\nTITLE: Implementing MLFlow Logging with PhysicsNeMo\nDESCRIPTION: Setting up a training loop with PhysicsNeMo's MLFlow integration. This example shows how to initialize MLFlow for experiment tracking, set experiment parameters, and log metrics during training that will be stored in the MLFlow database.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Initialize MLFlow Tracking\ninitialize_mlflow(\n    experiment_name=\"simple-mlflow-logging\",\n    run_name=\"test_run\",\n    tracking_uri=\"./mlruns_0\",\n    registry_uri=\"./mlruns_0\",\n)\n\n# Create a logger instance with MLFlow enabled\nlogger = LaunchLogger(use_console=True, use_mlflow=True)\nlogger.info(\"Starting Training!\")\n\n# Setup a simple diffusion solver\ntrainer, model, solver, domain = setup_1d_diffusion_solver()\n\n# Setup optimizer, scheduler and criterion\noptimizer = Adam(model.parameters(), lr=1e-2)\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\ncriterion = nn.MSELoss()\n\n# Run a simple training loop\nfor epoch in range(20):\n    loss = trainer.train(model, solver, domain, optimizer, criterion)\n    \n    # Log metrics using the train function of the logger\n    logger.train({\n        \"Learning Rate\": scheduler.get_last_lr()[0],\n        \"Loss\": loss.item(),\n    })\n    \n    scheduler.step()\n\nlogger.info(\"Finished Training!\")\n```\n\n----------------------------------------\n\nTITLE: Single Node Multi-GPU Training Command in Bash\nDESCRIPTION: Command for launching distributed training on a single node with multiple GPUs using torchrun.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --nodes=1 --nproc-per-node=4 train.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Profiling Tools in Python\nDESCRIPTION: This code snippet demonstrates how to configure and initialize the profiling tools in PhysicsNeMo. It sets up the Profiler object and enables specific profiling tools based on the configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# configure the profiling tools:\np = Profiler()\n\nprint(p)\n\nfor key, val in config.profile.items():\n    # This is not the mandatory way to enable tools\n    # I've set up the config to have the keys match\n    # the registered profilers.  You can do it manually\n    # too such as `p.enable(\"line_profiler\")`\n    if val: p.enable(key)\n\n# The profiler has to be initilized before use.  Using it in a context\n# will do it automatically, but to use it as a decorator we should do\n# it manually here:\np.initialize()\nprint(p)\n\nworkload(config)\n```\n\n----------------------------------------\n\nTITLE: Converting PhysicsNeMo Model to PhysicsNeMo Sym Model\nDESCRIPTION: Demonstrates how to convert a PhysicsNemo model to a PhysicsNeMo Sym model using the Arch class, enabling use of Constraints and other PhysicsNeMo Sym features.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo_sym.arch import Arch\nfrom physicsnemo_sym.models.meta import ModelMetaData\n\nclass UNetSym(Arch):\n    def __init__(self, in_channels=1, out_channels=1):\n        super().__init__(meta=ModelMetaData(name=\"UNetSym\"))\n        self.unet = UNet(in_channels, out_channels)\n\n    def forward(self, x):\n        out = self.unet(x[\"input\"])\n        return {\"output\": out}\n```\n\n----------------------------------------\n\nTITLE: Implementing Console Logging with PhysicsNeMo\nDESCRIPTION: Setting up a basic training loop with PhysicsNeMo's console logging. This example demonstrates how to initialize the LaunchLogger and use it to track training metrics like loss and learning rate during the training process.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Create a logger instance\nlogger = LaunchLogger(use_console=True)\nlogger.info(\"Starting Training!\")\n\n# Setup a simple diffusion solver\ntrainer, model, solver, domain = setup_1d_diffusion_solver()\n\n# Setup optimizer, scheduler and criterion\noptimizer = Adam(model.parameters(), lr=1e-2)\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\ncriterion = nn.MSELoss()\n\n# Run a simple training loop\nfor epoch in range(20):\n    loss = trainer.train(model, solver, domain, optimizer, criterion)\n    \n    # Log metrics using the train function of the logger\n    logger.train({\n        \"Learning Rate\": scheduler.get_last_lr()[0],\n        \"Loss\": loss.item(),\n    })\n    \n    scheduler.step()\n\nlogger.info(\"Finished Training!\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple CNN Model Architecture\nDESCRIPTION: Defines a basic CNN model class with a single convolutional layer, ReLU activation, pooling, and fully connected layer.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(16, 10)\n        \n    def forward(self, x):\n        # This is automatically parallel:\n        x = self.conv(x)\n        x = self.relu(x)\n        # This operation reduces on the parallel dimension.\n        # This will leave x as a Partial placement, meaning\n        # it isn't really sharded anymore but the results on the domain\n        # pieces haven't been computed yet.\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n```\n\n----------------------------------------\n\nTITLE: Initializing and Loading FIGConvNet Model with Pre-trained Weights\nDESCRIPTION: Creates a FIGConvUNetDrivAerNet model with specific architecture parameters and loads pre-trained weights from a checkpoint file. Configures grid resolution, channel dimensions, and network structure.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport src.networks\nfrom physicsnemo.models.figconvnet.geometries import GridFeaturesMemoryFormat\n\n\nmodel = src.networks.FIGConvUNetDrivAerNet(\n  aabb_max=[2.75, 1.5, 1.0],\n  aabb_min=[-2.75, -1.5, -1.0],\n  hidden_channels=[16, 16, 16],\n  in_channels=1,\n  kernel_size=5,\n  mlp_channels=[2048, 2048],\n  neighbor_search_type=\"radius\",\n  num_down_blocks=1,\n  num_levels=2,\n  out_channels=1,\n  pooling_layers=[2],\n  pooling_type=\"max\",\n  reductions=[\"mean\"],\n  resolution_memory_format_pairs=[\n    (GridFeaturesMemoryFormat.b_xc_y_z, [  5, 150, 100]),\n    (GridFeaturesMemoryFormat.b_yc_x_z, [250,   3, 100]),\n    (GridFeaturesMemoryFormat.b_zc_x_y, [250, 150,   2]),\n  ],\n  use_rel_pos_encode=True,\n)\n# Load checkpoint.\nchk = torch.load(\"/data/src/physicsnemo/models/fignet/2060187/model_00103.pth\")\nmodel.load_state_dict(chk[\"model\"])\nmodel = model.to(device)\nmodel.eval()\n```\n\n----------------------------------------\n\nTITLE: Running Navier Stokes RNN Example (Seq2Seq)\nDESCRIPTION: Command to run the main script for the Navier Stokes RNN example using the seq2seq (many-to-many) variant of the model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/navier_stokes_rnn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython navier_stokes_rnn.py model_type=seq2seq\n```\n\n----------------------------------------\n\nTITLE: Initializing FNO Model in PhysicsNeMo\nDESCRIPTION: Shows the creation and usage of a Fourier Neural Operator (FNO) model with specific architecture parameters for 2D input processing.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom physicsnemo.models.fno.fno import FNO\nmodel = FNO(\n        in_channels=4,\n        out_channels=3,\n        decoder_layers=2,\n        decoder_layer_size=32,\n        dimension=2,\n        latent_channels=32,\n        num_fno_layers=2,\n        padding=0,\n    )\ninput = torch.randn(32, 4, 32, 32) #(N, C, H, W)\noutput = model(input)\noutput.size()\n```\n\n----------------------------------------\n\nTITLE: Implementing Distributed GraphCast with CuGraphCSC (Python)\nDESCRIPTION: This snippet demonstrates how to set up and use the CuGraphCSC wrapper class for distributed GraphCast. It shows the initialization of the DistributedManager, creation of process groups, and how to work with partitioned tensors in the distributed graph.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.distributed import DistributedManager\nfrom physicsnemo.models.gnn_layers import CuGraphCSC\n\n...\n\n# setup distributed manager and process groups\nDistributedManager.initialize()\nDistributedManager.create_process_subgroup(\n    name=graph_partition_pg_name,\n    size=graph_partition_pg_size,\n)\ndist_manager = DistributedManager()\n\n...\n\n# create wrapper graph\ngraph = CuGraphCSC.from_dgl(\n    dgl_graph,\n    partition_size=graph_partition_pg_size,\n    partition_group_name=graph_partition_pg_name,\n)\n\n...\n\n# get partitioned tensors from global tensors\npart_src_feat = graph.get_src_node_features_in_partition(global_src_feat)\npart_dst_feat = graph.get_dst_node_features_in_partition(global_dst_feat)\npart_edge_feat = graph.get_edge_features_in_partition(global_edge_feat)\n\n# get tensors in local graph from global tensors\nlocal_src_feat = graph.get_src_node_features_in_local_graph(global_src_feat)\n# by design, local_dst_feat and local_edge_feat should be the same as\n# part_dst_feat and part_edge_feat\nlocal_dst_feat = graph.get_dst_node_features_in_local_graph(global_dst_feat)\nlocal_edge_feat = graph.get_edge_features_in_local_graph(global_edge_feat)\n```\n\n----------------------------------------\n\nTITLE: Launching Multi-GPU Training with OpenMPI in Bash\nDESCRIPTION: This command demonstrates how to launch distributed training using OpenMPI's mpirun, an alternative to torchrun for distributed execution.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_gpus> python train.py\n```\n\n----------------------------------------\n\nTITLE: Converting Existing PyTorch Model to PhysicsNeMo Model\nDESCRIPTION: Shows how to convert an existing PyTorch model to a PhysicsNeMo model using the physicsnemo.Module.from_torch method, allowing use of PhysicsNeMo features without modifying the original model code.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.models.module import Module\nfrom physicsnemo.models.meta import ModelMetaData\n\n# Assuming 'model' is your PyTorch model\nphysicsnemo_model = Module.from_torch(model, ModelMetaData(name=\"UNet\"))\n```\n\n----------------------------------------\n\nTITLE: Distributed Training Workflow in PhysicsNeMo\nDESCRIPTION: Demonstrates how to set up a distributed training workflow using PhysicsNeMo's distributed utilities, including initialization, data parallelism, and synchronized logging.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.distributed import init_distributed, get_local_rank, get_world_size\nfrom physicsnemo.distributed.utils import DistributedDataParallel as DDP\nfrom physicsnemo.distributed.utils import DistributedSampler\n\n# Initialize distributed environment\ninit_distributed()\n\n# Initialize the model and move to GPU\nmodel = FNO(modes1=12, modes2=12, width=32).to(get_local_rank())\nmodel = DDP(model)\n\n# Initialize the optimizer\noptimizer = Adam(model.parameters(), lr=1e-3)\n\n# Initialize the data loader with DistributedSampler\ndataset = Darcy2D(batch_size=32 // get_world_size(), shuffle=False)\ndataset.sampler = DistributedSampler(dataset, shuffle=True)\n\n# Training loop\nfor epoch in range(10):\n    dataset.sampler.set_epoch(epoch)\n    for batch in dataset:\n        optimizer.zero_grad()\n        out = model(batch[\"input\"].to(get_local_rank()))\n        loss = torch.mean((out - batch[\"output\"].to(get_local_rank())) ** 2)\n        loss.backward()\n        optimizer.step()\n    \n    # Synchronize logging across all processes\n    if get_local_rank() == 0:\n        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n```\n\n----------------------------------------\n\nTITLE: Training the FNO Darcy Flow Model\nDESCRIPTION: This command initiates the training of the Fourier Neural Operator model for Darcy flow. The training data will be generated on-the-fly during the process.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_fno/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train_fno_darcy.py\n```\n\n----------------------------------------\n\nTITLE: Using FullyConnected Model in PhysicsNeMo with PyTorch\nDESCRIPTION: Demonstrates how to import and use a FullyConnected model from PhysicsNeMo in a PyTorch environment. The example shows model initialization, input generation, and forward pass.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> from physicsnemo.models.mlp.fully_connected import FullyConnected\n>>> model = FullyConnected(in_features=32, out_features=64)\n>>> input = torch.randn(128, 32)\n>>> output = model(input)\n>>> output.shape\ntorch.Size([128, 64])\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU GraphCast Training with torchrun\nDESCRIPTION: Command to launch a data-parallel multi-GPU training using torchrun, allowing specification of both the number of nodes and GPUs per node for distributed training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=<num_nodes> --nproc_per_node=<num_GPUs> python train_graphcast.py\n```\n\n----------------------------------------\n\nTITLE: Converting PyTorch Models to PhysicsNeMo\nDESCRIPTION: Example of converting an existing PyTorch model to a PhysicsNeMo model using the Module.from_torch method.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nimport physicsnemo\nimport torch.nn as nn\n\nclass TorchModel(nn.Module):\n    def __init__(self):\n        super(TorchModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        return self.conv2(x)\n\n@dataclass\nclass ConvMetaData(ModelMetaData):\n    name: str = \"UNet\"\n    # Optimization\n    jit: bool = True\n    cuda_graphs: bool = True\n    amp_cpu: bool = True\n    amp_gpu: bool = True\n\nPhysicsNeMoModel = physicsnemo.Module.from_torch(TorchModel, meta=ConvMetaData())\n```\n\n----------------------------------------\n\nTITLE: Physics-Informed Fine-Tuning of Predictions\nDESCRIPTION: Command to apply physics-informed neural network (PINN) techniques to refine the MeshGraphNet predictions, enforcing physics-based constraints from the Stokes flow equations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython pi_fine_tuning.py\n```\n\n----------------------------------------\n\nTITLE: Training Command for Lid Driven Cavity Flow PINN\nDESCRIPTION: Command to initiate the training of the physics-informed neural network model for lid driven cavity flow simulation. Executes the main training script that handles geometry generation, point cloud sampling, and physics loss computation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/ldc_pinns/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Retraining the DoMINO Model from Checkpoint\nDESCRIPTION: Retrains the DoMINO model starting from a pre-trained checkpoint with a small learning rate for a specified number of epochs. This allows fine-tuning of an existing model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/domino/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nretraining.py\n```\n\n----------------------------------------\n\nTITLE: Implementing Checkpointing with PhysicsNeMo\nDESCRIPTION: Setting up a training loop with PhysicsNeMo's checkpointing capabilities. This example demonstrates how to save model checkpoints during training and load them to resume training from a previous state, handling model weights, optimizer state, and scheduler configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Create a logger instance\nlogger = LaunchLogger(use_console=True)\nlogger.info(\"Starting Training!\")\n\n# Setup a simple diffusion solver\ntrainer, model, solver, domain = setup_1d_diffusion_solver()\n\n# Setup optimizer, scheduler and criterion\noptimizer = Adam(model.parameters(), lr=1e-2)\nscheduler = CosineAnnealingLR(optimizer, T_max=10)\ncriterion = nn.MSELoss()\n\n# Setup checkpointing directory\nos.makedirs(\"checkpoints\", exist_ok=True)\n\nstart_epoch = 0\n\n# Check if a checkpoint exists and load it\ncheckpoint_path = \"checkpoints/checkpoint.0.10.pt\"\nmodel_path = \"checkpoints/FourierNeuralOperator.0.10.mdlus\"\nif os.path.exists(checkpoint_path) and os.path.exists(model_path):\n    # Load model, optimizer, scheduler and other metadata\n    try:\n        checkpoint = load_checkpoint(\n            model, checkpoint_path, model_path, optimizer, scheduler\n        )\n        start_epoch = checkpoint[\"epoch\"] + 1  # Start from the next epoch\n    except:\n        logger.warning(\"Failed to load checkpoint. Starting from scratch.\")\n\n# Run a simple training loop\nfor epoch in range(start_epoch, 20):\n    loss = trainer.train(model, solver, domain, optimizer, criterion)\n    \n    # Log metrics using the train function of the logger\n    logger.train({\n        \"Learning Rate\": scheduler.get_last_lr()[0],\n        \"Loss\": loss.item(),\n    })\n    \n    scheduler.step()\n    \n    # Save checkpoint every 5 epochs\n    if (epoch + 1) % 5 == 0:\n        save_checkpoint(\n            model,\n            \"checkpoints/checkpoint.0.10.pt\",\n            \"checkpoints/FourierNeuralOperator.0.10.mdlus\",\n            optimizer=optimizer,\n            scheduler=scheduler,\n            epoch=epoch,\n            metadata={\"loss\": loss.item()},\n        )\n\nlogger.info(\"Finished Training!\")\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training Command\nDESCRIPTION: Example of running FIGConvUNet training on multiple GPUs using mpirun with custom configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np 2 python train.py \\\n    +experiment=drivaernet/figconv_unet \\\n    data.data_path=./dataset/drivaer/ \\\n    'model.hidden_channels=[16, 16, 16, 16]' \\\n    optimizer=adamw \\\n    optimizer.lr=0.1 \\\n    seed=1 \\\n    train.num_epochs=10 \\\n    ~loggers.wandb\n```\n\n----------------------------------------\n\nTITLE: GraphCastNet Model Configuration in Python\nDESCRIPTION: Configuration setup for the GraphCastNet model including partition size, group name, input/output handling, and lat-lon partitioning settings. This snippet shows the initialization parameters for distributed training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel = GraphCastNet(\n    *,\n    partition_size=dist_manager.group_size(graph_partition_pg_name),\n    partition_group_name=graph_partition_pg_name,\n    # simplified data-loading scheme: only rank 0 has valid inputs\n    # model then takes care of scattering these onto participating ranks\n    expect_partitioned_input=False,\n    global_features_on_rank_0=True,\n    # simplilfied loss computation, to allow e.g. the l2_loss_sphere\n    # without having to distribute this loss computation, valid\n    # output is only on rank 0, model aggregates the output accordingly\n    produce_aggregated_output=True,\n    produce_aggregated_output_on_all_ranks=False,\n    # to reduce the number of edges between partitions, we rely\n    # on the lat-long coordinates of vertices and divide them\n    # into partitions based on these instead of their initial IDs\n    use_lat_lon_partitioning=cfg.model.use_lat_lon_partitioning,\n)\n```\n\n----------------------------------------\n\nTITLE: Using PhysicsNeMo Model Registry\nDESCRIPTION: Shows how to use the ModelRegistry class to list available models and instantiate them using the factory method.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.registry import ModelRegistry\n>>> model_registry = ModelRegistry()\n>>> model_registry.list_models()\n['AFNO', 'DLWP', 'FNO', 'FullyConnected', 'GraphCastNet', 'MeshGraphNet', 'One2ManyRNN', 'Pix2Pix', 'SFNO', 'SRResNet']\n>>> FullyConnected = model_registry.factory(\"FullyConnected\")\n>>> model = FullyConnected(in_features=32, out_features=64)\n```\n\n----------------------------------------\n\nTITLE: Training Coupled DLWP Model in Bash\nDESCRIPTION: Command to train the coupled Deep Learning Weather Prediction model. This version likely incorporates both atmospheric and oceanic data for more comprehensive weather forecasting.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp_healpix/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name config_hpx32_coupled_dlwp\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Generating MHD Dataset\nDESCRIPTION: Commands to install required dependencies and generate the magnetohydrodynamics training data using either sequential or parallel processing\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/mhd_pino/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npython3 dedalus_mhd.py\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npython3 dedalus_mhd_parallel.py\n```\n\n----------------------------------------\n\nTITLE: Running Multi-GPU GraphCast Training with MPI\nDESCRIPTION: Command to launch a data-parallel multi-GPU training using MPI, where num_GPUs specifies the number of GPUs to use for distributed training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> --allow-run-as-root python train_graphcast.py\n```\n\n----------------------------------------\n\nTITLE: Converting PyTorch Model to PhysicsNeMo Model\nDESCRIPTION: Demonstrates how to convert a PyTorch UNet model to a PhysicsNeMo model using the Module class and MetaData. This allows the model to utilize PhysicsNeMo's optimization features.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nfrom physicsnemo.models.meta import ModelMetaData\nfrom physicsnemo.models.module import Module\n\n@dataclass\nclass MetaData(ModelMetaData):\n    name: str = \"UNet\"\n    # Optimization\n    jit: bool = False\n    cuda_graphs: bool = True\n    amp_cpu: bool = True\n    amp_gpu: bool = True\n\nclass UNet(Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNet, self).__init__(meta=MetaData())\n\n        self.enc1 = self.conv_block(in_channels, 64)\n        self.enc2 = self.conv_block(64, 128)\n        # ... rest of the implementation remains the same\n```\n\n----------------------------------------\n\nTITLE: Setting Up Model with FSDP and Domain Decomposition\nDESCRIPTION: Configures the model with both FSDP for data parallelism and spatial decomposition.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef setup_model():\n    # Create base model\n    model = SimpleCNN().to(f\"cuda:{dm.device}\")\n    \n    # Take the module and distributed it over the spatial mesh\n    # This will replicate the model over the spatial mesh\n    # You can, if you want FSDP, get more fancy than this.\n    model = distribute_module(\n        model,\n        device_mesh=spatial_mesh,\n    )\n\n    # Wrap with FSDP\n    # Since the model is replicated, this will mimic DDP behavior.\n    model = FSDP(\n        model,\n        device_mesh=data_mesh,\n        use_orig_params=True\n    )\n\n    \n    return model\n```\n\n----------------------------------------\n\nTITLE: GPU-optimized Random Data Generation in PyTorch\nDESCRIPTION: Improved implementation using torch.normal() to generate random data directly on GPU, eliminating CPU-GPU transfer overhead.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nreturn torch.normal(idx, idx, self.shape, device=\"cuda\" )\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Attention Model with Profiling Decorators in Python\nDESCRIPTION: This diff shows the changes made to instrument the Attention model with profiling decorators. It adds the @profile decorator to forward methods of Attention, MLP, and Block classes.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_3\n\nLANGUAGE: diff\nCODE:\n```\n*** attn_baseline.py\t2025-01-27 07:41:37.749753000 -0800\n--- attn_instrumented.py\t2025-01-27 11:27:09.162202000 -0800\n***************\n*** 1,6 ****\n--- 1,8 ----\n  import torch\n  from torch import nn\n\n+ from physicsnemo.utils.profiling import profile, annotate\n+\n  class Attention(nn.Module):\n      \"\"\"Dummy example Attention mechanism.  Meant not for efficienct computation\n      but to show how to use the profiling tools!\n***************\n*** 26,31 ****\n--- 28,34 ----\n          self.proj = nn.Linear(dim, dim)\n          self.proj_drop = nn.Dropout(proj_drop)\n\n+     @profile\n      def forward(self, x: torch.Tensor) -> torch.Tensor:\n\n          B, N, C = x.shape\n***************\n*** 59,64 ****\n--- 62,68 ----\n          self.fc2 = nn.Linear(hidden_features, out_features)\n          self.drop2 = nn.Dropout(drop)\n\n+     @profile\n      def forward(self, x):\n          x = self.fc1(x)\n          x = self.gelu(x)\n***************\n*** 97,102 ****\n--- 101,107 ----\n              drop=proj_drop,\n          )\n\n+     @profile\n      def forward(self, x: torch.Tensor) -> torch.Tensor:\n          x = x + self.attn(self.norm1(x))\n          x = x + self.mlp(self.norm2(x))\n```\n\n----------------------------------------\n\nTITLE: Training Loop with StaticCaptureTraining\nDESCRIPTION: Example of using PhysicsNeMo's StaticCaptureTraining decorator for optimized training with CUDA Graphs and AMP support.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom physicsnemo.utils import StaticCaptureTraining\n\nmodel = UNet().to(\"cuda\")\ninput = torch.randn(8, 1, 128, 128).to(\"cuda\")\noutput = torch.zeros(8, 1, 64, 64).to(\"cuda\")\n\noptim = torch.optim.Adam(model.parameters(), lr=0.001)\n\n@StaticCaptureTraining(\n    model=model,\n    optim=optim,\n    cuda_graph_warmup=11,\n)\ndef training_step(invar, outvar):\n    predvar = model(invar)\n    loss = torch.sum(torch.pow(predvar - outvar, 2))\n    return loss\n\nfor i in range(20):\n    input.copy_(torch.randn(8, 1, 128, 128).to(\"cuda\"))\n    output.copy_(torch.zeros(8, 1, 64, 64).to(\"cuda\"))\n    loss = training_step(input, output)\n```\n\n----------------------------------------\n\nTITLE: Running Inversion for Anomaly Detection\nDESCRIPTION: Command to use the trained FNO model for gradient computation and anomaly detection. This script loads a starting dataset and applies the trained model to identify anomalies in brain scans.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/brain_anomaly_detection/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython invert.py\n```\n\n----------------------------------------\n\nTITLE: Training Coupled DLOM Model in Bash\nDESCRIPTION: Command to train the coupled Deep Learning Ocean Model. This model focuses on forecasting sea surface temperature and is designed to work in conjunction with the DLWP model for atmosphere-ocean coupling.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp_healpix/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name config_hpx32_coupled_dlom\n```\n\n----------------------------------------\n\nTITLE: Importing PhysicsNeMo Utilities for Training\nDESCRIPTION: This snippet shows the necessary imports for setting up a basic training workflow in PhysicsNeMo, including model, data, and optimization utilities.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_training_example.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.models import FNO\nfrom physicsnemo.data import Darcy2D\nfrom physicsnemo.utils import StaticCaptureTraining\nfrom physicsnemo.optim import Adam\n\nimport torch\n```\n\n----------------------------------------\n\nTITLE: Visualizing FIGConvNet Predictions vs Ground Truth\nDESCRIPTION: Creates a visualization comparing the input point cloud, model predictions, and ground truth pressure values. Uses PyVista to render 3D plots with color mapping to pressure values for easy comparison.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncamera_position = [\n    (-3., -4.5, 5),\n    (0.5, 0, 0.6),\n    (0.1, 0.1, 0.9),\n]\n\ndef plot_results(\n    vertices: np.ndarray,\n    pred: np.ndarray,\n    gt: np.ndarray,\n    camera_position,\n    scalar_name: str = \"p\",\n):\n    plotter = pv.Plotter(shape=(1, 3))\n\n    pc = pv.PolyData(vertices)\n    gt_name = scalar_name + \"_gt\"\n    pc[gt_name] = gt\n    pred_name = scalar_name + \"_pred\"\n    pc[pred_name] = pred\n\n    plotter.subplot(0, 0)\n    plotter.add_points(pv.PolyData(vertices))\n    plotter.camera_position = camera_position\n    plotter.camera.zoom(0.5)\n    plotter.add_text(\"Input point cloud\", position=\"upper_left\")\n\n    plotter.subplot(0, 1)\n    plotter.add_mesh(pc, scalars=pred_name, cmap=\"jet\", show_scalar_bar=False)\n    plotter.camera_position = camera_position\n    plotter.camera.zoom(0.5)\n    plotter.add_scalar_bar(title=scalar_name, vertical=True)\n    plotter.add_text(\"Predicted point cloud\", position=\"upper_left\")\n\n    plotter.subplot(0, 2)\n    plotter.add_mesh(pc, scalars=gt_name, cmap=\"jet\", show_scalar_bar=False)\n    plotter.camera_position = camera_position\n    plotter.camera.zoom(0.5)\n    plotter.add_scalar_bar(title=scalar_name + \" \", vertical=True)\n    plotter.add_text(\"GT point cloud\", position=\"upper_left\")\n\n    plotter.show()\n\nplot_results(\n    vertices[0].cpu().numpy(),\n    pred[0].cpu().numpy(),\n    pressure[0].cpu().numpy(),\n    camera_position,\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Super-resolution Fluid Data using Trained Diffusion Model in Python\nDESCRIPTION: This snippet demonstrates how to use the trained diffusion model to generate super-resolution fluid data. It offers two options: one without physics-informed conditioning and one with physics-informed conditioning. The script uses configuration files to set up the generation parameters.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/diffusion/README.md#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\npython train.py --config-name=config_dfsr_generate\n```\n\nLANGUAGE: Python\nCODE:\n```\npython train.py --config-name=config_dfsr_cond_generate\n```\n\n----------------------------------------\n\nTITLE: Computing CRPS Metric in Python using PhysicsNeMo\nDESCRIPTION: This example demonstrates how to compute the Continuous Ranked Probability Score (CRPS) using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.metrics.general import crps\n>>> x = torch.randn((1_000,1))\n>>> y = torch.randn((1,))\n>>> crps.crps(x, y)\ntensor([0.8023])\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training for FourCastNet\nDESCRIPTION: Launches a multi-GPU training session using mpirun, specifying the number of GPUs to use.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python train_era5.py provide_script_parameters_here\n```\n\n----------------------------------------\n\nTITLE: Retrieving Global Tensors from Partitioned Data in Python\nDESCRIPTION: Code for aggregating partitioned tensor features into global tensors using graph operations. This includes source node features, destination node features, and edge features.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nglobal_src_feat = graph.get_global_src_node_features(part_src_feat)\nglobal_dst_feat = graph.get_global_dst_node_features(part_dst_feat)\nglobal_edge_feat = graph.get_global_edge_features(part_edge_feat)\n```\n\n----------------------------------------\n\nTITLE: Training Nested FNO Model on Multiple GPUs\nDESCRIPTION: MPI commands to train the model using two different reference configurations on two GPUs\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -n 2 python train_nested_darcy.py +model=ref0\nmpirun -n 2 python train_nested_darcy.py +model=ref1\n```\n\n----------------------------------------\n\nTITLE: Main Training Script\nDESCRIPTION: Implements the main training script that sets up the model, optimizer, and runs multiple training epochs.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef main():\n    # Create model and optimizer\n    model = setup_model()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n    \n    # Train for 5 epochs\n    for epoch in range(5):\n        if dm.rank == 0:\n            print(f\"Epoch {epoch+1}\")\n        train_epoch(model, optimizer, criterion)\n        \n    # Cleanup\n    DistributedManager.cleanup()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Dataset for CorrDiff\nDESCRIPTION: Python code snippet demonstrating the structure of a custom dataset class for use with CorrDiff, including the required __getitem__ method.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndef __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]:\n    \"\"\"\n    Returns:\n        Tuple containing:\n        - img_clean: Target high-resolution data [output_channels, height, width]\n        - img_lr: Input low-resolution data [input_channels, height, width]\n        - lead_time_label: (Optional) Lead time information [1]\n    \"\"\"\n    # Your implementation here\n    # For basic implementation without lead time:\n    return img_clean, img_lr\n    # If including lead time information:\n    # return img_clean, img_lr, lead_time_label\n```\n\n----------------------------------------\n\nTITLE: Initializing MLFlow Logger in PhysicsNeMo\nDESCRIPTION: Importing necessary modules for MLFlow integration in PhysicsNeMo. These imports are required to set up MLFlow for experiment tracking alongside the standard console logging functionality.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom physicsnemo.core import LaunchLogger, initialize_mlflow\nfrom physicsnemo.datapipes.benchmarks import setup_1d_diffusion_solver\n```\n\n----------------------------------------\n\nTITLE: Training the MeshGraphNet Model for Stokes Flow\nDESCRIPTION: Command to start the training process for the MeshGraphNet model that will learn to predict velocity and pressure fields from polygon geometry.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: PyTorch UNet Implementation\nDESCRIPTION: Basic PyTorch implementation of a UNet model with convolutional and upconvolutional blocks.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport torch.nn as nn\n\nclass UNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1):\n        super(UNet, self).__init__()\n\n        self.enc1 = self.conv_block(in_channels, 64)\n        self.enc2 = self.conv_block(64, 128)\n\n        self.dec1 = self.upconv_block(128, 64)\n        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n\n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2)\n        )\n\n    def upconv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x1 = self.enc1(x)\n        x2 = self.enc2(x1)\n        x = self.dec1(x2)\n        return self.final(x)\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training with MPI\nDESCRIPTION: Command to train the FNO model using data parallelism across multiple GPUs. This requires MPI and distributes the training workload to speed up the process.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/brain_anomaly_detection/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <Number of GPUs> python train_FNO.py\n```\n\n----------------------------------------\n\nTITLE: Training Diffusion Model for Fluid Super-resolution in Python\nDESCRIPTION: This snippet shows how to train the diffusion model for fluid super-resolution. It provides two options: one without physics-informed conditioning and one with physics-informed conditioning. The script uses configuration files to set up the training parameters.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/diffusion/README.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npython train.py --config-name=config_dfsr_train\n```\n\nLANGUAGE: Python\nCODE:\n```\npython train.py --config-name=config_dfsr_cond_train\n```\n\n----------------------------------------\n\nTITLE: Training the MeshGraphNet Model\nDESCRIPTION: Python command to start training the MeshGraphNet model. Includes an additional command for multi-GPU training using MPI.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mgn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python train.py\n```\n\n----------------------------------------\n\nTITLE: Building PhysicsNeMo from Source\nDESCRIPTION: Commands to build the PhysicsNeMo Python package from source by cloning the repository and installing it using pip.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_4\n\nLANGUAGE: Bash\nCODE:\n```\ngit clone git@github.com:NVIDIA/physicsnemo.git && cd physicsnemo\n\npip install --upgrade pip\npip install .\n```\n\n----------------------------------------\n\nTITLE: Updated Code Path for Training from Object Store using MSC with Zarr\nDESCRIPTION: Example showing how to update existing code to use Multi-Storage Client for accessing data from an object store instead of the local file system. Only the input path changes, using the MSC protocol prefix.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/multi_storage_client/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninput_path = \"msc://cwb-diffusions/2023-01-24-cwb-4years.zarr\"\nzarr.open_consolidated(input_path)\n```\n\n----------------------------------------\n\nTITLE: Training CorrDiff Regression Model (Bash)\nDESCRIPTION: Command to start training the regression model for CorrDiff using the HRRR-Mini dataset configuration. This command uses the train.py script with a specific configuration file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name=config_training_hrrr_mini_regression.yaml\n```\n\n----------------------------------------\n\nTITLE: Distributed StormCast Training with Torchrun\nDESCRIPTION: Example of distributed training for StormCast models using torchrun across 8 GPUs on a single node with a custom configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/stormcast/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=1 --nproc_per_node=8 train.py --config-name <your_distributed_training_config>\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Trained Lagrangian MeshGraphNet Model\nDESCRIPTION: Command to run inference using a trained model on test data. Specifies data directory, test sequence count, model checkpoint directory, and output location for generated animations and error metrics.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py +experiment=water \\\n    data.data_dir=/data/Water \\\n    data.test.num_sequences=4 \\\n    resume_dir=/data/models/lmgn/water \\\n    output=/data/models/lmgn/water/inference\n```\n\n----------------------------------------\n\nTITLE: Implementing Training Loop\nDESCRIPTION: Defines the training loop for one epoch with forward pass, loss calculation, and optimization steps.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef train_epoch(model, optimizer, criterion):\n    model.train()\n    \n    for i in range(10):  # 10 training steps\n        # Get sharded data\n        inputs, targets = create_sample_data()\n        \n        # Forward pass\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, targets)\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if dm.rank == 0 and i % 2 == 0:\n            print(f\"Step {i}, Loss: {loss.item():.4f}\")\n```\n\n----------------------------------------\n\nTITLE: Advanced FIGConvUNet Training Command\nDESCRIPTION: Extended training command with custom model parameters, optimizer settings, and other configuration overrides.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython train.py \\\n    +experiment=drivaernet/figconv_unet \\\n    data.data_path=./dataset/drivaer/ \\\n    'model.hidden_channels=[16, 16, 16, 16]' \\\n    optimizer=adamw \\\n    optimizer.lr=0.1 \\\n    seed=1 \\\n    train.num_epochs=10 \\\n    ~loggers.wandb\n```\n\n----------------------------------------\n\nTITLE: Starting Diagnostic Precipitation Model Training from Scratch\nDESCRIPTION: Command to execute the training script for the precipitation diagnostic model. This starts the training process from scratch using configuration settings from the diagnostic_precip.yaml file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train_diagnostic_precip.py\n```\n\n----------------------------------------\n\nTITLE: Installing Pre-commit Hooks for PhysicsNeMo Development\nDESCRIPTION: These commands install and set up pre-commit hooks for the PhysicsNeMo project. Pre-commit is required for development and helps ensure proper code formatting and passing CI checks before commits are made.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install pre-commit\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Trained MeshGraphNet Model\nDESCRIPTION: Command to execute inference using the trained model to predict velocity and pressure fields for new geometries in the test dataset.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Downloading Data for Darcy Flow Model\nDESCRIPTION: Commands to install required packages and download the dataset for the Darcy flow physics-informed machine learning model. This prepares the environment for running the examples.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_physics_informed/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npython download_data.py\n```\n\n----------------------------------------\n\nTITLE: Enabling Mixed Precision and Model Compilation Changes\nDESCRIPTION: Code changes showing the addition of mixed precision training using torch.amp.autocast and model compilation with torch.compile. Also enables CUDNN benchmarking.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_10\n\nLANGUAGE: diff\nCODE:\n```\n< torch.backends.cudnn.benchmark = True\n52,53d50\n<     model = torch.compile(model)\n<\n63,65c60,61\n<             with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n<                 with annotate(domain=\"forward\", color=\"blue\"):\n<                     output = model(image)\n---\n>             with annotate(domain=\"forward\", color=\"blue\"):\n>                 output = model(image)\n106d101\n```\n\n----------------------------------------\n\nTITLE: Marking Shared Weights in Distributed GraphCast Model (Python)\nDESCRIPTION: This snippet shows how to mark the weights of a GraphCast model as shared across distributed processes. This is necessary for proper gradient reduction in the backward pass of distributed training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.distributed import mark_module_as_shared\n\n...\n\n\nmodel_with_shared_weights = GraphCast(...)\nmark_module_as_shared(model_with_shared_weights)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for FNO Darcy Flow Project\nDESCRIPTION: This command installs all required dependencies for the Fourier Neural Operator model from the requirements.txt file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_fno/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Training Physics-Informed Model for Datacenter Airflow Prediction\nDESCRIPTION: This command initiates the training of a variant model that incorporates physics losses in addition to data loss. This approach is beneficial in low-data scenarios.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/datacenter/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train_physics_informed.py\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training with Data Parallelism\nDESCRIPTION: Commands for running distributed training across multiple GPUs using MPI, with a note about using '--allow-run-as-root' when running in Docker containers.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python train.py +experiment=ahmed/mgn data.data_dir=/data/ahmed_body/\n```\n\n----------------------------------------\n\nTITLE: Implementing Mesh Visualization Functions for DrivAerNet Data\nDESCRIPTION: Defines functions to visualize the DrivAerNet meshes showing both the original geometry and the pressure distribution. Creates side-by-side comparisons of car surface models with ground truth pressure data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Design id 0001 corresponds to DrivAer_F_D_WM_WW_0001.vtk file which belongs to the test set.\ndesign_ids = [\"0001\"]\n\n\ncamera_position = [\n    (-3., -4.5, 5),\n    (1, 0, 0.6),\n    (0.1, 0.1, 0.9),\n]\n\n\ndef create_mesh_vis(\n    mesh: pv.PolyData,\n    plotter: pv.Plotter,\n    camera_position,\n\n):\n    plotter.subplot(0, 0)\n    # Solid mesh visualization\n    plotter.add_mesh(mesh, color=\"lightgrey\")\n    plotter.camera_position = camera_position\n    plotter.add_text(\"Mesh\", position=\"upper_left\")\n\n\ndef create_mesh_vis_gt(\n    mesh: pv.PolyData,\n    scalar_name: str,\n    plotter: pv.Plotter,\n    camera_position,\n):\n    plotter.subplot(0, 1)\n    # Solid mesh visualization with scalar.\n    plotter.add_mesh(\n        mesh,\n        scalars=scalar_name,\n        cmap=\"jet\",\n        clim=(-600, 400),\n        show_scalar_bar=False,\n    )\n    plotter.camera_position = camera_position\n    plotter.add_text('GT Pressure', position='upper_right')\n\n\ndef visualize_meshes(\n    output_dir: Path = None,\n):\n    for design in design_ids:\n        mesh_file = vtk_path / f\"DrivAer_F_D_WM_WW_{design}.vtk\"\n        mesh = pv.read(mesh_file)\n\n        plotter = pv.Plotter(shape=(1, 2))\n        # Create input mesh vis.\n        create_mesh_vis(mesh, plotter, camera_position)\n        # Create GT pressure vis.\n        create_mesh_vis_gt(mesh, \"p\", plotter, camera_position)\n\n        if output_dir:\n            output_dir.mkdir(parents=True, exist_ok=True)\n            plotter.save_graphic(output_dir / f\"{design}_gt_p_mesh.pdf\")\n        else:\n            plotter.show()\n\n\noutput_dir = None\n# Uncomment and update the below to render to pdf files instead.\n# output_dir = Path(\"/data/src/physicsnemo/data/DrivAerNet/vis\")\nvisualize_meshes(output_dir)\n```\n\n----------------------------------------\n\nTITLE: Continuing Diagnostic Model Training from Latest Checkpoint\nDESCRIPTION: Command to resume training from the most recent checkpoint. This allows training to continue from where it left off without starting over.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython train_diagnostic_precip.py +training.load_epoch=latest\n```\n\n----------------------------------------\n\nTITLE: PyTorch Model Compilation Example\nDESCRIPTION: Simple example showing how to enable PyTorch's model compilation feature using torch.compile() for potential performance improvements through kernel fusion.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmodel = torch.compile(model)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Distributed Environment and Device Mesh\nDESCRIPTION: Initializes the distributed environment and creates a 2D mesh for hybrid parallelism with data parallel and spatial decomposition dimensions.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Initialize distributed environment\nDistributedManager.initialize()\ndm = DistributedManager()\n\n# Create a 2D mesh for hybrid parallelism\n# First dimension for data parallel, second for spatial decomposition\nmesh = dm.initialize_mesh((-1, 2), mesh_dim_names=[\"data\", \"spatial\"])\n\n# Get submeshes for different parallel strategies\ndata_mesh = mesh[\"data\"]      # For FSDP\nspatial_mesh = mesh[\"spatial\"] # For spatial decomposition\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training Using MPI\nDESCRIPTION: Command to launch distributed training across multiple GPUs using MPI, which improves training speed through data parallelism.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python train.py\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training - Bash\nDESCRIPTION: Command to launch training across multiple GPUs using MPI.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python train.py\n```\n\n----------------------------------------\n\nTITLE: Downloading the Lennard Jones System Dataset with Python\nDESCRIPTION: Command to download the Molecular Dynamics dataset for the Lennard Jones system. Uses gdown library to retrieve the dataset and the download_data.py script to process it.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/molecular_dynamics/lennard_jones/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install gdown\npython download_data.py\n```\n\n----------------------------------------\n\nTITLE: Importing PhysicsNeMo Profiling Utilities in Python\nDESCRIPTION: This snippet demonstrates how to import the main profiling tools provided by PhysicsNeMo. These include the Profiler class, profile decorator, and annotate function, which are used for various profiling tasks in the framework.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom physicsnemo.utils.profiling import Profiler, profile, annotate\n```\n\n----------------------------------------\n\nTITLE: Training Standard MGN Model on Ahmed Body Dataset\nDESCRIPTION: Command to train the MeshGraphNet model on the Ahmed Body dataset, with additional examples showing how to customize model parameters, optimizer settings, and enable logging with Weights & Biases.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=ahmed/mgn data.data_dir=/data/ahmed_body/\n```\n\nLANGUAGE: bash\nCODE:\n```\npython train.py \\\n    +experiment=ahmed/mgn \\\n    data.data_dir=/data/ahmed_body/ \\\n    model.processor_size=10 \\\n    optimizer.lr=0.0003 \\\n    loggers.wandb.mode=online\n```\n\n----------------------------------------\n\nTITLE: Evaluating the Diagnostic Precipitation Model\nDESCRIPTION: Command to evaluate a trained model against out-of-sample data. This computes performance metrics such as RMSE and saves the results for further analysis.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython eval_diagnostic_precip.py +training.load_epoch=latest\n```\n\n----------------------------------------\n\nTITLE: Training Transolver for Darcy Flow with Fixed Dataset\nDESCRIPTION: This command runs the training script for the Transolver model using a fixed dataset, which corresponds to the settings used in the original Transolver paper. It requires pre-generated data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_transolver/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train_transolver_darcy_fix.py\n```\n\n----------------------------------------\n\nTITLE: Training and Testing Commands\nDESCRIPTION: Commands to run the training and testing scripts for both the encoding-decoding model and sequence model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mesh_reduced/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\npython test.py\npython train_sequence.py\npython test_sequence.py\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using ShardTensor in Python\nDESCRIPTION: Demonstrates how to create and work with ShardTensor, including initialization of distributed environment, creation of device mesh, tensor scattering with uneven sharding, and tensor redistribution. Shows core functionality for distributed tensor operations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.shardtensor.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch.distributed.device_mesh import DeviceMesh \nfrom torch.distributed.tensor.placement_types import Shard\nfrom physicsnemo.distributed import DistributedManager\nfrom physicsnemo.distributed.shard_tensor import ShardTensor, scatter_tensor\n\ndef main():\n    # Initialize distributed environment\n    DistributedManager.initialize()\n    dm = DistributedManager()\n\n    # Create a 1D device mesh - by default, a -1 will use all devices\n    # (For a 2D mesh, -1 will work to infer a single dimension in a mesh tensor)\n    mesh = dm.initialize_mesh((-1,), mesh_dim_names=[\"spatial\"])\n\n    # Create a tensor on rank 0\n    if dist.rank == 0:\n        tensor = torch.randn(100, 64)\n    else:\n        tensor = None\n\n    # Scatter the tensor across devices with uneven sharding\n    # This will automatically determine appropriate local sizes\n    sharded = scatter_tensor(\n        tensor,\n        global_src=0, \n        mesh=mesh,\n        placements=(Shard(0),)  # Shard along first dimension\n    )\n\n    # Work with local portions\n    local_tensor = sharded.to_local()\n    \n    # Redistribute to different sharding scheme\n    new_sharded = sharded.redistribute(\n        placements=(Shard(1),)  # Change to shard along second dimension\n    )\n```\n\n----------------------------------------\n\nTITLE: Training the MeshGraphNet Model\nDESCRIPTION: Command to start the model training process. Training parameters can be configured in the config.yaml file, with options for different geometry types (healthy, pathological, or mixed).\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/bloodflow_1d_mgn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Train Physics Informed Neural Operator Model\nDESCRIPTION: Command to start the training process for the PINO model on shallow water equations using physics-informed constraints.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_nonlinear_pino/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train_swe_nl_pino.py\n```\n\n----------------------------------------\n\nTITLE: Training the MeshGraphNet Model for Lennard Jones System\nDESCRIPTION: Command to execute the Lennard Jones system training script which uses MeshGraphNet to predict atomic forces. Trains a model that maps atom positions to forces in a Lennard Jones system.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/molecular_dynamics/lennard_jones/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython lennard_jones_system.py\n```\n\n----------------------------------------\n\nTITLE: Training CorrDiff Model on Multiple GPUs\nDESCRIPTION: Command to initiate distributed training of a CorrDiff model across multiple GPUs or nodes using torchrun.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=<NUM_NODES> --nproc_per_node=<NUM_GPUS_PER_NODE> train.py\n```\n\n----------------------------------------\n\nTITLE: Training StormCast Regression Model\nDESCRIPTION: Command for training the StormCast regression model by specifying the 'regression' configuration and providing an experiment name.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/stormcast/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name regression training.experiment_name=regression\n```\n\n----------------------------------------\n\nTITLE: Running Navier Stokes RNN Example (One-to-Many)\nDESCRIPTION: Command to run the main script for the Navier Stokes RNN example, which uses the default one-to-many prediction model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/navier_stokes_rnn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython navier_stokes_rnn.py\n```\n\n----------------------------------------\n\nTITLE: Running Distributed Training Command\nDESCRIPTION: Command to launch distributed training across 4 GPUs in a 2x2 configuration using torchrun.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --nproc_per_node=4 train_cnn.py\n```\n\n----------------------------------------\n\nTITLE: Training Transolver for Darcy Flow with Dynamic Data Generation\nDESCRIPTION: This command runs the training script for the Transolver model using dynamically generated data for each batch. It follows PhysicsNeMo's default settings.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_transolver/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train_transolver_darcy.py\n```\n\n----------------------------------------\n\nTITLE: Training Diffusion Model Command for Weather Data\nDESCRIPTION: Bash command for running the diffusion model training script with various parameters including output directory, configuration file, and logging options.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/regen/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd training\npython3 train_diffusions.py \\\n  --outdir /expts \\\n  --tick 100 \\\n  --config_file ./config/hrrr.yaml \\\n  --config_name unconditional_diffusion_downscaling_a2s_v3_1_oklahoma \\\n  --log_to_wandb True \\\n  --run_id 0\n```\n\n----------------------------------------\n\nTITLE: Downloading DrivAer ML Dataset\nDESCRIPTION: Downloads the DrivAer ML dataset using a provided script or from the Hugging Face repository. This dataset contains 500 parametrically morphed variants of the DrivAer notchback generic vehicle.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/domino/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndownload_aws_dataset.sh\n```\n\n----------------------------------------\n\nTITLE: Training Nested FNO Model on Single GPU\nDESCRIPTION: Commands to train the model using two different reference configurations on a single GPU\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train_nested_darcy.py +model=ref0\npython train_nested_darcy.py +model=ref1\n```\n\n----------------------------------------\n\nTITLE: Generating Training Dataset for Nested Darcy Flow\nDESCRIPTION: Script execution to generate training, validation, and out-of-sample datasets stored in ./data directory\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython generate_nested_darcy.py\n```\n\n----------------------------------------\n\nTITLE: Generation Script with Custom Parameters\nDESCRIPTION: Example command for running the generation process with custom checkpoint paths, dataset configuration, and ensemble settings using Hydra's configuration system.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\npython generate.py --config-name=config_generate_custom.yaml \\\n  ++generation.io.res_ckpt_filename=/path/to/diffusion/checkpoint.mdlus \\\n  ++generation.io.reg_ckpt_filename=/path/to/regression/checkpoint.mdlus \\\n  ++dataset.type=path/to/your/dataset.py::CustomDataset \\\n  ++generation.num_ensembles=10\n```\n\n----------------------------------------\n\nTITLE: Running Model Inference\nDESCRIPTION: Command to perform inference using a trained model. The specific model and test graphs need to be specified in the config.yaml file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/bloodflow_1d_mgn/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py\n```\n\n----------------------------------------\n\nTITLE: Capturing NSight Systems Trace for Python Application\nDESCRIPTION: Command to capture a detailed performance trace using NSight Systems profiler. Enables Python sampling, CUDA tracing, NVTX annotations, OS runtime events, and CUDA library traces like cuBLAS and cuDNN.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nnsys profile --python-sampling=true --trace=cuda,nvtx,osrt,cublas,cudnn --python-backtrace=cuda python workload.py\n```\n\n----------------------------------------\n\nTITLE: Creating and Sharding Sample Data\nDESCRIPTION: Generates sample data and converts it to ShardTensor for spatial decomposition across devices.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef create_sample_data(batch_size=32, height=32, width=64):\n    # Create random data\n    data = torch.randn(batch_size, 3, height, width, device=f\"cuda:{dm.device}\")\n    labels = torch.randint(0, 10, (batch_size,), device=f\"cuda:{dm.device}\")\n    \n    # Convert to ShardTensor for spatial decomposition\n    placements = (Shard(2),)  # Shard H dimensions\n    data = ShardTensor.from_local(\n        data,\n        device_mesh=spatial_mesh,\n        placements=placements\n    )\n\n    # For the labels, we can leverage DTensor to distribute them:\n    labels = ShardTensor.from_dtensor(\n        distribute_tensor(labels,\n            device_mesh=spatial_mesh,\n            placements=(Replicate(),)\n        )\n    )\n    \n    return data, labels\n```\n\n----------------------------------------\n\nTITLE: Running Data Processing Script for DoMINO Model\nDESCRIPTION: Processes VTP/VTU files and converts them to NPY format for faster processing in the DoMINO datapipe. This prepares the DrivAerML dataset for training and validation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/domino/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nprocess_data.py\n```\n\n----------------------------------------\n\nTITLE: Launching Multi-GPU Training with torchrun in Bash\nDESCRIPTION: This snippet shows the command to launch distributed training using torchrun, which is PyTorch's distributed launcher tool. It specifies the number of nodes and processes per node for distributed training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.rst#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=1 --nproc_per_node=<num_gpus> train.py\n```\n\n----------------------------------------\n\nTITLE: Training FourCastNet Model\nDESCRIPTION: Runs the training script for FourCastNet, specifying paths for training data, validation data, and statistics directory.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train_era5.py train_dir=path_to_train_dir validation_dir=path_to_val_dir stats_dir=path_to_stats_dir\n```\n\n----------------------------------------\n\nTITLE: Training with Weights & Biases Logging\nDESCRIPTION: Command to train the model with Weights & Biases logging enabled for monitoring progress and loss metrics. Requires an active W&B account.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=water data.data_dir=/data/Water loggers.wandb.mode=online\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for FourCastNet\nDESCRIPTION: Installs the required dependencies for the FourCastNet project using pip.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Converting Simulation Files to DGL Graphs\nDESCRIPTION: Python command to convert the downloaded VTP simulation files into graph structures compatible with Deep Graph Library (DGL). This creates a new 'graphs' folder within the raw_dataset directory.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/bloodflow_1d_mgn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd ..\npython generate_graphs.py\n```\n\n----------------------------------------\n\nTITLE: Preprocessing the Stokes Flow Dataset\nDESCRIPTION: Command to execute the preprocessing script that distributes the data randomly across training, validation, and test directories for model training and evaluation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython preprocess.py\n```\n\n----------------------------------------\n\nTITLE: Training the FNO Model in Python\nDESCRIPTION: Command to train the Fourier Neural Operator model using a single GPU. This script loads the wavefield dataset and trains the FNO to predict subsequent timesteps based on initial inputs.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/brain_anomaly_detection/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train_FNO.py\n```\n\n----------------------------------------\n\nTITLE: Enabling PyTorch Profiler Configuration\nDESCRIPTION: Code snippet showing how to enable the PyTorch profiler through configuration settings for detailed performance analysis.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\np.enable(\"torch\")\n\nworkload(config)\n```\n\n----------------------------------------\n\nTITLE: Training the DoMINO Model\nDESCRIPTION: Starts the training process for the DoMINO model using configuration settings specified in config.yaml. This trains the model on the processed DrivAerML dataset.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/domino/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntrain.py\n```\n\n----------------------------------------\n\nTITLE: Installing Multi-Storage Client with Various Object Storage Dependencies\nDESCRIPTION: Installation commands for Multi-Storage Client with different backend options, including basic installation and specialized versions for different cloud storage providers.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/multi_storage_client/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Using Online Statistical Methods in Python with PhysicsNeMo\nDESCRIPTION: This example demonstrates how to use online (out-of-memory) statistical methods for computing means and variances using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> from physicsnemo.metrics.general import ensemble_metrics as em\n>>> x = torch.randn((1_000, 2)) # Interpret as 1_000 members of size (2,).\n>>> torch.mean(x, dim = 0) # Compute mean of entire data.\ntensor([-0.0545,  0.0267])\n>>> x0, x1 = x[:500], x[500:] # Split data into two.\n>>> M = em.Mean(input_shape = (2,)) # Must pass shape of data\n>>> M(x0) # Compute mean of initial batch.\ntensor([-0.0722,  0.0414])\n>>> M.update(x1) # Update with second batch.\ntensor([-0.0545,  0.0267])\n```\n\n----------------------------------------\n\nTITLE: Creating DataLoader for DrivAerNet Dataset\nDESCRIPTION: Instantiates a WebDataset-based dataloader for the DrivAerNet dataset with preprocessing for point cloud sampling. Configures the number of points to sample from each car surface model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport src.data\n\n\nnum_points = 65536 #2048\ndataset = src.data.DrivAerNetDataModule(\n    drivaer_orig_path.parent / \"drivaernet_webdataset\",\n    num_points=num_points,\n    preprocessors=[\n        src.data.drivaernet_datamodule.DrivAerNetPreprocessor(num_points)\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Setup Configuration for Custom Model Package\nDESCRIPTION: Example setup.py and pyproject.toml configuration for registering a custom model with PhysicsNeMo via entry points.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# setup.py\n\nfrom setuptools import setup, find_packages\n\nsetup()\n```\n\nLANGUAGE: python\nCODE:\n```\n# pyproject.toml\n\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"MyPackage\"\ndescription = \"My Neural Network Zoo.\"\nversion = \"0.1.0\"\n\n[project.entry-points.\"physicsnemo.models\"]\nMyPhysicsNeMoModel = \"mypackage.models.MyPhysicsNeMoModel:MyPhysicsNeMoModel\"\n```\n\n----------------------------------------\n\nTITLE: Using Synthetic Dataset for GraphCast Training\nDESCRIPTION: Command to train GraphCast with a synthetic dataset, which is useful for trying out the model without access to the ERA5 dataset. It's recommended to set num_samples_per_year_train to a small number when using this option.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython train_graphcast.py synthetic_dataset=true\n```\n\n----------------------------------------\n\nTITLE: Training Lagrangian MeshGraphNet on Water Dataset\nDESCRIPTION: Command to train the MeshGraphNet model on the Water dataset with specific experiment configuration. Specifies the data directory path.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=water data.data_dir=/data/Water\n```\n\n----------------------------------------\n\nTITLE: Console Logger Output in Terminal\nDESCRIPTION: Example output from the console logger showing training progress information including metrics like learning rate, loss, and execution time per iteration and epoch.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nWarp 0.10.1 initialized:\n   CUDA Toolkit: 11.5, Driver: 12.2\n   Devices:\n     \"cpu\"    | x86_64\n     \"cuda:0\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:1\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:2\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:3\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:4\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:5\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:6\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:7\" | Tesla V100-SXM2-16GB-N (sm_70)\n   Kernel cache: /root/.cache/warp/0.10.1\n/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n\nYou may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n* 'schema_extra' has been renamed to 'json_schema_extra'\n  warnings.warn(message, UserWarning)\n[21:23:57 - main - INFO] Starting Training!\nModule physicsnemo.datapipes.benchmarks.kernels.initialization load on device 'cuda:0' took 73.06 ms\nModule physicsnemo.datapipes.benchmarks.kernels.utils load on device 'cuda:0' took 314.91 ms\nModule physicsnemo.datapipes.benchmarks.kernels.finite_difference load on device 'cuda:0' took 149.86 ms\n[21:24:02 - train - INFO] Epoch 0 Metrics: Learning Rate =  4.437e-03, Loss =  1.009e+00\n[21:24:02 - train - INFO] Epoch Execution Time:  5.664e+00s, Time/Iter:  1.133e+03ms\n[21:24:06 - train - INFO] Epoch 1 Metrics: Learning Rate =  1.969e-03, Loss =  6.040e-01\n[21:24:06 - train - INFO] Epoch Execution Time:  4.013e+00s, Time/Iter:  8.025e+02ms\n...\n[21:25:32 - train - INFO] Epoch 19 Metrics: Learning Rate =  8.748e-10, Loss =  1.384e-01\n[21:25:32 - train - INFO] Epoch Execution Time:  4.010e+00s, Time/Iter:  8.020e+02ms\n[21:25:32 - main - INFO] Finished Training!\n```\n\n----------------------------------------\n\nTITLE: Computing Statistical Entropy in Python using PhysicsNeMo\nDESCRIPTION: This example shows how to compute the statistical entropy of a random variable using a histogram with the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>> from physicsnemo.metrics.general import entropy\n>>> entropy.entropy_from_counts(counts, bins)\ntensor(0.4146)\n```\n\n----------------------------------------\n\nTITLE: Running StormCast Inference\nDESCRIPTION: Command for running inference with trained StormCast models using a specified inference configuration file that points to regression and diffusion model checkpoints.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/stormcast/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py --config-name <your_inference_config>\n```\n\n----------------------------------------\n\nTITLE: Pulling PhysicsNeMo Docker Image from NVIDIA Container Registry\nDESCRIPTION: Command to pull the recommended PhysicsNeMo docker image from the NVIDIA Container Registry (NGC).\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\ndocker pull nvcr.io/nvidia/physicsnemo/physicsnemo:25.03\n```\n\n----------------------------------------\n\nTITLE: Training BSMS MGN Model with Multi-scale Layers\nDESCRIPTION: Command to train the Bistride Multiscale MeshGraphNet model with custom layer settings and cache directory for improved performance.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=ahmed/bsms_mgn \\\n    data.data_dir=. \\\n    data.train.num_layers=6 \\\n    data.val.num_layers=6 \\\n    data.train.cache_dir=./cache_dir \\\n    data.val.cache_dir=./cache_dir \\\n    model.num_mesh_levels=6 \\\n```\n\n----------------------------------------\n\nTITLE: Importing Packages and Initializing Environment for FIGConvNet Inference\nDESCRIPTION: Sets up the Python environment by importing necessary packages like numpy, pyvista, torch, and warp. Initializes CUDA device settings for GPU acceleration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nimport sys\n\nimport numpy as np\nimport pyvista as pv\nimport torch\nimport warp as wp\n\nif sys.path[0] != \"..\":\n    sys.path.insert(0, \"..\")\n\ndevice = torch.device(\"cuda:0\")\ntorch.cuda.device(device)\nwp.init()\nwp.set_device(str(device))\n\n```\n\n----------------------------------------\n\nTITLE: Running Inference on Trained Model\nDESCRIPTION: Python command to run inference using the trained model, which will save predictions for the test dataset as GIF animations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mgn/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py\n```\n\n----------------------------------------\n\nTITLE: Training DLWP Model in Python\nDESCRIPTION: This command initiates the training process for the DLWP model. It runs the main training script 'train_dlwp.py' which likely contains the model definition, data loading, and training loop.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train_dlwp.py\n```\n\n----------------------------------------\n\nTITLE: Installing PhysicsNeMo with Launch Extras\nDESCRIPTION: Command to install PhysicsNeMo with the 'launch' extras from the repository directory, which is required for training diagnostic precipitation models.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install .[launch]\n```\n\n----------------------------------------\n\nTITLE: Computing Ranks in Python using PhysicsNeMo\nDESCRIPTION: This snippet shows how to compute ranks of observations with respect to given counts and bins using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.metrics.general import histogram, calibration\n>>> x = torch.randn((1_000,1))\n>>> y = torch.randn((1,))\n>>> bins, counts = histogram.histogram(x, bins = 10)\n>>> ranks = calibration.find_rank(bins, counts, y)\ntensor([0.1920])\n```\n\n----------------------------------------\n\nTITLE: Initializing Dependencies and Patches for ShardTensor\nDESCRIPTION: Sets up required imports and patches Conv2d operation to work with ShardTensor functionality.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/fsdp_and_shard_tensor.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\n# This is necessary to patch Conv2d to work with ShardTensor\nfrom physicsnemo.distributed.shard_utils import patch_operations\n\nimport torch.nn as nn\n\nfrom physicsnemo.distributed import DistributedManager\nfrom physicsnemo.distributed.shard_tensor import ShardTensor\nfrom torch.distributed.tensor import distribute_module, distribute_tensor\nfrom torch.distributed.tensor.placement_types import Shard, Replicate\nfrom torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n```\n\n----------------------------------------\n\nTITLE: Setting Weights & Biases API Key via Environment Variable\nDESCRIPTION: Command to set the Weights & Biases API key as an environment variable before running the training script, avoiding the need to include it in the command line.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_API_KEY=key\npython train.py ...\n```\n\n----------------------------------------\n\nTITLE: Training CorrDiff Model on Single GPU\nDESCRIPTION: Command to start training a CorrDiff model on a single GPU using a specified configuration file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name=config_training_taiwan_regression.yaml\n```\n\n----------------------------------------\n\nTITLE: Generating Samples from Trained CorrDiff Model\nDESCRIPTION: Command to generate predictions using a trained CorrDiff model and save them in netCDF format.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython generate.py --config-name=config_generate_taiwan.yaml\n```\n\n----------------------------------------\n\nTITLE: Training StormCast Diffusion Model\nDESCRIPTION: Command for training the StormCast diffusion model which requires a pre-trained regression model as specified in the diffusion configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/stormcast/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name diffusion training.experiment_name=diffusion\n```\n\n----------------------------------------\n\nTITLE: Configuring Dataset Paths for DrivAerNet Visualization\nDESCRIPTION: Sets up file paths to the DrivAerNet dataset and output directory for visualizations. This configuration is needed before accessing the dataset files.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Path to the dataset and pressure VTK files.\n# Note: update `drivaer_orig_path` as needed.\ndrivaer_orig_path = Path(\"/data/src/physicsnemo/data/DrivAerNet/mini\")\nvtk_path = drivaer_orig_path / \"SurfacePressureVTK\"\n\noutput_dir = drivaer_orig_path.parent / \"vis\"\n```\n\n----------------------------------------\n\nTITLE: Computing Cumulative Density Function (CDF) in Python using PhysicsNeMo\nDESCRIPTION: This snippet demonstrates how to compute the Cumulative Density Function (CDF) of a PyTorch tensor using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> bins, cdf = histogram.cdf(x, bins = 10)\n>>> bins\ntensor([-3.7709, -3.0633, -2.3556, -1.6479, -0.9403, -0.2326,  0.4751,  1.1827,\n        1.8904,  2.5980,  3.3057])\n>>> cdf\ntensor([0.0030, 0.0120, 0.0550, 0.2050, 0.4320, 0.6860, 0.8920, 0.9730, 0.9970,\n        1.0000])\n```\n\n----------------------------------------\n\nTITLE: Installing Required PyTorch Dependencies\nDESCRIPTION: Commands to install torch-scatter and torch-cluster libraries needed for graph node aggregation using conda.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mesh_reduced/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda install pytorch-scatter -c pyg\nconda install pytorch-cluster -c pyg\n```\n\n----------------------------------------\n\nTITLE: Generating Predictions with CorrDiff (Bash)\nDESCRIPTION: Command to generate new predictions using trained CorrDiff models. This command uses the generate.py script, specifying paths to both the regression and diffusion model checkpoints.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython generate.py --config-name=\"config_generate_hrrr_mini.yaml\" \\\n  ++generation.io.res_ckpt_filename=</path/to/diffusion/model> \\\n  ++generation.io.reg_ckpt_filename=</path/to/regression/model>\n```\n\n----------------------------------------\n\nTITLE: Launching MLflow UI for DLWP Model Monitoring\nDESCRIPTION: This command starts the MLflow user interface on port 2458 for monitoring the training progress of the DLWP model. MLflow is used for tracking experiments, logging parameters, and visualizing results.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmlflow ui -p 2458\n```\n\n----------------------------------------\n\nTITLE: Training UNet Model for Datacenter Airflow Prediction\nDESCRIPTION: This command starts the training process for the UNet model using the prepared dataset. It can be run on a single GPU or multiple GPUs using MPI.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/datacenter/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <#GPUs> python train.py\n```\n\n----------------------------------------\n\nTITLE: Analyzing Line Profiler Output for Workload Function\nDESCRIPTION: This text snippet shows the output of the line profiler for the workload function. It provides a breakdown of execution time for each line in the function, helping identify performance bottlenecks.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nTotal time: 4.54253 s\nFile: /root/physicsnemo/docs/test_scripts/profiling/annotated_code/workload.py\nFunction: workload at line 30\n\nLine #      Hits         Time  Per Hit   % Time  Line Contents\n==============================================================\n    30                                           @profile\n    31                                           def workload(cfg):\n    32\n    33         1     304686.0 304686.0      0.0      ds = RandomNoiseDataset(cfg[\"shape\"])\n    34\n    35         2     202324.0 101162.0      0.0      loader = DataLoader(\n    36         1        170.0    170.0      0.0          ds,\n    37         1      42921.0  42921.0      0.0          batch_size=cfg[\"batch_size\"],\n    38         1        180.0    180.0      0.0          shuffle = True,\n    39                                               )\n    40\n    41\n    42                                               # Initialize the model:\n    43         3   79343062.0    3e+07      1.7      model = Block(\n    44         1      79202.0  79202.0      0.0          dim = cfg[\"shape\"][-1],\n    45         1      73421.0  73421.0      0.0          num_heads = cfg.model[\"num_heads\"],\n    46         1      52831.0  52831.0      0.0          qkv_bias  = cfg.model[\"qkv_bias\"] ,\n    47         1      50570.0  50570.0      0.0          attn_drop = cfg.model[\"attn_drop\"],\n    48         1      50352.0  50352.0      0.0          proj_drop = cfg.model[\"proj_drop\"],\n    49         1  109143037.0    1e+08      2.4      ).to(\"cuda\")\n    50\n    51         1     107952.0 107952.0      0.0      if cfg[\"train\"]:\n    52         1 2059751411.0    2e+09     45.3          opt = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n    53\n    54         1        270.0    270.0      0.0      times = []\n    55         2      74021.0  37010.5      0.0      with Profiler() as p:\n    56         1       1521.0   1521.0      0.0          start = time.perf_counter()\n    57         9 2022090217.0    2e+08     44.5          for i, batch in enumerate(loader):\n    58         8      74692.0   9336.5      0.0              image = batch[\"image\"]\n    59         8   47176297.0    6e+06      1.0              image = image.to(\"cuda\")\n    60        16     364408.0  22775.5      0.0              with annotate(domain=\"forward\", color=\"blue\"):\n    61         8   85942255.0    1e+07      1.9                  output = model(image)\n    62         8     871577.0 108947.1      0.0              if cfg[\"train\"]:\n    63         8    1728264.0 216033.0      0.0                  opt.zero_grad()\n    64                                                           # Compute the loss:\n    65         8   24881952.0    3e+06      0.5                  loss = loss_fn(output)\n```\n\n----------------------------------------\n\nTITLE: Installing gdown Package for Dataset Download\nDESCRIPTION: Command to install the gdown package, which is required for downloading the dataset used in this example.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/navier_stokes_rnn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install gdown\n```\n\n----------------------------------------\n\nTITLE: Accessing CMIP6 Dataset from AWS S3 Using Zarr with MSC\nDESCRIPTION: Example of using Multi-Storage Client with Zarr to access climate data from the CMIP6 dataset stored in AWS S3. The example demonstrates setting the MSC configuration and using zarr.open to access the data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/multi_storage_client/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport MSC_CONFIG=./msc_config.yaml\npython\n>>> import zarr\n>>> zarr_group = zarr.open(\"msc://cmip6-pds/CMIP6/ScenarioMIP/NOAA-GFDL/GFDL-ESM4/ssp119/r1i1p1f1/day/tas/gr1/v20180701\")\n>>> zarr_group.tree()\n/\n ├── bnds (2,) float64\n ├── height () float64\n ├── lat (180,) float64\n ├── lat_bnds (180, 2) float64\n ├── lon (288,) float64\n ├── lon_bnds (288, 2) float64\n ├── tas (31390, 180, 288) float32\n ├── time (31390,) int64\n └── time_bnds (31390, 2) float64\n```\n\n----------------------------------------\n\nTITLE: Weights and Biases Logger Output Example\nDESCRIPTION: Example output from the Weights and Biases logger showing training progress information including metrics like learning rate, loss, and execution times. The output includes a summary of the run and instructions for syncing with wandb cloud.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nWarp 0.10.1 initialized:\n   CUDA Toolkit: 11.5, Driver: 12.2\n   Devices:\n     \"cpu\"    | x86_64\n     \"cuda:0\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:1\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:2\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:3\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:4\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:5\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:6\" | Tesla V100-SXM2-16GB-N (sm_70)\n     \"cuda:7\" | Tesla V100-SXM2-16GB-N (sm_70)\n   Kernel cache: /root/.cache/warp/0.10.1\n/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n\nYou may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n* 'schema_extra' has been renamed to 'json_schema_extra'\n  warnings.warn(message, UserWarning)\nwandb: Tracking run with wandb version 0.15.12\nwandb: W&B syncing is set to `offline` in this directory.  \nwandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n[21:26:38 - main - INFO] Starting Training!\nModule physicsnemo.datapipes.benchmarks.kernels.initialization load on device 'cuda:0' took 74.11 ms\nModule physicsnemo.datapipes.benchmarks.kernels.utils load on device 'cuda:0' took 310.06 ms\nModule physicsnemo.datapipes.benchmarks.kernels.finite_difference load on device 'cuda:0' took 151.24 ms\n[21:26:48 - train - INFO] Epoch 0 Metrics: Learning Rate =  1.969e-03, Loss =  7.164e-01\n[21:26:48 - train - INFO] Epoch Execution Time:  9.703e+00s, Time/Iter:  9.703e+02ms\n...\n[21:29:47 - train - INFO] Epoch 19 Metrics: Learning Rate =  7.652e-17, Loss =  3.519e-01\n[21:29:47 - train - INFO] Epoch Execution Time:  1.125e+01s, Time/Iter:  1.125e+03ms\n[21:29:47 - main - INFO] Finished Training!\nwandb: Waiting for W&B process to finish... (success).\nwandb: \nwandb: Run history:\nwandb:                    epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\nwandb:     train/Epoch Time (s) ▃▁▃▃▃▃▁█▁▁▁▃▃▃▃▆▁▃▃▆\nwandb:      train/Learning Rate █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\nwandb:               train/Loss █▁▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃\nwandb: train/Time per iter (ms) ▃▁▃▃▃▃▁█▁▁▁▃▃▃▃▆▁▃▃▆\nwandb: \nwandb: Run summary:\nwandb:                    epoch 19\nwandb:     train/Epoch Time (s) 11.24806\nwandb:      train/Learning Rate 0.0\nwandb:               train/Loss 0.35193\nwandb: train/Time per iter (ms) 1124.80645\nwandb: \nwandb: You can sync this run to the cloud by running:\nwandb: wandb sync /workspace/physicsnemo/docs/test_scripts/wandb/wandb/offline-run-20231115_212638-ib4ylq4e\nwandb: Find logs at: ./wandb/wandb/offline-run-20231115_212638-ib4ylq4e/logs\n```\n\n----------------------------------------\n\nTITLE: Training Model - Python\nDESCRIPTION: Basic command to start model training using configured parameters.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Curating ERA5 Dataset - Python\nDESCRIPTION: Script execution for generating a curated dataset from downloaded ERA5 data. Creates zarr dataset with necessary transformations like regridding.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npython curate_era5.py\n```\n\n----------------------------------------\n\nTITLE: Training MHD Models with Different Configurations\nDESCRIPTION: Commands to train different variations of the MHD models including standard FNO with magnetic field evolution, FNO with vector potential, and TFNO with vector potential\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/mhd_pino/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=1 --nproc_per_node=<num_gpus> train_mhd.py\n```\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=1 --nproc_per_node=<num_gpus> train_mhd_vec_pot.py\n```\n\nLANGUAGE: bash\nCODE:\n```\ntorchrun --standalone --nnodes=1 --nproc_per_node=<num_gpus> train_mhd_vec_pot_tfno.py\n```\n\n----------------------------------------\n\nTITLE: Package Requirements List\nDESCRIPTION: A list of required Python packages including data structures (xarray), geospatial plotting (cartopy), visualization (seaborn), CLI tools (click), experiment tracking (wandb), YAML parsing (ruamel.yaml), and parallel computing (dask).\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/regen/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nxarray[io]\ncartopy\nseaborn\nclick\nwandb\nruamel.yaml\ndask\n```\n\n----------------------------------------\n\nTITLE: Initializing Weights and Biases Logger in PhysicsNeMo\nDESCRIPTION: Importing necessary modules for Weights and Biases (wandb) integration in PhysicsNeMo. These imports are required to set up wandb for experiment tracking alongside the standard console logging functionality.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom physicsnemo.core import LaunchLogger, initialize_wandb\nfrom physicsnemo.datapipes.benchmarks import setup_1d_diffusion_solver\n```\n\n----------------------------------------\n\nTITLE: Setting Batch Size for CorrDiff Training (Bash)\nDESCRIPTION: Command to override the total batch size setting when running the training script. This demonstrates how to use Hydra's command line override syntax to modify configuration options at runtime.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train.py ++training.hp.total_batch_size=64  # Sets batch size to 64\n```\n\n----------------------------------------\n\nTITLE: ERA-5 Data Directory Structure for Diagnostic Model Training\nDESCRIPTION: Example directory structure for organizing ERA-5 atmospheric state and precipitation data files. The structure includes training, testing, and out-of-sample datasets, each containing yearly data files.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n├── data_dir\n    ├── train\n    │   ├── 1980.h5\n    │   ├── 1981.h5\n    │   ├── 1982.h5\n    │   ├── ...\n    │   └── 2016.h5\n    ├── test\n    │   ├── 2017.h5\n    ├── out_of_sample\n    │   ├── 2018.h5\n```\n\n----------------------------------------\n\nTITLE: Multi-GPU Training for Diagnostic Precipitation Model\nDESCRIPTION: Command to run training across multiple GPUs using MPI. This enables parallel processing across the specified number of GPUs to accelerate training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/diagnostic/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <NUM_GPUS> python train_diagnostic_precip.py --config-name=\"diagnostic_precip.yaml\"\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Binary Dataset\nDESCRIPTION: Shows the required directory structure for the converted DrivAerML dataset in binary format, including partitions for training, testing and validation data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n├─ partitions\n│  ├─ graph_partitions_1.bin\n│  ├─ graph_partitions_2.bin\n│  ├─ ...\n├─ test_partitions\n│  ├─ graph_partitions_100.bin\n│  ├─ graph_partitions_101.bin\n│  ├─ ...\n├─ validation_partitions\n│  ├─ graph_partitions_200.bin\n│  ├─ graph_partitions_201.bin\n│  ├─ ...\n└─ global_stats.json\n```\n\n----------------------------------------\n\nTITLE: Initializing Checkpointing in PhysicsNeMo\nDESCRIPTION: Importing necessary modules for model checkpointing in PhysicsNeMo. These imports are required to set up the functionality for saving and loading model weights and training state during the training process.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom physicsnemo.core import LaunchLogger\nfrom physicsnemo.core.checkpoint import load_checkpoint, save_checkpoint\nfrom physicsnemo.datapipes.benchmarks import setup_1d_diffusion_solver\n```\n\n----------------------------------------\n\nTITLE: Scoring Generated Samples\nDESCRIPTION: Command to compute deterministic and probabilistic scores for generated samples from a CorrDiff model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython score_samples.py path=<PATH_TO_NC_FILE> output=<OUTPUT_FILE>\n```\n\n----------------------------------------\n\nTITLE: Running Single-GPU GraphCast Training\nDESCRIPTION: Command to train the GraphCast model on a single GPU using the base configurations specified in the config.yaml file. This will launch training with up to 12 steps of fine-tuning.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train_graphcast.py\n```\n\n----------------------------------------\n\nTITLE: Distributed Training with MPI for Lennard Jones System Model\nDESCRIPTION: Command for multi-GPU distributed training using MPI. This enables faster training by distributing the workload across multiple GPUs using Distributed Data Parallel (DDP) training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/molecular_dynamics/lennard_jones/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmpirun -np <num_GPUs> python lennard_jones_system.py\n```\n\n----------------------------------------\n\nTITLE: Signing Git Commits for PhysicsNeMo Contributions\nDESCRIPTION: This command demonstrates how to sign off on a Git commit when contributing to PhysicsNeMo. Using the --signoff option appends the contributor's name and email to the commit message, certifying the contribution's origin.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit commit -s -m \"Add cool feature.\"\n```\n\n----------------------------------------\n\nTITLE: Setting Weights & Biases API Key\nDESCRIPTION: Command to set the Weights & Biases API key as an environment variable for monitoring training progress and visualizing results.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Running Inference with Trained Models\nDESCRIPTION: Command to perform inference using a trained model on test data, specifying the experiment type, data directory, sample count, and checkpoint location. The script saves predictions in .vtp format for visualization.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython inference.py +experiment=drivaernet/mgn \\\n    data.data_dir=/data/DrivAerNet/ \\\n    data.test.num_samples=2 \\\n    resume_dir=./outputs/\n```\n\n----------------------------------------\n\nTITLE: Running PhysicsNeMo Docker Container with Examples\nDESCRIPTION: Commands to launch the PhysicsNeMo container, clone the repository, and run an example. The example shows how to set up the container environment and run a Darcy FNO training example.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\ndocker run --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 --runtime nvidia \\\n--rm -it nvcr.io/nvidia/physicsnemo/physicsnemo:25.03 bash\ngit clone https://github.com/NVIDIA/physicsnemo.git\ncd physicsnemo/examples/cfd/darcy_fno/\npip install warp-lang # install NVIDIA Warp to run the darcy example\npython train_fno_darcy.py\n```\n\n----------------------------------------\n\nTITLE: Basic FIGConvUNet Training Command\nDESCRIPTION: Simple command to start training using the DrivAerNet configuration with dataset sampling enabled.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py \\\n    +experiment=drivaernet/figconv_unet \\\n    data.data_path=./datasets/drivaer/\n```\n\n----------------------------------------\n\nTITLE: Launching MLFlow Server for Remote Training Monitoring\nDESCRIPTION: Command to start MLFlow server for remote access on port 8080\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nmlflow server --host 0.0.0.0 --port 8080\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for AeroGraphNet\nDESCRIPTION: Commands to install the necessary Python libraries for AeroGraphNet, including pyvista, shapely, and vtk for basic functionality and sparse_dot_mkl for BSMS MGN models.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install pyvista shapely vtk\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install sparse_dot_mkl\n```\n\n----------------------------------------\n\nTITLE: ERA5 Data Citation\nDESCRIPTION: Citation for the ERA5 dataset used in the FourCastNet project.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_5\n\nLANGUAGE: text\nCODE:\n```\nHersbach, H., Bell, B., Berrisford, P., Biavati, G., Horányi, A., Muñoz Sabater, J.,\nNicolas, J., Peubey, C., Radu, R., Rozum, I., Schepers, D., Simmons, A., Soci, C.,\nDee, D., Thépaut, J-N. (2018): ERA5 hourly data on pressure levels from 1959 to present.\nCopernicus Climate Change Service (C3S) Climate Data Store (CDS). 10.24381/cds.bd0915c6\n\nHersbach, H., Bell, B., Berrisford, P., Biavati, G., Horányi, A., Muñoz Sabater, J.,\nNicolas, J., Peubey, C., Radu, R., Rozum, I., Schepers, D., Simmons, A., Soci, C.,\nDee, D., Thépaut, J-N. (2018): ERA5 hourly data on single levels from 1959 to present.\nCopernicus Climate Change Service (C3S) Climate Data Store (CDS). 10.24381/cds.adbb2d47\n```\n\n----------------------------------------\n\nTITLE: Initializing Weights & Biases\nDESCRIPTION: Command to log in and initialize Weights & Biases for experiment tracking.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nwandb login\n```\n\n----------------------------------------\n\nTITLE: Downloading the Dataset with Bash Script\nDESCRIPTION: Commands to install the gdown dependency and execute the dataset download script. This fetches the vtp simulation files required for the model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/healthcare/bloodflow_1d_mgn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install gdown\ncd raw_dataset\nbash download_dataset.sh\n```\n\n----------------------------------------\n\nTITLE: Downloading ERA5 Dataset - Python\nDESCRIPTION: Script execution for downloading temporally subsampled ERA5 dataset from ARCO ERA5. Requires ~40TB storage for full dataset, with download time of ~1.5 days on 2.5 Gb/s connection.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npython download_era5.py\n```\n\n----------------------------------------\n\nTITLE: Training DLWP HEALPix Model in Bash\nDESCRIPTION: Command to train the DLWP HEALPix model for weather prediction. This script likely initializes and trains the deep learning model using historical weather data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp_healpix/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Weights & Biases Logging\nDESCRIPTION: Instructions for enabling Weights & Biases logging and setting up the required API key as an environment variable.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Downloading File from Google Drive using gdown in Bash\nDESCRIPTION: This command uses gdown to download a file from Google Drive. It requires the file ID from the Google Drive share link. The --fuzzy flag is used to handle Google Drive's warning page.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_physics_informed/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngdown --fuzzy https://drive.google.com/file/d/1-0Tz1veLcC7LmTqJc3DgC5Q2FRpFAhTB/view?usp=sharing\n```\n\n----------------------------------------\n\nTITLE: Monitoring Training Progress with MLFlow\nDESCRIPTION: Launches the MLFlow UI to monitor training progress on a specified port.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmlflow ui -p 2458\n```\n\n----------------------------------------\n\nTITLE: Computing Histogram of Samples in Python using PhysicsNeMo\nDESCRIPTION: This example shows how to compute a histogram of samples from a PyTorch tensor using the PhysicsNeMo library's histogram function.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> from physicsnemo.metrics.general import histogram\n>>> x = torch.randn(1_000)\n>>> bins, counts = histogram.histogram(x, bins = 10)\n>>> bins\ntensor([-3.7709, -3.0633, -2.3556, -1.6479, -0.9403, -0.2326,  0.4751,  1.1827,\n        1.8904,  2.5980,  3.3057])\n>>> counts\ntensor([  3,   9,  43, 150, 227, 254, 206,  81,  24,   3])\n```\n\n----------------------------------------\n\nTITLE: Launching Multi-GPU Training with SLURM in Bash\nDESCRIPTION: This command shows how to launch distributed training on a SLURM cluster using the srun command, which allocates resources and executes the training script across the allocated nodes.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.distributed.rst#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsrun -n <num_gpus> python train.py\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Package Version Requirement\nDESCRIPTION: Defines the minimum required version of MLflow package as 2.1.1 or newer. This requirement ensures compatibility with the project's MLflow integration features.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_fno/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plain\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Starting MLFlow UI for Training Monitoring\nDESCRIPTION: Command to launch MLFlow user interface for monitoring training progress on port 2458\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmlflow ui -p 2458\n```\n\n----------------------------------------\n\nTITLE: Downloading CWA Dataset with NGC CLI\nDESCRIPTION: Command to download the Central Weather Administration (CWA) dataset from the NGC catalog using the NGC CLI tool.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nngc registry resource download-version \"nvidia/modulus/modulus_datasets_cwa:v1\"\n```\n\n----------------------------------------\n\nTITLE: Reverse Diffusion SDE Formula\nDESCRIPTION: The reverse SDE that enables generation by gradually denoising the image, including both stochastic and deterministic components.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\nd\\mathbf{x} = - \\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})dt + d\\omega_{\\mathbf{x}}\n```\n\n----------------------------------------\n\nTITLE: Sample Python Configuration File Structure\nDESCRIPTION: Example Python code showing the structure of configuration files that define paths to data sources and model files used throughout the project.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/regen/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nisd_path = \"<path to isd data>\"\npath_to_pretrained = \"<path to the pretrained model>\"\npath_to_model_state = \"<path to model state from a training checkpoint>\"\npath_to_hrrr = \"<path to Zarr file containing 2017 HRRR data>\"\nstation_locations = \"<path to station_locations_on_grid.nc generated by preprocess_isd.py>\"\npath_to_isp = \"<path to ISD csv data>\"\nval_station_path = \"<path to validation station locations generated by val_stations.py>\"\n```\n\n----------------------------------------\n\nTITLE: Current Code Path for Training from File System using Zarr\nDESCRIPTION: Example showing the current code path for accessing data from the local file system using Zarr. This represents the code before migrating to MSC.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/multi_storage_client/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ninput_path = \"/code/2023-01-24-cwb-4years.zarr\"\nzarr.open_consolidated(input_path)\n```\n\n----------------------------------------\n\nTITLE: SLURM Cluster Training Command in Bash\nDESCRIPTION: Command for running training on a SLURM cluster with allocated GPUs.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython train.py\n```\n\n----------------------------------------\n\nTITLE: Running MLFlow Server for Remote Training Monitoring\nDESCRIPTION: This command launches the MLFlow server on port 8080 with external access enabled, allowing for monitoring of model training on remote machines.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_fno/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmlflow server --host 0.0.0.0 --port 8080\n```\n\n----------------------------------------\n\nTITLE: Score Function Evaluation through Denoising\nDESCRIPTION: Formula showing how to evaluate the score function using an optimal L2 denoiser D, eliminating the need for direct access to the density function.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_3\n\nLANGUAGE: latex\nCODE:\n```\n\\left( D(\\mathbf{x}; \\sigma) - \\mathbf{x} \\right) / \\sigma^2\n```\n\n----------------------------------------\n\nTITLE: Deterministic ODE Formulation\nDESCRIPTION: The ordinary differential equation formulation introduced by Song et al. that removes the stochastic component for deterministic generation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_4\n\nLANGUAGE: latex\nCODE:\n```\nd\\mathbf{x} = - \\frac{1}{2} \\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})dt\n```\n\n----------------------------------------\n\nTITLE: Scoring Inference Results Command\nDESCRIPTION: Bash commands for evaluating the inference results using the score_inference.py script, comparing model outputs with ground truth data.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/regen/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd paper_figures\npython score_inference.py figure_data/scores/<_my_regen_model_name>\npython score_inference.py -g truth figure_data/scores/hrrr\n```\n\n----------------------------------------\n\nTITLE: Testing the DoMINO Model on VTP/VTU Files\nDESCRIPTION: Tests the trained DoMINO model on VTP/VTU files and writes predictions back to the same files. The evaluation settings are specified in the config file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/domino/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntest.py\n```\n\n----------------------------------------\n\nTITLE: Launching MLFlow UI - Bash\nDESCRIPTION: Command to start MLFlow UI for monitoring training progress on port 2458.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmlflow ui -p 2458\n```\n\n----------------------------------------\n\nTITLE: EDM Generalized ODE Formula\nDESCRIPTION: Comprehensive ODE formula used in EDM that parameterizes the trajectory in terms of sigma and scale functions, defining noise levels and appropriate scaling at different time instances.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_7\n\nLANGUAGE: latex\nCODE:\n```\nd\\mathbf{x} = \\left[ \\dot{s}(t) / s(t) - {s(t)}^2 \\dot{\\sigma}(t) \\sigma(t) \\nabla_{\\mathbf{x}} \\log p(\\mathbf{x}/s(t);\\sigma(t)) \\right] dt\n```\n\n----------------------------------------\n\nTITLE: Building PhysicsNeMo Docker Image for Deployment\nDESCRIPTION: Command to build a Docker image for deploying PhysicsNeMo, targeting the linux/amd64 platform.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\ndocker build -t physicsnemo:deploy \\\n    --build-arg TARGETPLATFORM=linux/amd64 --target deploy -f Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: Running the Gray Scott RNN Model in Python\nDESCRIPTION: Command to execute the Gray Scott RNN example script which includes dataset download, preprocessing, model training and prediction for the 3D Gray-Scott reaction-diffusion system.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/gray_scott_rnn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython gray_scott_rnn.py\n```\n\n----------------------------------------\n\nTITLE: Generating Mesh and Map Files with TempestRemap in Bash\nDESCRIPTION: A sequence of bash commands using the TempestRemap library to generate various mesh and map files. This includes creating lat-lon and cubed-sphere meshes, overlap meshes, and offline maps for coordinate transformations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp/data_curation/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nGenerateRLLMesh \\\n    --lat 721 \\\n    --lon 1440 \\\n    --file out_latlon.g \\\n    --lat_begin 90 \\\n    --lat_end -90 \\\n    --out_format Netcdf4\nGenerateCSMesh \\\n    --res <desired-res> \\\n    --file out_cubedsphere.g \\\n    --out_format Netcdf4\nGenerateOverlapMesh \\\n    --a out_latlon.g \\\n    --b out_cubedsphere.g \\\n    --out overlap_latlon_cubedsphere.g \\\n    --out_format Netcdf4\nGenerateOfflineMap \\\n    --in_mesh out_latlon.g \\\n    --out_mesh out_cubedsphere.g \\\n    --ov_mesh overlap_latlon_cubedsphere.g \\\n    --in_np 1 \\\n    --in_type FV \\\n    --out_type FV \\\n    --out_map map_LL_CS.nc \\\n    --out_format Netcdf4\nGenerateOverlapMesh \\\n    --a out_cubedsphere.g \\\n    --b out_latlon.g \\\n    --out overlap_cubedsphere_latlon.g \\\n    --out_format Netcdf4\nGenerateOfflineMap \\\n    --in_mesh out_cubedsphere.g \\\n    --out_mesh out_latlon.g \\\n    --ov_mesh overlap_cubedsphere_latlon.g \\\n    --in_np 1 \\\n    --in_type FV \\\n    --out_type FV \\\n    --out_map map_CS_LL.nc \\\n    --out_format Netcdf4\n```\n\n----------------------------------------\n\nTITLE: Installing FIGConvUNet Dependencies\nDESCRIPTION: Command to install FIGConvUNet dependencies using pip in a PhysicsNeMo Docker container.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install -e .[figconv]\n```\n\n----------------------------------------\n\nTITLE: Downloading Dataset Commands for Cylinder Flow\nDESCRIPTION: Commands to download and extract the cylinder flow dataset required for training the model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mesh_reduced/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nwget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/modulus/modulus_datasets_cylinder-flow/versions/v1/zip -O modulus_datasets_cylinder-flow_v1.zip\nunzip modulus_datasets_cylinder-flow_v1.zip\nunzip dataset.zip\n```\n\n----------------------------------------\n\nTITLE: Configuring Weights & Biases Integration\nDESCRIPTION: YAML configuration snippet for setting up Weights & Biases integration in CorrDiff training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\nwandb:\n  mode: offline       # Options: \"online\", \"offline\", \"disabled\"\n  results_dir: \"./wandb\"  # Directory to store wandb results\n  watch_model: true  # Whether to track model parameters and gradients\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for DLWP Model in Python\nDESCRIPTION: This command installs the required dependencies for the DLWP model from a requirements file. It ensures all necessary Python packages are available for running the model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Accessing Custom Model via Registry\nDESCRIPTION: Demonstrates how to access a custom registered model through the PhysicsNeMo model registry after installation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.models.rst#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.registry import ModelRegistry\n>>> model_registry = ModelRegistry()\n>>> model_registry.list_models()\n['MyPhysicsNeMoModel', 'AFNO', 'DLWP', 'FNO', 'FullyConnected', 'GraphCastNet', 'MeshGraphNet', 'One2ManyRNN', 'Pix2Pix', 'SFNO', 'SRResNet']\n>>> MyPhysicsNeMoModel = model_registry.factory(\"MyPhysicsNeMoModel\")\n```\n\n----------------------------------------\n\nTITLE: Modifying Training Parameters Using Hydra CLI\nDESCRIPTION: Example of overriding training configuration parameters using Hydra's command-line syntax to adjust the learning rate.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name=config_training_custom.yaml ++training.hp.lr=0.0001\n```\n\n----------------------------------------\n\nTITLE: Basic Variance-Exploding Noise Schedule Formula\nDESCRIPTION: Mathematical formula representing the variance-exploding scheme that adds noise at a constant rate, where the variance grows linearly over time.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_5\n\nLANGUAGE: latex\nCODE:\n```\n\\sigma(t) = \\sqrt{(t)}\n```\n\n----------------------------------------\n\nTITLE: Implementing Attention Layer in Python\nDESCRIPTION: This code snippet defines an Attention class in PyTorch, implementing a simple attention mechanism. It includes methods for initialization and forward pass.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass Attention(nn.Module):\n    \"\"\"Dummy example Attention mechanism.  Meant not for efficienct computation\n    but to show how to use the profiling tools!\n    \"\"\"\n    def __init__(\n        self,\n        dim,\n        num_heads=8,\n        qkv_bias=False,\n        qk_scale=None,\n        attn_drop=0.0,\n        proj_drop=0.0,\n    ):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim**-0.5\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)\n\n    @profile\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n\n        B, N, C = x.shape\n```\n\n----------------------------------------\n\nTITLE: Running Workload with Line Profiler in Bash\nDESCRIPTION: This bash command demonstrates how to run the workload with Python's line profiling enabled. It uses Hydra to configure the profiler.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npython workload.py +profiler.line_profiler=true\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Noise Dataset in Python\nDESCRIPTION: This code snippet defines a RandomNoiseDataset class that generates random data using numpy. It's a simple dataset implementation for demonstration purposes.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nfrom torch.utils.data import Dataset\n\nclass RandomNoiseDataset(Dataset):\n    def __init__(self, shape):\n        self.shape = shape\n\n    def __len__(self):\n        return 100\n\n    def __getitem__(self, idx):\n        return {\n            \"image\": np.random.randn(*self.shape).astype(np.float32),\n        }\n```\n\n----------------------------------------\n\nTITLE: DDIM Noise Schedule Formula\nDESCRIPTION: Mathematical formula for DDIM noise schedule where the standard deviation increases at a constant rate.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_6\n\nLANGUAGE: latex\nCODE:\n```\n\\sigma(t) = t\n```\n\n----------------------------------------\n\nTITLE: Downloading DeepMind's Vortex Shedding Dataset\nDESCRIPTION: Bash commands to navigate to the raw_dataset directory and download the cylinder_flow dataset from DeepMind's repository.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mgn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd raw_dataset\nsh download_dataset.sh cylinder_flow\n```\n\n----------------------------------------\n\nTITLE: Downloading DeepMind's Particle Physics Dataset\nDESCRIPTION: Commands to download the Water dataset from DeepMind's repository to a specified data directory. This dataset is used to train the Lagrangian MeshGraphNet model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd raw_dataset\nbash download_dataset.sh Water /data/\n```\n\n----------------------------------------\n\nTITLE: CPU-based Random Data Generation in PyTorch DataLoader\nDESCRIPTION: Initial CPU-bound implementation of data generation using numpy's random normal distribution, identified as a performance bottleneck.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/profiling.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef gen_single_image(self, idx):\n    return self.rng.normal(loc=idx, scale=idx, size=self.shape).astype(np.float32)\n```\n\n----------------------------------------\n\nTITLE: Setting Up SSH Tunnel for TensorBoard\nDESCRIPTION: Command to create an SSH tunnel for accessing TensorBoard on a remote server.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nssh -L 6006:localhost:6006 <user>@<remote-server-ip>\n```\n\n----------------------------------------\n\nTITLE: Installing NVIDIA TransformerEngine Git Dependency\nDESCRIPTION: Git dependency specification that points to the stable branch of NVIDIA's TransformerEngine repository. Used for including the TransformerEngine as a project dependency.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: git\nCODE:\n```\ngit+https://github.com/NVIDIA/TransformerEngine.git@stable\n```\n\n----------------------------------------\n\nTITLE: Running TensorBoard in a Docker Container with SSH Tunneling\nDESCRIPTION: Commands for setting up TensorBoard logging for XAeroNet models, including exposing the port in Docker, launching TensorBoard, and creating an SSH tunnel to access the dashboard from a local machine.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/xaeronet/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ntensorboard --logdir=/path/to/logdir --port=6006\n```\n\nLANGUAGE: bash\nCODE:\n```\nssh -L 6006:localhost:6006 <user>@<remote-server-ip>\n```\n\n----------------------------------------\n\nTITLE: Installing Required Visualization Libraries\nDESCRIPTION: Pip command to install the pyvista and vtk libraries needed for visualization and processing of the .vtp files used in this example.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install pyvista vtk\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages with pip\nDESCRIPTION: Command for installing the project dependencies from requirements.txt file using pip.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/regen/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Disabling Weights & Biases via Environment Variable\nDESCRIPTION: Command to disable Weights & Biases logging by setting the WANDB_MODE environment variable to 'disabled'.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_MODE='disabled'\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Dependency Version\nDESCRIPTION: Defines the minimum required version of MLflow package using pip requirements format. Sets version 2.1.1 as the minimum compatible version.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Setting Weights & Biases API Key\nDESCRIPTION: Bash command to set the Weights & Biases API key as an environment variable for monitoring training progress and logs.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mgn/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Downloading and Setting Up Dataset for Datacenter CFD Surrogate Model\nDESCRIPTION: These commands download the required dataset from NGC and set up the directory structure for training. It requires NGC CLI and access to NVAIE.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/datacenter/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nngc registry resource download-version \"nvidia/physicsnemo/physicsnemo_datacenter_cfd_dataset:v1\"\nmv physicsnemo_datacenter_cfd_dataset_vv1/datasets .\n```\n\n----------------------------------------\n\nTITLE: Adding License Header to Source Files in PhysicsNeMo\nDESCRIPTION: This code snippet provides the standard license header that should be included at the beginning of all source code files in the PhysicsNeMo project. It includes copyright information and the Apache 2.0 license details.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.\n# SPDX-FileCopyrightText: All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Computing Wasserstein Metric in Python using PhysicsNeMo\nDESCRIPTION: This example demonstrates how to compute the Wasserstein metric between two distributions using their CDFs with the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.metrics.general import wasserstein, histogram\n>>> x = torch.randn((1_000,1))\n>>> y = torch.randn((1_000,1))\n>>> bins, cdf_x = histogram.cdf(x)\n>>> bins, cdf_y = histogram.cdf(y, bins = bins)\n>>> wasserstein(bins, cdf_x, cdf_y)\n>>> wasserstein.wasserstein(bins, cdf_x, cdf_y)\ntensor([0.0459])\n```\n\n----------------------------------------\n\nTITLE: Downloading the Stokes Flow Dataset\nDESCRIPTION: Bash command to download the dataset containing numerical simulations of Stokes flow in a pipe domain obstructed by random polygons. The dataset includes 1000 samples with mesh and flow information for training the MeshGraphNet model.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/stokes_mgn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbash download_dataset.sh\n```\n\n----------------------------------------\n\nTITLE: Running Interrogate Code Documentation Check\nDESCRIPTION: Command to run the interrogate tool for checking code documentation coverage. Configures various ignore rules for init methods, private functions, and specific method names. Targets 99% documentation coverage for the physicsnemo directory.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ninterrogate \\\n  --ignore-init-method \\\n  --ignore-init-module \\\n  --ignore-module \\\n  --ignore-private \\\n  --ignore-semiprivate \\\n  --ignore-magic \\\n  --fail-under 99 \\\n  --exclude '[setup.py]' \\\n  --ignore-regex forward \\\n  --ignore-regex reset_parameters \\\n  --ignore-regex extra_repr \\\n  --ignore-regex MetaData \\\n  -vv \\\n  --color \\\n  ./physicsnemo/\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Dependency in Requirements File\nDESCRIPTION: This specifies that the project requires MLflow version 2.1.1 or newer. MLflow is a platform for the machine learning lifecycle, including experiment tracking, reproducible runs, and model management.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/dlwp/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Specifying trimesh Library Dependency for Physics Nemo\nDESCRIPTION: Defines the required version of the trimesh library (4.5.0) needed for the Physics Nemo project. Trimesh is a Python library for loading and using triangular meshes with various operations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/xaeronet/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntrimesh==4.5.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker for TensorBoard\nDESCRIPTION: Docker run command to enable port forwarding for TensorBoard integration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -p 6006:6006 ...  # Include port forwarding\n```\n\n----------------------------------------\n\nTITLE: Displaying Training Script Help Information with Hydra\nDESCRIPTION: Command to view all available configuration options for the training script using Hydra's help system, with an additional command showing how to get more detailed error messages when troubleshooting Hydra configurations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --help\n```\n\nLANGUAGE: bash\nCODE:\n```\nHYDRA_FULL_ERROR=1 python train.py ...\n```\n\n----------------------------------------\n\nTITLE: Hydra Debug Command\nDESCRIPTION: Command to enable detailed Hydra error messages for debugging configuration issues.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nHYDRA_FULL_ERROR=1 python train.py ...\n```\n\n----------------------------------------\n\nTITLE: Download Training Data for Shallow Water Equations\nDESCRIPTION: Command to download and preprocess the training and validation datasets from the PINO Applications Github repository.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_nonlinear_pino/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython download_data.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Dataset in YAML\nDESCRIPTION: YAML configuration snippet for specifying a custom dataset in the CorrDiff training configuration file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\ndataset:\n    type: path/to/your/dataset.py::CustomDataset  # Path to file::class name\n    # All parameters below will be passed to your dataset's __init__\n    data_path: /path/to/your/data\n    stats_path: /path/to/statistics.json  # Optional normalization stats\n    input_variables: [\"temperature\", \"pressure\"]  # Example parameters\n    output_variables: [\"high_res_temperature\"]\n    invariant_variables: [\"topography\"]  # Optional static fields\n    # Add any other parameters needed by your dataset class\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow Dependency for Lagrangian MeshGraphNet\nDESCRIPTION: Commands to install TensorFlow, which is required to load data in the .tfrecord format. Limited to version 2.17.1 or earlier for compatibility.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"tensorflow<=2.17.1\"\n```\n\n----------------------------------------\n\nTITLE: Installing Makani for SFNO - Bash\nDESCRIPTION: Commands to clone and install PhysicsNeMo Makani, required for SFNO model training.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:NVIDIA/makani.git\ncd makani\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Evaluating Trained Nested FNO Model\nDESCRIPTION: Command to evaluate the trained model performance\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython evaluate_nested_darcy.py\n```\n\n----------------------------------------\n\nTITLE: Setting Small Model Configuration in YAML\nDESCRIPTION: YAML configuration snippet showing how to configure a smaller model architecture for testing and debugging purposes.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\ndefaults:\n    - model_size: mini  # Use smaller architecture for testing\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Nested FNO Project\nDESCRIPTION: Command to install required project dependencies from requirements.txt file\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Running StormCast Regression Training with Command-line Overrides\nDESCRIPTION: Example command for training the StormCast regression model with custom batch size parameter specified through command-line overrides using Hydra configuration.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/stormcast/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name regression training.batch_size=4\n```\n\n----------------------------------------\n\nTITLE: Specifying Dependencies for PhysicsNemo Project in Python\nDESCRIPTION: This code snippet defines the required Python packages for the PhysicsNemo project. It specifies TensorFlow version 2.15 for generating TFRecord files, and optionally includes PyVista version 0.32.1 for data preprocessing from raw simulations.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/additive_manufacturing/sintering_physics/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# pyvista is optional, required if need to run data preprocessing from raw simulation\n# pyvista==0.32.1\ntensorflow==2.15 # generate tfrecord\n```\n\n----------------------------------------\n\nTITLE: Initializing Console Logger in PhysicsNeMo\nDESCRIPTION: Importing necessary modules for console logging in PhysicsNeMo. These imports are required to set up the basic logging functionality that outputs training progress to the console.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom physicsnemo.core import LaunchLogger\nfrom physicsnemo.datapipes.benchmarks import setup_1d_diffusion_solver\n```\n\n----------------------------------------\n\nTITLE: Viewing Hydra Configuration Options\nDESCRIPTION: Command to display all available configuration options for the training script. The project uses Hydra for experiment configuration management.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --help\n```\n\n----------------------------------------\n\nTITLE: Building PhysicsNeMo CI Docker Image\nDESCRIPTION: Command to build a Docker image for continuous integration of PhysicsNeMo, targeting the linux/amd64 platform.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/README.md#2025-04-23_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\ndocker build -t physicsnemo:ci \\\n    --build-arg TARGETPLATFORM=linux/amd64 --target ci -f Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Bash\nDESCRIPTION: Command to install required project dependencies from requirements.txt file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Using Weighted Reductions in Python with PhysicsNeMo\nDESCRIPTION: This snippet shows how to use weighted mean and variance reductions provided by the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n>>> from physicsnemo.metrics.general import reduction\n>>> x = torch.randn((1_000,))\n>>> weights = torch.cos(torch.linspace(-torch.pi/4, torch.pi/4, 1_000))\n>>> wm = reduction.WeightedMean(weights)\n>>> wm(x, dim = 0)\ntensor(0.0365)\n>>> wv = reduction.WeightedVariance(weights)\n>>> wv(x, dim = 0)\ntensor(1.0148)\n```\n\n----------------------------------------\n\nTITLE: Checkpoint Loading Output Example\nDESCRIPTION: Example terminal output when loading a checkpoint in PhysicsNeMo. This shows the logging information during the checkpoint loading process, confirming that the model state, optimizer state, and scheduler state were successfully restored.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\n>>> python test_scripts/test_basic_checkpointing.py\n...\n[23:11:09 - checkpoint - INFO] Loaded model state dictionary /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/FourierNeuralOperator.0.10.mdlus to device cuda\n[23:11:09 - checkpoint - INFO] Loaded checkpoint file /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/checkpoint.0.10.pt to device cuda\n[23:11:09 - checkpoint - INFO] Loaded optimizer state dictionary\n[23:11:09 - checkpoint - INFO] Loaded scheduler state dictionary\n...\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Version Requirement\nDESCRIPTION: This snippet defines the minimum required version of MLflow for the NVIDIA PhysicsNemo project. It uses the greater than or equal to operator to ensure compatibility with MLflow version 2.1.1 and above.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/unified_recipe/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Displaying Diffusion Intuition Image in Markdown\nDESCRIPTION: This snippet uses HTML within Markdown to center-align and display an image illustrating the intuition behind diffusion models. The image shows the process of denoising from random noise to a clear image.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<p align=\"center\">\n<img src=\"../../docs/img/diffusion_doc/diffusion_intuition.png\" />\n</p>\n```\n\n----------------------------------------\n\nTITLE: Shallow Water Equations Mathematical Formulation (LaTeX)\nDESCRIPTION: This LaTeX snippet presents the mathematical formulation of the nonlinear shallow water equations used in the project. It includes equations for fluid column height and velocity fields, along with initial conditions and coefficients.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_2\n\nLANGUAGE: latex\nCODE:\n```\n\\begin{align}\n\\frac{\\partial(\\eta)}{\\partial t}+\\frac{\\partial(\\eta u)}{\\partial x}+\n\\frac{\\partial(\\eta v)}{\\partial y}&=0,  \\\\\n\\frac{\\partial(\\eta u)}{\\partial t}+\n\\frac{\\partial}{\\partial x}\\left(\\eta u^{2}+\\frac{1}{2} g\n\\eta^{2}\\right)+\n\\frac{\\partial(\\eta u v)}{\\partial y}&=\\nu\\left(u_{xx} + u_{yy}\\right), \\\\\n\\frac{\\partial(\\eta v)}{\\partial t}+\\frac{\\partial(\\eta u v)}{\\partial x}+\n\\frac{\\partial}{\\partial y}\\left(\\eta v^{2}+\\frac{1}{2} g\n\\eta^{2}\\right)&=\\nu\\left(v_{xx} + v_{yy}\\right),\n\\end{align}\n```\n\nLANGUAGE: latex\nCODE:\n```\n\\begin{align}\n\\textrm{with} \\quad \\eta(x,y,0) = \\eta_{0}(x,y),\\ u(x,y,0)=0,\\\nv(x,y,0)=0,\\ \\quad\nx,y \\in[0,1), \\ t \\in[0,1],\n\\end{align}\n```\n\n----------------------------------------\n\nTITLE: Model Checkpoint Save Logs\nDESCRIPTION: System logs showing the automatic saving of model state dictionaries and training checkpoints at different training intervals. Files are saved in .mdlus and .pt formats.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/tutorials/simple_logging_and_checkpointing.rst#2025-04-23_snippet_11\n\nLANGUAGE: plaintext\nCODE:\n```\n[23:11:11 - checkpoint - INFO] Saved model state dictionary: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/FourierNeuralOperator.0.10.mdlus\n[23:11:12 - checkpoint - INFO] Saved training checkpoint: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/checkpoint.0.10.pt\n[23:11:16 - checkpoint - INFO] Saved model state dictionary: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/FourierNeuralOperator.0.15.mdlus\n[23:11:16 - checkpoint - INFO] Saved training checkpoint: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/checkpoint.0.15.pt\n[23:11:21 - checkpoint - INFO] Saved model state dictionary: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/FourierNeuralOperator.0.20.mdlus\n[23:11:21 - checkpoint - INFO] Saved training checkpoint: /workspace/release_23.11/docs_upgrade/physicsnemo/docs/checkpoints/checkpoint.0.20.pt\n```\n\n----------------------------------------\n\nTITLE: Forward Diffusion SDE Formula\nDESCRIPTION: The basic stochastic differential equation describing the forward diffusion process where noise is gradually added to the image.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_1\n\nLANGUAGE: latex\nCODE:\n```\nd\\mathbf{x} = d\\omega\n```\n\n----------------------------------------\n\nTITLE: Message Passing in Graph Neural Networks Mathematical Formulation (LaTeX)\nDESCRIPTION: This LaTeX snippet defines the mathematical formulation of message passing in Graph Neural Networks. It includes equations for message preparation and aggregation steps in the GNN layers.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/swe_distributed_gnn/README.md#2025-04-23_snippet_3\n\nLANGUAGE: latex\nCODE:\n```\nm_{uv}^{(k)} = COMBINE^{(k)} \\left(\nf_{\\theta_{src}}^{(k)}\\left(h_{src,u}^{(k-1)}\\right),\nf_{\\theta_{dst}}^{(k)}\\left(h_{dst,v}^{(k-1)}\\right),\nf_{\\theta_{edge}}^{(k)}\\left(h_{edge,uv}^{(k-1)}\n\\right)\\right)\n```\n\nLANGUAGE: latex\nCODE:\n```\nh_{dst,v}^{(k)} = AGG_{u: u\\in \\mathcal{N}(v)} \\left(m_{uv}^{(k)}\\right)\n```\n\nLANGUAGE: latex\nCODE:\n```\nh_{dst,v}^{(k)} = AGG_{u: u\\in \\mathcal{N}(v)} \\left(\nf_{\\theta_{src}}^{(k)}\\left(h_{src,u}^{(k-1)}\\right),\nf_{\\theta_{dst}}^{(k)}\\left(h_{dst,v}^{(k-1)}\\right),\nf_{\\theta_{edge}}^{(k)}\\left(h_{edge,uv}^{(k-1)}\\right)\\right\n)\n```\n\n----------------------------------------\n\nTITLE: Citation for FourCastNet Research\nDESCRIPTION: BibTeX citation for the FourCastNet research paper.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/fcn_afno/README.md#2025-04-23_snippet_4\n\nLANGUAGE: text\nCODE:\n```\n@article{pathak2022fourcastnet,\n  title={Fourcastnet: A global data-driven high-resolution weather model\n         using adaptive fourier neural operators},\n  author={Pathak, Jaideep and Subramanian, Shashank and Harrington, Peter\n          and Raja, Sanjeev and Chattopadhyay, Ashesh and Mardani, Morteza\n          and Kurth, Thorsten and Hall, David and Li, Zongyi and Azizzadenesheli, Kamyar\n          and Hassanzadeh, Pedram and Kashinath, Karthik and Anandkumar, Animashree},\n  journal={arXiv preprint arXiv:2202.11214},\n  year={2022}\n}\n```\n\n----------------------------------------\n\nTITLE: Disabling Weights & Biases via Command Line Parameter\nDESCRIPTION: Command to disable Weights & Biases logging by passing the wb_mode parameter when launching the training script.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython train_graphcast.py wb_mode=disabled\n```\n\n----------------------------------------\n\nTITLE: Installing Multi-Storage Client with Various Backend Dependencies\nDESCRIPTION: Commands to install Multi-Storage Client with specific dependencies for different object storage backends including POSIX, NVIDIA AIStore, Azure, AWS S3, Google Cloud Storage, and Oracle Cloud.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/multi_storage_client/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# POSIX file systems.\npip install multi-storage-client\n\n# NVIDIA AIStore.\npip install \"multi-storage-client[aistore]\"\n\n# Azure Blob Storage.\npip install \"multi-storage-client[azure-storage-blob]\"\n\n# AWS S3 and S3-compatible object stores.\npip install \"multi-storage-client[boto3]\"\n\n# Google Cloud Storage (GCS).\npip install \"multi-storage-client[google-cloud-storage]\"\n\n# Oracle Cloud Infrastructure (OCI) Object Storage.\npip install \"multi-storage-client[oci]\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Detailed Hydra Error Messages\nDESCRIPTION: Command to enable detailed error information for Hydra configuration issues by setting the HYDRA_FULL_ERROR environment variable.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/lagrangian_mgn/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nHYDRA_FULL_ERROR=1 python train.py ...\n```\n\n----------------------------------------\n\nTITLE: Denoising Score Matching ODE Formula\nDESCRIPTION: Mathematical equation showing how the image is modified at each step by moving toward higher or lower data density at the current noise level. The formula includes scale factors and gradient terms.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/README.md#2025-04-23_snippet_8\n\nLANGUAGE: latex\nCODE:\n```\nd\\mathbf{x} = - \\dot{\\sigma}(t) \\sigma(t) \\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x}; \\sigma(t))dt\n```\n\n----------------------------------------\n\nTITLE: RST Documentation Tree Definition\nDESCRIPTION: Sphinx documentation tree structure defining the organization of PhysicsNeMo documentation including tutorials, API references, and example categories.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/index.rst#2025-04-23_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n   :maxdepth: 2\n   :caption: PhysicsNeMo Tutorials\n   :name: PhysicsNeMo Tutorials\n\n   tutorials/simple_training_example.rst\n   tutorials/simple_logging_and_checkpointing.rst\n   tutorials/profiling.rst\n   tutorials/fsdp_and_shard_tensor.rst\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Dependency Requirement\nDESCRIPTION: Defines the minimum required version of MLflow as 2.1.1 or higher. MLflow is an open-source platform for managing the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_nested_fnos/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Starting TensorBoard Server\nDESCRIPTION: Command to start a TensorBoard server for monitoring training metrics.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ntensorboard --logdir=/path/to/logdir --port=6006\n```\n\n----------------------------------------\n\nTITLE: Specifying MLflow Version Requirement\nDESCRIPTION: Defines the minimum required version of MLflow package as 2.1.1 using pip's greater-than-or-equal-to version specifier.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/pangu_weather/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmlflow>=2.1.1\n```\n\n----------------------------------------\n\nTITLE: Computing Anomaly Correlation Coefficient in Python using PhysicsNeMo\nDESCRIPTION: This snippet demonstrates how to compute the Anomaly Correlation Coefficient, a metric widely used in weather and climate sciences, using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> import numpy as np\n>>> from physicsnemo.metrics.climate.acc import acc\n>>> channels = 1\n>>> img_shape = (32, 64)\n>>> time_means = np.pi / 2 * np.ones((channels, img_shape[0], img_shape[1]), dtype=np.float32)\n>>> x = np.linspace(-180, 180, img_shape[1], dtype=np.float32)\n>>> y = np.linspace(-90, 90, img_shape[0], dtype=np.float32)\n>>> xv, yv = np.meshgrid(x, y)\n>>> pred_tensor_np = np.cos(2 * np.pi * yv / (180))\n>>> targ_tensor_np = np.cos(np.pi * yv / (180))\n>>> pred_tensor = torch.from_numpy(pred_tensor_np).expand(channels, -1, -1)\n>>> targ_tensor = torch.from_numpy(targ_tensor_np).expand(channels, -1, -1)\n>>> means_tensor = torch.from_numpy(time_means)\n>>> lat = torch.from_numpy(y)\n>>> acc(pred_tensor, targ_tensor, means_tensor, lat)\ntensor([0.9841])\n```\n\n----------------------------------------\n\nTITLE: Running FIGConvNet Inference on DrivAerNet Sample\nDESCRIPTION: Executes inference on a sample from the DrivAerNet dataset using the loaded model. Takes a point cloud as input and predicts pressure values at each surface point, then denormalizes the output.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/figconvnet/notebooks/figconvnet_vis.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntorch.set_grad_enabled(False)\n\nsample = next(iter(dataset.train_dataloader()))\nvertices = model.data_dict_to_input(sample)\npressure = sample[\"time_avg_pressure\"]\nnormalized_pred, drag_pred = model(vertices)\npred = dataset.normalizer.decode(normalized_pred)\n```\n\n----------------------------------------\n\nTITLE: Computing Histograms for Batched Data in Python using PhysicsNeMo\nDESCRIPTION: This snippet demonstrates how to compute histograms for batched 2D data using the PhysicsNeMo library, including entropy calculation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> from physicsnemo.metrics.general import histogram, entropy\n>>> x = torch.randn((1_000, 3, 3))\n>>> bins, counts = histogram.histogram(x, bins = 10)\n>>> bins.shape, counts.shape\n(torch.Size([11, 3, 3]), torch.Size([10, 3, 3]))\n>>> entropy.entropy_from_counts(counts, bins)\ntensor([[0.5162, 0.4821, 0.3976],\n        [0.5099, 0.5309, 0.4519],\n        [0.4580, 0.4290, 0.5121]])\n```\n\n----------------------------------------\n\nTITLE: Training CorrDiff Diffusion Model (Bash)\nDESCRIPTION: Command to start training the diffusion model for CorrDiff, specifying the path to the pre-trained regression model checkpoint. This command uses the train.py script with a diffusion-specific configuration file.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/generative/corrdiff/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython train.py --config-name=config_training_hrrr_mini_diffusion.yaml \\\n  ++training.io.regression_checkpoint_path=</path/to/regression/model>\n```\n\n----------------------------------------\n\nTITLE: Computing RMSE Metric in Python using PhysicsNeMo\nDESCRIPTION: This snippet demonstrates how to compute the Root Mean Squared Error (RMSE) between two PyTorch tensors using the PhysicsNeMo library.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/docs/api/physicsnemo.metrics.rst#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import torch\n>>> from physicsnemo.metrics.general.mse import rmse\n>>> pred_tensor = torch.randn(16, 32)\n>>> targ_tensor = torch.randn(16, 32)\n>>> rmse(pred_tensor, targ_tensor)\ntensor(1.4781)\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow for Data Loading\nDESCRIPTION: Command to install TensorFlow library, which is required to load data in .tfrecord format. A specific version constraint is recommended when installing inside the PhysicsNeMo docker container.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/vortex_shedding_mgn/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install tensorflow\n```\n\nLANGUAGE: bash\nCODE:\n```\npip install \"tensorflow<=2.17.1\"\n```\n\n----------------------------------------\n\nTITLE: Setting Weights & Biases API Key for Monitoring\nDESCRIPTION: Command to set the Weights & Biases API key as an environment variable for monitoring training progress and loss. This requires an active Weights & Biases account.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/weather/graphcast/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nexport WANDB_API_KEY=<your_api_key>\n```\n\n----------------------------------------\n\nTITLE: Training Models on DrivAerNet Dataset\nDESCRIPTION: Commands for training both standard MeshGraphNet and extended AeroGraphNet models on the DrivAerNet dataset, with AeroGraphNet additionally predicting drag coefficients directly.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/external_aerodynamics/aero_graph_net/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=drivaernet/mgn data.data_dir=/data/DrivAerNet/\n```\n\nLANGUAGE: bash\nCODE:\n```\npython train.py +experiment=drivaernet/agn data.data_dir=/data/DrivAerNet/\n```\n\n----------------------------------------\n\nTITLE: Running DeepONet-based Physics-Informed Darcy Flow Model\nDESCRIPTION: Command to execute the DeepONet approach for the physics-informed Darcy flow model. This script implements the model using automatic differentiation for gradient computation.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_physics_informed/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython darcy_physics_informed_deeponet.py\n```\n\n----------------------------------------\n\nTITLE: Starting MLFlow UI for Model Training Monitoring\nDESCRIPTION: This command launches the MLFlow UI on port 2458 to monitor the training progress of the FNO model in a web browser.\nSOURCE: https://github.com/nvidia/physicsnemo/blob/main/examples/cfd/darcy_fno/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmlflow ui -p 2458\n```"
  }
]