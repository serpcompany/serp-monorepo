[
  {
    "owner": "huggingface",
    "repo": "transformers.js",
    "content": "TITLE: Creating a Sentiment Analysis Pipeline in JavaScript\nDESCRIPTION: Demonstrates how to create and use a sentiment analysis pipeline using the default model.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from '@huggingface/transformers';\n\nconst classifier = await pipeline('sentiment-analysis');\n\nconst result = await classifier('I love transformers!');\n// [{'label': 'POSITIVE', 'score': 0.9998}]\n```\n\n----------------------------------------\n\nTITLE: Using Sentiment Analysis Pipeline in JavaScript\nDESCRIPTION: Demonstrates how to use the pipeline API for sentiment analysis in JavaScript, similar to the Python version.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from '@huggingface/transformers';\n\n// Allocate a pipeline for sentiment-analysis\nconst pipe = await pipeline('sentiment-analysis');\n\nconst out = await pipe('I love transformers!');\n// [{'label': 'POSITIVE', 'score': 0.999817686}]\n```\n\n----------------------------------------\n\nTITLE: Using Custom Models for Sentiment Analysis in JavaScript\nDESCRIPTION: Shows how to use a specific model for sentiment analysis, in this case, one trained to predict review ratings as stars.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst reviewer = await pipeline('sentiment-analysis', 'Xenova/bert-base-multilingual-uncased-sentiment');\n\nconst result = await reviewer('The Shawshank Redemption is a true masterpiece of cinema.');\n// [{label: '5 stars', score: 0.8167929649353027}]\n```\n\n----------------------------------------\n\nTITLE: Computing Text Embeddings on WebGPU with Transformers.js\nDESCRIPTION: This example demonstrates how to create a feature-extraction pipeline using WebGPU acceleration to compute text embeddings. It loads the mxbai-embed-xsmall-v1 model, processes multiple text inputs, and returns normalized embeddings.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/webgpu.md#2025-04-11_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from \"@huggingface/transformers\";\n\n// Create a feature-extraction pipeline\nconst extractor = await pipeline(\n  \"feature-extraction\",\n  \"mixedbread-ai/mxbai-embed-xsmall-v1\",\n  { device: \"webgpu\" },\n);\n\n// Compute embeddings\nconst texts = [\"Hello world!\", \"This is an example sentence.\"];\nconst embeddings = await extractor(texts, { pooling: \"mean\", normalize: true });\nconsole.log(embeddings.tolist());\n// [\n//   [-0.016986183822155, 0.03228696808218956, -0.0013630966423079371, ... ],\n//   [0.09050482511520386, 0.07207386940717697, 0.05762749910354614, ... ],\n// ]\n```\n\n----------------------------------------\n\nTITLE: Running a Model on WebGPU\nDESCRIPTION: Demonstrates how to run a model on WebGPU by setting the device option in the pipeline configuration.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n// Run the model on WebGPU\nconst pipe = await pipeline('sentiment-analysis', 'Xenova/distilbert-base-uncased-finetuned-sst-2-english', {\n  device: 'webgpu',\n});\n```\n\n----------------------------------------\n\nTITLE: Performing Automatic Speech Recognition in JavaScript\nDESCRIPTION: Demonstrates how to use the pipeline for Automatic Speech Recognition (ASR) using OpenAI's Whisper model.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-small.en');\n\nconst result = await transcriber('https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac');\n// {text: ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n```\n\n----------------------------------------\n\nTITLE: Customizing Model Loading Options in JavaScript\nDESCRIPTION: Shows how to use custom PretrainedOptions to control model loading, such as specifying the model precision or revision.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst pipe = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2', {\n    dtype: \"fp32\",\n});\n\nconst transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en', {\n    revision: 'output_attentions',\n});\n```\n\n----------------------------------------\n\nTITLE: Multilingual Translation Pipeline in JavaScript\nDESCRIPTION: Demonstrates how to use a translation pipeline with specified source and target languages.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst translator = await pipeline('translation', 'Xenova/nllb-200-distilled-600M');\n\nconst result = await translator('I like to walk my dog.', {\n    src_lang: 'eng_Latn',\n    tgt_lang: 'ell_Grek'\n});\n// [ { translation_text: 'Μου αρέσει να περπατάω το σκυλί μου.' } ]\n\nconst result2 = await translator(result[0].translation_text, {\n    src_lang: 'ell_Grek',\n    tgt_lang: 'eng_Latn'\n});\n// [ { translation_text: 'I like to walk my dog.' } ]\n```\n\n----------------------------------------\n\nTITLE: Text Generation with Custom Parameters in JavaScript\nDESCRIPTION: Shows how to use a text generation pipeline with custom generation parameters for creating a poem.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nconst poet = await pipeline('text2text-generation', 'Xenova/LaMini-Flan-T5-783M');\nconst result = await poet('Write me a love poem about cheese.', {\n    max_new_tokens: 200,\n    temperature: 0.9,\n    repetition_penalty: 2.0,\n    no_repeat_ngram_size: 3,\n});\n```\n\n----------------------------------------\n\nTITLE: Loading a Gated Model with Transformers.js\nDESCRIPTION: Example of loading a tokenizer from a gated repository (meta-llama/Llama-2-7b-hf) and using it to encode text. This demonstrates the basic usage pattern for accessing private models.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/private.md#2025-04-11_snippet_0\n\nLANGUAGE: js\nCODE:\n```\nimport { AutoTokenizer } from '@huggingface/transformers';\n\n// Load tokenizer for a gated repository.\nconst tokenizer = await AutoTokenizer.from_pretrained('meta-llama/Llama-2-7b-hf');\n\n// Encode text.\nconst text = 'Hello world!';\nconst encoded = tokenizer.encode(text);\nconsole.log(encoded);\n```\n\n----------------------------------------\n\nTITLE: Streaming Text Generation in JavaScript\nDESCRIPTION: Demonstrates how to use streaming output with a text generation pipeline, particularly for chat models.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/pipelines.md#2025-04-11_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline, TextStreamer } from \"@huggingface/transformers\";\n\nconst generator = await pipeline(\n  \"text-generation\",\n  \"onnx-community/Qwen2.5-Coder-0.5B-Instruct\",\n  { dtype: \"q4\" },\n);\n\nconst messages = [\n  { role: \"system\", content: \"You are a helpful assistant.\" },\n  { role: \"user\", content:  \"Write a quick sort algorithm.\" },\n];\n\nconst streamer = new TextStreamer(generator.tokenizer, {\n  skip_prompt: true,\n  // Optionally, do something with the text (e.g., write to a textbox)\n  // callback_function: (text) => { /* Do something with text */ },\n})\n\nconst result = await generator(messages, { max_new_tokens: 512, do_sample: false, streamer });\n```\n\n----------------------------------------\n\nTITLE: Performing Automatic Speech Recognition with Whisper on WebGPU\nDESCRIPTION: This example shows how to implement automatic speech recognition using OpenAI's Whisper model with WebGPU acceleration. It creates a pipeline for the whisper-tiny.en model, processes an audio file from a URL, and outputs the transcribed text.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/webgpu.md#2025-04-11_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from \"@huggingface/transformers\";\n\n// Create automatic speech recognition pipeline\nconst transcriber = await pipeline(\n  \"automatic-speech-recognition\",\n  \"onnx-community/whisper-tiny.en\",\n  { device: \"webgpu\" },\n);\n\n// Transcribe audio from a URL\nconst url = \"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav\";\nconst output = await transcriber(url);\nconsole.log(output);\n// { text: ' And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.' }\n```\n\n----------------------------------------\n\nTITLE: Performing Image Classification with MobileNetV4 on WebGPU\nDESCRIPTION: This example demonstrates image classification using the MobileNetV4 model with WebGPU acceleration. It creates a classification pipeline, processes an image from a URL, and returns the top predicted labels with their confidence scores.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/webgpu.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from \"@huggingface/transformers\";\n\n// Create image classification pipeline\nconst classifier = await pipeline(\n  \"image-classification\",\n  \"onnx-community/mobilenetv4_conv_small.e2400_r224_in1k\",\n  { device: \"webgpu\" },\n);\n\n// Classify an image from a URL\nconst url = \"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/tiger.jpg\";\nconst output = await classifier(url);\nconsole.log(output);\n// [\n//   { label: 'tiger, Panthera tigris', score: 0.6149784922599792 },\n//   { label: 'tiger cat', score: 0.30281734466552734 },\n//   { label: 'tabby, tabby cat', score: 0.0019135422771796584 },\n//   { label: 'lynx, catamount', score: 0.0012161266058683395 },\n//   { label: 'Egyptian cat', score: 0.0011465961579233408 }\n// ]\n```\n\n----------------------------------------\n\nTITLE: Loading Custom Models from Hugging Face Hub in Transformers.js\nDESCRIPTION: This snippet shows how to load a custom model from the Hugging Face Hub using Transformers.js. It demonstrates the process of importing the pipeline, specifying the model, and generating text.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/custom_usage.md#2025-04-11_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from '@xenova/transformers';\n\n// Specify the model you want to use\nconst model = 'Xenova/distilgpt2-base';\n\n// Create a generator\nconst generator = await pipeline('text-generation', model);\n\n// Generate text\nconst result = await generator('I love paris because', {\n    max_new_tokens: 20,\n});\n\nconsole.log(result);\n```\n\n----------------------------------------\n\nTITLE: Using Local Models in Transformers.js\nDESCRIPTION: This snippet demonstrates how to use a local model with Transformers.js. It shows the process of importing the pipeline, specifying the local model path, and generating text using the local model.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/custom_usage.md#2025-04-11_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from '@xenova/transformers';\n\n// Specify the path to your local model\nconst model = './path/to/your/model';\n\n// Create a generator\nconst generator = await pipeline('text-generation', model);\n\n// Generate text\nconst result = await generator('I love paris because', {\n    max_new_tokens: 20,\n});\n\nconsole.log(result);\n```\n\n----------------------------------------\n\nTITLE: Running Qwen2.5-0.5B-Instruct with 4-bit Quantization in JavaScript\nDESCRIPTION: This snippet demonstrates how to create a text generation pipeline using the Qwen2.5-0.5B-Instruct model with 4-bit quantization. It sets up the pipeline, defines a list of messages, and generates a response.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/dtypes.md#2025-04-11_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from \"@huggingface/transformers\";\n\n// Create a text generation pipeline\nconst generator = await pipeline(\n  \"text-generation\",\n  \"onnx-community/Qwen2.5-0.5B-Instruct\",\n  { dtype: \"q4\", device: \"webgpu\" },\n);\n\n// Define the list of messages\nconst messages = [\n  { role: \"system\", content: \"You are a helpful assistant.\" },\n  { role: \"user\", content: \"Tell me a funny joke.\" },\n];\n\n// Generate a response\nconst output = await generator(messages, { max_new_tokens: 128 });\nconsole.log(output[0].generated_text.at(-1).content);\n```\n\n----------------------------------------\n\nTITLE: Running Florence-2 with Per-module Dtypes on WebGPU in JavaScript\nDESCRIPTION: This example shows how to use Florence-2 model with per-module dtypes on WebGPU. It demonstrates setting different quantization levels for various modules of the model to optimize performance and accuracy.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/dtypes.md#2025-04-11_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Florence2ForConditionalGeneration } from \"@huggingface/transformers\";\n\nconst model = await Florence2ForConditionalGeneration.from_pretrained(\n  \"onnx-community/Florence-2-base-ft\",\n  {\n    dtype: {\n      embed_tokens: \"fp16\",\n      vision_encoder: \"fp16\",\n      encoder_model: \"q4\",\n      decoder_model_merged: \"q4\",\n    },\n    device: \"webgpu\",\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: Full Example of Florence-2 Image Captioning with Transformers.js\nDESCRIPTION: This comprehensive example demonstrates loading the Florence-2 model, processor, and tokenizer, preparing vision and text inputs, generating text based on an image, and post-processing the results. It showcases the full pipeline for image captioning using Florence-2.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/dtypes.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport {\n  Florence2ForConditionalGeneration,\n  AutoProcessor,\n  AutoTokenizer,\n  RawImage,\n} from \"@huggingface/transformers\";\n\n// Load model, processor, and tokenizer\nconst model_id = \"onnx-community/Florence-2-base-ft\";\nconst model = await Florence2ForConditionalGeneration.from_pretrained(\n  model_id,\n  {\n    dtype: {\n      embed_tokens: \"fp16\",\n      vision_encoder: \"fp16\",\n      encoder_model: \"q4\",\n      decoder_model_merged: \"q4\",\n    },\n    device: \"webgpu\",\n  },\n);\nconst processor = await AutoProcessor.from_pretrained(model_id);\nconst tokenizer = await AutoTokenizer.from_pretrained(model_id);\n\n// Load image and prepare vision inputs\nconst url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg\";\nconst image = await RawImage.fromURL(url);\nconst vision_inputs = await processor(image);\n\n// Specify task and prepare text inputs\nconst task = \"<MORE_DETAILED_CAPTION>\";\nconst prompts = processor.construct_prompts(task);\nconst text_inputs = tokenizer(prompts);\n\n// Generate text\nconst generated_ids = await model.generate({\n  ...text_inputs,\n  ...vision_inputs,\n  max_new_tokens: 100,\n});\n\n// Decode generated text\nconst generated_text = tokenizer.batch_decode(generated_ids, {\n  skip_special_tokens: false,\n})[0];\n\n// Post-process the generated text\nconst result = processor.post_process_generation(\n  generated_text,\n  task,\n  image.size,\n);\nconsole.log(result);\n// { '<MORE_DETAILED_CAPTION>': 'A green car is parked in front of a tan building. The building has a brown door and two brown windows. The car is a two door and the door is closed. The green car has black tires.' }\n```\n\n----------------------------------------\n\nTITLE: Creating a Translation Pipeline Worker\nDESCRIPTION: Implementation of a worker.js file that creates a singleton translation pipeline using Transformers.js. This pattern ensures the model is loaded only once and handles the heavy computational work in a separate thread.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline, TextStreamer } from '@huggingface/transformers';\n\nclass MyTranslationPipeline {\n  static task = 'translation';\n  static model = 'Xenova/nllb-200-distilled-600M';\n  static instance = null;\n\n  static async getInstance(progress_callback = null) {\n    this.instance ??= pipeline(this.task, this.model, { progress_callback });\n    return this.instance;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating HTTP Server for Sentiment Analysis\nDESCRIPTION: JavaScript code to create an HTTP server that handles requests for text classification using the Transformers.js pipeline.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n// Define the HTTP server\nconst server = http.createServer();\nconst hostname = '127.0.0.1';\nconst port = 3000;\n\n// Listen for requests made to the server\nserver.on('request', async (req, res) => {\n  // Parse the request URL\n  const parsedUrl = url.parse(req.url);\n\n  // Extract the query parameters\n  const { text } = querystring.parse(parsedUrl.query);\n\n  // Set the response headers\n  res.setHeader('Content-Type', 'application/json');\n\n  let response;\n  if (parsedUrl.pathname === '/classify' && text) {\n    const classifier = await MyClassificationPipeline.getInstance();\n    response = await classifier(text);\n    res.statusCode = 200;\n  } else {\n    response = { 'error': 'Bad request' }\n    res.statusCode = 400;\n  }\n\n  // Send the JSON response\n  res.end(JSON.stringify(response));\n});\n\nserver.listen(port, hostname, () => {\n  console.log(`Server running at http://${hostname}:${port}/`);\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Classification Pipeline Class for ESM\nDESCRIPTION: JavaScript class definition for a singleton classification pipeline using Transformers.js in ECMAScript module format.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nclass MyClassificationPipeline {\n  static task = 'text-classification';\n  static model = 'Xenova/distilbert-base-uncased-finetuned-sst-2-english';\n  static instance = null;\n\n  static async getInstance(progress_callback = null) {\n    if (this.instance === null) {\n      // NOTE: Uncomment this to change the cache directory\n      // env.cacheDir = './.cache';\n\n      this.instance = pipeline(this.task, this.model, { progress_callback });\n    }\n\n    return this.instance;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Classification Pipeline Class for CommonJS\nDESCRIPTION: JavaScript class definition for a singleton classification pipeline using Transformers.js in CommonJS format, with dynamic import.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nclass MyClassificationPipeline {\n  static task = 'text-classification';\n  static model = 'Xenova/distilbert-base-uncased-finetuned-sst-2-english';\n  static instance = null;\n\n  static async getInstance(progress_callback = null) {\n    if (this.instance === null) {\n      // Dynamically import the Transformers.js library\n      let { pipeline, env } = await import('@huggingface/transformers');\n\n      // NOTE: Uncomment this to change the cache directory\n      // env.cacheDir = './.cache';\n\n      this.instance = pipeline(this.task, this.model, { progress_callback });\n    }\n\n    return this.instance;\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up Web Worker in React Component\nDESCRIPTION: Implementation of a React component that creates and manages a web worker for running the translation model. This approach keeps the UI thread responsive by offloading the heavy computation to a separate thread.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_5\n\nLANGUAGE: jsx\nCODE:\n```\n// Remember to import the relevant hooks\nimport { useEffect, useRef, useState } from 'react'\nimport './App.css'\n\nfunction App() {\n  // Create a reference to the worker object.\n  const worker = useRef(null);\n\n  // We use the `useEffect` hook to setup the worker as soon as the `App` component is mounted.\n  useEffect(() => {\n    // Create the worker if it does not yet exist.\n    worker.current ??= new Worker(new URL('./worker.js', import.meta.url), {\n        type: 'module'\n    });\n\n    // Create a callback function for messages from the worker thread.\n    const onMessageReceived = (e) => {\n      // TODO: Will fill in later\n    };\n\n    // Attach the callback function as an event listener.\n    worker.current.addEventListener('message', onMessageReceived);\n\n    // Define a cleanup function for when the component is unmounted.\n    return () => worker.current.removeEventListener('message', onMessageReceived);\n  });\n  \n  return (\n    // TODO: Rest of our app goes here...\n  )\n}\n\nexport default App\n```\n\n----------------------------------------\n\nTITLE: Creating a Singleton Text Classification Pipeline with Transformers.js\nDESCRIPTION: Implementation of a pipeline.js file that uses the Singleton pattern to create a reusable text classification pipeline using distilbert model. Includes special handling for development vs production environments.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from \"@huggingface/transformers\";\n\n// Use the Singleton pattern to enable lazy construction of the pipeline.\n// NOTE: We wrap the class in a function to prevent code duplication (see below).\nconst P = () => class PipelineSingleton {\n    static task = 'text-classification';\n    static model = 'Xenova/distilbert-base-uncased-finetuned-sst-2-english';\n    static instance = null;\n\n    static async getInstance(progress_callback = null) {\n        if (this.instance === null) {\n            this.instance = pipeline(this.task, this.model, { progress_callback });\n        }\n        return this.instance;\n    }\n}\n\nlet PipelineSingleton;\nif (process.env.NODE_ENV !== 'production') {\n    // When running in development mode, attach the pipeline to the\n    // global object so that it's preserved between hot reloads.\n    // For more information, see https://vercel.com/guides/nextjs-prisma-postgres\n    if (!global.PipelineSingleton) {\n        global.PipelineSingleton = P();\n    }\n    PipelineSingleton = global.PipelineSingleton;\n} else {\n    PipelineSingleton = P();\n}\nexport default PipelineSingleton;\n```\n\n----------------------------------------\n\nTITLE: Implementing Worker Thread Message Handler\nDESCRIPTION: Sets up a worker thread event listener to handle translation requests, load the translation pipeline, and stream results back to the main thread. Includes progress tracking and partial output streaming.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_12\n\nLANGUAGE: javascript\nCODE:\n```\nself.addEventListener('message', async (event) => {\n  const translator = await MyTranslationPipeline.getInstance(x => {\n      self.postMessage(x);\n  });\n\n  const streamer = new TextStreamer(translator.tokenizer, {\n      skip_prompt: true,\n      skip_special_tokens: true,\n      callback_function: function (text) {\n          self.postMessage({\n              status: 'update',\n              output: text\n          });\n      }\n  });\n\n  const output = await translator(event.data.text, {\n      tgt_lang: event.data.tgt_lang,\n      src_lang: event.data.src_lang,\n      streamer,\n  });\n\n  self.postMessage({\n      status: 'complete',\n      output,\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Object Detection Pipeline in JavaScript\nDESCRIPTION: Initializes the object detection pipeline using Transformers.js, updating the status message during model loading.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nstatus.textContent = \"Loading model...\";\n\nconst detector = await pipeline(\"object-detection\", \"Xenova/detr-resnet-50\");\n\nstatus.textContent = \"Ready\";\n```\n\n----------------------------------------\n\nTITLE: Running Object Detection Model in JavaScript\nDESCRIPTION: Defines an asynchronous function to run the object detection model on the uploaded image, updating the status and logging the output.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nasync function detect(img) {\n  status.textContent = \"Analysing...\";\n  const output = await detector(img.src, {\n    threshold: 0.5,\n    percentage: true,\n  });\n  status.textContent = \"\";\n  console.log(\"output\", output);\n  // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Rendering Detection Output with forEach in JavaScript\nDESCRIPTION: Code that iterates through each detected object and applies the renderBox function to visualize detection results.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_6\n\nLANGUAGE: js\nCODE:\n```\noutput.forEach(renderBox);\n```\n\n----------------------------------------\n\nTITLE: Importing Transformers.js in Vanilla JavaScript\nDESCRIPTION: Example of importing the Transformers.js library using ES Modules in vanilla JavaScript without a bundler.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<script type=\"module\">\n    import { pipeline } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.4.2';\n</script>\n```\n\n----------------------------------------\n\nTITLE: Using Quantized Models for Optimization\nDESCRIPTION: Shows how to use quantized models to optimize performance in resource-constrained environments by setting the dtype option.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n// Run the model at 4-bit quantization\nconst pipe = await pipeline('sentiment-analysis', 'Xenova/distilbert-base-uncased-finetuned-sst-2-english', {\n  dtype: 'q4',\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Settings in Transformers.js\nDESCRIPTION: This snippet demonstrates how to customize Transformers.js environment settings, including specifying custom model paths, controlling remote model loading, and setting WASM file locations.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { env } from '@huggingface/transformers';\n\n// Specify a custom location for models (defaults to '/models/').\nenv.localModelPath = '/path/to/models/';\n\n// Disable the loading of remote models from the Hugging Face Hub:\nenv.allowRemoteModels = false;\n\n// Set location of .wasm files. Defaults to use a CDN.\nenv.backends.onnx.wasm.wasmPaths = '/path/to/files/';\n```\n\n----------------------------------------\n\nTITLE: Running Node.js with HF_TOKEN Environment Variable\nDESCRIPTION: Command to run a Node.js script with the HF_TOKEN environment variable set to authenticate with the Hugging Face Hub. This allows access to gated models without hardcoding the token in the script.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/private.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nHF_TOKEN=hf_... node tests/llama.js\n```\n\n----------------------------------------\n\nTITLE: Setting HF_TOKEN in JavaScript Code\nDESCRIPTION: Alternative approach to set the HF_TOKEN environment variable directly in the JavaScript code. This method should be used carefully to avoid exposing the token in client-side code.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/private.md#2025-04-11_snippet_2\n\nLANGUAGE: js\nCODE:\n```\n// Set access token (NB: Keep this private!)\nprocess.env.HF_TOKEN = 'hf_...';\n\n// ... rest of your code\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js via NPM\nDESCRIPTION: Command to install the Transformers.js library using NPM package manager.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js via NPM\nDESCRIPTION: Commands to initialize a new Node.js project and install Transformers.js using npm.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y\nnpm i @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js via NPM\nDESCRIPTION: Sets up a new Node.js project and installs the Transformers.js package from NPM.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm init -y\nnpm i @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for ESM\nDESCRIPTION: JavaScript code to import necessary Node.js modules and Transformers.js for ECMAScript module implementation.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport http from 'http';\nimport querystring from 'querystring';\nimport url from 'url';\n\nimport { pipeline, env } from '@huggingface/transformers';\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for CommonJS\nDESCRIPTION: JavaScript code to import necessary Node.js modules for CommonJS implementation.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nconst http = require('http');\nconst querystring = require('querystring');\nconst url = require('url');\n```\n\n----------------------------------------\n\nTITLE: Structuring Main App Component in React Translator\nDESCRIPTION: This snippet shows the JSX structure for the main App component, including language selectors, text areas for input and output, and a translation button. It also includes a progress bar container for model loading.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_9\n\nLANGUAGE: jsx\nCODE:\n```\nreturn (\n  <>\n    <h1>Transformers.js</h1>\n    <h2>ML-powered multilingual translation in React!</h2>\n\n    <div className='container'>\n      <div className='language-container'>\n        <LanguageSelector type={\"Source\"} defaultLanguage={\"eng_Latn\"} onChange={x => setSourceLanguage(x.target.value)} />\n        <LanguageSelector type={\"Target\"} defaultLanguage={\"fra_Latn\"} onChange={x => setTargetLanguage(x.target.value)} />\n      </div>\n\n      <div className='textbox-container'>\n        <textarea value={input} rows={3} onChange={e => setInput(e.target.value)}></textarea>\n        <textarea value={output} rows={3} readOnly></textarea>\n      </div>\n    </div>\n\n    <button disabled={disabled} onClick={translate}>Translate</button>\n\n    <div className='progress-bars-container'>\n      {ready === false && (\n        <label>Loading models... (only run once)</label>\n      )}\n      {progressItems.map(data => (\n        <div key={data.file}>\n          <Progress text={data.file} percentage={data.progress} />\n        </div>\n      ))}\n    </div>\n  </>\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Next.js Route Handler for Text Classification\nDESCRIPTION: Code for a route.js file that processes requests to the /classify endpoint, accessing the text classification pipeline to analyze text provided as a URL parameter.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nimport { NextResponse } from 'next/server'\nimport PipelineSingleton from './pipeline.js';\n\nexport async function GET(request) {\n    const text = request.nextUrl.searchParams.get('text');\n    if (!text) {\n        return NextResponse.json({\n            error: 'Missing text parameter',\n        }, { status: 400 });\n    }\n    // Get the classification pipeline. When called for the first time,\n    // this will load the pipeline and cache it for future use.\n    const classifier = await PipelineSingleton.getInstance();\n\n    // Actually perform the classification\n    const result = await classifier(text);\n\n    return NextResponse.json(result);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a React UI for Text Classification with Transformers.js\nDESCRIPTION: Next.js React component implementation for the UI that accepts user input, sends it to the classification endpoint, and displays the results. Includes loading state handling.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_9\n\nLANGUAGE: jsx\nCODE:\n```\n'use client'\n\nimport { useState } from 'react'\n\nexport default function Home() {\n\n  // Keep track of the classification result and the model loading status.\n  const [result, setResult] = useState(null);\n  const [ready, setReady] = useState(null);\n\n  const classify = async (text) => {\n    if (!text) return;\n    if (ready === null) setReady(false);\n\n    // Make a request to the /classify route on the server.\n    const result = await fetch(`/classify?text=${encodeURIComponent(text)}`);\n\n    // If this is the first time we've made a request, set the ready flag.\n    if (!ready) setReady(true);\n\n    const json = await result.json();\n    setResult(json);\n  };\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-center p-12\">\n      <h1 className=\"text-5xl font-bold mb-2 text-center\">Transformers.js</h1>\n      <h2 className=\"text-2xl mb-4 text-center\">Next.js template (server-side)</h2>\n      <input\n        type=\"text\"\n        className=\"w-full max-w-xs p-2 border border-gray-300 rounded mb-4\"\n        placeholder=\"Enter text here\"\n        onInput={e => {\n          classify(e.target.value);\n        }}\n      />\n\n      {ready !== null && (\n        <pre className=\"bg-gray-100 p-2 rounded\">\n          {\n            (!ready || !result) ? 'Loading...' : JSON.stringify(result, null, 2)}\n        </pre>\n      )}\n    </main>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Speech Recognition Pipeline\nDESCRIPTION: Creates an automatic speech recognition pipeline using the Xenova/whisper-tiny.en model.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nlet transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Audio Data\nDESCRIPTION: Loads a WAV file from a URL, converts it to the required format (32-bit float, 16kHz sample rate), and merges stereo channels if necessary for processing with Whisper.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n// Load audio data\nlet url = 'https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/jfk.wav';\nlet buffer = Buffer.from(await fetch(url).then(x => x.arrayBuffer()))\n\n// Read .wav file and convert it to required format\nlet wav = new wavefile.WaveFile(buffer);\nwav.toBitDepth('32f'); // Pipeline expects input as a Float32Array\nwav.toSampleRate(16000); // Whisper expects audio with a sampling rate of 16000\nlet audioData = wav.getSamples();\nif (Array.isArray(audioData)) {\n  if (audioData.length > 1) {\n    const SCALING_FACTOR = Math.sqrt(2);\n\n    // Merge channels (into first channel to save memory)\n    for (let i = 0; i < audioData[0].length; ++i) {\n      audioData[0][i] = SCALING_FACTOR * (audioData[0][i] + audioData[1][i]) / 2;\n    }\n  }\n\n  // Select first channel\n  audioData = audioData[0];\n}\n```\n\n----------------------------------------\n\nTITLE: Running Speech Recognition and Timing Execution\nDESCRIPTION: Processes the audio with the speech recognition pipeline, measures execution time, and logs the transcription output.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nlet start = performance.now();\nlet output = await transcriber(audioData);\nlet end = performance.now();\nconsole.log(`Execution duration: ${(end - start) / 1000} seconds`);\nconsole.log(output);\n```\n\n----------------------------------------\n\nTITLE: Importing Transformers.js and Setting Up JavaScript\nDESCRIPTION: Imports the necessary functions from Transformers.js, configures environment settings, and sets up DOM element references for the object detection application.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline, env } from \"https://cdn.jsdelivr.net/npm/@huggingface/transformers\";\n\nenv.allowLocalModels = false;\n\nconst fileUpload = document.getElementById(\"file-upload\");\nconst imageContainer = document.getElementById(\"image-container\");\nconst status = document.getElementById(\"status\");\n```\n\n----------------------------------------\n\nTITLE: Implementing renderBox Function for Object Detection Visualization\nDESCRIPTION: Function that creates and positions HTML elements to display bounding boxes and labels for detected objects. It generates random colors for each box and configures their position based on the detection coordinates.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_7\n\nLANGUAGE: js\nCODE:\n```\n// Render a bounding box and label on the image\nfunction renderBox({ box, label }) {\n  const { xmax, xmin, ymax, ymin } = box;\n\n  // Generate a random color for the box\n  const color = \"#\" + Math.floor(Math.random() * 0xffffff).toString(16).padStart(6, 0);\n\n  // Draw the box\n  const boxElement = document.createElement(\"div\");\n  boxElement.className = \"bounding-box\";\n  Object.assign(boxElement.style, {\n    borderColor: color,\n    left: 100 * xmin + \"%\",\n    top: 100 * ymin + \"%\",\n    width: 100 * (xmax - xmin) + \"%\",\n    height: 100 * (ymax - ymin) + \"%\",\n  });\n\n  // Draw the label\n  const labelElement = document.createElement(\"span\");\n  labelElement.textContent = label;\n  labelElement.className = \"bounding-box-label\";\n  labelElement.style.backgroundColor = color;\n\n  boxElement.appendChild(labelElement);\n  imageContainer.appendChild(boxElement);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Main Thread Message Handler in React\nDESCRIPTION: Handles various message types from the worker thread, including model loading progress, translation updates, and completion status. Updates the application state accordingly.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_13\n\nLANGUAGE: jsx\nCODE:\n```\nconst onMessageReceived = (e) => {\n  switch (e.data.status) {\n    case 'initiate':\n      setReady(false);\n      setProgressItems(prev => [...prev, e.data]);\n      break;\n\n    case 'progress':\n      setProgressItems(\n        prev => prev.map(item => {\n          if (item.file === e.data.file) {\n            return { ...item, progress: e.data.progress }\n          }\n          return item;\n        })\n      );\n      break;\n\n    case 'done':\n      setProgressItems(\n        prev => prev.filter(item => item.file !== e.data.file)\n      );\n      break;\n\n    case 'ready':\n      setReady(true);\n      break;\n\n    case 'update':\n      setOutput(o => o + e.data.output);\n      break;\n\n    case 'complete':\n      setDisabled(false);\n      break;\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Implementing Translation Function in React Component\nDESCRIPTION: Defines the translate function that sends input text and language selections to a worker thread for processing. The function disables the translate button during processing and clears previous output.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_11\n\nLANGUAGE: jsx\nCODE:\n```\nconst translate = () => {\n  setDisabled(true);\n  setOutput('');\n  worker.current.postMessage({\n    text: input,\n    src_lang: sourceLanguage,\n    tgt_lang: targetLanguage,\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring package.json for ECMAScript Modules\nDESCRIPTION: JSON configuration to set the project type to 'module' in package.json for using ECMAScript modules.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  ...\n  \"type\": \"module\",\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Next.js Client Component\nDESCRIPTION: React component implementation for the main application interface, including worker thread management and UI elements.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_4\n\nLANGUAGE: jsx\nCODE:\n```\n'use client'\n\nimport { useState, useEffect, useRef, useCallback } from 'react'\n\nexport default function Home() {\n  const [result, setResult] = useState(null);\n  const [ready, setReady] = useState(null);\n  const worker = useRef(null);\n\n  useEffect(() => {\n    if (!worker.current) {\n      worker.current = new Worker(new URL('./worker.js', import.meta.url), {\n        type: 'module'\n      });\n    }\n\n    const onMessageReceived = (e) => {\n      switch (e.data.status) {\n        case 'initiate':\n          setReady(false);\n          break;\n        case 'ready':\n          setReady(true);\n          break;\n        case 'complete':\n          setResult(e.data.output[0])\n          break;\n      }\n    };\n\n    worker.current.addEventListener('message', onMessageReceived);\n    return () => worker.current.removeEventListener('message', onMessageReceived);\n  });\n\n  const classify = useCallback((text) => {\n    if (worker.current) {\n      worker.current.postMessage({ text });\n    }\n  }, []);\n\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-center p-12\">\n      <h1 className=\"text-5xl font-bold mb-2 text-center\">Transformers.js</h1>\n      <h2 className=\"text-2xl mb-4 text-center\">Next.js template</h2>\n\n      <input\n        className=\"w-full max-w-xs p-2 border border-gray-300 rounded mb-4\"\n        type=\"text\"\n        placeholder=\"Enter text here\"\n        onInput={e => {\n            classify(e.target.value);\n        }}\n      />\n\n      {ready !== null && (\n        <pre className=\"bg-gray-100 p-2 rounded\">\n          { (!ready || !result) ? 'Loading...' : JSON.stringify(result, null, 2) }\n        </pre>\n      )}\n    </main>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Using a Custom Model for Sentiment Analysis\nDESCRIPTION: Shows how to use a specific model for sentiment analysis by providing the model ID to the pipeline function.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n// Use a different model for sentiment-analysis\nconst pipe = await pipeline('sentiment-analysis', 'Xenova/bert-base-multilingual-uncased-sentiment');\n```\n\n----------------------------------------\n\nTITLE: Converting Models to ONNX Format with Optimum\nDESCRIPTION: This command shows how to use the conversion script to transform PyTorch, TensorFlow, or JAX models to ONNX format with quantization. The script utilizes Hugging Face Optimum for conversion and optimization.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -m scripts.convert --quantize --model_id <model_name_or_path>\n```\n\n----------------------------------------\n\nTITLE: Converting BERT Model to ONNX Example\nDESCRIPTION: A specific example showing how to convert and quantize the bert-base-uncased model to ONNX format. This command will save the converted model files to the ./models/ directory.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/README.md#2025-04-11_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\npython -m scripts.convert --quantize --model_id bert-base-uncased\n```\n\n----------------------------------------\n\nTITLE: Customizing Model Caching in Transformers.js\nDESCRIPTION: JavaScript code snippet to customize the cache directory for Transformers.js models.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nenv.cacheDir = './.cache';\n```\n\n----------------------------------------\n\nTITLE: Styling React Translator App with CSS\nDESCRIPTION: This snippet contains CSS styles for the React translator app, including global styles, component-specific styles, and layout adjustments for a polished user interface.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_10\n\nLANGUAGE: css\nCODE:\n```\n#root {\n  max-width: 1280px;\n  margin: 0 auto;\n  padding: 2rem;\n  text-align: center;\n}\n\n.language-container {\n  display: flex;\n  gap: 20px;\n}\n\n.textbox-container {\n  display: flex;\n  justify-content: center;\n  gap: 20px;\n  width: 800px;\n}\n\n.textbox-container>textarea, .language-selector {\n  width: 50%;\n}\n\n.language-selector>select {\n  width: 150px;\n}\n\n.progress-container {\n  position: relative;\n  font-size: 14px;\n  color: white;\n  background-color: #e9ecef;\n  border: solid 1px;\n  border-radius: 8px;\n  text-align: left;\n  overflow: hidden;\n}\n\n.progress-bar {\n  padding: 0 4px;\n  z-index: 0;\n  top: 0;\n  width: 1%;\n  overflow: hidden;\n  background-color: #007bff;\n  white-space: nowrap;\n}\n\n.progress-text {\n  z-index: 2;\n}\n\n.selector-container {\n  display: flex;\n  gap: 20px;\n}\n\n.progress-bars-container {\n  padding: 8px;\n  height: 140px;\n}\n\n.container {\n  margin: 25px;\n  display: flex;\n  flex-direction: column;\n  gap: 10px;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Model Path in Transformers.js\nDESCRIPTION: JavaScript code to set a custom local model path for Transformers.js.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\n// Specify a custom location for models (defaults to '/models/').\nenv.localModelPath = '/path/to/models/';\n```\n\n----------------------------------------\n\nTITLE: Disabling Remote Model Loading in Transformers.js\nDESCRIPTION: JavaScript code to disable loading of remote models from the Hugging Face Hub in Transformers.js.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\n// Disable the loading of remote models from the Hugging Face Hub:\nenv.allowRemoteModels = false;\n```\n\n----------------------------------------\n\nTITLE: CSS Styling for Object Detection Boxes and Labels\nDESCRIPTION: CSS rules for styling the bounding boxes and their labels. It defines positioning, border properties, and text formatting to make detection results visually clear.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_8\n\nLANGUAGE: css\nCODE:\n```\n.bounding-box {\n    position: absolute;\n    box-sizing: border-box;\n    border-width: 2px;\n    border-style: solid;\n}\n\n.bounding-box-label {\n    color: white;\n    position: absolute;\n    font-size: 12px;\n    margin-top: -16px;\n    margin-left: -2px;\n    padding: 1px;\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Language Selector Component in React\nDESCRIPTION: This snippet defines a LanguageSelector component that renders a dropdown menu for selecting input and output languages. It uses a predefined LANGUAGES object to populate the options.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_6\n\nLANGUAGE: jsx\nCODE:\n```\nconst LANGUAGES = {\n  \"Acehnese (Arabic script)\": \"ace_Arab\",\n  \"Acehnese (Latin script)\": \"ace_Latn\",\n  \"Afrikaans\": \"afr_Latn\",\n  ...\n  \"Zulu\": \"zul_Latn\",\n}\n\nexport default function LanguageSelector({ type, onChange, defaultLanguage }) {\n  return (\n    <div className='language-selector'>\n      <label>{type}: </label>\n      <select onChange={onChange} defaultValue={defaultLanguage}>\n        {Object.entries(LANGUAGES).map(([key, value]) => {\n          return <option key={key} value={value}>{key}</option>\n        })}\n      </select>\n    </div>\n  )\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Progress Component for Model Download in React\nDESCRIPTION: This snippet defines a Progress component that displays a progress bar for downloading model files. It takes text and percentage as props to show the current download status.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_7\n\nLANGUAGE: jsx\nCODE:\n```\nexport default function Progress({ text, percentage }) {\n  percentage = percentage ?? 0;\n  return (\n    <div className=\"progress-container\">\n      <div className='progress-bar' style={{ 'width': `${percentage}%` }}>\n        {text} ({`${percentage.toFixed(2)}%`})\n      </div>\n    </div>\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up State Variables in React Translator App\nDESCRIPTION: This snippet initializes state variables for the main App component, including model loading status, language selections, and input/output text fields.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_8\n\nLANGUAGE: jsx\nCODE:\n```\nfunction App() {\n\n  // Model loading\n  const [ready, setReady] = useState(null);\n  const [disabled, setDisabled] = useState(false);\n  const [progressItems, setProgressItems] = useState([]);\n\n  // Inputs and outputs\n  const [input, setInput] = useState('I love walking my dog.');\n  const [sourceLanguage, setSourceLanguage] = useState('eng_Latn');\n  const [targetLanguage, setTargetLanguage] = useState('fra_Latn');\n  const [output, setOutput] = useState('');\n\n  // rest of the code...\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing ML Worker Thread\nDESCRIPTION: Web Worker implementation for handling machine learning tasks using Transformers.js pipeline in a separate thread.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline, env } from \"@huggingface/transformers\";\n\nenv.allowLocalModels = false;\n\nclass PipelineSingleton {\n    static task = 'text-classification';\n    static model = 'Xenova/distilbert-base-uncased-finetuned-sst-2-english';\n    static instance = null;\n\n    static async getInstance(progress_callback = null) {\n        if (this.instance === null) {\n            this.instance = pipeline(this.task, this.model, { progress_callback });\n        }\n        return this.instance;\n    }\n}\n\nself.addEventListener('message', async (event) => {\n    let classifier = await PipelineSingleton.getInstance(x => {\n        self.postMessage(x);\n    });\n\n    let output = await classifier(event.data.text);\n\n    self.postMessage({\n        status: 'complete',\n        output: output,\n    });\n});\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules for Audio Processing\nDESCRIPTION: Imports the pipeline function from Transformers.js and the wavefile module for audio processing.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nimport { pipeline } from '@huggingface/transformers';\nimport wavefile from 'wavefile';\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Upload Functionality in JavaScript\nDESCRIPTION: Sets up an event listener for image file uploads, reads the selected image file, and displays it in the application interface.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nfileUpload.addEventListener(\"change\", function (e) {\n  const file = e.target.files[0];\n  if (!file) {\n    return;\n  }\n\n  const reader = new FileReader();\n\n  // Set up a callback when the file is loaded\n  reader.onload = function (e2) {\n    imageContainer.innerHTML = \"\";\n    const image = document.createElement(\"img\");\n    image.src = e2.target.result;\n    imageContainer.appendChild(image);\n    // detect(image); // Uncomment this line to run the model\n  };\n  reader.readAsDataURL(file);\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js Library\nDESCRIPTION: Command to install the Transformers.js library from NPM which provides machine learning capabilities.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js Package\nDESCRIPTION: NPM command to install the Transformers.js library as a project dependency.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Installing Transformers.js via NPM\nDESCRIPTION: Command to install the Transformers.js package from NPM using npm command line tool.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @huggingface/transformers\n```\n\n----------------------------------------\n\nTITLE: Configuring Next.js Webpack Settings\nDESCRIPTION: Next.js configuration to handle node-specific modules and setup webpack aliases for browser bundling.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n    output: 'export',\n    webpack: (config) => {\n        config.resolve.alias = {\n            ...config.resolve.alias,\n            \"sharp$\": false,\n            \"onnxruntime-node$\": false,\n        }\n        return config;\n    },\n}\n\nmodule.exports = nextConfig\n```\n\n----------------------------------------\n\nTITLE: Configuring Next.js for Transformers.js Integration\nDESCRIPTION: Configuration for next.config.js to prevent Webpack from bundling certain packages required by Transformers.js, specifically sharp and onnxruntime-node.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n    // (Optional) Export as a standalone site\n    // See https://nextjs.org/docs/pages/api-reference/next-config-js/output#automatically-copying-traced-files\n    output: 'standalone', // Feel free to modify/remove this option\n    \n    // Indicate that these packages should not be bundled by webpack\n    experimental: {\n        serverComponentsExternalPackages: ['sharp', 'onnxruntime-node'],\n    },\n};\n\nmodule.exports = nextConfig\n```\n\n----------------------------------------\n\nTITLE: Creating Image Matching Function in Supabase\nDESCRIPTION: SQL function that performs vector similarity search to match images based on embeddings. Returns relevant image metadata and similarity scores.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search/README.md#2025-04-11_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate or replace function match_images (\n    query_embedding vector(512),\n    match_threshold float,\n    match_count int\n)\nreturns table (\n    photo_id text,\n    photo_url text,\n    photo_image_url text,\n    photo_width int,\n    photo_height int,\n    photo_aspect_ratio float,\n    photo_description text,\n    ai_description text,\n    blur_hash text,\n    similarity float\n)\nlanguage sql stable\nas $$\nselect\n    photo_id,\n    photo_url,\n    photo_image_url,\n    photo_width,\n    photo_height,\n    photo_aspect_ratio,\n    photo_description,\n    ai_description,\n    blur_hash,\n    1 - (image_embedding <=> query_embedding) as similarity\nfrom images\nwhere 1 - (image_embedding <=> query_embedding) > match_threshold\norder by similarity desc\nlimit match_count;\n$$;\n```\n\n----------------------------------------\n\nTITLE: Installing wavefile Package for WAV Processing\nDESCRIPTION: Installs the wavefile package which will be used to load and process .wav audio files.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/guides/node-audio-processing.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm i wavefile\n```\n\n----------------------------------------\n\nTITLE: Structuring HTML for Object Detection App\nDESCRIPTION: Sets up the basic HTML structure for the object detection application, including an image upload button, container for displaying the image, and a status message area.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<main class=\"container\">\n  <label class=\"custom-file-upload\">\n    <input id=\"file-upload\" type=\"file\" accept=\"image/*\" />\n    <img class=\"upload-icon\" src=\"https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/upload-icon.png\" />\n    Upload image\n  </label>\n  <div id=\"image-container\"></div>\n  <p id=\"status\"></p>\n</main>\n```\n\n----------------------------------------\n\nTITLE: Styling Object Detection App with CSS\nDESCRIPTION: Provides CSS styles for the object detection application, including layout, button styling, and image container positioning.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/vanilla-js.md#2025-04-11_snippet_1\n\nLANGUAGE: css\nCODE:\n```\nhtml,\nbody {\n    font-family: Arial, Helvetica, sans-serif;\n}\n\n.container {\n    margin: 40px auto;\n    width: max(50vw, 400px);\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n}\n\n.custom-file-upload {\n    display: flex;\n    align-items: center;\n    gap: 10px;\n    border: 2px solid black;\n    padding: 8px 16px;\n    cursor: pointer;\n    border-radius: 6px;\n}\n\n#file-upload {\n    display: none;\n}\n\n.upload-icon {\n    width: 30px;\n}\n\n#image-container {\n    width: 100%;\n    margin-top: 20px;\n    position: relative;\n}\n\n#image-container>img {\n    width: 100%;\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing React Project with Vite\nDESCRIPTION: Command to create a new React project using Vite as the build tool.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm create vite@latest react-translator -- --template react\n```\n\n----------------------------------------\n\nTITLE: Installing Project Dependencies\nDESCRIPTION: Commands to navigate to the project directory and install the necessary dependencies.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd react-translator\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Development Server\nDESCRIPTION: Command to start the React development server for testing the application.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/react.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Initializing Next.js Project with create-next-app\nDESCRIPTION: Command to create a new Next.js application using the create-next-app CLI tool.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-next-app@latest\n```\n\n----------------------------------------\n\nTITLE: Starting the Node.js Server\nDESCRIPTION: Command to start the Node.js server running the Transformers.js sentiment analysis application.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/node.md#2025-04-11_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nnode app.js\n```\n\n----------------------------------------\n\nTITLE: Running the Next.js Application with Transformers.js\nDESCRIPTION: Command to start the Next.js development server to run the application locally.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/docs/source/tutorials/next.md#2025-04-11_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Adding Vector Column in Supabase SQL\nDESCRIPTION: SQL command to add a new vector column with 512 dimensions to the images table for storing image embeddings.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search/README.md#2025-04-11_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nalter table images add column image_embedding vector(512);\n```\n\n----------------------------------------\n\nTITLE: Updating Database Embeddings Bash Command\nDESCRIPTION: Bash command to update image embeddings in the Supabase database using environment variables for authentication.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search/README.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nSUPABASE_URL=your-project-url \\\nSUPABASE_SECRET_KEY=your-secret-key \\\nnode scripts/update-database.mjs\n```\n\n----------------------------------------\n\nTITLE: Creating Database Access Policy\nDESCRIPTION: SQL command to create a policy allowing public read access to the images table.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search/README.md#2025-04-11_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\ncreate policy \"policy_name\"\non public.images\nfor select using (\n    true\n);\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server\nDESCRIPTION: Command to start the local development server for the application.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search/README.md#2025-04-11_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Starting Next.js Development Server\nDESCRIPTION: Commands to run the Next.js development server using npm, yarn, or pnpm. This allows developers to start the local development environment.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/semantic-image-search-client/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Running Development Server in Next.js Project\nDESCRIPTION: Commands to start the Next.js development server using different package managers (npm, yarn, or pnpm). Running these commands will launch the development environment at http://localhost:3000.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/next-client/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Running Next.js Development Server\nDESCRIPTION: Commands to start the Next.js development server using npm, yarn, or pnpm. This allows developers to run the project locally for development and testing.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/next-server/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n# or\nyarn dev\n# or\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Cloning the Transformers.js Repository\nDESCRIPTION: Command to clone the Transformers.js repository from GitHub and navigate to the extension example directory.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/extension/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/huggingface/transformers.js.git\ncd transformers.js/examples/extension/\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for the Extension\nDESCRIPTION: Command to install the necessary Node.js dependencies for the browser extension project.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/extension/README.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Building the Transformers.js Extension\nDESCRIPTION: Command to build the browser extension project, which compiles the source code into the build directory.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/extension/README.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Development Mode Command for Extension\nDESCRIPTION: Command to run the extension in development mode, which automatically rebuilds the project when changes are detected.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/extension/README.md#2025-04-11_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Cloning Transformers.js Repository and Entering Project Directory\nDESCRIPTION: Commands to clone the Transformers.js repository from GitHub and navigate to the Electron example directory.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/electron/README.md#2025-04-11_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/huggingface/transformers.js.git\ncd transformers.js/examples/electron/\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Electron Application\nDESCRIPTION: Command to install all necessary npm dependencies for the Transformers.js Electron example.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/electron/README.md#2025-04-11_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Running the Transformers.js Electron Application\nDESCRIPTION: Command to start the Electron application which will launch the application window.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/electron/README.md#2025-04-11_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run start\n```\n\n----------------------------------------\n\nTITLE: React Vite Project Documentation\nDESCRIPTION: Markdown documentation explaining the available official Vite plugins for React integration, including links to plugin documentation and their respective bundler implementations.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/musicgen-web/README.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# React + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for React-Vite Setup\nDESCRIPTION: Documentation listing the official plugins available for React with Vite, specifically highlighting options for Fast Refresh implementation using either Babel or SWC.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/webgpu-vlm/README.md#2025-04-11_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# React + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n```\n\n----------------------------------------\n\nTITLE: Listing Official Vite Plugins for React\nDESCRIPTION: Enumerates the two official Vite plugins available for React projects, detailing their dependencies and purposes.\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/examples/florence2-webgpu/README.md#2025-04-11_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n```\n\n----------------------------------------\n\nTITLE: Defining Package Dependencies for transformers.js Project\nDESCRIPTION: This requirements file specifies exact versions of packages needed for the transformers.js project. It includes transformers with PyTorch backend (4.49.0), ONNX runtime (1.20.1), a specific commit of Optimum from GitHub, ONNX (1.17.0), tqdm for progress bars (4.67.1), and onnxslim (0.1.48).\nSOURCE: https://github.com/huggingface/transformers.js/blob/main/scripts/requirements.txt#2025-04-11_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntransformers[torch]==4.49.0\nonnxruntime==1.20.1\noptimum@git+https://github.com/huggingface/optimum.git@b04feaea78cda58d79b8da67dca3fd0c4ab33435\nonnx==1.17.0\ntqdm==4.67.1\nonnxslim==0.1.48\n```"
  }
]