[
  {
    "owner": "quivrhq",
    "repo": "quivr",
    "content": "TITLE: Defining Brain Class for Quivr Knowledge Management in Python\nDESCRIPTION: Implementation of the Brain class with initialization for knowledge management in Quivr. The class is responsible for handling vector storage, retrieval operations, and knowledge exploration with support for different vector store types.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/brain/brain.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Brain:\\n    \"\"\"Brain class for Quivr.\\n\\n    A brain is a set of documents and their embeddings, stored in a vector store.\\n    One needs a brain to create chat session or explore documents.\\n    \"\"\"\\n\\n    id: UUID\\n    user_id: UUID\\n    name: str\\n    status: Literal[\\\"creating\\\", \\\"updating\\\", \\\"ready\\\", \\\"error\\\"]\\n    model: str\\n    max_tokens: int\\n    temperature: float\\n    description: Optional[str] = None\\n    prompt_id: Optional[UUID] = None\\n    brain_definition: Optional[BrainDefinition] = None\\n    brain_type: Optional[BrainType] = None\\n    connected_brains_ids: Optional[list[UUID]] = None\\n    vector_db: Optional[str] = None\\n\\n    _brain_service: Optional[BrainService] = None\\n    _brain_stats_service: Optional[BrainStatsService] = None\\n    _brain_dag_service: Optional[BrainDagService] = None\\n    _prompt_service: Optional[PromptService] = None\\n    _brain_vector_store_service: Optional[BrainVectorStoreService] = None\\n\\n    def __init__(\\n        self,\\n        id: UUID,\\n        name: str,\\n        user_id: UUID,\\n        status: Literal[\\\"creating\\\", \\\"updating\\\", \\\"ready\\\", \\\"error\\\"] = \\\"creating\\\",\\n        model: str = \\\"gpt-3.5-turbo-1106\\\",\\n        max_tokens: int = 256,\\n        temperature: float = 0.1,\\n        description: Optional[str] = None,\\n        prompt_id: Optional[UUID] = None,\\n        brain_type: Optional[BrainType] = None,\\n        connected_brains_ids: Optional[list[UUID]] = None,\\n        brain_definition: Optional[BrainDefinition] = None,\\n        vector_db: Optional[str] = None,\\n        prompt_service: Optional[PromptService] = None,\\n        brain_service: Optional[BrainService] = None,\\n        brain_stats_service: Optional[BrainStatsService] = None,\\n        brain_vector_store_service: Optional[BrainVectorStoreService] = None,\\n    ):\\n        \"\"\"Initialize a Brain object.\\n\\n        Args:\\n            id: UUID of the brain.\\n            name: Name of the brain.\\n            user_id: UUID of the user who created the brain.\\n            status: Status of the brain. Defaults to \\\"creating\\\".\\n            model: Model used for the brain. Defaults to \\\"gpt-3.5-turbo-1106\\\".\\n            max_tokens: Max tokens used for the brain. Defaults to 256.\\n            temperature: Temperature used for the brain. Defaults to 0.1.\\n            description: Description of the brain. Defaults to None.\\n            prompt_id: UUID of the prompt. Defaults to None.\\n            brain_type: Type of the brain. Defaults to None.\\n            connected_brains_ids: List of connected brains UUIDs. Defaults to None.\\n            brain_definition: Definition of the brain. Defaults to None.\\n            vector_db: Vector store type. Defaults to None.\\n        \"\"\"\\n        self.id = id\\n        self.name = name\\n        self.status = status\\n        self.model = model\\n        self.max_tokens = max_tokens\\n        self.temperature = temperature\\n        self.description = description\\n        self.prompt_id = prompt_id\\n        self.user_id = user_id\\n        self.brain_type = brain_type or BrainType.PUBLIC\\n        self.connected_brains_ids = connected_brains_ids or []\\n        self.brain_definition = brain_definition or None\\n        self.vector_db = vector_db\\n\\n        self._brain_service = brain_service\\n        self._prompt_service = prompt_service\\n        self._brain_stats_service = brain_stats_service\\n        self._brain_vector_store_service = brain_vector_store_service\n```\n\n----------------------------------------\n\nTITLE: Configuring Standard RAG Workflow in YAML for Quivr\nDESCRIPTION: This example shows a complete YAML configuration for a standard RAG workflow, defining the flow between nodes (START, filter_history, rewrite, retrieve, generate_rag), setting conversation context limits, and configuring reranker and LLM parameters. It demonstrates how to structure a workflow with proper node connections and parameter settings.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/config/index.md#2025-04-07_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nworkflow_config:\n  name: \"standard RAG\"\n  nodes:\n    - name: \"START\"\n      edges: [\"filter_history\"]\n\n    - name: \"filter_history\"\n      edges: [\"rewrite\"]\n\n    - name: \"rewrite\"\n      edges: [\"retrieve\"]\n\n    - name: \"retrieve\"\n      edges: [\"generate_rag\"]\n\n    - name: \"generate_rag\" # the name of the last node, from which we want to stream the answer to the user, should always start with \"generate\"\n      edges: [\"END\"]\n# Maximum number of previous conversation iterations\n# to include in the context of the answer\nmax_history: 10\n\nprompt: \"my prompt\"\n\nmax_files: 20\nreranker_config:\n  # The reranker supplier to use\n  supplier: \"cohere\"\n\n  # The model to use for the reranker for the given supplier\n  model: \"rerank-multilingual-v3.0\"\n\n  # Number of chunks returned by the reranker\n  top_n: 5\nllm_config:\n\n  max_context_tokens: 2000\n\n  temperature: 0.7\n  streaming: true\n```\n\n----------------------------------------\n\nTITLE: Configuring RAG Workflow with YAML\nDESCRIPTION: Defines the workflow configuration including tools, nodes, history limits, and reranker settings in YAML format. Includes settings for maximum history, chunk retrieval, and LLM parameters.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/rag_with_web_search.md#2025-04-07_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nworkflow_config:\n  name: \"RAG with web search\"\n\n  # List of tools that the agent can activate if the user instructions require it\n  available_tools:\n    - \"web search\"\n\n  nodes:\n    - name: \"START\"\n      conditional_edge:\n        routing_function: \"routing_split\"\n        conditions: [\"edit_system_prompt\", \"filter_history\"]\n\n    - name: \"edit_system_prompt\"\n      edges: [\"filter_history\"]\n\n    - name: \"filter_history\"\n      edges: [\"dynamic_retrieve\"]\n\n    - name: \"dynamic_retrieve\"\n      conditional_edge:\n        routing_function: \"tool_routing\"\n        conditions: [\"run_tool\", \"generate_rag\"]\n\n    - name: \"run_tool\"\n      edges: [\"generate_rag\"]\n\n    - name: \"generate_rag\" # the name of the last node, from which we want to stream the answer to the user\n      edges: [\"END\"]\n      tools:\n        - name: \"cited_answer\"\n\n# Maximum number of previous conversation iterations\n# to include in the context of the answer\nmax_history: 10\n\n# Number of chunks returned by the retriever\nk: 40\n\n# Reranker configuration\nreranker_config:\n  # The reranker supplier to use\n  supplier: \"cohere\"\n\n  # The model to use for the reranker for the given supplier\n  model: \"rerank-multilingual-v3.0\"\n\n  # Number of chunks returned by the reranker\n  top_n: 5\n\n  # Among the chunks returned by the reranker, only those with relevance\n  # scores equal or above the relevance_score_threshold will be returned\n  # to the LLM to generate the answer (allowed values are between 0 and 1,\n  # a value of 0.1 works well with the cohere and jina rerankers)\n  relevance_score_threshold: 0.01\n\n# LLM configuration\nllm_config:\n\n  # maximum number of tokens passed to the LLM to generate the answer\n  max_input_tokens: 8000\n\n  # temperature for the LLM\n  temperature: 0.7\n```\n\n----------------------------------------\n\nTITLE: RAG Workflow Configuration\nDESCRIPTION: YAML configuration file defining the RAG workflow structure, including node connections, history limits, reranker settings, and LLM parameters. Specifies the workflow steps from start to end with various configuration options for reranking and token management.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_rag.md#2025-04-07_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nworkflow_config:\n  name: \"standard RAG\"\n  nodes:\n    - name: \"START\"\n      edges: [\"filter_history\"]\n\n    - name: \"filter_history\"\n      edges: [\"rewrite\"]\n\n    - name: \"rewrite\"\n      edges: [\"retrieve\"]\n\n    - name: \"retrieve\"\n      edges: [\"generate_rag\"]\n\n    - name: \"generate_rag\" # the name of the last node, from which we want to stream the answer to the user\n      edges: [\"END\"]\n\n# Maximum number of previous conversation iterations\n# to include in the context of the answer\nmax_history: 10\n\n# Reranker configuration\nreranker_config:\n  # The reranker supplier to use\n  supplier: \"cohere\"\n\n  # The model to use for the reranker for the given supplier\n  model: \"rerank-multilingual-v3.0\"\n\n  # Number of chunks returned by the reranker\n  top_n: 5\n\n# Configuration for the LLM\nllm_config:\n\n  # maximum number of tokens passed to the LLM to generate the answer\n  max_input_tokens: 4000\n\n  # temperature for the LLM\n  temperature: 0.7\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic RAG System with Quivr\nDESCRIPTION: Example Python code demonstrating how to create a basic RAG system using Quivr. The code creates a temporary text file, initializes a Brain instance, and performs a question-answering task in French.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/index.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\n\nfrom quivr_core import Brain\n\nif __name__ == \"__main__\":\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\") as temp_file:\n        temp_file.write(\"Gold is a liquid of blue-like colour.\")\n        temp_file.flush()\n\n        brain = Brain.from_files(\n            name=\"test_brain\",\n            file_paths=[temp_file.name],\n        )\n\n        answer = brain.ask(\n            \"what is gold? asnwer in french\"\n        )\n        print(\"answer:\", answer)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Querying Quivr Brain with Default Settings\nDESCRIPTION: This snippet demonstrates how to create a Brain instance from files, and use it to ask a question. It uses the default Quivr RAG workflow for information retrieval.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/brain/index.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\nfrom quivr_core.quivr_rag_langgraph import QuivrQARAGLangGraph\n\n\nbrain = Brain.from_files(name=\"My Brain\", file_paths=[\"file1.pdf\", \"file2.pdf\"])\nanswer = brain.ask(\"What is Quivr ?\")\nprint(\"Answer Quivr :\", answer.answer)\n```\n\n----------------------------------------\n\nTITLE: Defining StorageBase Abstract Class in Python\nDESCRIPTION: This code defines the StorageBase abstract base class with abstract methods for various storage operations. It includes methods for uploading, retrieving, and deleting files, as well as handling chat history and user settings.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/storage/base.md#2025-04-07_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List\n\nfrom fastapi import UploadFile\n\n\nclass StorageBase(ABC):\n    @abstractmethod\n    def get_file(self, file_name: str) -> bytes:\n        pass\n\n    @abstractmethod\n    def get_files(self) -> List[str]:\n        pass\n\n    @abstractmethod\n    def upload_file(self, file: UploadFile) -> str:\n        pass\n\n    @abstractmethod\n    def delete_file(self, file_name: str) -> None:\n        pass\n\n    @abstractmethod\n    def get_chat_history(self, chat_id: str) -> Dict[str, Any]:\n        pass\n\n    @abstractmethod\n    def update_chat_history(self, chat_id: str, history: Dict[str, Any]) -> None:\n        pass\n\n    @abstractmethod\n    def create_chat_history(self, chat_id: str) -> None:\n        pass\n\n    @abstractmethod\n    def get_user_settings(self, user_id: str) -> Dict[str, Any]:\n        pass\n\n    @abstractmethod\n    def update_user_settings(self, user_id: str, settings: Dict[str, Any]) -> None:\n        pass\n\n    @abstractmethod\n    def create_user_settings(self, user_id: str) -> None:\n        pass\n```\n\n----------------------------------------\n\nTITLE: Customizing Quivr Brain with Custom LLM and Embedder\nDESCRIPTION: This advanced example shows how to create a Brain instance with custom LLM and embedder components. It uses a fake LLM model and a deterministic fake embedding for demonstration purposes.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/brain/index.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\nfrom quivr_core.llm.llm_endpoint import LLMEndpoint\nfrom quivr_core.embedder.embedder import DeterministicFakeEmbedding\nfrom quivr_core.llm.llm_endpoint import LLMEndpointConfig\nfrom quivr_core.llm.llm_endpoint import FakeListChatModel\n\nbrain = Brain.from_files(\n        name=\"test_brain\",\n        file_paths=[\"my/information/source/file.pdf\"],\n        llm=LLMEndpoint(\n            llm=FakeListChatModel(responses=[\"good\"]),\n            llm_config=LLMEndpointConfig(model=\"fake_model\", llm_base_url=\"local\"),\n        ),\n        embedder=DeterministicFakeEmbedding(size=20),\n    )\n\nanswer = brain.ask(\n            \"What is Quivr ?\"\n        )\nprint(\"Answer Quivr :\", answer.answer)\n```\n\n----------------------------------------\n\nTITLE: Customizing Quivr Brain with Mistral LLM and Custom Embeddings\nDESCRIPTION: Demonstrates how to create a Brain instance with custom LLM configuration using Mistral and specific embedding parameters.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/quickstart.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\nfrom langchain_core.embeddings import Embeddings\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"/my_smart_doc.pdf\", \"/my_intelligent_doc.txt\"],\n                        llm=LLMEndpoint(\n                            llm_config=LLMEndpointConfig(model=\"mistral-small-latest\", llm_base_url=\"https://api.mistral.ai/v1/chat/completions\"),\n                        ),\n                        embedder=Embeddings(size=64),\n                        )\n```\n\n----------------------------------------\n\nTITLE: Implementing Local Storage in Python\nDESCRIPTION: Interface for local storage operations including save and get methods for handling file data. Implements file system operations for data persistence.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/storage/local_storage.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: quivr_core.storage.local_storage\noptions:\nheading_level: 2\n\n```\n\n----------------------------------------\n\nTITLE: Creating YAML Configuration for Document Parsing and Chunking\nDESCRIPTION: Defines a YAML configuration file for document parsing strategy and chunking parameters. The configuration specifies the parsing strategy, PDF parser, chunk size, and chunk overlap for effective document processing.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_ingestion.md#2025-04-07_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nparser_config:\n  megaparse_config:\n    strategy: \"auto\" # for unstructured, it can be \"auto\", \"fast\", \"hi_res\", \"ocr_only\", see https://docs.unstructured.io/open-source/concepts/partitioning-strategies#partitioning-strategies\n    pdf_parser: \"unstructured\"\n  splitter_config:\n    chunk_size: 400 # in tokens\n    chunk_overlap: 100 # in tokens\n```\n\n----------------------------------------\n\nTITLE: Basic Quivr Brain Implementation\nDESCRIPTION: Example showing how to create and use a basic Quivr brain instance with a temporary test file\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\n\nfrom quivr_core import Brain\n\nif __name__ == \"__main__\":\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\") as temp_file:\n        temp_file.write(\"Gold is a liquid of blue-like colour.\")\n        temp_file.flush()\n\n        brain = Brain.from_files(\n            name=\"test_brain\",\n            file_paths=[temp_file.name],\n        )\n\n        answer = brain.ask(\n            \"what is gold? asnwer in french\"\n        )\n        print(\"answer:\", answer)\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Quivr Brain Instance\nDESCRIPTION: Shows how to initialize a Brain instance with default configuration, specifying a name and file paths for document processing.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/quickstart.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"/my_smart_doc.pdf\", \"/my_intelligent_doc.txt\"],\n                        )\n\n```\n\n----------------------------------------\n\nTITLE: RAG Workflow Configuration\nDESCRIPTION: YAML configuration file defining the RAG workflow, including node structure, history limits, reranker settings, and LLM parameters\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nworkflow_config:\n  name: \"standard RAG\"\n  nodes:\n    - name: \"START\"\n      edges: [\"filter_history\"]\n\n    - name: \"filter_history\"\n      edges: [\"rewrite\"]\n\n    - name: \"rewrite\"\n      edges: [\"retrieve\"]\n\n    - name: \"retrieve\"\n      edges: [\"generate_rag\"]\n\n    - name: \"generate_rag\"\n      edges: [\"END\"]\n\nmax_history: 10\n\nreranker_config:\n  supplier: \"cohere\"\n  model: \"rerank-multilingual-v3.0\"\n  top_n: 5\n\nllm_config:\n  max_input_tokens: 4000\n  temperature: 0.7\n```\n\n----------------------------------------\n\nTITLE: Creating Quivr Brain Instance\nDESCRIPTION: Python code demonstrating how to create a Brain instance with multiple input files\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"./my_first_doc.pdf\", \"./my_second_doc.txt\"],\n                        )\n```\n\n----------------------------------------\n\nTITLE: Interactive Chat Implementation\nDESCRIPTION: Complete implementation of an interactive chat interface using Quivr brain with rich console formatting\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nbrain.print_info()\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\nfrom quivr_core.config import RetrievalConfig\n\nconfig_file_name = \"./basic_rag_workflow.yaml\"\n\nretrieval_config = RetrievalConfig.from_yaml(config_file_name)\n\nconsole = Console()\nconsole.print(Panel.fit(\"Ask your brain !\", style=\"bold magenta\"))\n\nwhile True:\n    question = Prompt.ask(\"[bold cyan]Question[/bold cyan]\")\n\n    if question.lower() == \"exit\":\n        console.print(Panel(\"Goodbye!\", style=\"bold yellow\"))\n        break\n\n    answer = brain.ask(question, retrieval_config=retrieval_config)\n    console.print(f\"[bold green]Quivr Assistant[/bold green]: {answer.answer}\")\n\n    console.print(\"-\" * console.width)\n\nbrain.print_info()\n```\n\n----------------------------------------\n\nTITLE: Creating a Brain with Document Ingestion in Quivr\nDESCRIPTION: Initializes a Brain object using the configuration file and ingests the specified documents. The function loads the YAML configuration, sets up processing parameters, and creates a Brain object with the provided files.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_ingestion.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\nfrom quivr_core.config import IngestionConfig\n\nconfig_file_name = \"./basic_ingestion_workflow.yaml\"\n\ningestion_config = IngestionConfig.from_yaml(config_file_name)\n\nprocessor_kwargs = {\n    \"megaparse_config\": ingestion_config.parser_config.megaparse_config,\n    \"splitter_config\": ingestion_config.parser_config.splitter_config,\n}\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"./my_first_doc.pdf\", \"./my_second_doc.txt\"],\n                        processor_kwargs=processor_kwargs,\n                        )\n\n```\n\n----------------------------------------\n\nTITLE: Creating Brain Instance\nDESCRIPTION: Initializes a Brain instance from document files, allowing the system to process and store information from PDF and text documents.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_rag.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"./my_first_doc.pdf\", \"./my_second_doc.txt\"],\n                        )\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Qdrant Vector Store in Python\nDESCRIPTION: This code snippet demonstrates how to initialize a Qdrant vector store for Quivr. It sets up the connection parameters and creates a Qdrant client instance.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/index.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom qdrant_client import QdrantClient\nfrom langchain.vectorstores import Qdrant\n\nqdrant_client = QdrantClient(\n    url=self.settings.qdrant_url,\n    api_key=self.settings.qdrant_api_key,\n)\nself.vectorstore = Qdrant(\n    client=qdrant_client,\n    collection_name=self.settings.qdrant_collection_name,\n    embeddings=self.embeddings,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Chroma Vector Store in Python\nDESCRIPTION: This code snippet shows the initialization of a Chroma vector store for Quivr. It sets up the necessary parameters and creates a Chroma instance.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/index.md#2025-04-07_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain.vectorstores import Chroma\n\nself.vectorstore = Chroma(\n    collection_name=self.settings.chroma_collection_name,\n    embedding_function=self.embeddings,\n    client_settings=chromadb.config.Settings(\n        chroma_api_impl=\"rest\",\n        chroma_server_host=self.settings.chroma_endpoint,\n        chroma_server_http_port=self.settings.chroma_port,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Weaviate Vector Store in Python\nDESCRIPTION: This code snippet illustrates the initialization of a Weaviate vector store for Quivr. It configures the connection settings and creates a Weaviate instance.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/index.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport weaviate\nfrom langchain.vectorstores import Weaviate\n\nclient = weaviate.Client(\n    url=self.settings.weaviate_url,\n    auth_client_secret=weaviate.AuthApiKey(api_key=self.settings.weaviate_api_key),\n)\nself.vectorstore = Weaviate(\n    client=client,\n    index_name=self.settings.weaviate_index_name,\n    text_key=\"text\",\n    embedding=self.embeddings,\n    attributes=[\"source\", \"doc_id\"],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Chat Interface\nDESCRIPTION: Sets up an interactive chat interface with the configured brain, including user input handling and response formatting using Rich library.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/rag_with_web_search.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbrain.print_info()\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\nfrom quivr_core.config import RetrievalConfig\n\nconfig_file_name = \"./rag_with_web_search_workflow.yaml\"\n\nretrieval_config = RetrievalConfig.from_yaml(config_file_name)\n\nconsole = Console()\nconsole.print(Panel.fit(\"Ask your brain !\", style=\"bold magenta\"))\n\nwhile True:\n    # Get user input\n    question = Prompt.ask(\"[bold cyan]Question[/bold cyan]\")\n\n    # Check if user wants to exit\n    if question.lower() == \"exit\":\n        console.print(Panel(\"Goodbye!\", style=\"bold yellow\"))\n        break\n\n    answer = brain.ask(question, retrieval_config=retrieval_config)\n    # Print the answer with typing effect\n    console.print(f\"[bold green]Quivr Assistant[/bold green]: {answer.answer}\")\n\n    console.print(\"-\" * console.width)\n\nbrain.print_info()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Interface\nDESCRIPTION: Sets up an interactive chat interface using Rich library for formatted console output. Implements a loop for continuous question-answering interaction with the brain using the configured retrieval settings.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_rag.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbrain.print_info()\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\nfrom quivr_core.config import RetrievalConfig\n\nconfig_file_name = \"./basic_rag_workflow.yaml\"\n\nretrieval_config = RetrievalConfig.from_yaml(config_file_name)\n\nconsole = Console()\nconsole.print(Panel.fit(\"Ask your brain !\", style=\"bold magenta\"))\n\nwhile True:\n    # Get user input\n    question = Prompt.ask(\"[bold cyan]Question[/bold cyan]\")\n\n    # Check if user wants to exit\n    if question.lower() == \"exit\":\n        console.print(Panel(\"Goodbye!\", style=\"bold yellow\"))\n        break\n\n    answer = brain.ask(question, retrieval_config=retrieval_config)\n    # Print the answer with typing effect\n    console.print(f\"[bold green]Quivr Assistant[/bold green]: {answer.answer}\")\n\n    console.print(\"-\" * console.width)\n\nbrain.print_info()\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Chat with Quivr Brain\nDESCRIPTION: Creates an interactive chat interface to communicate with the Quivr Brain. The code sets up a loop that takes user questions, queries the brain for answers, and displays the responses with rich formatting until the user exits.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_ingestion.md#2025-04-07_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nbrain.print_info()\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\n\nconsole = Console()\nconsole.print(Panel.fit(\"Ask your brain !\", style=\"bold magenta\"))\n\nwhile True:\n    # Get user input\n    question = Prompt.ask(\"[bold cyan]Question[/bold cyan]\")\n\n    # Check if user wants to exit\n    if question.lower() == \"exit\":\n        console.print(Panel(\"Goodbye!\", style=\"bold yellow\"))\n        break\n\n    answer = brain.ask(question)\n    # Print the answer with typing effect\n    console.print(f\"[bold green]Quivr Assistant[/bold green]: {answer.answer}\")\n\n    console.print(\"-\" * console.width)\n\nbrain.print_info()\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Chat with Quivr Brain\nDESCRIPTION: Creates an interactive chat interface using Rich library for console formatting, allowing users to ask questions and receive responses from the brain.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/quickstart.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nbrain.print_info()\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.prompt import Prompt\n\nconsole = Console()\nconsole.print(Panel.fit(\"Ask your brain !\", style=\"bold magenta\"))\n\nwhile True:\n    # Get user input\n    question = Prompt.ask(\"[bold cyan]Question[/bold cyan]\")\n\n    # Check if user wants to exit\n    if question.lower() == \"exit\":\n        console.print(Panel(\"Goodbye!\", style=\"bold yellow\"))\n        break\n\n    answer = brain.ask(question)\n    # Print the answer with typing effect\n    console.print(f\"[bold green]Quivr Assistant[/bold green]: {answer.answer}\")\n\n    console.print(\"-\" * console.width)\n\nbrain.print_info()\n```\n\n----------------------------------------\n\nTITLE: Describing Storage Class Functionality in Markdown\nDESCRIPTION: This snippet outlines the key features and capabilities of the Storage class, including its relationship with brain objects, file management operations, and the StorageBase class.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/storage/index.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# 🗄️ Storage\n\n## Your Brain's File Management System\n\nThe `Storage` class is the backbone of how a brain interacts with files in `quivr-core`. Every brain holds a reference to an underlying storage system to manage its files. All storages should implement the `StorageBase` base classe that provides the structure and methods to make that happen seamlessly. Let's walk through how it works:\n\n- **Brain-Storage Connection:** Your brain holds a reference to a storage system. This class is the main way your brain can interact with and manage the files it uses. Adding files to a brain will upload them to the storage. This means that files in the storage are stored **before** processing!\n- **File Management:** the storage holds a set of `QuivrFile` objects, which are the building blocks of your brain's file system. The storage can store them remotely or locally or hold simple\n\n### What can you do with this storage system?\n\n1. Upload Files: You can add new files to your storage whenever you need. The system also lets you decide whether to overwrite existing files or not.\n2. Get Files: Need to see what's in your storage? No problem. You can easily retrieve a list of all the files that are stored.\n3. Delete Files: Clean-up is simple. You can remove any file from your storage by referencing its unique file ID (more on that in `QuivrFile`).\n\nStorageBase is the foundation of how your brain organizes, uploads, retrieves, and deletes its files. It ensures that your brain can always stay up-to-date with the files it needs, making file management smooth and intuitive. You can build your own storage system by subclassing the `StorageBase` class and passing it to the brain. See [custom_storage](../examples/custom_storage.md) for more details.\n```\n\n----------------------------------------\n\nTITLE: Explaining Storage Implementations in Markdown\nDESCRIPTION: This snippet describes two storage implementations available in quivr_core: LocalStorage and TransparentStorage. It outlines their characteristics, use cases, and mentions potential future implementations.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/storage/index.md#2025-04-07_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### Storage Implementations in `quivr_core`\n\n`quivr_core` currently offers two storage implementations: `LocalStorage` and `TransparentStorage`:\n\n- **LocalStorage**:  \n  This storage type is perfect when you want to keep files on your local machine. `LocalStorage` saves your files to a specific directory, either a default path (`~/.cache/quivr/files`) or a user-defined location. It can store files by copying them or by creating symbolic links to the original files, based on your preference. This storage type also keeps track of file hashes to prevent accidental overwrites during uploads.\n\n- **TransparentStorage**:  \n  The `TransparentStorage` implementation offers a lightweight and flexible approach, mainly managing files in memory without a need for local file paths. This storage system is useful when you don't need persistent storage but rather an easy way to store and retrieve files temporarily during the brain's operation.\n\nEach of these storage systems has its own strengths, catering to different use cases. As `quivr_core` evolves, we will implementat more ande more storage systems allowing for even more advanced and customized ways to manage your files like `S3Storage`, `NFSStorage` ...\n```\n\n----------------------------------------\n\nTITLE: Error Handling with Logging in Python\nDESCRIPTION: Demonstrates proper error handling pattern using specific exception types with logging. Shows how to catch operation-specific errors and log them for debugging purposes.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/core/tests/processor/data/guidelines_code.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    result = perform_operation()\nexcept OperationError as e:\n    log.error(f\"Operation failed: {str(e)}\")\n    return error_response()\n```\n\n----------------------------------------\n\nTITLE: Creating Brain Instance from Files\nDESCRIPTION: Initializes a Brain instance using provided document files for knowledge base creation.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/rag_with_web_search.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core import Brain\n\nbrain = Brain.from_files(name = \"my smart brain\",\n                        file_paths = [\"./my_first_doc.pdf\", \"./my_second_doc.txt\"],\n                        )\n\n```\n\n----------------------------------------\n\nTITLE: Initializing API Keys for OpenAI and Tavily\nDESCRIPTION: Sets up required API keys for OpenAI and Tavily services as environment variables.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/rag_with_web_search.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"my_openai_api_key\"\nos.environ[\"TAVILY_API_KEY\"] = \"my_tavily_api_key\"\n\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Configures the OpenAI API key as an environment variable for authentication. The system also supports APIs from Anthropic, Mistral, and local models via Ollama.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_rag.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"myopenai_apikey\"\n\n```\n\n----------------------------------------\n\nTITLE: Setting up OpenAI API Key for Quivr\nDESCRIPTION: Sets the OpenAI API key as an environment variable. Quivr supports APIs from OpenAI, Anthropic, Mistral, and local models using Ollama as specified in the .env.example file.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/workflows/examples/basic_ingestion.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"myopenai_apikey\"\n\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable in Python\nDESCRIPTION: Demonstrates how to set up the OpenAI API key as an environment variable for Quivr. The system also supports APIs from Anthropic, Mistral, and local models via Ollama.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/quickstart.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"myopenai_apikey\"\n\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Code snippet showing how to set the OpenAI API key as an environment variable\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.environ[\"OPENAI_API_KEY\"] = \"myopenai_apikey\"\n```\n\n----------------------------------------\n\nTITLE: Creating Vector Table for Quivr Data\nDESCRIPTION: This SQL snippet creates a table named 'items' with a vector column for storing embeddings in Quivr. It includes an ID, content field, and a 1536-dimensional vector for embeddings.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE items (\n  id BIGSERIAL PRIMARY KEY,\n  content TEXT,\n  embedding VECTOR(1536)\n);\n```\n\n----------------------------------------\n\nTITLE: Creating Index for Vector Similarity Search in Quivr\nDESCRIPTION: This SQL command creates an index on the 'embedding' column of the 'items' table using the HNSW algorithm. It optimizes vector similarity searches in Quivr.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE INDEX ON items USING hnsw (embedding vector_cosine_ops);\n```\n\n----------------------------------------\n\nTITLE: Inserting Vector Data into Quivr Database\nDESCRIPTION: This SQL snippet demonstrates how to insert vector data into the 'items' table in Quivr. It includes both the content and the corresponding embedding vector.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nINSERT INTO items (content, embedding) VALUES ('example text', '[1,2,3,...]');\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Similarity Search in Quivr\nDESCRIPTION: This SQL query performs a vector similarity search in Quivr. It finds the top 5 most similar items to a given query vector, ordered by cosine similarity.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nSELECT content, 1 - (embedding <=> '[1,2,3,...]') as similarity\nFROM items\nORDER BY embedding <=> '[1,2,3,...]'\nLIMIT 5;\n```\n\n----------------------------------------\n\nTITLE: Initializing PGVector Extension in Quivr\nDESCRIPTION: This SQL command initializes the PGVector extension in the PostgreSQL database for Quivr. It enables vector operations and indexing capabilities.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nCREATE EXTENSION vector;\n```\n\n----------------------------------------\n\nTITLE: Creating PostgreSQL Database for PGVector in Quivr\nDESCRIPTION: This SQL snippet creates a new PostgreSQL database named 'vectordb' for use with PGVector in Quivr. It also creates a new user 'myuser' with a password and grants necessary privileges.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/vectorstores/pgvector.md#2025-04-07_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE DATABASE vectordb;\nCREATE USER myuser WITH PASSWORD 'mypassword';\nGRANT ALL PRIVILEGES ON DATABASE vectordb TO myuser;\n```\n\n----------------------------------------\n\nTITLE: Importing ChatHistory Class in Python\nDESCRIPTION: This snippet shows how to import the ChatHistory class from the Quivr project. The ChatHistory class is located in the quivr_core.rag.entities.chat module.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/brain/chat.md#2025-04-07_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom quivr_core.rag.entities.chat import ChatHistory\n```\n\n----------------------------------------\n\nTITLE: Defining Base Configuration Class Structure\nDESCRIPTION: Base configuration class documentation comment defining the structure and organization of configuration parameters in Markdown format.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/config/base_config.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: quivr_core.base_config\n    options:\n      heading_level: 2\n```\n\n----------------------------------------\n\nTITLE: Markdown Configuration Structure Documentation\nDESCRIPTION: Documentation structure defining the key configuration components of the Quivr Core RAG system, including path references to configuration entity definitions.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/config/config.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Configuration\n\n## Retrieval Configuration\n::: quivr_core.rag.entities.config.RetrievalConfig\n\n## Workflow Configuration\n::: quivr_core.rag.entities.config.WorkflowConfig\n\n## LLM Configuration\n::: quivr_core.rag.entities.config.LLMEndpointConfig\n\n## Reranker Configuration\n::: quivr_core.rag.entities.config.RerankerConfig\n\n## Supported LLM Model Suppliers\n::: quivr_core.rag.entities.config.DefaultModelSuppliers\n\n## Supported Rerankers\n::: quivr_core.rag.entities.config.DefaultRerankers\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Rye Package Manager\nDESCRIPTION: Command to install required dependencies using the Rye package manager. This step syncs all the dependencies specified in the project configuration.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot/README.md#2025-04-07_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nrye sync\n```\n\n----------------------------------------\n\nTITLE: Activating the Python Virtual Environment\nDESCRIPTION: Command to activate the Python virtual environment created by Rye. This ensures that the chatbot runs with the correct dependencies.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot/README.md#2025-04-07_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nsource ./venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Running the Chainlit Chatbot Server\nDESCRIPTION: Command to start the Chainlit server with the main.py file. This launches the chatbot interface that will be accessible through a web browser.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot/README.md#2025-04-07_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip\nDESCRIPTION: Command to install required Python packages for the chatbot implementation using pip package manager.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot/chainlit.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit Server\nDESCRIPTION: Command to launch the Chainlit server which hosts the chatbot interface.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot/chainlit.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Quivr Chatbot\nDESCRIPTION: This command installs the required dependencies for the Quivr chatbot from the requirements.lock file. It should be run in the project's root directory or the core/examples/chatbot directory.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot_voice/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.lock\n```\n\n----------------------------------------\n\nTITLE: Running Chainlit Server for Quivr Chatbot\nDESCRIPTION: This command starts the Chainlit server, which hosts the chatbot interface. It runs the main.py file, which contains the chatbot logic.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot_voice/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Quivr Chatbot\nDESCRIPTION: Command to install required Python packages for the chatbot implementation using pip package manager.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot_voice/chainlit.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Starting Chainlit Server\nDESCRIPTION: Command to launch the Chainlit server which hosts the chatbot interface.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/chatbot_voice/chainlit.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating to Project Directory\nDESCRIPTION: Commands to clone the Quivr repository and navigate to the chatbot example directory.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/QuivrHQ/quivr\ncd examples/chatbot\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key as Environment Variable\nDESCRIPTION: Command to set the OpenAI API key as an environment variable for the chatbot to use.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='<your-key-here>'\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Command to install the necessary Python dependencies for the chatbot project.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.lock\n```\n\n----------------------------------------\n\nTITLE: Starting the Chainlit Server\nDESCRIPTION: Command to run the main Python script and start the Chainlit server for the chatbot.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Repository in Bash\nDESCRIPTION: Commands to clone the Quivr repository and navigate to the chatbot voice example directory.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/QuivrHQ/quivr\ncd examples/chatbot_voice\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Bash Environment\nDESCRIPTION: Command to set the OpenAI API key as an environment variable required for the chatbot functionality.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='<your-key-here>'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Pip\nDESCRIPTION: Command to install all required Python dependencies from the requirements lock file.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.lock\n```\n\n----------------------------------------\n\nTITLE: Starting the Chainlit Server\nDESCRIPTION: Command to launch the Chainlit server that hosts the chatbot interface.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nchainlit run main.py\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Project Directory in Bash\nDESCRIPTION: Commands to clone the Quivr repository and navigate to the quivr-whisper example directory, which contains the voice chatbot implementation.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice_flask.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/QuivrHQ/quivr\ncd examples/quivr-whisper\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key as Environment Variable in Bash\nDESCRIPTION: Command to set the OpenAI API key as an environment variable, which is required for the application to interact with OpenAI services like Whisper and text-to-speech.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice_flask.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='<your-key-here>'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Pip in Bash\nDESCRIPTION: Command to install all the required Python dependencies from the requirements.lock file, ensuring compatible versions of all libraries are used.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice_flask.md#2025-04-07_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.lock\n```\n\n----------------------------------------\n\nTITLE: Starting the Flask Server in Bash\nDESCRIPTION: Command to start the Flask application server, which will host the voice chatbot interface and handle requests for file uploads and audio processing.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/examples/chatbot_voice_flask.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython app.py\n```\n\n----------------------------------------\n\nTITLE: Installing Quivr Core Package using pip\nDESCRIPTION: Command to install the quivr-core package via pip package manager. This is the first step in setting up Quivr in your environment.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/index.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install quivr-core # Check that the installation worked\n```\n\n----------------------------------------\n\nTITLE: Cloning and Navigating to Quivr-Whisper Repository\nDESCRIPTION: Commands to clone the Quivr-Whisper repository from GitHub and navigate to the project directory.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/quivr-whisper/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/stangirard/quivr-whisper.git\ncd Quivr-talk\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Packages for Quivr-Whisper\nDESCRIPTION: Command to install the necessary Python packages using pip, including Flask, OpenAI, requests, and python-dotenv.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/quivr-whisper/README.md#2025-04-07_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install flask openai requests python-dotenv\n```\n\n----------------------------------------\n\nTITLE: Configuring Environment Variables for Quivr-Whisper\nDESCRIPTION: Example content for the .env file, including API keys and configuration variables required for the application to function properly.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/quivr-whisper/README.md#2025-04-07_snippet_2\n\nLANGUAGE: env\nCODE:\n```\nOPENAI_API_KEY='your_openai_api_key'\nQUIVR_API_KEY='your_quivr_api_key'\nQUIVR_CHAT_ID='your_quivr_chat_id'\nQUIVR_BRAIN_ID='your_quivr_brain_id'\nQUIVR_URL='https://api.quivr.app' # Optional, only if different from the default\n```\n\n----------------------------------------\n\nTITLE: Running the Quivr-Whisper Flask Application\nDESCRIPTION: Command to start the Flask application, which will run the Quivr-Whisper web service on the local machine.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/quivr-whisper/README.md#2025-04-07_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nflask run\n```\n\n----------------------------------------\n\nTITLE: Configuring Simple Text Processor Documentation\nDESCRIPTION: YAML configuration block that sets up documentation parameters for the quivr_core.processor.implementations.simple_txt_processor module. Specifies a heading level of 2 for the documentation output.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/parsers/simple.md#2025-04-07_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n::: quivr_core.processor.implementations.simple_txt_processor\n    options:\n      heading_level: 2\n```\n\n----------------------------------------\n\nTITLE: Launching Quivr with Chainlit Interface\nDESCRIPTION: Command sequence for launching a Chainlit interface for Quivr, including synchronizing dependencies and running the application.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/docs/quickstart.md#2025-04-07_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncd examples/chatbot /\nrye sync /\nrye run chainlit run chainlit.py\n```\n\n----------------------------------------\n\nTITLE: Installing quivr-core Package via pip\nDESCRIPTION: This code snippet demonstrates how to install the quivr-core package using pip, the Python package installer. It installs the latest version of quivr-core from the Python Package Index (PyPI).\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/core/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install quivr-core\n```\n\n----------------------------------------\n\nTITLE: Installing Quivr Core Package\nDESCRIPTION: Command to install the Quivr core package using pip package manager\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/README.md#2025-04-07_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install quivr-core\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown Header for Simple Question Project\nDESCRIPTION: This snippet demonstrates the use of a top-level markdown header to title the project. It's followed by a prompt for the user to add their project description.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/examples/simple_question/README.md#2025-04-07_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# simple-question\n\nDescribe your project here.\n```\n\n----------------------------------------\n\nTITLE: Markdown Changelog Format\nDESCRIPTION: Formatted changelog entries using conventional commits style, documenting version history with features, bug fixes, and other changes\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/core/CHANGELOG.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Changelog\n\n## [0.0.33] (2025-02-03)\n\n### Features\n\n* **zendesk:** add zendesk workflow (#3586)\n\n### Bug Fixes\n\n* CLI-24\n```\n\n----------------------------------------\n\nTITLE: Markdown Version History Documentation\nDESCRIPTION: A comprehensive changelog documenting version updates from v0.0.181 to v0.0.203, including new features, bug fixes, and contributor information.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/CHANGELOG.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## What's Changed\n\n- feat: 🎸 ocr by @StanGirard in https://github.com/QuivrHQ/quivr/pull/2187\n- feat(lcel): migrated to lcel and pydantic by @StanGirard in https://github.com/QuivrHQ/quivr/pull/2185\n- feat(frontend): new brain creation modal by @Zewed in https://github.com/QuivrHQ/quivr/pull/2192\n- feat(integration): implementation by @StanGirard in https://github.com/QuivrHQ/quivr/pull/2191\n- feat(frontend): new design for brain table by @Zewed in https://github.com/QuivrHQ/quivr/pull/2193\n```\n\n----------------------------------------\n\nTITLE: Project Documentation Header\nDESCRIPTION: Basic markdown documentation placeholder with project title.\nSOURCE: https://github.com/QuivrHQ/quivr/blob/main/docs/README.md#2025-04-07_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# docs\\n\\nDescribe your project here.\n```"
  }
]