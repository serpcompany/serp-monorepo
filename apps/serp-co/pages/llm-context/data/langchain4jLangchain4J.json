[
  {
    "owner": "langchain4j",
    "repo": "langchain4j",
    "content": "TITLE: Initializing OpenAI Chat Model with Demo Key\nDESCRIPTION: Example of creating an OpenAI Chat Model instance using the demo API key for testing purposes.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel model = OpenAiChatModel.builder()\n    .baseUrl(\"http://langchain4j.dev/demo/openai/v1\")\n    .apiKey(\"demo\")\n    .modelName(\"gpt-4o-mini\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple AI Service Interface in Java\nDESCRIPTION: Demonstrates how to define a basic AI Service interface with a single chat method that takes a String input and returns a String output.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    String chat(String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating and Using EmbeddingStoreIngestor in Java\nDESCRIPTION: Demonstrates how to create a basic EmbeddingStoreIngestor to embed documents and store them in an embedding store. The ingestor uses an embedding model to convert documents into vector embeddings that are then stored for later retrieval.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStoreIngestor ingestor = EmbeddingStoreIngestor.builder()\n        .embeddingModel(embeddingModel)\n        .embeddingStore(embeddingStore)\n        .build();\n\ningestor.ingest(document1);\ningestor.ingest(document2, document3);\nIngestionResult ingestionResult = ingestor.ingest(List.of(document4, document5, document6));\n```\n\n----------------------------------------\n\nTITLE: JSON Schema Implementation with ChatModel\nDESCRIPTION: Demonstrates how to use JSON Schema with ChatModel API to generate structured output from unstructured text. Shows configuration for multiple LLM providers including OpenAI, Azure, Google AI Gemini, Ollama, and Mistral.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nResponseFormat responseFormat = ResponseFormat.builder()\n        .type(JSON) // type can be either TEXT (default) or JSON\n        .jsonSchema(JsonSchema.builder()\n                .name(\"Person\") // OpenAI requires specifying the name for the schema\n                .rootElement(JsonObjectSchema.builder() // see [1] below\n                        .addStringProperty(\"name\")\n                        .addIntegerProperty(\"age\")\n                        .addNumberProperty(\"height\")\n                        .addBooleanProperty(\"married\")\n                        .required(\"name\", \"age\", \"height\", \"married\") // see [2] below\n                        .build())\n                .build())\n        .build();\n\nUserMessage userMessage = UserMessage.from(\"\"\"\n        John is 42 years old and lives an independent life.\n        He stands 1.75 meters tall and carries himself with confidence.\n        Currently unmarried, he enjoys the freedom to focus on his personal goals and interests.\n        \"\"\");\n\nChatRequest chatRequest = ChatRequest.builder()\n        .responseFormat(responseFormat)\n        .messages(userMessage)\n        .build();\n\nChatModel chatModel = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n// OR\nChatModel chatModel = AzureOpenAiChatModel.builder()\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_API_KEY\"))\n        .deploymentName(\"gpt-4o-mini\")\n        .logRequestsAndResponses(true)\n        .build();\n// OR\nChatModel chatModel = GoogleAiGeminiChatModel.builder()\n        .apiKey(System.getenv(\"GOOGLE_AI_GEMINI_API_KEY\"))\n        .modelName(\"gemini-1.5-flash\")\n        .logRequestsAndResponses(true)\n        .build();\n// OR\nChatModel chatModel = OllamaChatModel.builder()\n        .baseUrl(\"http://localhost:11434\")\n        .modelName(\"llama3.1\")\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n// OR\nChatModel chatModel = MistralAiChatModel.builder()\n        .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\"))\n        .modelName(\"mistral-small-latest\")\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n\nChatResponse chatResponse = chatModel.chat(chatRequest);\n\nString output = chatResponse.aiMessage().text();\nSystem.out.println(output); // {\"name\":\"John\",\"age\":42,\"height\":1.75,\"married\":false}\n\nPerson person = new ObjectMapper().readValue(output, Person.class);\nSystem.out.println(person); // Person[name=John, age=42, height=1.75, married=false]\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Spring Boot Starter Dependency\nDESCRIPTION: XML configuration for adding the main LangChain4j Spring Boot starter dependency to a Maven project. This starter enables AI Services and other core functionalities.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Implementing a Multi-Model Chatbot System with Service Decomposition in Java\nDESCRIPTION: This example demonstrates how to break down a company chatbot into separate AI services: one for detecting greetings (using a cheaper model) and another for answering questions using RAG. The code shows how these services are defined as interfaces, implemented, and coordinated in a main controller class.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_27\n\nLANGUAGE: java\nCODE:\n```\ninterface GreetingExpert {\n\n    @UserMessage(\"Is the following text a greeting? Text: {{it}}\")\n    boolean isGreeting(String text);\n}\n\ninterface ChatBot {\n\n    @SystemMessage(\"You are a polite chatbot of a company called Miles of Smiles.\")\n    String reply(String userMessage);\n}\n\nclass MilesOfSmiles {\n\n    private final GreetingExpert greetingExpert;\n    private final ChatBot chatBot;\n    \n    ...\n    \n    public String handle(String userMessage) {\n        if (greetingExpert.isGreeting(userMessage)) {\n            return \"Greetings from Miles of Smiles! How can I make your day better?\";\n        } else {\n            return chatBot.reply(userMessage);\n        }\n    }\n}\n\nGreetingExpert greetingExpert = AiServices.create(GreetingExpert.class, llama2);\n\nChatBot chatBot = AiServices.builder(ChatBot.class)\n    .chatModel(gpt4)\n    .contentRetriever(milesOfSmilesContentRetriever)\n    .build();\n\nMilesOfSmiles milesOfSmiles = new MilesOfSmiles(greetingExpert, chatBot);\n\nString greeting = milesOfSmiles.handle(\"Hello\");\nSystem.out.println(greeting); // Greetings from Miles of Smiles! How can I make your day better?\n\nString answer = milesOfSmiles.handle(\"Which services do you provide?\");\nSystem.out.println(answer); // At Miles of Smiles, we provide a wide range of services ...\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Service with Naive RAG in Java\nDESCRIPTION: Demonstrates how to configure an AI service with a ContentRetriever for naive Retrieval Augmented Generation (RAG). This setup enables the assistant to retrieve and use relevant content from an embedding store.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_25\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore  = ...\nEmbeddingModel embeddingModel = ...\n\nContentRetriever contentRetriever = new EmbeddingStoreContentRetriever(embeddingStore, embeddingModel);\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .contentRetriever(contentRetriever)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Naive RAG with AI Services in Java\nDESCRIPTION: This code demonstrates how to set up a basic naive RAG implementation using EmbeddingStoreContentRetriever with AI Services in LangChain4j. It configures the retriever with embedding store, model, and relevance thresholds.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nContentRetriever contentRetriever = EmbeddingStoreContentRetriever.builder()\n    .embeddingStore(embeddingStore)\n    .embeddingModel(embeddingModel)\n    .maxResults(5)\n    .minScore(0.75)\n    .build();\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .contentRetriever(contentRetriever)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Using AI Service in a Spring RestController\nDESCRIPTION: Java code demonstrating how to autowire and use an AI Service in a Spring RestController. This example shows a simple chat endpoint that uses the configured AI Service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\n@RestController\nclass AssistantController {\n\n    @Autowired\n    Assistant assistant;\n\n    @GetMapping(\"/chat\")\n    public String chat(String message) {\n        return assistant.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating AI Assistant with RAG Capabilities in Java\nDESCRIPTION: Java code for creating an AI Service that serves as an API to the LLM. It configures the Assistant to use OpenAI LLM, maintain chat memory, and retrieve relevant content from the embedding store.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    String chat(String userMessage);\n}\n\nChatModel chatModel = OpenAiChatModel.builder()\n    .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n    .modelName(GPT_4_O_MINI)\n    .build();\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(chatModel)\n    .chatMemory(MessageWindowChatMemory.withMaxMessages(10))\n    .contentRetriever(EmbeddingStoreContentRetriever.from(embeddingStore))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Sending ChatRequest with ToolSpecifications in Java\nDESCRIPTION: Shows how to create a ChatRequest with tool specifications and send it to a ChatModel, then handle the response including potential tool execution requests.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatRequest request = ChatRequest.builder()\n    .messages(UserMessage.from(\"What will the weather be like in London tomorrow?\"))\n    .toolSpecifications(toolSpecifications)\n    .build();\nChatResponse response = model.chat(request);\nAiMessage aiMessage = response.aiMessage();\n```\n\n----------------------------------------\n\nTITLE: Configuring RetrievalAugmentor with AI Services in Java\nDESCRIPTION: This code shows how to integrate a RetrievalAugmentor into an AI Service. The RetrievalAugmentor is responsible for enhancing user messages with relevant content from various sources before sending them to the LLM.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nAssistant assistant = AiServices.builder(Assistant.class)\n    ...\n    .retrievalAugmentor(retrievalAugmentor)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Accessing Retrieved Content Sources with Result Class in AI Services\nDESCRIPTION: Illustrates how to access the sources (retrieved Content objects) used to augment a message when using AI Services. The Result class wraps the return type and provides access to both the content and sources.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_15\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    Result<String> chat(String userMessage);\n}\n\nResult<String> result = assistant.chat(\"How to do Easy RAG with LangChain4j?\");\n\nString answer = result.content();\nList<Content> sources = result.sources();\n```\n\n----------------------------------------\n\nTITLE: Configuring EmbeddingStoreContentRetriever with Filtering in Java\nDESCRIPTION: This code demonstrates how to configure an EmbeddingStoreContentRetriever with advanced options including static and dynamic parameters for max results, minimum score, and metadata filtering based on query context.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore = ...\nEmbeddingModel embeddingModel = ...\n\nContentRetriever contentRetriever = EmbeddingStoreContentRetriever.builder()\n    .embeddingStore(embeddingStore)\n    .embeddingModel(embeddingModel)\n    .maxResults(3)\n     // maxResults can also be specified dynamically depending on the query\n    .dynamicMaxResults(query -> 3)\n    .minScore(0.75)\n     // minScore can also be specified dynamically depending on the query\n    .dynamicMinScore(query -> 0.75)\n    .filter(metadataKey(\"userId\").isEqualTo(\"12345\"))\n    // filter can also be specified dynamically depending on the query\n    .dynamicFilter(query -> {\n        String userId = getUserId(query.metadata().chatMemoryId());\n        return metadataKey(\"userId\").isEqualTo(userId);\n    })\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Service with Advanced RAG in Java\nDESCRIPTION: Shows how to implement advanced Retrieval Augmented Generation using a RetrievalAugmentor. This provides more flexibility with capabilities like query transformation, routing, content aggregation, and injection.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_26\n\nLANGUAGE: java\nCODE:\n```\nRetrievalAugmentor retrievalAugmentor = DefaultRetrievalAugmentor.builder()\n        .queryTransformer(...)\n        .queryRouter(...)\n        .contentAggregator(...)\n        .contentInjector(...)\n        .executor(...)\n        .build();\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .retrievalAugmentor(retrievalAugmentor)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Service with Chat Memory in Java\nDESCRIPTION: Demonstrates how to build an assistant with chat memory capability for a single user. The chat memory allows the assistant to remember previous interactions with a specified maximum message limit.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_20\n\nLANGUAGE: java\nCODE:\n```\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .chatMemory(MessageWindowChatMemory.withMaxMessages(10))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Chat Model with Generic Settings\nDESCRIPTION: This Java code demonstrates how to configure an OpenAI chat model using generic settings, including the base URL, API key, and model name.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .baseUrl(System.getenv(\"OPENAI_BASE_URL\"))\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Descriptions to Tool Parameters using @Description in Java\nDESCRIPTION: Demonstrates using the @Description annotation to provide descriptive information for complex parameter classes and their fields. This information helps the LLM understand the purpose of the tool and its parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\n@Description(\"Query to execute\")\nclass Query {\n\n  @Description(\"Fields to select\")\n  private List<String> select;\n\n  @Description(\"Conditions to filter on\")\n  private List<Condition> where;\n}\n\n@Tool\nResult executeQuery(Query query) {\n  ...\n}\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Mode with OpenAI via Java Builder\nDESCRIPTION: This snippet demonstrates configuring JSON mode in OpenAI models for structured outputs. Conditional configurations are applied based on model type, supporting JSON schema responses.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel.builder()\n    ...\n    .supportedCapabilities(RESPONSE_FORMAT_JSON_SCHEMA)\n    .strictJsonSchema(true)\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel.builder()\n    ...\n    .responseFormat(\"json_object\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Using Multimodal Inputs with Gemini AI in Java\nDESCRIPTION: Shows how to create a multimodal input for Gemini by combining text, images, and Markdown documents. This example demonstrates loading a README.md file and an image from GitHub, then asking Gemini to evaluate if the logo matches the project description.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\n// README.md markdown file from LangChain4j's project Github repos\nString base64Text = b64encoder.encodeToString(readBytes(\n  \"https://github.com/langchain4j/langchain4j/blob/main/README.md\"));\n\n// PNG of the cute colorful parrot mascot of the LangChain4j project\nString base64Img = b64encoder.encodeToString(readBytes(\n  \"https://avatars.githubusercontent.com/u/132277850?v=4\"));\n\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .build();\n\nChatResponse response = gemini.chat(\n    UserMessage.from(\n        TextFileContent.from(base64Text, \"text/x-markdown\"),\n        ImageContent.from(base64Img, \"image/png\"),\n        TextContent.from(\"\"\"\n            Do you think this logo fits well\n            with the project description?\n            \"\"\")\n    )\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Math Tools in Java\nDESCRIPTION: Demonstrates how to define simple math tools using the @Tool annotation in Java. These tools can be used by LLMs to perform calculations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\n@Tool(\"Sums 2 given numbers\")\ndouble sum(double a, double b) {\n    return a + b;\n}\n\n@Tool(\"Returns a square root of a given number\")\ndouble squareRoot(double x) {\n    return Math.sqrt(x);\n}\n```\n\n----------------------------------------\n\nTITLE: Ingesting Documents into In-Memory Embedding Store in Java\nDESCRIPTION: Java code for preprocessing and storing documents in an in-memory embedding store. This step is crucial for quickly finding relevant information when a user asks a question.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nInMemoryEmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();\nEmbeddingStoreIngestor.ingest(documents, embeddingStore);\n```\n\n----------------------------------------\n\nTITLE: Basic Chat Interaction with OpenAI Model\nDESCRIPTION: Simple example demonstrating how to send a message to the chat model and receive a response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nString answer = model.chat(\"Say 'Hello World'\");\nSystem.out.println(answer); // Hello World\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Basic Tools with AI Services in Java\nDESCRIPTION: Illustrates defining an AI Service interface (MathGenius) and a class (Calculator) containing methods annotated with @Tool. It shows how to build the AI Service, associating the tool methods, and invoking a service method that triggers an underlying tool execution based on the LLM's decision.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\ninterface MathGenius {\n    \n    String ask(String question);\n}\n\nclass Calculator {\n    \n    @Tool\n    double add(int a, int b) {\n        return a + b;\n    }\n\n    @Tool\n    double squareRoot(double x) {\n        return Math.sqrt(x);\n    }\n}\n\nMathGenius mathGenius = AiServices.builder(MathGenius.class)\n    .chatModel(model)\n    .tools(new Calculator())\n    .build();\n\nString answer = mathGenius.ask(\"What is the square root of 475695037565?\");\n\nSystem.out.println(answer); // The square root of 475695037565 is 689706.486532.\n```\n\n----------------------------------------\n\nTITLE: Making Fields Optional in Complex Parameters using @JsonProperty in Java\nDESCRIPTION: Shows how to designate a field within a complex parameter type (like a record or class) as optional using the Jackson annotation @JsonProperty(required = false). This is used when the complex type is passed to a @Tool method.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nrecord User(String name, @JsonProperty(required = false) String email) {}\n\n@Tool\nvoid add(User user) {\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Defining AI Services with Explicit Wiring\nDESCRIPTION: Java code demonstrating how to define AI Services with explicit wiring mode. This example shows two different assistants using OpenAI and Ollama models respectively.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\n@AiService(wiringMode = EXPLICIT, chatModel = \"openAiChatModel\")\ninterface OpenAiAssistant {\n\n    @SystemMessage(\"You are a polite assistant\")\n    String chat(String userMessage);\n}\n\n@AiService(wiringMode = EXPLICIT, chatModel = \"ollamaChatModel\")\ninterface OllamaAssistant {\n\n    @SystemMessage(\"You are a polite assistant\")\n    String chat(String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses in Java using OpenAI Model\nDESCRIPTION: Illustrates streaming AI service responses one token at a time using the TokenStream interface with OpenAI models. Configures callbacks for each part of the streaming process.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_18\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    TokenStream chat(String message);\n}\n\nStreamingChatModel model = OpenAiStreamingChatModel.builder()\n    .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n    .modelName(GPT_4_O_MINI)\n    .build();\n\nAssistant assistant = AiServices.create(Assistant.class, model);\n\nTokenStream tokenStream = assistant.chat(\"Tell me a joke\");\n\ntokenStream.onPartialResponse((String partialResponse) -> System.out.println(partialResponse))\n    .onRetrieved((List<Content> contents) -> System.out.println(contents))\n    .onToolExecuted((ToolExecution toolExecution) -> System.out.println(toolExecution))\n    .onCompleteResponse((ChatResponse response) -> System.out.println(response))\n    .onError((Throwable error) -> error.printStackTrace())\n    .start();\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini AI for JSON Response Format in Java\nDESCRIPTION: Sets up a Gemini chat model with JSON response format. This configuration forces Gemini to respond in structured JSON format, as demonstrated with a simple dice roll example that returns a JSON object.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .responseFormat(ResponseFormat.JSON)\n    .build();\n\nString roll = gemini.chat(\"Roll a 6-sided dice\");\n\nSystem.out.println(roll);\n// {\"roll\": \"3\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing Persistent ChatMemoryStore in Java\nDESCRIPTION: This code snippet demonstrates how to implement a custom PersistentChatMemoryStore interface to store ChatMessages in a persistent store. It includes methods for getting, updating, and deleting messages associated with a memory ID.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-memory.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nclass PersistentChatMemoryStore implements ChatMemoryStore {\n\n        @Override\n        public List<ChatMessage> getMessages(Object memoryId) {\n          // TODO: Implement getting all messages from the persistent store by memory ID.\n          // ChatMessageDeserializer.messageFromJson(String) and \n          // ChatMessageDeserializer.messagesFromJson(String) helper methods can be used to\n          // easily deserialize chat messages from JSON.\n        }\n\n        @Override\n        public void updateMessages(Object memoryId, List<ChatMessage> messages) {\n            // TODO: Implement updating all messages in the persistent store by memory ID.\n            // ChatMessageSerializer.messageToJson(ChatMessage) and \n            // ChatMessageSerializer.messagesToJson(List<ChatMessage>) helper methods can be used to\n            // easily serialize chat messages into JSON.\n        }\n\n        @Override\n        public void deleteMessages(Object memoryId) {\n          // TODO: Implement deleting all messages in the persistent store by memory ID.\n        }\n    }\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n        .id(\"12345\")\n        .maxMessages(10)\n        .chatMemoryStore(new PersistentChatMemoryStore())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Using AllMiniLmL6V2 Embedding Model in Java\nDESCRIPTION: Java code example showing how to instantiate the AllMiniLmL6V2 embedding model and use it to generate an embedding for a text string. The response contains the embedding which can be extracted with the content() method.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel embeddingModel = new AllMiniLmL6V2EmbeddingModel();\nResponse<Embedding> response = embeddingModel.embed(\"test\");\nEmbedding embedding = response.content();\n```\n\n----------------------------------------\n\nTITLE: Configuring AI Service with Tools for Function Calling in Java\nDESCRIPTION: Shows how to enhance an AI service with tools that the language model can use to perform calculations or other functions. The example implements addition and multiplication tools that can be called by the LLM.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_24\n\nLANGUAGE: java\nCODE:\n```\nclass Tools {\n    \n    @Tool\n    int add(int a, int b) {\n        return a + b;\n    }\n\n    @Tool\n    int multiply(int a, int b) {\n        return a * b;\n    }\n}\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .tools(new Tools())\n    .build();\n\nString answer = assistant.chat(\"What is 1+2 and 3*4?\");\n```\n\n----------------------------------------\n\nTITLE: Configuring WebSearchContentRetriever with Google Search in Java\nDESCRIPTION: This code shows how to set up a WebSearchContentRetriever using Google Custom Search Engine as the underlying web search engine. It retrieves relevant content from the web for a given query.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nWebSearchEngine googleSearchEngine = GoogleCustomWebSearchEngine.builder()\n        .apiKey(System.getenv(\"GOOGLE_API_KEY\"))\n        .csi(System.getenv(\"GOOGLE_SEARCH_ENGINE_ID\"))\n        .build();\n\nContentRetriever contentRetriever = WebSearchContentRetriever.builder()\n        .webSearchEngine(googleSearchEngine)\n        .maxResults(3)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code demonstrating various configuration options for GoogleAiGeminiChatModel, including temperature, response format, and safety settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .temperature(1.0)\n    .topP(0.95)\n    .topK(64)\n    .maxOutputTokens(8192)\n    .timeout(Duration.ofSeconds(60))\n    .candidateCount(1)\n    .responseFormat(ResponseFormat.JSON) // or .responseFormat(ResponseFormat.builder()...build()) \n    .stopSequences(List.of(...))\n    .toolConfig(GeminiFunctionCallingConfig.builder()...build()) // or below\n    .toolConfig(GeminiMode.ANY, List.of(\"fnOne\", \"fnTwo\"))\n    .allowCodeExecution(true)\n    .includeCodeExecution(output)\n    .logRequestsAndResponses(true)\n    .safetySettings(List<GeminiSafetySetting> or Map<GeminiHarmCategory, GeminiHarmBlockThreshold>)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing Complete Sentiment Classification Service with LangChain4j in Java\nDESCRIPTION: This snippet presents the full Java implementation for a sentiment classification service using LangChain4j. It initializes an OpenAI chat model, defines a `Sentiment` enum, declares a `SentimentAnalyzer` interface using LangChain4j annotations, creates an AI service instance, and demonstrates analyzing sentiment for sample texts. Requires LangChain4j core, OpenAI integration, and a valid OpenAI API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.openai.OpenAiChatModel;\nimport dev.langchain4j.service.AiServices;\nimport dev.langchain4j.service.UserMessage;\n\npublic class SentimentClassification {\n\n    // Initialize the chat model using OpenAI\n    static ChatModel chatModel = OpenAiChatModel.withApiKey(\"YOUR_OPENAI_API_KEY\");\n\n    // Define the Sentiment enum\n    enum Sentiment {\n        POSITIVE, NEUTRAL, NEGATIVE\n    }\n\n    // Define the AI-powered Sentiment Analyzer interface\n    interface SentimentAnalyzer {\n\n        @UserMessage(\"Analyze sentiment of {{it}}\")\n        Sentiment analyzeSentimentOf(String text);\n\n        @UserMessage(\"Does {{it}} have a positive sentiment?\")\n        boolean isPositive(String text);\n    }\n\n    public static void main(String[] args) {\n\n        // Create an AI-powered Sentiment Analyzer instance\n        SentimentAnalyzer sentimentAnalyzer = AiServices.create(SentimentAnalyzer.class, chatModel);\n\n        // Example Sentiment Analysis\n        Sentiment sentiment = sentimentAnalyzer.analyzeSentimentOf(\"I love this product!\");\n        System.out.println(sentiment); // Expected Output: POSITIVE\n\n        boolean positive = sentimentAnalyzer.isPositive(\"This is a terrible experience.\");\n        System.out.println(positive); // Expected Output: false\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Documents from File System in Java with LangChain4j\nDESCRIPTION: Examples of loading documents from the file system using FileSystemDocumentLoader with different configurations. Shows how to load a single document, all documents from a directory, documents matching a pattern, and documents recursively from directories.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n// Load a single document\nDocument document = FileSystemDocumentLoader.loadDocument(\"/home/langchain4j/file.txt\", new TextDocumentParser());\n\n// Load all documents from a directory\nList<Document> documents = FileSystemDocumentLoader.loadDocuments(\"/home/langchain4j\", new TextDocumentParser());\n\n// Load all *.txt documents from a directory\nPathMatcher pathMatcher = FileSystems.getDefault().getPathMatcher(\"glob:*.txt\");\nList<Document> documents = FileSystemDocumentLoader.loadDocuments(\"/home/langchain4j\", pathMatcher, new TextDocumentParser());\n\n// Load all documents from a directory and its subdirectories\nList<Document> documents = FileSystemDocumentLoader.loadDocumentsRecursively(\"/home/langchain4j\", new TextDocumentParser());\n```\n\n----------------------------------------\n\nTITLE: Using an AI Service in Java\nDESCRIPTION: Shows how to use the created AI Service instance to send a message and receive a response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nString answer = assistant.chat(\"Hello\");\nSystem.out.println(answer); // Hello, how can I help you?\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Chat Model using Builder Pattern in Java\nDESCRIPTION: This snippet demonstrates how to create an OpenAiChatModel instance using the builder pattern, setting various parameters such as API key, model name, temperature, timeout, and logging options.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/model-parameters.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel model = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .temperature(0.3)\n        .timeout(ofSeconds(60))\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAiChatModel in Plain Java\nDESCRIPTION: Java code to create an OpenAiChatModel instance with API key and model name, and an alternative version with default request parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .build();\n\n\n// You can also specify default chat request parameters using ChatRequestParameters or OpenAiChatRequestParameters\nChatModel model = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .defaultRequestParameters(OpenAiChatRequestParameters.builder()\n                .modelName(\"gpt-4o-mini\")\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Accessing Executed Tool Details with Result Wrapper in Java\nDESCRIPTION: Demonstrates how to retrieve information about executed tools after an AI Service call by wrapping the return type in the `Result` class. The `Result` object provides access to both the original content (`result.content()`) and a list of `ToolExecution` objects (`result.toolExecutions()`).\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    Result<String> chat(String userMessage);\n}\n\nResult<String> result = assistant.chat(\"Cancel my booking 123-456\");\n\nString answer = result.content();\nList<ToolExecution> toolExecutions = result.toolExecutions();\n```\n\n----------------------------------------\n\nTITLE: Creating AI Service Instance with LangChain4j AiServices in Java\nDESCRIPTION: This Java code demonstrates how to create an instance of the `SentimentAnalyzer` interface using `AiServices.create()`. This method dynamically implements the interface by leveraging the provided `chatModel` (an initialized OpenAI chat model instance) to handle the method calls.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nSentimentAnalyzer sentimentAnalyzer = AiServices.create(SentimentAnalyzer.class, chatModel);\n```\n\n----------------------------------------\n\nTITLE: Using OpenAiChatModel in Spring Boot Controller\nDESCRIPTION: Java code demonstrating how to use the OpenAiChatModel bean in a Spring Boot REST controller.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n@RestController\nclass ChatModelController {\n\n    ChatModel chatModel;\n\n    ChatModelController(ChatModel chatModel) {\n        this.chatModel = chatModel;\n    }\n\n    @GetMapping(\"/model\")\n    public String model(@RequestParam(value = \"message\", defaultValue = \"Hello\") String message) {\n        return chatModel.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Responses with Source Retrieval in LangChain4j\nDESCRIPTION: Shows how to handle streaming responses while accessing retrieved Content sources. The onRetrieved method allows specifying a Consumer to process the sources when they become available.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_16\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    TokenStream chat(String userMessage);\n}\n\nassistant.chat(\"How to do Easy RAG with LangChain4j?\")\n    .onRetrieved((List<Content> sources) -> ...)\n    .onPartialResponse(...)\n    .onCompleteResponse(...)\n    .onError(...)\n    .start();\n```\n\n----------------------------------------\n\nTITLE: Enabling Structured Outputs for Tools\nDESCRIPTION: This Java code demonstrates how to enable the Structured Outputs feature for tools when configuring an OpenAI chat model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nOpenAiOfficialChatModel.builder()\n        // ...\n        .strictTools(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Accessing Executed Tool Details in Streaming Mode in Java\nDESCRIPTION: Shows how to access details of executed tools when using streaming responses from an AI Service. This is achieved by attaching an `onToolExecuted` callback to the `TokenStream` returned by the service method.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n    TokenStream chat(String message);\n}\n\nTokenStream tokenStream = assistant.chat(\"Cancel my booking\");\n\ntokenStream\n    .onToolExecuted((ToolExecution toolExecution) -> System.out.println(toolExecution))\n    .onPartialResponse(...)\n    .onCompleteResponse(...)\n    .onError(...)\n    .start();\n```\n\n----------------------------------------\n\nTITLE: Configuring Advanced EmbeddingStoreIngestor with Transformers and Splitters in Java\nDESCRIPTION: Demonstrates creating an advanced EmbeddingStoreIngestor with document transformation, splitting, and text segment enhancement. This configuration adds metadata, splits documents into manageable segments, and enhances text segments before embedding.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStoreIngestor ingestor = EmbeddingStoreIngestor.builder()\n\n    // adding userId metadata entry to each Document to be able to filter by it later\n    .documentTransformer(document -> {\n        document.metadata().put(\"userId\", \"12345\");\n        return document;\n    })\n\n    // splitting each Document into TextSegments of 1000 tokens each, with a 200-token overlap\n    .documentSplitter(DocumentSplitters.recursive(1000, 200, new OpenAiTokenCountEstimator(\"gpt-4o-mini\")))\n\n    // adding a name of the Document to each TextSegment to improve the quality of search\n    .textSegmentTransformer(textSegment -> TextSegment.from(\n            textSegment.metadata().getString(\"file_name\") + \"\\n\" + textSegment.text(),\n            textSegment.metadata()\n    ))\n\n    .embeddingModel(embeddingModel)\n    .embeddingStore(embeddingStore)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Defining an AI Service with System Message in Java\nDESCRIPTION: Demonstrates how to use the @SystemMessage annotation to provide instructions to the LLM in an AI Service interface.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\ninterface Friend {\n\n    @SystemMessage(\"You are a good friend of mine. Answer using slang.\")\n    String chat(String userMessage);\n}\n\nFriend friend = AiServices.create(Friend.class, model);\n\nString answer = friend.chat(\"Hello\"); // Hey! What's up?\n```\n\n----------------------------------------\n\nTITLE: Implementing a ToolExecutor for Programmatic Tools in Java\nDESCRIPTION: Shows the implementation of a `ToolExecutor` functional interface. This implementation defines the actual logic to be executed when the LLM requests the corresponding programmatically defined tool (`ToolSpecification`). It receives the `ToolExecutionRequest` and optionally a `memoryId`.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_14\n\nLANGUAGE: java\nCODE:\n```\nToolExecutor toolExecutor = (toolExecutionRequest, memoryId) -> {\n    Map<String, Object> arguments = fromJson(toolExecutionRequest.arguments());\n    String bookingNumber = arguments.get(\"bookingNumber\").toString();\n    Booking booking = getBooking(bookingNumber);\n    return booking.toString();\n};\n```\n\n----------------------------------------\n\nTITLE: Defining AI Service Interface for Sentiment Analysis with LangChain4j in Java\nDESCRIPTION: This snippet defines the `SentimentAnalyzer` interface using LangChain4j. The `@UserMessage` annotation provides the prompt template for the AI model. The `analyzeSentimentOf` method classifies text into the `Sentiment` enum, and the `isPositive` method returns a boolean indicating positive sentiment. The `{{it}}` placeholder injects the method argument into the prompt.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\ninterface SentimentAnalyzer {\n    \n    @UserMessage(\"Analyze sentiment of {{it}}\")\n    Sentiment analyzeSentimentOf(String text);\n\n    @UserMessage(\"Does {{it}} have a positive sentiment?\")\n    boolean isPositive(String text);\n}\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAiEmbeddingModel in Plain Java\nDESCRIPTION: Java code snippet for creating an OpenAiEmbeddingModel instance in a plain Java environment. It uses the builder pattern and retrieves the API key from an environment variable.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel model = OpenAiEmbeddingModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"text-embedding-3-small\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Accessing and Managing Chat Memories in Java\nDESCRIPTION: Demonstrates how to access and evict chat memories by extending the ChatMemoryAccess interface. This allows retrieving conversation history and cleaning up memory for terminated conversations to prevent memory leaks.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_22\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant extends ChatMemoryAccess {\n    String chat(@MemoryId int memoryId, @UserMessage String message);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Response Format for GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code demonstrating how to configure a custom JSON response format for GoogleAiGeminiChatModel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nResponseFormat responseFormat = ResponseFormat.builder()\n        .type(ResponseFormatType.JSON)\n        .jsonSchema(JsonSchema.builder() // see [1] below\n                .rootElement(JsonObjectSchema.builder()\n                        .addStringProperty(\"title\")\n                        .addIntegerProperty(\"preparationTimeMinutes\")\n                        .addProperty(\"ingredients\", JsonArraySchema.builder()\n                                .items(new JsonStringSchema())\n                                .build())\n                        .addProperty(\"steps\", JsonArraySchema.builder()\n                                .items(new JsonStringSchema())\n                                .build())\n                        .build())\n                .build())\n        .build();\n\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n        .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n        .modelName(\"gemini-1.5-flash\")\n        .responseFormat(responseFormat)\n        .build();\n\nString recipeResponse = gemini.chat(\"Suggest a dessert recipe with strawberries\");\n\nSystem.out.println(recipeResponse);\n```\n\n----------------------------------------\n\nTITLE: Executing ChatRequest with JSON Schema using Java\nDESCRIPTION: Illustrates sending a chat request with JSON schema using OllamaChatModel in Java. Constructs a 'ChatRequest' with custom messages and a specified JSON schema for the response format. Suitable for applications requiring schema-compliant outputs.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"llama3.1\")\n    .build();\n\nChatResponse chatResponse = ollamaChatModel.chat(ChatRequest.builder()\n        .messages(userMessage(\"Tell me about Canada.\"))\n        .responseFormat(ResponseFormat.builder()\n                .type(ResponseFormatType.JSON)\n                .jsonSchema(JsonSchema.builder().rootElement(JsonObjectSchema.builder()\n                                .addProperty(\"name\", JsonStringSchema.builder().build())\n                                .addProperty(\"capital\", JsonStringSchema.builder().build())\n                                .addProperty(\n                                        \"languages\",\n                                        JsonArraySchema.builder()\n                                                .items(JsonStringSchema.builder().build())\n                                                .build())\n                                .required(\"name\", \"capital\", \"languages\")\n                                .build())\n                        .build())\n                .build())\n        .build());\n\nString jsonFormattedResponse = chatResponse.aiMessage().text();\n\n/* jsonFormattedResponse value:\n\n  {\n    \"capital\" : \"Ottawa\",\n    \"languages\" : [ \"English\", \"French\" ],\n    \"name\" : \"Canada\"\n  }\n\n */\n```\n\n----------------------------------------\n\nTITLE: Using GoogleAiGeminiStreamingChatModel in Java\nDESCRIPTION: Java code showing how to use GoogleAiGeminiStreamingChatModel for streaming chat responses token by token.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel gemini = GoogleAiGeminiStreamingChatModel.builder()\n        .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n        .modelName(\"gemini-1.5-flash\")\n        .build();\n\nCompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();\n\ngemini.chat(\"Tell me a joke about Java\", new StreamingChatResponseHandler() {\n\n    @Override\n    public void onPartialResponse(String partialResponse) {\n        System.out.print(partialResponse);\n    }\n\n    @Override\n    public void onCompleteResponse(ChatResponse completeResponse) {\n        futureResponse.complete(completeResponse);\n    }\n\n    @Override\n    public void onError(Throwable error) {\n        futureResponse.completeExceptionally(error);\n    }\n});\n\n        futureResponse.join();\n```\n\n----------------------------------------\n\nTITLE: Interacting with MistralAiChatModel using Shell\nDESCRIPTION: This snippet illustrates a shell command output from the PaymentDataAssistantApp where the user communicates with the agent through MistralAI chat model, expecting a status and date response for a particular transaction ID. The input entails specifying a valid transaction ID, and the expected output is a formatted response containing the status and date of the specified transaction.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nThe status of transaction T1005 is Pending. The payment date is October 8, 2021.\n```\n\n----------------------------------------\n\nTITLE: Making Tool Parameters Optional using @P in Java\nDESCRIPTION: Demonstrates how to make a method parameter optional within a LangChain4j @Tool definition using the @P annotation with 'required = false'. By default, parameters are required.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\n@Tool\nvoid getTemperature(String location, @P(required = false) Unit unit) {\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OllamaChatModel with RESPONSE_FORMAT_JSON_SCHEMA\nDESCRIPTION: Shows initialization of the OllamaChatModel in Java with RESPONSE_FORMAT_JSON_SCHEMA capability. Utilizes the AIService for generating schema from interfaces. Ideal for users requiring automatic schema generation for structured outputs.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"...\")\n    .modelName(\"...\")\n    .supportedCapabilities(RESPONSE_FORMAT_JSON_SCHEMA)    \n    .build();\n```\n\n----------------------------------------\n\nTITLE: Extracting Person Information into POJO in Java\nDESCRIPTION: The 'PersonExtractor' interface utilizes POJO to extract structured information about a person from text. Descriptions are added for clarity, and the method returns a 'Person' object filled with extracted data.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nclass Person {\n\n    @Description(\"first name of a person\") // you can add an optional description to help an LLM have a better understanding\n    String firstName;\n    String lastName;\n    LocalDate birthDate;\n    Address address;\n}\n\n@Description(\"an address\") // you can add an optional description to help an LLM have a better understanding\nclass Address {\n    String street;\n    Integer streetNumber;\n    String city;\n}\n\ninterface PersonExtractor {\n\n    @UserMessage(\"Extract information about a person from {{it}}\")\n    Person extractPersonFrom(String text);\n}\n\nPersonExtractor personExtractor = AiServices.create(PersonExtractor.class, model);\n\nString text = \"\"\"\n            In 1968, amidst the fading echoes of Independence Day,\n            a child named John arrived under the calm evening sky.\n            This newborn, bearing the surname Doe, marked the start of a new journey.\n            He was welcomed into the world at 345 Whispering Pines Avenue\n            a quaint street nestled in the heart of Springfield\n            an abode that echoed with the gentle hum of suburban dreams and aspirations.\n            \"\"\";\n\nPerson person = personExtractor.extractPersonFrom(text);\n\nSystem.out.println(person); // Person { firstName = \"John\", lastName = \"Doe\", birthDate = 1968-07-04, address = Address { ... } }\n```\n\n----------------------------------------\n\nTITLE: Using Vertex AI PaLM 2 Chat Model in Java\nDESCRIPTION: Java example demonstrating how to use the Vertex AI PaLM 2 chat model with LangChain4j. It sets up the model, sends a user message, and prints the AI's response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-palm.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.data.message.UserMessage;\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.output.Response;\nimport dev.langchain4j.model.vertexai.VertexAiChatModel;\n\npublic class ChatModelExample {\n\n    private static final String PROJECT_ID = \"YOUR-PROJECT-ID\";\n    // `chat-bison` means PaLM2 general purpose chat model\n    private static final String MODEL_NAME = \"chat-bison\";\n\n    public static void main(String[] args) {\n        ChatModel model = VertexAiChatModel.builder()\n            .endpoint(\"us-central1-aiplatform.googleapis.com:443\")\n            .location(\"us-central1\")\n            .publisher(\"google\")\n            .project(PROJECT_ID)\n            .modelName(MODEL_NAME)\n            .temperature(0.0)\n            .build();\n\n        ChatResponse response = model.chat(\n            UserMessage.from(\n                \"Describe in several sentences what language model you are: \\n\" +\n                \"Describe in several sentences what is your code name: \"\n            )\n        );\n        System.out.println(response.aiMessage().text());\n\n        // I am a large language model, trained by Google. \n        // I am a transformer-based language model that has been trained \n        //     on a massive dataset of text and code. \n        // I am able to understand and generate human language, \n        //     and I can also write code in a variety of programming languages.\n        //\n        // My code name is PaLM 2, which stands for Pathways Language Model 2.\n\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a ToolProvider for Dynamic Tool Specification in Java\nDESCRIPTION: Illustrates implementing a `ToolProvider` functional interface. This provider is called for each AI service invocation and can dynamically decide which tools (`ToolSpecification` and `ToolExecutor` pairs) to make available to the LLM based on the request context (e.g., user message content).\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_16\n\nLANGUAGE: java\nCODE:\n```\nToolProvider toolProvider = (toolProviderRequest) -> {\n    if (toolProviderRequest.userMessage().singleText().contains(\"booking\")) {\n        ToolSpecification toolSpecification = ToolSpecification.builder()\n            .name(\"get_booking_details\")\n            .description(\"Returns booking details\")\n            .parameters(JsonObjectSchema.builder()\n                .addStringProperty(\"bookingNumber\")\n                .build())\n            .build();\n        return ToolProviderResult.builder()\n            .add(toolSpecification, toolExecutor)\n            .build();\n    } else {\n        return null;\n    }\n};\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .toolProvider(toolProvider)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatModelListener for OpenAI Chat Model in Java\nDESCRIPTION: This snippet demonstrates how to implement a ChatModelListener to observe requests, responses, and errors from an OpenAI chat model. It shows how to access various attributes of the request and response, including model parameters, messages, and token usage.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/observability.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nChatModelListener listener = new ChatModelListener() {\n\n    @Override\n    public void onRequest(ChatModelRequestContext requestContext) {\n        ChatRequest chatRequest = requestContext.chatRequest();\n\n        List<ChatMessage> messages = chatRequest.messages();\n        System.out.println(messages);\n\n        ChatRequestParameters parameters = chatRequest.parameters();\n        System.out.println(parameters.modelName());\n        System.out.println(parameters.temperature());\n        System.out.println(parameters.topP());\n        System.out.println(parameters.topK());\n        System.out.println(parameters.frequencyPenalty());\n        System.out.println(parameters.presencePenalty());\n        System.out.println(parameters.maxOutputTokens());\n        System.out.println(parameters.stopSequences());\n        System.out.println(parameters.toolSpecifications());\n        System.out.println(parameters.toolChoice());\n        System.out.println(parameters.responseFormat());\n\n        if (parameters instanceof OpenAiChatRequestParameters openAiParameters) {\n            System.out.println(openAiParameters.maxCompletionTokens());\n            System.out.println(openAiParameters.logitBias());\n            System.out.println(openAiParameters.parallelToolCalls());\n            System.out.println(openAiParameters.seed());\n            System.out.println(openAiParameters.user());\n            System.out.println(openAiParameters.store());\n            System.out.println(openAiParameters.metadata());\n            System.out.println(openAiParameters.serviceTier());\n            System.out.println(openAiParameters.reasoningEffort());\n        }\n\n        System.out.println(requestContext.modelProvider());\n\n        Map<Object, Object> attributes = requestContext.attributes();\n        attributes.put(\"my-attribute\", \"my-value\");\n    }\n\n    @Override\n    public void onResponse(ChatModelResponseContext responseContext) {\n        ChatResponse chatResponse = responseContext.chatResponse();\n\n        AiMessage aiMessage = chatResponse.aiMessage();\n        System.out.println(aiMessage);\n\n        ChatResponseMetadata metadata = chatResponse.metadata();\n        System.out.println(metadata.id());\n        System.out.println(metadata.modelName());\n        System.out.println(metadata.finishReason());\n\n        if (metadata instanceof OpenAiChatResponseMetadata openAiMetadata) {\n            System.out.println(openAiMetadata.created());\n            System.out.println(openAiMetadata.serviceTier());\n            System.out.println(openAiMetadata.systemFingerprint());\n        }\n\n        TokenUsage tokenUsage = metadata.tokenUsage();\n        System.out.println(tokenUsage.inputTokenCount());\n        System.out.println(tokenUsage.outputTokenCount());\n        System.out.println(tokenUsage.totalTokenCount());\n        if (tokenUsage instanceof OpenAiTokenUsage openAiTokenUsage) {\n            System.out.println(openAiTokenUsage.inputTokensDetails().cachedTokens());\n            System.out.println(openAiTokenUsage.outputTokensDetails().reasoningTokens());\n        }\n\n        ChatRequest chatRequest = responseContext.chatRequest();\n        System.out.println(chatRequest);\n\n        System.out.println(responseContext.modelProvider());\n\n        Map<Object, Object> attributes = responseContext.attributes();\n        System.out.println(attributes.get(\"my-attribute\"));\n    }\n\n    @Override\n    public void onError(ChatModelErrorContext errorContext) {\n        Throwable error = errorContext.error();\n        error.printStackTrace();\n\n        ChatRequest chatRequest = errorContext.chatRequest();\n        System.out.println(chatRequest);\n\n        System.out.println(errorContext.modelProvider());\n\n        Map<Object, Object> attributes = errorContext.attributes();\n        System.out.println(attributes.get(\"my-attribute\"));\n    }\n};\n\nChatModel model = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(GPT_4_O_MINI)\n        .listeners(List.of(listener))\n        .build();\n\nmodel.chat(\"Tell me a joke about Java\");\n```\n\n----------------------------------------\n\nTITLE: Instantiating an AI Service in Java\nDESCRIPTION: Demonstrates how to create an instance of an AI Service using the AiServices class, passing the interface class and the ChatModel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nAssistant assistant = AiServices.create(Assistant.class, model);\n```\n\n----------------------------------------\n\nTITLE: Implementing AnthropicStreamingChatModel in Java\nDESCRIPTION: Java code demonstrating the setup and usage of AnthropicStreamingChatModel. It shows how to create the model instance and handle streaming responses using a StreamingChatResponseHandler.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nAnthropicStreamingChatModel model = AnthropicStreamingChatModel.builder()\n    .apiKey(System.getenv(\"ANTHROPIC_API_KEY\"))\n    .modelName(CLAUDE_3_5_SONNET_20240620)\n    .build();\n\nmodel.chat(\"Say 'Hello World'\", new StreamingChatResponseHandler() {\n\n    @Override\n    public void onPartialResponse(String partialResponse) {\n        // this method is called when a new partial response is available. It can consist of one or more tokens.\n    }\n\n    @Override\n    public void onCompleteResponse(ChatResponse completeResponse) {\n        // this method is called when the model has completed responding\n    }\n\n    @Override\n    public void onError(Throwable error) {\n        // this method is called when an error occurs\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Managing Chat Memory Access and Eviction in Java\nDESCRIPTION: Shows how to retrieve chat messages from memory for a specific user and how to evict chat memory for users who no longer need their conversation history stored.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_23\n\nLANGUAGE: java\nCODE:\n```\nString answerToKlaus = assistant.chat(1, \"Hello, my name is Klaus\");\nString answerToFrancine = assistant.chat(2, \"Hello, my name is Francine\");\n\nList<ChatMessage> messagesWithKlaus = assistant.getChatMemory(1).messages();\nboolean chatMemoryWithFrancineEvicted = assistant.evictChatMemory(2);\n```\n\n----------------------------------------\n\nTITLE: Using ChatModel in a Spring RestController\nDESCRIPTION: This Java code shows how to use a ChatModel in a Spring RestController, demonstrating how to autowire and use the model in a REST API endpoint.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\n@RestController\nclass ChatModelController {\n\n    ChatModel chatModel;\n\n    ChatModelController(ChatModel chatModel) {\n        this.chatModel = chatModel;\n    }\n\n    @GetMapping(\"/model\")\n    public String model(@RequestParam(value = \"message\", defaultValue = \"Hello\") String message) {\n        return chatModel.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Memory Provider for Multiple Users in Java\nDESCRIPTION: Shows how to implement an AI service with separate chat memories for different users using the ChatMemoryProvider. Each user is identified by a unique memory ID parameter.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_21\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant  {\n    String chat(@MemoryId int memoryId, @UserMessage String message);\n}\n\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(model)\n    .chatMemoryProvider(memoryId -> MessageWindowChatMemory.withMaxMessages(10))\n    .build();\n\nString answerToKlaus = assistant.chat(1, \"Hello, my name is Klaus\");\nString answerToFrancine = assistant.chat(2, \"Hello, my name is Francine\");\n```\n\n----------------------------------------\n\nTITLE: Implementing DuckDB Embedding Store with Search Functionality\nDESCRIPTION: Complete example showing initialization of DuckDB embedding store, creation of embeddings from text segments, and performing similarity search with results handling\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/duckdb.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// Init Model and Store\nvar embeddingStore = DuckDBEmbeddingStore.inMemory();\nvar embeddingModel = new AllMiniLmL6V2QuantizedEmbeddingModel();\n\n//Create embeddings\nStream.of(\n            \"DuckDB is an amazing database engine!\",\n            \"Python really lack of typing :D\")\n    .forEach(text -> {\n        var segment = TextSegment.from(text);\n        var embedding = embeddingModel.embed(segment).content();\n        embeddingStore.add(embedding, segment);\n    });\n\n\n// Search request\nvar queryEmbedding = embeddingModel.embed(\"What is the best database engine\").content();\nvar request = EmbeddingSearchRequest.builder()\n               .queryEmbedding(queryEmbedding)\n               .maxResults(1)\n               .build();\n\nvar relevant = embeddingStore.search(request);\nEmbeddingMatch<TextSegment> embeddingMatch = relevant.matches().get(0);\n\n// Show results\nSystem.out.println(embeddingMatch.score()); // 0.8416415629618381\nSystem.out.println(embeddingMatch.embedded().text()); //DuckDB is an amazing database engine!\n```\n\n----------------------------------------\n\nTITLE: Priority Analysis with Java Enum Return Type\nDESCRIPTION: Using the 'PriorityAnalyzer' interface, a method is defined to analyze issue priority based on given descriptions. The method utilizes the 'Priority' Enum consisting of CRITICAL, HIGH, and LOW values.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nenum Priority {\n    CRITICAL, HIGH, LOW\n}\n\ninterface PriorityAnalyzer {\n    \n    @UserMessage(\"Analyze the priority of the following issue: {{it}}\")\n    Priority analyzePriority(String issueDescription);\n}\n\nPriorityAnalyzer priorityAnalyzer = AiServices.create(PriorityAnalyzer.class, model);\n\nPriority priority = priorityAnalyzer.analyzePriority(\"The main payment gateway is down, and customers cannot process transactions.\");\n// CRITICAL\n```\n\n----------------------------------------\n\nTITLE: Extracting Structured Data with GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code showing how to extract structured data from free-form text using GoogleAiGeminiChatModel and AiServices.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nrecord WeatherForecast(\n    @Description(\"minimum temperature\")\n    Integer minTemperature,\n    @Description(\"maximum temperature\")\n    Integer maxTemperature,\n    @Description(\"chances of rain\")\n    boolean rain\n) { }\n\ninterface WeatherForecastAssistant {\n    WeatherForecast extract(String forecast);\n}\n\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .responseFormat(ResponseFormat.JSON) // this is required to enable structured outputs feature\n    .build();\n\nWeatherForecastAssistant forecastAssistant =\n    AiServices.builder(WeatherForecastAssistant.class)\n        .chatModel(gemini)\n        .build();\n\nWeatherForecast forecast = forecastAssistant.extract(\"\"\"\n    Morning: The day dawns bright and clear in Osaka, with crisp\n    autumn air and sunny skies. Expect temperatures to hover\n    around 18°C (64°F) as you head out for your morning stroll\n    through Namba.\n    Afternoon: The sun continues to shine as the city buzzes with\n    activity. Temperatures climb to a comfortable 22°C (72°F).\n    Enjoy a leisurely lunch at one of Osaka's many outdoor cafes,\n    or take a boat ride on the Okawa River to soak in the beautiful\n    scenery.\n    Evening: As the day fades, expect clear skies and a slight chill\n    in the air. Temperatures drop to 15°C (59°F). A cozy dinner at a\n    traditional Izakaya will be the perfect way to end your day in\n    Osaka.\n    Overall: A beautiful autumn day in Osaka awaits, perfect for\n    exploring the city's vibrant streets, enjoying the local cuisine,\n    and soaking in the sights.\n    Don't forget: Pack a light jacket for the evening and wear\n    comfortable shoes for all the walking you'll be doing.\n    \"\"\");\n```\n\n----------------------------------------\n\nTITLE: Multi-turn Conversation Example in Java\nDESCRIPTION: Demonstrates how to maintain conversation context by passing previous messages in subsequent chat calls.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nUserMessage firstUserMessage = UserMessage.from(\"Hello, my name is Klaus\");\nAiMessage firstAiMessage = model.chat(firstUserMessage).aiMessage(); // Hi Klaus, how can I help you?\nUserMessage secondUserMessage = UserMessage.from(\"What is my name?\");\nAiMessage secondAiMessage = model.chat(firstUserMessage, firstAiMessage, secondUserMessage).aiMessage(); // Klaus\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming with StreamingChatModel in Java\nDESCRIPTION: This example demonstrates how to implement streaming with StreamingChatModel by creating an instance of OpenAiStreamingChatModel and implementing the StreamingChatResponseHandler interface.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/response-streaming.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel model = OpenAiStreamingChatModel.builder()\n    .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n    .modelName(GPT_4_O_MINI)\n    .build();\n\nString userMessage = \"Tell me a joke\";\n\nmodel.chat(userMessage, new StreamingChatResponseHandler() {\n\n    @Override\n    public void onPartialResponse(String partialResponse) {\n        System.out.println(\"onPartialResponse: \" + partialResponse);\n    }\n\n    @Override\n    public void onCompleteResponse(ChatResponse completeResponse) {\n        System.out.println(\"onCompleteResponse: \" + completeResponse);\n    }\n\n    @Override\n    public void onError(Throwable error) {\n        error.printStackTrace();\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Required JSON Schema Properties in Java\nDESCRIPTION: This code shows how to make certain fields required in the generated JSON Schema by using the @JsonProperty annotation. By default, all fields are optional to avoid hallucination issues, but specific fields can be marked as required when needed.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nrecord Person(@JsonProperty(required = true) String name, String surname) {\n}\n\ninterface PersonExtractor {\n    \n    Person extractPersonFrom(String text);\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Structured Outputs for Response Format in OpenAiChatModel\nDESCRIPTION: Java code to enable Structured Outputs feature for response formatting in OpenAiChatModel, used with AI Services.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel.builder()\n    ...\n    .supportedCapabilities(RESPONSE_FORMAT_JSON_SCHEMA)\n    .strictJsonSchema(true)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Defining StreamingChatResponseHandler Interface in Java\nDESCRIPTION: This code snippet defines the StreamingChatResponseHandler interface with methods for handling partial responses, complete responses, and errors during streaming.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/response-streaming.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npublic interface StreamingChatResponseHandler {\n\n    void onPartialResponse(String partialResponse);\n\n    void onCompleteResponse(ChatResponse completeResponse);\n\n    void onError(Throwable error);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j Bedrock Integration\nDESCRIPTION: XML snippet for adding the LangChain4j Bedrock dependency to a Maven project. This dependency is required to use Amazon Bedrock models with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/amazon-bedrock.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-bedrock</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Descriptions to JSON Schema Elements in Java\nDESCRIPTION: This code demonstrates how to add descriptions to JsonSchemaElement objects to provide more instructions and examples to the LLM about the expected output format.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nJsonSchemaElement stringSchema = JsonStringSchema.builder()\n        .description(\"The name of the person, for example: John Doe\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Synchronous Chat Completion with MistralAI in Java\nDESCRIPTION: Java code demonstrating synchronous chat completion using MistralAI with LangChain4j. It creates a ChatModel instance and generates a response to a simple prompt.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.mistralai.MistralAiChatModel;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        ChatModel model = MistralAiChatModel.builder()\n                .apiKey(ApiKeys.MISTRALAI_API_KEY)\n                .modelName(MistralAiChatModelName.MISTRAL_SMALL_LATEST)\n                .build();\n\n        String response = model.chat(\"Say 'Hello World'\");\n        System.out.println(response);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatModelListener for Observability\nDESCRIPTION: Java code showing how to implement a ChatModelListener for observability. This listener provides methods to handle chat model requests, responses, and errors.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\n@Configuration\nclass MyConfiguration {\n    \n    @Bean\n    ChatModelListener chatModelListener() {\n        return new ChatModelListener() {\n\n            private static final Logger log = LoggerFactory.getLogger(ChatModelListener.class);\n\n            @Override\n            public void onRequest(ChatModelRequestContext requestContext) {\n                log.info(\"onRequest(): {}\", requestContext.chatRequest());\n            }\n\n            @Override\n            public void onResponse(ChatModelResponseContext responseContext) {\n                log.info(\"onResponse(): {}\", responseContext.chatResponse());\n            }\n\n            @Override\n            public void onError(ChatModelErrorContext errorContext) {\n                log.info(\"onError(): {}\", errorContext.error().getMessage());\n            }\n        };\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining an AI Service with User Message in Java\nDESCRIPTION: Demonstrates how to use the @UserMessage annotation with a template variable to provide instructions and user input to the LLM.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\ninterface Friend {\n\n    @UserMessage(\"You are a good friend of mine. Answer using slang. {{it}}\")\n    String chat(String userMessage);\n}\n\nFriend friend = AiServices.create(Friend.class, model);\n\nString answer = friend.chat(\"Hello\"); // Hey! What's shakin'?\n```\n\n----------------------------------------\n\nTITLE: Handling Tool Execution Results in Java\nDESCRIPTION: Demonstrates how to handle the result of a tool execution and send it back to the LLM for further processing.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nString result = \"It is expected to rain in London tomorrow.\";\nToolExecutionResultMessage toolExecutionResultMessage = ToolExecutionResultMessage.from(toolExecutionRequest, result);\nChatRequest request2 = ChatRequest.builder()\n        .messages(List.of(userMessage, aiMessage, toolExecutionResultMessage))\n        .toolSpecifications(toolSpecifications)\n        .build();\nChatResponse response2 = model.chat(request2);\n```\n\n----------------------------------------\n\nTITLE: Building an MCP Tool Provider in Java\nDESCRIPTION: This snippet describes the process of creating an MCP Tool Provider in Java. It integrates multiple MCP clients into a single provider capable of executing tools from connected servers. Options exist to define behavior in case of server failures.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_3\n\nLANGUAGE: Java\nCODE:\n```\nToolProvider toolProvider = McpToolProvider.builder()\n    .mcpClients(List.of(mcpClient))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Chatting with AI Assistant using RAG in Java\nDESCRIPTION: Java code demonstrating how to interact with the AI Assistant using RAG. This snippet shows how to ask a question and receive an answer augmented with retrieved information.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nString answer = assistant.chat(\"How to do Easy RAG with LangChain4j?\");\n```\n\n----------------------------------------\n\nTITLE: Spring Boot Controller Implementation\nDESCRIPTION: Example Spring Boot REST controller using the Azure OpenAI chat model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\n@RestController\nclass ChatModelController {\n\n    ChatModel chatModel;\n\n    ChatModelController(ChatModel chatModel) {\n        this.chatModel = chatModel;\n    }\n\n    @GetMapping(\"/model\")\n    public String model(@RequestParam(value = \"message\", defaultValue = \"Hello\") String message) {\n        return chatModel.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Models Embedding with Official SDK\nDESCRIPTION: Java code for setting up a GitHub Models embedding model using the Official SDK integration. The isGitHubModels flag specifies the use of GitHub Models service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai-official.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel model = OpenAiOfficialEmbeddingModel.builder()\n        .modelName(EmbeddingModel.TEXT_EMBEDDING_3_SMALL)\n        .isGitHubModels(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Jina Reranker in Java with LangChain4j\nDESCRIPTION: This Java code demonstrates how to set up and use Jina Reranker with LangChain4j. It includes creating a ScoringModel, ContentAggregator, and RetrievalAugmentor, which are then used to build an AI service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/jina-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nScoringModel scoringModel = JinaScoringModel.builder()\n    .apiKey(System.getenv(\"JINA_API_KEY\"))\n    .modelName(\"jina-reranker-v2-base-multilingual\")\n    .build();\n\nContentAggregator contentAggregator = ReRankingContentAggregator.builder()\n    .scoringModel(scoringModel)\n    ... \n    .build();\n\nRetrievalAugmentor retrievalAugmentor = DefaultRetrievalAugmentor.builder()\n    ...\n    .contentAggregator(contentAggregator)\n    .build();\n\nreturn AiServices.builder(Assistant.class)\n    .chatModel(...)\n    .retrievalAugmentor(retrievalAugmentor)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with Jlama in Java\nDESCRIPTION: Java code showing how to create a streaming chat model using Jlama and LangChain4j. It sets up a streaming model, sends a prompt, and handles the streamed response using a callback mechanism.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/jlama.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.model.chat.response.StreamingChatResponseHandler;\nimport dev.langchain4j.model.jlama.JlamaStreamingChatModel;\nimport dev.langchain4j.model.output.Response;\n\nimport java.util.concurrent.CompletableFuture;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        StreamingChatModel model = JlamaStreamingChatModel.builder()\n                .modelName(\"tjake/TinyLlama-1.1B-Chat-v1.0-Jlama-Q4\")\n                .build();\n\n        CompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();         \n        model.chat(\"Tell me a joke about Java\", new StreamingChatResponseHandler() {\n\n            @Override\n            public void onPartialResponse(String partialResponse) {\n                System.out.print(partialResponse);\n            }\n\n            @Override\n            public void onCompleteResponse(ChatResponse completeResponse) {\n                futureResponse.complete(completeResponse);\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                futureResponse.completeExceptionally(error);\n            }    \n        });\n\n        futureResponse.join();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Simplified JsonObjectSchema Property Configuration\nDESCRIPTION: Shows the simplified approach to adding properties using type-specific methods.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nJsonSchemaElement rootElement = JsonObjectSchema.builder()\n        .addStringProperty(\"city\", \"The city for which the weather forecast should be returned\")\n        .addEnumProperty(\"temperatureUnit\", List.of(\"CELSIUS\", \"FAHRENHEIT\"))\n        .required(\"city\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Enabling Logging for OpenAI Chat Model in Java\nDESCRIPTION: This snippet shows how to enable logging of requests and responses when creating an instance of OpenAiChatModel in pure Java.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/logging.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel.builder()\n    ...\n    .logRequests(true)\n    .logResponses(true)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing AI Service Registration Event Listener\nDESCRIPTION: Java code showing how to implement a listener for AI Service registration events. This listener provides information about registered AI services and their tools at runtime.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\n@Component\nclass AiServiceRegisteredEventListener implements ApplicationListener<AiServiceRegisteredEvent> {\n\n\n    @Override\n    public void onApplicationEvent(AiServiceRegisteredEvent event) {\n        Class<?> aiServiceClass = event.aiServiceClass();\n        List<ToolSpecification> toolSpecifications = event.toolSpecifications();\n        for (int i = 0; i < toolSpecifications.size(); i++) {\n            System.out.printf(\"[%s]: [Tool-%s]: %s%n\", aiServiceClass.getSimpleName(), i + 1, toolSpecifications.get(i));\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Content Injection with PromptTemplate in LangChain4j\nDESCRIPTION: Demonstrates how to override the default PromptTemplate in DefaultContentInjector when building a RetrievalAugmentor. The custom template defines how user messages and retrieved contents will be formatted.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nRetrievalAugmentor retrievalAugmentor = DefaultRetrievalAugmentor.builder()\n    .contentInjector(DefaultContentInjector.builder()\n        .promptTemplate(PromptTemplate.from(\"{{userMessage}}\\n{{contents}}\"))\n        .build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Defining Weather Tool with Annotations in Java\nDESCRIPTION: Demonstrates how to define a weather forecasting tool using the @Tool and @P annotations, which can be automatically converted to ToolSpecifications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass WeatherTools { \n  \n    @Tool(\"Returns the weather forecast for a given city\")\n    String getWeather(\n            @P(\"The city for which the weather forecast should be returned\") String city,\n            TemperatureUnit temperatureUnit\n    ) {\n        ...\n    }\n}\n\nList<ToolSpecification> toolSpecifications = ToolSpecifications.toolSpecificationsFrom(WeatherTools.class);\n```\n\n----------------------------------------\n\nTITLE: Loading Documents from File System in Java\nDESCRIPTION: Java code for loading documents from a specified directory using FileSystemDocumentLoader. This is the first step in the RAG process, where documents are loaded for processing.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nList<Document> documents = FileSystemDocumentLoader.loadDocuments(\"/home/langchain4j/documentation\");\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple OVHcloud AI Embedding Example\nDESCRIPTION: Comprehensive Java example demonstrating how to use OVHcloud AI Embedding model to generate embeddings for text segments and perform semantic similarity search. The example includes embedding creation, storage, and retrieval based on semantic similarity.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/ovh-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.embedding.Embedding;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.model.embedding.EmbeddingModel;\nimport dev.langchain4j.model.ovhai.OvhAiEmbeddingModel;\nimport dev.langchain4j.store.embedding.EmbeddingMatch;\nimport dev.langchain4j.store.embedding.EmbeddingStore;\nimport dev.langchain4j.store.embedding.inmemory.InMemoryEmbeddingStore;\n\nimport java.util.List;\n\npublic class OvhAiEmbeddingSimpleExample {\n\n    public static void main(String[] args) {\n        EmbeddingModel embeddingModel = OvhAiEmbeddingModel.builder()\n                .apiKey(System.getenv(\"OVH_AI_API_KEY\"))\n                .baseUrl(\"https://multilingual-e5-base.endpoints.kepler.ai.cloud.ovh.net\")\n                .build();\n\n        // For simplicity, this example uses an in-memory store, but you can choose any external compatible store for production environments.\n        EmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();\n\n        TextSegment segment1 = TextSegment.from(\"I like football.\");\n        Embedding embedding1 = embeddingModel.embed(segment1).content();\n        embeddingStore.add(embedding1, segment1);\n\n        TextSegment segment2 = TextSegment.from(\"The weather is good today.\");\n        Embedding embedding2 = embeddingModel.embed(segment2).content();\n        embeddingStore.add(embedding2, segment2);\n\n        String userQuery = \"What is your favourite sport?\";\n        Embedding queryEmbedding = embeddingModel.embed(userQuery).content();\n        EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n                .queryEmbedding(queryEmbedding)\n                .maxResults(1)\n                .build();\n        EmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);\n        EmbeddingMatch<TextSegment> embeddingMatch = searchResult.matches().get(0);\n\n        System.out.println(\"Question: \" + userQuery); // What is your favourite sport?\n        System.out.println(\"Response: \" + embeddingMatch.embedded().text()); // I like football.\n    }\n\n}\n```\n\n----------------------------------------\n\nTITLE: Using Custom Messages in OllamaChatModel\nDESCRIPTION: Demonstrates the use of custom messages with the OllamaChatModel in Java. This snippet utilizes a 'CustomMessage' to integrate a custom context, useful in models like Granite Guardian which utilize non-standard messages for context assessment.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"granite3-guardian\")\n    .build();\n \nString retrievedContext = \"One significant part of treaty making is that signing a treaty implies recognition that the other side is a sovereign state and that the agreement being considered is enforceable under international law. Hence, nations can be very careful about terming an agreement to be a treaty. For example, within the United States, agreements between states are compacts and agreements between states and the federal government or between agencies of the government are memoranda of understanding.\";\n\nList<ChatMessage> messages = List.of(\n    SystemMessage.from(\"context_relevance\"),\n    UserMessage.from(\"What is the history of treaty making?\"),\n    CustomMessage.from(Map.of(\n        \"role\", \"context\",\n        \"content\", retrievedContext\n    ))\n);\n\nChatResponse chatResponse = ollamaChatModel.chat(ChatRequest.builder().messages(messages).build());\n\nSystem.out.println(chatResponse.aiMessage().text()); // \"Yes\" (meaning risk detected by Granite Guardian)\n```\n\n----------------------------------------\n\nTITLE: Configuring a Strategy for Handling Hallucinated Tool Names in Java\nDESCRIPTION: Demonstrates how to provide a custom strategy for handling situations where the LLM attempts to call a tool that does not exist (hallucination). This is done by implementing a `Function<ToolExecutionRequest, ToolExecutionResultMessage>` and passing it to the `.hallucinatedToolNameStrategy()` method when building the AI Service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_17\n\nLANGUAGE: java\nCODE:\n```\nAssistantHallucinatedTool assistant = AiServices.builder(AssistantHallucinatedTool.class)\n        .chatModel(chatModel)\n        .tools(new HelloWorld())\n        .hallucinatedToolNameStrategy(toolExecutionRequest -> ToolExecutionResultMessage.from(\n                toolExecutionRequest, \"Error: there is no tool called \" + toolExecutionRequest.name()))\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating JsonReferenceSchema for Recursive Structures in Java\nDESCRIPTION: This code demonstrates how to create a recursive JSON schema using JsonReferenceSchema. It defines a schema for a person with children that are also persons, using a reference to enable recursion. This feature is only supported by Azure OpenAI, Mistral and OpenAI.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nString reference = \"person\"; // reference should be unique withing the schema\n\nJsonObjectSchema jsonObjectSchema = JsonObjectSchema.builder()\n        .addStringProperty(\"name\")\n        .addProperty(\"children\", JsonArraySchema.builder()\n                .items(JsonReferenceSchema.builder()\n                        .reference(reference)\n                        .build())\n                .build())\n        .required(\"name\", \"children\")\n        .definitions(Map.of(reference, JsonObjectSchema.builder()\n                .addStringProperty(\"name\")\n                .addProperty(\"children\", JsonArraySchema.builder()\n                        .items(JsonReferenceSchema.builder()\n                                .reference(reference)\n                                .build())\n                        .build())\n                .required(\"name\", \"children\")\n                .build()))\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Storing Document Embeddings in MongoDB\nDESCRIPTION: Code for creating document embeddings and storing them in MongoDB Atlas with metadata\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mongodb-atlas.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nArrayList<Document> docs = new ArrayList<>();\n\ndocs.add(new Document()\n        .append(\"text\", \"Penguins are flightless seabirds that live almost exclusively below the equator. Some island-dwellers can be found in warmer climates.\")\n        .append(\"metadata\", new Metadata(Map.of(\"website\", \"Science Direct\"))));\n\ndocs.add(new Document()\n        .append(\"text\", \"Emperor penguins are amazing birds. They not only survive the Antarctic winter, but they breed during the worst weather conditions on earth.\")\n        .append(\"metadata\", new Metadata(Map.of(\"website\", \"Our Earth\"))));\n\ndocs.add(...);\n\nSystem.out.println(\"Persisting document embeddings...\");\n\nfor (Document doc : docs) {\n    TextSegment segment = TextSegment.from(\n            doc.getString(\"text\"),\n            doc.get(\"metadata\", Metadata.class)\n    );\n    Embedding embedding = embeddingModel.embed(segment).content();\n    embeddingStore.add(embedding, segment);\n}\n```\n\n----------------------------------------\n\nTITLE: JsonObjectSchema Property Configuration Example\nDESCRIPTION: Shows different approaches to configure properties in JsonObjectSchema for weather forecast data.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nJsonSchemaElement citySchema = JsonStringSchema.builder()\n        .description(\"The city for which the weather forecast should be returned\")\n        .build();\n\nJsonSchemaElement temperatureUnitSchema = JsonEnumSchema.builder()\n        .enumValues(\"CELSIUS\", \"FAHRENHEIT\")\n        .build();\n\nMap<String, JsonSchemaElement> properties = Map.of(\n        \"city\", citySchema,\n        \"temperatureUnit\", temperatureUnitSchema\n);\n\nJsonSchemaElement rootElement = JsonObjectSchema.builder()\n        .addProperties(properties)\n        .required(\"city\") // required properties should be specified explicitly\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Using OpenAI Embedding Model with LangChain4j\nDESCRIPTION: Java code demonstrating how to use a configured embedding model to create embeddings for a text input.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai-official.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nResponse<Embedding> response = model.embed(\"Please embed this sentence.\");\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Models with Automatic Token Detection\nDESCRIPTION: This Java code demonstrates how to configure GitHub Models with automatic token detection, which is useful in GitHub Actions or Codespaces environments.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .modelName(ChatModel.GPT_4O_MINI)\n        .isGitHubModels(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing Custom QwenChatModel in Java\nDESCRIPTION: Advanced initialization of QwenChatModel with additional parameters like search enablement, temperature control, token limits, and stop words.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nChatModel qwenModel = QwenChatModel.builder()\n                    .apiKey(\"You API key here\")\n                    .modelName(\"qwen-max\")\n                    .enableSearch(true)\n                    .temperature(0.7)\n                    .maxTokens(4096)\n                    .stops(List.of(\"Hello\"))\n                    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing Gemini Pro Vision with Image Input\nDESCRIPTION: Java example demonstrating how to use Vertex AI Gemini chat model with image input, including model initialization and message handling.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.data.message.ImageContent;\nimport dev.langchain4j.data.message.TextContent;\nimport dev.langchain4j.data.message.UserMessage;\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.output.Response;\nimport dev.langchain4j.model.vertexai.VertexAiGeminiChatModel;\n\npublic class GeminiProVisionWithImageInput {\n\n    private static final String PROJECT_ID = \"YOUR-PROJECT-ID\";\n    private static final String LOCATION = \"us-central1\";\n    private static final String MODEL_NAME = \"gemini-1.5-flash\";\n    private static final String CAT_IMAGE_URL = \"https://upload.wikimedia.org/\" +\n        \"wikipedia/commons/e/e9/\" +\n        \"Felis_silvestris_silvestris_small_gradual_decrease_of_quality.png\";\n\n    public static void main(String[] args) {\n        ChatModel visionModel = VertexAiGeminiChatModel.builder()\n            .project(PROJECT_ID)\n            .location(LOCATION)\n            .modelName(MODEL_NAME)\n            .build();\n\n        ChatResponse response = visionModel.chat(\n            UserMessage.from(\n                ImageContent.from(CAT_IMAGE_URL),\n                TextContent.from(\"What do you see?\")\n            )\n        );\n        \n        System.out.println(response.aiMessage().text());\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Partial Responses and Errors with LambdaStreamingResponseHandler in Java\nDESCRIPTION: This example demonstrates how to use the onPartialResponseAndError method of LambdaStreamingResponseHandler to handle both partial responses and errors in a compact manner.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/response-streaming.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nimport static dev.langchain4j.model.LambdaStreamingResponseHandler.onPartialResponseAndError;\n\nmodel.chat(\"Tell me a joke\", onPartialResponseAndError(System.out::print, Throwable::printStackTrace));\n```\n\n----------------------------------------\n\nTITLE: Configuring ElasticsearchEmbeddingStore with KNN\nDESCRIPTION: Explicit configuration of ElasticsearchEmbeddingStore using KNN query implementation\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/elasticsearch.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nElasticsearchEmbeddingStore store = ElasticsearchEmbeddingStore.builder()\n        .configuration(ElasticsearchConfigurationKnn.builder().build())\n        .restClient(restClient)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Performing Semantic Search with MongoDB Atlas\nDESCRIPTION: Implementation of semantic search using MongoDB Atlas Vector Search with result scoring\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mongodb-atlas.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nString query = \"Where do penguins live?\";\nEmbedding queryEmbedding = embeddingModel.embed(query).content();\n\nEmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n        .queryEmbedding(queryEmbedding)\n        .maxResults(3)\n        .build();\n\nSystem.out.println(\"Performing the query...\");\n\nEmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);\nList<EmbeddingMatch<TextSegment>> matches = searchResult.matches();\n\nfor (EmbeddingMatch<TextSegment> embeddingMatch : matches) {\n    System.out.println(\"Response: \" + embeddingMatch.embedded().text());\n    System.out.println(\"Author: \" + embeddingMatch.embedded().metadata().getString(\"author\"));\n    System.out.println(\"Score: \" + embeddingMatch.score());\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Default ElasticsearchEmbeddingStore\nDESCRIPTION: Basic configuration for creating an ElasticsearchEmbeddingStore instance using default kNN implementation\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/elasticsearch.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nElasticsearchEmbeddingStore store = ElasticsearchEmbeddingStore.builder()\n        .restClient(restClient)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Defining an AI Service Interface with @AiService Annotation\nDESCRIPTION: Java code showing how to define an AI Service interface using the @AiService annotation. This example demonstrates a simple chat assistant with a system message.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n@AiService\ninterface Assistant {\n\n    @SystemMessage(\"You are a polite assistant\")\n    String chat(String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing AzureOpenAiStreamingChatModel in Java\nDESCRIPTION: This Java snippet shows how to programmatically build an AzureOpenAiStreamingChatModel for streaming responses from OpenAI in Azure. It uses the builder pattern and environment variables to configure API endpoint, API key, and deployment name (e.g., gpt-4o). Requires langchain4j's AzureOpenAiStreamingChatModel and environment variables AZURE_OPENAI_URL and AZURE_OPENAI_KEY. The main inputs are deployment/routing parameters, and this approach is recommended for users who want fine-grained programmatic setup before consuming streamed chat completion tokens.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel model = AzureOpenAiStreamingChatModel.builder()\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .deploymentName(\"gpt-4o\")\n        ...\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Streaming with Flux<String> in Java\nDESCRIPTION: Supports using Flux<String> for streaming data in place of TokenStream. Requires importing langchain4j-reactor dependency for asynchronous operations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_19\n\nLANGUAGE: java\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-reactor</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n\n  Flux<String> chat(String message);\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing QianfanChatModel Configuration\nDESCRIPTION: Extended configuration options for QianfanChatModel showing various customizable parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nQianfanChatModel model = QianfanChatModel.builder()\n    .baseUrl(...)\n    .apiKey(...)\n    .secretKey(...)\n    .temperature(...)\n    .maxRetries(...)\n    .topP(...)\n    .modelName(...)\n    .endpoint(...)\n    .responseFormat(...)\n    .penaltyScore(...)\n    .logRequests(...)\n    .logResponses()\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Streamlined Asynchronous Chat with Kotlin Builder DSL\nDESCRIPTION: This Kotlin extension function `chat` for `ChatModel` provides a concise way to initiate asynchronous chat requests using a type-safe builder DSL. It accepts a lambda function (`block`) with `ChatRequestBuilder` as its receiver to construct the `ChatRequest` internally. It leverages `chatAsync` for non-blocking execution via coroutines. This method simplifies request building while maintaining asynchronous behavior.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_8\n\nLANGUAGE: kotlin\nCODE:\n```\nChatModel.chat(block: ChatRequestBuilder.() -> Unit)\n```\n\n----------------------------------------\n\nTITLE: Configuring Safety Settings for Vertex AI Gemini Chat Model in Java\nDESCRIPTION: This snippet demonstrates how to configure safety settings for a Vertex AI Gemini chat model to filter or block harmful content based on different threshold levels. It includes setting up different harm categories with specific blocking thresholds and building the model with these safety settings along with logging configurations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nHashMap<HarmCategory, SafetyThreshold> safetySettings = new HashMap<>();\nsafetySettings.put(HARM_CATEGORY_HARASSMENT, BLOCK_LOW_AND_ABOVE);\nsafetySettings.put(HARM_CATEGORY_DANGEROUS_CONTENT, BLOCK_ONLY_HIGH);\nsafetySettings.put(HARM_CATEGORY_SEXUALLY_EXPLICIT, BLOCK_MEDIUM_AND_ABOVE);\n\nvar model = VertexAiGeminiChatModel.builder()\n    .project(PROJECT_ID)\n    .location(LOCATION)\n    .modelName(\"gemini-1.5-flash-001\")\n    .safetySettings(safetySettings)\n    .logRequests(true)\n    .logResponses(true)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Setting Up Couchbase Container for Testing with Testcontainers\nDESCRIPTION: Creates a containerized Couchbase server using the Testcontainers library for testing purposes, then initializes a CouchbaseEmbeddingStore that connects to this container.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nCouchbaseContainer couchbaseContainer =\n        new CouchbaseContainer(DockerImageName.parse(\"couchbase:enterprise\").asCompatibleSubstituteFor(\"couchbase/server\"))\n                .withCredentials(\"Administrator\", \"password\")\n                .withBucket(testBucketDefinition)\n                .withStartupTimeout(Duration.ofMinutes(1));\n\nCouchbaseEmbeddingStore embeddingStore = CouchbaseEmbeddingStore.builder()\n        .clusterUrl(couchbaseContainer.getConnectionString())\n        .username(couchbaseContainer.getUsername())\n        .password(couchbaseContainer.getPassword())\n        .bucketName(testBucketDefinition.getName())\n        .scopeName(\"_default\")\n        .collectionName(\"_default\")\n        .searchIndexName(\"test\")\n        .dimensions(384)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Setting Up MistralAiModerationModel in Plain Java\nDESCRIPTION: This snippet demonstrates the creation of a moderation model using MistralAiModerationModel.Builder to evaluate and moderate user content. It relies on the MistralAI framework for model building. Input requires an API key, and moderation is performed on sample strings, with expected outputs moderating harmful content. The Builder provides options to log requests and manage moderation settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nModerationModel model = new MistralAiModerationModel.Builder()\n    .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\"))\n    .modelName(\"mistral-moderation-latest\")\n    .logRequests(true)\n    .logResponses(false)\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nModeration moderation = model.moderate(\"I want to kill them.\").content();\n```\n\n----------------------------------------\n\nTITLE: Building AI Service with Programmatic Tools in Java\nDESCRIPTION: Demonstrates how to configure an AI Service to use programmatically defined tools by passing a map of `ToolSpecification` to `ToolExecutor` pairs to the `.tools()` method of the `AiServices.builder()`.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_15\n\nLANGUAGE: java\nCODE:\n```\nAssistant assistant = AiServices.builder(Assistant.class)\n    .chatModel(chatModel)\n    .tools(Map.of(toolSpecification, toolExecutor))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring AzureOpenAiStreamingChatModel via Spring Boot Properties\nDESCRIPTION: This snippet details how to configure the AzureOpenAiStreamingChatModel within a Spring Boot application using application.properties. Each property maps to a model configuration option, including endpoint, API key, deployment, and various response controls (like max tokens, temperature, and penalties). Inputs are property values, some of which are environment variables, providing a declarative setup path for streaming chat models in managed environments; key constraint is proper property naming and value sourcing.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_14\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.azure-open-ai.streaming-chat-model.endpoint=${AZURE_OPENAI_URL}\nlangchain4j.azure-open-ai.streaming-chat-model.service-version=...\nlangchain4j.azure-open-ai.streaming-chat-model.api-key=${AZURE_OPENAI_KEY}\nlangchain4j.azure-open-ai.streaming-chat-model.deployment-name=gpt-4o\nlangchain4j.azure-open-ai.streaming-chat-model.max-tokens=...\nlangchain4j.azure-open-ai.streaming-chat-model.temperature=...\nlangchain4j.azure-open-ai.streaming-chat-model.top-p=...\nlangchain4j.azure-open-ai.streaming-chat-model.logit-bias=...\nlangchain4j.azure-open-ai.streaming-chat-model.user=...\nlangchain4j.azure-open-ai.streaming-chat-model.stop=...\nlangchain4j.azure-open-ai.streaming-chat-model.presence-penalty=...\nlangchain4j.azure-open-ai.streaming-chat-model.frequency-penalty=...\nlangchain4j.azure-open-ai.streaming-chat-model.seed=...\nlangchain4j.azure-open-ai.streaming-chat-model.timeout=...\nlangchain4j.azure-open-ai.streaming-chat-model.max-retries=...\nlangchain4j.azure-open-ai.streaming-chat-model.log-requests-and-responses=...\nlangchain4j.azure-open-ai.streaming-chat-model.user-agent-suffix=...\nlangchain4j.azure-open-ai.streaming-chat-model.customHeaders=...\n```\n\n----------------------------------------\n\nTITLE: Using LambdaStreamingResponseHandler for Compact Streaming in Java\nDESCRIPTION: This snippet shows how to use the LambdaStreamingResponseHandler class to create a more compact implementation of streaming, using lambda expressions to handle partial responses.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/response-streaming.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport static dev.langchain4j.model.LambdaStreamingResponseHandler.onPartialResponse;\n\nmodel.chat(\"Tell me a joke\", onPartialResponse(System.out::print));\n```\n\n----------------------------------------\n\nTITLE: Defining AugmentedGenerationConfig Interface in Java\nDESCRIPTION: This code snippet defines the AugmentedGenerationConfig interface with methods for configuring various parameters for augmented generation in language models. It includes options for temperature, top-k, top-p, presence penalty, frequency penalty, and more.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j/src/test/resources/blank-file.txt#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\npackage dev.langchain4j.model.output;\n\nimport dev.langchain4j.data.message.AiMessage;\n\nimport java.util.List;\n\npublic interface AugmentedGenerationConfig {\n\n    AugmentedGenerationConfig DEFAULT = AugmentedGenerationConfig.builder().build();\n\n    static Builder builder() {\n        return new Builder();\n    }\n\n    Double temperature();\n\n    Integer topK();\n\n    Double topP();\n\n    List<String> stop();\n\n    Integer maxTokens();\n\n    Double presencePenalty();\n\n    Double frequencyPenalty();\n\n    List<AiMessage> logitBias();\n\n    String user();\n\n    Boolean stream();\n\n    class Builder {\n\n        private Double temperature;\n        private Integer topK;\n        private Double topP;\n        private List<String> stop;\n        private Integer maxTokens;\n        private Double presencePenalty;\n        private Double frequencyPenalty;\n        private List<AiMessage> logitBias;\n        private String user;\n        private Boolean stream;\n\n        public Builder temperature(Double temperature) {\n            this.temperature = temperature;\n            return this;\n        }\n\n        public Builder topK(Integer topK) {\n            this.topK = topK;\n            return this;\n        }\n\n        public Builder topP(Double topP) {\n            this.topP = topP;\n            return this;\n        }\n\n        public Builder stop(List<String> stop) {\n            this.stop = stop;\n            return this;\n        }\n\n        public Builder maxTokens(Integer maxTokens) {\n            this.maxTokens = maxTokens;\n            return this;\n        }\n\n        public Builder presencePenalty(Double presencePenalty) {\n            this.presencePenalty = presencePenalty;\n            return this;\n        }\n\n        public Builder frequencyPenalty(Double frequencyPenalty) {\n            this.frequencyPenalty = frequencyPenalty;\n            return this;\n        }\n\n        public Builder logitBias(List<AiMessage> logitBias) {\n            this.logitBias = logitBias;\n            return this;\n        }\n\n        public Builder user(String user) {\n            this.user = user;\n            return this;\n        }\n\n        public Builder stream(Boolean stream) {\n            this.stream = stream;\n            return this;\n        }\n\n        public AugmentedGenerationConfig build() {\n            return new AugmentedGenerationConfig() {\n                @Override\n                public Double temperature() {\n                    return temperature;\n                }\n\n                @Override\n                public Integer topK() {\n                    return topK;\n                }\n\n                @Override\n                public Double topP() {\n                    return topP;\n                }\n\n                @Override\n                public List<String> stop() {\n                    return stop;\n                }\n\n                @Override\n                public Integer maxTokens() {\n                    return maxTokens;\n                }\n\n                @Override\n                public Double presencePenalty() {\n                    return presencePenalty;\n                }\n\n                @Override\n                public Double frequencyPenalty() {\n                    return frequencyPenalty;\n                }\n\n                @Override\n                public List<AiMessage> logitBias() {\n                    return logitBias;\n                }\n\n                @Override\n                public String user() {\n                    return user;\n                }\n\n                @Override\n                public Boolean stream() {\n                    return stream;\n                }\n            };\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating ToolSpecification Manually in Java\nDESCRIPTION: Shows how to manually create a ToolSpecification object for a weather forecasting tool, including name, description, and parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nToolSpecification toolSpecification = ToolSpecification.builder()\n    .name(\"getWeather\")\n    .description(\"Returns the weather forecast for a given city\")\n    .parameters(JsonObjectSchema.builder()\n        .addStringProperty(\"city\", \"The city for which the weather forecast should be returned\")\n        .addEnumProperty(\"temperatureUnit\", List.of(\"CELSIUS\", \"FAHRENHEIT\"))\n        .required(\"city\") // the required properties should be specified explicitly\n        .build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing ZhipuAiChatModel with Custom Configuration\nDESCRIPTION: Java code snippet for initializing ZhipuAiChatModel with custom parameters including model, temperature, max tokens, and retry settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/zhipu-ai.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nChatModel qwenModel = ZhipuAiChatModel.builder()\n                    .apiKey(\"You API key here\")\n                    .model(\"glm-4\")\n                    .temperature(0.6)\n                    .maxToken(1024)\n                    .maxRetries(1)\n                    .callTimeout(Duration.ofSeconds(60))\n                    .connectTimeout(Duration.ofSeconds(60))\n                    .writeTimeout(Duration.ofSeconds(60))\n                    .readTimeout(Duration.ofSeconds(60))\n                    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Chat with Kotlin Flow\nDESCRIPTION: Kotlin code demonstrating how to use the chatFlow extension function for streaming responses from a language model, utilizing Kotlin coroutines and Flow.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/kotlin.md#2025-04-22_snippet_3\n\nLANGUAGE: kotlin\nCODE:\n```\nval flow = model.chatFlow { // similar to non-streaming scenario\n    messages += userMessage(\"Can you explain how streaming works?\")\n    parameters { // ChatRequestParameters\n        temperature = 0.7\n        maxOutputTokens = 42\n    }\n}\n\nrunBlocking { // must run in a coroutine context \n    flow.collect { reply ->\n        when (reply) {\n            is StreamingChatModelReply.PartialResponse -> {\n                print(reply.partialResponse) // Stream output as it arrives\n            }\n            is StreamingChatModelReply.CompleteResponse -> {\n                println(\"\\nComplete: ${reply.response.aiMessage().text()}\")\n            }\n            is StreamingChatModelReply.Error -> {\n                println(\"Error occurred: ${reply.cause.message}\")\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming with VertexAiGeminiStreamingChatModel\nDESCRIPTION: Java example showing how to use streaming capabilities with Vertex AI Gemini chat model using callback handlers.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nvar model = VertexAiGeminiStreamingChatModel.builder()\n        .project(PROJECT_ID)\n        .location(LOCATION)\n        .modelName(GEMINI_1_5_PRO)\n        .build();\n\nmodel.chat(\"Why is the sky blue?\", new StreamingChatResponseHandler() {\n\n    @Override\n    public void onPartialResponse(String partialResponse) {\n        System.print(partialResponse);\n    }\n\n    @Override\n    public void onCompleteResponse(ChatResponse completeResponse){\n        System.print(completeResponse);\n    }\n\n    @Override\n    public void onError(Throwable error) {\n        error.printStackTrace();\n    }\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Tools as Spring Components\nDESCRIPTION: Java code showing how to implement tools as Spring components. This example demonstrates booking-related tools that can be automatically wired into AI Services.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\n@Component\npublic class BookingTools {\n\n    private final BookingService bookingService;\n\n    public BookingTools(BookingService bookingService) {\n        this.bookingService = bookingService;\n    }\n\n    @Tool\n    public Booking getBookingDetails(String bookingNumber, String customerName, String customerSurname) {\n        return bookingService.getBookingDetails(bookingNumber, customerName, customerSurname);\n    }\n\n    @Tool\n    public void cancelBooking(String bookingNumber, String customerName, String customerSurname) {\n        bookingService.cancelBooking(bookingNumber, customerName, customerSurname);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Vertex AI Embedding Model Parameters\nDESCRIPTION: Example showing all available configuration options for the Vertex AI embedding model including retry settings, batch limits, task types, and other model-specific parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/google-vertex-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel embeddingModel = VertexAiEmbeddingModel.builder()\n    .project(PROJECT_ID)\n    .location(\"us-central1\")\n    .endpoint(\"us-central1-aiplatform.googleapis.com:443\") // optional\n    .publisher(\"google\")\n    .modelName(MODEL_NAME)\n    .maxRetries(3)             // 3 by default\n    .maxSegmentsPerBatch(250)  // up to 250 segments per batch\n    .maxTokensPerBatch(2048)   // up to 2048 tokens per segment\n    .taskType()                // see below for the different task types\n    .titleMetadataKey()        // for the RETRIEVAL_DOCUMENT task, you can specify a title  \n                               // for the text segment to identify its document origin\n    .autoTruncate(false)       // false by default: truncates segments longer than 2,048 input tokens\n    .outputDimensionality(512) // for models that support different output vector dimensions\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Vertex AI Embedding Model Implementation Example\nDESCRIPTION: Complete example demonstrating how to initialize and use the Vertex AI embedding model to generate embeddings from text input. Shows model configuration, embedding generation, and accessing embedding dimensions and vectors.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/google-vertex-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.embedding.Embedding;\nimport dev.langchain4j.model.embedding.EmbeddingModel;\nimport dev.langchain4j.model.output.Response;\nimport dev.langchain4j.model.vertexai.VertexAiEmbeddingModel;\n\npublic class VertexAiEmbeddingModelExample {\n    \n    private static final String PROJECT_ID = \"YOUR-PROJECT-ID\";\n    private static final String MODEL_NAME = \"textembedding-gecko@latest\";\n\n    public static void main(String[] args) {\n\n        EmbeddingModel embeddingModel = VertexAiEmbeddingModel.builder()\n                .project(PROJECT_ID)\n                .location(\"us-central1\")\n                .endpoint(\"us-central1-aiplatform.googleapis.com:443\")\n                .publisher(\"google\")\n                .modelName(MODEL_NAME)\n                .build();\n\n        Response<Embedding> response = embeddingModel.embed(\"Hello, how are you?\");\n        \n        Embedding embedding = response.content();\n\n        int dimension = embedding.dimension(); // 768\n        float[] vector = embedding.vector(); // [-0.06050122, -0.046411075, ...\n\n        System.out.println(dimension);\n        System.out.println(embedding.vectorAsList());\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing PaymentDataAssistantApp Using MistralAI in Java\nDESCRIPTION: This Java class PaymentDataAssistantApp integrates the MistralAI chat model for processing payment-related inquiries by users. Dependencies include MistralAI SDK and LangChain4j framework. Key components are setting up the ChatModel with user API keys, querying details, and interfacing via PaymentTransactionAgent to extract and provide desired transaction information based on user messages.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.memory.chat.MessageWindowChatMemory;\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.mistralai.MistralAiChatModel;\nimport dev.langchain4j.model.mistralai.MistralAiChatModelName;\nimport dev.langchain4j.service.AiServices;\n\npublic class PaymentDataAssistantApp {\n\n    ChatModel mistralAiModel = MistralAiChatModel.builder()\n            .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\")) // Please use your own Mistral AI API key\n            .modelName(MistralAiChatModelName.MISTRAL_LARGE_LATEST) // Also you can use MistralAiChatModelName.OPEN_MIXTRAL_8X22B as open source model\n            .logRequests(true)\n            .logResponses(true)\n            .build();\n    \n    public static void main(String[] args) {\n        // STEP 1: User specify tools and query\n        PaymentTransactionTool paymentTool = new PaymentTransactionTool();\n        String userMessage = \"What is the status and the payment date of transaction T1005?\";\n\n        // STEP 2: User asks the agent and AiServices call to the functions\n        PaymentTransactionAgent agent = AiServices.builder(PaymentTransactionAgent.class)\n                .chatModel(mistralAiModel)\n                .tools(paymentTool)\n                .chatMemory(MessageWindowChatMemory.withMaxMessages(10))\n                .build();\n        \n        // STEP 3: User gets the final response from the agent\n        String answer = agent.chat(userMessage);\n        System.out.println(answer);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing MistralAI Embedding Example\nDESCRIPTION: Complete Java example demonstrating how to use MistralAI's embedding model for text similarity search, including model initialization, text embedding, and similarity search implementation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.embedding.Embedding;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.model.mistralai.MistralAiEmbeddingModel;\nimport dev.langchain4j.model.embedding.EmbeddingModel;\nimport dev.langchain4j.store.embedding.EmbeddingMatch;\nimport dev.langchain4j.store.embedding.EmbeddingStore;\nimport dev.langchain4j.store.embedding.inmemory.InMemoryEmbeddingStore;\n\nimport java.util.List;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        EmbeddingModel embeddingModel = MistralAiEmbeddingModel.builder()\n                .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\"))\n                .modelName(\"mistral-embed\")\n                .build();\n\n        // For simplicity, this example uses an in-memory store, but you can choose any external compatible store for production environments.\n        EmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();\n\n        TextSegment segment1 = TextSegment.from(\"I like football.\");\n        Embedding embedding1 = embeddingModel.embed(segment1).content();\n        embeddingStore.add(embedding1, segment1);\n        \n        TextSegment segment2 = TextSegment.from(\"The weather is good today.\");\n        Embedding embedding2 = embeddingModel.embed(segment2).content();\n        embeddingStore.add(embedding2, segment2);\n        \n        String userQuery = \"What is your favourite sport?\";\n        Embedding queryEmbedding = embeddingModel.embed(userQuery).content();\n        EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n                .queryEmbedding(queryEmbedding)\n                .maxResults(1)\n                .build();\n        EmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);\n        EmbeddingMatch<TextSegment> embeddingMatch = searchResult.matches().get(0);\n\n        System.out.println(\"Question: \" + userQuery); // What is your favourite sport?\n        System.out.println(\"Response: \" + embeddingMatch.embedded().text()); // I like football.\n    }\n```\n\n----------------------------------------\n\nTITLE: Enabling Structured Outputs for Tools in OpenAiChatModel\nDESCRIPTION: Java code to enable Structured Outputs feature for tools when building an OpenAiChatModel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel.builder()\n    ...\n    .strictTools(true)\n    .build(),\n```\n\n----------------------------------------\n\nTITLE: Initializing MongoDB Atlas Embedding Store\nDESCRIPTION: Java code to initialize the MongoDB client and configure the embedding store with VoyageAI embedding model\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mongodb-atlas.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nString embeddingApiKey = System.getenv(\"VOYAGE_AI_KEY\");\nString uri = System.getenv(\"MONGODB_URI\");\n\nEmbeddingModel embeddingModel = VoyageAiEmbeddingModel.builder()\n        .apiKey(embeddingApiKey)\n        .modelName(\"voyage-3\")\n        .build();\n\nMongoClient mongoClient = MongoClients.create(uri);\n\nSystem.out.println(\"Instantiating the embedding store...\");\n\nBoolean createIndex = true;\n\nIndexMapping indexMapping = IndexMapping.builder()\n        .dimension(embeddingModel.dimension())\n        .metadataFieldNames(new HashSet<>())\n        .build();\n\nMongoDbEmbeddingStore embeddingStore = MongoDbEmbeddingStore.builder()\n        .databaseName(\"search\")\n        .collectionName(\"langchaintest\")\n        .createIndex(createIndex)\n        .indexName(\"vector_index\")\n        .indexMapping(indexMapping)\n        .fromClient(mongoClient)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Positive Sentiment Analysis using Java SentimentAnalyzer\nDESCRIPTION: The 'SentimentAnalyzer' interface defines a method for determining if a given text has a positive sentiment. It requires an AI service configuration and a source providing text input. The method returns a boolean indicating the sentiment.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\ninterface SentimentAnalyzer {\n\n    @UserMessage(\"Does {{it}} has a positive sentiment?\")\n    boolean isPositive(String text);\n\n}\n\nSentimentAnalyzer sentimentAnalyzer = AiServices.create(SentimentAnalyzer.class, model);\n\nboolean positive = sentimentAnalyzer.isPositive(\"It's wonderful!\");\n// true\n```\n\n----------------------------------------\n\nTITLE: Configuring Streaming Chat Model\nDESCRIPTION: This Java code demonstrates how to configure a streaming chat model using the OpenAiOfficialStreamingChatModel class for real-time interactions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel model = OpenAiOfficialStreamingChatModel.builder()\n        .baseUrl(System.getenv(\"OPENAI_BASE_URL\"))\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing MistralAiStreamingChatModel for JSON Streaming in Java\nDESCRIPTION: Demonstrates the setup of a MistralAiStreamingChatModel to handle streaming chat requests and respond in JSON format. Dependencies are the MistralAi SDK and response handlers for managing responses. The model is set up with an API key and configured to stream responses asynchronously through completion handlers, providing outputs as JSON-formatted data.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel streamingModel = MistralAiStreamingChatModel.builder()\n                .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\")) // Please use your own Mistral AI API key\n                .responseFormat(MistralAiResponseFormatType.JSON_OBJECT)\n                .build();\n\nString userMessage = \"Return JSON with two fields: transactionId and status with the values T123 and paid.\";\n\nCompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();\n\nstreamingModel.chat(userMessage, new StreamingChatResponseHandler() {\n\n    @Override\n    public void onPartialResponse(String partialResponse) {\n        System.out.print(partialResponse);\n    }\n\n    @Override\n    public void onCompleteResponse(ChatResponse completeResponse) {\n        futureResponse.complete(completeResponse);\n    }\n\n    @Override\n    public void onError(Throwable error) {\n        futureResponse.completeExceptionally(error);\n    }\n});\n\nString json = futureResponse.get().content().text();\n\nSystem.out.println(json); // {\"transactionId\":\"T123\",\"status\":\"paid\"}\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Tool with GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code demonstrating how to implement a weather tool using GoogleAiGeminiChatModel and AiServices for function calling.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nrecord WeatherForecast(\n    String location,\n    String forecast,\n    int temperature) {}\n\nclass WeatherForecastService {\n    @Tool(\"Get the weather forecast for a location\")\n    WeatherForecast getForecast(\n        @P(\"Location to get the forecast for\") String location) {\n        if (location.equals(\"Paris\")) {\n            return new WeatherForecast(\"Paris\", \"sunny\", 20);\n        } else if (location.equals(\"London\")) {\n            return new WeatherForecast(\"London\", \"rainy\", 15);\n        } else if (location.equals(\"Tokyo\")) {\n            return new WeatherForecast(\"Tokyo\", \"warm\", 32);\n        } else {\n            return new WeatherForecast(\"Unknown\", \"unknown\", 0);\n        }\n    }\n}\n\ninterface WeatherAssistant {\n    String chat(String userMessage);\n}\n\nWeatherForecastService weatherForecastService =\n    new WeatherForecastService();\n\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .temperature(0.0)\n    .build();\n\nWeatherAssistant weatherAssistant =\n    AiServices.builder(WeatherAssistant.class)\n        .chatModel(gemini)\n        .tools(weatherForecastService)\n        .build();\n\nString tokyoWeather = weatherAssistant.chat(\n        \"What is the weather forecast for Tokyo?\");\n\nSystem.out.println(\"Gemini> \" + tokyoWeather);\n// Gemini> The weather forecast for Tokyo is warm\n//         with a temperature of 32 degrees.\n```\n\n----------------------------------------\n\nTITLE: Executing Sentiment Analysis using LangChain4j AI Service in Java\nDESCRIPTION: This snippet shows how to use the created `sentimentAnalyzer` instance to perform sentiment analysis on input text. It calls the `analyzeSentimentOf` method to get a `Sentiment` enum value and the `isPositive` method to get a boolean result, printing both outputs to the console.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nSentiment sentiment = sentimentAnalyzer.analyzeSentimentOf(\"I love this product!\");\nSystem.out.println(sentiment); // Output: POSITIVE\n\nboolean positive = sentimentAnalyzer.isPositive(\"This is a terrible experience.\");\nSystem.out.println(positive); // Output: false\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI DALL-E Image Model in Plain Java\nDESCRIPTION: Code for creating an OpenAiImageModel instance with DALL-E 3 configuration in a plain Java application.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/dall-e.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nImageModel model = OpenAiImageModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"dall-e-3\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing PgVectorEmbeddingStore with Required Parameters\nDESCRIPTION: Java code example showing the minimal configuration required to create a PgVectorEmbeddingStore instance. Includes essential parameters like host, port, database, credentials, and embedding dimensions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pgvector.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore<TextSegment> embeddingStore = PgVectorEmbeddingStore.builder()\n        .host(\"localhost\")                           // Required: Host of the PostgreSQL instance\n        .port(5432)                                  // Required: Port of the PostgreSQL instance\n        .database(\"postgres\")                        // Required: Database name\n        .user(\"my_user\")                             // Required: Database user\n        .password(\"my_password\")                     // Required: Database password\n        .table(\"my_embeddings\")                      // Required: Table name to store embeddings\n        .dimension(embeddingModel.dimension())       // Required: Dimension of embeddings\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Mode with Google AI Gemini via Java Configuration\nDESCRIPTION: Enables JSON responses in Google AI Gemini models using ResponseFormat. Supports parsing JSON schemas directly from Java classes or described JSON schemas.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_15\n\nLANGUAGE: java\nCODE:\n```\nGoogleAiGeminiChatModel.builder()\n    ...\n    .responseFormat(ResponseFormat.JSON)\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nGoogleAiGeminiChatModel.builder()\n    ...\n    .responseFormat(ResponseFormat.builder()\n        .type(JSON)\n        .jsonSchema(JsonSchemas.jsonSchemaFrom(Person.class).get())\n        .build())\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nGoogleAiGeminiChatModel.builder()\n    ...\n    .responseFormat(ResponseFormat.builder()\n        .type(JSON)\n        .jsonSchema(JsonSchema.builder()...build())\n        .build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Mode with Vertex AI Gemini using Java\nDESCRIPTION: Configures Vertex AI Gemini models to use JSON responses. Supports explicit schema definitions from Java classes or JSON schema.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_14\n\nLANGUAGE: java\nCODE:\n```\nVertexAiGeminiChatModel.builder()\n    ...\n    .responseMimeType(\"application/json\")\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nVertexAiGeminiChatModel.builder()\n    ...\n    .responseSchema(SchemaHelper.fromClass(Person.class))\n    .build();\n```\n\nLANGUAGE: java\nCODE:\n```\nVertexAiGeminiChatModel.builder()\n    ...\n    .responseSchema(Schema.builder()...build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAiStreamingChatModel in Plain Java\nDESCRIPTION: Java code to create an OpenAiStreamingChatModel instance with API key and model name, and an alternative version with default request parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel model = OpenAiStreamingChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .build();\n\n// You can also specify default chat request parameters using ChatRequestParameters or OpenAiChatRequestParameters\nStreamingChatModel model = OpenAiStreamingChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .defaultRequestParameters(OpenAiChatRequestParameters.builder()\n                .modelName(\"gpt-4o-mini\")\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring BedrockStreamingChatModel using ConverseAPI in Java\nDESCRIPTION: Java code snippet for configuring a BedrockStreamingChatModel using the ConverseAPI. This configuration is similar to the ChatModel but specifically for streaming responses.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/amazon-bedrock.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nStreamingChatModel model = BedrockStreamingChatModel.builder()\n        .modelId(\"us.amazon.nova-lite-v1:0\")\n        .region(...)\n        .maxRetries(...)\n        .timeout(...)\n        .logRequests(...)\n        .logResponses(...)\n        .listeners(...)\n        .defaultRequestParameters(BedrockChatRequestParameters.builder()\n                .topP(...)\n                .temperature(...)\n                .maxOutputTokens(...)\n                .stopSequences(...)\n                .toolSpecifications(...)\n                .additionalModelRequestFields(...)\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Using ChatModel with Kotlin Coroutines and Type-Safe Builders\nDESCRIPTION: Kotlin code demonstrating how to use coroutines, suspend functions, and type-safe builders to interact with a ChatModel in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/kotlin.md#2025-04-22_snippet_1\n\nLANGUAGE: kotlin\nCODE:\n```\nval model = OpenAiChatModel.builder()\n    .apiKey(\"YOUR_API_KEY\")\n    // more configuration parameters here ...\n    .build()\n\nCoroutineScope(Dispatchers.IO).launch {\n    val response = model.chat {\n        messages += systemMessage(\"You are a helpful assistant\")\n        messages += userMessage(\"Hello!\")\n        parameters {\n            temperature = 0.7\n        }\n    }\n    println(response.aiMessage().text())\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Python Code Execution with Gemini in Java\nDESCRIPTION: Configures a Gemini model to allow Python code execution in a sandboxed environment. This setup enables Gemini to solve problems by creating and executing Python code, with options to include the code and execution output in the response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .allowCodeExecution(true)\n    .includeCodeExecutionOutput(true)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Customizing Spring RestClient for LangChain4j OpenAI Integration\nDESCRIPTION: Shows how to customize Spring's RestClient builder with custom request factory and streaming executor for OpenAI chat model integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/customizable-http-client.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nRestClient.Builder restClientBuilder = RestClient.builder()\n        .requestFactory(new HttpComponentsClientHttpRequestFactory());\n\nSpringRestClientBuilder springRestClientBuilder = SpringRestClient.builder()\n        .restClientBuilder(restClientBuilder)\n        .streamingRequestExecutor(new VirtualThreadTaskExecutor());\n\nOpenAiChatModel model = OpenAiChatModel.builder()\n        .httpClientBuilder(springRestClientBuilder)\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with MistralAI in Java\nDESCRIPTION: Java code showcasing streaming chat completion using MistralAI with LangChain4j. It sets up a StreamingChatResponseHandler to process partial responses and handle completion or errors.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.model.chat.response.StreamingChatResponseHandler;\nimport dev.langchain4j.model.mistralai.MistralAiStreamingChatModel;\nimport dev.langchain4j.model.output.Response;\n\nimport java.util.concurrent.CompletableFuture;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        MistralAiStreamingChatModel model = MistralAiStreamingChatModel.builder()\n                .apiKey(ApiKeys.MISTRALAI_API_KEY)\n                .modelName(MistralAiChatModelName.MISTRAL_SMALL_LATEST)\n                .build();\n\n        CompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();         \n        model.chat(\"Tell me a joke about Java\", new StreamingChatResponseHandler() {\n            \n            @Override\n            public void onPartialResponse(String partialResponse) {\n                System.out.print(partialResponse);\n            }\n\n            @Override\n            public void onCompleteResponse(ChatResponse completeResponse) {\n                futureResponse.complete(completeResponse);\n            }\n\n            @Override\n            public void onError(Throwable error) {\n                futureResponse.completeExceptionally(error);\n            }    \n        });\n\n        futureResponse.join();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: AI Assistant Demo Implementation\nDESCRIPTION: Example demonstrating how to use the StockPriceService with an AI Assistant.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n    String chat(String userMessage);\n}\n\npublic class Demo {\n    String functionCalling(Model model) {\n        String question = \"Is the current Microsoft stock higher than $450?\";\n        StockPriceService stockPriceService = new StockPriceService();\n\n        Assistant assistant = AiServices.builder(Assistant.class)\n                .chatModel(model)\n                .tools(stockPriceService)\n                .build();\n\n        String answer = assistant.chat(question);\n\n        model.addAttribute(\"answer\", answer);\n        return \"demo\";\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating MilvusEmbeddingStore with Existing Client in Java\nDESCRIPTION: This Java code shows how to create a MilvusEmbeddingStore using an existing MilvusServiceClient. It first sets up a custom client and then uses it in the MilvusEmbeddingStore builder, allowing for more customized configurations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/milvus.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n// Set up a custom MilvusServiceClient\nMilvusServiceClient customMilvusClient = new MilvusServiceClient(\n    ConnectParam.newBuilder()\n        .withHost(\"localhost\")\n        .withPort(19530)\n        .build()\n);\n\n// Use the custom client in the builder\nMilvusEmbeddingStore store = MilvusEmbeddingStore.builder()\n\n    .milvusClient(customMilvusClient)          // Use an existing Milvus client\n    .collectionName(\"example_collection\")      // Name of the collection\n    .dimension(128)                            // Dimension of vectors\n    .indexType(IndexType.FLAT)                 // Index type\n    .metricType(MetricType.COSINE)             // Metric type\n    .consistencyLevel(ConsistencyLevelEnum.EVENTUALLY)  // Consistency level\n    .autoFlushOnInsert(true)                   // Auto flush after insert\n    .idFieldName(\"id\")                         // ID field name\n    .textFieldName(\"text\")                     // Text field name\n    .metadataFieldName(\"metadata\")             // Metadata field name\n    .vectorFieldName(\"vector\")                 // Vector field name\n    .build();                                  // Build the MilvusEmbeddingStore instance\n```\n\n----------------------------------------\n\nTITLE: Using Quantized AllMiniLmL6V2 Embedding Model in Java\nDESCRIPTION: Java code example showing how to instantiate the quantized version of the AllMiniLmL6V2 embedding model and use it to generate an embedding for a text string.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel embeddingModel = new AllMiniLmL6V2QuantizedEmbeddingModel();\nResponse<Embedding> response = embeddingModel.embed(\"test\");\nEmbedding embedding = response.content();\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Chat Models in application.properties\nDESCRIPTION: Properties configuration for setting up multiple chat models (OpenAI and Ollama) in a Spring Boot application. This example shows how to configure different models with their respective settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_8\n\nLANGUAGE: properties\nCODE:\n```\n# OpenAI\nlangchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.chat-model.model-name=gpt-4o-mini\n\n# Ollama\nlangchain4j.ollama.chat-model.base-url=http://localhost:11434\nlangchain4j.ollama.chat-model.model-name=llama3.1\n```\n\n----------------------------------------\n\nTITLE: Ollama Chat Implementation with TestContainers\nDESCRIPTION: Example implementation of chat functionality using Ollama running in TestContainers. Includes container setup, model pulling, and chat interaction.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic class OllamaChatExample {\n  private static final Logger log = LoggerFactory.getLogger(OllamaChatExample.class);\n\n  static final String OLLAMA_IMAGE = \"ollama/ollama:latest\";\n  static final String TINY_DOLPHIN_MODEL = \"tinydolphin\";\n  static final String DOCKER_IMAGE_NAME = \"tc-ollama/ollama:latest-tinydolphin\";\n\n  public static void main(String[] args) {\n    // Create and start the Ollama container\n    DockerImageName dockerImageName = DockerImageName.parse(OLLAMA_IMAGE);\n    DockerClient dockerClient = DockerClientFactory.instance().client();\n    List<Image> images = dockerClient.listImagesCmd().withReferenceFilter(DOCKER_IMAGE_NAME).exec();\n    OllamaContainer ollama;\n    if (images.isEmpty()) {\n        ollama = new OllamaContainer(dockerImageName);\n    } else {\n        ollama = new OllamaContainer(DockerImageName.parse(DOCKER_IMAGE_NAME).asCompatibleSubstituteFor(OLLAMA_IMAGE));\n    }\n    ollama.start();\n\n    // Pull the model and create an image based on the selected model.\n    try {\n        log.info(\"Start pulling the '{}' model ... would take several minutes ...\", TINY_DOLPHIN_MODEL);\n        Container.ExecResult r = ollama.execInContainer(\"ollama\", \"pull\", TINY_DOLPHIN_MODEL);\n        log.info(\"Model pulling competed! {}\", r);\n    } catch (IOException | InterruptedException e) {\n        throw new RuntimeException(\"Error pulling model\", e);\n    }\n    ollama.commitToImage(DOCKER_IMAGE_NAME);\n\n    // Build the ChatModel\n    ChatModel model = OllamaChatModel.builder()\n            .baseUrl(ollama.getEndpoint())\n            .temperature(0.0)\n            .logRequests(true)\n            .logResponses(true)\n            .modelName(TINY_DOLPHIN_MODEL)\n            .build();\n\n    // Example usage\n    String answer = model.chat(\"Provide 3 short bullet points explaining why Java is awesome\");\n    System.out.println(answer);\n\n    // Stop the Ollama container\n    ollama.stop();\n  }\n```\n\n----------------------------------------\n\nTITLE: Initializing AzureOpenAiChatModel with API Key\nDESCRIPTION: Java code demonstrating how to create an instance of AzureOpenAiChatModel using an API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = AzureOpenAiChatModel.builder()\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .deploymentName(\"gpt-4o\")\n        ...\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Moderation Model Properties in LangChain4j\nDESCRIPTION: Optional configuration properties for OpenAI moderation model in LangChain4j. These properties allow customization of the API endpoint, headers, logging behavior, retry logic, organization/project identification, and timeout settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_12\n\nLANGUAGE: properties\nCODE:\n```\n# Optional properties:\nlangchain4j.open-ai.moderation-model.base-url=...\nlangchain4j.open-ai.moderation-model.custom-headers=...\nlangchain4j.open-ai.moderation-model.log-requests=...\nlangchain4j.open-ai.moderation-model.log-responses=...\nlangchain4j.open-ai.moderation-model.max-retries=...\nlangchain4j.open-ai.moderation-model.organization-id=...\nlangchain4j.open-ai.moderation-model.project-id=...\nlangchain4j.open-ai.moderation-model.timeout=...\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Chat Request with Kotlin Coroutines\nDESCRIPTION: This Kotlin extension function `chatAsync` for `ChatModel` enables asynchronous chat interactions using coroutines. It accepts a `ChatRequest` object and wraps the synchronous `chat` call within a coroutine dispatched on `Dispatchers.IO`, ensuring non-blocking execution. It returns a `ChatResponse` asynchronously. This method is marked experimental.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_7\n\nLANGUAGE: kotlin\nCODE:\n```\nsuspend fun ChatModel.chatAsync(request: ChatRequest): ChatResponse\n```\n\n----------------------------------------\n\nTITLE: Creating a Math Problem Solver with Gemini's Code Execution\nDESCRIPTION: Demonstrates how to use Gemini's Python code execution capability to solve a mathematical problem. The example shows a chat request with a system prompt that guides Gemini to use Python for solving math problems and a user question about Fibonacci and Ackermann functions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nChatResponse mathQuizz = gemini.chat(\n    SystemMessage.from(\"\"\"\n        You are an expert mathematician.\n        When asked a math problem or logic problem,\n        you can solve it by creating a Python program,\n        and execute it to return the result.\n        \"\"\"),\n    UserMessage.from(\"\"\"\n        Implement the Fibonacci and Ackermann functions.\n        What is the result of `fibonacci(22)` - ackermann(3, 4)?\n        \"\"\")\n);\n```\n\n----------------------------------------\n\nTITLE: Integrating Google Cloud Vertex AI Ranking with AiServices in Java\nDESCRIPTION: This Java code snippet shows how to integrate the VertexAiScoringModel with AiServices using a ContentAggregator and RetrievalAugmentor. It demonstrates the setup for using the scoring model in a more complex AI service configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/vertex-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nVertexAiScoringModel scoringModel = VertexAiScoringModel.builder()\n    .projectId(System.getenv(\"GCP_PROJECT_ID\"))\n    .projectNumber(System.getenv(\"GCP_PROJECT_NUM\"))\n    .projectLocation(System.getenv(\"GCP_LOCATION\"))\n    .model(\"semantic-ranker-512\")\n    .build();\n\nContentAggregator contentAggregator = ReRankingContentAggregator.builder()\n    .scoringModel(scoringModel)\n    ... \n    .build();\n\nRetrievalAugmentor retrievalAugmentor = DefaultRetrievalAugmentor.builder()\n    ...\n    .contentAggregator(contentAggregator)\n    .build();\n\nreturn AiServices.builder(Assistant.class)\n    .chatModel(...)\n    .retrievalAugmentor(retrievalAugmentor)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Defining JSON Schema using Builder in Java\nDESCRIPTION: Demonstrates establishing a JSON schema for response format within the OllamaChatModel. The builder pattern configures elements like 'name', 'capital', and an array of 'languages', mandating these properties in responses. Appropriate for APIs requiring structured data validation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"llama3.1\")\n    .responseFormat(ResponseFormat.builder()\n            .type(ResponseFormatType.JSON)\n            .jsonSchema(JsonSchema.builder().rootElement(JsonObjectSchema.builder()\n                            .addProperty(\"name\", JsonStringSchema.builder().build())\n                            .addProperty(\"capital\", JsonStringSchema.builder().build())\n                            .addProperty(\n                                    \"languages\",\n                                    JsonArraySchema.builder()\n                                            .items(JsonStringSchema.builder().build())\n                                            .build())\n                            .required(\"name\", \"capital\", \"languages\")\n                            .build())\n                    .build())\n            .build())\n    .temperature(0.8)\n    .timeout(Duration.ofSeconds(60))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Generating Article Outline with Java Assistant Interface\nDESCRIPTION: The interface 'Assistant' defines a method for generating an article outline based on a given topic. It utilizes Result wrapping to provide additional metadata like token usage and source content. The dependencies include Result class and related metadata classes.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\ninterface Assistant {\n    \n    @UserMessage(\"Generate an outline for the article on the following topic: {{it}}\")\n    Result<List<String>> generateOutlineFor(String topic);\n}\n\nResult<List<String>> result = assistant.generateOutlineFor(\"Java\");\n\nList<String> outline = result.content();\nTokenUsage tokenUsage = result.tokenUsage();\nList<Content> sources = result.sources();\nList<ToolExecution> toolExecutions = result.toolExecutions();\nFinishReason finishReason = result.finishReason();\n```\n\n----------------------------------------\n\nTITLE: Initializing Oracle Embedding Store with Existing Table\nDESCRIPTION: Creates an instance of Oracle Embedding Store using an existing embedding table in the database. Requires a DataSource and the name of the embedding table.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore = OracleEmbeddingStore.builder()\n   .dataSource(myDataSource)\n   .embeddingTable(\"my_embedding_table\")\n   .build();\n```\n\n----------------------------------------\n\nTITLE: Forcing GitHub Models Usage\nDESCRIPTION: This Java code shows how to explicitly force the usage of GitHub Models by using the isGitHubModels() method in the configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .apiKey(System.getenv(\"GITHUB_TOKEN\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .isGitHubModels(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Streaming Chat Model in Spring Boot Properties\nDESCRIPTION: Application properties configuration for OpenAI streaming chat model in Spring Boot, including mandatory and optional parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_9\n\nLANGUAGE: properties\nCODE:\n```\n# Mandatory properties:\nlangchain4j.open-ai.streaming-chat-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.streaming-chat-model.model-name=gpt-4o-mini\n\n# Optional properties:\nlangchain4j.open-ai.streaming-chat-model.base-url=...\nlangchain4j.open-ai.streaming-chat-model.custom-headers=...\nlangchain4j.open-ai.streaming-chat-model.frequency-penalty=...\nlangchain4j.open-ai.streaming-chat-model.log-requests=...\nlangchain4j.open-ai.streaming-chat-model.log-responses=...\nlangchain4j.open-ai.streaming-chat-model.logit-bias=...\nlangchain4j.open-ai.streaming-chat-model.max-retries=...\nlangchain4j.open-ai.streaming-chat-model.max-completion-tokens=...\nlangchain4j.open-ai.streaming-chat-model.max-tokens=...\nlangchain4j.open-ai.streaming-chat-model.metadata=...\nlangchain4j.open-ai.streaming-chat-model.organization-id=...\nlangchain4j.open-ai.streaming-chat-model.parallel-tool-calls=...\nlangchain4j.open-ai.streaming-chat-model.presence-penalty=...\nlangchain4j.open-ai.streaming-chat-model.project-id=...\nlangchain4j.open-ai.streaming-chat-model.reasoning-effort=...\nlangchain4j.open-ai.streaming-chat-model.response-format=...\nlangchain4j.open-ai.streaming-chat-model.seed=...\nlangchain4j.open-ai.streaming-chat-model.service-tier=...\nlangchain4j.open-ai.streaming-chat-model.stop=...\nlangchain4j.open-ai.streaming-chat-model.store=...\nlangchain4j.open-ai.streaming-chat-model.strict-schema=...\nlangchain4j.open-ai.streaming-chat-model.strict-tools=...\nlangchain4j.open-ai.streaming-chat-model.temperature=...\nlangchain4j.open-ai.streaming-chat-model.timeout=...\nlangchain4j.open-ai.streaming-chat-model.top-p=...\nlangchain4j.open-ai.streaming-chat-model.user=...\n```\n\n----------------------------------------\n\nTITLE: Configuring Oracle Embedding Store with Custom Table Settings\nDESCRIPTION: Creates an embedding store with custom table configuration using the EmbeddingTable builder. Allows customizing column names and table creation options.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore embeddingStore =\nOracleEmbeddingStore.builder()\n    .dataSource(myDataSource)\n    .embeddingTable(EmbeddingTable.builder()\n            .createOption(CREATE_OR_REPLACE) // use NONE if the table already exists\n            .name(\"my_embedding_table\")\n            .idColumn(\"id_column_name\")\n            .embeddingColumn(\"embedding_column_name\")\n            .textColumn(\"text_column_name\")\n            .metadataColumn(\"metadata_column_name\")\n            .build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Azure Credentials Integration\nDESCRIPTION: Java code showing how to create AzureOpenAiChatModel using Azure Credentials instead of API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = AzureOpenAiChatModel.builder()\n        .deploymentName(\"gpt-4o\")\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .tokenCredential(new DefaultAzureCredentialBuilder().build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing OracleEmbeddingStore with Table Creation Option - Java\nDESCRIPTION: This Java snippet sets up an EmbeddingStore, instructing the builder to create the embedding table if it does not already exist by passing CreateOption.CREATE_IF_NOT_EXISTS. It allows seamless integration where the database schema may need to be established at runtime. Requires a DataSource, table name, and the CreateOption enum.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore = OracleEmbeddingStore.builder()\\n   .dataSource(myDataSource)\\n   .embeddingTable(\"my_embedding_table\", CreateOption.CREATE_IF_NOT_EXISTS)\\n   .build();\n```\n\n----------------------------------------\n\nTITLE: Customizing AnthropicChatModel in Java\nDESCRIPTION: Java code snippet showing various customization options for AnthropicChatModel. It includes parameters for base URL, API key, version, model name, and various model-specific settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nAnthropicChatModel model = AnthropicChatModel.builder()\n    .baseUrl(...)\n    .apiKey(...)\n    .version(...)\n    .beta(...)\n    .modelName(...)\n    .temperature(...)\n    .topP(...)\n    .topK(...)\n    .maxTokens(...)\n    .stopSequences(...)\n    .cacheSystemMessages(...)\n    .cacheTools(...)\n    .thinkingType(...)\n    .thinkingBudgetTokens(...)\n    .timeout(...)\n    .maxRetries(...)\n    .logRequests(...)\n    .logResponses(...)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Response Format with Ollama and Other Providers in Java\nDESCRIPTION: Demonstrates JSON mode configuration for Ollama and adaptability for models lacking native support using prompt engineering.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_17\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel.builder()\n    ...\n    .responseFormat(JSON)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Scoring Text Segments with Google Cloud Vertex AI Ranking Model in Java\nDESCRIPTION: This Java code demonstrates how to configure and use the VertexAiScoringModel to score multiple text segments against a query. It includes setting up the model with project details and using the scoreAll method.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/vertex-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nVertexAiScoringModel scoringModel = VertexAiScoringModel.builder()\n    .projectId(System.getenv(\"GCP_PROJECT_ID\"))\n    .projectNumber(System.getenv(\"GCP_PROJECT_NUM\"))\n    .projectLocation(System.getenv(\"GCP_LOCATION\"))\n    .model(\"semantic-ranker-512\")\n    .build();\n\nResponse<List<Double>> score = scoringModel.scoreAll(Stream.of(\n        \"The sky appears blue due to a phenomenon called Rayleigh scattering. \" +\n            \"Sunlight is comprised of all the colors of the rainbow. Blue light has shorter \" +\n            \"wavelengths than other colors, and is thus scattered more easily.\",\n\n        \"A canvas stretched across the day,\\n\" +\n            \"Where sunlight learns to dance and play.\\n\" +\n            \"Blue, a hue of scattered light,\\n\" +\n            \"A gentle whisper, soft and bright.\"\n        ).map(TextSegment::from).collect(Collectors.toList()),\n    \"Why is the sky blue?\");\n\n// [0.8199999928474426, 0.4300000071525574]\n```\n\n----------------------------------------\n\nTITLE: Using OllamaChatModel with JSON Response Format in Java\nDESCRIPTION: Illustrates initializing OllamaChatModel with JSON response format in Java. The snippet involves specifying 'responseFormat' and other configuration parameters. The inclusion of 'ResponseFormat.JSON' indicates the desired output format. This setup is essential for applications requiring JSON-structured outputs.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"llama3.1\")\n    .responseFormat(ResponseFormat.JSON)    \n    .temperature(0.8)\n    .timeout(Duration.ofSeconds(60))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Using ChatRequest with GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code showing how to use the ChatRequest object with GoogleAiGeminiChatModel for more detailed chat interactions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    .build();\n\nChatResponse chatResponse = gemini.chat(ChatRequest.builder()\n    .messages(UserMessage.from(\n        \"How many R's are there in the word 'strawberry'?\"))\n    .build());\n\nString response = chatResponse.aiMessage().text();\n```\n\n----------------------------------------\n\nTITLE: Initializing Elasticsearch RestClient with API Key\nDESCRIPTION: Configuration for creating an Elasticsearch RestClient instance with API key authentication\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/elasticsearch.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nString apiKey = \"VnVhQ2ZHY0JDZGJrU...\";\nRestClient restClient = RestClient\n    .builder(HttpHost.create(\"https://localhost:9200\"))\n    .setDefaultHeaders(new Header[]{\n        new BasicHeader(\"Authorization\", \"ApiKey \" + apiKey)\n    })\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Persisting InMemoryEmbeddingStore Data\nDESCRIPTION: Example showing how to serialize and deserialize InMemoryEmbeddingStore to/from JSON string and file. Demonstrates both in-memory persistence and file-based storage options.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/1-in-memory.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nInMemoryEmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();\nembeddingStore.addAll(embeddings, embedded);\n\nString serializedStore = embeddingStore.serializeToJson();\nInMemoryEmbeddingStore<TextSegment> deserializedStore = InMemoryEmbeddingStore.fromJson(serializedStore);\n\nString filePath = \"/home/me/store.json\";\nembeddingStore.serializeToFile(filePath);\nInMemoryEmbeddingStore<TextSegment> deserializedStore = InMemoryEmbeddingStore.fromFile(filePath);\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Memory with QianfanChatModel\nDESCRIPTION: Implementation example showing how to use message window chat memory with QianfanChatModel for maintaining conversation context.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nQianfanChatModel model = QianfanChatModel.builder()\n          .apiKey(\"apiKey\")\n          .secretKey(\"secretKey\")\n          .modelName(\"Yi-34B-Chat\")\n          .build();\n\nChatMemory chatMemory = MessageWindowChatMemory.builder()\n          .maxMessages(10)\n          .build();\n\nIAiService assistant = AiServices.builder(IAiService.class)\n          .chatModel(model)\n          .chatMemory(chatMemory)\n          .build();\n```\n\n----------------------------------------\n\nTITLE: Person Assistant Implementation Example\nDESCRIPTION: Example showing how to use the PersonAssistant interface with structured outputs.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nString question = \"Julien likes the colors blue, white and red\";\n\nPersonAssistant assistant = AiServices.builder(PersonAssistant.class)\n                .chatModel(chatModel)\n                .build();\n\nPerson person = assistant.extractPerson(question);\n```\n\n----------------------------------------\n\nTITLE: Local Ollama Chat Implementation\nDESCRIPTION: Example of chat functionality using locally running Ollama instance. Demonstrates both regular and JSON response format chat interactions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nclass OllamaChatLocalModelTest {\n  static String MODEL_NAME = \"llama3.2\"; // try other local ollama model names\n  static String BASE_URL = \"http://localhost:11434\"; // local ollama base url\n\n  public static void main(String[] args) {\n      ChatModel model = OllamaChatModel.builder()\n              .baseUrl(BASE_URL)\n              .modelName(MODEL_NAME)\n              .build();\n      String answer = model.chat(\"List top 10 cites in China\");\n      System.out.println(answer);\n\n      model = OllamaChatModel.builder()\n              .baseUrl(BASE_URL)\n              .modelName(MODEL_NAME)\n              .responseFormat(JSON)\n              .build();\n\n      String json = model.chat(\"List top 10 cites in US\");\n      System.out.println(json);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHubModelsStreamingChatModel in Spring Boot\nDESCRIPTION: Spring Boot configuration class for creating a GitHubModelsStreamingChatModel bean with streaming capabilities.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\npackage com.example.demo.configuration.github;\n\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.github.GitHubModelsChatModel;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.Profile;\n\n@Configuration\n@Profile(\"github\")\npublic class GitHubModelsStreamingChatModelConfiguration {\n\n    @Value(\"${GITHUB_TOKEN}\")\n    private String gitHubToken;\n\n    @Bean\n    GitHubModelsStreamingChatModel gitHubModelsStreamingChatModel() {\n        return GitHubModelsStreamingChatModel.builder()\n                .gitHubToken(System.getenv(\"GITHUB_TOKEN\"))\n                .modelName(\"gpt-4o-mini\")\n                .logRequestsAndResponses(true)\n                .build();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Chat Responses\nDESCRIPTION: Example of implementing streaming responses with QianfanStreamingChatModel using StreamingChatResponseHandler.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nQianfanStreamingChatModel qianfanStreamingChatModel = QianfanStreamingChatModel.builder()\n          .apiKey(\"apiKey\")\n          .secretKey(\"secretKey\")\n          .modelName(\"Yi-34B-Chat\")\n          .build();\n\nqianfanStreamingChatModel.chat(userMessage, new StreamingChatResponseHandler() {\n        @Override\n        public void onPartialResponse(String partialResponse) {\n            System.out.print(partialResponse);\n        }\n        @Override\n        public void onCompleteResponse(ChatResponse completeResponse) {\n            System.out.println(\"onCompleteResponse: \" + completeResponse);\n        }\n        @Override\n        public void onError(Throwable throwable) {\n            throwable.printStackTrace();\n        }\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code demonstrating how to initialize and use the GoogleAiGeminiChatModel for basic chat functionality.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n    .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n    .modelName(\"gemini-1.5-flash\")\n    ...\n    .build();\n\nString response = gemini.chat(\"Hello Gemini!\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Embedding Model with Official SDK\nDESCRIPTION: Java code for setting up an Azure OpenAI embedding model using the Official SDK integration. The isAzure flag is set to true to specify the Azure service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai-official.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel model = OpenAiOfficialEmbeddingModel.builder()\n        .baseUrl(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .modelName(EmbeddingModel.TEXT_EMBEDDING_3_SMALL)\n        .isAzure(true) // Not necessary if the base URL ends with `openai.azure.com`\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing AnthropicChatModel in Java\nDESCRIPTION: Java code for setting up and using AnthropicChatModel. It demonstrates how to create an instance of the model, send a chat message, and print the response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nAnthropicChatModel model = AnthropicChatModel.builder()\n    .apiKey(System.getenv(\"ANTHROPIC_API_KEY\"))\n    .modelName(CLAUDE_3_5_SONNET_20240620)\n    .build();\nString answer = model.chat(\"Say 'Hello World'\");\nSystem.out.println(answer);\n```\n\n----------------------------------------\n\nTITLE: Embedding Stores Comparison Table in Markdown\nDESCRIPTION: Markdown table comparing features of different embedding stores including metadata storage, filtering, and removal capabilities. Shows support status for 28 different embedding store implementations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/index.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Embedding Store                                                                       | Storing Metadata | Filtering by Metadata      | Removing Embeddings |\n|---------------------------------------------------------------------------------------|------------------|----------------------------|---------------------|\n| [In-memory](/integrations/embedding-stores/in-memory)                                 | ✅                | ✅                          | ✅                   |\n| [AlloyDB for Postgres](/integrations/embedding-stores/alloydb)                                     | ✅               | ✅                         | ✅                  |\n| [Astra DB](/integrations/embedding-stores/astra-db)                                   | ✅                |                            |                     |\n| [Azure AI Search](/integrations/embedding-stores/azure-ai-search)                     | ✅                | ✅                          | ✅                   |\n| [Azure CosmosDB Mongo vCore](/integrations/embedding-stores/azure-cosmos-mongo-vcore) | ✅                |                            |                     |\n| [Azure CosmosDB NoSQL](/integrations/embedding-stores/azure-cosmos-nosql)             | ✅                |                            |                     |\n| [Cassandra](/integrations/embedding-stores/cassandra)                                 | ✅                |                            |                     |\n| [Chroma](/integrations/embedding-stores/chroma)                                       | ✅                | ✅                          | ✅                   |\n| [ClickHouse](/integrations/embedding-stores/clickhouse)                               | ✅                | ✅                          | ✅                   |\n| [Cloud SQL for Postgres](/integrations/embedding-stores/cloud-sql)                    | ✅                | ✅                          | ✅                   |\n| [Coherence](/integrations/embedding-stores/coherence)                                 | ✅                | ✅                          | ✅                   |\n| [Couchbase](/integrations/embedding-stores/couchbase)                                 | ✅                |                            | ✅                   |\n| [DuckDB](/integrations/embedding-stores/duckdb)                                       | ✅                | ✅                          | ✅                   |\n| [Elasticsearch](/integrations/embedding-stores/elasticsearch)                         | ✅                | ✅                          | ✅                   |\n| [Infinispan](/integrations/embedding-stores/infinispan)                               | ✅                |                            |                     |\n| [Milvus](/integrations/embedding-stores/milvus)                                       | ✅                | ✅                          | ✅                   |\n| [MongoDB Atlas](/integrations/embedding-stores/mongodb-atlas)                         | ✅                | ✅                          | ✅                   |\n| [Neo4j](/integrations/embedding-stores/neo4j)                                         | ✅                |                            |                     |\n| [OpenSearch](/integrations/embedding-stores/opensearch)                               | ✅                |                            |                     |\n| [Oracle](/integrations/embedding-stores/oracle)                                       | ✅                | ✅                          | ✅                   |\n| [PGVector](/integrations/embedding-stores/pgvector)                                   | ✅                | ✅                          | ✅                   |\n| [Pinecone](/integrations/embedding-stores/pinecone)                                   | ✅                | ✅                          | ✅                   |\n| [Qdrant](/integrations/embedding-stores/qdrant)                                       | ✅                | ✅                          | ✅                   |\n| [Redis](/integrations/embedding-stores/redis)                                         | ✅                |                            |                     |\n| [Tablestore](/integrations/embedding-stores/tablestore)                               | ✅                | ✅                          | ✅                   |\n| [Vearch](/integrations/embedding-stores/vearch)                                       | ✅                |                            |                     |\n| [Vespa](/integrations/embedding-stores/vespa)                                         |                  |                            |                     |\n| [Weaviate](/integrations/embedding-stores/weaviate)                                   | ✅               |                            | ✅                  |\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Chat Model with LangChain4j in Java\nDESCRIPTION: This snippet shows how to initialize the OpenAI Chat Model using LangChain4j's `OpenAiChatModel` class. It requires a valid OpenAI API key to be passed to the `withApiKey` method. This `chatModel` instance is then used by AI services to interact with the OpenAI API.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nstatic ChatModel chatModel = OpenAiChatModel.withApiKey(\"YOUR_OPENAI_API_KEY\");\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key in Java\nDESCRIPTION: Code snippet showing how to securely retrieve the OpenAI API key from environment variables.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nString apiKey = System.getenv(\"OPENAI_API_KEY\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Anthropic Thinking Feature in Java\nDESCRIPTION: Java code snippet showing how to enable and configure the thinking feature for AnthropicChatModel. It demonstrates setting the thinking type, budget tokens, and other related parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = AnthropicChatModel.builder()\n        .apiKey(System.getenv(\"ANTHROPIC_API_KEY\"))\n        .modelName(CLAUDE_3_7_SONNET_20250219)\n        .thinkingType(\"enabled\")\n        .thinkingBudgetTokens(1024)\n        .maxTokens(1024 + 100)\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Implementation with TestContainers\nDESCRIPTION: Implementation of streaming chat functionality using Ollama in TestContainers. Includes container setup and streaming response handling.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npublic class OllamaStreamingChatExample {\n  private static final Logger log = LoggerFactory.getLogger(OllamaStreamingChatExample.class);\n\n  static final String OLLAMA_IMAGE = \"ollama/ollama:latest\";\n  static final String TINY_DOLPHIN_MODEL = \"tinydolphin\";\n  static final String DOCKER_IMAGE_NAME = \"tc-ollama/ollama:latest-tinydolphin\";\n\n  public static void main(String[] args) {\n    // ... Container setup code ...\n\n    StreamingChatModel model = OllamaStreamingChatModel.builder()\n            .baseUrl(ollama.getEndpoint())\n            .temperature(0.0)\n            .logRequests(true)\n            .logResponses(true)\n            .modelName(TINY_DOLPHIN_MODEL)\n            .build();\n\n    String userMessage = \"Write a 100-word poem about Java and AI\";\n\n    CompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();\n    model.chat(userMessage, new StreamingChatResponseHandler() {\n\n        @Override\n        public void onPartialResponse(String partialResponse) {\n            System.out.print(partialResponse);\n        }\n\n        @Override\n        public void onCompleteResponse(ChatResponse completeResponse) {\n            futureResponse.complete(completeResponse);\n        }\n\n        @Override\n        public void onError(Throwable error) {\n            futureResponse.completeExceptionally(error);\n        }\n    });\n\n    futureResponse.join();\n    ollama.stop();\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAiChatModel with Demo Key\nDESCRIPTION: Java code to create an OpenAiChatModel instance using a demo API key for demonstration purposes.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel model = OpenAiChatModel.builder()\n    .baseUrl(\"http://langchain4j.dev/demo/openai/v1\")\n    .apiKey(\"demo\")\n    .modelName(\"gpt-4o-mini\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using GPU-based ONNX Scoring Model in Java\nDESCRIPTION: Java code to initialize an ONNX scoring model using GPU (CUDA) and perform scoring on a query-passage pair.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/in-process.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nString pathToModel = \"/home/langchain4j/model.onnx\";\nString pathToTokenizer = \"/home/langchain4j/tokenizer.json\";\n\nOrtSession.SessionOptions options = new OrtSession.SessionOptions();\noptions.addCUDA(0);\nOnnxScoringModel scoringModel = new OnnxScoringModel(pathToModel, options, pathToTokenizer);\n\nResponse<Double> response = scoringModel.score(\"query\", \"passage\");\nDouble score = response.content();\n```\n\n----------------------------------------\n\nTITLE: Initializing CouchbaseEmbeddingStore with Local Couchbase Server\nDESCRIPTION: Creates a CouchbaseEmbeddingStore instance that connects to a locally running Couchbase server. This configuration specifies connection details including credentials, bucket, scope, collection, and vector dimensions.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nCouchbaseEmbeddingStore embeddingStore = CouchbaseEmbeddingStore.builder()\n        .clusterUrl(\"localhost:8091\")\n        .username(\"Administrator\")\n        .password(\"password\")\n        .bucketName(\"langchain4j\")\n        .scopeName(\"_default\")\n        .collectionName(\"_default\")\n        .searchIndexName(\"test\")\n        .dimensions(512)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Defining AI Service with Flux Support for Streaming\nDESCRIPTION: Java code demonstrating how to define an AI Service interface with Flux support for streaming responses. This example shows a chat method returning a Flux of String.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\n@AiService\ninterface Assistant {\n\n    @SystemMessage(\"You are a polite assistant\")\n    Flux<String> chat(String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Tool Programmatically using ToolSpecification in Java\nDESCRIPTION: Illustrates how to define a tool's metadata programmatically using the `ToolSpecification.builder()`. This allows specifying the tool's name, description, and parameters (including their types and descriptions) without relying solely on annotations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nToolSpecification toolSpecification = ToolSpecification.builder()\n        .name(\"get_booking_details\")\n        .description(\"Returns booking details\")\n        .parameters(JsonObjectSchema.builder()\n                .properties(Map.of(\n                        \"bookingNumber\", JsonStringSchema.builder()\n                                .description(\"Booking number in B-12345 format\")\n                                .build()\n                ))\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating API Key Class in Java\nDESCRIPTION: Java code for creating an ApiKeys class to store the MistralAI API key as an environment variable.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic class ApiKeys {\n    public static final String MISTRALAI_API_KEY = System.getenv(\"MISTRAL_AI_API_KEY\");\n}\n```\n\n----------------------------------------\n\nTITLE: Defining PaymentTransactionTool Class in Java\nDESCRIPTION: This Java class, PaymentTransactionTool, represents a tool for managing payment transactions. It initializes hardcoded payment data into a Map structure. Required dependencies include Java's standard utilities. The key parameters are transaction_id and payment data fields, and the expected output includes specific transaction details such as status and date, based on transaction ID lookup.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nimport java.util.*;\n\npublic class PaymentTransactionTool {\n\n   private final Map<String, List<String>> paymentData = Map.of(\n            \"transaction_id\", List.of(\"T1001\", \"T1002\", \"T1003\", \"T1004\", \"T1005\"),\n            \"customer_id\", List.of(\"C001\", \"C002\", \"C003\", \"C002\", \"C001\"),\n            \"payment_amount\", List.of(\"125.50\", \"89.99\", \"120.00\", \"54.30\", \"210.20\"),\n            \"payment_date\", List.of(\"2021-10-05\", \"2021-10-06\", \"2021-10-07\", \"2021-10-05\", \"2021-10-08\"),\n            \"payment_status\", List.of(\"Paid\", \"Unpaid\", \"Paid\", \"Paid\", \"Pending\"));\n   \n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Embedding Model in Spring Boot\nDESCRIPTION: Properties configuration for OpenAI embedding model in a Spring Boot application. It includes mandatory and optional properties for customizing the model's behavior.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\n# Mandatory properties:\nlangchain4j.open-ai.embedding-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.embedding-model.model-name=text-embedding-3-small\n\n# Optional properties:\nlangchain4j.open-ai.embedding-model.base-url=...\nlangchain4j.open-ai.embedding-model.custom-headers=...\nlangchain4j.open-ai.embedding-model.dimensions=...\nlangchain4j.open-ai.embedding-model.log-requests=...\nlangchain4j.open-ai.embedding-model.log-responses=...\nlangchain4j.open-ai.embedding-model.max-retries=...\nlangchain4j.open-ai.embedding-model.organization-id=...\nlangchain4j.open-ai.embedding-model.project-id=...\nlangchain4j.open-ai.embedding-model.timeout=...\nlangchain4j.open-ai.embedding-model.user=...\n```\n\n----------------------------------------\n\nTITLE: Instantiating ChatGlmChatModel in Java\nDESCRIPTION: Java code to create an instance of ChatGlmChatModel with custom configuration including base URL and logging options.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/chatglm.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = ChatGlmChatModel.builder()\n        .baseUrl(System.getenv(\"CHATGLM_BASE_URL\"))\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Bedrock Cohere Embedding Model\nDESCRIPTION: Example of configuring a Bedrock Cohere embedding model with specific parameters including region, model type, input type, and truncation settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/amazon-bedrock.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nBedrockCohereEmbeddingModel embeddingModel = BedrockCohereEmbeddingModel\n        .builder()\n        .region(Region.US_EAST_1)\n        .model(\"cohere.embed-multilingual-v3\")\n        .inputType(BedrockCohereEmbeddingModel.InputType.SEARCH_QUERY)\n        .truncation(BedrockCohereEmbeddingModel.Truncate.NONE)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Generic OpenAI Embedding Model with Official SDK\nDESCRIPTION: Java code for setting up a generic OpenAI embedding model using the Official SDK integration. This configuration uses environment variables for the API endpoint and key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai-official.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nimport com.openai.models.embeddings.EmbeddingModel;\nimport dev.langchain4j.model.embedding.EmbeddingModel;\nimport dev.langchain4j.model.openaiofficial.OpenAiOfficialEmbeddingModel;\n\n// ....\n\nEmbeddingModel model = OpenAiOfficialEmbeddingModel.builder()\n        .baseUrl(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .modelName(EmbeddingModel.TEXT_EMBEDDING_3_SMALL)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Generating Images with WanxImageModel in Java\nDESCRIPTION: Example of using WanxImageModel to generate images from text prompts using the DashScope API.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nWanxImageModel wanxImageModel = WanxImageModel.builder()\n                    .modelName(\"wanx2.1-t2i-plus\") \n                    .apiKey(\"阿里云百炼apikey\")     \n                    .build();\nResponse<Image> response = wanxImageModel.generate(\"美女\");\nSystem.out.println(response.content().url());\n```\n\n----------------------------------------\n\nTITLE: Interface Method Declarations for Structured Output in Java\nDESCRIPTION: Example interface showing various method declarations for extracting structured data from text, including person details, sentiments, and generating outlines. Demonstrates different return types supported by the system.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_12\n\nLANGUAGE: java\nCODE:\n```\nrecord Person(String firstName, String lastName) {}\n\nenum Sentiment {\n    POSITIVE, NEGATIVE, NEUTRAL\n}\n\ninterface Assistant {\n\n    Person extractPersonFrom(String text);\n\n    Set<Person> extractPeopleFrom(String text);\n\n    Sentiment extractSentimentFrom(String text);\n\n    List<Sentiment> extractSentimentsFrom(String text);\n\n    List<String> generateOutline(String topic);\n\n    boolean isSentimentPositive(String text);\n\n    Integer extractNumberOfPeopleMentionedIn(String text);\n}\n```\n\n----------------------------------------\n\nTITLE: Using ChatModel in a Spring RestController\nDESCRIPTION: Java code demonstrating how to autowire and use a ChatModel in a Spring RestController. This example shows a simple chat endpoint that uses the configured chat model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n@RestController\npublic class ChatController {\n\n    ChatModel chatModel;\n\n    public ChatController(ChatModel chatModel) {\n        this.chatModel = chatModel;\n    }\n\n    @GetMapping(\"/chat\")\n    public String model(@RequestParam(value = \"message\", defaultValue = \"Hello\") String message) {\n        return chatModel.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing GitHub Models Embedding Model\nDESCRIPTION: Java code to create an instance of GitHubModelsEmbeddingModel using a GitHub token and model configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/github-models.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nGitHubModelsEmbeddingModel model = GitHubModelsEmbeddingModel.builder()\n        .gitHubToken(System.getenv(\"GITHUB_TOKEN\"))\n        .modelName(TEXT_EMBEDDING_3_SMALL)\n        .logRequestsAndResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Spring Boot Starter Dependency in Maven\nDESCRIPTION: XML configuration for adding the LangChain4j OpenAI Spring Boot starter dependency to a Maven project. This dependency enables easy integration of OpenAI models with Spring Boot applications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Initializing and Using CPU-based ONNX Scoring Model in Java\nDESCRIPTION: Java code to initialize an ONNX scoring model using CPU and perform scoring on a query-passage pair.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/in-process.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nString pathToModel = \"/home/langchain4j/model.onnx\";\nString pathToTokenizer = \"/home/langchain4j/tokenizer.json\";\nOnnxScoringModel scoringModel = new OnnxScoringModel(pathToModel, pathToTokenizer);\n\nResponse<Double> response = scoringModel.score(\"query\", \"passage\");\nDouble score = response.content();\n```\n\n----------------------------------------\n\nTITLE: Enabling Structured Outputs for Response Format\nDESCRIPTION: This Java code shows how to enable the Structured Outputs feature for response formatting when using AI Services with an OpenAI chat model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nimport static dev.langchain4j.model.chat.Capability.RESPONSE_FORMAT_JSON_SCHEMA;\n\n// ...\n\nOpenAiChatModel.builder()\n        // ...\n        .supportedCapabilities(Set.of(RESPONSE_FORMAT_JSON_SCHEMA))\n        .strictJsonSchema(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring QwenChatModel in Spring Boot Properties\nDESCRIPTION: Spring Boot configuration properties for setting up QwenChatModel using langchain4j-community-dashscope-spring-boot-starter.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_8\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.community.dashscope.api-key=<You API Key here>\nlangchain4j.community.dashscope.model-name=qwen-max\n# The properties are the same as `QwenChatModel`\n# e.g.\n# langchain4j.community.dashscope.temperature=0.7\n# langchain4j.community.dashscope.max-tokens=4096\n```\n\n----------------------------------------\n\nTITLE: Generating Images Using Configured Model\nDESCRIPTION: Java code showing how to use the configured image model to generate images with a text prompt and retrieve the resulting image URL.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/open-ai-official.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nString imageUrl = imageModel\n        .generate(\"A coffee mug in Paris, France\")\n        .content()\n        .url()\n        .toString();\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Image Model\nDESCRIPTION: Java code showing the configuration for Azure OpenAI image model integration using Azure-specific endpoints and authentication.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/open-ai-official.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nImageModel model = OpenAiOfficialImageModel.builder()\n        .baseUrl(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .modelName(ImageModel.DALL_E_3)\n        .isAzure(true) // Not necessary if the base URL ends with `openai.azure.com`\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Defining ChatModel Interface in Java\nDESCRIPTION: Basic interface definition showing the simplest chat method that takes a String input and returns a String output.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\npublic interface ChatModel {\n\n    String chat(String userMessage);\n    \n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Synchronous Chat Completion with Jlama in Java\nDESCRIPTION: Java code demonstrating how to create a synchronous chat model using Jlama and LangChain4j. It initializes the model with a specific pre-trained model and generates a response to a simple prompt.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/jlama.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.jlama.JlamaChatModel;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        ChatModel model = JlamaChatModel.builder()\n                .modelName(\"tjake/TinyLlama-1.1B-Chat-v1.0-Jlama-Q4\")\n                .build();\n\n        String response = model.chat(\"Say 'Hello World'\");\n        System.out.println(response);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Chat Model in application.properties\nDESCRIPTION: Properties configuration for setting up an OpenAI chat model in a Spring Boot application. It includes API key, model name, and logging settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.chat-model.model-name=gpt-4o\nlangchain4j.open-ai.chat-model.log-requests=true\nlangchain4j.open-ai.chat-model.log-responses=true\n...\n```\n\n----------------------------------------\n\nTITLE: Configuring MistralAiChatModel for JSON Response in Java\nDESCRIPTION: The snippet shows the configuration of a MistralAiChatModel to return responses in JSON format by setting the responseFormat parameter. Dependencies include the LangChain4j package for chat model integration. Users need to supply API keys for setup, and the expected output is a JSON formatted string containing user query results.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = MistralAiChatModel.builder()\n                .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\")) // Please use your own Mistral AI API key\n                .responseFormat(ResponseFormat.JSON)\n                .build();\n\nString userMessage = \"Return JSON with two fields: transactionId and status with the values T123 and paid.\";\nString json = model.chat(userMessage);\n\nSystem.out.println(json); // {\"transactionId\":\"T123\",\"status\":\"paid\"}\n```\n\n----------------------------------------\n\nTITLE: Example Output from Jlama Embedding Model\nDESCRIPTION: The expected output when running the Jlama embedding example code. Shows the question text and the retrieved most similar text segment response.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/jlama.md#2025-04-22_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\nQuestion: What is your favourite sport?\nResponse: I like football.\n```\n\n----------------------------------------\n\nTITLE: Defining High-Level Tools in Java\nDESCRIPTION: Shows how to define high-level tools using @Tool annotations on Java methods, which can be used with AI Services for automatic handling of tool execution.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\n@Tool(\"Searches Google for relevant URLs, given the query\")\npublic List<String> searchGoogle(@P(\"search query\") String query) {\n    return googleSearchService.search(query);\n}\n\n@Tool(\"Returns the content of a web page, given the URL\")\npublic String getWebPageContent(@P(\"URL of the page\") String url) {\n    Document jsoupDocument = Jsoup.connect(url).get();\n    return jsoupDocument.body().text();\n}\n```\n\n----------------------------------------\n\nTITLE: Creating VearchEmbeddingStore for 1.0.0-alpha1 and Previous\nDESCRIPTION: Java code for instantiating a VearchEmbeddingStore using the configured VearchConfig object for versions 1.0.0-alpha1 and previous. This connects to a Vearch server using the provided base URL.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nVearchEmbeddingStore embeddingStore = VearchEmbeddingStore.builder()\n        .vearchConfig(vearchConfig)\n        .baseUrl(baseUrl)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating GitHubModelsChatModel in Plain Java\nDESCRIPTION: Java code to initialize a GitHubModelsChatModel instance using a builder pattern with GitHub token and model configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nGitHubModelsChatModel model = GitHubModelsChatModel.builder()\n        .gitHubToken(System.getenv(\"GITHUB_TOKEN\"))\n        .modelName(\"gpt-4o-mini\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Loading a Single File from GCS\nDESCRIPTION: Loads a single document from a specified file in a Google Cloud Storage bucket. This method requires the bucket name, file name, and a document parser.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nGoogleCloudStorageDocumentLoader gcsLoader = GoogleCloudStorageDocumentLoader.builder()\n    .project(System.getenv(\"GCP_PROJECT_ID\"))\n    .build();\n\nDocument document = gcsLoader.loadDocument(\"BUCKET_NAME\", \"FILE_NAME.txt\", new TextDocumentParser());\n```\n\n----------------------------------------\n\nTITLE: Using Custom ONNX Embedding Model in Java\nDESCRIPTION: Java code example showing how to instantiate and use a custom ONNX embedding model by providing paths to the model file and tokenizer, along with the desired pooling mode. This enables using any custom model in ONNX format.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nString pathToModel = \"/home/langchain4j/model.onnx\";\nString pathToTokenizer = \"/home/langchain4j/tokenizer.json\";\nPoolingMode poolingMode = PoolingMode.MEAN;\nEmbeddingModel embeddingModel = new OnnxEmbeddingModel(pathToModel, pathToTokenizer, poolingMode);\n\nResponse<Embedding> response = embeddingModel.embed(\"test\");\nEmbedding embedding = response.content();\n```\n\n----------------------------------------\n\nTITLE: ChatModel Request-Based Method in Java\nDESCRIPTION: Method signature for customized chat requests using ChatRequest object.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\n    ...\n    \n    ChatResponse chat(ChatRequest chatRequest);\n        \n    ...\n```\n\n----------------------------------------\n\nTITLE: Initializing OllamaChatModel with Parameters in Java\nDESCRIPTION: Demonstrates how to initialize the OllamaChatModel with basic parameters using Java. Required dependencies include 'java.time.Duration' for the timeout feature. Parameters like 'baseUrl', 'modelName', and 'temperature' are used to configure the chat model. The generated instance can be used for executing chat requests.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"llama3.1\")\n    .temperature(0.8)\n    .timeout(Duration.ofSeconds(60))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Advanced ChatModel Usage with Custom Parameters\nDESCRIPTION: Kotlin code showing how to use custom ChatRequestParameters with the chat model, demonstrating advanced configuration options.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/kotlin.md#2025-04-22_snippet_2\n\nLANGUAGE: kotlin\nCODE:\n```\nmodel.chat {\n    messages += systemMessage(\"You are a helpful assistant\")\n    messages += userMessage(\"Hello!\")\n    parameters(OpenAiChatRequestParameters.builder()) {\n        temperature = 0.7 // DefaultChatRequestParameters.Builder property\n        builder.seed(42) // OpenAiChatRequestParameters.Builder property\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Using Custom Response Format in Chat Request with GoogleAiGeminiChatModel in Java\nDESCRIPTION: Java code showing how to use a custom response format in a chat request with GoogleAiGeminiChatModel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nChatModel gemini = GoogleAiGeminiChatModel.builder()\n        .apiKey(System.getenv(\"GEMINI_AI_KEY\"))\n        .modelName(\"gemini-1.5-flash\")\n        .build();\n\nResponseFormat responseFormat = ...;\n\nChatRequest chatRequest = ChatRequest.builder()\n        .messages(UserMessage.from(\"Suggest a dessert recipe with strawberries\"))\n        .responseFormat(responseFormat)\n        .build();\n\nChatResponse chatResponse = gemini.chat(chatRequest);\n\nSystem.out.println(chatResponse.aiMessage().text());\n```\n\n----------------------------------------\n\nTITLE: Listing Docker Images\nDESCRIPTION: The snippet lists all available Docker images. This is used to verify the successful build of the local MCP server Docker image.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\ndocker image ls\n\nREPOSITORY   TAG         IMAGE ID        SIZE\nmcp/github   latest      b141704170b1    173MB\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Core with Maven\nDESCRIPTION: Maven dependency configuration for adding LangChain4j core library for AI Services API.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Dependencies with Gradle\nDESCRIPTION: Gradle dependency configuration for adding both LangChain4j OpenAI integration and core library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-open-ai:1.0.0-beta3'\nimplementation 'dev.langchain4j:langchain4j:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Initializing AzureOpenAiEmbeddingModel in Plain Java\nDESCRIPTION: Code example showing how to create an instance of AzureOpenAiEmbeddingModel in a plain Java application. The builder pattern is used to configure the model with API key, deployment name, and endpoint.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/azure-open-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel model = AzureOpenAiEmbeddingModel.builder()\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .deploymentName(\"text-embedding-3-small\")\n        .endpoint(\"https://langchain4j.openai.azure.com/\")\n        ...\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Forcing Azure OpenAI Usage\nDESCRIPTION: This Java code shows how to explicitly force the usage of Azure OpenAI by using the isAzure() method in the configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .baseUrl(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .isAzure(true)\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI in Spring Boot Properties\nDESCRIPTION: Spring Boot application.properties configuration for Azure OpenAI embedding model. Includes settings for endpoint, API key, deployment name, timeout, and other parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/azure-open-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.azure-open-ai.embedding-model.endpoint=https://langchain4j.openai.azure.com/\nlangchain4j.azure-open-ai.embedding-model.service-version=...\nlangchain4j.azure-open-ai.embedding-model.api-key=${AZURE_OPENAI_KEY}\nlangchain4j.azure-open-ai.embedding-model.deployment-name=text-embedding-3-small\nlangchain4j.azure-open-ai.embedding-model.timeout=...\nlangchain4j.azure-open-ai.embedding-model.max-retries=...\nlangchain4j.azure-open-ai.embedding-model.log-requests-and-responses=...\nlangchain4j.azure-open-ai.embedding-model.user-agent-suffix=...\nlangchain4j.azure-open-ai.embedding-model.dimensions=...\nlangchain4j.azure-open-ai.embedding-model.customHeaders=...\n```\n\n----------------------------------------\n\nTITLE: Building ChatRequest with Parameters in Java\nDESCRIPTION: Example showing how to construct a ChatRequest object with various parameters like model name, temperature, and tool specifications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatRequest chatRequest = ChatRequest.builder()\n    .messages(...)\n    .modelName(...)\n    .temperature(...)\n    .topP(...)\n    .topK(...)\n    .frequencyPenalty(...)\n    .presencePenalty(...)\n    .maxOutputTokens(...)\n    .stopSequences(...)\n    .toolSpecifications(...)\n    .toolChoice(...)\n    .responseFormat(...)\n    .parameters(...) // you can also set common or provider-specific parameters all at once\n    .build();\n\nChatResponse chatResponse = chatModel.chat(chatRequest);\n```\n\n----------------------------------------\n\nTITLE: Local Ollama Streaming Chat Implementation\nDESCRIPTION: Example of streaming chat functionality using locally running Ollama instance with streaming response handling.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nclass OllamaStreamingChatLocalModelTest {\n  static String MODEL_NAME = \"llama3.2\"; // try other local ollama model names\n  static String BASE_URL = \"http://localhost:11434\"; // local ollama base url\n\n  public static void main(String[] args) {\n      StreamingChatModel model = OllamaStreamingChatModel.builder()\n              .baseUrl(BASE_URL)\n              .modelName(MODEL_NAME)\n              .temperature(0.0)\n              .build();\n      String userMessage = \"Write a 100-word poem about Java and AI\";\n\n      CompletableFuture<ChatResponse> futureResponse = new CompletableFuture<>();\n      model.chat(userMessage, new StreamingChatResponseHandler() {\n\n          @Override\n          public void onPartialResponse(String partialResponse) {\n              System.out.print(partialResponse);\n          }\n\n          @Override\n          public void onCompleteResponse(ChatResponse completeResponse) {\n              futureResponse.complete(completeResponse);\n          }\n\n          @Override\n          public void onError(Throwable error) {\n              futureResponse.completeExceptionally(error);\n          }\n      });\n\n      futureResponse.join();\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HTTP MCP Transport in Java\nDESCRIPTION: This code snippet shows how to set up an MCP Transport using HTTP in Java. It requires two URLs for opening an SSE channel and submitting HTTP POST requests. Logging facilities are included to track requests and responses.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_1\n\nLANGUAGE: Java\nCODE:\n```\nMcpTransport transport = new HttpMcpTransport.Builder()\n    .sseUrl(\"http://localhost:3001/sse\")\n    .logRequests(true) // if you want to see the traffic in the log\n    .logResponses(true)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Creating ClickHouseEmbeddingStore Instance in LangChain4j\nDESCRIPTION: Java code snippet for initializing a ClickHouseEmbeddingStore object using the previously configured ClickHouseSettings. This store can be used for vector storage and retrieval in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/clickhouse.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nClickHouseEmbeddingStore embeddingStore = ClickHouseEmbeddingStore.builder()\n    .settings(settings)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Dependencies for Maven\nDESCRIPTION: Maven dependencies required to integrate LangChain4j and MistralAI into a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-mistral-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Google AI Gemini Maven Dependency\nDESCRIPTION: XML snippet for adding the LangChain4j Google AI Gemini dependency to a Maven project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-ai-gemini.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-google-ai-gemini</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Maven Dependency for Plain Java\nDESCRIPTION: XML configuration to add the LangChain4j OpenAI dependency for plain Java projects.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Implementing Jlama Embedding Model with LangChain4J\nDESCRIPTION: Complete Java example demonstrating how to use the Jlama Embedding model with LangChain4J. Shows how to create an embedding model using a BERT-based model, embed text segments, store them in memory, and retrieve the most relevant segment for a user query.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/jlama.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.data.embedding.Embedding;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.model.jlama.JlamaEmbeddingModel;\nimport dev.langchain4j.model.embedding.EmbeddingModel;\nimport dev.langchain4j.store.embedding.EmbeddingMatch;\nimport dev.langchain4j.store.embedding.EmbeddingStore;\nimport dev.langchain4j.store.embedding.inmemory.InMemoryEmbeddingStore;\n\nimport java.util.List;\n\npublic class HelloWorld {\n    public static void main(String[] args) {\n        EmbeddingModel embeddingModel = JlamaEmbeddingModel\n                                        .modelName(\"intfloat/e5-small-v2\")\n                                        .build();\n\n        // For simplicity, this example uses an in-memory store, but you can choose any external compatible store for production environments.\n        EmbeddingStore<TextSegment> embeddingStore = new InMemoryEmbeddingStore<>();\n\n        TextSegment segment1 = TextSegment.from(\"I like football.\");\n        Embedding embedding1 = embeddingModel.embed(segment1).content();\n        embeddingStore.add(embedding1, segment1);\n        \n        TextSegment segment2 = TextSegment.from(\"The weather is good today.\");\n        Embedding embedding2 = embeddingModel.embed(segment2).content();\n        embeddingStore.add(embedding2, segment2);\n        \n        String userQuery = \"What is your favourite sport?\";\n        Embedding queryEmbedding = embeddingModel.embed(userQuery).content();\n        EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n                .queryEmbedding(queryEmbedding)\n                .maxResults(1)\n                .build();\n        EmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);\n        EmbeddingMatch<TextSegment> embeddingMatch = searchResult.matches().get(0);\n\n        System.out.println(\"Question: \" + userQuery); // What is your favourite sport?\n        System.out.println(\"Response: \" + embeddingMatch.embedded().text()); // I like football.\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Models Chat Model\nDESCRIPTION: This Java code demonstrates how to configure a GitHub Models chat model by specifying the base URL and GitHub token.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .baseUrl(\"https://models.inference.ai.azure.com\")\n        .apiKey(System.getenv(\"GITHUB_TOKEN\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Storing Text Embeddings in Couchbase\nDESCRIPTION: Demonstrates generating embeddings from text segments using an embedding model and storing them in Couchbase. The example uses the AllMiniLmL6V2EmbeddingModel to create vectors that represent text meanings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingModel embeddingModel = new AllMiniLmL6V2EmbeddingModel();\n\nTextSegment segment1 = TextSegment.from(\"I like football.\");\nEmbedding embedding1 = embeddingModel.embed(segment1).content();\nembeddingStore.add(embedding1, segment1);\n\nTextSegment segment2 = TextSegment.from(\"The weather is good today.\");\nEmbedding embedding2 = embeddingModel.embed(segment2).content();\nembeddingStore.add(embedding2, segment2);\n\nThread.sleep(1000); // to be sure that embeddings were persisted\n```\n\n----------------------------------------\n\nTITLE: Configuring ClickHouse Settings for LangChain4j\nDESCRIPTION: Java code for creating a ClickHouseSettings object. This configuration includes the ClickHouse server URL, table name, credentials, embedding dimension, and metadata type mapping.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/clickhouse.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n// Mapping metadata key to ClickHouse data type.\nMap<String, ClickHouseDataType> metadataTypeMap = new HashMap<>();\n\nClickHouseSettings settings = ClickHouseSettings.builder()\n    .url(\"http://localhost:8123\")\n    .table(\"langchain4j_table\")\n    .username(System.getenv(\"USERNAME\"))\n    .password(System.getenv(\"PASSWORD\"))\n    .dimension(embeddingModel.dimension())\n    .metadataTypeMap(metadataTypeMap)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Mode with Mistral AI via Java Builder\nDESCRIPTION: Configures Mistral AI models to produce responses following JSON object format, ensuring predictability through strict output specifications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_16\n\nLANGUAGE: java\nCODE:\n```\nMistralAiChatModel.builder()\n    ...\n    .responseFormat(MistralAiResponseFormatType.JSON_OBJECT)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAI Token Count Estimator in Java\nDESCRIPTION: Code snippet demonstrating how to initialize an OpenAiTokenCountEstimator with a specific model (gpt-4o-mini). This class is used to estimate token counts for prompt inputs when using OpenAI models.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nTokenCountEstimator tokenCountEstimator = new OpenAiTokenCountEstimator(\"gpt-4o-mini\");\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Executor for Embedding Model Parallelization\nDESCRIPTION: Java code example demonstrating how to provide a custom Executor instance when creating an embedding model. This allows customizing the thread pool used for parallelization of the embedding process.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nExecutor = ...;\nEmbeddingModel embeddingModel = new AllMiniLmL6V2QuantizedEmbeddingModel(executor);\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4J and Jlama Dependencies in Gradle\nDESCRIPTION: Gradle configuration to add LangChain4J and Jlama dependencies to a project. Includes the core LangChain4J library and the Jlama integration module.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/jlama.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j:1.0.0-beta3'\nimplementation 'dev.langchain4j:langchain4j-jlama:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: OpenSearch Maven Dependency Configuration for Langchain4j\nDESCRIPTION: Maven dependency configuration for integrating OpenSearch with Langchain4j. This dependency provides the OpenSearchEmbeddingStore functionality for storing and retrieving embeddings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/opensearch.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-opensearch</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Creating OpenAiModerationModel in Plain Java\nDESCRIPTION: Java code to create an OpenAiModerationModel instance with API key and model name.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nModerationModel model = OpenAiModerationModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"text-moderation-stable\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating MilvusEmbeddingStore with Automatic Client Creation in Java\nDESCRIPTION: This Java code demonstrates how to create a MilvusEmbeddingStore instance using the builder pattern. It sets various parameters such as host, port, collection name, vector dimensions, index type, and authentication details.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/milvus.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nMilvusEmbeddingStore store = MilvusEmbeddingStore.builder()\n\n    .host(\"localhost\")                         // Host for Milvus instance\n    .port(19530)                               // Port for Milvus instance\n    .collectionName(\"example_collection\")      // Name of the collection\n    .dimension(128)                            // Dimension of vectors\n    .indexType(IndexType.FLAT)                 // Index type\n    .metricType(MetricType.COSINE)             // Metric type\n    .username(\"username\")                      // Username for Milvus\n    .password(\"password\")                      // Password for Milvus\n    .consistencyLevel(ConsistencyLevelEnum.EVENTUALLY)  // Consistency level\n    .autoFlushOnInsert(true)                   // Auto flush after insert\n    .idFieldName(\"id\")                         // ID field name\n    .textFieldName(\"text\")                     // Text field name\n    .metadataFieldName(\"metadata\")             // Metadata field name\n    .vectorFieldName(\"vector\")                 // Vector field name\n    .build();                                  // Build the MilvusEmbeddingStore instance\n```\n\n----------------------------------------\n\nTITLE: Creating REST Controller for ChatModel\nDESCRIPTION: Example Spring Boot REST controller showing how to autowire and use the ChatModel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\n@RestController\nclass ChatModelController {\n\n    ChatModel chatModel;\n\n    ChatModelController(ChatModel chatModel) {\n        this.chatModel = chatModel;\n    }\n\n    @GetMapping(\"/model\")\n    public String model(@RequestParam(value = \"message\", defaultValue = \"Hello\") String message) {\n        return chatModel.chat(message);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Loading All Files from GCS Bucket\nDESCRIPTION: Loads all documents from a Google Cloud Storage bucket. This method requires the bucket name and a document parser to process all files in the bucket.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nGoogleCloudStorageDocumentLoader gcsLoader = GoogleCloudStorageDocumentLoader.builder()\n    .project(System.getenv(\"GCP_PROJECT_ID\"))\n    .build();\n\nList<Document> documents = gcsLoader.loadDocuments(\"BUCKET_NAME\", new TextDocumentParser());\n```\n\n----------------------------------------\n\nTITLE: Using GitHub Models for Text Embedding\nDESCRIPTION: Java code demonstrating how to use the GitHubModelsEmbeddingModel to generate embeddings for text input.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/github-models.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nResponse<Embedding> response = model.embed(\"Please embed this sentence.\");\n```\n\n----------------------------------------\n\nTITLE: Creating GitHubModelsStreamingChatModel in Plain Java\nDESCRIPTION: Java code to initialize a streaming version of GitHubModelsChatModel for handling streaming responses.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nGitHubModelsStreamingChatModel model = GitHubModelsStreamingChatModel.builder()\n        .gitHubToken(System.getenv(\"GITHUB_TOKEN\"))\n        .modelName(\"gpt-4o-mini\")\n        .logRequestsAndResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Defining Person Record Class in Java\nDESCRIPTION: Basic Java record definition for a Person class with name, age, height, and marital status fields.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nrecord Person(String name, int age, double height, boolean married) {\n}\n```\n\n----------------------------------------\n\nTITLE: Including Metadata from Retrieved Content in LangChain4j\nDESCRIPTION: Shows how to configure DefaultContentInjector to include specific metadata keys from retrieved TextSegments. This example includes the 'source' metadata in the final user message.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nDefaultContentInjector.builder()\n    .metadataKeysToInclude(List.of(\"source\"))\n    .build()\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Selenium Document Loader Maven Dependency\nDESCRIPTION: Maven dependency configuration for integrating the Selenium document loader module into a LangChain4j project. Uses version 1.0.0-beta3 of the document loader package.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/selenium.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-selenium</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Vertex AI Gemini\nDESCRIPTION: XML configuration to add langchain4j Vertex AI Gemini dependency to a Maven project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>dev.langchain4j</groupId>\n  <artifactId>langchain4j-vertex-ai-gemini</artifactId>\n  <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Elasticsearch Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use Elasticsearch with LangChain4j\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/elasticsearch.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-elasticsearch</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring PgVectorEmbeddingStore with All Parameters\nDESCRIPTION: Comprehensive Java example demonstrating all available configuration options for PgVectorEmbeddingStore including DataSource, indexing options, table creation settings, and metadata storage configuration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pgvector.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nDataSource dataSource = ...;                 // Pre-configured DataSource, if available\n\nEmbeddingStore<TextSegment> embeddingStore = PgVectorEmbeddingStore.builder()\n        // Connection and table parameters\n        .datasource(dataSource)                      // Optional: If using a DataSource instead of host/port credentials\n        .host(\"localhost\")\n        .port(5432)\n        .database(\"postgres\")\n        .user(\"my_user\")\n        .password(\"my_password\")\n        .table(\"my_embeddings\")\n\n        // Embedding dimension\n        .dimension(embeddingModel.dimension())      // Required: Must match the embedding model's output dimension\n\n        // Indexing and performance options\n        .useIndex(true)                             // Enable IVFFlat index\n        .indexListSize(100)                         // Number of lists for IVFFlat index\n\n        // Table creation options\n        .createTable(true)                          // Automatically create the table if it doesn't exist\n        .dropTableFirst(false)                      // Don't drop the table first (set to true if you want a fresh start)\n\n        // Metadata storage format\n        .metadataStorageConfig(MetadataStorageConfig.combinedJsonb()) // Store metadata as a combined JSONB column\n\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding IVF Vector Index to Embedding Table - Java\nDESCRIPTION: This Java snippet adds an IVF (Inverted File Flat) index to the embedding column of the EmbeddingTable in OracleEmbeddingStore. It shows how to use the IVFIndexBuilder in combination with customized table settings and creation options. Improves vector search performance and enables efficient similarity queries. Requires access to Index.ivfIndexBuilder and CreateOption enums.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore embeddingStore =\\n    OracleEmbeddingStore.builder()\\n        .dataSource(myDataSource)\\n        .embeddingTable(EmbeddingTable.builder()\\n            .createOption(CreateOption.CREATE_OR_REPLACE) // use NONE if the table already exists\\n            .name(\"my_embedding_table\")\\n            .idColumn(\"id_column_name\")\\n            .embeddingColumn(\"embedding_column_name\")\\n            .textColumn(\"text_column_name\")\\n            .metadataColumn(\"metadata_column_name\")\\n            .build())\\n        .index(Index.ivfIndexBuilder().createOption(CreateOption.CREATE_OR_REPLACE).build())\\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Multimodal Message Example in Java\nDESCRIPTION: Shows how to create a UserMessage containing both text and image content.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nUserMessage userMessage = UserMessage.from(\n    TextContent.from(\"Describe the following image\"),\n    ImageContent.from(\"https://example.com/cat.jpg\")\n);\nChatResponse response = model.chat(userMessage);\n```\n\n----------------------------------------\n\nTITLE: Creating JsonAnyOfSchema for Polymorphic Structures in Java\nDESCRIPTION: This code shows how to use JsonAnyOfSchema to support polymorphic data structures. It creates a schema that can handle different shapes (circles and rectangles) in a single array. This feature is currently supported only by OpenAI and Azure OpenAI.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nJsonSchemaElement circleSchema = JsonObjectSchema.builder()\n        .addNumberProperty(\"radius\")\n        .build();\n\nJsonSchemaElement rectangleSchema = JsonObjectSchema.builder()\n        .addNumberProperty(\"width\")\n        .addNumberProperty(\"height\")\n        .build();\n\nJsonSchemaElement shapeSchema = JsonAnyOfSchema.builder()\n        .anyOf(circleSchema, rectangleSchema)\n        .build();\n\nJsonSchema jsonSchema = JsonSchema.builder()\n        .name(\"Shapes\")\n        .rootElement(JsonObjectSchema.builder()\n                .addProperty(\"shapes\", JsonArraySchema.builder()\n                        .items(shapeSchema)\n                        .build())\n                .required(List.of(\"shapes\"))\n                .build())\n        .build();\n\nResponseFormat responseFormat = ResponseFormat.builder()\n        .type(ResponseFormatType.JSON)\n        .jsonSchema(jsonSchema)\n        .build();\n\nUserMessage userMessage = UserMessage.from(\"\"\"\n        Extract information from the following text:\n        1. A circle with a radius of 5\n        2. A rectangle with a width of 10 and a height of 20\n        \"\"\");\n\nChatRequest chatRequest = ChatRequest.builder()\n        .messages(userMessage)\n        .responseFormat(responseFormat)\n        .build();\n\nChatResponse chatResponse = model.chat(chatRequest);\n\nSystem.out.println(chatResponse.aiMessage().text()); // {\"shapes\":[{\"radius\":5},{\"width\":10,\"height\":20}]}\n```\n\n----------------------------------------\n\nTITLE: ChatModel Message-Based Methods in Java\nDESCRIPTION: Additional chat methods that accept single or multiple ChatMessage objects as input and return ChatResponse.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\n    ...\n    \n    ChatResponse chat(ChatMessage... messages);\n\n    ChatResponse chat(List<ChatMessage> messages);\n        \n    ...\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHubModelsChatModel in Spring Boot\nDESCRIPTION: Spring Boot configuration class for creating a GitHubModelsChatModel bean with customizable parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\npackage com.example.demo.configuration.github;\n\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.github.GitHubModelsChatModel;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.Profile;\n\n@Configuration\n@Profile(\"github\")\npublic class GitHubModelsChatModelConfiguration {\n\n    @Value(\"${GITHUB_TOKEN}\")\n    private String gitHubToken;\n\n    @Bean\n    ChatModel gitHubModelsChatModel() {\n        return GitHubModelsChatModel.builder()\n                .gitHubToken(gitHubToken)\n                .modelName(\"gpt-4o-mini\")\n                .logRequestsAndResponses(true)\n                .build();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Executor for Parallel Processing in DefaultRetrievalAugmentor\nDESCRIPTION: Demonstrates how to provide a custom Executor instance to DefaultRetrievalAugmentor for parallel processing of queries and content retrieval operations.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_14\n\nLANGUAGE: java\nCODE:\n```\nDefaultRetrievalAugmentor.builder()\n        ...\n        .executor(executor)\n        .build;\n```\n\n----------------------------------------\n\nTITLE: Adding Cloudflare Workers AI Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the langchain4j Cloudflare Workers AI integration in a Java project. Uses version 1.0.0-beta3 of the langchain4j-workers-ai artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/workers-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-workers-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Vertex AI Dependency in Maven\nDESCRIPTION: XML snippet for adding the LangChain4j Vertex AI dependency to a Maven project's pom.xml file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-palm.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>dev.langchain4j</groupId>\n  <artifactId>langchain4j-vertex-ai</artifactId>\n  <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use LangChain4j's in-memory embedding store functionality.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/1-in-memory.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring ElasticsearchEmbeddingStore with ScriptScore\nDESCRIPTION: Configuration of ElasticsearchEmbeddingStore using scriptScore query implementation for cosine similarity\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/elasticsearch.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nElasticsearchEmbeddingStore store = ElasticsearchEmbeddingStore.builder()\n        .configuration(ElasticsearchConfigurationScript.builder().build())\n        .restClient(restClient)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding JSON-Based Index to Metadata Column - Java\nDESCRIPTION: This Java code example configures an OracleEmbeddingStore using the JSONIndexBuilder to build a function-based index on individual keys within the metadata JSON column. Demonstrates indexing on multiple keys with ascending and descending order, optimizing query performance for metadata-driven use cases. Requires the Index.jsonIndexBuilder, CreateOption, and JSONIndexBuilder.Order classes.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore.builder()\\n    .dataSource(myDataSource)\\n    .embeddingTable(EmbeddingTable.builder()\\n        .createOption(CreateOption.CREATE_OR_REPLACE) // use NONE if the table already exists\\n        .name(\"my_embedding_table\")\\n        .idColumn(\"id_column_name\")\\n        .embeddingColumn(\"embedding_column_name\")\\n        .textColumn(\"text_column_name\")\\n        .metadataColumn(\"metadata_column_name\")\\n        .build())\\n    .index(Index.jsonIndexBuilder()\\n        .createOption(CreateOption.CREATE_OR_REPLACE)\\n        .key(\"name\", String.class, JSONIndexBuilder.Order.ASC)\\n        .key(\"year\", Integer.class, JSONIndexBuilder.Order.DESC)\\n        .build())\\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Creating API Key Configuration Class\nDESCRIPTION: Java class for managing the MistralAI API key using environment variables.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\npublic class ApiKeys {\n    public static final String MISTRALAI_API_KEY = System.getenv(\"MISTRAL_AI_API_KEY\");\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring VearchConfig for 1.0.0-alpha1 and Later\nDESCRIPTION: Java code for configuring the VearchConfig object with latest API parameters for versions 1.0.0-alpha1 and later. This sets up vector fields, string fields, and search parameters using the new Vearch API structure.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nString embeddingFieldName = \"text_embedding\";\nString textFieldName = \"text\";\nString spaceName = \"embedding_space_\" + ThreadLocalRandom.current().nextInt(0, Integer.MAX_VALUE);\n\n// init Fields\nList<Field> fields = new ArrayList<>(4);\nList<String> metadataFieldNames = new ArrayList<>();\nfields.add(VectorField.builder()\n        .name(embeddingFieldName)\n        .dimension(embeddingModel.dimension())\n        .index(Index.builder()\n                .name(\"gamma\")\n                .type(IndexType.HNSW)\n                .params(HNSWParam.builder()\n                        .metricType(MetricType.INNER_PRODUCT)\n                        .efConstruction(100)\n                        .nLinks(32)\n                        .efSearch(64)\n                        .build())\n                .build())\n        .build()\n);\nfields.add(StringField.builder().name(textFieldName).fieldType(FieldType.STRING).build());\n// put metadata... e.g. fields.add(StringField.builder().name(\"name\").fieldType(FieldType.STRING).build());\n\nVearchConfig vearchConfig = VearchConfig.builder()\n        .databaseName(databaseName)\n        .spaceName(spaceName)\n        .textFieldName(textFieldName)\n        .embeddingFieldName(embeddingFieldName)\n        .fields(fields)\n        .metadataFieldNames(metadataFieldNames)\n        .searchIndexParam(HNSWSearchParam.builder()\n                // Only support INNER_PRODUCT now\n                .metricType(MetricType.INNER_PRODUCT)\n                .efSearch(64)\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Defining Person Record with Description Annotations in Java\nDESCRIPTION: Example showing how to use @Description annotations on a record class to provide guidance to LLMs about expected output format. The annotations help specify the expected format for name, age, height, and marital status fields.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\n@Description(\"a person\")\nrecord Person(@Description(\"person's first and last name, for example: John Doe\") String name,\n              @Description(\"person's age, for example: 42\") int age,\n              @Description(\"person's height in meters, for example: 1.78\") double height,\n              @Description(\"is person married or not, for example: false\") boolean married) {\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic QwenChatModel in Java\nDESCRIPTION: Basic initialization of QwenChatModel with required API key and model name parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nChatModel qwenModel = QwenChatModel.builder()\n                    .apiKey(\"You API key here\")\n                    .modelName(\"qwen-max\")\n                    .build();\n```\n\n----------------------------------------\n\nTITLE: Enable JSON Mode with Azure OpenAI via Java Builder\nDESCRIPTION: This code configures Azure OpenAI to respond with JSON using the ChatCompletionsJsonResponseFormat class, ensuring LLM responses meet expected JSON format requirements.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_13\n\nLANGUAGE: java\nCODE:\n```\nAzureOpenAiChatModel.builder()\n    ...\n    .responseFormat(new ChatCompletionsJsonResponseFormat())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j GraalVM Polyglot Integration\nDESCRIPTION: This XML snippet shows how to add the Maven dependency for the LangChain4j GraalVM Polyglot code execution engine. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/code-execution-engines/graalvm-polyglot.md#2025-04-22_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-code-execution-engine-graalvm-polyglot</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Example Output from Embedding Search\nDESCRIPTION: Sample output showing the question-answer interaction using MistralAI embeddings for semantic search.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_5\n\nLANGUAGE: plaintext\nCODE:\n```\nQuestion: What is your favourite sport?\nResponse: I like football.\n```\n\n----------------------------------------\n\nTITLE: Adding Gradle Dependency for Vertex AI Integration\nDESCRIPTION: Gradle dependency configuration to include langchain4j-vertex-ai library in a project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/google-vertex-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-vertex-ai:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Querying Couchbase for Relevant Embeddings\nDESCRIPTION: Searches the Couchbase embedding store for relevant content by converting a query into an embedding vector and finding similar vectors. The example finds the most semantically similar text to the query \"What is your favourite sport?\".\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nEmbedding queryEmbedding = embeddingModel.embed(\"What is your favourite sport?\").content();\nEmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n        .queryEmbedding(queryEmbedding)\n        .maxResults(1)\n        .build();\nEmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);\nEmbeddingMatch<TextSegment> embeddingMatch = searchResult.matches().get(0);\n```\n\n----------------------------------------\n\nTITLE: Creating a GCS Loader with Default Authentication\nDESCRIPTION: Initializes a Google Cloud Storage document loader using the default authentication method. This approach relies on the GCP environment or local gcloud authentication.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nGoogleCloudStorageDocumentLoader gcsLoader = GoogleCloudStorageDocumentLoader.builder()\n    .project(System.getenv(\"GCP_PROJECT_ID\"))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Removing Specific Embeddings from Couchbase\nDESCRIPTION: Demonstrates how to delete a specific embedding from the Couchbase store by its ID. This is useful for managing the lifecycle of stored embeddings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nembeddingStore.remove(embeddingMatch.id())\n```\n\n----------------------------------------\n\nTITLE: Weaviate Parameter Table in Markdown\nDESCRIPTION: This Markdown table lists and describes the various parameters used for configuring the WeaviateEmbeddingStore. It includes details on each parameter's purpose, whether it's required or optional, and default values where applicable.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/weaviate.md#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n|      Parameter      | Description                                                                                                                                                                                                      | Required/Optional               |\n|:-------------------:|--------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------|\n|      `apiKey`       | Your Weaviate API key. Not required for local deployment.                                                                                                                                                        | Optional                        |\n|      `scheme`       | The scheme, e.g. \"https\" of cluster URL. Find it under Details of your Weaviate cluster.                                                                                                                         | Required                        |\n|       `host`        | The host, e.g. \"langchain4j-4jw7ufd9.weaviate.network\" of cluster URL. Find it under Details of your Weaviate cluster.                                                                                           | Required                        |\n|       `port`        | The port, e.g. 8080.                                                                                                                                                                                             | Optional                        |\n|    `objectClass`    | The object class you want to store, e.g. \"MyGreatClass\". Must start from an uppercase letter.                                                                                                    | Optional (default: `Default`)   |\n|     `avoidDups`     | If `true` (default), then `WeaviateEmbeddingStore` will generate a hashed ID based on the provided text segment, which avoids duplicated entries in DB. If false, then a random ID will be generated.            | Optional (default: `true`)      |\n| `consistencyLevel`  | Consistency level: `ONE`, `QUORUM` (default) or `ALL`. Find more details [here](https://weaviate.io/developers/weaviate/concepts/replication-architecture/consistency#tunable-write-consistency).                | Optional (default: `QUORUM`)    |\n| `useGrpcForInserts` | Use GRPC instead of HTTP for batch inserts only. You still need HTTP configured for search.                                                                                                                      | Optional                        |\n|    `securedGrpc`    | The GRPC connection is secured.                                                                                                                                                                                  | Optional                        |\n|     `grpcPort`      | The port, e.g. 50051.                                                                                                                                                                                            | Optional                        |\n|   `textFieldName`   | The name of the field that contains the text of a `TextSegment`.                                                                                                                                                 | Optional (default: `text`)      |\n| `metadataFieldName` | The name of the field where `Metadata` entries are stored. If set to an empty string (`\"\"`), `Metadata` entries will be stored in the root object. It is recommended to use `metadataKeys` if using root object. | Optional (default: `_metadata`) |\n|   `metadataKeys`    | Metadata keys that should be persisted.                                                                                                                                                                          | Optional                        |\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI in Spring Boot Properties\nDESCRIPTION: Application properties configuration for OpenAI chat model in Spring Boot, including mandatory and optional parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_4\n\nLANGUAGE: properties\nCODE:\n```\n# Mandatory properties:\nlangchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.chat-model.model-name=gpt-4o-mini\n\n# Optional properties:\nlangchain4j.open-ai.chat-model.base-url=...\nlangchain4j.open-ai.chat-model.custom-headers=...\nlangchain4j.open-ai.chat-model.frequency-penalty=...\nlangchain4j.open-ai.chat-model.log-requests=...\nlangchain4j.open-ai.chat-model.log-responses=...\nlangchain4j.open-ai.chat-model.logit-bias=...\nlangchain4j.open-ai.chat-model.max-retries=...\nlangchain4j.open-ai.chat-model.max-completion-tokens=...\nlangchain4j.open-ai.chat-model.max-tokens=...\nlangchain4j.open-ai.chat-model.metadata=...\nlangchain4j.open-ai.chat-model.organization-id=...\nlangchain4j.open-ai.chat-model.parallel-tool-calls=...\nlangchain4j.open-ai.chat-model.presence-penalty=...\nlangchain4j.open-ai.chat-model.project-id=...\nlangchain4j.open-ai.chat-model.reasoning-effort=...\nlangchain4j.open-ai.chat-model.response-format=...\nlangchain4j.open-ai.chat-model.seed=...\nlangchain4j.open-ai.chat-model.service-tier=...\nlangchain4j.open-ai.chat-model.stop=...\nlangchain4j.open-ai.chat-model.store=...\nlangchain4j.open-ai.chat-model.strict-schema=...\nlangchain4j.open-ai.chat-model.strict-tools=...\nlangchain4j.open-ai.chat-model.supported-capabilities=...\nlangchain4j.open-ai.chat-model.temperature=...\nlangchain4j.open-ai.chat-model.timeout=...\nlangchain4j.open-ai.chat-model.top-p=\nlangchain4j.open-ai.chat-model.user=...\n```\n\n----------------------------------------\n\nTITLE: Creating a GCS Loader with Service Account Authentication\nDESCRIPTION: Initializes a Google Cloud Storage document loader using service account credentials. This approach uses a service account key file for authentication.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nGoogleCloudStorageDocumentLoader gcsLoader = GoogleCloudStorageDocumentLoader.builder()\n    .project(System.getenv(\"GCP_PROJECT_ID\"))\n    .credentials(GoogleCredentials.fromStream(new FileInputStream(System.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring BedrockAnthropicMessageChatModel using InvokeAPI in Java\nDESCRIPTION: Java code snippet for configuring a BedrockAnthropicMessageChatModel using the InvokeAPI. This example shows how to set up an Anthropic model with a specific model ID.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/amazon-bedrock.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = BedrockAnthropicMessageChatModel.builder()\n.model(\"anthropic.claude-3-sonnet-20240229-v1:0\")\n.build();\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Official SDK Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the langchain4j-open-ai-official library in your project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai-official.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-official</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Voyage AI Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Voyage AI dependency in a Maven project. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/voyage-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-voyage-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Community DashScope Dependency (v1.0.0-alpha1 and Later)\nDESCRIPTION: Maven dependency configuration for the DashScope integration with LangChain4j for version 1.0.0-alpha1 and later, which has been moved to the community package.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/dashscope.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-dashscope</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Creating Oracle Embedding Store with New Table\nDESCRIPTION: Creates an instance of Oracle Embedding Store and creates a new table if it doesn't exist. Uses CreateOption parameter to control table creation behavior.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore = OracleEmbeddingStore.builder()\n   .dataSource(myDataSource)\n   .embeddingTable(\"my_embedding_table\", CreateOption.CREATE_IF_NOT_EXISTS)\n   .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring ChatModel with JSON Schema for Structured Response in Java\nDESCRIPTION: This snippet constructs a ChatRequest for langchain4j's ChatModel, specifying a custom JSON schema so the model returns structured JSON data matching a defined Person schema. The Request builder pattern and schema composition require the langchain4j framework and depend on classes like ChatRequest, UserMessage, ResponseFormat, and various JsonSchema subtypes. Inputs include user messages and schema definitions; the output is a model-compliant JSON string suitable for deserialization, with constraints being the correct configuration of both schema and model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nChatRequest chatRequest = ChatRequest.builder()\n    .messages(UserMessage.from(\"Julien likes the colors blue, white and red\"))\n    .responseFormat(ResponseFormat.builder()\n        .type(JSON)\n        .jsonSchema(JsonSchema.builder()\n            .name(\"Person\")\n            .rootElement(JsonObjectSchema.builder()\n                .addStringProperty(\"name\")\n                .addProperty(\"favouriteColors\", JsonArraySchema.builder()\n                    .items(new JsonStringSchema())\n                    .build())\n                .required(\"name\", \"favouriteColors\")\n                .build())\n            .build())\n        .build())\n    .build();\n\nString answer = chatModel.chat(chatRequest).aiMessage().text();\n```\n\n----------------------------------------\n\nTITLE: Custom Embedding Table Configuration with Builder Pattern - Java\nDESCRIPTION: This Java example demonstrates constructing an OracleEmbeddingStore with a fully customized EmbeddingTable via builder pattern. Developers can specify custom table names and column mappings for id, embedding, text, and metadata fields, as well as table creation strategy. This provides flexibility for integrating with non-standard schemas or legacy tables. Requires access to the EmbeddingTable builder and CreateOption enums.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore embeddingStore =\\nOracleEmbeddingStore.builder()\\n    .dataSource(myDataSource)\\n    .embeddingTable(EmbeddingTable.builder()\\n            .createOption(CREATE_OR_REPLACE) // use NONE if the table already exists\\n            .name(\"my_embedding_table\")\\n            .idColumn(\"id_column_name\")\\n            .embeddingColumn(\"embedding_column_name\")\\n            .textColumn(\"text_column_name\")\\n            .metadataColumn(\"metadata_column_name\")\\n            .build())\\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing Stdio MCP Transport in Java\nDESCRIPTION: This snippet demonstrates how to create an instance of MCP Transport using stdio with Java. It requires the '@modelcontextprotocol/server-everything' NPM package and uses it as a local subprocess. Key dependencies include Java and the NPM package.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nMcpTransport transport = new StdioMcpTransport.Builder()\n    .command(List.of(\"/usr/bin/npm\", \"exec\", \"@modelcontextprotocol/server-everything@0.6.2\"))\n    .logEvents(true) // only if you want to see the traffic in the log\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI Chat Model\nDESCRIPTION: This Java code demonstrates how to configure an Azure OpenAI chat model by specifying the Azure OpenAI endpoint and API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .baseUrl(System.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Configuring BedrockChatModel using ConverseAPI in Java\nDESCRIPTION: Java code snippet for configuring a BedrockChatModel using the ConverseAPI. This configuration includes setting the model ID, region, and various request parameters such as topP, temperature, and maxOutputTokens.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/amazon-bedrock.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = BedrockChatModel.builder()\n        .modelId(\"us.amazon.nova-lite-v1:0\")\n        .region(...)\n        .maxRetries(...)\n        .timeout(...)\n        .logRequests(...)\n        .logResponses(...)\n        .listeners(...)\n        .defaultRequestParameters(BedrockChatRequestParameters.builder()\n                .topP(...)\n                .temperature(...)\n                .maxOutputTokens(...)\n                .stopSequences(...)\n                .toolSpecifications(...)\n                .additionalModelRequestFields(...)\n                .build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Initializing OracleEmbeddingStore with Existing Table - Java\nDESCRIPTION: This Java snippet initializes an EmbeddingStore using OracleEmbeddingStore's builder pattern, referencing an existing embedding table in the database. It requires a configured DataSource (e.g., from a connection pool) and the table's name. The store is suitable for applications where the embedding table schema matches the expected default and already exists in the database.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingStore embeddingStore = OracleEmbeddingStore.builder()\\n   .dataSource(myDataSource)\\n   .embeddingTable(\"my_embedding_table\")\\n   .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Apache PDFBox Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Apache PDFBox document parser dependency in a Maven project. It specifies the groupId, artifactId, and version for the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-parsers/apache-pdfbox.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-parser-apache-pdfbox</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Quantized AllMiniLmL6V2 Embedding Model Dependency to Maven Project\nDESCRIPTION: Maven dependency configuration for including the quantized version of the AllMiniLmL6V2 embedding model. Quantized models are smaller and faster but may have slightly lower accuracy.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-embeddings-all-minilm-l6-v2-q</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for LangChain4j Couchbase Integration\nDESCRIPTION: Maven dependency required to add Couchbase integration capabilities to a LangChain4j project. This dependency provides the CouchbaseEmbeddingStore implementation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-couchbase</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Creating VearchEmbeddingStore for 1.0.0-alpha1 and Later\nDESCRIPTION: Java code for instantiating a VearchEmbeddingStore using the configured VearchConfig object for versions 1.0.0-alpha1 and later. This connects to a Vearch server with additional options for request and response logging.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nVearchEmbeddingStore embeddingStore = VearchEmbeddingStore.builder()\n        .vearchConfig(vearchConfig)\n        .baseUrl(baseUrl)\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: JSON Output Example for Person Schema Response\nDESCRIPTION: This example shows a typical JSON response string generated by the ChatModel when given a schema as a ChatRequest. The response adheres to the pre-defined structure with fields for name and a list of favorite colors. Such output is designed for further processing, including deserialization to Java objects (for example, using Jackson); inputs are driven by prior code configuration, with this being a sample output.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Julien\",\n  \"favouriteColors\": [\"blue\", \"white\", \"red\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting up PostgreSQL with PGVector using Docker\nDESCRIPTION: Docker command to create a PostgreSQL instance with PGVector extension. Sets up a test container with specified user credentials and port mapping.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pgvector.md#2025-04-22_snippet_2\n\nLANGUAGE: docker\nCODE:\n```\ndocker run --rm --name langchain4j-postgres-test-container -p 5432:5432 -e POSTGRES_USER=my_user -e POSTGRES_PASSWORD=my_password pgvector/pgvector\n```\n\n----------------------------------------\n\nTITLE: Creating an MCP Client in Java\nDESCRIPTION: This snippet illustrates how to build an MCP client from an existing transport in Java. The `DefaultMcpClient.Builder` provides a way to initialize the client which will handle communications with the MCP server.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_2\n\nLANGUAGE: Java\nCODE:\n```\nMcpClient mcpClient = new DefaultMcpClient.Builder()\n    .transport(transport)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Spring Boot Application Properties Configuration\nDESCRIPTION: Properties configuration for Azure OpenAI chat model in Spring Boot application.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.azure-open-ai.chat-model.endpoint=${AZURE_OPENAI_URL}\nlangchain4j.azure-open-ai.chat-model.service-version=...\nlangchain4j.azure-open-ai.chat-model.api-key=${AZURE_OPENAI_KEY}\nlangchain4j.azure-open-ai.chat-model.non-azure-api-key=${OPENAI_API_KEY}\nlangchain4j.azure-open-ai.chat-model.deployment-name=gpt-4o\nlangchain4j.azure-open-ai.chat-model.max-tokens=...\nlangchain4j.azure-open-ai.chat-model.temperature=...\nlangchain4j.azure-open-ai.chat-model.top-p=\nlangchain4j.azure-open-ai.chat-model.logit-bias=...\nlangchain4j.azure-open-ai.chat-model.user=\nlangchain4j.azure-open-ai.chat-model.stop=...\nlangchain4j.azure-open-ai.chat-model.presence-penalty=...\nlangchain4j.azure-open-ai.chat-model.frequency-penalty=...\nlangchain4j.azure-open-ai.chat-model.seed=...\nlangchain4j.azure-open-ai.chat-model.strict-json-schema=...\nlangchain4j.azure-open-ai.chat-model.timeout=...\nlangchain4j.azure-open-ai.chat-model.max-retries=...\nlangchain4j.azure-open-ai.chat-model.log-requests-and-responses=...\nlangchain4j.azure-open-ai.chat-model.user-agent-suffix=\nlangchain4j.azure-open-ai.chat-model.custom-headers=...\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Chat Model with Default Base URL\nDESCRIPTION: This Java code shows how to configure an OpenAI chat model using the default base URL, which is the standard OpenAI API endpoint.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiOfficialChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(ChatModel.GPT_4O_MINI)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Creating Oracle Embedding Store with JSON Metadata Index\nDESCRIPTION: Creates an Oracle Embedding Store with a function-based index on keys in the metadata column to enable efficient filtering during vector searches.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore.builder()\n    .dataSource(myDataSource)\n    .embeddingTable(EmbeddingTable.builder()\n        .createOption(CreateOption.CREATE_OR_REPLACE) // use NONE if the table already exists\n        .name(\"my_embedding_table\")\n        .idColumn(\"id_column_name\")\n        .embeddingColumn(\"embedding_column_name\")\n        .textColumn(\"text_column_name\")\n        .metadataColumn(\"metadata_column_name\")\n        .build())\n    .index(Index.jsonIndexBuilder()\n        .createOption(CreateOption.CREATE_OR_REPLACE)\n        .key(\"name\", String.class, JSONIndexBuilder.Order.ASC)\n        .key(\"year\", Integer.class, JSONIndexBuilder.Order.DESC)\n        .build())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j DuckDB Integration\nDESCRIPTION: Maven dependency configuration required to add DuckDB support to a LangChain4j project\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/duckdb.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-duckdb</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Azure OpenAI Maven Dependency for Plain Java\nDESCRIPTION: Maven dependency configuration required to use the Azure OpenAI integration with plain Java applications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/azure-open-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven BOM Configuration for LangChain4j Community Dependencies\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for managing LangChain4j community dependencies consistently across the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/zhipu-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Initializing AzureOpenAiImageModel in Plain Java\nDESCRIPTION: Java code for creating an instance of AzureOpenAiImageModel with basic configuration including API key, deployment name, and endpoint.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/azure-dall-e.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nImageModel model = AzureOpenAiImageModel.builder()\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .deploymentName(\"dall-e-3\")\n        .endpoint(\"https://langchain4j.openai.azure.com/\")\n        ...\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Structured Output Model Configuration\nDESCRIPTION: Configuration for AzureOpenAiChatModel with JSON schema support.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = AzureOpenAiChatModel.builder()\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_KEY\"))\n        .deploymentName(\"gpt-4o\")\n        .strictJsonSchema(true)\n        .supportedCapabilities(Set.of(RESPONSE_FORMAT_JSON_SCHEMA))\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Setting LangChain4j Parameters in Quarkus application.properties\nDESCRIPTION: This snippet shows how to configure LangChain4j parameters for OpenAI in a Quarkus application using the application.properties file. It sets the API key, chat model temperature, and timeout.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/model-parameters.md#2025-04-22_snippet_1\n\nLANGUAGE: properties\nCODE:\n```\nquarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}\nquarkus.langchain4j.openai.chat-model.temperature=0.5\nquarkus.langchain4j.openai.timeout=60s\n```\n\n----------------------------------------\n\nTITLE: Tool Implementation with Stock Price Service\nDESCRIPTION: Example service class implementing a tool for getting stock prices using the @Tool annotation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nclass StockPriceService {\n\n    private Logger log = Logger.getLogger(StockPriceService.class.getName());\n\n    @Tool(\"Get the stock price of a company by its ticker\")\n    public double getStockPrice(@P(\"Company ticker\") String ticker) {\n        log.info(\"Getting stock price for \" + ticker);\n        if (Objects.equals(ticker, \"MSFT\")) {\n            return 400.0;\n        } else {\n            return 0.0;\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Sentiment Enum Categories in Java\nDESCRIPTION: This Java code defines an `enum` named `Sentiment` which represents the possible classification categories for the sentiment analysis task: POSITIVE, NEUTRAL, and NEGATIVE. This enum is used as the return type for the classification method in the AI service interface.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/classification.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nenum Sentiment {\n    POSITIVE, NEUTRAL, NEGATIVE\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing PostgreSQL Embedding Store with Vector Search\nDESCRIPTION: Complete example demonstrating the setup and usage of PostgresEmbeddingStore, including initialization, adding embeddings, searching, and removing entries. Shows integration with embedding model and handling of metadata.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/cloud-sql.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nPostgresEngine engine = new PostgresEngine.Builder()\n    .projectId(\"\")\n    .region(\"\")\n    .instance(\"\")\n    .database(\"\")\n    .build();\n\nPostgresEmbeddingStore store = new PostgresEmbeddingStore.Builder(engine, TABLE_NAME)\n    .build();\n\nList<String> testTexts = Arrays.asList(\"cat\", \"dog\", \"car\", \"truck\");\nList<Embedding> embeddings = new ArrayList<>();\nList<TextSegment> textSegments = new ArrayList<>();\nEmbeddingModel embeddingModel = new AllMiniLmL6V2EmbeddingModel();\n\nfor (String text : testTexts) {\n    Map<String, Object> metaMap = new HashMap<>();\n    metaMap.put(\"my_metadata\", \"string\");\n    Metadata metadata = new Metadata(metaMap);\n    textSegments.add(new TextSegment(text, metadata));\n    embeddings.add(MyEmbeddingModel.embed(text).content());\n}\nList<String> ids = store.addAll(embeddings, textSegments);\n// search for \"cat\"\nEmbeddingSearchRequest request = EmbeddingSearchRequest.builder()\n        .queryEmbedding(embeddings.get(0))\n        .maxResults(10)\n        .minScore(0.9)\n        .build();\nList<EmbeddingMatch<TextSegment>> result = store.search(request).matches();\n// remove \"cat\"\nstore.removeAll(singletonList(result.get(0).embeddingId()));\n```\n\n----------------------------------------\n\nTITLE: Implementing Payment Data Retrieval Methods in Java\nDESCRIPTION: This snippet adds methods to the PaymentTransactionTool class to retrieve payment status and date. These methods use annotations for description and parameter specification, requiring dependencies from the 'dev.langchain4j.agent.tool' package. Input is the transaction ID, output is the payment status or date, and a limitation is that queries for non-existent IDs return 'Transaction ID not found'.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\n// Tool to be executed to get payment status\n@Tool(\"Get payment status of a transaction\") // function description\nString retrievePaymentStatus(@P(\"Transaction id to search payment data\") String transactionId) {\n    return getPaymentData(transactionId, \"payment_status\");\n}\n\n// Tool to be executed to get payment date\n@Tool(\"Get payment date of a transaction\") // function description\nString retrievePaymentDate(@P(\"Transaction id to search payment data\") String transactionId) {\n   return getPaymentData(transactionId, \"payment_date\");\n}\n\nprivate String getPaymentData(String transactionId, String data) {\n    List<String> transactionIds = paymentData.get(\"transaction_id\");\n    List<String> paymentData = paymentData.get(data);\n\n    int index = transactionIds.indexOf(transactionId);\n    if (index != -1) {\n        return paymentData.get(index);\n    } else {\n        return \"Transaction ID not found\";\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Langchain4j Maven Dependency\nDESCRIPTION: Maven dependency configuration required to include Langchain4j core library in a Java project. Uses version 1.0.0-beta3.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-parsers/text.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Vertex AI Dependency in Gradle\nDESCRIPTION: Groovy snippet for adding the LangChain4j Vertex AI dependency to a Gradle project's build.gradle file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-palm.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-vertex-ai:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Adding GPU-based ONNX Scoring Dependencies in Maven\nDESCRIPTION: XML configuration to add the LangChain4j ONNX scoring dependency for GPU-based usage, excluding the CPU runtime and including the GPU runtime.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/in-process.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-onnx-scoring</artifactId>\n    <version>1.0.0-beta3</version>\n    <exclusions>\n        <exclusion>\n            <groupId>com.microsoft.onnxruntime</groupId>\n            <artifactId>onnxruntime</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n<!-- 1.18.0 support CUDA 12.x -->\n<dependency>\n    <groupId>com.microsoft.onnxruntime</groupId>\n    <artifactId>onnxruntime_gpu</artifactId>\n    <version>1.18.0</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Loading Files Matching a Pattern from GCS Bucket\nDESCRIPTION: Loads documents from a Google Cloud Storage bucket that match a specified glob pattern. This approach allows filtering files by extension or naming pattern.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nGoogleCloudStorageDocumentLoader gcsLoader = GoogleCloudStorageDocumentLoader.builder()\n    .project(System.getenv(\"GCP_PROJECT_ID\"))\n    .build();\n\nList<Document> documents = gcsLoader.loadDocuments(\"BUCKET_NAME\", \"*.txt\", new TextDocumentParser());\n```\n\n----------------------------------------\n\nTITLE: Developing MCP GitHub Tools in Java\nDESCRIPTION: Detailed snippet for creating a Java application that uses LangChain4j to interact with a GitHub MCP server. It demonstrates starting the server, setting up a connection, and summarizing the latest commits.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_7\n\nLANGUAGE: Java\nCODE:\n```\npublic static void main(String[] args) throws Exception {\n\n    ChatModel model = OpenAiChatModel.builder()\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n\n    McpTransport transport = new StdioMcpTransport.Builder()\n        .command(List.of(\"/usr/local/bin/docker\", \"run\", \"-e\", \"GITHUB_PERSONAL_ACCESS_TOKEN\", \"-i\", \"mcp/github\"))\n        .logEvents(true)\n        .build();\n\n    McpClient mcpClient = new DefaultMcpClient.Builder()\n        .transport(transport)\n        .build();\n\n    ToolProvider toolProvider = McpToolProvider.builder()\n        .mcpClients(List.of(mcpClient))\n        .build();\n\n    Bot bot = AiServices.builder(Bot.class)\n        .chatModel(model)\n        .toolProvider(toolProvider)\n        .build();\n\n    try {\n        String response = bot.chat(\"Summarize the last 3 commits of the LangChain4j GitHub repository\");\n        System.out.println(\"RESPONSE: \" + response);\n    } finally {\n        mcpClient.close();\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring LangChain4j Parameters in Spring Boot application.properties\nDESCRIPTION: This example demonstrates how to set LangChain4j parameters for OpenAI in a Spring Boot application using the application.properties file. It configures the API key and model name.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/model-parameters.md#2025-04-22_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.open-ai.chat-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.chat-model.model-name=gpt-4-1106-preview\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Dependency for Spring Boot in Maven\nDESCRIPTION: Maven dependency configuration for integrating OpenAI with Spring Boot in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Basic QianfanChatModel Implementation\nDESCRIPTION: Basic implementation of QianfanChatModel showing how to initialize and use the chat model with required parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nQianfanChatModel model = QianfanChatModel.builder()\n        .apiKey(\"apiKey\")\n        .secretKey(\"secretKey\")\n        .modelName(\"Yi-34B-Chat\") // 一个免费的模型名称 \n        .build();\n\nString answer = model.chat(\"雷军\");\n\nSystem.out.println(answer);\n```\n\n----------------------------------------\n\nTITLE: Creating Oracle Embedding Store with IVF Index\nDESCRIPTION: Configures an Oracle Embedding Store with an IVF (Inverted File Flat) index on the embedding column to improve vector search performance.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nOracleEmbeddingStore embeddingStore =\n    OracleEmbeddingStore.builder()\n        .dataSource(myDataSource)\n        .embeddingTable(EmbeddingTable.builder()\n            .createOption(CreateOption.CREATE_OR_REPLACE) // use NONE if the table already exists\n            .name(\"my_embedding_table\")\n            .idColumn(\"id_column_name\")\n            .embeddingColumn(\"embedding_column_name\")\n            .textColumn(\"text_column_name\")\n            .metadataColumn(\"metadata_column_name\")\n            .build())\n        .index(Index.ivfIndexBuilder().createOption(CreateOption.CREATE_OR_REPLACE).build())\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Handling MCP Log Messages in Java\nDESCRIPTION: This Java snippet provides an implementation for handling log messages received from an MCP server. The `McpLogMessageHandler` interface can be customized to process logs differently using a user-defined handler.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_4\n\nLANGUAGE: Java\nCODE:\n```\nMcpClient mcpClient = new DefaultMcpClient.Builder()\n    .transport(transport)\n    .logMessageHandler(new MyLogMessageHandler())\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Weaviate Dependency in Maven for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Weaviate dependency to a Maven project. It specifies the groupId, artifactId, and version for the Weaviate integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/weaviate.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-weaviate</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven BOM for Dependency Management\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for managing Langchain4j dependencies consistently across a project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/xinference.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Base Embeddings Dependency for Custom ONNX Models\nDESCRIPTION: Maven dependency configuration for including the base langchain4j-embeddings package, which is required when working with custom ONNX embedding models not provided directly by LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-embeddings</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Initializing OpenAI Chat Model\nDESCRIPTION: Example of creating an OpenAI Chat Model instance with a custom API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\nOpenAiChatModel model = OpenAiChatModel.builder()\n    .apiKey(apiKey)\n    .modelName(\"gpt-4o-mini\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j and Jlama Dependencies in Maven\nDESCRIPTION: XML configuration for adding LangChain4j and Jlama dependencies to a Maven project. Includes core LangChain4j, Jlama integration, and native Jlama library with OS-specific classifier.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/jlama.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-jlama</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>com.github.tjake</groupId>\n    <artifactId>jlama-native</artifactId>\n    <!-- for faster inference. supports linux-x86_64, macos-x86_64/aarch_64, windows-x86_64 \n       Use https://github.com/trustin/os-maven-plugin to detect os and arch -->\n    <classifier>${os.detected.name}-${os.detected.arch}</classifier>\n    <version>${jlama.version}</version> <!-- Version from langchain4j-jlama pom -->\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI DALL-E in Spring Boot Properties\nDESCRIPTION: Application properties configuration for OpenAI DALL-E integration in Spring Boot, including both mandatory and optional settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/dall-e.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\n# Mandatory properties:\nlangchain4j.open-ai.image-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.image-model.model-name=dall-e-3\n\n# Optional properties:\nlangchain4j.open-ai.image-model.base-url=...\nlangchain4j.open-ai.image-model.custom-headers=...\nlangchain4j.open-ai.image-model.log-requests=...\nlangchain4j.open-ai.image-model.log-responses=...\nlangchain4j.open-ai.image-model.max-retries=...\nlangchain4j.open-ai.image-model.organization-id=...\nlangchain4j.open-ai.image-model.project-id=...\nlangchain4j.open-ai.image-model.quality=...\nlangchain4j.open-ai.image-model.response-format=...\nlangchain4j.open-ai.image-model.size=...\nlangchain4j.open-ai.image-model.style=...\nlangchain4j.open-ai.image-model.timeout=...\nlangchain4j.open-ai.image-model.user=...\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependency for LangChain4j Community Vearch (1.0.0-alpha1 and later)\nDESCRIPTION: Maven dependency configuration for the new langchain4j-community-vearch module for versions 1.0.0-alpha1 and later. This adds the updated Vearch integration to a LangChain4j project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-vearch</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Initializing ZhipuAiChatModel with Basic Configuration\nDESCRIPTION: Java code snippet for initializing ZhipuAiChatModel with API key and timeout settings.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/zhipu-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nChatModel qwenModel = ZhipuAiChatModel.builder()\n                    .apiKey(\"You API key here\")\n                    .callTimeout(Duration.ofSeconds(60))\n                    .connectTimeout(Duration.ofSeconds(60))\n                    .writeTimeout(Duration.ofSeconds(60))\n                    .readTimeout(Duration.ofSeconds(60))\n                    .build();\n```\n\n----------------------------------------\n\nTITLE: Implementing Metadata Filtering in MongoDB Search\nDESCRIPTION: Example of adding metadata filtering to semantic search requests using the IsIn filter\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mongodb-atlas.md#2025-04-22_snippet_4\n\nLANGUAGE: java\nCODE:\n```\nEmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()\n        .queryEmbedding(queryEmbedding)\n        .filter(new IsIn(\"website\", List.of(\"Our Earth\", \"Natural Habitats\")))\n        .maxResults(3)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Removing All Embeddings from Couchbase Store\nDESCRIPTION: Shows how to delete all embeddings from the Couchbase embedding store. This operation clears all stored vectors and is useful for resetting the store or during testing.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nembeddingStore.removeAll();\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Infinispan Dependency in Maven\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Infinispan dependency to a Maven project. It specifies the groupId, artifactId, and version for the langchain4j-infinispan artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/infinispan.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-infinispan</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for Plain Java (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with LangChain4j in plain Java applications before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/qianfan.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-qianfan</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Redis Spring Boot Starter for LangChain4j (1.0.0-beta1 and later)\nDESCRIPTION: Maven dependency configuration for integrating Redis with LangChain4j in Spring Boot applications, for version 1.0.0-beta1 and later which uses the community package.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/redis.md#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-redis-spring-boot-starter</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j OpenAI Integration with Maven\nDESCRIPTION: Maven dependency configuration for adding LangChain4j OpenAI integration to a project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding langchain4j Google Custom Search Maven Dependency\nDESCRIPTION: Maven dependency configuration required to integrate Google Custom Search functionality into a langchain4j project. Uses version 1.0.0-beta3 of the langchain4j-web-search-engine-google-custom artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/google-custom-search.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-web-search-engine-google-custom</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Dependencies for Gradle\nDESCRIPTION: Gradle dependencies required to integrate LangChain4j and MistralAI into a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j:1.0.0-beta3'\nimplementation 'dev.langchain4j:langchain4j-mistral-ai:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Creating a ChatModel Instance for OpenAI in Java\nDESCRIPTION: Shows how to create a ChatModel instance for OpenAI, which will be used as a component in the AI Service.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nChatModel model = OpenAiChatModel.builder()\n    .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n    .modelName(GPT_4_O_MINI)\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Displaying Embedding Search Results\nDESCRIPTION: Outputs the relevancy score and text content of embedding matches found in the Couchbase store. This shows how to access and display the search results after performing a vector similarity search.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nSystem.out.println(embeddingMatch.score()); // 0.81442887\nSystem.out.println(embeddingMatch.embedded().text()); // I like football.\n```\n\n----------------------------------------\n\nTITLE: Configuring VearchConfig for 1.0.0-alpha1 and Previous\nDESCRIPTION: Java code for configuring the VearchConfig object with old API parameters for versions 1.0.0-alpha1 and previous. This sets up vector space properties, embedding fields, and model parameters for the Vearch integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nString embeddingFieldName = \"text_embedding\";\nString textFieldName = \"text\";\nMap<String, Object> metadata = createMetadata().toMap();\n\n// init properties\nMap<String, SpacePropertyParam> properties = new HashMap<>(4);\nproperties.put(embeddingFieldName, SpacePropertyParam.VectorParam.builder()\n        .index(true)\n        .storeType(SpaceStoreType.MEMORY_ONLY)\n        .dimension(384)\n        .build());\nproperties.put(textFieldName, SpacePropertyParam.StringParam.builder().build());\n// put metadata... e.g. properties.put(\"name\", SpacePropertyParam.StringParam.builder().build());\n\nVearchConfig vearchConfig = VearchConfig.builder()\n        .spaceEngine(SpaceEngine.builder()\n                .name(\"gamma\")\n                .indexSize(1L)\n                .retrievalType(RetrievalType.FLAT)\n                .retrievalParam(RetrievalParam.FLAT.builder()\n                        .build())\n                .build())\n        .properties(properties)\n        .embeddingFieldName(embeddingFieldName)\n        .textFieldName(textFieldName)\n        .databaseName(databaseName)\n        .spaceName(spaceName)\n        .modelParams(singletonList(ModelParam.builder()\n                .modelId(\"vgg16\")\n                .fields(singletonList(\"string\"))\n                .out(\"feature\")\n                .build()))\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Using JSON Schema with AI Services in LangChain4j\nDESCRIPTION: This comprehensive example shows how to use JSON Schema with AI Services in LangChain4j across various LLM providers (OpenAI, Azure OpenAI, Google Gemini, Ollama, and Mistral). It demonstrates how to configure each model to support JSON Schema and how to create an AI service interface that automatically uses schema generation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\ninterface PersonExtractor {\n    \n    Person extractPersonFrom(String text);\n}\n\nChatModel chatModel = OpenAiChatModel.builder() // see [1] below\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .supportedCapabilities(Set.of(RESPONSE_FORMAT_JSON_SCHEMA)) // see [2] below\n        .strictJsonSchema(true) // see [2] below\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n// OR\nChatModel chatModel = AzureOpenAiChatModel.builder() // see [1] below\n        .endpoint(System.getenv(\"AZURE_OPENAI_URL\"))\n        .apiKey(System.getenv(\"AZURE_OPENAI_API_KEY\"))\n        .deploymentName(\"gpt-4o-mini\")\n        .strictJsonSchema(true)\n        .supportedCapabilities(Set.of(RESPONSE_FORMAT_JSON_SCHEMA)) // see [3] below\n        .logRequestsAndResponses(true)\n        .build();\n// OR\nChatModel chatModel = GoogleAiGeminiChatModel.builder() // see [1] below\n        .apiKey(System.getenv(\"GOOGLE_AI_GEMINI_API_KEY\"))\n        .modelName(\"gemini-1.5-flash\")\n        .responseFormat(ResponseFormat.JSON) // see [4] below\n        .logRequestsAndResponses(true)\n        .build();\n// OR\nChatModel chatModel = OllamaChatModel.builder() // see [1] below\n        .baseUrl(\"http://localhost:11434\")\n        .modelName(\"llama3.1\")\n        .supportedCapabilities(RESPONSE_FORMAT_JSON_SCHEMA) // see [5] below\n        .logRequests(true)\n        .logResponses(true)\n        .build();\n// OR\nChatModel chatModel = MistralAiChatModel.builder()\n         .apiKey(System.getenv(\"MISTRAL_AI_API_KEY\"))\n         .modelName(\"mistral-small-latest\")\n         .supportedCapabilities(RESPONSE_FORMAT_JSON_SCHEMA) // see [6] below\n         .logRequests(true)\n         .logResponses(true)\n         .build();\n\nPersonExtractor personExtractor = AiServices.create(PersonExtractor.class, chatModel); // see [1] below\n\nString text = \"\"\"\n        John is 42 years old and lives an independent life.\n        He stands 1.75 meters tall and carries himself with confidence.\n        Currently unmarried, he enjoys the freedom to focus on his personal goals and interests.\n        \"\"\";\n\nPerson person = personExtractor.extractPersonFrom(text);\n\nSystem.out.println(person); // Person[name=John, age=42, height=1.75, married=false]\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j DashScope Spring Boot Starter (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for integrating DashScope with LangChain4j in Spring Boot applications before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-dashscope-spring-boot-starter</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for ZhiPu AI Post-1.0.0-alpha1\nDESCRIPTION: Maven dependency configuration for integrating ZhiPu AI with LangChain4j for version 1.0.0-alpha1 and later using the langchain4j-community-zhipu-ai artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/zhipu-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-zhipu-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Nomic Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the Maven dependency for the Nomic integration in LangChain4j. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/nomic.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-nomic</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring LangChain4j BOM for Dependency Management\nDESCRIPTION: Maven BOM (Bill of Materials) configuration for consistent dependency management across LangChain4j components.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/xinference.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j Hugging Face Integration\nDESCRIPTION: This XML snippet shows how to add the Maven dependency for the LangChain4j Hugging Face integration. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/hugging-face.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-hugging-face</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Including LangChain4j Jina Integration Maven Dependency\nDESCRIPTION: Maven dependency configuration for adding Jina AI integration support to a LangChain4j project. The dependency provides the JinaEmbeddingModel and related functionality.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/jina.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-jina</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring OllamaChatModel Properties for Spring Boot\nDESCRIPTION: Demonstrates how to set up OllamaChatModel properties in a Spring Boot application. Parameters such as 'base-url', 'model-name', and 'temperature' help configure the chat model. This configuration ensures the OllamaChatModel is initialized with these properties during application startup.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_6\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.ollama.chat-model.base-url=http://localhost:11434\nlangchain4j.ollama.chat-model.model-name=llama3.1\nlangchain4j.ollama.chat-model.temperature=0.8\nlangchain4j.ollama.chat-model.timeout=PT60S\n```\n\n----------------------------------------\n\nTITLE: Sample Embedding Document Structure in Couchbase\nDESCRIPTION: Illustrates the JSON structure of an embedding document as stored in Couchbase, including the UUID-based identifier, vector values, original text, associated metadata, and similarity score.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/couchbase.md#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"f4831648-07ca-4c77-a031-75acb6c1cf2f\",\n  \"vector\": [\n    ...\n    0.037255168,\n    -0.001608681\n  ],\n  \"text\": \"text\",\n  \"metadata\": {\n    \"some\": \"value\"\n  },\n  \"score\": 0\n}\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Dependency for Plain Java in Maven\nDESCRIPTION: Maven dependency configuration for integrating OpenAI with plain Java in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/open-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Redis Spring Boot Starter for LangChain4j (pre-1.0.0-beta1)\nDESCRIPTION: Maven dependency configuration for integrating Redis with LangChain4j in Spring Boot applications, for versions before 1.0.0-beta1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/redis.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-redis-spring-boot-starter</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LocalAI Maven Dependency for LangChain4j\nDESCRIPTION: Maven dependency configuration required to integrate LocalAI functionality into a LangChain4j project. Uses version 1.0.0-beta3 of the langchain4j-local-ai artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/local-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-local-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Defining PaymentTransactionAgent Interface in Java\nDESCRIPTION: The PaymentTransactionAgent interface acts as an integration layer for sending chat messages by using the SystemMessage annotation to define chat behavior. It uses LangChain4J's dev.langchain4j.service package and is designed for chat interaction with a payment transaction tool. It requires user message inputs and entails dependency on SystemMessage configuration for internal chat logic.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.service.SystemMessage;\n\ninterface PaymentTransactionAgent {\n    @SystemMessage({\n            \"You are a payment transaction support agent.\",\n            \"You MUST use the payment transaction tool to search the payment transaction data.\",\n            \"If there a date convert it in a human readable format.\"\n    })\n    String chat(String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Xinference Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the Langchain4j Xinference community module in a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/xinference.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-xinference</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j OpenAI Official Integration\nDESCRIPTION: This XML snippet shows how to add the Maven dependency for the LangChain4j OpenAI Official integration to your project's pom.xml file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-official</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven BOM for LangChain4j Community Dependencies\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for managing LangChain4j community dependencies consistently.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>${latest version here}</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Enum Description Annotation Example in Java\nDESCRIPTION: Demonstrates the usage of @Description annotations on enum values, noting that these annotations are ignored and not included in the generated JSON schema. Shows example with Priority levels.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_11\n\nLANGUAGE: java\nCODE:\n```\nenum Priority {\n\n    @Description(\"Critical issues such as payment gateway failures or security breaches.\") // this is ignored\n    CRITICAL,\n    \n    @Description(\"High-priority issues like major feature malfunctions or widespread outages.\") // this is ignored\n    HIGH,\n    \n    @Description(\"Low-priority issues such as minor bugs or cosmetic problems.\") // this is ignored\n    LOW\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Generic OpenAI Image Model\nDESCRIPTION: Java code demonstrating how to configure a generic OpenAI image model using environment variables for base URL and API key.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/open-ai-official.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nImageModel model = OpenAiOfficialImageModel.builder()\n        .baseUrl(System.getenv(\"OPENAI_BASE_URL\"))\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(ImageModel.DALL_E_3)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for Plain Java\nDESCRIPTION: XML configuration for adding the langchain4j-azure-open-ai dependency to a plain Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using BOM for Consistent Dependency Management in Maven\nDESCRIPTION: XML configuration for using Bill of Materials (BOM) to manage LangChain4j Community dependencies consistently in a Maven project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/chatglm.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>${latest version here}</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j DashScope Dependency (Before v1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for the DashScope integration with LangChain4j for versions before 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/dashscope.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-dashscope</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Person Class and Assistant Interface Definition\nDESCRIPTION: Example classes for implementing structured outputs with Azure OpenAI.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_9\n\nLANGUAGE: java\nCODE:\n```\ninterface PersonAssistant {\n    Person extractPerson(String message);\n}\n\nclass Person {\n    private final String name;\n    private final List<String> favouriteColors;\n\n    public Person(String name, List<String> favouriteColors) {\n        this.name = name;\n        this.favouriteColors = favouriteColors;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public List<String> getFavouriteColors() {\n        return favouriteColors;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j DashScope Spring Boot Starter (1.0.0-alpha1 and later)\nDESCRIPTION: Maven dependency configuration for integrating DashScope with LangChain4j in Spring Boot applications for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-dashscope-spring-boot-starter</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Cloudflare Workers AI in LangChain4j\nDESCRIPTION: This XML snippet shows the Maven dependency configuration required to include the LangChain4j Cloudflare Workers AI integration in a Java project. It specifies the groupId, artifactId, and version of the required library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/workers-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-workers-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j DashScope Integration (1.0.0-alpha1 and later)\nDESCRIPTION: Maven dependency configuration for integrating DashScope with LangChain4j in plain Java applications for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-dashscope</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Image Content from Base64 Example in Java\nDESCRIPTION: Demonstrates creating ImageContent from Base64-encoded binary data.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/chat-and-language-models.md#2025-04-22_snippet_6\n\nLANGUAGE: java\nCODE:\n```\nbyte[] imageBytes = readBytes(\"/home/me/cat.jpg\");\nString base64Data = Base64.getEncoder().encodeToString(imageBytes);\nImageContent imageContent = ImageContent.from(base64Data, \"image/jpg\");\nUserMessage userMessage = UserMessage.from(imageContent);\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j OpenAI Dependency for Plain Java\nDESCRIPTION: Maven dependency configuration for using OpenAI integration in a plain Java application.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/dall-e.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Including LangChain4j Maven Dependency\nDESCRIPTION: Maven dependency configuration for adding LangChain4j to your project. This dependency provides functionality for file system operations in version 1.0.0-beta3.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/file-system.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Tencent COS Document Loader\nDESCRIPTION: Maven dependency configuration required to use the Tencent COS document loader functionality in LangChain4j. This dependency provides the classes needed to load documents from Tencent Cloud Object Storage.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/tencent-cos.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-tencent-cos</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency for LangChain4j Google Cloud Storage Document Loader\nDESCRIPTION: Maven dependency configuration for integrating the Google Cloud Storage document loader with LangChain4j. This dependency is required to use GCS document loading functionality.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/google-cloud-storage.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-google-cloud-storage</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing GitHub Models Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use GitHub Models integration in a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-github-models</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Azure OpenAI in Spring Boot Properties\nDESCRIPTION: Spring Boot application.properties configuration for Azure OpenAI image model settings including endpoint, API key, deployment name, and various optional parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/azure-dall-e.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.azure-open-ai.image-model.endpoint=https://langchain4j.openai.azure.com/\nlangchain4j.azure-open-ai.image-model.service-version=...\nlangchain4j.azure-open-ai.image-model.api-key=${AZURE_OPENAI_KEY}\nlangchain4j.azure-open-ai.image-model.deployment-name=dall-e-3\nlangchain4j.azure-open-ai.image-model.quality=...\nlangchain4j.azure-open-ai.image-model.size=...\nlangchain4j.azure-open-ai.image-model.user=...\nlangchain4j.azure-open-ai.image-model.style=...\nlangchain4j.azure-open-ai.image-model.response-format=...\nlangchain4j.azure-open-ai.image-model.timeout=...\nlangchain4j.azure-open-ai.image-model.max-retries=...\nlangchain4j.azure-open-ai.image-model.log-requests-and-responses=...\nlangchain4j.azure-open-ai.image-model.user-agent-suffix=...\nlangchain4j.azure-open-ai.image-model.customHeaders=...\n```\n\n----------------------------------------\n\nTITLE: Spring Boot Starter Dependency Configuration (Post-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with Spring Boot applications for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/qianfan.md#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-qianfan-spring-boot-starter</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using Lambda Streaming Response Handlers\nDESCRIPTION: Java example demonstrating the use of lambda-based streaming response handlers for simpler implementation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nmodel.chat(\"Why is the sky blue?\", onPartialResponse(System.out::print));\nmodel.chat(\"Why is the sky blue?\", onPartialResponseAndError(System.out::print, Throwable::printStackTrace));\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j OpenAI Spring Boot Starter\nDESCRIPTION: Maven dependency configuration for using OpenAI integration in a Spring Boot application.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/dall-e.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Starting local development server for LangChain4j documentation\nDESCRIPTION: This command starts a local development server for the LangChain4j documentation and opens a browser window. It supports live reloading for most changes without needing to restart the server.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/README.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run start\n```\n\n----------------------------------------\n\nTITLE: Adding Langchain4j Tablestore Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the Langchain4j Tablestore integration in a Java project. Uses version 1.0.0-beta3 of the langchain4j-tablestore artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/tablestore.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-tablestore</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring GitHub Models for Image Generation\nDESCRIPTION: Java code demonstrating how to configure GitHub-hosted models for image generation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/open-ai-official.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nImageModel model = OpenAiOfficialImageModel.builder()\n        .modelName(ImageModel.DALL_E_3)\n        .isGitHubModels(true)\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding ClickHouse Maven Dependency for LangChain4j\nDESCRIPTION: XML snippet for including the LangChain4j ClickHouse community dependency in a Maven project. This dependency is required to use ClickHouse with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/clickhouse.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-clickhouse</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for ZhiPu AI (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for integrating ZhiPu AI with LangChain4j before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/zhipu-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-zhipu-ai</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Anthropic in LangChain4j\nDESCRIPTION: XML snippet for adding the LangChain4j Anthropic dependency to a Maven project. This dependency is required to use Anthropic models in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-anthropic</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing Google Cloud CLI\nDESCRIPTION: Series of bash commands to download, extract and install Google Cloud SDK CLI tool and set up authentication.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-467.0.0-linux-x86_64.tar.gz\n```\n\nLANGUAGE: bash\nCODE:\n```\ntar -xf google-cloud-cli-467.0.0-linux-x86_64.tar.gz\n```\n\nLANGUAGE: bash\nCODE:\n```\ncd google-cloud-sdk/\n./install.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\ngcloud auth application-default login\n```\n\n----------------------------------------\n\nTITLE: Installing Maven Dependency for Plain Java\nDESCRIPTION: Maven dependency configuration for using Azure OpenAI integration in a plain Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/azure-dall-e.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Dependencies for Maven\nDESCRIPTION: XML snippet for adding LangChain4j and MistralAI dependencies to a Maven project's pom.xml file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-mistral-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Setting GitHub Token Environment Variable\nDESCRIPTION: Bash command to set the GitHub authentication token as an environment variable for use with the GitHub Models API.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/github-models.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GITHUB_TOKEN=\"<your-github-token-goes-here>\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j PGVector Maven Dependency\nDESCRIPTION: Maven dependency configuration for adding LangChain4j PGVector integration to a Java project. Uses version 1.0.0-beta3 of the langchain4j-pgvector artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pgvector.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-pgvector</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j ZhiPu AI Dependency (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for integrating ZhiPu AI with LangChain4j before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/zhipu-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-zhipu-ai</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Spring Boot Starter for Anthropic in Maven\nDESCRIPTION: XML snippet for adding the Spring Boot starter dependency for Anthropic in a Maven project. This is required for Spring Boot integration with Anthropic in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/anthropic.md#2025-04-22_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-anthropic-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Creating OllamaChatModel with Deprecated JSON Format\nDESCRIPTION: Shows how to construct the OllamaChatModel with a deprecated 'format' field set to 'json' in Java. Although functional, it is preferable to use 'responseFormat(ResponseFormat.JSON)' for better maintainability. This snippet should be updated to prevent reliance on deprecated features.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_8\n\nLANGUAGE: java\nCODE:\n```\nOllamaChatModel ollamaChatModel = OllamaChatModel.builder()\n    .baseUrl(\"http://localhost:11434\")\n    .modelName(\"llama3.1\")\n    .format(\"json\")    \n    .temperature(0.8)\n    .timeout(Duration.ofSeconds(60))\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Installing Maven Dependency for OpenAI Official SDK\nDESCRIPTION: Maven dependency configuration required to add the LangChain4j OpenAI Official integration to a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/open-ai-official.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-official</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding SearXNG Web Search Engine Dependency via Maven (Java)\nDESCRIPTION: This XML snippet shows how to include the Langchain4j SearXNG web search engine integration as a dependency in a Maven-managed Java project. To use this web search engine component, add the provided <dependency> block to your project's pom.xml. Required parameters include the groupId, artifactId, and version number; ensure the version matches the intended release. The dependency is necessary for accessing the SearxngWebSearchEngine API and related functionality. No further configuration is needed at this stage, but network connectivity to the SearXNG backend will be required at runtime.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/searxng.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\\n    <groupId>dev.langchain4j</groupId>\\n    <artifactId>langchain4j-community-web-search-engine-searxng</artifactId>\\n    <version>0.36.0</version>\\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Gradle Dependency for Vertex AI Gemini\nDESCRIPTION: Gradle configuration to add langchain4j Vertex AI Gemini dependency to a Gradle project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/google-vertex-ai-gemini.md#2025-04-22_snippet_2\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-vertex-ai-gemini:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Adding Vespa Dependency in Maven for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Vespa dependency to a Maven project. It specifies the groupId, artifactId, and version for the langchain4j-vespa module.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vespa.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-vespa</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependency for Plain Java (Post-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with LangChain4j in plain Java applications for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-qianfan</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Including LangChain4j Maven Dependency for URL Document Loading\nDESCRIPTION: Maven dependency configuration required to use URL document loading functionality in LangChain4j. This dependency provides access to the UrlDocumentLoader class and related utilities.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/url.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LocalAI Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the LocalAI integration dependency for LangChain4j to a Maven project. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/local-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-local-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Neo4j Dependencies for LangChain4j\nDESCRIPTION: Maven dependencies required for integrating Neo4j with LangChain4j. Includes both the core Neo4j connector and the Neo4j retriever module, both at version 1.0.0-beta3.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/neo4j.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-neo4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-neo4j-retriever</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Implementing Web Search Assistant with SearchApi and OpenAI\nDESCRIPTION: Java code example demonstrating how to create a web search assistant using SearchApi and OpenAI integration in LangChain4j. It includes setting up the search engine, chat model, and defining an assistant interface.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/searchapi.md#2025-04-22_snippet_2\n\nLANGUAGE: java\nCODE:\n```\nimport dev.langchain4j.memory.chat.MessageWindowChatMemory;\nimport dev.langchain4j.model.chat.ChatModel;\nimport dev.langchain4j.model.openai.OpenAiChatModel;\nimport dev.langchain4j.model.openai.OpenAiChatModelName;\nimport dev.langchain4j.service.AiServices;\nimport dev.langchain4j.web.search.WebSearchTool;\nimport dev.langchain4j.web.search.searchapi.SearchApiEngine;\nimport dev.langchain4j.web.search.searchapi.SearchApiWebSearchEngine;\n\npublic class SearchApiTool {\n\n    interface Assistant {\n        @SystemMessage({\n                \"You are a web search support agent.\",\n                \"If there is any event that has not happened yet\",\n                \"You MUST create a web search request with user query and\",\n                \"use the web search tool to search the web for organic web results.\",\n                \"Include the source link in your final response.\"\n        })\n        String answer(String userMessage);\n    }\n\n    private static final String SEARCHAPI_API_KEY = \"YOUR_SEARCHAPI_KEY\";\n    private static final String OPENAI_API_KEY = \"YOUR_OPENAI_KEY\";\n\n    public static void main(String[] args) {\n        Map<String, Object> optionalParameters = new HashMap<>();\n        optionalParameters.put(\"gl\", \"us\");\n        optionalParameters.put(\"hl\", \"en\");\n        optionalParameters.put(\"google_domain\", \"google.com\");\n        \n        SearchApiWebSearchEngine searchEngine = SearchApiWebSearchEngine.builder()\n                .apiKey(SEARCHAPI_API_KEY)\n                .engine(\"google\")\n                .optionalParameters(optionalParameters)\n                .build();\n        ChatModel chatModel = OpenAiChatModel.builder()\n                .apiKey(OPENAI_API_KEY)\n                .modelName(OpenAiChatModelName.GPT_3_5_TURBO)\n                .logRequests(true)\n                .build();\n\n        WebSearchTool webTool = WebSearchTool.from(searchEngine);\n\n        Assistant assistant = AiServices.builder(Assistant.class)\n                .chatModel(chatModel)\n                .tools(webTool)\n                .build();\n\n        String answer = assistant.answer(\"My family is coming to visit me in Madrid next week, list the best tourist activities suitable for the whole family\");\n        System.out.println(answer);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Streaming Chat Model in application.properties\nDESCRIPTION: Properties configuration for setting up a streaming chat model in a Spring Boot application. This example shows how to configure the API key for a streaming model.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/spring-boot-integration.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\nlangchain4j.open-ai.streaming-chat-model.api-key=${OPENAI_API_KEY}\n...\n```\n\n----------------------------------------\n\nTITLE: Adding OpenAI Maven Dependency for Spring Boot\nDESCRIPTION: XML configuration to add the LangChain4j OpenAI Spring Boot starter dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Complete Maven Configuration with Coherence Community Edition\nDESCRIPTION: Full Maven configuration showing how to include both LangChain4j Coherence module and Oracle Coherence Community Edition, including the BOM (Bill of Materials) for version management.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/coherence.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.oracle.coherence.ce</groupId>\n            <artifactId>coherence-bom</artifactId>\n            <version>24.09</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n\n<dependencies>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-coherence</artifactId>\n        <version>1.0.0-beta3</version>\n    </dependency>\n    <dependency>\n        <groupId>com.oracle.coherence.ce</groupId>\n        <artifactId>coherence</artifactId>\n    </dependency>\n</dependencies>\n```\n\n----------------------------------------\n\nTITLE: Adding SearchApi Dependency in Gradle\nDESCRIPTION: Groovy snippet for adding the LangChain4j SearchApi dependency to a Gradle project's build.gradle file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/searchapi.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-web-search-engine-searchapi:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j GitHub Document Loader Maven Dependency in XML\nDESCRIPTION: Maven dependency configuration for integrating the LangChain4j GitHub document loader functionality into a Java project. This dependency provides the ability to load documents from GitHub repositories.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/github.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-github</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Langchain4j Azure AI Search Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the Azure AI Search integration module in a Langchain4j project. Uses version 1.0.0-beta3 of the langchain4j-azure-ai-search artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/azure-ai-search.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-ai-search</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Azure CosmosDB NoSQL Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the LangChain4j Azure CosmosDB NoSQL integration in your project. The dependency allows you to use Azure CosmosDB NoSQL as an embedding store with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/azure-cosmos-nosql.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-cosmos-nosql</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Setting MistralAI API Key as Environment Variable\nDESCRIPTION: Shell commands for setting the MistralAI API key as an environment variable in Unix and Windows operating systems.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport MISTRAL_AI_API_KEY=your-api-key #For Unix OS based\nSET MISTRAL_AI_API_KEY=your-api-key #For Windows OS\n```\n\n----------------------------------------\n\nTITLE: Displaying LangChain4j GitHub Commits Summary Output\nDESCRIPTION: Example output showing a structured summary of the last three commits in the LangChain4j GitHub repository. Each commit is formatted with author, message, and details about the changes made.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\nHere are the summaries of the last three commits in the LangChain4j GitHub repository:\n\n1. **Commit [36951f9](https://github.com/langchain4j/langchain4j/commit/36951f9649c1beacd8b9fc2d910a2e23223e0d93)** (Date: 2025-02-05)\n   - **Author:** Dmytro Liubarskyi\n   - **Message:** Updated to `upload-pages-artifact@v3`.\n   - **Details:** This commit updates the GitHub Action used for uploading pages artifacts to version 3.\n\n2. **Commit [6fcd19f](https://github.com/langchain4j/langchain4j/commit/6fcd19f50c8393729a0878d6125b0bb1967ac055)** (Date: 2025-02-05)\n   - **Author:** Dmytro Liubarskyi\n   - **Message:** Updated to `checkout@v4`, `deploy-pages@v4`, and `upload-pages-artifact@v4`.\n   - **Details:** This commit updates multiple GitHub Actions to their version 4.\n\n3. **Commit [2e74049](https://github.com/langchain4j/langchain4j/commit/2e740495d2aa0f16ef1c05cfcc76f91aef6f6599)** (Date: 2025-02-05)\n   - **Author:** Dmytro Liubarskyi\n   - **Message:** Updated to `setup-node@v4` and `configure-pages@v4`.\n   - **Details:** This commit updates the `setup-node` and `configure-pages` GitHub Actions to version 4.\n\nAll commits were made by the same author, Dmytro Liubarskyi, on the same day, focusing on updating various GitHub Actions to newer versions.\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Dependencies for Gradle\nDESCRIPTION: Groovy snippet for adding LangChain4j and MistralAI dependencies to a Gradle project's build.gradle file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/mistral-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j:1.0.0-beta3'\nimplementation 'dev.langchain4j:langchain4j-mistral-ai:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependency for LangChain4j Vearch (0.36.2 and previous)\nDESCRIPTION: Maven dependency configuration for the legacy langchain4j-vearch module for versions 0.36.2 and previous. This adds the Vearch integration to a LangChain4j project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-vearch</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Chroma Maven Dependency for Langchain4j\nDESCRIPTION: Maven dependency configuration to include the Langchain4j Chroma integration in a Java project. This dependency provides the necessary classes to work with Chroma as an embedding store within the Langchain4j framework.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/chroma.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-chroma</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Google Cloud Vertex AI Ranking in Java\nDESCRIPTION: This XML snippet shows the Maven dependency required to use the Google Cloud Vertex AI Ranking API in a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/vertex-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-vertex-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring LangChain4j BOM in Maven\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for version management of LangChain4j dependencies.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_3\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>dev.langchain4j</groupId>\n            <artifactId>langchain4j-bom</artifactId>\n            <version>1.0.0-beta3</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Redis dependency for Plain Java in LangChain4j (pre-1.0.0-beta1)\nDESCRIPTION: Maven dependency configuration for integrating Redis with LangChain4j in plain Java applications, for versions before 1.0.0-beta1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/redis.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-redis</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Kotlin Compiler for Java Reflection Compatibility\nDESCRIPTION: Gradle configuration snippet to set javaParameters to true, ensuring Kotlin compilation preserves metadata for Java reflection on method parameters.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/kotlin.md#2025-04-22_snippet_4\n\nLANGUAGE: kotlin\nCODE:\n```\nkotlin {\n    compilerOptions {\n        javaParameters = true\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Hugging Face Dependencies with Maven\nDESCRIPTION: Maven dependency configuration for adding langchain4j Hugging Face integration to a Java project. Uses version 1.0.0-beta3 of the langchain4j-hugging-face artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/hugging-face.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-hugging-face</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Cohere Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Cohere integration in a Maven project. It specifies the groupId, artifactId, and version for the dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/cohere.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-cohere</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for AlloyDB PostgreSQL Integration\nDESCRIPTION: Maven dependency configuration required to use the AlloyDB PostgreSQL integration with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/alloydb.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artificatId>langchain4j-community-alloydb-pg</artificatId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding SearchApi Dependency in Maven\nDESCRIPTION: XML snippet for adding the LangChain4j SearchApi dependency to a Maven project's pom.xml file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/searchapi.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>dev.langchain4j</groupId>\n  <artifactId>langchain4j-web-search-engine-searchapi</artifactId>\n  <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Vertex AI Integration\nDESCRIPTION: Maven dependency configuration to include langchain4j-vertex-ai library in a project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/google-vertex-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n  <groupId>dev.langchain4j</groupId>\n  <artifactId>langchain4j-vertex-ai</artifactId>\n  <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring SNAPSHOT Dependencies in Maven\nDESCRIPTION: Maven configuration for using SNAPSHOT versions of LangChain4j to access newest features.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/get-started.md#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<repositories>\n    <repository>\n        <id>snapshots-repo</id>\n        <url>https://s01.oss.sonatype.org/content/repositories/snapshots</url>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n\n<dependencies>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j</artifactId>\n        <version>1.0.0-beta4-SNAPSHOT</version>\n    </dependency>\n</dependencies>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Workers AI Dependency in Maven\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Workers AI dependency in a Maven project. It specifies the groupId, artifactId, and version for the required library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/workers-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-workers-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Alternative JsonObjectSchema Property Configuration\nDESCRIPTION: Demonstrates alternative methods for adding properties to JsonObjectSchema.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/structured-outputs.md#2025-04-22_snippet_3\n\nLANGUAGE: java\nCODE:\n```\nJsonSchemaElement rootElement = JsonObjectSchema.builder()\n        .addProperty(\"city\", citySchema)\n        .addProperty(\"temperatureUnit\", temperatureUnitSchema)\n        .required(\"city\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Maven Dependencies Configuration for Ollama Integration\nDESCRIPTION: Required Maven dependencies for integrating Ollama and TestContainers with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/ollama.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-ollama</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>org.testcontainers</groupId>\n    <artifactId>ollama</artifactId>\n    <version>1.19.1</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for ZhiPu AI (1.0.0-alpha1 and later)\nDESCRIPTION: Updated Maven dependency configuration for ZhiPu AI integration after the package was renamed and migrated to langchain4j-community.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/zhipu-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-zhipu-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven BOM for LangChain4j Community\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for managing dependencies consistently across a LangChain4j project. This ensures compatible versions of all LangChain4j community components.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/vearch.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Tavily Web Search Engine Maven Dependency\nDESCRIPTION: This XML snippet defines the Maven dependency required to include the Langchain4j Tavily web search engine integration in a Java project. It specifies the group ID (`dev.langchain4j`), artifact ID (`langchain4j-web-search-engine-tavily`), and version (`1.0.0-beta3`). Adding this dependency allows the project to utilize the `TavilyWebSearchEngine` class for web search capabilities.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/web-search-engines/tavily.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-web-search-engine-tavily</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Community ZhiPu AI Dependency (1.0.0-alpha1 and later)\nDESCRIPTION: Maven dependency configuration for integrating ZhiPu AI with LangChain4j for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/zhipu-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-zhipu-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using BOM for Dependency Management in Maven\nDESCRIPTION: This snippet demonstrates the use of BOM in Maven to manage dependencies consistently across a project. The BOM ensures that all modules use compatible versions. It specifies the groupId, artifactId, version, type, and scope for the BOM file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/xinference.md#2025-04-22_snippet_1\n\nLANGUAGE: XML\nCODE:\n```\n<dependencyManagement>\\n    <dependency>\\n        <groupId>dev.langchain4j</groupId>\\n        <artifactId>langchain4j-community-bom</artifactId>\\n        <version>0.37.0</version>\\n        <typ>pom</typ>\\n        <scope>import</scope>\\n    </dependency>\\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Amazon S3 Document Loader in LangChain4j\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Amazon S3 document loader dependency in a Maven project. It specifies the groupId, artifactId, and version of the required library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/amazon-s3.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-amazon-s3</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring OVHcloud AI API Key in Java\nDESCRIPTION: Java code snippet showing how to access the OVHcloud AI API key from system environment variables.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/ovh-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\npublic static final String OVHAI_AI_API_KEY = System.getenv(\"OVHAI_AI_API_KEY\");\n```\n\n----------------------------------------\n\nTITLE: Adding Azure OpenAI Maven Dependency for Spring Boot\nDESCRIPTION: Maven dependency configuration required to use the Azure OpenAI integration with Spring Boot applications.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/azure-open-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Moderation Model in Spring Boot Properties\nDESCRIPTION: Application properties configuration for OpenAI moderation model in Spring Boot, including mandatory properties.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai.md#2025-04-22_snippet_11\n\nLANGUAGE: properties\nCODE:\n```\n# Mandatory properties:\nlangchain4j.open-ai.moderation-model.api-key=${OPENAI_API_KEY}\nlangchain4j.open-ai.moderation-model.model-name=text-moderation-stable\n```\n\n----------------------------------------\n\nTITLE: Using BOM for consistent dependency management in LangChain4j\nDESCRIPTION: Maven configuration for using Bill of Materials (BOM) to manage LangChain4j community dependencies consistently across the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/redis.md#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>${latest version here}</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4J and Jlama Dependencies in Maven\nDESCRIPTION: Maven configuration to add LangChain4J and Jlama dependencies to a project. Includes core LangChain4J, Jlama integration, and optional native Jlama library with OS-specific classifiers for faster inference.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/jlama.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-jlama</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n\n<dependency>\n    <groupId>com.github.tjake</groupId>\n    <artifactId>jlama-native</artifactId>\n    <!-- for faster inference. supports linux-x86_64, macos-x86_64/aarch_64, windows-x86_64 \n        Use https://github.com/trustin/os-maven-plugin to detect os and arch -->\n    <classifier>${os.detected.name}-${os.detected.arch}</classifier>\n    <version>${jlama.version}</version> <!-- Version from langchain4j-jlama pom -->\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Milvus Dependency in Maven for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Milvus dependency to a Maven project. It specifies the groupId, artifactId, and version for the Milvus integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/milvus.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-milvus</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Xinference Maven Dependency for LangChain4j\nDESCRIPTION: Maven dependency configuration for including LangChain4j Xinference integration in version 1.0.0-beta3.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/xinference.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-xinference</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for OVHcloud AI Integration\nDESCRIPTION: Maven dependency configuration needed to integrate OVHcloud AI functionality into a LangChain4j project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/ovh-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-ovh-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using Custom Variable Names in AI Service User Message\nDESCRIPTION: Shows how to use the @V annotation to assign custom names to template variables in the user message.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_7\n\nLANGUAGE: java\nCODE:\n```\ninterface Friend {\n\n    @UserMessage(\"You are a good friend of mine. Answer using slang. {{message}}\")\n    String chat(@V(\"message\") String userMessage);\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j ChatGLM (Pre-1.0.0-alpha1)\nDESCRIPTION: XML configuration for adding the LangChain4j ChatGLM dependency to a Maven project before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/chatglm.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-chatglm</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding langchain4j-easy-rag Dependency in Maven\nDESCRIPTION: XML snippet for adding the langchain4j-easy-rag dependency to a Maven project. This dependency is required for using the Easy RAG feature in LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/rag.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-easy-rag</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Logback Dependency in Maven\nDESCRIPTION: This XML snippet demonstrates how to add the Logback dependency to your Maven project for SLF4J logging backend.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/logging.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>ch.qos.logback</groupId>\n    <artifactId>logback-classic</artifactId>\n    <version>1.5.8</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Key\nDESCRIPTION: Shell commands for setting the MistralAI API key as an environment variable in different operating systems.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/mistral-ai.md#2025-04-22_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nexport MISTRAL_AI_API_KEY=your-api-key #For Unix OS based\nSET MISTRAL_AI_API_KEY=your-api-key #For Windows OS\n```\n\n----------------------------------------\n\nTITLE: Maven BOM Configuration for Dependency Management\nDESCRIPTION: Maven Bill of Materials (BOM) configuration for consistent dependency management across the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/zhipu-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Xinference Maven Dependency\nDESCRIPTION: Maven dependency configuration for including the Langchain4j Xinference integration in version 1.0.0-beta3.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/xinference.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-xinference</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j DashScope Integration (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for integrating DashScope with LangChain4j in plain Java applications before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/dashscope.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-dashscope</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Judge0 Maven Dependency for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the Judge0 code execution engine dependency for LangChain4j to a Maven project. It specifies the group ID, artifact ID, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/code-execution-engines/judge0.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-code-execution-engine-judge0</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Apache Tika Document Parser Dependency in Maven for LangChain4j\nDESCRIPTION: This XML snippet shows how to add the Apache Tika document parser dependency to a Maven project for use with LangChain4j. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-parsers/apache-tika.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-parser-apache-tika</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j Cohere Integration\nDESCRIPTION: Maven dependency configuration required to add Cohere support to a LangChain4j project. This dependency provides the necessary classes and methods to interact with Cohere's API.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/cohere.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-cohere</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using LangChain4j Community BOM for Dependency Management\nDESCRIPTION: Maven configuration using BOM (Bill of Materials) to manage LangChain4j Community dependencies consistently, including the DashScope integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/dashscope.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>${latest version here}</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Using System Message Provider in Java AI Service\nDESCRIPTION: Shows how to use a system message provider to dynamically set the system message based on chat memory ID.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/ai-services.md#2025-04-22_snippet_5\n\nLANGUAGE: java\nCODE:\n```\nFriend friend = AiServices.builder(Friend.class)\n    .chatModel(model)\n    .systemMessageProvider(chatMemoryId -> \"You are a good friend of mine. Answer using slang.\")\n    .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Voyage AI Maven Dependency for LangChain4j\nDESCRIPTION: Maven dependency configuration for integrating Voyage AI with LangChain4j. This dependency provides access to the Voyage AI embedding model implementation.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/voyage-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-voyage-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j and Jlama Dependencies in Gradle\nDESCRIPTION: Gradle configuration for adding LangChain4j and Jlama dependencies to a Gradle project. Includes both core LangChain4j and Jlama integration libraries.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/jlama.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j:{your-version}'\nimplementation 'dev.langchain4j:langchain4j-jlama:{your-version}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Maven Dependency for Plain Java (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with LangChain4j in plain Java applications before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/qianfan.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-qianfan</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Activating Node.js version with NVM for LangChain4j docs\nDESCRIPTION: If Node.js is managed by Node Version Manager (nvm), this command activates the appropriate Node.js version for the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/README.md#2025-04-22_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnvm use\n```\n\n----------------------------------------\n\nTITLE: Installing langchain4j-oracle via Maven Dependency - XML\nDESCRIPTION: This XML snippet demonstrates how to include the langchain4j-oracle library as a Maven dependency, required for enabling Oracle Database-backed EmbeddingStore operations in Java. Specify the groupId, artifactId, and version in your pom.xml. Ensure the Oracle Database and Java application meet the compatibility requirements.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j-oracle/README.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\\n    <groupId>dev.langchain4j</groupId>\\n    <artificatId>langchain4j-oracle</artificatId>\\n    <version>0.1.0</version>\\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Jina Reranker Maven Dependency in XML\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Jina dependency to a Maven project. It specifies the groupId, artifactId, and version for the Jina integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/jina-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-jina</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for ZhiPu AI Pre-1.0.0-alpha1\nDESCRIPTION: Maven dependency configuration for integrating ZhiPu AI with LangChain4j before version 1.0.0-alpha1 using the langchain4j-zhipu-ai artifact.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/zhipu-ai.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-zhipu-ai</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding CPU-based ONNX Scoring Dependency in Maven\nDESCRIPTION: XML configuration to add the LangChain4j ONNX scoring dependency for CPU-based usage.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/in-process.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-onnx-scoring</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing GitHub Models Maven Dependency\nDESCRIPTION: Maven dependency configuration required to use GitHub Models with LangChain4j in a plain Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/github-models.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-github-models</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Community BOM Dependency\nDESCRIPTION: Maven dependency management configuration for using BOM to manage LangChain4j Community dependencies consistently.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/zhipu-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Azure Identity Dependency for Passwordless Authentication\nDESCRIPTION: This XML snippet shows how to add the Azure Identity dependency to your Maven pom.xml file for passwordless authentication with Azure OpenAI.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/open-ai-official.md#2025-04-22_snippet_5\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>com.azure</groupId>\n    <artifactId>azure-identity</artifactId>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for Plain Java (Post-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with LangChain4j in plain Java applications for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/qianfan.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-qianfan</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Implementing AlloyDB Embedding Store Operations\nDESCRIPTION: Complete example demonstrating the setup and usage of AlloyDBEmbeddingStore, including initialization, adding embeddings, searching, and removing entries. Shows integration with embedding model and handling of metadata.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/alloydb.md#2025-04-22_snippet_1\n\nLANGUAGE: java\nCODE:\n```\nAlloyDBEngine engine = new AlloyDBEngine.Builder()\n    .projectId(\"\")\n    .region(\"\")\n    .cluster(\"\")\n    .instance(\"\")\n    .database(\"\")\n    .build();\n\nAlloyDBEmbeddingStore store = new AlloyDBEmbeddingStore.Builder(engine, TABLE_NAME)\n    .build();\n\nList<String> testTexts = Arrays.asList(\"cat\", \"dog\", \"car\", \"truck\");\nList<Embedding> embeddings = new ArrayList<>();\nList<TextSegment> textSegments = new ArrayList<>();\nEmbeddingModel embeddingModel = new AllMiniLmL6V2EmbeddingModel();\n\nfor (String text : testTexts) {\n    Map<String, Object> metaMap = new HashMap<>();\n    metaMap.put(\"my_metadata\", \"string\");\n    Metadata metadata = new Metadata(metaMap);\n    textSegments.add(new TextSegment(text, metadata));\n    embeddings.add(MyEmbeddingModel.embed(text).content());\n}\nList<String> ids = store.addAll(embeddings, textSegments);\n// search for \"cat\"\nEmbeddingSearchRequest request = EmbeddingSearchRequest.builder()\n        .queryEmbedding(embeddings.get(0))\n        .maxResults(10)\n        .minScore(0.9)\n        .build();\nList<EmbeddingMatch<TextSegment>> result = store.search(request).matches();\n// remove \"cat\"\nstore.removeAll(singletonList(result.get(0).embeddingId()));\n```\n\n----------------------------------------\n\nTITLE: BOM Dependency Management Configuration\nDESCRIPTION: Maven BOM (Bill of Materials) configuration for consistent dependency management across the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/qianfan.md#2025-04-22_snippet_4\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>${latest version here}</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Basic Markdown Structure\nDESCRIPTION: Front matter and markdown configuration for the documentation page structure.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/intro.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\nsidebar_position: 1\ntitle: Introduction\n---\n```\n\n----------------------------------------\n\nTITLE: Spring Boot Starter Dependency Configuration (Pre-1.0.0-alpha1)\nDESCRIPTION: Maven dependency configuration for using Qianfan with Spring Boot applications before version 1.0.0-alpha1.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/qianfan.md#2025-04-22_snippet_2\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-qianfan-spring-boot-starter</artifactId>\n    <version>${previous version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Xinference Dependency in Maven\nDESCRIPTION: This snippet shows how to add the Xinference dependency to a Maven project, specifying the groupId, artifactId, and version. It is essential for accessing the Xinference functionality within the Langchain4j library, starting from version 0.37.0.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/scoring-reranking-models/xinference.md#2025-04-22_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<dependency>\\n    <groupId>dev.langchain4j</groupId>\\n    <artifactId>langchain4j-community-xinference</artifactId>\\n    <version>0.37.0</version>\\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j Community ChatGLM (1.0.0-alpha1 and later)\nDESCRIPTION: XML configuration for adding the LangChain4j Community ChatGLM dependency to a Maven project for version 1.0.0-alpha1 and later.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/chatglm.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-chatglm</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Jackson Module Kotlin Dependency in Maven\nDESCRIPTION: XML snippet showing how to add the Jackson Module Kotlin dependency to a Maven project for runtime use with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/kotlin.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>com.fasterxml.jackson.module</groupId>\n    <artifactId>jackson-module-kotlin</artifactId>\n    <version>[LATEST_VERSION]</version>\n    <scope>runtime</scope>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Maven Dependency\nDESCRIPTION: This XML snippet shows how to include the LangChain4j library as a dependency in a Maven project. It specifies the groupId, artifactId, and version of the library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/classpath.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Setting OVHcloud AI API Key as Environment Variable\nDESCRIPTION: Shell commands for setting the OVHcloud AI API key as an environment variable in Unix-based and Windows operating systems.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/ovh-ai.md#2025-04-22_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nexport OVHAI_AI_API_KEY=your-api-key #For Unix OS based\nSET OVHAI_AI_API_KEY=your-api-key #For Windows OS\n```\n\n----------------------------------------\n\nTITLE: Adding Redis dependency for Plain Java in LangChain4j (1.0.0-beta1 and later)\nDESCRIPTION: Maven dependency configuration for integrating Redis with LangChain4j in plain Java applications, for version 1.0.0-beta1 and later which uses the community package.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/redis.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-community-redis</artifactId>\n    <version>${latest version here}</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging in Quarkus application.properties\nDESCRIPTION: This properties snippet shows how to configure logging for LangChain4j in a Quarkus application using the application.properties file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/logging.md#2025-04-22_snippet_2\n\nLANGUAGE: properties\nCODE:\n```\n...\nquarkus.langchain4j.openai.chat-model.log-requests = true\nquarkus.langchain4j.openai.chat-model.log-responses = true\nquarkus.log.console.enable = true\nquarkus.log.file.enable = false\n```\n\n----------------------------------------\n\nTITLE: Adding Mariadb Vector Dependency for LangChain4j in Maven\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Mariadb integration dependency in a Maven project. It specifies the groupId, artifactId, and version for the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mariadb.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-mariadb</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Using Template Placeholder for Recipe Input\nDESCRIPTION: This snippet features the `{{it}}` placeholder, commonly used in templating engines like Mustache. Within the context of Langchain4j prompt templates, `{{it}}` typically represents the primary input variable provided to the template. Here, it likely serves to insert specific ingredients or constraints into the recipe generation prompt.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j/src/test/resources/dev/langchain4j/service/chefs-prompt-based-on-ingredients.txt#2025-04-22_snippet_0\n\nLANGUAGE: Template\nCODE:\n```\n{{it}}\n```\n\n----------------------------------------\n\nTITLE: Adding Azure CosmosDB Mongo vCore Dependency in Maven\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Azure CosmosDB Mongo vCore dependency in a Maven project. It specifies the groupId, artifactId, and version of the required dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/azure-cosmos-mongo-vcore.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-cosmos-mongo-vcore</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j PGVector Gradle Dependency\nDESCRIPTION: Gradle dependency configuration for adding LangChain4j PGVector integration to a Java project. Uses version 1.0.0-beta3 of the langchain4j-pgvector library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pgvector.md#2025-04-22_snippet_1\n\nLANGUAGE: groovy\nCODE:\n```\nimplementation 'dev.langchain4j:langchain4j-pgvector:1.0.0-beta3'\n```\n\n----------------------------------------\n\nTITLE: Adding Oracle Embedding Store Maven Dependency\nDESCRIPTION: Maven dependency configuration needed to use the Oracle Embedding Store with Langchain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/oracle.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-oracle</artifactId>\n    <version>1.0.0-beta3</version>\n\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Qdrant Dependency in Maven\nDESCRIPTION: Maven dependency configuration for including the LangChain4j Qdrant integration in a Java project. This dependency provides the necessary classes to connect to and work with Qdrant vector database.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/qdrant.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-qdrant</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Pinecone Maven Dependency\nDESCRIPTION: XML snippet showing how to add the LangChain4j Pinecone integration dependency to a Maven project. This dependency is required for using Pinecone as an embedding store in a Java application with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/pinecone.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-pinecone</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j MongoDB Dependencies\nDESCRIPTION: Maven dependencies required for integrating LangChain4j with MongoDB Atlas and Voyage AI for embeddings\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/mongodb-atlas.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-mongodb-atlas</artifactId>\n</dependency>\n<dependency>\n    <groupId>org.mongodb</groupId>\n    <artifactId>mongodb-driver-sync</artifactId>\n    <version>5.4.0</version>\n</dependency>\n```\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-voyage-ai</artifactId>\n</dependency>\n```\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <type>pom</type>\n    </dependency>\n</dependencyManagement>\n```\n\n----------------------------------------\n\nTITLE: Adding Apache POI Document Parser Dependency in Maven\nDESCRIPTION: This XML snippet shows how to add the Apache POI document parser dependency to a Maven project. It specifies the groupId, artifactId, and version for the LangChain4j Apache POI integration.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-parsers/apache-poi.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-parser-apache-poi</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Basic LangChain4j Coherence Dependency in Maven\nDESCRIPTION: Maven configuration for adding the LangChain4j Coherence module to your project. This is the basic dependency that needs to be included.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/coherence.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-coherence</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding LangChain4j Ollama Dependency in Maven\nDESCRIPTION: This XML snippet shows how to add the LangChain4j Ollama dependency to a Maven project. It specifies the groupId, artifactId, and version for the langchain4j-ollama library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/ollama.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-ollama</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding AllMiniLmL6V2 Embedding Model Dependency to Maven Project\nDESCRIPTION: Maven dependency configuration for including the original AllMiniLmL6V2 embedding model in your project. This adds the non-quantized version of the model to your dependencies.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/1-in-process.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-embeddings-all-minilm-l6-v2</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Illustrating Ignored @Description on Enum Values in Java\nDESCRIPTION: Shows an example of using @Description on enum constants. It highlights that descriptions placed on enum values using this annotation are ignored and not included in the generated JSON schema for the LLM.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/tools.md#2025-04-22_snippet_10\n\nLANGUAGE: java\nCODE:\n```\nenum Priority {\n\n    @Description(\"Critical issues such as payment gateway failures or security breaches.\") // this is ignored\n    CRITICAL,\n    \n    @Description(\"High-priority issues like major feature malfunctions or widespread outages.\") // this is ignored\n    HIGH,\n    \n    @Description(\"Low-priority issues such as minor bugs or cosmetic problems.\") // this is ignored\n    LOW\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Azure Blob Storage in LangChain4j\nDESCRIPTION: XML configuration for adding the LangChain4j Azure Blob Storage document loader dependency to a Maven project. This dependency is required to use Azure Blob Storage integration with LangChain4j.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/document-loaders/azure-blob-storage.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-document-loader-azure-storage-blob</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for Cloud SQL PostgreSQL Integration\nDESCRIPTION: Maven dependency configuration required to use the Cloud SQL PostgreSQL integration library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-stores/cloud-sql.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artificatId>langchain4j-community-cloud-sql-pg</artificatId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Customizing JDK HttpClient for LangChain4j OpenAI Integration\nDESCRIPTION: Demonstrates how to customize the JDK HttpClient builder for use with OpenAI chat model. Shows configuration of SSL context and integration with the OpenAiChatModel builder.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/customizable-http-client.md#2025-04-22_snippet_0\n\nLANGUAGE: java\nCODE:\n```\nHttpClient.Builder httpClientBuilder = HttpClient.newBuilder()\n        .sslContext(...);\n\nJdkHttpClientBuilder jdkHttpClientBuilder = JdkHttpClient.builder()\n        .httpClientBuilder(httpClientBuilder);\n\nOpenAiChatModel model = OpenAiChatModel.builder()\n        .httpClientBuilder(jdkHttpClientBuilder)\n        .apiKey(System.getenv(\"OPENAI_API_KEY\"))\n        .modelName(\"gpt-4o-mini\")\n        .build();\n```\n\n----------------------------------------\n\nTITLE: Adding Maven Dependency for LangChain4j Vertex AI Integration\nDESCRIPTION: This XML snippet shows how to include the LangChain4j Vertex AI dependency in a Maven project. It specifies the group ID, artifact ID, and version number for the required library.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/imagen.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-vertex-ai</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for GitHub MCP Server\nDESCRIPTION: This bash snippet demonstrates how to build a Docker image for the GitHub MCP server from a Dockerfile. The setup is intended for running the server locally to interact with GitHub through MCP.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/mcp.md#2025-04-22_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\ndocker build -t mcp/github -f src/github/Dockerfile .\n```\n\n----------------------------------------\n\nTITLE: Building static artifacts for LangChain4j documentation\nDESCRIPTION: This command builds the deployable static artifacts (html, js, css, etc) for the LangChain4j documentation under the 'build' directory, ready for deployment to platforms like GitHub Pages or Vercel.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Configuring Logging in Spring Boot application.properties\nDESCRIPTION: This properties snippet demonstrates how to configure logging for LangChain4j in a Spring Boot application using the application.properties file.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/tutorials/logging.md#2025-04-22_snippet_3\n\nLANGUAGE: properties\nCODE:\n```\n...\nlangchain4j.open-ai.chat-model.log-requests = true\nlangchain4j.open-ai.chat-model.log-responses = true\nlogging.level.dev.langchain4j = DEBUG\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain4j Bedrock Maven Dependency\nDESCRIPTION: Maven dependency configuration required to add LangChain4j Bedrock support to a Java project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/embedding-models/amazon-bedrock.md#2025-04-22_snippet_0\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-bedrock</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing Node dependencies for LangChain4j documentation\nDESCRIPTION: This command installs all the required Node.js dependencies for the LangChain4j documentation project using npm.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm ci\n```\n\n----------------------------------------\n\nTITLE: Setting GitHub Token Environment Variable\nDESCRIPTION: Bash command to set the GitHub authentication token as an environment variable.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/github-models.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GITHUB_TOKEN=\"<your-github-token-goes-here>\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Local Maven Repository in pom.xml\nDESCRIPTION: This XML snippet shows how to add a local folder as a Maven repository in the project's pom.xml file. It's used to include the test JAR file for ClassPath document loading tests.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/langchain4j/src/test/externalLib/README.md#2025-04-22_snippet_0\n\nLANGUAGE: XML\nCODE:\n```\n<repositories>\n  <!-- Local repository configuration -->\n</repositories>\n```\n\n----------------------------------------\n\nTITLE: Maven Dependency Configuration for Spring Boot\nDESCRIPTION: XML configuration for adding the langchain4j-azure-open-ai Spring Boot starter dependency.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/language-models/azure-open-ai.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Installing Maven Dependency for Spring Boot\nDESCRIPTION: Maven dependency configuration for using Azure OpenAI integration in a Spring Boot project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/azure-dall-e.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependency>\n    <groupId>dev.langchain4j</groupId>\n    <artifactId>langchain4j-azure-open-ai-spring-boot-starter</artifactId>\n    <version>1.0.0-beta3</version>\n</dependency>\n```\n\n----------------------------------------\n\nTITLE: Configuring Xinference BOM Dependency Management\nDESCRIPTION: Maven BOM (Bill of Materials) configuration for managing Langchain4j dependencies consistently across the project.\nSOURCE: https://github.com/langchain4j/langchain4j/blob/main/docs/docs/integrations/image-models/xinference.md#2025-04-22_snippet_1\n\nLANGUAGE: xml\nCODE:\n```\n<dependencyManagement>\n    <dependency>\n        <groupId>dev.langchain4j</groupId>\n        <artifactId>langchain4j-community-bom</artifactId>\n        <version>1.0.0-beta3</version>\n        <typ>pom</typ>\n        <scope>import</scope>\n    </dependency>\n</dependencyManagement>\n```"
  }
]