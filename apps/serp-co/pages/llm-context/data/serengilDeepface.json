[
  {
    "owner": "serengil",
    "repo": "deepface",
    "content": "TITLE: Performing Face Verification with DeepFace in Python\nDESCRIPTION: This code snippet demonstrates how to use DeepFace for face verification. It calculates the similarity between two face embeddings and determines if they belong to the same person based on a threshold.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(\"same person\" if calculated_similarity >= 1 - threshold else \"different persons\")\n```\n\n----------------------------------------\n\nTITLE: Face Verification with DeepFace\nDESCRIPTION: Verifies if two face images belong to the same person using the verify function.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nresult = DeepFace.verify(img1_path = \"img1.jpg\", img2_path = \"img2.jpg\")\n```\n\n----------------------------------------\n\nTITLE: Face Recognition in Database\nDESCRIPTION: Searches for a face in a database of images and returns matching results as pandas dataframes.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndfs = DeepFace.find(img_path = \"img1.jpg\", db_path = \"C:/my_db\")\n```\n\n----------------------------------------\n\nTITLE: Extracting Face Embeddings\nDESCRIPTION: Generates facial embedding vectors for given face images using various models.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nembedding_objs = DeepFace.represent(img_path = \"img.jpg\")\n```\n\n----------------------------------------\n\nTITLE: Facial Attribute Analysis\nDESCRIPTION: Analyzes facial attributes including age, gender, race, and emotion from face images.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nobjs = DeepFace.analyze(\n  img_path = \"img4.jpg\", actions = ['age', 'gender', 'race', 'emotion']\n)\n```\n\n----------------------------------------\n\nTITLE: Using Different Face Recognition Models\nDESCRIPTION: Demonstrates how to use different pre-trained models for face recognition tasks.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodels = [\n    \"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\",\n    \"DeepID\", \"ArcFace\", \"Dlib\", \"SFace\", \"GhostFaceNet\",\n    \"Buffalo_L\",\n]\n\nresult = DeepFace.verify(\n  img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", model_name = models[0]\n)\n\ndfs = DeepFace.find(\n  img_path = \"img1.jpg\", db_path = \"C:/my_db\", model_name = models[1]\n)\n\nembeddings = DeepFace.represent(\n  img_path = \"img.jpg\", model_name = models[2]\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Similarity Metrics\nDESCRIPTION: Shows how to use different similarity metrics for face comparison.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmetrics = [\"cosine\", \"euclidean\", \"euclidean_l2\", \"angular\"]\n\nresult = DeepFace.verify(\n  img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", distance_metric = metrics[1]\n)\n\ndfs = DeepFace.find(\n  img_path = \"img1.jpg\", db_path = \"C:/my_db\", distance_metric = metrics[2]\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Detection Backends and Alignment in DeepFace\nDESCRIPTION: Shows how to set detector backend and alignment parameters in various DeepFace functions including verify, find, represent, analyze, and extract_faces. The example demonstrates setting MTCNN as the detector with alignment enabled.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nbackends = [\n    'opencv', 'ssd', 'dlib', 'mtcnn', 'fastmtcnn',\n    'retinaface', 'mediapipe', 'yolov8', 'yolov11s',\n    'yolov11n', 'yolov11m', 'yunet', 'centerface',\n]\ndetector = backends[3]\nalign = True\n\nobj = DeepFace.verify(\n  img1_path = \"img1.jpg\", img2_path = \"img2.jpg\", detector_backend = detector, align = align\n)\n\ndfs = DeepFace.find(\n  img_path = \"img.jpg\", db_path = \"my_db\", detector_backend = detector, align = align\n)\n\nembedding_objs = DeepFace.represent(\n  img_path = \"img.jpg\", detector_backend = detector, align = align\n)\n\ndemographies = DeepFace.analyze(\n  img_path = \"img4.jpg\", detector_backend = detector, align = align\n)\n\nface_objs = DeepFace.extract_faces(\n  img_path = \"img.jpg\", detector_backend = detector, align = align\n)\n```\n\n----------------------------------------\n\nTITLE: Running Real-Time Face Analysis with DeepFace\nDESCRIPTION: Demonstrates how to use DeepFace's stream function to perform real-time face recognition and analysis using a webcam. The function takes a database path as input to recognize faces.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nDeepFace.stream(db_path = \"C:/database\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Face Anti-Spoofing in DeepFace\nDESCRIPTION: Demonstrates how to activate DeepFace's anti-spoofing feature to detect fake images. The code shows how to enable anti-spoofing in both face extraction and real-time analysis functions.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# anti spoofing test in face detection\nface_objs = DeepFace.extract_faces(img_path=\"dataset/img1.jpg\", anti_spoofing = True)\nassert all(face_obj[\"is_real\"] is True for face_obj in face_objs)\n\n# anti spoofing test in real time analysis\nDeepFace.stream(db_path = \"C:/database\", anti_spoofing = True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Homomorphic Encryption for Face Embeddings\nDESCRIPTION: Demonstrates using homomorphic encryption to secure face embeddings while still allowing similarity calculations. This example uses the LightPHE library with the Paillier algorithm to encrypt embeddings and compute similarity scores.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom lightphe import LightPHE\n\n# build an additively homomorphic cryptosystem (e.g. Paillier) on-prem\ncs = LightPHE(algorithm_name = \"Paillier\", precision = 19)\n\n# define plain vectors for source and target\nalpha = DeepFace.represent(\"img1.jpg\")[0][\"embedding\"]\nbeta = DeepFace.represent(\"target.jpg\")[0][\"embedding\"]\n\n# encrypt source embedding on-prem - private key not required\nencrypted_alpha = cs.encrypt(alpha)\n\n# dot product of encrypted & plain embedding in cloud - private key not required\nencrypted_cosine_similarity = encrypted_alpha @ beta\n\n# decrypt similarity on-prem - private key required\ncalculated_similarity = cs.decrypt(encrypted_cosine_similarity)[0]\n```\n\n----------------------------------------\n\nTITLE: Running DeepFace API Server\nDESCRIPTION: Shows how to start the DeepFace API service using either direct execution or Docker. The API provides endpoints for face verification, analysis, and representation.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ncd script\n\n# run the service directly\n./service.sh\n\n# run the service via docker\n./dockerize.sh\n```\n\n----------------------------------------\n\nTITLE: Executing DeepFace Verification Experiments\nDESCRIPTION: Runs face verification experiments using all combinations of models, detectors, distance metrics, and alignment options. For each configuration, it calculates distances between face pairs and saves results to CSV files.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfor model_name in models:\n    for detector_backend in detectors:\n        for distance_metric in metrics:\n            for align in alignment:\n                \n                if detector_backend == \"skip\" and align is True:\n                    # Alignment is not possible for a skipped detector configuration\n                    continue\n                \n                alignment_text = \"aligned\" if align is True else \"unaligned\"\n                task = f\"{model_name}_{detector_backend}_{distance_metric}_{alignment_text}\"\n                output_file = f\"outputs/test/{task}.csv\"\n                if os.path.exists(output_file):\n                     #print(f\"{output_file} is available already\")\n                     continue\n                \n                distances = []\n                for i in tqdm(range(0, instances), desc = task):\n                    img1_target = f\"lfwe/test/{i}_1.jpg\"\n                    img2_target = f\"lfwe/test/{i}_2.jpg\"\n                    result = DeepFace.verify(\n                        img1_path=img1_target,\n                        img2_path=img2_target,\n                        model_name=model_name,\n                        detector_backend=detector_backend,\n                        distance_metric=distance_metric,\n                        align=align,\n                        enforce_detection=False,\n                        expand_percentage=expand_percentage,\n                    )\n                    distance = result[\"distance\"]\n                    distances.append(distance)\n                # -----------------------------------\n                df = pd.DataFrame(list(labels), columns = [\"actuals\"])\n                df[\"distances\"] = distances\n                df.to_csv(output_file, index=False)\n```\n\n----------------------------------------\n\nTITLE: Plotting ROC Curves for DeepFace Models in Python\nDESCRIPTION: This function plots ROC curves for DeepFace models, calculating AUC and accuracy scores for different configurations of models, detectors, distance metrics, and alignment settings.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef plot_roc(model_name, detector_backend, distance_metric, align):\n    alignment_text = \"aligned\" if align == True else \"unaligned\"\n\n    df = pd.read_csv(f\"outputs/test/{model_name}_{detector_backend}_{distance_metric}_{alignment_text}.csv\")\n    \n    #normalize\n    df[\"distances_normalized\"] = df[\"distances\"] / df[\"distances\"].max()\n    df[\"actuals_normalized\"] = 0\n    idx = df[df[\"actuals\"] == False].index\n    df.loc[idx, \"actuals_normalized\"] = 1\n    \n    y_actual = df[\"actuals_normalized\"].values.tolist()\n    y_pred_proba = df[\"distances_normalized\"].values.tolist()\n    \n    fpr, tpr, _ = metrics.roc_curve(y_actual, y_pred_proba)\n    auc = metrics.roc_auc_score(y_actual, y_pred_proba)\n    auc = round(auc, 4)\n\n    # best accuracy score\n    result_path = f\"results/pivot_{distance_metric}_with_alignment_{align}.csv\"\n    result_df = pd.read_csv(result_path)\n    acc = result_df[result_df[\"Unnamed: 0\"] == detector_backend][model_name].values[0]\n\n    label = f\"{model_name}_{detector_backend}_{distance_metric}_{alignment_text} (acc: {acc}, auc: {auc})\"\n\n    return acc, auc, fpr, tpr, label\n```\n\n----------------------------------------\n\nTITLE: Generating and Plotting ROC Curves for All DeepFace Configurations in Python\nDESCRIPTION: This code generates and plots ROC curves for all combinations of DeepFace models, detectors, distance metrics, and alignment settings, displaying the best performing configuration for each model.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# to show all models in same graph\nplt.figure(figsize=(17, 8))\n\nfor model_name in models:\n    # to show graphs model by model\n    # plt.figure(figsize=(17, 8))\n    accs = []\n    aucs = []\n    fprs = []\n    tprs = []\n    labels = []\n    for distance_metric in distance_metrics:\n        # for detector_backend in robust_face_detectors:\n        for detector_backend in detectors:\n            for align in alignment:\n                if detector_backend == \"skip\" and align is True:\n                    continue\n                acc, auc, fpr, tpr, label = plot_roc(model_name, detector_backend, distance_metric, align)\n                accs.append(acc)\n                aucs.append(auc)\n                fprs.append(fpr)\n                tprs.append(tpr)\n                labels.append(label)\n    # ---------------------------------\n    #sort by auc\n    df = pd.DataFrame({\"acc\": accs, \"auc\": aucs, \"fpr\": fprs, \"tpr\": tprs, \"label\": labels})\n    # df = df.sort_values(by = [\"auc\"], ascending = False).reset_index()\n    df = df.sort_values(by = [\"acc\"], ascending = False).reset_index()\n    \n    for index, instance in df.iterrows():\n        fpr = instance[\"fpr\"]\n        tpr = instance[\"tpr\"]\n        auc = instance[\"auc\"]\n        acc = instance[\"acc\"]\n        label = instance[\"label\"]\n        \n        plt.plot(fpr, tpr, label=label)\n        plt.ylabel(\"True Positive Rate\")\n        plt.xlabel(\"False Positive Rate\")\n        plt.legend(loc=\"lower center\", ncol=2)\n        # normally this should be [0, 1] but that scale makes graphs not legible\n        # plt.xlim([0, 1])\n        plt.xlim([0, 0.3])\n\n        # to show the best auc value\n        break\n    \n    # to show graphs model by model\n    # plt.show()\n    # print(\"----------------\")\n\n# to show all models in same graph\nplt.show()\n```\n\n----------------------------------------\n\nTITLE: Calculating Best Scores for Facial Recognition Models in Python\nDESCRIPTION: This code calculates and displays the best accuracy scores for each facial recognition model across all configurations, including a comparison with human performance.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndf = pd.DataFrame()\nfor align in alignment:\n    for distance_metric in distance_metrics:\n        tmp_df = (\n            pd.read_csv(f\"results/pivot_{distance_metric}_with_alignment_{align}.csv\")\n            .rename(columns = {'Unnamed: 0': 'detector'})\n            .set_index('detector')\n        )\n        df = pd.concat([df, tmp_df])\n\npivot_df = pd.DataFrame(df.max(), columns = [\"best_accuracy_score\"])\n\n# add human comparison\npivot_df.loc[\"Human-beings\"] = 97.5\n\npivot_df = pivot_df.sort_values(by = [\"best_accuracy_score\"], ascending = False)\npivot_df\n```\n\n----------------------------------------\n\nTITLE: Analyzing Alignment Impact on DeepFace Performance in Python\nDESCRIPTION: This code calculates and displays the impact of alignment on DeepFace performance across different distance metrics and models.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nalign_df = None\n\nfor distance_metric in distance_metrics:\n    df1 = (\n        pd.read_csv(f\"results/pivot_{distance_metric}_with_alignment_True.csv\")\n        .rename(columns = {'Unnamed: 0': 'detector'})\n        .set_index('detector')\n    )\n    df2 = (\n        pd.read_csv(f\"results/pivot_{distance_metric}_with_alignment_False.csv\")\n        .rename(columns = {'Unnamed: 0': 'detector'})\n        .set_index('detector')\n    )\n    df1 = df1[df1.index != \"skip\"]\n    df2 = df2[df2.index != \"skip\"]\n    pivot_df = df1.subtract(df2)\n    \n    pivot_df = pivot_df.max()\n    pivot_df = pd.DataFrame(pivot_df, columns=[f'alignment_impact_of_{distance_metric}'])\n    # display(HTML(pivot_df.to_html()))\n\n    if align_df is None:\n        align_df = pivot_df.copy()\n    else:\n        align_df = align_df.merge(pivot_df, left_index=True, right_index=True)\n\n# display(HTML(align_df.to_html()))\nalign_df = pd.DataFrame(align_df.max(axis=1), columns = [\"max_alignment_impact\"])\nalign_df = align_df.sort_values(by=[\"max_alignment_impact\"], ascending=False)\ndisplay(HTML(align_df.to_html()))\n```\n\n----------------------------------------\n\nTITLE: Analyzing Detection Impact on DeepFace Performance in Python\nDESCRIPTION: This code calculates and displays the impact of face detection on DeepFace performance across different distance metrics and models.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndetect_df = None\nfor distance_metric in distance_metrics:\n    tmp_df = (\n        pd.read_csv(f\"results/pivot_{distance_metric}_with_alignment_False.csv\")\n        .rename(columns = {'Unnamed: 0': 'detector'})\n        .set_index('detector')\n    )\n    ref_df = tmp_df[tmp_df.index == \"skip\"]\n    \n    j = []\n    for i in range(0, len(detectors) - 1):\n        j.append(ref_df)\n    minus_df = pd.concat(j)\n    \n    tmp_df = tmp_df[tmp_df.index != \"skip\"]\n    minus_df.index = tmp_df.index\n    \n    tmp_df = tmp_df.subtract(minus_df)\n    \n    avg_df = pd.DataFrame(tmp_df.max(), columns=[f\"detection_impact_of_{distance_metric}\"])\n\n    if detect_df is None:\n        detect_df = avg_df.copy()\n    else:\n        detect_df = detect_df.merge(avg_df, left_index=True, right_index=True)\n\ndetect_df = pd.DataFrame(detect_df.max(axis=1), columns = [\"max_detection_impact\"])\ndetect_df = detect_df.sort_values(by=[\"max_detection_impact\"], ascending=False)\ndisplay(HTML(detect_df.to_html()))\n```\n\n----------------------------------------\n\nTITLE: Calculating Accuracy Results for DeepFace Experiments\nDESCRIPTION: Analyzes experiment results to find the optimal threshold for each configuration and calculates the corresponding accuracy. Results are saved as CSV files organized by distance metric and alignment setting.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfor is_aligned in alignment:\n    for distance_metric in metrics:\n\n        current_df = base_df.copy()\n        \n        target_file = f\"results/pivot_{distance_metric}_with_alignment_{is_aligned}.csv\"\n        if os.path.exists(target_file):\n            continue\n        \n        for model_name in models:\n            for detector_backend in detectors:\n\n                align = \"aligned\" if is_aligned is True else \"unaligned\"\n\n                if detector_backend == \"skip\" and is_aligned is True:\n                    # Alignment is not possible for a skipped detector configuration\n                    align = \"unaligned\"\n\n                source_file = f\"outputs/test/{model_name}_{detector_backend}_{distance_metric}_{align}.csv\"\n                df = pd.read_csv(source_file)\n                  \n                positive_mean = df[(df[\"actuals\"] == True) | (df[\"actuals\"] == 1)][\"distances\"].mean()\n                negative_mean = df[(df[\"actuals\"] == False) | (df[\"actuals\"] == 0)][\"distances\"].mean()\n\n                distances = sorted(df[\"distances\"].values.tolist())\n\n                items = []\n                for i, distance in enumerate(distances):\n                    if distance >= positive_mean and distance <= negative_mean:\n                        sandbox_df = df.copy()\n                        sandbox_df[\"predictions\"] = False\n                        idx = sandbox_df[sandbox_df[\"distances\"] < distance].index\n                        sandbox_df.loc[idx, \"predictions\"] = True\n\n                        actuals = sandbox_df.actuals.values.tolist()\n                        predictions = sandbox_df.predictions.values.tolist()\n                        accuracy = 100*accuracy_score(actuals, predictions)\n                        items.append((distance, accuracy))\n\n                pivot_df = pd.DataFrame(items, columns = [\"distance\", \"accuracy\"])\n                pivot_df = pivot_df.sort_values(by = [\"accuracy\"], ascending = False)\n                threshold = pivot_df.iloc[0][\"distance\"]\n                # print(f\"threshold for {model_name}/{detector_backend} is {threshold}\")\n                accuracy = pivot_df.iloc[0][\"accuracy\"]\n\n                # print(source_file, round(accuracy, 1))\n                current_df.at[detector_backend, model_name] = round(accuracy, 1)\n        \n        current_df.to_csv(target_file)\n        print(f\"{target_file} saved\")\n```\n\n----------------------------------------\n\nTITLE: Importing Dependencies for DeepFace LFW Evaluation\nDESCRIPTION: Sets up the required libraries for the experiment, including built-in dependencies like os and third-party packages such as numpy, pandas, tqdm, matplotlib, scikit-learn components, and DeepFace.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# built-in dependencies\nimport os\n\n# 3rd party dependencies\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import fetch_lfw_pairs\nfrom deepface import DeepFace\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for DeepFace Analysis in Python\nDESCRIPTION: This snippet imports necessary Python libraries for data analysis and visualization, including pandas for data manipulation, IPython for display, sklearn for metrics, and matplotlib for plotting.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom IPython.display import display, HTML\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Setting Configuration Parameters for DeepFace Experiments\nDESCRIPTION: Defines all possible configuration parameters for the experiments, including alignment options, face recognition models, face detection backends, distance metrics, and image expansion percentage.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# all configuration alternatives for 4 dimensions of arguments\nalignment = [True, False]\nmodels = [\"Facenet512\", \"Facenet\", \"VGG-Face\", \"ArcFace\", \"Dlib\", \"GhostFaceNet\", \"SFace\", \"OpenFace\", \"DeepFace\", \"DeepID\"]\ndetectors = [\"retinaface\", \"mtcnn\", \"fastmtcnn\", \"dlib\", \"yolov8\", \"yunet\", \"centerface\", \"mediapipe\", \"ssd\", \"opencv\", \"skip\"]\nmetrics = [\"euclidean\", \"euclidean_l2\", \"cosine\"]\nexpand_percentage = 0\n```\n\n----------------------------------------\n\nTITLE: Defining Parameters for DeepFace Evaluation in Python\nDESCRIPTION: This code defines lists of parameters used in the DeepFace evaluation, including alignment options, face recognition models, face detectors, and distance metrics.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nalignment = [False, True]\nmodels = [\"Facenet512\", \"Facenet\", \"VGG-Face\", \"ArcFace\", \"Dlib\", \"GhostFaceNet\", \"SFace\", \"OpenFace\", \"DeepFace\", \"DeepID\"]\ndetectors = [\"retinaface\", \"mtcnn\", \"fastmtcnn\", \"dlib\", \"yolov8\", \"yunet\", \"centerface\", \"mediapipe\", \"ssd\", \"opencv\", \"skip\"]\ndistance_metrics = [\"euclidean\", \"euclidean_l2\", \"cosine\"]\n```\n\n----------------------------------------\n\nTITLE: Loading LFW Dataset\nDESCRIPTION: Loads the Labeled Faces in the Wild dataset, either by fetching it newly or by loading previously saved numpy arrays. The code handles both initial download and cached data scenarios.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntarget_path = \"dataset/test_lfw.npy\"\nlabels_path = \"dataset/test_labels.npy\"\n\nif os.path.exists(target_path) != True:\n    fetch_lfw_pairs = fetch_lfw_pairs(subset = 'test', color = True\n                                  , resize = 2\n                                  , funneled = False\n                                  , slice_=None\n                                 )\n    pairs = fetch_lfw_pairs.pairs\n    labels = fetch_lfw_pairs.target\n    target_names = fetch_lfw_pairs.target_names\n    np.save(target_path, pairs)\n    np.save(labels_path, labels)\nelse:\n    if not os.path.exists(pairs_touch):\n        # loading pairs takes some time. but if we extract these pairs as image, no need to load it anymore\n        pairs = np.load(target_path)\n    labels = np.load(labels_path)    \n```\n\n----------------------------------------\n\nTITLE: Saving LFW Image Pairs to Filesystem\nDESCRIPTION: Extracts and saves individual images from the LFW dataset pairs to the filesystem for processing by DeepFace. Uses tqdm to display a progress bar during extraction.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfor i in tqdm(range(0, instances)):\n    img1_target = f\"lfwe/test/{i}_1.jpg\"\n    img2_target = f\"lfwe/test/{i}_2.jpg\"\n    \n    if not os.path.exists(img1_target):\n        img1 = pairs[i][0]\n        # plt.imsave(img1_target, img1/255) #works for my mac\n        plt.imsave(img1_target, img1) #works for my debian\n    \n    if not os.path.exists(img2_target):\n        img2 = pairs[i][1]\n        # plt.imsave(img2_target, img2/255) #works for my mac\n        plt.imsave(img2_target, img2) #works for my debian\n    \nif not os.path.exists(pairs_touch):\n    open(pairs_touch,'a').close()\n```\n\n----------------------------------------\n\nTITLE: Displaying Main Results of DeepFace Evaluation in Python\nDESCRIPTION: This function loads and displays the main results of the DeepFace evaluation for different alignment settings and distance metrics using pandas and IPython HTML display.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfor align in alignment:\n    for metric in distance_metrics:\n        df = pd.read_csv(f\"results/pivot_{metric}_with_alignment_{align}.csv\")\n        df = df.rename(columns = {'Unnamed: 0': 'detector'})\n        df = df.set_index('detector')\n\n        print(f\"{metric} for alignment {align}\")\n        display(HTML(df.to_html()))\n        display(HTML(\"<hr>\"))\n```\n\n----------------------------------------\n\nTITLE: Creating GitHub-Compatible Table for DeepFace Results in Python\nDESCRIPTION: This function generates a GitHub-compatible markdown table for DeepFace evaluation results, highlighting performance scores above 97.5.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Evaluate-Results.ipynb#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef create_github_table():\n    for metric in distance_metrics:\n        for align in [True, False]:\n            df = pd.read_csv(f\"results/pivot_{metric}_with_alignment_{align}.csv\")\n            df = df.rename(columns = {'Unnamed: 0': 'detector'})\n            df = df.set_index('detector')\n            \n            print(f\"Performance Matrix for {metric} while alignment is {align} \\n\")\n            header = \"| | \"\n            for col_name in df.columns.tolist():\n                header += f\"{col_name} |\"\n            print(header)\n            # -------------------------------\n            seperator = \"| --- | \"\n            for col_name in df.columns.tolist():\n                seperator += \" --- |\"\n            print(seperator)\n            # -------------------------------\n            for index, instance in df.iterrows():\n                line = f\"| {instance.name} |\"\n                for i in instance.values:\n                    if i < 97.5:\n                        line += f\"{i} |\"\n                    else:\n                        line += f\"**{i}** |\"\n                print(line)\n            \n            print(\"\\n---------------------------\")\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for DeepFace\nDESCRIPTION: This requirements file specifies all the Python packages required for the DeepFace project to function properly. It includes libraries for data processing (numpy, pandas), image handling (Pillow, OpenCV), deep learning (TensorFlow, Keras), web services (Flask), and face detection models (MTCNN, RetinaFace).\nSOURCE: https://github.com/serengil/deepface/blob/master/requirements.txt#2025-04-17_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nrequests>=2.27.1\nnumpy>=1.14.0\npandas>=0.23.4\ngdown>=3.10.1\ntqdm>=4.30.0\nPillow>=5.2.0\nopencv-python>=4.5.5.64\ntensorflow>=1.9.0\nkeras>=2.2.0\nFlask>=1.1.2\nflask_cors>=4.0.1\nmtcnn>=0.1.0\nretina-face>=0.0.14\nfire>=0.4.0\ngunicorn>=20.1.0\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies Configuration\nDESCRIPTION: Specifies the required Python packages and their minimum versions for the DeepFace library. Includes core dependencies for computer vision (OpenCV), facial detection (dlib, mediapipe), deep learning frameworks (PyTorch, TensorFlow), and auxiliary libraries.\nSOURCE: https://github.com/serengil/deepface/blob/master/requirements_additional.txt#2025-04-17_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nopencv-contrib-python>=4.3.0.36\nmediapipe>=0.8.7.3\ndlib>=19.20.0\nultralytics>=8.0.122\nfacenet-pytorch>=2.5.3\ntorch>=2.1.2\ninsightface>=0.7.3\nonnxruntime>=1.9.0\ntf-keras\ntyping-extensions\npydantic\nalbumentations\n```\n\n----------------------------------------\n\nTITLE: Database Directory Structure for Multiple Face Images\nDESCRIPTION: Shows the recommended directory structure for storing multiple face images per person in the database. Each person should have their own directory containing their images.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nuser\n├── database\n│   ├── Alice\n│   │   ├── Alice1.jpg\n│   │   ├── Alice2.jpg\n│   ├── Bob\n│   │   ├── Bob.jpg\n```\n\n----------------------------------------\n\nTITLE: Importing DeepFace Library\nDESCRIPTION: Basic import statement to use DeepFace functionality in Python code.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom deepface import DeepFace\n```\n\n----------------------------------------\n\nTITLE: Installing DeepFace via pip\nDESCRIPTION: Simple installation of DeepFace library using pip package manager.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n$ pip install deepface\n```\n\n----------------------------------------\n\nTITLE: Installing DeepFace from Source\nDESCRIPTION: Installation process for DeepFace directly from GitHub source code, which may include newer unreleased features.\nSOURCE: https://github.com/serengil/deepface/blob/master/README.md#2025-04-17_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ git clone https://github.com/serengil/deepface.git\n$ cd deepface\n$ pip install -e .\n```\n\n----------------------------------------\n\nTITLE: Creating Directory Structure for Experiment\nDESCRIPTION: Creates the necessary directory structure for the experiment if it doesn't already exist, including folders for the LFW dataset, outputs, and results.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntarget_paths = [\"lfwe\", \"dataset\", \"outputs\", \"outputs/test\", \"results\"]\nfor target_path in target_paths:\n    if not os.path.exists(target_path):\n        os.mkdir(target_path)\n        print(f\"{target_path} is just created\")\n```\n\n----------------------------------------\n\nTITLE: Setting LFW Dataset Parameters\nDESCRIPTION: Defines the file path for a touch file to track progress and sets the number of face pairs to process in the experiment.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npairs_touch = \"outputs/test_lfwe.txt\"\ninstances = 1000 #pairs.shape[0]\n```\n\n----------------------------------------\n\nTITLE: Initializing Results DataFrame\nDESCRIPTION: Creates an empty DataFrame to store accuracy results for each model and detector combination for further analysis.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndata = [[0 for _ in range(len(models))] for _ in range(len(detectors))]\nbase_df = pd.DataFrame(data, columns=models, index=detectors)\n```\n\n----------------------------------------\n\nTITLE: Checking DeepFace Version\nDESCRIPTION: Prints the version of the DeepFace package being used in the experiment for reproducibility purposes.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/Perform-Experiments.ipynb#2025-04-17_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nprint(f\"This experiment is done with pip package of deepface with {DeepFace.__version__} version\")\n```\n\n----------------------------------------\n\nTITLE: BibTeX Citation for DeepFace Research\nDESCRIPTION: BibTeX entry for citing the DeepFace framework in academic publications, referencing a 2024 paper by Serengil and Ozpinar about facial recognition pipelines and module co-usability.\nSOURCE: https://github.com/serengil/deepface/blob/master/benchmarks/README.md#2025-04-17_snippet_0\n\nLANGUAGE: BibTeX\nCODE:\n```\n@article{serengil2024lightface,\n  title         = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},\n  author        = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  journal       = {Bilisim Teknolojileri Dergisi},\n  volume        = {17},\n  number        = {2},\n  pages         = {95-107},\n  year          = {2024},\n  doi           = {10.17671/gazibtd.1399077},\n  url           = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},\n  publisher     = {Gazi University}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing LightFace Facial Recognition Benchmark Paper in BibTeX\nDESCRIPTION: BibTeX citation for a 2024 paper benchmarking facial recognition pipelines published in Bilisim Teknolojileri Dergisi.\nSOURCE: https://github.com/serengil/deepface/blob/master/CITATION.md#2025-04-17_snippet_0\n\nLANGUAGE: BibTeX\nCODE:\n```\n@article{serengil2024lightface,\n  title         = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},\n  author        = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  journal       = {Bilisim Teknolojileri Dergisi},\n  volume        = {17},\n  number        = {2},\n  pages         = {95-107},\n  year          = {2024},\n  doi           = {10.17671/gazibtd.1399077},\n  url           = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},\n  publisher     = {Gazi University}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing LightFace Hybrid Deep Face Recognition Framework in BibTeX\nDESCRIPTION: BibTeX citation for the 2020 conference paper introducing the LightFace framework, published in the Innovations in Intelligent Systems and Applications Conference.\nSOURCE: https://github.com/serengil/deepface/blob/master/CITATION.md#2025-04-17_snippet_1\n\nLANGUAGE: BibTeX\nCODE:\n```\n@inproceedings{serengil2020lightface,\n  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\n  pages        = {23-27},\n  year         = {2020},\n  doi          = {10.1109/ASYU50717.2020.9259802},\n  url          = {https://ieeexplore.ieee.org/document/9259802},\n  organization = {IEEE}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing HyperExtended LightFace Facial Attribute Analysis in BibTeX\nDESCRIPTION: BibTeX citation for the 2021 conference paper on facial attribute analysis (age, gender, emotion, ethnicity) published in the International Conference on Engineering and Emerging Technologies.\nSOURCE: https://github.com/serengil/deepface/blob/master/CITATION.md#2025-04-17_snippet_2\n\nLANGUAGE: BibTeX\nCODE:\n```\n@inproceedings{serengil2021lightface,\n  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\n  pages        = {1-4},\n  year         = {2021},\n  doi          = {10.1109/ICEET53442.2021.9659697},\n  url          = {https://ieeexplore.ieee.org/document/9659697/},\n  organization = {IEEE}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing CipherFace Homomorphic Encryption Paper in BibTeX\nDESCRIPTION: BibTeX citation for a 2025 arXiv paper on homomorphic encryption for facial recognition, describing a framework for secure cloud-based facial recognition.\nSOURCE: https://github.com/serengil/deepface/blob/master/CITATION.md#2025-04-17_snippet_3\n\nLANGUAGE: BibTeX\nCODE:\n```\n@misc{serengil2025cipherface,\n   title     = {CipherFace: A Fully Homomorphic Encryption-Driven Framework for Secure Cloud-Based Facial Recognition}, \n   author    = {Serengil, Sefik and Ozpinar, Alper},\n   year      = {2025},\n   publisher = {arXiv},\n   url       = {https://arxiv.org/abs/2502.18514},\n   doi       = {10.48550/arXiv.2502.18514}\n}\n```\n\n----------------------------------------\n\nTITLE: Citing Database Evaluation for Facial Recognition in BibTeX\nDESCRIPTION: BibTeX citation for a 2023 paper evaluating SQL and NoSQL databases for facial recognition pipelines, published in Cambridge Open Engage.\nSOURCE: https://github.com/serengil/deepface/blob/master/CITATION.md#2025-04-17_snippet_4\n\nLANGUAGE: BibTeX\nCODE:\n```\n@misc{serengil2023db,\n  title         = {An evaluation of sql and nosql databases for facial recognition pipelines},\n  author        = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n  year          = {2023},\n  archivePrefix = {Cambridge Open Engage},\n  doi           = {10.33774/coe-2023-18rcn},\n  url           = {https://www.cambridge.org/engage/coe/article-details/63f3e5541d2d184063d4f569}\n}\n```"
  }
]