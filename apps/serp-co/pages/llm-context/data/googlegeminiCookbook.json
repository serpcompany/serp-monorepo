[
  {
    "owner": "google-gemini",
    "repo": "cookbook",
    "content": "TITLE: Implementing Gemini API Client with Real-time Audio I/O in Python\nDESCRIPTION: Client implementation for connecting to the Gemini API with real-time audio input and output. Uses websockets for communication and includes functions for encoding/decoding audio data and text, managing the WebSocket connection, and handling audio playback.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# @title Client implementation {display-mode: 'form'}\n# @markdown This cell runs client connection to BidiGenerate with realtime audio I/O\nfrom websockets.asyncio.client import connect\nimport asyncio\nimport contextlib\nimport base64\nimport json\n\n\nHOST = 'generativelanguage.googleapis.com' # @param {type:'string'}\nAPI_KEY = GOOGLE_API_KEY\nMODEL = 'models/gemini-flash-2.0-live-001' # @param {type:'string'}\nINITIAL_REQUEST_TEXT = \"what's up?\" # @param {type:'string'}\n\n\ndef encode_audio_input(data: bytes, config: AudioConfig) -> dict:\n  \"\"\"Build JSPB message with user input audio bytes.\"\"\"\n  return {\n      'realtimeInput': {\n          'mediaChunks': [{\n              'mimeType': f'audio/pcm;rate={config.sample_rate}',\n              'data': base64.b64encode(data).decode('UTF-8'),\n          }],\n      },\n  }\n\n\ndef encode_text_input(text: str) -> dict:\n  \"\"\"Builds JSPB message with user input text.\"\"\"\n  return {\n      'clientContent': {\n          'turns': [{\n              'role': 'USER',\n              'parts': [{'text': text}],\n          }],\n          'turnComplete': True,\n      },\n  }\n\n\ndef decode_audio_output(input: dict) -> bytes:\n  \"\"\"Returns byte string with model output audio.\"\"\"\n  result = []\n  content_input = input.get('serverContent', {})\n  content = content_input.get('modelTurn', {})\n  for part in content.get('parts', []):\n    data = part.get('inlineData', {}).get('data', '')\n    if data:\n      result.append(base64.b64decode(data))\n  return b''.join(result)\n\n\nasync def main():\n  async with contextlib.AsyncExitStack() as es:\n    tg = await es.enter_async_context(asyncio.TaskGroup())\n    audio = await es.enter_async_context(RunningLiveAudio(AudioConfig(sample_rate=24000)))\n    conn = await es.enter_async_context(connect(f'wss://{HOST}/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key={API_KEY}'))\n    print('<connected>')\n\n    initial_request = {\n        'setup': {\n            'model': MODEL,\n        },\n    }\n    await conn.send(json.dumps(initial_request))\n\n    if text := INITIAL_REQUEST_TEXT:\n      await conn.send(json.dumps(encode_text_input(text)))\n\n    async def send_audio():\n      while True:\n        data = await audio.read()\n        await conn.send(json.dumps(encode_audio_input(data, audio.config)))\n\n    tg.create_task(send_audio())\n    enqueued_audio = []\n    async for msg in conn:\n      msg = json.loads(msg)\n      if to_play := decode_audio_output(msg):\n        enqueued_audio.append(to_play)\n        await audio.enqueue(to_play)  # enqueue TTS\n      elif 'interrupted' in msg.get('serverContent', {}):\n        print('<interrupted by the user>')\n        await audio.clear_queue()  # stop TTS\n      elif 'turnComplete' in msg.get('serverContent', {}):\n        if enqueued_audio:  # display it for later playback\n          display.display(Audio(config=audio.config, data=b''.join(enqueued_audio)))\n        enqueued_audio = []\n        print('<end of turn>')\n      else:\n        if msg != {'serverContent': {}}:\n          print(f'unhandled message: {msg}')\n\ntry:\n  await main()\nexcept asyncio.ExceptionGroup as e:\n  raise e.exceptions[0]\n```\n\n----------------------------------------\n\nTITLE: Generating Company Report with Gemini 2.0 Search Tool\nDESCRIPTION: Uses the Gemini 2.0 search tool to generate a company research report. It includes system instructions, configuration setup, and streaming of the generated content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsys_instruction = \"\"\"You are an analyst that conducts company research.\nYou are given a company name, and you will work on a company report. You have access\nto Google Search to look up company news, updates and metrics to write research reports.\n\nWhen given a company name, identify key aspects to research, look up that information\nand then write a concise company report.\n\nFeel free to plan your work and talk about it, but when you start writing the report,\nput a line of dashes (---) to demarcate the report itself, and say nothing else after\nthe report has finished.\n\"\"\"\n\nconfig = GenerateContentConfig(system_instruction=sys_instruction, tools=[Tool(google_search={})], temperature=0)\nresponse_stream = client.models.generate_content_stream(\n    model=MODEL, config=config, contents=[COMPANY])\n\nreport = io.StringIO()\nfor chunk in response_stream:\n  candidate = chunk.candidates[0]\n\n  for part in candidate.content.parts:\n    if part.text:\n      display(Markdown(part.text))\n\n      # Find and save the report itself.\n      if m := re.search('(^|\\n)-+\\n(.*)$', part.text, re.M):\n          # Find the starting '---' line and start saving.\n          report.write(m.group(2))\n      elif report.tell():\n        # If there's already something in the buffer, keep recording.\n        report.write(part.text)\n\n    else:\n      print(json.dumps(part.model_dump(exclude_none=True), indent=2))\n\n  # You must enable Google Search Suggestions\n  if gm := candidate.grounding_metadata:\n    if sep := gm.search_entry_point:\n      display(HTML(sep.rendered_content))\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Monkey Patching for Gemini 2.0 in Colab\nDESCRIPTION: This code installs required packages (websockets and taskgroup) and applies a monkey patch to backport taskgroup functionality for Python 3.11 in Colab.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q websockets taskgroup\n\n# Colab runs Python 3.11, but this needs a backport of taskgroup\n# monkey patch:\nimport asyncio, taskgroup, exceptiongroup\nasyncio.TaskGroup = taskgroup.TaskGroup\nasyncio.ExceptionGroup = exceptiongroup.ExceptionGroup\n```\n\n----------------------------------------\n\nTITLE: Implementing Asynchronous Response Streaming with Gemini API\nDESCRIPTION: Example of asynchronous streaming where text chunks are printed as they are generated asynchronously by the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync for chunk in await client.aio.models.generate_content_stream(\n    model='gemini-2.0-flash',\n    contents=\"Write a cute story about cats.\"):\n    if chunk.text:\n        print(chunk.text)\n    print(\"_\"*80)\n```\n\n----------------------------------------\n\nTITLE: Executing SQL Queries with QuerySQLDataBaseTool\nDESCRIPTION: Sets up an execution chain that takes a natural language question, converts it to SQL, and automatically executes it against the database, returning the query results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nexecute_query = QuerySQLDataBaseTool(db=db)\nexecute_chain = validate_chain | execute_query\nexecute_chain.invoke({\"question\": \"What is the total population?\"})\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Google Search Integration with Gemini\nDESCRIPTION: Shows how to use the google_search tool with Gemini to retrieve up-to-date information about recent events that would not be in the model's training data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nprompt=\"When the latest Brazil vs. Argentina soccer match happened and what was the final score?\"\n\ntools = [\n   {'google_search': {}}\n]\n\nawait run(prompt, tools=tools, modality=\"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Creating Gemini Live API Runner Function\nDESCRIPTION: An asynchronous function that handles the interaction with the Gemini 2.0 Live API. It sends a prompt, processes various response types including text, audio, and tool calls, and displays the results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nn = 0\nasync def run(prompt, modality=\"TEXT\", tools=None):\n  global n\n  if tools is None:\n    tools=[]\n\n  config = {\n          \"tools\": tools,\n          \"response_modalities\": [modality]}\n\n  async with client.aio.live.connect(model=model_name, config=config) as session:\n    display.display(display.Markdown(prompt))\n    display.display(display.Markdown('-------------------------------'))\n    await session.send(input=prompt, end_of_turn=True)\n\n    audio = False\n    filename = f'audio_{n}.wav'\n    with wave_file(filename) as wf:\n      async for response in session.receive():\n        logger.debug(str(response))\n        if text:=response.text:\n          display.display(display.Markdown(text))\n          continue\n\n        if data:=response.data:\n          print('.', end='')\n          wf.writeframes(data)\n          audio = True\n          continue\n\n        server_content = response.server_content\n        if server_content is not None:\n          handle_server_content(wf, server_content)\n          continue\n\n        tool_call = response.tool_call\n        if tool_call is not None:\n          await handle_tool_call(session, tool_call)\n\n\n  if audio:\n    display.display(display.Audio(filename, autoplay=True))\n    n = n+1\n```\n\n----------------------------------------\n\nTITLE: Installing Google GenAI SDK for Gemini 2.0\nDESCRIPTION: Installation of the Google Gen AI SDK which provides programmatic access to Gemini 2.0 models using both Google AI for Developers and Vertex AI APIs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q google-genai\n```\n\n----------------------------------------\n\nTITLE: Querying the Vector Store with Custom Prompt Template\nDESCRIPTION: This snippet demonstrates how to use the previously created prompt template with a query engine to ask questions about the stored data. It creates a query engine from the index and uses it to query for information about Gemini.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Query data from the persisted index\nquery_engine = index.as_query_engine(text_qa_template=llm_prompt)\nresponse = query_engine.query(\"What is Gemini?\")\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Code Execution with Gemini\nDESCRIPTION: Shows how to use the code_execution tool with Gemini to solve a computational problem - finding the largest prime palindrome under 100,000 - that the model can't solve from memory alone.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprompt=\"Can you compute the largest prime palindrome under 100000.\"\n\ntools = [\n    {'code_execution': {}}\n]\n\nawait run(prompt, tools=tools, modality=\"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Prompt Template for Question Answering\nDESCRIPTION: This code creates a custom prompt template for the LLM to answer questions. The template includes placeholders for the query string and context information that will be retrieved from the vector store.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.core import PromptTemplate\n\ntemplate = (\n    \"\"\" You are an assistant for question-answering tasks.\nUse the following context to answer the question.\nIf you don't know the answer, just say that you don't know.\nUse five sentences maximum and keep the answer concise.\\n\nQuestion: {query_str} \\nContext: {context_str} \\nAnswer:\"\"\"\n)\nllm_prompt = PromptTemplate(template)\n```\n\n----------------------------------------\n\nTITLE: Building a RAG Chain with LangChain Expression Language\nDESCRIPTION: Implements a Retrieval-Augmented Generation (RAG) chain using LangChain Expression Language (LCEL). The chain combines document retrieval, context formatting, and LLM prompting in a sequential pipeline.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Combine data from documents to readable string format.\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# Create stuff documents chain using LCEL.\n#\n# This is called a chain because you are chaining together different elements\n# with the LLM. In the following example, to create the stuff chain, you will\n# combine the relevant context from the website data matching the question, the\n# LLM model, and the output parser together like a chain using LCEL.\n#\n# The chain implements the following pipeline:\n# 1. Extract the website data relevant to the question from the Chroma\n#    vector store and save it to the variable `context`.\n# 2. `RunnablePassthrough` option to provide `question` when invoking\n#    the chain.\n# 3. The `context` and `question` are then passed to the prompt where they\n#    are populated in the respective variables.\n# 4. This prompt is then passed to the LLM (`gemini-2.0-flash`).\n# 5. Output from the LLM is passed through an output parser\n#    to structure the model's response.\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | llm_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Output with Gemini API using curl\nDESCRIPTION: This bash script demonstrates how to make a REST API call to the Gemini API using curl, requesting JSON output for cookie recipes based on a specified schema.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/JSON_mode_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\n    \"contents\": [{\n      \"parts\":[\n        {\"text\": \"List a few popular cookie recipes using this JSON schema:\n          {\\'type\\': \\'object\\', \\'properties\\': { \\'recipe_name\\': {\\'type\\': \\'string\\'}}}\"}\n        ]\n    }],\n    \"generationConfig\": {\n        \"response_mime_type\": \"application/json\",\n    }\n}' 2> /dev/null | head\n```\n\n----------------------------------------\n\nTITLE: Using Multiple Tools Simultaneously with Gemini API in Python\nDESCRIPTION: This snippet demonstrates how to combine multiple tools (Google Search, code execution, and function declarations) in a single Gemini API request. The code sets up a prompt that asks for three distinct actions and configures the appropriate tools array to handle all requested capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n  Hey, I need you to do three things for me.\n\n  1. Then compute the largest prime plaindrome under 100000.\n  2. Then use google search to lookup unformation about the largest earthquake in california the week of Dec 5 2024?\n  3. Turn on the lights\n\n  Thanks!\n  \"\"\"\n\ntools = [\n    {'google_search': {}},\n    {'code_execution': {}},\n    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n]\n\nawait run(prompt, tools=tools, modality=\"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Creating Prompt Templates for Document Summarization\nDESCRIPTION: Defining two prompt templates: one to extract content from web documents and another to instruct the Gemini model to create a concise summary of the extracted text.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# To extract data from WebBaseLoader\ndoc_prompt = PromptTemplate.from_template(\"{page_content}\")\n\n# To query Gemini\nllm_prompt_template = \"\"\"Write a concise summary of the following:\n\"{text}\"\nCONCISE SUMMARY:\"\"\"\nllm_prompt = PromptTemplate.from_template(llm_prompt_template)\n\nprint(llm_prompt)\n```\n\n----------------------------------------\n\nTITLE: Implementing the Barista Bot Conversation Loop\nDESCRIPTION: Creates an interactive chat loop that continues until an order is placed, sending user input to the Gemini model and displaying responses. The loop handles the entire conversation flow from initial greeting to order placement.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import display, Markdown\n\nprint(\"Welcome to Barista bot!\\n\\n\")\n\nwhile not placed_order:\n    response = chat.send_message(input(\"> \"))\n    display(Markdown(response.text))\n\n\nprint(\"\\n\\n\")\nprint(\"[barista bot session over]\")\nprint()\nprint(\"Your order:\")\nprint(f\"  {placed_order}\\n\")\nprint(\"- Thanks for using Barista Bot!\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Calling Mechanism for ReAct Framework in Python\nDESCRIPTION: Defines the main execution flow of the ReAct framework, handling the conversation between the user and the model. It uses stop sequences to detect action tokens, calls the appropriate functions, and manages the conversation flow with a maximum number of model calls to get the final answer.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n@ReAct.add_method\ndef __call__(self, user_question, max_calls: int=8, **generation_kwargs):\n  \"\"\"Starts multi-turn conversation with the chat models with function calling\n\n  Args:\n      max_calls: max calls made to the model to get the final answer.\n\n      generation_kwargs: Same as genai.GenerativeModel.GenerationConfig\n              candidate_count: (int | None) = None,\n              stop_sequences: (Iterable[str] | None) = None,\n              max_output_tokens: (int | None) = None,\n              temperature: (float | None) = None,\n              top_p: (float | None) = None,\n              top_k: (int | None) = None\n\n  Raises:\n      AssertionError: if max_calls is not between 1 and 8\n  \"\"\"\n\n  # hyperparameter fine-tuned according to the paper\n  assert 0 < max_calls <= 8, \"max_calls must be between 1 and 8\"\n\n  if len(self.chat.history) == 0:\n    model_prompt = self.prompt.format(question=user_question)\n  else:\n    model_prompt = user_question\n\n  # stop_sequences for the model to immitate function calling\n  callable_entities = ['</search>', '</lookup>', '</finish>']\n\n  generation_kwargs.update({'stop_sequences': callable_entities})\n\n  self.should_continue_prompting = True\n  for idx in range(max_calls):\n\n    self.response = self.chat.send_message(content=[model_prompt],\n              generation_config=generation_kwargs, stream=False)\n\n    for chunk in self.response:\n      print(chunk.text, end=' ')\n\n    response_cmd = self.chat.history[-1].parts[-1].text\n\n    try:\n      # regex to extract <function name writen in between angular brackets>\n      cmd = re.findall(r'<(.*)>', response_cmd)[-1]\n      print(f'</{cmd}>')\n      # regex to extract param\n      query = response_cmd.split(f'<{cmd}>')[-1].strip()\n      # call to appropriate function\n      observation = self.__getattribute__(cmd)(query)\n\n      if not self.should_continue_prompting:\n        break\n\n      stream_message = f\"\\nObservation {idx + 1}\\n{observation}\"\n      print(stream_message)\n      # send function's output as user's response\n      model_prompt = f\"<{cmd}>{query}</{cmd}>'s Output: {stream_message}\"\n\n    except (IndexError, AttributeError) as e:\n      model_prompt = \"Please try to generate thought-action-observation traces \\\n      as instructed by the prompt.\"\n```\n\n----------------------------------------\n\nTITLE: Building SQL Query Validation Chain\nDESCRIPTION: Creates a chain that takes a question, generates a SQL query, validates and formats it, and returns the clean SQL query ready for execution.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nvalidate_chain = write_query_chain | validate_prompt | llm | StrOutputParser()\nvalidate_chain.invoke({\"question\": \"What is the total population?\"})\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Image\nDESCRIPTION: Demonstrates how to generate content using both text and image inputs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[prompt, img],\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Downloading and Processing Images in Parallel\nDESCRIPTION: Demonstrates how to download and process multiple images in parallel using asyncio.as_completed for optimal performance. This creates tasks for each image and processes the results as they complete.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nasync def download_and_describe():\n\n  async with aiohttp.ClientSession() as sesh:\n    response_futures = []\n    for img_filename in img_filenames:\n\n      # Create the image download tasks (this does not schedule them yet).\n      img_future = download_image(sesh, img_dir + img_filename)\n\n      # Kick off the Gemini API request using the pending image download tasks.\n      text_future = process_image(img_future)\n\n      # Save the reference so they can be processed as they complete.\n      response_futures.append(text_future)\n\n    print(f\"Download and content generation queued for {len(response_futures)} images.\")\n\n    # Process responses as they complete (may be a different order). The tasks are started here.\n    for response in asyncio.as_completed(response_futures):\n      print()\n      print(await response)\n\n\nawait download_and_describe()\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Gemini API for Video Analysis\nDESCRIPTION: Sends a request to the Gemini API to analyze the uploaded video, using the specified model, system prompt, and safety settings. The response contains the model's analysis of the historic event in the video.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nresponse = client.models.generate_content(\n    model=f\"models/{MODEL_ID}\",\n    contents=[\n        \"Analyze the video please\",\n        video_file\n        ],\n    config=types.GenerateContentConfig(\n        system_instruction=system_prompt,\n        safety_settings=safety_settings,\n        ),\n    )\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Defining ReAct Prompt for Wikipedia Search\nDESCRIPTION: Creates the instruction prompt for the Gemini model that defines the ReAct methodology with Thought, Action, and Observation steps. The prompt outlines three possible actions: search Wikipedia, lookup keywords, and finish with an answer.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel_instructions = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, Observation is understanding relevant information from an Action's output and Action can be of three types:\n(1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search and you can try to search the information from those topics.\n(2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches, so keep your searches short.\n(3) <finish>answer</finish>, which returns the answer and finishes the task.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API Authentication\nDESCRIPTION: Configuring the Google API key from Colab Secrets for authentication with the Gemini API, which is required for accessing the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Multi-Turn Conversation with Function Calling in Gemini API\nDESCRIPTION: Bash script demonstrating a multi-turn conversation with the Gemini API, where the model calls functions to answer different user queries. The conversation includes a function call response about theaters showing Barbie and a follow-up question about comedy movies.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%%bash\n\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"contents\": [{\n      \"role\": \"user\",\n      \"parts\": [{\n        \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n    }]\n  }, {\n    \"role\": \"model\",\n    \"parts\": [{\n      \"functionCall\": {\n        \"name\": \"find_theaters\",\n        \"args\": {\n          \"location\": \"Mountain View, CA\",\n          \"movie\": \"Barbie\"\n        }\n      }\n    }]\n  }, {\n    \"role\": \"function\",\n    \"parts\": [{\n      \"functionResponse\": {\n        \"name\": \"find_theaters\",\n        \"response\": {\n          \"name\": \"find_theaters\",\n          \"content\": {\n            \"movie\": \"Barbie\",\n            \"theaters\": [{\n              \"name\": \"AMC Mountain View 16\",\n              \"address\": \"2000 W El Camino Real, Mountain View, CA 94040\"\n            }, {\n              \"name\": \"Regal Edwards 14\",\n              \"address\": \"245 Castro St, Mountain View, CA 94040\"\n            }]\n          }\n        }\n      }\n    }]\n  },\n  {\n    \"role\": \"model\",\n    \"parts\": [{\n      \"text\": \" OK. Barbie is showing in two theaters in Mountain View, CA: AMC Mountain View 16 and Regal Edwards 14.\"\n    }]\n  },{\n    \"role\": \"user\",\n    \"parts\": [{\n      \"text\": \"Can you recommend some comedy movies on show in Mountain View?\"\n    }]\n  }],\n  \"tools\": [{\n    \"functionDeclarations\": [{\n      \"name\": \"find_movies\",\n      \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"description\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n          }\n        },\n        \"required\": [\"description\"]\n      }\n    }, {\n      \"name\": \"find_theaters\",\n      \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"movie\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any movie title\"\n          }\n        },\n        \"required\": [\"location\"]\n      }\n    }, {\n      \"name\": \"get_showtimes\",\n      \"description\": \"Find the start times for movies playing in a specific theater\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"movie\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any movie title\"\n          },\n          \"theater\": {\n            \"type\": \"STRING\",\n            \"description\": \"Name of the theater\"\n          },\n          \"date\": {\n            \"type\": \"STRING\",\n            \"description\": \"Date for requested showtime\"\n          }\n        },\n        \"required\": [\"location\", \"movie\", \"theater\", \"date\"]\n      }\n    }]\n  }]\n}'  2> /dev/null\n```\n\n----------------------------------------\n\nTITLE: Analyzing YouTube Video Content with Gemini API\nDESCRIPTION: Shows how to analyze a YouTube video by providing the URL directly to the Gemini API. The prompt requests a comprehensive analysis including main thesis, key topics, and summary.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\nfrom IPython.display import display, Markdown\n\nyoutube_url = \"https://www.youtube.com/watch?v=RDOMKIw1aF4\" # Repalce with the youtube url you want to analyze\n\nprompt = \"\"\"\n    Analyze the following YouTube video content. Provide a concise summary covering:\n\n    1.  **Main Thesis/Claim:** What is the central point the creator is making?\n    2.  **Key Topics:** List the main subjects discussed, referencing specific examples or technologies mentioned (e.g., AI models, programming languages, projects).\n    3.  **Call to Action:** Identify any explicit requests made to the viewer.\n    4.  **Summary:** Provide a concise summary of the video content.\n\n    Use the provided title, chapter timestamps/descriptions, and description text for your analysis.\n\"\"\"\n# Analyze the video\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=types.Content(\n        parts=[\n            types.Part(text=prompt),\n            types.Part(\n                file_data=types.FileData(file_uri=youtube_url)\n            )\n        ]\n    )\n)\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Generating Personalized Product Descriptions with Google Gemini in Python\nDESCRIPTION: This code retrieves a product by ID, then iterates through all personas to generate personalized product descriptions using the Gemini Flash model. Each generated description is stored in a 'Personalized' collection with cross-references to both the original product and the persona.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_26\n\nLANGUAGE: python\nCODE:\n```\npersonalized = client.collections.get(\"Personalized\")\n\nproduct = products.query.fetch_object_by_id(product.uuid)\ndisplay_image(product.properties['link'])\n\npersonas = client.collections.get(\"Personas\")\n\nfor persona in personas.iterator():\n    generated_description = gemini_flash_model.generate_content([\"Create a product description tailored to the following person, make sure to use the name (\", persona.properties[\"name\"],\") of the persona.\\n\\n\", \"# Product Description\\n\", product.properties[\"description\"], \"# Persona\", persona.properties[\"description\"]]) # generate a description tailored to the persona\n    print(generated_description.text)\n    print('====')\n    # Add the personalized description to the `description` property in the Personalized collection\n    new_uuid = personalized.data.insert(\n        properties={\n            \"description\": generated_description.text },\n        references={\n            \"ofProduct\": product.uuid, # add cross-reference to the Product collection\n            \"ofPersona\": persona.uuid # add cross-reference to the Persona collection\n        },\n    )\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Compositional Function Calling with Gemini\nDESCRIPTION: Shows how to combine user-defined functions with code execution in Gemini to perform a sequence of operations - turning lights on, waiting, then turning them off.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprompt=\"Can you turn on the lights wait 10s and then turn them off?\"\n\ntools = [\n    {'code_execution': {}},\n    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n]\n\nawait run(prompt, tools=tools, modality=\"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up the Gemini Model with Function Calling\nDESCRIPTION: Configures the Gemini chat model with the ordering system functions as tools and the barista bot prompt as the system instruction, preparing it for automatic function calling during conversation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\nfrom google.api_core import retry\n\nordering_system = [\n    add_to_order,\n    get_order,\n    remove_item,\n    clear_order,\n    confirm_order,\n    place_order,\n]\nmodel_name = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\n\nchat = client.chats.create(\n    model=model_name,\n    config=types.GenerateContentConfig(\n        tools=ordering_system,\n        system_instruction=COFFEE_BOT_PROMPT,\n    ),\n)\n\nplaced_order = []\norder = []\n```\n\n----------------------------------------\n\nTITLE: Implementing Generative Feedback Loop with Gemini API and Weaviate in Python\nDESCRIPTION: Demonstrates a generative feedback loop where search results are enhanced with AI-generated content that's stored back in the database. The code finds travel jackets, uses Gemini to generate Facebook ad copy for each product, then updates the products with this new data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nresponse = products.query.near_text( # first find travel jackets\n    query=\"travel jacket\",\n    return_properties=[\"title\", \"description\", \"category\", \"link\"],\n    auto_limit=1, # limit it to 1 close group\n)\n\nfor product in response.objects:\n    if \"link\" in product.properties:\n        id = product.uuid\n        img_url = product.properties[\"link\"]\n\n        pil_image = url_to_pil(img_url) # convert image to PIL object\n        generated_description = gemini_flash_model.generate_content([\"Write a short Facebook ad about this product photo.\", pil_image]) # prompt to the Gemini API\n        generated_description = generated_description.text\n        display_image(product.properties['link'])\n        print(generated_description)\n        print('===')\n\n        # Update the Product collection with the generated description\n        products.data.update(uuid=id, properties={\"generated_description\": generated_description})\n```\n\n----------------------------------------\n\nTITLE: Implementing ReAct Class for Gemini Model in Python\nDESCRIPTION: This class sets up the ReAct pipeline for the Gemini model. It initializes the model, handles the ReAct prompt, and provides methods for cleaning text and adding new methods to the class.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclass ReAct:\n  def __init__(self, model: str, ReAct_prompt: str | os.PathLike):\n    \"\"\"Prepares Gemini to follow a `Few-shot ReAct prompt` by imitating\n    `function calling` technique to generate both reasoning traces and\n    task-specific actions in an interleaved manner.\n\n    Args:\n        model: name to the model.\n        ReAct_prompt: ReAct prompt OR path to the ReAct prompt.\n    \"\"\"\n    self.model = genai.GenerativeModel(model)\n    self.chat = self.model.start_chat(history=[])\n    self.should_continue_prompting = True\n    self._search_history: list[str] = []\n    self._search_urls: list[str] = []\n\n    try:\n      # try to read the file\n      with open(ReAct_prompt, 'r') as f:\n        self._prompt = f.read()\n    except FileNotFoundError:\n      # assume that the parameter represents prompt itself rather than path to the prompt file.\n      self._prompt = ReAct_prompt\n\n  @property\n  def prompt(self):\n    return self._prompt\n\n  @classmethod\n  def add_method(cls, func):\n    setattr(cls, func.__name__, func)\n\n  @staticmethod\n  def clean(text: str):\n    \"\"\"Helper function for responses.\"\"\"\n    text = text.replace(\"\\n\", \" \")\n    return text\n```\n\n----------------------------------------\n\nTITLE: Creating embedding generation functions\nDESCRIPTION: Defines functions to generate embeddings for text using the Gemini API. The embedding function uses retry logic for robustness and is configured for the classification task type.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom tqdm.auto import tqdm\nfrom google.genai import types\n\ntqdm.pandas()\n\nfrom google.api_core import retry\nimport numpy as np\nimport math\n\ndef make_embed_text_fn(model):\n\n    @retry.Retry(timeout=300.0)\n    def embed_fn(texts: list[str]) -> list[list[float]]:\n        # Set the task_type to CLASSIFICATION and embed the batch of texts\n        embeddings = client.models.embed_content(\n            model=model,\n            contents=texts,\n            config=types.EmbedContentConfig(task_type=\"CLASSIFICATION\"),\n        ).embeddings\n        return np.array([embedding.values for embedding in embeddings])\n\n    return embed_fn\n\n\ndef create_embeddings(df):\n    MODEL_ID = \"text-embedding-004\" # @param [\"embedding-001\", \"text-embedding-004\",\"gemini-embedding-exp-03-07\"] {\"allow-input\":true, isTemplate: true}\n    model = f\"models/{MODEL_ID}\"\n    embed_fn = make_embed_text_fn(model)\n\n    batch_size = 100  # at most 100 requests can be in one batch\n    all_embeddings = []\n\n    # Loop over the texts in chunks of batch_size\n    for i in tqdm(range(0, len(df), batch_size)):\n        batch = df[\"Text\"].iloc[i : i + batch_size].tolist()\n        embeddings = embed_fn(batch)\n        all_embeddings.extend(embeddings)\n\n    df[\"Embeddings\"] = all_embeddings\n    return df\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Gemini API in Python\nDESCRIPTION: This snippet uses the Gemini API to generate a 5-paragraph article about sports, including one other topic. It demonstrates how to use the generate_content method and display the result using IPython's Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Classification.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=\"Generate a 5 paragraph article about Sports, include one other topic\",\n)\narticle = response.text\nMarkdown(article)\n```\n\n----------------------------------------\n\nTITLE: Creating ChromaDB Vector Database\nDESCRIPTION: This function creates a ChromaDB vector database using the custom Gemini API embedding function and adds documents to the collection.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef create_chroma_db(documents, name):\n  chroma_client = chromadb.Client()\n  db = chroma_client.create_collection(\n      name=name,\n      embedding_function=GeminiEmbeddingFunction()\n  )\n\n  for i, d in enumerate(documents):\n    db.add(\n      documents=d,\n      ids=str(i)\n    )\n  return db\n```\n\n----------------------------------------\n\nTITLE: Customizing Safety Settings for Gemini API\nDESCRIPTION: This code demonstrates how to customize safety settings to allow potentially unsafe content. It defines safety thresholds for different harm categories and sends the same prompt with adjusted settings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nresponse = client.models.generate_content(\n    model = MODEL_ID,\n    contents = unsafe_prompt,\n    config = types.GenerateContentConfig(\n        safety_settings=[\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n              threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n              threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n              threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n              threshold=types.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n            )\n        ]\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Query Agent Function for Weaviate Database Interaction\nDESCRIPTION: Implements a function to send queries to the Weaviate database using the QueryAgent. It connects to Weaviate Cloud, sets up the QueryAgent with specified collections, and executes the query.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef query_agent_request(query: str) -> str:\n    \"\"\"\n    Send a query to the database and get the response.\n\n    Args:\n        query (str): The question or query to search for in the database. This can be any natural language question related to the content stored in the database.\n\n    Returns:\n        str: The response from the database containing relevant information.\n    \"\"\"\n\n    # connect to your Weaviate Cloud instance\n    weaviate_client = weaviate.connect_to_weaviate_cloud(\n        cluster_url=os.getenv(\"WEAVIATE_URL\"),\n        auth_credentials=weaviate.auth.AuthApiKey(os.getenv(\"WEAVIATE_API_KEY\")),\n        headers={  # add the API key to the model provider from your Weaviate collection, for example `headers={\"X-Goog-Studio-Api-Key\": os.getenv(\"GEMINI_API_KEY\")}`\n        }\n    )\n\n    # connect the query agent to your Weaviate collection(s)\n    query_agent = QueryAgent(\n        client=weaviate_client,\n        collections=[\"WeaviateBlogChunks\"]\n    )\n    return query_agent.run(query).final_answer\n```\n\n----------------------------------------\n\nTITLE: Invoking Gemini Model for Question-Answering\nDESCRIPTION: This snippet demonstrates how to use the created stuff documents chain to query the Gemini model with a specific question.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nrag_chain.invoke(\"What is Gemini?\")\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings for Text using Gemini API\nDESCRIPTION: Demonstrates how to generate embeddings for a piece of text using the Gemini API's embedding model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\ntitle = \"The next generation of AI for developers and Google Workspace\"\nsample_text = \"\"\"\n    Title: The next generation of AI for developers and Google Workspace\n    Full article:\n    Gemini API & Google AI Studio: An approachable way to explore and\n    prototype with generative AI applications\n\"\"\"\n\nEMBEDDING_MODEL_ID = \"models/embedding-001\"  # @param [\"models/embedding-gecko-001\", \"models/embedding-001\", \"models/text-embedding-004\", \"models/gemini-embedding-exp-03-07\", \"models/gemini-embedding-exp\"] {\"allow-input\": true, \"isTemplate\": true}\nembedding = client.models.embed_content(\n        model=EMBEDDING_MODEL_ID,\n        contents=sample_text,\n        config=types.EmbedContentConfig(\n            task_type=\"retrieval_document\",\n            title=title\n    ))\n\nprint(embedding)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for RAG Implementation\nDESCRIPTION: Imports necessary modules from LangChain, Pinecone, and other libraries for implementing the retrieval-augmented generation system.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import hub\nfrom langchain import PromptTemplate\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.prompt_template import format_document\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_pinecone import Pinecone\n\nfrom pinecone import Pinecone as pc\nfrom pinecone import PodSpec\n```\n\n----------------------------------------\n\nTITLE: Querying Qdrant Index with Gemini API Embeddings in Python\nDESCRIPTION: This code performs a similarity search on a Qdrant collection named 'GeminiCollection' using a query vector generated from the Gemini API embedding model. It searches for documents related to 'How can AI address climate challenges?' and returns the top 3 matches with their scores.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nhits = qdrant.search(\n    collection_name=\"GeminiCollection\",\n    query_vector=make_embed_text_fn(\"How can AI address climate challenges?\",\n                                    task_type=\"retrieval_query\"),\n    limit=3,\n)\nfor hit in hits:\n    print(hit.payload, \"score:\", hit.score)\n```\n\n----------------------------------------\n\nTITLE: Calculating Similarity Between Query and Search Results\nDESCRIPTION: Computes similarity scores between the user's query embedding and each search result embedding to find the most relevant results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nsim_value = dot_product(search_res, embedded_query)\n```\n\n----------------------------------------\n\nTITLE: Implementing Manual Backoff and Retry for Gemini API Calls in Python\nDESCRIPTION: Demonstrates a custom implementation of backoff and retry mechanism for finer control over error handling in Gemini API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.api_core import retry, exceptions\n\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")\n\n@retry.Retry(\n    predicate=retry.if_transient_error,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef generate_with_retry(model, prompt):\n    response = model.generate_content(prompt)\n    return response\n\nprompt = \"Write a one-liner advertisement for magic backpack.\"\n\ngenerate_with_retry(model=model, prompt=prompt)\n```\n\n----------------------------------------\n\nTITLE: Configuring API Authentication for Gemini\nDESCRIPTION: Sets up authentication for the Gemini API by retrieving the API key from Google Colab secrets and initializing the client with the key.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Viewing Default SQL Query Prompt Template\nDESCRIPTION: Displays the default prompt template used by the SQL query chain to understand how the system instructs the LLM to generate SQL queries.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nMarkdown(write_query_chain.get_prompts()[0].template)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini LLM Model with LangChain\nDESCRIPTION: Demonstrates how to initialize the Gemini model using ChatGoogleGenerativeAI from LangChain. The code shows configuration of model parameters like temperature and topP for the gemini-2.0-flash model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# To configure model parameters use the `generation_config` parameter.\n# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n# If you only want to set a custom temperature for the model use the\n# \"temperature\" parameter directly.\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n```\n\n----------------------------------------\n\nTITLE: Creating SQL Query Validation Prompt\nDESCRIPTION: Defines a prompt template to extract and validate SQL queries from the model's output, ensuring they are properly formatted for database execution.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nvalidate_prompt = PromptTemplate(\n    input_variables=[\"not_formatted_query\"],\n    template=\"\"\"\n        You are going to receive a text that contains a SQL query. Extract that query.\n        Make sure that it is a valid SQL command that can be passed directly to the Database.\n        Avoid using Markdown for this task.\n        Text: {not_formatted_query}\n    \"\"\"\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Text Summary Types\nDESCRIPTION: Defines TypedDict classes for structured story data including characters, locations, and summary information.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing_extensions import TypedDict  # in python 3.12 replace typing_extensions with typing\n\nclass Character(TypedDict):\n  name: str\n  description: str\n  alignment: str\n\nclass Location(TypedDict):\n  name: str\n  description: str\n\nclass TextSummary(TypedDict):\n  synopsis: str\n  genres: list[str]\n  locations: list[Location]\n  characters: list[Character]\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini API Client in Python\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab secrets and configures the model ID.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Story_Writing_with_Prompt_Chaining.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\nfrom google.colab import userdata\nfrom pprint import pprint\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient=genai.Client(api_key=GOOGLE_API_KEY)\n\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Generating Video Summary with Gemini API in Python\nDESCRIPTION: This snippet uses the Gemini API to generate a summary of a screen recording video. It allows customization of the prompt and video source, and outputs the response using Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\" # @param [\"Generate a paragraph that summarizes this video. Keep it to 3 to 5 sentences with corresponding timecodes.\", \"Choose 5 key shots from this video and put them in a table with the timecode, text description of 10 words or less, and a list of objects visible in the scene (with representative emojis).\", \"Generate bullet points for the video. Place each bullet point into an object with the timecode of the bullet point in the video.\"] {\"allow-input\":true}\n\nvideo = user_study_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n\nresponse = client.models.generate_content(\n    model=model_name,\n    contents=[\n        video,\n        prompt,\n    ]\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Embedding Model\nDESCRIPTION: Python code that imports and initializes Google's Gemini embedding model (embedding-001) from LlamaIndex, which will be used to create text embeddings of the website data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.embeddings.gemini import GeminiEmbedding\n\ngemini_embedding_model = GeminiEmbedding(model_name=\"models/embedding-001\")\n```\n\n----------------------------------------\n\nTITLE: Extracting phone numbers from text with Gemini\nDESCRIPTION: This code uses the Gemini API to extract all phone numbers from the customer service email and return them as a list, displaying the results using Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nphone_prompt = f\"\"\"\n  From the given text, extract the following entities and return a list of them.\n  Entities to extract: phone numbers.\n  Text: {customer_service_email}\n  Return your answer in a list:\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=phone_prompt\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Creating a Cached Content Object with Gemini Model\nDESCRIPTION: Creates a cached content object with the Apollo 11 transcript and system instructions using a specific Gemini model. This caches the prompt for efficient reuse.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Note that caching requires a frozen model, e.g. one with a `-001` suffix.\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\"  # @param [\"gemini-1.5-flash-8b-latest\", \"gemini-1.5-flash-002\", \"gemini-1.5-pro-002\", \"gemini-2.0-flash-001\", \"gemini-2.5-flash-preview-04-17\", \"gemini-2.5-pro-preview-03-25\"] {\"allow-input\":true, isTemplate: true}\n\napollo_cache = client.caches.create(\n    model=MODEL_ID,\n    config={\n        'contents': [document],\n        'system_instruction': 'You are an expert at analyzing transcripts.',\n    },\n)\n\napollo_cache\n```\n\n----------------------------------------\n\nTITLE: Few-shot prompting for city extraction with JSON output\nDESCRIPTION: Demonstrates few-shot prompting for extracting cities and their countries from text, with a JSON output format. The prompt provides two examples of the desired input-output pattern and configures the response MIME type as JSON.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Extract cities from text, include country they are in.\n    USER: I visited Mexico City and Poznan last year\n    MODEL: {\"Mexico City\": \"Mexico\", \"Poznan\": \"Poland\"}\n    USER: She wanted to visit Lviv, Monaco and Maputo\n    MODEL: {\"Minsk\": \"Ukraine\", \"Monaco\": \"Monaco\", \"Maputo\": \"Mozambique\"}\n    USER: I am currently in Austin, but I will be moving to Lisbon soon\n    MODEL:\n\"\"\"\n\nrespose=client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config=types.GenerateContentConfig(\n        response_mime_type= 'application/json',\n    ),\n)\n\nprint(respose.text)\n```\n\n----------------------------------------\n\nTITLE: Configuring Google API Key for Gemini\nDESCRIPTION: Sets up the Google API key as an environment variable for authentication with Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Storing Document Embeddings in Chroma Vector Store with LlamaIndex\nDESCRIPTION: This code initializes a Chroma persistent client, creates a collection, and builds a VectorStoreIndex to store document embeddings. It sets up the required settings for LLM and embedding models, then indexes the documents for later retrieval.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Create a client and a new collection\nclient = chromadb.PersistentClient(path=\"./chroma_db\")\nchroma_collection = client.get_or_create_collection(\"quickstart\")\n\n# Create a vector store\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n\n# Create a storage context\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# Set Global settings\nSettings.llm = llm\nSettings.embed_model = gemini_embedding_model\n\n# Create an index from the documents and save it to the disk.\nindex = VectorStoreIndex.from_documents(\n    documents, storage_context=storage_context\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Embedding Function for Gemini API\nDESCRIPTION: This snippet defines a custom embedding function using the Gemini API, which will be used with ChromaDB.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n  def __call__(self, input: Documents) -> Embeddings:\n    EMBEDDING_MODEL_ID = \"models/embedding-001\"  # @param [\"models/embedding-001\", \"models/text-embedding-004\", \"models/gemini-embedding-exp-03-07\", \"models/gemini-embedding-exp\"] {\"allow-input\": true, \"isTemplate\": true}\n    title = \"Custom query\"\n    response = client.models.embed_content(\n        model=EMBEDDING_MODEL_ID,\n        contents=input,\n        config=types.EmbedContentConfig(\n          task_type=\"retrieval_document\",\n          title=title\n        )\n    )\n\n    return response.embeddings[0].values\n```\n\n----------------------------------------\n\nTITLE: Creating Natural Language Answer Generation Chain\nDESCRIPTION: Defines the final chain that takes a question, generates and executes a SQL query, and formats the results into a natural language answer using the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nanswer_prompt = PromptTemplate.from_template(\"\"\"\n    You are going to receive a original user question, generated SQL query, and result of said query. You should use this information to answer the original question. Use only information provided to you.\n\n    Original Question: {question}\n    SQL Query: {query}\n    SQL Result: {result}\n    Answer: \"\"\"\n)\n\nanswer_chain = (\n    RunnablePassthrough.assign(query=validate_chain).assign(\n        result=itemgetter(\"query\") | execute_query\n    )\n    | answer_prompt | llm | StrOutputParser()\n)\n\nanswer_chain.invoke({\"question\": \"What is the total population?\"})\n```\n\n----------------------------------------\n\nTITLE: Creating a Function to Extract Structured Data from PDF Files in Python\nDESCRIPTION: Implements a reusable function that combines file uploading and structured data extraction using Gemini API and Pydantic models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef extract_structured_data(file_path: str, model: BaseModel):\n    # Upload the file to the File API\n    file = client.files.upload(file=file_path, config={'display_name': file_path.split('/')[-1].split('.')[0]})\n    # Generate a structured response using the Gemini API\n    prompt = f\"Extract the structured data from the following PDF file\"\n    response = client.models.generate_content(model=model_id, contents=[prompt, file], config={'response_mime_type': 'application/json', 'response_schema': model})\n    # Convert the response to the pydantic model and return it\n    return response.parsed\n```\n\n----------------------------------------\n\nTITLE: Performing Vector Search with Near Text in Weaviate Python\nDESCRIPTION: Demonstrates using the near_text operator to find objects with similar vectors to a query text. This searches for products matching 'travel mug', returns specific properties, and limits results to 3 objects.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nresponse = products.query.near_text(\n        query=\"travel mug\",\n        return_properties=[\"title\", \"description\", \"link\"], # only return these 3 properties\n        limit=3 # limited to 3 objects\n)\n\nfor product in response.objects:\n    print(json.dumps(product.properties, indent=2))\n    display_image(product.properties['link'])\n    print('===')\n```\n\n----------------------------------------\n\nTITLE: Basic Text Generation with Gemini API\nDESCRIPTION: Demonstrates how to make a basic REST call to Gemini API's generateContent endpoint for text generation\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[{\"text\": \"Give me python code to sort a list.\"}]\n        }]\n       }' 2> /dev/null\n```\n\n----------------------------------------\n\nTITLE: Generating Grocery List from Recipe\nDESCRIPTION: Processes a recipe text using Gemini API to extract a list of groceries with quantities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrecipe = \"\"\"\n  Step 1:\n  Grind 3 garlic cloves, knob of fresh ginger, roughly chopped, 3 spring onions to a paste in a food processor.\n  Add 2 tbsp of clear honey, juice from one orange, 1 tbsp of light soy sauce and 2 tbsp of vegetable oil, then blend again.\n  Pour the mixture over the cubed chicken from 4 small breast fillets and leave to marnate for at least 1hr.\n  Toss in the 20 button mushrooms for the last half an hour so the take on some of the flavour, too.\n\n  Step 2:\n  Thread the chicken, 20 cherry tomatoes, mushrooms and 2 large red peppers onto 20 wooden skewers,\n  then cook on a griddle pan for 7-8 mins each side or until the chicken is thoroughly cooked and golden brown.\n  Turn the kebabs frequently and baste with the marinade from time to time until evenly cooked.\n  Arrange on a platter, and eat with your fingers.\n\"\"\"\n\ngrocery_list = client.models.generate_content(\n    model=MODEL_ID,\n    contents=recipe,\n    config=grocery_extraction_config\n)\nprint(grocery_list.text)\n```\n\n----------------------------------------\n\nTITLE: Uploading PDF to Gemini API\nDESCRIPTION: Uploads the PDF file to the Gemini API using the File API, which allows the model to process the content of the PDF.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfile_ref = client.files.upload(file='test.pdf')\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Asynchronous Tasks with Gemini API\nDESCRIPTION: Comprehensive example demonstrating concurrent execution of a Gemini API streaming request alongside another asynchronous function, showing non-blocking behavior.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\n\nasync def get_response():\n    async for chunk in await client.aio.models.generate_content_stream(\n        model='gemini-2.0-flash',\n        contents='Tell me a story in 500 words.'\n    ):\n        if chunk.text:\n            print(chunk.text)\n        print(\"_\" * 80)\n\nasync def something_else():\n    for i in range(5):\n        print(\"==========not blocked!==========\")\n        await asyncio.sleep(1)\n\nasync def async_demo():\n    # Create tasks for concurrent execution\n    task1 = asyncio.create_task(get_response())\n    task2 = asyncio.create_task(something_else())\n    # Wait for both tasks to complete\n    await asyncio.gather(task1, task2)\n\n# In IPython notebooks, you can await the coroutine directly:\nawait async_demo()\n```\n\n----------------------------------------\n\nTITLE: Defining Examples for Few-Shot Prompting in Python\nDESCRIPTION: This snippet defines a set of examples to be used for few-shot prompting with the Gemini model. It includes several question-answer pairs with detailed thought processes and actions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nexamples = \"\"\"\nHere are some examples.\n\nQuestion\nWhat is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n\nThought 1\nI need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n\nAction 1\n<search>Colorado orogeny</search>\n\nObservation 1\nThe Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought 2\nIt does not mention the eastern sector. So I need to look up eastern sector.\n\nAction 2\n<lookup>eastern sector</lookup>\n\nObservation 2\nThe eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought 3\nThe eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n\nAction 3\n<search>High Plains</search>\n\nObservation 3\nHigh Plains refers to one of two distinct land regions\n\nThought 4\nI need to instead search High Plains (United States).\n\nAction 4\n<search>High Plains (United States)</search>\n\nObservation 4\nThe High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n\nThought 5\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n\nAction 5\n<finish>1,800 to 7,000 ft</finish>\n\nQuestion\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n\nThought 1\nThe question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n\nAction 1\n<search>Milhouse</search>\n\nObservation 1\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n\nThought 2\nThe paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n\nAction 2\n<lookup>named after</lookup>\n\nObservation 2\nMilhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n\nThought 3\nMilhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n\nAction 3\n<finish>Richard Nixon</finish>\n\nQuestion\nWhich documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n\nThought 1\nI need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.\n\nAction 1\n<search>Adam Clayton Powell</search>\n\nObservation 1\nCould not find [Adam Clayton Powell]. Similar: ['Adam Clayton Powell III', 'Seventh Avenue (Manhattan)', 'Adam Clayton Powell Jr. State Office Building', 'Isabel Washington Powell', 'Adam Powell', 'Adam Clayton Powell (film)', 'Giancarlo Esposito'].\n\nThought 2\nTo find the documentary, I can search Adam Clayton Powell (film).\n\nAction 2\n<search>Adam Clayton Powell (film)</search>\n\nObservation 2\nAdam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the rise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the PBS series The American Experience.\n\nThought 3\nAdam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.\n\nAction 3\n<finish>The Saimaa Gesture</finish>\n\nQuestion\nWhat profession does Nicholas Ray and Elia Kazan have in common?\n\nThought 1\nI need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n\nAction 1\n<search>Nicholas Ray</search>\n\nObservation 1\nNicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n\nThought 2\nProfessions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n\nAction 2\n<search>Elia Kazan</search>\n\nObservation 2\nElia Kazan was an American film and theatre director, producer, screenwriter and actor.\n\nThought 3\nProfessions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n\nAction 3\n<finish>director, screenwriter, actor</finish>\n\nQuestion\nWhich magazine was started first Arthur's Magazine or First for Women?\n\nThought 1\nI need to search Arthur's Magazine and First for Women, and find which was started first.\n\nAction 1\n<search>Arthur's Magazine</search>\n\nObservation 1\nArthur's Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n\nThought 2\nArthur's Magazine was started in 1844. I need to search First for Women next.\n\nAction 2\n<search>First for Women</search>\n\nObservation 2\nFirst for Women is a woman's magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n\nThought 3\nFirst for Women was started in 1989. 1844 (Arthur's Magazine) < 1989 (First for Women), so Arthur's Magazine was started first.\n\nAction 3\n<finish>Arthur's Magazine</finish>\n\nQuestion\nWere Pavel Urysohn and Leonid Levin known for the same type of work?\n\nThought 1\nI need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n\nAction 1\n<search>Pavel Urysohn</search>\n\nObservation 1\nPavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n\nThought 2\nPavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n\nAction 2\n<search>Leonid Levin</search>\n\nObservation 2\nLeonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n\nThought 3\nLeonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n\nAction 3\n<finish>yes</finish>\n\nQuestion\n{question}\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Processing Local Images Asynchronously\nDESCRIPTION: Demonstrates how to process local images using the Gemini API's async methods. This example processes images sequentially but uses async calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport PIL\n\nasync def describe_local_images():\n\n  for img_filename in img_filenames:\n\n    img = PIL.Image.open(img_filename)\n    r = await client.aio.models.generate_content(\n        model=MODEL_ID,\n        contents=[prompt, img]\n    )\n    print(r.text)\n\n\nawait describe_local_images()\n```\n\n----------------------------------------\n\nTITLE: Defining and Using Invoice Extraction Model with Gemini API in Python\nDESCRIPTION: Creates a Pydantic model for invoice data extraction and uses it to process an invoice PDF, demonstrating structured data extraction from documents.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\nclass Item(BaseModel):\n    description: str = Field(description=\"The description of the item\")\n    quantity: float = Field(description=\"The Qty of the item\")\n    gross_worth: float = Field(description=\"The gross worth of the item\")\n\nclass Invoice(BaseModel):\n    \"\"\"Extract the invoice number, date and all list items with description, quantity and gross worth and the total gross worth.\"\"\"\n    invoice_number: str = Field(description=\"The invoice number e.g. 1234567890\")\n    date: str = Field(description=\"The date of the invoice e.g. 2024-01-01\")\n    items: list[Item] = Field(description=\"The list of items with description, quantity and gross worth\")\n    total_gross_worth: float = Field(description=\"The total gross worth of the invoice\")\n\n\nresult = extract_structured_data(\"invoice.pdf\", Invoice)\nprint(type(result))\nprint(f\"Extracted Invoice: {result.invoice_number} on {result.date} with total gross worth {result.total_gross_worth}\")\nfor item in result.items:\n    print(f\"Item: {item.description} with quantity {item.quantity} and gross worth {item.gross_worth}\")\n```\n\n----------------------------------------\n\nTITLE: Extracting and Organizing Text from Video\nDESCRIPTION: API call to Gemini that transcribes and organizes text from sticky notes in a video, with options to generate additional ideas.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\" # @param [\"Transcribe the sticky notes, organize them and put it in a table. Can you come up with a few more ideas?\", \"Which of those names who fit an AI product that can resolve complex questions using its thinking abilities?\"] {\"allow-input\":true}\n\nvideo = post_its_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n\nresponse = client.models.generate_content(\n    model=model_name,\n    contents=[\n        video,\n        prompt,\n    ]\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings for Search Results and Query\nDESCRIPTION: Creates embedding vectors for both the search results and the user's query, which will be used to determine which search results are most relevant to the query.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nsearch_res = get_embeddings(summaries)\nembedded_query = get_embeddings([query])\n```\n\n----------------------------------------\n\nTITLE: Initializing the Gemini Model with LangChain\nDESCRIPTION: Setting up the Gemini 2.0 Flash model using LangChain's ChatGoogleGenerativeAI interface, which provides access to the model's text summarization capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# To configure model parameters use the `generation_config` parameter.\n# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n# If you only want to set a custom temperature for the model use the\n# \"temperature\" parameter directly.\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Model with LangChain\nDESCRIPTION: This snippet initializes the Gemini model using LangChain's ChatGoogleGenerativeAI class, configuring it for text summarization.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# To configure model parameters use the `generation_config` parameter.\n# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n# If you only want to set a custom temperature for the model use the\n# \"temperature\" parameter directly.\n\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n```\n\n----------------------------------------\n\nTITLE: Creating Embedding Function for Text Content\nDESCRIPTION: Defines a function that generates embeddings for text content using Gemini's embedding model. The embeddings are normalized and reshaped for semantic similarity calculations.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ndef get_embeddings(content: list[str]) -> np.ndarray:\n  embeddings = genai.embed_content('models/embedding-001', content, 'SEMANTIC_SIMILARITY')\n  embds = embeddings.get('embedding', None)\n  embds = np.array(embds).reshape(len(embds), -1)\n  return embds\n```\n\n----------------------------------------\n\nTITLE: Initializing Chat Session with Gemini API in Python\nDESCRIPTION: This snippet sets up a chat session with the Gemini API, configuring system instructions and enabling code execution tools. It prepares the model to act as an expert software developer and coding assistant.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nsystem_instruction = \"\"\"\n  You are an expert software developer and a helpful coding assistant.\n  You are able to generate high-quality code in any programming language.\n\"\"\"\n\nchat = client.chats.create(\n    model=MODEL_ID,\n    config=types.GenerateContentConfig(\n        system_instruction=system_instruction,\n        tools=[types.Tool(code_execution=types.ToolCodeExecution)],\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Embeddings for Hypothetical Answer\nDESCRIPTION: Generates an embedding vector for the hypothetical answer that will be used to re-rank search results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nhypothetical_ans = get_embeddings([res.text])\n```\n\n----------------------------------------\n\nTITLE: Setting up Chroma Retriever\nDESCRIPTION: Initializing a retriever interface for the Chroma vector store and testing its functionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nvectorstore_disk = Chroma(\n                        persist_directory=\"./chroma_db\",       # Directory of db\n                        embedding_function=gemini_embeddings   # Embedding model\n                   )\nretriever = vectorstore_disk.as_retriever(search_kwargs={\"k\": 1})\n\nprint(len(retriever.get_relevant_documents(\"MMLU\")))\n```\n\n----------------------------------------\n\nTITLE: Generating Embedding for Query\nDESCRIPTION: Creates an embedding for a sample query using the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nquery = \"How to shift gears in the Google car?\"\n\nrequest = client.models.embed_content(\n    model=EMBEDDING_MODEL_ID,\n    contents=query,\n    config=types.EmbedContentConfig(\n        task_type=\"retrieval_document\",\n        )\n)\n```\n\n----------------------------------------\n\nTITLE: Installing the Google Generative AI Python SDK\nDESCRIPTION: Pip command to install the Google Generative AI Python SDK for interacting with Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU 'google-genai>=1.0.0'\n```\n\n----------------------------------------\n\nTITLE: Generating Document Summary with Gemini API\nDESCRIPTION: Invoking the document processing chain with the loaded web documents to generate a concise summary using the Gemini 2.0 Flash model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nstuff_chain.invoke(docs)\n```\n\n----------------------------------------\n\nTITLE: Executing Wikipedia Search Function with Generated Arguments\nDESCRIPTION: Manually executes the Wikipedia search function using the arguments that were generated by the model in its function call.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nsummaries = wikipedia_search(**fc['args'])\n```\n\n----------------------------------------\n\nTITLE: Implementing Wikipedia Search Function for Gemini Function Calling\nDESCRIPTION: Defines a function that searches Wikipedia for a list of queries and extracts relevant information. This function uses the Gemini model to summarize Wikipedia content and can handle disambiguation errors and page errors.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef wikipedia_search(search_queries: list[str]) -> list[str]:\n  \"\"\"Search wikipedia for each query and summarize relevant docs.\"\"\"\n  n_topics=3\n  search_history = set() # tracking search history\n  search_urls = []\n  mining_model = genai.GenerativeModel('gemini-2.0-flash')\n  summary_results = []\n\n  for query in search_queries:\n    print(f'Searching for \"{query}\"')\n    search_terms = wikipedia.search(query)\n\n    print(f\"Related search terms: {search_terms[:n_topics]}\")\n    for search_term in search_terms[:n_topics]: # select first `n_topics` candidates\n      if search_term in search_history: # check if the topic is already covered\n        continue\n\n      print(f'Fetching page: \"{search_term}\"')\n      search_history.add(search_term) # add to search history\n\n      try:\n        # extract the relevant data by using `gemini-2.0-flash` model\n        page = wikipedia.page(search_term, auto_suggest=False)\n        url = page.url\n        print(f\"Information Source: {url}\")\n        search_urls.append(url)\n        page = page.content\n        response = mining_model.generate_content(textwrap.dedent(f\"\"\"\\\n            Extract relevant information\n            about user's query: {query}\n            From this source:\n\n            {page}\n\n            Note: Do not summarize. Only Extract and return the relevant information\n        \"\"\"))\n\n        urls = [url]\n        if response.candidates[0].citation_metadata:\n          extra_citations = response.candidates[0].citation_metadata.citation_sources\n          extra_urls = [source.url for source in extra_citations]\n          urls.extend(extra_urls)\n          search_urls.extend(extra_urls)\n          print(\"Additional citations:\", response.candidates[0].citation_metadata.citation_sources)\n        try:\n          text = response.text\n        except ValueError:\n          pass\n        else:\n          summary_results.append(text + \"\\n\\nBased on:\\n  \" + ',\\n  '.join(urls))\n\n      except DisambiguationError:\n        print(f\"\"\"Results when searching for \"{search_term}\" (originally for \"{query}\")\n        were ambiguous, hence skipping\"\"\")\n        continue\n\n      except PageError:\n        print(f'{search_term} did not match with any page id, hence skipping.')\n        continue\n        \n      except:\n        print(f'{search_term} did not match with any page id, hence skipping.')\n        continue\n\n  print(f\"Information Sources:\")\n  for url in search_urls:\n    print('    ', url)\n\n  return summary_results\n```\n\n----------------------------------------\n\nTITLE: Sending Function Results Back to Gemini\nDESCRIPTION: Creates a function response with the search results and sends it back to the model, allowing it to generate a final response based on the data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nresponse = chat.send_message(\n    genai.protos.Content(\n      parts=[genai.protos.Part(\n          function_response = genai.protos.FunctionResponse(\n            name='wikipedia_search',\n            response={'result': summaries}\n          )\n      )]\n    )\n)\n\nto_markdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Defining and Extracting Structured Data from Handwritten Form PDF using Python\nDESCRIPTION: This code defines a Form class using Pydantic BaseModel to structure the data extraction from a handwritten form PDF. It includes fields for form number, fiscal dates, and plan liabilities. The extract_structured_data function is used to process the PDF and extract the defined fields.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Form(BaseModel):\n    \"\"\"Extract the form number, fiscal start date, fiscal end date, and the plan liabilities beginning of the year and end of the year.\"\"\"\n    form_number: str = Field(description=\"The Form Number\")\n    start_date: str = Field(description=\"Effective Date\")\n    beginning_of_year: float = Field(description=\"The plan liabilities beginning of the year\")\n    end_of_year: float = Field(description=\"The plan liabilities end of the year\")\n\nresult = extract_structured_data(\"handwriting_form.pdf\", Form)\n\nprint(f'Extracted Form Number: {result.form_number} with start date {result.start_date}. \\nPlan liabilities beginning of the year {result.beginning_of_year} and end of the year {result.end_of_year}')\n```\n\n----------------------------------------\n\nTITLE: Processing Function Responses in Gemini Chat\nDESCRIPTION: Shows how to handle function responses and build message history for continued conversation with the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nmessages = [\n    genai.types.Content(role=\"user\", parts=[genai.types.Part(text=\"Which theaters in Mountain View show the Barbie movie?.\")]),\n    genai.types.Content(role=\"model\", parts=[part]),\n    {\"role\":\"user\", \"parts\":[{\"function_response\":{\"response\":{\"output\":result}, \"name\":part.function_call.name}}]},\n]\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=messages,\n    config = {\n        \"tools\": theater_functions,\n        \"automatic_function_calling\": {\"disable\": True}\n    }\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Using Function-Calling Mode (ANY) with Specific Functions\nDESCRIPTION: Forces the model to call a function from a specified subset of available functions by setting the mode to 'any' and providing allowed function names.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\navailable_fns = [\"set_light_color\", \"stop_lights\"]\n\ntool_config = tool_config_from_mode(\"any\", available_fns)\n\nresponse = chat.send_message(\"Make this place PURPLE!\", tool_config=tool_config)\nprint(response.parts[0])\n```\n\n----------------------------------------\n\nTITLE: Invoking the RAG Chain for Question Answering\nDESCRIPTION: Shows how to use the constructed RAG chain to answer questions by invoking it with a query string.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nrag_chain.invoke(\"What is Gemini?\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Wikipedia Search Method for ReAct Framework in Python\nDESCRIPTION: Defines a search method that queries Wikipedia for information on a specified topic. It retrieves the summary of the Wikipedia article if found, or returns similar search suggestions if the page doesn't exist. The method also maintains search history and source URLs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@ReAct.add_method\ndef search(self, query: str):\n    \"\"\"Perfoms search on `query` via Wikipedia api and returns its summary.\n\n    Args:\n        query: Search parameter to query the Wikipedia API with.\n\n    Returns:\n        observation: Summary of Wikipedia search for `query` if found else\n        similar search results.\n    \"\"\"\n    observation = None\n    query = query.strip()\n    try:\n      # try to get the summary for requested `query` from the Wikipedia\n      observation = wikipedia.summary(query, sentences=4, auto_suggest=False)\n      wiki_url = wikipedia.page(query, auto_suggest=False).url\n      observation = self.clean(observation)\n\n      # if successful, return the first 2-3 sentences from the summary as model's context\n      observation = self.model.generate_content(f'Retun the first 2 or 3 \\\n      sentences from the following text: {observation}')\n      observation = observation.text\n\n      # keep track of the model's search history\n      self._search_history.append(query)\n      self._search_urls.append(wiki_url)\n      print(f\"Information Source: {wiki_url}\")\n\n    # if the page is ambiguous/does not exist, return similar search phrases for model's context\n    except (DisambiguationError, PageError) as e:\n      observation = f'Could not find [\"{query}\"].'\n      # get a list of similar search topics\n      search_results = wikipedia.search(query)\n      observation += f' Similar: {search_results}. You should search for one of those instead.'\n\n    return observation\n```\n\n----------------------------------------\n\nTITLE: Implementing Chain of Thought Prompting in Python\nDESCRIPTION: This snippet shows how to use chain of thought prompting with the Gemini API. It provides an example problem and solution to guide the model in solving a similar problem step-by-step.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Chain_of_thought_prompting.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n  Question: 11 factories can make 22 cars per hour. How much time would it take 22 factories to make 88 cars?\n  Answer: A factory can make 22/11=2 cars per hour. 22 factories can make 22*2=44 cars per hour. Making 88 cars would take 88/44=2 hours. The answer is 2 hours.\n  Question: 5 people can create 5 donuts every 5 minutes. How much time would it take 25 people to make 100 donuts?\n  Answer:\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Creating a Prompt for Q&A in Python\nDESCRIPTION: This function creates a prompt for the Q&A system by formatting the query and relevant passage. It escapes special characters and structures the prompt with instructions for the AI model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport textwrap\n\ndef make_prompt(query, relevant_passage):\n  escaped = (\n      relevant_passage\n      .replace(\"'\", \"\")\n      .replace('\"', \"\")\n      .replace(\"\\n\", \" \")\n  )\n  prompt = textwrap.dedent(\"\"\"\n    You are a helpful and informative bot that answers questions using text\n    from the reference passage included below. Be sure to respond in a\n    complete sentence, being comprehensive, including all relevant\n    background information.\n\n    However, you are talking to a non-technical audience, so be sure to\n    break down complicated concepts and strike a friendly and conversational\n    tone. If the passage is irrelevant to the answer, you may ignore it.\n\n    QUESTION: '{query}'\n    PASSAGE: '{relevant_passage}'\n\n    ANSWER:\n  \"\"\").format(query=query, relevant_passage=escaped)\n\n\n  return prompt\n```\n\n----------------------------------------\n\nTITLE: Printing Tour Guide Response\nDESCRIPTION: Prints the generated content from the model responding as a German tour guide providing art museum recommendations in Berlin and Cologne.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Using Automatic Mode (AUTO) with Gemini Function Calling\nDESCRIPTION: Shows how to let the model decide whether to respond with text or call a function by setting the function calling mode to 'auto'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntool_config = tool_config_from_mode(\"auto\")\n\nresponse = chat.send_message(\"Light this place up!\", tool_config=tool_config)\nprint(response.parts[0])\nchat.rewind();  # You are not actually calling the function, so remove this from the history.\n```\n\n----------------------------------------\n\nTITLE: Translating Book Chunks with Progress Tracking\nDESCRIPTION: Processes each chunk of text by sending it to the Gemini API for translation, handling exceptions for sensitive content, and tracking progress with tqdm. Stores translated results in a list.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nresults = []\nindex = 0\ntranslation = None\n\nfor chunk in tqdm(chunks):\n    try:\n        translation = generate_output(translations(chunk))\n        results.append(translation)\n    except Exception as ex:\n        print(f\"Chunk was not included in translation due to possible sensitive content. Text: {chunk}\")\n\n    index += 1\n```\n\n----------------------------------------\n\nTITLE: Generating Blog Post Draft with Gemini\nDESCRIPTION: Creates a prompt to generate a blog post draft using the Gemini model, providing the audio file and blog examples, with system instructions and extended timeout for processing multimodal content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Draft my next blog post based on my thoughts in this audio file and these two previous blog posts I wrote.\"\n\nmodel = genai.GenerativeModel(model_name=\"models/gemini-2.0-flash\", system_instruction=si)\n\nresponse = model.generate_content([prompt, blog_file, blog_file2, audio_file],\n                                  request_options={\"timeout\": 600})\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Response Using Direct Schema Validation\nDESCRIPTION: Makes an API call with a schema object directly supplied in the configuration. This enforces strict adherence to the defined schema structure in the response, providing better type safety and validation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresult = client.models.generate_content(\n    model=MODEL_ID,\n    contents=\"List a few imaginative cookie recipes along with a one-sentence description as if you were a gourmet restaurant and their main ingredients\",\n    config={\n        'response_mime_type': 'application/json',\n        'response_schema': list[Recipe],\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Packages\nDESCRIPTION: Installation of necessary Python packages including LangChain and its dependencies, and ChromaDB for vector storage.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install --quiet langchain-core==0.1.23\n%pip install --quiet langchain==0.1.1\n%pip install --quiet langchain-google-genai==0.0.6\n%pip install --quiet -U langchain-community==0.0.20\n%pip install --quiet chromadb\n```\n\n----------------------------------------\n\nTITLE: Generating Code with Gemini\nDESCRIPTION: Using Gemini API to generate a countdown timer implementation based on user requirements\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncode_generation_prompt = \"\"\"\n  Create a countdown timer that ticks down every second and prints\n  \"Time is up!\" after 20 seconds\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=code_generation_prompt,\n    config=code_generation_model_config\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Extracting street names and transportation methods with Gemini\nDESCRIPTION: This code uses the Gemini API to extract street names and transportation methods from the directions text, displaying the results using IPython's Markdown renderer.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\ndirections_prompt = f\"\"\"\n  From the given text, extract the following entities and return a list of them.\n  Entities to extract: street name, form of transport.\n  Text: {directions}\n  Street = []\n  Transport = []\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=directions_prompt\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating embeddings for training and test data\nDESCRIPTION: Applies the embedding generation function to create embeddings for the texts in both the training and test datasets using the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndf_train = create_embeddings(df_train)\ndf_test = create_embeddings(df_test)\n```\n\n----------------------------------------\n\nTITLE: Creating Sentiment Analysis Helper Function in Python\nDESCRIPTION: This function generates content using the Gemini model for sentiment analysis. It takes a review as input and returns the sentiment scores using the defined structure.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\ndef generate_content(review):\n    MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n    return client.models.generate_content(\n        model=MODEL_ID,\n        contents=review,\n        config=types.GenerateContentConfig(\n            system_instruction=system_instruct,\n            response_mime_type=\"application/json\",\n            response_schema=Sentiment,\n        )\n    )\n```\n\n----------------------------------------\n\nTITLE: Building a Document Processing Chain with LangChain\nDESCRIPTION: Creating a 'Stuff documents chain' using LangChain Expression Language (LCEL) to combine document extraction, prompt formatting, LLM processing, and output parsing into a single workflow.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Create Stuff documents chain using LCEL.\n# This is called a chain because you are chaining\n# together different elements with the LLM.\n# In the following example, to create stuff chain,\n# you will combine content, prompt, LLM model and\n# output parser together like a chain using LCEL.\n#\n# The chain implements the following pipeline:\n# 1. Extract data from documents and save to variable `text`.\n# 2. This `text` is then passed to the prompt and input variable\n#    in prompt is populated.\n# 3. The prompt is then passed to the LLM (Gemini).\n# 4. Output from the LLM is passed through an output parser\n#    to structure the model response.\n\nstuff_chain = (\n    # Extract data from the documents and add to the key `text`.\n    {\n        \"text\": lambda docs: \"\\n\\n\".join(\n            format_document(doc, doc_prompt) for doc in docs\n        )\n    }\n    | llm_prompt         # Prompt for Gemini\n    | llm                # Gemini API function\n    | StrOutputParser()  # output parser\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Embeddings for Documents\nDESCRIPTION: Creates embeddings for each document in the DataFrame using the Gemini API and adds them to a new 'Embeddings' column.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Get the embeddings of each text and add to an embeddings column in the dataframe\ndef embed_fn(title, text):\n  response = client.models.embed_content(\n        model=EMBEDDING_MODEL_ID,\n        contents=text,\n        config=types.EmbedContentConfig(\n            task_type=\"retrieval_document\",\n            title=title\n        )\n    )\n\n  return response.embeddings[0].values\n\ndf['Embeddings'] = df.apply(lambda row: embed_fn(row['Title'], row['Text']), axis=1)\ndf\n```\n\n----------------------------------------\n\nTITLE: Training the classification model\nDESCRIPTION: Trains the neural network model on the embeddings with early stopping to prevent overfitting, using training data and validating on test data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nNUM_EPOCHS = 25\nBATCH_SIZE = 32\n\n# Split the x and y components of the train and validation subsets.\ny_train = df_train['Encoded Label']\nx_train = np.stack(df_train['Embeddings'])\ny_val = df_test['Encoded Label']\nx_val = np.stack(df_test['Embeddings'])\n\n# Train the model for the desired number of epochs.\ncallback = keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n\nhistory = classifier.fit(x=x_train,\n                         y=y_train,\n                         validation_data=(x_val, y_val),\n                         callbacks=[callback],\n                         batch_size=BATCH_SIZE,\n                         epochs=NUM_EPOCHS,)\n```\n\n----------------------------------------\n\nTITLE: Listing Tunable Models in Gemini API with Python\nDESCRIPTION: This snippet retrieves and displays a list of models available for tuning using the Gemini API. It filters models based on their support for the 'createTunedModel' generation method.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntunable_models = [\n    m for m in genai.list_models()\n    if \"createTunedModel\" in m.supported_generation_methods]\ntunable_models  # ['models/gemini-1.0-pro-001', 'models/gemini-1.5-flash-001-tuning']\n```\n\n----------------------------------------\n\nTITLE: Defining Instructions for Query Generation with Gemini\nDESCRIPTION: Creates a prompt template that instructs the Gemini model to generate supporting search queries for a user's original query. This helps to generate comprehensive search results by covering various aspects of the user's question.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ninstructions = \"\"\"You have access to the Wikipedia API which you will be using\nto answer a user's query. Your job is to generate a list of search queries which\nmight answer a user's question. Be creative by using various key-phrases from\nthe user's query. To generate variety of queries, ask questions which are\nrelated to  the user's query that might help to find the answer. The more\nqueries you generate the better are the odds of you finding the correct answer.\nHere is an example:\n\nuser: Tell me about Cricket World cup 2023 winners.\n\nfunction_call: wikipedia_search(['What is the name of the team that\nwon the Cricket World Cup 2023?', 'Who was the captain of the Cricket World Cup\n2023 winning team?', 'Which country hosted the Cricket World Cup 2023?', 'What\nwas the venue of the Cricket World Cup 2023 final match?', 'Cricket World cup 2023',\n'Who lifted the Cricket World Cup 2023 trophy?'])\n\nThe search function will return a list of article summaries, use these to\nanswer the  user's question.\n\nHere is the user's query: {query}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating Pinecone Retriever\nDESCRIPTION: This snippet creates a retriever from the Pinecone vector store and tests it by retrieving documents related to 'MMLU'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nretriever = vectorstore.as_retriever()\n# Check if the retriever is working by trying to fetch the relevant docs related\n# to the word 'MMLU'(Massive Multitask Language Understanding). If the length is\n# greater than zero, it means that the retriever is functioning well.\nprint(len(retriever.invoke(\"MMLU\")))\n```\n\n----------------------------------------\n\nTITLE: Making Authenticated REST Calls to Gemini API\nDESCRIPTION: This code shows how to make direct REST API calls to the Gemini API using OAuth authentication. It retrieves an access token from application default credentials and uses it to list available models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\naccess_token = !gcloud auth application-default print-access-token\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {access_token[0]}',\n}\n\nresponse = requests.get('https://generativelanguage.googleapis.com/v1/models', headers=headers)\nresponse_json = response.json()\n\n# All the model names\nfor model in response_json['models']:\n    print(model['name'])\n```\n\n----------------------------------------\n\nTITLE: Generating Hypothetical Document for HyDE Approach\nDESCRIPTION: Creates a hypothetical answer to the query using Gemini's internal knowledge, which will serve as a baseline for comparing search results using the HyDE (Hypothetical Document Embeddings) technique.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nhypothetical_ans_model = genai.GenerativeModel('gemini-2.0-flash')\nres = hypothetical_ans_model.generate_content(f\"\"\"Generate a hypothetical answer\nto the user's query by using your own knowledge. Assume that you know everything\nabout the said topic. Do not use factual information, instead use placeholders\nto complete your answer. Your answer should feel like it has been written by a human.\n\nquery: {query}\"\"\")\n\nto_markdown(res.text)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Authentication\nDESCRIPTION: Retrieves the API key from Google Colab's userdata secrets and configures the Gemini API client with the key for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Prompting Gemini API with Uploaded Audio File\nDESCRIPTION: Sends a request to the Gemini API to analyze the uploaded audio file and generate a description.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n. vars.sh\n\nfile_uri=$(jq \".file.uri\" file_info.json)\n\ncurl \"${BASE_URL}/v1beta/models/gemini-2.0-flash:generateContent?key=${GOOGLE_API_KEY}\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[\n          {\"text\": \"Please describe this file.\"},\n          {\"file_data\": {\n            \"mime_type\": \"'${MIME_TYPE}'\",\n            \"file_uri\": '${file_uri}'}}]\n        }]\n       }' 2>/dev/null >response.json\n\njq -C .candidates[].content response.json\n```\n\n----------------------------------------\n\nTITLE: Text Embedding Function Implementation\nDESCRIPTION: Function to create embeddings from text using Gemini's embedding model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\n# Select embedding model\nembedding_model = \"models/embedding-001\"  # @param [\"models/embedding-001\", \"models/text-embedding-004\", \"models/gemini-embedding-exp-03-07\", \"models/gemini-embedding-exp\"] {\"allow-input\": true, \"isTemplate\": true}\n\n\n# Function to convert text to embeddings\ndef make_embed_text_fn(text, model=embedding_model,\n                       task_type=\"retrieval_document\"):\n    embedding = client.models.embed_content(\n        model=model,\n        contents=text,\n        config=types.EmbedContentConfig(\n          task_type=task_type,\n        )\n    )\n    return embedding.embeddings[0].values\n```\n\n----------------------------------------\n\nTITLE: Chat Conversation with Gemini API\nDESCRIPTION: Demonstrates how to have a multi-turn conversation using the Gemini API with roles and context\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [\n        {\"role\":\"user\",\n         \"parts\":[{\n           \"text\": \"In one sentence, explain how a computer works to a young child.\"}]},\n        {\"role\": \"model\",\n         \"parts\":[{\n           \"text\": \"A computer is like a smart helper that can store information, do math problems, and follow our instructions to make things happen.\"}]},\n        {\"role\": \"user\",\n         \"parts\":[{\n           \"text\": \"Okay, how about a more detailed explanation to a high schooler?\"}]},\n      ]\n    }' 2> /dev/null | grep -C 5 \"text\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Code Execution Results with Gemini API in Python\nDESCRIPTION: This code demonstrates how to use streaming with code execution in the Gemini API. It sends a multimodal prompt and processes the streamed response, displaying results in real-time as they are generated.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nresult = client.models.generate_content_stream(\n    model=MODEL_ID,\n    contents=[\n        prompt,\n        montey_hall_image\n    ],\n    config=types.GenerateContentConfig(\n        tools=[types.Tool(code_execution=types.ToolCodeExecution)]\n    )\n)\n\nfor chunk in result:\n  display_code_execution_result(chunk)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini SDK Client with Beta API Version\nDESCRIPTION: Initializes the Google GenAI client with the v1beta API version, which is required for accessing the Gemini 2.0 live API features.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n\nclient = genai.Client(http_options={'api_version': 'v1beta'})\n```\n\n----------------------------------------\n\nTITLE: Pretty-Printing Schema-Validated JSON Response\nDESCRIPTION: Parses and formats the schema-validated response with indentation for better readability, then prints it to confirm the structure matches the Recipe schema definition.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(json.dumps(json.loads(result.text), indent=4))\n```\n\n----------------------------------------\n\nTITLE: Displaying Database Table Information\nDESCRIPTION: Retrieves and displays metadata about the database tables to understand what information is available for querying.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# you can see what information is available\nMarkdown(db.get_table_info())\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Model with Automatic Function Calling\nDESCRIPTION: Creates a Gemini model configured with Wikipedia search tool and starts a chat session with automatic function calling enabled. This allows the model to autonomously execute the function when needed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(\n    'gemini-2.0-flash', tools=[wikipedia_search], generation_config={'temperature': 0.6})\n\nchat = model.start_chat(enable_automatic_function_calling=True)\n\nquery = \"Explain how deep-sea life survives.\"\n\nres = chat.send_message(instructions.format(query=query))\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Selected Gemini Model in Python\nDESCRIPTION: This snippet selects a Gemini model and uses it to generate content based on the prompt. It allows for model selection through a parameter and uses the 'client' object to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nanswer = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Pinecone Client and Creating Index\nDESCRIPTION: This snippet initializes a Pinecone client, checks if an index exists, and creates a new one if it doesn't. It then initializes a vector store using the created index.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\npine_client= pc(\n    api_key = os.getenv(\"PINECONE_API_KEY\"),  # API key from app.pinecone.io\n    )\nindex_name = \"langchain-demo\"\n\n# First, check if the index already exists. If it doesn't, create a new one.\nif index_name not in pine_client.list_indexes().names():\n    # Create a new index.\n    # https://docs.pinecone.io/docs/new-api#creating-a-starter-index\n    print(\"Creating index\")\n    pine_client.create_index(name=index_name,\n                      # `cosine` distance metric compares different documents\n                      # for similarity.\n                      # Read more about different distance metrics from\n                      # https://docs.pinecone.io/docs/indexes#distance-metrics.\n                      metric=\"cosine\",\n                      # The Gemini embedding model `embedding-001` uses\n                      # 768 dimensions.\n                      dimension=768,\n                      # Specify the pod details.\n                      spec=PodSpec(\n                        # Starter indexes are hosted in the `gcp-starter`\n                        # environment.\n                        environment=\"gcp-starter\",\n                        pod_type=\"starter\",\n                        pods=1)\n    )\n    print(pine_client.describe_index(index_name))\n\nvectorstore = Pinecone.from_documents(docs,\n                      gemini_embeddings, index_name=index_name)\n```\n\n----------------------------------------\n\nTITLE: Performing Entity Extraction with Gemini API\nDESCRIPTION: Implementation of entity extraction using Gemini API. The code defines entity categories (Person, Company, State, City) through a Python class structure, sends a text sample for analysis, and configures the model to return JSON output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Entity_Extraction_JSON.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\nfrom typing_extensions import TypedDict # in python 3.12 replace typing_extensions with typing\nfrom google.genai import types\n\nentity_recognition_text = \"John Johnson, the CEO of the Oil Inc. and Coal Inc. companies, has unveiled plans to build a new factory in Houston, Texas.\"\nprompt = f\"\"\"\nGenerate list of entities in text based on the following Python class structure:\n\nclass CategoryEnum(str, Enum):\n    Person = 'Person'\n    Company = 'Company'\n    State = 'State'\n    City = 'City'\n\nclass Entity(TypedDict):\n  name: str\n  category: CategoryEnum\n\nclass Entities(TypedDict):\n  entities: list[Entity]\n\n{entity_recognition_text}\"\"\"\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config=types.GenerateContentConfig(\n        temperature=0,\n        response_mime_type=\"application/json\"\n    )\n  )\n```\n\n----------------------------------------\n\nTITLE: Storing Embeddings in Qdrant\nDESCRIPTION: Inserting document embeddings into Qdrant collection using batch processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nqdrant.upsert(\n    collection_name=\"GeminiCollection\",\n    points=[\n        # Use PointStruct function to intialize the point.\n        models.PointStruct(\n            # Use `make_embed_text_fn` to convert text to embeddings.\n            # Pass the same data as payload for a refined search.\n            id=idx, vector=make_embed_text_fn(doc[\"content\"]), payload = doc\n        )\n        for idx, doc in enumerate(documents)\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Response Using Schema in Prompt\nDESCRIPTION: Makes an API call to the Gemini model with JSON mode enabled by setting the response_mime_type parameter. The model will attempt to format its response according to the schema described in the prompt.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nraw_response = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config={\n        'response_mime_type': 'application/json'\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Selecting a Gemini Model for Use\nDESCRIPTION: Specifies which Gemini model to use via a parameter dropdown. Allows selection from various models including gemini-2.0-flash-lite, gemini-2.0-flash, gemini-2.5-flash-preview, and gemini-2.5-pro-exp models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\n# Ideally order the model by \"cabability\" ie. generation then within generation\n# 8b/flash-lite then flash then pro\n```\n\n----------------------------------------\n\nTITLE: Generating Basic Text Embeddings with Gemini API\nDESCRIPTION: Demonstrates how to generate a text embedding for a single text prompt using the text-embedding-004 model. The example shows the beginning of the resulting embedding vector and prints its dimensionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntext = [\"Hello world\"]\nresult = client.models.embed_content(model=\"text-embedding-004\", contents=text)\n[embedding] = result.embeddings\n\n# Print just a part of the embedding to keep the output manageable\nprint(str(embedding.values)[:50], '... TRIMMED]')\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini Tool with Query Agent\nDESCRIPTION: Sets up the Gemini API to use the query_agent_request function as a tool for generating content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nconfig = types.GenerateContentConfig(tools=[query_agent_request])\n```\n\n----------------------------------------\n\nTITLE: Calculating Similarity with Hypothetical Answer\nDESCRIPTION: Computes similarity scores between the hypothetical answer embedding and each search result embedding to find results that align with the hypothetical document.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nsim_value = dot_product(search_res, hypothetical_ans)\n```\n\n----------------------------------------\n\nTITLE: Creating Prompt for Gemini API\nDESCRIPTION: This function creates a prompt for the Gemini API using the query and relevant passage retrieved from the ChromaDB database.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef make_prompt(query, relevant_passage):\n  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n  prompt = (\"\"\"\n    You are a helpful and informative bot that answers questions using\n    text from the reference passage included below.\n    Be sure to respond in a complete sentence, being comprehensive,\n    including all relevant background information.\n    However, you are talking to a non-technical audience, so be sure to\n    break down complicated concepts and strike a friendly\n    and converstional tone. If the passage is irrelevant to the answer,\n    you may ignore it.\n    QUESTION: '{query}'\n    PASSAGE: '{relevant_passage}'\n\n    ANSWER:\n  \"\"\").format(query=query, relevant_passage=escaped)\n\n  return prompt\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Call Handler in Python\nDESCRIPTION: Creates a utility function to handle function calls dynamically based on function name and arguments.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef call_function(function_call, functions):\n    function_name = function_call.name\n    function_args = function_call.args\n    # Find the function object from the list based on the function name\n    for func in functions:\n        if func.__name__ == function_name:\n            return func(**function_args)\n\npart = response.candidates[0].content.parts[0]\n\n# Check if it's a function call; in real use you'd need to also handle text\n# responses as you won't know what the model will respond with.\nif part.function_call:\n    result = call_function(part.function_call, theater_functions)\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Authentication with Google Generative AI\nDESCRIPTION: Retrieves the API key from Colab Secrets and initializes the Generative AI client. This is required for authenticating API requests to the Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Creating DeepLake Database\nDESCRIPTION: Setting up DeepLake database with embeddings for document storage\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# define path to database\ndataset_path = 'mem://deeplake/langchain_google'\n\n# define the embedding model\nembeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n\ndb = DeepLake.from_documents(docs, embeddings, dataset_path=dataset_path)\n```\n\n----------------------------------------\n\nTITLE: Creating User Personas with Gemini API in Python\nDESCRIPTION: Generates fictional buyer personas using the Gemini API. Creates two personas (Alice and Bob) with AI-generated descriptions and stores them in the Personas collection for use in personalized content generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\npersonas = client.collections.get(\"Personas\")\n\nfor persona in ['Alice', 'Bob']:\n  generated_description = gemini_flash_model.generate_content([\"Create a fictional buyer persona named \" + persona + \", write a short description about them\"]) # use gemini-2.0-flash to generate persona description\n  uuid = personas.data.insert({\n    \"name\": persona,\n    \"description\": generated_description.text\n  })\n  print(uuid)\n  print(generated_description.text)\n  print(\"===\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with API Key\nDESCRIPTION: Sets up the Google Generative AI client using an API key stored in Google Colab Secrets. This authenticates the application to make API calls to Gemini.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Models for Structured Data Extraction in Python\nDESCRIPTION: Creates Pydantic models to define the structure for person data extraction, showing how to use Field() for adding descriptions to properties.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel, Field\n\n# Define a Pydantic model\n# Use the Field class to add a description and default value to provide more context to the model\nclass Topic(BaseModel):\n    name: str = Field(description=\"The name of the topic\")\n\nclass Person(BaseModel):\n    first_name: str = Field(description=\"The first name of the person\")\n    last_name: str = Field(description=\"The last name of the person\")\n    age: int = Field(description=\"The age of the person, if not provided please return 0\")\n    work_topics: list[Topic] = Field(description=\"The fields of interest of the person, if not provided please return an empty list\")\n\n\n# Define the prompt\nprompt = \"Philipp Schmid is a Senior AI Developer Relations Engineer at Google DeepMind working on Gemini, Gemma with the mission to help every developer to build and benefit from AI in a responsible way.  \"\n\n# Generate a response using the Person model\nresponse = client.models.generate_content(model=model_id, contents=prompt, config={'response_mime_type': 'application/json', 'response_schema': Person})\n\n# print the response as a json string\nprint(response.text)\n\n# sdk automatically converts the response to the pydantic model\nphilipp: Person = response.parsed\n\n# access an attribute of the json response\nprint(f\"First name is {philipp.first_name}\")\n```\n\n----------------------------------------\n\nTITLE: Loading Web Data Using SimpleWebPageReader\nDESCRIPTION: Python code that loads data from a Google blog about Gemini AI using LlamaIndex's SimpleWebPageReader, then extracts the HTML content from the loaded document.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nweb_documents = SimpleWebPageReader().load_data(\n    [\"https://blog.google/technology/ai/google-gemini-ai/\"]\n)\n\n# Extract the content from the website data document\nhtml_content = web_documents[0].text\n```\n\n----------------------------------------\n\nTITLE: Defining JSON Schema in the Prompt\nDESCRIPTION: Creates a prompt that requests cookie recipes and specifies the expected JSON schema format directly in the prompt text. This approach uses natural language to constrain the model's output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n  List a few popular cookie recipes using this JSON schema:\n\n  Recipe = {'recipe_name': str}\n  Return: list[Recipe]\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Examining Safety Ratings After Settings Adjustment\nDESCRIPTION: This code displays the safety ratings for the response after adjusting safety settings. It shows which categories were triggered and their corresponding safety ratings, even if the content was allowed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\npprint(response.candidates[0].safety_ratings, indent=2)\n```\n\n----------------------------------------\n\nTITLE: Implementing Wikipedia Lookup Method for ReAct Framework in Python\nDESCRIPTION: Defines a lookup method that searches for a specific phrase within the last visited Wikipedia page. It extracts text surrounding the phrase based on a specified context length, providing targeted information retrieval capabilities within a larger document.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@ReAct.add_method\ndef lookup(self, phrase: str, context_length=200):\n    \"\"\"Searches for the `phrase` in the lastest Wikipedia search page\n    and returns number of sentences which is controlled by the\n    `context_length` parameter.\n\n    Args:\n        phrase: Lookup phrase to search for within a page. Generally\n        attributes to some specification of any topic.\n\n        context_length: Number of words to consider\n        while looking for the answer.\n\n    Returns:\n        result: Context related to the `phrase` within the page.\n    \"\"\"\n    # get the last searched Wikipedia page and find `phrase` in it.\n    page = wikipedia.page(self._search_history[-1], auto_suggest=False)\n    page = page.content\n    page = self.clean(page)\n    start_index = page.find(phrase)\n\n    # extract sentences considering the context length defined\n    result = page[max(0, start_index - context_length):start_index+len(phrase)+context_length]\n    print(f\"Information Source: {self._search_urls[-1]}\")\n    return result\n```\n\n----------------------------------------\n\nTITLE: Analyzing Images in PDF with Gemini\nDESCRIPTION: Queries the Gemini model to specifically explain the images on the first page of the PDF document, demonstrating multimodal understanding.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresponse_2 = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[file_ref, 'Can you explain the images on the first page of the document?']\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Parameters\nDESCRIPTION: Shows how to configure various parameters like temperature, safety settings, and output tokens for the Gemini API\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n        \"contents\": [{\n            \"parts\":[\n                {\"text\": \"Give me a numbered list of cat facts.\"}\n            ]\n        }],\n        \"safetySettings\": [\n            {\n                \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n                \"threshold\": \"BLOCK_ONLY_HIGH\"\n            }\n        ],\n        \"generationConfig\": {\n            \"stopSequences\": [\n                \"Title\"\n            ],\n            \"temperature\": 0.9,\n            \"maxOutputTokens\": 2000,\n        }\n    }'  2> /dev/null | grep \"text\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini API Client\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Google Colab secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Parsing HTML Content with BeautifulSoup\nDESCRIPTION: Python code that uses BeautifulSoup to parse the HTML content, extracts text from all paragraph tags, and converts the extracted text back to LlamaIndex's Document format.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Parse the data.\nsoup = BeautifulSoup(html_content, 'html.parser')\np_tags = soup.findAll('p')\ntext_content = \"\"\nfor each in p_tags:\n    text_content += each.text + \"\\n\"\n\n# Convert back to Document format\ndocuments = [Document(text=text_content)]\n```\n\n----------------------------------------\n\nTITLE: Uploading File to Gemini API\nDESCRIPTION: Uploads the Apollo 11 transcript file to the Gemini API using the File API for further processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndocument = client.files.upload(file=\"a11.txt\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Self-ask Prompting with Gemini API\nDESCRIPTION: This code demonstrates how to use self-ask prompting with the Gemini API. It includes a prompt template and generates a response using the selected model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Self_ask_prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nprompt = \"\"\"\n  Question: Who was the president of the united states when Mozart died?\n  Are follow up questions needed?: yes.\n  Follow up: When did Mozart died?\n  Intermediate answer: 1791.\n  Follow up: Who was the president of the united states in 1791?\n  Intermediate answer: George Washington.\n  Final answer: When Mozart died George Washington was the president of the USA.\n\n  Question: Where did the Emperor of Japan, who ruled the year Maria\n  Skodowska was born, die?\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Response using Gemini API\nDESCRIPTION: This snippet uses the Gemini API to generate a response based on the created prompt and selected model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\nanswer = client.models.generate_content(\n    model = MODEL_ID,\n    contents = prompt\n)\nMarkdown(answer.text)\n```\n\n----------------------------------------\n\nTITLE: Defining Topic Classification Schema and Generating Topics with Gemini API in Python\nDESCRIPTION: This code defines an enum for relevance and a TypedDict for topics. It then uses the Gemini API to generate topics from the previously created article, with a custom system instruction and JSON output schema.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Classification.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport enum\nfrom typing_extensions import TypedDict  # in python 3.12 replace typing_extensions with typing\n\nfrom google.genai import types\n\n\nclass Relevance(enum.Enum):\n  WEAK = \"weak\"\n  STRONG = \"strong\"\n\nclass Topic(TypedDict):\n  topic: str\n  relevance: Relevance\n\n\nsys_int = \"\"\"\nGenerate topics from text. Ensure that topics are general e.g. \"Health\".\nStrong relevance is obtained when the topic is a core tenent of the content\nand weak relevance reflects one or two mentions.\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=article,\n    config=types.GenerateContentConfig(\n        system_instruction=sys_int,\n        response_mime_type=\"application/json\",\n        response_schema=list[Topic],\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Performing Hybrid Search in Weaviate Python\nDESCRIPTION: Shows how to use hybrid search which combines keyword (BM25) and vector search techniques. The alpha parameter (0.75) leans more towards vector search while still using some keyword matching for the query 'dishwasher safe container'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nresponse = products.query.hybrid(\n    query = \"dishwasher safe container\", # query\n    alpha = 0.75, # leaning more towards vector search\n    return_properties=[\"title\", \"description\", \"link\"], # return these 3 properties\n    limit = 3 # limited to only 3 objects\n)\n\nfor product in response.objects:\n    print(json.dumps(product.properties, indent=2))\n    display_image(product.properties['link'])\n    print('===')\n```\n\n----------------------------------------\n\nTITLE: Defining Mathematical Operation Functions\nDESCRIPTION: Implementation of basic arithmetic functions with type annotations for function calling\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\ndef add(a: float, b: float):\n    \"\"\"returns a + b.\"\"\"\n    return a + b\n\n\ndef subtract(a: float, b: float):\n    \"\"\"returns a - b.\"\"\"\n    return a - b\n\n\ndef multiply(a: float, b: float):\n    \"\"\"returns a * b.\"\"\"\n    return a * b\n\n\ndef divide(a: float, b: float):\n    \"\"\"returns a / b.\"\"\"\n    return a / b\n\n\noperation_tools = [add, subtract, multiply, divide]\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Gemini API using Service Account Credentials in Python\nDESCRIPTION: This snippet demonstrates how to authenticate with the Google Generative AI API using a service account key stored in Google Colab's secrets. It loads the service account credentials, applies appropriate OAuth scopes for cloud platform and generative language retrieval, then configures the genai SDK with these credentials and lists available models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\nimport pathlib\nfrom google.colab import userdata\nfrom google.oauth2 import service_account\n\npathlib.Path('service_account_key.json').write_text(userdata.get('SERVICE_ACCOUNT_KEY'))\n\ncredentials = service_account.Credentials.from_service_account_file('service_account_key.json')\n\n# Adjust scopes as needed\nscoped_credentials = credentials.with_scopes(\n    ['https://www.googleapis.com/auth/cloud-platform', 'https://www.googleapis.com/auth/generative-language.retriever'])\n\ngenai.configure(credentials=scoped_credentials)\n\nprint('Available base models:', [m.name for m in genai.list_models()])\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Metadata from Gemini API File API in Python\nDESCRIPTION: Shows how to retrieve metadata for a file previously uploaded to the Gemini API File API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfile = client.files.get(name=sample_file.name)\nprint(f\"Retrieved file '{file.name}' as: {sample_file.uri}\")\n```\n\n----------------------------------------\n\nTITLE: Checking Finish Reason After Safety Settings Adjustment\nDESCRIPTION: This code checks if the request succeeded after adjusting safety settings. If the finish_reason is STOP, it means the content was successfully generated without being blocked by safety filters.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(response.candidates[0].finish_reason)\n```\n\n----------------------------------------\n\nTITLE: Listing Available Gemini Models\nDESCRIPTION: Lists all available models that support the generateContent method for prompting\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\nfor model in client.models.list():\n    print(model.name)\n```\n\n----------------------------------------\n\nTITLE: Querying with Context Example\nDESCRIPTION: Demonstrates how to query the Gemini API with additional context about Olympic athletes' participation records.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n  QUERY: provide a list of atheletes that competed in olympics exactly 9 times.\n  CONTEXT:\n\n  Table title: Olympic athletes and number of times they've competed\n  Ian Millar, 10\n  Hubert Raudaschl, 9\n  Afanasijs Kuzmins, 9\n  Nino Salukvadze, 9\n  Piero d'Inzeo, 8\n  Raimondo d'Inzeo, 8\n  Claudia Pechstein, 8\n  Jaqueline Mouro, 8\n  Ivan Osiier, 7\n  Franois Lafortune, Jr, 7\n\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt\n    )\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Creating LangChain Prompt Templates for Question Answering\nDESCRIPTION: Shows how to create a prompt template using LangChain's PromptTemplate class. The template includes placeholders for the question and context that will be populated during execution.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Prompt template to query Gemini\nllm_prompt_template = \"\"\"You are an assistant for question-answering tasks.\nUse the following context to answer the question.\nIf you don't know the answer, just say that you don't know.\nUse five sentences maximum and keep the answer concise.\\n\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\"\n\nllm_prompt = PromptTemplate.from_template(llm_prompt_template)\n\nprint(llm_prompt)\n```\n\n----------------------------------------\n\nTITLE: License Declaration for Apache License 2.0 in Python\nDESCRIPTION: Standard license header that declares the project is licensed under Apache License 2.0, specifying usage permissions and limitations.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring API Authentication\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Setting up QA Chain\nDESCRIPTION: Configuration of retrieval-based question answering chain using Gemini model\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nretriever = db.as_retriever()\nretriever.search_kwargs['distance_metric'] = 'cos'\nretriever.search_kwargs['k'] = 20 # number of documents to return\n\n# define the chat model\nllm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")\n\nqa = RetrievalQA.from_llm(llm, retriever=retriever)\n```\n\n----------------------------------------\n\nTITLE: Defining Order Management Functions for Caf System\nDESCRIPTION: Creates a set of functions that manage a caf ordering system, including adding, removing, and clearing items, getting order status, confirming with the customer, and placing the final order. These functions will be exposed to the Gemini model as tools.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Optional\nfrom random import randint\n\norder = []  # The in-progress order.\nplaced_order = []  # The confirmed, completed order.\n\n\ndef add_to_order(drink: str, modifiers: Optional[list[str]] = None) -> None:\n    \"\"\"Adds the specified drink to the customer's order, including any modifiers.\"\"\"\n    if modifiers is None:  # Ensures safe handling of None\n        modifiers = []\n    order.append((drink, modifiers))\n\n\ndef get_order() -> list[tuple[str, list[str]]]:\n    \"\"\"Returns the customer's order.\"\"\"\n    return order\n\n\ndef remove_item(n: int) -> str:\n    \"\"\"Removes the nth (one-based) item from the order.\n\n    Returns:\n        The item that was removed.\n    \"\"\"\n    item, _ = order.pop(n - 1)\n    return item\n\n\ndef clear_order() -> None:\n    \"\"\"Removes all items from the customer's order.\"\"\"\n    order.clear()\n\n\ndef confirm_order() -> str:\n    \"\"\"Asks the customer if the order is correct.\n\n    Returns:\n        The user's free-text response.\n    \"\"\"\n    print(\"Your order:\")\n    if not order:\n        print(\"  (no items)\")\n\n    for drink, modifiers in order:\n        print(f\"  {drink}\")\n        if modifiers:\n            print(f'   - {\", \".join(modifiers)}')\n\n    return input(\"Is this correct? \")\n\n\ndef place_order() -> int:\n    \"\"\"Submit the order to the kitchen.\n\n    Returns:\n        The estimated number of minutes until the order is ready.\n    \"\"\"\n    placed_order[:] = order.copy()\n    clear_order()\n\n    # TODO: Implement coffee fulfillment.\n    return randint(1, 10)\n```\n\n----------------------------------------\n\nTITLE: Generating PDF Summary with Gemini\nDESCRIPTION: Sends the PDF file along with a prompt to the Gemini model to generate a bulleted list summary of the document.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[file_ref, 'Can you summarize this file as a bulleted list?']\n)\n```\n\n----------------------------------------\n\nTITLE: Solving a Mathematical Triangle Area Problem with Gemini\nDESCRIPTION: Demonstrates solving a basic geometry problem about calculating the area of a triangle by sending the problem to the Gemini API with the previously defined system instructions and displaying the response as Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmath_problem = \"\"\"\n  Given a triangle with base b=6 and height h=8, calculate its area\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=math_problem,\n    config=config,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Zero-shot Sentiment Analysis Example with Gemini\nDESCRIPTION: Shows how to use zero-shot prompting for sentiment classification of a restaurant review. The code queries the Gemini model and formats the response as Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Classify sentiment of review as positive, negative or neutral:\n    I go to this restaurant every week, I love it so much.\n\"\"\"\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Loading and Parsing Website Data with LangChain\nDESCRIPTION: Uses LangChain's WebBaseLoader to load content from a specified URL and extract relevant portions of the text.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nloader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/\")\ndocs = loader.load()\n\n# Extract the text from the website data document\ntext_content = docs[0].page_content\n# The text content between the substrings \"code, audio, image and video.\" to\n# \"Cloud TPU v5p\" is relevant for this tutorial. You can use Python's `split()`\n# to select the required content.\ntext_content_1 = text_content.split(\"code, audio, image and video.\",1)[1]\nfinal_text = text_content_1.split(\"Cloud TPU v5p\",1)[0]\n\n# Convert the text to LangChain's `Document` format\ndocs = [Document(page_content=final_text, metadata={\"source\": \"local\"})]\n```\n\n----------------------------------------\n\nTITLE: Building a neural network classification model\nDESCRIPTION: Defines a function to build a simple neural network model for classification with one hidden layer and a softmax output layer for multi-class classification.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nimport keras\nfrom keras import layers\n\ndef build_classification_model(input_size: int, num_classes: int) -> keras.Model:\n  inputs = x = keras.Input(shape=(input_size,))\n  x = layers.Dense(input_size, activation='relu')(x)\n  x = layers.Dense(num_classes, activation='softmax')(x)\n  return keras.Model(inputs=inputs, outputs=x)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini 2.0 Client with API Key\nDESCRIPTION: Creates a Gemini 2.0 client instance using the provided API key. This client is used to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Implementing Finish Method for ReAct Framework in Python\nDESCRIPTION: Defines a finish method that terminates the conversation pipeline by setting the 'should_continue_prompting' flag to False. It also prints the information sources used during the conversation, providing transparency about the knowledge base consulted.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n@ReAct.add_method\ndef finish(self, _):\n  \"\"\"Finishes the conversation on encountering <finish> token by\n  setting the `self.should_continue_prompting` flag to `False`.\n  \"\"\"\n  self.should_continue_prompting = False\n  print(f\"Information Sources: {self._search_urls}\")\n```\n\n----------------------------------------\n\nTITLE: Testing Standard Gemini Model in Python\nDESCRIPTION: Demonstrates how to query the standard Gemini model without the ReAct framework for comparison purposes. This allows seeing the differences in how the model handles the same question with and without the ReAct reasoning and action capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ngemini_ReAct_chat.model.generate_content(\"What is the total of ages of the main trio from the new Percy Jackson and the Olympians TV series in real life?\").text\n```\n\n----------------------------------------\n\nTITLE: Creating a Translation Prompt Function\nDESCRIPTION: Defines a function that constructs a translation prompt with the source text, source language, and target language, positioning the request as a professional book translation task.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef translations(text,\n                 inputLanguage='Polish',\n                 targetLanguage='English'):\n\n    translation_prompt = f\"\"\"\n      As a professional book translator,\n      translate the following book from {inputLanguage} into {targetLanguage}.\n\n      Book to Translate:\n      {text}\n\n    \"\"\"\n    return translation_prompt\n```\n\n----------------------------------------\n\nTITLE: Creating Chroma Vector Store\nDESCRIPTION: Creating and persisting a Chroma vector database using document embeddings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nvectorstore = Chroma.from_documents(\n                     documents=docs,                 # Data\n                     embedding=gemini_embeddings,    # Embedding model\n                     persist_directory=\"./chroma_db\" # Directory to save data\n                     )\n```\n\n----------------------------------------\n\nTITLE: Testing OAuth Authentication with Gemini API\nDESCRIPTION: This snippet demonstrates how to list available base models using the Python SDK with OAuth authentication. Note that no API key is configured, as the SDK automatically uses the application default credentials.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n\nprint('Available base models:', [m.name for m in genai.list_models()])\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini Model ID Parameter\nDESCRIPTION: Defines the Gemini model ID to be used for generating responses. The cell includes a parameter selection dropdown with various Gemini model options.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini Model with Function Calling\nDESCRIPTION: Sets up the Gemini model with the Wikipedia search function as a tool for function calling. This enables the model to call the function when needed to answer user queries.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(\n    'gemini-2.0-flash',\n    tools=[wikipedia_search],\n    generation_config={'temperature': 0.6})\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain Dependencies for Gemini Integration\nDESCRIPTION: Installing required packages including LangChain's core library, Google Generative AI integration, and community tools for document loading functionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install --quiet langchain-core==0.1.23\n%pip install --quiet langchain==0.1.1\n%pip install --quiet langchain-google-genai==0.0.6\n%pip install --quiet -U langchain-community==0.0.20\n```\n\n----------------------------------------\n\nTITLE: Implementing Movie Theater Search Functions in Python\nDESCRIPTION: Defines three functions for searching movies, theaters, and showtimes. These functions serve as mock implementations for a movie theater API integration.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef find_movies(description: str, location: str):\n    \"\"\"find movie titles currently playing in theaters based on any description, genre, title words, etc.\n\n    Args:\n        description: Any kind of description including category or genre, title words, attributes, etc.\n        location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n    \"\"\"\n    return [\"Barbie\", \"Oppenheimer\"]\n\n\ndef find_theaters(location: str, movie: str):\n    \"\"\"Find theaters based on location and optionally movie title which are is currently playing in theaters.\n\n    Args:\n        location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n        movie: Any movie title\n    \"\"\"\n    return [\"Googleplex 16\", \"Android Theatre\"]\n\n\ndef get_showtimes(location: str, movie: str, theater: str, date: str):\n    \"\"\"\n    Find the start times for movies playing in a specific theater.\n\n    Args:\n      location: The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\n      movie: Any movie title\n      thearer: Name of the theater\n      date: Date for requested showtime\n    \"\"\"\n    return [\"10:00\", \"11:00\"]\n\ntheater_functions = [find_movies, find_theaters, get_showtimes]\n```\n\n----------------------------------------\n\nTITLE: Evaluating and Correcting Essay with Gemini API\nDESCRIPTION: Creates a teacher model with evaluation criteria to grade the student essay on a 1-5 scale across multiple dimensions and generate a corrected version with explanations of changes made.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nteacher_system_prompt = f\"\"\"\nAs a teacher, you are tasked with grading students' essays.\nPlease follow these instructions for evaluation:\n\n1. Evaluate the essay on a scale of 1-5 based on the following criteria:\n- Thesis statement,\n- Clarity and precision of language,\n- Grammar and punctuation,\n- Argumentation\n\n2. Write a corrected version of the essay, addressing any identified issues\nin the original submission. Point what changes were made.\n\"\"\"\nteacher_model = genai.GenerativeModel(model_name='gemini-2.0-flash', generation_config={\"temperature\": 0},\n                                         system_instruction=teacher_system_prompt)\n\nMarkdown(teacher_model.generate_content(essay).text)\n```\n\n----------------------------------------\n\nTITLE: Few-shot prompting for animal size sorting\nDESCRIPTION: Demonstrates few-shot prompting by providing examples of sorting animals by size, then asking the model to complete a new example. The prompt includes two example question-answer pairs to establish the pattern.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Sort the animals from biggest to smallest.\n    Question: Sort Tiger, Bear, Dog\n    Answer: Bear > Tiger > Dog}\n    Question: Sort Cat, Elephant, Zebra\n    Answer: Elephant > Zebra > Cat}\n    Question: Sort Whale, Goldfish, Monkey\n    Answer:\n\"\"\"\n\nrespose=client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\n\nprint(respose.text)\n```\n\n----------------------------------------\n\nTITLE: Deleting Cached Content\nDESCRIPTION: Sends a DELETE request to remove the cached content, demonstrating proper resource management.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n!curl -X DELETE \"https://generativelanguage.googleapis.com/v1beta/$(cat cache_name.txt)?key=$GOOGLE_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Creating CSV File for Training Data in Python\nDESCRIPTION: This code creates a CSV file named 'data.csv' containing training data for model tuning. The CSV file has two columns: 'text_input' for input and 'output' for expected output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%%writefile data.csv\ntext_input,output\n1,2\n3,4\n-3,-2\ntwenty two,twenty three\ntwo hundred,two hundred one\nninety nine,one hundred\n8,9\n-98,-97\n\"1,000\",\"1,001\"\n\"1,01,00,000\",\"1,01,00,001\"\nthirteen,fourteen\neighty,eighty one\none,two\nthree,four\nseven,eight\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini LLM and SQL Query Chain\nDESCRIPTION: Creates a ChatGoogleGenerativeAI instance using the Gemini model and initializes the SQL query chain that will generate SQL queries from natural language questions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Define query chain\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\nwrite_query_chain = create_sql_query_chain(llm, db)\n```\n\n----------------------------------------\n\nTITLE: Creating DataFrame from Sample Documents\nDESCRIPTION: Organizes the contents of the sample documents into a pandas DataFrame for better visualization.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\ndf = pd.DataFrame(documents)\ndf.columns = ['Title', 'Text']\ndf\n```\n\n----------------------------------------\n\nTITLE: Testing the Order Management Functions\nDESCRIPTION: Tests the ordering system by adding drinks with modifiers, removing items, and confirming the order to ensure the functions work as expected before integration with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Test it out!\n\nclear_order()\nadd_to_order(\"Latte\", [\"Extra shot\"])\nadd_to_order(\"Tea\")\nremove_item(2)\nadd_to_order(\"Tea\", [\"Earl Grey\", \"hot\"])\nconfirm_order()\n```\n\n----------------------------------------\n\nTITLE: Defining Music Connoisseur System Prompt\nDESCRIPTION: Creates a system prompt that instructs the model to assume the role of a music connoisseur with a specific interest in Mozart's work.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"\"\"\n    You are a highly regarded music connoisseur, you are a big fan of Mozart.\n    You recently listened to Mozart's Requiem.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for Video Analysis\nDESCRIPTION: Creates a system prompt that instructs the Gemini model to act as a historian specializing in events caught on film, providing specific questions to answer about the video.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"\"\"\n  You are historian who specializes in events caught on film.\n  When you receive a video answer following questions:\n  When did it happen?\n  Who is the most important person in video?\n  How the event is called?\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Setting System Prompt for Mathematical Problem Solving\nDESCRIPTION: Creates a system instruction that guides the model to act as a teacher solving mathematical and logical problems with a structured approach, including condition summarization, problem identification, and step-by-step solutions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nsystem_prompt = \"\"\"\n  You are a teacher solving mathematical and logical problems. Your task:\n  1. Summarize given conditions.\n  2. Identify the problem.\n  3. Provide a clear, step-by-step solution.\n  4. Provide an explanation for each step.\n\n  Ensure simplicity, clarity, and correctness in all steps of your explanation.\n  Each of your task should be done in order and seperately.\n\"\"\"\n\nconfig = types.GenerateContentConfig(\n    system_instruction=system_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Stuff Documents Chain with LangChain\nDESCRIPTION: This snippet creates a stuff documents chain using LangChain Expression Language (LCEL), combining document retrieval, prompt formatting, and LLM processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Combine data from documents to readable string format.\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# Create stuff documents chain using LCEL.\n# This is called a chain because you are chaining\n# together different elements with the LLM.\n# In the following example, to create a stuff chain,\n# you will combine content, prompt, LLM model, and\n# output parser together like a chain using LCEL.\n#\n# The chain implements the following pipeline:\n# 1. Extract data from documents and save to the variable `context`.\n# 2. Use the `RunnablePassthrough` option to provide question during invoke.\n# 3. The `context` and `question` are then passed to the prompt and\n#    input variables in the prompt are populated.\n# 4. The prompt is then passed to the LLM (`gemini-2.0-flash`).\n# 5. Output from the LLM is passed through an output parser\n#    to structure the model response.\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | llm_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n----------------------------------------\n\nTITLE: Executing Query with Gemini and Weaviate Integration\nDESCRIPTION: Demonstrates how to use the configured Gemini model with the Weaviate Query Agent to answer a question about deploying Weaviate on Docker.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\nYou are connected to a database that has a blog post on deploying Weaviate on Docker.\nCan you answer how I can Weaviate with Docker?\n\"\"\"\n\nchat = client.chats.create(model='gemini-2.0-flash', config=config)\nresponse = chat.send_message(prompt)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Preparing Training Data as Python Dictionary for Gemini API Tuning\nDESCRIPTION: This code creates a list of dictionaries containing training data for model tuning. Each dictionary represents an input-output pair for the task of generating the next number in a sequence.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndict_data =[\n    {\n          'text_input': '1',\n          'output': '2',\n    },{\n          'text_input': '3',\n          'output': '4',\n    },{\n          'text_input': '-3',\n          'output': '-2',\n    },{\n          'text_input': 'twenty two',\n          'output': 'twenty three',\n    },{\n          'text_input': 'two hundred',\n          'output': 'two hundred one',\n    },{\n          'text_input': 'ninety nine',\n          'output': 'one hundred',\n    },{\n          'text_input': '8',\n          'output': '9',\n    },{\n          'text_input': '-98',\n          'output': '-97',\n    },{\n          'text_input': '1,000',\n          'output': '1,001',\n    },{\n          'text_input': '10,100,000',\n          'output': '10,100,001',\n    },{\n          'text_input': 'thirteen',\n          'output': 'fourteen',\n    },{\n          'text_input': 'eighty',\n          'output': 'eighty one',\n    },{\n          'text_input': 'one',\n          'output': 'two',\n    },{\n          'text_input': 'three',\n          'output': 'four',\n    },{\n          'text_input': 'seven',\n          'output': 'eight',\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Searching Generated Content in Weaviate Python\nDESCRIPTION: Shows how to search the AI-generated descriptions that were stored in the database. This vector search looks for 'travel jacket' in the generated content, returning the most relevant match along with its properties.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nresponse = products.query.near_text(\n        query=\"travel jacket\",\n        return_properties=[\"generated_description\", \"description\", \"title\"],\n        limit=1\n    )\n\nfor o in response.objects:\n    print(o.uuid)\n    print(json.dumps(o.properties, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Generating Video Summary with Gemini\nDESCRIPTION: Sends the video file to the Gemini model along with instructions to summarize it, configuring the request with the previously defined system prompt and selecting a specific model variant.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nresponse = client.models.generate_content(\n    model=f\"models/{MODEL_ID}\",\n    contents=[\n        \"Summarise this video please.\",\n        video_file\n        ],\n    config=types.GenerateContentConfig(\n        system_instruction=system_prompt,\n        ),\n    )\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Flawed Essay with Gemini API\nDESCRIPTION: Creates a generative model with system instructions to act as a student writing an essay with intentional mistakes, then generates the essay about reading benefits with temperature set to 0 for consistent output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nstudent_system_prompt = \"\"\"You're a college student. Your job is to write an essay riddled with common mistakes and a few major ones.\nThe essay should have mistakes regarding clarity, grammar, argumentation, and vocabulary.\nEnsure your essay includes a clear thesis statement. You should write only an essay, so do not include any notes.\"\"\"\n\nstudent_model = genai.GenerativeModel(model_name='gemini-2.0-flash', generation_config={\"temperature\": 0},\n                              system_instruction=student_system_prompt)\n\nessay = student_model.generate_content(\"Write an essay about benefits of reading.\").text\nMarkdown(essay)\n```\n\n----------------------------------------\n\nTITLE: Creating Gemini API Client\nDESCRIPTION: Initializes the Gemini API client for interacting with the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client()\n```\n\n----------------------------------------\n\nTITLE: Solving a Logical Probability Problem with Gemini\nDESCRIPTION: Demonstrates solving a logical probability problem about weighted dice by sending the problem to the Gemini API with the previously defined system instructions and displaying the response as Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nlogical_problem = \"\"\"\n  Assume a world where 1 in 5 dice are weighted and have 100% to roll a 6.\n  A person rolled a dice and rolled a 6.\n  Is it more likely that the die was weighted or not?\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=logical_problem,\n    config=config,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Preprocessing newsgroup data function\nDESCRIPTION: Defines a function to preprocess the newsgroup data by removing sensitive information like names and emails, truncating long texts, and organizing the data into a Pandas dataframe.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport re\nimport pandas as pd\n\ndef preprocess_newsgroup_data(newsgroup_dataset):\n  # Apply functions to remove names, emails, and extraneous words from data points in newsgroups.data\n  newsgroup_dataset.data = [re.sub(r'[\\w\\.-]+@[\\w\\.-]+', '', d) for d in newsgroup_dataset.data] # Remove email\n  newsgroup_dataset.data = [re.sub(r\"\\([^()]*\\)\", \"\", d) for d in newsgroup_dataset.data] # Remove names\n  newsgroup_dataset.data = [d.replace(\"From: \", \"\") for d in newsgroup_dataset.data] # Remove \"From: \"\n  newsgroup_dataset.data = [d.replace(\"\\nSubject: \", \"\") for d in newsgroup_dataset.data] # Remove \"\\nSubject: \"\n\n  # Cut off each text entry after 5,000 characters\n  newsgroup_dataset.data = [d[0:5000] if len(d) > 5000 else d for d in newsgroup_dataset.data]\n\n  # Put data points into dataframe\n  df_processed = pd.DataFrame(newsgroup_dataset.data, columns=['Text'])\n  df_processed['Label'] = newsgroup_dataset.target\n  # Match label to target name index\n  df_processed['Class Name'] = ''\n  for idx, row in df_processed.iterrows():\n    df_processed.at[idx, 'Class Name'] = newsgroup_dataset.target_names[row['Label']]\n\n  return df_processed\n```\n\n----------------------------------------\n\nTITLE: Sending Inline Audio Data to Gemini API\nDESCRIPTION: Demonstrates sending audio data inline in the API request rather than uploading via the File API. This is useful for small audio clips under the 20MB limit.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nresponse = client.models.generate_content(\n  model=MODEL_ID,\n  contents=[\n    'Describe this audio clip',\n    types.Part.from_bytes(\n      data=sound[:10000].export().read(),\n      mime_type='audio/mp3',\n    )\n  ]\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Selecting Base Model for Tuning in Gemini API with Python\nDESCRIPTION: This code selects a base model for tuning from the list of tunable models. It specifically chooses a model with 'flash' in its name.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nbase_model = [m for m in tunable_models if 'flash' in m.name][-1]  # models/gemini-1.5-flash-001-tuning\nbase_model\n```\n\n----------------------------------------\n\nTITLE: Creating a Classification Prompt Template\nDESCRIPTION: Defines a template for classification prompts with few-shot examples to guide the model in classifying comments.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Define a template that you will reuse in examples below\nclassification_template = \"\"\"\n  Topic: What can I do after highschool?\n  Comment: You should do a gap year!\n  Class: Neutral\n\n  Topic: Where can I buy a cheap phone?\n  Comment: You have just won an IPhone 15 Pro Max!!! Click the link to receive the prize!!!\n  Class: Spam\n\n  Topic: How long do you boil eggs?\n  Comment: Are you stupid?\n  Class: Offensive\n\n  Topic: {topic}\n  Comment: {comment}\n  Class:\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining Simple Functions for Function Calling Demo\nDESCRIPTION: Defines two simple function declarations for demonstrating the function calling capability - turn_on_the_lights and turn_off_the_lights.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nturn_on_the_lights = {'name': 'turn_on_the_lights'}\nturn_off_the_lights = {'name': 'turn_off_the_lights'}\n```\n\n----------------------------------------\n\nTITLE: Estimating Token Counts for Text Chunks\nDESCRIPTION: Calculates estimated token counts for each non-empty chunk using a simple character-to-token ratio (1 token  4 characters) and prints the results for analysis.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nestimated_token_counts = []\n\nfor chunk in chunks:\n    if not chunk:  # Check if chunk is empty or None\n        continue  # Skip this iteration if chunk is empty\n\n    # Process non-empty chunk\n    estimated_token_count = len(chunk)/4\n    estimated_token_counts.append(estimated_token_count)\n\n# You can print number of estimated tokens in each non empty chunk to see what are you working with\nprint(estimated_token_counts)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Weaviate and Gemini\nDESCRIPTION: Installs the necessary Python libraries: google-genai for Gemini API and weaviate-client with agents support for Weaviate.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U google-genai\n%pip install -U \"weaviate-client[agents]\"\n```\n\n----------------------------------------\n\nTITLE: Creating Tuned Model with Gemini API in Python\nDESCRIPTION: This snippet demonstrates how to create a tuned model using the Gemini API. It specifies the source model, training data, and various tuning parameters such as epoch count, batch size, and learning rate.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\nname = f'generate-num-{random.randint(0,10000)}'\noperation = genai.create_tuned_model(\n    # You can use a tuned model here too. Set `source_model=\"tunedModels/...\"` \n    source_model=base_model.name,\n    # Pass the dataset created earlier.\n    training_data=train_data,\n    id = name,\n    epoch_count = 100,\n    batch_size=4,\n    learning_rate=0.001,\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gemini API and LangChain\nDESCRIPTION: Installs the necessary Python libraries including google-genai, langchain, langchain-community, and langchain-google-genai packages required for working with the Gemini API and LangChain.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.7.0\" langchain langchain-community langchain-google-genai\n```\n\n----------------------------------------\n\nTITLE: Rendering Final Company Report Output\nDESCRIPTION: Displays the final company report generated by Gemini 2.0, including the report content and Google Search Suggestions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndisplay(Markdown(report.getvalue().replace('$', r'\\$')))  # Escape $ signs for better MD rendering\ndisplay(HTML(sep.rendered_content))\n```\n\n----------------------------------------\n\nTITLE: Finding Best Matching Passage for Query\nDESCRIPTION: Defines a function to find the best matching passage from the document database based on the query embedding.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef find_best_passage(query, dataframe):\n  \"\"\"\n  Compute the distances between the query and each document in the dataframe\n  using the dot product.\n  \"\"\"\n  query_embedding = client.models.embed_content(\n      model=EMBEDDING_MODEL_ID,\n      contents=query,\n      config=types.EmbedContentConfig(\n          task_type=\"retrieval_document\",\n          )\n  )\n\n  dot_products = np.dot(\n      np.stack(dataframe['Embeddings']),\n      query_embedding.embeddings[0].values\n  )\n  idx = np.argmax(dot_products)\n  return dataframe.iloc[idx]['Text'] # Return text from index with max value\n```\n\n----------------------------------------\n\nTITLE: Creating Tool Call Handler for Function Calling\nDESCRIPTION: Asynchronous function that processes tool calls from the Gemini API, specifically handling function calls by responding with a simple 'ok' response for demonstration purposes.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nasync def handle_tool_call(session, tool_call):\n  for fc in tool_call.function_calls:\n    tool_response = types.LiveClientToolResponse(\n        function_responses=[types.FunctionResponse(\n            name=fc.name,\n            id=fc.id,\n            response={'result':'ok'},\n        )]\n    )\n\n    print('\\n>>> ', tool_response)\n    await session.send(input=tool_response)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Video Content with Scene Descriptions\nDESCRIPTION: Makes an API call to Gemini to analyze a selected video with a specified prompt, generating scene descriptions with timecodes.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\"  # @param [\"For each scene in this video, generate captions that describe the scene along with any spoken text placed in quotation marks. Place each caption into an object with the timecode of the caption in the video.\", \"Organize all scenes from this video in a table, along with timecode, a short description, a list of objects visible in the scene (with representative emojis) and an estimation of the level of excitement on a scale of 1 to 10\"] {\"allow-input\":true}\n\nvideo = trailcam_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n\nresponse = client.models.generate_content(\n    model=model_name,\n    contents=[\n        video,\n        prompt,\n    ]\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Displaying Image Analysis Results\nDESCRIPTION: Renders the model's explanation of the images from the PDF as formatted Markdown in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nMarkdown(response_2.text)\n```\n\n----------------------------------------\n\nTITLE: Creating Sample Documents for Embeddings Database\nDESCRIPTION: Defines three sample documents to be used for building an embeddings database.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nDOCUMENT1 = {\n    \"title\": \"Operating the Climate Control System\",\n    \"content\": \"Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"}\nDOCUMENT2 = {\n    \"title\": \"Touchscreen\",\n    \"content\": \"Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \\\"Navigation\\\" icon to get directions to your destination or touch the \\\"Music\\\" icon to play your favorite songs.\"}\nDOCUMENT3 = {\n    \"title\": \"Shifting Gears\",\n    \"content\": \"Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"}\n\ndocuments = [DOCUMENT1, DOCUMENT2, DOCUMENT3]\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Gemini API Client with Authentication\nDESCRIPTION: Sets up the Google Gemini API client by retrieving the API key from Colab Secrets and initializing the client object for API interaction.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Frequency Penalty in Gemini 002 Models with Python\nDESCRIPTION: Shows the effect of frequency_penalty on repetitive tasks and warns about potential issues with negative penalties.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name)\nresponse = model.generate_content(contents='please repeat \"Cat\" 50 times, 10 per line',\n                                  generation_config=dict(frequency_penalty=1.999))\n```\n\nLANGUAGE: python\nCODE:\n```\nprint(response.text)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = model.generate_content(\n    prompt,\n    generation_config=genai.GenerationConfig(\n        max_output_tokens=400,\n        frequency_penalty=-2.0))\n```\n\nLANGUAGE: python\nCODE:\n```\nMarkdown(response.text)  # the, the, the, ...\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse.candidates[0].finish_reason\n```\n\n----------------------------------------\n\nTITLE: Checking Tuning Progress in Gemini API with Python\nDESCRIPTION: This snippet shows how to monitor the progress of model tuning. It uses the operation metadata and a wait bar to track the tuning process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\noperation.metadata\n\nimport time\n\nfor n,status in enumerate(operation.wait_bar()):\n  if n%100 == 0:\n    print()\n  print('.', end='')\n  time.sleep(10)\n```\n\n----------------------------------------\n\nTITLE: Verifying File Upload with Files API\nDESCRIPTION: Bash script to verify the successful upload of the video file by querying the files.get endpoint with the file URI.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n. vars.sh\n\nfile_uri=$(jq -r \".file.uri\" file_info.json)\n\ncurl \"${file_uri}?key=${GOOGLE_API_KEY}\" 2>/dev/null\n```\n\n----------------------------------------\n\nTITLE: Zero-shot Sorting Example with Gemini\nDESCRIPTION: Demonstrates a zero-shot prompting example for sorting animals by size. The code sends a prompt to the Gemini model and displays the response as Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Sort following animals from biggest to smallest:\n    fish, elephant, dog\n\"\"\"\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Token Usage Breakdown with Markdown\nDESCRIPTION: Creates a formatted Markdown display that breaks down the token usage into cached content tokens, prompt tokens, output tokens, and total tokens.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndisplay(Markdown(f\"\"\"\n  As you can see in the `usage_metadata`, the token usage is split between:\n  *  {response.usage_metadata.cached_content_token_count} tokens for the cache,\n  *  {response.usage_metadata.prompt_token_count} tokens for the input (including the cache, so {response.usage_metadata.prompt_token_count - response.usage_metadata.cached_content_token_count} for the actual prompt),\n  *  {response.usage_metadata.candidates_token_count} tokens for the output,\n  *  {response.usage_metadata.total_token_count} tokens in total.\n\"\"\"))\n```\n\n----------------------------------------\n\nTITLE: Setting Up API Key Authentication in Python\nDESCRIPTION: Code to set up the Google API key as an environment variable using Colab's userdata functionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Implementing Dot Product for Similarity Calculation\nDESCRIPTION: Creates a function to calculate dot product between embedding vectors, which is equivalent to cosine similarity for unit vectors. This is used to measure relevance between embeddings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ndef dot_product(a: np.ndarray, b: np.ndarray):\n  return (a @ b.T)\n```\n\n----------------------------------------\n\nTITLE: Single-Turn Function Calling with Gemini API using curl\nDESCRIPTION: Example of making a REST API call to Gemini's generateContent endpoint with function declarations for movie theater information, including functions for finding movies, theaters, and showtimes\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"contents\": {\n      \"role\": \"user\",\n      \"parts\": {\n        \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n    }\n  },\n  \"tools\": [\n    {\n      \"function_declarations\": [\n        {\n          \"name\": \"find_movies\",\n          \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n              },\n              \"description\": {\n                \"type\": \"string\",\n                \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n              }\n            },\n            \"required\": [\n              \"description\"\n            ]\n          }\n        },\n        {\n          \"name\": \"find_theaters\",\n          \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n              },\n              \"movie\": {\n                \"type\": \"string\",\n                \"description\": \"Any movie title\"\n              }\n            },\n            \"required\": [\n              \"location\"\n            ]\n          }\n        },\n        {\n          \"name\": \"get_showtimes\",\n          \"description\": \"Find the start times for movies playing in a specific theater\",\n          \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n              \"location\": {\n                \"type\": \"string\",\n                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n              },\n              \"movie\": {\n                \"type\": \"string\",\n                \"description\": \"Any movie title\"\n              },\n              \"theater\": {\n                \"type\": \"string\",\n                \"description\": \"Name of the theater\"\n              },\n              \"date\": {\n                \"type\": \"string\",\n                \"description\": \"Date for requested showtime\"\n              }\n            },\n            \"required\": [\n              \"location\",\n              \"movie\",\n              \"theater\",\n              \"date\"\n            ]\n          }\n        }\n      ]\n    }\n  ]\n}' 2> /dev/null\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Helper Functions\nDESCRIPTION: Imports required libraries for Weaviate, Gemini API integration, and image handling. Defines helper functions for converting image URLs to PIL objects and displaying images.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport weaviate\nfrom weaviate.classes.config import Configure\nfrom weaviate.embedded import EmbeddedOptions\nimport weaviate.classes as wvc\nfrom weaviate.classes.config import Property, DataType, ReferenceProperty\nfrom weaviate.util import generate_uuid5\nfrom weaviate.classes.query import QueryReference\n\nimport os\nimport json\nimport requests\nimport PIL\nimport IPython\n\nfrom PIL import Image\nfrom io import BytesIO\nfrom IPython.display import Markdown\n\nimport google\nimport google.generativeai as genai\nfrom google.colab import userdata\n\n# Convert image links to PIL object\ndef url_to_pil(url):\n    response = requests.get(url)\n    return Image.open(BytesIO(response.content))\n\n# display images\ndef display_image(url, size=100):\n    response = requests.get(url)\n    image_data = BytesIO(response.content)\n    image = Image.open(image_data)\n\n    resized_image = image.resize((size,size))\n\n    display(resized_image)\n```\n\n----------------------------------------\n\nTITLE: Document Loading and Splitting\nDESCRIPTION: Code for loading and splitting Python files using RecursiveCharacterTextSplitter\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndocs = []\nfor file in glob(repo_match, recursive=True):\n  loader = TextLoader(file, encoding='utf-8')\n  splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON, chunk_size=2000, chunk_overlap=0)\n  docs.extend(loader.load_and_split(splitter))\n```\n\n----------------------------------------\n\nTITLE: Classifying a Spam Comment Example\nDESCRIPTION: Implements classification of a potential spam comment using the Gemini API and the defined template. The example formats the template with a specific topic and comment.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nspam_topic = \"\"\"\n  I am looking for a vet in our neighbourhood.\n  Can anyone recommend someone good? Thanks.\n\"\"\"\nspam_comment = \"You can win 1000$ by just following me!\"\nspam_prompt = classification_template.format(\n    topic=spam_topic,\n    comment=spam_comment\n)\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=spam_prompt,\n    config=generation_config\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini API Client\nDESCRIPTION: Imports necessary modules and initializes the Gemini API client using an API key stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import  genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Uploading Audio File to Gemini File API\nDESCRIPTION: Initiates a resumable upload request, uploads the audio file, and retrieves the file URI for later use.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n. vars.sh\n\ntmp_header_file=upload-header.tmp\n\ncurl \"${BASE_URL}/upload/v1beta/files?key=${GOOGLE_API_KEY}\" \\\n  -D upload-header.tmp \\\n  -H \"X-Goog-Upload-Protocol: resumable\" \\\n  -H \"X-Goog-Upload-Command: start\" \\\n  -H \"X-Goog-Upload-Header-Content-Length: ${NUM_BYTES}\" \\\n  -H \"X-Goog-Upload-Header-Content-Type: ${MIME_TYPE}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{'file': {'display_name': '${DISPLAY_NAME}'}}\" 2> /dev/null\n\nupload_url=$(grep -i \"x-goog-upload-url: \" \"${tmp_header_file}\" | cut -d\" \" -f2 | tr -d \"\\r\")\nrm \"${tmp_header_file}\"\n\ncurl \"${upload_url}\" \\\n  -H \"Content-Length: ${NUM_BYTES}\" \\\n  -H \"X-Goog-Upload-Offset: 0\" \\\n  -H \"X-Goog-Upload-Command: upload, finalize\" \\\n  --data-binary \"@${AUDIO_PATH}\" 2> /dev/null > file_info.json\n\nfile_uri=$(jq \".file.uri\" file_info.json)\n```\n\n----------------------------------------\n\nTITLE: Truncating Embedding Dimensions in Gemini API\nDESCRIPTION: Demonstrates how to reduce the dimensionality of generated embeddings using the output_dimensionality parameter. This compares the default embedding size with a truncated embedding of only 10 dimensions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntext=[\"Hello world\"]\n# Not truncated\nresult1 = client.models.embed_content(\n    model=\"text-embedding-004\",\n    contents=text)\n\n\n# Truncated\nfrom google.genai import types\n\nresult2 = client.models.embed_content(\n    model=\"text-embedding-004\",\n    contents=text,\n    config=types.EmbedContentConfig(output_dimensionality=10))\n\n[embedding1] = result1.embeddings\n[embedding2] = result2.embeddings\n\n\n(len(embedding1.values), len(embedding2.values))\n```\n\n----------------------------------------\n\nTITLE: Requesting Transcript with Timestamp Range\nDESCRIPTION: Demonstrates how to request a transcript for a specific portion of an audio file by specifying timestamp ranges in the prompt (between 02:30 and 03:29).\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n# Create a prompt containing timestamps.\nprompt = \"Provide a transcript of the speech between the timestamps 02:30 and 03:29.\"\n\nresponse = client.models.generate_content(\n  model=MODEL_ID,\n  contents=[\n    prompt,\n    your_audio_file,\n  ]\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Extracting Rendered Content for Search Suggestions in Python\nDESCRIPTION: This snippet extracts the rendered content for search suggestions from the API result and saves it to an HTML file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n!jq -r \".candidates[0].groundingMetadata.searchEntryPoint.renderedContent\" result.json > rendered_content.html\n```\n\n----------------------------------------\n\nTITLE: Creating a Retriever from Chroma Vector Store\nDESCRIPTION: This snippet demonstrates how to load a previously created Chroma vector store and access its collection to retrieve document embeddings. It includes testing the retriever by querying for information about 'MMLU' to verify functionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Load from disk\nload_client = chromadb.PersistentClient(path=\"./chroma_db\")\n\n# Fetch the collection\nchroma_collection = load_client.get_collection(\"quickstart\")\n\n# Fetch the vector store\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n\n# Get the index from the vector store\nindex = VectorStoreIndex.from_vector_store(\n    vector_store\n)\n\n# Check if the retriever is working by trying to fetch the relevant docs related\n# to the phrase 'MMLU' (Multimodal Machine Learning Understanding).\n# If the length is greater than zero, it means that the retriever is\n# functioning well.\n# You can ask questions about your data using a generic interface called\n# a query engine. You have to use the `as_query_engine` function of the\n# index to create a query engine and use the `query` function of query engine\n# to inquire the index.\ntest_query_engine = index.as_query_engine()\nresponse = test_query_engine.query(\"MMLU\")\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Sampling data for training and testing\nDESCRIPTION: Samples data points from the training and test datasets, keeping only science-related categories (containing 'sci' in their names) with a specified number of samples per category.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nTRAIN_NUM_SAMPLES = 100\nTEST_NUM_SAMPLES = 25\nCLASSES_TO_KEEP = 'sci' # Class name should contain 'sci' in it to keep science categories\ndf_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\ndf_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)\n```\n\n----------------------------------------\n\nTITLE: Loading Product Data from GitHub JSON Source\nDESCRIPTION: Fetches e-commerce product data from a GitHub repository's raw JSON file and loads it for use in populating the Weaviate database.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# URL to the raw JSON file\nurl = 'https://raw.githubusercontent.com/bkauf/next-store/main/first_99_objects.json'\nresponse = requests.get(url)\n\n# Load the entire JSON content\ndata = json.loads(response.text)\n```\n\n----------------------------------------\n\nTITLE: Downloading a Video for Analysis\nDESCRIPTION: Downloads the open-source short film 'Wing It!' from Wikimedia Commons to use as a test video for the Gemini API's video summarization capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Download video\npath = \"wingit.webm\"\nurl = \"https://upload.wikimedia.org/wikipedia/commons/3/38/WING_IT%21_-_Blender_Open_Movie-full_movie.webm\"\n!wget $url -O $path\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Parameter cell to select which Gemini model to use, with a default of gemini-2.5-pro-exp-03-25 which is recommended for video understanding.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Grouping Text Chunks for Optimal Processing\nDESCRIPTION: Defines and applies a function to combine smaller chunks into larger groups while staying within token limits, creating more context-rich segments for translation and reducing API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Combine short chunks into larger groups based on token counts.\ndef chunk_grouping(chunks, token_counts, max_len=5000):\n    grouped_chunks = []\n    current_group = \"\"\n    current_token_sum = 0\n\n    # Process each chunk and group them based on token limits\n    for chunk, count in zip(chunks, token_counts):\n        # Skip chunks that exceed the max token limit\n        if count > max_len:\n            continue\n\n        # Add a new chunk if there is space available in the current group.\n        if current_token_sum + 1 + count <= max_len:\n            current_group += \"\\n\\n\" + chunk\n            current_token_sum += 1 + count  # Count in 1 token for newlines\n\n        # If adding this chunk exceeds the current group's capacity, start a new group\n        else:\n            grouped_chunks.append(current_group)\n            current_group = chunk\n            current_token_sum = count\n\n    if current_group:  # Add the last remaining group\n        grouped_chunks.append(current_group)\n\n    return grouped_chunks\n\n\nchunks = chunk_grouping(chunks, estimated_token_counts)\nprint(len(chunks))\n```\n\n----------------------------------------\n\nTITLE: Implementing Automatic Retries for Gemini API Calls in Python\nDESCRIPTION: Demonstrates how to use the built-in retry mechanism for handling transient errors in Gemini API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.api_core import retry\n\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")\nprompt = \"Write a story about a magic backpack.\"\n\nmodel.generate_content(\n    prompt, request_options={\"retry\": retry.Retry(predicate=retry.if_transient_error)}\n)\n```\n\n----------------------------------------\n\nTITLE: Analyzing YouTube Video Content with Gemini API in Python\nDESCRIPTION: This code snippet demonstrates how to use the Gemini API to analyze a YouTube video. It specifically looks for instances where Sundar mentions 'AI', providing timestamps and context for each occurrence.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=model_name,\n    contents=types.Content(\n        parts=[\n            types.Part(text=\"Find all the instances where Sundar says \\\"AI\\\". Provide timestamps and broader context for each instance.\"),\n            types.Part(\n                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=ixRanV-rdAQ')\n            )\n        ]\n    )\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Running Animal Classification with Gemini API\nDESCRIPTION: This code sends the video to the Gemini model with specific instructions to identify the animals in the video, using the system prompt defined earlier.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nresponse = client.models.generate_content(\n    model=f\"models/{MODEL_ID}\",\n    contents=[\n        \"Please identify the animal(s) in this video\",\n        video_file\n        ],\n    config=types.GenerateContentConfig(\n        system_instruction=system_prompt,\n        ),\n    )\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Client with API Key\nDESCRIPTION: Sets up the Gemini client using an API key stored in Colab Secrets\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n```\n\n----------------------------------------\n\nTITLE: Creating Cached Content with Gemini API\nDESCRIPTION: Sends a POST request to create cached content using the prepared JSON and displays the response.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"https://generativelanguage.googleapis.com/v1beta/cachedContents?key=$GOOGLE_API_KEY\" \\\n -H 'Content-Type: application/json' \\\n -d @request.json > cache.json\n\n cat cache.json\n```\n\n----------------------------------------\n\nTITLE: Uploading File to Gemini API File API in Python\nDESCRIPTION: Demonstrates how to upload a file to the Gemini API File API and retrieve its URI.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsample_file = client.files.upload(file=\"image.jpg\")\n\nprint(f\"Uploaded file '{sample_file.name}' as: {sample_file.uri}\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Helper Function for Function Calling Configuration in Python\nDESCRIPTION: Defines a utility function that creates a tool configuration with the specified function calling mode and allowed function names.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.generativeai.types import content_types\nfrom collections.abc import Iterable\n\n\ndef tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n    return content_types.to_tool_config(\n        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n    )\n```\n\n----------------------------------------\n\nTITLE: Displaying Most Relevant Result Using HyDE Approach\nDESCRIPTION: Identifies and displays the most relevant search result based on similarity to the hypothetical document, using the HyDE re-ranking approach.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\nto_markdown(summaries[np.argmax(sim_value)])\n```\n\n----------------------------------------\n\nTITLE: Uploading Video to Gemini API\nDESCRIPTION: Uploads the downloaded video file to the Gemini API for processing, making it available for analysis by the Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Upload video\nvideo_file = client.files.upload(file=path)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Parallel Function Calls in Gemini\nDESCRIPTION: Demonstrates how to configure and execute parallel function calls using the Gemini chat API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(\n    model = MODEL_ID,\n    config = {\n        \"tools\": house_fns,\n    }\n)\n\nresponse = chat.send_message(\n    \"Turn this place into a party!\"\n)\n\nfor content in chat.get_history():\n    display(Markdown(\"###\" + content.role + \":\"))\n    for part in content.parts:\n        if part.text:\n            display(Markdown(part.text))\n        if part.function_call:\n            print(\"Function call: {\", part.function_call, \"}\")\n        if part.function_response:\n            print(\"Function response: {\", part.function_response, \"}\")\n    print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Creating AudioSession Class in Python\nDESCRIPTION: Implements the AudioSession class for managing client-side audio recording and playback. It handles connections, data queues, and provides methods for enqueueing audio data and reading from the input stream.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nclass AudioSession:\n  \"\"\"Connection to audio recording/playback on client side.\"\"\"\n\n  def __init__(self, config: AudioConfig, connection: Connection):\n    self._config = config\n    self._connection = connection\n    self._done = False\n    self._read_queue: asyncio.Queue[bytes] = asyncio.Queue()\n    self._started = asyncio.Future()\n\n  @property\n  def config(self) -> AudioConfig:\n    return self._config\n\n  async def await_start(self):\n    await self._started\n\n  async def _read_loop(self):\n    # print ('read_loop')\n    while True:\n      # print ('await read')\n      data = await self._connection.read()\n      # print(\"data\", data)\n      if 'audio_in' in data:\n        # print(\"audio_in\", data['audio_in'])\n        raw_data = base64.b64decode(data['audio_in'].encode('utf-8'))\n        # print(\"audio_in\", raw_data)\n        self._read_queue.put_nowait(raw_data)\n      if 'started' in data:\n        self._started.set_result(None)\n      if 'failed_to_start' in data:\n        self._started.set_exception(\n            FailedToStartError(\n                f'Failed to start audio: {data[\"failed_to_start\"]}'\n            )\n        )\n\n  async def enqueue(self, audio_data: bytes):\n    b64_data = base64.b64encode(audio_data).decode('utf-8')\n    await self._connection.write({'audio_out': b64_data})\n\n  async def clear_queue(self):\n    await self._connection.write({'flush': True})\n\n  async def read(self) -> bytes:\n    return await self._read_queue.get()\n```\n\n----------------------------------------\n\nTITLE: Uploading Video to Gemini API\nDESCRIPTION: This code uploads the downloaded video file to the Gemini API using the Files API, which makes it easier to pass the video to the model later.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Upload video\nvideo_file = client.files.upload(file=path)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Authentication Environment\nDESCRIPTION: Code to import required libraries and set up Google API key authentication for the Gemini API\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Extracting URLs with Gemini and formatting as Markdown links\nDESCRIPTION: This code uses the Gemini API to extract all unique URLs from the billing FAQ text and returns them formatted as clickable Markdown links for better usability.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nurl_prompt = f\"\"\"\n  From the given text, extract the following entities and return a list of them.\n  Entities to extract: URLs.\n  Text: {url_text}\n  Do not duplicate entities.\n  Return your answer in a markdown format:\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=url_prompt\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Loading Website Data using WebBaseLoader\nDESCRIPTION: Using LangChain's WebBaseLoader to fetch and load content from a specified URL.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nloader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/\")\ndocs = loader.load()\n```\n\n----------------------------------------\n\nTITLE: Printing the Generated Prompt in Python\nDESCRIPTION: This code snippet prints the prompt generated by the make_prompt function. It assumes that 'query' and 'passage' variables are defined elsewhere in the code.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nprompt = make_prompt(query, passage)\nprint(prompt)\n```\n\n----------------------------------------\n\nTITLE: Generating Formatted Shopping List\nDESCRIPTION: Converts the extracted grocery list into a categorized shopping list using few-shot prompting.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nshopping_list_prompt = f\"\"\"\n  LIST: 3 tomatoes, 1 turkey, 4 tomatoes\n  OUTPUT:\n  ## VEGETABLES\n  - [ ] 7 tomatoes\n  ## MEAT\n  - [ ] 1 turkey\n\n  LIST: {grocery_list.text}\n  OUTPUT:\n\"\"\"\n\nshopping_list = client.models.generate_content(\n    model=MODEL_ID,\n    contents=shopping_list_prompt,\n    config=shopping_list_config\n)\n\nMarkdown(shopping_list.text)\n```\n\n----------------------------------------\n\nTITLE: Verifying Model Deletion with Gemini API in Python\nDESCRIPTION: Attempts to retrieve a deleted model to confirm it no longer exists. Uses exception handling to capture and display the error that occurs when trying to access a model that has been removed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ntry:\n  m = genai.get_tuned_model(f'tunedModels/{name}')\n  print(m)\nexcept Exception as e:\n  print(f\"{type(e)}: {e}\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up the Gemini API Client with Authentication\nDESCRIPTION: Code to configure the Gemini API client with an API key stored in Google Colab secrets. This authenticates the session for making API calls to the Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Entity_Extraction_JSON.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Function Calling in Gemini\nDESCRIPTION: Demonstrates how to generate content using the Gemini API with function calling configuration disabled for manual handling.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=\"Which theaters in Mountain View show the Barbie movie?\",\n    config = {\n        \"tools\": theater_functions,\n        \"automatic_function_calling\": {\"disable\": True} # This line is not needed as automatic_function_calling is enabled by default\n    }\n)\n\nresponse.candidates[0].content.parts\n```\n\n----------------------------------------\n\nTITLE: Continuing Chat Conversation with Cached Context\nDESCRIPTION: Sends a follow-up message to the chat session, continuing the conversation while still using the cached Apollo 11 transcript as context.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nresponse = chat.send_message(\n    message=\"What was recounted after that?\",\n    config={\"cached_content\": apollo_cache.name}\n)\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Implementing AudioWorklet Processor in JavaScript\nDESCRIPTION: Defines a PortProcessor class for real-time audio processing in an AudioWorklet. It handles audio input/output, encoding/decoding, and message passing between the main thread and the audio thread.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: JavaScript\nCODE:\n```\nclass PortProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this._queue = [];\n    this.port.onmessage = (event) => {\n      //console.log(event.data);\n      if ('enqueue' in event.data) {\n        this.enqueueAudio(event.data.enqueue);\n      }\n      if ('clear' in event.data) {\n        this.clearAudio();\n      }\n    };\n    this._out = [];\n    this._out_len = 0;\n    console.log(\"PortProcessor ctor\", this);\n\n    this.port.postMessage({\n      debug: \"Hello from the processor!\",\n    });\n  }\n\n  encodeAudio(input) {\n    const channel = input[0];\n    const data = new ArrayBuffer(2 * channel.length);\n    const view = new DataView(data);\n    for (let i=0; i<channel.length; i++) {\n      view.setInt16(2*i, channel[i] * 32767, true);\n    }\n    return data;\n  }\n\n  enqueueAudio(input) { // bytearray\n    let view = new DataView(input);\n    let floats = [];\n    for (let i=0; i<input.byteLength; i+=2) {\n      floats.push(view.getInt16(i, true) / 32768.0);\n    }\n    this._queue.push(Float32Array.from(floats));\n  }\n\n  dequeueIntoBuffer(output) { // Float32Array\n    //console.log('deq', output)\n    let idx = 0;\n    while (idx < output.length) {\n      if (this._queue.length === 0) {\n        return;\n      }\n      let input = this._queue[0];\n      if (input.length == 0) {\n        this._queue.shift();\n        continue;\n      }\n      let n = Math.min(input.length, output.length - idx);\n      output.set(input.subarray(0, n), idx);\n      this._queue[0] = input.subarray(n);\n      idx += n;\n    }\n  }\n\n  clearAudio() {\n    this._queue = [];\n  }\n\n  process(inputs, outputs, parameters) {\n    // forward input audio\n    let data = this.encodeAudio(inputs[0]);\n    this._out.push(data);\n    this._out_len += data.byteLength;\n    // only send in 50ms batches, ipykernel will die when it gets too frequent\n    if (this._out_len > (2*sampleRate / 20)) {\n      let concat = new Uint8Array(this._out_len);\n      let idx = 0;\n      for (let a of this._out) {\n        concat.set(new Uint8Array(a), idx);\n        idx += a.byteLength;\n      }\n      this._out = [];\n      this._out_len = 0;\n      this.port.postMessage({\n        'audio_in': concat.buffer,\n      });\n    }\n\n    // forward output\n    this.dequeueIntoBuffer(outputs[0][0]);\n    // copy to other channels\n    for (let i=1; i<outputs[0].length; i++) {\n      const src = outputs[0][0];\n      const dst = outputs[0][i];\n      dst.set(src.subarray(0, dst.length));\n    }\n    return true;\n  }\n}\n\nregisterProcessor('port-processor', PortProcessor);\n```\n\n----------------------------------------\n\nTITLE: Deleting File from Gemini API File API in Python\nDESCRIPTION: Shows how to manually delete a file uploaded to the Gemini API File API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclient.files.delete(name=sample_file.name)\nprint(f\"Deleted {sample_file.name}.\")\n```\n\n----------------------------------------\n\nTITLE: Defining Classification System Prompt and Configuration\nDESCRIPTION: Creates a system prompt for social media comment classification and configures generation parameters with zero temperature for deterministic results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nclassification_system_prompt = \"\"\"\n  As a social media moderation system, your task is to categorize user\n  comments under a post. Analyze the comment related to the topic and\n  classify it into one of the following categories:\n\n  Abusive\n  Spam\n  Offensive\n\n  If the comment does not fit any of the above categories,\n  classify it as: Neutral.\n\n  Provide only the category as a response without explanations.\n\"\"\"\n\ngeneration_config = types.GenerateContentConfig(\n    temperature=0,\n    system_instruction=classification_system_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Wave File Utility for Audio Output\nDESCRIPTION: A context manager utility function that creates WAV files to store audio output from the Gemini Live API, making it easier to play audio in Colab.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@contextlib.contextmanager\ndef wave_file(filename, channels=1, rate=24000, sample_width=2):\n    with wave.open(filename, \"wb\") as wf:\n        wf.setnchannels(channels)\n        wf.setsampwidth(sample_width)\n        wf.setframerate(rate)\n        yield wf\n```\n\n----------------------------------------\n\nTITLE: Uploading and Processing Markdown File with Gemini API in Python\nDESCRIPTION: Demonstrates uploading a markdown file to the Gemini API File API and using it in a content generation request.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\nfrom IPython.display import Markdown\n\n!curl -so contrib.md https://raw.githubusercontent.com/google-gemini/cookbook/main/CONTRIBUTING.md\n\nmd_file = client.files.upload(\n    file=\"contrib.md\",\n    config={\n        \"display_name\": \"CONTRIBUTING.md\",\n        \"mime_type\": \"text/markdown\"\n    }\n)\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[\n        \"What should I do before I start writing, when following these guidelines?\",\n        md_file,\n    ]\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Defines the specific Gemini model version to be used for generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Topics from Gemini API Response in Python\nDESCRIPTION: This snippet prints the parsed response from the Gemini API, which contains the generated topics and their relevance to the input article.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Classification.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\npprint(response.parsed)\n```\n\n----------------------------------------\n\nTITLE: Text Content Processing and Document Creation\nDESCRIPTION: Processing and extracting relevant portions of website content and converting it to LangChain's Document format.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntext_content = docs[0].page_content\n\ntext_content_1 = text_content.split(\"code, audio, image and video.\",1)[1]\nfinal_text = text_content_1.split(\"Cloud TPU v5p\",1)[0]\n\ndocs = [Document(page_content=final_text, metadata={\"source\": \"local\"})]\n```\n\n----------------------------------------\n\nTITLE: Using Candidate Count in Gemini 002 Models with Python\nDESCRIPTION: Demonstrates how to use the candidate_count parameter to generate multiple responses.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name)\n```\n\nLANGUAGE: python\nCODE:\n```\ngeneration_config = dict(candidate_count=2)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = model.generate_content(test_prompt, generation_config=generation_config)\n```\n\n----------------------------------------\n\nTITLE: Plotting Training and Validation Learning Curves with Matplotlib\nDESCRIPTION: This function plots the training and validation learning curves for loss and accuracy over epochs using matplotlib. It takes the model history as input and creates a 2x1 subplot to display both metrics.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\n\ndef plot_history(history):\n  \"\"\"\n    Plotting training and validation learning curves.\n\n    Args:\n      history: model history with all the metric measures\n  \"\"\"\n  fig, (ax1, ax2) = plt.subplots(1,2)\n  fig.set_size_inches(20, 8)\n\n  # Plot loss\n  ax1.set_title('Loss')\n  ax1.plot(history.history['loss'], label = 'train')\n  ax1.plot(history.history['val_loss'], label = 'test')\n  ax1.set_ylabel('Loss')\n\n  ax1.set_xlabel('Epoch')\n  ax1.legend(['Train', 'Validation'])\n\n  # Plot accuracy\n  ax2.set_title('Accuracy')\n  ax2.plot(history.history['accuracy'],  label = 'train')\n  ax2.plot(history.history['val_accuracy'], label = 'test')\n  ax2.set_ylabel('Accuracy')\n  ax2.set_xlabel('Epoch')\n  ax2.legend(['Train', 'Validation'])\n\n  plt.show()\n\nplot_history(history)\n```\n\n----------------------------------------\n\nTITLE: Simulating Monty Hall Problem with Gemini API in Python\nDESCRIPTION: This snippet sends a multimodal prompt to the Gemini API, including text and an image, to run a simulation of the Monty Hall Problem. It demonstrates how to use code execution with visual inputs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nprompt=\"\"\"\n    Run a simulation of the Monty Hall Problem with 1,000 trials.\n\n    The answer has always been a little difficult for me to understand when people\n    solve it with math - so run a simulation with Python to show me what the\n    best strategy is.\n\"\"\"\nresult = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[\n        prompt,\n        montey_hall_image\n    ],\n    config=types.GenerateContentConfig(\n        tools=[types.Tool(code_execution=types.ToolCodeExecution)]\n    )\n)\n\ndisplay_code_execution_result(result)\n```\n\n----------------------------------------\n\nTITLE: Loading and Processing Image\nDESCRIPTION: Loads an image using PIL for analysis with Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport PIL.Image\nimg = PIL.Image.open('image.jpg')\nimg\n```\n\n----------------------------------------\n\nTITLE: Selecting Most Relevant Search Result\nDESCRIPTION: Identifies and displays the most relevant search result based on embedding similarity to the user's query using argmax to find the highest similarity score.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nprint(summaries[np.argmax(sim_value)])\n```\n\n----------------------------------------\n\nTITLE: Initializing Weaviate Embedded Client\nDESCRIPTION: Creates a Weaviate client using embedded options, configuring it with text2vec-palm and generative-palm modules. This sets up a Weaviate instance that runs within the notebook environment.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nclient = weaviate.WeaviateClient(\n    embedded_options=EmbeddedOptions(\n        version=\"1.25.10\",\n        additional_env_vars={\n            \"ENABLE_MODULES\": \"text2vec-palm, generative-palm\"\n        }),\n        additional_headers={\n            \"X-Google-Studio-Api-Key\": GEMINI_API_KEY\n        }\n)\n\nclient.connect()\n```\n\n----------------------------------------\n\nTITLE: Qdrant Collection Setup\nDESCRIPTION: Initialization of Qdrant client and creation of vector collection for storing embeddings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Initialize Qdrant client.\nqdrant = QdrantClient(\":memory:\")\n\n# Create a collection named \"GeminiCollection\".\nqdrant.recreate_collection(\n    collection_name=\"GeminiCollection\",\n    vectors_config=models.VectorParams(\n        size=768,  # Vector size of `embedding-001`\n        distance=models.Distance.COSINE,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Generating Content Using Cached Context\nDESCRIPTION: Generates content by using the cached Apollo 11 transcript as context and displays the response using Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents='Find a lighthearted moment from this transcript',\n    config=types.GenerateContentConfig(\n        cached_content=apollo_cache.name,\n    )\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Defining Story Writing Prompts for Gemini API\nDESCRIPTION: Constructs a series of prompts for story generation including persona definition, writing guidelines, and templates for premise, outline, and story starting points.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Story_Writing_with_Prompt_Chaining.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npersona = '''\\\nYou are an award-winning science fiction author with a penchant for expansive,\nintricately woven stories. Your ultimate goal is to write the next award winning\nsci-fi novel.'''\n\nguidelines = '''\\\nWriting Guidelines\n\nDelve deeper. Lose yourself in the world you're building. Unleash vivid\ndescriptions to paint the scenes in your reader's mind. Develop your\ncharacterslet their motivations, fears, and complexities unfold naturally.\nWeave in the threads of your outline, but don't feel constrained by it. Allow\nyour story to surprise you as you write. Use rich imagery, sensory details, and\nevocative language to bring the setting, characters, and events to life.\nIntroduce elements subtly that can blossom into complex subplots, relationships,\nor worldbuilding details later in the story. Keep things intriguing but not\nfully resolved. Avoid boxing the story into a corner too early. Plant the seeds\nof subplots or potential character arc shifts that can be expanded later.\n\nRemember, your main goal is to write as much as you can. If you get through\nthe story too fast, that is bad. Expand, never summarize.\n'''\n\npremise_prompt = f'''\\\n{persona}\n\nWrite a single sentence premise for a sci-fi story featuring cats.'''\n\noutline_prompt = f'''\\\n{persona}\n\nYou have a gripping premise in mind:\n\n{{premise}}\n\nWrite an outline for the plot of your story.'''\n\nstarting_prompt = f'''\\\n{persona}\n\nYou have a gripping premise in mind:\n\n{{premise}}\n\nYour imagination has crafted a rich narrative outline:\n\n{{outline}}\n\nFirst, silently review the outline and the premise. Consider how to start the\nstory.\n\nStart to write the very beginning of the story. You are not expected to finish\nthe whole story now. Your writing should be detailed enough that you are only\nscratching the surface of the first bullet of your outline. Try to write AT\nMINIMUM 1000 WORDS and MAXIMUM 2000 WORDS.\n\n{guidelines}'''\n```\n\n----------------------------------------\n\nTITLE: Updating Cached Content\nDESCRIPTION: Sends a PATCH request to update the TTL (Time To Live) of the cached content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \"https://generativelanguage.googleapis.com/v1beta/$(cat cache_name.txt)?key=$GOOGLE_API_KEY\" \\\n -H 'Content-Type: application/json' \\\n -d '{\"ttl\": \"300s\"}'\n```\n\n----------------------------------------\n\nTITLE: Testing Gemini Live API with Simple Prompt\nDESCRIPTION: Basic demonstration of the Gemini Live API with a simple greeting prompt, without any tools enabled, to verify that the setup is working correctly.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nawait run(prompt=\"Hello?\", tools=None, modality = \"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Polling for Video Processing Completion\nDESCRIPTION: Bash script that polls the File API to check if the uploaded video has finished processing before it can be used with the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n\nstate=$(jq -r \".file.state\" file_info.json)\nfile_uri=$(jq -r \".file.uri\" file_info.json)\n\nwhile [[ \"${state}\" == \"PROCESSING\" ]];\ndo\n  echo \"Processing video...\"\n  sleep 5\n  # Get the file of interest to check state\n  curl \"${file_uri}?key=${GOOGLE_API_KEY}\" >file_info.json 2>/dev/null\n  state=$(jq -r \".state\" file_info.json)\ndone\n\necho \"Video is now ${state}.\"\n```\n\n----------------------------------------\n\nTITLE: Setting System Prompt for Video Summarization\nDESCRIPTION: Defines a system prompt that instructs the Gemini model to provide a brief 2-3 sentence summary of the video content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"You should provide a quick 2 or 3 sentence summary of what is happening in the video.\"\n```\n\n----------------------------------------\n\nTITLE: Using Function Calling Config with Automatic Function Calling\nDESCRIPTION: Demonstrates how to use tool_config with automatic function calling enabled, forcing the model to use a specific function.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\navailable_fns = [\"enable_lights\"]\ntool_config = tool_config_from_mode(\"any\", available_fns)\n\nauto_chat = model.start_chat(enable_automatic_function_calling=True)\nauto_chat.send_message(\"It's awful dark in here...\", tool_config=tool_config)\n```\n\n----------------------------------------\n\nTITLE: Analyzing Sentiment of Reviews in Python\nDESCRIPTION: These code snippets demonstrate how to use the generate_content function to analyze the sentiment of the predefined reviews and print the results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\nresponse = generate_content(negative_review)\npprint(response.parsed)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = generate_content(positive_review)\npprint(response.parsed)\n```\n\nLANGUAGE: python\nCODE:\n```\nresponse = generate_content(neutral_review)\npprint(response.parsed)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with API Key\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Google Colab's userdata secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini model for entity extraction\nDESCRIPTION: This code selects the Gemini model to use from a list of available options, allowing customization of the model for the entity extraction task.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Checking Audio File Processing Status\nDESCRIPTION: Polls the file status until it's ready for use with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nstate=$(jq -r \".file.state\" file_info.json)\nfile_uri=$(jq -r \".file.uri\" file_info.json)\n\nwhile [[ \"${state}\" == \"PROCESSING\" ]];\ndo\n  echo \"Processing audio...\"\n  sleep 5\n  curl \"${file_uri}?key=${GOOGLE_API_KEY}\" >file_info.json 2>/dev/null\n  state=$(jq -r \".state\" file_info.json)\ndone\n\necho \"Audio is now ${state}.\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Image for Multimodal Prompting with Gemini API\nDESCRIPTION: This command downloads an image file to be used in a multimodal prompt for the Monty Hall Problem simulation. It demonstrates how to prepare visual inputs for the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n! curl -o montey_hall.png https://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Monty_open_door.svg/640px-Monty_open_door.svg.png\n```\n\n----------------------------------------\n\nTITLE: Testing Error Handling with Retry Mechanism for Gemini API in Python\nDESCRIPTION: Defines a function that deliberately raises a ServiceUnavailable error on the first call to test the retry mechanism for Gemini API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom google.api_core import retry, exceptions\n\n@retry.Retry(\n    predicate=retry.if_transient_error,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef generate_content_first_fail(model, prompt):\n    if not hasattr(generate_content_first_fail, \"call_counter\"):\n        generate_content_first_fail.call_counter = 0\n\n    generate_content_first_fail.call_counter += 1\n\n    try:\n        if generate_content_first_fail.call_counter == 1:\n            raise exceptions.ServiceUnavailable(\"Service Unavailable\")\n\n        response = model.generate_content(prompt)\n        return response.text\n    except exceptions.ServiceUnavailable as e:\n        print(f\"Error: {e}\")\n        raise\n\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")\nprompt = \"Write a one-liner advertisement for magic backpack.\"\n\ngenerate_content_first_fail(model=model, prompt=prompt)\n```\n\n----------------------------------------\n\nTITLE: Creating System Instructions for the Gemini Model\nDESCRIPTION: Defines detailed system instructions that guide the model on how to transform audio thoughts and example blog posts into a polished draft that matches the user's writing style.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nsi=\"\"\"Objective: Transform raw thoughts and ideas into polished, engaging blog posts that capture a writers unique style and voice.\nInput:\nExample Blog Posts (1-5): A user will provide examples of blog posts that resonate with their desired style and tone. These will guide you in understanding the preferences for word choice, sentence structure, and overall voice.\nAudio Clips: A user will share a selection of brainstorming thoughts and key points through audio recordings. They will talk freely and openly, as if they were explaining their ideas to a friend.\nOutput:\nBlog Post Draft: A well-structured first draft of the blog post, suitable for platforms like Substack or LinkedIn.\nThe draft will include:\nClear and engaging writing: you will strive to make the writing clear, concise, and interesting for the target audience.\nTone and style alignment: The language and style will closely match the examples provided, ensuring consistency with the desired voice.\nLogical flow and structure: The draft will be organized with clear sections based on the content of the post.\nTarget word count: Aim for 500-800 words, but this can be adjusted based on user preferences.\nProcess:\nStyle Analysis: Carefully analyze the example blog posts provided by the user to identify key elements of their preferred style, including:\nVocabulary and word choice: Formal vs. informal, technical terms, slang, etc.\nSentence structure and length: Short and impactful vs. longer and descriptive sentences.\nTone and voice: Humorous, serious, informative, persuasive, etc.\nAudio Transcription and Comprehension: Your audio clips will be transcribed with high accuracy. you will analyze them to extract key ideas, arguments, and supporting points.\nDraft Generation: Using the insights from the audio and the style guidelines from the examples, you will generate a first draft of the blog post. This draft will include all relevant sections with supporting arguments or evidence, and a great ending that ties everything together and makes the reader want to invest in future readings.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Curl Request Using Previous Function Call Response\nDESCRIPTION: Bash script using curl to call the Gemini API with a conversation context that includes the previous user query, model's function call, and function response. This demonstrates how to use a previous function call result in a multi-turn conversation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%%bash\n\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"contents\": [{\n      \"role\": \"user\",\n      \"parts\": [{\n        \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n    }]\n  }, {\n    \"role\": \"model\",\n    \"parts\": [{\n      \"functionCall\": {\n        \"name\": \"find_theaters\",\n        \"args\": {\n          \"location\": \"Mountain View, CA\",\n          \"movie\": \"Barbie\"\n        }\n      }\n    }]\n  }, {\n    \"role\": \"function\",\n    \"parts\": [{\n      \"functionResponse\": {\n        \"name\": \"find_theaters\",\n        \"response\": {\n          \"name\": \"find_theaters\",\n          \"content\": {\n            \"movie\": \"Barbie\",\n            \"theaters\": [{\n              \"name\": \"AMC Mountain View 16\",\n              \"address\": \"2000 W El Camino Real, Mountain View, CA 94040\"\n            }, {\n              \"name\": \"Regal Edwards 14\",\n              \"address\": \"245 Castro St, Mountain View, CA 94040\"\n            }]\n          }\n        }\n      }\n    }]\n  }],\n  \"tools\": [{\n    \"functionDeclarations\": [{\n      \"name\": \"find_movies\",\n      \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"description\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n          }\n        },\n        \"required\": [\"description\"]\n      }\n    }, {\n      \"name\": \"find_theaters\",\n      \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"movie\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any movie title\"\n          }\n        },\n        \"required\": [\"location\"]\n      }\n    }, {\n      \"name\": \"get_showtimes\",\n      \"description\": \"Find the start times for movies playing in a specific theater\",\n      \"parameters\": {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n          \"location\": {\n            \"type\": \"STRING\",\n            \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n          },\n          \"movie\": {\n            \"type\": \"STRING\",\n            \"description\": \"Any movie title\"\n          },\n          \"theater\": {\n            \"type\": \"STRING\",\n            \"description\": \"Name of the theater\"\n          },\n          \"date\": {\n            \"type\": \"STRING\",\n            \"description\": \"Date for requested showtime\"\n          }\n        },\n        \"required\": [\"location\", \"movie\", \"theater\", \"date\"]\n      }\n    }]\n  }]\n}' 2> /dev/null\n```\n\n----------------------------------------\n\nTITLE: Generating Text Embeddings with REST API\nDESCRIPTION: Using curl to call the embedContent endpoint with text-embedding-004 model to generate embeddings for a simple text input.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\"model\": \"models/text-embedding-004\",\n    \"content\": {\n    \"parts\":[{\n      \"text\": \"Hello world\"}]}, }' 2> /dev/null | head\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Gemini API Using File Contents\nDESCRIPTION: Code that uses the Gemini API to generate a response based on the uploaded text file content. It sends a prompt asking about the transcript and includes the full text data as context.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Upload_files_to_Colab.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[\n        'What is this transcript?',\n        text_data\n    ]\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Video Metadata in Bash\nDESCRIPTION: Bash script to prepare video metadata needed for the upload process, including MIME type detection and file size calculation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n\nVIDEO_PATH=\"./BigBuckBunny_320x180.mp4\"\nDISPLAY_NAME=\"Big Buck Bunny\"\n\n# Auto-detect the metadata needed when you upload the video.\nMIME_TYPE=$(file -b --mime-type \"${VIDEO_PATH}\")\nNUM_BYTES=$(wc -c < \"${VIDEO_PATH}\")\n\necho $VIDEO_PATH $MIME_TYPE $NUM_BYTES\n\n# Colab doesn't allow sharing shell variables between cells, so save them.\ncat >./vars.sh <<-EOF\n  export BASE_URL=\"https://generativelanguage.googleapis.com\"\n  export DISPLAY_NAME=\"${DISPLAY_NAME}\"\n  export VIDEO_PATH=${VIDEO_PATH}\n  export MIME_TYPE=${MIME_TYPE}\n  export NUM_BYTES=${NUM_BYTES}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Customizing entity extraction output format for directions\nDESCRIPTION: This code modifies the previous query to extract the same entities but with a more specific output format, asking for two separate lists of street names and transportation methods.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndirections_list_prompt = f\"\"\"\n  From the given text, extract the following entities and\n  return a list of them.\n  Entities to extract: street name, form of transport.\n  Text: {directions}\n  Return your answer as two lists:\n  Street = [street names]\n  Transport = [forms of transport]\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=directions_list_prompt\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client\nDESCRIPTION: This snippet sets up the Gemini API client using an API key stored in a Colab Secret.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Defining Functions for Asynchronous Image Processing\nDESCRIPTION: Creates helper functions for downloading images asynchronously with aiohttp and processing them with the Gemini API. The functions are designed to maximize parallelism by using futures.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport io, aiohttp, asyncio\n\nasync def download_image(session: aiohttp.ClientSession, img_url: str) -> PIL.Image:\n  \"\"\"Returns a PIL.Image object from the provided URL.\"\"\"\n  async with session.get(img_url) as img_resp:\n    buffer = io.BytesIO()\n    buffer.write(await img_resp.read())\n    return PIL.Image.open(buffer)\n\n\nasync def process_image(img_future: asyncio.Future[PIL.Image]) -> str:\n  \"\"\"Summarise the image using the Gemini API.\"\"\"\n  # This code uses a future so that it defers work as late as possible. Using a\n  # concrete Image object would require awaiting the download task before *queueing*\n  # this content generation task - this approach chains the futures together\n  # so that the download only starts when the generation is scheduled.\n  r = await client.aio.models.generate_content(\n      model=MODEL_ID,\n      contents=[prompt, await img_future]\n  )\n  return r.text\n```\n\n----------------------------------------\n\nTITLE: Inspecting Specific Model Details\nDESCRIPTION: Retrieves and displays detailed information about a specific model (gemini-2.0-flash), including token limits\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor model in client.models.list():\n    if model.name == \"models/gemini-2.0-flash\":\n        print(model)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Code Generation System Prompt\nDESCRIPTION: Configures system instructions for generating front-end code without explanations\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"\"\"\n    You are a coding expert that specializes in front end interfaces. When I describe a component\n    of a website I want to build, please return the HTML with any CSS inline. Do not give an\n    explanation for this code.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Batch Importing Remaining Data to Weaviate in Python\nDESCRIPTION: Shows how to use Weaviate's batch import functionality to efficiently add multiple objects to a collection. This code uploads the remaining 98 items from the dataset using a batch operation, then verifies the total count is 99.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nremaining_data = data[1:]\n\nwith products.batch.dynamic() as batch:\n  for item in remaining_data:\n    batch.add_object(\n      properties={\n        \"product_id\": item['product_id'],\n        \"title\": item['title'],\n        \"category\": item['category'],\n        \"link\": item['link'],\n        \"description\": item['description'],\n        \"brand\": item['brand']\n    }\n  )\n\nresponse = products.aggregate.over_all(total_count=True)\nprint(response.total_count) # this should print 99\n```\n\n----------------------------------------\n\nTITLE: Querying ChromaDB for Relevant Passages\nDESCRIPTION: This function performs a nearest neighbors search in the ChromaDB collection to find similar embeddings or documents based on a query.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef get_relevant_passage(query, db):\n  passage = db.query(query_texts=[query], n_results=1)['documents'][0][0]\n  return passage\n```\n\n----------------------------------------\n\nTITLE: Creating SQLite Database with California Housing Data\nDESCRIPTION: Establishes a connection to a SQLite database and writes the California housing DataFrame to a table named 'housing'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconn = sqlite3.connect(\"mydatabase.db\")\n\n# Write the DataFrame to a SQL table named 'housing'.\ncalifornia_housing_df.to_sql(\"housing\", conn, index=False)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Grocery Extraction Configuration\nDESCRIPTION: Configures the system prompt and generation settings for extracting groceries from recipe text.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\ngroceries_system_prompt = f\"\"\"\n  Your task is to extract to a list all the groceries with its quantities based on the provided recipe.\n  Make sure that groceries are in the order of appearance.\n\"\"\"\n\ngrocery_extraction_config =  types.GenerateContentConfig(\n    system_instruction=groceries_system_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up the Gemini API Client with Authentication\nDESCRIPTION: Code to retrieve the Google API key from Colab's userdata and initialize the Gemini client for API access.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Embedding Model\nDESCRIPTION: Sets up the Gemini embedding model (embedding-001) for creating text embeddings of the website data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\ngemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n```\n\n----------------------------------------\n\nTITLE: Querying Personalized Descriptions with Cross-References in Python\nDESCRIPTION: This snippet fetches objects from the 'Personalized' collection with their cross-referenced properties from both Product and Persona collections. It demonstrates how to retrieve related information across collections and display the combined data including product images.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_27\n\nLANGUAGE: python\nCODE:\n```\npersonalized = client.collections.get(\"Personalized\")\n\nresponse = personalized.query.fetch_objects(\n    limit=2,\n    return_references=[QueryReference(\n            link_on=\"ofProduct\", # return the title property from the Product collection\n            return_properties=[\"title\", \"link\"]\n        ),\n        QueryReference(\n            link_on=\"ofPersona\",\n            return_properties=[\"name\"] # return the name property from the Persona collection\n        )\n    ]\n)\n\nfor item in response.objects:\n    print(item.properties)\n    for ref_obj in item.references[\"ofProduct\"].objects:\n        print(ref_obj.properties)\n    for ref_obj in item.references[\"ofPersona\"].objects:\n        print(ref_obj.properties)\n    display_image(product.properties['link'])\n    print(\"===\")\n```\n\n----------------------------------------\n\nTITLE: Parsing JSON Response String\nDESCRIPTION: Converts the raw text response from the API into a Python object using the json.loads() function, then prints the result for verification.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nresponse = json.loads(raw_response.text)\nprint(response)\n```\n\n----------------------------------------\n\nTITLE: Initializing Chat Session\nDESCRIPTION: Creates a chat session for multi-turn conversations with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(model=MODEL_ID)\n```\n\n----------------------------------------\n\nTITLE: Loading Web Content using WebBaseLoader\nDESCRIPTION: Using LangChain's WebBaseLoader to fetch and load content from a Google blog post about Gemini AI, which will be processed and summarized.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nloader = WebBaseLoader(\"https://blog.google/technology/ai/google-gemini-ai/#sundar-note\")\ndocs = loader.load()\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model for PDF Processing\nDESCRIPTION: Sets the model ID to be used for PDF processing, allowing selection from various Gemini models with different capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Updating Tuned Model Description in Gemini API with Python\nDESCRIPTION: This code shows how to update the description of a tuned model using the Gemini API. It demonstrates setting and retrieving the model description.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ngenai.update_tuned_model(f'tunedModels/{name}', {\"description\":\"This is my model.\"});\n\nmodel = genai.get_tuned_model(f'tunedModels/{name}')\n\nmodel.description\n```\n\n----------------------------------------\n\nTITLE: Making API Request with Modified Safety Settings\nDESCRIPTION: Executes a curl command to call the Gemini API with the modified request containing custom safety settings and saves the response to a file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n%%bash\n\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d @request.json  2> /dev/null > response.json\n```\n\n----------------------------------------\n\nTITLE: Listing Existing Tuned Models in Gemini API with Python\nDESCRIPTION: This snippet shows how to retrieve and print a list of existing tuned models using the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfor m in genai.list_tuned_models():\n  print(m.name)\n```\n\n----------------------------------------\n\nTITLE: Implementing Synchronous Response Streaming with Gemini API\nDESCRIPTION: Example of synchronous streaming where text chunks are printed as they are generated by the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfor chunk in client.models.generate_content_stream(\n  model='gemini-2.0-flash',\n  contents='Tell me a story in 300 words.'\n):\n    print(chunk.text)\n    print(\"_\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Listing Cached Contents\nDESCRIPTION: Sends a GET request to list all cached contents for the user's API key.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!curl \"https://generativelanguage.googleapis.com/v1beta/cachedContents?key=$GOOGLE_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Dictionary of Class Labels and Encoded Values\nDESCRIPTION: This code creates a dictionary that maps class names to their encoded label values from the test dataset.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_21\n\nLANGUAGE: python\nCODE:\n```\nlabels_dict = dict(zip(df_test['Class Name'], df_test['Encoded Label']))\nlabels_dict\n```\n\n----------------------------------------\n\nTITLE: Checking Response Finish Reason\nDESCRIPTION: Uses jq to extract the finishReason field from the API response to determine if the model completed normally or was stopped due to safety concerns.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n%%bash\njq .candidates[0].finishReason < response.json\n```\n\n----------------------------------------\n\nTITLE: Creating Async Context Manager for Live Audio in Python\nDESCRIPTION: Implements an async context manager that runs an audio connection to the Colab UI. It initializes the required JavaScript, creates an AudioSession, and manages tasks for reading data and monitoring the session status.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@contextlib.asynccontextmanager\nasync def RunningLiveAudio(\n    config: AudioConfig = STANDARD_AUDIO_CONFIG, pump_interval=0.1\n):\n  \"\"\"Runs audio connection to Colab UI and returns `AudioConnection` connected to it.\"\"\"\n  assert config.channels == 1\n  assert config.format == 'S16_LE'\n  required_js = f\"\"\"\n    const audio_worklet_js = {json.dumps(_audio_processor_worklet_js)};\n    const sample_rate = {json.dumps(config.sample_rate)};\n    {_audio_session_js}\n  \"\"\"\n  try:\n    async with contextlib.AsyncExitStack() as stack:\n      tg = await stack.enter_async_context(asyncio.TaskGroup())\n      connection = await stack.enter_async_context(\n          RunningLiveJs(required_js, pump_interval)\n      )\n      session = AudioSession(config, connection)\n      read_task = tg.create_task(session._read_loop())  # copy data to queue\n      tg.create_task(session.await_start())  # fail session if it fails to start\n      yield session\n      read_task.cancel()\n  except asyncio.ExceptionGroup as e:\n    if len(e.exceptions) == 1:\n      raise e.exceptions[0]\n    else:\n      raise\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Cat Persona\nDESCRIPTION: Demonstrates using system instructions to make the model respond as a cat named Neko\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"You are a cat. Your name is Neko.\"\nprompt = \"Good morning! How are you?\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config=types.GenerateContentConfig(\n        system_instruction=system_prompt\n    )\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Uploading Audio File to Gemini API\nDESCRIPTION: Uploads an audio file (voice memo) to the Gemini API to be used as input for content generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\naudio_file_name = \"Walking_thoughts_3.m4a\"\naudio_file = genai.upload_file(path=audio_file_name)\n```\n\n----------------------------------------\n\nTITLE: Loading MP3 Audio File with PyDub\nDESCRIPTION: Loads the downloaded MP3 file into a PyDub AudioSegment object for further manipulation and processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nsound = AudioSegment.from_mp3(\"sample.mp3\")\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens in PDF File Request\nDESCRIPTION: Counts the total number of tokens that will be used when processing the PDF file with the specified prompt, which helps understand API usage.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclient.models.count_tokens(\n    model=MODEL_ID,\n    contents=[file_ref, 'Can you summarize this file as a bulleted list?']\n).total_tokens\n```\n\n----------------------------------------\n\nTITLE: Displaying Entity Extraction Results with Pretty Printing\nDESCRIPTION: Code to parse and display the JSON response from the Gemini API with proper formatting. It uses the json module to parse the response text and format it with indentation for better readability.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Entity_Extraction_JSON.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nprint(json.dumps(json.loads(response.text), indent=4))\n```\n\n----------------------------------------\n\nTITLE: Creating and Plotting a Confusion Matrix for Multi-class Classification\nDESCRIPTION: This snippet creates and plots a confusion matrix for the multi-class classification problem using scikit-learn. It uses the actual values from the validation set and the predicted values to generate the matrix.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nimport sklearn.metrics as skmetrics\n\ncm = skmetrics.confusion_matrix(y_val, y_hat)\ndisp = skmetrics.ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=labels_dict.keys())\ndisp.plot(xticks_rotation='vertical')\nplt.title('Confusion matrix for newsgroup test dataset');\nplt.grid(False)\n```\n\n----------------------------------------\n\nTITLE: Calling Gemini API with cURL\nDESCRIPTION: Example of calling the Gemini API using cURL from the command line, reading the API key from an environment variable.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[{\n          \"text\": \"Please give me Python code to sort a list.\"\n        }]\n      }]\n    }'\n```\n\n----------------------------------------\n\nTITLE: Comparing Bogo-sort Implementations with Gemini API in Python\nDESCRIPTION: This snippet requests an alternate implementation of the Bogo-sort algorithm and compares the number of iterations between two runs. It showcases the ability to have multi-turn conversations and execute multiple code snippets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresponse = chat.send_message(\"Run an alternate implementation of the bogo-sort algorithm with the same input\")\ndisplay_code_execution_result(response)\n\nresponse = chat.send_message(\"How many iterations did it take this time? Compare it with the first try.\")\ndisplay_code_execution_result(response)\n```\n\n----------------------------------------\n\nTITLE: Uploading Single Object to Weaviate Products Collection in Python\nDESCRIPTION: Demonstrates how to upload a single object to a Weaviate collection and verify it was added successfully. The code inserts a product with properties like product_id, title, category, link, description, and brand, then confirms the total count.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nfirst_object = data[0]\n\nproducts.data.insert(\n    properties={\n        \"product_id\": first_object['product_id'],\n        \"title\": first_object['title'],\n        \"category\": first_object['category'],\n        \"link\": first_object['link'],\n        \"description\": first_object['description'],\n        \"brand\": first_object['brand']\n    }\n)\n\nresponse = products.aggregate.over_all(total_count=True)\nprint(response.total_count) # This should output 1\n```\n\n----------------------------------------\n\nTITLE: Creating Server Content Handler for Gemini Live API\nDESCRIPTION: Function to process server content responses from the Gemini API, including handling executable code, code execution results, and grounding metadata from search tools.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef handle_server_content(wf, server_content):\n  model_turn = server_content.model_turn\n  if model_turn:\n    for part in model_turn.parts:\n      executable_code = part.executable_code\n      if executable_code is not None:\n        display.display(display.Markdown('-------------------------------'))\n        display.display(display.Markdown(f'``` python\\n{executable_code.code}\\n```'))\n        display.display(display.Markdown('-------------------------------'))\n\n      code_execution_result = part.code_execution_result\n      if code_execution_result is not None:\n        display.display(display.Markdown('-------------------------------'))\n        display.display(display.Markdown(f'```\\n{code_execution_result.output}\\n```'))\n        display.display(display.Markdown('-------------------------------'))\n\n  grounding_metadata = getattr(server_content, 'grounding_metadata', None)\n  if grounding_metadata is not None:\n    display.display(\n        display.HTML(grounding_metadata.search_entry_point.rendered_content))\n\n  return\n```\n\n----------------------------------------\n\nTITLE: Single Turn Gemini API System Instruction\nDESCRIPTION: Curl command demonstrating a single API call to Gemini with system instructions to make the model respond as a cat\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{ \"system_instruction\": {\n    \"parts\":\n      { \"text\": \"You are Neko the cat respond like one\"}},\n    \"contents\": {\n      \"parts\": {\n        \"text\": \"Hello there\"}}}'\n```\n\n----------------------------------------\n\nTITLE: Sampling data function for specific categories\nDESCRIPTION: Defines a function to sample a specific number of data points from each category and filter to keep only categories containing a specified string in their class name.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef sample_data(df, num_samples, classes_to_keep):\n  df = df.groupby('Label', as_index = False).apply(lambda x: x.sample(num_samples)).reset_index(drop=True)\n\n  df = df[df['Class Name'].str.contains(classes_to_keep)]\n\n  # Reset the encoding of the labels after sampling and dropping certain categories\n  df['Class Name'] = df['Class Name'].astype('category')\n  df['Encoded Label'] = df['Class Name'].cat.codes\n\n  return df\n```\n\n----------------------------------------\n\nTITLE: Configuring API Key for Gemini Client\nDESCRIPTION: This code retrieves the API key from Colab secrets and initializes the Gemini client for making API requests.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nAPI_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Gemini API\nDESCRIPTION: Example of generating content using the Gemini API with the configured client and model, displaying the result as Markdown.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=\"Please give me python code to sort a list.\"\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Pretty-Printing JSON Response\nDESCRIPTION: Serializes the Python object back to a formatted JSON string with indentation for better readability, then prints it to the console.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(json.dumps(response, indent=4))\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated HTML in IPython\nDESCRIPTION: This snippet extracts the HTML code from the Gemini API response and displays it using IPython's HTML display function.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport IPython\ncode = response.text.split('```')[1][len('html'):]\nIPython.display.HTML(code)\n```\n\n----------------------------------------\n\nTITLE: Website Data Extraction and Processing\nDESCRIPTION: Code to fetch and parse website content using BeautifulSoup, removing scripts and styles.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nurl = \"https://blog.google/outreach-initiatives/sustainability/\"\\\n      \"report-ai-sustainability-google-cop28/\"\nhtml = urlopen(url).read()\nsoup = BeautifulSoup(html, features=\"html.parser\")\n\n# Remove all script and style elements\nfor script in soup([\"script\", \"style\"]):\n    script.extract()    # Self-destruct\n\n# Get the text\ntext_content = soup.get_text()\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Import statements for BeautifulSoup, Qdrant client, and URL handling.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom bs4 import BeautifulSoup\nfrom qdrant_client import models, QdrantClient\nfrom urllib.request import urlopen\n```\n\n----------------------------------------\n\nTITLE: Generating Story Summary\nDESCRIPTION: Uses Gemini API to generate a structured summary of the story with JSON output following the defined schema.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = f\"\"\"\nGenerate summary of the story. With a list of genres locations and characters.\n\n{story}\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config={\n        \"response_mime_type\": \"application/json\",\n        \"response_schema\": TextSummary\n        }\n    )\n```\n\n----------------------------------------\n\nTITLE: Creating Personalized Collection with Cross-References in Weaviate Python\nDESCRIPTION: Creates a new collection with cross-references to establish relationships between collections. The 'Personalized' collection links to both 'Products' and 'Personas' collections, enabling personalized content generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_23\n\nLANGUAGE: python\nCODE:\n```\nPROJECT_ID = \"\" # leave this empty\nAPI_ENDPOINT = \"generativelanguage.googleapis.com\"\nembedding_model = \"text-embedding-004\" # embedding model\ngenerative_model = \"gemini-2.0-flash\" # language mdodel\n\n# Personalized Collection\n\nif not client.collections.exists(\"Personalized\"):\n  collection = client.collections.create(\n    name=\"Personalized\",\n    vectorizer_config=Configure.Vectorizer.text2vec_palm(\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = embedding_model\n    ),\n    generative_config=Configure.Generative.palm(\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = generative_model\n    ),\n    properties=[\n            Property(name=\"description\", data_type=DataType.TEXT),\n    ],\n    # cross-references\n    references=[\n        ReferenceProperty(\n            name=\"ofProduct\",\n            target_collection=\"Products\" # connect personalized to the products collection\n        ),\n        ReferenceProperty(\n            name=\"ofPersona\",\n            target_collection=\"Personas\" # connect personalized to the personas collection\n        )\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Text Content Processing and Chunking\nDESCRIPTION: Processing extracted text content into manageable chunks for embedding.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntext_content_1 = text_content.split(\"Later this month at COP28\",1)[1]\nfinal_text = text_content_1.split(\"POSTED IN:\",1)[0]\n\ntexts = final_text.split(\".\")\n\ndocuments = []\n\n# Convert text into a chunk of 3 sentences.\nfor i in range(0, len(texts), 3):\n  documents.append({\"content\": \" \".join(texts[i:i+3])})\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple Candidates in Python\nDESCRIPTION: Shows how to iterate through multiple candidates when using candidate_count > 1.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfor candidate in response.candidates:\n  display(Markdown(candidate.content.parts[0].text))\n  display(Markdown(\"-------------\"))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Code Generation System\nDESCRIPTION: Configuring the code generation system with specific prompts and parameters\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncode_generation_system_prompt = f\"\"\"\n  You are a coding assistant. Your task is to generate a code snippet that\n  accomplishes a specific goal. The code snippet must be concise, efficient,\n  and well-commented for clarity. Consider any constraints or requirements\n  provided for the task.\n\n  If the task does not specify a programming language, default to Python.\n\"\"\"\n\ncode_generation_model_config = types.GenerateContentConfig(\n    temperature= 0,\n    system_instruction=code_generation_system_prompt\n  )\n```\n\n----------------------------------------\n\nTITLE: Evaluating Model Performance with Keras Model.evaluate\nDESCRIPTION: This snippet uses Keras Model.evaluate to get the loss and accuracy on the test dataset. It returns the results as a dictionary.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nclassifier.evaluate(x=x_val, y=y_val, return_dict=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Error Analysis\nDESCRIPTION: Processing and analyzing a specific error message using the Gemini API\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nerror_message = \"\"\"\n    1 my_list = [1,2,3]\n  ----> 2 print(my_list[3])\n\n  IndexError: list index out of range\n\"\"\"\n\nerror_prompt = f\"\"\"\n  You've encountered the following error message:\n  Error Message: {error_message}\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=error_prompt,\n    config=error_handling_model_config\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Generation Config Usage in Python\nDESCRIPTION: Shows how to use generation_config with the GenerativeModel and generate_content method.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name, generation_config={'temperature':1.0})\nresponse = model.generate_content('hello', generation_config = genai.GenerationConfig(max_output_tokens=5))\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API Authentication\nDESCRIPTION: This code initializes the Gemini API client with an API key stored in Colab's secrets. It imports the necessary modules and authenticates the user with the API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Manual Function Call Implementation with Gemini\nDESCRIPTION: Demonstrates manual implementation of function calling by starting a chat session without automatic function calling. This shows the underlying process that happens when automatic function calling is enabled.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nchat = model.start_chat()\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Defines the Gemini model ID to be used for text generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Preparing Cached Content JSON for Gemini API\nDESCRIPTION: Creates a JSON file with the base64 encoded Apollo 11 transcript and Gemini model configuration for caching.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\necho '{\n  \"model\": \"models/gemini-1.5-flash-002\",\n  \"contents\":[\n    {\n      \"parts\":[\n        {\n          \"inline_data\": {\n            \"mime_type\":\"text/plain\",\n            \"data\": \"'$(base64 -w0 a11.txt)'\"\n          }\n        }\n      ],\n    \"role\": \"user\"\n    }\n  ],\n  \"systemInstruction\": {\n    \"parts\": [\n      {\n        \"text\": \"You are an expert at analyzing transcripts.\"\n      }\n    ]\n  },\n  \"ttl\": \"600s\"\n}' > request.json\n```\n\n----------------------------------------\n\nTITLE: Configuring Safety Settings for Gemini API\nDESCRIPTION: Defines custom safety settings for the Gemini API to prevent content filtering from blocking literary translation. Sets all harm categories to BLOCK_NONE threshold.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\nsafety_settings =[\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n            ),\n            types.SafetySetting(\n              category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n              threshold=types.HarmBlockThreshold.BLOCK_NONE,\n            )\n        ]\n```\n\n----------------------------------------\n\nTITLE: Getting Model Details using curl\nDESCRIPTION: This bash command uses curl to get detailed information about a specific model (gemini-2.0-flash) including version, display name, and input token limit.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Models_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash?key=$GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Retrieving Most Relevant Document for Query\nDESCRIPTION: Uses the find_best_passage function to retrieve the most relevant document from the database based on the sample query.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npassage = find_best_passage(query, df)\npassage\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini LLM for Text Generation\nDESCRIPTION: Python code that imports and initializes the Gemini 2.0 Flash model from LlamaIndex for text generation, with notes on how to configure model parameters if needed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom llama_index.llms.gemini import Gemini\n\n# To configure model parameters use the `generation_config` parameter.\n# eg. generation_config = {\"temperature\": 0.7, \"topP\": 0.8, \"topK\": 40}\n# If you only want to set a custom temperature for the model use the\n# \"temperature\" parameter directly.\n\nllm = Gemini(model_name=\"models/gemini-2.0-flash\")\n```\n\n----------------------------------------\n\nTITLE: Filtering Vector Search Results in Weaviate Python\nDESCRIPTION: Shows how to narrow down vector search results using filters. This example searches for 'travel cup' but only returns products where the category is exactly 'Drinkware', limiting to 3 results.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nproducts = client.collections.get(\"Products\")\n\nresponse = products.query.near_text(\n    query=\"travel cup\",\n    return_properties=[\"title\", \"description\", \"category\", \"link\"], # returned properties\n    filters=wvc.query.Filter.by_property(\"category\").equal(\"Drinkware\"), # filter\n    limit=3, # limit to 3 objects\n)\n\nfor product in response.objects:\n    print(json.dumps(product.properties, indent=2))\n    display_image(product.properties['link'])\n    print('===')\n```\n\n----------------------------------------\n\nTITLE: Checking Embedding Dimensions in Gemini API\nDESCRIPTION: Outputs the number of dimensions in the embedding vector generated by the text-embedding-004 model, which by default is 768 dimensions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(len(embedding.values))  # The embeddings have 768 dimensions\n```\n\n----------------------------------------\n\nTITLE: Generating Web App Content with Gemini API in Python\nDESCRIPTION: This code uses the Gemini API to generate the content for the Opossum Search web app based on the provided instructions and prompt.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import display, Markdown\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n    config=GenerateContentConfig(\n        system_instruction=instruction\n    )\n)\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Batch Embedding Multiple Prompts with REST API\nDESCRIPTION: Using curl to batch embed multiple text prompts in a single API call for improved efficiency, demonstrating the batchEmbedContents endpoint with three different text inputs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\"requests\": [{\n      \"model\": \"models/text-embedding-004\",\n      \"content\": {\n      \"parts\":[{\n        \"text\": \"What is the meaning of life?\"}]}, },\n      {\n      \"model\": \"models/text-embedding-004\",\n      \"content\": {\n      \"parts\":[{\n        \"text\": \"How much wood would a woodchuck chuck?\"}]}, },\n      {\n      \"model\": \"models/text-embedding-004\",\n      \"content\": {\n      \"parts\":[{\n        \"text\": \"How does the brain work?\"}]}, }, ]}' 2> /dev/null | grep -C 5 values\n```\n\n----------------------------------------\n\nTITLE: Sending Request to Gemini API using Curl in Bash\nDESCRIPTION: This curl command sends the prepared JSON request to the Gemini API for content generation. It uses environment variables for the API URL and key, and saves the response to a JSON file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\n. vars.sh\n\ncurl \"${BASE_URL}/v1beta/models/gemini-2.0-flash:generateContent?key=${GOOGLE_API_KEY}\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d @request.json 2>/dev/null >response.json\n\ncat response.json\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API with Authentication Key in Python\nDESCRIPTION: This code configures the Gemini API using an authentication key stored in a Colab Secret. It demonstrates how to set up the API for use in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\ngenai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model for Audio Processing\nDESCRIPTION: Sets the model ID for the Gemini model to be used in this tutorial, with options for different models including thinking models like Gemini 2.5.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Defining Sentiment Analysis Structure in Python\nDESCRIPTION: This snippet defines the structure for sentiment analysis, including enums for magnitude and a TypedDict for sentiment scores. It also sets up the system instruction for the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport enum\nfrom typing_extensions import TypedDict\n\n\nclass Magnitude(enum.Enum):\n  WEAK = \"weak\"\n  STRONG = \"strong\"\n\n\nclass Sentiment(TypedDict):\n  positive_sentiment_score: Magnitude\n  negative_sentiment_score: Magnitude\n  neutral_sentiment_score: Magnitude\n\n\nsystem_instruct = \"\"\"\nGenerate each sentiment score probability (positive, negative, or neutral) for the whole text.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating a Prompt for Audio Transcript\nDESCRIPTION: Defines a prompt that requests the Gemini API to generate a transcript of the speech. This variable will be used in subsequent API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Generate a transcript of the speech.\"\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini 2.0 Model for Search Tool\nDESCRIPTION: Sets the model ID for the Gemini 2.0 model to be used with the search tool. The selected model is 'gemini-2.0-flash'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\n```\n\n----------------------------------------\n\nTITLE: Creating a 10-Second Audio Slice\nDESCRIPTION: Creates a 10-second slice from the beginning of the audio file using PyDub. The slice time is specified in milliseconds (10000ms = 10s).\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nsound[:10000] # slices are in ms\n```\n\n----------------------------------------\n\nTITLE: Setting Up ChromaDB Database\nDESCRIPTION: This snippet creates the ChromaDB database using the previously defined function and sample documents.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Set up the DB\ndb = create_chroma_db(documents, \"googlecarsdatabase\")\n```\n\n----------------------------------------\n\nTITLE: Filtering Embedding-Capable Models\nDESCRIPTION: Lists models that specifically support the embedContent action for embeddings\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor model in client.models.list():\n    if \"embedContent\" in model.supported_actions:\n        print(model.name)\n```\n\n----------------------------------------\n\nTITLE: Generating Predicted Classes for Validation Set\nDESCRIPTION: This snippet uses Model.predict() to generate predicted classes for each example in the validation set. It then uses argmax to convert the predicted probabilities to class labels.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_20\n\nLANGUAGE: python\nCODE:\n```\ny_hat = classifier.predict(x=x_val)\ny_hat = np.argmax(y_hat, axis=1)\n```\n\n----------------------------------------\n\nTITLE: Defining the Barista Bot System Prompt\nDESCRIPTION: Creates a detailed prompt that defines the caf's menu, available modifiers, and operating instructions for the model. The prompt includes specific guidance on how the functions should be called and how to handle customer interactions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nCOFFEE_BOT_PROMPT = \"\"\"\\You are a coffee order taking system and you are restricted to talk only about drinks on the MENU. Do not talk about anything but ordering MENU drinks for the customer, ever.\nYour goal is to do place_order after understanding the menu items and any modifiers the customer wants.\nAdd items to the customer's order with add_to_order, remove specific items with remove_item, and reset the order with clear_order.\nTo see the contents of the order so far, call get_order (by default this is shown to you, not the user)\nAlways confirm_order with the user (double-check) before calling place_order. Calling confirm_order will display the order items to the user and returns their response to seeing the list. Their response may contain modifications.\nAlways verify and respond with drink and modifier names from the MENU before adding them to the order.\nIf you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect.\nYou only have the modifiers listed on the menu below: Milk options, espresso shots, caffeine, sweeteners, special requests.\nOnce the customer has finished ordering items, confirm_order and then place_order.\n\nHours: Tues, Wed, Thurs, 10am to 2pm\nPrices: All drinks are free.\n\nMENU:\nCoffee Drinks:\nEspresso\nAmericano\nCold Brew\n\nCoffee Drinks with Milk:\nLatte\nCappuccino\nCortado\nMacchiato\nMocha\nFlat White\n\nTea Drinks:\nEnglish Breakfast Tea\nGreen Tea\nEarl Grey\n\nTea Drinks with Milk:\nChai Latte\nMatcha Latte\nLondon Fog\n\nOther Drinks:\nSteamer\nHot Chocolate\n\nModifiers:\nMilk options: Whole, 2%, Oat, Almond, 2% Lactose Free; Default option: whole\nEspresso shots: Single, Double, Triple, Quadruple; default: Double\nCaffeine: Decaf, Regular; default: Regular\nHot-Iced: Hot, Iced; Default: Hot\nSweeteners (option to add one or more): vanilla sweetener, hazelnut sweetener, caramel sauce, chocolate sauce, sugar free vanilla sweetener\nSpecial requests: any reasonable modification that does not involve items not on the menu, for example: 'extra hot', 'one pump', 'half caff', 'extra foam', etc.\n\n\"dirty\" means add a shot of espresso to a drink that doesn't usually have it, like \"Dirty Chai Latte\".\n\"Regular milk\" is the same as 'whole milk'.\n\"Sweetened\" means add some regular sugar, not a sweetener.\n\nSoy milk has run out of stock today, so soy is not available.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Simple Function Calling with Gemini\nDESCRIPTION: Example of using the Gemini Live API's function calling capability to respond to a prompt about turning on lights by calling the appropriate function.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Turn on the lights\"\n\ntools = [\n    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n]\n\nawait run(prompt, tools=tools, modality = \"TEXT\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Authentication\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Uploading and Processing C++ Code File with Gemini API in Python\nDESCRIPTION: Shows how to upload a C++ code file to the Gemini API File API, specifying a custom MIME type, and use it in a content generation request.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n!curl -so gemma.cpp https://raw.githubusercontent.com/google/gemma.cpp/main/examples/hello_world/run.cc\n\ncpp_file = client.files.upload(\n    file=\"gemma.cpp\",\n    config={\n        \"display_name\":\"gemma.cpp\",\n        \"mime_type\":\"text/plain\"\n    }\n)\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[\"What does this program do?\", cpp_file]\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Retrieving File Information\nDESCRIPTION: Fetches and displays information about the uploaded audio file using the Gemini File API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n. vars.sh\n\nfile_uri=$(jq -r \".file.uri\" file_info.json)\n\ncurl \"${file_uri}?key=${GOOGLE_API_KEY}\" 2>/dev/null\n```\n\n----------------------------------------\n\nTITLE: Analyzing Chat Response Token Usage with Markdown\nDESCRIPTION: Creates a formatted Markdown display that breaks down the token usage for the chat response, highlighting the benefits of using cached tokens.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\ndisplay(Markdown(f\"\"\"\n  As you can see in the `usage_metadata`, the token usage is split between:\n  *  {response.usage_metadata.cached_content_token_count} tokens for the cache,\n  *  {response.usage_metadata.prompt_token_count} tokens for the input (including the cache, so {response.usage_metadata.prompt_token_count - response.usage_metadata.cached_content_token_count} for the actual prompt),\n  *  {response.usage_metadata.candidates_token_count} tokens for the output,\n  *  {response.usage_metadata.total_token_count} tokens in total.\n\"\"\"))\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini Model Configuration\nDESCRIPTION: Selects the Gemini model version to be used for code execution\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.5-flash-preview-04-17\", \"gemini-2.5-pro-preview-03-25\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Model in Python\nDESCRIPTION: Sets up the Gemini API model for generating content. Configures the API with the key and initializes the gemini-2.0-flash model which can handle both images and text inputs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_19\n\nLANGUAGE: python\nCODE:\n```\ngenai.configure(api_key=GEMINI_API_KEY) # gemini api key\n\ngemini_flash_model = genai.GenerativeModel(model_name='gemini-2.0-flash') # this model handles both images and text\n```\n\n----------------------------------------\n\nTITLE: Loading Image for Multimodal Prompting with Gemini API in Python\nDESCRIPTION: This code loads the downloaded image file using PIL library to be used in a multimodal prompt for the Gemini API. It prepares the visual input for the Monty Hall Problem simulation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nimport PIL\nmontey_hall_image = PIL.Image.open(\"montey_hall.png\")\nmontey_hall_image\n```\n\n----------------------------------------\n\nTITLE: Displaying First Frame of Video for Visualization\nDESCRIPTION: This code extracts and displays the first frame of the video to demonstrate the content that will be analyzed by the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport matplotlib.pyplot as plt\n\ncap = cv2.VideoCapture(path)\n_, frame = cap.read()\n\nframe_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n# Display using matplotlib\nplt.imshow(frame_rgb)\nplt.axis('off')\nplt.show()\n\n# close video file\ncap.release()\n```\n\n----------------------------------------\n\nTITLE: Creating and compiling the classifier model\nDESCRIPTION: Instantiates and compiles the classification model with the appropriate input size based on embedding dimensions and output size based on the number of classes.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Derive the embedding size from the first training element.\nembedding_size = len(df_train['Embeddings'].iloc[0])\n\n# Give your model a different name, as you have already used the variable name 'model'\nclassifier = build_classification_model(embedding_size, len(df_train['Class Name'].unique()))\nclassifier.summary()\n\nclassifier.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                   optimizer = keras.optimizers.Adam(learning_rate=0.001),\n                   metrics=['accuracy'])\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Tour Guide Role\nDESCRIPTION: Sends a request to generate content about German art museums using the tour guide system prompt, with the same model as the previous example.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nprompt = 'Could you give me some recommendations on art museums in Berlin and Cologne?'\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    config=types.GenerateContentConfig(system_instruction=system_prompt),\n    contents=prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Selecting Training Data for Gemini API Model Tuning in Python\nDESCRIPTION: This code selects the training data to be used for model tuning. It allows flexibility in choosing between dictionary data or CSV file data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Here you can specify any of the supported formats, e.g. dict_data or csv_file.\ntrain_data = dict_data\n```\n\n----------------------------------------\n\nTITLE: Displaying Original Text in Markdown Format\nDESCRIPTION: Shows a sample of the original text (the second chunk) in Markdown format for comparison with the translated version.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nMarkdown(chunks[1])\n```\n\n----------------------------------------\n\nTITLE: Using Autocut for Dynamic Result Limiting in Weaviate Python\nDESCRIPTION: Demonstrates the autocut feature which dynamically limits search results based on significant variations in vector distance or score. Instead of a fixed limit, auto_limit stops returning results after a specified number of 'jumps' in relevance.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\n# auto_limit set to 1\n\nproducts = client.collections.get(\"Products\")\n\nresponse = products.query.hybrid(\n    query = \"dishwasher safe container\", # query\n    alpha = 0.75, # leaning more towards vector search\n    return_properties=[\"title\", \"description\", \"link\"], # return these 3 properties\n    auto_limit = 1 # autocut after 1 jump\n)\n\nfor product in response.objects:\n    print(json.dumps(product.properties, indent=2))\n    display_image(product.properties['link'])\n    print('===')\n```\n\n----------------------------------------\n\nTITLE: Creating Chat Session with Function Calling\nDESCRIPTION: Initializing a chat session with automatic function calling enabled\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(\n    model = MODEL_ID,\n    config = {\n        \"tools\": operation_tools,\n        \"automatic_function_calling\": {\"disable\": False} # This line is not needed as automatic_function_calling is enabled by default\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Generative AI API Authentication\nDESCRIPTION: Sets up authentication for the Gemini API using an API key stored in Colab Secrets. This configuration is required before making any API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Defining German Tour Guide System Prompt\nDESCRIPTION: Creates a system prompt that instructs the model to assume the role of a German tour guide providing travel recommendations.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"\"\"\n    You are a German tour guide. Your task is to give recommendations to people visiting your country.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Sending Message to Gemini for Manual Function Call\nDESCRIPTION: Sends a message to the model which will trigger a function call response that needs to be manually handled.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nresult = chat.send_message(instructions.format(query=query))\n```\n\n----------------------------------------\n\nTITLE: Uploading Videos to Gemini API\nDESCRIPTION: Function to upload video files to the Gemini API and wait for processing completion, then uploads all sample videos.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\ndef upload_video(video_file_name):\n  video_file = client.files.upload(file=video_file_name)\n\n  while video_file.state == \"PROCESSING\":\n      print('Waiting for video to be processed.')\n      time.sleep(10)\n      video_file = client.files.get(name=video_file.name)\n\n  if video_file.state == \"FAILED\":\n    raise ValueError(video_file.state)\n  print(f'Video processing complete: ' + video_file.uri)\n\n  return video_file\n\npottery_video = upload_video('Pottery.mp4')\ntrailcam_video = upload_video('Trailcam.mp4')\npost_its_video = upload_video('Post_its.mp4')\nuser_study_video = upload_video('User_study.mp4')\n```\n\n----------------------------------------\n\nTITLE: Displaying Parsed Results\nDESCRIPTION: Prints the structured story summary data using pretty print formatting.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\npprint(response.parsed)\n```\n\n----------------------------------------\n\nTITLE: Configuring the SDK with API Key from Colab Secrets\nDESCRIPTION: Code to configure the Google Generative AI client using an API key securely stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python SDK with a minimum version requirement of 1.0.0. This ensures compatibility with the notebook as there were breaking changes in earlier versions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\" # Install the Python SDK\n\n# Always set at least 1.0.0 as the minimal version as there were breaking\n# changes through the previous versions\n# Of course, if your notebook uses a new feature and needs a more recent\n# version, set the right minimum version to indicate when the feature was\n# introduced\n```\n\n----------------------------------------\n\nTITLE: Creating SQLDatabase Object for LangChain Integration\nDESCRIPTION: Creates an SQLDatabase object from the SQLite database URI, which provides database schema information that the LLM can access.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Create an SQLDatabase object\ndb = SQLDatabase.from_uri(\"sqlite:///mydatabase.db\")\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Library in Python\nDESCRIPTION: This snippet installs the latest version of the google-genai library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Chain_of_thought_prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Content Generation with Curl\nDESCRIPTION: Makes a streaming API call to Gemini's content generation endpoint using curl. Uses server-sent events (SSE) for streaming and sends a prompt about cats.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Streaming_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:streamGenerateContent?alt=sse&key=${GOOGLE_API_KEY}\" \\\n        -H 'Content-Type: application/json' \\\n        --no-buffer \\\n        -d '{ \"contents\":[{\"parts\":[{\"text\": \"Write a cute story about cats.\"}]}]}'\n```\n\n----------------------------------------\n\nTITLE: Testing Presence Penalty in Gemini 002 Models with Python\nDESCRIPTION: Demonstrates the effect of presence_penalty on output diversity using the unique_words function.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nprompt='Tell me a story'\n```\n\nLANGUAGE: python\nCODE:\n```\n# baseline\nv = unique_words(prompt, generation_config={})\n```\n\nLANGUAGE: python\nCODE:\n```\n# the penalty encourages diversity in the oputput tokens.\nv = unique_words(prompt, generation_config=dict(presence_penalty=1.999))\n```\n\nLANGUAGE: python\nCODE:\n```\n# a negative penalty discourages diversity in the output tokens.\nv = unique_words(prompt, generation_config=dict(presence_penalty=-1.999))\n```\n\n----------------------------------------\n\nTITLE: Executing Generated Code\nDESCRIPTION: Extracting and executing the generated code using regex pattern matching\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport re\nmatchFound = re.search(r\"python\\n(.*?)```\", response.text, re.DOTALL)\nif matchFound:\n  code = matchFound.group(1)\n  exec(code)\n```\n\n----------------------------------------\n\nTITLE: Executing Bogo-sort Algorithm with Gemini API in Python\nDESCRIPTION: This code sends a message to the Gemini API chat to run a Bogo-sort algorithm on a list of numbers. It demonstrates how to interact with the chat and execute code through the API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nresponse = chat.send_message(\"Run the bogo-sort algorithm with this list of numbers as input until it is sorted: [2,34,1,65,4]\")\ndisplay_code_execution_result(response)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for ReAct Implementation\nDESCRIPTION: Imports necessary Python libraries including re for regular expressions, os for operating system functionalities, wikipedia for accessing Wikipedia API, and google.generativeai for interacting with the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport re\nimport os\n\nimport wikipedia\nfrom wikipedia.exceptions import DisambiguationError, PageError\n\nimport google.generativeai as genai\n```\n\n----------------------------------------\n\nTITLE: Creating a Chat Session with Cached Content\nDESCRIPTION: Creates a chat session using the cached Apollo 11 transcript and sends an initial message to get a quote from the transcript.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(\n  model=MODEL_ID,\n  config={\"cached_content\": apollo_cache.name}\n)\n\nresponse = chat.send_message(message=\"Give me a quote from the most important part of the transcript.\")\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Gemini API\nDESCRIPTION: Imports the Google Generative AI module for API access and the Markdown display function from IPython to render formatted text.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n\nfrom IPython.display import Markdown\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-turn Chat Conversation\nDESCRIPTION: Shows how to create and maintain a chat conversation with system instructions\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nchat = client.chats.create(\n    model=MODEL_ID,\n    config=types.GenerateContentConfig(\n        system_instruction=system_prompt\n    )\n)\n\nresponse = chat.send_message(\"Good day fine chatbot\")\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Answer as Markdown in Python\nDESCRIPTION: This code snippet uses IPython's Markdown display function to render the generated answer as markdown. It assumes that 'answer' is the response object from the Gemini API call.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nMarkdown(answer.text)\n```\n\n----------------------------------------\n\nTITLE: Extracting and Saving Cache Name\nDESCRIPTION: Extracts the cache name from the API response and saves it to a file for later use.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nCACHE_NAME=$(cat cache.json | grep '\"name\":' | cut -d '\"' -f 4 | head -n 1)\n\necho $CACHE_NAME > cache_name.txt\n\ncat cache_name.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring API key from Colab Secrets\nDESCRIPTION: Retrieves the Google API key from Colab Secrets and initializes the Gemini client with the API key for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nclient=genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gemini API\nDESCRIPTION: Installs the Google Generative AI Python client library and aiohttp for asynchronous HTTP requests.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU 'google-genai>=1.0.0' aiohttp\n```\n\n----------------------------------------\n\nTITLE: Uploading Audio File to Gemini API\nDESCRIPTION: Uploads the downloaded audio file to the Gemini API using the File API, which enables referencing the file in subsequent API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nyour_audio_file = client.files.upload(file='sample.mp3')\n```\n\n----------------------------------------\n\nTITLE: Importing Display Libraries\nDESCRIPTION: Importing necessary libraries for displaying results, including JSON processing, PIL for image handling, and IPython display utilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport json\nfrom PIL import Image\nfrom IPython.display import display, Markdown, HTML\n```\n\n----------------------------------------\n\nTITLE: Setting up API Authentication for Gemini API\nDESCRIPTION: Retrieves the Google API key from Colab secrets and initializes the Gemini API client. This authentication is required to access the embedding generation models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Implementing Unique Word Count Function in Python\nDESCRIPTION: Defines a function to calculate the fraction of unique words in model responses for testing penalty effects.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom statistics import mean\n```\n\nLANGUAGE: python\nCODE:\n```\ndef unique_words(prompt, generation_config, N=10):\n  responses = []\n  vocab_fractions = []\n  for n in range(N):\n    model = genai.GenerativeModel(model_name)\n    response = model.generate_content(contents=prompt, generation_config=generation_config)\n    responses.append(response)\n\n    words = response.text.lower().split()\n    score = len(set(words))/len(words)\n    print(score)\n    vocab_fractions.append(score)\n\n  return vocab_fractions\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with API Key\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab Secrets. This step is necessary for authentication and accessing the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nAPI_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Checking embedding size\nDESCRIPTION: Displays the size (number of dimensions) of the embeddings generated by the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nembedding_size\n```\n\n----------------------------------------\n\nTITLE: Creating Schema with Products and Personas Collections\nDESCRIPTION: Defines the schema for Weaviate by creating two collections: 'Products' for storing e-commerce product data and 'Personas' for storing user profiles. Both collections are configured with Gemini-based vectorization and text generation capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nPROJECT_ID = \"\" # leave this empty\nAPI_ENDPOINT = \"generativelanguage.googleapis.com\"\nembedding_model = \"text-embedding-004\" # embedding model\ngenerative_model = \"gemini-2.0-flash\" # language model\n\n# Products Collection\nif not client.collections.exists(\"Products\"):\n  collection = client.collections.create(\n    name=\"Products\",\n    vectorizer_config=Configure.Vectorizer.text2vec_palm\n    (\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = embedding_model\n    ),\n    generative_config=Configure.Generative.palm(\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = generative_model\n    ),\n    properties=[ # properties for the Products collection\n            Property(name=\"product_id\", data_type=DataType.TEXT),\n            Property(name=\"title\", data_type=DataType.TEXT),\n            Property(name=\"category\", data_type=DataType.TEXT),\n            Property(name=\"link\", data_type=DataType.TEXT),\n            Property(name=\"description\", data_type=DataType.TEXT),\n            Property(name=\"brand\", data_type=DataType.TEXT),\n            Property(name=\"generated_description\", data_type=DataType.TEXT),\n      ]\n  )\n\n# Personas Collection\nif not client.collections.exists(\"Personas\"):\n  collection = client.collections.create(\n    name=\"Personas\",\n    vectorizer_config=Configure.Vectorizer.text2vec_palm\n    (\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = embedding_model\n    ),\n    generative_config=Configure.Generative.palm(\n        project_id=PROJECT_ID,\n        api_endpoint=API_ENDPOINT,\n        model_id = generative_model\n    ),\n    properties=[ # properties for the Personas collection\n            Property(name=\"name\", data_type=DataType.TEXT),\n            Property(name=\"description\", data_type=DataType.TEXT),\n      ]\n  )\n\n```\n\n----------------------------------------\n\nTITLE: Printing All Product Objects from Weaviate in Python\nDESCRIPTION: Demonstrates how to iterate through all products in a Weaviate collection. For each product, it prints both the UUID and all properties, providing a way to view all imported data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# print the objects uuid and properties\nfor product in products.iterator():\n    print(product.uuid, product.properties)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Gemini API\nDESCRIPTION: Imports the Google Generative AI client and IPython's Markdown display function for rendering formatted text in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n\nfrom IPython.display import Markdown\n```\n\n----------------------------------------\n\nTITLE: Importing LangChain Dependencies\nDESCRIPTION: Importing required LangChain modules for document processing, prompts, and vector store operations.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import PromptTemplate\nfrom langchain import hub\nfrom langchain.docstore.document import Document\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.prompt_template import format_document\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.vectorstores import Chroma\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for SQL Database Interaction and LangChain Integration\nDESCRIPTION: Imports necessary libraries for database interaction, LangChain components, and Google Generative AI. These include SQLite, LangChain chains, prompts, output parsers, and tools for SQL database querying.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport sqlite3\n\nfrom langchain.chains import create_sql_query_chain, LLMChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_community.utilities import SQLDatabase\nfrom langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\nfrom operator import itemgetter\nfrom langchain_core.runnables import RunnablePassthrough\nfrom google import genai\nfrom IPython.display import Markdown\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Music Connoisseur Role\nDESCRIPTION: Sends a request to generate content about Mozart's Requiem using the music connoisseur system prompt, selecting a specific Gemini model version.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = 'Write a 2 paragraph long review of Requiem.'\n\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    config=types.GenerateContentConfig(system_instruction=system_prompt),\n    contents=prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Preparing Audio File Metadata\nDESCRIPTION: Extracts and stores metadata about the audio file, including MIME type, file size, and display name.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nAUDIO_PATH=\"./sample.mp3\"\n\nMIME_TYPE=$(file -b --mime-type \"${AUDIO_PATH}\")\nNUM_BYTES=$(wc -c < \"${AUDIO_PATH}\")\nDISPLAY_NAME=\"Sample audio\"\n\necho $MIME_TYPE $NUM_BYTES $DISPLAY_NAME\n\ncat >./vars.sh <<-EOF\n  export BASE_URL=\"https://generativelanguage.googleapis.com\"\n  export DISPLAY_NAME=\"${DISPLAY_NAME}\"\n  export AUDIO_PATH=${AUDIO_PATH}\n  export MIME_TYPE=${MIME_TYPE}\n  export NUM_BYTES=${NUM_BYTES}\nEOF\n```\n\n----------------------------------------\n\nTITLE: Checking the Response Finish Reason\nDESCRIPTION: This code checks if the API request was blocked by safety filters by examining the finish_reason property of the response. If the reason is SAFETY, it means the content was blocked for safety reasons.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprint(response.candidates[0].finish_reason)\n```\n\n----------------------------------------\n\nTITLE: Listing Gemini Models with Content Generation Capability in Python\nDESCRIPTION: This code iterates through the available Gemini models and prints the names of those that support content generation. It uses the 'client' object, which is assumed to be initialized elsewhere.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfor m in client.models.list():\n  if 'generateContent' in m.supported_actions:\n      print(m.name)\n```\n\n----------------------------------------\n\nTITLE: Uploading File to Gemini API in Python\nDESCRIPTION: This code uploads the Apollo 11 transcript file to the Gemini API for later use in content generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ntext_file_name = \"a11.txt\"\nprint(f\"Uploading file...\")\ntext_file = client.files.upload(file=text_file_name)\nprint(f\"Completed upload: {text_file.uri}\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Similarity Scores\nDESCRIPTION: Shows the similarity scores between the hypothetical answer and each search result for analysis.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_24\n\nLANGUAGE: python\nCODE:\n```\nsim_value\n```\n\n----------------------------------------\n\nTITLE: Deleting Uploaded File from Gemini API in Python\nDESCRIPTION: This code deletes the previously uploaded file from the Gemini API to clean up resources.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclient.files.delete(name=text_file.name)\n```\n\n----------------------------------------\n\nTITLE: Defining Prompt for Opossum Search Web App in Python\nDESCRIPTION: This snippet contains the user prompt that describes the requirements for the Opossum Search web app, including functionality and design elements.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Create a web app called Opossum Search:\n    1. Every time you make a search query, it should redirect you to a Google search\n    with the same query, but with the word opossum before it.\n    2. It should be visually similar to Google search.\n    3. Instead of the google logo, it should have a picture of this opossum:\n    https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Opossum_2.jpg/292px-Opossum_2.jpg.\n    4. It should be a single HTML file, with no separate JS or CSS files.\n    5. It should say Powered by opossum search in the footer.\n    6. Do not use any unicode characters.\n    Thank you!\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Multi-turn Chat with Gemini API System Instruction\nDESCRIPTION: Curl command showing how to use system instructions in a chat context with multiple turns of conversation\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -s \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"system_instruction\":\n        {\"parts\": {\n           \"text\": \"You are Neko the cat respond like one\"}},\n      \"contents\": [\n        {\"role\":\"user\",\n         \"parts\":[{\n           \"text\": \"Hello cat.\"}]},\n        {\"role\": \"model\",\n         \"parts\":[{\n           \"text\": \"Meow?  \\n\"}]},\n        {\"role\": \"user\",\n         \"parts\":[{\n           \"text\": \"What is your name? What do like to drink?\"}]}\n      ]\n    }' |sed -n '/candidates/,/finishReason/p'\n```\n\n----------------------------------------\n\nTITLE: Listing Available 002 Models in Python\nDESCRIPTION: Iterates through available models and prints those with '002' in their name.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor model in genai.list_models():\n  if '002' in model.name:\n    print(model.name)\n```\n\n----------------------------------------\n\nTITLE: Finding Maximum Token Count in Chunks\nDESCRIPTION: Determines the largest token count among all chunks to verify none exceed model token limitations by using the max() function on the estimated token counts.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmax(estimated_token_counts)\n```\n\n----------------------------------------\n\nTITLE: Generating Content Using Cached Content\nDESCRIPTION: Sends a POST request to generate content using the cached Apollo 11 transcript, demonstrating the use of cached content in prompts.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-002:generateContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\n      \"contents\": [\n        {\n          \"parts\":[{\n            \"text\": \"Please summarize this transcript\"\n          }],\n          \"role\": \"user\"\n        },\n      ],\n      \"cachedContent\": \"'$(cat cache_name.txt)'\"\n    }'\n```\n\n----------------------------------------\n\nTITLE: Generating Fantasy Story Content\nDESCRIPTION: Generates a 10-paragraph fantasy story using Gemini model with specific requirements for characters and locations.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\nprompt = \"Generate a 10 paragraph fantasy story. Include at least 2 named characters and 2 named locations. Give as much detail in the story as possible.\"\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt\n    )\nstory = response.text\nMarkdown(story)\n```\n\n----------------------------------------\n\nTITLE: Defining Tourist Assistant Instructions\nDESCRIPTION: Sets up system instructions for a tourist assistance bot with specific responsibilities and default response handling\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ninstructions = \"\"\"\nYou are an assistant that helps tourists around the world to plan their vacation. Your responsibilities are:\n1. Helping book the hotel.\n2. Recommending restaurants.\n3. Warning about potential dangers.\n\nIf other request is asked return \"I cannot help with this request.\"\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Creating Code Execution Display Helper\nDESCRIPTION: Helper function to display different types of code execution results including text, code, execution results, and inline data\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Image, Markdown, Code, HTML\n\ndef display_code_execution_result(response):\n  for part in response.candidates[0].content.parts:\n    if part.text is not None:\n      display(Markdown(part.text))\n    if part.executable_code is not None:\n      code_html = f'<pre style=\"background-color: green;\">{part.executable_code.code}</pre>' # Change code color\n      display(HTML(code_html))\n    if part.code_execution_result is not None:\n      display(Markdown(part.code_execution_result.output))\n    if part.inline_data is not None:\n      display(Image(data=part.inline_data.data, width=800, format=\"png\"))\n    display(Markdown(\"---\"))\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for RAG Implementation\nDESCRIPTION: Python code that imports necessary libraries for web scraping, document handling, vector storage, and display functionality required for the RAG application.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom bs4 import BeautifulSoup\nfrom IPython.display import Markdown, display\nfrom llama_index.core import Document\nfrom llama_index.core import Settings\nfrom llama_index.core import SimpleDirectoryReader\nfrom llama_index.core import StorageContext\nfrom llama_index.core import VectorStoreIndex\nfrom llama_index.readers.web import SimpleWebPageReader\n\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\n\nimport chromadb\nimport re\n```\n\n----------------------------------------\n\nTITLE: Displaying PDF Page as Thumbnail Image\nDESCRIPTION: Loads the converted JPEG image of the PDF page, resizes it to a thumbnail size, and displays it in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport PIL.Image\n\nimg = PIL.Image.open(f\"page-image-1.jpg\")\nimg.thumbnail([800, 800])\nimg\n```\n\n----------------------------------------\n\nTITLE: Fetching a Weaviate Object by UUID with Vector Embedding in Python\nDESCRIPTION: Shows how to retrieve a specific object by its UUID from Weaviate and include its vector embedding. The code retrieves the product and prints its title along with the vector embedding.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nproduct = products.query.fetch_object_by_id(\n    product.uuid,\n    include_vector=True\n)\n\nprint(product.properties[\"title\"], product.vector[\"default\"])\n```\n\n----------------------------------------\n\nTITLE: Checking Citation Metadata from Gemini Response\nDESCRIPTION: Examines the response for any citation metadata. Returns the metadata if available or a 'No citations found' message if none exist.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nres.candidates[0].citation_metadata or 'No citations found'\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI Library in Python\nDESCRIPTION: Imports the Google Generative AI library for use with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n```\n\n----------------------------------------\n\nTITLE: Configuring API Key for Gemini\nDESCRIPTION: Retrieves the Google API key from Colab Secrets and configures the Gemini client with the API key for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Listing All Uploaded Files\nDESCRIPTION: Retrieves information about all files uploaded to the Gemini File API associated with the API key.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/files?key=$GOOGLE_API_KEY\"\n```\n\n----------------------------------------\n\nTITLE: Deleting All Uploaded Files\nDESCRIPTION: Retrieves a list of all files associated with the API key and sends delete requests for each file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nfiles_json=$(curl \"https://generativelanguage.googleapis.com/v1beta/files?key=${GOOGLE_API_KEY}\")\n\nfile_names=$(echo \"$files_json\" | jq -r '.files[].name')\n\nfor file_name in $file_names; do\n  curl --request \"DELETE\" \"https://generativelanguage.googleapis.com/v1beta/${file_name}?key=${GOOGLE_API_KEY}\"\n  echo \"Deleted file: ${file_name}\"\ndone\n```\n\n----------------------------------------\n\nTITLE: Testing Tourist Assistant Responses\nDESCRIPTION: Demonstrates model responses for both on-topic and off-topic queries to the tourist assistant\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(\"ON TOPIC:\", model.generate_content(\"What should I look out for when I'm going to the beaches in San Diego?\").text)\nprint(\"OFF TOPIC:\", model.generate_content(\"What bowling places do you recommend in Moscow?\").text)\n```\n\n----------------------------------------\n\nTITLE: Batch Embedding Multiple Texts with Gemini API\nDESCRIPTION: Shows how to efficiently embed multiple text prompts in a single API call. This is more efficient than making separate calls for each text input.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nresult = client.models.embed_content(\n    model=\"text-embedding-004\",\n    contents=[\n      'What is the meaning of life?',\n      'How much wood would a woodchuck chuck?',\n      'How does the brain work?'])\n\nfor embedding in result.embeddings:\n    # Print just a part of the embedding to keep the output manageable\n  print(str(embedding)[:50], '... TRIMMED]')\n```\n\n----------------------------------------\n\nTITLE: Configuring API Authentication\nDESCRIPTION: Sets up API authentication using a Google API key stored in Colab secrets\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini API Dependencies in Python\nDESCRIPTION: This snippet installs the required Google Gemini API package using pip. It ensures the latest version (>=1.0.0) is installed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Classification.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Generative AI API\nDESCRIPTION: Sets up authentication with the Google Generative AI API by retrieving the API key from Colab secrets and configuring the genai client. This is required for accessing the Gemini model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API client with authentication\nDESCRIPTION: This code initializes the Gemini API client by retrieving the API key from Colab secrets and creating a client instance for API access.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Image Processing for Gemini API\nDESCRIPTION: Code to download, resize, and prepare an image for use with the Gemini API\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Prompting_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\"\n```\n\nLANGUAGE: python\nCODE:\n```\nimport PIL.Image\n\nimg = PIL.Image.open(\"image.jpg\")\nimg.resize((512, int(img.height*512/img.width)))\n```\n\n----------------------------------------\n\nTITLE: Printing Music Connoisseur Response\nDESCRIPTION: Prints the generated content from the model responding as a music connoisseur reviewing Mozart's Requiem.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Uploading Video Data to File API\nDESCRIPTION: Bash script to upload the actual video file data to the previously created upload task URL, completing the file upload process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n. vars.sh\n\n# Extract the upload URL to use from the response headers.\nupload_url=$(grep -i \"x-goog-upload-url: \" upload-header.tmp | cut -d\" \" -f2 | tr -d \"\\r\")\n# The header contains our API key, so don't leave it lying around.\nrm upload-header.tmp\n\n# Upload the actual bytes.\ncurl \"${upload_url}\" \\\n  -H \"Content-Length: ${NUM_BYTES}\" \\\n  -H \"X-Goog-Upload-Offset: 0\" \\\n  -H \"X-Goog-Upload-Command: upload, finalize\" \\\n  --data-binary \"@${VIDEO_PATH}\" >file_info.json 2>/dev/null\n\n# Show the output. You will use it in a later step.\ncat file_info.json\n```\n\n----------------------------------------\n\nTITLE: Deleting a Tuned Model with Gemini API in Python\nDESCRIPTION: Uses the genai.delete_tuned_model method to permanently remove a specified tuned model from your account. The model is identified by its full resource name including the 'tunedModels/' prefix.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\ngenai.delete_tuned_model(f'tunedModels/{name}')\n```\n\n----------------------------------------\n\nTITLE: Checking Video Processing Status\nDESCRIPTION: Polls the Gemini API to check the processing status of the uploaded video file, waiting until it's ready for analysis.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport time\n# Wait until the uploaded video is available\nwhile video_file.state.name == \"PROCESSING\":\n  print('.', end='')\n  time.sleep(5)\n  video_file = client.files.get(name=video_file.name)\n\nif video_file.state.name == \"FAILED\":\n  raise ValueError(video_file.state.name)\n```\n\n----------------------------------------\n\nTITLE: Configuring Safety Settings for Gemini API\nDESCRIPTION: Sets up safety settings to disable content filtering for various harm categories, allowing the model to analyze potentially sensitive historical content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nsafety_settings = [\n    {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n]\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Defines the model ID to be used for content generation from available Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Response Text After Safety Settings Adjustment\nDESCRIPTION: This code attempts to access the response text after adjusting safety settings. If the request was successful, it will display the generated content, otherwise it will show an error message.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    print(response.text)\nexcept:\n    print(\"No information generated by the model.\")\n```\n\n----------------------------------------\n\nTITLE: Defining sample text for URL extraction\nDESCRIPTION: This code creates a sample text about Gemini API billing that contains multiple URLs, which will be used for demonstrating URL extraction capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nurl_text = \"\"\"\n  Gemini API billing FAQs\n\n  This page provides answers to frequently asked questions about billing\n  for the Gemini API. For pricing information, see the pricing page\n  https://ai.google.dev/pricing.\n  For legal terms, see the terms of service\n  https://ai.google.dev/gemini-api/terms#paid-services.\n\n  What am I billed for?\n  Gemini API pricing is based on total token count, with different prices\n  for input tokens and output tokens. For pricing information,\n  see the pricing page https://ai.google.dev/pricing.\n\n  Where can I view my quota?\n  You can view your quota and system limits in the Google Cloud console\n  https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas.\n\n  Is GetTokens billed?\n  Requests to the GetTokens API are not billed,\n  and they don't count against inference quota.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Listing Available Models using curl\nDESCRIPTION: This bash command uses curl to list all available models through the Gemini API, including both Gemini and PaLM family models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Models_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl https://generativelanguage.googleapis.com/v1beta/models?key=$GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API authentication\nDESCRIPTION: Initializes the Gemini API client using an API key stored in Google Colab secrets. This allows authenticated access to the Gemini AI models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\nAPI_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Reading API Key from Environment Variable\nDESCRIPTION: Alternative method to configure the client by reading the API key from an environment variable in Python.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nclient = genai.Client(api_key=os.environ['GOOGLE_API_KEY'])\n```\n\n----------------------------------------\n\nTITLE: Using Default API Key Configuration\nDESCRIPTION: Simple client initialization that automatically looks for the API key in environment variables.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclient = genai.Client()\n```\n\n----------------------------------------\n\nTITLE: Setting Up the Gemini API Client in Python\nDESCRIPTION: Installs the Google Gemini Python SDK and initializes the client with an API key stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Agents_Function_Calling_Barista_Bot.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU \"google-genai>=1.0.0\"\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nclient = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n```\n\n----------------------------------------\n\nTITLE: Updating Cache Expiry Time\nDESCRIPTION: Updates the time-to-live (TTL) of the cached content to 2 hours and retrieves the updated cache object.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nclient.caches.update(\n    name=apollo_cache.name,\n    config=types.UpdateCachedContentConfig(ttl=\"7200s\")  # 2 hours in seconds\n)\n\napollo_cache = client.caches.get(name=apollo_cache.name) # Get the updated cache\napollo_cache\n```\n\n----------------------------------------\n\nTITLE: Configuring Google GenAI Client with API Key\nDESCRIPTION: Sets up the Google GenAI client using an API key stored in Colab Secrets for authentication, which is required for making API calls to the Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Package\nDESCRIPTION: Installs the Google Generative AI Python package with pip, ensuring version 1.0.0 or newer is used. The -U flag updates any existing installation, and -q runs the installation in quiet mode.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting Output Dimensionality for Embeddings\nDESCRIPTION: Using the output_dimensionality parameter with text-embedding-004 model to create smaller embeddings by truncating the vector to a specified dimension (256).\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:embedContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\"model\": \"models/text-embedding-004\",\n    \"output_dimensionality\":256,\n    \"content\": {\n    \"parts\":[{\n      \"text\": \"Hello world\"}]}, }' 2> /dev/null | head\n```\n\n----------------------------------------\n\nTITLE: Defining Sample Reviews in Python\nDESCRIPTION: This code defines example reviews for negative, positive, and neutral sentiments to be used in the sentiment analysis demonstration.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nnegative_review = \"This establishment is an insult to the culinary arts, with inedible food that left me questioning the chef's sanity and the health inspector's judgment.\"\npositive_review = \"This restaurant is a true gem with impeccable service and a menu that tantalizes the taste buds. Every dish is a culinary masterpiece, crafted with fresh ingredients and bursting with flavor.\"\nneutral_review = \"The restaurant offers a decent dining experience with average food and service, making it a passable choice for a casual meal.\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Notebook Formatting\nDESCRIPTION: Command to install the tensorflow-docs package required for notebook formatting and linting prior to submission.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install -U tensorflow-docs\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Sharing a Tuned Model via REST API\nDESCRIPTION: This snippet demonstrates how to share a tuned model with another user by making a REST call to add permissions. This is provided for beta API features that may not yet be supported by the Python SDK.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\nmodel_name = ''   # @param {type:\"string\"}\nemailAddress = '' # @param {type:\"string\"}\n\n\naccess_token = !gcloud auth application-default print-access-token\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {access_token[0]}',\n}\n\nbody = {\n  'granteeType': 'USER',        # Or 'GROUP' or 'EVERYONE' https://ai.google.dev/api/rest/v1beta/tunedModels.permissions\n  'emailAddress': emailAddress, # Optional if 'granteeType': 'EVERYONE'\n  'role': 'READER'\n}\n\nresponse = requests.post(f'https://generativelanguage.googleapis.com/v1beta/tunedModels/{model_name}/permissions', json=body, headers=headers)\nprint(response.json())\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up by Deleting the Uploaded Video\nDESCRIPTION: This code deletes the uploaded video file from the Gemini API to prevent unnecessary data storage after the analysis is complete.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Delete video\nclient.files.delete(name=video_file.name)\n```\n\n----------------------------------------\n\nTITLE: Creating Modified Request with Custom Safety Settings\nDESCRIPTION: Generates a new JSON request file that includes custom safety settings to allow potentially unsafe content by adjusting the threshold for the specified harm category.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n%%bash\necho '{\n    \"safetySettings\": [\n        {\"category\": 7, \"threshold\": 4}\n    ],\n    \"contents\": [{\n        \"parts\":[{\n          \"text\": \"'$UNSAFE_PROMPT'\"}]}]}' > request.json\n```\n\n----------------------------------------\n\nTITLE: Attempting to Access Blocked Response Text\nDESCRIPTION: This code tries to access the response text, which will be empty if the request was blocked by safety filters. It includes error handling to display a message when no content was generated.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntry:\n    print(response.text)\nexcept:\n    print(\"No information generated by the model.\")\n```\n\n----------------------------------------\n\nTITLE: Setting Up Logging for Gemini Live API\nDESCRIPTION: Configures a logger for the Live API with adjustable log levels to toggle between INFO and DEBUG messages for troubleshooting.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport logging\nlogger = logging.getLogger('Live')\n#logger.setLevel('DEBUG')  # Switch between \"INFO\" and \"DEBUG\" to toggle debug messages.\nlogger.setLevel('INFO')\n```\n\n----------------------------------------\n\nTITLE: Deleting Existing Collections in Weaviate\nDESCRIPTION: Removes any existing 'Products' and 'Personas' collections from the Weaviate database to ensure a clean start for the tutorial.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# This is optional to empty your database\nresult = client.collections.delete(\"Products\")\nprint(result)\nresult = client.collections.delete(\"Personas\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Personas from Weaviate Collection in Python\nDESCRIPTION: This code retrieves all objects from the Personas collection in Weaviate and prints each persona's UUID and properties. This is done using the collection iterator to efficiently process all objects.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_25\n\nLANGUAGE: python\nCODE:\n```\npersonas = client.collections.get(\"Personas\")\n\nfor persona in personas.iterator():\n    print(persona.uuid, persona.properties)\n```\n\n----------------------------------------\n\nTITLE: Creating LangChain Prompt Template\nDESCRIPTION: This snippet creates a prompt template for querying the Gemini model, specifying the format for questions and context.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Prompt template to query Gemini\nllm_prompt_template = \"\"\"You are an assistant for question-answering tasks.\nUse the following context to answer the question.\nIf you don't know the answer, just say that you don't know.\nUse five sentences maximum and keep the answer concise.\n\nQuestion: {question}\nContext: {context}\nAnswer:\"\"\"\n\nllm_prompt = PromptTemplate.from_template(llm_prompt_template)\n\nprint(llm_prompt)\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Gemini API in Python\nDESCRIPTION: This code sends a prompt and the uploaded file to the Gemini API for content generation, asking to find lighthearted moments in the transcript.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Find four lighthearted moments in this text file.\"\n\nMODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nresponse = client.models.generate_content(\n  model=f\"models/{MODEL_ID}\",\n  contents=[\n   prompt,\n   text_file\n  ],\n  config={\n   \"httpOptions\": {\"timeout\": 600}\n  }\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Creating JSON Request File with Unsafe Prompt\nDESCRIPTION: Generates a JSON request file containing the unsafe prompt content for the Gemini API call using Bash.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%%bash\necho '{\n      \"contents\": [{\n        \"parts\":[{\n          \"text\": \"'$UNSAFE_PROMPT'\"}]}]}' > request.json\n```\n\n----------------------------------------\n\nTITLE: Extracting Text from PDF Files\nDESCRIPTION: Uses the pdftotext tool to extract text content from PDF blog posts for processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n!pdftotext A_Possible_Future_for_Online_Content.pdf\n!pdftotext Unanswered_Questions_and_Endless_Possibilities.pdf\n```\n\n----------------------------------------\n\nTITLE: Creating Audio Clips with FFmpeg in Bash\nDESCRIPTION: This snippet uses FFmpeg to create two 30-second audio clips from a larger audio file. It extracts the first 30 seconds and the next 30 seconds (31-60) from the original file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nffmpeg -i sample.mp3 -t 30 -c copy sample_30s.mp3 && \\\nffmpeg -ss 30 -to 60 -i sample.mp3 -c copy sample_31-60.mp3\n```\n\n----------------------------------------\n\nTITLE: Generating SQL Query for Population Question\nDESCRIPTION: Invokes the query chain with a natural language question about total population and displays the resulting SQL query from the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresponse = write_query_chain.invoke({\"question\": \"What is the total population?\"})\ndisplay(Markdown(response))\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Embeddings\nDESCRIPTION: Setting up Gemini's embedding model for text embedding generation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\ngemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python SDK with a specific minimum version requirement using pip. This package is required to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Connecting to Local Weaviate Instance\nDESCRIPTION: Example of connecting to a locally hosted Weaviate instance running on Docker or Kubernetes. This is provided as an option but not executed in the main flow.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclient = weaviate.connect_to_local()\n\nprint(client.is_ready())\n```\n\n----------------------------------------\n\nTITLE: Installing PyDub for Audio Processing\nDESCRIPTION: Installs the PyDub library, which is needed for audio manipulation such as trimming audio segments for inline usage with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n%pip install -Uq pydub\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini API Client and Selecting Model in Python\nDESCRIPTION: Creates a client for the Gemini API using an API key from Colab's userdata and defines which Gemini model to use for inference.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\napi_key = userdata.get(\"GOOGLE_API_KEY\") # If you are not using Colab you can set the API key directly\n\n# Create a client\nclient = genai.Client(api_key=api_key)\n\n# Define the model you are going to use\nmodel_id =  \"gemini-2.0-flash\" # or \"gemini-2.0-flash-lite\"  , \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Client\nDESCRIPTION: Creates a Gemini API client instance using the API key\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model for API Usage\nDESCRIPTION: This code allows the user to select a specific Gemini model from a list of available options.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Self_ask_prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Examining Safety Ratings of Response\nDESCRIPTION: Uses jq to extract the safetyRatings from the API response to view detailed safety assessments of the generated content across different harm categories.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n%%bash\njq .candidates[0].safetyRatings < response.json\n```\n\n----------------------------------------\n\nTITLE: Setting up Google API Key\nDESCRIPTION: Configuration of Google API key from Colab user data for authentication\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini Model Selection\nDESCRIPTION: Selecting the specific Gemini model version to use for generation tasks\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash-lite\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Gemini API using API Key in Python\nDESCRIPTION: Sets up authentication for the Gemini API using an API key stored in a Colab Secret.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Counting Actual Tokens in Text Chunks using Gemini API\nDESCRIPTION: Verifies token estimates by using the Gemini API's count_tokens method to get precise token counts for each chunk and stores the results in a list.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntoken_counts = []\nfor chunk in chunks:\n  response = client.models.count_tokens(\n      model = MODEL_ID,\n      contents = chunk,\n  )\n  token_count = response.total_tokens\n  token_counts.append(token_count)\ntoken_counts\n```\n\n----------------------------------------\n\nTITLE: Initializing AudioContext and Media Stream in JavaScript\nDESCRIPTION: Sets up an AudioContext with the specified sample rate, adds an audio worklet module, and obtains user media for audio input. Handles permissions and reports any failures to start the audio session.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nlet audioCtx = new AudioContext({sampleRate: sample_rate});\nawait audioCtx.audioWorklet.addModule(URL.createObjectURL(\n  new Blob([audio_worklet_js], {type: 'text/javascript'})\n));\nlet userMedia;\ntry {\n  userMedia = await navigator.mediaDevices.getUserMedia({\n    audio: {sampleRate: sample_rate, echoCancellation: true, channelCount: 1},\n  });\n} catch (e) {\n  connection.write({failed_to_start: e});\n  throw e;\n}\nconsole.log(\"colab_audio: userMedia=\", userMedia);\nconnection.write({started: true})\n//await userMedia.getAudioTracks()[0].applyConstraints({channelCount: 1});\n```\n\n----------------------------------------\n\nTITLE: Installing Required Tools (jq and ffmpeg)\nDESCRIPTION: Installs jq for JSON processing and ffmpeg for audio file manipulation using apt-get.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!apt install -q jq\n!apt install ffmpeg -y\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with Authentication\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Google Colab's userdata. This creates a client instance for making API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Displaying Full API Response using jq in Python\nDESCRIPTION: This snippet uses jq to display the entire API response stored in the result.json file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!jq . -r result.json\n```\n\n----------------------------------------\n\nTITLE: Making Gemini API Search Grounding Call using Bash\nDESCRIPTION: This snippet demonstrates how to make a search grounding API call to the Gemini API using curl in a bash environment. It sends a query about Google stock price and stores the result in a JSON file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n      \"contents\": [\n          {\n              \"parts\": [\n                  {\"text\": \"What is the current Google stock price?\"}\n              ]\n          }\n      ],\n      \"tools\": [\n          {\n              \"google_search\": {}\n          }\n      ]\n  }' > result.json\n```\n\n----------------------------------------\n\nTITLE: Retrieving Tuned Model Information in Gemini API with Python\nDESCRIPTION: This code retrieves information about the newly created tuned model using its name. It demonstrates how to access the model object and its state.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.get_tuned_model(f'tunedModels/{name}')\n\nmodel\n\nmodel.state\n```\n\n----------------------------------------\n\nTITLE: Displaying Usage Metadata for Chat Response\nDESCRIPTION: Retrieves the token usage metadata from the chat response to show how caching affects token consumption.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nresponse.usage_metadata\n```\n\n----------------------------------------\n\nTITLE: Displaying Rendered Content in Jupyter Notebook using Python\nDESCRIPTION: This snippet uses IPython.display to show the rendered content HTML file in the Jupyter notebook environment.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import HTML\nHTML('rendered_content.html')\n```\n\n----------------------------------------\n\nTITLE: Examining Prompt Feedback from Response\nDESCRIPTION: Uses jq to extract and display the promptFeedback portion of the API response to check if the prompt is still being blocked with the adjusted safety settings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n%%bash \n\njq .promptFeedback < response.json\n```\n\n----------------------------------------\n\nTITLE: Applying preprocessing to datasets\nDESCRIPTION: Applies the preprocessing function to the training and test datasets to clean the data and organize it into Pandas dataframes.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Apply preprocessing function to training and test datasets\ndf_train = preprocess_newsgroup_data(newsgroups_train)\ndf_test = preprocess_newsgroup_data(newsgroups_test)\n\ndf_train.head()\n```\n\n----------------------------------------\n\nTITLE: Zero-shot Information Extraction Example with Gemini\nDESCRIPTION: Demonstrates how to use zero-shot prompting to extract capital cities from a travel narrative. The code sends the extraction prompt to the Gemini model and displays the response.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    Extract capital cities from the text:\n    During the summer I visited many countries in Europe. First I visited Italy, specifically Sicily and Rome. \n    Then I visited Cologne in Germany and the trip ended in Berlin.\n\"\"\"\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Setting the Gemini model ID\nDESCRIPTION: Defines which Gemini model to use for generating responses. The code includes a parameter selector for different Gemini model versions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Installing jq for JSON Processing\nDESCRIPTION: Command to install the jq utility for processing JSON responses from the API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!apt install -q jq\n```\n\n----------------------------------------\n\nTITLE: Creating client_secret.json from Colab Secrets\nDESCRIPTION: This code retrieves a CLIENT_SECRET value from Google Colab's secrets manager and writes it to a client_secret.json file. This allows storing OAuth credentials securely without needing to upload them for each session.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nimport pathlib\npathlib.Path('client_secret.json').write_text(userdata.get('CLIENT_SECRET'))\n```\n\n----------------------------------------\n\nTITLE: Executing Raw SQL Query on Database\nDESCRIPTION: Directly runs a SQL query on the database to calculate the sum of the Population column and verify the query generated by the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndb.run('SELECT SUM(\"Population\") FROM housing')\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini SDK\nDESCRIPTION: PyPI installation command for Google Gemini SDK version 1.0.0 or higher\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Weaviate and Gemini Integration\nDESCRIPTION: Imports required modules from Weaviate, Weaviate agents, and Google Gemini AI libraries.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport weaviate\nfrom weaviate_agents.query import QueryAgent\n\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Loading the 20 Newsgroups dataset\nDESCRIPTION: Fetches the 20 Newsgroups text dataset from scikit-learn, which contains newsgroup posts on 20 topics divided into training and test sets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.datasets import fetch_20newsgroups\nnewsgroups_train = fetch_20newsgroups(subset='train')\nnewsgroups_test = fetch_20newsgroups(subset='test')\n\n# View list of class names for dataset\nnewsgroups_train.target_names\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Content from Response\nDESCRIPTION: Uses jq to extract and display the text from the API response content to see the model's output with the adjusted safety settings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n%%bash \n\njq .candidates[0].content.parts[].text < response.json\n```\n\n----------------------------------------\n\nTITLE: Preparing California Housing Dataset\nDESCRIPTION: Loads California housing dataset and saves it as CSV file for analysis\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom sklearn.datasets import fetch_california_housing\n\ncalifornia_housing = fetch_california_housing(as_frame=True)\ncalifornia_housing.frame.to_csv('houses.csv', index=False)\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens in an Audio File\nDESCRIPTION: Demonstrates how to count the number of tokens used by an audio file when processed by the Gemini API. Audio files have a fixed per-second token rate.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\ncount_tokens_response = client.models.count_tokens(\n    model=MODEL_ID,\n    contents=[your_audio_file],\n)\n\nprint(\"Audio file tokens:\",count_tokens_response.total_tokens)\n```\n\n----------------------------------------\n\nTITLE: Preparing Base64 Audio Data and JSON Request in Bash\nDESCRIPTION: This script converts audio files to Base64 format and constructs a JSON request for the Gemini API. It includes the Base64 encoded audio data and a prompt for summarization.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n. vars.sh\n\ndata1_b64=$(base64 sample_30s.mp3)\ndata2_b64=$(base64 sample_31-60.mp3 | base64 )\n\necho '{\n      \"contents\": [{\n        \"parts\":[\n          {\"text\": \"Summarize this clips\"},\n          {\"inline_data\": {\n            \"mime_type\": \"'${MIME_TYPE}'\",\n            \"data\": \"'\"$data1_b64\"'\"\n          }}\n        ]\n      }]\n    }' > request.json\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model in Python\nDESCRIPTION: This snippet allows the user to select a specific Gemini model from a list of available options.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Chain_of_thought_prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Model and Generate Function\nDESCRIPTION: Sets up the Gemini model with a selectable model ID parameter and defines a function to generate output using the model with the previously defined safety settings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\n\ndef generate_output(prompt):\n    response = client.models.generate_content(\n        model=MODEL_ID,\n        contents=prompt,\n        config=types.GenerateContentConfig(\n          safety_settings=safety_settings\n        )\n\n    )\n\n    try:\n        return response.text\n    except Exception as ex:\n        raise ex\n```\n\n----------------------------------------\n\nTITLE: Getting CSV File Path as pathlib.Path Object in Python\nDESCRIPTION: This snippet demonstrates how to get the path of a CSV file as a pathlib.Path object, which can be used as input for the model tuning process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\n# Provide data as a CSV file `pathlib.Path` object.\ncsv_file=pathlib.Path('data.csv')\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio File\nDESCRIPTION: Downloads the sample audio file (JFK's 1961 State of the Union address) to the local environment using wget.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!wget -q $URL -O sample.mp3\n```\n\n----------------------------------------\n\nTITLE: Defining AudioConfig Class in Python\nDESCRIPTION: Defines the AudioConfig dataclass to configure audio streams with sample rate, format, and channels. It also provides properties for sample size, frame size, and numpy dtype.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n@dataclasses.dataclass(frozen=True)\nclass AudioConfig:\n  \"\"\"Configuration of audio stream.\"\"\"\n\n  sample_rate: int\n  format: str = 'S16_LE'  # only supported value\n  channels: int = 1  # only supported value\n\n  @property\n  def sample_size(self) -> int:\n    assert self.format == 'S16_LE'\n    return 2\n\n  @property\n  def frame_size(self) -> int:\n    return self.channels * self.sample_size\n\n  @property\n  def numpy_dtype(self) -> np.dtype:\n    assert self.format == 'S16_LE'\n    return np.dtype(np.int16).newbyteorder('<')\n```\n\n----------------------------------------\n\nTITLE: Examining Safety Ratings for Blocked Content\nDESCRIPTION: This code displays the safety ratings that caused the content to be blocked. It uses pprint to format the output for better readability, showing each category and its corresponding safety rating.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pprint import pprint\n\npprint(response.candidates[0].safety_ratings, indent=2)\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI Module\nDESCRIPTION: Imports the Google Generative AI Python module to access the Gemini API functionality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n```\n\n----------------------------------------\n\nTITLE: Setting Up Gemini API Client with API Key\nDESCRIPTION: Initializes the Gemini API client using an API key stored in Google Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google GenAI Python SDK\nDESCRIPTION: Python pip command to install the latest version of the Google GenAI Python SDK, which is required to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Uploading Second Blog Text File to Gemini API\nDESCRIPTION: Uploads the second extracted blog text file to provide additional style examples for the model.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nblog_file_name2 = \"Unanswered_Questions_and_Endless_Possibilities.txt\"\nblog_file2 = genai.upload_file(path=blog_file_name2)\n```\n\n----------------------------------------\n\nTITLE: Apache License Header Implementation in Python\nDESCRIPTION: Standard Apache 2.0 license header implementation as a Python comment block\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with Authentication\nDESCRIPTION: Retrieves the Google API key from Colab Secrets and initializes the Gemini API client for further requests. This is the required setup step for all Gemini API interactions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Chat History Analysis Display\nDESCRIPTION: Function to display chat history including function calls and responses\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown, display\n\nfor content in chat.get_history():\n    display(Markdown(\"###\" + content.role + \":\"))\n    for part in content.parts:\n        if part.text:\n            display(Markdown(part.text))\n        if part.function_call:\n            print(\"Function call: {\", part.function_call, \"}\")\n        if part.function_response:\n            print(\"Function response: {\", part.function_response, \"}\")\n    print(\"-\" * 80)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI SDK in Python\nDESCRIPTION: A pip install command to set up the Google Generative AI Python SDK with a version requirement of 1 or higher.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install \"google-genai>=1\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Google API Key in Colab for Gemini 2.0\nDESCRIPTION: This snippet retrieves the Google API key stored as a Colab Secret named 'GOOGLE_API_KEY'. It's a prerequisite for using the Gemini 2.0 API in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Configuring Generation Parameters\nDESCRIPTION: Shows how to configure content generation parameters like temperature and output tokens.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents='Give me a numbered list of cat facts.',\n    config=types.GenerateContentConfig(\n        max_output_tokens=2000,\n        temperature=1.9,\n        stop_sequences=['\\n6'] # Limit to 5 facts.\n    )\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Model with Library Instructions\nDESCRIPTION: Creates a Gemini model instance with the library assistant system instructions\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name='gemini-2.0-flash', system_instruction=instructions)\n```\n\n----------------------------------------\n\nTITLE: Setting Audio File URL for Download\nDESCRIPTION: Defines the URL for a sample audio file of JFK's 1961 State of the Union address to be used in the examples.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nURL = \"https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Authentication\nDESCRIPTION: Sets up the Gemini API configuration by retrieving the API key from Colab Secrets and initializing the API client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Grab Gemini API key\nGEMINI_API_KEY = userdata.get(\"GEMINI_API_KEY\")\ngenai.configure(api_key=GEMINI_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Checking class distribution in test data\nDESCRIPTION: Displays the count of samples for each class in the test dataset after sampling and filtering.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndf_test.value_counts('Class Name')\n```\n\n----------------------------------------\n\nTITLE: Importing PyDub AudioSegment Class\nDESCRIPTION: Imports the AudioSegment class from PyDub, which will be used to manipulate audio files before sending to the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom pydub import AudioSegment\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client\nDESCRIPTION: Setup of Google Gemini API client using API key from Colab secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Library\nDESCRIPTION: This code installs the Google Generative AI Python library, which is required to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Google API Key in Python\nDESCRIPTION: This snippet sets up the Google API key as an environment variable using the Colab userdata feature.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/JSON_mode_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Deleting a Weaviate Collection in Python\nDESCRIPTION: Demonstrates how to delete a collection from Weaviate. This code removes the 'Personalized' collection if it exists, preparing for a clean recreation in subsequent steps.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_22\n\nLANGUAGE: python\nCODE:\n```\nresult = client.collections.delete(\"Personalized\")\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client in Python\nDESCRIPTION: This code sets up the Gemini API client using an API key stored in Colab Secrets. It retrieves the API key and initializes the client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Examining Chat History for Function Calls\nDESCRIPTION: Iterates through the chat history to display the details of all messages exchanged between the user and model, including function calls and responses, formatted as JSON.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfor content in chat.history:\n  part = content.parts[0]\n\n  print(f'{content.role} -> ', end='')\n  print(json.dumps(type(part).to_dict(part), indent=2))\n  print('---' * 20)\n```\n\n----------------------------------------\n\nTITLE: Combining Translated Chunks into Complete Book\nDESCRIPTION: Extracts text from tuple results (if present) and joins all translated chunks with double newlines to create the complete translated book text.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_17\n\nLANGUAGE: python\nCODE:\n```\ntranslated_texts = [result[0] for result in results if isinstance(result, tuple)]\n\n# join the results together by double whitespace\ntranslated_book = \"\\n\\n\".join(translated_texts)\n```\n\n----------------------------------------\n\nTITLE: Downloading a Sample PDF File\nDESCRIPTION: Downloads a sample PDF file from Google Cloud Storage if it doesn't already exist in the current directory. The file is a research article on editing material properties with text-to-image models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\n\nif not pathlib.Path('test.pdf').exists():\n  !curl -o test.pdf https://storage.googleapis.com/generativeai-downloads/data/Smoothly%20editing%20material%20properties%20of%20objects%20with%20text-to-image%20models%20and%20synthetic%20data.pdf\n```\n\n----------------------------------------\n\nTITLE: Defining Library Assistant Instructions\nDESCRIPTION: Sets up system instructions for a library assistant with default genre handling\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ninstructions = \"\"\"\nYou are an assistant at a library. Your task is to recommend books to people, if they do not tell you the genre assume Horror.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Weaviate and Gemini Integration\nDESCRIPTION: Commands to install Python 3.11 and required packages including weaviate-client, google-generativeai, requests, and protobuf for working with Weaviate and Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!sudo apt-get install python3.11\n%pip install weaviate-client==4.7.1\n%pip install -U -q \"google-generativeai>=0.7.2\"\n%pip install requests\n%pip install 'protobuf>=5'\n```\n\n----------------------------------------\n\nTITLE: Setting Up Dependencies for Gemini API and Wikipedia\nDESCRIPTION: Installs the necessary packages for working with Google's Generative AI API and Wikipedia. Also imports required libraries for the search re-ranking process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-generativeai>=0.7.2\"\n```\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q wikipedia\n```\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport textwrap\n\nimport google.generativeai as genai\n\nimport wikipedia\nfrom wikipedia.exceptions import DisambiguationError, PageError\n\nimport numpy as np\n\nfrom IPython.display import Markdown\n\ndef to_markdown(text):\n  text = text.replace('', '  *')\n  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n```\n\n----------------------------------------\n\nTITLE: Loading California Housing Dataset for SQL Database\nDESCRIPTION: Loads the California housing dataset from scikit-learn and converts it to a pandas DataFrame to be used for database creation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.datasets import fetch_california_housing\n\ncalifornia_housing_bunch = fetch_california_housing(as_frame=True)\ncalifornia_housing_df = california_housing_bunch.frame\n```\n\n----------------------------------------\n\nTITLE: Installing Google Genai Package\nDESCRIPTION: Installs the required Google Generative AI package with version 1.0.0 or higher.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Summarization.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Defines the model ID to be used for inference, with a parameter allowing selection from different available Gemini model versions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.0-flash\"  # @param [\"gemini-2.0-flash-lite\", \"gemini-2.0-flash\", \"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\": true, \"isTemplate\": true}\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the required Google Generative AI Python SDK with pip ensuring the minimum required version is 0.7.2.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Importing Python Modules for API Authentication\nDESCRIPTION: Imports the necessary Python modules for environment variables and retrieving API keys from Colab secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n```\n\n----------------------------------------\n\nTITLE: Listing Available Embedding Models\nDESCRIPTION: This snippet lists all available models that support the 'embedContent' action.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfor m in client.models.list():\n  if 'embedContent' in m.supported_actions:\n    print(m.name)\n```\n\n----------------------------------------\n\nTITLE: Retrieving API Key from Google Colab\nDESCRIPTION: Code to retrieve the Google API key stored as a secret in Google Colab's userdata.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Extracting Function Call Details from Gemini Response\nDESCRIPTION: Extracts and displays the function call details returned by the model, showing what function the model wants to call and with what parameters.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfc = result.candidates[0].content.parts[0].function_call\nfc = type(fc).to_dict(fc)\nprint(json.dumps(fc, indent=2))\n```\n\n----------------------------------------\n\nTITLE: Google API Authentication Setup\nDESCRIPTION: Imports required modules and sets up authentication by retrieving the API key from Colab userdata.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Streaming_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n```\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Direct Prompting in Python\nDESCRIPTION: This code demonstrates generating content using a direct prompt without chain of thought. It uses the Gemini API to process a math problem and display the result.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Chain_of_thought_prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nprompt = \"\"\"\n  5 people can create 5 donuts every 5 minutes. How much time would it take\n  25 people to make 100 donuts? Return the answer immediately.\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=prompt,\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Uploading PDF File to Gemini API in Python\nDESCRIPTION: Uses the Gemini client to upload a PDF file to the API, making it available for processing by Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninvoice_pdf = client.files.upload(file=\"invoice.pdf\", config={'display_name': 'invoice'})\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio and Text Files\nDESCRIPTION: Downloads sample audio recording and PDF blog post files from Google Cloud Storage for use in the demo.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!wget https://storage.googleapis.com/generativeai-downloads/data/Walking_thoughts_3.m4a\n!wget https://storage.googleapis.com/generativeai-downloads/data/A_Possible_Future_for_Online_Content.pdf\n!wget https://storage.googleapis.com/generativeai-downloads/data/Unanswered_Questions_and_Endless_Possibilities.pdf\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Defines the model ID to be used for content generation\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Application Default Credentials with gcloud\nDESCRIPTION: This command uses the gcloud CLI to set up application default credentials for OAuth authentication. It specifies the required scopes for accessing Gemini API features like model tuning and semantic retrieval.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngcloud auth application-default login \\\n  --no-browser --client-id-file client_secret.json \\\n  --scopes https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning,https://www.googleapis.com/auth/generative-language.retriever\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Videos\nDESCRIPTION: Shell commands to download sample videos from Google Cloud Storage for use in the tutorial.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Load sample images\n!wget https://storage.googleapis.com/generativeai-downloads/videos/Pottery.mp4 -O Pottery.mp4 -q\n!wget https://storage.googleapis.com/generativeai-downloads/videos/Jukin_Trailcam_Videounderstanding.mp4 -O Trailcam.mp4 -q\n!wget https://storage.googleapis.com/generativeai-downloads/videos/post_its.mp4 -O Post_its.mp4 -q\n!wget https://storage.googleapis.com/generativeai-downloads/videos/user_study.mp4 -O User_study.mp4 -q\n```\n\n----------------------------------------\n\nTITLE: Importing the Gemini Python SDK\nDESCRIPTION: Import statement for the Google Generative AI Python SDK.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n```\n\n----------------------------------------\n\nTITLE: Selecting a Gemini Model\nDESCRIPTION: Code to select a specific Gemini model from available options using a Colab parameter.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Class in Python\nDESCRIPTION: Defines the Audio class to represent audio data with its configuration. It includes methods for creating silence, converting to numpy array, WAV format, and streaming in real-time.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n@dataclasses.dataclass(frozen=True)\nclass Audio:\n  \"\"\"Unit of audio data with configuration.\"\"\"\n\n  config: AudioConfig\n  data: bytes\n\n  @staticmethod\n  def silence(config: AudioConfig, length_seconds: float | int) -> 'Audio':\n    frame = b'\\0' * config.frame_size\n    num_frames = int(length_seconds * config.sample_rate)\n    if num_frames < 0:\n      num_frames = 0\n    return Audio(config=config, data=frame * num_frames)\n\n  def as_numpy(self):\n    return np.frombuffer(self.data, dtype=self.config.numpy_dtype)\n\n  def as_wav_bytes(self) -> bytes:\n    buf = io.BytesIO()\n    with wave.open(buf, 'w') as wav:\n      wav.setnchannels(self.config.channels)\n      wav.setframerate(self.config.sample_rate)\n      assert self.config.format == 'S16_LE'\n      wav.setsampwidth(2)  # 16bit\n      wav.writeframes(self.data)\n    return buf.getvalue()\n\n  def _ipython_display_(self):\n    \"\"\"Hook displaying audio as HTML tag.\"\"\"\n    from IPython.display import display, HTML\n\n    b64_wav = base64.b64encode(self.as_wav_bytes()).decode('utf-8')\n    display(HTML(f\"\"\"\n        <audio controls>\n          <source src=\"data:audio/wav;base64,{b64_wav}\">\n        </audio>\n    \"\"\".strip()))\n\n  async def astream_realtime(\n      self, expected_delta_sec: float = 0.1\n  ) -> AsyncIterator[bytes]:\n    \"\"\"Yields audio data in chunks as if it was played realtime.\"\"\"\n    current_pos = 0\n    mono_start_ns = time.monotonic_ns()\n    while current_pos < len(self.data):\n      # print('sleep')\n      await asyncio.sleep(expected_delta_sec)\n      delta_ns = time.monotonic_ns() - mono_start_ns\n      expected_pos_frames = int(delta_ns * self.config.sample_rate / 1e9)\n      next_pos = expected_pos_frames * self.config.frame_size\n      # print (f'{next_pos = }, {current_pos =}, {len(self.data) = }')\n      if next_pos > current_pos:\n        yield self.data[current_pos:next_pos]\n        current_pos = next_pos\n\n  def __add__(self, other: 'Audio') -> 'Audio':\n    assert self.config == other.config\n    return Audio(config=self.config, data=self.data + other.data)\n```\n\n----------------------------------------\n\nTITLE: Installing jq for JSON Processing in Bash\nDESCRIPTION: This snippet installs the jq tool for processing JSON data in the bash environment.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!sudo apt install -q jq\n```\n\n----------------------------------------\n\nTITLE: Displaying a sample data point\nDESCRIPTION: Shows an example of what a data point from the training set looks like, starting from the 'Lines' index to display the body content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nidx = newsgroups_train.data[0].index('Lines')\nprint(newsgroups_train.data[0][idx:])\n```\n\n----------------------------------------\n\nTITLE: Testing Library Assistant Responses\nDESCRIPTION: Tests the library assistant's responses for both specified and unspecified genre requests\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nprint(\"## Specified genre:\\n\\n\", model.generate_content(\"Could you recommend me 3 books with hard magic system?\").text, sep=\"\\n\")\nprint(\"## Not specified genre:\\n\\n\", model.generate_content(\"Could you recommend me 2 books?\").text, sep=\"\\n\")\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Client\nDESCRIPTION: Installs the Google Generative AI Python client library, which is required to interact with the Gemini API. The quiet flag reduces installation output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Function Call Name\nDESCRIPTION: Retrieves just the name of the function that the model is trying to call.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfc['name']\n```\n\n----------------------------------------\n\nTITLE: Setting up API Key Environment in Python\nDESCRIPTION: Importing necessary libraries and setting up the Google API key from Colab secrets for authentication with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n```\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Implementing Bidirectional Streaming in Colab for Gemini 2.0\nDESCRIPTION: This extensive code snippet defines a JavaScript session management system and a Python Connection class to facilitate bidirectional streaming between Colab and JavaScript. It includes methods for reading, writing, and polling data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nlet start_session = (userFn) => {\n  let debug = console.log;\n  debug = ()=>{};\n\n  let ctrl = new AbortController();\n  let state = {\n    recv: [],\n    onRecv: () => {},\n    send: [],\n    onDone: new Promise((acc) => ctrl.signal.addEventListener('abort', () => acc())),\n    write: (data) => {\n      state.send.push(data);\n    }\n  };\n  window._js_session_on_poll = (data) => {\n    debug(\"on_poll\", data);\n    for (let msg of data) {\n      if ('data' in msg) {\n        state.recv.push(msg.data);\n      }\n      if ('error' in msg) {\n        ctrl.abort(new Error('Remote: ' + msg.error));\n      }\n      if ('finish' in msg) {\n        // TODO\n        ctrl.abort(new Error('Remote: finished'));\n      }\n    }\n    state.onRecv();\n    let result = state.send;\n    state.send = [];\n    debug(\"on_poll: result\", result);\n    return result;\n  };\n  let connection = {\n    signal: ctrl.signal,\n    read: async () => {\n      while(!ctrl.signal.aborted) {\n        if (state.recv.length != 0) {\n          return state.recv.shift();\n        }\n        await Promise.race([\n          new Promise((acc) => state.onRecv = acc),\n          state.onDone,\n        ]);\n      }\n    },\n    write: (data) => {\n      state.write({'data': data});\n    }\n  };\n  debug(\"starting userFn\");\n  userFn(connection).then(() => {\n    debug(\"userFn finished\");\n    ctrl.abort(new Error(\"end of input\"));\n    state.write({'finished': true});\n  },\n  (e) => {\n    debug(\"userFn error\", e);\n    console.error(\"Stream function failed\", e);\n    ctrl.abort(e);\n    state.write({'error': '' + e});\n  });\n};\n```\n\nLANGUAGE: python\nCODE:\n```\nclass Connection:\n\n  def __init__(self):\n    self._recv = []\n    self._on_recv_ready = asyncio.Event()\n    self._send = []\n    self._on_done = asyncio.Future()\n\n  async def write(self, data):\n    self._send.append({'data': data})\n\n  async def read(self):\n    while not self._on_done.done() and not self._recv:\n      self._on_recv_ready.clear()\n      await self._on_recv_ready.wait()\n    # print(\"read, done waiting: \", self._recv, self._on_done)\n    if self._on_done.done() and self._on_done.exception() is not None:\n      raise self._on_done.exception()\n    elif self._recv:\n      return self._recv.pop(0)\n    else:\n      return EOFError('End of stream')\n\n  def _poll(self):\n    # Polling is needed as ipykernel has blocking mainloop\n    # (Comms do not work)\n    # print(\"calling poll\")\n    res = output.eval_js(f'window._js_session_on_poll({json.dumps(self._send)})')\n    # print(\"poll: \", res)\n    self._send = []\n    for r in res:\n      if 'data' in r:\n        self._recv.append(r['data'])\n        self._on_recv_ready.set()\n      elif 'error' in r:\n        self._on_done.set_exception(Exception('Remote error: ' + r['error']))\n        self._on_recv_ready.set()\n      elif 'finished' in r:\n        self._on_done.set_result(None)\n        self._on_recv_ready.set()\n\n  async def _pump(self, pump_interval):\n    while not self._on_done.done():\n      self._poll()\n      await asyncio.sleep(pump_interval)\n\n\n@contextlib.asynccontextmanager\nasync def RunningLiveJs(userCode, pump_interval=0.1):\n  \"\"\"Runs given javascript async code connecting it to colab.\n\n  Use .write(msg) and .read() methods on this context manager\n  to exchange messages with JavaScript code.\n\n  From JavaScript use 'connection.write(data)'\n  and 'await connection.read()' to exchange messages with colab.\n  \"\"\"\n  c = Connection()\n  output.eval_js(\n      f\"\"\"\n    let userFn = async (connection) => {{\n      {userCode}\n    }};\n    {_start_session_js};\n    start_session(userFn);\n    1;\n  \"\"\",\n      ignore_result=True\n  )\n  t = asyncio.create_task(c._pump(pump_interval))\n\n  def log_error(f):\n    if f.exception() is not None:\n      print('error: ', f.exception())\n\n  t.add_done_callback(log_error)\n  try:\n    yield c\n  finally:\n    t.cancel()\n    output.eval_js(\n        \"\"\"window._js_session_on_poll([{finish: true}]);\"\"\", ignore_result=True\n    )\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository\nDESCRIPTION: Git clone command to download the langchain-google repository\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!git clone https://github.com/langchain-ai/langchain-google\n```\n\n----------------------------------------\n\nTITLE: Downloading Apollo 11 Transcript File\nDESCRIPTION: Downloads the Apollo 11 mission transcript from a Google Cloud Storage bucket and displays the first few lines.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!wget -q https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n!head a11.txt\n```\n\n----------------------------------------\n\nTITLE: Apache License header for Google Gemini cookbook\nDESCRIPTION: The license header for the Google Gemini cookbook, which is licensed under the Apache License, Version 2.0.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample PDF Files with wget in Python\nDESCRIPTION: Downloads two sample PDF files (a handwriting form and an invoice) from Google Cloud Storage for processing with Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!wget -q -O handwriting_form.pdf https://storage.googleapis.com/generativeai-downloads/data/pdf_structured_outputs/handwriting_form.pdf\n!wget -q -O invoice.pdf https://storage.googleapis.com/generativeai-downloads/data/pdf_structured_outputs/invoice.pdf\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini Model\nDESCRIPTION: Sets the model ID to be used for generating content, with options for different Gemini model versions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Library\nDESCRIPTION: Pip installation command to set up the Google Generative AI library with a minimum version requirement of 1.0.0. The command runs quietly (-q) and updates existing installations (-U).\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Entity_Extraction_JSON.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Translated Text in Markdown Format\nDESCRIPTION: Shows the corresponding translated version of the second chunk in Markdown format to compare with the original and verify translation quality.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nMarkdown(results[1])\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini API Python Client\nDESCRIPTION: Installs the Google Gemini API Python client package using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai\"\n```\n\n----------------------------------------\n\nTITLE: Installing LangChain Dependencies\nDESCRIPTION: Pip installation command for required LangChain packages and dependencies\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U langchain-google-genai deeplake langchain langchain-text-splitters langchain-community\n```\n\n----------------------------------------\n\nTITLE: Splitting Book Text into Chunks for Processing\nDESCRIPTION: Splits the book text into chunks using double newlines as separators and removes content after the Project Gutenberg end marker. Counts and prints the number of chunks.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nchunks = book[:book.find(\"END OF THE PROJECT GUTENBERG EBOOK TAJEMNICA BASKERVILLE'W: DZIWNE PRZYGODY SHERLOCKA HOLMES\")].split(\"\\n\\n\")\n\nnum_chunks = len(chunks)\nprint(f\"Number of chunks: {num_chunks}\")\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Response from Gemini\nDESCRIPTION: Converts the response text from Gemini into markdown format for better readability.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nto_markdown(res.text)\n```\n\n----------------------------------------\n\nTITLE: Loading and Previewing Housing Data\nDESCRIPTION: Reads the CSV file into a pandas DataFrame and displays first 5000 entries\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Read the CSV file into a pandas DataFrame\nhouses_data = pd.read_csv('houses.csv', nrows=5000) # only keeping the first 5000 entries to keep the request light (still 500k tokens). Use pro 1.5 to ingest the full dataset.\nhouses_data.to_csv('houses.csv', index=False)\nhouses_data.head()\n```\n\n----------------------------------------\n\nTITLE: Apache 2.0 License Header in Python\nDESCRIPTION: Standard Apache 2.0 license header implemented as a Python comment block, specifying usage terms and conditions for the Google Gemini codebase.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/websockets/live_api_streaming_in_colab.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Prompting Gemini with Video File via REST API\nDESCRIPTION: Bash script that sends a prompt to the Gemini API with a reference to the uploaded video file, demonstrating how to use video in multimodal prompting.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n. vars.sh\n\nfile_uri=$(jq \".uri\" file_info.json)\n\nmodel=\"gemini-2.0-flash\"\n\ncurl \"${BASE_URL}/v1beta/models/${model}:generateContent?key=${GOOGLE_API_KEY}\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d '{\n      \"contents\": [{\n        \"parts\":[\n          {\"text\": \"Please describe this file.\"},\n          {\"file_data\": {\n            \"mime_type\": \"'${MIME_TYPE}'\",\n            \"file_uri\": '${file_uri}'}}]\n        }]\n       }' 2>/dev/null >response.json\n\njq -C .candidates[].content response.json\n```\n\n----------------------------------------\n\nTITLE: Defining sample text for travel directions entity extraction\nDESCRIPTION: This code defines a text variable containing travel directions from Rome's airport to the Colosseum that will be used for extracting street names and transportation methods.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndirections = \"\"\"\n  To reach the Colosseum from Rome's Fiumicino Airport (FCO),\n  your options are diverse. Take the Leonardo Express train from FCO\n  to Termini Station, then hop on metro line A towards Battistini and\n  alight at Colosseo station.\n  Alternatively, hop on a direct bus, like the Terravision shuttle, from\n  FCO to Termini, then walk a short distance to the Colosseum on\n  Via dei Fori Imperiali.\n  If you prefer a taxi, simply hail one at the airport and ask to be taken\n  to the Colosseum. The taxi will likely take you through Via del Corso and\n  Via dei Fori Imperiali.\n  A private transfer service offers a direct ride from FCO to the Colosseum,\n  bypassing the hustle of public transport.\n  If you're feeling adventurous, consider taking the train from\n  FCO to Ostiense station, then walking through the charming\n  Trastevere neighborhood, crossing Ponte Palatino to reach the Colosseum,\n  passing by the Tiber River and Via della Lungara.\n  Remember to validate your tickets on the metro and buses,\n  and be mindful of pickpockets, especially in crowded areas.\n  No matter which route you choose, you're sure to be awed by the\n  grandeur of the Colosseum.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing PDF Processing Tools\nDESCRIPTION: Installs the poppler-utils package to enable PDF processing capabilities, used for displaying a screenshot of a PDF page.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!apt install poppler-utils\n```\n\n----------------------------------------\n\nTITLE: Configuring Apache License in Python\nDESCRIPTION: Python code block that defines the Apache License 2.0 notice as a comment, indicating the licensing terms under which the notebook is distributed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing LangChain Components for Document Processing\nDESCRIPTION: Importing necessary LangChain components including PromptTemplate for creating prompts, WebBaseLoader for loading web content, and schema components for handling document output.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import PromptTemplate\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.schema import StrOutputParser\nfrom langchain.schema.prompt_template import format_document\n```\n\n----------------------------------------\n\nTITLE: Configuring Google API Key from Colab Secret\nDESCRIPTION: Sets up the Google API key by retrieving it from Google Colab Secrets and setting it as an environment variable for authentication with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Chat_with_SQL_using_langchain.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Video File in Python\nDESCRIPTION: Command to download the Big Buck Bunny sample video file that will be used for prompting the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!wget https://download.blender.org/peach/bigbuckbunny_movies/BigBuckBunny_320x180.mp4\n```\n\n----------------------------------------\n\nTITLE: Selecting Gemini 2.0 Flash Live Model\nDESCRIPTION: Specifies the Gemini 2.0 Flash Live model to be used for the multimodal Live API examples in this notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = \"gemini-2.0-flash-live-001\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Library\nDESCRIPTION: Installs the Google Generative AI Python library from PyPI using pip, ensuring the latest version (1.7.0 or newer) is used.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.7.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Gemini API Dependencies\nDESCRIPTION: Installation of the google-genai package using pip\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU 'google-genai'\n```\n\n----------------------------------------\n\nTITLE: Defining System Prompt for Animal Classification\nDESCRIPTION: This code creates a system prompt that instructs the Gemini model to act as a zoologist who identifies animals in videos, providing both English and Latin names.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsystem_prompt = \"\"\"\nYou are a zoologist whose job is to name animals in videos.\nYou should always provide an english and latin name.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Generated Summary\nDESCRIPTION: Renders the model's response as Markdown in the notebook, showing the bulleted summary of the PDF document.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini API Python Client\nDESCRIPTION: Installs the latest version of the Google Gemini API Python client library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Library in Python\nDESCRIPTION: This snippet installs the latest version of the google-genai library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Sentiment_Analysis.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Downloading a Public Domain Book from Project Gutenberg\nDESCRIPTION: Uses curl to download a text file of a Sherlock Holmes book in Polish from Project Gutenberg and saves it locally as 'Sherlock.txt'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!curl https://www.gutenberg.org/cache/epub/34079/pg34079.txt > Sherlock.txt\n```\n\n----------------------------------------\n\nTITLE: Setting Google API Key Environment Variable in Python\nDESCRIPTION: Code to retrieve and set the Google API key from Colab user data into an environment variable\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Setting up and running Python sample for Gemini File API\nDESCRIPTION: Instructions for setting up a Python virtual environment, configuring API credentials, installing dependencies, and running the sample code for the Gemini File API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Prepare a virtual environment for Python.\npython3 -m venv venv\nsource venv/bin/activate\n\n# Add API key to .env file\ntouch .env\necho \"GOOGLE_API_KEY='YOUR_API_KEY'\" >> .env\n\n# Install dependencies.\npip3 install -U -r requirements.txt\n\n# Run the sample code.\npython3 sample.py\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI Module\nDESCRIPTION: Imports the Google Generative AI (genai) module which provides the interface for working with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n```\n\n----------------------------------------\n\nTITLE: Configuring Shopping List Formatting\nDESCRIPTION: Sets up the system prompt for organizing groceries into a categorized shopping list format.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nshopping_list_system_prompt = \"\"\"\n  You are given a list of groceries. Complete the following:\n  - Organize groceries into categories for easier shopping.\n  - List each item one under another with a checkbox [].\n\"\"\"\n\nshopping_list_config = types.GenerateContentConfig(\n    system_instruction=shopping_list_system_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Checking class distribution in training data\nDESCRIPTION: Displays the count of samples for each class in the training dataset after sampling and filtering.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndf_train.value_counts('Class Name')\n```\n\n----------------------------------------\n\nTITLE: Setting Up Google API Key in Colab\nDESCRIPTION: Code to retrieve the Google API key from Colab Secrets and set it as an environment variable for authentication with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nimport os\n\nos.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: License Header Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license header declaration for the Google Gemini project.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Streaming_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini Package in Python\nDESCRIPTION: Installs the required Google Genai package for interacting with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Story_Writing_with_Prompt_Chaining.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n! pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Example Function Call Response from Gemini API (JSON)\nDESCRIPTION: JSON structure showing a function call response from Gemini API, containing the function name 'find_theaters' and arguments for movie and location parameters.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Function_calling_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"functionCall\": {\n  \"name\": \"find_theaters\",\n  \"args\": {\n    \"movie\": \"Barbie\",\n    \"location\": \"Mountain View, CA\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Helper Function for QA Chain\nDESCRIPTION: Utility function to call the retrieval chain and display formatted results\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef call_qa_chain(prompt):\n  response = qa.invoke(prompt)\n  display(Markdown(response[\"result\"]))\n```\n\n----------------------------------------\n\nTITLE: Downloading Video File for Analysis\nDESCRIPTION: This code downloads a sample video of an American black bear from Wikimedia Commons for analysis with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Download video\npath = \"black_bear.webm\"\nurl = \"https://upload.wikimedia.org/wikipedia/commons/8/81/American_black_bears_%28Ursus_americanus%29.webm\"\n!wget $url -O $path\n```\n\n----------------------------------------\n\nTITLE: Initializing Google GenAI Client\nDESCRIPTION: Imports the necessary modules and initializes the Google GenAI client with the API key.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Generative AI with API Key in Python\nDESCRIPTION: Sets up the Google Generative AI library using an API key stored in Colab Secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nimport google.generativeai as genai\n\ngenai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API Client in Python\nDESCRIPTION: This code retrieves the Google API key from Colab secrets and initializes the Gemini API client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Loading Book Text from File in Python\nDESCRIPTION: Opens and reads the downloaded book file 'Sherlock.txt' into a variable named 'book' for further processing.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith open(\"/content/Sherlock.txt\") as f:\n      book = f.read()\n```\n\n----------------------------------------\n\nTITLE: Installing jq for JSON Processing in Bash\nDESCRIPTION: Installs the jq command-line JSON processor to parse and format API responses.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!apt install jq\n```\n\n----------------------------------------\n\nTITLE: Setting up and running Node.js sample for Gemini File API\nDESCRIPTION: Instructions for setting up a Node.js environment, configuring API credentials, installing dependencies, and running the sample code for the Gemini File API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Make sure npm is installed first. \n\n# Add API key to .env file\ntouch .env\necho \"GOOGLE_API_KEY='YOUR_API_KEY'\" >> .env\n\n# Install dependencies.\nnpm install\n\n# Run the sample code.\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the latest version of the Google Generative AI Python SDK to use the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client in Python\nDESCRIPTION: This code sets up the Gemini API client using an API key stored in Google Colab secrets. It imports necessary modules and initializes the client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Chain_of_thought_prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Setting Google API Key in Python\nDESCRIPTION: Sets the Google API key as an environment variable using a Colab Secret.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python SDK using pip, ensuring version 0.7.2 or higher which supports OAuth authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Licensing Information for Apache License 2.0 in Python\nDESCRIPTION: Copyright notice and Apache License 2.0 details implemented as a Python comment block.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Imports the necessary modules from google-genai and IPython for displaying markdown content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n\nfrom IPython.display import Markdown\n```\n\n----------------------------------------\n\nTITLE: Apache License for Google Gemini API Usage\nDESCRIPTION: Displays the Apache License 2.0 licensing information that applies to the usage of Google's Gemini API and related code examples.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Evaluation.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Downloading Video File for Analysis\nDESCRIPTION: Downloads a video file of President Ronald Reagan's speech at the Berlin Wall using wget. This video will be used as an example for historic event recognition.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Download video\npath = \"berlin.mp4\"\nurl = \"https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4\"\n!wget $url -O $path\n```\n\n----------------------------------------\n\nTITLE: Cleaning Up Uploaded Video File\nDESCRIPTION: Deletes the uploaded video file from the Gemini API to free up resources after the analysis is complete.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# delete video\nclient.files.delete(name=video_file.name)\n```\n\n----------------------------------------\n\nTITLE: Installing Google GenAI SDK\nDESCRIPTION: Pip command to install the latest version of the Google GenAI SDK, which provides access to Gemini models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q 'google-genai'\n```\n\n----------------------------------------\n\nTITLE: Installing and Importing Google Generative AI Library in Python\nDESCRIPTION: This snippet installs the latest version of the google-generativeai library and imports it for use in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-generativeai>=0.7.2\"\n\nimport google.generativeai as genai\n```\n\n----------------------------------------\n\nTITLE: Initializing Gemini Model with Tourist Instructions\nDESCRIPTION: Creates a Gemini model instance with the tourist assistant system instructions\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name='gemini-2.0-flash', system_instruction=instructions)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Google API Key\nDESCRIPTION: Retrieves the Google API key from Colab user data storage for authentication\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: License Declaration Python Comment Block\nDESCRIPTION: Standard Apache 2.0 license declaration included as a Python comment block\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package\nDESCRIPTION: Installing the required Google Generative AI package using pip\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Pip installation command to set up the latest version of the Google Generative AI Python SDK, which is required to interact with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python library\nDESCRIPTION: This snippet installs the latest version of the Google Generative AI Python library using pip in a Jupyter notebook cell.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Importing IPython Display Functions in Python\nDESCRIPTION: Imports display functions from IPython for rendering Markdown and HTML in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import display, Markdown, HTML\n```\n\n----------------------------------------\n\nTITLE: Writing ReAct Prompt to File in Python\nDESCRIPTION: This snippet writes the ReAct prompt, which includes the model instructions and examples, to a file named 'model_instructions.txt'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nReAct_prompt = model_instructions + examples\nwith open('model_instructions.txt', 'w') as f:\n  f.write(ReAct_prompt)\n```\n\n----------------------------------------\n\nTITLE: Importing and Configuring Google Generative AI in Python\nDESCRIPTION: Imports the Google Generative AI package and configures it with an API key stored in Google Colab's userdata.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\ngenai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n```\n\n----------------------------------------\n\nTITLE: Converting PDF to Image for Visualization\nDESCRIPTION: Uses pdftoppm command-line tool to convert the first page of the PDF to a JPEG image for visualization purposes.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!pdftoppm test.pdf -f 1 -l 1 page-image -jpeg\n!ls\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Gemini Live API\nDESCRIPTION: Imports necessary Python modules including asyncio for asynchronous operations, contextlib, json, wave for audio processing, and IPython display utilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport contextlib\nimport json\nimport wave\n\nfrom IPython import display\n\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Configuring API Authentication\nDESCRIPTION: Retrieves the Google API key from Colab Secrets and initializes the Gemini client with the API key for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Uploading Video File to Gemini API\nDESCRIPTION: Uploads the downloaded video file to the Gemini API for processing and analysis.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Upload video\nvideo_file = client.files.upload(file=path)\n```\n\n----------------------------------------\n\nTITLE: Installing the Gemini Python SDK\nDESCRIPTION: Command to install or update the Google Generative AI Python SDK using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai\" # Install the Python SDK\n```\n\n----------------------------------------\n\nTITLE: Displaying Usage Metadata for Generated Content\nDESCRIPTION: Retrieves and displays the token usage metadata from the generated content response, showing cached vs. non-cached token usage.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nresponse.usage_metadata\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API Client in Python\nDESCRIPTION: This snippet imports necessary modules, retrieves the API key from Colab secrets, and initializes the Gemini API client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai.types import GenerateContentConfig\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Notice in Python\nDESCRIPTION: Standard Apache License 2.0 copyright notice and disclaimer that indicates the legal terms under which the code is distributed. This informs users about their rights and limitations when using this code.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/websockets/live_api_starter.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gemini, LangChain, and Pinecone\nDESCRIPTION: Installs the necessary Python packages including LangChain, its Gemini integration, Pinecone client, and related dependencies.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install --quiet langchain==0.1.1\n%pip install --quiet langchain-google-genai==0.0.6\n%pip install --quiet langchain-pinecone\n%pip install --quiet pinecone-client\n%pip install --quiet langchain-community==0.0.20\n```\n\n----------------------------------------\n\nTITLE: Setting up Apache License 2.0 for Python project\nDESCRIPTION: Defines the Apache License 2.0 header as a Python comment block, establishing the licensing terms for the codebase. This license grants users the freedom to use, modify, and distribute the code under specific conditions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package\nDESCRIPTION: Installs the required Google Generative AI package with version 1.4.0 or higher for chat history support.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.4.0\"\n```\n\n----------------------------------------\n\nTITLE: Defining sample text for phone number extraction\nDESCRIPTION: This code defines a sample customer service email text containing multiple phone numbers that will be used for demonstrating phone number extraction.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ncustomer_service_email = \"\"\"\n  Hello,\n  Thank you for reaching out to our customer support team regarding your\n  recent purchase of our premium subscription service.\n  Your activation code has been sent to +87 668 098 344\n  Additionally, if you require immediate assistance, feel free to contact us\n  directly at +1 (800) 555-1234.\n  Our team is available Monday through Friday from 9:00 AM to 5:00 PM PST.\n  For after-hours support, please call our\n  dedicated emergency line at +87 455 555 678.\n  Thanks for your business and look forward to resolving any issues\n  you may encounter promptly.\n  Thank you.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Rendering Generated HTML\nDESCRIPTION: Displays the generated HTML code using IPython's HTML display functionality\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import HTML\n\n# Render the HTML\nHTML(response.text.strip().removeprefix(\"```html\").removesuffix(\"```\"))\n```\n\n----------------------------------------\n\nTITLE: Setting Up Pinecone API Key\nDESCRIPTION: Configures the Pinecone API key as an environment variable for authentication with Pinecone services.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Pinecone_WebLoad.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nPINECONE_API_KEY=userdata.get('PINECONE_API_KEY')\n\nos.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image for Gemini API File Upload in Python\nDESCRIPTION: Downloads a sample image to be used for demonstrating file upload to the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Image\n\n!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\"\nImage(filename=\"image.jpg\")\n```\n\n----------------------------------------\n\nTITLE: Checking Video Processing Status\nDESCRIPTION: Monitors the processing status of the uploaded video file, waiting until it's ready for analysis or raising an error if processing fails.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport time\n# Wait until the uploaded video is available\nwhile video_file.state.name == \"PROCESSING\":\n  print('.', end='')\n  time.sleep(5)\n  video_file = client.files.get(name=video_file.name)\n\nif video_file.state.name == \"FAILED\":\n  raise ValueError(video_file.state.name)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python SDK with version 1.0.0 or higher, using pip in quiet mode.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting up Google API Key in Python\nDESCRIPTION: This code snippet sets up the Google API key as an environment variable using the userdata from Google Colab.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Models_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Installing Gemini SDK for 002 Models in Python\nDESCRIPTION: Installs a version of the Google Generative AI SDK compatible with 002 models using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q \"google-generativeai>=0.8.2\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package in Python\nDESCRIPTION: Installs the Google Generative AI Python package with a minimum version of 0.7.2 using pip in quiet mode.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Applying Apache License 2.0 to Gemini 2.0 Notebook\nDESCRIPTION: License declaration for the Gemini 2.0 multimodal live API notebook, specifying the Apache License 2.0 terms and conditions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Get_started_LiveAPI_tools.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting Up Unsafe Prompt Environment Variable\nDESCRIPTION: Creates an environment variable for storing the unsafe prompt to be used in API requests. This variable is intentionally left empty for users to define.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nos.environ['UNSAFE_PROMPT'] = \n```\n\n----------------------------------------\n\nTITLE: Reading and Displaying Text File Contents in Python\nDESCRIPTION: Code that opens and reads a text file ('a11.txt'), then displays the first 10 lines of its content. This demonstrates basic file handling in Python.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Upload_files_to_Colab.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith open('a11.txt') as file:\n  text_data = file.read()\n\n# Print first 10 lines\nfor line in text_data.splitlines()[:10]:\n  print(line)\n```\n\n----------------------------------------\n\nTITLE: Model Selection Configuration\nDESCRIPTION: Selecting the Gemini model version for function calling\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.5-flash-preview-04-17\", \"gemini-2.5-pro-preview-03-25\", \"gemini-2.0-flash\", \"gemini-2.0-flash-lite\"] {\"allow-input\":true, isTemplate: true}\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies for Google Gemini Project\nDESCRIPTION: Lists the required Python packages for a Google Gemini project. The dependencies include google-api-python-client for general Google API access, google-generativeai for interacting with Google's generative AI models, and python-dotenv for managing environment variables such as API keys.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/requirements.txt#2025-04-22_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngoogle-api-python-client\ngoogle-generativeai\npython-dotenv\n```\n\n----------------------------------------\n\nTITLE: Downloading Apollo 11 Transcript using wget in Bash\nDESCRIPTION: This command downloads the Apollo 11 transcript text file from a Google Cloud Storage bucket.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n```\n\n----------------------------------------\n\nTITLE: Defining TypedDict Schema for Direct Schema Usage\nDESCRIPTION: Creates a Python TypedDict class that defines the structure for a Recipe object with name, description, and ingredients fields. This will be used for direct schema validation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/JSON_mode.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport typing_extensions as typing\n\nclass Recipe(typing.TypedDict):\n    recipe_name: str\n    recipe_description: str\n    recipe_ingredients: list[str]\n```\n\n----------------------------------------\n\nTITLE: Saving Translated Book to File in Python\nDESCRIPTION: This code opens a file named 'translated_book.txt' in write mode and writes the contents of the 'translated_book' variable to it. This is typically the final step after translating a book using a machine learning model like Google Gemini.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\nwith open(f\"/content/translated_book.txt\", \"w\") as f:\n  f.write(translated_book)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package\nDESCRIPTION: Installs the Google Generative AI Python package with version 1.0.0 or higher using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -Uq \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in HTML\nDESCRIPTION: HTML code to embed a YouTube video about Gemini 2.0's video understanding capabilities within the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n%%html\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Mot-JEU26GQ?si=pcb7-_MZTSi_1Zkw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n```\n\n----------------------------------------\n\nTITLE: Downloading Apollo 11 Transcript\nDESCRIPTION: Uses wget to download the Apollo 11 transcript file.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Caching_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package\nDESCRIPTION: Installs the latest version of the google-genai package silently using pip\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q google-genai\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio File\nDESCRIPTION: Downloads a sample audio file (1961 US State of the Union Address) using wget.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n!wget https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3 -O sample.mp3\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the latest version of the Google Generative AI Python SDK quietly with the pip package manager.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -qU \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini API Package\nDESCRIPTION: Installs the required Google Gemini API Python package.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Package\nDESCRIPTION: Installs the required Google Generative AI package with version 0.7.2 or higher\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-generativeai>=0.7.2\"\n```\n\n----------------------------------------\n\nTITLE: Alternate Connection Methods for Weaviate\nDESCRIPTION: Examples of alternative ways to connect to Weaviate including Weaviate Cloud (WCS) and connecting to a local instance. These are provided as options but not executed in the main flow.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nWCD_URL = \"https://sandbox.gcp.weaviate.cloud\"\nWCD_AUTH_KEY = \"sk-key\"\nGEMINI_API_KEY = \"sk-key\"\n\nclient = weaviate.connect_to_wcs(\n    cluster_url=WCD_URL,\n    auth_credentials=weaviate.auth.AuthApiKey(WCD_AUTH_KEY),\n    headers={\"X-Google-Studio-Api-Key\": GEMINI_API_KEY},\n)\n\nprint(client.is_ready())\n```\n\n----------------------------------------\n\nTITLE: Visualizing Tuning Loss Curve with Seaborn in Python\nDESCRIPTION: This code visualizes the loss curve from the tuning results using Seaborn. It helps in understanding how the model's predictions deviate from ideal outputs during the tuning process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport seaborn as sns\n\nmodel = operation.result()\n\nsnapshots = pd.DataFrame(model.tuning_task.snapshots)\n\nsns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Library in Python\nDESCRIPTION: This code installs the latest version of the google-genai library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Apache License Header in Python\nDESCRIPTION: Standard Apache 2.0 license header for the code file\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Deleting the Cached Content\nDESCRIPTION: Displays the cache name and deletes the cached content to avoid ongoing storage costs when it's no longer needed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nprint(apollo_cache.name)\nclient.caches.delete(name=apollo_cache.name)\n```\n\n----------------------------------------\n\nTITLE: Displaying Relocation Notice for Gemini 2.0 Multimodal Live API Tool Use Notebook in Markdown\nDESCRIPTION: This Markdown snippet informs users about the relocation of the Gemini 2.0 Multimodal Live API tool use notebook. It provides a link to the new location in the quickstarts section and mentions the availability of guides and tutorials for Gemini capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/live_api_tool_use.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Gemini 2.0 - Multimodal live API: Tool use\n\n### This notebook has been moved in the [quickstarts](../quickstarts/Get_started_LiveAPI_tools.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Setting up License Information in Python\nDESCRIPTION: License information for the Apache License, Version 2.0, formatted as a Python comment block.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Streaming.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up Apache License Header in Python\nDESCRIPTION: Standard Apache License 2.0 header included at the beginning of the file to establish licensing terms.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Markdown Redirect Notice\nDESCRIPTION: A markdown header and notice informing users about the relocation of the video understanding notebook to the quickstarts section.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/video_understanding.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Video understanding with Gemini 2.0\n\n### This notebook has been moved in the [quickstarts](../quickstarts/Video_understanding.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Import statements for necessary Python modules including LangChain, DeepLake, and utility functions\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom glob import glob\nfrom IPython.display import Markdown, display\n\nfrom langchain.vectorstores import DeepLake\nfrom langchain.document_loaders import TextLoader\nfrom langchain_text_splitters import (\n    Language,\n    RecursiveCharacterTextSplitter,\n)\nfrom langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\nfrom langchain.chains import RetrievalQA\n```\n\n----------------------------------------\n\nTITLE: Apache License Header Declaration in Python\nDESCRIPTION: Standard Apache 2.0 license header declaration for the codebase.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Wikipedia Python Package\nDESCRIPTION: Installs the Wikipedia Python package which provides an API to search and retrieve content from Wikipedia. This package is needed for the ReAct implementation to query Wikipedia for information.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q wikipedia\n```\n\n----------------------------------------\n\nTITLE: Defining Instructions for Web App Generation in Python\nDESCRIPTION: This code defines the system instructions for the Gemini model, specifying the role of a coding expert to create a web page based on user requests.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Opossum_search.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ninstruction = \"\"\"\n    You are a coding expert that specializes in creating web pages based on a user request.\n    You create correct and simple code that is easy to understand.\n    You implement all the functionality requested by the user.\n    You ensure your code works properly, and you follow best practices for HTML programming.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens for Uploaded PDF File with Gemini API in Python\nDESCRIPTION: Checks how many tokens a PDF file was converted to, which helps track context size and potential API costs.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Pdf_structured_outputs_on_invoices_and_forms.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfile_size = client.models.count_tokens(model=model_id,contents=invoice_pdf)\nprint(f'File: {invoice_pdf.display_name} equals to {file_size.total_tokens} tokens')\n# File: invoice equals to 821 tokens\n```\n\n----------------------------------------\n\nTITLE: Installing ChromaDB and Gemini API Python Library\nDESCRIPTION: This snippet installs the required libraries: ChromaDB and the Gemini API Python library.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n%pip install -q chromadb\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 declaration for the Google LLC project\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Code_analysis_using_Gemini_LangChain_and_DeepLake.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Gemini API License Header\nDESCRIPTION: Contains the Apache License 2.0 header that applies to the Gemini API code examples. This is a standard license notification for open source software.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Information in Python\nDESCRIPTION: License information for the Gemini API, specifying the terms under the Apache License 2.0.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Content for Object Detection with Gemini 1.5 Flash\nDESCRIPTION: This Markdown snippet provides information about the replacement of the object detection notebook, links to new resources, and the location of an archived version.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Object_detection.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Object detection with Gemini 1.5 Flash\n\n### This notebook has been replaced by the new [spatial understanding](../quickstarts/Spatial_understanding.ipynb) notebook highliting the latest Gemini capabilities.\n\nYou can also check the [Spatial demo](https://aistudio.google.com/starter-apps/spatial) on AI Studio.\n\nAnd if you still need it, you can find an archived version of the notebook [here](../../gemini-1.5-archive/examples/Object_detection.ipynb).\n```\n\n----------------------------------------\n\nTITLE: Importing Gemini API Library\nDESCRIPTION: Import statement for the google-genai package\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache 2.0 license declaration header for the codebase.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Apache License Header for Python\nDESCRIPTION: Standard Apache License 2.0 header that specifies the licensing terms for the code in this notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Upload_files_to_Colab.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gemini API in Python\nDESCRIPTION: Installs the required Google Generative AI library for interacting with the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting License Terms in Python\nDESCRIPTION: License declaration for the notebook, specifying Apache License 2.0 terms and conditions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/PDF_Files.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up License and Copyright Information in Python\nDESCRIPTION: Python code snippet that defines the Apache License 2.0 copyright notice as a code cell title in a Jupyter notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Header for Apache License 2.0\nDESCRIPTION: Standard license header for the Apache License 2.0, indicating that the content is licensed under this open source license.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Processing and Communication in JavaScript\nDESCRIPTION: Creates a MediaStreamSource from user media and connects it to an AudioWorklet processor for handling audio data. Manages bidirectional communication between the processor and the connection, including base64 encoding/decoding of audio data.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/websockets/LiveAPI_streaming_in_colab.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\ntry {\n  let source = audioCtx.createMediaStreamSource(userMedia);\n  let processor = new AudioWorkletNode(audioCtx, 'port-processor');\n  processor.port.onmessage = (event) => {\n    if ('audio_in' in event.data) {\n      // base64 encode ugly way\n      let encoded = btoa(String.fromCharCode(\n          ...Array.from(new Uint8Array(event.data.audio_in))));\n      //console.log(\"base64 input\", encoded);\n      connection.write({audio_in: encoded});\n    } else {\n      console.log(\"from processor (unhandled)\", event);\n    }\n  };\n  source.connect(processor);\n  processor.connect(audioCtx.destination);\n  //await new Promise((acc) => setTimeout(acc, 1000));\n  while(!connection.signal.aborted) {\n    let request = await connection.read();\n    //console.log(request);\n    if ('audio_out' in request) {\n      let decoded = Uint8Array.from(\n          atob(request.audio_out), c => c.charCodeAt(0)).buffer;\n      //console.log('Enqueue', decoded);\n      processor.port.postMessage({'enqueue': decoded});\n    } else if('flush' in request) {\n      processor.port.postMessage({'clear': ''});\n    }\n  }\n} finally {\n  userMedia.getTracks().forEach(t => t.stop());\n  audioCtx.close();\n}\n```\n\n----------------------------------------\n\nTITLE: Formatting Notebooks with nbfmt Tool\nDESCRIPTION: Command to run the nbfmt formatting tool from tensorflow-docs to automatically format notebooks according to project standards.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython -m tensorflow_docs.tools.nbfmt path/to/notebook\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Header for Gemini API Guide\nDESCRIPTION: This snippet shows a markdown header for the Gemini API getting started guide, indicating the content's original purpose before relocation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/get_started.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Gemini API: Getting started with Gemini 2.0\n```\n\n----------------------------------------\n\nTITLE: Setting up License in Python for Gemini API\nDESCRIPTION: This code snippet defines the Apache License 2.0 terms for the Gemini API usage. It establishes the legal framework under which the API can be used.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Making an Initial API Request to Gemini with Unsafe Prompt\nDESCRIPTION: Executes a curl command to call the Gemini API with the unsafe prompt and saves the response to a file, displaying the output to identify why the prompt might be blocked.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%%bash\n\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=$GOOGLE_API_KEY\" \\\n    -H 'Content-Type: application/json' \\\n    -X POST \\\n    -d @request.json  2> /dev/null | tee response.json\n```\n\n----------------------------------------\n\nTITLE: Setting Target Company for Research\nDESCRIPTION: Defines the target company for the research report. In this example, the company is set to 'Alphabet'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nCOMPANY = 'Alphabet' # @param {type:\"string\"}\n```\n\n----------------------------------------\n\nTITLE: Downloading Test Images Using wget\nDESCRIPTION: Downloads the test images from a Google Cloud Storage bucket using wget.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!wget -nv {img_dir}{{{','.join(img_filenames)}}}\n```\n\n----------------------------------------\n\nTITLE: Apache License Notice for Gemini API Usage\nDESCRIPTION: License notice indicating that the code is licensed under Apache License 2.0, specifying terms and conditions for usage of the provided examples.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_Summarization_WebLoad.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Using Text-Only Mode (NONE) with Gemini Function Calling\nDESCRIPTION: Demonstrates how to make the model respond with text only by setting the function calling mode to 'none', even though tools are available.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ntool_config = tool_config_from_mode(\"none\")\n\nresponse = chat.send_message(\n    \"Hello light-bot, what can you do?\", tool_config=tool_config\n)\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Library\nDESCRIPTION: Installs the latest version of the google-genai Python package silently.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Adding_context_information.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Python Packages\nDESCRIPTION: Installation of Google Genai and Qdrant client packages using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/qdrant/Qdrant_similarity_search.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q \"google-genai>=1.0.0\"\n%pip install -q protobuf==4.25.1 qdrant-client[fastembed]\n```\n\n----------------------------------------\n\nTITLE: Extracting Grounding Metadata from API Result using jq in Python\nDESCRIPTION: This snippet extracts and displays the grounding metadata, including links to supports used, from the API result using jq.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n!jq -r \".candidates[0].groundingMetadata\" result.json\n```\n\n----------------------------------------\n\nTITLE: Uploading Housing Data to Gemini File API\nDESCRIPTION: Uploads the housing dataset CSV file to Gemini File API for analysis\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Upload diving_data.csv file using the File API\nhouses_file = client.files.upload(\n    file='houses.csv',\n    config=types.FileDict(display_name='Blocks Data')\n)\n\nprint(f\"Uploaded file '{houses_file.display_name}' as: {houses_file.uri}\")\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI libraries\nDESCRIPTION: Imports the necessary modules from the Google Generative AI package, including the main genai module and types for configuration.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Few_shot_prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Installing PDF Processing Tools\nDESCRIPTION: Installs poppler-utils, which provides the pdftotext utility for extracting text from PDF files.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n!apt install poppler-utils\n```\n\n----------------------------------------\n\nTITLE: Installing Google GenAI and tqdm Python Libraries\nDESCRIPTION: Installs the Google GenAI Python client library and tqdm progress bar library using pip with quiet output and ensuring the latest version.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\" tqdm\n```\n\n----------------------------------------\n\nTITLE: Importing Required Python Libraries\nDESCRIPTION: Imports the tqdm progress bar library for showing progress and IPython.display's Markdown for formatted text display in the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Translate_a_Public_Domain_Book.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom tqdm import tqdm\n\nfrom IPython.display import Markdown\n```\n\n----------------------------------------\n\nTITLE: Running cURL Bash script for Gemini File API upload\nDESCRIPTION: A bash command to execute the provided sample script that uploads a file to the Gemini File API. The script takes arguments for the API key, input file path, and file description.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/file-api/README.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbash ./sample.sh -a \"<YOUR_KEY>\" -i \"sample_data/gemini_logo.png\" -d \"Gemini logo\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client\nDESCRIPTION: Setting up the Gemini API client with authentication using an API key stored in Colab Secrets\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gen AI SDK for Python\nDESCRIPTION: Installs the latest version of the Google Gen AI SDK using pip. This SDK provides programmatic access to Gemini 2.0 and previous models.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q google-genai\n```\n\n----------------------------------------\n\nTITLE: Uploading Extracted Text Files to Gemini API\nDESCRIPTION: Uploads the extracted text files from the blog PDFs to the Gemini API to be used as examples of writing style.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Voice_memos.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nblog_file_name = \"A_Possible_Future_for_Online_Content.txt\"\nblog_file = genai.upload_file(path=blog_file_name)\n```\n\n----------------------------------------\n\nTITLE: Displaying Video Frame Preview\nDESCRIPTION: Uses OpenCV and Matplotlib to display a specific frame from the video for demonstration purposes, providing a visual reference of the content being analyzed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# this is only needed for demonstration purposes\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Display some of the video content\ncap = cv2.VideoCapture(path)\nframe_number = 1000\nfor _ in range(frame_number):\n    ret, frame = cap.read()\nframe_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\nplt.imshow(frame_rgb)\nplt.axis('off')\nplt.show()\n\ncap.release()\n```\n\n----------------------------------------\n\nTITLE: Setting up Google API Key\nDESCRIPTION: Retrieves Google API key from Colab user data for authentication\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Code_Execution.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Setting Up Apache License in Python\nDESCRIPTION: License declaration for the notebook, specifying usage rights under Apache License 2.0 with conditions for distribution and modification.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 declaration in a Python comment block, explaining the terms under which the code is licensed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Reasoning.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Sending a Potentially Unsafe Prompt to Gemini\nDESCRIPTION: This code sends a potentially unsafe prompt to the Gemini model and stores the response. It defines a model ID parameter with options and creates a prompt about sports teams that might trigger safety filters.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID=\"gemini-2.0-flash-lite\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nunsafe_prompt = \"\"\"\n  I support Martians Soccer Club and I think Jupiterians Football Club\n  sucks! Write a ironic phrase about them.\n\"\"\"\nresponse = client.models.generate_content(\n    model = MODEL_ID,\n    contents = unsafe_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for API Keys and Weaviate URL\nDESCRIPTION: Sets environment variables for Weaviate URL, Weaviate API key, and Google API key. These are required for connecting to Weaviate and using Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/query-agent-as-a-tool.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nos.environ[\"WEAVIATE_URL\"] = \"\"\nos.environ[\"WEAVIATE_API_KEY\"] = \"\"\nos.environ[\"GOOGLE_API_KEY\"] = \"\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Google API Key from Colab Secret\nDESCRIPTION: Retrieves the Google API key stored in a Colab Secret named 'GOOGLE_API_KEY'. This key is necessary for authenticating API requests.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Apache License Declaration in Python\nDESCRIPTION: License declaration for the notebook, indicating it's licensed under Apache License 2.0. This provides legal information about usage rights and restrictions.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Template.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: API Key Configuration Setup\nDESCRIPTION: Setting up API key authentication for Gemini client\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: License Declaration for Apache License 2.0\nDESCRIPTION: Python code block containing the Apache License 2.0 header that specifies the terms under which the notebook content is licensed.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Implementing Party Automation Functions\nDESCRIPTION: Defines functions for controlling party-related features like disco ball, music, and lighting that can be called in parallel.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ndef power_disco_ball(power: bool) -> bool:\n    \"\"\"Powers the spinning disco ball.\"\"\"\n    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n    return True\n\n\ndef start_music(energetic: bool, loud: bool, bpm: int) -> str:\n    \"\"\"Play some music matching the specified parameters.\n\n    Args:\n      energetic: Whether the music is energetic or not.\n      loud: Whether the music is loud or not.\n      bpm: The beats per minute of the music.\n\n    Returns: The name of the song being played.\n    \"\"\"\n    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n    return \"Never gonna give you up.\"\n\n\ndef dim_lights(brightness: float) -> bool:\n    \"\"\"Dim the lights.\n\n    Args:\n      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n    \"\"\"\n    print(f\"Lights are now set to {brightness:.0%}\")\n    return True\n\nhouse_fns = [power_disco_ball, start_music, dim_lights]\n```\n\n----------------------------------------\n\nTITLE: Creating Image Analysis Prompt\nDESCRIPTION: Defines a prompt for analyzing product features from an image.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"\"\"\n    This image contains a sketch of a potential product along with some notes.\n    Given the product sketch, describe the product as thoroughly as possible based on what you\n   see in the image, making sure to note all of the product features. Return output in json format:\n   {description: description, features: [feature1, feature2, feature3, etc]}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client\nDESCRIPTION: Sets up the Gemini API client using an API key stored in Colab secrets.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Information_Extraction.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.colab import userdata\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Setting Google API Key as Environment Variable\nDESCRIPTION: Retrieves the Google API Key from Colab secrets and stores it as an environment variable for use in API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Safety_REST.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Google API Key Environment Setup\nDESCRIPTION: Python code to import required modules and set up the Google API key from Colab userdata\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/System_instructions_REST.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\n```\n\nLANGUAGE: python\nCODE:\n```\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Setting up Gemini API Client with Authentication in Python\nDESCRIPTION: This code retrieves the Google API key from Colab secrets and initializes the Gemini API client. It requires the API key to be stored as a Colab Secret named 'GOOGLE_API_KEY'.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Text_Classification.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Apache License 2.0 Header in Python\nDESCRIPTION: Standard Apache 2.0 license header implemented as a Python comment block. Defines usage terms and conditions for the Google Gemini cookbook content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/websockets/live_api_tool_use.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 header for the codebase\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting Up Gemini API Authentication\nDESCRIPTION: Code that initializes the Gemini API client using an API key stored in a Colab Secret. This is the standard authentication pattern for using Google's Generative AI services securely.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Upload_files_to_Colab.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Client with API Key\nDESCRIPTION: This snippet sets up the Gemini API client using an API key stored in a Colab Secret.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Self_ask_prompting.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Testing ReAct Prompted Gemini Model in Python\nDESCRIPTION: Demonstrates how to initialize and use the ReAct framework with a Gemini model. The example includes asking a specific question with the ReAct-prompted model and comparing it with the response from the standard Gemini model to highlight the differences in reasoning and information retrieval.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_Wikipedia_using_ReAct.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ngemini_ReAct_chat = ReAct(model='gemini-2.0-flash', ReAct_prompt='model_instructions.txt')\n# Note: try different combinations of generational_config parameters for variational results\ngemini_ReAct_chat(\"What are the total of ages of the main trio from the new Percy Jackson and the Olympians TV series in real life?\", temperature=0.2)\n```\n\n----------------------------------------\n\nTITLE: License Declaration in Python\nDESCRIPTION: Apache License 2.0 declaration included at the beginning of the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Specifying Task Type for Embedding Generation in Gemini API\nDESCRIPTION: Shows how different task types can affect the generated embeddings. This example compares the default embedding with one specifically generated for retrieval document tasks.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Notice the API returns different embeddings depending on `task_type`\nresult1 = client.models.embed_content(\n    model=\"text-embedding-004\",\n    contents=[\"Hello world\"])\n\nresult2 = client.models.embed_content(\n    model=\"text-embedding-004\",\n    contents=[\"Hello world\"],\n    config={\"task_type\": \"retrieval_document\"})\n\n\n[embedding1] = result1.embeddings\n[embedding2] = result2.embeddings\n\nprint(str(embedding1)[:50], '... TRIMMED]')\nprint(str(embedding2)[:50], '... TRIMMED]')\n```\n\n----------------------------------------\n\nTITLE: Initiating Video Upload Task with REST API\nDESCRIPTION: Bash script using curl to create a new upload task with the File API, which returns the upload URL for later steps.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Video_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n%%bash\n. vars.sh\n\n# Create the \"new upload\" request by providing the relevant metadata.\ncurl \"${BASE_URL}/upload/v1beta/files?key=${GOOGLE_API_KEY}\" \\\n  -D upload-header.tmp \\\n  -H \"X-Goog-Upload-Protocol: resumable\" \\\n  -H \"X-Goog-Upload-Command: start\" \\\n  -H \"X-Goog-Upload-Header-Content-Length: ${NUM_BYTES}\" \\\n  -H \"X-Goog-Upload-Header-Content-Type: ${MIME_TYPE}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{'file': {'display_name': '${DISPLAY_NAME}'}}\" 2>/dev/null\n\n# Print the status.\nhead -1 upload-header.tmp\n```\n\n----------------------------------------\n\nTITLE: Using Task Type Parameter for Specialized Embeddings\nDESCRIPTION: Demonstrating how to use the task_type parameter to provide a hint to the model about the intended use of embeddings, in this case setting it to RETRIEVAL_DOCUMENT with a document title.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Embeddings_REST.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl \"https://generativelanguage.googleapis.com/v1beta/models/embedding-001:embedContent?key=$GOOGLE_API_KEY\" \\\n-H 'Content-Type: application/json' \\\n-d '{\"model\": \"models/text-embedding-004\",\n    \"content\": {\n    \"parts\":[{\n      \"text\": \"Hello world\"}]},\n    \"task_type\": \"RETRIEVAL_DOCUMENT\",\n    \"title\": \"My title\"}' 2> /dev/null | head\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for LlamaIndex and Chroma Integration\nDESCRIPTION: Python code that installs necessary packages including LlamaIndex, Gemini integrations, web page reader, vector store connector for Chroma, and ChromaDB client.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This guide was tested with 0.10.17, but feel free to try newer versions.\n%pip install -q llama-index==0.10.17\n%pip install -q llama-index-llms-gemini\n%pip install -q llama-index-embeddings-gemini\n%pip install -q llama-index-readers-web\n%pip install -q llama-index-vector-stores-chroma\n%pip install -q chromadb\n```\n\n----------------------------------------\n\nTITLE: Setting Google API Key in Python for Colab Environment\nDESCRIPTION: This snippet copies the Google API key from Colab Secrets to an environment variable for use in subsequent API calls.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Deleting Uploaded Video File\nDESCRIPTION: Removes the uploaded video file from the Gemini API to prevent unnecessary data storage after analysis is complete.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Historic_Event_Recognition.ipynb#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Delete video\nclient.files.delete(name=video_file.name)\n```\n\n----------------------------------------\n\nTITLE: Evaluating Tuned Model with Gemini API in Python\nDESCRIPTION: This snippet demonstrates how to evaluate the tuned model by generating text for various inputs. It shows how the model performs on different types of number sequences.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Tuning.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(model_name=f'tunedModels/{name}')\n\nresult = model.generate_content('55')\nresult.text\n\nresult = model.generate_content('123455')\nresult.text\n\nresult = model.generate_content('four')\nresult.text\n\nresult = model.generate_content('quatre') # French 4\nresult.text                               # French 5 is \"cinq\"\n\nresult = model.generate_content('III')    # Roman numeral 3\nresult.text                               # Roman numeral 4 is IV\n\nresult = model.generate_content('')  # Japanese 7\nresult.text                            # Japanese 8 is !\n```\n\n----------------------------------------\n\nTITLE: Structuring Information from Pottery Video\nDESCRIPTION: API call to Gemini that analyzes a video of pottery items, extracts information, and structures it into a table with system instructions to handle special characters.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Give me a table of my items and notes\" # @param [\"Give me a table of my items and notes\", \"Help me come up with a selling pitch for my potteries\"] {\"allow-input\":true}\n\nvideo = pottery_video # @param [\"trailcam_video\", \"pottery_video\", \"post_its_video\", \"user_study_video\"] {\"type\":\"raw\",\"allow-input\":true}\n\nresponse = client.models.generate_content(\n    model=model_name,\n    contents=[\n        video,\n        prompt,\n    ],\n    config = types.GenerateContentConfig(\n        system_instruction=\"Don't forget to escape the dollar signs\",\n    )\n)\n\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Displaying Relocation Notice in Markdown\nDESCRIPTION: This markdown snippet informs users about the relocation of the Gemini 2.0 Flash Thinking notebook to the quickstarts section. It provides a link to the new location where users can find guides and tutorials about Gemini capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/thinking.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n# Introduction to Gemini 2.0 Flash Thinking\n\n### This notebook has been moved in the [quickstarts](../quickstarts/Get_started_thinking.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Google API Key Configuration\nDESCRIPTION: Setting up Google API key from Colab user data for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/langchain/Gemini_LangChain_QA_Chroma_WebLoad.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Downloading Image for Analysis\nDESCRIPTION: Downloads a sample image for demonstration of image analysis capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Apache License in Python\nDESCRIPTION: This snippet contains the Apache License 2.0 as a Python comment block, which is included at the beginning of the file to specify the licensing terms for the code.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication_with_OAuth.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Gemini Workspace Integration README Documentation\nDESCRIPTION: Markdown documentation explaining the purpose and context of the codelab repository for integrating Gemini API with Google Workspace applications.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Apps_script_and_Workspace_codelab/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Gemini API and Google Workspace Codelab\n\nThese are the final, accompanying files for the [Automate Google Workspace tasks with the Gemini API\n](https://codelabs.developers.google.com/codelabs/gemini-workspace) codelab. This codelabs shows you how to\nconnect to the Gemini API using Apps Script, and uses the function calling, vision and text capabilities to automate\nGoogle Workspace tasks - summarising a document, analyzing a chart, sending an email and generating some slides directly. All of this is done from a free text input.\n\nPlease read and follow along with the main codelab, and if you get stuck you can load these files directly.\n\nThis workshop was featured at [Google I/O 2024](https://io.google/2024/).\n```\n\n----------------------------------------\n\nTITLE: Initializing Apache License Header in Python\nDESCRIPTION: License header for the project, specifying that it's licensed under Apache License 2.0, with terms and conditions for usage, distribution, and modification.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Video_understanding.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up API Key in Python Environment\nDESCRIPTION: Retrieves the Google API key from Colab secrets and sets it as an environment variable for authentication.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Audio_REST.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nos.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n```\n\n----------------------------------------\n\nTITLE: License Declaration for Gemini API Documentation\nDESCRIPTION: The Apache License 2.0 declaration for the Gemini API documentation, defining the terms under which the code samples can be used.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Classifying a Neutral Comment Example\nDESCRIPTION: Demonstrates how to classify a likely neutral comment using the same template and Gemini API. This example uses a different topic and comment that should be classified as neutral.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Classification.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nneutral_topic = \"My computer froze. What should I do?\"\nneutral_comment = \"Try turning it off and on.\"\n\nneutral_prompt = classification_template.format(\n    topic=neutral_topic,\n    comment=neutral_comment\n)\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=neutral_prompt,\n    config=generation_config\n)\nMarkdown(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Basic Content\nDESCRIPTION: Demonstrates basic content generation using the Gemini API with a simple text prompt.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=\"Give me python code to sort a list\"\n)\n\ndisplay(Markdown(response.text))\n```\n\n----------------------------------------\n\nTITLE: Displaying Sample Product Data\nDESCRIPTION: Prints the first object from the loaded JSON data to inspect its structure before importing into Weaviate.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/weaviate/personalized_description_with_weaviate_and_gemini_api.ipynb#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n# Print first object\ndata[0]\n```\n\n----------------------------------------\n\nTITLE: Importing Required Modules\nDESCRIPTION: This snippet imports the necessary Python modules for the tutorial, including ChromaDB, numpy, pandas, and IPython display utilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/chromadb/Vectordb_with_chroma.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport textwrap\nimport chromadb\nimport numpy as np\nimport pandas as pd\n\nfrom IPython.display import Markdown\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Gemini 2.0 Search Tool\nDESCRIPTION: Imports necessary libraries and modules for working with the Gemini 2.0 search tool, including genai, IPython display functions, and standard Python libraries.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai.types import GenerateContentConfig, Tool\nfrom IPython.display import display, HTML, Markdown\nimport io\nimport json\nimport re\n```\n\n----------------------------------------\n\nTITLE: Installing Google Genai Python Client Library\nDESCRIPTION: Installs the latest version of the Google Genai Python client library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Talk_to_documents_with_embeddings.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI Modules\nDESCRIPTION: Imports the necessary modules from the Google Generative AI package, including the main client and types for configuration.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Role_prompting.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google import genai\nfrom google.genai import types\n```\n\n----------------------------------------\n\nTITLE: Setting Up Google API Key for Authentication\nDESCRIPTION: Python code that retrieves the Google API key from Colab Secrets and sets it as an environment variable for authentication with Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/llamaindex/Gemini_LlamaIndex_QA_Chroma_WebPageReader.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom google.colab import userdata\nGOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n```\n\n----------------------------------------\n\nTITLE: Generating Audio Summary with Gemini API\nDESCRIPTION: Sends a request to the Gemini API to analyze the uploaded audio file and provide a summary of its contents. This demonstrates basic audio analysis capabilities.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Audio.ipynb#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nresponse = client.models.generate_content(\n  model=MODEL_ID,\n  contents=[\n    'Listen carefully to the following audio file. Provide a brief summary.',\n    your_audio_file,\n  ]\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Generating Content with Uploaded File in Gemini API\nDESCRIPTION: Demonstrates how to use an uploaded file in a content generation request to the Gemini API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/File_API.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nMODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n\nresponse = client.models.generate_content(\n    model=MODEL_ID,\n    contents=[\"Describe the image with a creative description.\", sample_file]\n)\n\nprint(response.text)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Client Library\nDESCRIPTION: Pip command to install or upgrade the Google Generative AI Python client library. The '-U' flag ensures the latest version is installed, and '-q' keeps the output quiet.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Upload_files_to_Colab.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Displaying Cached Token Count with Markdown\nDESCRIPTION: Displays the total token count that was cached in the previous step using Markdown formatting.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import Markdown\n\ndisplay(Markdown(f\"As you can see in the output, you just cached **{apollo_cache.usage_metadata.total_token_count}** tokens.\"))\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python library which is required to interact with the Gemini API. The command uses pip to install the latest version of the package.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Zero_shot_prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Testing the Wikipedia Search Function\nDESCRIPTION: Runs a test query about LLMs through the Wikipedia search function and displays the results in a formatted manner to verify the function is working properly.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexample = wikipedia_search([\"What are LLMs?\"])\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom IPython.display import display\n\nfor e in example:\n  display(to_markdown(e))\n```\n\n----------------------------------------\n\nTITLE: Listing Tuned Models\nDESCRIPTION: Retrieves all tuned models by setting query_base to False in the configuration\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Models.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfor model in client.models.list(config={'query_base': False}):\n    print(model)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python Package\nDESCRIPTION: This command installs the latest version of the Google Generative AI Python package required to interact with the Gemini API. The -q flag makes the installation quieter.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Increasing Timeout for Gemini API Calls in Python\nDESCRIPTION: Shows how to manually adjust the timeout for Gemini API calls to handle longer response times.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")\nprompt = \"Write a story about a magic backpack.\"\n\nmodel.generate_content(\n    prompt, request_options={\"timeout\": 900}  # Increase timeout to 15 minutes\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring API Authentication for Gemini\nDESCRIPTION: Sets up authentication for the Gemini API by retrieving an API key from Colab Secrets and initializing a client instance to interact with the API.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Summarization.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\nfrom google import genai\n\nAPI_KEY = userdata.get('GOOGLE_API_KEY')\nclient = genai.Client(api_key=API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK for Embeddings\nDESCRIPTION: Installs the Google Generative AI Python package that provides access to the Gemini API for generating embeddings.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Extracting Text Response from API Result using jq in Python\nDESCRIPTION: This snippet extracts and displays the text response from the API result using jq.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/Search_Grounding.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n!jq -r \".candidates[0].content.parts[0].text\" result.json\n```\n\n----------------------------------------\n\nTITLE: Installing Google Generative AI Python SDK\nDESCRIPTION: Installs the Google Generative AI Python SDK using pip with a specific version requirement.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n%pip install -q -U \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Setting Up Test Image Files\nDESCRIPTION: Defines the prompt and image filenames to be used in the examples.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Asynchronous_requests.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nprompt = \"Describe this image in just 3 words.\"\n\nimg_filenames = [\"firefighter.jpg\", \"elephants.jpeg\", \"jetpack.jpg\"]\nimg_dir = \"https://storage.googleapis.com/generativeai-downloads/images/\"\n```\n\n----------------------------------------\n\nTITLE: Installing Google Genai Library for Python\nDESCRIPTION: This snippet installs the latest version of the google-genai library using pip.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Self_ask_prompting.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini API Key in Python\nDESCRIPTION: Sets up the API key for authentication with the Gemini API using a Colab Secret.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Error_handling.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom google.colab import userdata\n\nGOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n```\n\n----------------------------------------\n\nTITLE: Basic Markdown Code Block with cURL Command\nDESCRIPTION: Shows the usage of inline code formatting for the curl command within a Markdown document\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/rest/README.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n`curl`\n```\n\n----------------------------------------\n\nTITLE: Providing Relocation Notice in Markdown\nDESCRIPTION: This markdown snippet informs users about the relocation of the notebook to the quickstarts section and provides a link to the new location.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/get_started.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### This notebook has been moved in the [quickstarts](../quickstarts/Get_started.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Installing Google Gemini Python SDK\nDESCRIPTION: Installs the required Google Generative AI Python SDK package version 1.0.0 or higher\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/System_instructions.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n%pip install -U -q \"google-genai>=1.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Importing Google Generative AI Module\nDESCRIPTION: Imports the main Google Generative AI module for API access\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Providing_base_cases.ipynb#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport google.generativeai as genai\n```\n\n----------------------------------------\n\nTITLE: Gemini 2.0 Search Documentation Redirect\nDESCRIPTION: Markdown notice redirecting users to the quickstarts section for Gemini search capabilities documentation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/search_tool.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Gemini 2.0 - Search as a tool\n\n### This notebook has been moved in the [quickstarts](../quickstarts/Search_Grounding.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Linting Notebooks with nblint Tool\nDESCRIPTION: Command to run the nblint tool with specific style configurations for checking notebook consistency and adherence to project guidelines.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/CONTRIBUTING.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython -m tensorflow_docs.tools.nblint \\\n            --styles=google,tensorflow \\\n            --arg=repo:google-gemini/cookbook \\\n            --arg=branch:main \\\n            --exclude_lint=tensorflow::button_download \\\n            --exclude_lint=tensorflow::button_website \\\n            --arg=base_url:https://ai.google.dev/ \\\n            --exclude_lint=tensorflow::button_github \\\n            path/to/notebook\n```\n\n----------------------------------------\n\nTITLE: Displaying Markdown Header for Multimodal Live API Quickstart\nDESCRIPTION: This snippet uses Markdown syntax to create a main header for the Multimodal Live API Quickstart guide. It also includes a subheader providing information about the notebook's relocation.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/gemini-2/live_api_starter.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Multimodal Live API - Quickstart\n\n### This notebook has been moved in the [quickstarts](../quickstarts/Get_started_LiveAPI.ipynb) section where you can find all the guides and tutorials to get to know the Gemini capabilities.\n```\n\n----------------------------------------\n\nTITLE: Configuring License Information for Gemini API Notebook\nDESCRIPTION: License declaration for the notebook, specifying the Apache License 2.0 terms and conditions under which the code can be used.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/json_capabilities/Entity_Extraction_JSON.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Setting up license information in Python\nDESCRIPTION: This snippet sets up the Apache License 2.0 information as a code cell in Python, establishing the legal terms for using the notebook.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Entity_Extraction.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Checking embedding results\nDESCRIPTION: Displays the first few rows of the training dataset with the generated embeddings column to verify the embedding generation process.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Classify_text_with_embeddings.ipynb#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndf_train.head()\n```\n\n----------------------------------------\n\nTITLE: Configuring License Information for Gemini API Project\nDESCRIPTION: This code block includes the license information for the Apache License 2.0 that governs the use of this notebook content.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n```\n\n----------------------------------------\n\nTITLE: Waiting for Video Processing Completion\nDESCRIPTION: This code implements a polling mechanism to wait until the uploaded video is fully processed by the Gemini API before proceeding with analysis.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/Analyze_a_Video_Classification.ipynb#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport time\n# Wait until the uploaded video is available\nwhile video_file.state.name == \"PROCESSING\":\n  print('.', end='')\n  time.sleep(5)\n  video_file = client.files.get(name=video_file.name)\n\nif video_file.state.name == \"FAILED\":\n  raise ValueError(video_file.state.name)\n```\n\n----------------------------------------\n\nTITLE: Configuring Error Handling System\nDESCRIPTION: Setting up the error handling configuration with system prompts and temperature settings\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/examples/prompting/Basic_Code_Generation.ipynb#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom google.genai import types\n\nerror_handling_system_prompt =f\"\"\"\n  Your task is to explain exactly why this error occurred and how to fix it.\n\"\"\"\n\nerror_handling_model_config = types.GenerateContentConfig(\n    temperature=0,\n    system_instruction=error_handling_system_prompt\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Gemini Model with Tools for Lighting Control\nDESCRIPTION: Creates a Gemini model with three functions to control a hypothetical lighting system. The functions allow turning lights on, setting their color, and turning them off.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = \"gemini-2.0-flash\" # @param [\"gemini-1.5-flash-latest\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true}\n\ndef enable_lights():\n    \"\"\"Turn on the lighting system.\"\"\"\n    print(\"LIGHTBOT: Lights enabled.\")\n\n\ndef set_light_color(rgb_hex: str):\n    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n\n\ndef stop_lights():\n    \"\"\"Stop flashing lights.\"\"\"\n    print(\"LIGHTBOT: Lights turned off.\")\n\n\nlight_controls = [enable_lights, set_light_color, stop_lights]\ninstruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n\nmodel = genai.GenerativeModel(\n    model_name, tools=light_controls, system_instruction=instruction\n)\n\nchat = model.start_chat()\n```\n\n----------------------------------------\n\nTITLE: Setting Model and Test Prompt in Python\nDESCRIPTION: Defines the model name and a test prompt for subsequent examples.\nSOURCE: https://github.com/google-gemini/cookbook/blob/main/quickstarts/New_in_002.ipynb#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel_name = \"models/gemini-1.5-flash-002\"\ntest_prompt=\"Why don't people have tails\"\n```"
  }
]