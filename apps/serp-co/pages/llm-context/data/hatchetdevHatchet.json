[
  {
    "owner": "hatchet-dev",
    "repo": "hatchet",
    "content": "TITLE: Retries with Backoff - Python\nDESCRIPTION: This snippet shows how to implement exponential backoff for retries in Python. Exponential backoff increases the delay between retries, giving failing services more time to recover.  This leads to more resilient handling of intermittent failures.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nexamples/retries/worker.py\n```\n\n----------------------------------------\n\nTITLE: Add Base Task to Workflow - TypeScript\nDESCRIPTION: This snippet adds a basic task to the workflow in TypeScript, which outputs a random number. This serves as the initial task in the conditional workflow example and will be a parent to other tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event in Go\nDESCRIPTION: This snippet shows how to push an event to the Hatchet event queue by calling the `push` method on the Hatchet event client in Go. It includes the event name and payload. The example uses the `EventGoTrigger` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/run/event.go\n```\n\n----------------------------------------\n\nTITLE: Building DAG with Task Dependencies - Python\nDESCRIPTION: This snippet illustrates how to build a DAG by defining task dependencies in Hatchet using the Python SDK. The `second_task` depends on `first_task` and accesses its output using `ctx.task_output(first_task)`. The `@simple.task(parents=[first_task])` decorator registers `second_task` and establishes the dependency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@simple.task()\ndef first_task(input: EmptyModel, ctx: Context) -> dict:\n    return {\"result\": \"Hello World\"}\n\n@simple.task(parents=[first_task])\ndef second_task(input: EmptyModel, ctx: Context) -> dict:\n    # Access output from parent task\n    first_result = ctx.task_output(first_task)\n    print(f\"First task said: {first_result['result']}\")\n    return {\"final_result\": \"Completed\"}\n```\n\n----------------------------------------\n\nTITLE: Defining a Task - Typescript\nDESCRIPTION: This snippet shows how to define a task within a Hatchet workflow using the Typescript SDK.  It defines a task named 'to-lower' which transforms the input message to lowercase. The `fn` property defines the task's function, which receives the workflow's input as an argument and returns an object containing the transformed message.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst toLower = simple.task({\n  name: \"to-lower\",\n  fn: (input) => {\n    return {\n      TransformedMessage: input.Message.toLowerCase(),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Concurrency Strategy with Key - Go\nDESCRIPTION: This snippet shows how to set concurrency limits with a key function in Go. It demonstrates configuring concurrency to ensure fair resource allocation and avoid overloading the system. The `slots` option limits the number of concurrent runs per group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/workflows/concurrency-rr.go\n```\n\n----------------------------------------\n\nTITLE: Pushing Events with Additional Metadata - Typescript\nDESCRIPTION: This snippet demonstrates how to push an event with additional metadata using the Hatchet TypeScript client. It uses the `hatchet.event.push` method with an options object that includes an `additionalMetadata` property.  The `additionalMetadata` property accepts a key-value pair represented as a JavaScript object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nhatchet.event.push(\n  'user:create',\n  {\n    test: 'test',\n  },\n  {\n    additionalMetadata: {\n      source: 'api', // Arbitrary key-value pair\n    },\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Running a Task in Python\nDESCRIPTION: This Python code snippet demonstrates how to run the 'SimpleTask' task defined previously. It creates an instance of the `SimpleInput` model with a message and then calls the `run` method on the task to execute it.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/your-first-task.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsimple.run(SimpleInput(message=\"HeLlO WoRlD\"))\n```\n\n----------------------------------------\n\nTITLE: Handling Webhooks in Express.js (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to handle Hatchet webhooks in an Express.js application. It initializes Hatchet, creates a webhooks instance, and mounts the webhook handler on the `/api/webhook` route using `webhooks.expressHandler`. It requires the `@hatchet-dev/typescript-sdk` and `express` dependencies, as well as the `HATCHET_WEBHOOK_SECRET` environment variable. It also sets `maxDuration` for Vercel deployments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/webhooks.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport express from \"express\";\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nexport const maxDuration = 60; // add this on vercel: 60 for free plans, 300 for pro plans\n\nconst hatchet = Hatchet.init();\n\nconst webhooks = hatchet.webhooks([workflow]);\n\nconst app = express();\n\napp.use(\n  \"/api/webhook\",\n  webhooks.expressHandler({ secret: process.env.HATCHET_WEBHOOK_SECRET }),\n);\n\napp.listen(8080, () => {\n  console.log(\"Server is listening on port 8080\");\n});\n```\n\n----------------------------------------\n\nTITLE: Defining a DAG with Hatchet (Typescript)\nDESCRIPTION: This snippet demonstrates how to define a Directed Acyclic Graph (DAG) using the `hatchet.workflow` factory function in Typescript. It shows how to declare the input and output types for the DAG, and how to define tasks within the DAG using the `dag.task` method. Each task can specify its parents to define the execution order.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\ntype DagInput = {\n  Message: string;\n};\n\ntype DagOutput = {\n  reverse: {\n    Original: string;\n    Transformed: string;\n  };\n};\n\nexport const dag = hatchet.workflow<DagInput, DagOutput>({\n  name: \"simple\",\n});\n\n// Next, we declare the tasks bound to the workflow\nconst toLower = dag.task({\n  name: \"to-lower\",\n  fn: (input) => {\n    return {\n      TransformedMessage: input.Message.toLowerCase(),\n    };\n  },\n});\n\n// Next, we declare the tasks bound to the workflow\ndag.task({\n  name: \"reverse\",\n  parents: [toLower],\n  fn: async (input, ctx) => {\n    const lower = await ctx.parentOutput(toLower);\n    return {\n      Original: input.Message,\n      Transformed: lower.TransformedMessage.split(\"\").reverse().join(\"\"),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Typescript\nDESCRIPTION: This Typescript code snippet demonstrates how to spawn child workflows within a parent workflow. It takes a number of pages as input, and spawns a child workflow for each page using `ctx.spawnWorkflow`. The `result()` method is called on each spawned workflow to await its completion. The snippet shows how to create durable workflows, ensuring that child workflows are only spawned once, even if the parent workflow is retried.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/child-workflows.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nasync function f(ctx) {\n  const { pages } = ctx.workflowInput();\n  const promises: Promise<Result>[] = [];\n\n  for (let i = 0; i < pages; i++) {\n      promises.push(ctx.spawnWorkflow<Result>('process-page', { page: i }).result());\n  }\n  const results = await Promise.all(promises);\n\n  return {\n    results,\n  };\n}\n```\n\n----------------------------------------\n\nTITLE: Bulk Running Tasks in Typescript\nDESCRIPTION: This Typescript code snippet demonstrates how to use the `run` method to bulk run tasks in Hatchet by passing an array of inputs.  It shows how to execute the same task multiple times with different inputs using a single call.  It also mentions `runNoWait` method.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-run.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\nsrc/v1/examples/simple/bulk.ts\n```\n\n----------------------------------------\n\nTITLE: Defining a Task - Python\nDESCRIPTION: This snippet demonstrates how to define a task within a Hatchet workflow using the Python SDK. The `@simple.task()` decorator registers the `task_1` function as a task in the 'simple' workflow. The function takes `input` (a Pydantic model) and `ctx` (Hatchet `Context` object) as arguments. The types are optional, but suggested.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@simple.task()\ndef task_1(input: EmptyModel, ctx: Context) -> None:\n    print(\"executed task_1\")\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow - Go\nDESCRIPTION: This snippet shows how to run a Hatchet workflow in Go. It illustrates both running the workflow and waiting for the result using `simple.Run(ctx, input)` and enqueuing the workflow for asynchronous execution using `simple.RunNoWait(ctx, input)`. Both methods take a context and input data as arguments, and return a result and an error.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\n// Run workflow and wait for the result\nresult, err := simple.Run(ctx, input)\n\n// Enqueue workflow to be executed asynchronously\nrunID, err := simple.RunNoWait(ctx, input)\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for JavaScript with pnpm\nDESCRIPTION: This Dockerfile builds a JavaScript Hatchet worker using pnpm.  It uses a multi-stage build process, first building the application in a builder stage with Node.js 18, then copying the built artifacts to a production stage based on Node.js 18-alpine. It installs pnpm globally, copies package files, installs dependencies using `pnpm install --frozen-lockfile`, builds the application, and defines the command to run the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/docker.mdx#_snippet_3\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\n# Install pnpm\nRUN npm install -g pnpm\n\nCOPY pnpm-lock.yaml package.json ./\n\nRUN pnpm install --frozen-lockfile\n\nCOPY . .\n\nRUN pnpm build\n\n# Stage 2: Production\nFROM node:18-alpine\n\nWORKDIR /app\n\nRUN npm install -g pnpm\n\nCOPY pnpm-lock.yaml package.json ./\n\nRUN pnpm install --frozen-lockfile --prod\n\nCOPY --from=builder /app/dist ./dist\n\nENV NODE_ENV=production\n\nCMD [\"node\", \"dist/worker.js\"]\n```\n\n----------------------------------------\n\nTITLE: Simple Step Retries - Python\nDESCRIPTION: This snippet demonstrates how to define a task with a simple retry policy in Python.  The `retries` property is added to the task object to specify the number of times the task should be retried if it fails.  This configuration improves the reliability of tasks by automatically retrying them upon failure.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/retries/worker.py\n```\n\n----------------------------------------\n\nTITLE: Listing and Bulk Cancelling Workflow Runs in Python\nDESCRIPTION: This Python code snippet demonstrates how to use the Hatchet client to list workflow runs and then perform a bulk cancellation operation on those runs. It utilizes the `hatchet.runs.list()` method to retrieve workflow runs based on a workflow ID, and `hatchet.runs.bulk_cancel()` to cancel multiple runs either by their IDs or based on filter criteria. The example showcases the use of `BulkCancelReplayOpts` and `RunFilter` for specifying cancellation options.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nhatchet = Hatchet()\n\nworkflows = hatchet.workflows.list()\n\nassert workflows.rows\n\nworkflow = workflows.rows[0]\n\nworkflow_runs = hatchet.runs.list(workflow_ids=[workflow.metadata.id])\n\nworkflow_run_ids = [workflow_run.metadata.id for workflow_run in workflow_runs.rows]\n\nbulk_cancel_by_ids = BulkCancelReplayOpts(ids=workflow_run_ids)\n\nhatchet.runs.bulk_cancel(bulk_cancel_by_ids)\n\nbulk_cancel_by_filters = BulkCancelReplayOpts(\n    filters=RunFilter(\n        since=datetime.today() - timedelta(days=1),\n        until=datetime.now(),\n        statuses=[V1TaskStatus.RUNNING],\n        workflow_ids=[workflow.metadata.id],\n        additional_metadata={\"key\": \"value\"},\n    )\n)\n\nhatchet.runs.bulk_cancel(bulk_cancel_by_filters)\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Workflow - Python\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet workflow using the Python SDK.  It imports necessary modules, creates a Hatchet client, and defines a simple workflow named 'SimpleWorkflow'.  The `debug=True` flag enables debug logging. It returns a workflow object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, EmptyModel, Hatchet\n\nhatchet = Hatchet(debug=True)\n\nsimple = hatchet.workflow(name=\"SimpleWorkflow\")\n```\n\n----------------------------------------\n\nTITLE: Create a Durable Workflow (worker.py)\nDESCRIPTION: This code snippet demonstrates how to define a Hatchet workflow in Python, which serves as the foundation for adding tasks, including durable ones. The workflow is the container for organizing and executing tasks within a Hatchet application.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-execution.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk\n\nhatchet = hatchet_sdk.new_client()\n\n@hatchet.workflow(\n    name=\"durable-workflow\",\n    version=\"v1\"\n)\ndef my_workflow(context):\n  pass\n```\n\n----------------------------------------\n\nTITLE: Defining On Failure Step in Python\nDESCRIPTION: This Python code snippet demonstrates how to define an `on_failure_step` using the `@hatchet.on_failure_step()` decorator.  It takes the `context` as input, which allows access to information about the workflow run. In this example, it sends a Slack notification with the workflow run ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/on-failure-step.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.on_failure_step()\ndef on_failure(self, context):\n    slack_client.send_message(\n        f\"Workflow {context.workflow_run_id()} failed\"\n    )\n```\n\n----------------------------------------\n\nTITLE: Running a Hatchet Task (Typescript)\nDESCRIPTION: This snippet illustrates how to run a Hatchet task defined using the factory pattern. It shows how to pass an input object to the `run` method of the task object. The `run` method executes the task and returns the result. The `runNoWait` method executes the task without waiting for the result. The `schedule` and `cron` functions allows to schedule future runs using time and CRON expressions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst input = { Message: \"Hello, World!\" };\n// run now\nconst result = await simple.run(input);\nconst runReference = await simple.runNoWait(input);\n\n// or in the future\nconst runAt = new Date(new Date().setHours(12, 0, 0, 0) + 24 * 60 * 60 * 1000);\nconst scheduled = await simple.schedule(runAt, input);\nconst cron = await simple.cron(\"simple-daily\", \"0 0 * * *\", input);\n```\n\n----------------------------------------\n\nTITLE: Hatchet Buffer Settings Example\nDESCRIPTION: This shell script provides an example configuration for Hatchet's buffer settings aimed at achieving higher throughput. The script sets values for flush periods and item thresholds for different types of data, including workflow runs, events, semaphore releases, and queue step runs. These settings control how often Hatchet writes data to the database in batches.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n# Default values if the values below are not set\nSERVER_FLUSH_PERIOD_MILLISECONDS=250\nSERVER_FLUSH_ITEMS_THRESHOLD=1000\n\n# Settings for writing workflow runs to the database\nSERVER_WORKFLOWRUNBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_WORKFLOWRUNBUFFER_FLUSH_ITEMS_THRESHOLD=500\n\n# Settings for writing events to the database\nSERVER_EVENTBUFFER_FLUSH_PERIOD_MILLISECONDS=1000\nSERVER_EVENTBUFFER_FLUSH_ITEMS_THRESHOLD=1000\n\n# Settings for releasing slots for workers\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_ITEMS_THRESHOLD=200\n\n# Settings for writing queue items to the database\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_ITEMS_THRESHOLD=500\n```\n\n----------------------------------------\n\nTITLE: Declaring Durable Event in Python\nDESCRIPTION: This snippet demonstrates how to declare a durable event in Python using Hatchet. It uses the `WaitForEvent` utility on the `DurableContext` object to wait for an event to occur before continuing the workflow. The code is located in the `examples/durable_event/worker.py` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={DurablePy} target=\"Durable Event\" />\n```\n\n----------------------------------------\n\nTITLE: Defining a DAG with Hatchet (Go)\nDESCRIPTION: This snippet demonstrates defining a Directed Acyclic Graph (DAG) using the `factory.NewWorkflow` function in Go. It illustrates how to create a workflow, define tasks within the workflow using `simple.Task`, and specify task dependencies using the `Parents` field with task references. It also shows how to access parent task outputs using `ctx.ParentOutput` and a task reference.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_6\n\nLANGUAGE: go\nCODE:\n```\nsimple := factory.NewWorkflow[DagInput, DagResult](\n    create.WorkflowCreateOpts[DagInput]{\n        Name: \"simple-dag\",\n    },\n    hatchet,\n)\n\nstep1 := simple.Task(\n    create.WorkflowTask[DagInput, DagResult]{\n        Name: \"Step1\",\n    }, func(ctx worker.HatchetContext, input DagInput) (interface{}, error) {\n        // ...\n    },\n)\n\nsimple.Task(\n    create.WorkflowTask[DagInput, DagResult]{\n        Name: \"Step2\",\n        Parents: []create.NamedTask{\n            step1,\n        },\n    }, func(ctx worker.HatchetContext, input DagInput) (interface{}, error) {\n        // getting parent input also uses the task reference, for example:\n        var step1Output SimpleOutput\n        ctx.ParentOutput(step1, &step1Output)\n\n        // ...\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Refreshing Timeout in Go\nDESCRIPTION: This Go snippet demonstrates how to refresh a task's timeout using the `refreshTimeout` method within a step. It shows how to extend the execution time of a running task. The target `RefreshTimeout` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nexamples/timeout/main.go\n```\n\n----------------------------------------\n\nTITLE: Declaring a Task in Python\nDESCRIPTION: This Python code snippet demonstrates how to declare a task in Hatchet. It uses the `hatchet_sdk` to define a task named 'SimpleTask' with an input validator `SimpleInput`. The task transforms the input message to lowercase and returns it in a dictionary.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/your-first-task.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, EmptyModel, Hatchet\nfrom pydantic import BaseModel\n\nhatchet = Hatchet(debug=True)\n\nclass SimpleInput(BaseModel):\n    message: str\n\n@hatchet.task(name=\"SimpleTask\", input_validator=SimpleInput)\ndef simple(input: SimpleInput, ctx: Context) -> dict[str, str]:\n    return {\n      \"transformed_message\": input.message.lower(),\n    }\n```\n\n----------------------------------------\n\nTITLE: Running the Typescript Hatchet worker\nDESCRIPTION: This command starts the Typescript Hatchet worker, which will listen for workflow events and execute the defined steps. Prerequisite: Node.js, npm, and the required dependencies installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nnpm run worker\n```\n\n----------------------------------------\n\nTITLE: Add Branching Logic - Python\nDESCRIPTION: This snippet adds branching logic to the workflow in Python using `ParentCondition` and `skip_if`. It checks if the output of an upstream task is greater or less than 50, and only one of the two branches will run based on this condition. Demonstrates complex conditional routing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_12\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Spawning Tasks from within a Task - Go\nDESCRIPTION: Demonstrates how to spawn a task from within another task by calling the `Run` method on the task object from within a task function in Go.  This associates the runs in the dashboard for easier debugging.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={ParentTaskGo} target=\"Spawning Tasks from within a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Pushing Internal Events - Python\nDESCRIPTION: Demonstrates how to push an internal event from within a Python application using the Hatchet SDK. The `hatchet.client.event.push` method is used to push the event with a specified name and payload. Requires the `hatchet_sdk` library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nhatchet.client.event.push(\n\"user:create\",\n{\n\"test\": \"test\"\n}\n)\n\n```\n\n----------------------------------------\n\nTITLE: Create a Workflow with Conditions - Python\nDESCRIPTION: This snippet demonstrates how to create a workflow with conditional logic in Python using Hatchet V1. It leverages `wait_for`, `skip_if`, and `cancel_if` to control task execution based on conditions like sleep duration, events, and parent task outputs. The workflow showcases conditional branching and task skipping.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Creating a Scheduled Run - Python\nDESCRIPTION: This code snippet demonstrates how to create a scheduled run in Python using the Hatchet SDK. It sets a specific datetime for the schedule and prints the schedule ID. The `simple.schedule` function is assumed to be defined elsewhere and represents the Hatchet SDK method for creating schedules.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nschedule = simple.schedule([datetime(2025, 3, 14, 15, 9, 26)])\n\n## do something with the id\n\nprint(schedule.id)\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet Client Token\nDESCRIPTION: This shell snippet demonstrates how to set the Hatchet client token in a `.env` file. This is required for authenticating with the Hatchet Cloud service.  The `<your-api-key>` placeholder should be replaced with the actual API key obtained from the Hatchet dashboard.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nHATCHET_CLIENT_TOKEN=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Multiple Concurrency Keys - Typescript\nDESCRIPTION: This snippet demonstrates using multiple concurrency keys in Typescript to create a more complex concurrency control system. This allows for finer-grained control over task execution rates by grouping tasks based on different criteria, offering flexibility in resource allocation and fairness.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/concurrency-rr/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Dynamic Rate Limit Configuration (Typescript)\nDESCRIPTION: This snippet shows how to configure dynamic rate limits for a task in Typescript, using the `rate_limits` configuration. The `dynamicKey` is defined as a CEL expression, referencing input or additional metadata.  The units and limit are defined as integers. It requires the Hatchet SDK to be available.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet src={RateLimitTs} target=\"Dynamic\" />\n```\n\n----------------------------------------\n\nTITLE: Dynamic Rate Limit Configuration (Python)\nDESCRIPTION: This snippet demonstrates how to configure dynamic rate limits for a task in Python using the `rate_limits` configuration. The `dynamic_key` uses a CEL expression to derive the rate limit key from the input data.  The units and limits are defined as integers. It requires the `hatchet` library to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n<GithubSnippet src={RateLimitPy} target=\"Dynamic\" />\n```\n\n----------------------------------------\n\nTITLE: Multi-Region A100-80GB Configuration (Python)\nDESCRIPTION: This Python code configures a Hatchet compute resource to use the A100-80GB GPU across multiple regions.  It specifies the GPU type, the number of GPUs, the memory allocation, the number of replicas, and the regions where the replicas will be randomly distributed. Requires the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Multi-region A100-80GB configuration\ncompute = Compute(\n    gpu_kind=\"a100-80gb\",\n    gpus=1,\n    memory_mb=163840,\n    num_replicas=3,\n    regions=[\"ams\", \"sjc\", \"syd\"]  # Replicas will be randomly distributed\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Task and Awaiting Result - Typescript\nDESCRIPTION: Demonstrates how to run a task and wait for its result in Typescript using the `run` method of the `Task` object. This method returns a promise that resolves when the task completes, returning the result.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Running a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Setting a unique namespace in Bash\nDESCRIPTION: This snippet sets a unique namespace for each developer using the `HATCHET_CLIENT_NAMESPACE` environment variable. This allows developers to work independently without conflicting with each other's workflows, events, and jobs. The namespace ensures that workflows are only triggered for the namespace that created them, events remain isolated to their originating namespace, and workers only process jobs from their assigned namespace. This command should be executed in the developer's shell environment before interacting with Hatchet.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/environments.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport HATCHET_CLIENT_NAMESPACE=\"dev-alice\"\n```\n\n----------------------------------------\n\nTITLE: Pydantic Workflow Example (Python)\nDESCRIPTION: This code snippet demonstrates how to use Pydantic for input validation in a Hatchet workflow. It showcases defining a Pydantic model for the workflow input and using it as an `input_validator` in the workflow definition. Type hints are used for step outputs and typing.cast is used for improved IDE support.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/pydantic.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\n\nexport const PydanticPy = {\n  path: \"examples/pydantic/worker.py\",\n};\n\nexport const getStaticProps = ({}) => getSnippets([PydanticPy]);\n```\n\n----------------------------------------\n\nTITLE: Add Wait for Event Task - Python\nDESCRIPTION: This snippet adds a task that waits for a specific event to be triggered before it starts execution using `wait_for` in Python. It highlights the event-driven capabilities of Hatchet's conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_15\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event in Typescript\nDESCRIPTION: This code snippet demonstrates how to push an event to the Hatchet event queue using the `push` method on the Hatchet event client in TypeScript. It includes the event name and payload. The example uses the `EventTs` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/on_event/event.ts\n```\n\n----------------------------------------\n\nTITLE: Defining Cron in Task Definition - Python\nDESCRIPTION: This snippet demonstrates how to define a cron schedule within a task definition using Python. The `on_cron` property specifies the cron expression, determining when the task is triggered. This approach statically defines the cron schedule as part of the task's configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/workflow-definition.py\n```\n\n----------------------------------------\n\nTITLE: Multiple Concurrency Keys - Python\nDESCRIPTION: This snippet demonstrates using multiple concurrency keys in Python to create a more complex concurrency control system. This allows for finer-grained control over task execution rates by grouping tasks based on different criteria, offering flexibility in resource allocation and fairness.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexamples/concurrency_workflow_level/worker.py\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Consumption (Go)\nDESCRIPTION: This snippet demonstrates how to consume a static rate limit in a Go task by specifying the `rate_limits` in the step definition. This connects the task execution to an existing rate limit.  Requires the Hatchet Go SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={RateLimitGo} target=\"Static Rate Limit\" />\n```\n\n----------------------------------------\n\nTITLE: Multiple Concurrency Keys - Go\nDESCRIPTION: This snippet demonstrates using multiple concurrency keys in Go to create a more complex concurrency control system. This allows for finer-grained control over task execution rates by grouping tasks based on different criteria, offering flexibility in resource allocation and fairness.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/workflows/concurrency-rr.go\n```\n\n----------------------------------------\n\nTITLE: Setting Runtime Priority - Go\nDESCRIPTION: This snippet shows how to set the priority of a Hatchet run when triggering it in Go. It provides a mechanism to override the default workflow priority for a single run.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/run/priority.go\n```\n\n----------------------------------------\n\nTITLE: Declaring a DAG Workflow with Hatchet (TypeScript)\nDESCRIPTION: This snippet shows how to declare DAG workflows using the `hatchet.workflow` method in the V1 SDK. DAGs are still defined as workflows. The example provides the file path for the DAG workflow definition.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const DagsWorker = {\n  path: \"src/v1/examples/dag/workflow.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Returning Step Output Data\nDESCRIPTION: This snippet illustrates how to return data from a step. Step outputs should be JSON serializable. The example shows a step returning an object with an 'awesome' property. This output can be accessed by subsequent steps using `ctx.stepOutput(\"<step_name>\")`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepReturnsData: Step = {\n  name: \"step2\",\n  run: (ctx) => {\n    return { awesome: \"data\" };\n  },\n};\n\n```\n\n----------------------------------------\n\nTITLE: Triggering Task Run with Additional Metadata - Python\nDESCRIPTION: This snippet demonstrates how to trigger a task run with additional metadata using the Hatchet Python client. It uses the `simple_task.run` method with the `TriggerTaskOptions` class to attach a key-value pair to the task run. The key-value pair is passed as a dictionary to the `additional_metadata` argument.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nsimple_task.run(\n    SimpleInput(user_id=1234),\n    options=TriggerTaskOptions(\n        additional_metadata={\n          \"hello\": \"moon\" # Arbitrary key-value pair\n        }\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Scheduled Runs - Typescript\nDESCRIPTION: This snippet demonstrates how to create a scheduled run programmatically using the Typescript Hatchet SDK. It defines the schedule and triggers a workflow.  Requires a configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nSee GithubSnippet: src/examples/scheduled-runs/programatic-schedules.ts - Create\n```\n\n----------------------------------------\n\nTITLE: Using Context Playground for Data Overrides in Hatchet (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to use the `context.playground` method within a Hatchet step to expose configuration options that can be overridden from the Hatchet dashboard during manual retries. It allows for dynamic adjustment of step behavior without code redeployment, particularly useful for scenarios like prompt engineering in LLM applications. The step retrieves input from the workflow and a potentially overridden prompt from the playground, uses them to get user feedback, processes it, and returns a result.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/manual.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Step, Context } from \"@hatchet-dev/typescript-sdk\";\n\ninterface MyStepInput {\n  message: string;\n  // other input fields...\n}\n\ninterface MyStepOutput {\n  result: string;\n  // other output fields...\n}\n\nconst myStep: Step<MyStepInput, MyStepOutput> = async (\n  context: Context<MyStepInput>,\n) => {\n  const { message } = context.workflowInput();\n\n  const defaultPrompt = \"Please provide your feedback:\";\n\n  // Expose the prompt variable through context.playground\n  const prompt = context.playground(\"prompt\", defaultPrompt);\n\n  // Use the prompt variable in your step logic\n  const userFeedback = await getUserFeedback(message, prompt);\n\n  // Process the user feedback and return the result\n  const result = processUserFeedback(userFeedback);\n\n  return { result };\n};\n\nexport default myStep;\n```\n\n----------------------------------------\n\nTITLE: Bulk Spawning: Child Workflows in Python\nDESCRIPTION: This Python snippet shows how to spawn child workflows in bulk using `context.spawn_workflows`. It constructs a list of workflow requests, each defining the workflow name, input, key, and options.  The `hatchet` library is required and the workflow is decorated with `@hatchet.workflow` and the step with `@hatchet.step`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\"fanout:create\")\nclass Parent:\n    @hatchet.step()\n    def spawn(self, context: Context):\n        workflow_requests = [\n            {\n                \"workflow\": \"Child\",\n                \"input\": {\"a\": str(i)},\n                \"key\": f\"child{i}\",\n                \"options\": {}\n            }\n            for i in range(10)\n        ]\n\n        # Spawn the workflows in bulk using spawn_workflows\n        context.spawn_workflows(workflow_requests)\n        return {}\n```\n\n----------------------------------------\n\nTITLE: Running a Simple Task in Python\nDESCRIPTION: This code snippet demonstrates how to run a simple Hatchet task in Python. It imports the `simple` task and invokes it using the `run` method, passing an input object. The task is assumed to be defined in a separate file and accessible via the relative import.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/running-your-task.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom .task import simple\n\nsimple.run(\n    input=SimpleInput(Message=\"Hello, World!\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection via Environment Variables (YAML)\nDESCRIPTION: This YAML snippet demonstrates configuring the database connection for Hatchet using environment variables. It sets variables like DATABASE_URL, DATABASE_POSTGRES_HOST, DATABASE_POSTGRES_PORT, DATABASE_POSTGRES_USERNAME, DATABASE_POSTGRES_PASSWORD, DATABASE_POSTGRES_DB_NAME, and DATABASE_POSTGRES_SSL_MODE. Either DATABASE_URL or all DATABASE_POSTGRES_* variables are required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsharedConfig:\n  env:\n    DATABASE_URL: \"postgres://<user>:<password>@<host>:5432/<db-name>?sslmode=disable\"\n    DATABASE_POSTGRES_HOST: \"<host>\"\n    DATABASE_POSTGRES_PORT: \"5432\"\n    DATABASE_POSTGRES_USERNAME: \"<user>\"\n    DATABASE_POSTGRES_PASSWORD: \"<password>\"\n    DATABASE_POSTGRES_DB_NAME: \"<db-name>\"\n    DATABASE_POSTGRES_SSL_MODE: \"disable\"\n```\n\n----------------------------------------\n\nTITLE: Concurrency Strategy with Key - Typescript\nDESCRIPTION: This snippet shows how to set concurrency limits with a key function in Typescript.  It demonstrates configuring concurrency to ensure fair resource allocation and avoid overloading the system. The `slots` option limits the number of concurrent runs per group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/concurrency-rr/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Add Summing Task - TypeScript\nDESCRIPTION: This snippet adds the final task to the workflow in TypeScript, which collects the outputs from all parent tasks and sums them up. It utilizes `ctx.was_skipped` to handle cases where tasks were skipped due to conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_19\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Async Safe Task Example\nDESCRIPTION: This code snippet demonstrates a simple asynchronous task that uses `asyncio.sleep` to simulate an operation without blocking the event loop. It showcases the correct way to introduce delays in an asyncio environment.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/asyncio.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nasync def my_task() -> int:\n    await asyncio.sleep(5)\n\n    return 42\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic RAG Workflow in Python\nDESCRIPTION: This code defines a basic Retrieval-Augmented Generation (RAG) workflow in Python using Hatchet. It consists of four steps: `start`, `load_docs`, `reason_docs`, and `generate_response`. Each step is decorated with `@hatchet.step()` and defines the logic for that step. The `parents` argument specifies the dependencies between steps. The workflow is triggered by the `question:create` event.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workflows.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n    @hatchet.step()\n    def start(self, context: Context):\n        return {\n            \"status\": \"starting...\",\n        }\n    @hatchet.step()\n    def load_docs(self, context: Context):\n        # Load the relevant documents\n        return {\n            \"status\": \"docs loaded\",\n            \"docs\": text_content,\n        }\n\n    @hatchet.step(parents=[\"load_docs\"])\n    def reason_docs(self, ctx: Context):\n        docs = ctx.step_output(\"load_docs\")['docs']\n        # Reason about the relevant docs\n\n        return {\n            \"status\": \"writing a response\",\n            \"research\": research,\n        }\n\n    @hatchet.step(parents=[\"reason_docs\"])\n    def generate_response(self, ctx: Context):\n        docs = ctx.step_output(\"reason_docs\")['research']\n        # Reason about the relevant docs\n\n        return {\n            \"status\": \"complete\",\n            \"message\": message,\n        }\n\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow with Additional Metadata - Typescript\nDESCRIPTION: This snippet shows how to trigger a workflow run with additional metadata using the Typescript client. It configures the 'source' metadata key with the value 'api'. The workflow is identified by the 'user-workflow' name and includes a 'userId' in the input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflowRunId = await hatchet.admin.run_workflow(\n  'user-workflow',\n  {\n    userId: '1234',\n  },\n  {\n    additionalMetadata: {\n      source: 'api', // Arbitrary key-value pair\n    },\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Defining a simple Hatchet workflow in Go\nDESCRIPTION: This Go code defines a basic Hatchet workflow with one step. It uses the `github.com/hatchet-dev/hatchet` packages to define the workflow and registers it with a worker. Dependencies: github.com/joho/godotenv, github.com/hatchet-dev/hatchet.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_9\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/joho/godotenv\"\n\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/cmdutils\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype stepOutput struct{}\n\nfunc main() {\n\terr := godotenv.Load()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tc, err := client.New()\n\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating client: %v\", err))\n\t}\n\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithMaxRuns(1),\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating worker: %v\", err))\n\t}\n\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tName:        \"simple-workflow\",\n\t\t\tDescription: \"Simple one-step workflow.\",\n\t\t\tOn:          worker.Events(\"simple\"),\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOutput, err error) {\n\t\t\t\t\tfmt.Println(\"executed step 1\")\n\n\t\t\t\t\treturn &stepOutput{}, nil\n\t\t\t\t},\n\t\t\t\t).SetName(\"step-one\"),\n\t\t\t},\n\t\t},\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error registering workflow: %v\", err))\n\t}\n\n\tinterruptCtx, cancel := cmdutils.InterruptContextFromChan(cmdutils.InterruptChan())\n\tdefer cancel()\n\n\tcleanup, err := w.Start()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error starting worker: %v\", err))\n\t}\n\n\t<-interruptCtx.Done()\n\tif err := cleanup(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Simple Worker Path Definition\nDESCRIPTION: This JavaScript snippet defines a constant object `SimpleWorker` which stores the relative path to a Python worker file.  This path is used to retrieve the code snippet, presumably for display or execution in the Hatchet Cloud environment. It relies on modules imported at the top of the file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport const SimpleWorker = {\n  path: \"examples/simple/worker.py\",\n};\n```\n\n----------------------------------------\n\nTITLE: Creating a Postgres Database and User for Hatchet (SQL)\nDESCRIPTION: This SQL snippet creates a new Postgres database named `hatchet` and a user also named `hatchet`. It grants the user permissions to write and modify schemas on the newly created database. This is necessary for Hatchet to run database migrations.  It's crucial to change the username/password for production usage.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate database hatchet;\n\ncreate role hatchet\nwith\n    login password 'hatchet';\n\ngrant hatchet to postgres;\n\nalter database hatchet owner to hatchet;\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum WAL Size for PostgreSQL Performance\nDESCRIPTION: This snippet configures the `max_wal_size` parameter in PostgreSQL to potentially improve performance when sufficient disk capacity is available. Increasing the WAL size allows for more write operations to be buffered before being flushed to disk, which can reduce I/O contention and improve overall database throughput.  However, it also increases the potential for data loss in the event of a crash, so it should be used judiciously.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nmax_wal_size=15040\n```\n\n----------------------------------------\n\nTITLE: Running a Task and Awaiting Result - Python\nDESCRIPTION: Demonstrates how to run a task and wait for its result in Python using the `run` method of the `Task` object. This blocks until the task completes and returns the result. It also shows how to use `aio_run` and `await` the result.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={SimplePy} target=\"Running a Task\" />\n```\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={SimplePy} target=\"Running a Task AIO\" />\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Declaration (Go)\nDESCRIPTION: This snippet demonstrates how to declare static rate limits in Go, using the `Admin` client to set the rate limit. It involves defining the key, limit, and duration for the rate limit. Requires the Hatchet Go SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={RateLimitGo} target=\"Upsert Rate Limit\" />\n```\n\n----------------------------------------\n\nTITLE: Defining On-Failure Task in TypeScript\nDESCRIPTION: This snippet demonstrates how to define an on-failure task within a Hatchet workflow using TypeScript. It showcases the syntax and structure for specifying the on-failure function, which will be executed if any main task in the workflow fails. The snippet is located in `src/v1/examples/on_failure/workflow.ts` and targets the \"On Failure Task\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/on-failure-tasks.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/on_failure/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Async Safe Task with loop.run_in_executor\nDESCRIPTION: This code snippet shows how to execute a blocking operation (`time.sleep`) within an asyncio task using `loop.run_in_executor`.  This allows the blocking code to run in a separate thread, preventing the asyncio event loop from being blocked, so other tasks can execute concurrently.  `asyncio.get_event_loop()` is used to get the event loop.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/asyncio.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nasync def my_task() -> int:\n    loop = asyncio.get_event_loop()\n\n    await loop.run_in_executor(None, time.sleep, 5)\n\n    return 42\n```\n\n----------------------------------------\n\nTITLE: Async Blocking Task Example\nDESCRIPTION: This code snippet illustrates an asynchronous task that will block the asyncio event loop due to the usage of `time.sleep`. It serves as a negative example, highlighting the importance of avoiding blocking operations in asyncio functions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/asyncio.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nasync def my_task() -> int:\n    time.sleep(5)\n\n    return 42\n```\n\n----------------------------------------\n\nTITLE: Concurrency Strategy with Key - Python\nDESCRIPTION: This snippet shows how to set concurrency limits with a key function in Python. It demonstrates configuring concurrency to ensure fair resource allocation and avoid overloading the system. The `slots` option limits the number of concurrent runs per group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/concurrency.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/concurrency_limit_rr/worker.py\n```\n\n----------------------------------------\n\nTITLE: Defining Event Triggered Workflow - Go\nDESCRIPTION: Registers a Hatchet workflow that is triggered by the `user:created` event. The workflow includes a single step that prints the current time to the console. Requires the `hatchet-dev/hatchet/worker` package. The `On` property specifies the event that triggers the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"post-user-create\",\n        On: worker.Event(\"user:created\"),\n        Description: \"Cron workflow example.\",\n        Steps: []*worker.WorkflowStep{\n            {\n                Function: func(ctx context.Context) error {\n                    fmt.Println(\"triggered at:\", time.Now())\n                    return nil\n                },\n            },\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Task with Results in Hatchet (TypeScript)\nDESCRIPTION: This snippet illustrates how to run tasks and workflows and interact with the returned object directly. It provides an example of how to execute a task and obtain results using the new SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const SimpleRun = {\n  path: \"src/v1/examples/simple/run.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Configure Data Seeding in Helm Chart (YAML)\nDESCRIPTION: This snippet demonstrates configuring data seeding for Hatchet, including setting default admin credentials and tenant information via the `seed` section.  It uses environment variables to define the default admin email and password as well as tenant configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-helm-configuration.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nseed:\n  defaultAdminEmail: \"admin@example.com\" # in exposed/production environments, change this to a valid email\n  defaultAdminPassword: \"Admin123!!\" # in exposed/production environments, change this to a secure password\n  env:\n    ADMIN_NAME: \"Admin User\"\n    DEFAULT_TENANT_NAME: \"Default\"\n    DEFAULT_TENANT_SLUG: \"default\"\n    DEFAULT_TENANT_ID: \"707d0855-80ab-4e1f-a156-f1c4546cbf52\"\n```\n\n----------------------------------------\n\nTITLE: Defining a Basic RAG Workflow in Typescript\nDESCRIPTION: This code defines a basic RAG workflow in Typescript using Hatchet. It consists of four steps: `start`, `load_docs`, `reason_docs`, and `generate_response`.  The `parents` property specifies the dependencies between steps.  Each step defines an asynchronous `run` function, which dictates the steps function.  The workflow is triggered by the `question:create` event.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workflows.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\nconst workflow: Workflow = {\n  id: 'basic-rag-workflow',\n  on: {\n    event: 'question:create',\n  },\n  steps: [\n    {\n      name: 'start',\n      run: async (ctx) => {\n        return {\n            \"status\": \"starting...\",\n        }\n      },\n    },\n    {\n      name: 'load_docs',\n      parents: ['start'],\n      run: async (ctx) => {\n        // Load the relevant documents\n        return {\n            \"status\": \"docs loaded\",\n            \"docs\": text_content,\n        }\n      },\n    }\n    {\n      name: 'reason_docs',\n      parents: ['load_docs'],\n      run: (ctx) => {\n        const docs = ctx.stepOutput(\"load_docs\")['docs']\n        // Reason about the relevant docs\n\n        return {\n            \"status\": \"writing a response\",\n            \"research\": research,\n        }\n      },\n    },\n    {\n      name: 'generate_response',\n      parents: ['reason_docs'],\n      run: (ctx) => {\n        const research = ctx.stepOutput(\"reason_docs\")['research']\n        // Generate a message\n        return {\n            \"status\": \"complete\",\n            \"message\": message,\n        }\n      },\n    },\n\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Creating/Deleting/Listing Cron Trigger - Go\nDESCRIPTION: These snippets show how to programmatically create, delete, and list cron triggers using the Hatchet SDK in Go. This approach allows for dynamically setting the cron schedule of a task using the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_6\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/run/cron.go\n```\n\n----------------------------------------\n\nTITLE: Declaring Durable Event in Typescript\nDESCRIPTION: This snippet demonstrates how to declare a durable event in Typescript using Hatchet. It uses the `WaitForEvent` utility on the `DurableContext` object to wait for an event to occur before continuing the workflow. The code is located in the `src/v1/examples/durable-event/workflow.ts` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={DurableTs} target=\"Durable Event\" />\n```\n\n----------------------------------------\n\nTITLE: Non-retryable task - Python\nDESCRIPTION: This snippet demonstrates how to bypass pre-configured retry logic in Python using the `NonRetryable` exception. If a task raises this exception, it will not be retried, regardless of the retry configuration.  This is useful when retrying the task is not safe or effective.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nexamples/non_retryable/worker.py\n```\n\n----------------------------------------\n\nTITLE: Retries with Count - Typescript\nDESCRIPTION: This snippet demonstrates accessing the current retry count within a running task in TypeScript. It leverages the `retryCount` method available in the task context to determine the number of retries.  This information can be used to modify the task's execution based on the retry attempt.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/retries/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Self-cancelling task in Python\nDESCRIPTION: This Python snippet demonstrates how to use `Context.cancel` or `Context.aio_cancel` to cancel the task. This method will set the `exit_flag` to `True` and will notify the engine that it should cancel the task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cancellation.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n```python\n    async def my_task(context):\n        # Perform some initial setup\n        print(\"Task started...\")\n\n        # Simulate a long-running operation\n        await asyncio.sleep(5)\n\n        # Check if the task has been cancelled\n        if context.exit_flag:\n            print(\"Task cancelled, exiting...\")\n            return\n\n        # Perform some cleanup\n        print(\"Task completed successfully!\")\n```\n```\n\n----------------------------------------\n\nTITLE: Setting Default Workflow Priority - TypeScript\nDESCRIPTION: This snippet demonstrates how to set a default priority for a Hatchet workflow in TypeScript.  This will assign the same default priority to all runs of this workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/priority/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Setting Runtime Priority - TypeScript\nDESCRIPTION: This snippet demonstrates how to set the priority of a Hatchet run when triggering it in TypeScript. Setting the priority at runtime allows you to prioritize specific runs over others.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/priority/run.ts\n```\n\n----------------------------------------\n\nTITLE: Add Branching Logic - Go\nDESCRIPTION: This snippet adds branching logic to the workflow in Go using `ParentCondition` and `skip_if`. It checks if the output of an upstream task is greater or less than 50, and only one of the two branches will run based on this condition. Demonstrates complex conditional routing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_14\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration\nDESCRIPTION: This YAML configuration defines the services required to run Hatchet using Docker Compose. It includes services for Postgres, RabbitMQ, migration, setup-config, hatchet-engine, and hatchet-dashboard. The configuration specifies image versions, environment variables, port mappings, volumes, and dependencies for each service.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/docker-compose.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nservices:\n  postgres:\n    image: postgres:15.6\n    command: postgres -c 'max_connections=1000'\n    restart: always\n    hostname: \"postgres\"\n    environment:\n      - POSTGRES_USER=hatchet\n      - POSTGRES_PASSWORD=hatchet\n      - POSTGRES_DB=hatchet\n    ports:\n      - \"5435:5432\"\n    volumes:\n      - hatchet_postgres_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -d hatchet -U hatchet\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n  rabbitmq:\n    image: \"rabbitmq:3-management\"\n    hostname: \"rabbitmq\"\n    ports:\n      - \"5673:5672\" # RabbitMQ\n      - \"15673:15672\" # Management UI\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n    volumes:\n      - \"hatchet_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf\" # Configuration file mount\n    healthcheck:\n      test: [\"CMD\", \"rabbitmqctl\", \"status\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n  migration:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-migrate:latest\n    command: /hatchet/hatchet-migrate\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n  setup-config:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-admin:latest\n    command: /hatchet/hatchet-admin quickstart --skip certs --generated-config-dir /hatchet/config --overwrite=false\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@rabbitmq:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost:8080\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n      SERVER_DEFAULT_ENGINE_VERSION: \"V1\"\n      SERVER_INTERNAL_CLIENT_INTERNAL_GRPC_BROADCAST_ADDRESS: hatchet-engine:7077\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n    depends_on:\n      migration:\n        condition: service_completed_successfully\n      rabbitmq:\n        condition: service_healthy\n      postgres:\n        condition: service_healthy\n  hatchet-engine:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-engine:latest\n    command: /hatchet/hatchet-engine --config /hatchet/config\n    restart: on-failure\n    depends_on:\n      setup-config:\n        condition: service_completed_successfully\n      migration:\n        condition: service_completed_successfully\n    ports:\n      - \"7077:7070\"\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n  hatchet-dashboard:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-dashboard:latest\n    command: sh ./entrypoint.sh --config /hatchet/config\n    ports:\n      - 8080:80\n    restart: on-failure\n    depends_on:\n      setup-config:\n        condition: service_completed_successfully\n      migration:\n        condition: service_completed_successfully\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n\nvolumes:\n  hatchet_postgres_data:\n  hatchet_rabbitmq_data:\n  hatchet_rabbitmq.conf:\n  hatchet_config:\n  hatchet_certs:\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Trigger in Workflow - Python (Async)\nDESCRIPTION: Defines a workflow with a cron schedule using Python (asynchronous). This snippet showcases how to configure the `on cron` property in the workflow definition to specify the cron expression.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/workflow-definition.py\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Payload - Python\nDESCRIPTION: Demonstrates how to access the event payload within a Hatchet workflow step in Python.  The `context.workflow_input()` method is used to retrieve the event payload. The `hatchet_sdk` library is required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:created\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        event_payload = context.workflow_input()\n        # Use the event payload data in your step logic\n```\n\n----------------------------------------\n\nTITLE: Querying Success and Failure Rates (PromQL)\nDESCRIPTION: This PromQL query retrieves the rates of successful and failed tasks over a 5-minute window using the `hatchet_succeeded_tasks_total` and `hatchet_failed_tasks_total` metrics, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_3\n\nLANGUAGE: promql\nCODE:\n```\nrate(hatchet_succeeded_tasks_total[5m])\nrate(hatchet_failed_tasks_total[5m])\n```\n\n----------------------------------------\n\nTITLE: Checking for Cancellation in a Step (Typescript)\nDESCRIPTION: This code demonstrates how to check for cancellation signals within a Hatchet workflow step using Typescript's `AbortController` and `AbortSignal`. It shows how to use the `aborted` property and the `addEventListener` method to handle cancellation events. It depends on the `Step` and `Context` types which are part of the Hatchet framework.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/cancellation.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst myStep: Step = async (context: Context) => {\n  const { signal } = context.controller;\n\n  if (signal.aborted) {\n    // The step has been canceled\n    // Perform any necessary cleanup or termination logic\n    return;\n  }\n\n  // Rest of the step logic\n  // ...\n\n  // You can also register an event listener for cancellation\n  signal.addEventListener(\"abort\", () => {\n    // Cancellation signal received\n    // Perform any necessary cleanup or termination logic\n  });\n\n  // Perform asynchronous operations\n  // ...\n};\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with CEL Expression (Python)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Python using a CEL expression to define the concurrency group. It sets the maximum number of concurrent runs to 5 and uses the `input.group` expression to determine the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom hatchet_sdk import ConcurrencyLimitStrategy, ConcurrencyExpression\n\n@hatchet.workflow(\n  on_events=[\"concurrency-test\"],\n  concurrency=ConcurrencyExpression(\n    expression=\"input.group\",\n    max_runs=5,\n    limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n  )\n)\nclass ConcurrencyDemoWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Execution Timeout Task Definition in Python\nDESCRIPTION: This Python snippet defines a Hatchet worker that demonstrates the usage of execution timeouts. It shows how to configure a task with an execution timeout. The target `ExecutionTimeout` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/timeout/worker.py\n```\n\n----------------------------------------\n\nTITLE: Registering Workflows with Worker\nDESCRIPTION: This snippet demonstrates registering multiple workflows with a Hatchet worker. It first initializes a Hatchet client and defines two example workflows, then registers them with the worker using `worker.registerWorkflow`. Finally, it starts the worker to begin processing tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/worker.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflow1: Workflow = {\n  id: \"workflow-1\",\n  description: \"Example workflow 1\",\n  steps: [\n    {\n      name: \"step-1-workflow-1\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        console.log(\"step-1-workflow-1\");\n        return {\n          \"step-1-output\": \"results\",\n        };\n      },\n    },\n  ],\n};\n\nconst workflow2: Workflow = {\n  id: \"workflow-2\",\n  description: \"Example workflow 2\",\n  steps: [\n    {\n      name: \"step-1-workflow-2\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        console.log(\"step-1-workflow-2\");\n        return {\n          \"step-1-output\": \"results\",\n        };\n      },\n    },\n  ],\n};\n\nasync function main() {\n  const worker = await hatchet.worker(\"example-worker\");\n  await worker.registerWorkflow(workflow1);\n  await worker.registerWorkflow(workflow2);\n  worker.start();\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Create a Workflow with Conditions - Go\nDESCRIPTION: This snippet demonstrates how to create a workflow with conditional logic in Go using Hatchet V1. It leverages `wait_for`, `skip_if`, and `cancel_if` to control task execution based on conditions like sleep duration, events, and parent task outputs. The workflow showcases conditional branching and task skipping.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Bulk Spawn Workflows with Hatchet\nDESCRIPTION: This TypeScript snippet showcases spawning child workflows from a parent workflow using the Hatchet TypeScript SDK. It defines a 'parent-workflow' that, upon receiving a 'fanout:create' event, spawns 10 'child-workflow' instances with different inputs and metadata. The `ctx.spawnWorkflows` function handles the bulk spawning operation. A maximum limit of 1000 workflows per request is enforced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        const workflowRequests = Array.from({ length: 10 }, (_, i) => ({\n          workflow: \"child-workflow\",\n          input: { input: `child-input-${i}` },\n          options: { additionalMetadata: { childKey: `child-${i}` } },\n        }));\n\n        const spawnedWorkflows = await ctx.spawnWorkflows<string, string>(\n          workflowRequests,\n        );\n\n        return spawnedWorkflows;\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Initializing a Hatchet Worker in Go\nDESCRIPTION: This code snippet demonstrates how to initialize a Hatchet worker in Go. It creates a Hatchet client and then uses it to create a new worker. The worker is then started with a background context.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/creating-a-worker.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    \"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\nfunc main() {\n    c, err := client.New(\n        // this is the GRPC host and port of the Hatchet instance\n\t\tclient.WithHostPort(\"127.0.0.1\", 7077),\n\t)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n    w, err := worker.NewWorker(\n        worker.WithClient(c),\n    )\n\n    if err != nil {\n        panic(err)\n    }\n\n    // ... workflow code\n\n    // start the worker\n    w.Start(context.Background())\n}\n```\n\n----------------------------------------\n\nTITLE: Bulk Push Events with Hatchet\nDESCRIPTION: This Python snippet demonstrates how to use the Hatchet SDK to push multiple events in a single bulk request. It initializes the Hatchet client, creates a list of events with payloads and metadata, and then calls the `bulk_push` method. A maximum limit of 1000 events per request is enforced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nevents: List[BulkPushEventWithMetadata] = [\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 1\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user123\"},\n    },\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 2\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user456\"},\n    },\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 3\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user789\"},\n    },\n]\n\nresult = hatchet.client.event.bulk_push(events)\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client in Python\nDESCRIPTION: This snippet instantiates a Hatchet client, using the hatchet_sdk library and loads environment variables using dotenv. The client is initialized with debug mode enabled. It requires the hatchet_sdk and dotenv packages to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\nfrom dotenv import load_dotenv\nload_dotenv()  # we'll use dotenv to load the required Hatchet and OpenAI api keys\n\nhatchet = Hatchet(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Creating/Deleting/Listing Cron Trigger - Python Async\nDESCRIPTION: These snippets show how to programmatically create, delete, and list cron triggers using the Hatchet SDK in Python (asynchronous). This approach allows for dynamically setting the cron schedule of a task using the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-async.py\n```\n\n----------------------------------------\n\nTITLE: Analyzing Task Queue Query Plan with EXPLAIN ANALYZE in SQL\nDESCRIPTION: This SQL query uses `EXPLAIN ANALYZE` to examine the execution plan of a task queue query. It identifies the `WindowAgg` operation as a performance bottleneck when processing a large number of enqueued tasks. The query aims to diagnose and optimize the task selection process to improve overall queue performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\n                                                                        QUERY PLAN\n----------------------------------------------------------------------------------------------------------------------------------------------------------\n Update on tasks  (cost=259.44..514.23 rows=1 width=78) (actual time=132.717..154.337 rows=100 loops=1)\n   ->  Hash Join  (cost=259.44..514.23 rows=1 width=78) (actual time=125.423..141.271 rows=100 loops=1)\n         Hash Cond: (tasks.id = t1.id)\n         ->  Seq Scan on tasks  (cost=0.00..254.60 rows=48 width=14) (actual time=0.566..10.550 rows=10000 loops=1)\n               Filter: (status = 'QUEUED'::\"TaskStatus\")\n         ->  Hash  (cost=258.84..258.84 rows=48 width=76) (actual time=124.155..124.213 rows=100 loops=1)\n               Buckets: 1024  Batches: 1  Memory Usage: 18kB\n               ->  Subquery Scan on t1  (cost=258.24..258.84 rows=48 width=76) (actual time=123.500..123.791 rows=100 loops=1)\n                     ->  Limit  (cost=258.24..258.36 rows=48 width=52) (actual time=122.951..123.066 rows=100 loops=1)\n                           ->  Sort  (cost=258.24..258.36 rows=48 width=52) (actual time=122.830..122.866 rows=100 loops=1)\n                                 Sort Key: (row_number() OVER (?)), t.id\n                                 Sort Method: top-N heapsort  Memory: 36kB\n                                 ->  WindowAgg  (cost=255.94..256.90 rows=48 width=52) (actual time=77.962..111.874 rows=10000 loops=1)\n                                       ->  Sort  (cost=255.94..256.06 rows=48 width=44) (actual time=76.751..79.917 rows=10000 loops=1)\n                                             Sort Key: t.group_key, t.id\n                                             Sort Method: quicksort  Memory: 1010kB\n                                             ->  Seq Scan on tasks t  (cost=0.00..254.60 rows=48 width=44) (actual time=0.093..15.310 rows=10000 loops=1)\n                                                   Filter: (status = 'QUEUED'::\"TaskStatus\")\n Planning Time: 37.690 ms\n Execution Time: 159.286 ms\n(20 rows)\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Schedule Timeout in Python\nDESCRIPTION: This snippet demonstrates how to define a schedule timeout for a Hatchet workflow using Python. The `schedule_timeout` parameter in the `@hatchet.workflow` decorator specifies the maximum time a step can wait in the queue before being cancelled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(schedule_timeout=\"2m\")\nclass TimeoutWorkflow:\n  # ...\n```\n\n----------------------------------------\n\nTITLE: Retrieving Worker Metrics via cURL\nDESCRIPTION: This command retrieves metrics from a Hatchet worker by sending a request to the /metrics endpoint.  It expects the worker to be running on localhost:8001 with the healthcheck enabled.  The response is in Prometheus exposition format.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-healthchecks.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl localhost:8001/metrics\n\n# HELP python_gc_objects_collected_total Objects collected during gc\n# TYPE python_gc_objects_collected_total counter\npython_gc_objects_collected_total{generation=\"0\"} 18782.0\npython_gc_objects_collected_total{generation=\"1\"} 4907.0\npython_gc_objects_collected_total{generation=\"2\"} 244.0\n# HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC\n# TYPE python_gc_objects_uncollectable_total counter\npython_gc_objects_uncollectable_total{generation=\"0\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"1\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"2\"} 0.0\n# HELP python_gc_collections_total Number of times this generation was collected\n# TYPE python_gc_collections_total counter\npython_gc_collections_total{generation=\"0\"} 308.0\npython_gc_collections_total{generation=\"1\"} 27.0\npython_gc_collections_total{generation=\"2\"} 2.0\n# HELP python_info Python platform information\n# TYPE python_info gauge\npython_info{implementation=\"CPython\",major=\"3\",minor=\"10\",patchlevel=\"15\",version=\"3.10.15\"} 1.0\n# HELP hatchet_worker_status Current status of the Hatchet worker\n# TYPE hatchet_worker_status gauge\nhatchet_worker_status 1.0\n```\n\n----------------------------------------\n\nTITLE: Triggering a Hatchet task - Python\nDESCRIPTION: This snippet demonstrates how to trigger a Hatchet task from another part of the codebase.  The input is typed and can be statically type checked, and is also validated by Pydantic at runtime. Various `.run` methods are available, offering type-safe execution and Pydantic validation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={ChildTrigger} target=\"Running a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Triggering Task Run with Additional Metadata - Typescript\nDESCRIPTION: This snippet demonstrates how to trigger a task run with additional metadata using the Hatchet TypeScript client. It uses the `simple.run` method with an options object that includes an `additionalMetadata` property. The `additionalMetadata` property accepts a key-value pair represented as a JavaScript object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst taskRunId = await simple.run(\n  {\n    userId: '1234',\n  },\n  {\n    additionalMetadata: {\n      source: 'api', // Arbitrary key-value pair\n    },\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Timeout Step Definition in Go\nDESCRIPTION: This Go snippet shows how to define a Hatchet step with timeouts. It uses the `Timeout` option when defining a step. The target `TimeoutStep` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/timeout/main.go\n```\n\n----------------------------------------\n\nTITLE: Create a Workflow with Conditions - TypeScript\nDESCRIPTION: This snippet demonstrates how to create a workflow with conditional logic in TypeScript using Hatchet V1. It leverages `wait_for`, `skip_if`, and `cancel_if` to control task execution based on conditions like sleep duration, events, and parent task outputs. The workflow showcases conditional branching and task skipping.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for Python with pip\nDESCRIPTION: This Dockerfile builds a Python Hatchet worker using pip for dependency management. It sets the working directory, copies the requirements file, installs dependencies using pip, copies the application code, and defines the command to run the worker using Python.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/docker.mdx#_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM python:3.13-slim\n\nENV PYTHONUNBUFFERED=1 \\\n HATCHET_ENV=production\n\nWORKDIR /app\n\nCOPY requirements.txt .\n\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . /app\n\nCMD [\"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Defining Cron in Task Definition - Typescript\nDESCRIPTION: This snippet demonstrates how to define a cron schedule within a task definition using TypeScript. The `on` property specifies the cron expression, determining when the task is triggered. This approach statically defines the cron schedule as part of the task's configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/on_cron/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Configuring a Hatchet Worker with Sentry Error Alerter in Go\nDESCRIPTION: This code snippet demonstrates how to configure a Hatchet worker with a Sentry error alerter. It initializes a Sentry alerter and then passes it to the worker using the `worker.WithErrorAlerter` option. The Sentry DSN and environment variables are expected to be set.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/creating-a-worker.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport (\n\t\"os\"\n\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/errors/sentry\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\nfunc main() {\n    // client initialization code...\n\n    // create the sentry alerter\n    sentryAlerter, err := sentry.NewSentryAlerter(&sentry.SentryAlerterOpts{\n\t\tDSN:         os.Getenv(\"SENTRY_DSN\"),\n\t\tEnvironment: os.Getenv(\"SENTRY_ENVIRONMENT\"),\n\t})\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tclient,\n\t\t),\n        // call the `WithErrorAlerter` method to set up the sentry alerter\n\t\tworker.WithErrorAlerter(sentryAlerter),\n\t)\n}\n```\n\n----------------------------------------\n\nTITLE: Retries with Backoff - Go\nDESCRIPTION: This snippet shows how to implement exponential backoff retries in Go. Using exponential backoff increases the delay between each retry attempt.  This prevents overwhelming the potentially failing service, allowing it sufficient time to recover.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_8\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/retries.go\n```\n\n----------------------------------------\n\nTITLE: Streaming Data from a Step Context\nDESCRIPTION: This code snippet demonstrates how to stream data from within a Hatchet step using `context.put_stream`. It takes a string as input and streams it. This allows for real-time updates or debugging information to be sent from a step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step()\ndef step1(self, context: Context):\n    # Stream some data from the step context\n    context.put_stream('hello from step1')\n    # continue with the step run...\n    return {\"step1\": \"results\"}\n```\n\n----------------------------------------\n\nTITLE: Refreshing Step Timeout in Typescript\nDESCRIPTION: This snippet shows how to refresh the timeout for a running Hatchet step using Typescript. The `ctx.refreshTimeout` function is called with the desired extension time, effectively adding time to remaining time.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst myStep: CreateStep<any, any> = {\n  name: \"my-step\",\n  timeout: \"30s\",\n  run: async (ctx) => {\n    await sleep(20 * 1000);\n    ctx.refreshTimeout(\"15s\");\n    await sleep(10 * 1000);\n    return { step1: \"step1 results!\" };\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Triggering Task Run with Additional Metadata - Go\nDESCRIPTION: This snippet demonstrates how to trigger a task run with additional metadata using the Hatchet Go client. It uses the `c.Admin().RunWorkflow` method along with `client.WithRunMetadata` to attach metadata to the task run. The metadata is passed as a `map[string]interface{}` to the `client.WithRunMetadata` function.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\ntaskRunId, err := c.Admin().RunWorkflow(\n    \"user-task\",\n    &userCreateEvent{\n        UserID: \"1234\",\n    },\n    client.WithRunMetadata(map[string]interface{}{\n        \"source\": \"api\", // Arbitrary key-value pair\n    }),\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Input Data (Python)\nDESCRIPTION: This code demonstrates how to access workflow input data within a Hatchet step using the `context.workflow_input()` method. The `step1` function retrieves and prints the workflow input data received when the `user:create` event triggers the `MyWorkflow` workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context : Context):\n        print(\"executed step1\", context.workflow_input())\n        pass\n```\n\n----------------------------------------\n\nTITLE: Creating continuous aggregate for metric_events\nDESCRIPTION: This SQL code creates a materialized view, `metric_events_summary`, as a continuous aggregate. It aggregates metrics from the `metric_events` hypertable into one-minute buckets, counting successful and failed events. The `time_bucket` function groups events by minute. The index on `tenant_id`, `resource_id`, and `minute` improves query performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE MATERIALIZED VIEW metric_events_summary\n   WITH (timescaledb.continuous)\n   AS\n      SELECT\n        time_bucket('1 minute', created_at) AS minute,\n        tenant_id,\n        resource_id,\n        COUNT(*) FILTER (WHERE event_type = 'SUCCEEDED') AS succeeded_count,\n        COUNT(*) FILTER (WHERE event_type = 'FAILED') AS failed_count\n      FROM metric_events\n      GROUP BY minute, tenant_id, resource_id\n      ORDER BY minute;\n\nCREATE INDEX metric_events_summary__tenantId_resourceId_minute_idx ON metric_events_summary (tenant_id, resource_id, minute);\n```\n\n----------------------------------------\n\nTITLE: Declaring a Parent Task Spawning Child Task (TypeScript)\nDESCRIPTION: This snippet describes the implementation of a parent task that spawns a child task.  The compiler can infer the types of inputs and context for both the parent and child tasks, improving type safety and development experience.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const FanoutWorker = {\n  path: \"src/v1/examples/child_workflows/workflow.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Run Workflow on Event in Go\nDESCRIPTION: This code snippet illustrates how to configure a Hatchet workflow to run when a specific event occurs in Go. The `on_events` property is used to specify the event trigger. The example uses the `EventGo` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/on-event.go\n```\n\n----------------------------------------\n\nTITLE: Add Base Task to Workflow - Python\nDESCRIPTION: This snippet adds a basic task to the workflow in Python, which outputs a random number. This serves as the initial task in the conditional workflow example and will be a parent to other tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Logging with Context.Log Method (Python)\nDESCRIPTION: Shows how to use the `context.log` method to log messages directly from within a workflow task. This method is available on the `Context` object passed to each task. Limited to 1000 log lines per task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={LoggerWorkflowPy} target=\"ContextLogger\" />\n```\n\n----------------------------------------\n\nTITLE: Accessing Parent Task Outputs - Go\nDESCRIPTION: This snippet demonstrates how to access the output of a parent task within a task that has parent dependencies in Go.  It uses the `ctx.ParentOutput()` method, passing in the parent task and a pointer to a variable where the output should be stored. It also includes error handling.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\n// Inside a task with parent dependencies\nvar parentOutput ParentOutputType\nerr := ctx.ParentOutput(parentTask, &parentOutput)\nif err != nil {\n    return nil, err\n}\n```\n\n----------------------------------------\n\nTITLE: Enqueuing a Workflow (Fire and Forget) - Typescript\nDESCRIPTION: This snippet shows how to enqueue a workflow in Typescript using Hatchet. It uses the `GithubSnippet` component to include the code from the file specified by `SimpleTs`. The code enqueues a workflow and returns a `WorkflowRunRef` without waiting for completion, enabling 'fire and forget' execution.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet\n      src={SimpleTs}\n      target=\"Enqueuing a Workflow (Fire and Forget)\"\n    />\n```\n\n----------------------------------------\n\nTITLE: Dynamic Rate Limit Configuration (Go)\nDESCRIPTION: This snippet demonstrates configuring dynamic rate limits in Go.  Both `key` and `KeyExpr` must be set, and `LimitValueExpr` must be a CEL expression.  This allows rate limits to be dynamically adjusted based on runtime conditions.  It uses the Hatchet Go SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={RateLimitGo} target=\"Dynamic Rate Limit\" />\n```\n\n----------------------------------------\n\nTITLE: Non Retryable Error - Go\nDESCRIPTION: This snippet details how to circumvent pre-configured retry logic for a task in Go by raising a `NonRetryable` error. When this error is encountered, the task will not be retried. This capability is valuable in situations where retrying the task would be detrimental or ineffective.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_11\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/non-retryable-error.go\n```\n\n----------------------------------------\n\nTITLE: Setting Default Workflow Priority - Python\nDESCRIPTION: This snippet shows how to set a default priority for a Hatchet workflow in Python. The default priority applies to all runs and tasks within the workflow unless overridden.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/priority/worker.py\n```\n\n----------------------------------------\n\nTITLE: Declaring a Task in Typescript\nDESCRIPTION: This TypeScript snippet shows how to check for cancellation by accessing the `cancelled` property of the `Context`, which is a boolean value indicating whether the task has been cancelled or not. It also shows how to abort if the task is cancelled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cancellation.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n    hatchet.task('long-running-task', async (context) => {\n      const interval = setInterval(() => {\n        if (context.cancelled) {\n          clearInterval(interval);\n          console.log('Task cancelled!');\n          return;\n        }\n        console.log('Task running...');\n      }, 1000);\n    });\n```\n```\n\n----------------------------------------\n\nTITLE: Dockerfile Example for GPU Workloads\nDESCRIPTION: This Dockerfile sets up an environment for running GPU-accelerated applications with CUDA. It installs the necessary CUDA toolkit, libraries, and sets up the application's working directory and entrypoint. It uses Ubuntu 22.04 as the base image and installs CUDA 12.2.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Base image\nFROM ubuntu:22.04\n\n# Install CUDA and required libraries\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    cuda-nvcc-12-2 \\\n    libcublas-12-2 \\\n    libcudnn8 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Your application setup\nWORKDIR /app\nCOPY . .\n\n# Application entrypoint\nCMD [\"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Bulk Running Tasks in Go\nDESCRIPTION: This Go code snippet demonstrates how to use the `RunBulkNoWait` method directly on the `Task` object to bulk run tasks by passing an array of inputs. This call does not wait for the tasks to complete.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-run.mdx#_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/run/bulk.go\n```\n\n----------------------------------------\n\nTITLE: Spawning Tasks from within a Task - Python\nDESCRIPTION: Demonstrates how to spawn a task from within another task using the `aio_run` method in Python. This associates the runs in the dashboard for easier debugging and allows for complex workflow composition.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={FanoutPy} target=\"Running a Task from within a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Configuring Frontend Ingress for nginx (YAML)\nDESCRIPTION: This YAML snippet configures an ingress for the `frontend` service using `nginx-ingress`. It specifies annotations for proxy settings and cert-manager. It also defines paths for the API and frontend, directing them to the appropriate backend services. Requires `cert-manager` and `nginx-ingress` to be installed on the cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/networking.mdx#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfrontend:\n  ingress:\n    enabled: true\n    ingressClassName: nginx\n    labels: {}\n    annotations:\n      nginx.ingress.kubernetes.io/proxy-body-size: 50m\n      nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n      nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n      nginx.ingress.kubernetes.io/proxy-connect-timeout: \"60\"\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    hosts:\n      - host: hatchet.example.com\n        paths:\n          - path: /api\n            backend:\n              serviceName: hatchet-api\n              servicePort: 8080\n          - path: /\n            backend:\n              serviceName: hatchet-frontend\n              servicePort: 8080\n    tls:\n      - secretName: hatchet-api\n        hosts:\n          - hatchet.example.com\n```\n\n----------------------------------------\n\nTITLE: Setting Up Workers TypeScript\nDESCRIPTION: This snippet shows how to initialize a worker, register a workflow, and start the worker using the Hatchet TypeScript SDK.  It requires a pre-defined `workflow` constant.  The `hatchet` instance must also be initialized via `Hatchet.init()` before this snippet is executed.  The worker executes the provided workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/managed-compute.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  // Initialize worker\n  const worker = await hatchet.worker(\"managed-worker\");\n\n  // Register workflow\n  await worker.registerWorkflow(workflow);\n\n  // Start the worker\n  worker.start();\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Simple Step Retries - Go\nDESCRIPTION: This snippet showcases how to implement a simple retry policy for a task in Go. The `retries` property is set within the task object, defining the number of retry attempts in case of a task failure. This mechanism helps mitigate transient errors and improve the overall reliability of the task execution.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/retries.go\n```\n\n----------------------------------------\n\nTITLE: Retries with Backoff - Typescript\nDESCRIPTION: This snippet demonstrates how to configure exponential backoff for task retries in TypeScript. Exponential backoff increases the delay between retries, providing the failing service more time to recover before the next attempt. This strategy enhances the robustness of the system when dealing with transient issues.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_7\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/retries/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Common Environment Variable Examples\nDESCRIPTION: This block displays a set of commonly used environment variables and their potential values. It includes variables such as NODE_ENV, LOG_LEVEL, API_TIMEOUT, and DATABASE_URL, providing examples for configuring runtime environments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/environment-variables.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Examples of commonly used variables\nNODE_ENV=production\nLOG_LEVEL=info\nAPI_TIMEOUT=30000\nDATABASE_URL=postgresql://user:pass@host:5432/db\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Hatchet with OpenTelemetry\nDESCRIPTION: This code snippet shows how to install the `otel` extra for the `hatchet-sdk`, import the `HatchetInstrumentor`, and instrument Hatchet code with a provided trace provider.  The trace provider must be configured separately according to OpenTelemetry documentation. Requires the `otel` extra to be installed for `hatchet-sdk`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/opentelemetry.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom path.to.your.trace.provider import trace_provider\nfrom hatchet_sdk.opentelemetry.instrumentor import HatchetInstrumentor\n\nHatchetInstrumentor(tracer_provider=trace_provider).instrument()\n```\n\n----------------------------------------\n\nTITLE: Setting Scheduled Priority - Go\nDESCRIPTION: This snippet shows how to define the priority of a Hatchet run scheduled via cron or another trigger in Go. This enables assigning priorities to workflows that are automatically triggered.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/run/priority.go\n```\n\n----------------------------------------\n\nTITLE: Bulk Running Task in Python\nDESCRIPTION: This Python code snippet demonstrates how to use the `aio_run_many` method to bulk run a task in Hatchet.  It utilizes `Workflow.create_bulk_run_item` as a typed helper for creating inputs for each task.  The code shows how to efficiently execute a task multiple times with different inputs.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-run.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/child/bulk.py\n```\n\n----------------------------------------\n\nTITLE: Accessing Environment Variables in JavaScript\nDESCRIPTION: This code snippet shows how to access environment variables in JavaScript using `process.env`. It retrieves the values of the `DATABASE_URL` and `API_KEY` environment variables from the `process.env` object and assigns them to corresponding variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/environment-variables.mdx#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst databaseUrl = process.env.DATABASE_URL;\nconst apiKey = process.env.API_KEY;\n```\n\n----------------------------------------\n\nTITLE: Add Summing Task - Python\nDESCRIPTION: This snippet adds the final task to the workflow in Python, which collects the outputs from all parent tasks and sums them up. It utilizes `ctx.was_skipped` to handle cases where tasks were skipped due to conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_18\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Bulk Push Events with Hatchet\nDESCRIPTION: This TypeScript snippet shows how to bulk push events using the Hatchet TypeScript SDK. It initializes the Hatchet client, creates an array of event objects, each containing a payload and additional metadata, and then calls `hatchet.event.bulkPush` to send the events. The event key is 'user:create'. A maximum limit of 1000 events per request is enforced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst events = [\n  {\n    payload: { test: \"test1\" },\n    additionalMetadata: { user_id: \"user1\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test2\" },\n    additionalMetadata: { user_id: \"user2\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test3\" },\n    additionalMetadata: { user_id: \"user3\", source: \"test\" },\n  },\n];\n\nhatchet.event.bulkPush(\"user:create\", events);\n```\n\n----------------------------------------\n\nTITLE: Defining Rate Limits - Go\nDESCRIPTION: This snippet outlines how to define and apply rate limits to workflow steps using the Hatchet Go SDK. It first defines the rate limit using `c.Admin().PutRateLimit` and then applies it to a step using `SetRateLimit` when registering the workflow. It demonstrates the Go implementation for rate limiting.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/rate-limits.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nerr = c.Admin().PutRateLimit(\"example-limit\", &types.RateLimitOpts{\n    Max:      3,\n    Duration: \"minute\",\n})\n```\n\nLANGUAGE: go\nCODE:\n```\nerr = w.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"rate-limit-workflow\",\n        Description: \"This illustrates rate limiting.\",\n        On: worker.NoTrigger(),\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(StepOne).SetName(\"step-one\").SetRateLimit(\n                worker.RateLimit{\n                    Units: 1,\n                    Key:   \"example-limit\",\n                },\n            ),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Add Base Task to Workflow - Go\nDESCRIPTION: This snippet adds a basic task to the workflow in Go, which outputs a random number. This serves as the initial task in the conditional workflow example and will be a parent to other tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Declaring Workers Hatchet Go\nDESCRIPTION: This snippet shows how to declare workers using the `Worker` method on the `v1` Hatchet client. It demonstrates passing the workflows directly to the `Worker` method and starting the worker in a blocking manner.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-go.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n    v1 \"github.com/hatchet-dev/hatchet/pkg/v1\"\n\t\"github.com/hatchet-dev/hatchet/pkg/v1/worker\"\n\t\"github.com/hatchet-dev/hatchet/pkg/v1/workflow\"\n)\n\nfunc main() {\n\thatchet, err := v1.NewHatchetClient()\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tworker, err := hatchet.Worker(\n\t\tcreate.WorkerOpts{\n\t\t\tName: fmt.Sprintf(\"%s-worker\", workflowName),\n            Workflows: []workflow.WorkflowBase{workflow}, // add your workflow here\n\t\t},\n\t)\n\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\n\tworker.StartBlocking(ctx)\n}\n```\n\n----------------------------------------\n\nTITLE: Running a Single Workflow via API in Hatchet (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to trigger a Hatchet workflow using the `runWorkflow` method. It initializes the Hatchet client, calls `runWorkflow` with the workflow name, input data, and optional metadata. It requires the `@hatchet-dev/typescript-sdk` dependency. The workflow name will be concatenated with the client's namespace.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-api.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflowRun = hatchet.admin.runWorkflow(\n  \"api-trigger-workflow\",\n  {\n    test: \"test\",\n  },\n  {\n    additionalMetadata: {\n      hello: \"moon\",\n    },\n  },\n);\n\n```\n\n----------------------------------------\n\nTITLE: Simple Step Retries - Typescript\nDESCRIPTION: This snippet illustrates how to configure a task with a simple retry policy in TypeScript. The `retries` property is included in the task definition, indicating how many times the task should be retried upon failure.  This approach enhances task resilience by automatically handling transient errors.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/retries/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Streaming Workflow Run Results in Python\nDESCRIPTION: This code snippet illustrates how to stream the results of a workflow run as it executes. It retrieves a `WorkflowRunRef` using `get_workflow_run` and then calls the `stream()` method, which returns an async generator. The code then iterates over the events using `async for` and prints the event type and payload for each event received.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/get-workflow-results.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nworkflow_run_ref = hatchet.client.admin.get_workflow_run(\n    \"5a3a617d-1200-4ee2-92e6-be4bd27ca26f\",\n)\n\nlistener = workflow_run_ref.stream()\n\nasync for event in listener:\n    print(event.type, event.payload)\n```\n\n----------------------------------------\n\nTITLE: Creating a Scheduled Run - Typescript\nDESCRIPTION: This snippet refers to an external Typescript file (`src/v1/examples/simple/schedule.ts`) and targets a section labeled \"Create a Scheduled Run\".  It leverages the Hatchet SDK in Typescript to create a scheduled run, presumably using the `SimpleTs` object defined in the file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Create a Scheduled Run\" />\n```\n\n----------------------------------------\n\nTITLE: Filtering Durable Event in Typescript\nDESCRIPTION: This snippet demonstrates how to filter durable events in Typescript using Hatchet and CEL expressions. It shows how to receive only specific events based on a filter. The code is located in the `src/v1/examples/durable-event/workflow.ts` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_4\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={DurableTs} target=\"Durable Event With Filter\" />\n```\n\n----------------------------------------\n\nTITLE: Defining Step Timeout in Typescript\nDESCRIPTION: This snippet shows how to define a timeout for a specific Hatchet step using Typescript. The `timeout` property in the CreateStep configuration object specifies the maximum execution time for the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst myStep: CreateStep<any, any> = {\n  name: \"my-step\",\n  // ...\n  timeout: \"30s\",\n  run: async (ctx) => {\n    // ...\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Base64 Encoded Files\nDESCRIPTION: This code snippet shows how to stream a base64 encoded image file from a Hatchet step context. It reads an image file, encodes it as base64, and then streams the encoded data using `context.put_stream`. The relative path to the image is constructed to be compatible with the project structure.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step()\ndef step1(self, context: Context):\n    # Get the directory of the current script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Construct the path to the image file relative to the script's directory\n    image_path = os.path.join(script_dir, \"image.jpeg\")\n\n    # Load the image file\n    with open(image_path, \"rb\") as image_file:\n        image_data = image_file.read()\n\n    # Encode the image data as base64\n    base64_image = base64.b64encode(image_data).decode('utf-8')\n\n    # Stream the base64-encoded image data\n    context.put_stream(base64_image)\n\n    # continue with the step run...\n    return {\"step1\": \"results\"}\n\n```\n\n----------------------------------------\n\nTITLE: Running Workflow via API - Python\nDESCRIPTION: This code snippet demonstrates how to trigger a single workflow using the `run_workflow` method of the Hatchet Admin client. It requires the `hatchet_sdk` package. The `workflow_name` and `input` parameters are mandatory, and an `options` parameter, containing `additional_metadata`, is also demonstrated.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-api.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nhatchet = Hatchet()\n\nworkflowRun = hatchet.client.admin.run_workflow(\n    \"ManualTriggerWorkflow\",\n    {\"test\": \"test\"},\n    options={\"additional_metadata\": {\"hello\": \"moon\"}},\n)\n```\n\n----------------------------------------\n\nTITLE: Bulk Spawning: Child Workflows in Go\nDESCRIPTION: This Go snippet demonstrates spawning child workflows in bulk using `ctx.SpawnWorkflows`. It constructs a slice of `worker.SpawnWorkflowsOpts` to define each child workflow's properties such as name, input and key. It utilizes the `worker` package from the Hatchet Go SDK and the `strconv` package to convert integers to strings.  The parent workflow is registered using `w.RegisterWorkflow`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                // Prepare the batch of workflows to spawn\n                childWorkflows := make([]*worker.SpawnWorkflowsOpts, 10)\n\n                for i := 0; i < 10; i++ {\n                    childInput := \"child-input-\" + strconv.Itoa(i)\n                    childWorkflows[i] = &worker.SpawnWorkflowsOpts{\n                        WorkflowName: \"child-workflow\",\n                        Input:        childInput,\n                        Key:          \"child-key-\" + strconv.Itoa(i),\n                    }\n                }\n\n                // Spawn all workflows in bulk using SpawnWorkflows\n                createdWorkflows, err := ctx.SpawnWorkflows(childWorkflows)\n                if err != nil {\n                    return err\n                }\n\n                return nil\n            }),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Retries with Count - Go\nDESCRIPTION: This snippet details how to retrieve the current retry count within a running task in Go. Utilizing the `retryCount` function in the task context, the task can determine the current retry attempt. This is helpful for implementing dynamic error handling based on the number of retries performed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/retries.go\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for JavaScript with yarn\nDESCRIPTION: This Dockerfile builds a JavaScript Hatchet worker using yarn. It uses a multi-stage build process, first building the application in a builder stage with Node.js 18, then copying the built artifacts to a production stage based on Node.js 18-alpine. It copies package files, installs dependencies using `yarn install --frozen-lockfile`, builds the application, and defines the command to run the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/docker.mdx#_snippet_4\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\nCOPY package.json yarn.lock ./\n\nRUN yarn install --frozen-lockfile\n\nCOPY . .\n\nRUN yarn build\n\n# Stage 2: Production\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package.json yarn.lock ./\n\nRUN yarn install --frozen-lockfile --production\n\nCOPY --from=builder /app/dist ./dist\n\nENV NODE_ENV=production\n\nCMD [\"node\", \"dist/worker.js\"]\n```\n\n----------------------------------------\n\nTITLE: Bulk Cancelling Runs by Run IDs - Python\nDESCRIPTION: This snippet demonstrates how to cancel multiple task runs at once by providing a list of their IDs to the Hatchet API. This allows for efficient management of large numbers of runs.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-retries-and-cancellations.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nexamples/bulk_operations/cancel.py\n```\n\n----------------------------------------\n\nTITLE: Creating metric_events table in TimescaleDB\nDESCRIPTION: This SQL code defines a custom enum type `metric_event_type` and creates the `metric_events` table. The table includes columns for event ID, creation timestamp, tenant ID, resource ID, event type, and JSONB data. It also defines the primary key constraint and uses `create_hypertable` function to convert the table into a TimescaleDB hypertable, partitioned by `created_at` column. Requires TimescaleDB extension to be enabled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\n CREATE TYPE metric_event_type AS ENUM ('SUCCEEDED', 'FAILED');\n\n CREATE TABLE metric_events (\n    id BIGSERIAL NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL,\n    tenant_id UUID NOT NULL,\n    resource_id UUID NOT NULL,\n    event_type metric_event_type NOT NULL,\n    data JSONB,\n    CONSTRAINT metric_events_pkey PRIMARY KEY (id, created_at)\n);\n\nSELECT create_hypertable('metric_events', by_range('created_at'));\n```\n\n----------------------------------------\n\nTITLE: Add Branching Logic - TypeScript\nDESCRIPTION: This snippet adds branching logic to the workflow in TypeScript using `ParentCondition` and `skip_if`. It checks if the output of an upstream task is greater or less than 50, and only one of the two branches will run based on this condition. Demonstrates complex conditional routing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_13\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Checking exit flag in Python\nDESCRIPTION: This Python snippet shows how to check for cancellation using the `Context.exit_flag`. The `exit_flag` indicates whether a task has been cancelled. You can check this flag at any point in your task to determine whether or not to exit.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cancellation.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\n    def my_task(context):\n        while True:\n            if context.exit_flag:\n                print(\"Task cancelled, exiting...\")\n                return\n\n            # Perform task logic here\n            print(\"Task running...\")\n            time.sleep(1)\n```\n```\n\n----------------------------------------\n\nTITLE: Accessing Parent Task Outputs - Typescript\nDESCRIPTION: This snippet shows how to access the output of a parent task within a task that has parent dependencies in Typescript.  It uses the `ctx.parentOutput()` method to retrieve the parent's output. The `parentTaskName` variable should be the name or reference to the parent task.  Note that the call is `await`ed because the parent task could be asynchronous.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// Inside a task with parent dependencies\nconst parentOutput = await ctx.parentOutput(parentTaskName);\n```\n\n----------------------------------------\n\nTITLE: Refreshing Timeout in Typescript\nDESCRIPTION: This Typescript snippet demonstrates how to refresh a task's timeout using the `refreshTimeout` method within a step. It shows how to extend the execution time of a running task. The target `Refresh Timeout` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_4\n\nLANGUAGE: Typescript\nCODE:\n```\nsrc/v1/examples/with_timeouts/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Run ID in Python\nDESCRIPTION: This code shows how to retrieve the workflow run ID from a newly spawned workflow using `run_workflow`. The `workflow_run_id` attribute of the returned object is printed to the console. This ID can then be used to retrieve the workflow run later.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/get-workflow-results.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nworkflow_run = hatchet.client.admin.run_workflow(\n    \"ManualTriggerWorkflow\",\n    {\"test\": \"test\"},\n)\n\nprint(f\"spawned workflow run: {workflow_run.workflow_run_id}\")\n```\n\n----------------------------------------\n\nTITLE: Running a Worker with npm\nDESCRIPTION: This bash snippet shows how to start a Hatchet worker using npm. It executes the 'start:worker' script defined in the package.json file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run start:worker\n```\n\n----------------------------------------\n\nTITLE: Defining GPU Workflow Step in Hatchet\nDESCRIPTION: This code defines a Hatchet workflow with a step that utilizes GPU resources. It initializes a `Compute` object with specific parameters like `gpu_kind`, `gpus`, `memory_mb`, `num_replicas`, and `regions` and associates it with the `train_model` step using the `@hatchet.step` decorator.  The `compute` object defines the kind of computational resources that will be used in the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, Context\n\nhatchet = Hatchet()\n\n@hatchet.workflow()\nclass GPUWorkflow:\n    @hatchet.step(\n        compute=Compute(\n            gpu_kind=\"a100-80gb\",\n            gpus=1,\n            memory_mb=163840,\n            num_replicas=1,\n            regions=[\"ams\"]\n        )\n    )\n    def train_model(self, context: Context):\n        # GPU-accelerated code here\n        pass\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Consumption (Typescript)\nDESCRIPTION: This snippet shows how to consume a static rate limit in a Typescript task using the `rate_limits` configuration in the step definition. This links the task to a predefined rate limit. Requires the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet src={RateLimitTs} target=\"Static\" />\n```\n\n----------------------------------------\n\nTITLE: Setting Default Workflow Priority - Go\nDESCRIPTION: This snippet illustrates how to set a default priority for a Hatchet workflow in Go. This is a workflow-level setting that can be overridden by run-level priorities.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/workflows/priority.go\n```\n\n----------------------------------------\n\nTITLE: Starting a Hatchet Worker (Synchronous) in Python\nDESCRIPTION: This snippet shows how to start a Hatchet worker using the synchronous `worker.start()` method. It defines a `main` function that creates a worker, registers a workflow, and then starts the worker.  This call is blocking. The `hatchet_sdk` library is required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet()\n\n# ... workflow definitions\n\ndef main():\n    worker = hatchet.worker(\"test-worker\", max_runs=4)\n    worker.register_workflow(Workflow())\n    worker.start()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Run Workflow on Event in Typescript\nDESCRIPTION: This snippet shows how to run a Hatchet workflow on an event in TypeScript. It utilizes the `on_events` property in the task declaration. The example uses the `SimpleTs` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/on_event/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for Python with Poetry\nDESCRIPTION: This Dockerfile builds a Python Hatchet worker using Poetry for dependency management. It installs system dependencies, Poetry, sets the working directory, copies project files, installs dependencies using Poetry, copies the application code, and defines the command to run the worker using Poetry.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/docker.mdx#_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM python:3.13-slim\n\nENV PYTHONUNBUFFERED=1 \\\n POETRY_VERSION=1.4.2 \\\n HATCHET_ENV=production\n\n# Install system dependencies and Poetry\nRUN apt-get update && \\\n apt-get install -y curl && \\\n curl -sSL https://install.python-poetry.org | python3 - && \\\n ln -s /root/.local/bin/poetry /usr/local/bin/poetry && \\\n apt-get clean && \\\n rm -rf /var/lib/apt/lists/*\n\nWORKDIR /app\n\nCOPY pyproject.toml poetry.lock* /app/\n\nRUN poetry config virtualenvs.create false && \\\n poetry install --no-interaction --no-ansi\n\nCOPY . /app\n\nCMD [\"poetry\", \"run\", \"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Event Stream Generator (Python)\nDESCRIPTION: This Python function `event_stream_generator` is a generator that yields events from a Hatchet event stream. It filters and transforms the event data. Specifically, it checks if the event type is \"step_completed\", and then constructs a JSON string containing the event type, payload, and workflowRunId, which is then yielded in the `data: <json>\\n\\n` format required for Server-Sent Events (SSE). The snippet relies on the `hatchet` library and the `json` module.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndef event_stream_generator(workflowRunId):\n    ''' This helper function is a generator that yields events from the Hatchet event stream. '''\n    stream = hatchet.client.listener.stream(workflowRunId)\n    for event in stream:\n        ''' you can filter and transform event data here that will be sent to the client'''\n        if event.type == \"step_completed\":\n            data = json.dumps({\n                \"type\": event.type,\n                \"payload\": event.payload,\n                \"messageId\": workflowRunId\n            })\n            yield \"data: \" + data + \"\\n\\n\"\n```\n\n----------------------------------------\n\nTITLE: Adding a Worker Start Script to package.json\nDESCRIPTION: This JSON snippet shows how to add a script to your package.json file to start a Typescript Hatchet worker. It defines a \"start:worker\" script that uses ts-node to execute the worker file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"scripts\": {\n  \"start:worker\": \"ts-node src/v1/examples/simple/worker.ts\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Scheduled Run - Go\nDESCRIPTION: This snippet refers to an external Go file (`examples/scheduled/main.go`) and targets a section labeled \"Create\". It utilizes the Hatchet SDK in Go to create a scheduled run, likely using the `ScheduleTriggerGo` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={ScheduleTriggerGo} target=\"Create\" />\n```\n\n----------------------------------------\n\nTITLE: Defining a lifespan in Hatchet using Python\nDESCRIPTION: This snippet demonstrates how to define a lifespan in Hatchet using an async generator function. The lifespan is passed to the Hatchet worker and runs upon worker startup, stopping at the 'yield'.  Cleanup code after the 'yield' executes on worker shutdown.  Requires Hatchet's Python SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/lifespans.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/lifespans/worker.py\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Version Definition - Python\nDESCRIPTION: This code retrieves the definition of a specific or the latest version of a workflow. It sets up authentication using an API key or bearer token, configures the API client, creates a WorkflowApi instance, and calls the workflow_version_get_definition method, handling potential API exceptions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow_version_definition import WorkflowVersionDefinition\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow and Starting Worker in Go\nDESCRIPTION: This Go code demonstrates how to register workflows, configure a worker with integrations (like Slack), and start the worker. It uses the Hatchet Go client to initialize workflows and integrations, and then starts the worker in a goroutine. The `InterruptContextFromChan` function allows for graceful shutdown via an interrupt signal.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workers.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nclient, err := client.New(\n    client.InitWorkflows(),\n    client.WithWorkflows([]*types.Workflow{\n        &slackWorkflowFile,\n    }),\n)\nif err != nil {\n    panic(err)\n}\n\nworker, err := worker.NewWorker(\n    worker.WithClient(\n        client,\n    ),\n    worker.WithIntegration(\n        slackInt,\n    ),\n)\nif err != nil {\n    panic(err)\n}\n\ninterruptCtx, cancel := cmdutils.InterruptContextFromChan(cmdutils.InterruptChan())\ndefer cancel()\n\ngo worker.Start()\n```\n\n----------------------------------------\n\nTITLE: Add Skip On Event Task - TypeScript\nDESCRIPTION: This snippet adds a task that will be skipped if a specific event (`skip_on_event:skip`) is fired, using the `skip_if` condition in TypeScript. This task demonstrates how to skip tasks based on event conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_10\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Add Summing Task - Go\nDESCRIPTION: This snippet adds the final task to the workflow in Go, which collects the outputs from all parent tasks and sums them up. It utilizes `ctx.was_skipped` to handle cases where tasks were skipped due to conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_20\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Add Skip On Event Task - Python\nDESCRIPTION: This snippet adds a task that will be skipped if a specific event (`skip_on_event:skip`) is fired, using the `skip_if` condition in Python. This task demonstrates how to skip tasks based on event conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Adjusting Memory Allocation for PostgreSQL\nDESCRIPTION: This snippet shows the configuration of memory allocation parameters in PostgreSQL to improve performance on systems with ample memory. It increases the `maintenance_work_mem` and `work_mem` values to allow for larger in-memory operations, which can significantly speed up database tasks like indexing and sorting.  These settings are particularly beneficial for databases with large datasets and complex queries.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nmaintenance_work_mem=2147483647\nwork_mem=125828\n```\n\n----------------------------------------\n\nTITLE: Defining and Running a Hatchet Workflow in Python\nDESCRIPTION: This Python script defines a simple Hatchet workflow with two steps. It initializes the Hatchet client, defines a workflow class with steps, registers the workflow with a worker, and starts the worker. The workflow is triggered by the `user:create` event.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/index.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow(on_events=[\"user:create\"])\nclass Workflow:\n    def __init__(self):\n        self.my_value = \"test\"\n\n    @hatchet.step(timeout=\"2s\")\n    async def step1(self, context: Context):\n        context.refresh_timeout(\"5s\")\n\n        print(\"started step1\")\n        await asyncio.sleep(1)\n        print(\"finished step1\")\n\n        return {\"test\": \"test\"}\n\n    @hatchet.step(parents=[\"step1\"], timeout=\"4s\")\n    async def step2(self, context):\n        print(\"started async step2\")\n        await asyncio.sleep(1)\n        print(\"finished step2\")\n\nasync def main():\n    worker = hatchet.worker(\"first-worker\", max_runs=4)\n    worker.register_workflow(Workflow())\n    await worker.async_start()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Worker - TypeScript\nDESCRIPTION: This snippet defines a sticky worker in TypeScript. It shows the structure and required configurations for setting up a worker that maintains state across multiple tasks. The snippet targets the 'Sticky Task' section of the file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/sticky/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Non-retrying task - Typescript\nDESCRIPTION: This snippet illustrates how to bypass the default retry behavior in TypeScript by using the `NonRetryable` exception. When this exception is raised, the task will not be retried, even if `retries` is set to a non-zero value. This allows for selective skipping of retry attempts in scenarios where retries are not appropriate.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_10\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/non_retryable/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Enabling Trace Sampling using Environment Variables (Bash)\nDESCRIPTION: This code snippet demonstrates how to enable trace sampling and set the sampling rate using environment variables in a Bash shell. `SERVER_SAMPLING_ENABLED` enables the sampling and `SERVER_SAMPLING_RATE` defines the percentage of results that will be sampled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/sampling.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSERVER_SAMPLING_ENABLED=t\nSERVER_SAMPLING_RATE=0.1 # only 10% of results will be sampled\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Tasks in Parallel - Python\nDESCRIPTION: Demonstrates how to run multiple tasks in parallel in Python by using `asyncio.gather` to await multiple coroutines returned by `aio_run`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={SimplePy} target=\"Running Multiple Tasks\" />\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using CEL Expression in Python\nDESCRIPTION: This Python code snippet demonstrates how to define a workflow with a concurrency limit using a CEL expression.  It configures the workflow to cancel in-progress runs when the concurrency limit is reached, grouping instances by the `input.group` value. Requires `hatchet_sdk`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import ConcurrencyLimitStrategy, ConcurrencyExpression\n\n@hatchet.workflow(\n  on_events=[\"concurrency-test\"],\n  concurrency=ConcurrencyExpression(\n    expression=\"input.group\",\n    max_runs=5,\n    limit_strategy=ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS,\n  )\n)\nclass ConcurrencyDemoWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Using a lifespan in a Hatchet task with Python\nDESCRIPTION: This snippet shows how to access and use a defined lifespan within a Hatchet task. It extracts the lifespan from the task's context using `Context.lifespan`.  For type safety, cast the lifespan to the correct type that the lifespan generator yields.  Requires a pre-defined lifespan and Hatchet's Python SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/lifespans.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nexamples/lifespans/worker.py\n```\n\n----------------------------------------\n\nTITLE: Error Handling with Child Workflow Spawn in Python\nDESCRIPTION: This Python snippet demonstrates how to spawn a child workflow and handle potential exceptions that might occur during its execution. If an exception is caught, a recovery workflow is spawned to address the failure. It utilizes the hatchet framework.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\"fanout:create\")\nclass Parent:\n    @hatchet.step()\n    async def spawn(self, context: Context):\n        try:\n            (\n                await context.aio.spawn_workflow(\n                  \"Child\", {\"a\": str(i)}, key=f\"child{i}\"\n                )\n            ).result()\n        except Exception as e:\n          # Spawn a recovery workflow\n          context.spawn_workflow(\"recovery-workflow\", { \"error\": str(e) });\n\n        return {}\n\n```\n\n----------------------------------------\n\nTITLE: Spawning Sticky Child Workflow in Python\nDESCRIPTION: This Python code snippet demonstrates how to spawn a child workflow with the `sticky` option set to `True`. This ensures that the child workflow will be executed by the same worker as the parent workflow, provided the child workflow is registered with the same worker and defines a sticky strategy. The `spawn_workflow` method is used to initiate the child workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\n    on_events=[\"sticky:parent\"],\n)\nclass StickyWorkflow:\n    @hatchet.step(parents=[\"step1a\", \"step1b\"])\n    async def parent_step(self, context: Context):\n        ref = context.spawn_workflow('StickyChildWorkflow', {}, options={\"sticky\": True})\n        await ref.result()\n        return {\"worker\": context.worker.id()}\n\n```\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\non_events=[\"sticky:child\"],\nsticky=StickyStrategy.SOFT\n)\nclass StickyChildWorkflow:\n@hatchet.step()\ndef child(self, context: Context):\nreturn {\"worker\": context.worker.id()}\n\n```\n\n----------------------------------------\n\nTITLE: Error Handling with Child Workflow Spawn in Typescript\nDESCRIPTION: This Typescript snippet showcases how to spawn a child workflow and manage errors that could arise during its execution. In the event of an error, a recovery workflow is initiated. This implementation relies on the hatchet framework.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        try {\n          const result = await ctx\n            .spawnWorkflow<string>(\"child-workflow\", { input: `child-input` })\n            .result();\n          return result;\n        } catch (e) {\n          // Spawn a recovery workflow\n          ctx.spawnWorkflow<string>(\"recovery-workflow\", { error: e });\n        }\n\n        return {};\n      },\n    },\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Deleting a Scheduled Run - Typescript\nDESCRIPTION: This snippet references an external Typescript file (`src/v1/examples/simple/schedule.ts`) and targets the section titled \"Deleting a Scheduled Run\". It's intended to show how to delete a schedule using the Hatchet SDK for Typescript, likely interacting with the `SimpleTs` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_4\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Deleting a Scheduled Run\" />\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflow in Go\nDESCRIPTION: This code snippet demonstrates how to spawn a child workflow from an existing `ctx` object using the `SpawnWorkflow` method.  It takes the workflow name, input, and spawn options as parameters. It returns a `ChildWorkflow` object and an error, if any.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/child-workflows.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nchildWorkflow, err := ctx.SpawnWorkflow(\"child-workflow\", childInput, &worker.SpawnWorkflowOpts{})\n\nif err != nil {\n    return nil, err\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Worker with max_runs in Go\nDESCRIPTION: This snippet illustrates initializing a Hatchet worker in Go using the `worker.WithMaxRuns` option. This option is used to limit the number of concurrent step runs. The `WithMaxRuns` parameter specifies the maximum number of concurrent steps the worker can execute across all workflows. Requires the `hatchet.dev/go/sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/overview.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nw, err := worker.NewWorker(\n    worker.WithClient(c),\n    worker.WithMaxRuns(5),\n    worker.WithName(\"my-worker\")\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Webhooks in Next.js Pages Dir (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to handle Hatchet webhooks in a Next.js application using the Pages Router. It initializes Hatchet, creates a webhooks instance, and exports the GET, POST, and PUT handlers using `webhooks.nextJSHandler`. It requires the `@hatchet-dev/typescript-sdk` dependency and the `HATCHET_WEBHOOK_SECRET` environment variable. It also sets `maxDuration` for Vercel deployments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/webhooks.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nexport const maxDuration = 60; // add this on vercel: 60 for free plans, 300 for pro plans\n\nconst hatchet = Hatchet.init();\n\nconst webhooks = hatchet.webhooks([workflow]);\n\nexport const { GET, POST, PUT } = webhooks.nextJSHandler({\n  secret: process.env.HATCHET_WEBHOOK_SECRET || \"\",\n});\n```\n\n----------------------------------------\n\nTITLE: Scatter/Gather: Child Workflows in Go\nDESCRIPTION: This Go snippet illustrates a scatter/gather pattern for child workflows, leveraging `sync.WaitGroup` and channels to manage concurrent execution and result collection.  It uses `ctx.SpawnWorkflow` to create child workflows in goroutines.  The results of each child workflow are collected through a channel. It utilizes the `worker` package from the Hatchet Go SDK and the `strconv` package to convert integers to strings.  The `sync` package is essential for goroutine management. The parent workflow is registered using `w.RegisterWorkflow`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                var wg sync.WaitGroup\n                results := make([]string, 10)\n                resultCh := make(chan string, 10)\n                for i := 0; i < 10; i++ {\n                    wg.Add(1)\n                    go func(i int) {\n                        defer wg.Done()\n                        childInput := \"child-input-\" + strconv.Itoa(i)\n                        childWorkflow, err := ctx.SpawnWorkflow(\"child-workflow\", childInput, &worker.SpawnWorkflowOpts{})\n                        if err != nil {\n                            // Handle error here\n                            return\n                        }\n                        // Collect the result from the child workflow\n                        result, err := childWorkflow.Result()\n                        if err != nil {\n                            // Handle error here\n                            return\n                        }\n                        resultCh <- result\n                    }(i)\n                }\n                go func() {\n                    wg.Wait()\n                    close(resultCh)\n                }()\n\n                // Collect all results\n                for result := range resultCh {\n                    results = append(results, result)\n                }\n\n                return nil\n            }),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Webhooks in Next.js App Dir (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to handle Hatchet webhooks in a Next.js application using the App Router. It initializes Hatchet, creates a webhooks instance, and exports the GET, POST, and PUT handlers using `webhooks.nextJSHandler`. It requires the `@hatchet-dev/typescript-sdk` dependency and the `HATCHET_WEBHOOK_SECRET` environment variable.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/webhooks.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst webhooks = hatchet.webhooks([workflow]);\n\nexport const { GET, POST, PUT } = webhooks.nextJSHandler({\n  secret: process.env.HATCHET_WEBHOOK_SECRET,\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Events Table in Postgres\nDESCRIPTION: This SQL code defines a basic events table in Postgres with columns for ID, creation timestamp, tenant ID, resource ID, and JSONB data.  It includes an index on tenant_id and resource_id to speed up common queries. A primary key constraint is added to `id`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE simple_events (\n    id BIGSERIAL NOT NULL,\n    created_at TIMESTAMPTZ,\n    tenant_id UUID NOT NULL,\n    resource_id UUID NOT NULL,\n    data JSONB,\n    PRIMARY KEY (id)\n);\n\nCREATE INDEX ON simple_events (tenant_id, resource_id);\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Labels Update - Go\nDESCRIPTION: This Go code demonstrates dynamically updating worker labels within a task. It checks if the worker's `model` label matches the desired value (`fancy-vision-model`). If not, it clears the existing `model` label using `ctx.Worker().UpsertLabels(map[string]interface{}{ \"model\": nil })`, performs hypothetical `evictModel()` and `loadNewModel()` functions, and then updates the `model` label to the desired value using `ctx.Worker().UpsertLabels(map[string]interface{}{ \"model\": \"fancy-vision-model\" })`. The updated labels will be reflected in subsequent task assignments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-affinity.mdx#_snippet_3\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:          worker.Events(\"user:create:affinity\"),\n\t\t\tName:        \"affinity\",\n\t\t\tDescription: \"affinity\",\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *taskOneOutput, err error) {\n\n    \t\t\t\tmodel := ctx.Worker().GetLabels()[\"model\"]\n\n    \t\t\t\tif model != \"fancy-vision-model\" {\n    \t\t\t\t\tctx.Worker().UpsertLabels(map[string]interface{}{\n    \t\t\t\t\t\t\"model\": nil,\n    \t\t\t\t\t})\n    \t\t\t\t\t// Do something to load the model\n            evictModel();\n            loadNewModel(\"fancy-vision-model\");\n    \t\t\t\t\tctx.Worker().UpsertLabels(map[string]interface{}{\n    \t\t\t\t\t\t\"model\": \"fancy-vision-model\",\n    \t\t\t\t\t})\n    \t\t\t\t}\n\n    \t\t\t\treturn &taskOneOutput{\n    \t\t\t\t\tMessage: ctx.Worker().ID(),\n    \t\t\t\t}, nil\n    \t\t\t}).\n    \t\t\t\tSetName(\"task-one\").\n    \t\t\t\tSetDesiredLabels(map[string]*types.DesiredWorkerLabel{\n    \t\t\t\t\t\"model\": {\n    \t\t\t\t\t\tValue:  \"fancy-vision-model\",\n    \t\t\t\t\t\tWeight: 10,\n    \t\t\t\t\t},\n    \t\t\t\t\t\"memory\": {\n    \t\t\t\t\t\tValue:      512,\n    \t\t\t\t\t\tRequired:   true,\n    \t\t\t\t\t\tComparator: types.WorkerLabelComparator_GREATER_THAN,\n    \t\t\t\t\t},\n    \t\t\t\t}),\n    \t\t},\n    \t},\n    )\n```\n\n----------------------------------------\n\nTITLE: Using Pydantic Models with Hatchet V1 SDK in Python\nDESCRIPTION: This snippet showcases how to use Pydantic models with the Hatchet V1 SDK for more complex workflows. It illustrates declaring workflows with `hatchet.workflow` and registering tasks with `workflow.task`. It demonstrates defining Pydantic models as `input_validator`s for workflows and tasks and using the `run` methods on the `child_workflow` object, which is a Hatchet `Workflow`, instead of needing to refer to the workflow by its name. The `input` field to `run()` is now also properly typed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-python.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n<GithubSnippet src={PydanticWorker} target=\"FanoutParent\" />\n```\n\nLANGUAGE: python\nCODE:\n```\n<GithubSnippet src={PydanticWorker} target=\"FanoutChild\" />\n```\n\n----------------------------------------\n\nTITLE: Trigger Workflow Run with Hatchet SDK (Python)\nDESCRIPTION: This code snippet demonstrates how to trigger a workflow run using the Hatchet SDK's WorkflowRunApi. It configures API client with authentication (API Key or Bearer Token), creates an instance of the WorkflowRunApi, and then calls the workflow_run_create method with the workflow ID and trigger request. It includes error handling for API exceptions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowRunApi.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.trigger_workflow_run_request import TriggerWorkflowRunRequest\nfrom hatchet_sdk.clients.rest.models.workflow_run import WorkflowRun\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowRunApi(api_client)\n    workflow = 'workflow_example' # str | The workflow id\n    trigger_workflow_run_request = hatchet_sdk.clients.rest.TriggerWorkflowRunRequest() # TriggerWorkflowRunRequest | The input to the workflow run\n    version = 'version_example' # str | The workflow version. If not supplied, the latest version is fetched. (optional)\n\n    try:\n        # Trigger workflow run\n        api_response = api_instance.workflow_run_create(workflow, trigger_workflow_run_request, version=version)\n        print(\"The response of WorkflowRunApi->workflow_run_create:\\n\")\n        print(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowRunApi->workflow_run_create: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Bulk Push Events with Hatchet\nDESCRIPTION: This Go snippet demonstrates how to use the Hatchet Go SDK to bulk push events. It initializes the Hatchet client with a host and port, creates a slice of `EventWithMetadata` structs, each containing an event and additional metadata. It then calls `c.Event().BulkPush` to send the events. A maximum limit of 1000 events per request is enforced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nevents := []client.EventWithMetadata{\n  {\n    Event: &events.TestEvent{\n      Name: \"testing\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world1\"},\n    Key: \"user:create\",\n  },\n  {\n    Event: &events.TestEvent{\n      Name: \"testing2\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world2\"},\n    Key: \"user:create\",\n  },\n}\n\nc.Event().BulkPush(\n  context.Background(),\n  events,\n)\n```\n\n----------------------------------------\n\nTITLE: Bulk Spawning: Child Workflows in Typescript\nDESCRIPTION: This TypeScript snippet demonstrates spawning child workflows in bulk using `ctx.spawnWorkflows`. It creates an array of workflow requests with specified workflow name, input, and options (including metadata for the child key).  The workflow and step are defined as objects with properties like `id`, `on`, `steps`, and `run`. It relies on the `Workflow` type from the Hatchet library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        const workflowRequests = Array.from({ length: 10 }, (_, i) => ({\n          workflow: \"child-workflow\",\n          input: { input: `child-input-${i}` },\n          options: { additionalMetadata: { childKey: `child-${i}` } },\n        }));\n\n        const spawnedWorkflows = await ctx.spawnWorkflows<string, string>(\n          workflowRequests,\n        );\n\n        return spawnedWorkflows;\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client with Default Configuration - TypeScript\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet client with default configuration using the `Hatchet.init()` method.  It assumes that the necessary environment variables (e.g., HATCHET_CLIENT_TOKEN, HATCHET_CLIENT_NAMESPACE) are set. The `typescript-sdk` is a required dependency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/client.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow - Typescript\nDESCRIPTION: This snippet demonstrates how to run a Hatchet workflow in Typescript. It shows how to run the workflow and wait for the result using `simple.run()`, and how to enqueue it for asynchronous execution using `simple.runNoWait()`. Both methods take the input data as an argument and return a Promise.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\n// Run workflow and wait for the result\nconst result = await simple.run({ Message: \"Hello World\" });\n\n// Enqueue workflow to be executed asynchronously\nconst runId = await simple.runNoWait({ Message: \"Hello World\" });\n```\n\n----------------------------------------\n\nTITLE: Releasing Hatchet task slot in Go\nDESCRIPTION: This Go code snippet demonstrates how to manually release a Hatchet task slot using the `ctx.ReleaseSlot()` method. The slot is released after a resource-intensive process to allow other tasks to run concurrently.  The example includes a time delay to simulate the resource-intensive process.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/manual-slot-release.mdx#_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\nfunc StepOne(ctx worker.HatchetContext) (result *taskOneOutput, err error) {\n  fmt.Println(\"RESOURCE INTENSIVE PROCESS\")\n  time.Sleep(10 * time.Second)\n  // Release the slot after the resource-intensive process, so that other tasks can run\n  ctx.ReleaseSlot()\n  fmt.Println(\"NON RESOURCE INTENSIVE PROCESS\")\n  return &taskOneOutput{\n    Message: \"task1 results\",\n  }, nil\n},\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for JavaScript with npm\nDESCRIPTION: This Dockerfile builds a JavaScript Hatchet worker using npm. It uses a multi-stage build process, first building the application in a builder stage with Node.js 18, then copying the built artifacts to a production stage based on Node.js 18-alpine. It copies package files, installs dependencies using `npm ci`, builds the application, and defines the command to run the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/docker.mdx#_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci\n\nCOPY . .\n\nRUN npm run build\n\n# Stage 2: Production\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --omit=dev\n\nCOPY --from=builder /app/dist ./dist\n\nENV NODE_ENV=production\n\nCMD [\"node\", \"dist/worker.js\"]\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Bulk (Python)\nDESCRIPTION: This snippet demonstrates how to spawn multiple child workflows from a parent workflow in Hatchet using the Python SDK.  The `spawn_workflows` method is used to efficiently create and trigger multiple child workflows based on a list of workflow requests. This improves performance compared to spawning workflows individually.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\"fanout:create\")\nclass Parent:\n    @hatchet.step()\n    def spawn(self, context: Context):\n        workflow_requests = [\n            {\n                \"workflow\": \"Child\",\n                \"input\": {\"a\": str(i)},\n                \"key\": f\"child{i}\",\n                \"options\": {}\n            }\n            for i in range(10)\n        ]\n\n        # Spawn the workflows in bulk using spawn_workflows\n        context.spawn_workflows(workflow_requests)\n        return {}\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Consumption (Python)\nDESCRIPTION: This snippet illustrates how to consume a static rate limit within a task in Python by configuring the `rate_limits` in the step definition. It uses the previously defined `RATE_LIMIT_KEY`. Requires the Hatchet library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n<GithubSnippet src={RateLimitPy} target=\"Static\" />\n```\n\n----------------------------------------\n\nTITLE: Async-safe function using sync_to_async decorator in Python\nDESCRIPTION: This snippet demonstrates how to use the `sync_to_async` decorator to wrap a synchronous function, making it safe to run within an asynchronous context. The `blocking_function` is decorated to prevent blocking the main event loop. It imports necessary modules like `time`, `Context` and `Hatchet`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/asyncio.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nfrom hatchet_sdk import Context, sync_to_async\nfrom hatchet_sdk.v2.hatchet import Hatchet\n\nhatchet = Hatchet(debug=True)\n\n\n@sync_to_async  # This will now be async safe!\ndef blocking_function():\n    time.sleep(5)\n    return {\"type\": \"sync_blocking\"}\n\n\n@sync_to_async  # This will now be async safe!\nasync def async_blocking_function():\n    time.sleep(5)\n    return {\"type\": \"async_blocking\"}\n\n\n@hatchet.function()\nasync def my_func(context: Context) -> dict:\n    data = [\n        await blocking_function(),\n        await async_blocking_function(),\n    ]\n    return {\n        \"status\": \"success\",\n        \"data\": data,\n    }\n\n\nworker = hatchet.worker(\"worker\", max_runs=5)\n\nworker.start()\n```\n\n----------------------------------------\n\nTITLE: Declaring a Worker in Python\nDESCRIPTION: This code snippet demonstrates how to declare a Hatchet worker in Python. It initializes a worker named 'test-worker' and associates it with a specific workflow (simple). The worker is then started to listen for and execute tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef main() -> None:\n  worker = hatchet.worker(\"test-worker\", workflows=[simple])\n  worker.start()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Declaration (Typescript)\nDESCRIPTION: This snippet demonstrates how to declare static rate limits in Typescript using the `Admin` client's `put_rate_limit` method. It defines a rate limit with a specified key, limit, and duration. Requires the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet src={RateLimitTs} target=\"Upsert Rate Limit\" />\n```\n\n----------------------------------------\n\nTITLE: Defining Cron in Task Definition - Go\nDESCRIPTION: This snippet demonstrates how to define a cron schedule within a task definition using Go. The `on_cron` property specifies the cron expression, determining when the task is triggered. This approach statically defines the cron schedule as part of the task's configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nexamples/v1/workflows/on-cron.go\n```\n\n----------------------------------------\n\nTITLE: Declaring Durable Event in Go\nDESCRIPTION: This snippet demonstrates how to declare a durable event in Go using Hatchet. It uses the `WaitFor` method on the `DurableContext` object to wait for an event to occur before continuing the workflow. The code is located in the `examples/v1/workflows/durable-event.go` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={DurableGo} target=\"Durable Event\" />\n```\n\n----------------------------------------\n\nTITLE: Scatter/Gather: Child Workflows in Typescript\nDESCRIPTION: This TypeScript snippet demonstrates running child workflows in parallel and waiting for their completion using `Promise.all`. It spawns child workflows using `ctx.spawnWorkflow` and collects the promises returned by `.result()`.  `Promise.all` awaits all child workflow results. The workflow and step are defined as objects with properties like `id`, `on`, `steps`, and `run`. It relies on the `Workflow` type from the Hatchet library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        const promises: Promise<string>[] = [];\n\n        for (let i = 0; i < 5; i++) {\n          promises.push(\n            ctx\n              .spawnWorkflow<string>(\"child-workflow\", {\n                input: `child-input-${i}`,\n              })\n              .result(),\n          );\n        }\n\n        const results = await Promise.all(promises);\n\n        return {\n          results,\n        };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow with Desired Labels - Go\nDESCRIPTION: This code snippet shows how to register a workflow with Hatchet that specifies desired worker labels for a specific task. The `SetDesiredLabels` method is used to specify the desired label state, including the value, comparator, and weight. The workflow is registered with a client, a name, and a description. The `On` field specifies the events that trigger the workflow. The `Steps` field specifies the steps in the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-affinity.mdx#_snippet_1\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:          worker.Events(\"user:create:affinity\"),\n\t\t\tName:        \"affinity\",\n\t\t\tDescription: \"affinity\",\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *taskOneOutput, err error) {\n\t\t\t\t\treturn &taskOneOutput{\n\t\t\t\t\t\tMessage: ctx.Worker().ID(),\n\t\t\t\t\t}, nil\n\t\t\t\t}).\n\t\t\t\t\tSetName(\"task-one\").\n\t\t\t\t\tSetDesiredLabels(map[string]*types.DesiredWorkerLabel{\n\t\t\t\t\t\t\"model\": {\n\t\t\t\t\t\t\tValue:  \"fancy-ai-model-v2\",\n\t\t\t\t\t\t\tWeight: 10,\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"memory\": {\n\t\t\t\t\t\t\tValue:      512,\n\t\t\t\t\t\t\tRequired:   true,\n\t\t\t\t\t\t\tComparator: types.ComparatorPtr(types.WorkerLabelComparator_GREATER_THAN),\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t},\n\t\t},\n\t)\n```\n\n----------------------------------------\n\nTITLE: Listening for Workflow Events\nDESCRIPTION: This code snippet demonstrates how to listen for events from a Hatchet workflow using the `hatchet.listener.stream` method. It retrieves the `workflowRunId` and then iterates through the event stream, logging each event to the console.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nasync function listen_for_files() {\n  const workflowRunId = await hatchet.admin.run_workflow(\"simple-workflow\", {});\n  const stream = await hatchet.listener.stream(workflowRunId);\n  for await (const event of stream) {\n    console.log(\"event received\", event);\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining GPU Compute Configuration TypeScript\nDESCRIPTION: This snippet demonstrates how to define a GPU compute configuration using the `GPUCompute` interface from the `@hatchet-dev/typescript-sdk`.  It sets parameters like CPU kind, GPU kind, memory, number of replicas, CPUs, GPUs and regions. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/managed-compute.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GPUCompute } from \"@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config\";\n\nconst gpuCompute: GPUCompute = {\n  cpuKind: \"shared\",\n  gpuKind: \"l40s\",\n  memoryMb: 1024,\n  numReplicas: 1,\n  cpus: 2,\n  gpus: 1,\n  regions: [ManagedWorkerRegion.Ewr],\n};\n```\n\n----------------------------------------\n\nTITLE: Registering Worker with Labels - Go\nDESCRIPTION: This code snippet demonstrates how to register a Hatchet worker with specific labels. These labels are used to specify worker capabilities, resource availability, or other criteria that can be used to match workflows to workers. The worker is created with a client and a map of labels, where the keys are the label names and the values are the label values.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-affinity.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithLabels(map[string]interface{}{\n\t\t\t\"model\":  \"fancy-ai-model-v2\",\n\t\t\t\"memory\": 512,\n\t\t}),\n\t)\n```\n\n----------------------------------------\n\nTITLE: Execution Timeout Task Definition in Typescript\nDESCRIPTION: This Typescript snippet shows how to define a Hatchet workflow with execution timeouts. It uses the `executionTimeout` property when defining a step. The target `Execution Timeout` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\nsrc/v1/examples/with_timeouts/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Running a Worker with pnpm\nDESCRIPTION: This bash snippet shows how to start a Hatchet worker using pnpm. It executes the 'start:worker' script defined in the package.json file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm run start:worker\n```\n\n----------------------------------------\n\nTITLE: Pushing Bulk Events with Hatchet Client (Go)\nDESCRIPTION: This snippet demonstrates how to push multiple events to Hatchet in a single request using the Go SDK. It initializes a Hatchet client, defines a slice of events with payloads and metadata, and then uses the `BulkPush` method to send the events to the Hatchet server. This can significantly improve performance for high-volume event ingestion.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nevents := []client.EventWithMetadata{\n  {\n    Event: &events.TestEvent{\n      Name: \"testing\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world1\"},\n    Key: \"user:create\",\n  },\n  {\n    Event: &events.TestEvent{\n      Name: \"testing2\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world2\"},\n    Key: \"user:create\",\n  },\n}\n\nc.Event().BulkPush(\n  context.Background(),\n  events,\n)\n```\n\n----------------------------------------\n\nTITLE: Streaming Endpoint with FastAPI (Python)\nDESCRIPTION: This Python snippet creates a streaming GET endpoint using FastAPI at the `/message/{messageId}` route. It calls the `event_stream_generator` function with the `workflowRunId` (which, in this example, is the same as the `messageId`), and returns a `StreamingResponse` with the generated event stream and `media_type` set to `text/event-stream`. It uses FastAPI to handle the asynchronous request and stream the data. It relies on the `fastapi` library and the `StreamingResponse` object from `fastapi.responses`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n@app.get(\"/message/{messageId}\")\nasync def stream(messageId: str):\n    ''' in a normal application you might use the message id to look up a workflowRunId\n    for this simple case, we have no persistence and just use the message id as the workflowRunId\n    you might also consider looking up the workflowRunId in a database and returning the results\n    if the message has already been processed '''\n    workflowRunId = messageId\n    return StreamingResponse(event_stream_generator(workflowRunId), media_type='text/event-stream')\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Payload - Typescript\nDESCRIPTION: Demonstrates how to access the event payload within a Hatchet workflow step in Typescript.  The `context.workflowInput()` method is used to retrieve the event payload.  Requires `@hatchet-dev/typescript-sdk` package and a type definition for the `UserCreatedEvent` interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst myStep: Step = async (context: Context<UserCreatedEvent>) => {\n  const eventPayload = context.workflowInput();\n  // Use the event payload data in your step logic\n  // ...\n};\n```\n\n----------------------------------------\n\nTITLE: Add Durable Task to Workflow (worker.py)\nDESCRIPTION: This Python code snippet illustrates how to add both a regular (ephemeral) task and a durable task to a Hatchet workflow. The durable task utilizes the `DurableContext` for handling execution and waiting for events, ensuring resilience to interruptions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-execution.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk\nimport asyncio\nimport time\n\nhatchet = hatchet_sdk.new_client()\n\n@hatchet.workflow(\n    name=\"durable-workflow\",\n    version=\"v1\"\n)\ndef my_workflow(context):\n    # non-durable task\n    @hatchet.task(name=\"task1\")\n    def task1(context):\n        print(\"Starting task1\")\n        time.sleep(2)\n        print(\"Completing task1\")\n        return {\"message\": \"hello world\"}\n\n    # durable task\n    @hatchet.durable_task(name=\"durable-task1\")\n    async def durable_task1(context: hatchet_sdk.DurableContext):\n        print(\"Starting durable_task1\")\n\n        print(\"Sleeping for 10 seconds\")\n        await context.aio_sleep(10)\n\n        print(\"Waiting for event\")\n        event = await context.wait_for_event(match={\n            \"event\": \"test\"\n        })\n        print(\"Event received\", event)\n\n        print(\"Completing durable_task1\")\n\n    task1()\n    durable_task1()\n```\n\n----------------------------------------\n\nTITLE: Dockerfile Example with Multiple Workers\nDESCRIPTION: This example shows how to structure a repository with multiple Dockerfiles for different worker configurations in Hatchet. Each worker pool can have its own Dockerfile, dependencies, and entry points.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/git-ops.mdx#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n.\n├── Dockerfile.worker1        # For worker pool 1\n├── Dockerfile.worker2        # For worker pool 2\n└── services/\n    └── special/\n        └── Dockerfile        # For specialized worker\n```\n\n----------------------------------------\n\nTITLE: Install Common CUDA Libraries (Dockerfile)\nDESCRIPTION: This Dockerfile snippet shows how to install commonly needed CUDA libraries. This is essential for providing the necessary dependencies for GPU workloads. It installs libcublas, libcudnn, and the Nvidia driver.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_7\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Install commonly needed libraries\nRUN apt-get install -y \\\n    libcublas-12-2 \\\n    libcudnn8 \\\n    nvidia-driver-525\n```\n\n----------------------------------------\n\nTITLE: Creating Cron Trigger Programmatically - Typescript\nDESCRIPTION: Creates a cron trigger programmatically using the Hatchet SDK in Typescript. This allows for dynamic cron schedules defined at runtime.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/examples/crons/programatic-crons.ts\n```\n\n----------------------------------------\n\nTITLE: Defining Parent and Child Workflows in Hatchet (Python)\nDESCRIPTION: This code defines a parent workflow named `Parent` that spawns multiple child workflows named `Child` using `context.aio.spawn_workflow`. The child workflow receives input and returns a status. The parent workflow collects the results from each spawned child workflow. It shows how to use async methods to improve performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-child.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet()\n\n@hatchet.workflow()\nclass Parent:\n    @hatchet.step(timeout=\"5m\")\n    async def spawn(self, context: Context):\n        results = []\n\n        for i in range(10):\n            results.append(\n                (\n                    await context.aio.spawn_workflow(\n                        \"Child\", {\"a\": str(i)}, key=f\"child{i}\"\n                    )\n                ).result()\n            )\n\n        result = await asyncio.gather(*results)\n\n        return {\"results\": result}\n\n\n@hatchet.workflow()\nclass Child:\n    @hatchet.step()\n    async def process(self, context: Context):\n        a = context.workflow_input()[\"a\"]\n        return {\"status\": \"success \" + a}\n\ndef main():\n    worker = hatchet.worker(\"fanout-worker\", max_runs=40)\n    worker.register_workflow(Parent())\n    worker.register_workflow(Child())\n    worker.start()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet Client Token Environment Variable\nDESCRIPTION: Sets the HATCHET_CLIENT_TOKEN environment variable, which is essential for authenticating requests to the Hatchet API. Users must replace \"<your-client-token>\" with their actual API token, emphasizing the importance of keeping the token private.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/setup.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport HATCHET_CLIENT_TOKEN=\"<your-client-token>\"\n```\n\n----------------------------------------\n\nTITLE: Enabling Read Replica Configuration in Bash\nDESCRIPTION: This code snippet demonstrates how to configure read replica support in Hatchet by setting environment variables. It includes settings for enabling the read replica, specifying the database URL, and configuring connection pool sizes.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/read-replicas.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nREAD_REPLICA_ENABLED=true\nREAD_REPLICA_DATABASE_URL='postgresql://hatchet:hatchet@127.0.0.1:5432/hatchet'\nREAD_REPLICA_MAX_CONNS=200\nREAD_REPLICA_MIN_CONNS=50\n```\n\n----------------------------------------\n\nTITLE: Setting Runtime Priority - Python\nDESCRIPTION: This snippet showcases how to set the priority of a Hatchet run when triggering it in Python. This overrides the default workflow priority for that specific run.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexamples/priority/trigger.py\n```\n\n----------------------------------------\n\nTITLE: Defining On-Failure Task in Python\nDESCRIPTION: This snippet demonstrates how to define an on-failure task within a Hatchet workflow using Python. It showcases the syntax and structure for specifying the on-failure function, which will be executed if any main task in the workflow fails. The snippet is located in `examples/on_failure/worker.py` and targets the \"OnFailure Step\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/on-failure-tasks.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/on_failure/worker.py\n```\n\n----------------------------------------\n\nTITLE: Defining a Hatchet Workflow with Tasks in Python\nDESCRIPTION: This snippet demonstrates how to define a Hatchet workflow using the `hatchet.workflow` method and define a task using the `@workflow.task()` decorator.  It showcases the creation of a workflow with an input type defined using `pydantic.BaseModel` and how to trigger the workflow with a sample input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/sdks/python/runnables.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom hatchet_sdk import Hatchet\n\nclass MyInput(BaseModel):\n    name: str\n\nhatchet = Hatchet()\nworkflow = hatchet.workflow(\"my-workflow\", input_type=MyInput)\n\n@workflow.task()\ndef greet(input, ctx):\n    return f\"Hello, {input.name}!\"\n\n# Run the workflow\nresult = workflow.run(MyInput(name=\"World\"))\n```\n\n----------------------------------------\n\nTITLE: Pushing Events with Additional Metadata - Go\nDESCRIPTION: This snippet demonstrates how to push an event with additional metadata using the Hatchet Go client. It uses the `c.Event().Push` method along with `client.WithEventMetadata` to attach a key-value pair to the event. The metadata is passed as a `map[string]string` to the `client.WithEventMetadata` function.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nerr := c.Event().Push(\n    context.Background(),\n    \"user:create\",\n    testEvent,\n    client.WithEventMetadata(map[string]string{\n        \"source\": \"api\", // Arbitrary key-value pair\n    }),\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Event Triggered Workflow - Typescript\nDESCRIPTION: Defines a Hatchet workflow triggered by the `user:created` event. It includes an `on` property specifying the event that triggers the workflow. Requires the `@hatchet-dev/typescript-sdk` package.  The `steps` array should contain the workflow steps definition.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"A workflow triggered by an event\",\n  on: {\n    event: \"user:created\",\n  },\n  steps: [\n    // Define your workflow steps here\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Pushing Events with Additional Metadata - Python\nDESCRIPTION: This snippet demonstrates how to push an event with additional metadata using the Hatchet Python client. It uses the `hatchet.event.push` method with the `PushEventOptions` class to attach a key-value pair to the event. The key-value pair is passed as a dictionary to the `additional_metadata` argument.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/additional-metadata.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nhatchet.event.push(\n    \"user:create\",\n    {'userId': '1234'},\n    options=PushEventOptions(\n        additional_metadata={\n            \"source\": \"api\" # Arbitrary key-value pair\n        }\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client Go\nDESCRIPTION: This snippet demonstrates how to instantiate a new Hatchet client using the V1 SDK. It imports the necessary `v1` package and calls the `NewHatchetClient()` function, handling any potential errors during the instantiation process.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-go.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n    v1 \"github.com/hatchet-dev/hatchet/pkg/v1\"\n)\n\nfunc main() {\n    hatchet, err := v1.NewHatchetClient()\n\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Running a Task in Go\nDESCRIPTION: This code snippet, sourced from Github, demonstrates running a Hatchet task in Go. The code is retrieved from the file specified in `SimpleGo` and the section labelled \"Running a Task\". It illustrates how to execute a task as part of a Go-based workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/running-your-task.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={SimpleGo} target=\"Running a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Static Rate Limit Declaration (Python)\nDESCRIPTION: This snippet shows how to declare a static rate limit using the `put_rate_limit` method in the Hatchet `Admin` client in Python.  The `RATE_LIMIT_KEY` is defined, and a limit of 10 per minute is set. Requires the Hatchet library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/rate-limits.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nRATE_LIMIT_KEY = \"test-limit\"\n\nhatchet.rate_limits.put(RATE_LIMIT_KEY, 10, RateLimitDuration.MINUTE)\n```\n\n----------------------------------------\n\nTITLE: Setting Scheduled Priority - TypeScript\nDESCRIPTION: This snippet illustrates how to set the priority for Hatchet runs scheduled via cron or other mechanisms in TypeScript. This configuration ensures consistent prioritization of scheduled workflows.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/priority/run.ts\n```\n\n----------------------------------------\n\nTITLE: Add Wait For Sleep Task - Go\nDESCRIPTION: This snippet adds a task that waits for a specified sleep duration (10 seconds) using the `wait_for` condition in Go. This task is a child of the base task and demonstrates the use of sleep conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_8\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Compute Configuration TypeScript\nDESCRIPTION: This snippet demonstrates how to define a basic compute configuration using the `SharedCPUCompute` interface from the `@hatchet-dev/typescript-sdk`. It sets parameters like CPU kind, memory, number of replicas, and regions. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/managed-compute.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { SharedCPUCompute } from \"@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config\";\nimport { ManagedWorkerRegion } from \"@hatchet-dev/typescript-sdk/clients/rest/generated/cloud/data-contracts\";\n\n// Define a basic compute configuration\nconst basicCompute: SharedCPUCompute = {\n  cpuKind: \"shared\",\n  memoryMb: 1024,\n  numReplicas: 1,\n  cpus: 1,\n  regions: [ManagedWorkerRegion.Ewr],\n};\n\n// Define a more powerful compute configuration\nconst performanceCompute: PerformanceCPUCompute = {\n  cpuKind: \"performance\",\n  memoryMb: 2048,\n  numReplicas: 2,\n  cpus: 2,\n  regions: [ManagedWorkerRegion.Ewr],\n};\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Task Hatchet Go\nDESCRIPTION: This snippet shows how to define a simple task using the `factory` package in the V1 SDK. It defines input and result structs, and uses `factory.NewTask` with a `create.StandaloneTask` to create the task, along with a function that transforms the input message to lowercase.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-go.mdx#_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nimport \"github.com/hatchet-dev/hatchet/pkg/v1/factory\"\n\n// ...\n\ntype SimpleInput struct {\n    Message string\n}\n\ntype SimpleResult struct {\n    TransformedMessage string\n}\n\nsimple := factory.NewTask(\n    create.StandaloneTask{\n        Name: \"simple-task\",\n    }, func(ctx worker.HatchetContext, input SimpleInput) (*SimpleResult, error) {\n        return &SimpleResult{\n            TransformedMessage: strings.ToLower(input.Message),\n        }, nil\n    },\n    hatchet, // a Hatchet client instance\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Step Cancellations\nDESCRIPTION: This snippet demonstrates how to handle step cancellations using the `ctx.controller.signal` property, which returns an `AbortController` signal. It checks if the step has been aborted using `signal.aborted` and throws an error if it has. The signal can also be passed to HTTP libraries to cancel active requests.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\n{\n    \"step1\",\n    run: async (ctx) => {\n      const { data } = ctx.workflowInput();\n      const { signal } = ctx.controller;\n\n      if (signal.aborted) throw new Error(\"step1 was aborted\");\n\n      console.log(\"starting step1 and waiting 5 seconds...\", data);\n      await sleep(5000);\n\n      if (signal.aborted) throw new Error(\"step1 was aborted\");\n\n      // NOTE: the AbortController signal can be passed to many http libraries to cancel active requests\n      // fetch(url, { signal })\n      // axios.get(url, { signal })\n\n      console.log(\"executed step1!\");\n      return { step1: `step1 results for ${data}!` };\n    },\n  },\n\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow and Starting Worker in Typescript\nDESCRIPTION: This TypeScript snippet illustrates the process of registering a workflow with a Hatchet worker and initiating the worker. The `main` function initializes the worker asynchronously, registers a workflow, and then starts the worker, allowing it to receive and process tasks from the Hatchet engine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workers.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const worker = await hatchet.worker(\"example-worker\");\n  await worker.registerWorkflow(workflow);\n  worker.start();\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Abort Signal in Typescript\nDESCRIPTION: This Typescript snippet demonstrates how to pass the `AbortSignal` to an `axios` request. If the task is canceled while the request is still pending, the request will be automatically aborted, and an error will be thrown.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cancellation.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n```typescript\n    import axios from 'axios';\n\n    hatchet.task('abort-task', async (context) => {\n      try {\n        const response = await axios.get('https://example.com/data', {\n          signal: context.controller.signal,\n        });\n        console.log(response.data);\n      } catch (error: any) {\n        if (axios.isCancel(error)) {\n          console.log('Request cancelled', error.message);\n        } else {\n          // handle error\n        }\n      }\n    });\n```\n```\n\n----------------------------------------\n\nTITLE: Subscribing to results - Go\nDESCRIPTION: This snippet demonstrates subscribing to the results of a task in Go after it has been enqueued with `RunNoWait` in Hatchet.  It uses the `GithubSnippet` component to include the relevant code from the `SimpleGo` file. The code retrieves and handles the output or outcome of the enqueued task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={SimpleGo} target=\"Subscribing to results\" />\n```\n\n----------------------------------------\n\nTITLE: Filtering Durable Event in Go\nDESCRIPTION: This snippet demonstrates how to filter durable events in Go using Hatchet and CEL expressions. It shows how to receive only specific events based on a filter. The code is located in the `examples/v1/workflows/durable-event.go` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={DurableGo} target=\"Durable Event With Filter\" />\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Models for API Requests in Python\nDESCRIPTION: This snippet defines two Pydantic models, `Message` and `MessageRequest`, to structure the request body for the API.  The `Message` model defines the role and content of a single message, while the `MessageRequest` model defines a list of messages and a URL. These models are used for request validation and data serialization/deserialization.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/api-server-setup.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom typing import List\n\n\nclass Message(BaseModel):\n    role: str\n    content: str\n\n\nclass MessageRequest(BaseModel):\n    messages: List[Message]\n    url: str\n```\n\n----------------------------------------\n\nTITLE: Sticky Child Task - Python\nDESCRIPTION: This snippet demonstrates how to spawn child tasks on the same worker as the parent task in Python. It uses the 'sticky' property in the run method options.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexamples/sticky_workers/worker.py\n```\n\n----------------------------------------\n\nTITLE: Configuring Step Retries in Python\nDESCRIPTION: This snippet demonstrates how to configure step-level retries in a Hatchet workflow using Python. The `@hatchet.step` decorator is used to define a step with a timeout of 30 seconds and a retry count of 3.  Dependencies: `hatchet` library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout='30s', retries=3)\ndef step1(self, context: Context):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Initialize a New Go Project - Bash\nDESCRIPTION: This command initializes a new Go module named `hatchet-tutorial`. This command is required to manage dependencies for the project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngo mod init hatchet-tutorial\n```\n\n----------------------------------------\n\nTITLE: Spawning Tasks from within a Task - Typescript\nDESCRIPTION: Demonstrates how to spawn a task from within another task using the `runChild` method on the `ctx` parameter of the task function in Typescript.  This approach associates the runs in the dashboard for easier debugging.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_4\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Spawning Tasks from within a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Complete Workflow Example TypeScript\nDESCRIPTION: This snippet demonstrates a complete workflow example using different compute configurations (CPU and GPU) with the Hatchet TypeScript SDK. It defines compute configurations, a workflow with two steps using different configurations, and starts a worker to execute the workflow. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/managed-compute.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\nimport { ManagedWorkerRegion } from \"@hatchet-dev/typescript-sdk/clients/rest/generated/cloud/data-contracts\";\nimport {\n  GPUCompute,\n  SharedCPUCompute,\n} from \"@hatchet-dev/typescript-sdk/clients/worker/compute/compute-config\";\n\nconst hatchet = Hatchet.init();\n\n// Define compute configurations\nconst cpuCompute: SharedCPUCompute = {\n  cpuKind: \"shared\",\n  memoryMb: 1024,\n  numReplicas: 1,\n  cpus: 1,\n  regions: [ManagedWorkerRegion.Ewr],\n};\n\nconst gpuCompute: GPUCompute = {\n  cpuKind: \"shared\",\n  gpuKind: \"l40s\",\n  memoryMb: 1024,\n  numReplicas: 1,\n  cpus: 2,\n  gpus: 1,\n  regions: [ManagedWorkerRegion.Ewr],\n};\n\n// Define workflow\nconst workflow: Workflow = {\n  id: \"simple-workflow\",\n  description: \"Mixed compute workflow example\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      compute: cpuCompute,\n      run: async (ctx) => {\n        console.log(\"executed step1!\");\n        return { step1: \"step1 results!\" };\n      },\n    },\n    {\n      name: \"step2\",\n      parents: [\"step1\"],\n      compute: gpuCompute,\n      run: (ctx) => {\n        console.log(\n          \"executed step2 after step1 returned \",\n          ctx.stepOutput(\"step1\"),\n        );\n        return { step2: \"step2 results!\" };\n      },\n    },\n  ],\n};\n\n// Start worker\nasync function main() {\n  const worker = await hatchet.worker(\"managed-worker\");\n  await worker.registerWorkflow(workflow);\n  worker.start();\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client\nDESCRIPTION: This Go snippet initializes the Hatchet client using the `hatchet-dev/hatchet/pkg/client` package. It defines a `Client` function that returns a new Hatchet client instance or an error if initialization fails. The `client.New()` function handles the actual client creation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/go.mdx#_snippet_3\n\nLANGUAGE: go\nCODE:\n```\npackage hatchet\n\nimport (\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n)\n\nfunc Client() (client.Client, error) {\n\treturn client.New()\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Task with Hatchet (Typescript)\nDESCRIPTION: This code snippet demonstrates how to define a simple task using the `hatchet.task` factory function in Typescript. It shows how to define the task name, input type (`SimpleInput`), and the task's function (`fn`). The function takes an input of type `SimpleInput` and returns a transformed message in lowercase.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const simple = hatchet.task({\n  name: \"simple\",\n  fn: (input: SimpleInput) => {\n    return {\n      TransformedMessage: input.Message.toLowerCase(),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Trigger in Workflow - Typescript\nDESCRIPTION: Defines a workflow with a cron schedule using Typescript. This snippet showcases how to configure the `on cron` property in the workflow definition to specify the cron expression.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/examples/crons/cron-worker.ts\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Tasks in Parallel - Typescript\nDESCRIPTION: Demonstrates how to run multiple tasks in parallel in Typescript by using `Promise.all` to await multiple promises returned by `run`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_7\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Running Multiple Tasks\" />\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet REST API Client\nDESCRIPTION: This code snippet demonstrates how to initialize the Hatchet client and access the REST API for interacting with workflows.  It shows how to create a Hatchet client instance and then call the `workflow_list` method on the REST client to retrieve a list of workflows. The `debug=True` argument enables debugging mode.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/api.mdx#_snippet_0\n\nLANGUAGE: py\nCODE:\n```\nhatchet = Hatchet(debug=True)\n\nlist : WorkflowList = hatchet.client.rest().workflow_list()\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Internal Events - Python\nDESCRIPTION: Demonstrates how to push multiple internal events from within a Python application using the Hatchet SDK. The `hatchet.client.event.bulk_push` method is used to push a list of events with specified payloads and metadata. Requires the `hatchet_sdk` library and typing List, BulkPushEventWithMetadata\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nevents: List[BulkPushEventWithMetadata] = [\n    {\n        \"key\": \"event1\",\n        \"payload\": {\"message\": \"This is event 1\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user123\"},\n    },\n    {\n        \"key\": \"event2\",\n        \"payload\": {\"message\": \"This is event 2\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user456\"},\n    },\n    {\n        \"key\": \"event3\",\n        \"payload\": {\"message\": \"This is event 3\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user789\"},\n    },\n]\n\n\nresult =\nhatchet.client.event.bulk_push(\n    events\n)\n```\n\n----------------------------------------\n\nTITLE: Running concurrent API calls using async/await - Python\nDESCRIPTION: This snippet shows how Hatchet tasks can utilize `async` / `await` and `asyncio.gather` to make concurrent API calls. This allows developers to leverage the full power of `asyncio` in Python without needing to increase worker concurrency. This is more performant and puts less pressure on the backing queue.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\n```python\nimport asyncio\n\nfrom aiohttp import ClientSession\n\nfrom hatchet_sdk import Context, EmptyModel, Hatchet\n\nhatchet = Hatchet()\n\n\nasync def fetch(session: ClientSession, url: str) -> bool:\n    async with session.get(url) as response:\n        return response.status == 200\n\n\n@hatchet.task(name=\"Fetch\")\nasync def hello_from_hatchet(input: EmptyModel, ctx: Context) -> int:\n    num_requests = 10\n\n    async with ClientSession() as session:\n        tasks = [\n            fetch(session, \"https://docs.hatchet.run/home\") for _ in range(num_requests)\n        ]\n\n        results = await asyncio.gather(*tasks)\n\n        return results.count(True)\n```\n```\n\n----------------------------------------\n\nTITLE: Streaming Events by Metadata (Python)\nDESCRIPTION: This Python snippet demonstrates how to stream events by a specific additional metadata key-value pair using `hatchet.listener.stream_by_additional_metadata`. It retrieves events from the stream and prints their type and payload.  The snippet requires the `hatchet` library to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nlistener = hatchet.listener.stream_by_additional_metadata(streamKey, streamVal)\n\nasync for event in listener:\n    print(event.type, event.payload)\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Events with Hatchet Go Client\nDESCRIPTION: This code snippet demonstrates how to push multiple events in bulk to the Hatchet event processing system using the `Event().BulkPush` method. It creates a slice of `EventWithMetadata` structs, each containing an event, additional metadata, and a key. The `BulkPush` method sends all events in a single request, improving efficiency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/pushing-events.mdx#_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nevents := []client.EventWithMetadata{\n  {\n    Event: &events.TestEvent{\n      Name: \"testing\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world1\"},\n    Key: \"event1\",\n  },\n  {\n    Event: &events.TestEvent{\n      Name: \"testing2\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world2\"},\n    Key: \"event2\",\n  },\n}\n\nc.Event().BulkPush(\n  context.Background(),\n  events,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Data Retention Period Environment Variable\nDESCRIPTION: This snippet demonstrates how to set the SERVER_LIMITS_DEFAULT_TENANT_RETENTION_PERIOD environment variable, which configures the default data retention period for a Hatchet tenant. The retention period is specified as a Go duration string.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/data-retention.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nSERVER_LIMITS_DEFAULT_TENANT_RETENTION_PERIOD=720h # 30 days\n```\n\n----------------------------------------\n\nTITLE: Defining Action Model with Composite Key in Prisma\nDESCRIPTION: This code snippet defines a Prisma model named `Action` with a composite unique constraint on `tenantId` and `actionId`. It also establishes a relation to the `Tenant` model, specifying cascading deletes and updates.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nmodel Action {\n  actionId String\n\n  tenant   Tenant @relation(fields: [tenantId], references: [id], onDelete: Cascade, onUpdate: Cascade)\n  tenantId String @db.Uuid\n\n  @@unique([tenantId, actionId])\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Rate of Queue Invocations (PromQL)\nDESCRIPTION: This PromQL query calculates the rate of calls to the queuer method over a 5-minute window using the `hatchet_queue_invocations_total` metric, which is a counter.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_1\n\nLANGUAGE: promql\nCODE:\n```\nrate(hatchet_queue_invocations_total[5m])\n```\n\n----------------------------------------\n\nTITLE: Configuring Bearer Token Authentication with Hatchet SDK in Python\nDESCRIPTION: This snippet configures Bearer token authentication for the Hatchet SDK using an environment variable to store the Bearer token.  It initializes a `Configuration` object from the `hatchet_sdk.clients.rest` module, passing the access token.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Looping: Spawning Child Workflows in Typescript\nDESCRIPTION: This TypeScript snippet shows how to spawn child workflows within a loop in a parent workflow step. It uses `ctx.spawnWorkflow` to create multiple child workflows with dynamic input. The workflow and step are defined as objects with properties like `id`, `on`, `steps`, and `run`. It relies on the `Workflow` type from the Hatchet library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        for (let i = 0; i < 10; i++) {\n          ctx.spawnWorkflow<string>(\"child-workflow\", {\n            input: `child-input-${i}`,\n          });\n        }\n\n        return {};\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Add Wait For Sleep Task - TypeScript\nDESCRIPTION: This snippet adds a task that waits for a specified sleep duration (10 seconds) using the `wait_for` condition in TypeScript. This task is a child of the base task and demonstrates the use of sleep conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_7\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Create Project Directories\nDESCRIPTION: This command creates two directories: `workflows` and `workers`.  These directories are recommended for organizing your Hatchet workflows and worker implementations, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/ts.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir workflows &&\nmkdir workers\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Simple Task - Python\nDESCRIPTION: This code snippet demonstrates how to define a simple task in Python using Hatchet, including defining an input validator using BaseModel, registering the task with a worker, and invoking the task. The task transforms an input message to lowercase.  Requires the `hatchet` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# 1. Define your task input\nclass SimpleInput(BaseModel):\n    message: str\n\n# 2. Define your task using hatchet.task\n@hatchet.task(name=\"SimpleWorkflow\", input_validator=SimpleInput)\ndef simple(input: SimpleInput, ctx: Context) -> dict[str, str]:\n    return {\n      \"transformed_message\": input.message.lower(),\n    }\n\n# 3. Register your task on your worker\nworker = hatchet.worker(\"test-worker\", workflows=[simple])\nworker.start()\n\n# 4. Invoke tasks from your application\nsimple.run(SimpleInput(message=\"Hello World!\"))\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Worker - Go\nDESCRIPTION: This snippet defines a sticky worker in Go. It shows the structure and required configurations for setting up a worker that maintains state across multiple tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nexamples/assignment-sticky/run.go\n```\n\n----------------------------------------\n\nTITLE: Multi-stage Dockerfile Build for GPU\nDESCRIPTION: This Dockerfile uses a multi-stage build process to create a smaller and more efficient image for GPU workloads. The builder stage installs the CUDA compiler (nvcc), and the runtime stage copies only the necessary CUDA libraries. It requires Ubuntu 22.04 as the base image.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Build stage\nFROM ubuntu:22.04 AS builder\nRUN apt-get update && apt-get install -y cuda-nvcc-12-2\n\n# Runtime stage\nFROM ubuntu:22.04\nCOPY --from=builder /usr/local/cuda-12.2 /usr/local/cuda-12.2\n```\n\n----------------------------------------\n\nTITLE: Mounting Environment Variables from Secrets (YAML)\nDESCRIPTION: This YAML snippet shows how to mount the DATABASE_URL environment variable from a Kubernetes secret.  It uses the `deploymentEnvFrom` field to reference a secret named `hatchet-api-secrets` and specifies the key `DATABASE_URL`. This configuration applies to both the `hatchet-api` and `hatchet-engine` deployments. Prerequisites include a Kubernetes cluster and the creation of the specified secret.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nhatchet-api:\n  deploymentEnvFrom:\n    - secretRef:\n        name: hatchet-api-secrets\n        key: DATABASE_URL\n\nhatchet-engine:\n  deploymentEnvFrom:\n    - secretRef:\n        name: hatchet-api-secrets\n        key: DATABASE_URL\n```\n\n----------------------------------------\n\nTITLE: Creating a Go Worker\nDESCRIPTION: This Go code defines a simple Hatchet workflow with one step and registers it with a worker. It uses the `github.com/joho/godotenv` package for loading environment variables from a `.env` file, and the `github.com/hatchet-dev/hatchet` packages for the Hatchet SDK.  It initializes the Hatchet client, defines a workflow and a step, registers the workflow with the worker, and starts the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_13\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/joho/godotenv\"\n\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/cmdutils\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype stepOutput struct{}\n\nfunc main() {\n\terr := godotenv.Load()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tc, err := client.New()\n\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating client: %v\", err))\n\t}\n\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithMaxRuns(1),\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating worker: %v\", err))\n\t}\n\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tName:        \"simple-workflow\",\n\t\t\tDescription: \"Simple one-step workflow.\",\n      On:          worker.Events(\"simple\"),\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOutput, err error) {\n\t\t\t\t\tfmt.Println(\"executed step 1\")\n\n\t\t\t\t\treturn &stepOutput{}, nil\n\t\t\t\t},\n\t\t\t\t).SetName(\"step-one\"),\n\t\t\t},\n\t\t},\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error registering workflow: %v\", err))\n\t}\n\n\tinterruptCtx, cancel := cmdutils.InterruptContextFromChan(cmdutils.InterruptChan())\n\tdefer cancel()\n\n\tcleanup, err := w.Start()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error starting worker: %v\", err))\n\t}\n\n\t<-interruptCtx.Done()\n\tif err := cleanup(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Defining an Async Step in Hatchet (Python)\nDESCRIPTION: This code demonstrates how to define an asynchronous step in a Hatchet workflow using the `async` keyword. The `step1` function is defined as an `async` function, which allows it to perform asynchronous operations such as `await asyncio.sleep(1)`. This is useful for non-blocking operations.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    async def step1(self, context : Context):\n        print(\"executed step1\", context.workflow_input())\n        await asyncio.sleep(1)\n        pass\n```\n\n----------------------------------------\n\nTITLE: Configuring Step Retries in Typescript\nDESCRIPTION: This snippet shows how to define a step with retries in Typescript using the `@hatchet-dev/typescript-sdk`. It creates a `CreateStepSchema` object with properties for name, timeout, and retries.  Dependencies: `@hatchet-dev/typescript-sdk`, `z` (likely Zod for schema validation).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { CreateStepSchema } from \"@hatchet-dev/typescript-sdk\";\n\nconst step1: z.infer<typeof CreateStepSchema> = {\n  name: \"step1\",\n  timeout: \"30s\",\n  retries: 3,\n};\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Trigger in Workflow - Python (Sync)\nDESCRIPTION: Defines a workflow with a cron schedule using Python (synchronous). This snippet showcases how to configure the `on cron` property in the workflow definition to specify the cron expression.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/workflow-definition.py\n```\n\n----------------------------------------\n\nTITLE: Referencing Action Model in Step Model using Prisma\nDESCRIPTION: This snippet showcases how to reference the `Action` model within the `Step` model using a composite key (`actionId` and `tenantId`). It establishes a relation between the two models, ensuring data consistency across related tables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\nmodel Step {\n  action   Action @relation(fields: [actionId, tenantId], references: [actionId, tenantId])\n\n  actionId String\n  tenantId String @db.Uuid\n}\n```\n\n----------------------------------------\n\nTITLE: Add Skip On Event Task - Go\nDESCRIPTION: This snippet adds a task that will be skipped if a specific event (`skip_on_event:skip`) is fired, using the `skip_if` condition in Go. This task demonstrates how to skip tasks based on event conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_11\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Hatchet task for the future - Python\nDESCRIPTION: This snippet shows how to schedule a Hatchet task to run at a future time, similar to Celery's `eta` or `countdown` features.  Hatchet does not hold scheduled tasks in memory, allowing scheduling for arbitrary future times.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={ChildTrigger} target=\"Schedule a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Create Directories\nDESCRIPTION: Creates the 'workflows' and 'workers' directories. These directories are conventionally used to store workflow definitions and worker implementations, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/py.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir workflows &&\nmkdir workers\n```\n\n----------------------------------------\n\nTITLE: Scheduling Task (Go)\nDESCRIPTION: Schedules a Hatchet task to run tomorrow and schedules another task to run every day at midnight using cron scheduling in Go. Requires the `time` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nconst tomorrow = time.Now().Add(24 * time.Hour);\n\n// schedule a task to run tomorrow\nsimple.Schedule(ctx, tomorrow, ScheduleInput{\n  Message: \"Hello, World!\",\n})\n\n// schedule a task to run every day at midnight\nsimple.Cron(ctx, \"every-day\", \"0 0 * * *\", CronInput{\n  Message: \"Hello, World!\",\n})\n```\n\n----------------------------------------\n\nTITLE: Async Safe Task with asyncio.to_thread\nDESCRIPTION: This code snippet demonstrates how to safely execute a blocking operation (`time.sleep`) within an asyncio task using `asyncio.to_thread`. This prevents the event loop from being blocked, allowing other tasks to execute concurrently. This method requires Python 3.9+.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/asyncio.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nasync def my_task() -> int:\n    await asyncio.to_thread(time.sleep, 5)\n\n    return 42\n```\n\n----------------------------------------\n\nTITLE: Get Workflows using Hatchet SDK in Python\nDESCRIPTION: This snippet demonstrates how to retrieve a list of workflows for a given tenant using the Hatchet SDK. It configures API client with authentication (API Key or Bearer Token), creates a WorkflowApi instance, calls the workflow_list method, and prints the response.  It depends on the hatchet_sdk.clients.rest library and requires setting up authentication via environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow_list import WorkflowList\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    tenant = 'tenant_example' # str | The tenant id\n\n    try:\n        # Get workflows\n        api_response = api_instance.workflow_list(tenant)\n        print(\"The response of WorkflowApi->workflow_list:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_list: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Add Wait For Sleep Task - Python\nDESCRIPTION: This snippet adds a task that waits for a specified sleep duration (10 seconds) using the `wait_for` condition in Python. This task is a child of the base task and demonstrates the use of sleep conditions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nexamples/waits/worker.py\n```\n\n----------------------------------------\n\nTITLE: Port Forward Hatchet Engine\nDESCRIPTION: This script port forwards the Hatchet engine pod to localhost:7070, allowing local access to the Hatchet engine service. It retrieves the pod name and container port dynamically using `kubectl`. Requires `kubectl` and assumes that the Hatchet engine is running in the specified namespace.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nexport NAMESPACE=hatchet # TODO: change if you modified the namespace\nexport POD_NAME=$(kubectl get pods --namespace $NAMESPACE -l \"app.kubernetes.io/name=hatchet-engine,app.kubernetes.io/instance=hatchet\" -o jsonpath=\"{.items[0].metadata.name}\")\nexport CONTAINER_PORT=$(kubectl get pod --namespace $NAMESPACE $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\nkubectl --namespace $NAMESPACE port-forward $POD_NAME 7070:$CONTAINER_PORT\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Workflow with Tasks - Typescript\nDESCRIPTION: This Typescript code demonstrates how to define a workflow with two tasks using Hatchet. It includes attaching the first task to the workflow, then attaching the second task as a child of the first, creating a simple DAG. The second task accesses the output of the first task using `ctx.getParentOutput`. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_4\n\nLANGUAGE: Typescript\nCODE:\n```\n// 1. Define a workflow (a workflow is a collection of tasks)\nconst simple = hatchet.workflow<DagInput, DagOutput>({\n  name: \"simple\",\n});\n\n// 2. Attach the first task to the workflow\nconst task1 = simple.task({\n  name: \"task-1\",\n  fn: (input) => {\n    return {\n      result: \"task-1\",\n    };\n  },\n});\n\n// 3. Attach the second task to the workflow, which executes after task-1\nconst task2 = simple.task({\n  name: \"task-2\",\n  parents: [task1],\n  fn: (input, ctx) => {\n    const firstResult = ctx.getParentOutput(task1);\n    console.log(firstResult);\n  },\n});\n\n// 4. Invoke workflows from your application\nawait simple.run({ Message: \"Hello World\" });\n```\n\n----------------------------------------\n\nTITLE: Specifying Step Desired Labels - Python\nDESCRIPTION: This code snippet shows how to specify desired worker label state for a Hatchet step in Python. It uses the `desired_worker_labels` property on the `@hatchet.step` decorator to specify the desired label values, comparators, and weights. The step requires a worker with `memory` greater than 256 and prioritizes workers with `model` equal to \"fancy-ai-model-v2\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(\n    desired_worker_labels={\n        \"model\": {\n            \"value\": \"fancy-ai-model-v2\",\n            \"weight\": 10\n        },\n        \"memory\": {\n            \"value\": 256,\n            \"required\": True,\n            \"comparator\": WorkerLabelComparator.GREATER_THAN,\n        }\n    },\n)\nasync def step(self, context: Context):\n    return {\"worker\": context.worker.id()}\n```\n\n----------------------------------------\n\nTITLE: Sticky Child Task - TypeScript\nDESCRIPTION: This snippet demonstrates how to spawn child tasks on the same worker as the parent task in TypeScript. It uses the 'sticky' property in the run method options. The snippet targets the 'Sticky Task' section of the file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/sticky/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Steps with Compute Requirements in Python\nDESCRIPTION: This snippet demonstrates how to define workflow steps with specific compute requirements using the `hatchet.step` decorator. It shows how to pass a compute configuration (defined previously) to the `compute` parameter of the decorator. This allows you to specify different compute resources for different steps in your workflow.  Requires the `hatchet_sdk` package and a defined `Hatchet` instance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/managed-compute.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet()\n\n@hatchet.workflow(on_events=[\"user:create\"])\nclass ManagedWorkflow:\n    @hatchet.step(\n        timeout=\"11s\",\n        retries=3,\n        compute=default_compute\n    )\n    def step1(self, context: Context):\n        print(\"executed step1\")\n        time.sleep(10)\n        return {\n            \"step1\": \"step1\",\n        }\n\n    @hatchet.step(\n        timeout=\"11s\",\n        retries=3,\n        compute=basic\n    )\n    def step2(self, context: Context):\n        print(\"executed step2\")\n        time.sleep(10)\n        return {\n            \"step2\": \"step2\",\n        }\n```\n\n----------------------------------------\n\nTITLE: Import Hatchet Client\nDESCRIPTION: This TypeScript code imports the Hatchet client from the `hatchet-client.ts` file. This allows you to use the Hatchet client in other files within your project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/ts.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { hatchet } from \"./hatchet-client\";\n```\n\n----------------------------------------\n\nTITLE: Running a Task and Awaiting Result - Go\nDESCRIPTION: Demonstrates how to run a task and wait for its result in Go using the `Run` method of the `Task` object. This method blocks until the task completes and returns the result.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={SimpleGo} target=\"Running a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with CEL Expression (Typescript)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Typescript using an expression to define the concurrency group. It sets the maximum number of concurrent runs to 10 and uses the `input.group` expression to determine the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nexport const concurrencyDemoWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"My workflow with concurrency control\",\n  on: {\n    event: \"concurrency-test\",\n  },\n  steps: [\n    // ...\n  ],\n  concurrency: {\n    name: \"my-workflow-concurrency\",\n    maxRuns: 10,\n    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n    expression: \"input.group\",\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Run Result - Hatchet TypeScript\nDESCRIPTION: This snippet retrieves the result of a specific workflow run using the `getWorkflowRun` and `result` methods. It takes a workflow run ID as input and prints the final result of the workflow run to the console. Requires the `@hatchet-dev/typescript-sdk` package to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/get-workflow-results.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflowRun = hatchet.admin.getWorkflowRun(\n  \"5a3a617d-1200-4ee2-92e6-be4bd27ca26f\",\n);\nconst result = await workflowRun.result();\n\nconsole.log(\"workflow run result:\", result);\n```\n\n----------------------------------------\n\nTITLE: Bulk Running Tasks from within a Task in Typescript\nDESCRIPTION: This Typescript code snippet demonstrates how to use the `bulkRunChildren` and `bulkRunChildrenNoWait` methods to bulk run tasks from within a task in Hatchet using the `Context` object. These methods are useful for creating child tasks that run in parallel.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-run.mdx#_snippet_2\n\nLANGUAGE: Typescript\nCODE:\n```\nsrc/v1/examples/simple/bulk.ts\n```\n\n----------------------------------------\n\nTITLE: Creating/Deleting/Listing Cron Trigger - Typescript\nDESCRIPTION: These snippets show how to programmatically create, delete, and list cron triggers using the Hatchet SDK in TypeScript. This approach allows for dynamically setting the cron schedule of a task using the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/v1/examples/simple/cron.ts\n```\n\n----------------------------------------\n\nTITLE: Popping Tasks from Queue in Postgres\nDESCRIPTION: This SQL query retrieves tasks with the status 'QUEUED', orders them by ID, and updates their status to 'RUNNING'. The `FOR UPDATE SKIP LOCKED` clause ensures that concurrent workers do not process the same task, while the `LIMIT` clause controls the number of tasks retrieved.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\n-- name: PopTasks :many\nWITH\n    eligible_tasks AS (\n        SELECT\n            *\n        FROM\n            tasks\n        WHERE\n            \"status\" = 'QUEUED'\n        ORDER BY id ASC\n        FOR UPDATE SKIP LOCKED\n        LIMIT\n            COALESCE(sqlc.narg('limit'), 10)\n    )\nUPDATE tasks\nSET\n    \"status\" = 'RUNNING'\nFROM\n    eligible_tasks\nWHERE\n    tasks.id = eligible_tasks.id\nRETURNING tasks.*;\n```\n\n----------------------------------------\n\nTITLE: Chicago-Based A10 Configuration in Hatchet\nDESCRIPTION: This code snippet illustrates how to configure a `Compute` object for A10 GPUs specifically in the `ord` (Chicago) region using Hatchet. It sets the `gpu_kind` to `a10`, specifies the number of GPUs, memory allocation, number of replicas, and restricts the region to `ord`.  This ensures that all the GPU instances are created in Chicago.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Chicago-based A10 configuration\ncompute = Compute(\n    gpu_kind=\"a10\",\n    gpus=1,\n    memory_mb=49152,\n    num_replicas=2,\n    regions=[\"ord\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet SDK with poetry\nDESCRIPTION: This code snippet demonstrates how to install the Hatchet Python SDK using poetry. It uses the `poetry add` command, followed by the package name `hatchet-sdk`. This assumes that poetry is installed and configured correctly within the project environment.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/python/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry add hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Using Hatchet Feature Clients (Typescript)\nDESCRIPTION: This code snippet demonstrates how to use the feature clients exposed on the Hatchet client to interact with and control the environment.  It shows how to list workflow runs with a specified status, replay runs by their IDs, and cancel runs based on filters such as date and metadata.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst hatchet = HatchetClient.init();\nconst { runs } = hatchet;\n\nconst allFailedRuns = await runs.list({\n  statuses: [WorkflowRunStatus.FAILED],\n});\n\n// replay by ids\nawait runs.replay({ ids: allFailedRuns.rows?.map((r) => r.metadata.id) });\n\n// or you can run bulk operations with filters directly\nawait runs.cancel({\n  filters: {\n    since: new Date(\"2025-03-27\"),\n    additionalMetadata: { user: \"123\" },\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet client\nDESCRIPTION: Initializes the Hatchet client using the `Hatchet.init()` method from the `@hatchet-dev/typescript-sdk` package. This creates a singleton instance of the Hatchet client for use throughout the project.  It assumes the `@hatchet-dev/typescript-sdk` is installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/ts.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nexport const hatchet = Hatchet.init();\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow with Per-User Concurrency Limits\nDESCRIPTION: This code snippet defines a Hatchet workflow with a concurrency limit of 1, using `GROUP_ROUND_ROBIN` as the `limit_strategy`, and `input.user_id` as the expression. This setup enforces a per-user concurrency limit, ensuring that only one workflow execution per user (identified by `user_id` in the input) runs concurrently.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/fairness.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\n    on_events=[\"concurrency-test\"],\n    concurrency=Concurrency(\n        max_runs=1,\n        limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n        expression=\"input.user_id\",\n    ),\n)\nclass ConcurrencyDemoWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Sticky Child Task - Go\nDESCRIPTION: This snippet demonstrates how to spawn child tasks on the same worker as the parent task in Go. It uses the 'sticky' property in the run method options.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nexamples/assignment-sticky/run.go\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple 2-Step Workflow in Hatchet (Python)\nDESCRIPTION: This code defines a simple 2-step workflow using the `hatchet.workflow` and `hatchet.step` decorators. It initializes a Hatchet client and defines a workflow named `MyWorkflow` that triggers on the `user:create` event. The workflow consists of two steps, `step1` and `step2`, where `step2` depends on `step1` using the `parents` argument. Each step prints a message indicating its execution.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\n@hatchet.workflow(on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n\n    @hatchet.step(parents=[\"step1\"])\n    def step2(self, context):\n        print(\"executed step2\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: SQL Schema Definition for Axes Table\nDESCRIPTION: Defines the schema for an 'axes' table in a PostgreSQL database, including columns for ID (primary key), name, and description. The ID is a big serial, meaning it auto-increments. This schema is used by sqlc to generate type-safe code for interacting with the database.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE axes (\n  id   BIGSERIAL PRIMARY KEY,\n  name text      NOT NULL,\n  description text\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Trigger in Workflow - Go\nDESCRIPTION: Defines a workflow with a cron schedule using Go. This snippet showcases how to configure the `on cron` property in the workflow definition to specify the cron expression.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_3\n\nLANGUAGE: go\nCODE:\n```\nexamples/cron/main.go\n```\n\n----------------------------------------\n\nTITLE: Create Project Directories\nDESCRIPTION: This command creates the necessary 'src', 'src/workflows', and 'src/workers' directories within the project. These directories are used to organize the Hatchet project files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/py.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir src &&\nmkdir src/workflows &&\nmkdir src/workers\n```\n\n----------------------------------------\n\nTITLE: Declaring and Running a Task in Go\nDESCRIPTION: These snippets refer to an external file (examples/v1/workflows/simple.go) to show how to declare and run a task using Go.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/your-first-task.mdx#_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\nGithubSnippet src={SimpleGo} target=\"Declaring a Task\"\n```\n\nLANGUAGE: Go\nCODE:\n```\nGithubSnippet src={SimpleGo} target=\"Running a Task\"\n```\n\n----------------------------------------\n\nTITLE: Spawning Sticky Child Workflow in Go\nDESCRIPTION: This Go code snippet demonstrates how to spawn a child workflow with the `Sticky` option set to `true`. This attempts to force the child workflow to run on the same worker as the parent.  The code checks for errors when spawning the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:             worker.Events(\"user:create:sticky\"),\n\t\t\tName:           \"sticky\",\n\t\t\tDescription:    \"sticky\",\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\n    \t\t\t\tsticky := true\n\n    \t\t\t\t_, err = ctx.SpawnWorkflow(\"sticky-child\", nil, &worker.SpawnWorkflowOpts{\n    \t\t\t\t\tSticky: &sticky,\n    \t\t\t\t})\n\n    \t\t\t\tif err != nil {\n    \t\t\t\t\treturn nil, fmt.Errorf(\"error spawning workflow: %w\", err)\n    \t\t\t\t}\n\n    \t\t\t\treturn &stepOneOutput{\n    \t\t\t\t\tMessage: ctx.Worker().ID(),\n    \t\t\t\t}, nil\n    \t\t\t}).SetName(\"step-one\"),\n    \t\t},\n    \t},\n    )\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client (Python)\nDESCRIPTION: This snippet shows how to initialize a Hatchet client in Python. It creates an instance of the Hatchet client using the `hatchet_sdk` library. This client can be used to interact with the Hatchet service.  Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/mergent-migration-guide.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n```\n\nLANGUAGE: python\nCODE:\n```\nfrom .hatchet_client import hatchet\n```\n\n----------------------------------------\n\nTITLE: Popping Tasks With Concurrency Limit in SQL\nDESCRIPTION: This SQL query retrieves tasks from the queue while respecting a concurrency limit. It uses CTEs to find the minimum queued task ID (`min_id`) and then selects eligible tasks within a specified range determined by `concurrency` and `blockLength`. It updates the status of the selected tasks to 'RUNNING' and returns them, using `FOR UPDATE SKIP LOCKED` to handle concurrent access.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_11\n\nLANGUAGE: sql\nCODE:\n```\n-- name: PopTasksWithConcurrency :many\nWITH\n    min_id AS (\n        SELECT\n            COALESCE(min(id), 0) AS min_id\n        FROM\n            tasks\n        WHERE\n            \"status\" = 'QUEUED'\n    ),\n    eligible_tasks AS (\n        SELECT\n            tasks.id\n        FROM\n            tasks\n        WHERE\n            \"status\" = 'QUEUED' AND\n            \"id\" >= (SELECT min_id FROM min_id) AND\n            \"id\" < (SELECT min_id FROM min_id) + sqlc.arg('concurrency')::int * 1024 * 1024\n        ORDER BY id ASC\n        FOR UPDATE SKIP LOCKED\n        LIMIT\n            COALESCE(sqlc.narg('limit')::int, 10)\n    )\nUPDATE tasks\nSET\n    \"status\" = 'RUNNING'\nFROM\n    eligible_tasks\nWHERE\n    tasks.id = eligible_tasks.id\nRETURNING tasks.*;\n```\n\n----------------------------------------\n\nTITLE: Creating Task Queue Tables in SQL\nDESCRIPTION: This SQL code defines the table schemas necessary for implementing a task queue. `task_groups` maintains parent-child relationships, `tasks` stores task details, and `task_addr_ptrs` manages block addresses for assigning task IDs. The code establishes primary keys, foreign key constraints, and a unique constraint on the 'group_key'.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE\n    task_groups (\n        id BIGSERIAL NOT NULL,\n        group_key text,\n        block_addr BIGINT,\n        PRIMARY KEY (id)\n    );\n\nALTER TABLE task_groups ADD CONSTRAINT unique_group_key UNIQUE (group_key);\n\nALTER TABLE tasks ADD CONSTRAINT fk_tasks_group_key FOREIGN KEY (group_key) REFERENCES task_groups (group_key);\n\nCREATE TABLE\n    task_addr_ptrs (\n        max_assigned_block_addr BIGINT NOT NULL,\n        onerow_id bool PRIMARY KEY DEFAULT true,\n        CONSTRAINT onerow_uni CHECK (onerow_id)\n    );\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Task with Hatchet (Go)\nDESCRIPTION: This code snippet demonstrates defining a simple task using the `factory.NewTask` function in Go. It showcases how to define the task name, input and result types (`SimpleInput`, `SimpleResult`), and the task's function which transforms the input message to lowercase. It utilizes a Hatchet client instance for task execution.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\ntype SimpleInput struct {\n    Message string\n}\n\ntype SimpleResult struct {\n    TransformedMessage string\n}\n\nsimple := factory.NewTask(\n    create.StandaloneTask{\n        Name: \"simple-task\",\n    }, func(ctx worker.HatchetContext, input SimpleInput) (*SimpleResult, error) {\n        return &SimpleResult{\n            TransformedMessage: strings.ToLower(input.Message),\n        }, nil\n    },\n    hatchet, // a Hatchet client instance\n)\n```\n\n----------------------------------------\n\nTITLE: Initialize Hatchet Client\nDESCRIPTION: This TypeScript code initializes the Hatchet client as a singleton. It imports the `Hatchet` class from the `@hatchet-dev/typescript-sdk` package and exports a `hatchet` constant initialized with `Hatchet.init()`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/ts.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nexport const hatchet = Hatchet.init();\n```\n\n----------------------------------------\n\nTITLE: Scatter/Gather: Child Workflows in Python\nDESCRIPTION: This Python code shows how to run child workflows in parallel and wait for all of them to complete using `asyncio.gather`. It spawns multiple child workflows using `context.aio.spawn_workflow` and awaits their results using `.result()`. The collected results are then gathered using `asyncio.gather`.  The `hatchet` and `asyncio` libraries are required, and the workflows/steps are decorated with `@hatchet.workflow` and `@hatchet.step`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow()\nclass Parent:\n    @hatchet.step(timeout=\"5m\")\n    async def spawn(self, context: Context):\n        results = []\n\n        for i in range(10):\n            results.append(\n                (\n                    await context.aio.spawn_workflow(\n                        \"Child\", {\"a\": str(i)}, key=f\"child{i}\"\n                    )\n                ).result()\n            )\n\n        result = await asyncio.gather(*results)\n\n        return {\"results\": result}\n\n@hatchet.workflow()\nclass Child:\n    @hatchet.step()\n    async def process(self, context: Context):\n        a = context.workflow_input()[\"a\"]\n        return {\"status\": \"success \" + a}\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Tasks in Parallel - Go\nDESCRIPTION: Demonstrates how to run multiple tasks in parallel in Go by calling `Run` multiple times in goroutines and using a `sync.WaitGroup` to wait for them to complete.  It's noted that bulk run methods are recommended for a large number of tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-with-results.mdx#_snippet_8\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={SimpleGo} target=\"Running Multiple Tasks\" />\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Workflow with Go\nDESCRIPTION: This code snippet demonstrates how to define a workflow in Go with the `StickyStrategy` set to `types.StickyStrategy_SOFT`. This ensures that all steps within the workflow will attempt to be assigned to the same worker for the duration of the workflow execution. The workflow is triggered by the 'user:create:sticky' event. Each step returns the worker ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:             worker.Events(\"user:create:sticky\"),\n\t\t\tName:           \"sticky\",\n\t\t\tDescription:    \"sticky\",\n\t\t\tStickyStrategy: types.StickyStrategyPtr(types.StickyStrategy_SOFT),\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\t\t\t\t\treturn &stepOneOutput{\n\t\t\t\t\t\tMessage: ctx.Worker().ID(),\n\t\t\t\t\t}, nil\n\t\t\t\t}).SetName(\"step-one\"),\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\t\t\t\t\treturn &stepOneOutput{\n\t\t\t\t\t\tMessage: ctx.Worker().ID(),\n\t\t\t\t\t}, nil\n\t\t\t\t}).SetName(\"step-two\"),\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\t\t\t\t\treturn &stepOneOutput{\n\t\t\t\t\t\tMessage: ctx.Worker().ID(),\n\t\t\t\t\t}, nil\n\t\t\t\t}).SetName(\"step-three\").AddParents(\"step-one\", \"step-two\"),\n\t\t\t},\n\t\t},\n\t)\n\n```\n\n----------------------------------------\n\nTITLE: Registering Workflows with Hatchet Worker (Python)\nDESCRIPTION: This code snippet demonstrates how to register multiple workflows with a Hatchet worker. It defines two simple workflows, `WorkflowOne` and `WorkflowTwo`, each with a single step that returns a dictionary. The worker is then created and both workflows are registered before the worker is started. The `hatchet_sdk` library is required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow()\nclass WorkflowOne:\n    @hatchet.step()\n    async def step(self, context: Context):\n        return {\"test1\": \"test1\"}\n\n@hatchet.workflow()\nclass WorkflowTwo:\n    @hatchet.step()\n    async def step(self, context: Context):\n        return {\"test2\": \"test2\"}\n\nworker = hatchet.worker('test-worker')\nworker.register_workflow(WorkflowOne())\nworker.register_workflow(WorkflowTwo())\nworker.start()\n```\n\n----------------------------------------\n\nTITLE: Prometheus Query Example\nDESCRIPTION: This is an example Prometheus query to check if the worker is healthy. It checks the value of the `hatchet_worker_status` metric. If the metric doesn't exist (e.g., the worker is down), it returns 0 instead.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-healthchecks.mdx#_snippet_3\n\nLANGUAGE: N/A\nCODE:\n```\n(hatchet_worker_status{instance=\"localhost:8001\", job=\"hatchet\"}) or vector(0)\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet with Root Logger (Python)\nDESCRIPTION: Demonstrates how to pass the root logger to the Hatchet class during initialization to ensure all logs are captured. It is recommended to pass the root logger, especially when workflows are defined in multiple files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={LoggerClientPy} target=\"RootLogger\" />\n```\n\n----------------------------------------\n\nTITLE: Using a Custom Logger in a Workflow (TypeScript)\nDESCRIPTION: Illustrates how to use a custom logger, previously created and passed to the Hatchet client, within the steps of a workflow. This provides greater flexibility in logging configuration and integration with existing logging setups.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_5\n\nLANGUAGE: TypeScript\nCODE:\n```\n<GithubSnippet src={ByoLoggerTs} target=\"Use the logger\" />\n```\n\n----------------------------------------\n\nTITLE: Logging with Context.Log Method (TypeScript)\nDESCRIPTION: Demonstrates how to log messages from TypeScript tasks using the `ctx.log()` method. This method is simple to use but offers limited flexibility compared to using a custom logger.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_3\n\nLANGUAGE: TypeScript\nCODE:\n```\n<GithubSnippet src={LoggerWorkflowTs} target=\"Logger\" />\n```\n\n----------------------------------------\n\nTITLE: Configuring Autovacuum Settings for PostgreSQL\nDESCRIPTION: This code snippet configures autovacuum settings in PostgreSQL to aggressively manage table bloat, especially when storing large volumes of workflow run and step run data.  The settings adjust the autovacuum process by modifying parameters such as max workers, scale factors, thresholds, cost delay, and cost limit. These parameters control how frequently and intensely autovacuum operates, balancing resource usage with cleanup efficiency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nautovacuum_max_workers=10\nautovacuum_vacuum_scale_factor=0.1\nautovacuum_analyze_scale_factor=0.05\nautovacuum_vacuum_threshold=25\nautovacuum_analyze_threshold=25\nautovacuum_vacuum_cost_delay=10\nautovacuum_vacuum_cost_limit=1000\n```\n\n----------------------------------------\n\nTITLE: Running Workflow With Additional Metadata (Python)\nDESCRIPTION: This Python code demonstrates how to run a Hatchet workflow with additional metadata.  A random stream key is generated and used to track stream events.  This metadata is propagated to child workflows.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Generate a random stream key to use to track all\n# stream events for this workflow run.\nstreamKey = \"streamKey\"\nstreamVal = f\"sk-{random.randint(1, 100)}\"\n\n# Specify the stream key as additional metadata\n# when running the workflow.\n\n# This key gets propagated to all child workflows\n# and can have an arbitrary property name.\n\nworkflowRun = hatchet.admin.run_workflow(\n    \"Parent\",\n    {\"n\": 2},\n    options={\"additional_metadata\": {streamKey: streamVal}},\n)\n\n```\n\n----------------------------------------\n\nTITLE: Install Hatchet Stack using Helm\nDESCRIPTION: This command adds the Hatchet Helm repository and installs the hatchet-stack chart. It sets caddy.enabled to true to enable a reverse proxy for local access to the Hatchet server.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-quickstart.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nhelm repo add hatchet https://hatchet-dev.github.io/hatchet-charts\nhelm install hatchet-stack hatchet/hatchet-stack --set caddy.enabled=true\n```\n\n----------------------------------------\n\nTITLE: Bulk Cancelling Runs by Filters - Python\nDESCRIPTION: This snippet shows how to cancel task runs based on a set of filters. This is a powerful way to target specific runs based on their properties, such as status, workflow, or metadata.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-retries-and-cancellations.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexamples/bulk_operations/cancel.py\n```\n\n----------------------------------------\n\nTITLE: Importing Hatchet Client Factory\nDESCRIPTION: This Go snippet demonstrates how to import and use the Hatchet Client Factory.  It imports the `hatchet_client` package and calls the `Client()` function to obtain a Hatchet client instance.  Error handling is included to gracefully handle potential initialization failures.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/go.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"log\"\n\n\thatchet \"hatchet-tutorial/src/hatchet_client\"\n)\n\nfunc main() {\n\thatchet, err := hatchet.Client()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Port Forward to Hatchet Engine\nDESCRIPTION: These commands find the Hatchet engine pod, extract its container port, and forward it to localhost:7070. This allows connecting to the Hatchet engine from local examples.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-quickstart.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nexport NAMESPACE=default # TODO: replace with your namespace\nexport POD_NAME=$(kubectl get pods --namespace $NAMESPACE -l \"app.kubernetes.io/name=engine\" -o jsonpath=\"{.items[0].metadata.name}\")\nexport CONTAINER_PORT=$(kubectl get pod --namespace $NAMESPACE $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\nkubectl --namespace $NAMESPACE port-forward $POD_NAME 7070:$CONTAINER_PORT\n```\n\n----------------------------------------\n\nTITLE: Port Forward to Hatchet Frontend via Caddy\nDESCRIPTION: These commands find the Caddy pod, extract its container port, and forward it to localhost:8080. This allows local access to the Hatchet frontend.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-quickstart.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nexport NAMESPACE=default # TODO: replace with your namespace\nexport POD_NAME=$(kubectl get pods --namespace $NAMESPACE -l \"app=caddy\" -o jsonpath=\"{.items[0].metadata.name}\")\nexport CONTAINER_PORT=$(kubectl get pod --namespace $NAMESPACE $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\nkubectl --namespace $NAMESPACE port-forward $POD_NAME 8080:$CONTAINER_PORT\n```\n\n----------------------------------------\n\nTITLE: Getting Child Workflow Result in Go\nDESCRIPTION: This code snippet shows how to retrieve the result of a child workflow using the `Result` method on the `ChildWorkflow` object. It waits for the child workflow to complete and returns the result along with an error, if any.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/child-workflows.mdx#_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nchildResult, err := childWorkflow.Result()\n\nif err != nil {\n    return nil, err\n}\n```\n\n----------------------------------------\n\nTITLE: Running the Python Hatchet worker\nDESCRIPTION: This command starts the Python Hatchet worker, which will listen for workflow events and execute the defined steps. Prerequisite: Python 3 and the required dependencies installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\npython3 worker.py\n```\n\n----------------------------------------\n\nTITLE: Adding Group Key to Task Table in Postgres\nDESCRIPTION: This SQL code adds a `group_key` column to the `tasks` table. This column is used to identify the group to which a task belongs, enabling fair queueing based on user, tenant, or other custom groupings.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_3\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE\n    tasks (\n        id BIGSERIAL NOT NULL,\n        created_at timestamp,\n        status \"TaskStatus\" NOT NULL,\n        args jsonb,\n        group_key text,\n        PRIMARY KEY (id)\n    );\n```\n\n----------------------------------------\n\nTITLE: Configuring gRPC Broadcast Address\nDESCRIPTION: This YAML snippet shows how to configure the `SERVER_GRPC_BROADCAST_ADDRESS` environment variable within the `setup-config` service in the docker-compose.yml file. It's specifically designed for worker applications running inside the same docker-compose setup, directing traffic to the host machine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/docker-compose.mdx#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nSERVER_GRPC_BROADCAST_ADDRESS: \"host.docker.internal:7077\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Worker with Labels - Python\nDESCRIPTION: This code snippet shows how to initialize a Hatchet worker with labels in Python. The labels are key-value pairs that describe the worker's capabilities and resources. The worker is named \"affinity-worker\" and has labels for \"model\" and \"memory\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nworker = hatchet.worker(\n    \"affinity-worker\",\n    labels={\n        \"model\": \"fancy-ai-model-v2\",\n        \"memory\": 512,\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Internal Events - Go\nDESCRIPTION: Demonstrates how to push multiple internal events from within a Go application using the Hatchet client. The `c.Event().BulkPush` method is used to push a slice of events with specified payloads, metadata, and keys. Requires the `hatchet-dev/hatchet/sdk/pkg/client` and `hatchet-dev/hatchet/sdk/pkg/client/events` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nevents := []client.EventWithMetadata{\n  {\n    Event: &events.TestEvent{\n      Name: \"testing\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world1\"},\n    Key: \"event1\",\n  },\n  {\n    Event: &events.TestEvent{\n      Name: \"testing2\",\n    },\n    AdditionalMetadata: map[string]string{\"hello\": \"world2\"},\n    Key: \"event2\",\n  },\n}\n\nc.Event().BulkPush(\n  context.Background(),\n  events,\n)\n```\n\n----------------------------------------\n\nTITLE: Cancelled task in Go\nDESCRIPTION: This Go snippet demonstrates how to check for cancellation signals using the `Done()` method that context package provides.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cancellation.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\n```go\n    package main\n\n    import (\n    \t\"context\"\n    \t\"fmt\"\n    \ttime \"time\"\n    )\n\n    func main() {\n    \tctx, cancel := context.WithCancel(context.Background())\n    \tdefer cancel()\n\n    \tgo func() {\n    \t\ttime.Sleep(5 * time.Second)\n    \t\tcancel()\n    \t}()\n\n    \tfor {\n    \t\tselect {\n    \t\tcase <-ctx.Done():\n    \t\t\tfmt.Println(\"Task cancelled\")\n    \t\t\treturn\n    \t\tdefault:\n    \t\t\tfmt.Println(\"Task running\")\n    \t\t\ttime.Sleep(1 * time.Second)\n    \t\t}\n    \t}\n    }\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Typescript Hatchet Worker\nDESCRIPTION: Defines a Hatchet worker in Typescript. It uses the `@hatchet-dev/typescript-sdk` to define a workflow with a single step. The workflow is triggered by the `user:create` event. It loads environment variables from a .env file using `dotenv`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"first-typescript-workflow\",\n  description: \"This is my first workflow\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n\n        return {\n          result: \"success!\",\n        };\n      },\n    },\n  ],\n};\n\nhatchet.run(workflow);\n```\n\n----------------------------------------\n\nTITLE: Define a Hatchet task with Pydantic models - Python\nDESCRIPTION: This snippet demonstrates how to define a Hatchet task using Pydantic models for input and output. The Hatchet SDK handles serialization and deserialization of the Pydantic models, providing type safety and validation. This example defines a simple task that takes a Pydantic model as input and returns a Pydantic model as output.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={ChildWorker} target=\"Simple\" />\n```\n\n----------------------------------------\n\nTITLE: Setting a retention policy\nDESCRIPTION: This SQL command sets a retention policy on the `metric_events` hypertable, ensuring that only data from the last 24 hours is retained. This helps to manage storage space and improve query performance by reducing the amount of data that needs to be scanned. Requires the TimescaleDB extension.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_7\n\nLANGUAGE: sql\nCODE:\n```\nSELECT add_retention_policy('metric_events', INTERVAL '24 hours');\n```\n\n----------------------------------------\n\nTITLE: Defining Workflows with Compute TypeScript\nDESCRIPTION: This snippet demonstrates how to define a workflow with compute requirements for each step using the Hatchet TypeScript SDK. It specifies `basicCompute` for `step1` and `gpuCompute` for `step2`.  Requires the `@hatchet-dev/typescript-sdk` package and pre-defined `basicCompute` and `gpuCompute` constants.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/managed-compute.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"managed-workflow\",\n  description: \"Workflow with managed compute\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      compute: basicCompute,\n      run: async (ctx) => {\n        console.log(\"Executing step1 with basic compute\");\n        return { result: \"Step 1 complete\" };\n      },\n    },\n    {\n      name: \"step2\",\n      parents: [\"step1\"],\n      compute: gpuCompute,\n      run: async (ctx) => {\n        const step1Result = ctx.stepOutput(\"step1\");\n        console.log(\"Executing step2 with GPU compute after\", step1Result);\n        return { result: \"Step 2 complete\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Creating a POST Endpoint to Trigger Hatchet Workflow in Python\nDESCRIPTION: This snippet creates a POST endpoint `/message` that receives a `MessageRequest`, triggers a Hatchet workflow named `BasicRagWorkflow` with the request data as input, and returns the workflow run ID. The `data.dict()` method converts the `MessageRequest` object into a dictionary suitable for passing as input to the `run_workflow` method.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/api-server-setup.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@app.post(\"/message\")\ndef message(data: MessageRequest):\n    ''' This endpoint is called by the client to start a message generation workflow. '''\n    messageId = hatchet.client.admin.run_workflow(\"BasicRagWorkflow\", {\n        \"request\": data.dict()\n    })\n    # normally, we'd save the workflowRunId to a database and return a reference to the client\n    # for this simple example, we just return the workflowRunId\n    return {\"messageId\": messageId}\n```\n\n----------------------------------------\n\nTITLE: Dockerizing Hatchet app with Poetry\nDESCRIPTION: This Dockerfile sets up a Hatchet worker environment using Poetry for dependency management. It starts from a Python base image, installs system dependencies, Poetry, and project dependencies, copies the Hatchet application code, and sets the entrypoint to run the worker using `poetry run python worker.py`.  The `HATCHET_ENV` variable is set to `production`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/docker.mdx#_snippet_0\n\nLANGUAGE: Dockerfile\nCODE:\n```\n# Use the official Python image as the base\nFROM python:3.10-slim\n\n# Set environment variables\n\nENV PYTHONUNBUFFERED=1 \\\n POETRY_VERSION=1.4.2 \\\n HATCHET_ENV=production\n\n# Install system dependencies and Poetry\n\nRUN apt-get update && \\\n apt-get install -y curl && \\\n curl -sSL https://install.python-poetry.org | python3 - && \\\n ln -s /root/.local/bin/poetry /usr/local/bin/poetry && \\\n apt-get clean && \\\n rm -rf /var/lib/apt/lists/*\n\n# Set work directory\n\nWORKDIR /app\n\n# Copy dependency files first\n\nCOPY pyproject.toml poetry.lock* /app/\n\n# Install dependencies\n\nRUN poetry config virtualenvs.create false && \\\n poetry install --no-interaction --no-ansi\n\n# Copy Hatchet application code\n\nCOPY . /app\n\n# Set the entrypoint to run the Hatchet worker\n\nCMD [\"poetry\", \"run\", \"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Setting up Hatchet API key in .env file (Shell)\nDESCRIPTION: This snippet shows how to set up the Hatchet API key in a `.env` file. This allows the worker to authenticate with the Hatchet Cloud.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nHATCHET_CLIENT_TOKEN=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Parent Task Outputs - Python\nDESCRIPTION: This snippet shows how to access the output of a parent task within a task that has parent dependencies in Python.  It uses the `ctx.task_output()` method to retrieve the parent's output. The `parent_task_name` variable should be the name or reference to the parent task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# Inside a task with parent dependencies\nparent_output = ctx.task_output(parent_task_name)\n```\n\n----------------------------------------\n\nTITLE: Subscribing to results - Python\nDESCRIPTION: This snippet demonstrates how to subscribe to the results of an enqueued task in Hatchet using Python. It utilizes the `ref.result()` method to block until the result is available and the `aio_result` method for async operations. It assumes that a `WorkflowRunRef` object `ref` is already available from a previous `run_no_wait` call.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nresult = ref.result()\n```\n\nLANGUAGE: python\nCODE:\n```\nresult = await ref.aio_result()\n```\n\n----------------------------------------\n\nTITLE: WorkflowRun: Convert to/from Dictionary (Python)\nDESCRIPTION: This snippet shows how to convert a WorkflowRun object to a dictionary and back. It creates a dictionary representation of WorkflowRun object and converts it back to a WorkflowRun instance using the `to_dict` and `from_dict` methods respectively. The snippet utilizes the hatchet_sdk library and assumes a WorkflowRun object instance named workflow_run already exists.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowRun.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# convert the object into a dict\nworkflow_run_dict = workflow_run_instance.to_dict()\n# create an instance of WorkflowRun from a dict\nworkflow_run_form_dict = workflow_run.from_dict(workflow_run_dict)\n```\n\n----------------------------------------\n\nTITLE: Building DAG with Task Dependencies - Typescript\nDESCRIPTION: This snippet demonstrates how to create a task with parent dependencies using the Typescript SDK.  The `reverse` task depends on the `toLower` task.  It uses `ctx.parentOutput(toLower)` to retrieve the output of the parent task. The output of the parent task is awaited because the parent could have been an async function.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nconst toLower = dag.task({\n  name: \"to-lower\",\n  fn: (input) => {\n    return {\n      TransformedMessage: input.Message.toLowerCase(),\n    };\n  },\n});\n\ndag.task({\n  name: \"reverse\",\n  parents: [toLower],\n  fn: async (input, ctx) => {\n    const lower = await ctx.parentOutput(toLower);\n    return {\n      Original: input.Message,\n      Transformed: lower.TransformedMessage.split(\"\").reverse().join(\"\"),\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Accessing Retry Count in Typescript\nDESCRIPTION: This Typescript snippet shows how to access the retry count within a Hatchet step. The `context.retryCount()` method is used to get the current retry count. An error is thrown to simulate step failure and trigger retries.  Dependencies: `@hatchet-dev/typescript-sdk` (for the `Context` type).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync function step(context: Context) {\n  const retryCount = context.retryCount();\n  console.log(`Retry count: ${retryCount}`);\n  throw new Error(\"Step failed\");\n}\n```\n\n----------------------------------------\n\nTITLE: Creating or Updating a Workflow with Overrides\nDESCRIPTION: This code snippet demonstrates how to create or update a workflow using the `put_workflow` method. It defines a base workflow class with two steps and then uses the `put_workflow` method to create a new workflow named \"workflow-copy\", extending from the base workflow and overriding the cron triggers and input using `CreateWorkflowVersionOpts`. It also shows how to define steps with dependencies and timeouts.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/api.mdx#_snippet_1\n\nLANGUAGE: py\nCODE:\n```\n@hatchet.workflow()\nclass BaseWorkflow:\n    @hatchet.step()\n    def step1(self, context: Context):\n        return {\n            \"result\": \"success!\"\n        }\n\n    @hatchet.step(parents=[\"step1\"],timeout='4s')\n    def step2(self, context):\n        return {\n            \"result2\": \"success!\"\n        }\n\nhatchet.client.admin.put_workflow(\n    \"workflow-copy\",\n    BaseWorkflow(),\n    overrides=CreateWorkflowVersionOpts(\n        cron_triggers=[\"*/15 * * * *\"],\n        cron_input=json.dumps({\"test\": \"test\"}),\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Spawning Sticky Child Workflow in TypeScript\nDESCRIPTION: This TypeScript code snippet demonstrates how to spawn a child workflow with the `sticky` option set to `true`.  This ensures that the child workflows will attempt to be executed on the same worker as the parent workflow. It uses a loop to spawn multiple child workflows.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-sticky-workflow\",\n  description: \"test\",\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        const results: Promise<any>[] = [];\n\n        for (let i = 0; i < 50; i++) {\n          const result = await ctx.spawnWorkflow(\n            childWorkflow,\n            {},\n            { sticky: true },\n          );\n          results.push(result.result());\n        }\n\n        console.log(\"Results:\", await Promise.all(results));\n\n        return { step1: \"step1 results!\" };\n      },\n    },\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Version in TypeScript\nDESCRIPTION: This TypeScript interface `WorkflowVersionDefinition` defines the structure for representing a workflow version. It includes a `rawDefinition` property which holds the YAML representation of the workflow.  This interface is part of the Hatchet TypeScript SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkflowVersionDefinition.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface WorkflowVersionDefinition {\n  rawDefinition: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Instantiate Hatchet Client\nDESCRIPTION: This code snippet instantiates the Hatchet client. It imports the Hatchet class from the 'hatchet_sdk' and creates a Hatchet object. This object will be used to interact with the Hatchet service.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/py.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: These commands install the required Python dependencies for the Hatchet worker.  It installs the `python-dotenv` package for loading environment variables and the `hatchet-sdk`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\npip install python-dotenv\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Instrumenting Hatchet with OpenTelemetry (Python)\nDESCRIPTION: This code snippet demonstrates how to instrument Hatchet code for OpenTelemetry tracing using the HatchetInstrumentor. It requires the `hatchet-sdk[otel]` package to be installed.  It takes a trace provider as input, and then calls instrument.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/opentelemetry.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom path.to.your.trace.provider import trace_provider\nfrom hatchet_sdk.opentelemetry.instrumentor import HatchetInstrumentor\n\nHatchetInstrumentor(tracer_provider=trace_provider).instrument()\n```\n\n----------------------------------------\n\nTITLE: Setting a Timeout for a Step in Hatchet (Python)\nDESCRIPTION: This code shows how to declare a timeout for a Hatchet step using the `timeout` argument in the `hatchet.step` decorator.  The `step1` function is configured to timeout after 5 minutes (`5m`).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout=\"5m\")\ndef step1(self, context):\n    print(\"executed step1\")\n    pass\n```\n\n----------------------------------------\n\nTITLE: Listing Runs for a Task - Python\nDESCRIPTION: This snippet shows how to retrieve the runs associated with a specific task using the REST API. These runs can then be used for bulk cancellation or replay operations.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-retries-and-cancellations.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nexamples/bulk_operations/cancel.py\n```\n\n----------------------------------------\n\nTITLE: Installing Required CUDA Libraries in Dockerfile\nDESCRIPTION: This Dockerfile snippet showcases the best practice of selectively installing CUDA libraries instead of using meta-packages. It installs `cuda-nvcc`, `libcublas`, and `libcudnn` individually, which reduces the size of the Docker image and avoids unnecessary dependencies.  Meta-packages install a large number of extra packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\n# DO NOT use meta-packages\n# ❌ RUN apt-get install cuda-runtime-*\n\n# ✅ Install only required libraries\nRUN apt-get install -y \\\n    cuda-nvcc-12-2 \\\n    libcublas-12-2 \\\n    libcudnn8\n```\n\n----------------------------------------\n\nTITLE: Defining the 'reason_docs' step in Hatchet workflow\nDESCRIPTION: This snippet defines the 'reason_docs' step in a Hatchet workflow. It utilizes the OpenAI API to extract the most relevant sentences from a document based on a user's question. It uses the output of the 'load_docs' step and formulates a prompt for the OpenAI model, gpt-3.5-turbo. It requires the OpenAI library and access to the OpenAI API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n\n    # ... previous steps\n\n    @hatchet.step(parents=[\"load_docs\"])\n    def reason_docs(self, ctx: Context):\n        message = ctx.workflow_input()['request'][\"messages\"][-1]\n        docs = ctx.step_output(\"load_docs\")['docs']\n\n        prompt = \"The user is asking the following question:\\\n            {message}\\\n            What are the most relevant sentences in the following document?\\\n            {docs}\"\n\n        prompt = prompt.format(message=message['content'], docs=docs)\n        model = \"gpt-3.5-turbo\"\n\n        completion = openai.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n                message\n            ]\n        )\n\n        return {\n            \"status\": \"writing a response\",\n            \"research\": completion.choices[0].message.content,\n        }\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Events to Hatchet API in Typescript\nDESCRIPTION: This code snippet demonstrates how to push multiple events to the Hatchet API using the `hatchet.event.bulkPush` method. It initializes the Hatchet client and defines an array of event objects, each containing a payload and additional metadata. These events are then pushed to the \"user:create:bulk\" event topic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-events.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst events = [\n  {\n    payload: { test: \"test1\" },\n    additionalMetadata: { user_id: \"user1\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test2\" },\n    additionalMetadata: { user_id: \"user2\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test3\" },\n    additionalMetadata: { user_id: \"user3\", source: \"test\" },\n  },\n];\n\nhatchet.event.bulkPush(\"user:create:bulk\", events);\n```\n\n----------------------------------------\n\nTITLE: Fetching code snippets\nDESCRIPTION: This snippet defines a function that uses `getSnippets` to fetch the code snippets defined by `SimpleTs` and `SimplePy`.  It's likely used to provide static props to a Next.js page.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/orchestration.mdx#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport const getStaticProps = ({}) => getSnippets([SimpleTs, SimplePy]);\n```\n\n----------------------------------------\n\nTITLE: Creating API Token via CLI\nDESCRIPTION: This command creates an API token for a specific tenant within the Hatchet instance. It leverages the `hatchet-admin` CLI tool within a Docker container, specifying the configuration file and tenant ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/docker-compose.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose run --no-deps setup-config /hatchet/hatchet-admin token create --config /hatchet/config --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52\n```\n\n----------------------------------------\n\nTITLE: Accessing Retry Count in Go\nDESCRIPTION: This Go snippet demonstrates how to access the retry count within a Hatchet step using `ctx.RetryCount()`.  The retry count is converted to a string and included in the output message. Dependencies: `worker` package (likely part of the Hatchet Go SDK), `strconv` package for string conversion.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nfunc(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n  count := ctx.RetryCount()\n\n  return &stepOneOutput{\n  Message: \"Count is: \" + strconv.Itoa(count),\n  }, nil\n}\n```\n\n----------------------------------------\n\nTITLE: Starting a Hatchet Worker (Asynchronous) in Python\nDESCRIPTION: This snippet shows how to start a Hatchet worker using the asynchronous `worker.async_start()` method. It defines an `async main` function that creates a worker, registers a workflow, and then starts the worker using `await worker.async_start()`. The `asyncio` library and `hatchet_sdk` are required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Context, Hatchet\n\nhatchet = Hatchet()\n\n# ... workflow definitions\n\nasync def main():\n    worker = hatchet.worker(\"test-worker\", max_runs=4)\n    worker.register_workflow(Workflow())\n    await worker.async_start()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining API Resource Metadata with UUID in TSX\nDESCRIPTION: This code snippet illustrates the structure of API resource metadata, which includes createdAt, updatedAt (both DateTime), and id (UUID). It demonstrates how UUIDs were used for consistency across the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_12\n\nLANGUAGE: TSX\nCODE:\n```\n{\n  \"createdAt\": Datetime,\n  \"updatedAt\": Datetime,\n  \"id\": UUID\n}\n```\n\n----------------------------------------\n\nTITLE: Install Hatchet via Glasskube CLI\nDESCRIPTION: This command installs Hatchet on Kubernetes using the Glasskube CLI.  It assumes that the Kubernetes secret named `hatchet-secret` has already been created. The API server and engine replica count need to be set to 0.  Requires `glasskube` CLI.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nglasskube install hatchet\n```\n\n----------------------------------------\n\nTITLE: Durable Sleep in TypeScript\nDESCRIPTION: This code snippet demonstrates how to use durable sleep in a Hatchet workflow written in TypeScript. It utilizes the `SleepFor` method on the `DurableContext` object to pause execution for a specified duration. The snippet is sourced from the `src/v1/examples/durable-sleep/workflow.ts` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-sleep.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/durable-sleep/workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Payload - Go\nDESCRIPTION: Demonstrates how to access the event payload within a Hatchet workflow step in Go.  The `ctx.WorkflowInput()` method is used to retrieve the event payload and unmarshal it into a struct. Requires the `hatchet-dev/hatchet/worker` package and defining a struct `workflowInputExample` to receive the input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\ntype workflowInputExample struct{}\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"post-user-create\",\n        On: worker.Event(\"user:created\"),\n        Description: \"Cron workflow example.\",\n        Steps: []*worker.WorkflowStep{\n            {\n                Function: func(ctx context.Context) error {\n                    input := &workflowInputExample{}\n                    ctx.WorkflowInput(input)\n                    // Use the event payload data in your step logic\n                },\n            },\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Labels Update - TypeScript\nDESCRIPTION: This TypeScript code demonstrates dynamically updating worker labels within a task. It checks if the worker's `model` label matches the desired value (`fancy-vision-model`). If not, it clears the existing `model` label using `upsertLabels({ model: undefined })`, performs hypothetical `evictModel()` and `loadNewModel()` functions, and then updates the `model` label to the desired value using `upsertLabels({ model: \"fancy-vision-model\" })`. The updated labels will be reflected in subsequent task assignments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-affinity.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst affinity: Workflow = {\n  id: \"dynamic-affinity-workflow\",\n  description: \"test\",\n  tasks: [\n    {\n      name: \"child-task1\",\n      worker_labels: {\n        model: {\n          value: \"fancy-vision-model\",\n          required: false,\n        },\n      },\n      run: async (ctx) => {\n        if (ctx.worker.labels().model !== \"fancy-vision-model\") {\n          await ctx.worker.upsertLabels({ model: undefined });\n          await evictModel();\n          await loadNewModel(\"fancy-vision-model\");\n          await ctx.worker.upsertLabels({ model: \"fancy-vision-model\" });\n        }\n        // DO WORK\n        return { childStep1: \"childStep1 results!\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Creating Scheduled Runs - Python (Sync)\nDESCRIPTION: This snippet demonstrates how to create a scheduled run programmatically using the Python (Synchronous) Hatchet SDK. It shows how to define the schedule and trigger a workflow at a specific time. It assumes you have the Hatchet client initialized and configured.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-sync.py - Create\n```\n\n----------------------------------------\n\nTITLE: Checking for Cancellation in a Step (Go)\nDESCRIPTION: This code demonstrates how to check for cancellation signals within a Hatchet workflow step using Go's `context` package. It utilizes the `context.Context` and its `Done()` method to detect cancellation.  It assumes the existence of a Hatchet worker package with a WorkflowJob struct and a WorkflowStep struct.  It also uses the standard `context` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/cancellation.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"post-user-sign-up\",\n        On: worker.Event(\"user:created\"),\n        Description: \"Workflow that executes after a user signs up.\",\n        Timeout: \"60s\",\n        Steps: []*worker.WorkflowStep{\n            {\n                Function: func(ctx context.Context) error {\n                  stepDone := make(chan struct{})\n                  go func() {\n                    // Step business logic\n                    // ...\n                    stepDone <- struct{}{}\n                  }()\n                  select {\n                    case <- ctx.Done():\n                      // The step has been canceled\n                      // Perform any necessary cleanup or termination logic\n                      return nil\n                    case <- stepDone:\n                      // Workflow step finished executing\n                      return nil\n                  }\n                },\n            },\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Initializing FastAPI and Hatchet SDK in Python\nDESCRIPTION: This snippet initializes a FastAPI application, configures CORS middleware for local development, loads environment variables using dotenv, and initializes the Hatchet SDK. The CORS middleware allows requests from any origin, which is suitable for local development but not recommended for production.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/api-server-setup.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import StreamingResponse # we'll use this later in the tutorial\nimport uvicorn\nfrom dotenv import load_dotenv\nimport json\nfrom hatchet_sdk import Hatchet\nfrom .models import MessageRequest\n\nload_dotenv() # we'll use dotenv to load the required Hatchet and OpenAI api keys\n\napp = FastAPI()\nhatchet = Hatchet()\n\n# This is required for running a local react app,\n# but is not recommended for production.\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"]\n)\n\ndef start():\n    \"\"\"Launched with `poetry run api` at root level\"\"\"\n    uvicorn.run(\"src.api.main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n```\n\n----------------------------------------\n\nTITLE: Creating cron jobs dynamically in Hatchet - Python\nDESCRIPTION: This snippet demonstrates how to create cron jobs dynamically using the Hatchet SDK.  Hatchet has first-class support for cron jobs, eliminating the need for separate scheduling tools like Celery Beat. This example shows how to dynamically define a cron schedule for a Hatchet workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={Cron} target=\"Create\" />\n```\n\n----------------------------------------\n\nTITLE: Registering Hatchet Worker and Workflow\nDESCRIPTION: This snippet demonstrates how to register a Hatchet worker, register a workflow with the worker, and start the worker. It imports the Hatchet client and the BasicRagWorkflow class, then registers the workflow with the worker and starts the worker to listen for events. It utilizes the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom .hatchet import hatchet\nfrom .basicrag import BasicRagWorkflow\n\n\ndef start():\n    worker = hatchet.worker('basic-rag-worker')\n    worker.register_workflow(BasicRagWorkflow())\n    worker.start()\n```\n\n----------------------------------------\n\nTITLE: Running a Task Without Waiting - Go\nDESCRIPTION: This snippet shows how to run a task in Go without waiting for it to complete, using the `RunNoWait` method in Hatchet. The `GithubSnippet` component is used to include the relevant code from the `SimpleGo` file. The code enqueues the task and returns a `WorkflowRunRef` immediately.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\n<GithubSnippet src={SimpleGo} target=\"Running a Task Without Waiting\" />\n```\n\n----------------------------------------\n\nTITLE: Error Handling with Child Workflow Spawn in Go\nDESCRIPTION: This Go snippet illustrates how to spawn a child workflow and handle errors that may occur during its execution. If an error is detected, a recovery workflow is spawned. It makes use of the hatchet framework.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                childInput := \"child-input-\" + strconv.Itoa(i)\n                childWorkflow, err := ctx.SpawnWorkflow(\"child-workflow\", childInput, &worker.SpawnWorkflowOpts{})\n                if err != nil {\n                    // Handle error here\n                    return\n                }\n                // Collect the result from the child workflow\n                result, err := childWorkflow.Result()\n                if err != nil {\n                    // Spawn a recovery workflow\n                    recInput := err.Error()\n                    _, err = ctx.SpawnWorkflow(\"recovery-workflow\", recInput, &worker.SpawnWorkflowOpts{})\n                    return\n                }\n                return nil\n            }),\n        },\n    },\n)\n\n```\n\n----------------------------------------\n\nTITLE: Running a Worker with yarn\nDESCRIPTION: This bash snippet shows how to start a Hatchet worker using yarn. It executes the 'start:worker' script defined in the package.json file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nyarn start:worker\n```\n\n----------------------------------------\n\nTITLE: Starting Docker Compose Services\nDESCRIPTION: This bash command starts all the services defined in the `docker-compose.yml` file.  It is executed in the root of the repository where the `docker-compose.yml` file is located.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Filtering Durable Event in Python\nDESCRIPTION: This snippet demonstrates how to filter durable events in Python using Hatchet and CEL expressions.  It shows how to receive only specific events based on a filter. The code is located in the `examples/durable_event/worker.py` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-events.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={DurablePy} target=\"Durable Event With Filter\" />\n```\n\n----------------------------------------\n\nTITLE: Defining cron jobs declaratively - Python\nDESCRIPTION: This snippet shows how to define cron jobs declaratively when creating a Hatchet workflow. The `on_crons` parameter allows specifying a cron schedule directly within the workflow definition. This provides a clean and concise way to configure periodic tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/task-queue-modern-python.mdx#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n```python\ncron_workflow = hatchet.workflow(name=\"CronWorkflow\", on_crons=[\"* * * * *\"])\n```\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Simple Task - Go\nDESCRIPTION: This code snippet outlines how to define a simple task in Go using Hatchet. It involves defining the task input struct, creating a task using `factory.NewTask`, registering the task with a worker, and invoking the task.  The task transforms an input message to lowercase. Requires the `github.com/hatchet-dev/hatchet` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\n// 1. Define your task input\ntype SimpleInput struct {\n  Message string `json:\"message\"`\n}\n\n// 2. Define your task using factory.NewTask\nsimple := factory.NewTask(\n  create.StandaloneTask{\n    Name: \"simple-task\",\n  }, func(ctx worker.HatchetContext, input SimpleInput) (*SimpleResult, error) {\n    return &SimpleResult{\n      TransformedMessage: strings.ToLower(input.Message),\n    }, nil\n  },\n  hatchet,\n)\n\n// 3. Register your task on your worker\nworker, err := hatchet.Worker(v1worker.WorkerOpts{\n  Name: \"simple-worker\",\n  Workflows: []workflow.WorkflowBase{\n    simple,\n  },\n})\n\nworker.StartBlocking()\n\n// 4. Invoke tasks from your application\nsimple.Run(context.Background(), SimpleInput{Message: \"Hello, World!\"})\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Workflow with Python\nDESCRIPTION: This code snippet demonstrates how to define a workflow in Python with the `sticky` property set to `StickyStrategy.SOFT`. This ensures that all steps within the workflow will attempt to be assigned to the same worker for the duration of the workflow execution. The workflow is triggered by the 'user:create' event. Each step returns the worker ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\n    on_events=[\"user:create\"],\n    sticky=StickyStrategy.SOFT, # <-- specify the sticky strategy\n)\nclass StickyWorkflow:\n    @hatchet.step()\n    def step1a(self, context: Context):\n        return {\"worker\": context.worker.id()}\n\n    @hatchet.step()\n    def step1b(self, context: Context):\n        return {\"worker\": context.worker.id()}\n\n    @hatchet.step(parents=[\"step1a\", \"step1b\"])\n    def step2(self, context: Context):\n        return {\"worker\": context.worker.id()}\n\n```\n\n----------------------------------------\n\nTITLE: Adding and Installing Hatchet HA Helm Chart\nDESCRIPTION: This snippet demonstrates how to add the Hatchet Helm repository and install the `hatchet-ha` chart. It uses `helm repo add` to add the repository and `helm install` to deploy the chart.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/high-availability.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nhelm repo add hatchet https://hatchet-dev.github.io/hatchet-charts\nhelm install hatchet-ha hatchet/hatchet-ha\n```\n\n----------------------------------------\n\nTITLE: Defining a Hatchet Workflow class\nDESCRIPTION: This snippet defines a Hatchet workflow using the @hatchet.workflow decorator.  The on_events parameter specifies the events that trigger the workflow. This decorator is part of the Hatchet SDK and is used to define workflows that can be executed by the Hatchet worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n```\n\n----------------------------------------\n\nTITLE: Deleting Scheduled Runs - Python (Async)\nDESCRIPTION: This snippet shows how to delete a scheduled run using the Python (Asynchronous) Hatchet SDK. It uses either the scheduled run object or the scheduled run ID. Requires an initialized Hatchet client and the scheduled run ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-async.py - Delete\n```\n\n----------------------------------------\n\nTITLE: Streaming Events by Metadata (TypeScript)\nDESCRIPTION: This TypeScript snippet generates a random stream key and value, then uses these to run a Hatchet workflow with the stream key specified as additional metadata.  It then streams events with `hatchet.listener.streamByAdditionalMeta` and prints them. It relies on the `hatchet` library and assumes it is already configured.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\n// Generate a random stream key to use to track all\n// stream events for this workflow run.\nconst streamKey = \"streamKey\";\nconst streamVal = `sk-${Math.random().toString(36).substring(7)}`;\n\n// Specify the stream key as additional metadata\n// when running the workflow.\n\n// This key gets propagated to all child workflows\n// and can have an arbitrary property name.\nawait hatchet.admin.runWorkflow(\n  \"parent-workflow\",\n  {},\n  { additionalMetadata: { [streamKey]: streamVal } },\n);\n\n// Stream all events for the additional meta key value\nconst stream = await hatchet.listener.streamByAdditionalMeta(\n  streamKey,\n  streamVal,\n);\n\nfor await (const event of stream) {\n  console.log(\"event received\", event);\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Commonly Needed CUDA Libraries in Dockerfile\nDESCRIPTION: This Dockerfile snippet shows how to install essential CUDA libraries such as `libcublas`, `libcudnn`, and `nvidia-driver` within a Docker image. This provides the necessary dependencies for running GPU-accelerated applications by providing libraries that help the GPU interact with the user code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_8\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Install commonly needed libraries\nRUN apt-get install -y \\\n    libcublas-12-2 \\\n    libcudnn8 \\\n    nvidia-driver-525\n```\n\n----------------------------------------\n\nTITLE: Multi-Stage Dockerfile for GPU Application\nDESCRIPTION: This multi-stage Dockerfile demonstrates how to separate the build and runtime environments for a GPU application. The first stage (`builder`) installs the CUDA compiler (`cuda-nvcc`), and the second stage copies the necessary CUDA libraries from the builder stage to the runtime image, resulting in a smaller and more secure final image.  Separating the environments allows for cleaner builds.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_3\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Build stage\nFROM ubuntu:22.04 AS builder\nRUN apt-get update && apt-get install -y cuda-nvcc-12-2\n\n# Runtime stage\nFROM ubuntu:22.04\nCOPY --from=builder /usr/local/cuda-12.2 /usr/local/cuda-12.2\n```\n\n----------------------------------------\n\nTITLE: Providing a Traceparent (Python)\nDESCRIPTION: This code shows how to provide a `traceparent` in the `additional_metadata` field of Hatchet methods to link spans created in Hatchet to parent spans from other parts of the application.  It requires the use of the hatchet sdk.  The output is the effect of running the event with the traceparent included for purposes of tracing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/opentelemetry.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nhatchet.event.push(\n    \"user:create\",\n    {'userId': '1234'},\n    options={\n    \"additional_metadata\": {\n        \"traceparent\":\"00-f1aff5c5ea45185eff2a06fd5c0ed6c5-6f4116aff54d54d1-01\" ## example traceparent\n    }\n})\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limits for Hatchet Workflow (GROUP_ROUND_ROBIN)\nDESCRIPTION: This code snippet defines a Hatchet workflow using the `GROUP_ROUND_ROBIN` concurrency limit strategy.  It allows a maximum of 1 concurrent execution based on the expression `'default'`. The `limitStrategy` is set to `ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN`, enabling fair distribution of workflow executions across groups.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/fairness.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  id: \"concurrency-example\",\n  description: \"test\",\n  on: {\n    event: \"concurrency:create\",\n  },\n  concurrency: {\n    expression: \"'default'\",\n    maxRuns: 1,\n    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n  },\n  steps: [...],\n};\n```\n\n----------------------------------------\n\nTITLE: Creating User and Profile Tables with Deferred Constraints in SQL\nDESCRIPTION: This SQL code creates `users` and `profiles` tables with a mandatory one-to-one relationship enforced using foreign key constraints with `DEFERRABLE INITIALLY DEFERRED`. It includes an example of inserting related data into both tables within a single transaction.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    profile_id INT UNIQUE\n);\n\nCREATE TABLE profiles (\n    id SERIAL PRIMARY KEY,\n    user_id INT UNIQUE,\n    CONSTRAINT fk_user FOREIGN KEY (user_id) REFERENCES users(id) DEFERRABLE INITIALLY DEFERRED\n);\n\nALTER TABLE users\nADD CONSTRAINT fk_profile FOREIGN KEY (profile_id) REFERENCES profiles(id) DEFERRABLE INITIALLY DEFERRED;\n\nBEGIN;\n\n-- Insert into both tables in a single transaction\nWITH new_profile AS (\n    INSERT INTO profiles DEFAULT VALUES RETURNING id\n)\nINSERT INTO users (profile_id)\nVALUES ((SELECT id FROM new_profile));\n\n-- Link the profile to the user\nUPDATE profiles\nSET user_id = (SELECT id FROM users WHERE profile_id = profiles.id);\n\nCOMMIT;\n```\n\n----------------------------------------\n\nTITLE: Generate Encryption Keys\nDESCRIPTION: This bash script generates the necessary encryption keys and secrets required for Hatchet to run in Kubernetes. It uses Docker to run a Hatchet admin command to create the keysets, and then creates a Kubernetes secret YAML file containing the generated keys and secrets. Requires `docker` and `openssl`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n#!/bin/bash\n\n# Define an alias for generating random strings. This needs to be a function in a script.\nrandstring() {\n    openssl rand -base64 69 | tr -d \"\\n=+/\" | cut -c1-$1\n}\n\n# Create keys directory\nmkdir -p ./keys\n\n# Function to clean up the keys directory\ncleanup() {\n    rm -rf ./keys\n}\n\n# Register the cleanup function to be called on the EXIT signal\ntrap cleanup EXIT\n\n# Check if Docker is installed\nif ! command -v docker &> /dev/null\nthen\n    echo \"Docker could not be found. Please install Docker.\"\n    exit 1\nfi\n\n# Generate keysets using Docker\ndocker run --user $(id -u):$(id -g) -v $(pwd)/keys:/hatchet/keys ghcr.io/hatchet-dev/hatchet/hatchet-admin:latest /hatchet/hatchet-admin keyset create-local-keys --key-dir /hatchet/keys\n\n# Read keysets from files\nSERVER_ENCRYPTION_MASTER_KEYSET=$(<./keys/master.key)\nSERVER_ENCRYPTION_JWT_PRIVATE_KEYSET=$(<./keys/private_ec256.key)\nSERVER_ENCRYPTION_JWT_PUBLIC_KEYSET=$(<./keys/public_ec256.key)\n\n# Generate the random strings for SERVER_AUTH_COOKIE_SECRETS\nSERVER_AUTH_COOKIE_SECRET1=$(randstring 16)\nSERVER_AUTH_COOKIE_SECRET2=$(randstring 16)\n\n# Create the YAML file\ncat > hatchet-secret.yaml <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hatchet-secret\n  namespace: hatchet\nstringData:\n  SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n  SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n  SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n  SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\nEOF\n```\n\n----------------------------------------\n\nTITLE: Starting ngrok with Task\nDESCRIPTION: This command starts ngrok using a task runner (likely Taskfile). It exposes a local port to the internet, enabling the Github app to send webhooks to the local Hatchet instance.  The user needs to have task installed and a Taskfile configured to start ngrok.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/github-app-setup.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ntask start-ngrok\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Workflow with Hatchet\nDESCRIPTION: This TypeScript code snippet demonstrates how to define a cron-triggered workflow using the Hatchet SDK.  It initializes a Hatchet client, defines a workflow with a cron schedule set to run every 5 minutes (`*/5 * * * *`), and includes a single step that logs a message to the console. The workflow is identified by the id `example`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-cron.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"example\",\n  description: \"test\",\n  on: {\n    cron: \"*/5 * * * *\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: (input, ctx) => {\n        console.log(\"executed step1!\");\n        return { step1: \"step1\" };\n      },\n    },\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Github App\nDESCRIPTION: This block defines the environment variables required for configuring the Github App integration with Hatchet. These variables specify the VCS kind, enable Github, and provide the necessary credentials and settings for the Github App, including client ID, client secret, app name, webhook secret, webhook URL, app ID, and the path to the private key file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/github-app-setup.mdx#_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\nSERVER_VCS_KIND=github\nSERVER_VCS_GITHUB_ENABLED=true\nSERVER_VCS_GITHUB_APP_CLIENT_ID=<client-id>\nSERVER_VCS_GITHUB_APP_CLIENT_SECRET=<client-secret>\nSERVER_VCS_GITHUB_APP_NAME=<app-name>\nSERVER_VCS_GITHUB_APP_WEBHOOK_SECRET=<webhook-secret>\nSERVER_VCS_GITHUB_APP_WEBHOOK_URL=<webhook-url>\nSERVER_VCS_GITHUB_APP_ID=<app-id>\nSERVER_VCS_GITHUB_APP_SECRET_PATH=<path-to-pem-file>\n```\n\n----------------------------------------\n\nTITLE: Configuring Postgres Memory Settings\nDESCRIPTION: This code snippet showcases settings for `maintenance_work_mem` and `work_mem` in Postgres. Increasing these values can improve performance, particularly on database instances with significant memory capacity. These settings affect the amount of memory used for maintenance operations and individual queries, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nmaintenance_work_mem=2147483647\nwork_mem=125828\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Schedule Timeout in Typescript\nDESCRIPTION: This snippet shows how to define a schedule timeout for a Hatchet workflow using Typescript.  The `scheduleTimeout` property in the Workflow definition object sets the maximum time a step can wait in the queue before being cancelled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow: Workflow = {\n  id: \"my-workflow\",\n  // ...\n  scheduleTimeout: \"2m\",\n  // ...\n};\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose\nDESCRIPTION: Executes the docker-compose command to bring up the Hatchet Lite instance. This command reads the docker-compose.hatchet.yml file and starts the services defined within.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker-compose -f docker-compose.hatchet.yml up\n```\n\n----------------------------------------\n\nTITLE: Ensuring CUDA Version Compatibility in Dockerfile\nDESCRIPTION: This Dockerfile snippet demonstrates the importance of ensuring that the CUDA toolkit version matches the driver version. It installs `cuda-nvcc-12-2` to match a specific CUDA version, which helps avoid compatibility issues between the CUDA toolkit and the NVIDIA driver within the Docker container.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_7\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Ensure CUDA toolkit version matches driver\nRUN apt-get install -y cuda-nvcc-12-2\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using CEL Expression in Go\nDESCRIPTION: This Go code snippet illustrates defining a workflow with a concurrency limit using `worker.Concurrency`, configured to cancel in-progress runs (`types.CancelInProgress`). Requires the `hatchet-dev/hatchet/pkg/client/types` and `hatchet-dev/hatchet/pkg/worker` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport (\n  \"github.com/hatchet-dev/hatchet/pkg/client/types\"\n  \"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype MyUser struct {\n    UserId string `json:\"user_id\"`\n}\n\nerr = w.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"concurrency-limit-per-user\",\n        On: worker.Events(\"concurrency-test-event\"),\n        Description: \"This limits concurrency to 1 run at a time per user.\",\n        Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.CancelInProgress),\n        Steps: []*worker.WorkflowStep{\n            // your steps here...\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Step Output Data\nDESCRIPTION: This snippet demonstrates how to access the output data of a previous step using `ctx.stepOutput(\"<step_name>\")`. It retrieves the 'awesome' property from the 'step2' output, converts it to uppercase, and returns it as part of its own output. The `parents` array must include the name of any step whose output is being accessed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst futureStep: Step = {\n  name: \"step3\",\n  run: (ctx) => {\n    const uppercaseStep2 = ctx.stepOutput(\"step2\")[\"awesome\"].toUpperCase();\n    return { uppercase: uppercaseStep2 };\n  },\n};\n\n```\n\n----------------------------------------\n\nTITLE: Fetching Snippets with getStaticProps\nDESCRIPTION: This JavaScript snippet defines `getStaticProps`, which uses `getSnippets` to fetch code snippets based on the `SimpleWorker` configuration.  This function is likely used by Next.js to pre-render the page with the fetched code snippets. `getSnippets` requires an array of configuration objects, such as `SimpleWorker`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport const getStaticProps = ({}) => getSnippets([SimpleWorker]);\n```\n\n----------------------------------------\n\nTITLE: Defining a Hatchet Step (Python)\nDESCRIPTION: This code snippet demonstrates the basic structure of a Hatchet step defined in Python. It takes a `context` argument, performs an operation, and returns a JSON-serializable object. The context provides access to workflow input and logging facilities.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef my_step(context: Context) -> dict:\n    # Perform some operation\n    return output\n```\n\n----------------------------------------\n\nTITLE: Running a Worker in Go\nDESCRIPTION: This bash snippet demonstrates how to start a Hatchet worker written in Go. It directly executes the 'worker.go' file using the 'go run' command.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/workers.mdx#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngo run worker.go\n```\n\n----------------------------------------\n\nTITLE: Creating a Python Worker\nDESCRIPTION: This Python script defines a simple Hatchet workflow with one step and registers it with a worker. It uses `python-dotenv` to load environment variables from a `.env` file. It initializes the Hatchet client, defines a workflow and a step, registers the workflow with the worker, and starts the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow(name=\"first-python-workflow\",on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        return {\n            \"result\": \"success\"\n        }\n\nworker = hatchet.worker('first-worker')\nworker.register_workflow(MyWorkflow())\n\nworker.start()\n```\n\n----------------------------------------\n\nTITLE: Ensure CUDA Version Compatibility (Dockerfile)\nDESCRIPTION: This Dockerfile snippet demonstrates how to ensure the CUDA toolkit version matches the driver. This is crucial for compatibility and proper functioning of GPU-accelerated applications. It installs cuda-nvcc with a specific version number.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_6\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Ensure CUDA toolkit version matches driver\nRUN apt-get install -y cuda-nvcc-12-2\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with CEL Expression (Go)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Go using an expression to define the concurrency group. It sets the maximum number of concurrent runs to 10 and uses the `getConcurrencyKey` function to determine the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nimport (\n  \"github.com/hatchet-dev/hatchet/pkg/client/types\"\n  \"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype MyUser struct {\n    UserId string `json:\"user_id\"`\n}\n\nerr = w.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"concurrency-limit-per-user\",\n        On: worker.Events(\"concurrency-test-event\"),\n        Description: \"This limits concurrency to 10 run at a time per user.\",\n        Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.GroupRoundRobin),\n        Steps: []*worker.WorkflowStep{\n            // your steps here...\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Running Go Worker\nDESCRIPTION: This command starts the Go worker by executing the `main.go` file using `go run`. It assumes that the `main.go` file is in the current directory and contains the necessary Hatchet worker logic. All dependencies must be vendored or available in the Go module cache.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\ngo run main.go\n```\n\n----------------------------------------\n\nTITLE: Streaming GET Endpoint with FastAPI\nDESCRIPTION: This creates a streaming GET endpoint using FastAPI that the client connects to for real-time progress updates. It retrieves the workflowRunId from the messageId, subscribes to the event stream using the event_stream_generator, and returns a StreamingResponse with the event data as 'text/event-stream'.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/result-streaming.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n@app.get(\"/message/{messageId}\")\nasync def stream(messageId: str):\n    ''' in a normal application you might use the message id to look up a workflowRunId\n    for this simple case, we have no persistence and just use the message id as the workflowRunId\n    you might also consider looking up the workflowRunId in a database and returning the results\n    if the message has already been processed '''\n    workflowRunId = messageId\n    return StreamingResponse(event_stream_generator(workflowRunId), media_type='text/event-stream')\n```\n\n----------------------------------------\n\nTITLE: Start Glasskube GUI\nDESCRIPTION: This command starts the Glasskube GUI, which allows users to install and manage Kubernetes packages, including Hatchet, through a web interface.  Requires `glasskube` CLI.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nglasskube serve\n```\n\n----------------------------------------\n\nTITLE: Configuring Engine Ingress for nginx (YAML)\nDESCRIPTION: This YAML snippet configures an ingress for the `engine` service using `nginx-ingress`. It specifies annotations for cert-manager, TLS verification, and GRPC backend configuration.  Requires `cert-manager` and `nginx-ingress` to be installed on the cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/networking.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nengine:\n  env:\n    # TODO: insert these values from the output of the keyset generation command\n    SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n    SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n  ingress:\n    enabled: true\n    ingressClassName: nginx\n    labels: {}\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      nginx.ingress.kubernetes.io/auth-tls-verify-client: \"optional\"\n      nginx.ingress.kubernetes.io/auth-tls-secret: \"${kubernetes_namespace.cloud.metadata[0].name}/engine-cert\"\n      nginx.ingress.kubernetes.io/auth-tls-verify-depth: \"1\"\n      nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: \"true\"\n      nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      nginx.ingress.kubernetes.io/grpc-backend: \"true\"\n      nginx.ingress.kubernetes.io/server-snippet: |\n        grpc_read_timeout 1d;\n        grpc_send_timeout 1h;\n        client_header_timeout 1h;\n        client_body_timeout 1h;\n    hosts:\n      - host: engine.hatchet.example.com\n        paths:\n          - path: /\n        backend:\n          serviceName: hatchet-engine\n          servicePort: 7070\n    tls:\n      - hosts:\n          - engine.hatchet.example.com\n        secretName: engine-cert\n        servicePort: 7070\n```\n\n----------------------------------------\n\nTITLE: Serving Glasskube UI\nDESCRIPTION: This command starts the Glasskube UI, allowing Hatchet to be installed through a graphical interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nglasskube serve\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Workflow with Tasks - Go\nDESCRIPTION: This Go code shows how to define a workflow with two tasks using Hatchet. It includes attaching the first task to the workflow, and attaching the second task as a child of the first, creating a simple DAG. The parents are declared as `step1` without explicit definition and do not work as intended in the example. Requires the `github.com/hatchet-dev/hatchet` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n// 1. Define a workflow (a workflow is a collection of tasks)\nsimple := v1.WorkflowFactory[DagInput, DagOutput](\n    workflow.CreateOpts[DagInput]{\n        Name: \"simple-workflow\",\n    },\n    hatchet,\n)\n\n// 2. Attach the first task to the workflow\nconst task1 = simple.Task(\n    task.CreateOpts[DagInput]{\n        Name: \"task-1\",\n        Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {\n            return &SimpleOutput{\n                Result: \"task-1\",\n            }, nil\n        },\n    },\n);\n\n// 3. Attach the second task to the workflow, which executes after task-1\nconst task2 = simple.Task(\n    task.CreateOpts[DagInput]{\n        Name: \"task-2\",\n        Parents: []task.NamedTask{\n            step1,\n        },\n        Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {\n            return &SimpleOutput{\n                Result: \"task-2\",\n            }, nil\n        },\n    },\n);\n\n// 4. Invoke workflows from your application\nsimple.Run(ctx, DagInput{})\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limits for Hatchet Workflow (GROUP_ROUND_ROBIN with input)\nDESCRIPTION: This code snippet demonstrates configuring a Hatchet workflow with concurrency limits using the `GROUP_ROUND_ROBIN` strategy. It limits the maximum concurrent executions to 2, and uses the `input.group` to determine the group for round-robin scheduling, allowing to fairly distribute workflow executions across tenants/groups.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/fairness.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  id: 'concurrency-example-rr',\n  description: 'test',\n  on: {\n    event: 'concurrency:create',\n  },\n  concurrency: {\n    expression: \"input.group\",\n    maxRuns: 2,\n    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n  },\n  steps: [...],\n};\n```\n\n----------------------------------------\n\nTITLE: Adding worker script to package.json\nDESCRIPTION: This snippet shows how to add a script to the `package.json` file to start the Hatchet worker. This allows you to easily start the worker using `npm run worker`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  // ...rest of your `package.json`\n  \"scripts\": {\n    // ...existing scripts\n    \"worker\": \"npx ts-node worker.ts\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Querying Queue Time Distribution (PromQL)\nDESCRIPTION: This PromQL query retrieves the queue time distribution using the `hatchet_queued_to_assigned_seconds_bucket` histogram metric. It sums the rates of the buckets over a 5-minute window, grouped by the `le` (less than or equal to) label, representing the upper bound of each bucket.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_4\n\nLANGUAGE: promql\nCODE:\n```\nsum by (le) (\n  rate(hatchet_queued_to_assigned_seconds_bucket[5m])\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Scheduled Runs - Go\nDESCRIPTION: This snippet demonstrates creating a scheduled run programmatically using the Go Hatchet SDK. It defines the schedule and triggers the workflow. Requires initialized and configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_9\n\nLANGUAGE: go\nCODE:\n```\nSee GithubSnippet: examples/scheduled/main.go - Create\n```\n\n----------------------------------------\n\nTITLE: Fair Queueing with PARTITION BY (Attempt 2) in Postgres\nDESCRIPTION: This SQL query attempts to fix the error from the previous attempt by separating the `PARTITION BY` and `FOR UPDATE SKIP LOCKED` clauses into separate CTEs.  However, this introduces a concurrency issue where only one worker picks up tasks due to locked rows being excluded by `FOR UPDATE SKIP LOCKED` in the second CTE.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_5\n\nLANGUAGE: sql\nCODE:\n```\nWITH\n    ordered_tasks AS (\n        SELECT\n            t.id,\n            t.\"status\",\n            t.\"group_key\",\n            row_number() OVER (PARTITION BY t.\"group_key\" ORDER BY t.\"id\" ASC) AS rn\n        FROM\n            tasks t\n        WHERE\n            \"status\" = 'QUEUED'\n        ORDER BY rn, t.id ASC\n        LIMIT\n            COALESCE(sqlc.narg('limit'), 10)\n    ),\n    eligible_tasks AS (\n        SELECT\n            t1.id\n        FROM\n            ordered_tasks t1\n        FOR UPDATE SKIP LOCKED\n    )\nUPDATE tasks\nSET\n    \"status\" = 'RUNNING'\nFROM\n    eligible_tasks\nWHERE\n    tasks.id = eligible_tasks.id AND\n    tasks.\"status\" = 'QUEUED'\nRETURNING tasks.*;\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow State in Python Step\nDESCRIPTION: This Python code demonstrates how to access workflow state within a step using the `context` object. It shows how to access workflow input using `context.workflow_input()` and the output of a previous step using `ctx.step_output(\"previous_step\")`. The `parents` array defines the dependency on `previous_step`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workflows.mdx#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n@hatchet.step(parents=[\"previous_step\"])\ndef my_step(context: Context) -> dict:\n    data = context.workflow_input()\n    previous_step_data = ctx.step_output(\"previous_step\")\n    # Perform some operation\n    return output\n\n```\n\n----------------------------------------\n\nTITLE: Durable Sleep in Python\nDESCRIPTION: This code snippet demonstrates how to use durable sleep in a Hatchet worker written in Python. It utilizes the `SleepFor` method on the `DurableContext` object to pause execution for a specified duration. The snippet is sourced from the `examples/durable_sleep/worker.py` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-sleep.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/durable_sleep/worker.py\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Input Data\nDESCRIPTION: This code snippet shows how to access workflow input data using the `ctx.workflowInput()` method. It demonstrates typecasting the context to `Context<T>` to provide type safety when accessing the input data. The example assumes the input data has a 'name' property and logs it to the console.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ntype MyType = {\n  name: string;\n};\n\nconst stepPrintsInput: Step = {\n  name: \"step2\",\n  parents: [\"step1\"],\n  run: (ctx: Context<MyType>) => {\n    console.log(\"executed step2!\", ctx.workflowInput().name);\n  },\n};\n\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Bulk (Typescript)\nDESCRIPTION: This snippet demonstrates how to spawn multiple child workflows from a parent workflow in Hatchet using the Typescript SDK. It constructs an array of workflow requests and uses the `spawnWorkflows` method provided by the context to create and trigger the child workflows in a batch. This approach is more efficient than spawning workflows one at a time.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        const workflowRequests = Array.from({ length: 10 }, (_, i) => ({\n          workflow: \"child-workflow\",\n          input: { input: `child-input-${i}` },\n          options: { additionalMetadata: { childKey: `child-${i}` } },\n        }));\n\n        const spawnedWorkflows = await ctx.spawnWorkflows<string, string>(\n          workflowRequests,\n        );\n\n        return spawnedWorkflows;\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Labels - Typescript\nDESCRIPTION: This code snippet demonstrates how to dynamically update worker labels in a Hatchet step using Typescript. It checks if the worker's current model label matches the desired label and updates it if necessary.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nconst affinity: Workflow = {\n  id: \"dynamic-affinity-workflow\",\n  description: \"test\",\n  steps: [\n    {\n      name: \"child-step1\",\n      worker_labels: {\n        model: {\n          value: \"fancy-vision-model\",\n          required: false,\n        },\n      },\n      run: async (ctx) => {\n        if (ctx.worker.labels().model !== \"fancy-vision-model\") {\n          await ctx.worker.upsertLabels({ model: undefined });\n          await evictModel();\n          await loadNewModel(\"fancy-vision-model\");\n          await ctx.worker.upsertLabels({ model: \"fancy-vision-model\" });\n        }\n        // DO WORK\n        return { childStep1: \"childStep1 results!\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Defining Docker Compose Configuration (Existing Postgres)\nDESCRIPTION: Defines the Docker Compose configuration for Hatchet Lite, configured to use an existing Postgres database instance. It sets up environment variables, ports, and volumes.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nname: hatchet-lite\nservices:\n  hatchet-lite:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-lite:latest\n    ports:\n      - \"8888:8888\"\n      - \"7077:7077\"\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n      DATABASE_URL: \"postgresql://hatchet:hatchet@postgres:5432/hatchet?sslmode=disable\"\n      DATABASE_POSTGRES_PORT: \"5432\"\n      DATABASE_POSTGRES_HOST: \"postgres\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@localhost:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n      SERVER_GRPC_PORT: \"7077\"\n      SERVER_URL: http://localhost:8888\n      SERVER_AUTH_SET_EMAIL_VERIFIED: \"t\"\n      SERVER_LOGGER_LEVEL: warn\n      SERVER_LOGGER_FORMAT: console\n      DATABASE_LOGGER_LEVEL: warn\n      DATABASE_LOGGER_FORMAT: console\n    volumes:\n      - \"hatchet_lite_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_lite_config:/config\"\n\nvolumes:\n  hatchet_lite_rabbitmq_data:\n  hatchet_lite_config:\n```\n\n----------------------------------------\n\nTITLE: Hatchet Admin Token Creation (CLI)\nDESCRIPTION: This shell command executes the hatchet-admin tool within the hatchet-lite container to create an API token.  It requires a running Hatchet Lite instance deployed via Docker Compose and uses the provided configuration file. The output is piped to xargs to remove leading/trailing whitespace.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/hatchet-lite.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose -f docker-compose.hatchet.yml exec hatchet-lite /hatchet-admin token create --config /config --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52 | xargs\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet Client TLS Strategy environment variable\nDESCRIPTION: This command sets the `HATCHET_CLIENT_TLS_STRATEGY` environment variable to `none`. This is used to disable SSL when the Hatchet clients are configured to use SSL by default.  This may be necessary for self-hosted configurations.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/index.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nHATCHET_CLIENT_TLS_STRATEGY=none\n```\n\n----------------------------------------\n\nTITLE: Running Workflows in Bulk via API in Hatchet (TypeScript)\nDESCRIPTION: This code demonstrates how to trigger multiple Hatchet workflows in bulk using the `runWorkflows` method. It initializes the Hatchet client, creates an array of `WorkflowRun` objects, and then calls `runWorkflows` with the array. It requires the `@hatchet-dev/typescript-sdk` dependency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-api.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\nconst workflowRuns: WorkflowRun[] = [];\n\nworkflowRuns[0] = {\n  workflowName: \"bulk-parent-workflow\",\n  input: {},\n  options: {\n    additionalMetadata: {\n      key: \"value\",\n    },\n  },\n};\n\nworkflowRuns[1] = {\n  workflowName: \"bulk-parent-workflow\",\n  input: { second: \"second\" },\n  options: {\n    additionalMetadata: {\n      key: \"value\",\n    },\n  },\n};\n\nconst workflowRunResponse = hatchet.admin.runWorkflows(workflowRuns);\n\n```\n\n----------------------------------------\n\nTITLE: Running Python Worker\nDESCRIPTION: This command starts the Python worker by executing the `worker.py` script using `python3`.  It assumes that the `worker.py` file is in the current directory and has the necessary Hatchet worker logic implemented.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\npython3 worker.py\n```\n\n----------------------------------------\n\nTITLE: Declaring a Task with Hatchet V1 SDK (TypeScript)\nDESCRIPTION: This snippet demonstrates the new `hatchet.task` method in the V1 SDK for defining single-function tasks. It showcases the factory pattern used for creating tasks, offering improved type checking and access to new features. This method is recommended for migrating tasks to the new SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const SimpleWorker = {\n  path: \"src/v1/examples/simple/workflow.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Hatchet Load Test Kubernetes Pod Manifest\nDESCRIPTION: This Kubernetes Pod manifest defines a Pod to run the Hatchet load test container. It specifies the image, command, arguments, environment variables (including HATCHET_CLIENT_TOKEN and HATCHET_CLIENT_NAMESPACE), and resource limits. Requires Kubernetes and a valid Hatchet client token.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/benchmarking.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: loadtest1a\n  namespace: staging\nspec:\n  restartPolicy: Never\n  containers:\n    - image: ghcr.io/hatchet-dev/hatchet/hatchet-loadtest:v0.56.0\n      imagePullPolicy: Always\n      name: loadtest\n      command: [\"/hatchet/hatchet-load-test\"]\n      args:\n        - loadtest\n        - --duration\n        - \"60s\"\n        - --events\n        - \"100\"\n        - --slots\n        - \"100\"\n        - --wait\n        - \"10s\"\n        - --level\n        - warn\n      env:\n        - name: HATCHET_CLIENT_TOKEN\n          value: \"your-token\"\n        - name: HATCHET_CLIENT_NAMESPACE\n          value: \"loadtest1a\"\n      resources:\n        limits:\n          memory: 1Gi\n        requests:\n          cpu: 500m\n          memory: 1Gi\n```\n\n----------------------------------------\n\nTITLE: Dockerizing Hatchet app with PIP\nDESCRIPTION: This Dockerfile sets up a Hatchet worker environment using PIP for dependency management. It starts from a Python base image, copies the requirements.txt file, installs dependencies using pip, copies the Hatchet application code, and sets the entrypoint to run the worker using `python worker.py`. The `HATCHET_ENV` variable is set to `production`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/docker.mdx#_snippet_1\n\nLANGUAGE: Dockerfile\nCODE:\n```\n# Use the official Python image as base\nFROM python:3.10-slim\n\n# Set environment variables\n\nENV PYTHONUNBUFFERED=1 \\\n HATCHET_ENV=production\n\n# Set work directory\n\nWORKDIR /app\n\n# Copy dependency files first\n\nCOPY requirements.txt .\n\n# Install dependencies\n\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy Hatchet application code\n\nCOPY .\n\n# Set the entrypoint to run the Hatchet worker\n\nCMD [\"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Retries with Count - Python\nDESCRIPTION: This snippet shows how to access the current retry count within a running task in Python using the `retryCount` method. This allows tasks to adjust their behavior based on the number of retries attempted. Understanding the current retry count is essential for implementing adaptive error handling strategies.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/retry-policies.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nexamples/retries/worker.py\n```\n\n----------------------------------------\n\nTITLE: Deleting a Scheduled Run - Python\nDESCRIPTION: This snippet refers to an external Python file (`examples/scheduled/programatic-sync.py`) and targets a section labeled \"Delete\". It is assumed that this section contains code demonstrating how to delete a scheduled run using the Hatchet SDK in Python, potentially involving the `SchedulePy` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={SchedulePy} target=\"Delete\" />\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Admin Token (Go)\nDESCRIPTION: This Go command creates a new Hatchet admin token for a specific tenant, allowing the user to authenticate and interact with the Hatchet API. The token name is \"local\", and the tenant ID is dynamically inserted.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\ngo run ./cmd/hatchet-admin token create --name local --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet HA Helm Chart\nDESCRIPTION: This snippet demonstrates how to add the Hatchet Helm repository and install the Hatchet HA chart.  It's a standard Helm command sequence to deploy Hatchet in a high availability configuration. The snippet assumes Helm is already installed and configured to connect to a Kubernetes cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/high-availability.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nhelm repo add hatchet https://hatchet-dev.github.io/hatchet-charts\nhelm install hatchet-ha hatchet/hatchet-ha\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Workflow with Hatchet\nDESCRIPTION: This code snippet demonstrates how to schedule a workflow to run at a future time using the `hatchet.client.admin.schedule_workflow` method. It requires the `hatchet_sdk` library and uses the `datetime` and `timedelta` objects to define the schedule time. The method takes the workflow name, schedule time, and input data as parameters.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-schedule.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nhatchet = Hatchet()\n\nnow = datetime.now()\nfuture_time = now + timedelta(seconds=15)\n\nworkflowRun = hatchet.client.admin.schedule_workflow(\n    \"ManualTriggerWorkflow\",\n    [future_time],\n    {\"test\": \"test\"},\n)\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration (Postgres)\nDESCRIPTION: This Docker Compose configuration defines services for Hatchet Lite and a Postgres database. It sets up the necessary environment variables, ports, and volumes for Hatchet Lite to connect to the database and RabbitMQ. It is intended for use when a new Postgres instance is needed for Hatchet Lite.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/hatchet-lite.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nname: hatchet-lite\nservices:\n  postgres:\n    image: postgres:15.6\n    command: postgres -c 'max_connections=200'\n    restart: always\n    environment:\n      - POSTGRES_USER=hatchet\n      - POSTGRES_PASSWORD=hatchet\n      - POSTGRES_DB=hatchet\n    volumes:\n      - hatchet_lite_postgres_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -d hatchet -U hatchet\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n  hatchet-lite:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-lite:latest\n    ports:\n      - \"8888:8888\"\n      - \"7077:7077\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n      DATABASE_URL: \"postgresql://hatchet:hatchet@postgres:5432/hatchet?sslmode=disable\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@localhost:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n      SERVER_GRPC_PORT: \"7077\"\n      SERVER_URL: http://localhost:8888\n      SERVER_AUTH_SET_EMAIL_VERIFIED: \"t\"\n      SERVER_DEFAULT_ENGINE_VERSION: \"V1\"\n      SERVER_INTERNAL_CLIENT_INTERNAL_GRPC_BROADCAST_ADDRESS: localhost:7077\n    volumes:\n      - \"hatchet_lite_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_lite_config:/config\"\n\nvolumes:\n  hatchet_lite_postgres_data:\n  hatchet_lite_rabbitmq_data:\n  hatchet_lite_config:\n```\n\n----------------------------------------\n\nTITLE: Accessing Retry Count in Python\nDESCRIPTION: This Python snippet demonstrates how to access the current retry count within a Hatchet step. The `context.retry_count()` method is used to retrieve the number of times the step has been retried. A deliberate exception is raised to trigger retries. Dependencies: `hatchet` library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout='2s', retries=3)\ndef step1(self, context: Context):\n    retry_count = context.retry_count()\n    print(f\"Retry count: {retry_count}\")\n    raise Exception(\"Step failed\")\n```\n\n----------------------------------------\n\nTITLE: Defining API and Engine Environment Variables for values.yaml (YAML)\nDESCRIPTION: This snippet defines the API and Engine environment variables within a Helm chart's `values.yaml` file, and includes placeholders for secrets. It configures the authentication cookie domain, server URL, gRPC settings, and crucial secret keysets (auth cookie secrets, encryption master keyset, JWT keysets).  It is important to replace placeholder values with actual secrets generated using the key generation commands.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/networking.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napi:\n  env:\n    # TODO: insert these values from the output of the keyset generation command\n    SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n    SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n\nengine:\n  env:\n    # TODO: insert these values from the output of the keyset generation command\n    SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n    SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n```\n\n----------------------------------------\n\nTITLE: Creating Task with Event Trigger (Typescript)\nDESCRIPTION: Creates a Hatchet task that waits for either an external user event or sleeps for 10 seconds using Typescript. Uses `Or` to define the condition.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\n// Create a task which waits for an external user event or sleeps for 10 seconds\ndagWithConditions.task({\n  name: \"secondTask\",\n  parents: [firstTask],\n  waitFor: Or({ eventKey: \"user:event\" }, { sleepFor: \"10s\" }),\n  fn: async (_, ctx) => {\n    return {\n      Completed: true,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Running a Task in Typescript\nDESCRIPTION: This code snippet, sourced from Github, demonstrates running a Hatchet task in Typescript. The code is retrieved from the file specified in `SimpleRunTs` and the section labelled \"Running a Task\". It shows how to invoke a task within a Typescript workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/running-your-task.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet src={SimpleRunTs} target=\"Running a Task\" />\n```\n\n----------------------------------------\n\nTITLE: Logging with context.log (Python)\nDESCRIPTION: This snippet showcases using the `context.log` method within a Hatchet workflow step. The `context` object, passed to each step, provides the `log` method for emitting log messages. This method sends structured logs to the Hatchet platform. It includes a `for` loop to generate multiple logs to showcase it.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/logging.mdx#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:create\"],schedule_timeout=\"10m\")\nclass LoggingWorkflow:\n    @hatchet.step()\n    def logger(self, context : Context):\n\n        for i in range(1000):\n            context.log(f\"Logging message {i}\")\n\n        return {\n            \"step1\": \"completed\",\n        }\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet with Root Logger (Python)\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet client with a root logger.  It configures basic logging and passes the root logger to the Hatchet client configuration, ensuring that all logs are captured by Hatchet. Dependencies: hatchet_sdk, logging.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/logging.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport logging\n\nfrom hatchet_sdk import ClientConfig, Hatchet\n\nlogging.basicConfig(level=logging.INFO)\n\nroot_logger = logging.getLogger()\n\nhatchet = Hatchet(\n    debug=True,\n    config=ClientConfig(\n        logger=root_logger,\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Generate Example .env File (Shell)\nDESCRIPTION: This shell script generates an example `.env` file for the simple example workflow. It includes setting the tenant ID, TLS certificate paths, server name and client token, which are required for the application to connect to the Hatchet server.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nalias get_token='go run ./cmd/hatchet-admin token create --name local --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52'\n\ncat > ./examples/simple/.env <<EOF\nHATCHET_CLIENT_TENANT_ID=707d0855-80ab-4e1f-a156-f1c4546cbf52\nHATCHET_CLIENT_TLS_ROOT_CA_FILE=../../hack/dev/certs/ca.cert\nHATCHET_CLIENT_TLS_SERVER_NAME=cluster\nHATCHET_CLIENT_TOKEN=\"$(get_token)\"\nEOF\n```\n\n----------------------------------------\n\nTITLE: Apply Kubernetes Secret\nDESCRIPTION: This script applies the generated Kubernetes secret to the 'hatchet' namespace.  It first creates the 'hatchet' namespace if it doesn't exist, then applies the `hatchet-secret.yaml` file. Requires `kubectl` to be installed and configured.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nkubectl create namespace hatchet\nkubectl apply -f hatchet-secret.yaml\n```\n\n----------------------------------------\n\nTITLE: Hatchet RabbitMQ QOS Setting\nDESCRIPTION: This configuration setting increases the number of messages that can be processed in parallel for the internal message queue, potentially improving the time to start for each step run in a workflow. Be aware that if this value is significantly higher than the database connection pool size, performance will not improve. Decreasing this value may be necessary if connection saturation warnings appear in engine logs.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nSERVER_MSGQUEUE_RABBITMQ_QOS=200\n```\n\n----------------------------------------\n\nTITLE: Install Hatchet Typescript SDK\nDESCRIPTION: Installs the Hatchet Typescript SDK using npm or yarn.  This is a prerequisite for using the SDK in a Typescript project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm i @hatchet-dev/typescript-sdk\n```\n\n----------------------------------------\n\nTITLE: Add Wait for Event Task - TypeScript\nDESCRIPTION: This snippet adds a task that waits for a specific event to be triggered before it starts execution using `wait_for` in TypeScript. It highlights the event-driven capabilities of Hatchet's conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_16\n\nLANGUAGE: TypeScript\nCODE:\n```\nsrc/v1/examples/dag_match_condition/complex-workflow.ts\n```\n\n----------------------------------------\n\nTITLE: Configuring Hatchet Client with ClientConfig\nDESCRIPTION: This snippet demonstrates how to configure a Hatchet client using the `ClientConfig` class in Python. It imports both `Hatchet` and `ClientConfig` from the `hatchet_sdk` and initializes the `Hatchet` client by passing a `ClientConfig` object with specific configurations like token and namespace.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/client.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nhatchet = Hatchet(\n    config=ClientConfig(\n        token=\"my-token\",\n        namespace=\"my-namespace\",\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: JSON Input for Triggering Workflow\nDESCRIPTION: This snippet provides a JSON payload used to trigger the BasicRagWorkflow. It contains a list of messages and a URL. The messages array contains a user message object with role and content fields. The URL specifies the website to be processed by the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"how do i install hatchet?\"\n    }\n  ],\n  \"url\": \"https://docs.hatchet.run/home\"\n}\n```\n\n----------------------------------------\n\nTITLE: Chicago-Based A10 Configuration (Python)\nDESCRIPTION: This Python code configures a Hatchet compute resource to use the A10 GPU in the Chicago region. It specifies the GPU type, the number of GPUs, the memory allocation, the number of replicas, and the region where the workflow will run. Requires the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Chicago-based A10 configuration\ncompute = Compute(\n    gpu_kind=\"a10\",\n    gpus=1,\n    memory_mb=49152,\n    num_replicas=2,\n    regions=[\"ord\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus Environment Variables\nDESCRIPTION: This snippet demonstrates how to set environment variables to enable and configure the Prometheus metrics endpoint for a Hatchet server. It sets `SERVER_PROMETHEUS_ENABLED` to `true` to enable the endpoint, `SERVER_PROMETHEUS_ADDRESS` to `:9999` to define the address and port, and `SERVER_PROMETHEUS_PATH` to `/custom-metrics` to specify the HTTP path where metrics are exposed. Restarting the server is required for the changes to take effect.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport SERVER_PROMETHEUS_ENABLED=true\nexport SERVER_PROMETHEUS_ADDRESS=\":9999\"\nexport SERVER_PROMETHEUS_PATH=\"/custom-metrics\"\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event in Python\nDESCRIPTION: This snippet shows how to push an event to the Hatchet event queue using the `push` method on the Hatchet event client in Python. It provides the event name and payload. The example utilizes the `EventPyTrigger` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nexamples/events/event.py\n```\n\n----------------------------------------\n\nTITLE: Handling Webhooks in Node.js HTTP Server (TypeScript)\nDESCRIPTION: This code snippet demonstrates how to handle Hatchet webhooks in a standard Node.js HTTP server. It initializes Hatchet, creates a webhooks instance, and passes the webhook handler to `createServer` using `webhooks.httpHandler`. It requires the `@hatchet-dev/typescript-sdk` and `http` dependencies, as well as the `HATCHET_WEBHOOK_SECRET` environment variable.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/webhooks.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { createServer } from \"http\";\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst webhooks = hatchet.webhooks([workflow]);\n\nconst server = createServer(\n  webhooks.httpHandler({ secret: process.env.HATCHET_WEBHOOK_SECRET }),\n);\n\nserver.listen(8080, () => {\n  console.log(\"Server is listening on port 8080\");\n});\n```\n\n----------------------------------------\n\nTITLE: Subscribing to results - Typescript\nDESCRIPTION: This snippet shows how to subscribe to the results of a workflow in Typescript using Hatchet. It uses the `GithubSnippet` component to include the code from the file specified by `SimpleTs`. The code allows you to access the results after the workflow has completed, following a previous enqueue operation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Subscribing to results\" />\n```\n\n----------------------------------------\n\nTITLE: Define RAG Workflow with Hatchet in Python\nDESCRIPTION: This Python code defines a Retrieval-Augmented Generation (RAG) workflow using the Hatchet SDK. It includes steps for loading documents, reasoning about them, and generating a response. The workflow utilizes the `hatchet.workflow` decorator to define the workflow and `hatchet.step` to define individual steps. The playground function allows defining variables that are surfaced in the Hatchet UI.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n    @hatchet.step()\n    def load_docs(self, context: Context):\n        # use beautiful soup to parse the html content\n        url = context.workflow_input()['request']['url']\n\n        html_content = requests.get(url).text\n        soup = BeautifulSoup(html_content, 'html.parser')\n        element = soup.find('body')\n        text_content = element.get_text(separator=' | ')\n\n        return {\n            \"status\": \"making sense of the docs\",\n            \"docs\": text_content,\n        }\n\n    @hatchet.step(parents=[\"load_docs\"])\n    def reason_docs(self, ctx: Context):\n        message = ctx.workflow_input()['request'][\"messages\"][-1]\n        docs = ctx.step_output(\"load_docs\")['docs']\n\n        prompt = ctx.playground(\"prompt\", \"The user is asking the following question:\\\n            {message}\\\n            What are the most relevant sentences in the following document?\\\n            {docs}\")\n\n        prompt = prompt.format(message=message['content'], docs=docs)\n\n        model = ctx.playground(\"model\", \"gpt-3.5-turbo\")\n\n        completion = openai.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n                message\n            ]\n        )\n\n        return {\n            \"status\": \"writing a response\",\n            \"research\": completion.choices[0].message.content,\n        }\n\n    @hatchet.step(parents=[\"reason_docs\"])\n    def generate_response(self, ctx: Context):\n        messages = ctx.workflow_input()['request'][\"messages\"]\n        research = ctx.step_output(\"reason_docs\")['research']\n\n        prompt = ctx.playground(\"prompt\", \"You are a sales engineer for a company called Hatchet. Help address the user's question. Use the following context:\\\n            {research}\")\n\n        prompt = prompt.format(research=research)\n\n        model = ctx.playground(\"model\", \"gpt-3.5-turbo\")\n\n        completion = openai.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n            ] + messages\n        )\n\n        return {\n            \"completed\": \"true\",\n            \"status\": \"idle\",\n            \"message\": completion.choices[0].message.content,\n        }\n```\n\n----------------------------------------\n\nTITLE: Enqueuing a Task Run (Fire and Forget) - Python\nDESCRIPTION: This snippet demonstrates how to enqueue a task run in Hatchet using the `run_no_wait` method in Python. It shows how to obtain a `WorkflowRunRef` without waiting for the task to complete. The `input` parameter is a Pydantic model matching the task's input schema. The `aio_run_no_wait` is also shown for async operations.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-no-wait.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom src.workflows import my_workflow, MyWorkflowInputModel\n\nref = my_workflow.run_no_wait(MyWorkflowInputModel(foo=\"bar\"))\n```\n\nLANGUAGE: python\nCODE:\n```\nref = await my_task.aio_run_no_wait(input=MyTaskInputModel(foo=\"bar\"))\n```\n\n----------------------------------------\n\nTITLE: Initializing Compute Configuration in Hatchet (Python)\nDESCRIPTION: This snippet shows how to initialize a `Compute` object in Python using the Hatchet SDK. It defines the CPU type, number of cores, memory allocation, number of replicas, and regions for the compute instance. This configuration can then be used within a Hatchet workflow step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom hatchet_sdk.compute.configs import Compute\n\ncompute = Compute(\n    cpu_kind=\"shared\", # \"shared\" or \"performance\"\n    cpus=2, # Number of CPU cores\n    memory_mb=1024, # Memory in MB\n    num_replicas=2, # Number of instances\n    regions=[\"ewr\"] # Region codes\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring API and Engine Environment Variables (YAML)\nDESCRIPTION: This YAML snippet configures environment variables for the `api` and `engine` services in a Kubernetes deployment. It sets variables for authentication, server URLs, GRPC binding addresses, and broadcast addresses.  Replace `hatchet.example.com` with your domain.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/networking.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napi:\n  env:\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n\nengine:\n  env:\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n```\n\n----------------------------------------\n\nTITLE: Example Repository Structure for Hatchet Workers\nDESCRIPTION: This example shows a recommended repository structure for Hatchet workers, including Dockerfiles for multiple workers and a hatchet.yaml file. It demonstrates how to organize code for different worker configurations.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/git-ops.mdx#_snippet_1\n\nLANGUAGE: Text\nCODE:\n```\n.\n├── Dockerfile.worker1          # Primary worker configuration\n├── Dockerfile.worker2          # Secondary worker configuration\n├── .dockerignore\n├── src/\n│   ├── worker1/               # Worker 1 specific code\n│   │   └── worker.py\n│   └── worker2/               # Worker 2 specific code\n│       └── worker.py\n└── hatchet.yaml               # Optional Hatchet configuration\n```\n\n----------------------------------------\n\nTITLE: Bulk Spawn Workflows with Hatchet\nDESCRIPTION: This Go snippet demonstrates how to bulk spawn child workflows from a parent workflow using the Hatchet Go SDK. It registers a workflow named 'parent-workflow' that is triggered by the 'fanout:create' event. The workflow step prepares a slice of `SpawnWorkflowsOpts` and then calls `ctx.SpawnWorkflows` to spawn the workflows in bulk. A maximum limit of 1000 workflows per request is enforced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                // Prepare the batch of workflows to spawn\n                childWorkflows := make([]*worker.SpawnWorkflowsOpts, 10)\n\n                for i := 0; i < 10; i++ {\n                    childInput := \"child-input-\" + strconv.Itoa(i)\n                    childWorkflows[i] = &worker.SpawnWorkflowsOpts{\n                        WorkflowName: \"child-workflow\",\n                        Input:        childInput,\n                        Key:          \"child-key-\" + strconv.Itoa(i),\n                    }\n                }\n\n                // Spawn all workflows in bulk using SpawnWorkflows\n                createdWorkflows, err := ctx.SpawnWorkflows(childWorkflows)\n                if err != nil {\n                    return err\n                }\n\n                return nil\n            }),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Compute Configuration with Replicas Across Multiple Regions (Python)\nDESCRIPTION: This snippet shows how to configure a `Compute` object with a specified number of replicas distributed randomly across multiple regions. The replicas will be spread across the listed regions ('ewr', 'lax', 'lhr' in this case).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\n# Multiple regions, multiple replicas\ncompute = Compute(\n    cpu_kind=\"shared\",\n    cpus=2,\n    memory_mb=1024,\n    num_replicas=6,\n    regions=[\"ewr\", \"lax\", \"lhr\"]    # 6 replicas randomly distributed across the three regions\n)\n```\n\n----------------------------------------\n\nTITLE: Set Hatchet Client Token Environment Variable\nDESCRIPTION: Sets the HATCHET_CLIENT_TOKEN environment variable, which is required for authenticating with the Hatchet engine. Replace `<your-api-key>` with the actual API key obtained from the Hatchet dashboard.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nHATCHET_CLIENT_TOKEN=\"<your-api-key>\"\n```\n\n----------------------------------------\n\nTITLE: Setting Termination Signals for a Hatchet Worker in Go\nDESCRIPTION: This code snippet shows how to set up termination signals for a Hatchet worker. It uses the `cmdutils.NewInterruptContext` method to create a context that will be cancelled when the process receives an interrupt signal (e.g. `SIGINT` or `SIGTERM`).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/creating-a-worker.mdx#_snippet_1\n\nLANGUAGE: go\nCODE:\n```\nctx, cancel := cmdutils.NewInterruptContext()\n\ndefer cancel()\n\nw.Start(ctx)\n```\n\n----------------------------------------\n\nTITLE: Calculating Average Queue Time (PromQL)\nDESCRIPTION: This PromQL query calculates the average queue time in milliseconds over the past 5 minutes. It uses the `hatchet_queued_to_assigned_seconds_sum` and `hatchet_queued_to_assigned_seconds_count` metrics, divides the rate of the sum by the rate of the count, and multiplies the result by 1000 to convert seconds to milliseconds.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_2\n\nLANGUAGE: promql\nCODE:\n```\n# Calculates average queue time over the past 5 minutes, converted to ms\nrate(hatchet_queued_to_assigned_seconds_sum[5m])\n  / rate(hatchet_queued_to_assigned_seconds_count[5m])\n  * 1e3\n```\n\n----------------------------------------\n\nTITLE: Refreshing Step Timeout in Python\nDESCRIPTION: This snippet demonstrates how to refresh the timeout for a running Hatchet step using Python. The `context.refresh_timeout` function is called with the desired extension time, adding to the remaining time.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout=\"30s\")\ndef timeout(self, context):\n    time.sleep(20)\n    context.refresh_timeout(\"15s\")\n    time.sleep(10)\n    return {\n      step1: \"step1 results!\"\n    }\n```\n\n----------------------------------------\n\nTITLE: Running Workflows in Bulk via API - Python\nDESCRIPTION: This snippet shows how to trigger multiple workflows in bulk using the `run_workflows` method of the Hatchet Admin client. It requires the `hatchet_sdk` package. The code constructs a list of `WorkflowRun` objects, each specifying the workflow name, input, and options, including additional metadata. The list is then passed to the `run_workflows` method.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-api.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nhatchet = Hatchet()\n\nworkflowRuns: WorkflowRun = []\n\nfor i in range(20):\n    workflowRuns.append(\n        {\n            \"workflow_name\": \"BulkParent\",\n            \"input\": {\"n\": i},\n            \"options\": {\n                \"additional_metadata\": {\n                    \"bulk-trigger\": i,\n                    \"hello-{i}\": \"earth-{i}\",\n                },\n            },\n        }\n    )\n\nworkflowRunRefs = hatchet.admin.run_workflows(\n    workflowRuns,\n)\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow with Additional Metadata - Python\nDESCRIPTION: This snippet demonstrates how to trigger a workflow run with additional metadata using the Python client. It sets the 'hello' metadata key to 'moon'. The workflow is identified by the 'user-workflow' name and includes a 'userId' in the input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nworkflowRunId = hatchet.admin.run_workflow(\n    \"user-workflow\",\n    {'userId': '1234'},\n    options={\n        'additional_metadata': {\n          \"hello\": \"moon\" # Arbitrary key-value pair\n        }\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a TypeScript Worker\nDESCRIPTION: This TypeScript code defines a simple Hatchet workflow and registers it with a worker. It uses the `@hatchet-dev/typescript-sdk` and `dotenv` packages. It initializes the Hatchet client, defines a workflow with a single step, registers the workflow with the worker, and starts the worker. Environment variables are loaded from a `.env` file using `dotenv`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"first-typescript-workflow\",\n  description: \"This is my first workflow\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n\n        return {\n          result: \"success!\",\n        };\n      },\n    },\n  ],\n};\n\nconst worker = hatchet.worker(\"my-worker\");\nawait worker.registerWorkflow(workflow);\nworker.start();\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Python\nDESCRIPTION: This Python code snippet demonstrates spawning child workflows using the Hatchet Python SDK. It iterates through a list of pages from the workflow input and spawns a 'process-page' workflow for each page.  The `context.spawn_workflow` method is used, with a key and index to ensure durability. `asyncio.gather` is used to collect the results of the child workflows.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/child-workflows.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step()\nasync def fanout_pages(self, context: Context):\n    pages = context.workflow_input()[\"pages\"]\n    futures = []\n    for index, page in enumerate(pages):\n        future = context.spawn_workflow(\"process-page\", key=page, index=f'page-{index}')\n        futures.append(future.result())\n\n    results = await asyncio.gather(*futures)\n\n    return {\n        \"results\": results\n    }\n```\n\n----------------------------------------\n\nTITLE: Fetching code snippets for manual slot release examples\nDESCRIPTION: This code defines a `getStaticProps` function that retrieves code snippets for the manual slot release examples using the `getSnippets` function. The snippets are retrieved based on the file paths specified in `SlotReleasePy` and `SlotReleaseTS`. This function is used for static site generation to pre-render the code examples.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/manual-slot-release.mdx#_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const getStaticProps = ({}) =>\n  getSnippets([SlotReleasePy, SlotReleaseTS]);\n```\n\n----------------------------------------\n\nTITLE: Initializing Worker with Labels - Go\nDESCRIPTION: This code snippet shows how to initialize a Hatchet worker with labels in Go. The labels are key-value pairs that describe the worker's capabilities and resources. The worker is initialized with labels for \"model\" and \"memory\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithLabels(map[string]interface{}{\n\t\t\t\"model\":  \"fancy-ai-model-v2\",\n\t\t\t\"memory\": 512,\n\t\t}),\n\t)\n```\n\n----------------------------------------\n\nTITLE: Querying Task Creation and Retry Rates (PromQL)\nDESCRIPTION: This PromQL query retrieves the rates of created and retried tasks over a 5-minute window using the `hatchet_created_tasks_total` and `hatchet_retried_tasks_total` metrics, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/prometheus-metrics.mdx#_snippet_5\n\nLANGUAGE: promql\nCODE:\n```\nrate(hatchet_created_tasks_total[5m])\nrate(hatchet_retried_tasks_total[5m])\n```\n\n----------------------------------------\n\nTITLE: Defining WorkflowRunTriggeredBy Interface in TypeScript\nDESCRIPTION: This code snippet shows the definition of the `WorkflowRunTriggeredBy` interface in TypeScript. It outlines the properties related to how a workflow run was triggered, including properties for event-based and cron-based triggers, as well as parent workflow information. It utilizes other interfaces like `Event` and `APIResourceMeta`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkflowRunTriggeredBy.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface WorkflowRunTriggeredBy {\n  cronParentId?: string;\n  cronSchedule?: string;\n  event?: Event;\n  eventId?: string;\n  metadata: APIResourceMeta;\n  parentId: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining APIToken Interface in TypeScript\nDESCRIPTION: This code defines the TypeScript interface `APIToken` which is part of the `APIContracts` module. It specifies the structure of an API token, including the `expiresAt` (expiration date as a string), `metadata` (an `APIResourceMeta` object), and `name` (the name of the token as a string). The `expiresAt` property is formatted as a date-time string. The `name` property has a maximum length of 255 characters. The interface is located in `src/clients/rest/generated/data-contracts.ts`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIToken.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: APIToken\n *\n * [APIContracts](../modules/APIContracts.md).APIToken\n */\ninterface APIToken {\n  /**\n   * When the API token expires.\n   *\n   * **`Format`**\n   *\n   * date-time\n   */\n  expiresAt: string;\n\n  metadata: APIResourceMeta;\n\n  /**\n   * The name of the API token.\n   *\n   * **`Max Length`**\n   *\n   * 255\n   */\n  name: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Exponential Backoff in Typescript (GithubSnippet)\nDESCRIPTION: This section refers to a Typescript GithubSnippet which contains example of implementing Exponential Backoff using retries feature.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_7\n\n\n\n----------------------------------------\n\nTITLE: Listening for Workflow Events\nDESCRIPTION: This code snippet demonstrates how to listen for events from a Hatchet workflow using the `hatchet.listener.stream` method. It retrieves the `workflowRunId` and then iterates through the event stream, printing the event data. The Python version also demonstrates filtering and transforming event data.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync def listen_for_files():\n    workflowRunId = hatchet.admin.run_workflow(\"ManualTriggerWorkflow\", {\"test\": \"test\"})\n    listener = hatchet.listener.stream(workflowRunId)\n\n    async for event in listener:\n        # Filter and transform event data here\n        data = json.dumps({\n            \"type\": event.type,\n            \"messageId\": workflowRunId\n        })\n        print(\"data: \" + data + \"\\n\\n\")\n```\n\n----------------------------------------\n\nTITLE: APIErrors Instantiation and JSON Conversion in Python\nDESCRIPTION: This snippet demonstrates how to create an instance of the APIErrors model from a JSON string, print the JSON representation of the APIErrors class, convert the object to a dictionary, and then recreate an instance from the dictionary. It relies on the hatchet_sdk library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIErrors.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_errors import APIErrors\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIErrors from a JSON string\napi_errors_instance = APIErrors.from_json(json)\n# print the JSON string representation of the object\nprint APIErrors.to_json()\n\n# convert the object into a dict\napi_errors_dict = api_errors_instance.to_dict()\n# create an instance of APIErrors from a dict\napi_errors_form_dict = api_errors.from_dict(api_errors_dict)\n```\n\n----------------------------------------\n\nTITLE: Configuring Postgres WAL Size\nDESCRIPTION: This code snippet shows how to configure `max_wal_size` in Postgres. Increasing this value can lead to improved performance if there is sufficient disk capacity. This parameter determines the maximum size to which the write-ahead log (WAL) can grow before a checkpoint is forced.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_10\n\nLANGUAGE: text\nCODE:\n```\nmax_wal_size=15040\n```\n\n----------------------------------------\n\nTITLE: Cloning Hatchet Go Quickstart\nDESCRIPTION: Clones the Hatchet Go quickstart project repository from GitHub. This command downloads the project files to your local machine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/go.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/hatchet-dev/hatchet-go-quickstart.git\n```\n\n----------------------------------------\n\nTITLE: Declaring a Child Task in Hatchet (TypeScript)\nDESCRIPTION: This code snippet shows how to declare a child task within the Hatchet V1 SDK. It's part of the fanout example, demonstrating improved type support for spawning child tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const FanoutWorker = {\n  path: \"src/v1/examples/child_workflows/workflow.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Streaming Data from a Step Context\nDESCRIPTION: This code snippet demonstrates how to stream data from within a Hatchet step using `ctx.putStream`. It takes a string as input and streams it. This allows for real-time updates or debugging information to be sent from a step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync function step1(ctx: Context) {\n  // Stream some data from the step context\n  ctx.putStream(\"step1 stream\");\n  // continue with the step run...\n  return { step1: \"step1 results!\" };\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limit (Go)\nDESCRIPTION: Defines a Hatchet workflow with concurrency limits on a per-user basis using Go, allowing only 1 concurrent run based on the `userId` input. Includes a rate-limited task that restricts execution to 10 tasks per minute per user.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\n// limit concurrency on a per-user basis\nflowControlWorkflow := factory.NewWorkflow[DagInput, DagResult](\n  create.WorkflowCreateOpts[DagInput]{\n    Name: \"simple-dag\",\n    Concurrency: []*types.Concurrency{\n      {\n        Expression:    \"input.userId\",\n        MaxRuns:       1,\n        LimitStrategy: types.GroupRoundRobin,\n      },\n    },\n  },\n  hatchet,\n)\n\n// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit\nflowControlWorkflow.Task(\n  create.WorkflowTask[FlowControlInput, FlowControlOutput]{\n    Name: \"rate-limit-task\",\n    RateLimits: []*types.RateLimit{\n      {\n        Key:            \"user-rate-limit\",\n        KeyExpr:        \"input.userId\",\n        Units:          1,\n        LimitValueExpr: 10,\n        Duration:       types.Minute,\n      },\n    },\n  }, func(ctx worker.HatchetContext, input FlowControlInput) (interface{}, error) {\n    return &SimpleOutput{\n      Step: 1,\n    }, nil\n  },\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Rate Limits - Typescript\nDESCRIPTION: This snippet shows how to define and use rate limits in Hatchet workflows using TypeScript. It defines a rate limit with `hatchet.admin.put_rate_limit` and then configures a workflow step to consume units from that limit.  The rate limits are applied to specific steps within the workflow definition.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/rate-limits.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nawait hatchet.admin.put_rate_limit(\"test-limit\", 1, RateLimitDuration.MINUTE);\n```\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  // ... the rest of the workflow definition\n  steps: [\n    {\n      name: \"step1\",\n      rate_limits: [{ key: \"example-limit\", units: 1 }],\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n        return { step1: \"step1 results!\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Creating logs table\nDESCRIPTION: This SQL code creates a `logs` table designed to store application logs, with columns for the creation timestamp, tenant ID, resource ID, and the log message. The table is then converted into a TimescaleDB hypertable, partitioned by the `created_at` column. An index is created on `tenant_id`, `resource_id`, and `created_at` for efficient query performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\nCREATE TABLE logs (\n    created_at TIMESTAMPTZ NOT NULL,\n    tenant_id UUID NOT NULL,\n    resource_id UUID NOT NULL,\n    log TEXT\n);\n\nSELECT create_hypertable('logs', by_range('created_at'));\n\nCREATE INDEX ON logs (tenant_id, resource_id, created_at);\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: These pip commands install the required Python dependencies for running the Hatchet worker.  They install `python-dotenv` to load environment variables and `hatchet-sdk` for interacting with the Hatchet service.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\npip install python-dotenv\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Pushing Single Event to Hatchet API - Python\nDESCRIPTION: This code snippet demonstrates how to push a single event to the Hatchet API using the `client.event.push` method.  It initializes the Hatchet client and then calls `push` with the event name and payload. The event's input data will be passed to the workflow run. Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-events.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nhatchet.client.event.push(\n    \"user:create\",\n    {\n        \"test\": \"test\"\n    }\n)\n```\n\n----------------------------------------\n\nTITLE: Hatchet OpenTelemetry Configuration Example\nDESCRIPTION: This snippet shows an example of how to configure OpenTelemetry for distributed tracing in Hatchet using environment variables. It sets the service name and collector URL, with optional headers and endpoint configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nSERVER_OTEL_SERVICE_NAME=engine\nSERVER_OTEL_COLLECTOR_URL=<collector-url>\n\n# optional\nOTEL_EXPORTER_OTLP_HEADERS=<optional-headers>\n\n# optional\nOTEL_EXPORTER_OTLP_ENDPOINT=<collector-url>\n```\n\n----------------------------------------\n\nTITLE: Defining JobRun Interface - Hatchet TS SDK\nDESCRIPTION: This code snippet defines the `JobRun` interface, which represents a single job run in the Hatchet system. It includes properties for timestamps (`cancelledAt`, `finishedAt`, `startedAt`, `timeoutAt`), identifiers (`jobId`, `workflowRunId`, `tenantId`, `tickerId`), statuses (`status`), associated entities (`job`, `workflowRun`, `stepRuns`), and metadata (`metadata`). The interface is part of the `APIContracts` module and is used to define the structure of job run data.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.JobRun.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: JobRun\n *\n * [APIContracts](../modules/APIContracts.md).JobRun\n */\n\n/**\n * @public\n */\ninterface JobRun {\n  cancelledAt?: string; // date-time\n  cancelledError?: string;\n  cancelledReason?: string;\n  finishedAt?: string; // date-time\n  job?: Job;\n  jobId: string;\n  metadata: APIResourceMeta;\n  result?: object;\n  startedAt?: string; // date-time\n  status: JobRunStatus;\n  stepRuns?: StepRun[];\n  tenantId: string;\n  tickerId?: string;\n  timeoutAt?: string; // date-time\n  workflowRun?: WorkflowRun;\n  workflowRunId: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the 'generate_response' step in Hatchet workflow\nDESCRIPTION: This snippet defines the 'generate_response' step within a Hatchet workflow. It uses the OpenAI API to generate a response based on the reasoned context obtained from the 'reason_docs' step. It leverages the `playground` feature of the Hatchet Context to expose variables for interactive modification within the Hatchet Dashboard. This step depends on the 'reason_docs' step and requires access to the OpenAI API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n\n    # ... previous steps\n\n    @hatchet.step(parents=[\"reason_docs\"])\n    def generate_response(self, ctx: Context):\n        messages = ctx.workflow_input()['request'][\"messages\"]\n        research = ctx.step_output(\"reason_docs\")['research']\n\n        prompt = ctx.playground(\"prompt\", \"You are a sales engineer for a company called Hatchet.\\\n            Help address the user's question. \\\n            If asked how to install, respond by saying go to the store to buy a CD.\\\n            Use the following context:\\\n            {research}\")\n\n        prompt = prompt.format(research=research)\n\n        model = ctx.playground(\"model\", \"gpt-3.5-turbo\")\n\n        completion = openai.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": prompt},\n            ] + messages\n        )\n\n        return {\n            \"completed\": \"true\",\n            \"status\": \"idle\",\n            \"message\": completion.choices[0].message.content,\n        }\n```\n\n----------------------------------------\n\nTITLE: WorkflowTriggerCronRef Interface Definition (TypeScript)\nDESCRIPTION: Defines the `WorkflowTriggerCronRef` interface, representing a cron trigger for a workflow.  It includes optional `cron` (string) representing the cron expression and `parent_id` (string) for linking to a parent resource.  This interface is part of the Hatchet TypeScript SDK's generated data contracts.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkflowTriggerCronRef.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface WorkflowTriggerCronRef {\n  cron?: string;\n  parent_id?: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Internal Events - Typescript\nDESCRIPTION: Demonstrates how to push multiple internal events from within a Typescript application using the Hatchet SDK. The `hatchet.event.bulkPush` method is used to push a list of events with specified payloads and metadata. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst events = [\n  {\n    payload: { test: \"test1\" },\n    additionalMetadata: { user_id: \"user1\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test2\" },\n    additionalMetadata: { user_id: \"user2\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test3\" },\n    additionalMetadata: { user_id: \"user3\", source: \"test\" },\n  },\n];\n\nhatchet.event.bulkPush(\"user:create:bulk\", events);\n```\n\n----------------------------------------\n\nTITLE: Hatchet Worker in Go\nDESCRIPTION: This Go code defines a Hatchet worker that registers a simple workflow. The workflow is triggered by the `simple` event and contains a single step that prints a message. It depends on the `github.com/joho/godotenv`, `github.com/hatchet-dev/hatchet/pkg/client`, `github.com/hatchet-dev/hatchet/pkg/cmdutils`, and `github.com/hatchet-dev/hatchet/pkg/worker` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/joho/godotenv\"\n\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/cmdutils\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype stepOutput struct{}\n\nfunc main() {\n\terr := godotenv.Load()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tc, err := client.New()\n\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating client: %v\", err))\n\t}\n\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithMaxRuns(1),\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating worker: %v\", err))\n\t}\n\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tName:        \"simple-workflow\",\n\t\t\tDescription: \"Simple one-step workflow.\",\n      On:          worker.Events(\"simple\"),\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOutput, err error) {\n\t\t\t\t\tfmt.Println(\"executed step 1\")\n\n\t\t\t\t\treturn &stepOutput{}, nil\n\t\t\t\t},\n\t\t\t\t).SetName(\"step-one\"),\n\t\t\t},\n\t\t},\n\t)\n\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error registering workflow: %v\", err))\n\t}\n\n\tinterruptCtx, cancel := cmdutils.InterruptContextFromChan(cmdutils.InterruptChan())\n\tdefer cancel()\n\n\tcleanup, err := w.Start()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error starting worker: %v\", err))\n\t}\n\n\t<-interruptCtx.Done()\n\tif err := cleanup(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet SDK with pip\nDESCRIPTION: This code snippet demonstrates how to install the Hatchet Python SDK using pip.  It utilizes the `pip install` command followed by the package name `hatchet-sdk`. This assumes that pip is installed and configured correctly on the system.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/python/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Go\nDESCRIPTION: This Go code snippet showcases how to spawn child workflows using the Hatchet Go SDK. It receives a number of pages as input, and creates a slice of `worker.ChildWorkflow` pointers. Inside the loop, `ctx.SpawnWorkflow` is called to create a child workflow for each page. It then collects the results of each child workflow and assigns them to a slice of `childOutput` structs.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/child-workflows.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nfunc(ctx worker.HatchetContext) error {\n    input := &parentInput{}\n    err = ctx.WorkflowInput(input)\n\n    if err != nil {\n        return nil, err\n    }\n\n    childWorkflows := make([]*worker.ChildWorkflow, input.pages)\n\n    for i := 0; i < input.pages; i++ {\n        childInput := &childInput{\n            Index: i,\n        }\n\n        childWorkflow, err := ctx.SpawnWorkflow(\"process-page\", childInput, &worker.SpawnWorkflowOpts{})\n\n        if err != nil {\n            return nil, err\n        }\n\n        childWorkflows[i] = childWorkflow\n    }\n\n    childOutputs := make([]childOutput, input.pages)\n\n    for i, childWorkflow := range childWorkflows {\n        childResult, _ = childWorkflow.Result()\n\n        childOutput := childOutput{}\n        childResult.StepOutput(\"step-one\", &childOutput)\n\n        childOutputs[i] = childOutput\n    }\n\n    return nil\n\n}\n```\n\n----------------------------------------\n\nTITLE: Check Worker Health\nDESCRIPTION: This command demonstrates how to check the health status of a Hatchet worker using `curl`. It sends a request to the `/health` endpoint, which is available when healthchecks are enabled. The endpoint returns a JSON response indicating the worker's status.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker-healthchecks.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl localhost:8001/health\n\n{\"status\": \"HEALTHY\"}\n```\n\n----------------------------------------\n\nTITLE: Defining CPU Compute Configurations with Hatchet in Python\nDESCRIPTION: This snippet demonstrates how to define CPU compute configurations using the `Compute` class from the Hatchet SDK. It shows examples for a default and a basic configuration, specifying CPU type, number of cores, memory allocation, number of instances, and deployment regions. These configurations can then be used in workflow step definitions. Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/managed-compute.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.compute import Compute\n\n# Define a default compute configuration\ndefault_compute = Compute(\n    cpu_kind=\"shared\",    # CPU type: \"shared\" or \"performance\"\n    cpus=2,              # Number of CPU cores\n    memory_mb=1024,      # Memory allocation in MB\n    num_replicas=2,      # Number of instances\n    regions=[\"ewr\"]      # Deployment regions\n)\n\n# Define a basic compute configuration\nbasic = Compute(\n    cpu_kind=\"shared\",\n    cpus=1,\n    memory_mb=1024,\n    num_replicas=1,\n    regions=[\"ewr\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Refreshing Step Timeout in Go\nDESCRIPTION: This snippet shows how to refresh the timeout for a running Hatchet step using Go. The `ctx.RefreshTimeout` method is called with the desired extension time, adding time to the step's execution time.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nworker.WorkflowJob{\n\t\tName: \"timeout\",\n\t\tDescription: \"timeout\",\n\t\tSteps: []*worker.WorkflowStep{\n\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\t\t\t\ttime.Sleep(time.Second * 20)\n\t\t\t\tctx.RefreshTimeout(\"15s\")\n        time.Sleep(time.Second * 10)\n        return return &stepOneOutput{\n\t\t\t\t\tMessage: \"step1 results!\",\n\t\t\t\t}, nil\n\t\t\t}).SetName(\"step-one\").SetTimeout(\"30s\"),\n    },\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Database Connection via Environment Variables in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure the database connection parameters for Hatchet using environment variables. It specifies the database URL, host, port, username, password, database name, and SSL mode.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsharedConfig:\n  env:\n    DATABASE_URL: \"postgres://<user>:<password>@<host>:5432/<db-name>?sslmode=disable\"\n    DATABASE_POSTGRES_HOST: \"<host>\"\n    DATABASE_POSTGRES_PORT: \"5432\"\n    DATABASE_POSTGRES_USERNAME: \"<user>\"\n    DATABASE_POSTGRES_PASSWORD: \"<password>\"\n    DATABASE_POSTGRES_DB_NAME: \"<db-name>\"\n    DATABASE_POSTGRES_SSL_MODE: \"disable\"\n```\n\n----------------------------------------\n\nTITLE: Dockerizing with npm\nDESCRIPTION: This Dockerfile demonstrates how to build and run a Hatchet TypeScript application using npm. It uses a multi-stage build process to create an optimized production image. The first stage builds the application, and the second stage copies the built assets and installs only production dependencies.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_0\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\n# Copy package files\n\nCOPY package*.json ./\n\n# Install dependencies\n\nRUN npm ci\n\n# Copy source code\n\nCOPY . .\n\n# Build TypeScript\n\nRUN npm run build\n\n# Stage 2: Production\n\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files\n\nCOPY package*.json ./\n\n# Install production dependencies only\n\nRUN npm ci --omit=dev\n\n# Copy built assets from builder\n\nCOPY --from=builder /app/dist ./dist\n\n# Set production environment\n\nENV NODE_ENV=production\n\n# Start the worker\n\nCMD [\"node\", \"dist/worker.js\"]\n\n```\n\n----------------------------------------\n\nTITLE: Querying the continuous aggregate\nDESCRIPTION: This SQL query retrieves aggregated metrics from the `metric_events_summary` view. It groups the data into one-hour buckets and sums the `succeeded_count` and `failed_count` for a specific tenant and resource within a 24-hour time window. Requires the `metric_events_summary` view to be defined.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\nSELECT\n    time_bucket('1 hour', minute) as bucket,\n    SUM(succeeded_count)::int as succeeded_count,\n    SUM(failed_count)::int as failed_count\nFROM\n    metric_events_summary\nWHERE\n    tenant_id = '95e0aaaf-5f81-4b80-b5f4-5e398749ef7c' AND\n    resource_id = '35fde363-065d-457d-bdf8-43f7ac107817' AND\n    minute > NOW() AND\n    minute < NOW() + INTERVAL '24 hours'\nGROUP BY bucket\nORDER BY bucket;\n```\n\n----------------------------------------\n\nTITLE: Creating Tabbed Interface using UniversalTabs\nDESCRIPTION: This snippet creates a tabbed interface using the 'UniversalTabs' component.  It defines three tabs: Python, Typescript, and Go, each displaying the content from the corresponding imported Markdown file. The 'Tabs.Tab' component is likely provided by Nextra.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/new.mdx#_snippet_2\n\nLANGUAGE: JSX\nCODE:\n```\n<UniversalTabs items={[\"Python\", \"Typescript\", \"Go\"]}>\n  <Tabs.Tab title=\"Python\">\n    <Python />\n  </Tabs.Tab>\n  <Tabs.Tab title=\"Typescript\">\n    <Typescript />\n  </Tabs.Tab>\n  <Tabs.Tab title=\"Go\">\n    <Go />\n  </Tabs.Tab>\n</UniversalTabs>\n```\n\n----------------------------------------\n\nTITLE: Defining a simple Hatchet workflow in Typescript\nDESCRIPTION: This Typescript code defines a basic Hatchet workflow with one step. It uses the `@hatchet-dev/typescript-sdk` to define the workflow and registers it with a worker. Dependencies: @hatchet-dev/typescript-sdk, dotenv.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"first-typescript-workflow\",\n  description: \"This is my first workflow\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n\n        return {\n          result: \"success!\",\n        };\n      },\n    },\n  ],\n};\n\nconst worker = hatchet.worker(\"my-worker\");\nawait worker.registerWorkflow(workflow);\nworker.start();\n```\n\n----------------------------------------\n\nTITLE: Installing Typescript Dependencies\nDESCRIPTION: Installs the required Typescript packages for the Hatchet worker: `@hatchet-dev/typescript-sdk` and `dotenv`. The `dotenv` package is used to load environment variables from a `.env` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nnpm i @hatchet-dev/typescript-sdk\nnpm i dotenv\n```\n\n----------------------------------------\n\nTITLE: Define and Register Hatchet Workflow in Typescript\nDESCRIPTION: Defines a simple Hatchet workflow with one step using the Typescript SDK. The workflow listens for the 'user:create' event and logs a message to the console in its step. The `Hatchet.init()` function initializes the Hatchet client and creates a worker. The worker then registers the workflow and starts listening for events.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"first-typescript-workflow\",\n  description: \"This is my first workflow\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n\n        return {\n          result: \"success!\",\n        };\n      },\n    },\n  ],\n};\n\nconst worker = hatchet.worker(\"my-worker\");\nawait worker.registerWorkflow(workflow);\nworker.start();\n```\n\n----------------------------------------\n\nTITLE: Listening for Workflow Events (Go)\nDESCRIPTION: This code snippet demonstrates how to listen for events from a Hatchet workflow in Go. It starts a workflow, then subscribes to the event stream using the `c.Subscribe().Stream` method. The code includes error handling for both running the workflow and subscribing to the stream.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nworkflowRunId, err := c.Admin().RunWorkflow(\"stream-event-workflow\", &streamEventInput{\n  Index: 0,\n})\n\nif err != nil {\npanic(err)\n}\n\nerr = c.Subscribe().Stream(interruptCtx, workflowRunId, func(event client.StreamEvent) error {\nfmt.Println(string(event.Message))\n\nreturn nil\n})\n\nif err != nil {\npanic(err)\n}\n\n```\n\n----------------------------------------\n\nTITLE: Event Stream Generator Function in Python\nDESCRIPTION: This function subscribes to the Hatchet event stream for a specific workflow run ID and yields events. It allows filtering and transformation of event data before sending it to the client. It filters for 'step_completed' events, serializes the data into JSON, and formats it for streaming.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/result-streaming.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef event_stream_generator(workflowRunId):\n    ''' This helper function is a generator that yields events from the Hatchet event stream. '''\n    stream = hatchet.client.listener.stream(workflowRunId)\n    for event in stream:\n        ''' you can filter and transform event data here that will be sent to the client'''\n        if event.type == \"step_completed\":\n            data = json.dumps({\n                \"type\": event.type,\n                \"payload\": event.payload,\n                \"messageId\": workflowRunId\n            })\n            yield \"data: \" + data + \"\\n\\n\"\n```\n\n----------------------------------------\n\nTITLE: Instantiate Hatchet Client Factory - Go\nDESCRIPTION: This Go code defines a package `hatchet` and a function `Client` that instantiates a new Hatchet client using the `github.com/hatchet-dev/hatchet/pkg/client` package. It returns the client and any error that occurred during instantiation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_4\n\nLANGUAGE: go\nCODE:\n```\npackage hatchet\n\nimport (\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n)\n\nfunc Client() (client.Client, error) {\n\treturn client.New()\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with Key Function (Python)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Python using a key function to define the concurrency group. It sets the maximum number of concurrent runs to 10 and uses the `context.workflow_input()` to get the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom hatchet_sdk import ConcurrencyLimitStrategy\n\n@hatchet.workflow(on_events=[\"concurrency-test\"])\nclass ConcurrencyDemoWorkflow:\n    @hatchet.concurrency(max_runs=10, limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN)\n    def concurrency(self, context) -> str:\n        return context.workflow_input()[\"user_id\"]\n\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Starting the FastAPI Server with Poetry and Uvicorn in Shell\nDESCRIPTION: This command starts the FastAPI server using Uvicorn, as configured by the poetry script.  Uvicorn is an ASGI server implementation, used to run the FastAPI application.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/api-server-setup.mdx#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\npoetry run api\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows with Hatchet in TypeScript\nDESCRIPTION: This code snippet demonstrates how to define a parent workflow that spawns multiple child workflows using the `ctx.spawnWorkflow` method. It iterates five times, spawning a \"child-workflow\" with different input values and collects the results of each child workflow run into an array.  The promises are awaited using `Promise.all` to ensure all child workflows have completed before proceeding. The results from the child workflows are then returned.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-child.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst parentWorkflow: Workflow = {\n  id: \"parent-workflow\",\n  description: \"Example workflow for spawning child workflows\",\n  on: {\n    event: \"fanout:create\",\n  },\n  steps: [\n    {\n      name: \"parent-spawn\",\n      timeout: \"10s\",\n      run: async (ctx) => {\n        const promises: Promise<string>[] = [];\n\n        for (let i = 0; i < 5; i++) {\n          promises.push(\n            ctx\n              .spawnWorkflow(\"child-workflow\", {\n                input: `child-input-${i}`,\n              })\n              .result(),\n          );\n        }\n\n        const results = await Promise.all(promises);\n\n        return {\n          results,\n        };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Bash Script for Applying Atlas Migrations\nDESCRIPTION: This bash script automates the process of applying database migrations using Atlas. It checks if a Prisma migration already exists, and if so, uses it as a baseline for Atlas. Otherwise, it applies all migrations from the specified directory. It uses the `DATABASE_URL` environment variable for database connection details. This addresses `CREATE INDEX CONCURRENTLY` issues.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nMIGRATION_NAME=$(psql \"$DATABASE_URL\" -t -c \"SELECT migration_name FROM _prisma_migrations ORDER BY started_at DESC LIMIT 1;\" 2>/dev/null | xargs)\nMIGRATION_NAME=$(echo $MIGRATION_NAME | cut -d'_' -f1)\n\necho \"Migration name: $MIGRATION_NAME\"\n\nif [ $? -eq 0 ] && [ -n \"$MIGRATION_NAME\" ]; then\n  echo \"Using existing prisma migration: $MIGRATION_NAME\"\n\n  atlas migrate apply \\\n    --url \"$DATABASE_URL\" \\\n    --baseline \"$MIGRATION_NAME\" \\\n    --dir \"file://sql/migrations\"\nelse\n  echo \"No prisma migration found. Applying migrations via atlas...\"\n\n  atlas migrate apply \\\n    --url \"$DATABASE_URL\" \\\n    --dir \"file://sql/migrations\"\nfi\n```\n\n----------------------------------------\n\nTITLE: Prometheus Configuration\nDESCRIPTION: This YAML configuration snippet demonstrates how to configure Prometheus to scrape metrics from a Hatchet worker. It defines a job named \"hatchet\" that scrapes the `/metrics` endpoint at a specified interval. The `targets` parameter specifies the address of the Hatchet worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker-healthchecks.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nscrape_configs:\n  - job_name: \"hatchet\"\n    scrape_interval: 5s\n    static_configs:\n      - targets: [\"localhost:8001\"]\n```\n\n----------------------------------------\n\nTITLE: Specifying Step Desired Labels - Go\nDESCRIPTION: This code snippet shows how to specify desired worker label state for a Hatchet step in Go. The `SetDesiredLabels` method is used to specify the desired label values, comparators, and weights. The step requires a worker with `memory` greater than 512 and prioritizes workers with `model` equal to \"fancy-ai-model-v2\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:          worker.Events(\"user:create:affinity\"),\n\t\t\tName:        \"affinity\",\n\t\t\tDescription: \"affinity\",\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\t\t\t\t\treturn &stepOneOutput{\n\t\t\t\t\t\tMessage: ctx.Worker().ID(),\n\t\t\t\t\t}, nil\n\t\t\t\t}).\n\t\t\t\t\tSetName(\"step-one\").\n\t\t\t\t\tSetDesiredLabels(map[string]*types.DesiredWorkerLabel{\n\t\t\t\t\t\t\"model\": {\n\t\t\t\t\t\t\tValue:  \"fancy-ai-model-v2\",\n\t\t\t\t\t\t\tWeight: 10,\n\t\t\t\t\t\t},\n\t\t\t\t\t\t\"memory\": {\n\t\t\t\t\t\t\tValue:      512,\n\t\t\t\t\t\t\tRequired:   true,\n\t\t\t\t\t\t\tComparator: types.ComparatorPtr(types.WorkerLabelComparator_GREATER_THAN),\n\t\t\t\t\t\t},\n\t\t\t\t\t}),\n\t\t\t},\n\t\t},\n\t)\n```\n\n----------------------------------------\n\nTITLE: Start Database and Queue Services (Shell)\nDESCRIPTION: This shell command starts the necessary database and queue services required for the Hatchet development environment. It's a prerequisite for setting up and running the application locally.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ntask start-db\n```\n\n----------------------------------------\n\nTITLE: Defining APIMetaAuth Interface\nDESCRIPTION: This TypeScript code defines the APIMetaAuth interface, specifying the structure for authentication metadata.  It includes an optional property 'schemes' which is an array of strings representing supported authentication types (e.g., \"basic\", \"google\").  The interface is used to represent authentication configurations within the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIMetaAuth.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * the supported types of authentication\n *\n * @Example\n * ```ts\n * [\"basic\",\"google\"]\n * ```\n */\nschemes?: string[]\n```\n\n----------------------------------------\n\nTITLE: UserTenantPublic Email Property (TypeScript)\nDESCRIPTION: This snippet defines the 'email' property of the UserTenantPublic interface. The email is a required string and must adhere to the email format. This is part of the UserTenantPublic interface within the @hatchet-dev/typescript-sdk.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UserTenantPublic.md#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nemail: string\n```\n\n----------------------------------------\n\nTITLE: Set Additional Env Variables in Helm Chart (YAML)\nDESCRIPTION: This snippet shows how to set additional environment variables for Hatchet backend services using the `env` object within `sharedConfig` in the `values.yaml` file.  These variables will override any default settings.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-helm-configuration.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsharedConfig:\n  env:\n    MY_ENV_VAR: \"my-value\"\n```\n\n----------------------------------------\n\nTITLE: Defining EmptyModel with Pydantic\nDESCRIPTION: Defines a Pydantic model called `EmptyModel` that allows extra fields during validation. This is the default behavior when no `input_validator` is provided to a Hatchet workflow. It imports `BaseModel` and `ConfigDict` from `pydantic` and sets `extra=\"allow\"` in the `ConfigDict`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/pydantic.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom pydantic import BaseModel, ConfigDict\n\nclass EmptyModel(BaseModel):\n    model_config = ConfigDict(extra=\"allow\")\n```\n\n----------------------------------------\n\nTITLE: Caddy Configuration\nDESCRIPTION: This Caddyfile configures the reverse proxy for Hatchet, directing `/api/*` requests to the `hatchet-api` service and all other requests to the `hatchet-frontend` service. This setup allows accessing both the API and the frontend through a single port.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_1\n\nLANGUAGE: txt\nCODE:\n```\nhttp://localhost:8080 {\n\thandle /api/* {\n\t\treverse_proxy hatchet-api:8080\n\t}\n\n\thandle /* {\n\t\treverse_proxy hatchet-frontend:80\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Task Pointers in SQL\nDESCRIPTION: This SQL query updates the `task_addr_ptrs` table, adjusting the `max_assigned_block_addr` based on the highest completed task ID. It uses a CTE to identify the maximum task ID and then updates the `task_addr_ptrs` table accordingly.  The query guarantees only one row in `task_addr_ptrs` using a constraint, ensuring that only a single record is updated and returned.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n-- name: UpdateTaskPtrs :one\nWITH\n    max_assigned_id AS (\n        SELECT\n            id\n        FROM\n            tasks\n        WHERE\n            \"status\" != 'QUEUED'\n        ORDER BY id DESC\n        LIMIT 1\n    )\nUPDATE task_addr_ptrs\nSET\n    max_assigned_block_addr = COALESCE(\n        FLOOR((SELECT id FROM max_assigned_id)::decimal / 1024 / 1024),\n        COALESCE(\n            (SELECT MAX(block_addr) FROM task_groups),\n            0\n        )\n    )\nFROM\n    max_assigned_id\nRETURNING task_addr_ptrs.*;\n```\n\n----------------------------------------\n\nTITLE: Import Hatchet Client (Python)\nDESCRIPTION: Imports the Hatchet client instance from the `hatchet-client.py` file. This allows the client to be used in other parts of the application. It assumes that the client is created in `src/hatchet_client.py`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/py.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom src.hatchet_client import hatchet\n```\n\n----------------------------------------\n\nTITLE: Defining a Complex Workflow Hatchet Go\nDESCRIPTION: This snippet demonstrates how to define a complex, multi-task workflow using the `NewWorkflow` method on the `factory` package. It defines the workflow with two steps, where Step2 depends on Step1. It also shows how to access the output of a parent task using `ctx.ParentOutput`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-go.mdx#_snippet_3\n\nLANGUAGE: go\nCODE:\n```\nimport \"github.com/hatchet-dev/hatchet/pkg/v1/factory\"\n\n// ...\n\nsimple := factory.NewWorkflow[DagInput, DagResult](\n    create.WorkflowCreateOpts[DagInput]{\n        Name: \"simple-dag\",\n    },\n    hatchet,\n)\n\nstep1 := simple.Task(\n    create.WorkflowTask[DagInput, DagResult]{\n        Name: \"Step1\",\n    }, func(ctx worker.HatchetContext, input DagInput) (interface{}, error) {\n        return &SimpleOutput{\n            Step: 1,\n        }, nil\n    },\n)\n\nsimple.Task(\n    create.WorkflowTask[DagInput, DagResult]{\n        Name: \"Step2\",\n        Parents: []create.NamedTask{\n            step1,\n        },\n    }, func(ctx worker.HatchetContext, input DagInput) (interface{}, error) {\n        var step1Output SimpleOutput\n\n        err := ctx.ParentOutput(step1, &step1Output)\n        if err != nil {\n            return nil, err\n        }\n\n        return &SimpleOutput{\n            Step: 2,\n        }, nil\n    },\n)\n\nreturn simple\n```\n\n----------------------------------------\n\nTITLE: Get Workflow Runs List using Hatchet SDK in Python\nDESCRIPTION: This code shows how to retrieve a list of workflow runs for a tenant using the Hatchet SDK. It demonstrates the use of optional parameters such as offset, limit, event_id, and workflow_id to filter the results. The script configures the API client with authentication (API Key or Bearer Token), creates a WorkflowApi instance, and calls the workflow_run_list method, printing the API response. It depends on the hatchet_sdk.clients.rest library and requires setting up authentication via environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow_run_list import WorkflowRunList\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    tenant = 'tenant_example' # str | The tenant id\n    offset = 56 # int | The number to skip (optional)\n    limit = 56 # int | The number to limit by (optional)\n    event_id = 'event_id_example' # str | The event id to get runs for. (optional)\n    workflow_id = 'workflow_id_example' # str | The workflow id to get runs for. (optional)\n\n    try:\n        # Get workflow runs\n        api_response = api_instance.workflow_run_list(tenant, offset=offset, limit=limit, event_id=event_id, workflow_id=workflow_id)\n        print(\"The response of WorkflowApi->workflow_run_list:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_run_list: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Declaring a Task in Typescript\nDESCRIPTION: This snippet refers to an external file (src/v1/examples/simple/workflow.ts) to show how to declare a task using Typescript.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/your-first-task.mdx#_snippet_2\n\nLANGUAGE: Typescript\nCODE:\n```\nGithubSnippet src={SimpleTs} target=\"Declaring a Task\"\n```\n\n----------------------------------------\n\nTITLE: Open Hatchet via Glasskube CLI\nDESCRIPTION: This command opens the Hatchet service in a web browser using the Glasskube CLI. It directly opens the Hatchet UI after installation. Requires `glasskube` CLI.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nglasskube open hatchet\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using CEL Expression in Typescript\nDESCRIPTION: This TypeScript code snippet shows how to define a workflow with a concurrency limit using an expression. The `limitStrategy` is set to `ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS`. Requires the `Workflow` type to be defined and the `ConcurrencyLimitStrategy` enum to be available.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const concurrencyDemoWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"My workflow with concurrency control\",\n  on: {\n    event: \"concurrency-test\",\n  },\n  steps: [\n    // ...\n  ],\n  concurrency: {\n    name: \"my-workflow-concurrency\",\n    maxRuns: 10,\n    limitStrategy: ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS,\n    expression: \"input.group\",\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: createdAt Property Example\nDESCRIPTION: This example illustrates the format of the `createdAt` property within the APIResourceMeta interface.  It represents the creation timestamp of the resource as a date-time string. The string must conform to the ISO 8601 format.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIResourceMeta.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n\"2022-12-13T20:06:48.888Z\"\n```\n\n----------------------------------------\n\nTITLE: TenantMember.tenant Property\nDESCRIPTION: Defines the tenant property of the TenantMember interface. This property is of type Tenant, representing the tenant to which the member belongs. The property is optional.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantMember.md#_snippet_3\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * tenant: [`Tenant`](APIContracts.Tenant.md)\n *\n * The tenant associated with this tenant member.\n */\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Assignment (Python)\nDESCRIPTION: Defines Hatchet workflows with sticky assignment strategies in Python. One workflow prefers to run on the same worker (SOFT), while the other requires it (HARD).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n# create a workflow which prefers to run on the same worker, but can be\n# scheduled on any worker if the original worker is busy\nhatchet.workflow(\n  name=\"StickyWorkflow\",\n  sticky=StickyStrategy.SOFT,\n)\n\n# create a workflow which must run on the same worker\nhatchet.workflow(\n  name=\"StickyWorkflow\",\n  sticky=StickyStrategy.HARD,\n)\n```\n\n----------------------------------------\n\nTITLE: Running Hatchet Load Test in Docker\nDESCRIPTION: This command runs the Hatchet load test container with specified events per second, duration, log level, and slots.  It sets the HATCHET_CLIENT_TOKEN environment variable. Requires Docker and a valid Hatchet client token. The container emits events to the Hatchet engine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/benchmarking.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -e HATCHET_CLIENT_TOKEN=your-token ghcr.io/hatchet-dev/hatchet/hatchet-loadtest -e \"100\" -d \"60s\" --level \"warn\" --slots \"100\"\n```\n\n----------------------------------------\n\nTITLE: Defining Cron Scheduled Workflow with Hatchet (Python)\nDESCRIPTION: This code defines a Hatchet workflow named `MyWorkflow` that is scheduled to run every 5 minutes using the cron expression `*/5 * * * *`. The `on_crons` parameter within the `@hatchet.workflow` decorator specifies the cron schedule. The workflow consists of two steps: `step1` and `step2`, where `step2` depends on `step1`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-cron.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\n@hatchet.workflow(on_crons=[\"*/5 * * * *\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n\n    @hatchet.step(parents=[\"step1\"])\n    def step2(self, context):\n        print(\"executed step2\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event with Additional Metadata - Typescript\nDESCRIPTION: This snippet shows how to push an event to Hatchet with additional metadata using the Typescript client. It configures the 'source' metadata key with the value 'api'. The event is identified by the 'user:create' type and includes a 'test' property in the payload.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nhatchet.event.push(\n  'user:create',\n  {\n    test: 'test',\n  },\n  {\n    additionalMetadata: {\n      source: 'api', // Arbitrary key-value pair\n    },\n  }\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Step Timeout\nDESCRIPTION: This snippet shows how to set a timeout for a step using the `timeout` property in the step definition. The timeout is specified as a string, such as '1h', '1m', or '1s'. The example sets a timeout of 5 minutes for the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst stepWithTimeout: Step = {\n  name: \"step2\",\n  run: (ctx) => {\n    console.log(\"executed step2!\");\n    return { step2: \"step2\" };\n  },\n  timeout: \"5m\",\n};\n\n```\n\n----------------------------------------\n\nTITLE: Compute Configuration with Performance CPUs and Memory Scaling (Python)\nDESCRIPTION: This snippet demonstrates how to configure a `Compute` object with 'performance' CPU type, specifying the number of CPUs and memory allocation. It includes example memory calculation and validation. The `memory_mb` parameter must be between the minimum and maximum allowed memory for the specified CPU type.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\n# 4 performance CPUs\nmax_memory = 8192 * 4  # = 32768 MB (32GB)\nmin_memory = 2048 * 4  # = 8192 MB (8GB)\n\ncompute = Compute(\n    cpu_kind=\"performance\",\n    cpus=4,\n    memory_mb=16384,   # Must be between min_memory and max_memory\n    num_replicas=1,\n    regions=[\"ewr\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Defining a Custom Error Alerter Interface in Go\nDESCRIPTION: This code snippet shows the interface that a custom error alerter must implement. It defines a `SendAlert` method that takes a context, an error, and a map of data as input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/creating-a-worker.mdx#_snippet_3\n\nLANGUAGE: go\nCODE:\n```\ntype Alerter interface {\n\tSendAlert(ctx context.Context, err error, data map[string]interface{})\n}\n```\n\n----------------------------------------\n\nTITLE: Get Workflow Run using Hatchet SDK in Python\nDESCRIPTION: This snippet shows how to retrieve a specific workflow run by its ID for a given tenant using the Hatchet SDK. The code configures the API client, authenticates using either an API key or a Bearer token, creates an instance of the WorkflowApi, and calls the workflow_run_get method with the tenant and workflow run IDs. The result, if successful, is printed to the console.  It depends on the hatchet_sdk.clients.rest library and requires setting up authentication via environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow_run import WorkflowRun\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    tenant = 'tenant_example' # str | The tenant id\n    workflow_run = 'workflow_run_example' # str | The workflow run id\n\n    try:\n        # Get workflow run\n        api_response = api_instance.workflow_run_get(tenant, workflow_run)\n        print(\"The response of WorkflowApi->workflow_run_get:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_run_get: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using Key Function in Typescript\nDESCRIPTION: This TypeScript snippet uses a function `key` to determine the concurrency key, canceling in-progress workflows. The function extracts `userId` from the workflow input. Requires the `Workflow` type to be defined and the `ConcurrencyLimitStrategy` enum to be available.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport const concurrencyDemoWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"My workflow with concurrency control\",\n  on: {\n    event: \"concurrency-test\",\n  },\n  steps: [\n    // ...\n  ],\n  concurrency: {\n    name: \"my-workflow-concurrency\",\n    maxRuns: 10,\n    limitStrategy: ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS,\n    key: (ctx) => ctx.workflowInput().userId,\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Running a Task in Typescript\nDESCRIPTION: This snippet refers to an external file (src/v1/examples/simple/run.ts) to show how to run a task using Typescript.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/your-first-task.mdx#_snippet_3\n\nLANGUAGE: Typescript\nCODE:\n```\nGithubSnippet src={SimpleRunTs} target=\"Running a Task\"\n```\n\n----------------------------------------\n\nTITLE: Start Hatchet Dev Server (Shell)\nDESCRIPTION: This shell command starts the Hatchet engine, API server, dashboard, and Prisma studio, providing a complete development environment for building and testing Hatchet workflows.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ntask start-dev\n```\n\n----------------------------------------\n\nTITLE: Creating Task in SQL\nDESCRIPTION: This SQL query creates a new task by inserting into the `tasks` table and updating the `task_groups` table. It utilizes a Common Table Expression (CTE) to handle concurrent requests and assigns a unique ID to the task. The query takes 'group_key', 'created_at', and 'args' as input, using `sqlc.arg` for parameter binding and includes conflict resolution for existing `group_key` values.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nWITH\n    group_key_task AS (\n        INSERT INTO task_groups (\n            id,\n            group_key,\n            block_addr\n        ) VALUES (\n            COALESCE((SELECT max(id) FROM task_groups), -1) + 1,\n            sqlc.arg('group_key')::text,\n            (SELECT max_assigned_block_addr FROM task_addr_ptrs)\n        ) ON CONFLICT (group_key)\n        DO UPDATE SET\n            group_key = EXCLUDED.group_key,\n            block_addr = GREATEST(\n                task_groups.block_addr + 1,\n                (SELECT max_assigned_block_addr FROM task_addr_ptrs)\n            )\n        RETURNING id, group_key, block_addr\n    )\nINSERT INTO tasks (\n    id,\n    created_at,\n    status,\n    args,\n    group_key\n) VALUES (\n    (SELECT id FROM group_key_task) + 1024 * 1024 * (SELECT block_addr FROM group_key_task),\n    COALESCE(sqlc.arg('created_at')::timestamp, now()),\n    'QUEUED',\n    COALESCE(sqlc.arg('args')::jsonb, '{}'::jsonb),\n    sqlc.arg('group_key')::text\n)\nRETURNING *;\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Hatchet Load Test Containers in Docker\nDESCRIPTION: These commands run multiple Hatchet load test containers in parallel, each with a specific namespace to prevent workflow duplication. The commands set the HATCHET_CLIENT_TOKEN and HATCHET_CLIENT_NAMESPACE environment variables. Requires Docker and valid Hatchet client tokens.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/benchmarking.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# first container\ndocker run -e HATCHET_CLIENT_TOKEN=your-token -e HATCHET_CLIENT_NAMESPACE=loadtest1 ghcr.io/hatchet-dev/hatchet/hatchet-loadtest -e \"2000\" -d \"60s\" --level \"warn\" --slots \"100\"\n\n# second container\ndocker run -e HATCHET_CLIENT_TOKEN=your-token -e HATCHET_CLIENT_NAMESPACE=loadtest2 ghcr.io/hatchet-dev/hatchet/hatchet-loadtest -e \"2000\" -d \"60s\" --level \"warn\" --slots \"100\"\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Python\nDESCRIPTION: This snippet references an external Python file (`examples/scheduled/programatic-sync.py`) and targets the section \"List\". It aims to demonstrate how to list scheduled runs using the Hatchet SDK for Python, potentially utilizing the `SchedulePy` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={SchedulePy} target=\"List\" />\n```\n\n----------------------------------------\n\nTITLE: Defining file paths for code snippets\nDESCRIPTION: This snippet defines the file paths for two code snippets, one written in TypeScript and the other in Python. These paths are used to retrieve the code snippets for display or processing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/orchestration.mdx#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport const SimpleTs = {\n  path: \"src/v1/examples/simple/workflow.ts\",\n};\nexport const SimplePy = {\n  path: \"examples/simple/worker.py\",\n};\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Environment Variables in Helm Chart YAML\nDESCRIPTION: This YAML snippet shows how to set custom environment variables for backend services within the sharedConfig object in the Helm chart values.yaml file. The env object allows overriding default environment settings for the services.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-helm-configuration.mdx#_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\nsharedConfig:\n  env:\n    MY_ENV_VAR: \"my-value\"\n```\n\n----------------------------------------\n\nTITLE: UserTenantPublic Name Property (TypeScript)\nDESCRIPTION: This snippet defines the 'name' property of the UserTenantPublic interface. The name is an optional string representing the display name of the user. This is part of the UserTenantPublic interface within the @hatchet-dev/typescript-sdk.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UserTenantPublic.md#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\nname?: string\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event with Additional Metadata - Go\nDESCRIPTION: This snippet demonstrates how to push an event to Hatchet with additional metadata using the Go client. It sets the 'source' metadata key to 'api'. The event is identified by the 'user:create' type and includes a test event payload. It leverages the `WithEventMetadata` option.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nerr := c.Event().Push(\n    context.Background(),\n    \"user:create\",\n    testEvent,\n    client.WithEventMetadata(map[string]string{\n        \"source\": \"api\", // Arbitrary key-value pair\n    }),\n)\n```\n\n----------------------------------------\n\nTITLE: APIResourceMeta Model Usage\nDESCRIPTION: This Python snippet demonstrates how to use the APIResourceMeta model to create an instance from a JSON string, convert it to a dictionary, and back again. It uses the `from_json`, `to_json`, `to_dict`, and `from_dict` methods of the APIResourceMeta class. Requires `hatchet_sdk.clients.rest.models.api_resource_meta`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIResourceMeta.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_resource_meta import APIResourceMeta\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIResourceMeta from a JSON string\napi_resource_meta_instance = APIResourceMeta.from_json(json)\n# print the JSON string representation of the object\nprint APIResourceMeta.to_json()\n\n# convert the object into a dict\napi_resource_meta_dict = api_resource_meta_instance.to_dict()\n# create an instance of APIResourceMeta from a dict\napi_resource_meta_form_dict = api_resource_meta.from_dict(api_resource_meta_dict)\n```\n\n----------------------------------------\n\nTITLE: Inline Wrapping with sync_to_async in Python\nDESCRIPTION: This snippet shows how to use `sync_to_async` as an inline wrapper around a blocking function.  This is useful for wrapping external library calls directly within an async function. It showcases how a synchronous function is invoked within an async function using `await sync_to_async(blocking_function)()`. It requires the `hatchet_sdk` and `Context`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/asyncio.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef blocking_function():\n    time.sleep(5)\n    return {\"type\": \"sync_blocking\"}\n\n\n@hatchet.function()\nasync def my_func(context: Context) -> dict:\n    data = await sync_to_async(blocking_function)()\n    return {\n        \"status\": \"success\",\n        \"data\": data,\n    }\n```\n\n----------------------------------------\n\nTITLE: AcceptInviteRequest Interface Definition (TypeScript)\nDESCRIPTION: Defines the `AcceptInviteRequest` interface with a single property `invite` of type string.  The invite string must be a UUID with a minimum and maximum length of 36 characters.  This interface is used when accepting an invitation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.AcceptInviteRequest.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * Interface: AcceptInviteRequest\n */\n\n/**\n * @module APIContracts\n */\n\n/**\n * @property invite\n * @type {string}\n * @minLength 36\n * @maxLength 36\n * @example \"bb214807-246e-43a5-a25d-41761d1cff9e\"\n */\n\ninterface AcceptInviteRequest {\n invite: string\n}\n\n```\n\n----------------------------------------\n\nTITLE: Defining TriggerWorkflowRunRequest Interface\nDESCRIPTION: This code snippet defines the `TriggerWorkflowRunRequest` interface, which is used to specify the structure for triggering a workflow run. It includes a single property, `input`, which is an object that represents the input data for the workflow.  The interface is defined in the `data-contracts.ts` file within the generated REST client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TriggerWorkflowRunRequest.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: TriggerWorkflowRunRequest\n *\n * [APIContracts](../modules/APIContracts.md).TriggerWorkflowRunRequest\n */\n\n/**\n * Properties\n */\n\n/**\n * input\n */\n\n/** **input**: `object` */\n```\n\n----------------------------------------\n\nTITLE: Pushing Internal Events - Typescript\nDESCRIPTION: Demonstrates how to push an internal event from within a Typescript application using the Hatchet SDK. The `hatchet.event.push` method is used to push the event with a specified name and payload. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nhatchet.event.push(\"user:create\", {\n  test: \"test\",\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Shared Settings in Helm Chart YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure shared settings for Hatchet backend services using the sharedConfig object in the values.yaml file for Helm charts. It includes common configurations like server URL, authentication cookie settings, gRPC address, default admin credentials, and a way to set additional environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-helm-configuration.mdx#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nsharedConfig:\n  # you can disable shared config by setting this to false\n  enabled: true\n\n  # these are the most commonly configured values\n  serverUrl: \"http://localhost:8080\"\n  serverAuthCookieDomain: \"localhost:8080\" # the domain for the auth cookie\n  serverAuthCookieInsecure: \"t\" # allows cookies to be set over http\n  serverAuthSetEmailVerified: \"t\" # automatically sets email_verified to true for all users\n  serverAuthBasicAuthEnabled: \"t\" # allows login via basic auth (email/password)\n  grpcBroadcastAddress: \"localhost:7070\" # the endpoint for the gRPC server, exposed via the `grpc` service\n  grpcInsecure: \"true\" # allows gRPC to be served over http\n  defaultAdminEmail: \"admin@example.com\" # in exposed/production environments, change this to a valid email\n  defaultAdminPassword: \"Admin123!!\" # in exposed/production environments, change this to a secure password\n\n  # you can set additional environment variables here, which will override any defaults\n  env: {}\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client with Config Override - TypeScript\nDESCRIPTION: This snippet shows how to initialize a Hatchet client by overriding the default configuration with a `ClientConfig` object. It explicitly sets the token and namespace for the client using the `Hatchet.init()` method. The `typescript-sdk` is a required dependency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/client.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init({\n  token: \"my-token\",\n  namespace: \"my-namespace\",\n});\n```\n\n----------------------------------------\n\nTITLE: Streaming Context Data - Python\nDESCRIPTION: This Python snippet demonstrates how to stream data from a Hatchet workflow step's context.  The `context.put_stream` method is used to send arbitrary data (up to ~4mb) from within the step's execution. This allows real-time updates from the background worker to be sent to the frontend.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/rate-limits.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step()\ndef step1(self, context: Context):\n    # Stream some data from the step context\n    context.put_stream('hello from step1') # <-- any arbitrary data under ~4mb!\n    # continue with the step run...\n    return {\"step1\": \"results\"}\n```\n\n----------------------------------------\n\nTITLE: Using Hatchet Feature Clients (Go)\nDESCRIPTION: This code snippet demonstrates using the feature clients exposed on the Hatchet client in Go. It shows how to list workflow runs with a specified status (FAILED), replay runs by their IDs using `hatchet.Runs().Replay`, and cancel runs based on filters such as a time since and additional metadata using `hatchet.Runs().Cancel`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/v1-sdk-improvements.mdx#_snippet_7\n\nLANGUAGE: go\nCODE:\n```\nhatchet, err := v1.NewHatchetClient()\n\nif err != nil {\n    panic(err)\n}\n\nctx := context.Background()\nruns, err := hatchet.Runs().List(ctx, rest.V1WorkflowRunListParams{\n    Statuses: &[]rest.V1TaskStatus{rest.V1TaskStatusFAILED},\n})\n\nif err != nil {\n    panic(err)\n}\n\nreplayIds := []types.UUID{}\nfor _, run := range runs.JSON200.Rows {\n    replayIds = append(replayIds, uuid.MustParse(run.Metadata.Id))\n}\n\n// Replay the runs\nhatchet.Runs().Replay(ctx, rest.V1ReplayTaskRequest{\n    ExternalIds: &replayIds,\n})\n\n// Or run bulk operations with filters directly\nhatchet.Runs().Cancel(ctx, rest.V1CancelTaskRequest{\n    Filter: &rest.V1TaskFilter{\n        Since:              time.Now().Add(-time.Hour * 24),\n        AdditionalMetadata: &[]string{\"user:123\"},\n    },\n})\n```\n\n----------------------------------------\n\nTITLE: Defining a Workflow with Logging in TypeScript\nDESCRIPTION: This code snippet defines a Hatchet workflow named 'logger-example' with a single step. Within the step's `run` function, the `ctx.log` method is used to log 1000 messages.  The `ctx` object provides access to Hatchet's context, including the logging functionality. The workflow is triggered by the 'user:create' event. A key limitation is that each step is limited to 1000 log lines.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/logging.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  id: \"logger-example\",\n  description: \"test\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"logger-step1\",\n      run: async (ctx) => {\n        for (let i = 0; i < 1000; i++) {\n          ctx.log(`log message ${i}`);\n        }\n\n        return { step1: \"completed step run\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Creating .env file for Hatchet examples with shell redirection\nDESCRIPTION: This snippet uses shell redirection to create a `.env` file for a Hatchet example. It sets environment variables related to Hatchet client configuration, including the tenant ID, TLS root CA file, server name, and a token obtained from the `get_token` alias.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ncat > ./examples/simple/.env <<EOF\nHATCHET_CLIENT_TENANT_ID=707d0855-80ab-4e1f-a156-f1c4546cbf52\nHATCHET_CLIENT_TLS_ROOT_CA_FILE=../../hack/dev/certs/ca.cert\nHATCHET_CLIENT_TLS_SERVER_NAME=cluster\nHATCHET_CLIENT_TOKEN=\"$(get_token)\"\nEOF\n```\n\n----------------------------------------\n\nTITLE: Initializing GPU Compute Config with Hatchet\nDESCRIPTION: This code snippet shows how to initialize a `Compute` object with specific GPU configurations for Hatchet. It defines the GPU type (`gpu_kind`), the number of GPUs (`gpus`), memory allocation (`memory_mb`), number of replicas (`num_replicas`), and the regions where the compute resources will be provisioned (`regions`). This configuration specifies the resources needed to execute a particular task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.compute.configs import Compute\n\ncompute = Compute(\n    gpu_kind=\"a100-80gb\",    # GPU type\n    gpus=1,                  # Number of GPUs\n    memory_mb=163840,        # Memory in MB\n    num_replicas=1,          # Number of instances\n    regions=[\"ams\"]          # Must be a region that supports your chosen GPU\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow State in Typescript Step\nDESCRIPTION: This Typescript code demonstrates how to access workflow state within a step using the `ctx` object. It shows how to access workflow input using `ctx.workflowInput()` and the output of a previous step using `ctx.stepOutput(\"previous_step\")`. The `parents` array defines the dependency on `previous_step`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workflows.mdx#_snippet_3\n\nLANGUAGE: Typescript\nCODE:\n```\nconst workflow: Workflow = {\n  // ... rest of workflow definition\n  steps: [\n    // ... other steps\n    {\n      name: 'my_step',\n      parents=[\"previous_step\"]\n      run: async (ctx) => {\n        const data = ctx.workflowInput();\n        const previousStepData = ctx.stepOutput(\"previous_step\");\n        // Perform some operation\n        return output\n      },\n    },\n    // ... other steps\n  ]\n};\n\n```\n\n----------------------------------------\n\nTITLE: Importing Language-Specific Markdown Files\nDESCRIPTION: This snippet imports Markdown files containing content for Python, Typescript, and Go. These files will be displayed within the tabs.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/new.mdx#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport Python from \"./_new/py.mdx\";\nimport Typescript from \"./_new/ts.mdx\";\nimport Go from \"./_new/go.mdx\";\n```\n\n----------------------------------------\n\nTITLE: Converting APIMetaIntegration to/from Dictionary\nDESCRIPTION: This snippet shows how to convert an APIMetaIntegration object to a Python dictionary using the `to_dict` method, and vice versa using the `from_dict` method. This allows for easier manipulation of the object's data. The dictionary representation can be useful for serialization and data transfer.  The `hatchet_sdk.clients.rest.models.api_meta_integration` module is required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIMetaIntegration.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# convert the object into a dict\napi_meta_integration_dict = api_meta_integration_instance.to_dict()\n# create an instance of APIMetaIntegration from a dict\napi_meta_integration_form_dict = api_meta_integration.from_dict(api_meta_integration_dict)\n```\n\n----------------------------------------\n\nTITLE: Hatchet Client Token Environment Variable Setup\nDESCRIPTION: This shell script shows the format of the Hatchet client token environment variable, which is required for authenticating with the Hatchet instance. The actual token value should replace `<token>`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nHATCHET_CLIENT_TOKEN=\"<token>\"\n```\n\n----------------------------------------\n\nTITLE: Setting Scheduled Priority - Python\nDESCRIPTION: This snippet shows how to set the priority of a Hatchet run that is triggered via a scheduler, using Python. This enables scheduled workflows to run with a defined priority.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/priority.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nexamples/priority/trigger.py\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration (Existing Postgres)\nDESCRIPTION: This Docker Compose configuration defines the Hatchet Lite service, assuming an existing Postgres database is available. It sets environment variables, ports, and volumes for Hatchet Lite, connecting it to the existing database and RabbitMQ. This configuration requires an existing Postgres instance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/hatchet-lite.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nname: hatchet-lite\nservices:\n  hatchet-lite:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-lite:latest\n    ports:\n      - \"8888:8888\"\n      - \"7077:7077\"\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n      DATABASE_URL: \"postgresql://hatchet:hatchet@postgres:5432/hatchet?sslmode=disable\"\n      DATABASE_POSTGRES_PORT: \"5432\"\n      DATABASE_POSTGRES_HOST: \"postgres\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@localhost:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n      SERVER_GRPC_PORT: \"7077\"\n      SERVER_URL: http://localhost:8888\n      SERVER_AUTH_SET_EMAIL_VERIFIED: \"t\"\n      SERVER_DEFAULT_ENGINE_VERSION: \"V1\"\n    volumes:\n      - \"hatchet_lite_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_lite_config:/config\"\n\nvolumes:\n  hatchet_lite_rabbitmq_data:\n  hatchet_lite_config:\n```\n\n----------------------------------------\n\nTITLE: Fair Queueing with PARTITION BY (Attempt 1) in Postgres\nDESCRIPTION: This SQL query attempts to implement fair queueing using the `PARTITION BY` clause. It assigns a row number to each task within its group and then orders the tasks by row number. However, this query results in an error because `FOR UPDATE` is not allowed with window functions.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_4\n\nLANGUAGE: sql\nCODE:\n```\nWITH\n    eligible_tasks AS (\n        SELECT\n            t.id,\n            t.\"status\",\n            t.\"group_key\",\n            row_number() OVER (PARTITION BY t.\"group_key\" ORDER BY t.\"id\" ASC) AS rn\n        FROM\n            tasks t\n        WHERE\n            \"status\" = 'QUEUED'\n        ORDER BY rn, t.id ASC\n        LIMIT\n            COALESCE(sqlc.narg('limit'), 10)\n        FOR UPDATE SKIP LOCKED\n    )\nUPDATE tasks\nSET\n    \"status\" = 'RUNNING'\nFROM\n    eligible_tasks\nWHERE\n    tasks.id = eligible_tasks.id AND\n    tasks.\"status\" = 'QUEUED'\nRETURNING tasks.*;\n```\n\n----------------------------------------\n\nTITLE: Dockerizing with pnpm\nDESCRIPTION: This Dockerfile builds and runs a Hatchet TypeScript application using pnpm. It utilizes a multi-stage build, installing pnpm globally and employing `--frozen-lockfile` for reliable dependency management. The production stage copies built assets and installs only production dependencies.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\n# Install pnpm\nRUN npm install -g pnpm\n\n# Copy package files\nCOPY pnpm-lock.yaml package.json ./\n\n# Install dependencies\nRUN pnpm install --frozen-lockfile\n\n# Copy source code\nCOPY . .\n\n# Build TypeScript\nRUN pnpm build\n\n# Stage 2: Production\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Install pnpm\nRUN npm install -g pnpm\n\n# Copy package files\nCOPY pnpm-lock.yaml package.json ./\n\n# Install production dependencies only\nRUN pnpm install --frozen-lockfile --prod\n\n# Copy built assets from builder\nCOPY --from=builder /app/dist ./dist\n\n# Set production environment\nENV NODE_ENV=production\n\n# Start the worker\nCMD [\"node\", \"dist/worker.js\"]\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using Key Function in Python\nDESCRIPTION: This Python snippet uses a function to determine the concurrency key, canceling in-progress workflows. Requires `hatchet_sdk`. The function `concurrency` extracts the `user_id` from the workflow input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import ConcurrencyLimitStrategy\n\n@hatchet.workflow(on_events=[\"concurrency-test\"])\nclass ConcurrencyDemoWorkflow:\n    @hatchet.concurrency(max_runs=10, limit_strategy=ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS)\n    def concurrency(self, context) -> str:\n        return context.workflow_input()[\"user_id\"]\n\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Rendering the React UI with Messages and Status\nDESCRIPTION: This code renders the React UI, displaying the messages exchanged between the user and assistant. It dynamically creates links to the Hatchet dashboard for each workflow run via messageId, and displays the current status of an ongoing workflow run.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nreturn (\n  <div className=\"App\">\n    <div className=\"Messages\">\n      {messages.map(({ role, content, messageId }, i) => (\n        <p key={i}>\n          <b>{role === \"assistant\" ? \"Agent\" : \"You\"}</b>: {content}\n          {messageId && (\n            <a\n              target=\"_blank\"\n              rel=\"noreferrer\"\n              href={`http://localhost:8080/workflow-runs/${messageId}`}\n            >\n              🪓\n            </a>\n          )}\n        </p>\n      ))}\n\n      {openRequest && (\n        <a\n          target=\"_blank\"\n          rel=\"noreferrer\"\n          href={`http://localhost:8080/workflow-runs/${openRequest}`}\n        >\n          {status}\n        </a>\n      )}\n    </div>\n\n    <div className=\"Input\">\n      <textarea\n        value={message}\n        onChange={(e) => setMessage(e.target.value)}\n      ></textarea>\n      <button onClick={() => sendMessage(message)}>Ask</button>\n    </div>\n  </div>\n);\n```\n\n----------------------------------------\n\nTITLE: Example .dockerignore File\nDESCRIPTION: This `.dockerignore` file excludes unnecessary files and directories from the Docker build context, such as `node_modules`, debug logs, git directories, environment files, and the `dist` and `coverage` directories. This results in smaller image sizes and faster build times.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_6\n\nLANGUAGE: N/A\nCODE:\n```\nnode_modules\nnpm-debug.log\nyarn-debug.log\nyarn-error.log\n.git\n.gitignore\n.env\ndist\ncoverage\n```\n\n----------------------------------------\n\nTITLE: Creating Scheduled Runs - Python (Async)\nDESCRIPTION: This snippet demonstrates how to create a scheduled run programmatically using the Python (Asynchronous) Hatchet SDK.  It defines the schedule and triggers a workflow at a specific time. Requires initialized and configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-async.py - Create\n```\n\n----------------------------------------\n\nTITLE: Set Server Encryption CloudKMS Key URI (Shell)\nDESCRIPTION: This command sets the environment variable for the server encryption CloudKMS key URI. Replace `<PROJECT>` with your GCP project ID to configure the KMS key for encryption.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\nSERVER_ENCRYPTION_CLOUDKMS_KEY_URI=gcp-kms://projects/<PROJECT>/locations/global/keyRings/development/cryptoKeys/development\n```\n\n----------------------------------------\n\nTITLE: Creating Child Logger in Workflow (Python)\nDESCRIPTION: Illustrates how to create a child logger within a workflow file to maintain a hierarchical logging structure. This is useful when workflows are organized into separate files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n<GithubSnippet src={LoggerWorkflowPy} target=\"LoggingWorkflow\" />\n```\n\n----------------------------------------\n\nTITLE: Generating .env File\nDESCRIPTION: This bash script generates a `.env` file with the `HATCHET_CLIENT_TOKEN` and `HATCHET_CLIENT_TLS_STRATEGY` variables. It uses `docker compose run` to execute the `hatchet-admin token create` command and extracts the token value.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ncat <<EOF > .env\nHATCHET_CLIENT_TOKEN=\"$(docker compose run --no-deps setup-config /hatchet/hatchet-admin token create --config /hatchet/config --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52 | xargs)\"\nHATCHET_CLIENT_TLS_STRATEGY=none\nEOF\n```\n\n----------------------------------------\n\nTITLE: Hatchet Load Test Command Line Flags\nDESCRIPTION: These are the command-line flags available for the Hatchet load test container, including concurrency, delay, duration, eventFanout, events per second, failureRate, log level, payloadSize, slots, wait, and workerDelay. These flags configure the event emission and worker behavior of the load test tool.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/benchmarking.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nUsage:\n  loadtest [flags]\n\nFlags:\n  -c, --concurrency int        concurrency specifies the maximum events to run at the same time\n  -D, --delay duration         delay specifies the time to wait in each event to simulate slow tasks\n  -d, --duration duration      duration specifies the total time to run the load test (default 10s)\n  -F, --eventFanout int        eventFanout specifies the number of events to fanout (default 1)\n  -e, --events int             events per second (default 10)\n  -f, --failureRate float32    failureRate specifies the rate of failure for the worker\n  -h, --help                   help for loadtest\n  -l, --level string           logLevel specifies the log level (debug, info, warn, error) (default \"info\")\n  -P, --payloadSize string     payload specifies the size of the payload to send (default \"0kb\")\n  -s, --slots int              slots specifies the number of slots to use in the worker\n  -w, --wait duration          wait specifies the total time to wait until events complete (default 10s)\n  -p, --workerDelay duration   workerDelay specifies the time to wait before starting the worker\n```\n\n----------------------------------------\n\nTITLE: Deleting Cron Trigger - Python (Sync)\nDESCRIPTION: Deletes a cron trigger using the Hatchet SDK in Python (synchronous), either by passing the cron object or the cron trigger ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-sync.py\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Workflow with Hatchet in Go\nDESCRIPTION: This code snippet demonstrates how to schedule a workflow to run at a specific time using the Hatchet Go client. It initializes a Hatchet client, then calls the `Admin().ScheduleWorkflow` method, providing the workflow name, schedule, and optional input data. The input data includes the scheduled and execution times.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/scheduling-workflows.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nerr = c.Admin().ScheduleWorkflow(\n\t\"scheduled-workflow\",\n\tclient.WithSchedules(executeAt),\n  // optional input\n\tclient.WithInput(&scheduledInput{\n\t\tScheduledAt: time.Now(),\n\t\tExecuteAt:   executeAt,\n\t}),\n)\n```\n\n----------------------------------------\n\nTITLE: WorkflowDeploymentConfig Example\nDESCRIPTION: Demonstrates creating a WorkflowDeploymentConfig object from a JSON string, printing it to JSON, converting it to a dictionary, and creating a new instance from that dictionary. Requires the `hatchet_sdk.clients.rest.models.workflow_deployment_config` module. Assumes the existence of a `WorkflowDeploymentConfig` class with `from_json`, `to_json`, `to_dict`, and `from_dict` methods.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowDeploymentConfig.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_deployment_config import WorkflowDeploymentConfig\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowDeploymentConfig from a JSON string\nworkflow_deployment_config_instance = WorkflowDeploymentConfig.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowDeploymentConfig.to_json()\n\n# convert the object into a dict\nworkflow_deployment_config_dict = workflow_deployment_config_instance.to_dict()\n# create an instance of WorkflowDeploymentConfig from a dict\nworkflow_deployment_config_form_dict = workflow_deployment_config.from_dict(workflow_deployment_config_dict)\n```\n\n----------------------------------------\n\nTITLE: Configuring Hatchet HA Helm Chart Services\nDESCRIPTION: This snippet showcases how to configure the replica count for the `grpc`, `controllers`, and `scheduler` services in the Hatchet HA Helm chart.  It uses a YAML format to specify the desired replica counts.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/high-availability.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ngrpc:\n  replicaCount: 4\ncontrollers:\n  replicaCount: 2\nscheduler:\n  replicaCount: 2\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: tenantName\nDESCRIPTION: Defines the optional `tenantName` property of the `TenantInvite` interface. This property is a string representing the name of the tenant. It is optional, indicated by the `Optional` keyword.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_6\n\nLANGUAGE: TypeScript\nCODE:\n```\n`Optional` **tenantName**: `string`\n```\n\n----------------------------------------\n\nTITLE: Durable Sleep in Go\nDESCRIPTION: This code snippet demonstrates how to use durable sleep in a Hatchet workflow written in Go. It utilizes the `SleepFor` method on the `DurableContext` object to pause execution for a specified duration. The snippet is sourced from the `examples/v1/workflows/durable-sleep.go` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/durable-sleep.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/durable-sleep.go\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Simple Task - Typescript\nDESCRIPTION: This code snippet shows how to define a simple task in Typescript using Hatchet. It includes defining the task input type, creating a task using `hatchet.task`, registering the task with a worker, and invoking the task. The task transforms an input message to lowercase. Requires the `@hatchet-dev/typescript-sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_1\n\nLANGUAGE: Typescript\nCODE:\n```\n// 1. Define your task input\nexport type SimpleInput = {\n  Message: string;\n};\n\n// 2. Define your task using hatchet.task\nexport const simple = hatchet.task({\n  name: \"simple\",\n  fn: (input: SimpleInput) => {\n    return {\n      TransformedMessage: input.Message.toLowerCase(),\n    };\n  },\n});\n\n// 3. Register your task on your worker\nconst worker = await hatchet.worker(\"simple-worker\", {\n  workflows: [simple],\n});\n\nawait worker.start();\n\n// 4. Invoke tasks from your application\nawait simple.run({\n  Message: \"Hello World!\",\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet TypeScript SDK with npm\nDESCRIPTION: This code snippet demonstrates how to install the Hatchet TypeScript SDK using npm. This is the primary method for adding the SDK to your project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @hatchet-dev/typescript-sdk\n```\n\n----------------------------------------\n\nTITLE: Defining StepExpression Model with Composite Primary Key in Prisma\nDESCRIPTION: This code defines a Prisma model `StepExpression` with a composite primary key consisting of `key`, `stepId`, and `kind`. The `stepId` field is of type UUID. The `@@id` declaration specifies the composite primary key.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_2\n\nLANGUAGE: txt\nCODE:\n```\nmodel StepExpression {\n  key        String\n  stepId     String             @db.Uuid\n  expression String\n  kind       StepExpressionKind\n\n  @@id([key, stepId, kind])\n}\n```\n\n----------------------------------------\n\nTITLE: Defining EventData Interface in TypeScript\nDESCRIPTION: This code snippet defines the `EventData` interface in TypeScript. It includes a single property named `data` which is of type `string`. This string represents the JSON payload of the event. This interface is used within the Hatchet TypeScript SDK for defining event data in API contracts.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.EventData.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: EventData\n *\n * [APIContracts](../modules/APIContracts.md).EventData\n */\n\n/**\n * @public\n */\ninterface EventData {\n\t/**\n\t * The data for the event (JSON bytes).\n\t */\n\tdata: `string`\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Hatchet Buffer Settings (Shell)\nDESCRIPTION: This snippet shows how to configure Hatchet's buffer settings using environment variables to optimize database write performance. It lists several environment variables that control the flush period and item threshold for different buffers within Hatchet, such as workflow runs, events, semaphore releases, and queue step runs. Adjusting these settings can reduce database CPU load and improve throughput.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\n# Default values if the values below are not set\nSERVER_FLUSH_PERIOD_MILLISECONDS\nSERVER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing workflow runs to the database\nSERVER_WORKFLOWRUNBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_WORKFLOWRUNBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing events to the database\nSERVER_EVENTBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_EVENTBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for releasing slots for workers\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing queue items to the database\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_ITEMS_THRESHOLD\n```\n\nLANGUAGE: sh\nCODE:\n```\n# Default values if the values below are not set\nSERVER_FLUSH_PERIOD_MILLISECONDS=250\nSERVER_FLUSH_ITEMS_THRESHOLD=1000\n\n# Settings for writing workflow runs to the database\nSERVER_WORKFLOWRUNBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_WORKFLOWRUNBUFFER_FLUSH_ITEMS_THRESHOLD=500\n\n# Settings for writing events to the database\nSERVER_EVENTBUFFER_FLUSH_PERIOD_MILLISECONDS=1000\nSERVER_EVENTBUFFER_FLUSH_ITEMS_THRESHOLD=1000\n\n# Settings for releasing slots for workers\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_ITEMS_THRESHOLD=200\n\n# Settings for writing queue items to the database\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_PERIOD_MILLISECONDS=100\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_ITEMS_THRESHOLD=500\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pnpm\nDESCRIPTION: This command installs the necessary dependencies for developing the Hatchet TypeScript SDK itself.  It's part of the development setup.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm install\n```\n\n----------------------------------------\n\nTITLE: Triggering Hatchet Workflow via API Call\nDESCRIPTION: This function sends a POST request to the FastAPI server at '/message' to trigger the Hatchet workflow. It includes user messages and a URL. Upon success, it updates the 'openRequest' state with the returned 'messageId'.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nconst sendMessage = async (content: string) => {\n  try {\n    setMessages((prev) => [...prev, { role: \"user\", content }]);\n\n    const response = await fetch(`${API_URL}/message`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        url: \"https://docs.hatchet.run/home\",\n        messages: [\n          ...messages,\n          {\n            role: \"user\",\n            content,\n          },\n        ],\n      }),\n    });\n\n    if (response.ok) {\n      // Handle successful response\n      setOpenRequest((await response.json()).messageId);\n    } else {\n      // Handle error response\n    }\n  } catch (error) {\n    // Handle network error\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Get Worker Metrics\nDESCRIPTION: This command shows how to retrieve metrics from a Hatchet worker using `curl`. It queries the `/metrics` endpoint, which is intended for use with monitoring systems like Prometheus. The endpoint returns metrics in Prometheus exposition format.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker-healthchecks.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl localhost:8001/metrics\n\n# HELP python_gc_objects_collected_total Objects collected during gc\n# TYPE python_gc_objects_collected_total counter\npython_gc_objects_collected_total{generation=\"0\"} 18782.0\npython_gc_objects_collected_total{generation=\"1\"} 4907.0\npython_gc_objects_collected_total{generation=\"2\"} 244.0\n# HELP python_gc_objects_uncollectable_total Uncollectable objects found during GC\n# TYPE python_gc_objects_uncollectable_total counter\npython_gc_objects_uncollectable_total{generation=\"0\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"1\"} 0.0\npython_gc_objects_uncollectable_total{generation=\"2\"} 0.0\n# HELP python_gc_collections_total Number of times this generation was collected\n# TYPE python_gc_collections_total counter\npython_gc_collections_total{generation=\"0\"} 308.0\npython_gc_collections_total{generation=\"1\"} 27.0\npython_gc_collections_total{generation=\"2\"} 2.0\n# HELP python_info Python platform information\n# TYPE python_info gauge\npython_info{implementation=\"CPython\",major=\"3\",minor=\"10\",patchlevel=\"15\",version=\"3.10.15\"} 1.0\n# HELP hatchet_worker_status Current status of the Hatchet worker\n# TYPE hatchet_worker_status gauge\nhatchet_worker_status 1.0\n```\n\n----------------------------------------\n\nTITLE: Running Python Hatchet Worker\nDESCRIPTION: Starts the Python Hatchet worker by executing the `worker.py` script using `python3`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\npython3 worker.py\n```\n\n----------------------------------------\n\nTITLE: Listing Cron Triggers - Go\nDESCRIPTION: Lists all workflow cron triggers matching the specified criteria using the Hatchet SDK in Go.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_15\n\nLANGUAGE: go\nCODE:\n```\nexamples/cron-programmatic/main.go\n```\n\n----------------------------------------\n\nTITLE: Defining WorkflowRunList Interface (TypeScript)\nDESCRIPTION: This TypeScript code defines the `WorkflowRunList` interface. It includes two optional properties: `pagination` of type `PaginationResponse` and `rows` which is an array of `WorkflowRun` objects. This interface is likely used as a data structure for representing a list of workflow runs retrieved from an API, along with pagination metadata.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkflowRunList.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * @oas [get] /workflows/{workflow_id}/runs\n * @operation GetWorkflowRuns\n * @tag Workflow\n * @summary Gets a list of workflow runs for a workflow.\n */\nexport interface WorkflowRunList {\n  pagination?: PaginationResponse;\n  rows?: WorkflowRun[];\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Database and User in Postgres with SQL\nDESCRIPTION: This SQL script demonstrates how to create a new database and user in Postgres specifically for Hatchet. It also grants the Hatchet user the necessary permissions on the newly created database.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_2\n\nLANGUAGE: sql\nCODE:\n```\ncreate database hatchet;\n\ncreate role hatchet\nwith\n    login password 'hatchet';\n\ngrant hatchet to postgres;\n\nalter database hatchet owner to hatchet;\n```\n\n----------------------------------------\n\nTITLE: Pushing an Event with Additional Metadata - Python\nDESCRIPTION: This snippet demonstrates how to push an event to Hatchet with additional metadata using the Python client. It sets the 'source' metadata key to 'api'. The event is identified by the 'user:create' type and includes a 'userId' in the payload.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nhatchet.event.push(\"user:create\", {'userId': '1234'}, options={\n  \"additional_metadata\": {\n    \"source\": \"api\" # Arbitrary key-value pair\n  }\n})\n```\n\n----------------------------------------\n\nTITLE: Running a Simple Task Hatchet Go\nDESCRIPTION: This snippet demonstrates how to run the previously defined simple task.  It calls the `Run` method on the task instance, passing in a `SimpleInput` struct with a message. It then checks for errors and prints the transformed message from the result.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-go.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nresult, err := simple.Run(ctx, SimpleInput{\n    Message: \"Hello, World!\",\n})\n\nif err != nil {\n    return err\n}\n\nfmt.Println(result.TransformedMessage)\n```\n\n----------------------------------------\n\nTITLE: Get Step Run Diff using hatchet_sdk in Python\nDESCRIPTION: This snippet retrieves the diff between the most recent and first run of a specified step run using the `step_run_get_diff` method of the `WorkflowApi`. It requires the `step_run` ID as input and returns a `GetStepRunDiffResponse` object. It uses API key (cookieAuth) or Bearer authentication (bearerAuth).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.get_step_run_diff_response import GetStepRunDiffResponse\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    step_run = 'step_run_example' # str | The step run id\n\n    try:\n        # Get diff\n        api_response = api_instance.step_run_get_diff(step_run)\n        print(\"The response of WorkflowApi->step_run_get_diff:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->step_run_get_diff: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limit (Typescript)\nDESCRIPTION: Defines a Hatchet workflow with concurrency limits on a per-user basis using Typescript, allowing a maximum of 5 concurrent runs based on the `userId` input. Includes a rate-limited task that restricts execution to 10 tasks per minute per user.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\n// limit concurrency on a per-user basis\nflowControlWorkflow = hatchet.workflow<SimpleInput, SimpleOutput>({\n  name: \"ConcurrencyLimitWorkflow\",\n  concurrency: {\n    expression: \"input.userId\",\n    maxRuns: 5,\n    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n  },\n});\n\n// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit\nflowControlWorkflow.task({\n  name: \"rate-limit-task\",\n  rateLimits: [\n    {\n      dynamicKey: \"input.userId\",\n      units: 1,\n      limit: 10,\n      duration: RateLimitDuration.MINUTE,\n    },\n  ],\n  fn: async (input) => {\n    return {\n      Completed: true,\n    };\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Hatchet HA Helm Chart Replicas\nDESCRIPTION: This snippet shows the YAML configuration for setting the replica count for different Hatchet services within the HA Helm chart. `replicaCount` determines the number of instances for each service, increasing redundancy and availability. The configuration specifies the replica counts for the `grpc`, `controllers`, and `scheduler` services.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/high-availability.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ngrpc:\n  replicaCount: 4\ncontrollers:\n  replicaCount: 2\nscheduler:\n  replicaCount: 2\n```\n\n----------------------------------------\n\nTITLE: Handling Step Termination in Hatchet (Python)\nDESCRIPTION: This code demonstrates how to handle step termination using `context.done()` within a Hatchet step. The `step1` function continuously loops until `context.done()` returns `True`, indicating that the step has been cancelled or timed out, at which point the loop breaks and the step exits gracefully.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout=\"2s\")\ndef step1(self, context):\n    while True:\n        # this step will gracefully exit after 2 seconds\n        if context.done():\n            break\n        pass\n```\n\n----------------------------------------\n\nTITLE: Analyzing query execution plan\nDESCRIPTION: This is the output of the EXPLAIN ANALYZE command on a log query, showing how PostgreSQL executes the query. It shows that the query uses a custom scan (ChunkAppend) on the logs table and utilizes the index on `tenant_id`, `resource_id`, and `created_at` for each chunk, resulting in fast query performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_10\n\nLANGUAGE: sql\nCODE:\n```\n---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n Custom Scan (ChunkAppend) on logs  (cost=0.27..145.60 rows=93 width=155) (actual time=0.435..8.836 rows=847 loops=1)\n   Order: logs.created_at DESC\n   ->  Index Scan Backward using _hyper_8_324_chunk_logs_tenant_id_resource_id_created_at_idx on _hyper_8_324_chunk  (cost=0.27..3.57 rows=2 width=155) (actual time=0.433..0.529 rows=23 loops=1)\n         Index Cond: ((tenant_id = '77b7ed39-d3e0-4dec-a28a-6d1e69315d57'::uuid) AND (resource_id = 'b4d2e415-d957-438f-8340-50ef8f73badf'::uuid) AND (created_at >= '2024-10-19 20:06:45.570503+00'::timestamp with time zone) AND (created_at <= '2024-11-19 20:06:45.570503+00'::timestamp with time zone))\n   ->  Index Scan Backward using _hyper_8_323_chunk_logs_tenant_id_resource_id_created_at_idx on _hyper_8_323_chunk  (cost=0.27..4.62 rows=3 width=155) (actual time=0.312..0.315 rows=28 loops=1)\n         Index Cond: ((tenant_id = '77b7ed39-d3e0-4dec-a28a-6d1e69315d57'::uuid) AND (resource_id = 'b4d2e415-d957-438f-8340-50ef8f73badf'::uuid) AND (created_at >= '2024-10-19 20:06:45.570503+00'::timestamp with time zone) AND (created_at <= '2024-11-19 20:06:45.570503+00'::timestamp with time zone))\n   ->  Index Scan Backward using _hyper_8_322_chunk_logs_tenant_id_resource_id_created_at_idx on _hyper_8_322_chunk  (cost=0.27..4.64 rows=3 width=155) (actual time=0.231..0.256 rows=27 loops=1)\n         Index Cond: ((tenant_id = '77b7ed39-d3e0-4dec-a28a-6d1e69315d57'::uuid) AND (resource_id = 'b4d2e415-d957-438f-8340-50ef8f73badf'::uuid) AND (created_at >= '2024-10-19 20:06:45.570503+00'::timestamp with time zone) AND (created_at <= '2024-11-19 20:06:45.570503+00'::timestamp with time zone))\n   -- ... and so on...\n\n Planning Time: 1.615 ms\n Execution Time: 0.641 ms\n```\n\n----------------------------------------\n\nTITLE: Creating an alias to get a Hatchet admin token with go\nDESCRIPTION: This snippet creates a shell alias `get_token` that executes a Go program to create a Hatchet admin token. The alias then outputs that token to standard output, intended for use in setting environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nalias get_token='go run ./cmd/hatchet-admin token create --name local --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52'\n```\n\n----------------------------------------\n\nTITLE: Registering and Calling an Action in Hatchet Service (Go)\nDESCRIPTION: This code snippet demonstrates how to register an action with a Hatchet service and then call it within a workflow. It uses `RegisterAction` to register the `StepOne` function with the service and associates it with the action name \"step-one\". Then, it uses `testSvc.Call(\"step-one\")` to invoke this action within a workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/creating-a-workflow.mdx#_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\ntestSvc := w.NewService(\"test\")\n\nerr = testSvc.RegisterAction(StepOne, worker.WithActionName(\"step-one\"))\n\nif err != nil {\n\tpanic(err)\n}\n\nerr = testSvc.RegisterWorkflow(\n\ttestSvc.Call(\"step-one\"),\n)\n```\n\n----------------------------------------\n\nTITLE: Defining One-Many Relation with Tenant Model in Prisma\nDESCRIPTION: This snippet demonstrates how to define a one-to-many relationship from the `Tenant` model to the `Step` and `Action` models in Prisma. The `Step[]` and `Action[]` fields indicate that a tenant can have multiple steps and actions associated with it.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\nmodel Tenant {\n  steps     Step[]\n  actions   Action[]\n}\n```\n\n----------------------------------------\n\nTITLE: Streaming Workflow Run Results - Hatchet TypeScript\nDESCRIPTION: This snippet demonstrates how to stream the results of a workflow run as each step is executed. It utilizes the `stream` method on the `WorkflowRunRef` object, which returns an async generator. Requires the `@hatchet-dev/typescript-sdk` package to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/get-workflow-results.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflowRun = hatchet.admin.getWorkflowRun(\n  \"5a3a617d-1200-4ee2-92e6-be4bd27ca26f\",\n);\n\nconst listener = workflowRun.stream();\n\nfor await (const event of listener) {\n  console.log(event.type, event.payload);\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow Schedule Timeout in Go\nDESCRIPTION: This snippet shows how to define a schedule timeout for a Hatchet workflow using Go. The `ScheduleTimeout` property is set to a duration string, indicating the maximum time a step can wait in the queue before cancellation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ncleanup, err := run(events, worker.WorkflowJob{\n  Name: \"timeout\",\n  Description: \"timeout\",\n  ScheduleTimeout: \"2m\",\n  Steps: []*worker.WorkflowStep{\n    worker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n      time.Sleep(time.Second * 60)\n      return nil, nil\n    }).SetName(\"step-one\")\n  },\n})\n```\n\n----------------------------------------\n\nTITLE: Defining Package.json Script\nDESCRIPTION: Defines a script in the `package.json` file to start the Typescript Hatchet worker using `ts-node`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  // ...rest of your `package.json`\n  \"scripts\": {\n    // ...existing scripts\n    \"worker\": \"npx ts-node worker.ts\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Hatchet Workflow Step with Compute Configuration (Python)\nDESCRIPTION: This snippet demonstrates how to define a Hatchet workflow step and associate it with a previously defined `Compute` object. The `@hatchet.step(compute=compute)` decorator assigns the specified compute resources to the `process_data` step. The step function takes a `Context` object as input.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_5\n\nLANGUAGE: Python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, Context\n\nhatchet = Hatchet()\n\n@hatchet.workflow()\nclass MyWorkflow:\n    @hatchet.step(compute=compute)\n    def process_data(self, context: Context):\n        # Your code here\n        pass\n```\n\n----------------------------------------\n\nTITLE: Defining UserTenantPublic Interface (TypeScript)\nDESCRIPTION: This code snippet defines the UserTenantPublic interface in TypeScript. It includes properties for the user's email (a required string, formatted as an email address) and name (an optional string). The interface is located within the APIContracts module of the @hatchet-dev/typescript-sdk.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UserTenantPublic.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface UserTenantPublic {\n  email: string;\n  name?: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Listening for Base64 Encoded File Streams\nDESCRIPTION: This code snippet demonstrates how to listen for and process base64 encoded file streams. It subscribes to a Hatchet workflow, checks if the event type is a `STEP_RUN_EVENT_TYPE_STREAM`, decodes the base64 encoded payload, and writes it to a file in an output directory.  Dependencies include `dotenv`, `hatchet` and standard file system and path modules.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nasync def listen_for_files():\n    load_dotenv()\n    hatchet = new_client()\n    workflowRunId = hatchet.admin.run_workflow(\"ManualTriggerWorkflow\", {\"test\": \"test\"})\n    listener = hatchet.listener.stream(workflowRunId)\n\n    # Get the directory of the current script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Create the \"out\" directory if it doesn't exist\n    out_dir = os.path.join(script_dir, \"out\")\n    os.makedirs(out_dir, exist_ok=True)\n\n    async for event in listener:\n        if event.type == StepRunEventType.STEP_RUN_EVENT_TYPE_STREAM:\n            # Decode the base64-encoded payload\n            decoded_payload = base64.b64decode(event.payload)\n\n            # Construct the path to the payload file in the \"out\" directory\n            payload_path = os.path.join(out_dir, \"payload.jpg\")\n\n            with open(payload_path, \"wb\") as f:\n                f.write(decoded_payload)\n```\n\n----------------------------------------\n\nTITLE: Opening Hatchet via Glasskube\nDESCRIPTION: This command opens the Hatchet application through Glasskube, presumably using a CLI command to initiate the opening process.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nglasskube open hatchet\n```\n\n----------------------------------------\n\nTITLE: WorkflowTriggerCronRef Usage in Python\nDESCRIPTION: This code snippet demonstrates how to create a WorkflowTriggerCronRef object from a JSON string, convert it to a dictionary, and back to an object. It uses the `hatchet_sdk` library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowTriggerCronRef.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_trigger_cron_ref import WorkflowTriggerCronRef\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowTriggerCronRef from a JSON string\nworkflow_trigger_cron_ref_instance = WorkflowTriggerCronRef.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowTriggerCronRef.to_json()\n\n# convert the object into a dict\nworkflow_trigger_cron_ref_dict = workflow_trigger_cron_ref_instance.to_dict()\n# create an instance of WorkflowTriggerCronRef from a dict\nworkflow_trigger_cron_ref_form_dict = workflow_trigger_cron_ref.from_dict(workflow_trigger_cron_ref_dict)\n```\n\n----------------------------------------\n\nTITLE: Hatchet Client Token Export (Shell)\nDESCRIPTION: This shell command creates and exports a Hatchet client token using the `hatchet-admin` CLI. The token is generated for a specified tenant and is then stored in the `HATCHET_CLIENT_TOKEN` environment variable.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nexport HATCHET_CLIENT_TOKEN=\"$(go run ./cmd/hatchet-admin token create --tenant-id <tenant>)\"\n```\n\n----------------------------------------\n\nTITLE: Instantiate Hatchet Client (Python)\nDESCRIPTION: Instantiates the Hatchet client using the `hatchet_sdk` library. This client is used to interact with the Hatchet service. This code assumes that `hatchet_sdk` is installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/py.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n```\n\n----------------------------------------\n\nTITLE: Initializing AdminClient and Listing Workflows in TypeScript\nDESCRIPTION: This code snippet demonstrates how to initialize the Hatchet SDK, access the AdminClient, and use it to list available workflows. It iterates through the workflows and logs each row to the console. This snippet relies on the @hatchet-dev/typescript-sdk package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_admin-client.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst hatchet = Hatchet.init();\nconst admin = hatchet.admin as AdminClient;\n\n// Now you can use the admin client to interact with the Hatchet Admin API\nadmin.list_workflows().then((res) => {\n  res.rows?.forEach((row) => {\n    console.log(row);\n  });\n});\n```\n\n----------------------------------------\n\nTITLE: Pushing Single Event to Hatchet API in Typescript\nDESCRIPTION: This code snippet demonstrates how to push a single event to the Hatchet API using the `hatchet.event.push` method. It initializes the Hatchet client and then pushes an event named \"user:create\" with a payload containing test data. The event's input data will be passed to the workflow run.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-events.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nhatchet.event.push(\"user:create\", {\n  test: \"test\",\n});\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: expires\nDESCRIPTION: Defines the `expires` property of the `TenantInvite` interface. This property is a string representing the expiration timestamp of the invite. It is formatted as a date-time string. This property is required for the interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * The time that this invite expires.\n *\n * @format date-time\n */\nexpires: `string`\n```\n\n----------------------------------------\n\nTITLE: Configuring API and Engine Environment Variables (YAML)\nDESCRIPTION: This snippet configures the necessary environment variables for the Hatchet API and Engine services. It includes settings for authentication cookie domain, server URL, gRPC bind address, gRPC insecure mode, and gRPC broadcast address.  These variables are essential for the proper functioning of the Hatchet services within the Kubernetes cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/networking.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\napi:\n  env:\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"hatchet-engine.example.com:443\" # example.com should be replaced with your domain\n\nengine:\n  env:\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n```\n\n----------------------------------------\n\nTITLE: sync_to_async with Keyword Arguments in Python\nDESCRIPTION: This snippet demonstrates how to pass a custom `executor` and `loop` to the `sync_to_async` wrapper.  This allows for greater control over how the synchronous function is executed asynchronously. It involves importing `asyncio` and `concurrent.futures` and then defining an executor and a loop, which are then passed as keyword arguments to `sync_to_async` when calling the blocking function.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/asyncio.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport concurrent\n...\n\nexecutor = concurrent.futures.ThreadPoolExecutor()\nloop = asyncio.get_event_loop()\n\n\ndef blocking_function():\n    time.sleep(5)\n    return {\"type\": \"sync_blocking\"}\n\n\n@hatchet.function()\nasync def my_func(context: Context) -> dict:\n\n    data = await sync_to_async(blocking_function)(executor=executor, loop=loop)\n    return {\n        \"status\": \"success\",\n        \"data\": data,\n    }\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Labels - Go\nDESCRIPTION: This code snippet demonstrates how to dynamically update worker labels in a Hatchet step using Go. It checks if the worker's current model label matches the desired label and updates it if necessary using `UpsertLabels`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tOn:          worker.Events(\"user:create:affinity\"),\n\t\t\tName:        \"affinity\",\n\t\t\tDescription: \"affinity\",\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n\n    \t\t\t\tmodel := ctx.Worker().GetLabels()[\"model\"]\n\n    \t\t\t\tif model != \"fancy-vision-model\" {\n    \t\t\t\t\tctx.Worker().UpsertLabels(map[string]interface{}{\n    \t\t\t\t\t\t\"model\": nil,\n    \t\t\t\t\t})\n    \t\t\t\t\t// Do something to load the model\n            evictModel();\n            loadNewModel(\"fancy-vision-model\");\n    \t\t\t\t\tctx.Worker().UpsertLabels(map[string]interface{}{\n    \t\t\t\t\t\t\"model\": \"fancy-vision-model\",\n    \t\t\t\t\t})\n    \t\t\t\t}\n\n    \t\t\t\treturn &stepOneOutput{\n    \t\t\t\t\tMessage: ctx.Worker().ID(),\n    \t\t\t\t}, nil\n    \t\t\t}).\n    \t\t\t\tSetName(\"step-one\").\n    \t\t\t\tSetDesiredLabels(map[string]*types.DesiredWorkerLabel{\n    \t\t\t\t\t\"model\": {\n    \t\t\t\t\t\tValue:  \"fancy-vision-model\",\n    \t\t\t\t\t\tWeight: 10,\n    \t\t\t\t\t},\n    \t\t\t\t\t\"memory\": {\n    \t\t\t\t\t\tValue:      512,\n    \t\t\t\t\t\tRequired:   true,\n    \t\t\t\t\t\tComparator: types.WorkerLabelComparator_GREATER_THAN,\n    \t\t\t\t\t},\n    \t\t\t\t}),\n    \t\t},\n    \t},\n    )\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet SDK with pip\nDESCRIPTION: This command installs the Hatchet SDK using pip, the Python package installer. It allows you to use Hatchet's functionalities in your Python projects.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/index.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Current Page Example\nDESCRIPTION: This code shows an example of the current_page property within the PaginationResponse interface. This property is an optional number representing the current page number. The expected format is an integer.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.PaginationResponse.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n2\n```\n\n----------------------------------------\n\nTITLE: Setup Hatchet Environment (Shell)\nDESCRIPTION: This shell command installs the project's dependencies, runs database migrations, generates encryption keys, and seeds the database with initial data. It's a crucial step for initializing the development environment after starting the database.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ntask setup\n```\n\n----------------------------------------\n\nTITLE: Running the Go Hatchet worker\nDESCRIPTION: This command starts the Go Hatchet worker, which will listen for workflow events and execute the defined steps. Prerequisite: Go and the required dependencies installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\ngo run main.go\n```\n\n----------------------------------------\n\nTITLE: Pushing Multiple Events to Hatchet API - Python\nDESCRIPTION: This code snippet demonstrates how to push multiple events to the Hatchet API simultaneously using the `client.event.bulk_push` method. It defines a list of events, each with a key, payload, and additional metadata, and then calls `bulk_push` with the event list. Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/run-workflow-events.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nevents: List[BulkPushEventWithMetadata] = [\n    {\n        \"key\": \"event1\",\n        \"payload\": {\"message\": \"This is event 1\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user123\"},\n    },\n    {\n        \"key\": \"event2\",\n        \"payload\": {\"message\": \"This is event 2\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user456\"},\n    },\n    {\n        \"key\": \"event3\",\n        \"payload\": {\"message\": \"This is event 3\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user789\"},\n    },\n]\n\n\nresult =\nhatchet.client.event.bulk_push(\n    events\n)\n```\n\n----------------------------------------\n\nTITLE: Create project directory\nDESCRIPTION: Creates a new project directory named 'hatchet-tutorial' and navigates into it. This is the first step in setting up a new Hatchet project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/ts.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hatchet-tutorial && cd hatchet-tutorial\n```\n\n----------------------------------------\n\nTITLE: CreateAPITokenResponse Interface Definition\nDESCRIPTION: This TypeScript interface defines the structure of the response received after creating an API token. It includes a single property, 'token', which is a string that holds the generated API token.  This interface is used for type safety when working with API responses in the Hatchet TypeScript SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.CreateAPITokenResponse.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface CreateAPITokenResponse {\n  /**\n   * The API token.\n   */\n  token: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Step Timeout in Go\nDESCRIPTION: This snippet shows how to define a timeout for a specific Hatchet step using Go. The `SetTimeout` method on the WorkflowStep sets the maximum execution time for the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nworker.WorkflowJob{\n  Name: \"timeout\",\n  Description: \"timeout\",\n  Steps: []*worker.WorkflowStep{\n    worker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n      time.Sleep(time.Second * 60)\n      return nil, nil\n    }).SetName(\"step-one\").SetTimeout(\"30s\"),\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Cloning Quickstart Project\nDESCRIPTION: This command clones the Hatchet Python quickstart project from GitHub. This provides a pre-configured project structure to help users get started quickly with Hatchet.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/py.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/hatchet-dev/hatchet-python-quickstart.git\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: metadata\nDESCRIPTION: Defines the `metadata` property of the `TenantInvite` interface.  This property is of type `APIResourceMeta`, presumably defined elsewhere in the codebase. This is a required property for the interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_3\n\nLANGUAGE: TypeScript\nCODE:\n```\nmetadata: [`APIResourceMeta`](APIContracts.APIResourceMeta.md)\n```\n\n----------------------------------------\n\nTITLE: Full Data Payload Example (JSON)\nDESCRIPTION: This JSON snippet exemplifies a 'full' data payload in Hatchet. It includes detailed information about a task, such as its ID, type, status, execution details, assigned user, and priority. This provides comprehensive context without requiring additional data retrieval.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"task.executed\",\n  \"timestamp\": \"2022-11-03T20:26:10.344522Z\",\n  \"data\": {\n    \"id\": \"1f81eb52-5198-4599-803e-771906343485\",\n    \"type\": \"task\",\n    \"taskName\": \"Database Backup\",\n    \"taskStatus\": \"Completed\",\n    \"executionDetails\": \"Backup completed successfully at 2022-11-03T20:25:10.344522Z\",\n    \"assignedTo\": \"John Smith\",\n    \"priority\": \"High\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining and Running Workflow with Tasks - Python\nDESCRIPTION: This Python code demonstrates how to define a workflow with two tasks using Hatchet. It includes attaching the first task to the workflow, then attaching the second task as a child of the first, creating a simple DAG. The second task accesses the output of the first task using `ctx.task_output`.  Requires the `hatchet` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# 1. Define a workflow (a workflow is a collection of tasks)\nsimple = hatchet.workflow(name=\"SimpleWorkflow\")\n\n# 2. Attach the first task to the workflow\n@simple.task()\ndef task_1(input: EmptyModel, ctx: Context) -> dict[str, str]:\n    print(\"executed task_1\")\n    return {\"result\": \"task_1\"}\n\n# 3. Attach the second task to the workflow, which executes after task_1\n@simple.task(parents=[task_1])\ndef task_2(input: EmptyModel, ctx: Context) -> None:\n    first_result = ctx.task_output(task_1)\n    print(first_result)\n\n# 4. Invoke workflows from your application\nresult = simple.run(input_data)\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Go\nDESCRIPTION: This snippet demonstrates listing scheduled runs using the Go Hatchet SDK.  It retrieves a list of scheduled runs based on criteria. Requires configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nSee GithubSnippet: examples/scheduled/main.go - List\n```\n\n----------------------------------------\n\nTITLE: Generating a Webhook Secret\nDESCRIPTION: This command generates a random webhook secret using `cat /dev/urandom`, `base64` encoding, and `head`. The secret is used to verify the authenticity of webhooks sent from Github to Hatchet.  The secret should be securely stored and configured in both the Github app and the Hatchet instance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/github-app-setup.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ncat /dev/urandom | base64 | head -c 32\n```\n\n----------------------------------------\n\nTITLE: Pushing Bulk Events with Hatchet Client (Python)\nDESCRIPTION: This snippet demonstrates how to push multiple events to Hatchet in a single request using the Python SDK. It initializes a Hatchet client, defines a list of events with payloads and metadata, and then uses the `bulk_push` method to send the events to the Hatchet server. This can significantly improve throughput compared to sending events individually.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n\nevents: List[BulkPushEventWithMetadata] = [\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 1\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user123\"},\n    },\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 2\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user456\"},\n    },\n    {\n        \"key\": \"user:create\",\n        \"payload\": {\"message\": \"This is event 3\"},\n        \"additional_metadata\": {\"source\": \"test\", \"user_id\": \"user789\"},\n    },\n]\n\nresult = hatchet.client.event.bulk_push(events)\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Bulk (Go)\nDESCRIPTION: This snippet demonstrates how to spawn multiple child workflows from a parent workflow in Hatchet using the Go SDK. It creates a slice of `SpawnWorkflowsOpts` and calls `ctx.SpawnWorkflows` to efficiently spawn the child workflows in bulk. This approach minimizes the number of database interactions, improving performance.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                // Prepare the batch of workflows to spawn\n                childWorkflows := make([]*worker.SpawnWorkflowsOpts, 10)\n\n                for i := 0; i < 10; i++ {\n                    childInput := \"child-input-\" + strconv.Itoa(i)\n                    childWorkflows[i] = &worker.SpawnWorkflowsOpts{\n                        WorkflowName: \"child-workflow\",\n                        Input:        childInput,\n                        Key:          \"child-key-\" + strconv.Itoa(i),\n                    }\n                }\n\n                // Spawn all workflows in bulk using SpawnWorkflows\n                createdWorkflows, err := ctx.SpawnWorkflows(childWorkflows)\n                if err != nil {\n                    return err\n                }\n\n                return nil\n            }),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Setting up workflow dependencies in Python\nDESCRIPTION: This snippet imports necessary libraries for the workflow, including the Hatchet client, Context, BeautifulSoup, OpenAI, and requests. It also initializes an OpenAI client. These imports are required for interacting with Hatchet, parsing HTML, making HTTP requests, and using OpenAI's API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom .hatchet import hatchet\nfrom hatchet_sdk import Context\nfrom bs4 import BeautifulSoup\nfrom openai import OpenAI\nimport requests\n\nopenai = OpenAI()\n```\n\n----------------------------------------\n\nTITLE: Compute Configuration with Replicas in Single Region (Python)\nDESCRIPTION: This snippet illustrates how to configure a `Compute` object with a specified number of replicas within a single region. All replicas will be deployed in the specified region ('ewr' in this case).  This provides redundancy for the workload in that region.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\n# Single region, multiple replicas\ncompute = Compute(\n    cpu_kind=\"shared\",\n    cpus=2,\n    memory_mb=1024,\n    num_replicas=3,\n    regions=[\"ewr\"]    # All 3 replicas in ewr\n)\n```\n\n----------------------------------------\n\nTITLE: Asyncio workaround for Celery tasks\nDESCRIPTION: This code snippet shows a workaround for Celery's lack of native asyncio support. It links to a GitHub issue comment that suggests converting async methods to synchronous ones for use with Celery.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/problems-with-celery.mdx#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nhttps://github.com/celery/celery/issues/6552#issuecomment-1870832344\n```\n\n----------------------------------------\n\nTITLE: RejectInviteRequest Interface Definition\nDESCRIPTION: Defines the structure for the `RejectInviteRequest` interface in TypeScript.  It contains a single property, `invite`, which is a string representing the invite ID. The invite string must be a UUID with a length of 36 characters. This interface is part of the APIContracts module.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.RejectInviteRequest.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * [APIContracts](../modules/APIContracts.md).RejectInviteRequest\n */\n\n/**\n * invite\n */\n\n/**\n * **invite**: `string`\n *\n * `Min Length`**\n *\n * 36\n *\n * `Max Length`**\n *\n * 36\n *\n * `Example`**\n *\n * ```ts\n * \"bb214807-246e-43a5-a25d-41761d1cff9e\"\n * ```\n */\n```\n\n----------------------------------------\n\nTITLE: Create Project Directory\nDESCRIPTION: This command creates a new project directory named 'hatchet-tutorial' and navigates into it. This is the first step in setting up a new Hatchet project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/py.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hatchet-tutorial && cd hatchet-tutorial\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Go\nDESCRIPTION: This snippet links to an external Go file (`examples/scheduled/main.go`) and targets the section \"List\".  It's intended to show how to list scheduled runs using the Hatchet SDK in Go, using code from the `ScheduleTriggerGo` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_8\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={ScheduleTriggerGo} target=\"List\" />\n```\n\n----------------------------------------\n\nTITLE: TenantMember.user Property\nDESCRIPTION: Defines the user property of the TenantMember interface. This property is of type UserTenantPublic, which likely contains public information about the user within the context of the tenant.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantMember.md#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * user: [`UserTenantPublic`](APIContracts.UserTenantPublic.md)\n *\n * The user associated with this tenant member.\n */\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Client File\nDESCRIPTION: This command creates a new file named `hatchet-client.ts` in your project root. This file will contain the Hatchet client initialization code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/ts.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntouch hatchet-client.ts\n```\n\n----------------------------------------\n\nTITLE: Next Page Example\nDESCRIPTION: This code shows an example of the next_page property within the PaginationResponse interface. This property is an optional number representing the next page number. The expected format is an integer.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.PaginationResponse.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n3\n```\n\n----------------------------------------\n\nTITLE: CloudKMS Key Ring Creation (Shell)\nDESCRIPTION: These gcloud commands create a CloudKMS key ring and a key for encryption purposes. It sets the location to \"global\" and the purpose of the key to \"encryption\". These are used for generating encryption keys.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/contributing/index.mdx#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ngcloud kms keyrings create \"development\" --location \"global\"\ngcloud kms keys create \"development\" --location \"global\" --keyring \"development\" --purpose \"encryption\"\ngcloud kms keys list --location \"global\" --keyring \"development\"\n```\n\n----------------------------------------\n\nTITLE: Running Hatchet worker with Poetry\nDESCRIPTION: This command starts the Hatchet worker using Poetry.  It executes the `hatchet` command, presumably the entry point for the Hatchet worker application.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\npoetry run hatchet\n```\n\n----------------------------------------\n\nTITLE: Navigating to example directory\nDESCRIPTION: This command navigates the user to the `simple-examples` directory, which likely contains example workflows and related files for Hatchet.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ncd simple-examples\n```\n\n----------------------------------------\n\nTITLE: ESLint Parser Options Configuration JavaScript\nDESCRIPTION: This JavaScript snippet demonstrates how to configure the `parserOptions` property in an ESLint configuration file. It specifies the ECMAScript version, source type, project configuration files (tsconfig.json), and the root directory for the TypeScript project. This setup is crucial for enabling type-aware linting rules.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/app/README.md#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport default {\n  // other rules...\n  parserOptions: {\n    ecmaVersion: 'latest',\n    sourceType: 'module',\n    project: ['./tsconfig.json', './tsconfig.node.json'],\n    tsconfigRootDir: __dirname,\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Go Hatchet Worker\nDESCRIPTION: Defines a Hatchet worker in Go. It uses the `hatchet-dev/hatchet` Go module to register a workflow with a single step.  It loads environment variables from a .env file using `github.com/joho/godotenv`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/joho/godotenv\"\n\n\t\"github.com/hatchet-dev/hatchet/pkg/client\"\n\t\"github.com/hatchet-dev/hatchet/pkg/cmdutils\"\n\t\"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype stepOutput struct{}\n\nfunc main() {\n\terr := godotenv.Load()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tc, err := client.New()\n\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating client: %v\", err))\n\t}\n\n\tw, err := worker.NewWorker(\n\t\tworker.WithClient(\n\t\t\tc,\n\t\t),\n\t\tworker.WithMaxRuns(1),\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error creating worker: %v\", err))\n\t}\n\n\terr = w.RegisterWorkflow(\n\t\t&worker.WorkflowJob{\n\t\t\tName:        \"simple-workflow\",\n\t\t\tDescription: \"Simple one-step workflow.\",\n      On:          worker.Events(\"simple\"),\n\t\t\tSteps: []*worker.WorkflowStep{\n\t\t\t\tworker.Fn(func(ctx worker.HatchetContext) (result *stepOutput, err error) {\n\t\t\t\t\tfmt.Println(\"executed step 1\")\n\n\t\t\t\t\treturn &stepOutput{}, nil\n\t\t\t\t},\n\t\t\t\t).\n        SetName(\"step-one\"),\n\t\t\t},\n\t\t},\n\t)\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error registering workflow: %v\", err))\n\t}\n\n\tinterruptCtx, cancel := cmdutils.InterruptContextFromChan(cmdutils.InterruptChan())\n\tdefer cancel()\n\n\tcleanup, err := w.Start()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"error starting worker: %v\", err))\n\t}\n\n\t<-interruptCtx.Done()\n\tif err := cleanup(); err != nil {\n\t\tpanic(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Releasing Slot in Python Hatchet Workflow\nDESCRIPTION: This Python snippet demonstrates how to release a slot manually within a Hatchet workflow step. After a resource-intensive process (simulated by `time.sleep(10)`), the `context.release_slot()` method is called to allow other steps to run concurrently. The step continues its execution with non-resource-intensive tasks. Requires the `hatchet` and `time` modules.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/advanced/manual-slot-release.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:create\"])\n    @hatchet.step()\n    def step1(self, context: Context):\n        print('RESOURCE INTENSIVE PROCESS')\n        time.sleep(10)\n        # Release the slot after the resource-intensive process, so that other steps can run\n        context.release_slot()\n        print(\"NON RESOURCE INTENSIVE PROCESS\")\n        return {\"status\": \"success\"}\n```\n\n----------------------------------------\n\nTITLE: Defining UpdateTenantInviteRequest Interface\nDESCRIPTION: This code snippet defines the `UpdateTenantInviteRequest` interface in TypeScript. It includes a single property, `role`, which is of type `TenantMemberRole`.  This interface is used to specify the data required when updating a tenant invite.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UpdateTenantInviteRequest.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * # Interface: UpdateTenantInviteRequest\n *\n * [APIContracts](../modules/APIContracts.md).UpdateTenantInviteRequest\n *\n * ## Table of contents\n *\n * ### Properties\n *\n * - [role](APIContracts.UpdateTenantInviteRequest.md#role)\n *\n * ## Properties\n *\n * ### role\n *\n * • **role**: [`TenantMemberRole`](../enums/APIContracts.TenantMemberRole.md)\n *\n * The role of the user in the tenant.\n *\n * #### Defined in\n *\n * [src/clients/rest/generated/data-contracts.ts:185](https://github.com/hatchet-dev/hatchet/blob/af21f67/typescript-sdk/src/clients/rest/generated/data-contracts.ts#L185)\n```\n\n----------------------------------------\n\nTITLE: id Property Example\nDESCRIPTION: This example demonstrates the format of the `id` property within the APIResourceMeta interface. It represents the unique identifier of the resource as a UUID string.  The string must be 36 characters long and conform to the UUID format.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIResourceMeta.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"bb214807-246e-43a5-a25d-41761d1cff9e\"\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet Client Namespace Environment Variable (Bash)\nDESCRIPTION: This code snippet demonstrates how to set the `HATCHET_CLIENT_NAMESPACE` environment variable in a Bash shell. This variable is used to isolate events and workflows for different developers working within the same Hatchet tenant, creating separate worker groups for each developer. This is a crucial step for leveraging Hatchet's namespace feature for local development.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/environments.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport HATCHET_CLIENT_NAMESPACE=\"developer-initials\"\n```\n\n----------------------------------------\n\nTITLE: Defining User Interface Properties in TypeScript\nDESCRIPTION: This TypeScript code defines the `User` interface properties: `email` (string, with email format), `emailVerified` (boolean), `metadata` (APIResourceMeta), and an optional `name` (string). The interface is part of the `APIContracts` module. This interface describes the structure of a user object within the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.User.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: User\n */\n\n/**\n * email: `string`\n *\n * emailVerified: `boolean`\n *\n * metadata: [`APIResourceMeta`](APIContracts.APIResourceMeta.md)\n *\n * name?: `string`\n */\n```\n\n----------------------------------------\n\nTITLE: TenantMember.metadata Property\nDESCRIPTION: Defines the metadata property of the TenantMember interface. This property is of type APIResourceMeta, which likely contains information about the resource's creation and modification timestamps, and potentially other metadata.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantMember.md#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * metadata: [`APIResourceMeta`](APIContracts.APIResourceMeta.md)\n */\n```\n\n----------------------------------------\n\nTITLE: Querying Events from a Simple Events Table in Postgres\nDESCRIPTION: This SQL query retrieves events from the `simple_events` table based on `resource_id` and `tenant_id`, ordered by the event `id`. It's optimized for querying events for a specific resource within a tenant. It assumes the existence of the `simple_events` table.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_1\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM simple_events\nWHERE resource_id = $1 AND tenant_id = $2\nORDER BY id ASC;\n```\n\n----------------------------------------\n\nTITLE: Hatchet Worker in Typescript\nDESCRIPTION: This TypeScript code defines a Hatchet worker that registers a simple workflow. The workflow is triggered by the `user:create` event and contains a single step that logs a message and returns a success result. It depends on the `@hatchet-dev/typescript-sdk` and `dotenv` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\nimport dotenv from \"dotenv\";\n\ndotenv.config();\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"first-typescript-workflow\",\n  description: \"This is my first workflow\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\n          \"starting step1 with the following input\",\n          ctx.workflowInput(),\n        );\n\n        return {\n          result: \"success!\",\n        };\n      },\n    },\n  ],\n};\n\nconst worker = hatchet.worker(\"my-worker\");\nawait worker.registerWorkflow(workflow);\nworker.start();\n```\n\n----------------------------------------\n\nTITLE: Checking Worker Health via cURL\nDESCRIPTION: This command checks the health of a Hatchet worker by sending a request to the /health endpoint. It expects the worker to be running on localhost:8001 with the healthcheck enabled. The expected response is a JSON object with a \"status\" field set to \"HEALTHY\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-healthchecks.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl localhost:8001/health\n\n{\"status\": \"HEALTHY\"}\n```\n\n----------------------------------------\n\nTITLE: Setting CloudKMS Key URI for Hatchet Server Encryption\nDESCRIPTION: This snippet shows how to set the `SERVER_ENCRYPTION_CLOUDKMS_KEY_URI` environment variable with the Key URI obtained from CloudKMS.  It specifies the GCP project, location, keyring name, and key name.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nSERVER_ENCRYPTION_CLOUDKMS_KEY_URI=gcp-kms://projects/<PROJECT>/locations/global/keyRings/development/cryptoKeys/development\n```\n\n----------------------------------------\n\nTITLE: Importing React components from Nextra\nDESCRIPTION: This snippet imports several UI components from the 'nextra/components' library. These components are used to construct the user interface of the page, including Callout, Card, Cards, Steps, and Tabs.  These components are likely used to display information and guide users through the setup process.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/tabs.mdx#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { Callout, Card, Cards, Steps, Tabs } from \"nextra/components\";\n```\n\n----------------------------------------\n\nTITLE: Retrieving Workflow Version Definition using Hatchet SDK in Python\nDESCRIPTION: This snippet demonstrates how to use the Hatchet SDK's Workflow API to retrieve a workflow version definition. It initializes an API client and then uses it to create a `WorkflowApi` instance.  It calls `workflow_version_get_definition` with the workflow ID and optionally a version. It then prints the API response or any exceptions that occur.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    workflow = 'workflow_example' # str | The workflow id\n    version = 'version_example' # str | The workflow version. If not supplied, the latest version is fetched. (optional)\n\n    try:\n        # Get workflow version definition\n        api_response = api_instance.workflow_version_get_definition(workflow, version=version)\n        print(\"The response of WorkflowApi->workflow_version_get_definition:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_version_get_definition: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet client file\nDESCRIPTION: Creates an empty file `hatchet-client.ts` in the `src` directory. This file will contain the Hatchet client initialization code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/ts.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntouch src/hatchet-client.ts\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Interface Definition\nDESCRIPTION: Defines the structure of the `TenantInvite` interface, outlining the properties needed for inviting a user to a tenant. It includes properties such as `email` (the user's email), `expires` (invite expiration time), `metadata` (additional data), `role` (user's role in the tenant), `tenantId` (the tenant's ID), and `tenantName` (the tenant's name, optional).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: TenantInvite\n */\n\n/**\n * The email of the user to invite.\n */\n/**\n * The time that this invite expires.\n *\n * @format date-time\n */\n/**\n * The role of the user in the tenant.\n */\n/**\n * The tenant id associated with this tenant invite.\n */\n/**\n * The tenant name for the tenant.\n */\n```\n\n----------------------------------------\n\nTITLE: Streaming Events by Metadata (Go)\nDESCRIPTION: This Go snippet generates a stream key and value, runs a Hatchet workflow with the stream key included in the run metadata using `client.WithRunMetadata`, and then streams events using `c.Subscribe().StreamByAdditionalMetadata`. The received events are printed to the console.  It relies on the `hatchet` Go client and the `fmt` and `math/rand` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_12\n\nLANGUAGE: go\nCODE:\n```\n// Generate a random stream key to use to track all\n// stream events for this workflow run.\nstreamKey := \"streamKey\"\nstreamValue := fmt.Sprintf(\"stream-event-%d\", rand.Intn(100)+1)\n\n// Specify the stream key as additional metadata\n// when running the workflow.\n\n// This key gets propagated to all child workflows\n// and can have an arbitrary property name.\n_, err = c.Admin().RunWorkflow(\"stream-event-workflow\", &streamEventInput{\n    Index: 0,\n  },\n    client.WithRunMetadata(map[string]interface{}{\n    streamKey: streamValue,\n  }),\n)\n\nif err != nil {\n  panic(err)\n}\n\n// Stream all events for the additional meta key value\nerr = c.Subscribe().StreamByAdditionalMetadata(interruptCtx, streamKey, streamValue, func(event client.StreamEvent) error {\n  fmt.Println(string(event.Message))\n  return nil\n})\n```\n\n----------------------------------------\n\nTITLE: Dockerfile for GPU Workload\nDESCRIPTION: This Dockerfile sets up an environment for running GPU-accelerated applications. It starts from an Ubuntu 22.04 base image, installs CUDA and necessary libraries like `cuda-nvcc`, `libcublas`, and `libcudnn`. It then sets the working directory, copies application files, and defines the entrypoint for the application.  This allows the user to execute python code in the container.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Base image\nFROM ubuntu:22.04\n\n# Install CUDA and required libraries\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    cuda-nvcc-12-2 \\\n    libcublas-12-2 \\\n    libcudnn8 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Your application setup\nWORKDIR /app\nCOPY . .\n\n# Application entrypoint\nCMD [\"python\", \"worker.py\"]\n```\n\n----------------------------------------\n\nTITLE: Pushing Bulk Events with Hatchet Client (Typescript)\nDESCRIPTION: This snippet demonstrates how to push multiple events to Hatchet in a single request using the Typescript SDK. It initializes a Hatchet client, defines an array of events with payloads and metadata, and then uses the `bulkPush` method to send the events to the Hatchet server. This approach optimizes throughput compared to sending events individually.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst events = [\n  {\n    payload: { test: \"test1\" },\n    additionalMetadata: { user_id: \"user1\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test2\" },\n    additionalMetadata: { user_id: \"user2\", source: \"test\" },\n  },\n  {\n    payload: { test: \"test3\" },\n    additionalMetadata: { user_id: \"user3\", source: \"test\" },\n  },\n];\n\nhatchet.event.bulkPush(\"user:create\", events);\n```\n\n----------------------------------------\n\nTITLE: Hatchet Python Client Class Reference\nDESCRIPTION: This snippet documents the `hatchet.Hatchet` class, outlining its various members and available methods. These members provide access to different aspects of the Hatchet service, such as cron jobs, events, logs, metrics, rate limits, runs, scheduled workflows, workers, and workflows. It also includes access to tenant ID, namespace, worker, workflow, task, and durable task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/python/docs/client.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n::: hatchet.Hatchet\n    options:\n      members:\n        - cron\n        - event\n        - logs\n        - metrics\n        - rate_limits\n        - runs\n        - scheduled\n        - workers\n        - workflows\n        - tenant_id\n        - namespace\n        - worker\n        - workflow\n        - task\n        - durable_task\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration\nDESCRIPTION: This YAML file defines the Docker Compose configuration for deploying Hatchet. It includes services for PostgreSQL, RabbitMQ, Hatchet Migrate, Hatchet Admin, Hatchet Engine, Hatchet API, Hatchet Frontend, and Caddy. It configures the dependencies, ports, volumes, and environment variables required for each service to function correctly.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nservices:\n  postgres:\n    image: postgres:15.6\n    command: postgres -c 'max_connections=200'\n    restart: always\n    hostname: \"postgres\"\n    environment:\n      - POSTGRES_USER=hatchet\n      - POSTGRES_PASSWORD=hatchet\n      - POSTGRES_DB=hatchet\n    ports:\n      - \"5435:5432\"\n    volumes:\n      - hatchet_postgres_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -d hatchet -U hatchet\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n  rabbitmq:\n    image: \"rabbitmq:3-management\"\n    hostname: \"rabbitmq\"\n    ports:\n      - \"5673:5672\" # RabbitMQ\n      - \"15673:15672\" # Management UI\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n    volumes:\n      - \"hatchet_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf\" # Configuration file mount\n    healthcheck:\n      test: [\"CMD\", \"rabbitmqctl\", \"status\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n  migration:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-migrate:latest\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n  setup-config:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-admin:latest\n    command: /hatchet/hatchet-admin quickstart --skip certs --generated-config-dir /hatchet/config --overwrite=false\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@rabbitmq:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost:8080\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n    depends_on:\n      migration:\n        condition: service_completed_successfully\n      rabbitmq:\n        condition: service_healthy\n      postgres:\n        condition: service_healthy\n  hatchet-engine:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-engine:latest\n    command: /hatchet/hatchet-engine --config /hatchet/config\n    restart: on-failure\n    depends_on:\n      setup-config:\n        condition: service_completed_successfully\n      migration:\n        condition: service_completed_successfully\n    ports:\n      - \"7077:7070\"\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n  hatchet-api:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-api:latest\n    command: /hatchet/hatchet-api --config /hatchet/config\n    restart: on-failure\n    depends_on:\n      setup-config:\n        condition: service_completed_successfully\n      migration:\n        condition: service_completed_successfully\n    environment:\n      DATABASE_URL: \"postgres://hatchet:hatchet@postgres:5432/hatchet\"\n    volumes:\n      - hatchet_certs:/hatchet/certs\n      - hatchet_config:/hatchet/config\n  hatchet-frontend:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-frontend:latest\n  caddy:\n    image: caddy:2.7.6-alpine\n    ports:\n      - 8080:8080\n    volumes:\n      - ./Caddyfile:/etc/caddy/Caddyfile\n\nvolumes:\n  hatchet_postgres_data:\n  hatchet_rabbitmq_data:\n  hatchet_rabbitmq.conf:\n  hatchet_config:\n  hatchet_certs:\n```\n\n----------------------------------------\n\nTITLE: Executing pg-events Simple Utility\nDESCRIPTION: This bash command executes the `pg-events` utility with the `simple` subcommand. The `-t` flag specifies the number of tenants, `-r` specifies the number of resource IDs per tenant, and `-c` specifies the number of events per tenant and resource tuple.  It populates the `simple_events` table for performance testing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npg-events simple -t 10 -r 100000 -c 10\n```\n\n----------------------------------------\n\nTITLE: Port Forwarding to Hatchet Engine\nDESCRIPTION: This script sets up port forwarding to the Hatchet engine pod in the Kubernetes cluster. It retrieves the pod name and container port dynamically and then uses `kubectl` to forward traffic from localhost:7070 to the engine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nexport NAMESPACE=hatchet # TODO: change if you modified the namespace\nexport POD_NAME=$(kubectl get pods --namespace $NAMESPACE -l \"app.kubernetes.io/name=hatchet-engine,app.kubernetes.io/instance=hatchet\" -o jsonpath=\"{.items[0].metadata.name}\")\nexport CONTAINER_PORT=$(kubectl get pod --namespace $NAMESPACE $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\nkubectl --namespace $NAMESPACE port-forward $POD_NAME 7070:$CONTAINER_PORT\n```\n\n----------------------------------------\n\nTITLE: Releasing Slot in Go Hatchet Workflow\nDESCRIPTION: This Go snippet demonstrates the manual slot release feature using the `ctx.ReleaseSlot()` method within a Hatchet worker function. It mimics a resource-intensive operation with `time.Sleep(10 * time.Second)` before releasing the slot, allowing other steps to proceed concurrently. Requires the `worker` and `fmt` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/advanced/manual-slot-release.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nfunc StepOne(ctx worker.HatchetContext) (result \\*stepOneOutput, err error) {\n  fmt.Println(\"RESOURCE INTENSIVE PROCESS\")\n  time.Sleep(10 * time.Second)\n  // Release the slot after the resource-intensive process, so that other steps can run\n  ctx.ReleaseSlot()\n  fmt.Println(\"NON RESOURCE INTENSIVE PROCESS\")\n  return &stepOneOutput{\n    Message: \"step1 results\",\n  }, nil\n},\n\n```\n\n----------------------------------------\n\nTITLE: Scheduling a Workflow using Hatchet SDK in Typescript\nDESCRIPTION: This snippet shows how to schedule a workflow to run immediately using the `scheduleWorkflow` method from the Hatchet TypeScript SDK. It requires the `@hatchet-dev/typescript-sdk` package. The `workflowName` and an object containing an array of `Date` objects are passed to the function. In this case, the current time (`now`) is used as the scheduled time.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/run-workflow-schedule.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst now = new Date();\n\nhatchet.admin.scheduleWorkflow(\"workflowName\", {\n  schedules: [now],\n});\n```\n\n----------------------------------------\n\nTITLE: Defining CreateTenantRequest Interface\nDESCRIPTION: This TypeScript interface defines the structure of the `CreateTenantRequest` object. It specifies the required properties for creating a tenant, including `name` and `slug`, both of which are strings. This interface is used when creating a new tenant through the Hatchet API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.CreateTenantRequest.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface CreateTenantRequest {\n  name: string;\n  slug: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Tenant Interface - TypeScript\nDESCRIPTION: This code snippet defines the `Tenant` interface, which is part of the `APIContracts` module in the Hatchet TypeScript SDK. It outlines the structure of a tenant object, specifying properties like `metadata` (of type `APIResourceMeta`), `name` (a string), and `slug` (a string).  This interface is used for representing tenant data within the Hatchet platform.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.Tenant.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Tenant {\n  metadata: APIResourceMeta;\n  name: string;\n  slug: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Worker with max_runs in Python\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet worker in Python with a `max_runs` parameter to limit the number of concurrent step runs. The `max_runs` parameter specifies the maximum number of concurrent steps the worker can execute across all workflows. It requires the `hatchet` library to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/overview.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nworker = hatchet.worker(\"my-worker\", max_runs=5)\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Typescript\nDESCRIPTION: This snippet points to an external Typescript file (`src/v1/examples/simple/schedule.ts`) and targets the section \"Listing Scheduled Runs\". It's designed to showcase how to list schedules using the Hatchet SDK for Typescript, probably involving the `SimpleTs` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_7\n\nLANGUAGE: Typescript\nCODE:\n```\n<GithubSnippet src={SimpleTs} target=\"Listing Scheduled Runs\" />\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Workflow\nDESCRIPTION: This code snippet demonstrates how to create a basic two-step workflow using the Hatchet TypeScript SDK. It defines the workflow's ID, description, trigger event ('user:create'), and two steps. Step 2 depends on step 1, ensuring sequential execution. The steps log messages to the console and return simple objects.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/workflow.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport Hatchet, { Workflow } from \"@hatchet-dev/typescript-sdk\";\n\nconst hatchet = Hatchet.init();\n\nconst workflow: Workflow = {\n  id: \"example\",\n  description: \"test\",\n  on: {\n    event: \"user:create\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: (ctx) => {\n        console.log(\"executed step1!\");\n        return { step1: \"step1\" };\n      },\n    },\n    {\n      name: \"step2\",\n      parents: [\"step1\"],\n      run: (ctx) => {\n        console.log(\"executed step2!\");\n        return { step2: \"step2\" };\n      },\n    },\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Create Project Directory and Navigate into it - Bash\nDESCRIPTION: This command creates a new directory named `hatchet-tutorial` and then changes the current working directory to the newly created directory. This is the first step in setting up a new Hatchet project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hatchet-tutorial && cd hatchet-tutorial\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Input (Python)\nDESCRIPTION: This code snippet demonstrates how to access the workflow input within a Hatchet step defined in Python.  The `context.workflow_input()` method retrieves the input as a JSON object.  This input can then be used to perform operations within the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef my_step(context: Context) -> dict:\n    data = context.workflow_input()\n    # Perform some operation\n    return output\n```\n\n----------------------------------------\n\nTITLE: Defining a simple Hatchet workflow in Python\nDESCRIPTION: This Python code defines a basic Hatchet workflow with one step. It uses the `hatchet-sdk` to define the workflow and registers it with a worker. Dependencies: hatchet-sdk, python-dotenv.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow(name=\"first-python-workflow\",on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        return {\n            \"result\": \"success\"\n        }\n\nif __name__ == \"__main__\":\n\tworker = hatchet.worker('first-worker')\n\tworker.register_workflow(MyWorkflow())\n\n\tworker.start()\n```\n\n----------------------------------------\n\nTITLE: Change Directory to Project\nDESCRIPTION: This command changes the current directory to the cloned Hatchet Python quickstart project. This allows users to execute subsequent commands within the project's context.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/py.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd hatchet-python-quickstart\n```\n\n----------------------------------------\n\nTITLE: Defining User and Profile Models with One-to-One Relation in Prisma (Incorrect)\nDESCRIPTION: This code demonstrates an attempt to define a mandatory one-to-one relationship between `User` and `Profile` models in Prisma, which results in an error due to both sides defining the `references` argument. The snippet is used to illustrate a limitation of Prisma regarding enforcing mandatory one-to-one relationships at the database level.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_4\n\nLANGUAGE: txt\nCODE:\n```\nmodel User {\n  id       Int    @id @default(autoincrement())\n  profile  Profile @relation(fields: [profileId], references: [id])\n  profileId Int    @unique\n}\n\nmodel Profile {\n  id     Int    @id @default(autoincrement())\n  user   User   @relation(fields: [userId], references: [id])\n  userId Int    @unique\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limit (Python)\nDESCRIPTION: Defines a Hatchet workflow with concurrency limits on a per-user basis, allowing a maximum of 5 concurrent runs per user ID. The limit strategy is set to GROUP_ROUND_ROBIN. Includes a rate-limited task that restricts execution to 10 tasks per minute per user.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# limit concurrency on a per-user basis\nflow_control_workflow = hatchet.workflow(\n  name=\"FlowControlWorkflow\",\n  concurrency=ConcurrencyExpression(\n    expression=\"input.user_id\",\n    max_runs=5,\n    limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n  ),\n  input_validator=FlowControlInput,\n)\n\n# rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit\n@flow_control_workflow.task(\n    rate_limits=[\n        RateLimit(\n            dynamic_key=\"input.user_id\",\n            units=1,\n            limit=10,\n            duration=RateLimitDuration.MINUTE,\n        )\n    ]\n)\ndef rate_limit_task(input: FlowControlInput, ctx: Context) -> None:\n    print(\"executed rate_limit_task\")\n```\n\n----------------------------------------\n\nTITLE: List Pull Requests for Workflow Run in Python\nDESCRIPTION: This code snippet demonstrates how to list pull requests associated with a specific workflow run for a given tenant using the Hatchet SDK.  It configures the API client, authenticates, creates a WorkflowApi instance, and then calls the workflow_run_list_pull_requests method with the tenant and workflow run ID.  It depends on the hatchet_sdk.clients.rest library and requires setting up authentication via environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.list_pull_requests_response import ListPullRequestsResponse\nfrom hatchet_sdk.clients.rest.models.pull_request_state import PullRequestState\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n```\n\n----------------------------------------\n\nTITLE: Defining Step Timeout in Python\nDESCRIPTION: This snippet demonstrates how to define a timeout for a specific Hatchet step using Python. The `timeout` parameter in the `@hatchet.step` decorator specifies the maximum execution time for the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/timeouts.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(timeout=\"30s\")\ndef timeout(self, context):\n    try:\n        print(\"started step2\")\n        time.sleep(5)\n        print(\"finished step2\")\n    except Exception as e:\n        print(\"caught an exception: \" + str(e))\n        raise e\n```\n\n----------------------------------------\n\nTITLE: Configuring Frontend Ingress with Nginx and Cert-Manager (YAML)\nDESCRIPTION: This snippet configures an Nginx ingress for the Hatchet Frontend and API services, enabling SSL with cert-manager. It defines annotations for proxy settings, timeouts, and certificate issuance. It specifies hostnames, paths, and backend service details for routing traffic to the frontend and API services.  The API is accessible under the `/api` path and the frontend under `/`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/networking.mdx#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nfrontend:\n  ingress:\n    enabled: true\n    ingressClassName: nginx\n    labels: {}\n    annotations:\n      nginx.ingress.kubernetes.io/proxy-body-size: 50m\n      nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n      nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n      nginx.ingress.kubernetes.io/proxy-connect-timeout: \"60\"\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    hosts:\n      - host: hatchet.example.com\n        paths:\n          - path: /api\n            backend:\n              serviceName: hatchet-api\n              servicePort: 8080\n          - path: /\n            backend:\n              serviceName: hatchet-frontend\n              servicePort: 8080\n    tls:\n      - secretName: hatchet-api\n        hosts:\n          - hatchet.example.com\n```\n\n----------------------------------------\n\nTITLE: Change Directory\nDESCRIPTION: Navigates the command line to the specified project directory. This step is essential to ensure subsequent commands are executed within the correct project context.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/go.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd path-to-your-project\n```\n\n----------------------------------------\n\nTITLE: Defining GPU Workflow with Hatchet (Python)\nDESCRIPTION: This Python code defines a Hatchet workflow that utilizes a GPU.  It specifies the GPU type, the number of GPUs, the memory allocation, the number of replicas, and the regions where the workflow can run. It uses the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, Context\n\nhatchet = Hatchet()\n\n@hatchet.workflow()\nclass GPUWorkflow:\n    @hatchet.step(\n        compute=Compute(\n            gpu_kind=\"a100-80gb\",\n            gpus=1,\n            memory_mb=163840,\n            num_replicas=1,\n            regions=[\"ams\"]\n        )\n    )\n    def train_model(self, context: Context):\n        # GPU-accelerated code here\n        pass\n```\n\n----------------------------------------\n\nTITLE: Implementing Randomized Sleep Duration in Go\nDESCRIPTION: This Go code snippet introduces a randomized sleep duration to worker setup to prevent thundering herd problems during queue polling. It calculates the sleep duration based on the worker ID, polling interval, and the number of workers. This helps distribute the load and reduce contention when workers are polling for new tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_6\n\nLANGUAGE: go\nCODE:\n```\n// sleep for random duration between 0 and polling interval to avoid thundering herd\nsleepDuration := time.Duration(id) * interval / time.Duration(numWorkers)\nlog.Printf(\"(worker %d) sleeping for %v\\n\", id, sleepDuration)\ntime.Sleep(sleepDuration)\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Run ID - Hatchet TypeScript\nDESCRIPTION: This snippet demonstrates how to obtain the workflow run ID after initiating a workflow. It uses the `runWorkflow` method to start a workflow and then calls `getWorkflowRunId` on the returned object. Requires the `@hatchet-dev/typescript-sdk` package to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/get-workflow-results.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflowRun = hatchet.admin.runWorkflow(\"ManualTriggerWorkflow\", {\n  test: \"test\",\n});\n\nconst workflowRunId = await workflowRun.getWorkflowRunId();\n\nconsole.log(`spawned workflow run: ${workflowRunId}`);\n```\n\n----------------------------------------\n\nTITLE: Example lastHeartbeatAt Value - TypeScript\nDESCRIPTION: This code snippet provides an example value for the `lastHeartbeatAt` property of the `Worker` interface. It demonstrates the expected date-time format (ISO 8601) for the last heartbeat timestamp. This format is crucial for tracking worker availability and health within the Hatchet system.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.Worker.md#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\n\"2022-12-13T20:06:48.888Z\"\n```\n\n----------------------------------------\n\nTITLE: Creating Child Logger for Workflow (Python)\nDESCRIPTION: This snippet demonstrates how to create a child logger within a workflow file.  It imports the Hatchet client and creates a child logger using `logging.getLogger(__name__)`.  This ensures that logs are properly associated with the workflow. Dependencies: hatchet_sdk, logging, client.py.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/logging.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport logging\nfrom client import hatchet\n\nlogger = logging.getLogger(__name__)\n\n@hatchet.workflow()\nclass LoggingWorkflow:\n    @hatchet.step()\n    def step1(self, context: Context):\n        for i in range(12):\n            logger.info(\"executed step1 - {}\".format(i))\n            time.sleep(1)\n        return {\"status\": \"success\"}\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Worker with maxRuns in Typescript\nDESCRIPTION: This snippet shows how to initialize a Hatchet worker in Typescript, configuring the `maxRuns` parameter to limit the number of concurrent step runs.  The `maxRuns` option specifies the maximum number of concurrent steps that the worker can execute across all workflows.  This requires the `@hatchet.dev/sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/overview.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst worker = hatchet.worker(\"my-worker\", {\n  maxRuns: 5,\n});\n```\n\n----------------------------------------\n\nTITLE: Setting environment variables\nDESCRIPTION: This sets up environment variables required for the Hatchet client, including the client token and (optionally) the OpenAI API key for Generative AI workflows. The `HATCHET_CLIENT_TLS_STRATEGY` is set to `none` which disables TLS.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nHATCHET_CLIENT_TLS_STRATEGY=none\nHATCHET_CLIENT_TOKEN=\"<token>\"\nOPENAI_API_KEY=\"<openai-key>\" # (OPTIONAL) only required to run GenAI workflows\n```\n\n----------------------------------------\n\nTITLE: Exponential Backoff in Python (GithubSnippet)\nDESCRIPTION: This section refers to a Python GithubSnippet which contains example of implementing Exponential Backoff using retries feature.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_6\n\n\n\n----------------------------------------\n\nTITLE: Setting CloudKMS Credentials JSON for Hatchet Server Encryption\nDESCRIPTION: This snippet shows how to set the `SERVER_ENCRYPTION_CLOUDKMS_CREDENTIALS_JSON` environment variable with the JSON content of a service account that has encrypt/decrypt permissions on CloudKMS.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nSERVER_ENCRYPTION_CLOUDKMS_CREDENTIALS_JSON='{...}'\n```\n\n----------------------------------------\n\nTITLE: Looping: Spawning Child Workflows in Python\nDESCRIPTION: This Python snippet demonstrates how to spawn child workflows within a loop inside a parent workflow step. It uses the `context.spawn_workflow` method to create multiple child workflows with dynamic input and keys. The parent workflow is decorated with `@hatchet.workflow` and the step with `@hatchet.step`. It requires the `hatchet` library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\"fanout:create\")\nclass Parent:\n    @hatchet.step()\n    def spawn(self, context: Context):\n        for i in range(10):\n          context.spawn_workflow(\n            \"Child\", {\"a\": str(i)}, key=f\"child{i}\"\n          )\n\n        return {}\n```\n\n----------------------------------------\n\nTITLE: Selective CUDA Library Installation (Dockerfile)\nDESCRIPTION: This Dockerfile snippet demonstrates the best practice of installing only the required CUDA libraries instead of using meta-packages. This reduces the image size and potential conflicts.  It installs cuda-nvcc, libcublas, and libcudnn.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/gpu.mdx#_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\n# DO NOT use meta-packages\n# ❌ RUN apt-get install cuda-runtime-*\n\n# ✅ Install only required libraries\nRUN apt-get install -y \\\n    cuda-nvcc-12-2 \\\n    libcublas-12-2 \\\n    libcudnn8\n```\n\n----------------------------------------\n\nTITLE: Streaming Base64 Encoded Files\nDESCRIPTION: This Typescript snippet streams a base64 encoded image file from a Hatchet step context. It imports modules for file system operations and path manipulation, reads the image file, encodes it as base64 using Node.js Buffer and then streams the encoded data via `ctx.putStream`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as fs from \"fs\";\nimport * as path from \"path\";\n\nasync function step1(ctx: Context) {\n  // Get the directory of the current script\n  const scriptDir = path.dirname(__filename);\n\n  // Construct the path to the image file relative to the script's directory\n  const imagePath = path.join(scriptDir, \"image.jpeg\");\n\n  // Load the image file\n  const imageData = await fs.promises.readFile(imagePath);\n\n  // Encode the image data as base64\n  const base64Image = Buffer.from(imageData).toString(\"base64\");\n\n  // Stream the base64-encoded image data\n  ctx.putStream(base64Image);\n\n  // continue with the step run...\n  return { step1: \"results\" };\n}\n```\n\n----------------------------------------\n\nTITLE: Defining EventWorkflowRunSummary Interface (TypeScript)\nDESCRIPTION: This code defines the `EventWorkflowRunSummary` interface in TypeScript. It includes optional number properties representing the count of workflow runs in `failed`, `pending`, `running`, and `succeeded` states.  Each property is an optional number.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.EventWorkflowRunSummary.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: EventWorkflowRunSummary\n *\n * [APIContracts](../modules/APIContracts.md).EventWorkflowRunSummary\n */\n\n/**\n * @internal\n */\nexport interface EventWorkflowRunSummary {\n    /**\n     * The number of pending runs.\n     *\n     * @format int64\n     */\n    pending?: number;\n    /**\n     * The number of running runs.\n     *\n     * @format int64\n     */\n    running?: number;\n    /**\n     * The number of succeeded runs.\n     *\n     * @format int64\n     */\n    succeeded?: number;\n    /**\n     * The number of failed runs.\n     *\n     * @format int64\n     */\n    failed?: number;\n}\n```\n\n----------------------------------------\n\nTITLE: APIError Docs Link Example in TypeScript\nDESCRIPTION: Presents the optional 'docs_link' property of the APIError interface, which provides a URL to the documentation associated with the error. This allows developers to quickly access more information about the error.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIError.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"github.com/hatchet-dev/hatchet\"\n```\n\n----------------------------------------\n\nTITLE: Pulling Latest Docker Images\nDESCRIPTION: This command pulls the latest versions of the Docker images specified in the docker-compose.yml file. It allows users to update their Hatchet deployment with the newest releases.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/docker-compose.mdx#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose pull\n```\n\n----------------------------------------\n\nTITLE: Multi-Region A100-80GB Configuration in Hatchet\nDESCRIPTION: This code snippet demonstrates how to configure a `Compute` object for a multi-region deployment of A100-80GB GPUs using Hatchet. It defines the GPU type, number of GPUs, memory allocation, number of replicas, and a list of regions (`ams`, `sjc`, `syd`) where the replicas will be randomly distributed. This allows for distributed and fault-tolerant GPU workloads.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/gpu.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Multi-region A100-80GB configuration\ncompute = Compute(\n    gpu_kind=\"a100-80gb\",\n    gpus=1,\n    memory_mb=163840,\n    num_replicas=3,\n    regions=[\"ams\", \"sjc\", \"syd\"]  # Replicas will be randomly distributed\n)\n```\n\n----------------------------------------\n\nTITLE: Getting Workflow Run Result in Python\nDESCRIPTION: This code snippet demonstrates how to retrieve the result of a workflow run given a workflow run ID. It uses the `get_workflow_run` method on the `hatchet.client.admin` object to get a `WorkflowRunRef` and then awaits the `result()` method to get the final results of the workflow. The results are printed to the console.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/get-workflow-results.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet, ClientConfig\n\nhatchet = Hatchet()\n\nworkflow_run_ref = hatchet.client.admin.get_workflow_run(\n    \"5a3a617d-1200-4ee2-92e6-be4bd27ca26f\",\n)\n\nresult = await workflow_run_ref.result()\n\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Running Tests with pnpm\nDESCRIPTION: This command executes the tests for the Hatchet TypeScript SDK.  This is for verifying functionality after making changes or building.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npnpm test\n```\n\n----------------------------------------\n\nTITLE: Poetry Dependencies & Scripts Configuration\nDESCRIPTION: This section configures Poetry dependencies and scripts within the `pyproject.toml` file. It specifies the required Python version and external libraries such as `python-dotenv`, `uvicorn`, `fastapi`, `openai`, `beautifulsoup4`, `requests`, `urllib3`, and `hatchet-sdk`. It also defines executable scripts `api` and `hatchet` that start the API and workflow services, respectively. These scripts invoke the `start` functions defined in `src.api.main` and `src.workflows.main`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/project-setup.mdx#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[tool.poetry.dependencies]\npython = \"^3.8\"\npython-dotenv = \"^1.0.0\"\nuvicorn = {extras = [\"standard\"], version = \"^0.27.0\"}\nfastapi = \"^0.109.0\"\nopenai = \"^1.11.0\"\nbeautifulsoup4 = \"^4.12.3\"\nrequests = \"^2.31.0\"\nurllib3 = \"1.26.15\"\nhatchet-sdk = \"0.10.5\"\n\n[tool.poetry.scripts]\napi = \"src.api.main:start\"\nhatchet = \"src.workflows.main:start\"\n```\n\n----------------------------------------\n\nTITLE: Configuring tsconfig.json\nDESCRIPTION: This `tsconfig.json` configures the TypeScript compiler. It specifies the output directory (`outDir`), the root directory (`rootDir`), module system (`module`), target ECMAScript version (`target`), enables ES module interop (`esModuleInterop`), and enforces strict type checking (`strict`). It also includes the `src` directory and excludes `node_modules` and `dist`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"compilerOptions\": {\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"module\": \"commonjs\",\n    \"target\": \"es2020\",\n    \"esModuleInterop\": true,\n    \"strict\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Hatchet Worker\nDESCRIPTION: This snippet shows how to start a Hatchet worker after registering a workflow. It initializes the worker, registers the `workflow1`, and then calls `worker.start()` to begin processing tasks. The `worker.start()` call is recommended as the last call when running a worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/worker.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nasync function main() {\n  const worker = await hatchet.worker(\"example-worker\");\n  await worker.registerWorkflow(workflow1);\n  worker.start();\n}\n\nmain();\n```\n\n----------------------------------------\n\nTITLE: Thin Data Payload Example (JSON)\nDESCRIPTION: This JSON snippet exemplifies a 'thin' data payload in Hatchet. It includes only the essential identifier (ID) of a task. This approach minimizes payload size and enhances performance, especially in scalable, distributed environments.  Additional fields may also be present if considered critical.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"task.executed\",\n  \"timestamp\": \"2022-11-03T20:26:10.344522Z\",\n  \"data\": {\n    \"id\": \"1f81eb52-5198-4599-803e-771906343485\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: WorkflowTag Example: JSON Conversion\nDESCRIPTION: This code demonstrates how to create a WorkflowTag instance from a JSON string using `WorkflowTag.from_json()`, convert it to a JSON string using `WorkflowTag.to_json()`, convert it to a dictionary using `to_dict()`, and create a WorkflowTag instance from a dictionary using `from_dict()`. It uses the hatchet_sdk.clients.rest.models.workflow_tag module. A valid JSON string should be provided.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowTag.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_tag import WorkflowTag\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowTag from a JSON string\nworkflow_tag_instance = WorkflowTag.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowTag.to_json()\n\n# convert the object into a dict\nworkflow_tag_dict = workflow_tag_instance.to_dict()\n# create an instance of WorkflowTag from a dict\nworkflow_tag_form_dict = workflow_tag.from_dict(workflow_tag_dict)\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet SDK with poetry\nDESCRIPTION: This command adds the Hatchet SDK as a dependency to your project using Poetry, a Python dependency management and packaging tool.  Poetry manages the project's dependencies in the pyproject.toml file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/index.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npoetry add hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Example values.yaml for API Service\nDESCRIPTION: This YAML snippet provides a configuration example for the `api` service. It configures environment variables, including placeholders for authentication secrets and keys. You will need to generate secrets and keys to replace the placeholders before deployment.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/networking.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napi:\n  env:\n    # TODO: insert these values from the output of the keyset generation command\n    SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n    SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n    SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\n    SERVER_AUTH_COOKIE_DOMAIN: \"hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_URL: \"https://hatchet.example.com\" # example.com should be replaced with your domain\n    SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n    SERVER_GRPC_INSECURE: \"false\"\n    SERVER_GRPC_BROADCAST_ADDRESS: \"engine.hatchet.example.com:443\" # example.com should be replaced with your domain\n```\n\n----------------------------------------\n\nTITLE: Running Go mod tidy\nDESCRIPTION: This command downloads all the dependencies for the Go project. It is required before running the Go Hatchet worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\ngo mod tidy\n```\n\n----------------------------------------\n\nTITLE: Defining GPU Compute Configurations with Hatchet in Python\nDESCRIPTION: This snippet shows how to define a GPU compute configuration using the `Compute` class from the Hatchet SDK.  It includes parameters for CPU type, GPU type and count, CPU count, memory allocation, number of instances, and deployment regions. GPU compute support has limited region availability. Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/managed-compute.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ngpu_compute = Compute(\n    cpu_kind=\"shared\",\n    gpu_kind=\"a100\",\n    gpus=1,\n    cpus=1,\n    memory_mb=1024,\n    num_replicas=1,\n    regions=[\"ewr\"],\n)\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: email\nDESCRIPTION: Defines the `email` property of the `TenantInvite` interface.  This property is a string representing the email address of the user being invited to the tenant. This is a required property for the interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * The email of the user to invite.\n */\nemail: `string`\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: tenantId\nDESCRIPTION: Defines the `tenantId` property of the `TenantInvite` interface. This property is a string representing the ID of the tenant that the user is being invited to. This is a required property for the interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_5\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * The tenant id associated with this tenant invite.\n */\ntenantId: `string`\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Workflow - Typescript\nDESCRIPTION: This snippet shows how to initialize a Hatchet workflow using the Typescript SDK. It imports the Hatchet client, defines types for workflow input and output, and then creates a workflow named 'simple'. It uses generic types to strongly type the input and output of the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { hatchet } from \"../hatchet-client\";\n\ntype DagInput = {\n  Message: string;\n};\n\ntype DagOutput = {\n  reverse: {\n    Original: string;\n    Transformed: string;\n  };\n};\n\nexport const simple = hatchet.workflow<DagInput, DagOutput>({\n  name: \"simple\",\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Task Table with Enum in Postgres\nDESCRIPTION: This SQL code defines a custom enum type `TaskStatus` and creates a table named `tasks` to store information about tasks in a queue. The table includes fields for ID, creation timestamp, status, arguments, and a group key for fair queueing.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_0\n\nLANGUAGE: sql\nCODE:\n```\n-- CreateEnum\nCREATE TYPE \"TaskStatus\" AS ENUM (\n    'QUEUED',\n    'RUNNING',\n    'SUCCEEDED',\n    'FAILED',\n    'CANCELLED'\n);\n\n-- CreateTable\nCREATE TABLE\n    tasks (\n        id BIGSERIAL NOT NULL,\n        created_at timestamp,\n        status \"TaskStatus\" NOT NULL,\n        args jsonb,\n        PRIMARY KEY (id)\n    );\n```\n\n----------------------------------------\n\nTITLE: Configuring Step Retries in Go\nDESCRIPTION: This code snippet illustrates how to configure step-level retries in a Hatchet workflow using Go. It uses the `worker` package to define a step function with a name, retry count, and timeout. Dependencies: `worker` package (likely part of the Hatchet Go SDK).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nSteps: []*worker.WorkflowStep{\n  worker.Fn(func(ctx worker.HatchetContext) (result *stepOneOutput, err error) {\n    continue\n  }).SetName(\"step1\").SetRetries(3).SetTimeout(\"30s\"),\n},\n```\n\n----------------------------------------\n\nTITLE: Applying Kubernetes Secret\nDESCRIPTION: These commands create a namespace for Hatchet and apply the generated secret YAML file to the Kubernetes cluster. Requires `kubectl` to be configured and connected to a Kubernetes cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nkubectl create namespace hatchet\nkubectl apply -f hatchet-secret.yaml\n```\n\n----------------------------------------\n\nTITLE: Subscribing to Hatchet Event Stream with useEffect\nDESCRIPTION: This useEffect hook subscribes to the Hatchet event stream using EventSource API to receive real-time updates for a specific workflow run identified by 'openRequest'. It parses incoming events and updates the React component's state with status messages, and the final response.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nuseEffect(() => {\n  if (!openRequest) return;\n\n  const sse = new EventSource(`${API_URL}/message/${openRequest}`, {\n    withCredentials: true,\n  });\n\n  function getMessageStream(data: any) {\n    console.log(data);\n    if (data === null) return;\n    if (data.payload?.status) {\n      setStatus(data.payload?.status);\n    }\n    if (data.payload?.message) {\n      setMessages((prev) => [\n        ...prev,\n        {\n          role: \"assistant\",\n          content: data.payload.message,\n          messageId: data.messageId,\n        },\n      ]);\n      setOpenRequest(undefined);\n    }\n  }\n\n  sse.onmessage = (e) => getMessageStream(JSON.parse(e.data));\n\n  sse.onerror = () => {\n    setOpenRequest(undefined);\n    sse.close();\n  };\n\n  return () => {\n    setOpenRequest(undefined);\n    sse.close();\n  };\n}, [openRequest]);\n```\n\n----------------------------------------\n\nTITLE: Mounting Environment Variables from Secrets in YAML\nDESCRIPTION: This YAML configuration shows how to mount the `DATABASE_URL` environment variable from a Kubernetes secret. It defines the secret name and key for both the `hatchet-api` and `hatchet-engine` deployments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-external-database.mdx#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nhatchet-api:\n  deploymentEnvFrom:\n    - secretRef:\n        name: hatchet-api-secrets\n        key: DATABASE_URL\n\nhatchet-engine:\n  deploymentEnvFrom:\n    - secretRef:\n        name: hatchet-api-secrets\n        key: DATABASE_URL\n```\n\n----------------------------------------\n\nTITLE: Setting Default Engine Version - Environment Variable\nDESCRIPTION: This snippet demonstrates how to set the default engine version for new tenants in self-hosted Hatchet instances. It involves setting the `SERVER_DEFAULT_ENGINE_VERSION` environment variable to `V1`.  This ensures that all new tenants created will use the v1 engine by default.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-engine.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nSERVER_DEFAULT_ENGINE_VERSION=V1\n```\n\n----------------------------------------\n\nTITLE: WorkflowVersionDefinition Example\nDESCRIPTION: This code snippet demonstrates how to create an instance of the WorkflowVersionDefinition model from a JSON string, convert it to a dictionary, and then create a new instance from the dictionary using the hatchet-sdk. The code also prints the JSON string representation of the object. It requires the hatchet_sdk package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowVersionDefinition.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_version_definition import WorkflowVersionDefinition\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowVersionDefinition from a JSON string\nworkflow_version_definition_instance = WorkflowVersionDefinition.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowVersionDefinition.to_json()\n\n# convert the object into a dict\nworkflow_version_definition_dict = workflow_version_definition_instance.to_dict()\n# create an instance of WorkflowVersionDefinition from a dict\nworkflow_version_definition_form_dict = workflow_version_definition.from_dict(workflow_version_definition_dict)\n```\n\n----------------------------------------\n\nTITLE: Example Invite String\nDESCRIPTION: Provides an example of the 'invite' property value within the RejectInviteRequest interface. The example demonstrates the expected UUID format with a length of 36 characters.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.RejectInviteRequest.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"bb214807-246e-43a5-a25d-41761d1cff9e\"\n```\n\n----------------------------------------\n\nTITLE: APIMetaAuth Usage Example in Python\nDESCRIPTION: This code snippet demonstrates how to create, serialize, and deserialize APIMetaAuth objects in Python. It shows converting between JSON strings, dictionaries, and APIMetaAuth model instances. The example uses the `hatchet_sdk` library and assumes it is installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIMetaAuth.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_meta_auth import APIMetaAuth\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIMetaAuth from a JSON string\napi_meta_auth_instance = APIMetaAuth.from_json(json)\n# print the JSON string representation of the object\nprint APIMetaAuth.to_json()\n\n# convert the object into a dict\napi_meta_auth_dict = api_meta_auth_instance.to_dict()\n# create an instance of APIMetaAuth from a dict\napi_meta_auth_form_dict = api_meta_auth.from_dict(api_meta_auth_dict)\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Typescript\nDESCRIPTION: This snippet demonstrates listing scheduled runs using the Typescript Hatchet SDK. It retrieves a list of all scheduled runs. Requires a configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nSee GithubSnippet: src/examples/scheduled-runs/programatic-schedules.ts - List\n```\n\n----------------------------------------\n\nTITLE: WorkflowList Usage Example in Python\nDESCRIPTION: This code snippet demonstrates how to create an instance of the `WorkflowList` class from a JSON string, convert it back to JSON, convert it to a dictionary, and then create another `WorkflowList` instance from that dictionary. It requires the `hatchet_sdk.clients.rest.models.workflow_list` module to be imported.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowList.md#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_list import WorkflowList\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowList from a JSON string\nworkflow_list_instance = WorkflowList.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowList.to_json()\n\n# convert the object into a dict\nworkflow_list_dict = workflow_list_instance.to_dict()\n# create an instance of WorkflowList from a dict\nworkflow_list_form_dict = workflow_list.from_dict(workflow_list_dict)\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow with Concurrency Limits (max_runs)\nDESCRIPTION: This code snippet defines a Hatchet workflow named `ConcurrencyDemoWorkflow` that limits the number of concurrent executions to 5 using the `Concurrency` configuration. The `limit_strategy` is set to `GROUP_ROUND_ROBIN` with an expression of `'default'`, meaning that the concurrency limit applies to all executions without grouping.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/fairness.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import ConcurrencyLimitStrategy\n\n@hatchet.workflow(\n    on_events=[\"concurrency-test\"],\n    concurrency=Concurrency(\n        max_runs=5,\n        limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n        expression=\"'default'\",\n    ),\n)\nclass ConcurrencyDemoWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Polling for Tasks in Go\nDESCRIPTION: This Go code snippet implements a polling mechanism to retrieve tasks from a queue. It periodically calls the `PopTasks` function to fetch tasks and then executes a handler function for each task. The loop continues until the context is cancelled.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\ntype HandleTask func(ctx context.Context, task *dbsqlc.Task)\n\nfunc poll(ctx context.Context, handleTask HandleTask) {\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn\n\t\tcase <-time.After(5 * time.Second):\n\t\t\ttasks, err := queries.PopTasks(ctx, pool, 10)\n\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"could not pop tasks: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tfor _, task := range tasks {\n\t\t\t\thandleTask(ctx, task)\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: WorkflowTriggers Usage Example\nDESCRIPTION: Demonstrates creating, serializing, and deserializing a WorkflowTriggers object using the hatchet_sdk.  It shows how to instantiate the object from a JSON string, convert it to a dictionary, and create a new object from that dictionary. The example assumes `hatchet_sdk` is installed and available.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowTriggers.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_triggers import WorkflowTriggers\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowTriggers from a JSON string\nworkflow_triggers_instance = WorkflowTriggers.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowTriggers.to_json()\n\n# convert the object into a dict\nworkflow_triggers_dict = workflow_triggers_instance.to_dict()\n# create an instance of WorkflowTriggers from a dict\nworkflow_triggers_form_dict = workflow_triggers.from_dict(workflow_triggers_dict)\n```\n\n----------------------------------------\n\nTITLE: Explain Query Plan SQL\nDESCRIPTION: This is an explain query plan of a sample SQL query. It is used to show the process of SQL execution, which is not a valid SQL code snippet. This is for demostration purposes.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/multi-tenant-queues.mdx#_snippet_12\n\nLANGUAGE: sql\nCODE:\n```\n                                                                        QUERY PLAN\n-----------------------------------------------------------------------------------------------------------------------------------------------------------\n Nested Loop  (cost=12.89..853.72 rows=100 width=77) (actual time=17.521..20.227 rows=100 loops=1)\n   CTE eligible_tasks\n     ->  Limit  (cost=0.42..10.21 rows=100 width=14) (actual time=1.669..16.365 rows=100 loops=1)\n           ->  LockRows  (cost=0.42..97842.23 rows=999484 width=14) (actual time=1.662..16.231 rows=100 loops=1)\n                 ->  Index Scan using tasks_pkey on tasks tasks_1  (cost=0.42..87847.39 rows=999484 width=14) (actual time=0.711..13.331 rows=100 loops=1)\n                       Filter: (status = 'QUEUED'::\"TaskStatus\")\n   ->  HashAggregate  (cost=2.25..3.25 rows=100 width=8) (actual time=17.299..17.497 rows=100 loops=1)\n         Group Key: eligible_tasks.id\n         Batches: 1  Memory Usage: 24kB\n         ->  CTE Scan on eligible_tasks  (cost=0.00..2.00 rows=100 width=8) (actual time=1.720..16.959 rows=100 loops=1)\n   ->  Index Scan using tasks_pkey on tasks  (cost=0.42..8.40 rows=1 width=77) (actual time=0.022..0.022 rows=1 loops=100)\n         Index Cond: (id = eligible_tasks.id)\n Planning Time: 13.979 ms\n Execution Time: 21.433 ms\n```\n\n----------------------------------------\n\nTITLE: Creating Cron Trigger Programmatically - Go\nDESCRIPTION: Creates a cron trigger programmatically using the Hatchet SDK in Go. This allows for dynamic cron schedules defined at runtime.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_7\n\nLANGUAGE: go\nCODE:\n```\nexamples/cron-programmatic/main.go\n```\n\n----------------------------------------\n\nTITLE: Example Event Data (JSON)\nDESCRIPTION: This JSON snippet represents an example event data structure with a `name` field set to `test`.  It is used as an example of workflow input data that can be accessed within a Hatchet workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"test\"\n}\n```\n\n----------------------------------------\n\nTITLE: Hatchet Buffer Settings Configuration\nDESCRIPTION: This shell script shows the configurable buffer settings in Hatchet.  These settings affect how frequently Hatchet writes data to the database. Configuring larger buffer sizes with less frequent flushes increases throughput at the expense of slightly increased latency. Includes settings for workflow runs, events, semaphore releases, and queue items.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/improving-performance.mdx#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\n# Default values if the values below are not set\nSERVER_FLUSH_PERIOD_MILLISECONDS\nSERVER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing workflow runs to the database\nSERVER_WORKFLOWRUNBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_WORKFLOWRUNBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing events to the database\nSERVER_EVENTBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_EVENTBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for releasing slots for workers\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_RELEASESEMAPHOREBUFFER_FLUSH_ITEMS_THRESHOLD\n\n# Settings for writing queue items to the database\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_PERIOD_MILLISECONDS\nSERVER_QUEUESTEPRUNBUFFER_FLUSH_ITEMS_THRESHOLD\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with Key Function (Go)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Go using a key function to define the concurrency group. It sets the maximum number of concurrent runs to 10 and uses the `ctx.WorkflowInput()` to extract the `UserId` and determines the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\nimport (\n  \"github.com/hatchet-dev/hatchet/pkg/client/types\"\n  \"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype MyUser struct {\n    UserId string `json:\"user_id\"`\n}\n\nfunc getConcurrencyKey(ctx worker.HatchetContext) (string, error) {\n  event := &MyUser{}\n  err := ctx.WorkflowInput(event)\n\n    if err != nil {\n        return \"\", err\n    }\n\n    return event.UserId, nil\n\n}\n\nerr = w.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"concurrency-limit-per-user\",\n        On: worker.Events(\"concurrency-test-event\"),\n        Description: \"This limits concurrency to 10 run at a time per user.\",\n        Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.GroupRoundRobin),\n        Steps: []*worker.WorkflowStep{\n            // your steps here...\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Defining Worker Interface Properties - TypeScript\nDESCRIPTION: This code snippet defines the properties of the `Worker` interface in the Hatchet TypeScript SDK. It showcases optional string array for `actions`, optional string for `lastHeartbeatAt` with `date-time` format, an `APIResourceMeta` object for `metadata`, string for `name`, and an optional array of `StepRun` objects for `recentStepRuns`. These properties provide information about the capabilities, status, and recent activity of the worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.Worker.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * The actions this worker can perform.\n */\nactions?: string[];\n\n/**\n * The time this worker last sent a heartbeat.\n *\n * @format date-time\n * @example \"2022-12-13T20:06:48.888Z\"\n */\nlastHeartbeatAt?: string;\n\nmetadata: APIResourceMeta;\n\n/**\n * The name of the worker.\n */\nname: string;\n\n/**\n * The recent step runs for this worker.\n */\nrecentStepRuns?: StepRun[];\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Worker - Python\nDESCRIPTION: This snippet defines a sticky worker in Python. It shows the structure and required configurations for setting up a worker that maintains state across multiple tasks.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/sticky-assignment.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/sticky_workers/worker.py\n```\n\n----------------------------------------\n\nTITLE: Starting Database and RabbitMQ with Task\nDESCRIPTION: This snippet uses the `task` command-line tool to start the database and RabbitMQ services required for the Hatchet project. It assumes that the `task` tool is installed and configured with the necessary tasks defined.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\ntask start-db\n```\n\n----------------------------------------\n\nTITLE: Pushing events with a traceparent\nDESCRIPTION: This code shows how to push an event to Hatchet, providing a `traceparent` in the `additional_metadata` field of the `PushEventOptions`. This allows Hatchet spans to be children of a parent span created elsewhere. Requires the `PushEventOptions` to be initialized with additional metadata.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/opentelemetry.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nhatchet.event.push(\n    \"user:create\",\n    {'userId': '1234'},\n    options=PushEventOptions(\n      additional_metadata={\n          \"traceparent\":\"00-f1aff5c5ea45185eff2a06fd5c0ed6c5-6f4116aff54d54d1-01\" ## example traceparent\n      }\n    )\n)\n```\n\n----------------------------------------\n\nTITLE: Navigate and Start React Development Server\nDESCRIPTION: These commands navigate to the 'frontend' directory and start the React development server using npm. This allows for hot-reloading and interactive development.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd frontend\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Deleting Scheduled Runs - Typescript\nDESCRIPTION: This snippet shows how to delete a scheduled run using the Typescript Hatchet SDK.  It uses either the scheduled run object or scheduled run ID. Requires an initialized Hatchet client and the scheduled run ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nSee GithubSnippet: src/examples/scheduled-runs/programatic-schedules.ts - Delete\n```\n\n----------------------------------------\n\nTITLE: Starting Hatchet Instance with Docker Compose\nDESCRIPTION: This shell command starts the Hatchet instance using Docker Compose. It assumes that a `docker-compose.yml` file exists in the current directory and uses it to define and run the necessary Docker containers.  The Hatchet instance will be accessible on port 8080.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Hatchet Worker in Python\nDESCRIPTION: This Python code defines a Hatchet worker that registers a simple workflow. The workflow is triggered by the `user:create` event and contains a single step that returns a success result. It depends on the `hatchet_sdk` and `python-dotenv` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow(name=\"first-python-workflow\",on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        return {\n            \"result\": \"success\"\n        }\n\nif __name__ == \"__main__\":\n    worker = hatchet.worker('first-worker')\n    worker.register_workflow(MyWorkflow())\n\n    worker.start()\n```\n\n----------------------------------------\n\nTITLE: Declaring Event Trigger in Python\nDESCRIPTION: This snippet demonstrates how to declare an event trigger in Python using Hatchet. It showcases the `on_events` property in the task declaration which specifies the event that will trigger the task. The example uses the `EventPy` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/run-on-event.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexamples/events/worker.py\n```\n\n----------------------------------------\n\nTITLE: Streaming Context Data - Typescript\nDESCRIPTION: This TypeScript snippet demonstrates how to stream data from a Hatchet workflow step's context to the frontend. The `ctx.putStream` method is used to send data from within the step's execution. This enables real-time updates from the background worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/rate-limits.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nasync function step1(ctx: Context) {\n    // Stream some data from the step context\n    ctx.putStream('step1 stream'); // <-- any arbitrary data under ~4mb!\n    // continue with the step run...\n    return { step1: 'step1 results!' };\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring API Key Authentication with Hatchet SDK in Python\nDESCRIPTION: This snippet configures API key authentication for the Hatchet SDK using an environment variable to store the API key. It also shows how to set a prefix for the API key (commented out).  It uses the `os` module to access the environment variable.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n```\n\n----------------------------------------\n\nTITLE: Import OnFailure Definitions\nDESCRIPTION: These TypeScript, Python and Go code snippets specify the file paths for the OnFailure examples. These definitions are used to fetch the code snippets using the `GithubSnippet` component.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/on-failure-step.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const OnFailureTs = {\n  path: \"src/examples/on-failure.ts\",\n};\n```\n\nLANGUAGE: python\nCODE:\n```\nexport const OnFailurePy = {\n  path: \"examples/on_failure/worker.py\",\n};\n```\n\nLANGUAGE: go\nCODE:\n```\nexport const OnFailureGo = {\n  path: \"examples/on-failure/main.go\",\n};\n```\n\n----------------------------------------\n\nTITLE: Running Docker Compose\nDESCRIPTION: This command starts all the services defined in the docker-compose.yml file. It uses the `docker compose up` command to create and start the containers.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/docker-compose.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ndocker compose up\n```\n\n----------------------------------------\n\nTITLE: Linking Github Repository to Workflow - Python\nDESCRIPTION: This code snippet demonstrates how to link a GitHub repository to a workflow using the Hatchet SDK. It shows how to configure the API client, set up authentication (API key or bearer token), create an instance of the WorkflowApi class, and call the workflow_update_link_github method. Error handling is included to catch exceptions during the API call. It requires the `LinkGithubRepositoryRequest` model.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.link_github_repository_request import LinkGithubRepositoryRequest\nfrom hatchet_sdk.clients.rest.models.workflow import Workflow\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    workflow = 'workflow_example' # str | The workflow id\n    link_github_repository_request = hatchet_sdk.clients.rest.LinkGithubRepositoryRequest() # LinkGithubRepositoryRequest | The input to link a github repository\n\n    try:\n        # Link github repository\n        api_response = api_instance.workflow_update_link_github(workflow, link_github_repository_request)\n        print(\"The response of WorkflowApi->workflow_update_link_github:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_update_link_github: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Configuring GROUP_ROUND_ROBIN with Key Function (Typescript)\nDESCRIPTION: This snippet demonstrates how to configure the GROUP_ROUND_ROBIN concurrency limit strategy in Typescript using a key function to define the concurrency group. It sets the maximum number of concurrent runs to 10 and uses the `ctx.workflowInput().userId` to determine the group.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/round-robin.mdx#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\nexport const concurrencyDemoWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"My workflow with concurrency control\",\n  on: {\n    event: \"concurrency-test\",\n  },\n  steps: [\n    // ...\n  ],\n  concurrency: {\n    name: \"my-workflow-concurrency\",\n    maxRuns: 10,\n    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,\n    key: (ctx) => ctx.workflowInput().userId,\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow with Additional Metadata - Go\nDESCRIPTION: This snippet shows how to trigger a workflow run with additional metadata using the Go client. It sets the 'source' metadata key to 'api'. The workflow is identified by the 'user-workflow' name and uses a `userCreateEvent` struct for the input. It leverages the `WithRunMetadata` option.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/additional-metadata.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nworkflowRunId, err := c.Admin().RunWorkflow(\n    \"user-workflow\",\n    &userCreateEvent{\n        UserID: \"1234\",\n    },\n    client.WithRunMetadata(map[string]interface{}{\n        \"source\": \"api\", // Arbitrary key-value pair\n    }),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Typescript Hatchet SDK and dotenv\nDESCRIPTION: These commands install the necessary npm packages for interacting with the Hatchet SDK and loading environment variables from a `.env` file in a Typescript project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nnpm i @hatchet-dev/typescript-sdk\n```\n\nLANGUAGE: sh\nCODE:\n```\nnpm i dotenv\n```\n\n----------------------------------------\n\nTITLE: Setting Data Retention Period\nDESCRIPTION: This shell command sets the `SERVER_LIMITS_DEFAULT_TENANT_RETENTION_PERIOD` environment variable, which configures the default data retention period for a tenant in Hatchet.  The value is a Go duration string representing the retention period, in this case, 720 hours (30 days).  This variable must be set in the environment where the Hatchet server is running.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/data-retention.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nSERVER_LIMITS_DEFAULT_TENANT_RETENTION_PERIOD=720h # 30 days\n```\n\n----------------------------------------\n\nTITLE: APIError Usage Example in Python\nDESCRIPTION: This example demonstrates how to create an APIError instance from a JSON string, convert it to a dictionary, and then create a new APIError instance from the dictionary. It utilizes the `hatchet_sdk` library and assumes that the APIError class is available.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIError.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_error import APIError\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIError from a JSON string\napi_error_instance = APIError.from_json(json)\n# print the JSON string representation of the object\nprint APIError.to_json()\n\n# convert the object into a dict\napi_error_dict = api_error_instance.to_dict()\n# create an instance of APIError from a dict\napi_error_form_dict = api_error.from_dict(api_error_dict)\n```\n\n----------------------------------------\n\nTITLE: Defining WorkflowTag Interface in Typescript\nDESCRIPTION: This code snippet defines the `WorkflowTag` interface. It specifies that a `WorkflowTag` object must have a `name` and a `color` property, both of which are strings. This interface is used to represent workflow tags within the Hatchet system.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkflowTag.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * Interface: WorkflowTag\n *\n * [APIContracts](../modules/APIContracts.md).WorkflowTag\n */\n\n/**\n * @module APIContracts\n */\n\nexport interface WorkflowTag {\n  /**\n   * The name of the workflow.\n   */\n  name: string;\n  /**\n   * The description of the workflow.\n   */\n  color: string;\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring GRPC Broadcast Address for Docker\nDESCRIPTION: This snippet demonstrates how to configure the `SERVER_GRPC_BROADCAST_ADDRESS` environment variable when running the worker application inside of `docker-compose`.  This allows the worker to connect to the Hatchet engine using `host.docker.internal` as the hostname. Modifying the GRPC broadcast address requires re-issuing an API token.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\nSERVER_GRPC_BROADCAST_ADDRESS: \"host.docker.internal:7077\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Postgres Autovacuum Settings\nDESCRIPTION: This code snippet demonstrates recommended settings for Postgres autovacuum to improve performance when storing large amounts of workflow run and step run data. These settings are designed to more aggressively clean up and analyze the database.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_8\n\nLANGUAGE: text\nCODE:\n```\nautovacuum_max_workers=10\nautovacuum_vacuum_scale_factor=0.1\nautovacuum_analyze_scale_factor=0.05\nautovacuum_vacuum_threshold=25\nautovacuum_analyze_threshold=25\nautovacuum_vacuum_cost_delay=10\nautovacuum_vacuum_cost_limit=1000\n```\n\n----------------------------------------\n\nTITLE: Go Code Using sqlc Generated Queries\nDESCRIPTION: This Go code snippet demonstrates how to use the generated `queries` object from sqlc to interact with the database. It shows how to create a new axe using `CreateAxe` and retrieve an axe by ID using `GetAxe`. It utilizes the generated types and methods ensuring type safety.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_10\n\nLANGUAGE: go\nCODE:\n```\ninsertedAxe, _ := queries.CreateAxe(ctx, tutorial.CreateAxeParams{\n\tName:        \"hatchet\",\n\tDescription: pgtype.Text{String: \"A small axe suitable for one-handed use, (not to be confused with https://hatchet.run)\", Valid: true},\n})\n\nfetchedAxe, _ := queries.GetAxe(ctx, insertedAxe.ID)\n```\n\n----------------------------------------\n\nTITLE: Getting a Workflow Version - Python\nDESCRIPTION: This snippet demonstrates how to retrieve a specific or the latest version of a workflow using the Hatchet SDK. It covers configuring the API client, setting up authentication (API key or bearer token), creating a WorkflowApi instance, and calling the workflow_version_get method. It also includes error handling using a try-except block.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow_version import WorkflowVersion\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    workflow = 'workflow_example' # str | The workflow id\n    version = 'version_example' # str | The workflow version. If not supplied, the latest version is fetched. (optional)\n\n    try:\n        # Get workflow version\n        api_response = api_instance.workflow_version_get(workflow, version=version)\n        print(\"The response of WorkflowApi->workflow_version_get:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_version_get: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Cloning Hatchet Quickstart Project\nDESCRIPTION: This command clones the Hatchet TypeScript quickstart project from GitHub. It creates a local copy of the repository on your machine, allowing you to begin development.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/ts.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/hatchet-dev/hatchet-typescript-quickstart.git\n```\n\n----------------------------------------\n\nTITLE: Import and Use Hatchet Client Factory - Go\nDESCRIPTION: This Go code demonstrates how to import the Hatchet client factory and use it to instantiate a Hatchet client. It imports the `hatchet-tutorial/hatchet_client` package and handles potential errors during client creation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\npackage main\n\nimport (\n\t\"log\"\n\n\thatchet \"hatchet-tutorial/hatchet_client\"\n)\n\nfunc main() {\n\thatchet, err := hatchet.Client()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Starting a Hatchet Worker in Python\nDESCRIPTION: This snippet illustrates how to configure and start a Hatchet worker to execute workflows. It demonstrates creating a workflow instance, initializing a worker with a maximum runs limit, registering the workflow with the worker, and starting the worker. Requires the `hatchet_sdk` package, a defined `Hatchet` instance and `ManagedWorkflow` class.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/managed-compute.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef main():\n    # Create workflow instance\n    workflow = ManagedWorkflow()\n\n    # Initialize worker with max runs limit\n    worker = hatchet.worker(\"test-worker\", max_runs=1)\n\n    # Register workflow with worker\n    worker.register_workflow(workflow)\n\n    # Start the worker\n    worker.start()\n```\n\n----------------------------------------\n\nTITLE: package.json script for running worker\nDESCRIPTION: This JSON snippet shows how to add a script to `package.json` to start the Hatchet worker using `ts-node`.  It adds a `worker` script that executes `npx ts-node worker.ts`, allowing you to easily run the worker from the command line.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  // ...rest of your `package.json`\n  \"scripts\": {\n    // ...existing scripts\n    \"worker\": \"npx ts-node worker.ts\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Python Hatchet Worker\nDESCRIPTION: Defines a Hatchet worker in Python. It uses the `hatchet-sdk` to define a workflow with a single step. The workflow is triggered by the `user:create` event.  It loads environment variables from a .env file using `python-dotenv`\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nhatchet = Hatchet(debug=True)\n\n@hatchet.workflow(name=\"first-python-workflow\",on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        return {\n            \"result\": \"success\"\n        }\n\nworker = hatchet.worker('first-worker')\nworker.register_workflow(MyWorkflow())\n\nworker.start()\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client (Go)\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet client in Go. It defines a function `HatchetClient` that creates and returns a new Hatchet client using the `github.com/hatchet-dev/hatchet/pkg/v1` package. It handles potential errors during client creation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/mergent-migration-guide.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\npackage migration_guides\n\nimport (\n\tv1 \"github.com/hatchet-dev/hatchet/pkg/v1\"\n)\n\nfunc HatchetClient() (v1.HatchetClient, error) {\n\thatchet, err := v1.NewHatchetClient()\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn hatchet, nil\n}\n```\n\nLANGUAGE: go\nCODE:\n```\nimport (\n\t\"github.com/your-project/migration_guides\"\n)\n\nhatchet, err := migration_guides.HatchetClient()\nif err != nil {\n\tpanic(err)\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Indices on WorkflowRun Model with Prisma\nDESCRIPTION: This code shows how indices were defined on the `WorkflowRun` model using Prisma's schema definition language. It includes indices on `tenantId`, `workflowVersionId`, and `createdAt` fields, which are used for filtering and monitoring purposes.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_6\n\nLANGUAGE: sql\nCODE:\n```\n@@index([tenantId])\n@@index([workflowVersionId])\n@@index([createdAt])\n```\n\n----------------------------------------\n\nTITLE: Creating Task with Event Trigger (Python)\nDESCRIPTION: Creates a Hatchet task that waits for either an external user event or sleeps for 10 seconds using Python. Uses `SleepCondition` and `UserEventCondition` within an `or_` clause.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n# Create a task which waits for an external user event or sleeps for 10 seconds\n@dag_with_conditions.task(\n  parents=[first_task],\n  wait_for=[\n    or_(\n      SleepCondition(timedelta(seconds=10)),\n      UserEventCondition(event_key=\"user:event\"),\n    )\n  ]\n)\ndef second_task(input: EmptyModel, ctx: Context) -> dict[str, str]:\n    return {\"completed\": \"true\"}\n```\n\n----------------------------------------\n\nTITLE: Running a Workflow - Python\nDESCRIPTION: This snippet demonstrates how to run a Hatchet workflow in Python. It shows both running the workflow and waiting for the result using `simple.run(input_data)`, and enqueuing the workflow for asynchronous execution using `simple.run_no_wait(input_data)`. The `input_data` variable represents the input data for the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/dags.mdx#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n# Run workflow and wait for the result\nresult = simple.run(input_data)\n\n# Enqueue workflow to be executed asynchronously\nrun_id = simple.run_no_wait(input_data)\n```\n\n----------------------------------------\n\nTITLE: Disabling Heartbeat, Gossip, and Mingle in Celery\nDESCRIPTION: This code snippet shows the recommended command-line arguments to disable heartbeat, gossip, and mingle features in Celery. Disabling these features can significantly reduce data transfer costs, especially with a large number of workers, as the gossip feature scales quadratically with the number of workers. It is recommended for environments where clock synchronization is not critical.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/problems-with-celery.mdx#_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\n--without-heartbeat --without-gossip --without-mingle\n```\n\n----------------------------------------\n\nTITLE: Hatchet Server Logging Configuration Example\nDESCRIPTION: This snippet shows an example of how to configure Hatchet server and database logging levels and formats using environment variables. It sets the log level (e.g., debug, info, error) and format (e.g., json, console) for both server and database loggers.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: text\nCODE:\n```\n# info, debug, error, etc\nSERVER_LOGGER_LEVEL=debug\n\n# json or console\nSERVER_LOGGER_FORMAT=json\n\nDATABASE_LOGGER_LEVEL=debug\nDATABASE_LOGGER_FORMAT=console\n```\n\n----------------------------------------\n\nTITLE: Pushing Internal Events - Go\nDESCRIPTION: Demonstrates how to push an internal event from within a Go application using the Hatchet client.  The `c.Event().Push` method is used to push the event with a specified name and payload. Requires the `hatchet-dev/hatchet/sdk/pkg/client` and `hatchet-dev/hatchet/sdk/pkg/client/events` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_8\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\npanic(err)\n}\n\nc.Event().Push(\ncontext.Background(),\n\"test-called\",\n&events.TestEvent{\nName: \"testing\",\n},\n)\n\n```\n\n----------------------------------------\n\nTITLE: Listing Cron Triggers - Typescript\nDESCRIPTION: Lists all workflow cron triggers matching the specified criteria using the Hatchet SDK in Typescript.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/examples/crons/programatic-crons.ts\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client\nDESCRIPTION: This snippet shows the basic way to initialize a Hatchet client using the Hatchet SDK in Python. It requires the `hatchet_sdk` package to be installed. No specific configuration is set in this example, relying on default values or environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/client.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk import Hatchet\n\nhatchet = Hatchet()\n```\n\n----------------------------------------\n\nTITLE: Defining the 'start' step in Hatchet workflow\nDESCRIPTION: This snippet defines the 'start' step of a Hatchet workflow using the @hatchet.step decorator.  It takes a Context object as input and returns a dictionary with the initial status. This step is part of the BasicRagWorkflow class and provides an initial status update.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n    @hatchet.step()\n    def start(self, context: Context):\n        return {\n            \"status\": \"reading hatchet docs\",\n        }\n```\n\n----------------------------------------\n\nTITLE: Deleting Cron Trigger - Go\nDESCRIPTION: Deletes a cron trigger using the Hatchet SDK in Go, either by passing the cron object or the cron trigger ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_11\n\nLANGUAGE: go\nCODE:\n```\nexamples/cron-programmatic/main.go\n```\n\n----------------------------------------\n\nTITLE: Listening for Base64 Encoded File Streams\nDESCRIPTION: This TypeScript snippet listens for base64 encoded file streams from a Hatchet workflow. It sets up the environment using `dotenv`, retrieves a workflow run ID, subscribes to events, and writes the base64 decoded file to an 'out' directory when a stream event is received. It uses Node.js modules for file system, path and environment variable handling, and the Hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/streaming.mdx#_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport * as fs from 'fs';\nimport * as path from 'path';\nimport { config } from 'dotenv';\nimport { Hatchet, StepRunEventType } from 'hatchet';\n\nasync function listenForFiles() {\nconfig();\nconst hatchet = new Hatchet();\nconst workflowRunId = await hatchet.admin.runWorkflow('ManualTriggerWorkflow', { test: 'test' });\nconst listener = await hatchet.listener.stream(workflowRunId);\n\n// Get the directory of the current script\nconst scriptDir = path.dirname(__filename);\n\n// Create the \"out\" directory if it doesn't exist\nconst outDir = path.join(scriptDir, 'out');\nawait fs.promises.mkdir(outDir, { recursive: true });\n\nfor await (const event of listener) {\n    if (event.type === StepRunEventType.STEP_RUN_EVENT_TYPE_STREAM) {\n      // Decode the base64-encoded payload\n      const decodedPayload = Buffer.from(event.payload, 'base64');\n      // Construct the path to the payload file in the \"out\" directory\n      const payloadPath = path.join(outDir, 'payload.jpg');\n\n      // Write the decoded payload to the file\n      await fs.promises.writeFile(payloadPath, decodedPayload);\n    }\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: WorkflowVersion Usage Example in Python\nDESCRIPTION: This snippet demonstrates creating a WorkflowVersion object from a JSON string, converting it back to JSON, and converting between the object and a dictionary using the `hatchet-sdk` library. The example assumes the existence of the `WorkflowVersion` class within `hatchet_sdk.clients.rest.models.workflow_version`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowVersion.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_version import WorkflowVersion\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowVersion from a JSON string\nworkflow_version_instance = WorkflowVersion.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowVersion.to_json()\n\n# convert the object into a dict\nworkflow_version_dict = workflow_version_instance.to_dict()\n# create an instance of WorkflowVersion from a dict\nworkflow_version_form_dict = workflow_version.from_dict(workflow_version_dict)\n```\n\n----------------------------------------\n\nTITLE: Defining Event Triggered Workflow - Python\nDESCRIPTION: Defines a Hatchet workflow that is triggered by the `user:created` event. The workflow includes a single step that prints a message to the console.  Requires the `hatchet_sdk` library to be installed. The `on_events` parameter specifies the event that triggers the workflow.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/event-trigger.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:created\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: Initializing Worker with Labels - Typescript\nDESCRIPTION: This code snippet shows how to initialize a Hatchet worker with labels in Typescript.  The labels are key-value pairs describing worker capabilities and resources. The worker is named \"affinity-worker\" and has labels for \"model\" and \"memory\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst worker = await hatchet.worker(\"affinity-worker\", {\n  labels: {\n    model: \"fancy-ai-model-v2\",\n    memory: 512,\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Listing Cron Triggers - Python (Sync)\nDESCRIPTION: Lists all workflow cron triggers matching the specified criteria using the Hatchet SDK in Python (synchronous).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-sync.py\n```\n\n----------------------------------------\n\nTITLE: Setting up the Hatchet Development Environment with Task\nDESCRIPTION: This snippet uses the `task` command-line tool to install dependencies, run database migrations, generate encryption keys, and seed the database. It assumes that the `task` tool is installed and configured with the necessary tasks defined.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ntask setup\n```\n\n----------------------------------------\n\nTITLE: SQL Query to Get Axe by ID\nDESCRIPTION: This SQL query retrieves a single row from the 'axes' table based on the provided ID. The `:one` annotation indicates that sqlc should generate code expecting a single result. The query uses a parameterized value ($1) for the ID to prevent SQL injection.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_8\n\nLANGUAGE: sql\nCODE:\n```\n-- name: GetAxe :one\nSELECT * FROM axes\nWHERE id = $1 LIMIT 1;\n```\n\n----------------------------------------\n\nTITLE: Initializing React Component State\nDESCRIPTION: This code initializes the state variables for the React component, including 'openRequest', 'message', 'messages', and 'status'. These states manage the workflow run ID, user input, chat history, and the current status of the Hatchet workflow respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { useEffect, useState } from \"react\";\nimport \"./App.css\";\n\ninterface Messages {\n  role: \"user\" | \"assistant\";\n  content: string;\n  messageId?: string;\n}\n\nconst API_URL = \"http://localhost:8000\";\n\nfunction App() {\n  const [openRequest, setOpenRequest] = useState<string>();\n  const [message, setMessage] = useState<string>(\"\");\n  const [messages, setMessages] = useState<Messages[]>([\n    { role: \"assistant\", content: \"How can I help you?\" },\n  ]);\n  const [status, setStatus] = useState(\"idle\");\n\n  // ... rest of the component code\n}\n\nexport default App;\n```\n\n----------------------------------------\n\nTITLE: TenantMember Interface Definition\nDESCRIPTION: Defines the structure of the TenantMember interface.  It specifies the properties that a TenantMember object should have, including metadata, role, tenant and user. The role is a TenantMemberRole enum and other properties are other defined interfaces. \nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantMember.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: TenantMember\n *\n * [APIContracts](../modules/APIContracts.md).TenantMember\n */\n\n/**\n * @property metadata\n */\n\n/**\n * @property role\n */\n\n/**\n * @property tenant\n */\n\n/**\n * @property user\n */\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow to Cancel In-Progress Workflows\nDESCRIPTION: This code snippet defines a Hatchet workflow that cancels any in-progress workflows for a user if a new event is triggered. It sets the `limit_strategy` to `ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS` and `max_runs` to 1, ensuring that only the latest workflow execution runs, while canceling any previous ones.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/fairness.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(\n    on_events=[\"concurrency-test\"],\n    concurrency=Concurrency(\n        max_runs=1,\n        limit_strategy=ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS,\n    ),\n)\nclass ConcurrencyDemoWorkflow:\n    @hatchet.step()\n    def step1(self, context):\n        print(\"executed step1\")\n        pass\n```\n\n----------------------------------------\n\nTITLE: TenantInvite Properties: role\nDESCRIPTION: Defines the `role` property of the `TenantInvite` interface. This property is of type `TenantMemberRole`, an enum defined elsewhere in the codebase. It represents the role of the invited user within the tenant.  This is a required property for the interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantInvite.md#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * The role of the user in the tenant.\n */\nrole: [`TenantMemberRole`](../enums/APIContracts.TenantMemberRole.md)\n```\n\n----------------------------------------\n\nTITLE: Refreshing Timeout in Python\nDESCRIPTION: This Python snippet demonstrates how to refresh a task's timeout using the `refreshTimeout` method within a step.  It shows how to extend the execution time of a running task. The target `RefreshTimeout` specifies which part of the code to extract.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/timeouts.mdx#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nexamples/timeout/worker.py\n```\n\n----------------------------------------\n\nTITLE: Accessing Workflow Input (Typescript)\nDESCRIPTION: This code snippet demonstrates how to access the workflow input within a Hatchet step defined in Typescript. The `ctx.workflowInput()` method retrieves the input, which is expected to be a JSON object. This input is then used to perform operations in the step.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nexport const myStep = async (ctx: Context): Promise<object> => {\n    const data = ctx.workflowInput();\n    // Perform some operation\n    return output;\n};\n```\n\n----------------------------------------\n\nTITLE: Accessing Environment Variables in Python\nDESCRIPTION: This code snippet demonstrates how to access environment variables in Python using the `os.getenv()` method. It imports the `os` module and retrieves the values of `DATABASE_URL` and `API_KEY` environment variables, assigning them to respective variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/environment-variables.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\ndatabase_url = os.getenv('DATABASE_URL')\napi_key = os.getenv('API_KEY')\n```\n\n----------------------------------------\n\nTITLE: Disable SSL for Hatchet Client\nDESCRIPTION: Sets the HATCHET_CLIENT_TLS_STRATEGY environment variable to 'none' to disable SSL for the Hatchet client. This might be necessary in self-hosted configurations where SSL is not configured.  This should only be done in development/testing environments.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nHATCHET_CLIENT_TLS_STRATEGY=none\n```\n\n----------------------------------------\n\nTITLE: Prometheus Configuration Example\nDESCRIPTION: This is an example Prometheus configuration to scrape metrics from a Hatchet worker. It defines a job named \"hatchet\" that scrapes metrics from localhost:8001 every 5 seconds. This requires Prometheus to be installed and configured.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/worker-healthchecks.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nscrape_configs:\n  - job_name: \"hatchet\"\n    scrape_interval: 5s\n    static_configs:\n      - targets: [\"localhost:8001\"]\n```\n\n----------------------------------------\n\nTITLE: Example Invite UUID (TypeScript)\nDESCRIPTION: Provides an example of the `invite` property's value within the `AcceptInviteRequest` interface. This showcases the expected format (UUID) and length of the invite string.  This example highlights the valid format for the `invite` property.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.AcceptInviteRequest.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"bb214807-246e-43a5-a25d-41761d1cff9e\"\n```\n\n----------------------------------------\n\nTITLE: Dockerizing with yarn\nDESCRIPTION: This Dockerfile demonstrates building and running a Hatchet TypeScript application using yarn. It uses a multi-stage build, copies package files and the yarn lockfile, installs dependencies with `--frozen-lockfile`, and then copies the built output to a production image.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_2\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Stage 1: Build\nFROM node:18 AS builder\n\nWORKDIR /app\n\n# Copy package files\n\nCOPY package.json yarn.lock ./\n\n# Install dependencies\n\nRUN yarn install --frozen-lockfile\n\n# Copy source code\n\nCOPY . .\n\n# Build TypeScript\n\nRUN yarn build\n\n# Stage 2: Production\n\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files\n\nCOPY package.json yarn.lock ./\n\n# Install production dependencies only\n\nRUN yarn install --frozen-lockfile --production\n\n# Copy built assets from builder\n\nCOPY --from=builder /app/dist ./dist\n\n# Set production environment\n\nENV NODE_ENV=production\n\n# Start the worker\n\nCMD [\"node\", \"dist/worker.js\"]\n\n```\n\n----------------------------------------\n\nTITLE: Looping: Spawning Child Workflows in Go\nDESCRIPTION: This Go snippet demonstrates spawning child workflows within a loop. It utilizes the `ctx.SpawnWorkflow` method to create multiple child workflows with dynamic input.  The parent workflow is registered using `w.RegisterWorkflow`, defining its name, event trigger, description, and steps.  It leverages the `worker` package from the Hatchet Go SDK and the `strconv` package to convert integers to strings.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/child-workflows.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nw.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"parent-workflow\",\n        On: worker.Event(\"fanout:create\"),\n        Description: \"Example workflow for spawning child workflows.\",\n        Steps: []*worker.WorkflowStep{\n            worker.Fn(func(ctx worker.HatchetContext) error {\n                for i := 0; i < 10; i++ {\n                  childInput := \"child-input-\" + strconv.Itoa(i)\n                  childWorkflow, err := ctx.SpawnWorkflow(\"child-workflow\", childInput, &worker.SpawnWorkflowOpts{})\n                  if err != nil {\n                      return nil, err\n                  }\n                }\n                return nil\n            }),\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Pagination Response Example\nDESCRIPTION: This code shows an example of a PaginationResponse object.  It illustrates how the \"next_page\", \"num_pages\", and \"current_page\" properties are structured as numerical values, representing the pagination state. The expected format is a JSON object with integer values.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.PaginationResponse.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n{\"next_page\":3,\"num_pages\":10,\"current_page\":2}\n```\n\n----------------------------------------\n\nTITLE: Cloning Hatchet Python Quickstart Repository\nDESCRIPTION: This shell command clones the Hatchet Python Quickstart repository from GitHub. It uses the `git clone` command to download the repository to the local machine, followed by `cd` to change the directory to the cloned repository.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/hatchet-dev/hatchet-python-quickstart.git\ncd hatchet-python-quickstart\n```\n\n----------------------------------------\n\nTITLE: Accessing Environment Variables in Go\nDESCRIPTION: This code snippet illustrates how to access environment variables in Go using the `os.Getenv()` function. It imports the `os` package and retrieves the values of the `DATABASE_URL` and `API_KEY` environment variables, storing them in respective variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/compute/environment-variables.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\nimport \"os\"\n\ndatabaseUrl := os.Getenv(\"DATABASE_URL\")\napiKey := os.Getenv(\"API_KEY\")\n```\n\n----------------------------------------\n\nTITLE: Prometheus Query\nDESCRIPTION: This Prometheus query checks the health status of a Hatchet worker. It uses the `hatchet_worker_status` metric, which is a gauge that indicates the worker's health. The query returns 1 if the worker is healthy, or 0 if the metric is not found.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/worker-healthchecks.mdx#_snippet_3\n\nLANGUAGE: PromQL\nCODE:\n```\n(hatchet_worker_status{instance=\"localhost:8001\", job=\"hatchet\"}) or vector(0)\n```\n\n----------------------------------------\n\nTITLE: Running Typescript Worker\nDESCRIPTION: This npm command executes the `worker` script defined in the `package.json` file, which starts the Hatchet worker using `ts-node`. It is assumed that `ts-node` is installed and configured to run TypeScript files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\nnpm run worker\n```\n\n----------------------------------------\n\nTITLE: Defining the 'load_docs' step in Hatchet workflow\nDESCRIPTION: This snippet defines the 'load_docs' step of a Hatchet workflow. It uses BeautifulSoup to parse HTML content from a given URL (obtained from the workflow input) and extracts the text. The step depends on the 'start' step and requires the requests and BeautifulSoup libraries.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"question:create\"])\nclass BasicRagWorkflow:\n\n    # ... previous steps\n\n    @hatchet.step(parents=[\"start\"])\n    def load_docs(self, context: Context):\n        # use beautiful soup to parse the html content\n        url = context.workflow_input()['request']['url']\n\n        html_content = requests.get(url).text\n        soup = BeautifulSoup(html_content, 'html.parser')\n        element = soup.find('body')\n        text_content = element.get_text(separator=' | ')\n\n        return {\n            \"status\": \"making sense of the docs\",\n            \"docs\": text_content,\n        }\n```\n\n----------------------------------------\n\nTITLE: Creating/Deleting/Listing Cron Trigger - Python Sync\nDESCRIPTION: These snippets show how to programmatically create, delete, and list cron triggers using the Hatchet SDK in Python (synchronous). This approach allows for dynamically setting the cron schedule of a task using the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/cron-runs.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-sync.py\n```\n\n----------------------------------------\n\nTITLE: Deleting a Scheduled Run - Go\nDESCRIPTION: This snippet references an external Go file (`examples/scheduled/main.go`) and targets the section \"Delete\". It displays how to delete a scheduled run using the Hatchet SDK in Go, using code from the `ScheduleTriggerGo` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/scheduled-runs.mdx#_snippet_5\n\nLANGUAGE: Go\nCODE:\n```\n<GithubSnippet src={ScheduleTriggerGo} target=\"Delete\" />\n```\n\n----------------------------------------\n\nTITLE: Installing Typescript Dependencies\nDESCRIPTION: These npm commands install the required TypeScript dependencies for running the Hatchet worker.  It installs `@hatchet-dev/typescript-sdk` for interacting with the Hatchet service and `dotenv` to load environment variables.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/docker-compose.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nnpm i @hatchet-dev/typescript-sdk\nnpm i dotenv\n```\n\n----------------------------------------\n\nTITLE: Scheduling Task (Typescript)\nDESCRIPTION: Schedules a Hatchet task to run tomorrow and schedules another task to run every day at midnight using cron scheduling in Typescript.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nconst tomorrow = new Date(Date.now() + 1000 * 60 * 60 * 24);\n// schedule a task to run tomorrow\nconst scheduled = simple.schedule(tomorrow, {\n  Message: \"Hello, World!\",\n});\n\n// schedule a task to run every day at midnight\nconst cron = simple.cron(\"every-day\", \"0 0 * * *\", {\n  Message: \"Hello, World!\",\n});\n```\n\n----------------------------------------\n\nTITLE: Printing APIMetaIntegration as JSON\nDESCRIPTION: This snippet illustrates how to convert an `APIMetaIntegration` object to a JSON string representation. It makes use of the `to_json()` method from the `APIMetaIntegration` class. This requires an existing `APIMetaIntegration` object and the hatchet SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIMetaIntegration.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# print the JSON string representation of the object\nprint APIMetaIntegration.to_json()\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Client (Typescript)\nDESCRIPTION: This snippet demonstrates how to initialize a Hatchet client in TypeScript. It creates a singleton instance of the Hatchet client for use throughout the application. The `@hatchet-dev/typescript-sdk` package is required.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/mergent-migration-guide.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Hatchet } from \"@hatchet-dev/typescript-sdk\";\n\nexport const hatchet = Hatchet.init();\n```\n\nLANGUAGE: typescript\nCODE:\n```\nimport { hatchet } from \"./hatchet-client\";\n```\n\n----------------------------------------\n\nTITLE: Generating .env file\nDESCRIPTION: Generates a `.env` file containing the `HATCHET_CLIENT_TOKEN` and `HATCHET_CLIENT_TLS_STRATEGY` variables. The token is created using `hatchet-admin token create` command executed within the `hatchet-lite` container.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncat <<EOF > .env\nHATCHET_CLIENT_TOKEN=\"$(docker compose -f docker-compose.hatchet.yml exec hatchet-lite /hatchet-admin token create --config /config --tenant-id 707d0855-80ab-4e1f-a156-f1c4546cbf52 | xargs)\"\nHATCHET_CLIENT_TLS_STRATEGY=none\nEOF\n```\n\n----------------------------------------\n\nTITLE: Deleting Cron Trigger - Python (Async)\nDESCRIPTION: Deletes a cron trigger using the Hatchet SDK in Python (asynchronous), either by passing the cron object or the cron trigger ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-async.py\n```\n\n----------------------------------------\n\nTITLE: Import Hatchet Client\nDESCRIPTION: This code snippet demonstrates how to import the Hatchet client from the 'hatchet_client.py' file.  It assumes the client has been instantiated in the specified file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/py.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom src.hatchet_client import hatchet\n```\n\n----------------------------------------\n\nTITLE: APIError Field Example in TypeScript\nDESCRIPTION: Demonstrates the optional 'field' property of the APIError interface, indicating which field in the request caused the error. This is a string that identifies the specific field.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIError.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n\"name\"\n```\n\n----------------------------------------\n\nTITLE: Add Wait for Event Task - Go\nDESCRIPTION: This snippet adds a task that waits for a specific event to be triggered before it starts execution using `wait_for` in Go. It highlights the event-driven capabilities of Hatchet's conditional logic.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/conditional-workflows.mdx#_snippet_17\n\nLANGUAGE: Go\nCODE:\n```\nexamples/v1/workflows/complex-conditions.go\n```\n\n----------------------------------------\n\nTITLE: Create React App with Typescript\nDESCRIPTION: This command uses Create React App to generate a new React project named 'frontend' with TypeScript support. It simplifies initial project setup with a predefined structure and build configuration.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/simple-frontend.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpx create-react-app frontend --template typescript\n```\n\n----------------------------------------\n\nTITLE: Initializing Hatchet Worker\nDESCRIPTION: This snippet initializes a Hatchet worker with a specified name and the maximum number of concurrent step runs it can handle. If maxRuns is not set, it defaults to 100.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/worker.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nhatchet.worker(\"example-worker\", 1); // this worker can run only 1 step at a time\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow and Starting Worker in Python\nDESCRIPTION: This code snippet demonstrates how to register a workflow with a Hatchet worker in Python and start the worker process. It initializes a worker with a unique identifier ('test-worker') and a maximum number of runs (4), registers a workflow instance, and then starts the worker to listen for tasks from the Hatchet engine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/workers.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nworkflow = MyWorkflow()\nworker = hatchet.worker('test-worker', max_runs=4)\nworker.register_workflow(workflow)\nworker.start()\n```\n\n----------------------------------------\n\nTITLE: Run Hatchet Worker\nDESCRIPTION: Starts the Hatchet worker using the 'worker' script defined in the package.json file. This command executes the `worker.ts` file, which registers the workflow and starts listening for events.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nnpm run worker\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Logger (TypeScript)\nDESCRIPTION: Shows how to create a custom logger in TypeScript that implements Hatchet's `Logger` interface, using Pino logger as an example. The custom logger is then passed to the Hatchet client constructor.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/logging.mdx#_snippet_4\n\nLANGUAGE: TypeScript\nCODE:\n```\n<GithubSnippet src={ByoLoggerTs} target=\"Create Pino logger\" />\n```\n\n----------------------------------------\n\nTITLE: APIError Code Example in TypeScript\nDESCRIPTION: Illustrates the optional 'code' property of the APIError interface, which represents a custom Hatchet error code as a uint64 number. This property helps identify specific error types returned by the API.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIError.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n1400\n```\n\n----------------------------------------\n\nTITLE: Running the Hatchet Worker with Poetry\nDESCRIPTION: This snippet shows the command to start the Hatchet worker using Poetry. It assumes that Hatchet is installed as a dependency in a Poetry project and that the `hatchet` command is available in the Poetry environment.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/building-the-workflow.mdx#_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\npoetry run hatchet\n```\n\n----------------------------------------\n\nTITLE: Creating Task with Event Trigger (Go)\nDESCRIPTION: Creates a Hatchet task that waits for either an external user event or sleeps for 10 seconds using Go. Uses `condition.UserEventCondition` and `condition.SleepCondition`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_17\n\nLANGUAGE: go\nCODE:\n```\n// Create a task which waits for an external user event or sleeps for 10 seconds\nsimple.Task(\n  conditionOpts{\n    Name: \"Step2\",\n    Parents: []create.NamedTask{\n      step1,\n    },\n    WaitFor: condition.Conditions(\n      condition.UserEventCondition(\"user:event\", \"'true'\"),\n      condition.SleepCondition(10 * time.Second),\n    ),\n  }, func(ctx worker.HatchetContext, input DagWithConditionsInput) (interface{}, error) {\n    // ...\n  },\n);\n```\n\n----------------------------------------\n\nTITLE: TenantMember.role Property\nDESCRIPTION: Defines the role property of the TenantMember interface. This property is of type TenantMemberRole, which is an enum representing the possible roles a user can have within a tenant.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.TenantMember.md#_snippet_2\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * role: [`TenantMemberRole`](../enums/APIContracts.TenantMemberRole.md)\n *\n * The role of the user in the tenant.\n */\n```\n\n----------------------------------------\n\nTITLE: Specifying Step Desired Labels - Typescript\nDESCRIPTION: This code snippet shows how to specify desired worker label state for a Hatchet step in Typescript. The `worker_labels` property is set on the step definition to specify the desired label values and comparators. The step prioritizes workers with `model` equal to \"fancy-vision-model\" and requires workers with `memory` greater than or equal to 1024.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nconst affinity: Workflow = {\n  id: 'affinity-workflow',\n  description: 'test',\n  steps: [\n    {\n      name: 'child-step1',\n      worker_labels: {\n        model: {\n          value: 'fancy-vision-model',\n          required: false,\n        },\n        memory: {\n          value: 1024,\n          comparator: WorkerLabelComparator.GREATER_THAN_OR_EQUAL,\n        },\n      },\n      run: async (ctx) => {\n        // DO WORK\n        return { childStep1: 'childStep1 results!' };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Fetching Task Setup - Python\nDESCRIPTION: This snippet demonstrates how to fetch a task via the REST API. It sets up the necessary environment and prepares for subsequent operations on the task.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/bulk-retries-and-cancellations.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nexamples/bulk_operations/cancel.py\n```\n\n----------------------------------------\n\nTITLE: Defining Concurrency Limits for Hatchet Workflow (CANCEL_IN_PROGRESS)\nDESCRIPTION: This code snippet defines a Hatchet workflow with concurrency limits using the `CANCEL_IN_PROGRESS` strategy.  It limits concurrent executions to 1, cancelling the in-progress workflow if a new one is triggered with the same `user_id` specified in the `expression`. The workflow includes two steps with abort signal handling.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/fairness.mdx#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  id: \"concurrency-example\",\n  description: \"test\",\n  on: {\n    event: \"concurrency:create\",\n  },\n  concurrency: {\n    maxRuns: 1,\n    limitStrategy: ConcurrencyLimitStrategy.CANCEL_IN_PROGRESS,\n    expression: \"input.user_id\",\n  },\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        const { data } = ctx.workflowInput();\n        const { signal } = ctx.controller;\n\n        if (signal.aborted) throw new Error(\"step1 was aborted\");\n\n        console.log(\"starting step1 and waiting 5 seconds...\", data);\n        await sleep(5000);\n\n        if (signal.aborted) throw new Error(\"step1 was aborted\");\n\n        // NOTE: the AbortController signal can be passed to many http libraries to cancel active requests\n        // fetch(url, { signal })\n        // axios.get(url, { signal })\n\n        console.log(\"executed step1!\");\n        return { step1: `step1 results for ${data}!` };\n      },\n    },\n    {\n      name: \"step2\",\n      parents: [\"step1\"],\n      run: (ctx) => {\n        console.log(\n          \"executed step2 after step1 returned \",\n          ctx.stepOutput(\"step1\"),\n        );\n        return { step2: \"step2 results!\" };\n      },\n    },\n  ],\n};\n```\n\n----------------------------------------\n\nTITLE: Deleting Scheduled Runs - Python (Sync)\nDESCRIPTION: This snippet shows how to delete a scheduled run using the Python (Synchronous) Hatchet SDK. It uses either the scheduled run object or the scheduled run ID to delete the scheduled run. Requires the Hatchet client initialized and the scheduled run ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-sync.py - Delete\n```\n\n----------------------------------------\n\nTITLE: Defining On-Failure Task in Go\nDESCRIPTION: This snippet demonstrates how to define an on-failure task within a Hatchet workflow using Go. It showcases the syntax and structure for specifying the on-failure function, which will be executed if any main task in the workflow fails. The snippet is located in `examples/on-failure/main.go` and targets the \"OnFailure Step\".\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/on-failure-tasks.mdx#_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nexamples/on-failure/main.go\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet TypeScript SDK with yarn\nDESCRIPTION: This code snippet demonstrates how to install the Hatchet TypeScript SDK using yarn. It provides an alternative installation method for users who prefer yarn.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @hatchet-dev/typescript-sdk\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies\nDESCRIPTION: Installs the required Python packages for the Hatchet worker: `python-dotenv` and `hatchet-sdk`.  `python-dotenv` loads environment variables from a `.env` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\npip install python-dotenv\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Setting HATCHET_CLIENT_TOKEN using go in shell\nDESCRIPTION: This snippet shows how to set the `HATCHET_CLIENT_TOKEN` environment variable by running a Go program that creates a token, capturing its output, and assigning it to the variable.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nexport HATCHET_CLIENT_TOKEN=\"$(go run ./cmd/hatchet-admin token create --tenant-id <tenant>)\"\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Python (Sync)\nDESCRIPTION: This snippet demonstrates listing scheduled runs using the Python (Synchronous) Hatchet SDK. It retrieves a list of all scheduled runs matching the defined criteria. Requires a configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-sync.py - List\n```\n\n----------------------------------------\n\nTITLE: Create project directories\nDESCRIPTION: Creates the necessary directories for the Hatchet project structure: `src`, `src/workflows`, and `src/workers`.  This provides a structure for organizing the project files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/ts.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir src &&\nmkdir src/workflows &&\nmkdir src/workers\n```\n\n----------------------------------------\n\nTITLE: Caching Dependencies in Dockerfile\nDESCRIPTION: These Dockerfile snippets showcase dependency caching by copying package files before installing dependencies. This optimizes Docker image builds by leveraging Docker's caching mechanism, reducing build times when only source code changes.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_3\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Copy only package files first\nCOPY package*.json ./\n# or\nCOPY pnpm-lock.yaml package.json ./\n# or\nCOPY package.json yarn.lock ./\n\n# Install dependencies\nRUN <package-manager> install\n```\n\n----------------------------------------\n\nTITLE: Spawning Child Workflows in Bulk in Go\nDESCRIPTION: This code snippet demonstrates how to spawn multiple child workflows in bulk using the `SpawnWorkflows` method. It takes a slice of `SpawnWorkflowsOpts` as input, allowing for individual configuration of each child workflow. It returns an error, if any.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/child-workflows.mdx#_snippet_2\n\nLANGUAGE: go\nCODE:\n```\n_, err = ctx.SpawnWorkflows(\n[]*worker.SpawnWorkflowsOpts{\n    {\n        WorkflowName: \"step-one\",\n\n        Sticky: &sticky,\n    },\n    {\n        WorkflowName: \"step-one\",\n\n        Sticky: &sticky,\n    },\n})\n```\n\n----------------------------------------\n\nTITLE: Defining a Hatchet Step (Typescript)\nDESCRIPTION: This code snippet demonstrates the basic structure of a Hatchet step defined in Typescript. It takes a `context` argument of type `Context`, performs an operation, and returns a Promise that resolves to a JSON-serializable object. The context provides access to workflow input and logging facilities.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/basics/steps.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nexport const myStep = async (ctx: Context): Promise<object> => {\n    // Perform some operation\n    return output;\n};\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Client Directory and File - Bash\nDESCRIPTION: These commands create a new directory called `hatchet_client` and then create a new Go file named `main.go` inside that directory. This file will contain the Hatchet client initialization code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hatchet_client &&\ntouch hatchet_client/main.go\n```\n\n----------------------------------------\n\nTITLE: Get Workflow using hatchet_sdk in Python\nDESCRIPTION: This snippet retrieves a workflow for a tenant using the `workflow_get` method of the `WorkflowApi`. It requires the `workflow` ID as input and returns a `Workflow` object. It uses API key (cookieAuth) or Bearer authentication (bearerAuth).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.workflow import Workflow\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    workflow = 'workflow_example' # str | The workflow id\n\n    try:\n        # Get workflow\n        api_response = api_instance.workflow_get(workflow)\n        print(\"The response of WorkflowApi->workflow_get:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_get: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Creating Cron Trigger Programmatically - Python (Sync)\nDESCRIPTION: Creates a cron trigger programmatically using the Hatchet SDK in Python (synchronous). This allows for dynamic cron schedules defined at runtime.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-sync.py\n```\n\n----------------------------------------\n\nTITLE: APIError Description Example in TypeScript\nDESCRIPTION: Shows the 'description' property of the APIError interface, which provides a human-readable error message. This property is a string that explains the nature of the error.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIError.md#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\n\"A descriptive error message\"\n```\n\n----------------------------------------\n\nTITLE: Installing Python dependencies with Poetry\nDESCRIPTION: This command uses Poetry to install the project's dependencies.  It assumes Poetry is already installed and configured in the environment.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Listing Scheduled Runs - Python (Async)\nDESCRIPTION: This snippet demonstrates listing scheduled runs using the Python (Asynchronous) Hatchet SDK. It retrieves a list of scheduled runs matching criteria. Requires a configured Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nSee GithubSnippet: examples/scheduled/programatic-async.py - List\n```\n\n----------------------------------------\n\nTITLE: Defining Python file path for Hatchet manual slot release example\nDESCRIPTION: This code defines a constant `SlotReleasePy` that stores the file path to a Python example demonstrating manual slot release functionality within a Hatchet workflow. This path is then used to retrieve the code snippet for display.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/manual-slot-release.mdx#_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nexport const SlotReleasePy = {\n  path: \"examples/manual_slot_release/worker.py\",\n};\n```\n\n----------------------------------------\n\nTITLE: Deleting Scheduled Runs - Go\nDESCRIPTION: This snippet demonstrates deleting a scheduled run using the Go Hatchet SDK. It uses either the scheduled run object or the scheduled run ID. Requires initialized Hatchet client and scheduled run ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/schedule-trigger.mdx#_snippet_10\n\nLANGUAGE: go\nCODE:\n```\nSee GithubSnippet: examples/scheduled/main.go - Delete\n```\n\n----------------------------------------\n\nTITLE: Change Directory to Project\nDESCRIPTION: This command changes the current directory to your project directory. Replace `path-to-your-project` with the actual path to your project.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/ts.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd path-to-your-project\n```\n\n----------------------------------------\n\nTITLE: Change Directory to Quickstart\nDESCRIPTION: Navigates the command line to the cloned Hatchet Go quickstart project directory.  This allows you to execute subsequent commands within the project's context.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/go.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd hatchet-go-quickstart\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Assignment (Go)\nDESCRIPTION: Defines Hatchet workflows with sticky assignment strategies in Go. One workflow prefers to run on the same worker (SOFT), while the other requires it (HARD). Requires `types` and `create` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_14\n\nLANGUAGE: go\nCODE:\n```\n// create a workflow which prefers to run on the same worker, but can be\n// scheduled on any worker if the original worker is busy\nfactory.NewWorkflow[StickyInput, StickyOutput](\n  create.WorkflowCreateOpts[StickyInput]{\n    Name: \"sticky-dag\",\n    StickyStrategy: types.StickyStrategy_SOFT,\n  },\n  hatchet,\n);\n\n// create a workflow which must run on the same worker\nfactory.NewWorkflow[StickyInput, StickyOutput](\n  create.WorkflowCreateOpts[StickyInput]{\n    Name: \"sticky-dag\",\n    StickyStrategy: types.StickyStrategy_HARD,\n  },\n  hatchet,\n);\n```\n\n----------------------------------------\n\nTITLE: Defining Rate Limits - Python\nDESCRIPTION: This snippet demonstrates how to define rate limits in Hatchet using Python. It involves two steps: first, defining the rate limit using `hatchet.admin.put_rate_limit` and then specifying the consumption of the defined limit within a step definition using the `@hatchet.step` decorator.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/rate-limits.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nhatchet.admin.put_rate_limit('example-limit', 10, RateLimitDuration.MINUTE)\n```\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.step(rate_limits=[RateLimit(key='example-limit', units=1)])\ndef step1(self, context: Context):\n    print(\"executed step1\")\n    pass\n```\n\n----------------------------------------\n\nTITLE: Initializing a new Go project\nDESCRIPTION: This command initializes a new Go module, which is required for managing dependencies in a Go project. This needs to be run before defining the Go Hatchet worker.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\ngo mod init my-hatchet-project\n```\n\n----------------------------------------\n\nTITLE: Pushing a Single Event with Hatchet Go Client\nDESCRIPTION: This code snippet demonstrates how to push a single event to the Hatchet event processing system using the `Event().Push` method of the Go client. It initializes a Hatchet client, creates a `TestEvent` instance, and then pushes the event with a specified event name. The event is serialized to JSON before being sent.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/go-sdk/pushing-events.mdx#_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nc, err := client.New(\n  client.WithHostPort(\"127.0.0.1\", 7077),\n)\n\nif err != nil {\n  panic(err)\n}\n\nc.Event().Push(\n  context.Background(),\n  \"test-called\",\n  &events.TestEvent{\n    Name: \"testing\",\n  },\n)\n```\n\n----------------------------------------\n\nTITLE: Scheduling Task (Python)\nDESCRIPTION: Schedules a Hatchet task to run tomorrow and schedules another task to run every day at midnight using cron scheduling. Requires the `datetime` and `timedelta` modules.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntomorrow = datetime.today() + timedelta(days=1)\n\n# schedule a task to run tomorrow\nscheduled = simple.schedule(\n  tomorrow,\n  SimpleInput(message=\"Hello, World!\")\n)\n\n# schedule a task to run every day at midnight\ncron = simple.cron(\n  \"every-day\",\n  \"0 0 * * *\",\n  SimpleInput(message=\"Hello, World!\")\n)\n```\n\n----------------------------------------\n\nTITLE: Listing Cron Triggers - Python (Async)\nDESCRIPTION: Lists all workflow cron triggers matching the specified criteria using the Hatchet SDK in Python (asynchronous).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-async.py\n```\n\n----------------------------------------\n\nTITLE: Fetching Snippets for Static Props in Next.js (TypeScript)\nDESCRIPTION: This snippet utilizes the `getSnippets` function to fetch code snippets for static properties in a Next.js page. It imports necessary modules and exports a `getStaticProps` function that calls `getSnippets` with an array of worker configurations. These configurations point to specific code files.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-typescript.mdx#_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\nimport { Callout } from \"nextra/components\";\n\nexport const getStaticProps = ({}) =>\n  getSnippets([SimpleWorker, FanoutWorker, DagsWorker, SimpleRun]);\n```\n\n----------------------------------------\n\nTITLE: Exponential Backoff in Go (GithubSnippet)\nDESCRIPTION: This section refers to a Go GithubSnippet which contains example of implementing Exponential Backoff using retries feature.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/retries/simple.mdx#_snippet_8\n\n\n\n----------------------------------------\n\nTITLE: Deleting Cron Trigger - Typescript\nDESCRIPTION: Deletes a cron trigger using the Hatchet SDK in Typescript, either by passing the cron object or the cron trigger ID.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nsrc/examples/crons/programatic-crons.ts\n```\n\n----------------------------------------\n\nTITLE: Navigating to Project Directory\nDESCRIPTION: This command changes the current directory to the cloned Hatchet TypeScript quickstart project. It is necessary to execute subsequent commands within the project's root directory.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_clone/ts.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd hatchet-typescript-quickstart\n```\n\n----------------------------------------\n\nTITLE: SimpleGenAiWorkflow Input Example\nDESCRIPTION: This JSON payload represents the input for the `SimpleGenAiWorkflow`. It contains a list of messages with a user role and content, likely intended for a chat-based AI model.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/launches/prompt-engineering.mdx#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Are cows reptiles?\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Encryption Keys\nDESCRIPTION: This script generates the necessary encryption keys for Hatchet using `openssl` and Docker. It creates a keys directory, generates random strings for secrets, and outputs a YAML file containing the keys and secrets. Requires Docker and OpenSSL to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n#!/bin/bash\n\n# Define an alias for generating random strings. This needs to be a function in a script.\nrandstring() {\n    openssl rand -base64 69 | tr -d \"\\n=+/\" | cut -c1-$1\n}\n\n# Create keys directory\nmkdir -p ./keys\n\n# Function to clean up the keys directory\ncleanup() {\n    rm -rf ./keys\n}\n\n# Register the cleanup function to be called on the EXIT signal\ntrap cleanup EXIT\n\n# Check if Docker is installed\nif ! command -v docker &> /dev/null\nthen\n    echo \"Docker could not be found. Please install Docker.\"\n    exit 1\nfi\n\n# Generate keysets using Docker\ndocker run --user $(id -u):$(id -g) -v $(pwd)/keys:/hatchet/keys ghcr.io/hatchet-dev/hatchet/hatchet-admin:latest /hatchet/hatchet-admin keyset create-local-keys --key-dir /hatchet/keys\n\n# Read keysets from files\nSERVER_ENCRYPTION_MASTER_KEYSET=$(<./keys/master.key)\nSERVER_ENCRYPTION_JWT_PRIVATE_KEYSET=$(<./keys/private_ec256.key)\nSERVER_ENCRYPTION_JWT_PUBLIC_KEYSET=$(<./keys/public_ec256.key)\n\n# Generate the random strings for SERVER_AUTH_COOKIE_SECRETS\nSERVER_AUTH_COOKIE_SECRET1=$(randstring 16)\nSERVER_AUTH_COOKIE_SECRET2=$(randstring 16)\n\n# Create the YAML file\ncat > hatchet-secret.yaml <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hatchet-secret\n  namespace: hatchet\nstringData:\n  SERVER_AUTH_COOKIE_SECRETS: \"$SERVER_AUTH_COOKIE_SECRET1 $SERVER_AUTH_COOKIE_SECRET2\"\n  SERVER_ENCRYPTION_MASTER_KEYSET: \"$SERVER_ENCRYPTION_MASTER_KEYSET\"\n  SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET: \"$SERVER_ENCRYPTION_JWT_PRIVATE_KEYSET\"\n  SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET: \"$SERVER_ENCRYPTION_JWT_PUBLIC_KEYSET\"\nEOF\n```\n\n----------------------------------------\n\nTITLE: Importing Hatchet client\nDESCRIPTION: Imports the Hatchet client from the `hatchet-client.ts` file. This allows other files in the project to access the initialized Hatchet client.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/ts.mdx#_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { hatchet } from \"./hatchet-client\";\n```\n\n----------------------------------------\n\nTITLE: Adding Worker Script to package.json\nDESCRIPTION: This JSON snippet shows how to add a script to the `package.json` file to start the TypeScript worker using `ts-node`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  // ...rest of your `package.json`\n  \"scripts\": {\n    // ...existing scripts\n    \"worker\": \"npx ts-node worker.ts\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Optimizing Production Dependencies\nDESCRIPTION: These Dockerfile snippets optimize production images by setting the `NODE_ENV` to `production` and installing only production dependencies using `npm ci --omit=dev`, `pnpm install --frozen-lockfile --prod`, or `yarn install --frozen-lockfile --production`. This reduces the size of the final image.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/docker.mdx#_snippet_4\n\nLANGUAGE: dockerfile\nCODE:\n```\n# Set production environment\nENV NODE_ENV=production\n\n# Install only production dependencies\nRUN npm ci --omit=dev\n# or\nRUN pnpm install --frozen-lockfile --prod\n# or\nRUN yarn install --frozen-lockfile --production\n```\n\n----------------------------------------\n\nTITLE: Create Pull Request from Step Run using hatchet_sdk in Python\nDESCRIPTION: This snippet creates a pull request for a workflow using the `step_run_update_create_pr` method of the `WorkflowApi`. It requires the `step_run` ID and a `CreatePullRequestFromStepRun` object as input. It returns a `CreatePullRequestFromStepRun` object. It uses API key (cookieAuth) or Bearer authentication (bearerAuth).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport hatchet_sdk.clients.rest\nfrom hatchet_sdk.clients.rest.models.create_pull_request_from_step_run import CreatePullRequestFromStepRun\nfrom hatchet_sdk.clients.rest.rest import ApiException\nfrom pprint import pprint\n\n# Defining the host is optional and defaults to http://localhost\n# See configuration.py for a list of all supported configuration parameters.\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    step_run = 'step_run_example' # str | The step run id\n    create_pull_request_from_step_run = hatchet_sdk.clients.rest.CreatePullRequestFromStepRun() # CreatePullRequestFromStepRun | The input to create a pull request\n\n    try:\n        # Create pull request\n        api_response = api_instance.step_run_update_create_pr(step_run, create_pull_request_from_step_run)\n        print(\"The response of WorkflowApi->step_run_update_create_pr:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->step_run_update_create_pr: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Starting the Go Worker\nDESCRIPTION: This command starts the Go Hatchet worker.  It assumes that the `main.go` has been created.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\ngo run main.go\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Client File\nDESCRIPTION: Creates an empty file named `hatchet-client.py`. This file will contain the Hatchet client instantiation code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/py.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntouch hatchet-client.py\n```\n\n----------------------------------------\n\nTITLE: UniversalTabs component with tabs\nDESCRIPTION: This JSX snippet utilizes the UniversalTabs component to present different Hatchet project setup options within a tabbed interface.  Each Tabs.Tab component represents a different setup method: Cloning a quickstart project, creating a new project from scratch, and adding Hatchet to an existing project.  The imported New, Existing, and Clone components are rendered within each tab.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/tabs.mdx#_snippet_2\n\nLANGUAGE: JSX\nCODE:\n```\n<UniversalTabs\n  items={[\n    \"Clone a Quickstart Project\",\n    \"Create a New Project from Scratch\",\n    \"Add to an Existing Project\",\n  ]}\n  optionKey=\"setup\"\n>\n  <Tabs.Tab title=\"Clone a Quickstart Project\">\n    <Clone />\n  </Tabs.Tab>\n  <Tabs.Tab title=\"Create a New Project from Scratch\">\n    <New />\n  </Tabs.Tab>\n  <Tabs.Tab title=\"Add Hatchet to an Existing Project\">\n    <Existing />\n  </Tabs.Tab>\n</UniversalTabs>\n```\n\n----------------------------------------\n\nTITLE: Installing Python Hatchet SDK and dotenv\nDESCRIPTION: These commands install the necessary Python packages for interacting with the Hatchet SDK and loading environment variables from a `.env` file. Dependencies: python, pip.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/hatchet-cloud-quickstart.mdx#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npip install python-dotenv\n```\n\nLANGUAGE: sh\nCODE:\n```\npip install hatchet-sdk\n```\n\n----------------------------------------\n\nTITLE: Defining Docker Compose Configuration\nDESCRIPTION: Defines the Docker Compose configuration for Hatchet Lite, including the Postgres database and the Hatchet Lite service. It sets up environment variables, ports, volumes, and health checks for the Postgres service.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nversion: \"3.8\"\nname: hatchet-lite\nservices:\n  postgres:\n    image: postgres:15.6\n    command: postgres -c 'max_connections=200'\n    restart: always\n    environment:\n      - POSTGRES_USER=hatchet\n      - POSTGRES_PASSWORD=hatchet\n      - POSTGRES_DB=hatchet\n    volumes:\n      - hatchet_lite_postgres_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -d hatchet -U hatchet\"]\n      interval: 10s\n      timeout: 10s\n      retries: 5\n      start_period: 10s\n  hatchet-lite:\n    image: ghcr.io/hatchet-dev/hatchet/hatchet-lite:latest\n    ports:\n      - \"8888:8888\"\n      - \"7077:7077\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n    environment:\n      RABBITMQ_DEFAULT_USER: \"user\"\n      RABBITMQ_DEFAULT_PASS: \"password\"\n      DATABASE_URL: \"postgresql://hatchet:hatchet@postgres:5432/hatchet?sslmode=disable\"\n      SERVER_TASKQUEUE_RABBITMQ_URL: amqp://user:password@localhost:5672/\n      SERVER_AUTH_COOKIE_DOMAIN: localhost\n      SERVER_AUTH_COOKIE_INSECURE: \"t\"\n      SERVER_GRPC_BIND_ADDRESS: \"0.0.0.0\"\n      SERVER_GRPC_INSECURE: \"t\"\n      SERVER_GRPC_BROADCAST_ADDRESS: localhost:7077\n      SERVER_GRPC_PORT: \"7077\"\n      SERVER_URL: http://localhost:8888\n      SERVER_AUTH_SET_EMAIL_VERIFIED: \"t\"\n      SERVER_LOGGER_LEVEL: warn\n      SERVER_LOGGER_FORMAT: console\n      DATABASE_LOGGER_LEVEL: warn\n      DATABASE_LOGGER_FORMAT: console\n    volumes:\n      - \"hatchet_lite_rabbitmq_data:/var/lib/rabbitmq\"\n      - \"hatchet_lite_config:/config\"\n\nvolumes:\n  hatchet_lite_postgres_data:\n  hatchet_lite_rabbitmq_data:\n  hatchet_lite_config:\n```\n\n----------------------------------------\n\nTITLE: Add Worker Script to Package.json\nDESCRIPTION: Adds a 'worker' script to the package.json file to easily start the Hatchet worker using `npm run worker`.  This script executes the `worker.ts` file using `ts-node`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/index.mdx#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  // ...rest of your `package.json`\n  \"scripts\": {\n    // ...existing scripts\n    \"worker\": \"npx ts-node worker.ts\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Step Outputs in Hatchet (Python)\nDESCRIPTION: This code snippet illustrates how to define step outputs within a Hatchet workflow. The `step1` function returns a dictionary containing a single key-value pair: `step-1-output` with the value `test`. This output can be accessed by subsequent steps using `context.step_output(\"step1\")`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/workflow.mdx#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n@hatchet.workflow(on_events=[\"user:create\"])\nclass MyWorkflow:\n    @hatchet.step()\n    def step1(self, context : Context):\n        return {\n            \"step-1-output\": \"test\"\n        }\n```\n\n----------------------------------------\n\nTITLE: Configure Shared Settings in Helm Chart (YAML)\nDESCRIPTION: This snippet demonstrates how to configure shared settings for Hatchet backend services using the `sharedConfig` object in the `values.yaml` file. It includes common settings like `serverUrl`, authentication-related configurations, gRPC endpoint details, and default admin credentials.  It also allows overriding default settings with the `env` key.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/self-hosting/kubernetes-helm-configuration.mdx#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsharedConfig:\n  # you can disable shared config by setting this to false\n  enabled: true\n\n  # these are the most commonly configured values\n  serverUrl: \"http://localhost:8080\"\n  serverAuthCookieDomain: \"localhost:8080\" # the domain for the auth cookie\n  serverAuthCookieInsecure: \"t\" # allows cookies to be set over http\n  serverAuthSetEmailVerified: \"t\" # automatically sets email_verified to true for all users\n  serverAuthBasicAuthEnabled: \"t\" # allows login via basic auth (email/password)\n  grpcBroadcastAddress: \"localhost:7070\" # the endpoint for the gRPC server, exposed via the `grpc` service\n  grpcInsecure: \"true\" # allows gRPC to be served over http\n  defaultAdminEmail: \"admin@example.com\" # in exposed/production environments, change this to a valid email\n  defaultAdminPassword: \"Admin123!!\" # in exposed/production environments, change this to a secure password\n\n  # you can set additional environment variables here, which will override any defaults\n  env: {}\n```\n\n----------------------------------------\n\nTITLE: Create Project Directories - Bash\nDESCRIPTION: This command creates two new directories: `workflows` and `workers`. These directories are intended to store workflow definitions and worker implementations, respectively.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/go.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir workflows &&\nmkdir workers\n```\n\n----------------------------------------\n\nTITLE: WorkflowRunList Usage Example - Python\nDESCRIPTION: This snippet demonstrates how to create, serialize, and deserialize a WorkflowRunList object in Python. It showcases converting a JSON string to a WorkflowRunList instance, converting the object to a dictionary, and back from a dictionary to an object. The `WorkflowRunList` class is assumed to be part of the `hatchet_sdk.clients.rest.models` module.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowRunList.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_run_list import WorkflowRunList\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowRunList from a JSON string\nworkflow_run_list_instance = WorkflowRunList.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowRunList.to_json()\n\n# convert the object into a dict\nworkflow_run_list_dict = workflow_run_list_instance.to_dict()\n# create an instance of WorkflowRunList from a dict\nworkflow_run_list_form_dict = workflow_run_list.from_dict(workflow_run_list_dict)\n```\n\n----------------------------------------\n\nTITLE: Querying the logs table\nDESCRIPTION: This SQL query retrieves log entries from the `logs` table within a specific time range for a given tenant and resource. The results are ordered by the creation timestamp in descending order. The query uses the index on `(tenant_id, resource_id, created_at)` for efficient retrieval.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\nSELECT *\nFROM logs\nWHERE created_at >= '2024-10-19 20:06:45.570503+00'\nAND created_at <= '2024-11-19 20:06:45.570503+00'\nAND tenant_id = '77b7ed39-d3e0-4dec-a28a-6d1e69315d57'\nAND resource_id = 'b4d2e415-d957-438f-8340-50ef8f73badf'\nORDER BY created_at DESC;\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Client File\nDESCRIPTION: This command creates an empty file named 'hatchet_client.py' inside the 'src' directory. This file will contain the Hatchet client instantiation.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_new/py.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ntouch src/hatchet_client.py\n```\n\n----------------------------------------\n\nTITLE: Aborting Network Requests with Axios (Typescript)\nDESCRIPTION: This code illustrates how to abort network requests made with Axios when a Hatchet workflow step is canceled. It passes the `AbortSignal` from the `context.controller` to the Axios request configuration.  It relies on the axios library for making HTTP requests and the Hatchet framework's `Context` and `Step` types.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/cancellation.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport axios from \"axios\";\n\nconst myStep: Step = async (context: Context) => {\n  const { signal } = context.controller;\n\n  try {\n    const response = await axios.get(\"https://api.example.com/data\", {\n      signal,\n    });\n    // Handle the response\n    // ...\n  } catch (error) {\n    if (axios.isCancel(error)) {\n      // Request was canceled\n      console.log(\"Request canceled\");\n    } else {\n      // Handle other errors\n      // ...\n    }\n  }\n};\n```\n\n----------------------------------------\n\nTITLE: Starting the TypeScript Worker\nDESCRIPTION: This command starts the TypeScript Hatchet worker script using `npm`. It assumes that the `worker` script has been added to the `package.json` file.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\nnpm run worker\n```\n\n----------------------------------------\n\nTITLE: WorkflowRunTriggeredBy JSON Example\nDESCRIPTION: This snippet demonstrates how to create an instance of WorkflowRunTriggeredBy from a JSON string, convert it to a dictionary, and then create a new instance from the dictionary. It utilizes the `from_json`, `to_json`, `to_dict`, and `from_dict` methods of the `WorkflowRunTriggeredBy` class. Requires the `hatchet_sdk` library. Assumes a JSON string is available and properly formatted.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowRunTriggeredBy.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_run_triggered_by import WorkflowRunTriggeredBy\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowRunTriggeredBy from a JSON string\nworkflow_run_triggered_by_instance = WorkflowRunTriggeredBy.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowRunTriggeredBy.to_json()\n\n# convert the object into a dict\nworkflow_run_triggered_by_dict = workflow_run_triggered_by_instance.to_dict()\n# create an instance of WorkflowRunTriggeredBy from a dict\nworkflow_run_triggered_by_form_dict = workflow_run_triggered_by.from_dict(workflow_run_triggered_by_dict)\n```\n\n----------------------------------------\n\nTITLE: Change Directory\nDESCRIPTION: Changes the current working directory to the specified project directory. This command is essential for ensuring subsequent commands are executed in the correct location.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/py.mdx#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncd path-to-your-project\n```\n\n----------------------------------------\n\nTITLE: Defining WorkerList Interface\nDESCRIPTION: This TypeScript interface defines the structure of a list of workers returned from the Hatchet API. It includes optional pagination information (`PaginationResponse`) and an optional array of `Worker` objects. The interface is used to represent the response from the API when retrieving a list of workers.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.WorkerList.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: WorkerList\n */\n\n/**\n * [APIContracts](../modules/APIContracts.md).WorkerList\n */\n\ninterface WorkerList {\n  /**\n   * Optional pagination\n   */\n  pagination?: PaginationResponse;\n\n  /**\n   * Optional rows\n   */\n  rows?: Worker[];\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet TLS Strategy Environment Variable\nDESCRIPTION: Sets the HATCHET_CLIENT_TLS_STRATEGY environment variable to 'none' for self-hosted users without TLS. This step is not required for Hatchet Cloud users, as TLS is enabled by default. Setting this variable is crucial for those without TLS to connect correctly.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/setup.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport HATCHET_CLIENT_TLS_STRATEGY=none\n```\n\n----------------------------------------\n\nTITLE: Configuring RabbitMQ QOS (Shell)\nDESCRIPTION: This snippet shows how to configure the RabbitMQ QOS (Quality of Service) setting using the `SERVER_MSGQUEUE_RABBITMQ_QOS` environment variable. This setting controls the number of messages that can be processed in parallel by the Hatchet engine. Increasing this value can improve throughput for step runs, but it should be balanced with the database connection limits to avoid saturating connections.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/improving-performance.mdx#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nSERVER_MSGQUEUE_RABBITMQ_QOS=200\n```\n\n----------------------------------------\n\nTITLE: Importing React components from local files\nDESCRIPTION: This snippet imports React components, UniversalTabs, New, Existing, and Clone from local files.  UniversalTabs is likely a custom component for managing tabs, while New, Existing, and Clone are likely React components representing the content for each tab, corresponding to different project setup methods.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/tabs.mdx#_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport UniversalTabs from \"@/components/UniversalTabs\";\nimport New from \"./new.mdx\";\nimport Existing from \"./existing.mdx\";\nimport Clone from \"./clone.mdx\";\n```\n\n----------------------------------------\n\nTITLE: WorkflowTriggerEventRef Usage Example Python\nDESCRIPTION: This snippet demonstrates how to create, serialize, and deserialize a WorkflowTriggerEventRef object using the hatchet-sdk in Python. It includes converting from a JSON string, converting to a JSON string, converting to a dictionary, and converting from a dictionary.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowTriggerEventRef.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_trigger_event_ref import WorkflowTriggerEventRef\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowTriggerEventRef from a JSON string\nworkflow_trigger_event_ref_instance = WorkflowTriggerEventRef.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowTriggerEventRef.to_json()\n\n# convert the object into a dict\nworkflow_trigger_event_ref_dict = workflow_trigger_event_ref_instance.to_dict()\n# create an instance of WorkflowTriggerEventRef from a dict\nworkflow_trigger_event_ref_form_dict = workflow_trigger_event_ref.from_dict(workflow_trigger_event_ref_dict)\n```\n\n----------------------------------------\n\nTITLE: Starting the Python Worker\nDESCRIPTION: This command starts the Python Hatchet worker script. It requires Python 3 and the necessary dependencies to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\npython3 worker.py\n```\n\n----------------------------------------\n\nTITLE: Killing Prisma Query Engines with Task\nDESCRIPTION: This snippet uses the `task` command-line tool to kill spawned query engines from Prisma, typically needed on OSX during hot reloading. It assumes that the `task` tool is installed and configured with the necessary tasks defined.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\ntask kill-query-engines\n```\n\n----------------------------------------\n\nTITLE: Defining Step Interface in Typescript\nDESCRIPTION: This code snippet defines the `Step` interface, which specifies the structure for representing a step in a Hatchet workflow. It includes properties such as `action` (the action to execute), `jobId` (the ID of the job), `metadata` (associated metadata), `parents` (parent step IDs), `children` (child step IDs), `readableId` (a human-readable identifier), `tenantId` (the ID of the tenant), and `timeout` (the step timeout). The interface is used by the Hatchet TypeScript SDK for data contracts.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.Step.md#_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\n/**\n * Step\n */\ninterface Step {\n  /**\n   * action\n   */\n  action: string;\n  /**\n   * jobId\n   */\n  jobId: string;\n  /**\n   * metadata\n   */\n  metadata: APIResourceMeta;\n  /**\n   * readableId\n   *\n   * The readable id of the step.\n   */\n  readableId: string;\n  /**\n   * tenantId\n   */\n  tenantId: string;\n  /**\n   * children\n   */\n  children?: string[];\n  /**\n   * parents\n   */\n  parents?: string[];\n  /**\n   * timeout\n   *\n   * The timeout of the step.\n   */\n  timeout?: string;\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Assignment (Typescript)\nDESCRIPTION: Defines Hatchet workflows with sticky assignment strategies in Typescript. One workflow prefers to run on the same worker (SOFT), while the other requires it (HARD).\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/README.md#_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\n// create a workflow which prefers to run on the same worker, but can be\n// scheduled on any worker if the original worker is busy\nhatchet.workflow({\n  name: \"StickyWorkflow\",\n  sticky: StickyStrategy.SOFT,\n});\n\n// create a workflow which must run on the same worker\nhatchet.workflow({\n  name: \"StickyWorkflow\",\n  sticky: StickyStrategy.HARD,\n});\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Task with Hatchet V1 SDK in Python\nDESCRIPTION: This snippet demonstrates how to define a simple task using the Hatchet V1 SDK. It highlights the use of `hatchet.task` for task declaration, the new task signature with `input` and `context` arguments, and how to register workflows on a worker using the `workflows` keyword argument. The `input` is either of type `input_validator` (a Pydantic model you provide to the workflow), or is an `EmptyModel`, which is a helper Pydantic model Hatchet provides and uses as a default. The `context` is once again the Hatchet `Context` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/migration-guide-python.mdx#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport { GithubSnippet, getSnippets } from \"@/components/code\";\n\nexport const SimpleWorker = {\n  path: \"examples/simple/worker.py\",\n};\nexport const PydanticWorker = {\n  path: \"examples/fanout/worker.py\",\n};\n\nexport const getStaticProps = ({}) =>\n  getSnippets([SimpleWorker, PydanticWorker]);\n```\n\n----------------------------------------\n\nTITLE: Create Hatchet Client Directory/File\nDESCRIPTION: Creates the `hatchet_client` directory and `main.go` file. This directory will contain code related to the Hatchet client initialization.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/go.mdx#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir hatchet_client &&\ntouch hatchet_client/main.go\n```\n\n----------------------------------------\n\nTITLE: Creating WorkflowRun instance from JSON (Python)\nDESCRIPTION: This snippet demonstrates how to create an instance of the WorkflowRun class from a JSON string, using the from_json method. It also shows how to convert a WorkflowRun object to a JSON string using the to_json method. The snippet utilizes the hatchet_sdk library.  It prints a placeholder to_json representation, and requires the 'hatchet_sdk' library to be installed.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowRun.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_run import WorkflowRun\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowRun from a JSON string\nworkflow_run_instance = WorkflowRun.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowRun.to_json()\n\n```\n\n----------------------------------------\n\nTITLE: CloudKMS Keyring and Key Creation using gcloud\nDESCRIPTION: These snippets use the `gcloud` command-line tool to create a CloudKMS keyring and key for encryption purposes. It specifies the location, keyring name, key name, and key purpose.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\ngcloud kms keyrings create \"development\" --location \"global\"\ngcloud kms keys create \"development\" --location \"global\" --keyring \"development\" --purpose \"encryption\"\ngcloud kms keys list --location \"global\" --keyring \"development\"\n```\n\n----------------------------------------\n\nTITLE: Number of Pages Example\nDESCRIPTION: This code shows an example of the num_pages property within the PaginationResponse interface. This property is an optional number representing the total number of pages. The expected format is an integer.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.PaginationResponse.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n10\n```\n\n----------------------------------------\n\nTITLE: Defining UserTenantMembershipsList Interface (TypeScript)\nDESCRIPTION: This code snippet defines the `UserTenantMembershipsList` interface, which represents a list of tenant memberships for a user. It includes optional pagination information and an array of `TenantMember` objects.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UserTenantMembershipsList.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: UserTenantMembershipsList\n */\n\n/**\n * @module APIContracts\n */\n\nexport interface UserTenantMembershipsList {\n  /**\n   * Optional pagination information for the list of tenant memberships.\n   */\n  pagination?: PaginationResponse;\n\n  /**\n   * Optional array of TenantMember objects representing the tenant memberships.\n   */\n  rows?: TenantMember[];\n}\n\n```\n\n----------------------------------------\n\nTITLE: Creating Cron Trigger Programmatically - Python (Async)\nDESCRIPTION: Creates a cron trigger programmatically using the Hatchet SDK in Python (asynchronous). This allows for dynamic cron schedules defined at runtime.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/triggering-runs/cron-trigger.mdx#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nexamples/cron/programatic-async.py\n```\n\n----------------------------------------\n\nTITLE: Installing TypeScript Dependencies\nDESCRIPTION: These commands install the required TypeScript dependencies for the Hatchet worker.  It installs the `@hatchet-dev/typescript-sdk` and `dotenv`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nnpm i @hatchet-dev/typescript-sdk\nnpm i dotenv\n```\n\n----------------------------------------\n\nTITLE: Compute Configuration with Shared CPUs and Memory Scaling (Python)\nDESCRIPTION: This snippet demonstrates how to configure a `Compute` object with 'shared' CPU type, specifying the number of CPUs and memory allocation.  It includes example memory calculation and validation. The `memory_mb` parameter must be between the minimum and maximum allowed memory for the specified CPU type.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/compute/cpu.mdx#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\n# 4 shared CPUs\nmax_memory = 2048 * 4  # = 8192 MB (8GB)\nmin_memory = 256 * 4   # = 1024 MB (1GB)\n\ncompute = Compute(\n    cpu_kind=\"shared\",\n    cpus=4,\n    memory_mb=4096,    # Must be between min_memory and max_memory\n    num_replicas=1,\n    regions=[\"ewr\"]\n)\n```\n\n----------------------------------------\n\nTITLE: APIMeta Instance Creation and Conversion in Python\nDESCRIPTION: This code snippet demonstrates how to create an instance of the APIMeta model from a JSON string, convert the object to a dictionary and vice versa. It uses the `hatchet_sdk` library and assumes the existence of an `APIMeta` class with `from_json`, `to_json` and `to_dict` methods. It also showcases printing the JSON string representation of the APIMeta object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIMeta.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_meta import APIMeta\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIMeta from a JSON string\napi_meta_instance = APIMeta.from_json(json)\n# print the JSON string representation of the object\nprint APIMeta.to_json()\n\n# convert the object into a dict\napi_meta_dict = api_meta_instance.to_dict()\n# create an instance of APIMeta from a dict\napi_meta_form_dict = api_meta.from_dict(api_meta_dict)\n```\n\n----------------------------------------\n\nTITLE: WorkflowVersionMeta Example Usage\nDESCRIPTION: Demonstrates how to create, serialize, and deserialize the WorkflowVersionMeta object using `from_json()`, `to_json()`, `to_dict()`, and `from_dict()` methods. It showcases the conversion between JSON string, Python dictionary, and the WorkflowVersionMeta object. Requires the `hatchet_sdk` package.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowVersionMeta.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow_version_meta import WorkflowVersionMeta\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of WorkflowVersionMeta from a JSON string\nworkflow_version_meta_instance = WorkflowVersionMeta.from_json(json)\n# print the JSON string representation of the object\nprint WorkflowVersionMeta.to_json()\n\n# convert the object into a dict\nworkflow_version_meta_dict = workflow_version_meta_instance.to_dict()\n# create an instance of WorkflowVersionMeta from a dict\nworkflow_version_meta_form_dict = workflow_version_meta.from_dict(workflow_version_meta_dict)\n```\n\n----------------------------------------\n\nTITLE: Workflow Example Usage in Python\nDESCRIPTION: This code demonstrates how to create a Workflow object from a JSON string, convert it to a dictionary, and convert a dictionary back to a Workflow object using the hatchet-sdk.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/Workflow.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.workflow import Workflow\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of Workflow from a JSON string\nworkflow_instance = Workflow.from_json(json)\n# print the JSON string representation of the object\nprint Workflow.to_json()\n\n# convert the object into a dict\nworkflow_dict = workflow_instance.to_dict()\n# create an instance of Workflow from a dict\nworkflow_form_dict = workflow.from_dict(workflow_dict)\n```\n\n----------------------------------------\n\nTITLE: Create Directories for Workflows/Workers\nDESCRIPTION: Creates the `workflows` and `workers` directories, following the recommended project structure for organizing Hatchet workflows and worker definitions. Using separate directories helps maintain project organization and clarity.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/_existing/go.mdx#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmkdir workflows &&\nmkdir workers\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet via Glasskube CLI\nDESCRIPTION: This command installs Hatchet using the Glasskube CLI. It assumes that Glasskube is installed and configured to interact with the Kubernetes cluster.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/kubernetes-glasskube.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nglasskube install hatchet\n```\n\n----------------------------------------\n\nTITLE: Configuring Engine Ingress with Nginx and Cert-Manager (YAML)\nDESCRIPTION: This snippet configures an Nginx ingress for the Hatchet Engine service, enabling SSL with cert-manager. It defines annotations for certificate issuance, TLS verification, gRPC backend configuration, and backend protocol. It also includes server snippets to adjust gRPC timeouts and specifies hostnames, paths, and backend service details for routing traffic to the engine service.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/networking.mdx#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nengine:\n  ingress:\n    enabled: true\n    ingressClassName: nginx\n    labels: {}\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      nginx.ingress.kubernetes.io/auth-tls-verify-client: \"optional\"\n      nginx.ingress.kubernetes.io/auth-tls-secret: \"${kubernetes_namespace.cloud.metadata[0].name}/engine-cert\"\n      nginx.ingress.kubernetes.io/auth-tls-verify-depth: \"1\"\n      nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: \"true\"\n      nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      nginx.ingress.kubernetes.io/grpc-backend: \"true\"\n      nginx.ingress.kubernetes.io/server-snippet: |\n        grpc_read_timeout 1d;\n        grpc_send_timeout 1h;\n        client_header_timeout 1h;\n        client_body_timeout 1h;\n    hosts:\n      - host: engine.hatchet.example.com\n        paths:\n          - path: /\n        backend:\n          serviceName: hatchet-engine\n          servicePort: 7070\n    tls:\n      - hosts:\n          - engine.hatchet.example.com\n        secretName: engine-cert\n        servicePort: 7070\n```\n\n----------------------------------------\n\nTITLE: Running Typescript Hatchet Worker\nDESCRIPTION: Starts the Typescript Hatchet worker by executing the `worker` script defined in the `package.json` file using `npm run`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nnpm run worker\n```\n\n----------------------------------------\n\nTITLE: Building the SDK with pnpm\nDESCRIPTION: This command builds the Hatchet TypeScript SDK after the dependencies have been installed. It is required to compile the source code.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm build\n```\n\n----------------------------------------\n\nTITLE: Creating APIMetaIntegration from JSON\nDESCRIPTION: This snippet demonstrates how to create an instance of the APIMetaIntegration class from a JSON string using the `from_json` method. It assumes the `hatchet_sdk.clients.rest.models.api_meta_integration` module is available and imported.  The JSON string is initially empty but should be populated with valid APIMetaIntegration data. The result is an `APIMetaIntegration` object.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/APIMetaIntegration.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.api_meta_integration import APIMetaIntegration\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of APIMetaIntegration from a JSON string\napi_meta_integration_instance = APIMetaIntegration.from_json(json)\n```\n\n----------------------------------------\n\nTITLE: Making a POST Request to the API Endpoint with curl in Shell\nDESCRIPTION: This curl command sends a POST request to the `/message` endpoint with a JSON payload containing a message and a URL. The payload represents a `MessageRequest` object, triggering the Hatchet workflow upon successful submission.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/tutorials/fastapi-react/api-server-setup.mdx#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST -H \"Content-Type: application/json\" -d '{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"how do i install hatchet?\"\n        }\n    ],\n    \"url\": \"https://docs.hatchet.run/home\"\n}' http://localhost:8000/message\n```\n\n----------------------------------------\n\nTITLE: Defining CANCEL_IN_PROGRESS Concurrency Limit using Key Function in Go\nDESCRIPTION: This Go snippet defines a concurrency key function `getConcurrencyKey` to determine the concurrency limit. It cancels in-progress workflows based on `UserId`.  Requires the `hatchet-dev/hatchet/pkg/client/types` and `hatchet-dev/hatchet/pkg/worker` packages.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/concurrency/cancel-in-progress.mdx#_snippet_5\n\nLANGUAGE: go\nCODE:\n```\nimport (\n  \"github.com/hatchet-dev/hatchet/pkg/client/types\"\n  \"github.com/hatchet-dev/hatchet/pkg/worker\"\n)\n\ntype MyUser struct {\n    UserId string `json:\"user_id\"`\n}\n\nfunc getConcurrencyKey(ctx worker.HatchetContext) (string, error) {\n  event := &MyUser{}\n  err := ctx.WorkflowInput(event)\n\n    if err != nil {\n        return \"\", err\n    }\n\n    return event.UserId, nil\n\n}\n\nerr = w.RegisterWorkflow(\n    &worker.WorkflowJob{\n        Name: \"concurrency-limit-per-user\",\n        On: worker.Events(\"concurrency-test-event\"),\n        Description: \"This limits concurrency to 1 run at a time per user.\",\n        Concurrency: worker.Concurrency(getConcurrencyKey).MaxRuns(10).LimitStrategy(types.CancelInProgress),\n        Steps: []*worker.WorkflowStep{\n            // your steps here...\n        },\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Querying pg-events Simple Utility for performance testing\nDESCRIPTION: This bash command executes the `pg-events` utility with the `simple` subcommand, and the `query` command is issued to simulate queries against the events data generated by the utility, measuring query latency.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/postgres-events-table.mdx#_snippet_3\n\nLANGUAGE: txt\nCODE:\n```\n$ pg-events simple query\nquery samples: 1000\nelapsed time: 469.678042ms\naverage time per query: 469.678µs\n```\n\n----------------------------------------\n\nTITLE: Running Go Hatchet Worker\nDESCRIPTION: Starts the Go Hatchet worker by executing the `main.go` file using `go run`.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/self-hosting/hatchet-lite.mdx#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\ngo run main.go\n```\n\n----------------------------------------\n\nTITLE: Importing Nextra and Custom Components\nDESCRIPTION: This snippet imports necessary components from the 'nextra/components' library and a custom 'UniversalTabs' component. These components are used to structure the page and create the tabbed interface.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/_setup/new.mdx#_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { Callout, Card, Cards, Steps, Tabs } from \"nextra/components\";\nimport UniversalTabs from \"@/components/UniversalTabs\";\n```\n\n----------------------------------------\n\nTITLE: updatedAt Property Example\nDESCRIPTION: This example showcases the format of the `updatedAt` property within the APIResourceMeta interface.  It represents the last updated timestamp of the resource as a date-time string. The string must conform to the ISO 8601 format.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.APIResourceMeta.md#_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n\"2022-12-13T20:06:48.888Z\"\n```\n\n----------------------------------------\n\nTITLE: Installing Hatchet TypeScript SDK with pnpm\nDESCRIPTION: This code snippet shows how to install the Hatchet TypeScript SDK using pnpm.  It's another alternative for installation, useful for those preferring pnpm.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/sdks/typescript/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm add @hatchet-dev/typescript-sdk\n```\n\n----------------------------------------\n\nTITLE: PaginationResponse Instance Creation and Conversion (Python)\nDESCRIPTION: This snippet demonstrates how to create an instance of the PaginationResponse model from a JSON string, convert it to a dictionary, and then create another instance from that dictionary. It also shows how to print the JSON string representation of the class itself. Requires the hatchet_sdk library.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/PaginationResponse.md#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom hatchet_sdk.clients.rest.models.pagination_response import PaginationResponse\n\n# TODO update the JSON string below\njson = \"{}\"\n# create an instance of PaginationResponse from a JSON string\npagination_response_instance = PaginationResponse.from_json(json)\n# print the JSON string representation of the object\nprint PaginationResponse.to_json()\n\n# convert the object into a dict\npagination_response_dict = pagination_response_instance.to_dict()\n# create an instance of PaginationResponse from a dict\npagination_response_form_dict = pagination_response.from_dict(pagination_response_dict)\n```\n\n----------------------------------------\n\nTITLE: Defining Sticky Workflow with TypeScript\nDESCRIPTION: This code snippet demonstrates how to define a workflow in TypeScript with the `sticky` property set to `StickyStrategy.SOFT`. This ensures that all steps within the workflow will attempt to be assigned to the same worker for the duration of the workflow execution. The workflow is triggered by the 'user:created' event.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/sticky-assignment.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst myWorkflow: Workflow = {\n  id: \"my-workflow\",\n  description: \"A workflow triggered by an event\",\n  sticky: StickyStrategy.SOFT, // <-- specify the sticky strategy\n  on: {\n    event: \"user:created\",\n  },\n  steps: [\n    // Define your workflow steps here\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Releasing Slot in Typescript Hatchet Workflow\nDESCRIPTION: This Typescript snippet illustrates how to release a slot in a Hatchet workflow using the `ctx.releaseSlot()` method. Similar to the Python example, it simulates a resource-intensive task with `await sleep(5000)` and then releases the slot to allow other steps to run concurrently. Requires the Hatchet `Workflow` interface and a `sleep` function.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/advanced/manual-slot-release.mdx#_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nconst workflow: Workflow = {\n  // ... other workflow properties\n  steps: [\n    {\n      name: \"step1\",\n      run: async (ctx) => {\n        console.log(\"RESOURCE INTENSIVE PROCESS...\");\n        await sleep(5000);\n        // Release the slot after the resource-intensive process, so that other steps can run\n        await ctx.releaseSlot();\n        console.log(\"NON RESOURCE INTENSIVE PROCESS...\");\n        return { step1: \"step1 results!\" };\n      },\n    },\n  ],\n};\n\n```\n\n----------------------------------------\n\nTITLE: Dynamic Worker Labels - Python\nDESCRIPTION: This code snippet demonstrates how to dynamically update worker labels in a Hatchet step using Python. It checks the current value of the \"model\" label and, if it doesn't match the desired value, evicts the old model, loads a new model, and updates the worker's labels accordingly.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/home/features/worker-assignment/worker-affinity.mdx#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n    @hatchet.step(\n        desired_worker_labels={\n            \"model\": {\n              \"value\": \"fancy-vision-model\",\n              \"weight\": 10\n            },\n            \"memory\": {\n                \"value\": 256,\n                \"required\": True,\n                \"comparator\": WorkerLabelComparator.GREATER_THAN,\n            },\n        },\n    )\n    async def step(self, context: Context):\n        if context.worker.get_labels().get(\"model\") != \"fancy-vision-model\":\n            context.worker.upsert_labels({\"model\": \"unset\"})\n            # DO WORK TO EVICT OLD MODEL / LOAD NEW MODEL\n            evictModel()\n            loadNewModel(\"fancy-vision-model\")\n            context.worker.upsert_labels({\"model\": \"fancy-vision-model\"})\n\n        return {\"worker\": context.worker.id()}\n```\n\n----------------------------------------\n\nTITLE: Defining UserRegisterRequest Interface\nDESCRIPTION: Defines the `UserRegisterRequest` interface with properties for user registration. It includes `email`, `name`, and `password` fields as strings, defining the data structure for user registration requests within the Hatchet TypeScript SDK.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.UserRegisterRequest.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\ninterface UserRegisterRequest {\n  email: string;\n  name: string;\n  password: string;\n}\n```\n\n----------------------------------------\n\nTITLE: RerunStepRunRequest Interface Definition\nDESCRIPTION: Defines the structure for the request to rerun a step run. It includes an `input` property, which is an object containing the input data for the step rerun.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/typescript-sdk/_api/_interfaces/APIContracts.RerunStepRunRequest.md#_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n/**\n * Interface: RerunStepRunRequest\n *\n * [APIContracts](../modules/APIContracts.md).RerunStepRunRequest\n */\n\n/**\n *  Properties\n */\n\n/**\n * input\n *\n *• **input**: `object`\n *\n * Defined in\n *\n *[src/clients/rest/generated/data-contracts.ts:575](https://github.com/hatchet-dev/hatchet/blob/af21f67/typescript-sdk/src/clients/rest/generated/data-contracts.ts#L575)\n */\n```\n\n----------------------------------------\n\nTITLE: SQL Query to List All Axes\nDESCRIPTION: This SQL query retrieves all rows from the 'axes' table, ordered by the 'name' column. The `:many` annotation indicates that sqlc should generate code expecting multiple results. This query is used to fetch a list of axes from the database.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/blog/migrating-off-prisma.mdx#_snippet_9\n\nLANGUAGE: sql\nCODE:\n```\n-- name: ListAxes :many\nSELECT * FROM axes\nORDER BY name;\n```\n\n----------------------------------------\n\nTITLE: Defining Typescript file path for Hatchet manual slot release example\nDESCRIPTION: This code defines a constant `SlotReleaseTS` that stores the file path to a TypeScript example demonstrating manual slot release functionality within a Hatchet workflow. This path is then used to retrieve the code snippet for display.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/docs/pages/home/manual-slot-release.mdx#_snippet_1\n\nLANGUAGE: TypeScript\nCODE:\n```\nexport const SlotReleaseTS = {\n  path: \"src/examples/manual_slot_release.ts\",\n};\n```\n\n----------------------------------------\n\nTITLE: Starting the Hatchet Dev Server with Task\nDESCRIPTION: This snippet uses the `task` command-line tool to start the Hatchet engine, API server, dashboard, and Prisma studio. It assumes that the `task` tool is installed and configured with the necessary tasks defined.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ntask start-dev\n```\n\n----------------------------------------\n\nTITLE: Configuring API Client and Listing Pull Requests - Python\nDESCRIPTION: This snippet demonstrates how to configure the Hatchet SDK API client and list pull requests for a specific workflow run. It includes setting up authentication using an API key or a bearer token, creating an instance of the WorkflowApi class, and calling the workflow_run_list_pull_requests method. The code also includes error handling using a try-except block.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/_api/_types/WorkflowApi.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    host = \"http://localhost\"\n)\n\n# The client must configure the authentication and authorization parameters\n# in accordance with the API server security policy.\n# Examples for each auth method are provided below, use the example that\n# satisfies your auth use case.\n\n# Configure API key authorization: cookieAuth\nconfiguration.api_key['cookieAuth'] = os.environ[\"API_KEY\"]\n\n# Uncomment below to setup prefix (e.g. Bearer) for API key, if needed\n# configuration.api_key_prefix['cookieAuth'] = 'Bearer'\n\n# Configure Bearer authorization: bearerAuth\nconfiguration = hatchet_sdk.clients.rest.Configuration(\n    access_token = os.environ[\"BEARER_TOKEN\"]\n)\n\n# Enter a context with an instance of the API client\nwith hatchet_sdk.clients.rest.ApiClient(configuration) as api_client:\n    # Create an instance of the API class\n    api_instance = hatchet_sdk.clients.rest.WorkflowApi(api_client)\n    tenant = 'tenant_example' # str | The tenant id\n    workflow_run = 'workflow_run_example' # str | The workflow run id\n    state = hatchet_sdk.clients.rest.PullRequestState() # PullRequestState | The pull request state (optional)\n\n    try:\n        # List pull requests\n        api_response = api_instance.workflow_run_list_pull_requests(tenant, workflow_run, state=state)\n        print(\"The response of WorkflowApi->workflow_run_list_pull_requests:\\n\")\n        pprint(api_response)\n    except Exception as e:\n        print(\"Exception when calling WorkflowApi->workflow_run_list_pull_requests: %s\\n\" % e)\n```\n\n----------------------------------------\n\nTITLE: Setting Hatchet Client Token environment variable\nDESCRIPTION: This command sets the `HATCHET_CLIENT_TOKEN` environment variable. This token is necessary for authenticating with the Hatchet engine.\nSOURCE: https://github.com/hatchet-dev/hatchet/blob/main/frontend/v0-docs/pages/sdks/python-sdk/index.mdx#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nHATCHET_CLIENT_TOKEN=\"<your-api-key>\"\n```"
  }
]