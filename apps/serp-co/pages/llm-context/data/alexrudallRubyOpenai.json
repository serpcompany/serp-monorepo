[
  {
    "owner": "alexrudall",
    "repo": "ruby-openai",
    "content": "TITLE: Creating Completions with OpenAI API in Ruby\nDESCRIPTION: Shows how to use the completions endpoint with GPT models to generate text based on a prompt. The example includes setting the model, prompt, and limiting the response length with max_tokens.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_32\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.completions(\n  parameters: {\n    model: \"gpt-4o\",\n    prompt: \"Once upon a time\",\n    max_tokens: 5\n  }\n)\nputs response[\"choices\"].map { |c| c[\"text\"] }\n# => [\", there lived a great\"]\n```\n\n----------------------------------------\n\nTITLE: Handling Function Tool Calls in OpenAI Assistants\nDESCRIPTION: Example of working with function tools in an assistant run, including defining a weather function, checking for required actions, calling the appropriate functions based on tool requests, and submitting the results back to the run.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_80\n\nLANGUAGE: ruby\nCODE:\n```\ndef get_current_weather(location:, unit: \"celsius\")\n  # Your function code goes here\n  if location =~ /San Francisco/i\n    return unit == \"celsius\" ? \"The weather is nice  at 27掳C\" : \"The weather is nice  at 80掳F\"\n  else\n    return unit == \"celsius\" ? \"The weather is icy ザ at -5掳C\" : \"The weather is icy ザ at 23掳F\"\n  end\nend\n\nif status == 'requires_action'\n  tools_to_call = response.dig('required_action', 'submit_tool_outputs', 'tool_calls')\n\n  my_tool_outputs = tools_to_call.map { |tool|\n    # Call the functions based on the tool's name\n    function_name = tool.dig('function', 'name')\n    arguments = JSON.parse(\n      tool.dig(\"function\", \"arguments\"),\n      { symbolize_names: true },\n    )\n\n    tool_output = case function_name\n    when \"get_current_weather\"\n      get_current_weather(**arguments)\n    end\n\n    {\n      tool_call_id: tool['id'],\n      output: tool_output,\n    }\n  }\n\n  client.runs.submit_tool_outputs(\n    thread_id: thread_id,\n    run_id: run_id,\n    parameters: { tool_outputs: my_tool_outputs }\n  )\nend\n```\n\n----------------------------------------\n\nTITLE: Implementing Function Calling with OpenAI Chat API in Ruby\nDESCRIPTION: Demonstrates the complete workflow for function calling with OpenAI's Chat API. This example defines a function, makes an initial API call where the model calls the function, processes the function call, and then makes a follow-up API call with the function result.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_31\n\nLANGUAGE: ruby\nCODE:\n```\ndef get_current_weather(location:, unit: \"fahrenheit\")\n  # Here you could use a weather api to fetch the weather.\n  \"The weather in #{location} is nice  #{unit}\"\nend\n\nmessages = [\n  {\n    \"role\": \"user\",\n    \"content\": \"What is the weather like in San Francisco?\",\n  },\n]\n\nresponse =\n  client.chat(\n    parameters: {\n      model: \"gpt-4o\",\n      messages: messages,  # Defined above because we'll use it again\n      tools: [\n        {\n          type: \"function\",\n          function: {\n            name: \"get_current_weather\",\n            description: \"Get the current weather in a given location\",\n            parameters: {  # Format: https://json-schema.org/understanding-json-schema\n              type: :object,\n              properties: {\n                location: {\n                  type: :string,\n                  description: \"The city and state, e.g. San Francisco, CA\",\n                },\n                unit: {\n                  type: \"string\",\n                  enum: %w[celsius fahrenheit],\n                },\n              },\n              required: [\"location\"],\n            },\n          },\n        }\n      ],\n      # Optional, defaults to \"auto\"\n      # Can also put \"none\" or specific functions, see docs\n      tool_choice: \"required\"\n    },\n  )\n\nmessage = response.dig(\"choices\", 0, \"message\")\n\nif message[\"role\"] == \"assistant\" && message[\"tool_calls\"]\n  message[\"tool_calls\"].each do |tool_call|\n    tool_call_id = tool_call.dig(\"id\")\n    function_name = tool_call.dig(\"function\", \"name\")\n    function_args = JSON.parse(\n      tool_call.dig(\"function\", \"arguments\"),\n      { symbolize_names: true },\n    )\n    function_response =\n      case function_name\n      when \"get_current_weather\"\n        get_current_weather(**function_args)  # => \"The weather is nice \"\n      else\n        # decide how to handle\n      end\n\n    # For a subsequent message with the role \"tool\", OpenAI requires the preceding message to have a tool_calls argument.\n    messages << message\n\n    messages << {\n      tool_call_id: tool_call_id,\n      role: \"tool\",\n      name: function_name,\n      content: function_response\n    }  # Extend the conversation with the results of the functions\n  end\n\n  second_response = client.chat(\n    parameters: {\n      model: \"gpt-4o\",\n      messages: messages\n    }\n  )\n\n  puts second_response.dig(\"choices\", 0, \"message\", \"content\")\n\n  # At this point, the model has decided to call functions, you've called the functions\n  # and provided the response back, and the model has considered this and responded.\nend\n# => \"It looks like the weather is nice and sunny in San Francisco! If you're planning to go out, it should be a pleasant day.\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Vision Capabilities in OpenAI Threads\nDESCRIPTION: Complete example of using image analysis with OpenAI's vision capabilities, including uploading an image file, creating an assistant that can process images, creating a thread with the image, and retrieving the image description.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_79\n\nLANGUAGE: ruby\nCODE:\n```\nrequire \"openai\"\n\n# Make a client\nclient = OpenAI::Client.new(\n  access_token: \"access_token_goes_here\",\n  log_errors: true # Don't log errors in production.\n)\n\n# Upload image as a file\nfile_id = client.files.upload(\n  parameters: {\n    file: \"path/to/example.png\",\n    purpose: \"assistants\",\n  }\n)[\"id\"]\n\n# Create assistant (You could also use an existing one here)\nassistant_id = client.assistants.create(\n  parameters: {\n    model: \"gpt-4o\",\n    name: \"Image reader\",\n    instructions: \"You are an image describer. You describe the contents of images.\",\n  }\n)[\"id\"]\n\n# Create thread\nthread_id = client.threads.create[\"id\"]\n\n# Add image in message\nclient.messages.create(\n  thread_id: thread_id,\n  parameters: {\n    role: \"user\", # Required for manually created messages\n    content: [\n      {\n        \"type\": \"text\",\n        \"text\": \"What's in this image?\"\n      },\n      {\n        \"type\": \"image_file\",\n        \"image_file\": { \"file_id\": file_id }\n      }\n    ]\n  }\n)\n\n# Run thread\nrun_id = client.runs.create(\n  thread_id: thread_id,\n  parameters: { assistant_id: assistant_id }\n)[\"id\"]\n\n# Wait until run in complete\nstatus = nil\nuntil status == \"completed\" do\n  sleep(0.1)\n  status = client.runs.retrieve(id: run_id, thread_id: thread_id)['status']\nend\n\n# Get the response\nmessages = client.messages.list(thread_id: thread_id, parameters: { order: 'asc' })\nmessages.dig(\"data\", -1, \"content\", 0, \"text\", \"value\")\n```\n\n----------------------------------------\n\nTITLE: Creating an Assistant in Ruby\nDESCRIPTION: Shows how to create an AI assistant with specified model, instructions, and tools like code interpreter and file search capabilities.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_63\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.assistants.create(\n  parameters: {\n    model: \"gpt-4o\",\n    name: \"OpenAI-Ruby test assistant\",\n    description: nil,\n    instructions: \"You are a Ruby dev bot. When asked a question, write and run Ruby code to answer the question\",\n    tools: [\n      { type: \"code_interpreter\" },\n      { type: \"file_search\" }\n    ],\n    tool_resources: {\n      code_interpreter: {\n        file_ids: [] # See Files section above for how to upload files\n      },\n      file_search: {\n        vector_store_ids: [] # See Vector Stores section above for how to add vector stores\n      }\n    },\n    \"metadata\": { my_internal_version_id: \"1.0.0\" }\n  }\n)\nassistant_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Basic Chat Completion with OpenAI API in Ruby\nDESCRIPTION: Shows how to generate a basic chat completion response using the GPT-4o model, including setting the model, providing messages, and extracting the response content.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_18\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.chat(\n  parameters: {\n    model: \"gpt-4o\", # Required.\n    messages: [{ role: \"user\", content: \"Hello!\"}], # Required.\n    temperature: 0.7,\n  }\n)\nputs response.dig(\"choices\", 0, \"message\", \"content\")\n# => \"Hello! How may I assist you today?\"\n```\n\n----------------------------------------\n\nTITLE: Streaming JSON Responses in Chat Completions with Ruby\nDESCRIPTION: Demonstrates how to stream JSON responses from the OpenAI API by combining the response_format parameter with the streaming capability, allowing for real-time JSON data delivery.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_23\n\nLANGUAGE: ruby\nCODE:\n```\n  response = client.chat(\n    parameters: {\n      model: \"gpt-4o\",\n      messages: [{ role: \"user\", content: \"Can I have some JSON please?\"}],\n      response_format: { type: \"json_object\" },\n      stream: proc do |chunk, _bytesize|\n        print chunk.dig(\"choices\", 0, \"delta\", \"content\")\n      end\n    }\n  )\n  # =>\n  # {\n  #   \"message\": \"Sure, please let me know what specific JSON data you are looking for.\",\n  #   \"JSON_data\": {\n  #     \"example_1\": {\n  #       \"key_1\": \"value_1\",\n  #       \"key_2\": \"value_2\",\n  #       \"key_3\": \"value_3\"\n  #     },\n  #     \"example_2\": {\n  #       \"key_4\": \"value_4\",\n  #       \"key_5\": \"value_5\",\n  #       \"key_6\": \"value_6\"\n  #     }\n  #   }\n  # }\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat Completion with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to stream chat completions in real-time using a Proc callback, which improves user experience by showing responses as they're generated rather than waiting for the complete response.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_19\n\nLANGUAGE: ruby\nCODE:\n```\nclient.chat(\n  parameters: {\n    model: \"gpt-4o\", # Required.\n    messages: [{ role: \"user\", content: \"Describe a character called Anna!\"}], # Required.\n    temperature: 0.7,\n    stream: proc do |chunk, _bytesize|\n      print chunk.dig(\"choices\", 0, \"delta\", \"content\")\n    end\n  }\n)\n# => \"Anna is a young woman in her mid-twenties, with wavy chestnut hair that falls to her shoulders...\"\n```\n\n----------------------------------------\n\nTITLE: Configuring the OpenAI client globally\nDESCRIPTION: Set up global configuration for the OpenAI client using an initializer. This approach allows for centralized management of API credentials and settings.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_3\n\nLANGUAGE: ruby\nCODE:\n```\nOpenAI.configure do |config|\n  config.access_token = ENV.fetch(\"OPENAI_ACCESS_TOKEN\")\n  config.admin_token = ENV.fetch(\"OPENAI_ADMIN_TOKEN\") # Optional, used for admin endpoints, created here: https://platform.openai.com/settings/organization/admin-keys\n  config.organization_id = ENV.fetch(\"OPENAI_ORGANIZATION_ID\") # Optional\n  config.log_errors = true # Highly recommended in development, so you can see what errors OpenAI is returning. Not recommended in production because it could leak private data to your logs.\nend\n```\n\n----------------------------------------\n\nTITLE: Creating Embeddings with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to generate vector embeddings from text inputs using the embeddings endpoint. These vector representations can be used for semantic similarity comparisons and other NLP applications.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_33\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.embeddings(\n  parameters: {\n    model: \"text-embedding-ada-002\",\n    input: \"The food was delicious and the waiter...\"\n  }\n)\n\nputs response.dig(\"data\", 0, \"embedding\")\n# => Vector representation of your embedding\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for Assistants with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to upload files for use with OpenAI Assistants. The example shows both uploading via file path and using a File object.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_40\n\nLANGUAGE: ruby\nCODE:\n```\nclient.files.upload(parameters: { file: \"path/to/file.pdf\", purpose: \"assistants\" })\n```\n\n----------------------------------------\n\nTITLE: Creating a Thread and Adding Messages in Ruby\nDESCRIPTION: Demonstrates how to create a thread for an assistant and add initial user messages to start a conversation with the AI.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_68\n\nLANGUAGE: ruby\nCODE:\n```\n# Create thread\nresponse = client.threads.create # Note: Once you create a thread, there is no way to list it\n                                 # or recover it currently (as of 2023-12-10). So hold onto the `id`\nthread_id = response[\"id\"]\n\n# Add initial message from user (see https://platform.openai.com/docs/api-reference/messages/createMessage)\nmessage_id = client.messages.create(\n  thread_id: thread_id,\n  parameters: {\n    role: \"user\", # Required for manually created messages\n    content: \"Can you help me write an API library to interact with the OpenAI API please?\"\n  }\n)[\"id\"]\n\n# Retrieve individual message\nmessage = client.messages.retrieve(thread_id: thread_id, id: message_id)\n\n# Review all messages on the thread\nmessages = client.messages.list(thread_id: thread_id)\n```\n\n----------------------------------------\n\nTITLE: Handling Run Status States in Ruby\nDESCRIPTION: Shows how to implement a polling loop to monitor a run's status and take appropriate actions based on its current state until completion.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_73\n\nLANGUAGE: ruby\nCODE:\n```\nwhile true do\n  response = client.runs.retrieve(id: run_id, thread_id: thread_id)\n  status = response['status']\n\n  case status\n  when 'queued', 'in_progress', 'cancelling'\n    puts 'Sleeping'\n    sleep 1 # Wait one second and poll again\n  when 'completed'\n    break # Exit loop and report result to user\n  when 'requires_action'\n    # Handle tool calls (see below)\n  when 'cancelled', 'failed', 'expired'\n    puts response['last_error'].inspect\n    break # or `exit`\n  else\n    puts \"Unknown status response: #{status}\"\n  end\nend\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing Batches with OpenAI API in Ruby\nDESCRIPTION: Shows how to use the Batches endpoint to asynchronously process large volumes of requests. The example includes creating a batch, retrieving batch information, canceling a batch, and accessing output files.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_34\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.batches.create(\n  parameters: {\n    input_file_id: \"file-abc123\",\n    endpoint: \"/v1/chat/completions\",\n    completion_window: \"24h\"\n  }\n)\nbatch_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Run Steps and Messages from OpenAI Threads in Ruby\nDESCRIPTION: This code demonstrates how to retrieve run steps from an OpenAI thread, extract message IDs, fetch individual messages, and process their content. It handles different content types including text and images.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_75\n\nLANGUAGE: ruby\nCODE:\n```\nrun_steps = client.run_steps.list(thread_id: thread_id, run_id: run_id, parameters: { order: 'asc' })\nnew_message_ids = run_steps['data'].filter_map do |step|\n  if step['type'] == 'message_creation'\n    step.dig('step_details', \"message_creation\", \"message_id\")\n  end # Ignore tool calls, because they don't create new messages.\nend\n\n# Retrieve the individual messages\nnew_messages = new_message_ids.map do |msg_id|\n  client.messages.retrieve(id: msg_id, thread_id: thread_id)\nend\n\n# Find the actual response text in the content array of the messages\nnew_messages.each do |msg|\n  msg['content'].each do |content_item|\n    case content_item['type']\n    when 'text'\n      puts content_item.dig('text', 'value')\n      # Also handle annotations\n    when 'image_file'\n      # Use File endpoint to retrieve file contents via id\n      id = content_item.dig('image_file', 'file_id')\n    end\n  end\nend\n```\n\n----------------------------------------\n\nTITLE: Using JSON Mode in Chat Completions with Ruby\nDESCRIPTION: Shows how to request structured JSON responses from the OpenAI API by setting the response_format parameter to json_object, ensuring that the model returns well-formed JSON.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_22\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.chat(\n  parameters: {\n    model: \"gpt-4o\",\n    response_format: { type: \"json_object\" },\n    messages: [{ role: \"user\", content: \"Hello! Give me some JSON please.\"}],\n    temperature: 0.7,\n  })\n  puts response.dig(\"choices\", 0, \"message\", \"content\")\n  # =>\n  # {\n  #   \"name\": \"John\",\n  #   \"age\": 30,\n  #   \"city\": \"New York\",\n  #   \"hobbies\": [\"reading\", \"traveling\", \"hiking\"],\n  #   \"isStudent\": false\n  # }\n```\n\n----------------------------------------\n\nTITLE: Vision API Usage with GPT-4 in Ruby\nDESCRIPTION: Demonstrates how to use the GPT-4 Vision API to analyze images by providing both text and image URLs in the message content, allowing the model to generate descriptions of images.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_21\n\nLANGUAGE: ruby\nCODE:\n```\nmessages = [\n  { \"type\": \"text\", \"text\": \"What's in this image?\"},\n  { \"type\": \"image_url\",\n    \"image_url\": {\n      \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n    },\n  }\n]\nresponse = client.chat(\n  parameters: {\n    model: \"gpt-4-vision-preview\", # Required.\n    messages: [{ role: \"user\", content: messages}], # Required.\n  }\n)\nputs response.dig(\"choices\", 0, \"message\", \"content\")\n# => \"The image depicts a serene natural landscape featuring a long wooden boardwalk extending straight ahead\"\n```\n\n----------------------------------------\n\nTITLE: Creating Tool Calls with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to create a response with tool functionality, specifically defining a weather function that the model can call. This example shows how to structure tool definitions and access the response data.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_26\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.responses.create(parameters: {\n  model: \"gpt-4o\",\n  input: \"What's the weather in Paris?\",\n  tools: [\n    {\n      \"type\" => \"function\",\n      \"name\" => \"get_current_weather\",\n      \"description\" => \"Get the current weather in a given location\",\n      \"parameters\" => {\n        \"type\" => \"object\",\n        \"properties\" => {\n          \"location\" => {\n            \"type\" => \"string\",\n            \"description\" => \"The geographic location to get the weather for\"\n          }\n        },\n        \"required\" => [\"location\"]\n      }\n    }\n  ]\n})\nputs response.dig(\"output\", 0, \"name\")\n# => \"get_current_weather\"\n```\n\n----------------------------------------\n\nTITLE: Generating High-Quality Images with DALL路E 3 in Ruby\nDESCRIPTION: Example of using the more advanced DALL路E 3 model for image generation, demonstrating additional parameters like quality setting and different aspect ratio options.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_83\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.images.generate(\n  parameters: {\n    prompt: \"A springer spaniel cooking pasta wearing a hat of some sort\",\n    model: \"dall-e-3\",\n    size: \"1024x1792\",\n    quality: \"standard\",\n  }\n)\nputs response.dig(\"data\", 0, \"url\")\n# => \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-Rf437IxKhh...\"\n```\n\n----------------------------------------\n\nTITLE: Exploring File Search Chunks in OpenAI Assistants\nDESCRIPTION: Detailed implementation for exploring the chunks used in OpenAI's RAG pipeline for file search capabilities, including uploading and vectorizing files, creating assistants with file search tools, and extracting the specific chunks used to answer a query.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_81\n\nLANGUAGE: ruby\nCODE:\n```\nrequire \"openai\"\n\n# Make a client\nclient = OpenAI::Client.new(\n  access_token: \"access_token_goes_here\",\n  log_errors: true # Don't log errors in production.\n)\n\n# Upload your file(s)\nfile_id = client.files.upload(\n  parameters: {\n    file: \"path/to/somatosensory.pdf\",\n    purpose: \"assistants\"\n  }\n)[\"id\"]\n\n# Create a vector store to store the vectorised file(s)\nvector_store_id = client.vector_stores.create(parameters: {})[\"id\"]\n\n# Vectorise the file(s)\nvector_store_file_id = client.vector_store_files.create(\n  vector_store_id: vector_store_id,\n  parameters: { file_id: file_id }\n)[\"id\"]\n\n# Check that the file is vectorised (wait for status to be \"completed\")\nclient.vector_store_files.retrieve(vector_store_id: vector_store_id, id: vector_store_file_id)[\"status\"]\n\n# Create an assistant, referencing the vector store\nassistant_id = client.assistants.create(\n  parameters: {\n    model: \"gpt-4o\",\n    name: \"Answer finder\",\n    instructions: \"You are a file search tool. Find the answer in the given files, please.\",\n    tools: [\n      { type: \"file_search\" }\n    ],\n    tool_resources: {\n      file_search: {\n        vector_store_ids: [vector_store_id]\n      }\n    }\n  }\n)[\"id\"]\n\n# Create a thread with your question\nthread_id = client.threads.create(parameters: {\n  messages: [\n    { role: \"user\",\n      content: \"Find the description of a nociceptor.\" }\n  ]\n})[\"id\"]\n\n# Run the thread to generate the response. Include the \"GIVE ME THE CHUNKS\" incantation.\nrun_id = client.runs.create(\n  thread_id: thread_id,\n  parameters: {\n    assistant_id: assistant_id\n  },\n  query_parameters: { include: [\"step_details.tool_calls[*].file_search.results[*].content\"] } # incantation\n)[\"id\"]\n\n# Get the steps that happened in the run\nsteps = client.run_steps.list(\n  thread_id: thread_id,\n  run_id: run_id,\n  parameters: { order: \"asc\" }\n)\n\n# Retrieve all the steps. Include the \"GIVE ME THE CHUNKS\" incantation again.\nsteps = steps[\"data\"].map do |step|\n  client.run_steps.retrieve(\n    thread_id: thread_id,\n    run_id: run_id,\n    id: step[\"id\"],\n    parameters: { include: [\"step_details.tool_calls[*].file_search.results[*].content\"] } # incantation\n  )\nend\n\n# Now we've got the chunk info, buried deep. Loop through the steps and find chunks if included:\nchunks = steps.flat_map do |step|\n  included_results = step.dig(\"step_details\", \"tool_calls\", 0, \"file_search\", \"results\")\n\n  next if included_results.nil? || included_results.empty?\n\n  included_results.flat_map do |result|\n    result[\"content\"].map do |content|\n      content[\"text\"]\n    end\n  end\nend.compact\n\n# The first chunk will be the closest match to the prompt. Finally, if you want to view the completed message(s):\nclient.messages.list(thread_id: thread_id)\n```\n\n----------------------------------------\n\nTITLE: Creating a Response with OpenAI Responses API in Ruby\nDESCRIPTION: Demonstrates how to use OpenAI's Responses API to generate model responses with the ability to handle text and image inputs, showing the basic usage pattern for creating a new response.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_24\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.responses.create(parameters: {\n  model: \"gpt-4o\",\n  input: \"Hello! I'm Szymon!\"\n})\nputs response.dig(\"output\", 0, \"content\", 0, \"text\")\n# => Hello Szymon! How can I assist you today?\n```\n\n----------------------------------------\n\nTITLE: Creating Image Variations with OpenAI DALL-E in Ruby\nDESCRIPTION: Generates multiple variations of an existing image using OpenAI's image variation API. The example shows how to request a specific number of variations and access the resulting image URLs.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_85\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.images.variations(parameters: { image: \"image.png\", n: 2 })\nputs response.dig(\"data\", 0, \"url\")\n# => \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-Rf437IxKhh...\"\n```\n\n----------------------------------------\n\nTITLE: Generating Images with DALL路E 2 in Ruby\nDESCRIPTION: Example of generating images using OpenAI's DALL路E 2 model, showing how to create an image from a text prompt with specific size parameters.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_82\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.images.generate(\n  parameters: {\n    prompt: \"A baby sea otter cooking pasta wearing a hat of some sort\",\n    size: \"256x256\",\n  }\n)\nputs response.dig(\"data\", 0, \"url\")\n# => \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-Rf437IxKhh...\"\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with OpenAI Whisper in Ruby\nDESCRIPTION: Converts speech in an audio file to text in its original language using OpenAI's Whisper model. Supports specifying the language of the audio for improved accuracy using ISO-639-1 language codes.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_88\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.audio.transcribe(\n  parameters: {\n    model: \"whisper-1\",\n    file: File.open(\"path_to_file\", \"rb\"),\n    language: \"en\", # Optional\n  }\n)\nputs response[\"text\"]\n# => \"Transcription of the text\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Chat with Usage Information in Ruby\nDESCRIPTION: Shows how to stream chat completions while also retrieving usage information (token counts) by using the stream_options parameter, which provides detailed information about API usage in the final chunk.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_20\n\nLANGUAGE: ruby\nCODE:\n```\nstream_proc = proc { |chunk, _bytesize| puts \"--------------\"; puts chunk.inspect; }\nclient.chat(\n  parameters: {\n    model: \"gpt-4o\",\n    stream: stream_proc,\n    stream_options: { include_usage: true },\n    messages: [{ role: \"user\", content: \"Hello!\"}],\n  }\n)\n# => --------------\n# => {\"id\"=>\"chatcmpl-7bbq05PiZqlHxjV1j7OHnKKDURKaf\", \"object\"=>\"chat.completion.chunk\", \"created\"=>1718750612, \"model\"=>\"gpt-4o-2024-05-13\", \"system_fingerprint\"=>\"fp_9cb5d38cf7\", \"choices\"=>[{\"index\"=>0, \"delta\"=>{\"role\"=>\"assistant\", \"content\"=>\"\"}, \"logprobs\"=>nil, \"finish_reason\"=>nil}], \"usage\"=>nil}\n# => --------------\n# => {\"id\"=>\"chatcmpl-7bbq05PiZqlHxjV1j7OHnKKDURKaf\", \"object\"=>\"chat.completion.chunk\", \"created\"=>1718750612, \"model\"=>\"gpt-4o-2024-05-13\", \"system_fingerprint\"=>\"fp_9cb5d38cf7\", \"choices\"=>[{\"index\"=>0, \"delta\"=>{\"content\"=>\"Hello\"}, \"logprobs\"=>nil, \"finish_reason\"=>nil}], \"usage\"=>nil}\n# => --------------\n# => ... more content chunks\n# => --------------\n# => {\"id\"=>\"chatcmpl-7bbq05PiZqlHxjV1j7OHnKKDURKaf\", \"object\"=>\"chat.completion.chunk\", \"created\"=>1718750612, \"model\"=>\"gpt-4o-2024-05-13\", \"system_fingerprint\"=>\"fp_9cb5d38cf7\", \"choices\"=>[{\"index\"=>0, \"delta\"=>{}, \"logprobs\"=>nil, \"finish_reason\"=>\"stop\"}], \"usage\"=>nil}\n# => --------------\n# => {\"id\"=>\"chatcmpl-7bbq05PiZqlHxjV1j7OHnKKDURKaf\", \"object\"=>\"chat.completion.chunk\", \"created\"=>1718750612, \"model\"=>\"gpt-4o-2024-05-13\", \"system_fingerprint\"=>\"fp_9cb5d38cf7\", \"choices\"=>[], \"usage\"=>{\"prompt_tokens\"=>9, \"completion_tokens\"=>9, \"total_tokens\"=>18}}\n```\n\n----------------------------------------\n\nTITLE: Translating Audio with OpenAI Whisper in Ruby\nDESCRIPTION: Converts audio in any supported language into English text using OpenAI's Whisper model. Takes an audio file as input and returns the translated text in English.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_87\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.audio.translate(\n  parameters: {\n    model: \"whisper-1\",\n    file: File.open(\"path_to_file\", \"rb\"),\n  }\n)\nputs response[\"text\"]\n# => \"Translation of the text\"\n```\n\n----------------------------------------\n\nTITLE: Streaming OpenAI Responses in Ruby\nDESCRIPTION: Shows how to implement streaming for OpenAI API responses, where chunks of the response are processed as they arrive. The example uses a proc to handle each chunk and immediately display text deltas.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_27\n\nLANGUAGE: ruby\nCODE:\n```\nclient.responses.create(\n  parameters: {\n    model: \"gpt-4o\", # Required.\n    input: \"Hello!\", # Required.\n    stream: proc do |chunk, _bytesize|\n      if chunk[\"type\"] == \"response.output_text.delta\"\n        print chunk[\"delta\"]\n        $stdout.flush  # Ensure output is displayed immediately\n      end\n    end\n  }\n)\n# => \"Hi there! How can I assist you today?...\"\n```\n\n----------------------------------------\n\nTITLE: Generating Speech from Text with OpenAI TTS in Ruby\nDESCRIPTION: Converts text to speech using OpenAI's text-to-speech API. Allows specifying the voice type, output format, and speech speed to customize the audio output, then saves the result as an audio file.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_89\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.audio.speech(\n  parameters: {\n    model: \"tts-1\",\n    input: \"This is a speech test!\",\n    voice: \"alloy\",\n    response_format: \"mp3\", # Optional\n    speed: 1.0, # Optional\n  }\n)\nFile.binwrite('demo.mp3', response)\n# => mp3 file that plays: \"This is a speech test!\"\n```\n\n----------------------------------------\n\nTITLE: Streaming Run Results in Ruby\nDESCRIPTION: Shows how to create a run with streaming enabled to receive and process message chunks in real-time as they're generated.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_71\n\nLANGUAGE: ruby\nCODE:\n```\nclient.runs.create(\n  thread_id: thread_id,\n  parameters: {\n    assistant_id: assistant_id,\n    max_prompt_tokens: 256,\n    max_completion_tokens: 16,\n    stream: proc do |chunk, _bytesize|\n      if chunk[\"object\"] == \"thread.message.delta\"\n        print chunk.dig(\"delta\", \"content\", 0, \"text\", \"value\")\n      end\n    end\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Editing Images with OpenAI DALL-E in Ruby\nDESCRIPTION: Uses the OpenAI client to edit an image by filling in transparent parts or applying changes to masked areas according to a text prompt. Requires an image file and optionally a mask file to indicate editable regions.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_84\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.images.edit(\n  parameters: {\n    prompt: \"A solid red Ruby on a blue background\",\n    image: \"image.png\",\n    mask: \"mask.png\",\n  }\n)\nputs response.dig(\"data\", 0, \"url\")\n# => \"https://oaidalleapiprodscus.blob.core.windows.net/private/org-Rf437IxKhh...\"\n```\n\n----------------------------------------\n\nTITLE: Using a Fine-Tuned Model for Chat Completions in Ruby\nDESCRIPTION: Demonstrates how to use a fine-tuned model with the chat completions API to generate responses based on the custom-trained model.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_46\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.chat(\n  parameters: {\n    model: fine_tuned_model,\n    messages: [{ role: \"user\", content: \"I love Mondays!\" }]\n  }\n)\nresponse.dig(\"choices\", 0, \"message\", \"content\")\n```\n\n----------------------------------------\n\nTITLE: Searching a Vector Store in Ruby\nDESCRIPTION: Shows how to search a vector store for relevant content chunks based on a query string, with options for filtering and ranking results.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_53\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.vector_stores.search(\n  id: vector_store_id,\n  parameters: {\n    query: \"What is the return policy?\",\n    max_num_results: 20,\n    ranking_options: {\n      # Add any ranking options here in line with the API documentation\n    },\n    rewrite_query: true,\n    filters: {\n      type: \"eq\",\n      property: \"region\",\n      value: \"us\"\n    }\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Messages After Run Completion in Ruby\nDESCRIPTION: Demonstrates how to retrieve all messages from a thread after a run has completed, returning the messages in ascending order.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_74\n\nLANGUAGE: ruby\nCODE:\n```\n# Either retrieve all messages in bulk again, or...\nmessages = client.messages.list(thread_id: thread_id, parameters: { order: 'asc' })\n```\n\n----------------------------------------\n\nTITLE: Creating and Managing a Run in Ruby\nDESCRIPTION: Demonstrates how to submit a thread to an assistant for processing as a run, with options to control token usage limits.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_70\n\nLANGUAGE: ruby\nCODE:\n```\n# Create run (will use instruction/model/tools from Assistant's definition)\nresponse = client.runs.create(\n  thread_id: thread_id,\n  parameters: {\n    assistant_id: assistant_id,\n    max_prompt_tokens: 256,\n    max_completion_tokens: 16\n  }\n)\nrun_id = response['id']\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Store in Ruby\nDESCRIPTION: Shows how to create a vector store with specified files for the File Search tool. The vector store enables searching through file content.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_49\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.vector_stores.create(\n  parameters: {\n    name: \"my vector store\",\n    file_ids: [\"file-abc123\", \"file-def456\"]\n  }\n)\n\nvector_store_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Creating a Thread and Run in a Single Call with OpenAI\nDESCRIPTION: This snippet demonstrates creating a thread and immediately running an assistant on it in a single API call, which is more efficient than separate create and run calls.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_78\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.runs.create_thread_and_run(parameters: { assistant_id: assistant_id })\nrun_id = response['id']\nthread_id = response['thread_id']\n```\n\n----------------------------------------\n\nTITLE: Creating a Fine-Tuning Job in Ruby\nDESCRIPTION: Shows how to create a fine-tuning job using a previously uploaded file. The code specifies the training file ID and the base model to use for fine-tuning.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_43\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.finetunes.create(\n  parameters: {\n  training_file: file_id,\n  model: \"gpt-4o\"\n})\nfine_tune_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring Groq API Client with Ruby\nDESCRIPTION: Sets up a client for the Groq API (compatible with OpenAI's API) and performs a chat request with streaming enabled using the Llama 3 model.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_15\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(\n  access_token: \"groq_access_token_goes_here\",\n  uri_base: \"https://api.groq.com/openai\"\n)\n\nclient.chat(\n  parameters: {\n    model: \"llama3-8b-8192\", # Required.\n    messages: [{ role: \"user\", content: \"Hello!\"}], # Required.\n    temperature: 0.7,\n    stream: proc do |chunk, _bytesize|\n     print chunk.dig(\"choices\", 0, \"delta\", \"content\")\n    end\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Counting Tokens in Ruby for OpenAI API\nDESCRIPTION: Shows how to estimate the token count of text using the built-in rough token counter in the ruby-openai gem, which helps with cost estimation and context window management.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_16\n\nLANGUAGE: ruby\nCODE:\n```\nOpenAI.rough_token_count(\"Your text\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Ollama API Client with Ruby\nDESCRIPTION: Sets up a client for the locally running Ollama server and performs a chat request with the Llama 3 model, demonstrating how to stream the response.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_14\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(\n  uri_base: \"http://localhost:11434\"\n)\n\nclient.chat(\n  parameters: {\n    model: \"llama3\", # Required.\n    messages: [{ role: \"user\", content: \"Hello!\"}], # Required.\n    temperature: 0.7,\n    stream: proc do |chunk, _bytesize|\n      print chunk.dig(\"choices\", 0, \"delta\", \"content\")\n    end\n  }\n)\n\n# => Hi! It's nice to meet you. Is there something I can help you with, or would you like to chat?\n```\n\n----------------------------------------\n\nTITLE: Listing and Managing Models with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to list available models, retrieve information about a specific model, and delete custom fine-tuned models using the ruby-openai client.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_17\n\nLANGUAGE: ruby\nCODE:\n```\nclient.models.list\nclient.models.retrieve(id: \"gpt-4o\")\n\n```\n\nLANGUAGE: ruby\nCODE:\n```\nclient.models.delete(id: \"ft:gpt-4o-mini:acemeco:suffix:abc123\")\n```\n\n----------------------------------------\n\nTITLE: Checking Content Policy Violations with OpenAI Moderations API in Ruby\nDESCRIPTION: Uses OpenAI's Moderations API to analyze text for potential violations of OpenAI's Content Policy. Returns category scores indicating the likelihood that the content violates specific policy areas.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_86\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.moderations(parameters: { input: \"I'm worried about that.\" })\nputs response.dig(\"results\", 0, \"category_scores\", \"hate\")\n# => 5.505014632944949e-05\n```\n\n----------------------------------------\n\nTITLE: Retrieving Run Status in Ruby\nDESCRIPTION: Demonstrates how to check the status of a run to monitor its progress through various states from queued to completion.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_72\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.runs.retrieve(id: run_id, thread_id: thread_id)\nstatus = response['status']\n```\n\n----------------------------------------\n\nTITLE: Creating Follow-up Messages with OpenAI Responses API in Ruby\nDESCRIPTION: Shows how to create follow-up messages using the Responses API by referencing a previous response ID, enabling stateful conversations where the model remembers context from earlier interactions.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_25\n\nLANGUAGE: ruby\nCODE:\n```\nfollowup = client.responses.create(parameters: {\n  model: \"gpt-4o\",\n  input: \"Remind me, what is my name?\",\n  previous_response_id: response[\"id\"]\n})\nputs followup.dig(\"output\", 0, \"content\", 0, \"text\")\n# => Your name is Szymon! How can I help you today?\n```\n\n----------------------------------------\n\nTITLE: Listing Assistants in Ruby\nDESCRIPTION: Shows how to list all assistants available under the current organization to view and manage existing assistant resources.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_65\n\nLANGUAGE: ruby\nCODE:\n```\nclient.assistants.list\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for Fine-tuning with OpenAI API in Ruby\nDESCRIPTION: Shows how to upload JSONL files for fine-tuning purposes and interact with them using the Files API. The example demonstrates file upload, listing, retrieval, content access, and deletion.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_39\n\nLANGUAGE: ruby\nCODE:\n```\nclient.files.upload(parameters: { file: \"path/to/sentiment.jsonl\", purpose: \"fine-tune\" })\nclient.files.list\nclient.files.retrieve(id: \"file-123\")\nclient.files.content(id: \"file-123\")\nclient.files.delete(id: \"file-123\")\n```\n\n----------------------------------------\n\nTITLE: Modifying an Assistant in Ruby\nDESCRIPTION: Demonstrates how to update an existing assistant's properties such as name and metadata to adjust its configuration as needed.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_66\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.assistants.modify(\n  id: assistant_id,\n  parameters: {\n    name: \"Modified Test Assistant for OpenAI-Ruby\",\n    metadata: { my_internal_version_id: '1.0.1' }\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for Fine-Tuning in Ruby\nDESCRIPTION: Demonstrates how to upload a JSONL file for fine-tuning purposes. The file is uploaded with a designated purpose of 'fine-tune' and the response is parsed to extract the file ID.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_42\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.files.upload(parameters: { file: \"path/to/sarcasm.jsonl\", purpose: \"fine-tune\" })\nfile_id = JSON.parse(response.body)[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI client with custom timeout and base URI\nDESCRIPTION: Create an OpenAI client with custom request timeout, base URI for API requests, and additional headers for services like Helicone or proxy caching.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_6\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(\n  access_token: \"access_token_goes_here\",\n  uri_base: \"https://oai.hconeai.com/\",\n  request_timeout: 240,\n  extra_headers: {\n    \"X-Proxy-TTL\" => \"43200\", # For https://github.com/6/openai-caching-proxy-worker#specifying-a-cache-ttl\n    \"X-Proxy-Refresh\": \"true\", # For https://github.com/6/openai-caching-proxy-worker#refreshing-the-cache\n    \"Helicone-Auth\": \"Bearer HELICONE_API_KEY\", # For https://docs.helicone.ai/getting-started/integration-method/openai-proxy\n    \"helicone-stream-force-format\" => \"true\", # Use this with Helicone otherwise streaming drops chunks # https://github.com/alexrudall/ruby-openai/issues/251\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Modifying a Vector Store in Ruby\nDESCRIPTION: Demonstrates how to modify an existing vector store's properties, such as its name. Note that file_ids cannot be modified directly.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_52\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.vector_stores.modify(\n  id: vector_store_id,\n  parameters: {\n    name: \"Modified Test Vector Store\",\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving an OpenAI Response in Ruby\nDESCRIPTION: Demonstrates how to retrieve a previously created response using its ID. This allows accessing response data after initial creation.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_28\n\nLANGUAGE: ruby\nCODE:\n```\nretrieved_response = client.responses.retrieve(response_id: response[\"id\"])\nputs retrieved_response[\"object\"]\n# => \"response\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Vector Store Information in Ruby\nDESCRIPTION: Demonstrates how to retrieve information about a specific vector store using its ID to check its current configuration.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_50\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_stores.retrieve(id: vector_store_id)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Fine-Tuned Model Information in Ruby\nDESCRIPTION: Shows how to list all fine-tuning jobs and retrieve information about a specific fine-tuning job to get the fine-tuned model name.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_45\n\nLANGUAGE: ruby\nCODE:\n```\nclient.finetunes.list\nresponse = client.finetunes.retrieve(id: fine_tune_id)\nfine_tuned_model = response[\"fine_tuned_model\"]\n```\n\n----------------------------------------\n\nTITLE: Retrieving Assistant Information in Ruby\nDESCRIPTION: Demonstrates how to retrieve information about a specific assistant using its ID to check its configuration and capabilities.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_64\n\nLANGUAGE: ruby\nCODE:\n```\nclient.assistants.retrieve(id: assistant_id)\n```\n\n----------------------------------------\n\nTITLE: Creating an OpenAI client with direct access token\nDESCRIPTION: Instantiate an OpenAI client by directly providing the access token. This approach is suitable for quick testing but not recommended for production environments.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_2\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(\n  access_token: \"access_token_goes_here\",\n  log_errors: true # Highly recommended in development, so you can see what errors OpenAI is returning. Not recommended in production because it could leak private data to your logs.\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Store File Batch in Ruby\nDESCRIPTION: Shows how to add multiple files to a vector store at once by creating a batch operation, which is more efficient than adding files individually.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_59\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.vector_store_file_batches.create(\n  vector_store_id: \"vector-store-abc123\",\n  parameters: {\n    file_ids: [\"file-abc123\", \"file-def456\"]\n  }\n)\n\nfile_batch_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring the OpenAI client for Azure OpenAI Service\nDESCRIPTION: Configure the OpenAI client to use the Azure OpenAI Service API instead of the standard OpenAI API, specifying the Azure-specific endpoint and API version.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_11\n\nLANGUAGE: ruby\nCODE:\n```\nOpenAI.configure do |config|\n  config.access_token = ENV.fetch(\"AZURE_OPENAI_API_KEY\")\n  config.uri_base = ENV.fetch(\"AZURE_OPENAI_URI\")\n  config.api_type = :azure\n  config.api_version = \"2023-03-15-preview\"\nend\n```\n\n----------------------------------------\n\nTITLE: Creating a Vector Store File in Ruby\nDESCRIPTION: Shows how to add a file to an existing vector store by creating a vector store file association between them.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_55\n\nLANGUAGE: ruby\nCODE:\n```\nresponse = client.vector_store_files.create(\n  vector_store_id: \"vector-store-abc123\",\n  parameters: {\n    file_id: \"file-abc123\"\n  }\n)\n\nvector_store_file_id = response[\"id\"]\n```\n\n----------------------------------------\n\nTITLE: Listing Vector Stores in Ruby\nDESCRIPTION: Shows how to list all vector stores available under the current organization to view and manage existing resources.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_51\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_stores.list\n```\n\n----------------------------------------\n\nTITLE: Retrieving Vector Store File Batch Information in Ruby\nDESCRIPTION: Demonstrates how to retrieve information about a specific file batch operation in a vector store to check its status and files.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_60\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_file_batches.retrieve(\n  vector_store_id: \"vector-store-abc123\",\n  id: file_batch_id\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Message Metadata in OpenAI Threads\nDESCRIPTION: This snippet shows how to update metadata for an existing message in an OpenAI thread, including messages created by the assistant.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_76\n\nLANGUAGE: ruby\nCODE:\n```\nmetadata = {\n  user_id: \"abc123\"\n}\nmessage = client.messages.modify(\n  id: message_id,\n  thread_id: thread_id,\n  parameters: { metadata: metadata },\n)\n```\n\n----------------------------------------\n\nTITLE: Listing Runs in an OpenAI Thread\nDESCRIPTION: A simple code example showing how to list all runs that have been performed on a particular thread, with options for ordering and limiting results.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_77\n\nLANGUAGE: ruby\nCODE:\n```\nclient.runs.list(thread_id: thread_id, parameters: { order: \"asc\", limit: 3 })\n```\n\n----------------------------------------\n\nTITLE: Listing Vector Store Files in Ruby\nDESCRIPTION: Shows how to list all files associated with a specific vector store to view and manage the store's content.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_57\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_files.list(vector_store_id: \"vector-store-abc123\")\n```\n\n----------------------------------------\n\nTITLE: Deleting a Thread in Ruby\nDESCRIPTION: Shows how to delete a thread and all its associated messages when the conversation is complete or no longer needed.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_69\n\nLANGUAGE: ruby\nCODE:\n```\n# To delete the thread (and all associated messages):\nclient.threads.delete(id: thread_id)\n\nclient.messages.retrieve(thread_id: thread_id, id: message_id) # -> Fails after thread is deleted\n```\n\n----------------------------------------\n\nTITLE: Retrieving Batch Information from OpenAI API in Ruby\nDESCRIPTION: Shows how to retrieve information about a specific batch processing job using its ID.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_35\n\nLANGUAGE: ruby\nCODE:\n```\nbatch = client.batches.retrieve(id: batch_id)\n```\n\n----------------------------------------\n\nTITLE: Deleting an Assistant in Ruby\nDESCRIPTION: Shows how to delete an assistant when it's no longer needed, removing it and its associated configurations from the system.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_67\n\nLANGUAGE: ruby\nCODE:\n```\nclient.assistants.delete(id: assistant_id)\n```\n\n----------------------------------------\n\nTITLE: Accessing Batch Output Files with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to retrieve and access the output and error files after a batch job has completed.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_38\n\nLANGUAGE: ruby\nCODE:\n```\nbatch = client.batches.retrieve(id: batch_id)\noutput_file_id = batch[\"output_file_id\"]\noutput_response = client.files.content(id: output_file_id)\nerror_file_id = batch[\"error_file_id\"]\nerror_response = client.files.content(id: error_file_id)\n```\n\n----------------------------------------\n\nTITLE: Listing Input Items for an OpenAI Response in Ruby\nDESCRIPTION: Demonstrates how to retrieve the input items associated with a specific response, which can be useful for tracking conversation history or debugging.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_30\n\nLANGUAGE: ruby\nCODE:\n```\ninput_items = client.responses.input_items(response_id: response[\"id\"])\nputs input_items[\"object\"] # => \"list\"\n```\n\n----------------------------------------\n\nTITLE: Retrieving Events for a Fine-Tune Job in Ruby\nDESCRIPTION: Shows how to capture the events associated with a fine-tuning job to monitor its progress or diagnose issues.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_47\n\nLANGUAGE: ruby\nCODE:\n```\nclient.finetunes.list_events(id: fine_tune_id)\n```\n\n----------------------------------------\n\nTITLE: Deleting an OpenAI Response in Ruby\nDESCRIPTION: Shows how to delete a response by its ID, which can be useful for managing resources or removing sensitive data.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_29\n\nLANGUAGE: ruby\nCODE:\n```\ndeletion = client.responses.delete(response_id: response[\"id\"])\nputs deletion[\"deleted\"]\n# => true\n```\n\n----------------------------------------\n\nTITLE: Retrieving Vector Store File Information in Ruby\nDESCRIPTION: Demonstrates how to retrieve information about a specific file within a vector store to check its current status and configuration.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_56\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_files.retrieve(\n  vector_store_id: \"vector-store-abc123\",\n  id: vector_store_file_id\n)\n```\n\n----------------------------------------\n\nTITLE: Retrieving Usage Data from OpenAI Admin API in Ruby\nDESCRIPTION: Demonstrates how to retrieve usage and cost data for various OpenAI services using the Admin API. Shows how to query usage information for specific time periods and different service endpoints.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_91\n\nLANGUAGE: ruby\nCODE:\n```\none_day_ago = Time.now.to_i - 86_400\n\n# Retrieve costs data\nresponse = client.usage.costs(parameters: { start_time: one_day_ago })\nresponse[\"data\"].each do |bucket|\n  bucket[\"results\"].each do |result|\n    puts \"#{Time.at(bucket[\"start_time\"]).to_date}: $#{result.dig(\"amount\", \"value\").round(2)}\"\n  end\nend\n=> 2025-02-09: $0.0\n=> 2025-02-10: $0.42\n\n# Retrieve completions usage data\nresponse = client.usage.completions(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve embeddings usage data\nresponse = client.usage.embeddings(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve moderations usage data\nresponse = client.usage.moderations(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve image generation usage data\nresponse = client.usage.images(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve audio speech usage data\nresponse = client.usage.audio_speeches(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve audio transcription usage data\nresponse = client.usage.audio_transcriptions(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n\n# Retrieve vector stores usage data\nresponse = client.usage.vector_stores(parameters: { start_time: one_day_ago })\nputs response[\"data\"]\n```\n\n----------------------------------------\n\nTITLE: Listing Vector Store File Batch Files in Ruby\nDESCRIPTION: Shows how to list all files in a specific batch operation associated with a vector store to track batch processing.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_61\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_file_batches.list(\n  vector_store_id: \"vector-store-abc123\",\n  id: file_batch_id\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Faraday middleware for request/response logging\nDESCRIPTION: Add custom Faraday middleware to the OpenAI client for detailed logging of API requests and responses, including request and response bodies.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_10\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new do |f|\n  f.response :logger, Logger.new($stdout), bodies: true\nend\n```\n\n----------------------------------------\n\nTITLE: Listing All Batches with OpenAI API in Ruby\nDESCRIPTION: Shows how to list all batch processing jobs associated with the account.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_37\n\nLANGUAGE: ruby\nCODE:\n```\nclient.batches.list\n```\n\n----------------------------------------\n\nTITLE: Handling API Errors in Ruby OpenAI Client\nDESCRIPTION: Shows how to catch and handle HTTP errors when making API requests with the OpenAI client. Uses a try-catch block to capture Faraday errors that may occur during API calls.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_92\n\nLANGUAGE: ruby\nCODE:\n```\nbegin\n  OpenAI::Client.new.models.retrieve(id: \"gpt-4o\")\nrescue Faraday::Error => e\n  raise \"Got a Faraday error: #{e}\"\nend\n```\n\n----------------------------------------\n\nTITLE: Enabling error logging for the OpenAI client\nDESCRIPTION: Configure the OpenAI client to log Faraday errors that occur during API requests, which can be helpful for debugging but may leak sensitive data in logs.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_9\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(log_errors: true)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Client with Admin Token in Ruby\nDESCRIPTION: Sets up the OpenAI client with an admin token for accessing administrative APIs like the Usage API. Shows two different methods for configuration: global configuration and client instance configuration.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_90\n\nLANGUAGE: ruby\nCODE:\n```\nOpenAI.configure do |config|\n  config.admin_token = ENV.fetch(\"OPENAI_ADMIN_TOKEN\")\nend\n\n# or\n\nclient = OpenAI::Client.new(admin_token: \"123abc\")\n```\n\n----------------------------------------\n\nTITLE: Deleting a Vector Store File in Ruby\nDESCRIPTION: Demonstrates how to remove a file from a vector store without deleting the original file, severing only the association between them.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_58\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_files.delete(\n  vector_store_id: \"vector-store-abc123\",\n  id: vector_store_file_id\n)\n```\n\n----------------------------------------\n\nTITLE: Globally configuring OpenAI client with custom settings\nDESCRIPTION: Configure the OpenAI client globally with custom request timeout, base URI, and additional headers for services like Helicone or proxy caching.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_7\n\nLANGUAGE: ruby\nCODE:\n```\nOpenAI.configure do |config|\n  config.access_token = ENV.fetch(\"OPENAI_ACCESS_TOKEN\")\n  config.admin_token = ENV.fetch(\"OPENAI_ADMIN_TOKEN\") # Optional, used for admin endpoints, created here: https://platform.openai.com/settings/organization/admin-keys\n  config.organization_id = ENV.fetch(\"OPENAI_ORGANIZATION_ID\") # Optional\n  config.log_errors = true # Optional\n  config.uri_base = \"https://oai.hconeai.com/\" # Optional\n  config.request_timeout = 240 # Optional\n  config.extra_headers = {\n    \"X-Proxy-TTL\" => \"43200\", # For https://github.com/6/openai-caching-proxy-worker#specifying-a-cache-ttl\n    \"X-Proxy-Refresh\": \"true\", # For https://github.com/6/openai-caching-proxy-worker#refreshing-the-cache\n    \"Helicone-Auth\": \"Bearer HELICONE_API_KEY\" # For https://docs.helicone.ai/getting-started/integration-method/openai-proxy\n  } # Optional\nend\n```\n\n----------------------------------------\n\nTITLE: Deleting a Vector Store in Ruby\nDESCRIPTION: Demonstrates how to delete a vector store when it's no longer needed, removing it and its associated resources from the system.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_54\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_stores.delete(id: vector_store_id)\n```\n\n----------------------------------------\n\nTITLE: Adding extra headers to an existing OpenAI client\nDESCRIPTION: Dynamically add custom headers to an existing OpenAI client instance, which will be merged with any globally configured headers.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_8\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(access_token: \"access_token_goes_here\")\nclient.add_headers(\"X-Proxy-TTL\" => \"43200\")\n```\n\n----------------------------------------\n\nTITLE: Cancelling a Vector Store File Batch in Ruby\nDESCRIPTION: Demonstrates how to cancel an in-progress file batch operation to stop processing files as soon as possible.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_62\n\nLANGUAGE: ruby\nCODE:\n```\nclient.vector_store_file_batches.cancel(\n  vector_store_id: \"vector-store-abc123\",\n  id: file_batch_id\n)\n```\n\n----------------------------------------\n\nTITLE: Creating an OpenAI client with overridden credentials\nDESCRIPTION: Create an OpenAI client that overrides specific configuration settings while keeping other global settings.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_5\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(access_token: \"access_token_goes_here\", admin_token: \"admin_token_goes_here\")\n```\n\n----------------------------------------\n\nTITLE: Deleting a Fine-Tuned Model in Ruby\nDESCRIPTION: Demonstrates how to delete a fine-tuned model when it's no longer needed. This operation requires account Owner privileges.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_48\n\nLANGUAGE: ruby\nCODE:\n```\nclient.models.delete(id: fine_tune_id)\n```\n\n----------------------------------------\n\nTITLE: Creating a standard OpenAI client\nDESCRIPTION: Create an OpenAI client using the global configuration settings.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_4\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new\n```\n\n----------------------------------------\n\nTITLE: Cancelling a Fine-Tune Job in Ruby\nDESCRIPTION: Demonstrates how to cancel a fine-tuning job before it is processed, using the fine-tune ID obtained from creation.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_44\n\nLANGUAGE: ruby\nCODE:\n```\nclient.finetunes.cancel(id: fine_tune_id)\n```\n\n----------------------------------------\n\nTITLE: Configuring Deepseek API Client with Ruby\nDESCRIPTION: Sets up a client for the Deepseek API (compatible with OpenAI's chat API) and performs a chat request with streaming enabled.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_12\n\nLANGUAGE: ruby\nCODE:\n```\nclient = OpenAI::Client.new(\n  access_token: \"deepseek_access_token_goes_here\",\n  uri_base: \"https://api.deepseek.com/\"\n)\n\nclient.chat(\n  parameters: {\n    model: \"deepseek-chat\", # Required.\n    messages: [{ role: \"user\", content: \"Hello!\"}], # Required.\n    temperature: 0.7,\n    stream: proc do |chunk, _bytesize|\n     print chunk.dig(\"choices\", 0, \"delta\", \"content\")\n    end\n  }\n)\n```\n\n----------------------------------------\n\nTITLE: Canceling a Batch Job with OpenAI API in Ruby\nDESCRIPTION: Demonstrates how to cancel an in-progress batch processing job.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_36\n\nLANGUAGE: ruby\nCODE:\n```\nclient.batches.cancel(id: batch_id)\n```\n\n----------------------------------------\n\nTITLE: Uploading File Objects for Assistants with OpenAI API in Ruby\nDESCRIPTION: Shows how to upload a file as a File object rather than a path string for use with OpenAI Assistants.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_41\n\nLANGUAGE: ruby\nCODE:\n```\nmy_file = File.open(\"path/to/file.pdf\", \"rb\")\nclient.files.upload(parameters: { file: my_file, purpose: \"assistants\" })\n```\n\n----------------------------------------\n\nTITLE: Installing Ruby OpenAI with Bundler\nDESCRIPTION: Add the ruby-openai gem to your application's Gemfile and install it using Bundler.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: ruby\nCODE:\n```\ngem \"ruby-openai\"\n```\n\nLANGUAGE: bash\nCODE:\n```\nbundle install\n```\n\n----------------------------------------\n\nTITLE: Installing Ruby OpenAI manually with gem\nDESCRIPTION: Install the ruby-openai gem directly using the gem command and require it in your Ruby code.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngem install ruby-openai\n```\n\nLANGUAGE: ruby\nCODE:\n```\nrequire \"openai\"\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Ollama with Bash\nDESCRIPTION: Instructions for installing Ollama via Homebrew on macOS, starting the server, and pulling the Llama 3 model.\nSOURCE: https://github.com/alexrudall/ruby-openai/blob/main/README.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nbrew install ollama\nollama serve\nollama pull llama3:latest # In new terminal tab.\n```"
  }
]