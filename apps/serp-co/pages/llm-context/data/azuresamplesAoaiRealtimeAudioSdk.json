[
  {
    "owner": "azure-samples",
    "repo": "aoai-realtime-audio-sdk",
    "content": "TITLE: Configuring Azure OpenAI /realtime Session Settings - JSON\nDESCRIPTION: This JSON snippet provides an example payload for the `session.update` command used to configure a /realtime session. It specifies client voice settings, instructions for tool usage, input audio format and transcription model (Whisper-1), and voice activity detection parameters including threshold and silence duration. It also defines a tool with function parameters for location-based weather lookup. This configuration impacts audio capture, transcription, conversation turn handling, and tool invocation during sessions.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/README.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"type\": \"session.update\",\n  \"session\": {\n    \"voice\": \"alloy\",\n    \"instructions\": \"Call provided tools if appropriate for the user's input.\",\n    \"input_audio_format\": \"pcm16\",\n    \"input_audio_transcription\": {\n      \"model\": \"whisper-1\"\n    },\n    \"turn_detection\": {\n      \"threshold\": 0.4,\n      \"silence_duration_ms\": 600,\n      \"type\": \"server_vad\"\n    },\n    \"tools\": [\n      {\n        \"type\": \"function\",\n        \"name\": \"get_weather_for_location\",\n        \"description\": \"gets the weather for a location\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"location\": {\n              \"type\": \"string\",\n              \"description\": \"The city and state e.g. San Francisco, CA\"\n            },\n            \"unit\": {\n              \"type\": \"string\",\n              \"enum\": [\n                \"c\",\n                \"f\"\n              ]\n            }\n          },\n          \"required\": [\n            \"location\",\n            \"unit\"\n          ]\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Describing Azure OpenAI /realtime Session Architecture Diagram Using Mermaid\nDESCRIPTION: This Mermaid sequence diagram illustrates the interaction flow between an end user, the middle tier hosting the /realtime endpoint, and the Azure OpenAI backend. It outlines connection establishment, authentication, session configuration, message exchanges including audio, text, and control information, and the asynchronous streaming communication model. This visualization clarifies the roles of components involved in realtime audio conversations using the Azure OpenAI service.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/README.md#_snippet_0\n\nLANGUAGE: Mermaid\nCODE:\n```\nsequenceDiagram\n  actor User as End User\n  participant MiddleTier as /realtime host\n  participant AOAI as Azure OpenAI\n  User->>MiddleTier: Begin interaction\n  MiddleTier->>MiddleTier: Authenticate/Validate User\n  MiddleTier--)User: audio information\n  User--)MiddleTier: \n  MiddleTier--)User: text information\n  User--)MiddleTier: \n  MiddleTier--)User: control information\n  User--)MiddleTier: \n  MiddleTier->>AOAI: connect to /realtime\n  MiddleTier->>AOAI: configure session\n  AOAI->>MiddleTier: session start\n  MiddleTier--)AOAI: send/receive WS commands\n  AOAI--)MiddleTier: \n  AOAI--)MiddleTier: create/start conversation responses\n  AOAI--)MiddleTier: (within responses) create/start/add/finish items\n  AOAI--)MiddleTier: (within items) create/stream/finish content parts\n```\n\n----------------------------------------\n\nTITLE: Configuring Realtime Conversation Session - C#\nDESCRIPTION: Shows how to configure the real-time conversation session after it has been started. It uses the `ConversationSessionOptions` class to set properties like instructions and enable input audio transcription using the \"whisper-1\" model via `InputTranscriptionOptions`.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_2\n\nLANGUAGE: C#\nCODE:\n```\nConversationSessionOptions options = new()\n{\n    Instructions = \"You are a friendly assistant.\",\n    InputTranscriptionOptions = new()\n    {\n        Model = \"whisper-1\",\n    },\n};\nawait session.ConfigureSessionAsync(options);\n```\n\n----------------------------------------\n\nTITLE: Constructing Azure OpenAI /realtime WebSocket Request URI - HTTP\nDESCRIPTION: This snippet demonstrates how to construct a secure WebSocket URI for connecting to the Azure OpenAI /realtime endpoint. The URI combines the wss:// scheme, resource hostname, API path, version query parameter, and deployment name query parameter. This well-formed URI is essential for establishing a WebSocket session with the appropriate deployment of the gpt-4o-realtime-preview model in supported regions.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/README.md#_snippet_1\n\nLANGUAGE: HTTP\nCODE:\n```\nwss://my-eastus2-openai-resource.openai.azure.com/openai/realtime?api-version=2024-10-01-preview&deployment=gpt-4o-realtime-preview-1001\n```\n\n----------------------------------------\n\nTITLE: Initializing Azure OpenAI RealtimeClient - C#\nDESCRIPTION: Demonstrates how to create an instance of `AzureOpenAIClient` using endpoint and API key credentials, then obtain a `RealtimeConversationClient` instance from it, specifying the deployment name. This is the first step to interacting with the /realtime API.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_0\n\nLANGUAGE: C#\nCODE:\n```\nAzureOpenAIClient topLevelClient = new(\n    new Uri(Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\")),\n    new ApiKeyCredential(Environment.GetEnvironmentVariable(\"AZURE_OPENAI_API_KEY\")));\nRealtimeConversationClient client = topLevelClient.GetRealtimeConversationClient(\"my-gpt-4o-realtime-preview-deployment\");\n```\n\n----------------------------------------\n\nTITLE: Processing Conversation Updates - C#\nDESCRIPTION: This code snippet demonstrates how to receive and process updates from a conversation session.  It utilizes a `foreach` loop to iterate over an `IAsyncEnumerable<ConversationUpdate>` provided by `ReceiveUpdatesAsync()`.  The code checks the `Kind` property of each update to determine its type and then downcasts it to the appropriate derived class for specific processing, like handling a `ConversationSessionStartedUpdate`.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_6\n\nLANGUAGE: C#\nCODE:\n```\nawait foreach (ConversationUpdate update in conversation.ReceiveUpdatesAsync())\n{\n    // update.Kind == ConversationUpdateKind.SessionStarted (session.started)\n    if (update is ConversationSessionStartedUpdate sessionStartedUpdate)\n    {\n        Console.WriteLine($\"New session started, id = {sessionStartedUpdate.SessionId}\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Sending Realtime Audio Input - C#\nDESCRIPTION: Demonstrates sending audio data to the real-time session from a file stream. It uses the `SendInputAudioAsync(Stream)` method for a simple \"fire and forget\" pattern where the SDK handles reading and chunking the audio data automatically.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_3\n\nLANGUAGE: C#\nCODE:\n```\nusing Stream audioInputStream = File.OpenRead(\"..\\\\audio_hello_world.wav\");\n_ = session.SendInputAudioAsync(audioInputStream);\n```\n\n----------------------------------------\n\nTITLE: Sending Realtime Text/Data Item - C#\nDESCRIPTION: Illustrates how to send non-audio data, such as user messages, to the real-time conversation session. It uses the `AddItemAsync` method with a `ConversationItem` created via a static factory method like `CreateUserMessage`.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_4\n\nLANGUAGE: C#\nCODE:\n```\nawait session.AddItemAsync(\n    ConversationItem.CreateUserMessage([\"Hello, assistant! Can you help me today?\"]));\n```\n\n----------------------------------------\n\nTITLE: Defining Protocol Message Types for FastAPI WebSocket Backend in Python\nDESCRIPTION: Python type definitions using TypedDict and Literal to enforce structure and type safety for client-server communication messages within the custom simplified realtime protocol. These typed dictionaries define the fields required for partial text responses (TextDelta), transcriptions, user input messages, and control commands exchanged over WebSocket.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/python-fastapi/README.md#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass TextDelta(TypedDict):\n    id: str\n    type: Literal[\"text_delta\"]\n    delta: str\n\nclass Transcription(TypedDict):\n    id: str\n    type: Literal[\"transcription\"]\n    text: str\n\nclass UserMessage(TypedDict):\n    id: str\n    type: Literal[\"user_message\"]\n    text: str\n\nclass ControlMessage(TypedDict):\n    type: Literal[\"control\"]\n    action: str\n    greeting: str | None = None\n    id: str | None = None\n```\n\n----------------------------------------\n\nTITLE: Starting Realtime Conversation Session - C#\nDESCRIPTION: Illustrates starting a conversation session asynchronously using the `StartConversationSessionAsync` method of the `RealtimeConversationClient`. It emphasizes using the `using` keyword for proper resource cleanup of the `RealtimeConversationSession` which implements `IDisposable`.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_1\n\nLANGUAGE: C#\nCODE:\n```\nusing RealtimeConversationSession conversation = await client.StartConversationSessionAsync();\n```\n\n----------------------------------------\n\nTITLE: Sending Raw Realtime Command - C#\nDESCRIPTION: Shows how to send an arbitrary, raw message or command to the real-time session using the generic `SendCommandAsync(BinaryData)` method. This allows sending explicit WebSocket messages like `session.update` manually.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_5\n\nLANGUAGE: C#\nCODE:\n```\nawait session.SendCommandAsync(BinaryData.FromString(\"\"\"\n{\n  \"event\": \"session.update\",\n  \"session\": {\n  }\n}\n\"\"\"));\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Protocol Message Classes in Java for WebSocket Communication\nDESCRIPTION: This Java snippet defines classes representing the various message types used in the custom client-server protocol. These include TextDelta, UserMessage, TranscriptionMessage, and ControlMessage, each encapsulating fields such as id, type, and message-specific content like 'delta', 'text', 'action', or 'greeting'. The 'MessageType' enum distinguishes message categories (e.g., TEXT_DELTA, USER_MESSAGE). These classes are crucial for serializing and deserializing protocol messages for communication over the WebSocket server. Dependencies include the definition of the MessageType enum and integration with JSON serialization frameworks for network transmission.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/spring-boot/README.md#_snippet_0\n\nLANGUAGE: Java\nCODE:\n```\nclass TextDelta {\n    String id;\n    MessageType type = MessageType.TEXT_DELTA;\n    String delta;\n}\n\nclass UserMessage {\n    String id;\n    MessageType type = MessageType.USER_MESSAGE;\n    String text;\n}\n\nclass TranscriptionMessage {\n    String id;\n    MessageType type = MessageType.TRANSCRIPTION;\n    String text;\n}\n\nclass ControlMessage {\n    MessageType type = MessageType.CONTROL;\n    String action;\n    String greeting;\n    String id;\n}\n```\n\n----------------------------------------\n\nTITLE: Logging Raw Update Content - C#\nDESCRIPTION: This snippet demonstrates how to access the raw JSON payload of each received conversation update.  It uses the `GetRawContent()` method to retrieve a `BinaryData` instance that holds the raw content. The content is then converted to a string and printed to the console.  This is useful for debugging and understanding the underlying message format.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/dotnet/samples/README.md#_snippet_7\n\nLANGUAGE: C#\nCODE:\n```\nawait foreach (ConversationUpdate update in conversation.ReceiveUpdatesAsync())\n{\n    Console.WriteLine(message.GetRawContent().Content.ToString());\n}\n```\n\n----------------------------------------\n\nTITLE: Running the High-Level Client Sample (Shell)\nDESCRIPTION: Executes the `client_sample.py` Python script. It requires three command-line arguments: the path to an input `<audio_file>`, the path to an existing `<out_dir>` for storing output, and the target platform (`azure` or `openai`).\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/python/samples/README.md#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\npython client_sample.py <audio_file> <out_dir> <azure|openai>\n```\n\n----------------------------------------\n\nTITLE: Running the Low-Level Client Sample (Shell)\nDESCRIPTION: Executes the `low_level_sample.py` Python script. It requires two command-line arguments: the path to an input `<audio file>` and the target platform, which must be either `azure` or `openai`.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/python/samples/README.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\npython low_level_sample.py <audio file> <azure|openai>\n```\n\n----------------------------------------\n\nTITLE: Configuring and Running Middle Tier Service\nDESCRIPTION: This section describes the environment variables and configuration required to run the middle tier service. It supports both Azure OpenAI and standard OpenAI configurations. Key variables include AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT, AZURE_OPENAI_API_KEY, OPENAI_API_KEY, OPENAI_ENDPOINT, and OPENAI_MODEL. The service can be started using `dotnet run` after setting the appropriate configuration.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/dotnet-aspnetcore-mvc/README.md#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nIf the `AZURE_OPENAI_ENDPOINT` variable is set (via environment variable or IConfiguration), the middle tier will attempt to connect to that URI as an Azure OpenAI resource.\n\n- When providing an `AZURE_OPENAI_ENDPOINT` value, `AZURE_OPENAI_DEPLOYMENT` is also required and should specify the deployment name of a model deployment compatible with `/realtime`, e.g. `gpt-4o-realtime-preview`\n- If provided, the optional `AZURE_OPENAI_API_KEY` value will be used to authenticate. Otherwise, `DefaultAzureCredential` will be used for Entra authentication\n\nIf not using Azure OpenAI, an OpenAI endpoint will be used:\n\n- `OPENAI_API_KEY` is required and will be used to authenticate\n- If provided, an optional value of `OPENAI_ENDPOINT` will be used instead of the default\n- If provided, an optional value of `OPENAI_MODEL` will be used instead of a default of `gpt-4o-realtime-preview`\n\nWith configuration available, `dotnet run` will start the service on port 8080 or an override value specified via `PORT`. Once started, a frontend client can immediately connect to the middle tier.\n```\n\n----------------------------------------\n\nTITLE: Creating and Activating Python Virtual Environment (Shell)\nDESCRIPTION: Creates a Python 3 virtual environment named 'venv' in the current directory using `python3 -m venv` and then activates it using the `source` command. This is a standard practice to manage project-specific dependencies.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/python/samples/README.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n# Create a virtual environment\npython3 -m venv venv\n\n# Activate the virtual environment\nsource venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies via Pip (Shell)\nDESCRIPTION: Installs Python package dependencies using pip. The first command installs packages listed in the `requirements.txt` file, while the second command installs a specific custom package from the `rtclient-0.5.1-py3-none-any.whl` wheel file. Assumes the virtual environment is active and the wheel file is present.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/python/samples/README.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\npip install -r requirements.txt\npip install rtclient-0.5.1-py3-none-any.whl\n```\n\n----------------------------------------\n\nTITLE: Starting FastAPI Server with Uvicorn in Bash\nDESCRIPTION: Command to launch the FastAPI application using Uvicorn ASGI server in reload mode, binding to port 8080. This starts the realtime backend WebSocket service located in the 'rt-middle-tier.main' module.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/python-fastapi/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npoetry run uvicorn rt-middle-tier.main:app --reload --port 8080\n```\n\n----------------------------------------\n\nTITLE: Copying Environment Variable Template File (Shell)\nDESCRIPTION: Copies the template environment configuration file `development.env` to a new file named `.env`. The `.env` file will be used by the application to load necessary environment variables like API keys or endpoint URLs.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/python/samples/README.md#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\ncp development.env .env\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with Poetry in Bash\nDESCRIPTION: Commands to install Poetry (a Python package and dependency manager) and install project dependencies specified in the project configuration. These are prerequisite steps before running the FastAPI server.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/python-fastapi/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -sSL https://install.python-poetry.org | python3 -\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry install\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies - Bash\nDESCRIPTION: These commands install the necessary project dependencies listed in the package.json file. Choose either npm or yarn based on your preference and what is installed on your system. Requires Node.js and npm/yarn.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/generic-frontend/README.md#_snippet_1\n\nLANGUAGE: Bash\nCODE:\n```\nnpm install\n```\n\nLANGUAGE: Bash\nCODE:\n```\nyarn install\n```\n\n----------------------------------------\n\nTITLE: Running Development Tools via Poetry in Bash\nDESCRIPTION: Commands to run code formatting with 'black' and linting with 'ruff' across the 'rt-middle-tier' codebase to enforce style and code quality conventions as part of development workflow.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/python-fastapi/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npoetry run black rt-middle-tier\n```\n\nLANGUAGE: bash\nCODE:\n```\npoetry run ruff check rt-middle-tier\n```\n\n----------------------------------------\n\nTITLE: Install Dependencies - Yarn\nDESCRIPTION: Installs the necessary dependencies for the project using Yarn.  This command downloads and installs all packages listed in the `package.json` file.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/javascript/react/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nyarn install\n```\n\n----------------------------------------\n\nTITLE: Install Dependencies - npm\nDESCRIPTION: Installs the necessary dependencies for the project using npm. This command downloads and installs all packages listed in the `package.json` file.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/javascript/react/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server - Bash\nDESCRIPTION: These commands start the Next.js development server for the application. This compiles the code and serves it locally, typically with hot-reloading. Choose either npm or yarn. Requires dependencies to be installed first.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/generic-frontend/README.md#_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nnpm run dev\n```\n\nLANGUAGE: Bash\nCODE:\n```\nyarn dev\n```\n\n----------------------------------------\n\nTITLE: Start Development Server - Yarn\nDESCRIPTION: Starts the development server using Yarn.  This allows the user to preview and test their application in a local environment. The server typically watches for file changes and automatically reloads the application.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/javascript/react/README.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nyarn dev\n```\n\n----------------------------------------\n\nTITLE: Start Development Server - npm\nDESCRIPTION: Starts the development server using npm.  This allows the user to preview and test their application in a local environment. The server typically watches for file changes and automatically reloads the application.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/javascript/react/README.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository and Navigating - Bash\nDESCRIPTION: These commands are used to clone the sample repository from a remote Git server and change the current directory to the project's root. Requires Git to be installed on the system.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/middle-tier/generic-frontend/README.md#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\ngit clone <repository-url>\n```\n\nLANGUAGE: Bash\nCODE:\n```\ncd <project-directory>\n```\n\n----------------------------------------\n\nTITLE: Cloning Repository - Bash\nDESCRIPTION: Clones the specified repository to a local directory.  The user should replace `<repository-url>` with the actual URL of the git repository they want to clone. After cloning, the command changes the current directory to the newly cloned repository.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/samples/javascript/react/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone <repository-url>\ncd <project-directory>\n```\n\n----------------------------------------\n\nTITLE: Rebasing and Force Pushing a Fork in Git Shell\nDESCRIPTION: These Git shell commands are used to update a pull request branch after incorporating suggested changes. The first command interactively rebases the current branch onto the 'master' branch, allowing the contributor to squash or reorder commits. The second command force-pushes the rebased branch to the contributor's remote fork, updating the pull request.\nSOURCE: https://github.com/azure-samples/aoai-realtime-audio-sdk/blob/main/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngit rebase master -i\ngit push -f\n```"
  }
]