[
  {
    "owner": "arviz-devs",
    "repo": "arviz",
    "content": "TITLE: Defining and Sampling Non-Centered Eight Schools Model\nDESCRIPTION: Implements the non-centered parameterization of the Eight Schools model using PyMC. Includes prior and posterior sampling with specified parameters and dimensions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/non_centered_eight/non_centered_eight.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model(coords={\n    \"school\": schools,\n}) as non_centered_eight:\n    mu = pm.Normal(\"mu\", mu=0, sigma=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta_tilde = pm.Normal(\"theta_t\", mu=0, sigma=1, dims=\"school\")\n    theta = pm.Deterministic(\"theta\", mu + tau * theta_tilde, dims=\"school\")\n    y_obs = pm.ConstantData(\"scores\", scores, dims=\"school\")\n    obs = pm.Normal(\"obs\", mu=theta, sigma=sigma, observed=y_obs)\n\n    idata = pm.sample_prior_predictive()\n    idata.extend(pm.sample(draws, chains=chains, target_accept=0.86))\n    idata.extend(pm.sample_posterior_predictive(idata))\nidata\n```\n\n----------------------------------------\n\nTITLE: Custom NumPyro Sampling Wrapper Implementation\nDESCRIPTION: Implementation of a custom SamplingWrapper class for NumPyro with methods for observation selection and likelihood calculation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nclass NumPyroSamplingWrapper(az.SamplingWrapper):\n    def __init__(self, model, **kwargs):\n        self.model_fun = model.sampler.model\n        self.rng_key = kwargs.pop(\"rng_key\", random.PRNGKey(0))\n\n        super(NumPyroSamplingWrapper, self).__init__(model, **kwargs)\n\n    def log_likelihood__i(self, excluded_obs, idata__i):\n        samples = {\n            key: values.values.reshape((-1, *values.values.shape[2:]))\n            for key, values in idata__i.posterior.items()\n        }\n        log_likelihood_dict = numpyro.infer.log_likelihood(self.model_fun, samples, **excluded_obs)\n        if len(log_likelihood_dict) > 1:\n            raise ValueError(\"multiple likelihoods found\")\n        data = {}\n        nchains = idata__i.posterior.dims[\"chain\"]\n        ndraws = idata__i.posterior.dims[\"draw\"]\n        for obs_name, log_like in log_likelihood_dict.items():\n            shape = (nchains, ndraws) + log_like.shape[1:]\n            data[obs_name] = np.reshape(log_like.copy(), shape)\n        return az.dict_to_dataset(data)[obs_name]\n\n    def sample(self, modified_observed_data):\n        self.rng_key, subkey = random.split(self.rng_key)\n        mcmc = MCMC(**self.sample_kwargs)\n        mcmc.run(subkey, **modified_observed_data)\n        return mcmc\n\n    def get_inference_data(self, fit):\n        # Cloned from PyStanSamplingWrapper.\n        idata = az.from_numpyro(mcmc, **self.idata_kwargs)\n        return idata\n\n\nclass LinRegWrapper(NumPyroSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data[\"x\"].values\n        ydata = self.idata_orig.observed_data[\"y\"].values\n        mask = np.isin(np.arange(len(xdata)), idx)\n        data__i = {\"x\": xdata[~mask], \"y\": ydata[~mask], \"N\": len(ydata[~mask])}\n        data_ex = {\"x\": xdata[mask], \"y\": ydata[mask], \"N\": len(ydata[mask])}\n        return data__i, data_ex\n```\n\n----------------------------------------\n\nTITLE: Performing Re-LOO and Comparing Results\nDESCRIPTION: This code performs Re-LOO (Refitted Leave-One-Out Cross-Validation) using the custom wrapper and compares the results with the original LOO-CV.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed = az.reloo(pystan_wrapper, loo_orig=loo_orig)\n\nloo_relooed\n\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom PyMCLinRegWrapper\nDESCRIPTION: Defines a custom SamplingWrapper subclass for PyMC linear regression, including methods for sampling, log-likelihood calculation, and observation selection.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom scipy import stats\nfrom xarray_einstats.stats import XrContinuousRV\n\n\nclass PyMCLinRegWrapper(az.PyMCSamplingWrapper):\n    def sample(self, modified_observed_data):\n        with self.model:\n            # if the model had coords the dim needs to be updated before\n            # modifying the data in the model with set_data\n            # otherwise, we don't need to overwrite the sample method\n            n__i = len(modified_observed_data[\"x\"])\n            self.model.set_dim(\"time\", n__i, coord_values=np.arange(n__i))\n\n            pm.set_data(modified_observed_data)\n            idata = pm.sample(\n                **self.sample_kwargs,\n            )\n        return idata\n\n    def log_likelihood__i(self, excluded_observed_data, idata__i):\n        post = idata__i.posterior\n        dist = XrContinuousRV(\n            stats.norm,\n            post[\"b0\"] + post[\"b1\"] * excluded_observed_data[\"x\"],\n            post[\"sigma_e\"],\n        )\n        return dist.logpdf(excluded_observed_data[\"y_obs\"])\n\n    def sel_observations(self, idx):\n        xdata = self.idata_orig[\"constant_data\"][\"x\"]\n        ydata = self.idata_orig[\"observed_data\"][\"y\"]\n        mask = np.isin(np.arange(len(xdata)), idx)\n        data_dict = {\"x\": xdata, \"y_obs\": ydata}\n        data__i = {key: value.values[~mask] for key, value in data_dict.items()}\n        data_ex = {key: value.isel(time=idx) for key, value in data_dict.items()}\n        return data__i, data_ex\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ with all optional dependencies using pip\nDESCRIPTION: Installation command for ArviZ including all optional dependencies via pip\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/Installation.rst#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install \"arviz[all]\"\n```\n\n----------------------------------------\n\nTITLE: Creating InferenceData Object from NumPyro MCMC Results\nDESCRIPTION: This snippet creates an ArviZ InferenceData object from the NumPyro MCMC results, specifying dimensions and constant data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndims = {\"y\": [\"time\"], \"x\": [\"time\"]}\nidata_kwargs = {\"dims\": dims, \"constant_data\": {\"x\": xdata}}\nidata = az.from_numpyro(mcmc, **idata_kwargs)\ndel idata.log_likelihood\nidata\n```\n\n----------------------------------------\n\nTITLE: Performing Refitted LOO Cross-Validation with ArviZ\nDESCRIPTION: Executes the reloo function to refit the model for observations with high Pareto k values, providing more accurate LOO estimates.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed = az.reloo(pystan_wrapper, loo_orig=loo_orig)\n```\n\n----------------------------------------\n\nTITLE: Running MCMC Sampling with Prior and Posterior Predictive Checks\nDESCRIPTION: Performs Bayesian inference by sampling from the prior distribution, running MCMC with 500 samples after 1000 tuning steps, and generating posterior predictive samples. The code stores log-likelihood, log-prior, and transformed variables in an InferenceData object.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nvar_names = [v.name for v in model.free_RVs] \nwith model:\n    idata = pm.sample_prior_predictive()\n    idata.extend(\n        pm.sample(\n            500,\n            tune=1000,\n            idata_kwargs={\n                \"log_likelihood\": True,\n                \"log_prior\": var_names,\n                \"include_transformed\": True\n            },\n            random_seed=5\n        )\n    )\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True)\n```\n\n----------------------------------------\n\nTITLE: Defining Linear Regression Model in Stan\nDESCRIPTION: Creates a Stan model for linear regression with parameters for intercepts, slopes, and error terms. The model includes sections for data declaration, parameters, transformations, likelihood specification, and generated quantities for posterior predictions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nlinreg_code = \"\"\"\ndata {\n  int<lower=0> N;\n  vector<lower=0>[N] time_since_joined;\n  vector<lower=0>[N] slack_comments;\n  vector<lower=0>[N] github_commits;\n  \n  \n  // out of sample prediction\n  int<lower=0> N_pred;\n  vector<lower=0>[N_pred] time_since_joined_pred;\n}\n\nparameters {\n  real b0;\n  real b1;\n  real log_b_sigma;\n  \n  real c0;\n  real c1;\n  real log_c_sigma;\n}\n\ntransformed parameters {\n  real<lower=0> b_sigma = exp(log_b_sigma);\n  real<lower=0> c_sigma = exp(log_c_sigma);\n}\n\nmodel {\n  b0 ~ normal(0,200);\n  b1 ~ normal(0,200);\n  b_sigma ~ normal(0,300);\n  slack_comments ~ normal(b0 + b1 * time_since_joined, b_sigma);\n  github_commits ~ normal(c0 + c1 * time_since_joined, c_sigma);\n  \n}\n\ngenerated quantities {\n    // elementwise log likelihood\n    vector[N] log_likelihood_slack_comments;\n    vector[N] log_likelihood_github_commits;\n    \n    // posterior predictive\n    vector[N] slack_comments_hat;\n    vector[N] github_commits_hat;\n    \n    // out of sample prediction\n    vector[N_pred] slack_comments_pred;\n    vector[N_pred] github_commits_pred;\n    \n    // posterior predictive\n    for (n in 1:N) {\n        log_likelihood_slack_comments[n] = normal_lpdf(slack_comments[n] | b0 + b1 * time_since_joined[n], b_sigma);\n        slack_comments_hat[n] = normal_rng(b0 + b1 * time_since_joined[n], b_sigma);\n        \n        log_likelihood_github_commits[n] = normal_lpdf(github_commits[n] | c0 + c1 * time_since_joined[n], c_sigma);\n        github_commits_hat[n] = normal_rng(c0 + c1 * time_since_joined[n], c_sigma);\n    }\n    \n    // out of sample prediction\n    for (n in 1:N_pred) {\n        slack_comments_pred[n] = normal_rng(b0 + b1 * time_since_joined_pred[n], b_sigma);\n        github_commits_pred[n] = normal_rng(c0 + c1 * time_since_joined_pred[n], c_sigma);\n    }\n}\n\"\"\"\nsm = pystan.StanModel(model_code=linreg_code)\n```\n\n----------------------------------------\n\nTITLE: Calculating Log-Likelihood Using xarray's apply_ufunc\nDESCRIPTION: This code uses xarray's apply_ufunc to calculate the log-likelihood, handling broadcasting and dimension preservation automatically.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nlog_lik = xr.apply_ufunc(\n    calculate_log_lik,\n    idata.constant_data[\"x\"],\n    idata.observed_data[\"y\"],\n    idata.posterior[\"b0\"],\n    idata.posterior[\"b1\"],\n    idata.posterior[\"sigma_e\"],\n)\nidata.add_groups(log_likelihood=log_lik)\n```\n\n----------------------------------------\n\nTITLE: Performing Leave-One-Out Cross-Validation\nDESCRIPTION: Executes Leave-One-Out Cross-Validation using ArviZ's loo function.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nloo_orig = az.loo(idata, pointwise=True)\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Building Hierarchical Poisson Model for Rugby Match Scores\nDESCRIPTION: Creates a PyMC model for rugby match scores with team-specific attack and defense parameters, home field advantage, and a Poisson likelihood. The model represents each team's attacking and defensive strengths while enforcing sum-to-zero constraints.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# building the model\nwith pm.Model(coords=coords) as model:\n    # global model parameters\n    home = pm.Normal('home', mu=0, sigma=1)\n    sd_att = pm.HalfNormal('sd_att', sigma=2)\n    sd_def = pm.HalfNormal('sd_def', sigma=2)\n    intercept = pm.Normal('intercept', mu=3, sigma=1)\n    \n    # team-specific model parameters\n    atts_star = pm.Normal(\"atts_star\", mu=0, sigma=sd_att, dims=\"team\")\n    defs_star = pm.Normal(\"defs_star\", mu=0, sigma=sd_def, dims=\"team\")\n \n    atts = pm.Deterministic('atts', atts_star - pt.mean(atts_star), dims=\"team\")\n    defs = pm.Deterministic('defs', defs_star - pt.mean(defs_star), dims=\"team\")\n    home_theta = pt.exp(intercept + home + atts[home_team] + defs[away_team])\n    away_theta = pt.exp(intercept + atts[away_team] + defs[home_team])\n    \n    # likelihood of observed data\n    pm.Poisson('home_points', mu=home_theta, observed=observed_home_goals, dims=\"match\")\n    pm.Poisson('away_points', mu=away_theta, observed=observed_away_goals, dims=\"match\")\n```\n\n----------------------------------------\n\nTITLE: Defining PyMC Linear Regression Model\nDESCRIPTION: Creates a PyMC model for linear regression with mutable data for x and y variables.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model() as linreg_model:\n    # optional: add coords to \"time\" dimension\n    linreg_model.add_coord(\"time\", np.arange(len(xdata)), mutable=True)\n\n    x = pm.MutableData(\"x\", xdata, dims=\"time\")\n    y_obs = pm.MutableData(\"y_obs\", ydata, dims=\"time\")\n\n    b0 = pm.Normal(\"b0\", 0, 10)\n    b1 = pm.Normal(\"b1\", 0, 10)\n    sigma_e = pm.HalfNormal(\"sigma_e\", 10)\n\n    pm.Normal(\"y\", b0 + b1 * x, sigma_e, observed=y_obs, dims=\"time\")\n```\n\n----------------------------------------\n\nTITLE: Defining Custom NumPyro Sampling Wrapper\nDESCRIPTION: This class defines a custom SamplingWrapper for NumPyro, implementing methods for sampling and creating InferenceData objects.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass NumPyroSamplingWrapper(az.SamplingWrapper):\n    def __init__(self, model, **kwargs):\n        self.rng_key = kwargs.pop(\"rng_key\", random.PRNGKey(0))\n\n        super(NumPyroSamplingWrapper, self).__init__(model, **kwargs)\n\n    def sample(self, modified_observed_data):\n        self.rng_key, subkey = random.split(self.rng_key)\n        mcmc = MCMC(**self.sample_kwargs)\n        mcmc.run(subkey, **modified_observed_data)\n        return mcmc\n\n    def get_inference_data(self, fit):\n        # Cloned from PyStanSamplingWrapper.\n        idata = az.from_numpyro(mcmc, **self.idata_kwargs)\n        return idata\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom CmdStanPySamplingWrapper\nDESCRIPTION: Defines a custom LinearRegressionWrapper class that extends CmdStanPySamplingWrapper, implementing the sel_observations method for data selection in refitting.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass LinearRegressionWrapper(az.CmdStanPySamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data.x.values\n        ydata = self.idata_orig.observed_data.y.values\n        mask = np.full_like(xdata, True, dtype=bool)\n        mask[idx] = False\n        N_obs = len(mask)\n        N_ex = np.sum(~mask)\n        observations = {\n            \"N\": N_obs - N_ex,\n            \"x\": xdata[mask],\n            \"y\": ydata[mask],\n            \"N_ex\": N_ex,\n            \"x_ex\": xdata[~mask],\n            \"y_ex\": ydata[~mask],\n        }\n        return observations, \"log_lik_ex\"\n```\n\n----------------------------------------\n\nTITLE: Defining NumPyro Model\nDESCRIPTION: Implementation of a linear regression model using NumPyro's probabilistic programming syntax.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef model(N, x, y=None):\n    b0 = numpyro.sample(\"b0\", dist.Normal(0, 10))\n    b1 = numpyro.sample(\"b1\", dist.Normal(0, 10))\n    sigma_e = numpyro.sample(\"sigma_e\", dist.HalfNormal(10))\n    numpyro.sample(\"y\", dist.Normal(b0 + b1 * x, sigma_e), obs=y)\n```\n\n----------------------------------------\n\nTITLE: Creating ArviZ InferenceData Object\nDESCRIPTION: Converts the CmdStanPy fit results into an ArviZ InferenceData object, specifying dimensions and including posterior predictive and log likelihood data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndims = {\"y\": [\"time\"], \"x\": [\"time\"], \"log_likelihood\": [\"time\"], \"y_hat\": [\"time\"]}\nidata_kwargs = {\n    \"posterior_predictive\": [\"y_hat\"],\n    \"log_likelihood\": [\"log_lik\"],\n    \"dims\": dims,\n}\nidata = az.from_cmdstanpy(\n    posterior=fit, observed_data={\"y\": ydata}, constant_data={\"x\": xdata}, **idata_kwargs\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Linear Regression Wrapper\nDESCRIPTION: This class extends the NumPyroSamplingWrapper to implement specific functionality for linear regression, including observation selection for LOO-CV.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nclass LinRegWrapper(NumPyroSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data[\"x\"]\n        ydata = self.idata_orig.observed_data[\"y\"]\n        mask = np.isin(np.arange(len(xdata)), idx)\n        # data__i is passed to numpyro to sample on it -> dict of numpy array\n        # data_ex is passed to apply_ufunc -> list of DataArray\n        data__i = {\"x\": xdata[~mask].values, \"y\": ydata[~mask].values, \"N\": len(ydata[~mask])}\n        data_ex = [xdata[mask], ydata[mask]]\n        return data__i, data_ex\n```\n\n----------------------------------------\n\nTITLE: Defining NumPyro Model for Linear Regression\nDESCRIPTION: This snippet defines a NumPyro model for linear regression with priors on intercept, slope, and error standard deviation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef model(N, x, y=None):\n    b0 = numpyro.sample(\"b0\", dist.Normal(0, 10))\n    b1 = numpyro.sample(\"b1\", dist.Normal(0, 10))\n    sigma_e = numpyro.sample(\"sigma_e\", dist.HalfNormal(10))\n    numpyro.sample(\"y\", dist.Normal(b0 + b1 * x, sigma_e), obs=y)\n```\n\n----------------------------------------\n\nTITLE: Displaying Complete InferenceData Object\nDESCRIPTION: Shows the complete structure of the InferenceData object including all groups. This demonstrates how the Stan model results are organized into ArviZ's standardized schema.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nidata_stan\n```\n\n----------------------------------------\n\nTITLE: Performing Reloo with Custom Wrapper\nDESCRIPTION: Executes ArviZ's reloo function using the custom PyMCLinRegWrapper to refit the model for problematic observations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed = az.reloo(pymc_wrapper, loo_orig=loo_orig)\n```\n\n----------------------------------------\n\nTITLE: Converting PyStan Results to ArviZ InferenceData\nDESCRIPTION: Configures and creates an ArviZ InferenceData object from PyStan results, specifying dimensions and organizing model outputs.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndims = {\"y\": [\"time\"], \"x\": [\"time\"], \"log_likelihood\": [\"time\"], \"y_hat\": [\"time\"]}\nidata_kwargs = {\n    \"posterior_predictive\": [\"y_hat\"],\n    \"observed_data\": \"y\",\n    \"constant_data\": \"x\",\n    \"log_likelihood\": [\"log_lik\", \"log_lik_ex\"],\n    \"dims\": dims,\n}\nidata = az.from_pystan(posterior=fit, posterior_model=sm, **idata_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Data Setup for Eight Schools Model\nDESCRIPTION: Initializes the dataset for the Eight Schools problem including test scores, standard deviations, and school names. Sets up sample parameters with 500 draws across 4 chains.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/non_centered_eight/non_centered_eight.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndraws = 500\nchains = 4\n\nJ = 8\nscores = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\nschools = np.array([\n    \"Choate\",\n    \"Deerfield\",\n    \"Phillips Andover\",\n    \"Phillips Exeter\",\n    \"Hotchkiss\",\n    \"Lawrenceville\",\n    \"St. Paul's\",\n    \"Mt. Hermon\",\n])\n```\n\n----------------------------------------\n\nTITLE: Displaying Refitted LOO Results\nDESCRIPTION: Shows the LOO-CV results after refitting problematic observations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed\n```\n\n----------------------------------------\n\nTITLE: Creating InferenceData Object from PyStan Results\nDESCRIPTION: Constructs an ArviZ InferenceData object from PyStan results by organizing posterior samples, prior samples, observed data, and predictions. This includes setting appropriate dimensions and coordinates for all variables.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nidata_stan = az.from_pystan(\n    posterior=posterior,\n    prior=prior,\n    posterior_predictive=[\"slack_comments_hat\", \"github_commits_hat\"],\n    prior_predictive=[\"slack_comments_hat\", \"github_commits_hat\"],\n    observed_data=[\"slack_comments\", \"github_commits\"],\n    constant_data=[\"time_since_joined\"],\n    log_likelihood={\n        \"slack_comments\": \"log_likelihood_slack_comments\",\n        \"github_commits\": \"log_likelihood_github_commits\",\n    },\n    predictions=[\"slack_comments_pred\", \"github_commits_pred\"],\n    predictions_constant_data=[\"time_since_joined_pred\"],\n    coords={\"developer\": names, \"candidate developer\": candidate_devs},\n    dims={\n        \"slack_comments\": [\"developer\"],\n        \"github_commits\": [\"developer\"],\n        \"slack_comments_hat\": [\"developer\"],\n        \"github_commits_hat\": [\"developer\"],\n        \"time_since_joined\": [\"developer\"],\n        \"slack_comments_pred\": [\"candidate developer\"],\n        \"github_commits_pred\": [\"candidate developer\"],\n        \"time_since_joined_pred\": [\"candidate developer\"],\n    },\n)\n```\n\n----------------------------------------\n\nTITLE: Accessing observed data from an InferenceData object\nDESCRIPTION: Demonstrates how to access the observed data group from an InferenceData object, which is an xarray.Dataset containing the observed data used in the model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/XarrayforArviZ.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Get the observed xarray\nobserved_data = data.observed_data\nobserved_data\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Bayesian Modeling in Python\nDESCRIPTION: Imports the necessary Python libraries for Bayesian modeling: pathlib for file path operations, ArviZ for Bayesian analysis visualization, PyMC for probabilistic programming, and NumPy for numerical operations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/centered_eight/centered_eight.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\nimport arviz as az\nimport pymc as pm\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Computing Initial LOO Cross-Validation\nDESCRIPTION: Computes the initial Leave-One-Out Cross-Validation using Pareto Smoothed Importance Sampling (PSIS-LOO).\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nloo_orig = az.loo(idata, pointwise=True)\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Defining the Stan Model for Refitting\nDESCRIPTION: Implements a Stan model for linear regression that supports computing log likelihoods for both fitted and excluded data points, essential for cross-validation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nrefit_lr_code = \"\"\"\ndata {\n  // Define data for fitting\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n  // Define excluded data. It will not be used when fitting.\n  int<lower=0> N_ex;\n  vector[N_ex] x_ex;\n  vector[N_ex] y_ex;\n}\n\nparameters {\n  real b0;\n  real b1;\n  real<lower=0> sigma_e;\n}\n\nmodel {\n  b0 ~ normal(0, 10);\n  b1 ~ normal(0, 10);\n  sigma_e ~ normal(0, 10);\n  for (i in 1:N) {\n    y[i] ~ normal(b0 + b1 * x[i], sigma_e);  // use only data for fitting\n  }\n  \n}\n\ngenerated quantities {\n    vector[N] log_lik;\n    vector[N_ex] log_lik_ex;\n    vector[N] y_hat;\n    \n    for (i in 1:N) {\n        // calculate log likelihood and posterior predictive, there are \n        // no restrictions on adding more generated quantities\n        log_lik[i] = normal_lpdf(y[i] | b0 + b1 * x[i], sigma_e);\n        y_hat[i] = normal_rng(b0 + b1 * x[i], sigma_e);\n    }\n    for (j in 1:N_ex) {\n        // calculate the log likelihood of the excluded data given data_for_fitting\n        log_lik_ex[j] = normal_lpdf(y_ex[j] | b0 + b1 * x_ex[j], sigma_e);\n    }\n}\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Accessing posterior data from an InferenceData object\nDESCRIPTION: Shows how to access the posterior dataset from an InferenceData object, which is an xarray.Dataset containing MCMC samples from the posterior distribution.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/XarrayforArviZ.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Get the posterior dataset\nposterior = data.posterior\nposterior\n```\n\n----------------------------------------\n\nTITLE: Plotting Posterior with Variable Selection in ArviZ\nDESCRIPTION: This set of snippets demonstrates various ways to use the var_names argument in plot_posterior to select variables for plotting.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight);\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names='mu');\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=['mu', 'tau']);\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=['~mu', '~theta']);\n```\n\n----------------------------------------\n\nTITLE: Modifying PSIS Results for Demonstration\nDESCRIPTION: Artificially modifies some Pareto k values to simulate PSIS failure for certain observations, demonstrating the need for refitting.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nloo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])\n```\n\n----------------------------------------\n\nTITLE: Sampling from Posterior Distribution with PyStan\nDESCRIPTION: Executes MCMC sampling from the posterior distribution using the defined linear regression model and observed data. This generates posterior samples that represent the updated beliefs after observing the data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nlinreg_data_dict = {\n    \"N\": N,\n    \"slack_comments\": slack_comments,\n    \"github_commits\": github_commits,\n    \"time_since_joined\": time_since_joined,\n    \"N_pred\": N_pred,\n    \"time_since_joined_pred\": candidate_devs_time,\n}\nposterior = sm.sampling(data=linreg_data_dict, iter=200, chains=4)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for CmdStanPy and ArviZ Integration\nDESCRIPTION: This snippet imports the necessary libraries for working with CmdStanPy models and ArviZ for Bayesian inference and diagnostics.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nfrom cmdstanpy import CmdStanModel, write_stan_json\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Accessing Sample Statistics in InferenceData Object\nDESCRIPTION: Retrieves and displays the sample statistics group from the InferenceData object. This includes diagnostic information about the MCMC sampling process.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.sample_stats\n```\n\n----------------------------------------\n\nTITLE: Performing LOO-CV and Modifying Results\nDESCRIPTION: This code performs Leave-One-Out Cross-Validation (LOO-CV) and artificially modifies some Pareto k values to simulate PSIS failure for demonstration purposes.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nloo_orig = az.loo(idata, pointwise=True)\nloo_orig\n\nloo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])\n```\n\n----------------------------------------\n\nTITLE: Sampling from PyMC Model\nDESCRIPTION: Performs MCMC sampling from the defined PyMC model using specified parameters.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nsample_kwargs = {\"chains\": 4, \"draws\": 500}\nwith linreg_model:\n    idata = pm.sample(**sample_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Initializing Custom Sampling Wrapper\nDESCRIPTION: This snippet initializes the custom sampling wrapper with necessary parameters for refitting and log-likelihood calculation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\npystan_wrapper = LinRegWrapper(\n    mcmc,\n    rng_key=random.PRNGKey(7),\n    log_lik_fun=calculate_log_lik,\n    posterior_vars=(\"b0\", \"b1\", \"sigma_e\"),\n    idata_orig=idata,\n    sample_kwargs=sample_kwargs,\n    idata_kwargs=idata_kwargs,\n)\n```\n\n----------------------------------------\n\nTITLE: Combining Chains in ArviZ Forest Plots\nDESCRIPTION: These snippets demonstrate the use of the combined argument in plot_forest to either plot chains separately or combine them.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\naz.plot_forest(centered_eight, var_names=[\"mu\", \"tau\"]);\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_forest(centered_eight, var_names=[\"mu\", \"tau\"], combined=True);\n```\n\n----------------------------------------\n\nTITLE: Accessing Prior Distribution in InferenceData Object\nDESCRIPTION: Retrieves and displays the prior distribution group from the InferenceData object. This contains parameter values sampled from the prior distributions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.prior\n```\n\n----------------------------------------\n\nTITLE: Creating Complex Grid Layouts\nDESCRIPTION: Shows how to create a side-by-side comparison using custom axes with both ArviZ and Matplotlib plotting functions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", ax=ax1)\nax1.plot(X, y_pp.mean(axis=(0, 1)), c=\"black\")\nax2.scatter(X, Y, c=\"#0d7591\")\n```\n\n----------------------------------------\n\nTITLE: Building and Sampling from the Centered Eight Model using PyMC\nDESCRIPTION: Creates a hierarchical Bayesian model using PyMC's context manager with named coordinates. The model includes prior distributions for hyperparameters, a hierarchical structure for school effects, and observed data. It then samples from the prior predictive, posterior, and posterior predictive distributions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/centered_eight/centered_eight.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith pm.Model(coords={\n    \"school\": schools,\n}) as centered_eight:\n    mu = pm.Normal(\"mu\", mu=0, sigma=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta = pm.Normal(\"theta\", mu=mu, sigma=tau, shape=J, dims=\"school\")\n    y_obs = pm.ConstantData(\"scores\", scores, dims=\"school\")\n    obs = pm.Normal(\"obs\", mu=theta, sigma=sigma, observed=y_obs, dims=\"school\")\n\n    idata = pm.sample_prior_predictive()\n    idata.extend(pm.sample(draws, chains=chains))\n    idata.extend(pm.sample_posterior_predictive(idata))\nidata\n```\n\n----------------------------------------\n\nTITLE: Preparing Data and Sampling with CmdStanPy\nDESCRIPTION: Prepares the data dictionary, writes it to a JSON file, and samples from the model using CmdStanPy.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndata_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n    # No excluded data in initial fit\n    \"N_ex\": 0,\n    \"x_ex\": [],\n    \"y_ex\": [],\n}\nsample_kwargs = {\"iter_sampling\": 1000, \"chains\": 4}\nwrite_stan_json(\"linreg_ex_data.json\", data_dict)\nfit = model.sample(data=\"linreg_ex_data.json\", **sample_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Basic Label Usage with ArviZ Plot Trace\nDESCRIPTION: Demonstrates using plot_trace with custom variable names and coordinates to visualize tau and theta parameters for specific schools.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\naz.plot_trace(schools, var_names=[\"tau\", \"theta\"], coords={\"school\": [\"Choate\", \"St. Paul's\"]}, compact=False)\n```\n\n----------------------------------------\n\nTITLE: Making Predictions for New Developers\nDESCRIPTION: Uses the trained model to make predictions for new candidate developers using posterior predictive sampling.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyMC3_schema_example.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndims_pred = {\n    \"slack_comments\": [\"candidate developer\"],\n    \"github_commits\": [\"candidate developer\"],\n    \"time_since_joined\": [\"candidate developer\"],\n}\nwith model:\n    pm.set_data({\"time_since_joined\": candidate_devs_time})\n    predictions = pm.sample_posterior_predictive(trace)\n    az.from_pymc3_predictions(\n        predictions,\n        idata_orig=idata_pymc3,\n        inplace=True,\n        coords={\"candidate developer\": candidate_devs},\n        dims=dims_pred,\n    )\n```\n\n----------------------------------------\n\nTITLE: Managing Transformed Variables in InferenceData\nDESCRIPTION: Processes transformed variables from the posterior samples, renaming log-transformed variables and adding metadata about their transformations. This creates a new group in the InferenceData object to store the unconstrained posterior variables.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ntransformed_vars = idata.posterior[[\"sd_att_log__\", \"sd_def_log__\"]].rename(\n    sd_att_log__=\"sd_att\", sd_def_log__=\"sd_def\"\n)\ntransformed_vars.attrs = {\n    k.name: f\"{v.__module__}.{v.__class__.__name__}\"\n    for k, v in model.rvs_to_transforms.items()\n    if v is not None\n}\ntransformed_vars\nidata.add_groups(unconstrained_posterior=transformed_vars)\n```\n\n----------------------------------------\n\nTITLE: Building Hierarchical Bayesian Model with PyMC\nDESCRIPTION: Constructs a hierarchical Bayesian model for rugby match outcomes, incorporating team-specific attack and defense parameters, and home/away effects.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# building the model\ncoords = {\n    \"team\": teams,\n    \"match\": matches,\n    \"field\": [\"home\", \"away\"],\n}\nwith pm.Model(coords=coords) as model:\n    # global model parameters\n    sd_att = pm.HalfNormal('sd_att', sigma=2)\n    sd_def = pm.HalfNormal('sd_def', sigma=2)\n    sd_att_field = pm.HalfNormal('sd_att_field', sigma=2)\n    sd_def_field = pm.HalfNormal('sd_def_field', sigma=2)\n    intercept = pm.Normal('intercept', mu=3, sigma=1, dims=\"field\")\n    \n    # team-specific model parameters\n    atts_team = pm.Normal(\"atts_team\", mu=0, sigma=1, dims=\"team\") * sd_att\n    defs_team = pm.Normal(\"defs_team\", mu=0, sigma=1, dims=\"team\") * sd_def\n\n    # team-field specific parameters\n    atts = pm.Normal(\"atts\", mu=0, sigma=1, dims=(\"field\", \"team\")) * sd_att_field + atts_team\n    defs = pm.Normal(\"defs\", mu=0, sigma=1, dims=(\"field\", \"team\")) * sd_def_field + defs_team\n \n    atts_star = atts - pt.mean(atts, axis=0)\n    defs_star = defs - pt.mean(defs, axis=0)\n    home_theta = pt.exp(intercept[0] + atts_star[0, home_team] + defs_star[1, away_team])\n    away_theta = pt.exp(intercept[1] + atts_star[1, away_team] + defs_star[0, home_team])\n    \n    # likelihood of observed data\n    pm.Poisson('home_points', mu=home_theta, observed=observed_home_goals, dims=\"match\")\n    pm.Poisson('away_points', mu=away_theta, observed=observed_away_goals, dims=\"match\")\n```\n\n----------------------------------------\n\nTITLE: Modifying Pareto k Values for Specific Observations\nDESCRIPTION: Artificially modifies Pareto k values for specific observations to simulate PSIS failure.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nloo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ development version\nDESCRIPTION: Installation of the latest development version directly from GitHub repository\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/Installation.rst#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install git+https://github.com/arviz-devs/arviz\n```\n\n----------------------------------------\n\nTITLE: Accessing Predictions in InferenceData Object\nDESCRIPTION: Retrieves and displays the predictions group from the InferenceData object. This contains predictions for new, unobserved data points based on the posterior.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.predictions\n```\n\n----------------------------------------\n\nTITLE: Customizing Posterior Plot with Backend Arguments\nDESCRIPTION: Demonstrates using backend_kwargs to customize plot appearance by changing facecolor and grid width ratios.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(\n    data,\n    var_names=[\"g\"],\n    backend_kwargs={\n        \"facecolor\": \"#d3d0e3\",\n        \"gridspec_kw\": {\n            \"width_ratios\": [6,4]}})\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for PyMC and ArviZ\nDESCRIPTION: Imports necessary libraries including ArviZ, PyMC, NumPy, and Matplotlib for model fitting and visualization.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Displaying Reloo Results\nDESCRIPTION: Prints the results of the reloo process, showing the updated LOO-CV estimates after refitting.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed\n```\n\n----------------------------------------\n\nTITLE: Combining ArviZ and Matplotlib Plots\nDESCRIPTION: Demonstrates how to extend ArviZ plots with additional Matplotlib elements using regression data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndata = az.load_arviz_data('regression1d')\nX = data.observed_data.y_dim_0\nY = data.observed_data.y\ny_pp = data.posterior_predictive.y\nax = az.plot_hdi(X, y_pp, color=\"#b5a7b6\")\nax.scatter(X, Y, c=\"#0d7591\")\n```\n\n----------------------------------------\n\nTITLE: Using combine_dims in ArviZ Plots\nDESCRIPTION: These snippets show how to use the combine_dims argument to reduce dimensions in probability distribution plots.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=[\"mu\", \"theta\"], combine_dims={\"school\"});\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_pair(\n    non_centered_eight, var_names=[\"theta\", \"theta_t\"], combine_dims={\"school\"}, kind=\"kde\"\n);\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_forest(\n    centered_eight, var_names=\"theta\", combined=True, combine_dims={\"school\"}\n);\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_forest(\n    centered_eight, var_names=\"theta\", combine_dims={\"chain\", \"school\"}\n);\n```\n\n----------------------------------------\n\nTITLE: Setting Colors in ArviZ Plots\nDESCRIPTION: These snippets demonstrate how to set colors for plot elements using the color and colors arguments.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\naz.plot_hdi(x_data, y_data, color=\"red\");\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_density([centered_eight, non_centered_eight], colors=[\"salmon\", \"indigo\"]);\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Linear Regression Data\nDESCRIPTION: Creates synthetic data for linear regression with known parameters (intercept=-2, slope=1, sigma=3) for testing the workflow.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nnp.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)\n```\n\n----------------------------------------\n\nTITLE: Comparing with Original LOO Results\nDESCRIPTION: Displays the original LOO-CV results for comparison with the refitted version.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Combining ArviZ and Bokeh Plots in a Grid Layout\nDESCRIPTION: This snippet shows how to create a grid layout combining both ArviZ plots extended with Bokeh elements and pure Bokeh plots, demonstrating the flexibility of mixing both libraries.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_bokeh.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# load data\nobserved_data = data.observed_data.y.values\n# create axes\nf1 = figure(plot_width=400, plot_height=400, toolbar_location=\"below\")\nf2 = figure(plot_width=400, plot_height=400, toolbar_location=\"below\")\n# plot\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", show=False, ax=f1)\nf1.line(X, y_pp.mean(axis=(0, 1)), color=\"black\")\nf2.scatter(X, Y, marker=\"circle\", fill_color=\"#0d7591\")\n\nshow(row(f1, f2))\n```\n\n----------------------------------------\n\nTITLE: Accessing Constant Data in InferenceData Object\nDESCRIPTION: Retrieves and displays the constant data group from the InferenceData object. This contains values that were used as predictors or covariates in the model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.constant_data\n```\n\n----------------------------------------\n\nTITLE: Filtering Variables in ArviZ Plots\nDESCRIPTION: These snippets demonstrate the use of the filter_vars argument to select variables based on substrings or regular expressions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names='ta', filter_vars=\"like\");\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names='~ta', filter_vars=\"like\");\n```\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=\"u$\", filter_vars=\"regex\");\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data for Linear Regression\nDESCRIPTION: Creates synthetic data for a linear regression model with known parameters. This data will be used to demonstrate the refitting process.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.default_rng(251)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = rng.normal(loc=b1 * xdata + b0, scale=sigma)\n```\n\n----------------------------------------\n\nTITLE: Initial Model Fitting with PyStan\nDESCRIPTION: Prepares the data structure and fits the Stan model without any excluded data for the initial run.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndata_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n    # No excluded data in initial fit\n    \"N_ex\": 0,\n    \"x_ex\": [],\n    \"y_ex\": [],\n}\nsm = stan.build(program_code=refit_lr_code, data=data_dict)\nsample_kwargs = {\"num_samples\": 1000, \"num_chains\": 4}\nfit = sm.sample(**sample_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Calculating LOO-CV with PSIS\nDESCRIPTION: Computes the Leave-One-Out Cross-Validation using Pareto Smoothed Importance Sampling (PSIS) on the original data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nloo_orig = az.loo(idata, pointwise=True, var_name=\"log_lik\")\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Accessing Prior Sample Statistics in InferenceData Object\nDESCRIPTION: Retrieves and displays the prior sample statistics group from the InferenceData object. This includes diagnostic information about the prior sampling process.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.sample_stats_prior\n```\n\n----------------------------------------\n\nTITLE: Using Coords Argument in ArviZ Plots\nDESCRIPTION: This snippet shows how to use the coords argument to plot a subset of data based on specific coordinates.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ncoords = {\"school\": [\"Choate\", \"Phillips Exeter\"]};\naz.plot_posterior(centered_eight, var_names=[\"mu\", \"theta\"], coords=coords);\n```\n\n----------------------------------------\n\nTITLE: Enabling PyStan in Jupyter with nest_asyncio\nDESCRIPTION: Configures nest_asyncio to allow asynchronous PyStan operations to work properly in Jupyter environments.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# enable PyStan on Jupyter IDE\nimport nest_asyncio\n\nnest_asyncio.apply()\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data for Linear Regression\nDESCRIPTION: Creates synthetic data for a linear regression model with known parameters and random noise.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nrng = np.random.default_rng(4)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = rng.normal(loc=b1 * xdata + b0, scale=sigma)\n```\n\n----------------------------------------\n\nTITLE: Defining Log-Likelihood Calculation Function\nDESCRIPTION: This function calculates the log-likelihood for the linear regression model, designed to work with array inputs for vectorized operations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef calculate_log_lik(x, y, b0, b1, sigma_e):\n    mu = b0 + b1 * x\n    return stats.norm(mu, sigma_e).logpdf(y)\n```\n\n----------------------------------------\n\nTITLE: Preparing Out-of-Sample Prediction Data\nDESCRIPTION: Sets up data for out-of-sample predictions with candidate developers and their respective time values.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyMC3_schema_example.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# data for out of sample predictions\ncandidate_devs = [\"Francis\", \"Gerard\"]\ncandidate_devs_time = np.array([3.6, 5.1])\n```\n\n----------------------------------------\n\nTITLE: Accessing Predictions Constant Data in InferenceData Object\nDESCRIPTION: Retrieves and displays the predictions constant data group from the InferenceData object. This contains covariates or predictors used for generating out-of-sample predictions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.predictions_constant_data\n```\n\n----------------------------------------\n\nTITLE: Comparing with NumPy's Variance Implementation\nDESCRIPTION: Benchmarks NumPy's built-in variance function to compare performance against both custom implementations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n%timeit np.var(data, ddof=1)\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data\nDESCRIPTION: Create synthetic data for linear regression with known parameters (b0=-2, b1=1, sigma=3).\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nnp.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)\n```\n\n----------------------------------------\n\nTITLE: Setting Up and Running MCMC Sampling with NumPyro\nDESCRIPTION: This code sets up the data dictionary, MCMC sampler parameters, and runs the MCMC sampling process using NumPyro.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndata_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n}\nkernel = NUTS(model)\nsample_kwargs = dict(\n    sampler=kernel, num_warmup=1000, num_samples=1000, num_chains=4, chain_method=\"parallel\"\n)\nmcmc = MCMC(**sample_kwargs)\nmcmc.run(random.PRNGKey(0), **data_dict)\n```\n\n----------------------------------------\n\nTITLE: Preparing Out-of-Sample Prediction Data\nDESCRIPTION: Creates data for out-of-sample predictions with two candidate developers and their time since joining. This will be used to predict their expected activity based on the model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# data for out of sample predictions\ncandidate_devs = [\"Francis\", \"Gerard\"]\ncandidate_devs_time = np.array([3.6, 5.1])\nN_pred = len(candidate_devs)\n```\n\n----------------------------------------\n\nTITLE: Performing MCMC Sampling\nDESCRIPTION: Executes MCMC sampling on the model, including prior and posterior predictive sampling with specified parameters.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith model:\n    idata = pm.sample_prior_predictive()\n    idata.extend(\n        pm.sample(\n            500,\n            tune=1000,\n            target_accept=0.9,\n            random_seed=11,\n            idata_kwargs={\"log_likelihood\": True, \"log_prior\": True}\n        )\n    )\n    pm.sample_posterior_predictive(idata, extend_inferencedata=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Test Data for Performance Comparison\nDESCRIPTION: Generates a large random dataset for testing performance differences between regular and JIT-compiled functions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = np.random.randn(1000000)\n```\n\n----------------------------------------\n\nTITLE: Defining Prior Model in Stan\nDESCRIPTION: Creates a Stan model for sampling from prior distributions. The model generates prior predictions for slack comments and github commits based on time since joined, establishing baseline expectations before seeing the data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlinreg_prior_code = \"\"\"\ndata {\n  int<lower=0> N;\n  real time_since_joined[N];\n}\n\ngenerated quantities {\n    real b0;\n    real b1;\n    real log_b_sigma;\n    real<lower=0> b_sigma;\n    \n    real c0;\n    real c1;\n    real log_c_sigma;\n    real<lower=0> c_sigma;\n    \n    vector[N] slack_comments_hat;\n    vector[N] github_commits_hat;\n    \n    b0 = normal_rng(0,200);\n    b1 = normal_rng(0,200);\n    b_sigma = abs(normal_rng(0,300));\n    log_b_sigma = log(b_sigma);\n    \n    c0 = normal_rng(0,10);\n    c1 = normal_rng(0,10);\n    c_sigma = fabs(normal_rng(0,6));\n    log_c_sigma = log(b_sigma);\n    \n    for (n in 1:N) {\n        slack_comments_hat[n] = normal_rng(b0 + b1 * time_since_joined[n], b_sigma);\n        github_commits_hat[n] = normal_rng(c0 + c1 * time_since_joined[n], c_sigma);\n    }\n}\n\"\"\"\nsm_prior = pystan.StanModel(model_code=linreg_prior_code)\n```\n\n----------------------------------------\n\nTITLE: Using a Dictionary as ROPE Parameter for a Single Variable\nDESCRIPTION: This example shows how to use a dictionary to specify a ROPE for a single variable ('mu'). The dictionary contains a list of objects where each object has a 'rope' property with the desired range (4, 5).\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nrope = {'mu': [{\"rope\": (4, 5)}]}\n\naz.plot_forest(non_centered_eight, rope=rope, var_names='~theta_t', combined=True);\n```\n\n----------------------------------------\n\nTITLE: Using a Dictionary as ROPE Parameter for Multiple Variables\nDESCRIPTION: This example demonstrates specifying different ROPE values for different variables and their components. It defines separate ROPE ranges for 'mu' and for different schools in the 'theta' variable.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nrope = {\n    \"mu\": [{\"rope\": (4, 5)}],\n    \"theta\": [\n        {\"school\": \"Choate\",    \"rope\": (0, 3)},\n        {\"school\": \"Phillips Andover\", \"rope\": (10, 14)},\n        {\"school\": \"Hotchkiss\", \"rope\": (3, 9)},\n        {\"school\": \"St. Paul's\", \"rope\": (3, 8)},\n    ]\n}\n\naz.plot_forest(non_centered_eight, rope=rope, var_names=\"~theta_t\", combined=True);\n```\n\n----------------------------------------\n\nTITLE: Performing Reloo with Custom Wrapper\nDESCRIPTION: Executes the reloo function using the custom CmdStanPy wrapper to refit the model for problematic observations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed = az.reloo(cmdstanpy_wrapper, loo_orig=loo_orig)\n```\n\n----------------------------------------\n\nTITLE: Disabling Numba in ArviZ and Checking Status\nDESCRIPTION: Demonstrates how to disable Numba optimization in ArviZ using the Numba class and verify its status.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nNumba.disable_numba()\nNumba.numba_flag\n```\n\n----------------------------------------\n\nTITLE: Saving InferenceData to netCDF file format\nDESCRIPTION: Shows how to persist an InferenceData object to disk in netCDF format using the to_netcdf method, which allows for later retrieval or sharing of the complete inference results.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/XarrayforArviZ.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndata.to_netcdf(\"eight_schools_model.nc\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Axes for PPC Plots\nDESCRIPTION: Shows how to create custom matplotlib axes and use them with ArviZ plot_ppc function to create a vertically stacked comparison plot.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nobserved_data = data.observed_data.y.values\n_, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(6, 6))\nax[0].set_xlim(xmin=observed_data.min() - 1, xmax=observed_data.max() + 1)\naz.plot_ppc(data, group=\"prior\", num_pp_samples=100, ax=ax[0])\naz.plot_ppc(data, group=\"posterior\", num_pp_samples=100, ax=ax[1])\n```\n\n----------------------------------------\n\nTITLE: Saving Model Results\nDESCRIPTION: Exports the inference data (idata) to a NetCDF file format for persistence and future analysis\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/non_centered_eight/non_centered_eight.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nidata.to_netcdf(pathlib.Path(\"..\", \"..\", \"data\", \"non_centered_eight.nc\"))\n```\n\n----------------------------------------\n\nTITLE: Displaying Reloo Results\nDESCRIPTION: Shows the results of the reloo operation, which should be compared with the original LOO-CV results.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nloo_relooed\n```\n\nLANGUAGE: python\nCODE:\n```\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Matplotlib Template for ArviZ Gallery Examples\nDESCRIPTION: A template for creating Matplotlib-based examples for the ArviZ gallery. It includes necessary imports, style settings, and placeholders for plot-specific code and metadata.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_add_to_example_gallery.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\n{Plot Title}\n=========\n_gallery_category: {Gallery Category}\n_alt_text: {Alt Text}\n\"\"\"\n{Additional imports here}\n\nimport arviz as az\n\naz.style.use(\"arviz-doc\")\n\n{Additional code here}\n```\n\n----------------------------------------\n\nTITLE: Saving InferenceData to NetCDF Format in Python\nDESCRIPTION: Exports the ArviZ InferenceData object containing prior, posterior, and posterior predictive samples to a NetCDF file for persistence and later analysis. The file is saved to a relative path within the project structure.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/centered_eight/centered_eight.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Storing the model to .nc format\nidata.to_netcdf(pathlib.Path(\"..\", \"..\", \"data\", \"centered_eight.nc\"))\n```\n\n----------------------------------------\n\nTITLE: Extending ArviZ-Bokeh Plots with Additional Bokeh Elements\nDESCRIPTION: This example demonstrates how to extend an ArviZ plot created with Bokeh by adding additional Bokeh plot elements, such as scatter plots.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_bokeh.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# load data\ndata = az.load_arviz_data('regression1d')\nX = data.observed_data.y_dim_0.values\nY = data.observed_data.y.values\ny_pp = data.posterior_predictive.y.values\n# plot\nf1 = figure(plot_width=600, plot_height=600, toolbar_location=\"below\")\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", show=False, ax=f1)\nf1.scatter(X, Y, marker=\"circle\", fill_color=\"#0d7591\")\n\nshow(f1)\n```\n\n----------------------------------------\n\nTITLE: Saving Rugby Model Results to NetCDF File\nDESCRIPTION: Saves the InferenceData object containing all model results to a NetCDF file for later use or sharing.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n# Storing the model to .nc format\nidata.to_netcdf('rugby.nc')\n```\n\n----------------------------------------\n\nTITLE: Initializing PyMCLinRegWrapper\nDESCRIPTION: Creates an instance of the custom PyMCLinRegWrapper with the PyMC model, original inference data, and sampling parameters.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\npymc_wrapper = PyMCLinRegWrapper(model=linreg_model, idata_orig=idata, sample_kwargs=sample_kwargs)\n```\n\n----------------------------------------\n\nTITLE: Custom Label Mapping with MapLabeller\nDESCRIPTION: Shows how to create a custom labeller to display mathematical notation using LaTeX formatting for variable names.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport arviz.labels as azl\nlabeller = azl.MapLabeller(var_name_map={\"theta\": r\"$\\theta$\"})\ncoords = {\"school\": [\"Deerfield\", \"Hotchkiss\", \"Lawrenceville\"]}\naz.plot_posterior(schools, var_names=\"theta\", coords=coords, labeller=labeller, ref_val=5)\n```\n\n----------------------------------------\n\nTITLE: Cleaning and Enhancing InferenceData Structure\nDESCRIPTION: Removes redundant variables and enriches the InferenceData object with additional coordinates and indexing. This step assigns human-readable team names to match indices and sets up cross-indexing for more convenient data access.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nidata.posterior = idata.posterior.drop_vars([\"sd_att_log__\", \"sd_def_log__\"])\nidata.map(\n    lambda ds: ds.assign_coords(\n        home_team=(\"match\", df.home_team.values.astype(\"str\")),\n        away_team=(\"match\", df.away_team.values.astype(\"str\"))\n    ).set_xindex(\"home_team\").set_xindex(\"away_team\"),\n    groups=[\"observed_data\", \"posterior_predictive\", \"prior_predictive\", \"log_likelihood\"],\n    inplace=True\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Highly Customized Labeller with make_label_vert\nDESCRIPTION: Implements an alternative custom labeller that completely customizes the vertical labels by overriding the make_label_vert method. This approach allows for more specialized labels but doesn't work well with other plot types that use make_label_flat.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass NonIdxCoordLabeller(azl.BaseLabeller):\n    \"\"\"Use non indexing coordinates as labels.\"\"\"\n    def __init__(self, coords_ds):\n        self.coords_ds = coords_ds\n    def make_label_vert(self, var_name, sel, isel):\n        coords_ds_subset = self.coords_ds.sel(sel)\n        subj = coords_ds_subset[\"subject\"].values\n        subj_bis = coords_ds_subset[\"subject bis\"].values\n        return f\"Correlation between subjects\\n{subj} & {subj_bis}\"\n\nlabeller = NonIdxCoordLabeller(coords_ds)\n\n@savefig custom_plot_posterior2.png\naz.plot_posterior(idata, coords=coords, labeller=labeller);\n```\n\n----------------------------------------\n\nTITLE: Generating Synthetic Data for Linear Regression\nDESCRIPTION: This snippet creates synthetic data for a linear regression model with known parameters and added noise.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nnp.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)\n```\n\n----------------------------------------\n\nTITLE: Initializing the PyStan Sampling Wrapper\nDESCRIPTION: Creates an instance of the custom LinearRegressionWrapper with the Stan model, inference data, and sampling parameters.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npystan_wrapper = LinearRegressionWrapper(\n    refit_lr_code, idata_orig=idata, sample_kwargs=sample_kwargs, idata_kwargs=idata_kwargs\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Labeller for Non-Indexing Coordinates with sel_to_str\nDESCRIPTION: Implements a custom labeller that handles non-indexing coordinates by storing them in a dataset and overriding the sel_to_str method. This approach allows combining with other labellers and requires minimal code.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ncoords_ds = xr.Dataset(coords)\n\nclass NonIdxCoordLabeller(azl.BaseLabeller):\n    \"\"\"Use non indexing coordinates as labels.\"\"\"\n    def __init__(self, coords_ds):\n        self.coords_ds = coords_ds\n    def sel_to_str(self, sel, isel):\n        new_sel = {k: v.values for k, v in self.coords_ds.sel(sel).items()}\n        return super().sel_to_str(new_sel, new_sel)\n\nlabeller = NonIdxCoordLabeller(coords_ds)\n\n@savefig custom_plot_posterior1.png\naz.plot_posterior(idata, coords=coords, labeller=labeller);\n```\n\n----------------------------------------\n\nTITLE: Accessing Log Likelihood in InferenceData Object\nDESCRIPTION: Retrieves and displays the log likelihood group from the InferenceData object. This contains pointwise log likelihood values for observed data under the model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.log_likelihood\n```\n\n----------------------------------------\n\nTITLE: Creating PyMC3 Model and Sampling\nDESCRIPTION: Defines and samples from a PyMC3 model with normal distributions for slack comments and github commits, including prior and posterior predictive sampling.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyMC3_schema_example.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndims = {\n    \"slack_comments\": [\"developer\"],\n    \"github_commits\": [\"developer\"],\n    \"time_since_joined\": [\"developer\"],\n}\nwith pm.Model() as model:\n    time_since_joined = pm.Data(\"time_since_joined\", time)\n\n    b_sigma = pm.HalfNormal(\"b_sigma\", sd=300)\n    c_sigma = pm.HalfNormal(\"c_sigma\", sd=6)\n    b0 = pm.Normal(\"b0\", mu=0, sd=200)\n    b1 = pm.Normal(\"b1\", mu=0, sd=200)\n    c0 = pm.Normal(\"c0\", mu=0, sd=10)\n    c1 = pm.Normal(\"c1\", mu=0, sd=10)\n\n    pm.Normal(\n        \"slack_comments\", mu=b0 + b1 * time_since_joined, sigma=b_sigma, observed=slack_comments\n    )\n    pm.Normal(\n        \"github_commits\", mu=c0 + c1 * time_since_joined, sigma=c_sigma, observed=github_commits\n    )\n\n    trace = pm.sample(400, chains=4)\n    posterior_predictive = pm.sample_posterior_predictive(trace)\n    prior = pm.sample_prior_predictive(150)\n    idata_pymc3 = az.from_pymc3(\n        trace,\n        prior=prior,\n        posterior_predictive=posterior_predictive,\n        coords={\"developer\": names},\n        dims=dims,\n    )\n```\n\n----------------------------------------\n\nTITLE: Using Non-String Variable Names in ArviZ Plotting\nDESCRIPTION: This snippet shows how to use non-string variable names in ArviZ plotting functions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nmu = (\"mu\", \"var\")\nsamples = np.random.normal(0, 1, 100)\ndata = az.dict_to_dataset({mu: samples})\naz.plot_posterior(data);\n```\n\n----------------------------------------\n\nTITLE: Setting HDI Probability in ArviZ Plots\nDESCRIPTION: This snippet demonstrates how to set the highest density interval probability using the hdi_prob argument.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=\"mu\", hdi_prob=0.8);\n```\n\n----------------------------------------\n\nTITLE: Accessing Posterior Predictive Distribution in InferenceData Object\nDESCRIPTION: Retrieves and displays the posterior predictive distribution group from the InferenceData object. This contains simulated data based on the posterior distribution.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.posterior_predictive\n```\n\n----------------------------------------\n\nTITLE: Setting Up MCMC Sampling\nDESCRIPTION: Configuration and execution of MCMC sampling using the NUTS kernel with parallel chains.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndata_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n}\nkernel = NUTS(model)\nsample_kwargs = dict(\n    sampler=kernel, num_warmup=1000, num_samples=1000, num_chains=4, chain_method=\"parallel\"\n)\nmcmc = MCMC(**sample_kwargs)\nmcmc.run(random.PRNGKey(0), **data_dict)\n```\n\n----------------------------------------\n\nTITLE: Implementing a Standard Variance Function without Numba\nDESCRIPTION: Defines a pure Python implementation of a variance calculation function without using Numba optimization.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef variance(data, ddof=0):  # Method to calculate variance without using numba\n    a_a, b_b = 0, 0\n    for i in data:\n        a_a = a_a + i\n        b_b = b_b + i * i\n    var = b_b / (len(data)) - ((a_a / (len(data))) ** 2)\n    var = var * (len(data) / (len(data) - ddof))\n    return var\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for NumPyro and ArviZ\nDESCRIPTION: This snippet imports necessary libraries for NumPyro modeling, ArviZ for Bayesian inference, and other supporting libraries like numpy and matplotlib.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport numpyro\nimport numpyro.distributions as dist\nimport jax.random as random\nfrom numpyro.infer import MCMC, NUTS\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport xarray as xr\n```\n\n----------------------------------------\n\nTITLE: Using a Dictionary as ROPE Parameter for Multidimensional Variables\nDESCRIPTION: This example shows how to share a common ROPE for all components of multidimensional variables. It defines separate ROPE ranges for 'mu', 'theta', and 'tau' variables.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nrope = {\n    \"mu\": [{\"rope\": (4, 5)}],\n    \"theta\": [{\"rope\": (0, 3)}],\n    \"tau\": [{\"rope\": (0, 1)}],\n}\n\naz.plot_forest(non_centered_eight, rope=rope, var_names=\"~theta_t\", combined=True);\n```\n\n----------------------------------------\n\nTITLE: Accessing Observed Data in InferenceData Object\nDESCRIPTION: Retrieves and displays the observed data group from the InferenceData object. This contains the actual data used to fit the model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.observed_data\n```\n\n----------------------------------------\n\nTITLE: Preparing Rugby Match Data for Bayesian Modeling\nDESCRIPTION: Extracts and formats the observed goals, team indices, and creates coordinate references for the PyMC model. This prepares the data structure for the hierarchical model by organizing team names and match identifiers.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nobserved_home_goals = df.home_score.values\nobserved_away_goals = df.away_score.values\n\nhome_team = df.i_home.values\naway_team = df.i_away.values\n\nteams = np.array(['Wales', 'France', 'Ireland', 'Scotland', 'Italy', 'England'])\nmatches = [f\"{home} {away}\" for home, away in zip(df.home_team, df.away_team)]\ncoords = {\"team\": teams, \"match\": matches}\n```\n\n----------------------------------------\n\nTITLE: Modifying Pareto k Values for Testing Refitting\nDESCRIPTION: Artificially modifies some Pareto k diagnostic values to simulate cases where PSIS-LOO approximation would fail, requiring refitting.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nloo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Bayesian Analysis with PyStan and ArviZ\nDESCRIPTION: Imports necessary libraries for Bayesian analysis including ArviZ for visualization, PyStan for model fitting, Pandas for data handling, NumPy for numerical operations, and Xarray for labeled multi-dimensional arrays.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport pystan\nimport pandas as pd\nimport numpy as np\nimport xarray\n\nxarray.set_options(display_style=\"html\");\n```\n\n----------------------------------------\n\nTITLE: Using a Single List as ROPE Parameter in Forest Plot\nDESCRIPTION: This example demonstrates how to specify a single ROPE range using a list of two floats [-1, 2] that will apply to all variables in the forest plot. The example uses the non_centered_eight dataset and excludes theta_t variables.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\naz.plot_forest(non_centered_eight, var_names=\"~theta_t\", rope=[-1, 2]);\n```\n\n----------------------------------------\n\nTITLE: Accessing Prior Predictive Distribution in InferenceData Object\nDESCRIPTION: Retrieves and displays the prior predictive distribution group from the InferenceData object. This contains simulated data based on the prior distribution.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.prior_predictive\n```\n\n----------------------------------------\n\nTITLE: Adjusting Text Size in ArviZ Plots\nDESCRIPTION: This snippet shows how to adjust the text size in ArviZ plots using the textsize argument.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=\"theta\", coords=coords, textsize=30);\n```\n\n----------------------------------------\n\nTITLE: Preparing Data for ArviZ Function Performance Testing\nDESCRIPTION: Creates test datasets for measuring Numba's effect on ArviZ's statistical functions, including random data and a sample from the centered_eight dataset.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nsummary_data = np.random.randn(1000, 100, 10)\nschool = az.load_arviz_data(\"centered_eight\").posterior[\"mu\"].values\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ and Loading Sample Data in Python\nDESCRIPTION: This snippet imports ArviZ and NumPy, loads sample datasets, and generates random data for examples.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport numpy as np\n\ncentered_eight = az.load_arviz_data('centered_eight')\nnon_centered_eight = az.load_arviz_data('non_centered_eight')\n\nx_data = np.random.normal(0, 1, 100)\ny_data = np.random.normal(2 + x_data * 0.5, 0.5, (2, 50, 100))\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ Plotting Function Utility for Backend Support\nDESCRIPTION: Reference to the utility function 'get_plotting_function' that should be used to obtain the correct plotting function from the associated backend when implementing a new backend.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/plotting_backends.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\narviz.plots.plot_utils.get_plotting_function\n```\n\n----------------------------------------\n\nTITLE: Accessing Posterior Distribution in InferenceData Object\nDESCRIPTION: Retrieves and displays the posterior distribution group from the InferenceData object. This contains parameter estimates after conditioning on the observed data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nidata_stan.posterior\n```\n\n----------------------------------------\n\nTITLE: Accessing ArviZ Preview Namespace in Python\nDESCRIPTION: Demonstrates how to access the ArviZ preview namespace, which includes objects from arviz-base, arviz-stats, and arviz-plots. Also shows how to check the availability of sub-libraries using arviz.preview.info.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/preview.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz.preview\n\n# Access objects from arviz-base, arviz-stats, and arviz-plots\n# Example usage (not actual code):\n# result = arviz.preview.some_function()\n\n# Check availability of sub-libraries\ninfo = arviz.preview.info\n```\n\n----------------------------------------\n\nTITLE: Creating Test Data for Labeller Customization\nDESCRIPTION: Generates sample covariance matrix data with multiple dimensions for demonstrating custom labeller functionality. The data includes subject coordinates and is converted to an InferenceData object.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom numpy.random import default_rng\nimport numpy as np\nimport xarray as xr\nrng = default_rng()\ncov = rng.normal(size=(4, 500, 3, 3))\ncov = np.einsum(\"...ij,...kj\", cov, cov)\ncov[:, :, [0, 1, 2], [0, 1, 2]] = 1\nsubjects = [\"ecoli\", \"pseudomonas\", \"clostridium\"]\nidata = az.from_dict(\n    {\"cov\": cov},\n    dims={\"cov\": [\"subject\", \"subject bis\"]},\n    coords={\"subject\": subjects, \"subject bis\": subjects}\n)\nidata.posterior\n```\n\n----------------------------------------\n\nTITLE: Setting ArviZ Plot Style in Python\nDESCRIPTION: This snippet sets the ArviZ plot style to 'arviz-doc' for consistent styling in the documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\naz.style.use(\"arviz-doc\")\n```\n\n----------------------------------------\n\nTITLE: Loading ArviZ Sample Data\nDESCRIPTION: Loads the radon dataset from ArviZ sample data for demonstration.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndata = az.load_arviz_data('radon')\n```\n\n----------------------------------------\n\nTITLE: Implementing a JIT-Compiled Variance Function with Numba\nDESCRIPTION: Defines the same variance calculation function but optimized with Numba using the conditional_jit decorator from ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@conditional_jit\ndef variance_jit(data, ddof=0):  # Calculating variance with numba\n    a_a, b_b = 0, 0\n    for i in data:\n        a_a = a_a + i\n        b_b = b_b + i * i\n    var = b_b / (len(data)) - ((a_a / (len(data))) ** 2)\n    var = var * (len(data) / (len(data) - ddof))\n    return var\n```\n\n----------------------------------------\n\nTITLE: Dimension Ordering in ArviZ\nDESCRIPTION: Example of creating and ordering multidimensional data with custom coordinates and dimensions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom numpy.random import default_rng\nimport pandas as pd\nrng = default_rng()\nsamples = rng.normal(size=(4, 500, 2, 3, 4))\ncoords = {\n    \"subject\": [\"ecoli\", \"pseudomonas\", \"clostridium\"],\n    \"date\": [\"1-3-2020\", \"2-4-2020\", \"1-5-2020\", \"1-6-2020\"],\n    \"experiment\": [1, 2]\n}\nexperiments = az.from_dict(\n    posterior={\"b\": samples}, dims={\"b\": [\"experiment\", \"subject\", \"date\"]}, coords=coords\n)\n```\n\n----------------------------------------\n\nTITLE: Timing ArviZ ks_summary Function with Numba Disabled\nDESCRIPTION: Measures the performance of ArviZ's Kolmogorov-Smirnov summary function on both test datasets with Numba disabled.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n%timeit ks_summary(summary_data)\n```\n\nLANGUAGE: python\nCODE:\n```\n%timeit ks_summary(school)\n```\n\n----------------------------------------\n\nTITLE: Displaying Original LOO Results\nDESCRIPTION: Prints the original LOO-CV results for comparison with the relooed results.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nloo_orig\n```\n\n----------------------------------------\n\nTITLE: Configuring Bokeh Backend for ArviZ in Python\nDESCRIPTION: This snippet shows how to import necessary libraries, set the ArviZ style, configure Bokeh as the plotting backend, and enable Jupyter notebook output for Bokeh plots.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_bokeh.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\n\naz.style.use(\"arviz-doc\")\n\n# Confgure Bokeh as backend\naz.rcParams[\"plot.backend\"] = \"bokeh\"\naz.output_notebook()\n```\n\n----------------------------------------\n\nTITLE: Plotting Synthetic Data\nDESCRIPTION: Visualizes the generated synthetic data using Matplotlib.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pymc_refitting.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(xdata, ydata);\n```\n\n----------------------------------------\n\nTITLE: Defining ArviZ Plot Functions Index in RST\nDESCRIPTION: Sphinx documentation index defining the plotting API section of ArviZ. Uses autosummary directive to generate documentation for each plotting function automatically.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plots.rst#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz\n\n.. _plot_api:\n\nPlots\n-----\n\n.. autosummary::\n    :toctree: generated/\n\n    plot_autocorr\n    plot_bf\n    plot_bpv\n    plot_compare\n    plot_density\n    plot_dist\n    plot_dist_comparison\n    plot_dot\n    plot_ecdf\n    plot_elpd\n    plot_energy\n    plot_ess\n    plot_forest\n    plot_hdi\n    plot_kde\n    plot_khat\n    plot_loo_pit\n    plot_lm\n    plot_mcse\n    plot_pair\n    plot_parallel\n    plot_posterior\n    plot_ppc\n    plot_rank\n    plot_separation\n    plot_trace\n    plot_ts\n    plot_violin\n```\n\n----------------------------------------\n\nTITLE: Setting Figure Size in ArviZ Plots\nDESCRIPTION: This snippet demonstrates how to set the figure size using the figsize argument.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\naz.plot_posterior(centered_eight, var_names=[\"mu\", \"tau\"], figsize=(3, 6));\n```\n\n----------------------------------------\n\nTITLE: Plotting Generated Data\nDESCRIPTION: Visualizes the generated synthetic data for the linear regression model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(xdata, ydata)\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ InferenceData in Python\nDESCRIPTION: This snippet shows how to import the InferenceData class from ArviZ. It's the first step in using the InferenceData structure for Bayesian inference results.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/inference_data.rst#2025-04-16_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom arviz import InferenceData\n```\n\n----------------------------------------\n\nTITLE: Specifying Grid Layout in ArviZ Plots\nDESCRIPTION: This snippet shows how to use the grid argument to specify the number of rows and columns in the plot layout.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plots_arguments_guide.md#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\naz.plot_density([centered_eight, non_centered_eight], grid=(4, 5));\n```\n\n----------------------------------------\n\nTITLE: Defining ArviZ Stats Utilities Module in reStructuredText\nDESCRIPTION: This RST directive sets the current module to 'arviz' and creates a labeled section for the Stats utils API reference. It lists the available statistical utility functions using autosummary directive which will automatically generate individual function documentation pages.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/stats_utils.rst#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz\n\n.. _stats_utils_api:\n\nStats utils\n-----------\n\n.. autosummary::\n    :toctree: generated/\n\n    autocov\n    autocorr\n    make_ufunc\n    smooth_data\n    wrap_xarray_ufunc\n```\n\n----------------------------------------\n\nTITLE: Plotting Synthetic Data\nDESCRIPTION: This code plots the generated synthetic data using matplotlib.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(xdata, ydata)\n```\n\n----------------------------------------\n\nTITLE: Plotting the Synthetic Data\nDESCRIPTION: Visualizes the synthetic linear regression data using matplotlib.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nplt.plot(xdata, ydata)\n```\n\n----------------------------------------\n\nTITLE: Loading ArviZ data from netCDF file\nDESCRIPTION: Demonstrates how to load an InferenceData object from a netCDF file, showing the practical application of the netCDF format for data persistence in ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/XarrayforArviZ.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndata = az.load_arviz_data(\"centered_eight\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom Axes Grid with Bokeh and ArviZ\nDESCRIPTION: This snippet shows how to create custom axes using Bokeh and arrange multiple ArviZ plots in a grid, demonstrating the use of the 'ax' parameter and sharing axes ranges.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_bokeh.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom bokeh.io import show\nfrom bokeh.layouts import row\nfrom bokeh.plotting import figure\n\n# load data\nobserved_data = data.observed_data.y.to_numpy()\n# create axes\nf1 = figure(x_range=(observed_data.min() - 1, observed_data.max() + 1))\nf2 = figure(x_range=f1.x_range, y_range=f1.y_range)\n# plot\naz.plot_ppc(data, group=\"prior\", num_pp_samples=100, show=False, ax=f1)\naz.plot_ppc(data, group=\"posterior\", num_pp_samples=100, show=False, ax=f2)\n\naz.show_layout([[f1], [f2]])\n```\n\n----------------------------------------\n\nTITLE: Sampling from Prior Distribution with PyStan\nDESCRIPTION: Executes sampling from the prior model using the Fixed_param algorithm. This generates prior predictive samples without conditioning on the observed data, useful for prior predictive checks.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nlinreg_prior_data_dict = {\"N\": N, \"time_since_joined\": time_since_joined}\nprior = sm_prior.sampling(\n    data=linreg_prior_data_dict, iter=150, chains=1, algorithm=\"Fixed_param\", warmup=0\n)\n```\n\n----------------------------------------\n\nTITLE: Timing the Numba-Optimized Variance Function\nDESCRIPTION: Measures the execution time of the Numba JIT-compiled variance function to compare with the non-optimized version.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%timeit variance_jit(data, ddof=1)\n```\n\n----------------------------------------\n\nTITLE: Timing ArviZ ks_summary Function with Numba Enabled\nDESCRIPTION: Measures the performance of ArviZ's Kolmogorov-Smirnov summary function on both test datasets with Numba enabled to demonstrate the speed improvement.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n%timeit ks_summary(summary_data)\n```\n\nLANGUAGE: python\nCODE:\n```\n%timeit ks_summary(school)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Imports necessary Python packages including ArviZ, PyMC3, Pandas, NumPy and xarray. Sets xarray display style to HTML.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyMC3_schema_example.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport pymc3 as pm\nimport pandas as pd\nimport numpy as np\nimport xarray\n\nxarray.set_options(display_style=\"html\");\n```\n\n----------------------------------------\n\nTITLE: Forest Plot with Mixed Labellers\nDESCRIPTION: Demonstrates creating a forest plot with multiple models and custom labelling using DimCoordLabeller.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nschools2 = az.load_arviz_data(\"non_centered_eight\")\naz.plot_forest(\n    (schools, schools2),\n    model_names=(\"centered\", \"non_centered\"),\n    coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n    figsize=(10,7),\n    labeller=azl.DimCoordLabeller(),\n    legend=True\n)\n```\n\n----------------------------------------\n\nTITLE: Loading and Preparing Linear Regression Data\nDESCRIPTION: Reads CSV data for linear regression analysis, extracts time since joined, slack comments, and github commits for each developer. The data is used to model the relationship between time and activity metrics.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyStan_schema_example.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# read data\ndata = pd.read_csv(\"linear_regression_data.csv\", index_col=0)\ntime_since_joined = data.time.values\nslack_comments = data.comments.values\ngithub_commits = data.commits.values\nnames = data.index.values\nN = len(names)\ndata\n```\n\n----------------------------------------\n\nTITLE: Creating Mixed Labellers in ArviZ\nDESCRIPTION: Demonstrates combining DimCoordLabeller and NoModelLabeller using the mix_labellers function to create a custom labeller without writing a new class. The example shows applying this labeller to a forest plot with two models.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nMixtureLabeller = azl.mix_labellers((azl.DimCoordLabeller, azl.NoModelLabeller))\n\n@savefig mixture_plot_forest.png\naz.plot_forest(\n    (schools, schools2),\n    model_names=(\"centered\", \"non_centered\"),\n    coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n    figsize=(10,7),\n    labeller=MixtureLabeller(),\n    legend=True\n);\n```\n\n----------------------------------------\n\nTITLE: Enabling Numba in ArviZ and Checking Status\nDESCRIPTION: Demonstrates how to re-enable Numba optimization in ArviZ and verify its status has changed.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nNumba.enable_numba()\nNumba.numba_flag\n```\n\n----------------------------------------\n\nTITLE: Displaying InferenceData Object Summary\nDESCRIPTION: Shows a summary of the complete InferenceData object after all processing steps.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nidata\n```\n\n----------------------------------------\n\nTITLE: Customizing Bokeh Plot with backend_kwargs in ArviZ\nDESCRIPTION: This example demonstrates how to use the backend_kwargs argument to customize a Bokeh plot in ArviZ, specifically changing the background color and plot width.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_bokeh.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# load data\ndata = az.load_arviz_data('radon')\n\naz.plot_posterior(\n    data,\n    var_names=[\"g\"],\n    backend_kwargs={\"width\": 350,\n                    \"background_fill_color\": \"#d3d0e3\"});\n```\n\n----------------------------------------\n\nTITLE: Bokeh Template for ArviZ Gallery Examples\nDESCRIPTION: A template for creating Bokeh-based examples for the ArviZ gallery. It includes necessary imports, style settings, and placeholders for plot-specific code. The plot title must match the corresponding Matplotlib example.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_add_to_example_gallery.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"\n{Plot Title, must match the one in Matplotlib}\n=========\n\"\"\"\n{Additional imports here}\n\nimport arviz as az\n\naz.style.use(\"arviz-doc\")\n\n{Additional code here}\n```\n\n----------------------------------------\n\nTITLE: Creating Pointwise Selection Coordinates in xarray\nDESCRIPTION: Creates a non-rectangular slice with xarray by using DataArrays indexed with a dimension not present in the dataset. This approach is used to demonstrate the challenge of labelling with non-indexing coordinates.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ncoords = {\n    'subject': xr.DataArray(\n        [\"ecoli\", \"ecoli\", \"pseudomonas\"], dims=['pointwise_sel']\n    ),\n    'subject bis': xr.DataArray(\n        [\"pseudomonas\", \"clostridium\", \"clostridium\"], dims=['pointwise_sel']\n    )\n}\nidata.posterior.sel(coords)\n```\n\n----------------------------------------\n\nTITLE: Loading Libraries for Rugby Match Analysis with PyMC and ArviZ\nDESCRIPTION: Imports necessary Python libraries for Bayesian analysis: ArviZ for visualization, PyMC for modeling, PyTensor for tensor operations, and pandas/numpy for data manipulation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Loading libraries\nimport arviz as az\nimport pymc as pm\nimport pytensor.tensor as pt\nimport pandas as pd\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Preparing Rugby Match Data Variables\nDESCRIPTION: Extracts and processes match data into numpy arrays, including scores, team indices, and match details for model input.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nobserved_home_goals = df.home_score.values\nobserved_away_goals = df.away_score.values\n\nhome_team = df.i_home.values\naway_team = df.i_away.values\n\nnum_teams = len(df.i_home.drop_duplicates())\nnum_games = len(home_team)\n\nteams = np.array(['Wales', 'France', 'Ireland', 'Scotland', 'Italy', 'England'])\nmatches = [f\"{home} {away}\" for home, away in zip(df.home_team, df.away_team)]\n```\n\n----------------------------------------\n\nTITLE: Importing Necessary Libraries for Numba in ArviZ\nDESCRIPTION: Imports required packages including ArviZ, NumPy, and timeit, along with ArviZ-specific utilities for Numba integration such as conditional_jit and the Numba class.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport numpy as np\nimport timeit\n\nfrom arviz.utils import conditional_jit, Numba\nfrom arviz.stats.diagnostics import ks_summary\n```\n\n----------------------------------------\n\nTITLE: Defining Test Requirements for ArviZ Python Package\nDESCRIPTION: A requirements file that specifies the Python packages needed for testing the ArviZ library. It includes pytest for running tests, pytest-cov for code coverage reporting, cloudpickle for serialization, and includes references to optional and external requirements files.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/requirements-test.txt#2025-04-16_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npytest\npytest-cov\ncloudpickle\n\n-r requirements-optional.txt\n-r requirements-external.txt\n```\n\n----------------------------------------\n\nTITLE: Setting NumPyro Device Count\nDESCRIPTION: This code sets the number of host devices for NumPyro to use, enabling parallel computation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting_xr_lik.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnumpyro.set_host_device_count(4)\n```\n\n----------------------------------------\n\nTITLE: Reading Rugby Match Data from CSV\nDESCRIPTION: Loads rugby match data from a CSV file into a pandas DataFrame.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby/rugby.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Reading the data\ndf = pd.read_csv('rugby.csv')\n```\n\n----------------------------------------\n\nTITLE: Documenting ArviZ rc_context class using reStructuredText\nDESCRIPTION: This code snippet uses reStructuredText to document the rc_context class from the arviz module. It sets up the autosummary directive to generate documentation for the class using a specific template 'class_no_members.rst'.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/rcparams.rst#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz\n\nrcParams\n--------\n\n.. autosummary::\n    :toctree: generated/\n    :template: class_no_members.rst\n\n    rc_context\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for Rugby Analysis\nDESCRIPTION: Imports necessary Python libraries including ArviZ for visualization, PyMC for Bayesian modeling, PyTensor for tensor operations, and data manipulation libraries.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Loading libraries\nimport arviz as az\nimport pymc as pm\nimport pytensor.tensor as pt\nimport pandas as pd\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Initializing ArviZ with Matplotlib\nDESCRIPTION: Basic setup code to import required libraries and set ArviZ style for documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting_with_matplotlib.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\n\naz.style.use(\"arviz-doc\")\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ Sampling Wrappers\nDESCRIPTION: This code snippet demonstrates how to import various sampling wrappers from ArviZ. These wrappers are experimental features that provide integration with different probabilistic programming frameworks.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/wrappers.rst#2025-04-16_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom arviz import SamplingWrapper, CmdStanPySamplingWrapper, PyMCSamplingWrapper, PyStanSamplingWrapper, PyStan2SamplingWrapper\n```\n\n----------------------------------------\n\nTITLE: Loading Rugby Match Data\nDESCRIPTION: Reads rugby match data from a CSV file containing match scores and team information.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Reading the data\ndf = pd.read_csv('../rugby/rugby.csv')\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation Structure with Jinja2 for ArviZ\nDESCRIPTION: This Jinja2 template creates a structured documentation page for a class in ArviZ. It includes sections for methods and attributes, using autosummary directives to generate summaries. The template dynamically populates the content based on the class being documented.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/_templates/class_no_members.rst#2025-04-16_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n\n   {% block methods %}\n   {% if methods %}\n\n   .. rubric:: Methods\n\n   .. autosummary::\n   {% for item in methods %}\n      {% if item != \"__init__\" %}\n         {{ item }}\n      {% endif %}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block attributes %}\n   {% if attributes %}\n   .. rubric:: Attributes\n\n   .. autosummary::\n   {% for item in attributes %}\n      ~{{ name }}.{{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ Stats Functions in Python\nDESCRIPTION: This code snippet demonstrates how to import all the statistical functions from the ArviZ library. These functions include tools for model comparison, hypothesis testing, and various statistical calculations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/stats.rst#2025-04-16_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom arviz import (\n    apply_test_function,\n    compare,\n    hdi,\n    kde,\n    loo,\n    loo_pit,\n    psislw,\n    r2_score,\n    summary,\n    waic\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries for PyStan and ArviZ\nDESCRIPTION: Imports the necessary Python packages for working with ArviZ and PyStan, including numpy and matplotlib for data handling and visualization.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport stan\nimport numpy as np\nimport matplotlib.pyplot as plt\n```\n\n----------------------------------------\n\nTITLE: Defining Diagnostics Module Structure in reStructuredText\nDESCRIPTION: This RST code defines the structure for the ArviZ diagnostics API documentation. It specifies the current module, sets a reference label, and creates an autosummary table listing the key diagnostic functions available in the ArviZ package.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/diagnostics.rst#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz\n\n.. _diagnostics_api:\n\nDiagnostics\n-----------\n\n.. autosummary::\n    :toctree: generated/\n\n    bfmi\n    ess\n    rhat\n    mcse\n    psens\n```\n\n----------------------------------------\n\nTITLE: Loading ArviZ data from a centered eight schools model\nDESCRIPTION: Demonstrates how to load a pre-existing dataset into an InferenceData object using ArviZ's built-in data loading functionality.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/XarrayforArviZ.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Load the centered eight schools model\nimport arviz as az\n\ndata = az.load_arviz_data(\"centered_eight\")\ndata\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container Scripts on Linux/macOS\nDESCRIPTION: Commands for executing various Docker operations using the container.sh script on Linux and macOS, including clearing cache, building images, running tests, generating documentation, and starting shells or Jupyter environments.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/developing_in_docker.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ ./scripts/container.sh --clear-cache\n$ ./scripts/container.sh --build\n\n$ ./scripts/container.sh --test\n$ ./scripts/container.sh --docs\n$ ./scripts/container.sh --shell\n$ ./scripts/container.sh --notebook\n$ ./scripts/container.sh --lab\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ with pip\nDESCRIPTION: Basic installation of ArviZ using pip package manager\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/Installation.rst#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install arviz\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Import statements for NumPyro, ArviZ, JAX, and other dependencies needed for the implementation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport arviz as az\nimport numpyro\nimport numpyro.distributions as dist\nimport jax.random as random\nfrom numpyro.infer import MCMC, NUTS\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport xarray as xr\n```\n\n----------------------------------------\n\nTITLE: Importing ArviZ Stats Function (Python)\nDESCRIPTION: This code snippet demonstrates how to import the 'reloo' function from the ArviZ library. The 'reloo' function is part of the stats module and requires model refitting. It is marked as an experimental feature.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/stats_refitting.rst#2025-04-16_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nfrom arviz import reloo\n```\n\n----------------------------------------\n\nTITLE: Adding Matplotlib Reference with intersphinx in rST and MyST Markdown\nDESCRIPTION: Shows how to link to matplotlib documentation using intersphinx mapping with the optional intersphinx key. This example links to the plot method of matplotlib's Axes class.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_5\n\nLANGUAGE: rst\nCODE:\n```\n:meth:`mpl:matplotlib.axes.Axes.plot`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n{meth}`mpl:matplotlib.axes.Axes.plot`\n```\n\n----------------------------------------\n\nTITLE: Running Interactive Docker Sessions on Windows\nDESCRIPTION: Commands for starting interactive Docker sessions on Windows, including running a bash shell and starting a Jupyter notebook server with the ArviZ codebase mounted.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/developing_in_docker.md#2025-04-16_snippet_3\n\nLANGUAGE: powershell\nCODE:\n```\n$ docker run --mount type=bind,source=%CD%,target=/opt/arviz/ -it arviz bash\n```\n\nLANGUAGE: powershell\nCODE:\n```\n$ docker run --mount type=bind,source=%CD%,target=/opt/arviz/ --name jupyter-dock -it -d -p 8888:8888 arviz\n$ docker exec jupyter-dock bash -c \"pip install jupyter\"\n$ docker exec -it jupyter-dock bash -c \"jupyter notebook --ip 0.0.0.0 --no-browser --allow-root\"\n```\n\n----------------------------------------\n\nTITLE: Reading Stan Model Code\nDESCRIPTION: Reads and prints the Stan model code from a file. The model is designed to compute log likelihood for both fitted and excluded data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith open(\"linreg_ex_model.stan\", mode=\"r\") as f:\n    print(f.read())\n```\n\n----------------------------------------\n\nTITLE: Initializing CmdStanPy Sampling Wrapper\nDESCRIPTION: Creates an instance of the custom LinearRegressionWrapper for use with ArviZ's reloo function.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nidata_kwargs[\"log_likelihood\"] = [\"log_lik\", \"log_lik_ex\"]\ncmdstanpy_wrapper = LinearRegressionWrapper(\n    model=model,\n    idata_orig=idata,\n    data_file=\"linreg_ex_data.json\",\n    sample_kwargs=sample_kwargs,\n    idata_kwargs=idata_kwargs,\n)\n```\n\n----------------------------------------\n\nTITLE: Defining API Reference Structure with Sphinx toctree in reStructuredText\nDESCRIPTION: This is a Sphinx documentation configuration snippet that sets up the structure for the ArviZ API reference. It uses the toctree directive to organize documentation sections for various ArviZ modules, with a max depth of 2 levels.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/index.rst#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz\n\n.. _api:\n\nAPI Reference\n=============\n\n\n.. toctree::\n    :maxdepth: 2\n\n    plots\n    stats\n    diagnostics\n    stats_utils\n    data\n    inference_data\n    plot_utils\n    utils\n    rcparams\n    preview\n    wrappers\n    stats_refitting\n```\n\n----------------------------------------\n\nTITLE: Labeling Utils Summary\nDESCRIPTION: Autogenerated summary of labeling utility functions in ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plot_utils.md#2025-04-16_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n  :toctree: generated/\n\n  mix_labellers\n```\n\n----------------------------------------\n\nTITLE: Cloning an ArviZ Fork via SSH\nDESCRIPTION: Command to clone your forked ArviZ repository from GitHub to your local machine using SSH authentication.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<your GitHub handle>/arviz.git\n```\n\n----------------------------------------\n\nTITLE: Initializing CmdStanModel\nDESCRIPTION: Creates a CmdStanModel object from the Stan file containing the linear regression model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/wrappers/cmdstanpy_refitting.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nmodel = CmdStanModel(stan_file=\"linreg_ex_model.stan\")\n```\n\n----------------------------------------\n\nTITLE: Creating Custom PyStan Sampling Wrapper\nDESCRIPTION: Implements a custom PyStanSamplingWrapper subclass that handles selection of observations for cross-validation by implementing the sel_observations method.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/pystan_refitting.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nclass LinearRegressionWrapper(az.PyStanSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data.x.values\n        ydata = self.idata_orig.observed_data.y.values\n        mask = np.full_like(xdata, True, dtype=bool)\n        mask[idx] = False\n        N_obs = len(mask)\n        N_ex = np.sum(~mask)\n        observations = {\n            \"N\": int(N_obs - N_ex),\n            \"x\": xdata[mask],\n            \"y\": ydata[mask],\n            \"N_ex\": int(N_ex),\n            \"x_ex\": xdata[~mask],\n            \"y_ex\": ydata[~mask],\n        }\n        return observations, \"log_lik_ex\"\n```\n\n----------------------------------------\n\nTITLE: Adding See Also Section in Python Docstrings for ArviZ\nDESCRIPTION: Demonstrates how to add a 'See Also' section in ArviZ docstrings, which automatically links to other ArviZ objects and functions. This example shows how to reference the 'hdi' and 'plot_ppc' functions.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/docstrings.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n    See Also\n    --------\n    hdi : Calculate highest density interval (HDI) of array for given probability.\n    plot_ppc : plot for posterior/prior predictive checks.\n```\n\n----------------------------------------\n\nTITLE: Xarray Utils Summary\nDESCRIPTION: Autogenerated summary of xarray utility functions for data iteration and conversion.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plot_utils.md#2025-04-16_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n  :toctree: generated/\n\n  xarray_sel_iter\n  xarray_var_iter\n  xarray_to_ndarray\n```\n\n----------------------------------------\n\nTITLE: Adding Upstream Remote via HTTPS\nDESCRIPTION: Commands to navigate to the ArviZ directory and add the original repository as an upstream remote using HTTPS.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncd arviz\ngit remote add upstream https://github.com/arviz-devs/arviz.git\n```\n\n----------------------------------------\n\nTITLE: Setting NumPyro Device Count\nDESCRIPTION: Configure NumPyro to use multiple devices for parallel computation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/numpyro_refitting.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nnumpyro.set_host_device_count(4)\n```\n\n----------------------------------------\n\nTITLE: Adding Upstream Remote via SSH\nDESCRIPTION: Commands to navigate to the ArviZ directory and add the original repository as an upstream remote using SSH.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd arviz\ngit remote add upstream git@github.com:arviz-devs/arviz.git\n```\n\n----------------------------------------\n\nTITLE: Formatting Code with Black in ArviZ\nDESCRIPTION: Commands for installing and running the Black code formatter with 100 character line length on ArviZ codebase.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_checklist.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install black\n$ black arviz/ examples/ asv_benchmarks/\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for Sampling Wrappers in Markdown\nDESCRIPTION: A markdown toctree directive that lists available sampling wrapper documentation pages for different probabilistic programming libraries, including cmdstanpy, pystan, pymc, and numpyro implementations.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/sampling_wrappers.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\nwrappers/cmdstanpy_refitting\npystan_refitting\npymc_refitting\nnumpyro_refitting\nnumpyro_refitting_xr_lik\n```\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ Development Dependencies\nDESCRIPTION: Commands to install the required packages for ArviZ development, including documentation generation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install -r requirements.txt\npip install -r requirements-dev.txt\npip install -r requirements-docs.txt  # to generate docs locally\n```\n\n----------------------------------------\n\nTITLE: Running Tests with Plot Saving in ArviZ\nDESCRIPTION: Commands for running pytest with plot saving functionality. Allows saving test plots to default or custom directories for visual inspection and comparison.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_checklist.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pytest arviz/tests/base_tests/<name of test>.py --save\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ pytest arviz/tests/base_tests/<name of test>.py --save user_defined_directory\n```\n\n----------------------------------------\n\nTITLE: Cloning an ArviZ Fork via HTTPS\nDESCRIPTION: Command to clone your forked ArviZ repository from GitHub to your local machine using HTTPS.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/<your GitHub handle>/arviz.git\n```\n\n----------------------------------------\n\nTITLE: Running Pylint on ArviZ\nDESCRIPTION: Commands for installing and running Pylint for code quality checking on the ArviZ codebase.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_checklist.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install pylint\n$ pylint arviz/\n```\n\n----------------------------------------\n\nTITLE: Defining Gallery Categories in Python\nDESCRIPTION: A Python list defining the available categories for organizing examples in the ArviZ gallery. These categories are used for classification in the example gallery and table of contents.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_add_to_example_gallery.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n[\n    \"Mixed Plots\",\n    \"Distributions\",\n    \"Distribution Comparison\",\n    \"Inference Diagnostics\",\n    \"Regression or Time Series\",\n    \"Model Comparison\",\n    \"Model Checking\",\n    \"Miscellaneous\",\n    \"Styles\",\n]\n```\n\n----------------------------------------\n\nTITLE: Adding Changelog Template for Unreleased Version\nDESCRIPTION: Provides a markdown template for adding empty subheadings to the CHANGELOG.md file for the next unreleased version.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_release.md#2025-04-16_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n## v0.x.x Unreleased\n\n### New features\n\n### Maintenance and fixes\n\n### Deprecation\n\n### Documentation\n```\n\n----------------------------------------\n\nTITLE: Running Code Coverage Tests in ArviZ\nDESCRIPTION: Commands for installing and running code coverage tests using pytest-cov, ensuring maintain of code coverage standards.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_checklist.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install pytest pytest-cov coverage\n$ pytest --cov=arviz --cov-report=html arviz/tests/\n```\n\n----------------------------------------\n\nTITLE: Timing the Non-Numba Variance Function\nDESCRIPTION: Measures the execution time of the standard variance function using IPython's timeit magic command.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/Numba.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n%timeit variance(data, ddof=1)\n```\n\n----------------------------------------\n\nTITLE: Defining Data for the Eight Schools Model in Python\nDESCRIPTION: Sets up the data for the 'Eight Schools' example, including the number of MCMC draws and chains, test scores, standard deviations, and school names. This prepares the data structures needed for the hierarchical Bayesian model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/centered_eight/centered_eight.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndraws = 500\nchains = 4\n\nJ = 8\nscores = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\nschools = np.array(\n    [\n        \"Choate\",\n        \"Deerfield\",\n        \"Phillips Andover\",\n        \"Phillips Exeter\",\n        \"Hotchkiss\",\n        \"Lawrenceville\",\n        \"St. Paul's\",\n        \"Mt. Hermon\",\n    ]\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Changelog for New Release\nDESCRIPTION: Demonstrates how to update the CHANGELOG.md file to reflect a new release version and date.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_release.md#2025-04-16_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n- ## v0.x.x Unreleased\n+ ## v0.12.1 (2022 May 12)\n```\n\n----------------------------------------\n\nTITLE: Committing and Syncing Changes for ArviZ PR\nDESCRIPTION: Git commands to add, commit, fetch upstream changes, rebase, and push your feature branch to your fork.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngit add modified_files\ngit commit -m \"commit message here\"\ngit fetch upstream\ngit rebase upstream/main\ngit push -u origin my-feature\n```\n\n----------------------------------------\n\nTITLE: Adding External Library References in rST and MyST Markdown\nDESCRIPTION: Demonstrates how to reference functions and objects from external libraries like xarray, matplotlib, and bokeh using intersphinx. This creates hyperlinks to the documentation of these libraries.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_4\n\nLANGUAGE: rst\nCODE:\n```\n:meth:`xarray.Dataset.sel`\n:func:`matplotlib.pyplot.subplots`\n:func:`bokeh.plotting.figure`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n{meth}`xarray.Dataset.sel`\n{func}`matplotlib.pyplot.subplots`\n{func}`bokeh.plotting.figure`\n```\n\n----------------------------------------\n\nTITLE: Updating arviz_example_data Git Subtree\nDESCRIPTION: Command to update the embedded arviz_example_data repository when changes are made to the original repository. This pulls the latest commits from the main branch and squashes them into a single update commit.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/updating_example_data.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ git subtree pull --prefix arviz/data/example_data https://github.com/arviz-devs/arviz_example_data.git main --squash\n```\n\n----------------------------------------\n\nTITLE: Running Interactive Docker Sessions on Linux/macOS\nDESCRIPTION: Commands for starting interactive Docker sessions on Linux/macOS, including running a bash shell and starting a Jupyter notebook server with the ArviZ codebase mounted.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/developing_in_docker.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --mount type=bind,source=\"$(pwd)\",target=/opt/arviz/ -it arviz bash\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ docker run --mount type=bind,source=\"$(pwd)\",target=/opt/arviz/ --name jupyter-dock -it -d -p 8888:8888 arviz\n$ docker exec jupyter-dock bash -c \"pip install jupyter\"\n$ docker exec -it jupyter-dock bash -c \"jupyter notebook --ip 0.0.0.0 --no-browser --allow-root\"\n```\n\n----------------------------------------\n\nTITLE: Adding Targets in rST and MyST Markdown\nDESCRIPTION: Demonstrates how to add custom targets or anchors to headings for cross-referencing in both rST and MyST Markdown formats. These targets allow linking to specific sections using a simple syntax.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. _mytarget:\n```\n\nLANGUAGE: markdown\nCODE:\n```\n(mytarget)=\n```\n\n----------------------------------------\n\nTITLE: Running ArviZ Benchmark Tests with ASV\nDESCRIPTION: Commands to install ASV (Airspeed Velocity) and run benchmark tests for the ArviZ project. Users need to first install the ASV package and then navigate to the ArviZ directory to execute the benchmarks.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/running_benchmarks.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install asv\n$ cd arviz\n$ asv run\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx TOC Tree for ArviZ User Guide\nDESCRIPTION: ReStructuredText markup that configures the table of contents tree for the ArviZ user guide documentation. Sets maximum depth to 2 levels and includes key documentation sections.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/index.rst#2025-04-16_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n.. _user_guide:\n\nUser Guide\n==========\n\n.. toctree::\n  :maxdepth: 2\n\n  plotting\n  data_structures\n  computation\n  sampling_wrappers\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ development version with pip\nDESCRIPTION: Command to install the latest development version of ArviZ directly from the GitHub repository main branch using pip.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install git+git://github.com/arviz-devs/arviz.git\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for ArviZ\nDESCRIPTION: This snippet specifies the minimum version requirements for various Python packages that ArviZ depends on. It includes libraries for scientific computing, data manipulation, and visualization.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/requirements.txt#2025-04-16_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nsetuptools>=60.0.0\nmatplotlib>=3.5\nnumpy>=1.23.0\nscipy>=1.9.0\npackaging\npandas>=1.5.0\nxarray>=2022.6.0\nh5netcdf>=1.0.2\ntyping_extensions>=4.1.0\nxarray-einstats>=0.3\n```\n\n----------------------------------------\n\nTITLE: Referring to Targets in rST and MyST Markdown\nDESCRIPTION: Shows how to reference custom targets/anchors using the ref role in both rST and MyST Markdown formats. This allows creating internal links to other sections of the documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n:ref:`mytarget`\n```\n\nLANGUAGE: markdown\nCODE:\n```\n{ref}`mytarget`\n```\n\n----------------------------------------\n\nTITLE: Running PowerShell Container Script\nDESCRIPTION: Demonstrates how to execute the container.ps1 PowerShell script to start a Jupyter lab session.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/scripts/README.md#2025-04-16_snippet_0\n\nLANGUAGE: PowerShell\nCODE:\n```\npowershell -File container.ps1 --lab\n```\n\n----------------------------------------\n\nTITLE: Hidden TOC Tree for In-Depth Explanations\nDESCRIPTION: Sphinx toctree directive that creates a hidden table of contents for in-depth explanations, including documentation on toolchains, documentation frameworks, and plotting backends.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:hidden:\n:caption: In depth explanations\n\ndoc_toolchain\ndiataxis_for_arviz\nplotting_backends\n:::\n```\n\n----------------------------------------\n\nTITLE: Updating Version Number in Python File\nDESCRIPTION: Shows how to increment the version number in the __init__.py file of ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/how_to_release.md#2025-04-16_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n- __version = \"0.12.0\"\n+ __version = \"0.12.1\"\n```\n\n----------------------------------------\n\nTITLE: Hidden TOC Tree for Contribution Types\nDESCRIPTION: Sphinx toctree directive that creates a hidden table of contents for contribution types documentation, organizing resources related to different ways of contributing to ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:hidden:\n:caption: Contribution types\n\nissue_reports\ntranslate\nissue_triaging\noutreach\nreview_prs\ncontributing_prs\n```\n```\n\n----------------------------------------\n\nTITLE: Hidden TOC Tree for How-to Guides\nDESCRIPTION: Sphinx toctree directive that creates a hidden table of contents for how-to guides, including documentation for building Sphinx docs, updating example data, and other practical tasks.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:hidden:\n:caption: How-to guides\n\nsphinx_doc_build\nupdating_example_data\nrunning_benchmarks\nhow_to_release\nhow_to_add_to_example_gallery\n:::\n```\n\n----------------------------------------\n\nTITLE: Creating Collapsible Error Traceback in GitHub Issues using HTML Details Tag\nDESCRIPTION: Demonstrates how to use the HTML details tag to create a collapsible section for error tracebacks in GitHub issues, helping to keep issue reports clean and organized while still providing complete error information.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/issue_reports.md#2025-04-16_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<details><summary>Click to see full traceback</summary>\n\n```\nlong and barely comprehensible error traceback\n```\n\n</details>\n```\n\n----------------------------------------\n\nTITLE: Xarray Utils Module Declaration\nDESCRIPTION: Sets the current module context to arviz.sel_utils for xarray-related utility documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plot_utils.md#2025-04-16_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz.sel_utils\n```\n\n----------------------------------------\n\nTITLE: Running Docker Container Scripts on Windows\nDESCRIPTION: PowerShell commands for executing Docker operations on Windows systems, including clearing cache, building images, running tests, generating documentation, and starting shells or Jupyter environments.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/developing_in_docker.md#2025-04-16_snippet_1\n\nLANGUAGE: powershell\nCODE:\n```\n$ powershell.exe -File ./scripts/container.ps1 --clear-cache\n$ powershell.exe -File ./scripts/container.ps1 --build\n\n$ powershell.exe -File ./scripts/container.ps1 --test\n$ powershell.exe -File ./scripts/container.ps1 --docs\n$ powershell.exe -File ./scripts/container.ps1 --shell\n$ powershell.exe -File ./scripts/container.ps1 --notebook\n$ powershell.exe -File ./scripts/container.ps1 --lab\n```\n\n----------------------------------------\n\nTITLE: ArviZ Citation in BibTeX Format\nDESCRIPTION: BibTeX citation format for the ArviZ package. This can be used to cite ArviZ in academic publications.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/README.md#2025-04-16_snippet_4\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{arviz_2019,\n  doi = {10.21105/joss.01143},\n  url = {https://doi.org/10.21105/joss.01143},\n  year = {2019},\n  publisher = {The Open Journal},\n  volume = {4},\n  number = {33},\n  pages = {1143},\n  author = {Ravin Kumar and Colin Carroll and Ari Hartikainen and Osvaldo Martin},\n  title = {ArviZ a unified library for exploratory analysis of Bayesian models in Python},\n  journal = {Journal of Open Source Software}\n}\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ using conda-forge\nDESCRIPTION: Installation of ArviZ using conda package manager from conda-forge channel\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/Installation.rst#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge arviz\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation with Sphinx and Jinja2\nDESCRIPTION: This template creates a structured documentation page for a Python class. It includes the class name, module, methods, and attributes. The template uses Jinja2 syntax to dynamically generate content based on the class being documented.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/_templates/autosummary/class.rst#2025-04-16_snippet_0\n\nLANGUAGE: jinja2\nCODE:\n```\n{{ fullname | escape | underline}}\n\n.. currentmodule:: {{ module }}\n\n.. autoclass:: {{ objname }}\n\n   {% block methods %}\n   {% if methods %}\n\n   .. rubric:: Methods\n\n   .. autosummary::\n      :toctree:\n\n   {% for item in methods %}\n      {{ objname }}.{{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n\n   {% block attributes %}\n   {% if attributes %}\n   .. rubric:: Attributes\n\n   .. autosummary::\n   {% for item in attributes %}\n      ~{{ name }}.{{ item }}\n   {%- endfor %}\n   {% endif %}\n   {% endblock %}\n```\n\n----------------------------------------\n\nTITLE: Labeller Classes Summary\nDESCRIPTION: Autogenerated summary of available labeller classes in ArviZ for plot customization.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plot_utils.md#2025-04-16_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n.. autosummary::\n  :toctree: generated/\n\n  BaseLabeller\n  DimCoordLabeller\n  IdxLabeller\n  DimIdxLabeller\n  MapLabeller\n  NoModelLabeller\n  NoVarLabeller\n```\n\n----------------------------------------\n\nTITLE: Creating a Feature Branch in Git\nDESCRIPTION: Command to create and switch to a new feature branch for development changes in the ArviZ repository.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_tutorial.md#2025-04-16_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit checkout -b my-feature\n```\n\n----------------------------------------\n\nTITLE: Including External Resources in Markdown\nDESCRIPTION: A markdown include directive to append external resources content from external_resources.md file\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/community.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{include} external_resources.md\n```\n\n----------------------------------------\n\nTITLE: Including Python Examples in ArviZ Schema Documentation\nDESCRIPTION: A toctree directive that includes links to PyMC3 and PyStan examples of the ArviZ schema implementation for a 1D linear regression model.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/schema.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```{toctree}\nPyMC3 example <PyMC3_schema_example>\nPyStan example <PyStan_schema_example>\n```\n```\n\n----------------------------------------\n\nTITLE: RST Module Declaration\nDESCRIPTION: Sets the current module context to arviz.labels for documentation generation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/api/plot_utils.md#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. currentmodule:: arviz.labels\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ with conda\nDESCRIPTION: Command to install ArviZ through conda-forge channel using conda package manager.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nconda install -c conda-forge arviz\n```\n\n----------------------------------------\n\nTITLE: Adding arviz_example_data Repository as Git Subtree in ArviZ\nDESCRIPTION: Command to initially embed the arviz_example_data repository into the ArviZ codebase using git subtree. This command adds the external repository at the specified path with its commit history squashed into a single commit.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/updating_example_data.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ git subtree add --prefix arviz/data/example_data https://github.com/arviz-devs/arviz_example_data.git main --squash\n```\n\n----------------------------------------\n\nTITLE: CSS Styling for ArviZ Homepage\nDESCRIPTION: Custom CSS styles for the ArviZ homepage that override default styling to create a more visually appealing layout. Includes adjustments for content width, section padding, header styling, and text alignment.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/index.md#2025-04-16_snippet_0\n\nLANGUAGE: CSS\nCODE:\n```\n.bd-main .bd-content .bd-article-container {\n  max-width: 70rem; /* Make homepage a little wider instead of 60em */\n}\n/* Extra top/bottom padding to the sections */\narticle.bd-article section {\n  padding: 3rem 0 7rem;\n}\n/* Override all h1 headers except for the hidden ones */\nh1:not(.sd-d-none) {\n  font-weight: bold;\n  font-size: 48px;\n  text-align: center;\n  margin-bottom: 4rem;\n}\n/* Override all h3 headers that are not in hero */\nh3:not(#hero h3) {\n  font-weight: bold;\n  text-align: center;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Table of Contents in ReStructuredText\nDESCRIPTION: Sphinx toctree directive that defines the structure and organization of the getting started documentation. Includes pages for installation, introduction, Xarray integration, and working with inference data.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/getting_started/index.md#2025-04-16_snippet_0\n\nLANGUAGE: restructuredtext\nCODE:\n```\n{toctree}\n:maxdepth: 2\n\nInstallation\nIntroduction\nXarrayforArviZ\nCreatingInferenceData\nWorkingWithInferenceData\n```\n\n----------------------------------------\n\nTITLE: Running Lint Script in ArviZ\nDESCRIPTION: Command for running the lint script to check for code style warnings in ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/pr_checklist.md#2025-04-16_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ ./scripts/lint.sh\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ with pip\nDESCRIPTION: Command to install the stable version of ArviZ using pip package manager.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install arviz\n```\n\n----------------------------------------\n\nTITLE: Defining Table of Contents for ArviZ Plotting Guide in Markdown\nDESCRIPTION: This code snippet defines a table of contents for the ArviZ plotting guide using Markdown syntax. It includes links to subpages covering plot arguments, plotting with Matplotlib, and plotting with Bokeh.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/plotting.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\nplots_arguments_guide\nplotting_with_matplotlib\nplotting_with_bokeh\n```\n```\n\n----------------------------------------\n\nTITLE: ArviZ Example Gallery Links in Markdown\nDESCRIPTION: Markdown links to the ArviZ example gallery contribution guide and main gallery page.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/examples/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Charts for Example Gallery\n\n[See guide for writing scripts for the example gallery here](https://python.arviz.org/en/latest/contributing/how_to_add_to_example_gallery.html).\n\n[See Example Gallery here](https://python.arviz.org/en/latest/examples/index.html).\n```\n\n----------------------------------------\n\nTITLE: Installing ArviZ from source\nDESCRIPTION: Commands to clone the ArviZ repository from GitHub and install it using setuptools.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/README.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/arviz-devs/arviz.git\ncd arviz\npython setup.py install\n```\n\n----------------------------------------\n\nTITLE: Configuring ArviZ Table of Contents\nDESCRIPTION: Sphinx toctree directive defining the structure for computation-related documentation pages, including Numba and Dask integration guides.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/computation.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\nNumba\nDask\n```\n```\n\n----------------------------------------\n\nTITLE: Basic Sphinx Documentation Build Commands\nDESCRIPTION: Core commands for building and previewing ArviZ documentation locally using make. Includes commands for basic build, preview, and cleaning documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/sphinx_doc_build.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmake html\\nmake preview\\nmake livehtml\\nmake cleandocs\n```\n\n----------------------------------------\n\nTITLE: Defining toctree structure for ArviZ data structures documentation in Markdown\nDESCRIPTION: Sets up a toctree with maxdepth of 2 that includes label_guide and schema documentation pages. The toctree organizes the documentation hierarchy for ArviZ data structures.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/data_structures.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: 2\nlabel_guide\n../schema/schema\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Table of Contents in rST and MyST Markdown\nDESCRIPTION: Shows the syntax for adding a table of contents (toctree) in both rST and MyST Markdown formats. The toctree defines the hierarchy that appears in the navigation bar and sidebar.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_3\n\nLANGUAGE: rst\nCODE:\n```\n.. toctree::\n    developer_guide\n    doc_guide\n```\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\ndeveloper_guide\ndoc_guide\n:::\n```\n\n----------------------------------------\n\nTITLE: Importing Required Libraries\nDESCRIPTION: Imports necessary Python packages for Bayesian modeling (PyMC), visualization (ArviZ), numerical operations (NumPy), and file handling (pathlib)\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/non_centered_eight/non_centered_eight.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pathlib\nimport arviz as az\nimport pymc as pm\nimport numpy as np\n```\n\n----------------------------------------\n\nTITLE: Loading Data from CSV\nDESCRIPTION: Reads time series data from CSV file containing developer activity metrics including time, slack comments, and github commits.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/schema/PyMC3_schema_example.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# read data\ndata = pd.read_csv(\"linear_regression_data.csv\", index_col=0)\ntime = data.time.values\nslack_comments = data.comments.values\ngithub_commits = data.commits.values\nnames = data.index.values\nN = len(names)\ndata\n```\n\n----------------------------------------\n\nTITLE: Code Highlighting with Backticks in rST and MyST Markdown\nDESCRIPTION: Demonstrates how to highlight inline code keywords or file names using backticks. In rST, double backticks are used, while in Markdown, single backticks are sufficient.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/syntax_guide.md#2025-04-16_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n``conf.py``\n```\n\nLANGUAGE: markdown\nCODE:\n```\n`conf.py`\n```\n\n----------------------------------------\n\nTITLE: ReadTheDocs Warning Box Example\nDESCRIPTION: Example of the warning box syntax used in documentation to indicate content from a pull request\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/sphinx_doc_build.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n{warning}\\nThis page was created from a pull request (#PR Number).\\n\n```\n\n----------------------------------------\n\nTITLE: Referencing Matplotlib Test Module Path in ArviZ\nDESCRIPTION: Path reference to the matplotlib backend test module, provided as an example of how backend-specific tests should be organized in separate modules.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/plotting_backends.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\ntests.test_plots_matplotlib\n```\n\n----------------------------------------\n\nTITLE: Adding YouTube Video Embed in Markdown\nDESCRIPTION: Code snippet for embedding a YouTube video in Markdown documentation using the Sphinx youtube directive. This specific embed shows a webinar about contributing to ArviZ.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n:::{youtube} 457ZTes4xOI\n:::\n```\n\n----------------------------------------\n\nTITLE: Hidden TOC Tree for Tutorials\nDESCRIPTION: Sphinx toctree directive that creates a hidden table of contents for tutorials section, currently including the pull request tutorial documentation.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:hidden:\n:caption: Tutorials\n\npr_tutorial\n:::\n```\n\n----------------------------------------\n\nTITLE: Hidden TOC Tree for Reference Documentation\nDESCRIPTION: Sphinx toctree directive that creates a hidden table of contents for reference documentation, organizing resources related to PR checklist, architecture, and coding guidelines.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/contributing/index.md#2025-04-16_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n:::{toctree}\n:hidden:\n:caption: Reference\n\npr_checklist\narchitecture\ncontent_structure\ndocstrings\nsyntax_guide\ndeveloping_in_docker\n:::\n```\n\n----------------------------------------\n\nTITLE: Default Plot with Non-Indexing Coordinates\nDESCRIPTION: Creates a posterior plot using the default labeller with pointwise selection coordinates, demonstrating how non-indexing coordinates are not available to the default labeller.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/doc/source/user_guide/label_guide.rst#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n@savefig default_plot_posterior.png\naz.plot_posterior(idata, coords=coords);\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies Configuration\nDESCRIPTION: Specifies required Python packages and their version constraints needed to run ArviZ. Includes data processing, visualization and computation dependencies.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/requirements-optional.txt#2025-04-16_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumba\nnetcdf4\nbokeh>=3\ncontourpy\nujson\ndask[distributed]\nzarr>=2.5.0,<3\nxarray-datatree\ndm-tree>=0.1.8\n```\n\n----------------------------------------\n\nTITLE: Saving Model Results\nDESCRIPTION: Saves the inference data to a NetCDF file format for later analysis.\nSOURCE: https://github.com/arviz-devs/arviz/blob/main/arviz/data/example_data/code/rugby_field/rugby_field.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Storing the model to .nc format\nidata.to_netcdf('rugby_field.nc')\n```"
  }
]