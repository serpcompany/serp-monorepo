[
  {
    "owner": "eqtl-catalogue",
    "repo": "eqtl-catalogue-resources",
    "content": "TITLE: Requesting eQTL Associations with API Parameters in R\nDESCRIPTION: Function to fetch eQTL associations from the eQTL Catalogue API with support for multiple filter parameters including dataset_id, position, variant, rsid, molecular_trait_id, gene_id and p-value cutoff. Handles pagination and error responses.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_10\n\nLANGUAGE: r\nCODE:\n```\nrequest_associations_from_api <- function(\n    dataset_id, \n    pos=\"\",\n    variant=\"\", \n    rsid=\"\",\n    molecular_trait_id=\"\",\n    gene_id=\"\",\n    nlog10p=\"\"){\n  \n  size = 1000\n  start = 0\n  \n  parameter_values = c(dataset_id,pos,variant,rsid,molecular_trait_id, \n                       gene_id,nlog10p)\n  parameter_names = c('dataset_id','pos','variant','rsid','molecular_trait_id', \n                       'gene_id','nlog10p')\n  \n  while (T) {\n    URL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/{dataset_id}/associations?size={size}&start={start}\")\n    \n    #Adding defined parameters to the request\n    for (i in 1:length(parameter_values)) {\n      par = parameter_values[i]\n      par_name = parameter_names[i]\n      if (par != \"\")\n        URL = glue(\"{URL}&{par_name}={par}\")\n    }\n    \n    r <- GET(URL, accept_json())\n    cont <- content(r, \"text\", encoding = \"UTF-8\")\n    \n    # If the request was unsuccessful\n    if (status_code(r) != 200) {\n      #If we get no results at all, print error\n      if (start == 0) {\n        print(glue(\"Error {status_code(r)}\"))\n        print(cont)\n        return ()\n      }\n      #else just break\n      break\n    }\n    \n    cont_df <- fromJSON(cont)\n    \n    if (start == 0) {\n      responses <- cont_df\n    }\n    else{\n      responses <- rbind(responses, cont_df)\n    }\n    start <- start + size\n  }\n  return(responses)\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Reusable Function for Filtered Dataset Requests\nDESCRIPTION: A function that handles dataset retrieval with pagination and multiple optional filter parameters. It builds the API URL dynamically based on provided parameters and handles errors appropriately.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_4\n\nLANGUAGE: r\nCODE:\n```\nrequest_datasets_from_api <- function(study_id = \"\",\n                                      quant_method = \"\",\n                                      sample_group = \"\",\n                                      tissue_id = \"\",\n                                      study_label = \"\",\n                                      tissue_label = \"\",\n                                      condition_label = \"\") {\n  size = 1000 #Page size\n  start = 0 #Page start\n  \n  parameter_values = c(study_id,quant_method,sample_group,tissue_id,study_label, \n                       tissue_label,condition_label)\n  parameter_names = c('study_id','quant_method','sample_group','tissue_id',\n                      'study_label','tissue_label','condition_label')\n  \n  while (T) {\n    URL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/?size={size}&start={start}\")\n    \n    #Adding defined parameters to the request\n    for (i in 1:length(parameter_values)) {\n      par = parameter_values[i]\n      par_name = parameter_names[i]\n      if (par != \"\")\n        URL = glue(\"{URL}&{par_name}={par}\")\n    }\n    \n    r <- GET(URL, accept_json())\n    cont <- content(r, \"text\", encoding = \"UTF-8\")\n    \n    # If the request was unsuccessful\n    if (status_code(r) != 200) {\n      #If we get no results at all, print error\n      if (start == 0) {\n        print(glue(\"Error {status_code(r)}\"))\n        print(cont)\n        return ()\n      }\n      #else just break\n      break\n    }\n    \n    cont_df <- fromJSON(cont)\n    \n    if (start == 0) {\n      responses <- cont_df\n    }\n    else{\n      responses <- rbind(responses, cont_df)\n    }\n    start <- start + size\n  }\n  return(responses)\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching Dataset Associations Function Implementation in R\nDESCRIPTION: Implements a function to retrieve variant statistics from multiple datasets using the eQTL Catalogue API. The function merges variant information with dataset metadata and handles API responses.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_13\n\nLANGUAGE: r\nCODE:\n```\nget_assoc_over_datasets <- function(datasets, variant, gene_id) {\n  size = 1000\n  first = T\n  for (i in rownames(datasets)) {\n    row = datasets[i, ]\n    dataset_id = row$dataset_id\n    \n    URL = glue(\n      \"https://www.ebi.ac.uk/eqtl/api/v2/datasets/{dataset_id}/associations?size={size}&variant={variant}&gene_id={gene_id}\"\n    )\n    \n    r <- GET(URL, accept_json())\n    \n    if (status_code(r) != 200) {\n      next\n    }\n    \n    cont <- content(r, \"text\", encoding = \"UTF-8\")\n    cont_df <- fromJSON(cont)\n    cont_with_metadata <- cbind(cont_df, row)\n    \n    if (first) {\n      final_df <- cont_with_metadata\n      first = F\n    }\n    else{\n      final_df <- rbind(final_df, cont_with_metadata)\n    }\n  }\n  return (final_df)\n}\n```\n\n----------------------------------------\n\nTITLE: Function for Querying Genomic Region Associations in eQTL Catalogue\nDESCRIPTION: Defines a function that retrieves genetic associations within a specified genomic region around a position. The function handles pagination and returns results as a data frame.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_8\n\nLANGUAGE: r\nCODE:\n```\nrequest_associations_around_position <- function(dataset_id, position, chromosome_id, gene_id, offset = 500000){\n  size = 1000\n  start = 0\n  range_start = position - offset\n  range_end = position + offset\n  \n  \n  while (TRUE){\n    URL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/{dataset_id}/associations?size={size}&start={start}&pos={chromosome_id}:{range_start}-{range_end}&gene_id={gene_id}\")\n    \n    r <- GET(URL, accept_json())\n    cont <- content(r, \"text\", encoding = \"UTF-8\")\n    \n    if (status_code(r) != 200) {\n      # Loop will break if the request was unsuccessful\n      if(start==0) {\n        print(glue(\"Error {status_code(r)}\"))\n        print(cont)\n        return()}\n      break\n    }\n    \n   \n    cont_df <- fromJSON(cont)\n    \n    if (start == 0){\n      responses <- cont_df\n    }\n    else{\n      responses <- rbind(responses, cont_df)\n    }\n    start <- start + size\n  }\n  return(responses)\n}\n```\n\n----------------------------------------\n\nTITLE: Importing and Processing eQTL Datasets in R\nDESCRIPTION: This code imports eQTL datasets from tabix paths, processes them using the import_eQTLCatalogue function, and prepares them for colocalisation analysis. It includes error handling with purrr::safely and filtering of incomplete data.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_7\n\nLANGUAGE: r\nCODE:\n```\nrnaseq_df = dplyr::filter(imported_tabix_paths, quant_method == \"ge\") %>%\n  dplyr::mutate(qtl_id = paste(study, qtl_group, sep = \"_\"))\nftp_path_list = setNames(as.list(rnaseq_df$ftp_path), rnaseq_df$qtl_id)\n\n#Extract column names from first file\ncolumn_names = colnames(readr::read_tsv(ftp_path_list[[1]], n_max = 1))\n\n#Wrap the download function around purrr::safely to avoid catch erros\nsafe_import = purrr::safely(import_eQTLCatalogue)\n\n#Import summmary stats\nsummary_list = purrr::map(ftp_path_list, ~safe_import(., region, selected_gene_id = \"ENSG00000163947\", column_names))\n\n#Extract successful results\nresult_list = purrr::map(summary_list, ~.$result)\nresult_list = result_list[!unlist(purrr::map(result_list, is.null))]\n\n#Download failed\nmessage(\"Download failed for: \")\nfailed = names(which(!unlist(purrr::map(summary_list, ~is.null(.$error)))))\nfailed\n\n#Remove rows that have NAs for standard error\nresult_filtered = purrr::map(result_list, ~dplyr::filter(., !is.na(se)))\n\n#Run coloc\ncoloc_df_imported = purrr::map_df(result_filtered, ~run_coloc(., gwas_stats_hg38), .id = \"qtl_id\")\n```\n\n----------------------------------------\n\nTITLE: Performing Colocalisation Between Monocyte and Neutrophil eQTLs\nDESCRIPTION: Conducts colocalisation analysis between BLUEPRINT monocytes eQTL and BLUEPRINT neutrophils eQTL data using coloc.bf_bf(). The results are filtered to show only colocalisations with posterior probability (PP.H4.abf) greater than 0.8.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_6\n\nLANGUAGE: r\nCODE:\n```\neQTL_coloc = coloc::coloc.bf_bf(neutro_mat, mono_mat)\ndplyr::as_tibble(eQTL_coloc$summary) %>% dplyr::filter(PP.H4.abf > 0.8)\n```\n\n----------------------------------------\n\nTITLE: Performing Colocalization Analysis for Multiple Datasets\nDESCRIPTION: This code extends the colocalization analysis to multiple eQTL datasets from the eQTL Catalogue. It processes both microarray and RNA-seq datasets, importing summary statistics and running colocalization for each dataset.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_6\n\nLANGUAGE: R\nCODE:\n```\nmicroarray_df = dplyr::filter(tabix_paths, quant_method == \"microarray\") %>%\n  dplyr::mutate(qtl_id = paste(study, qtl_group, sep = \"_\"))\nftp_path_list = setNames(as.list(microarray_df$ftp_path), microarray_df$qtl_id)\n\n#Extract column names from first file\ncolumn_names = colnames(readr::read_tsv(ftp_path_list[[1]], n_max = 1))\n\n#Import summmary stats\nsummary_list = purrr::map(ftp_path_list, ~import_eQTLCatalogue(., region, selected_gene_id = \"ENSG00000163947\", column_names))\n\n#Run coloc\ncoloc_df_microarray = purrr::map_df(summary_list, ~run_coloc(., gwas_stats_hg38), .id = \"qtl_id\")\n\n# RNA-seq datasets\nrnaseq_df = dplyr::filter(tabix_paths, quant_method == \"ge\") %>%\n  dplyr::mutate(qtl_id = paste(study, qtl_group, sep = \"_\"))\nftp_path_list = setNames(as.list(rnaseq_df$ftp_path), rnaseq_df$qtl_id)\n\n#Extract column names from first file\ncolumn_names = colnames(readr::read_tsv(ftp_path_list[[1]], n_max = 1))\n\n#Wrap the download function around purrr::safely to avoid catch erros\nsafe_import = purrr::safely(import_eQTLCatalogue)\n\n#Import summmary stats\nsummary_list = purrr::map(ftp_path_list, ~safe_import(., region, selected_gene_id = \"ENSG00000163947\", column_names))\n\n#Extract successful results\nresult_list = purrr::map(summary_list, ~.$result)\nresult_list = result_list[!unlist(purrr::map(result_list, is.null))]\n\n#Download failed\nmessage(\"Download failed for: \")\nfailed = names(which(!unlist(purrr::map(summary_list, ~is.null(.$error)))))\nfailed\n\n#Run coloc\ncoloc_df_rnaseq = purrr::map_df(result_list, ~run_coloc(., gwas_stats_hg38), .id = \"qtl_id\")\n```\n\n----------------------------------------\n\nTITLE: Defining Colocalization Function\nDESCRIPTION: This function prepares eQTL and GWAS summary statistics for colocalization analysis using the coloc package. It formats the data and runs the coloc.abf function to perform Bayesian colocalization analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_5\n\nLANGUAGE: R\nCODE:\n```\nrun_coloc <- function(eqtl_sumstats, gwas_sumstats){\n    eQTL_dataset = list(beta = eqtl_sumstats$beta,\n                        varbeta = eqtl_sumstats$se^2,\n                        N = (eqtl_sumstats$an)[1]/2, # Samples size is allele number (AN) dvided by 2\n                        MAF = eqtl_sumstats$maf, \n                        type = \"quant\", \n                        snp = eqtl_sumstats$id)\n  gwas_dataset = list(beta = gwas_sumstats$ES,\n                      varbeta = gwas_sumstats$SE^2, \n                      type = \"quant\", \n                      snp = gwas_sumstats$id,\n                      MAF = gwas_sumstats$MAF, \n                      N = gwas_sumstats$SS)\n  coloc_res = coloc::coloc.abf(dataset1 = eQTL_dataset, dataset2 = gwas_dataset,p1 = 1e-4, p2 = 1e-4, p12 = 1e-5)\n  res_formatted = dplyr::as_tibble(t(as.data.frame(coloc_res$summary)))\n  return(res_formatted)\n}\n```\n\n----------------------------------------\n\nTITLE: SORT1 eQTL and VitD GWAS Colocalisation Analysis in R\nDESCRIPTION: Code performing colocalisation analysis between SORT1 eQTL data and Vitamin D GWAS statistics using coloc.abf. Includes data preparation and formatting for both datasets before running the colocalisation test.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_11\n\nLANGUAGE: r\nCODE:\n```\ndataset_id = \"QTD000266\"\nposition = 109274570\nchromosome_id = 1\ngene_id = \"ENSG00000134243\" #SORT1 gene\ngwas_region=\"chr1_107774781-110774507\"\n\nsort1 = request_associations_around_position(dataset_id, position, chromosome_id, gene_id) %>%\n  dplyr::select(-rsid) %>%\n  dplyr::distinct()\n\n# Import VitD \nVitD = readr::read_tsv(\"https://zenodo.org/record/7901534/files/VitD.coloc3_combined.tsv.gz\") \n\nVitD = VitD %>%\n  dplyr::filter(region == gwas_region) %>%\n  dplyr::filter(maf > 0 & maf < 1)\n\n# Run coloc.abf\nsort1_list = list(beta = sort1$beta, \n                varbeta = sort1$se^2, \n                N = sort1$an/2, \n                MAF = sort1$maf, \n                snp = sort1$variant, \n                type = \"quant\")\ncoloc::check_dataset(sort1_list)\n\nvitd_list = list(beta = VitD$beta, \n                varbeta = VitD$se^2, \n                N = VitD$an/2, \n                MAF = VitD$maf, \n                snp = VitD$variant, \n                type = \"quant\")\ncoloc::check_dataset(vitd_list)\n\nsort1_coloc_abf = coloc.abf(sort1_list, vitd_list)\n```\n\n----------------------------------------\n\nTITLE: Loading Required R Packages for Colocalisation Analysis\nDESCRIPTION: Loads the necessary R packages for colocalisation analysis, including coloc for performing the analysis, readr for data import, and dplyr for data manipulation.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_0\n\nLANGUAGE: r\nCODE:\n```\nlibrary(\"coloc\")\nlibrary(\"readr\")\nlibrary(\"dplyr\")\n```\n\n----------------------------------------\n\nTITLE: Example of Using the Association Function with the SORT1 Gene\nDESCRIPTION: Demonstrates how to use the previously defined function to query associations around the SORT1 gene. Shows parameters setup and how to display the results using knitr.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_9\n\nLANGUAGE: r\nCODE:\n```\n# Change parameters\ndataset_id = \"QTD000266\"\nposition = 109274570\nchromosome_id = 1\ngene_id = \"ENSG00000134243\" #SORT1 gene\n\nassociations <- request_associations_around_position(dataset_id, position, chromosome_id, gene_id)\nknitr::kable(head(associations), format=\"markdown\")\n```\n\n----------------------------------------\n\nTITLE: Retrieving SORT1 Gene Expression Associations\nDESCRIPTION: Demonstrates how to fetch and display associations for a specific variant (chr1_109274570_A_G) and gene (SORT1) across multiple gene expression datasets using the previously defined function.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_14\n\nLANGUAGE: r\nCODE:\n```\nvariant = \"chr1_109274570_A_G\"\ngene_id = \"ENSG00000134243\"\n\ndatasets_ge = request_datasets_from_api(quant_method = \"ge\")\n\nassociations <- get_assoc_over_datasets(datasets=datasets_ge, variant=variant, gene_id=gene_id)\nassociations\n```\n\n----------------------------------------\n\nTITLE: Visualizing Variant Effects with ggplot2\nDESCRIPTION: Creates a scatter plot using ggplot2 to visualize the effect of chr1_109274570_A_G variant on SORT1 expression across different tissues, plotting beta coefficients against -log10 p-values.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_15\n\nLANGUAGE: r\nCODE:\n```\nassociations %>%\n  unite(study, study_label, tissue_label, sep = \" \", remove = FALSE) %>%\nggplot(aes(x = beta, y = nlog10p, label = study)) +\n  geom_point() +\n  geom_text_repel() +\n  ggtitle(\"chr1_109274570_A_G effect on SORT1 expression\")\n```\n\n----------------------------------------\n\nTITLE: Cloning and Installing the eQTL-Catalogue/qcnorm Workflow\nDESCRIPTION: Commands to download the qcnorm workflow from GitHub repository. This workflow normalizes and performs QC on gene expression and genotype data from the rnaseq workflow output.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/eQTL-Catalogue/qcnorm.git\ncd qcnorm\n```\n\n----------------------------------------\n\nTITLE: Performing Colocalisation Between Neutrophil eQTL and Plasma pQTL\nDESCRIPTION: Uses coloc.bf_bf() to perform colocalisation analysis between BLUEPRINT neutrophils eQTL and INTERVAL plasma pQTL data. The results are filtered to show only colocalisations with posterior probability (PP.H4.abf) greater than 0.8.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_4\n\nLANGUAGE: r\nCODE:\n```\nneutro_coloc = coloc::coloc.bf_bf(neutro_mat, interval_mat)\ndplyr::as_tibble(neutro_coloc$summary) %>% dplyr::filter(PP.H4.abf > 0.8)\n```\n\n----------------------------------------\n\nTITLE: Performing Colocalisation Between Monocyte eQTL and Plasma pQTL\nDESCRIPTION: Performs colocalisation analysis between BLUEPRINT monocytes eQTL and INTERVAL plasma pQTL data using coloc.bf_bf() and filters the results to show only colocalisations with posterior probability (PP.H4.abf) greater than 0.8.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_5\n\nLANGUAGE: r\nCODE:\n```\nmono_coloc = coloc::coloc.bf_bf(mono_mat, interval_mat)\ndplyr::as_tibble(mono_coloc$summary) %>% dplyr::filter(PP.H4.abf > 0.8)\n```\n\n----------------------------------------\n\nTITLE: Merging and Sorting Colocalisation Results in R\nDESCRIPTION: This code combines colocalisation results from different data sources (microarray, RNA-seq, and imported datasets) and sorts them by the posterior probability of colocalisation (PP.H4.abf) in descending order.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_8\n\nLANGUAGE: r\nCODE:\n```\ncoloc_df = dplyr::bind_rows(coloc_df_microarray, coloc_df_rnaseq, coloc_df_imported)\ndplyr::arrange(coloc_df, -PP.H4.abf)\n```\n\n----------------------------------------\n\nTITLE: Filtering Datasets by Quantification Method and Tissue Type\nDESCRIPTION: Adding filters to the API request to retrieve only datasets with specific quantification method (gene expression) and tissue type (liver). This demonstrates how to add multiple filter parameters to the API URL.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_3\n\nLANGUAGE: r\nCODE:\n```\n# Change parameters\nset_quant_method = \"ge\"\nset_tissue_label = \"liver\"\n\nURL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/?quant_method={set_quant_method}&tissue_label={set_tissue_label}\")\n\nr <- GET(URL, accept_json())\ncont <- content(r, \"text\", encoding = \"UTF-8\")\ndatasets_filtered <- fromJSON(cont)\ndatasets_filtered\n```\n\n----------------------------------------\n\nTITLE: Importing and Visualizing Platelet eQTL Data\nDESCRIPTION: This code imports platelet eQTL data for a specific genomic region and gene, then visualizes the association using ggplot2. It demonstrates how to use the import_eQTLCatalogue function and create a scatter plot of p-values.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_3\n\nLANGUAGE: R\nCODE:\n```\nregion = \"3:56615721-57015721\"\n\nplatelet_df = dplyr::filter(tabix_paths, study == \"CEDAR\", tissue_label == \"platelet\")\n\n#Extract column names from first file\ncolumn_names = colnames(readr::read_tsv(platelet_df$ftp_path, n_max = 1))\n\n#Import summary statistics\nsummary_stats = import_eQTLCatalogue(platelet_df$ftp_path, region, selected_gene_id = \"ENSG00000163947\", column_names)\n\n#Visualize the association\nggplot(summary_stats, aes(x = position, y = -log(pvalue, 10))) + \ngeom_point()\n```\n\n----------------------------------------\n\nTITLE: Converting LBF Data Frames into Matrices for coloc.bf_bf()\nDESCRIPTION: Transforms the imported LBF data frames into matrices that are suitable for the coloc.bf_bf() method. This involves selecting the LBF variable columns, setting the variant IDs as row names, and transposing the matrices.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_3\n\nLANGUAGE: r\nCODE:\n```\n#BLUEPRINT monocytes\nmono_mat = as.matrix(dplyr::select(mono_lbf, lbf_variable1:lbf_variable10))\nrow.names(mono_mat) = mono_lbf$variant\nmono_mat = t(mono_mat)\n\n#BLUEPRINT neutrophils\nneutro_mat = as.matrix(dplyr::select(neutrophil_lbf, lbf_variable1:lbf_variable10))\nrow.names(neutro_mat) = neutrophil_lbf$variant\nneutro_mat = t(neutro_mat)\n\n#INTERVAL plasma pQTLs\ninterval_mat = as.matrix(dplyr::select(interval_lbf, lbf_variable1:lbf_variable10))\nrow.names(interval_mat) = interval_lbf$variant\ninterval_mat = t(interval_mat)\n```\n\n----------------------------------------\n\nTITLE: Requesting Datasets from eQTL Catalogue API in R\nDESCRIPTION: Demonstrates how to retrieve datasets from the eQTL Catalogue API by specifying quantification method and study label parameters.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_6\n\nLANGUAGE: r\nCODE:\n```\nrequest_datasets_from_api(quant_method = \"ge\", study_label = \"Alasoo_2018\")\n```\n\n----------------------------------------\n\nTITLE: Retrieving Dataset Metadata from eQTL Catalogue API in R\nDESCRIPTION: Shows how to fetch detailed metadata for a specific dataset using its ID. The code makes an HTTP GET request to the API and parses the JSON response.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_7\n\nLANGUAGE: r\nCODE:\n```\n# Change parameters\nset_dataset_id = 'QTD000266'\n  \nURL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/{set_dataset_id}\")\n\nr <- GET(URL, accept_json())\ncont <- content(r, \"text\", encoding = \"UTF-8\")\ndataset_metadata <- fromJSON(cont)\ndataset_metadata\n```\n\n----------------------------------------\n\nTITLE: Requesting All Dataset IDs from the eQTL API\nDESCRIPTION: Making a GET request to retrieve all available datasets from the eQTL API. This code demonstrates how to check the status code, extract and parse the JSON content, and display the results as a formatted table.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_2\n\nLANGUAGE: r\nCODE:\n```\n# Change parameters\nmax_pulled_rows = 1000 #All datasets will be pulled if this parameter is bigger than the actual number of datasets\n\nURL = glue(\"https://www.ebi.ac.uk/eqtl/api/v2/datasets/?size={max_pulled_rows}\")\n\n# Make a request\nr <- GET(URL, accept_json())\n# Check status\nstatus_code(r)\n\n# Extract content\ncont <- content(r, \"text\", encoding = \"UTF-8\")\n# Convert content to dataframe\ndatasets <- fromJSON(cont)\nknitr::kable(head(datasets, n = 20), format=\"markdown\")\n```\n\n----------------------------------------\n\nTITLE: Running QCNORM Workflow with Selective Normalization\nDESCRIPTION: Nextflow command to run the qcnorm workflow with specific normalization methods skipped. This configuration processes GEUVADIS_GBR20 dataset focusing only on gene-level expression.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf -profile tartu_hpc \\\n -resume\\\n --study_name GEUVADIS_GBR20\\\n --vcf_file /<absolute_path_to>/GEUVADIS_GBR20.vcf.gz\\\n --quant_results_path /<absolute_path_to>/rnaseq/results\\\n --sample_meta_path /<absolute_path_to>/GEUVADIS_GBR20_sample_metadata.tsv\\\n --skip_exon_norm true\\\n --skip_tx_norm true\\\n --skip_txrev_norm true\\\n --skip_leafcutter_norm true\\\n --outdir /<absolute_path_to>/GEUVADIS_GBR20_qcnorm\n```\n\n----------------------------------------\n\nTITLE: Importing eQTL Catalogue Tabix Paths\nDESCRIPTION: This code imports the paths to tabix-indexed summary statistics files from the eQTL Catalogue resources GitHub repository. It reads two TSV files containing file paths and converts them to tibbles.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_1\n\nLANGUAGE: R\nCODE:\n```\ntabix_paths = read.delim(\"https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/tabix/tabix_ftp_paths.tsv\", sep = \"\\t\", header = TRUE, stringsAsFactors = FALSE) %>% dplyr::as_tibble()\nimported_tabix_paths = read.delim(\"https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/tabix/tabix_ftp_paths_imported.tsv\", sep = \"\\t\", header = TRUE, stringsAsFactors = FALSE) %>% dplyr::as_tibble()\n```\n\n----------------------------------------\n\nTITLE: Defining Function to Import eQTL Catalogue Data\nDESCRIPTION: This function imports summary statistics from a tabix-indexed TSV file and performs necessary filtering. It removes duplicate rsids and multi-allelic variants to simplify colocalization analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_2\n\nLANGUAGE: R\nCODE:\n```\nimport_eQTLCatalogue <- function(ftp_path, region, selected_gene_id, column_names, verbose = TRUE){\n  \n  if(verbose){\n      print(ftp_path)\n  }\n  \n  #Fetch summary statistics with seqminer\n  fetch_table = seqminer::tabix.read.table(tabixFile = ftp_path, tabixRange = region, stringsAsFactors = FALSE) %>%\n    dplyr::as_tibble()\n  colnames(fetch_table) = column_names\n  \n  #Remove rsid duplicates and multi-allelic variant\n  summary_stats = dplyr::filter(fetch_table, gene_id == selected_gene_id) %>%\n    dplyr::select(-rsid) %>% \n    dplyr::distinct() %>% #rsid duplicates\n    dplyr::mutate(id = paste(chromosome, position, sep = \":\")) %>% \n    dplyr::group_by(id) %>% \n    dplyr::mutate(row_count = n()) %>% dplyr::ungroup() %>% \n    dplyr::filter(row_count == 1) #Multialllics\n}\n```\n\n----------------------------------------\n\nTITLE: Fetching and Processing GWAS Summary Statistics\nDESCRIPTION: This code fetches GWAS summary statistics for mean platelet volume from the IEU OpenGWAS database, converts coordinates from GRCh37 to GRCh38, and prepares the data for colocalization analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_4\n\nLANGUAGE: R\nCODE:\n```\ngwas_stats = gwasvcf::query_gwas(\"tabix_data/ebi-a-GCST004599.vcf.gz\", chrompos = \"3:56649749-57049749\")\ngwas_stats = gwasvcf::vcf_to_granges(gwas_stats) %>% \n  keepSeqlevels(\"3\") %>% \n  renameSeqlevels(\"chr3\")\n\nchain = rtracklayer::import.chain(\"tabix_data/hg19ToHg38.over.chain\")\n\ngwas_stats_hg38 = rtracklayer::liftOver(gwas_stats, chain) %>% \n  unlist() %>% \n  renameSeqlevels(\"3\") %>%\n  dplyr::as_tibble() %>%\n  dplyr::transmute(chromosome = seqnames, position = start, AF, ES, SE, LP, SS) %>%\n  dplyr::mutate(id = paste(chromosome, position, sep = \":\")) %>%\n  dplyr::mutate(MAF = pmin(AF, 1-AF)) %>% #Calculate MAF\n  dplyr::group_by(id) %>% #Keep bi-alleilic variants\n  dplyr::mutate(row_count = n()) %>% \n  dplyr::ungroup() %>% \n  dplyr::filter(row_count == 1)\n```\n\n----------------------------------------\n\nTITLE: Converting VCF Format to Binary PLINK Format\nDESCRIPTION: This command converts genotype data from VCF format to binary PLINK format (.bed/.bim/.fam), which is required for the eQTL-Catalogue/genimpute workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nplink --vcf <path_to_vcf_file> --make-bed --out <plink_file_prefix>\n```\n\n----------------------------------------\n\nTITLE: Hypothesis Testing Results Display\nDESCRIPTION: Shows the hypothesis priors and posterior probability results from an analysis, displaying numeric values for different hypotheses H0 through H4.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_12\n\nLANGUAGE: r\nCODE:\n```\n##         H0     H1        H2        H3      H4\n##  0.4797859 0.2538 0.1922582 0.0487759 0.02538\n\n## \n## Posterior\n\n##        nsnps           H0           H1           H2           H3           H4 \n## 2.538000e+03 5.317878e-91 3.574438e-07 5.494250e-87 2.937695e-03 9.970619e-01\n```\n\n----------------------------------------\n\nTITLE: Extracting BPI eQTL and pQTL Data from eQTL Catalogue\nDESCRIPTION: Bash commands to extract BPI gene-specific data from LBF variable files in the eQTL Catalogue. These commands filter the compressed files for entries related to ENSG00000101425 (BPI) and create gene-specific TSV files.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n#gunzip -c QTD000021.lbf_variable.txt.gz | head -n1 > QTD000021_ENSG00000101425.tsv && gunzip -c QTD000021.lbf_variable.txt.gz | grep ENSG00000101425 >> QTD000021_ENSG00000101425.tsv\n#gunzip -c QTD000026.lbf_variable.txt.gz | head -n1 > QTD000026_ENSG00000101425.tsv && gunzip -c QTD000026.lbf_variable.txt.gz | grep ENSG00000101425 >> QTD000026_ENSG00000101425.tsv\n#gunzip -c QTD000584.lbf_variable.txt.gz | head -n1 > QTD000584_BPI.tsv && gunzip -c QTD000584.lbf_variable.txt.gz | grep \"BPI.4126.22.1..1\" >> QTD000584_BPI.tsv\n```\n\n----------------------------------------\n\nTITLE: Importing LBF Variable Data into R\nDESCRIPTION: Reads the extracted LBF variable files for BLUEPRINT monocytes, BLUEPRINT neutrophils, and INTERVAL plasma pQTLs into R using readr::read_tsv(). The data represents different QTL datasets for the BPI gene.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/coloc.susie/coloc_susie.md#2025-04-22_snippet_2\n\nLANGUAGE: r\nCODE:\n```\n#BLUEPRINT monocytes\nmono_lbf = readr::read_tsv(\"input_data/QTD000026_ENSG00000101425.tsv.gz\", show_col_types = FALSE)\n\n#BLUEPRINT neutrophils\nneutrophil_lbf = readr::read_tsv(\"input_data/QTD000021_ENSG00000101425.tsv.gz\", show_col_types = FALSE)\n\n#INTERVAL plasma pQTLs\ninterval_lbf = readr::read_tsv(\"input_data/QTD000584_BPI.tsv.gz\", show_col_types = FALSE)\n```\n\n----------------------------------------\n\nTITLE: Installing Required R Packages for eQTL Analysis\nDESCRIPTION: Code to install the necessary R packages for working with the eQTL Catalogue API. This commented section shows how to install multiple packages at once using the install.packages function.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_0\n\nLANGUAGE: r\nCODE:\n```\n# If you do not already have all packages installed you can use this syntax to install them:\n#install.packages(c(\"tidyverse\", \"httr\", \"jsonlite\", \"dplyr\", \"coloc\", \"ggrepel\", \"glue\"))\n```\n\n----------------------------------------\n\nTITLE: Loading Required Libraries for eQTL API Interaction\nDESCRIPTION: Loading the necessary R packages for API requests, data manipulation, and visualization. This includes tidyverse for data wrangling, httr for API requests, jsonlite for JSON parsing, and coloc for colocalisation analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_1\n\nLANGUAGE: r\nCODE:\n```\nlibrary(\"tidyverse\")\nlibrary(\"httr\")\nlibrary(\"glue\")\nlibrary(\"dplyr\")\nlibrary(\"coloc\")\nlibrary(\"jsonlite\")\nlibrary(\"ggrepel\")\n```\n\n----------------------------------------\n\nTITLE: Running the eQTL-Catalogue/rnaseq Workflow with Single-end Unstranded Data\nDESCRIPTION: Nextflow command to run the rnaseq workflow on single-end unstranded RNA-seq data, specifying the singleEnd parameter to handle this type of sequencing data correctly.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf\\\n -profile tartu_hpc\\\n  -resume \\\n --readPathsFile data/read_paths_GEUVADIS_GBR20_SE.tsv\\\n --unstranded\\\n --singleEnd\\\n --run_mbv\\\n --mbv_vcf GEUVADIS_GBR20.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Running QTLMAP Workflow\nDESCRIPTION: Nextflow command to run the QTLMAP workflow, which performs QTL analysis and fine mapping using normalized molecular trait data and imputed genotypes.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_21\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf -profile eqtl_catalogue\\\n  --studyFile <qcnorm_output_directory>/<study_name>/<study_name>_qtlmap_inputs.tsv\\\n  --vcf_has_R2_field FALSE\\\n  --varid_rsid_map_file dbSNP_b151_GRCh38p7_splitted_var_rsid.vcf.gz\\\n  --n_batches 200\n```\n\n----------------------------------------\n\nTITLE: Running QTLMAP on CEDAR Dataset\nDESCRIPTION: Nextflow command to run the QTLMAP workflow on the CEDAR dataset with specific parameters for permutation testing, nominal analysis, and fine mapping with SuSiE.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_29\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf -profile tartu_hpc\\\n   --studyFile data/CEDAR_study_file.tsv\\\n    --vcf_has_R2_field true\\\n    --run_permutation true\\\n    --run_nominal true\\\n    --run_susie true\\\n    --vcf_genotype_field DS\\\n    --n_batches 200\\\n    --covariates sex\\\n    --varid_rsid_map_file data/dbSNP_b151_GRCh38p7_splitted_var_rsid.vcf.gz\\\n    -resume\n```\n\n----------------------------------------\n\nTITLE: Running QCNORM Workflow with Complete Normalization\nDESCRIPTION: Nextflow command to run the qcnorm workflow with all quantification methods included in the normalization process for the GEUVADIS_GBR20 dataset.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf -profile tartu_hpc \\\n -resume\\\n --study_name GEUVADIS_GBR20\\\n --vcf_file /<absolute_path_to>/GEUVADIS_GBR20.vcf.gz\\\n --quant_results_path /<absolute_path_to>/rnaseq/results\\\n --sample_meta_path /<absolute_path_to>/GEUVADIS_GBR20_sample_metadata.tsv\\\n --outdir /<absolute_path_to>/GEUVADIS_GBR20_qcnorm\n```\n\n----------------------------------------\n\nTITLE: Loading Required R Packages for eQTL Analysis\nDESCRIPTION: This snippet loads the necessary R libraries for accessing and analyzing eQTL Catalogue data. It includes packages for data manipulation, visualization, and genomic analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_0\n\nLANGUAGE: R\nCODE:\n```\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\nlibrary(\"readr\")\nlibrary(\"coloc\")\nlibrary(\"GenomicRanges\")\nlibrary(\"seqminer\")\n```\n\n----------------------------------------\n\nTITLE: Running QCNORM for Gene Expression Normalization Only\nDESCRIPTION: Nextflow command to run the qcnorm workflow with a pre-computed gene count matrix, focusing only on gene expression normalization without re-running the RNA-seq workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf -profile tartu_hpc -resume\\\n -entry norm_only\\\n --study_name GEUVADIS_GBR20\\\n --ge_exp_matrix_path GEUVADIS_GBR20_gene_counts.tsv.gz\\\n --sample_meta_path GEUVADIS_GBR20_sample_metadata.tsv\\\n --skip_exon_norm true\\\n --skip_tx_norm true\\\n --skip_txrev_norm true\\\n --skip_leafcutter_norm \\\n --outdir GEUVADIS_GBR20_qcnorm_ge\n```\n\n----------------------------------------\n\nTITLE: Running the eQTL-Catalogue/genimpute Workflow\nDESCRIPTION: Command to execute the genimpute workflow with Nextflow. This command performs genotype imputation on the CEDAR dataset, handling both pseudoautosomal regions (PAR) and non-PAR regions of the X chromosome.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf \\\n  -profile tartu_hpc -resume\\\n  --bfile plink_genimpute/CEDAR\\\n  --output_name CEDAR\\\n  --outdir CEDAR\\\n  --impute_PAR true\\\n  --impute_non_PAR true\n```\n\n----------------------------------------\n\nTITLE: Running the eQTL-Catalogue/rnaseq Workflow with Paired-end Stranded Data\nDESCRIPTION: Nextflow command for running the rnaseq workflow on paired-end stranded RNA-seq data, using the reverse_stranded parameter. Note that this example will complete on the GEUVADIS dataset but will ignore ~50% of reads as the dataset is unstranded.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf\\\n -profile tartu_hpc\\\n  -resume \\\n --readPathsFile data/read_paths_GEUVADIS_GBR20.tsv\\\n --reverse_stranded\\\n --run_mbv\\\n --mbv_vcf GEUVADIS_GBR20.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Checking for Missing Genotypes by Individual\nDESCRIPTION: This command identifies individuals with high levels of missing genotypes, which could cause the imputation workflow to fail. Individuals with >5% missingness should be excluded.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nplink --bfile <plink_file_prefix> --missing\n```\n\n----------------------------------------\n\nTITLE: Running the eQTL-Catalogue/rnaseq Workflow with Paired-end Unstranded Data\nDESCRIPTION: Nextflow command to run the rnaseq workflow on paired-end unstranded RNA-seq data from the GEUVADIS_GBR20 dataset. This includes genotype concordance checking using MBV.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nnextflow run main.nf\\\n -profile tartu_hpc\\\n  -resume \\\n --readPathsFile data/read_paths_GEUVADIS_GBR20.tsv\\\n --unstranded\\\n --run_mbv\\\n --mbv_vcf GEUVADIS_GBR20.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Cloning and Installing the eQTL-Catalogue/genimpute Workflow\nDESCRIPTION: Commands to download the genimpute workflow from GitHub repository. This workflow is used for genotype imputation and performs QC filtering, phasing, and imputation of genotype data.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/eQTL-Catalogue/genimpute.git\ncd genimpute\n```\n\n----------------------------------------\n\nTITLE: Cloning and Installing the eQTL-Catalogue/rnaseq Workflow\nDESCRIPTION: Commands to download the rnaseq workflow from GitHub. This workflow performs RNA-seq quantification including adapter trimming, alignment, gene/exon counting, and splice junction quantification.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/eQTL-Catalogue/rnaseq.git\ncd rnaseq\n```\n\n----------------------------------------\n\nTITLE: Using the API Request Function with Filtering Parameters\nDESCRIPTION: Example of using the custom function to request datasets filtered by quantification method and tissue label. This demonstrates practical application of the reusable function created earlier.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/API_v2/eQTL_API_tutorial.md#2025-04-22_snippet_5\n\nLANGUAGE: r\nCODE:\n```\nrequest_datasets_from_api(quant_method = \"ge\", tissue_label = \"liver\")\n```\n\n----------------------------------------\n\nTITLE: Cloning the QTLMAP Workflow Repository\nDESCRIPTION: Git commands to clone the eQTL-Catalogue/qtlmap repository from GitHub and navigate to its directory, preparing for QTL analysis and fine mapping.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_18\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/eQTL-Catalogue/qtlmap.git\ncd qtlmap\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Imputed Genotypes\nDESCRIPTION: Commands to download imputed genotypes for the CEDAR dataset from Zenodo, produced by the eQTL-Catalogue/genimpute workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_23\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6171348/files/CEDAR_genimpute_200921.vcf.gz\nwget https://zenodo.org/record/6171348/files/CEDAR_genimpute_200921.vcf.gz.csi\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Molecular Trait Metadata\nDESCRIPTION: Command to download the molecular trait metadata for the CEDAR dataset from Zenodo, which contains information about the Illumina HumanHT-12 V4 microarray probes.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_26\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/3366011/files/HumanHT-12_V4_Ensembl_96_phenotype_metadata.tsv.gz\n```\n\n----------------------------------------\n\nTITLE: Checking Chromosome Names in a PLINK File\nDESCRIPTION: This command displays the frequency of each chromosome in a PLINK .bim file, which helps to identify how chromosomes are encoded, particularly the X chromosome.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncut -f 1 fetal_geno.bim | uniq -c\n```\n\n----------------------------------------\n\nTITLE: Downloading Variant ID to rsID Mapping File\nDESCRIPTION: Command to download the mapping file that connects unique variant IDs (CHR_POS_REF_ALT format) to rsIDs, required for the QTLMAP workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_20\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6034023/files/dbSNP_b151_GRCh38p7_splitted_var_rsid.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading Variant ID to rsID Mapping for CEDAR Analysis\nDESCRIPTION: Command to download the mapping file that connects unique variant IDs to rsIDs for the CEDAR dataset analysis, used in the QTLMAP workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_28\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6034023/files/dbSNP_b151_GRCh38p7_splitted_var_rsid.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading RNA-seq Reference for QTLMAP\nDESCRIPTION: Command to download the RNA-seq reference dataset required for the QTLMAP workflow, containing molecular trait metadata files used in QTL analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_19\n\nLANGUAGE: bash\nCODE:\n```\nwget ftp://ftp.ebi.ac.uk/pub/databases/spot/eQTL/references/rnaseq_complete_reference_290322.tar.gz\ntar -xzvf rnaseq_complete_reference_290322.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Removing Samples with High Missingness from PLINK File\nDESCRIPTION: This command removes samples with high missingness from the PLINK binary files using the --remove option, creating a new set of files without problematic samples.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nplink -bfile OneK1K_AllChr --remove remove_list.txt --make-bed --out OneK1K_nonmissing\n```\n\n----------------------------------------\n\nTITLE: Downloading Reference Population Genotype Dataset\nDESCRIPTION: Commands to download and extract the reference population genotype dataset, used for projecting individuals in the VCF file to the 1000 Genomes reference populations.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6935520/files/popassign_complete_reference_280722.tar.gz\ntar -xzvf popassign_complete_reference_280722.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading 1000 Genomes Reference Panel for Imputation\nDESCRIPTION: Commands to download and extract the 1000 Genomes 30x on GRCh38 reference panel from the eQTL Catalogue FTP server. This reference panel is required for the genotype imputation process.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nwget ftp://ftp.ebi.ac.uk/pub/databases/spot/eQTL/references/genimpute_complete_reference_150322.tar.gz\ntar -xzvf genimpute_complete_reference_150322.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading RNA-seq Reference Dataset\nDESCRIPTION: Commands to download and extract the RNA-seq reference dataset required for molecular trait metadata files, used by the eQTL-Catalogue/rnaseq workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nwget ftp://ftp.ebi.ac.uk/pub/databases/spot/eQTL/references/rnaseq_complete_reference_290322.tar.gz\ntar -xzvf rnaseq_complete_reference_290322.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Normalized Gene Expression Matrix\nDESCRIPTION: Command to download the normalized gene expression matrix for the CEDAR dataset from Zenodo, produced by the eQTL-Catalogue/qcnorm workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_24\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6171348/files/CEDAR.platelet.tsv.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading RNA-seq Reference Annotations\nDESCRIPTION: Commands to download and extract reference transcriptome annotations for RNA-seq quantification. These files include HISAT2 index, GENCODE v39 annotations, and pre-computed txrevise annotations.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nwget ftp://ftp.ebi.ac.uk/pub/databases/spot/eQTL/references/rnaseq_complete_reference_290322.tar.gz\ntar -xzvf rnaseq_complete_reference_290322.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading Test VCF File for RNA-seq Genotype Concordance Check\nDESCRIPTION: Command to download a VCF file for the GEUVADIS_GBR20 test dataset from Zenodo. This file is used to check genotype concordance with RNA-seq data using QTLtools MBV.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6391156/files/GEUVADIS_GBR20.vcf.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading GEUVADIS Gene Count Matrix\nDESCRIPTION: Command to download a pre-computed gene count matrix for the GEUVADIS_GBR20 dataset from Zenodo, to be used for gene expression normalization only.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6631875/files/GEUVADIS_GBR20_gene_counts.tsv.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Dataset Genotypes for QTL Analysis\nDESCRIPTION: Commands to download and extract the CEDAR dataset genotypes from Zenodo. These raw genotypes serve as input for the genimpute workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6171348/files/CEDAR_HumanOmniExpress-12v1.tar.gz\ntar -xzvf CEDAR_HumanOmniExpress-12v1.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Study File\nDESCRIPTION: Command to download the study file for the CEDAR dataset from GitHub, which maps all input files to the correct workflow parameters.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_27\n\nLANGUAGE: bash\nCODE:\n```\nwget https://raw.githubusercontent.com/eQTL-Catalogue/eQTL-Catalogue-resources/master/tutorials/CEDAR_study_file.tsv\n```\n\n----------------------------------------\n\nTITLE: Creating Data Directory for CEDAR Dataset\nDESCRIPTION: Commands to create and navigate to a data directory for storing input files required for running the QTLMAP workflow on the CEDAR dataset.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_22\n\nLANGUAGE: bash\nCODE:\n```\nmkdir data\ncd data\n```\n\n----------------------------------------\n\nTITLE: Loading CSV Data Matrix from eQTL Catalogue\nDESCRIPTION: A tab-separated data matrix containing sample measurements across 16 parameters. Each row represents a different tissue/condition combination from various studies, with the first column containing sample identifiers and subsequent columns containing numerical measurements.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/manuscript/figures/factor_heatmap/K30_a1900_l11100_Run4.txt#2025-04-22_snippet_0\n\nLANGUAGE: CSV\nCODE:\n```\n\"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\" \"10\" \"11\" \"12\" \"13\" \"14\" \"15\" \"16\"\n\"Alasoo_2018.macrophage_IFNg\" 5.08018482029746 0 0 0 0 0 0 0 0 0 11.3308928373498 0 0 0 0 0\n\"Alasoo_2018.macrophage_IFNg+Salmonella\" 4.42736223065446 0 0 0 0 0 1.1896285936153 0 0 0 9.65417416791487 0 0 0 0 0\n```\n\n----------------------------------------\n\nTITLE: Downloading CEDAR Sample Metadata\nDESCRIPTION: Command to download the sample metadata file for the CEDAR dataset from Zenodo, required for QTL analysis.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_25\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6171348/files/CEDAR_sample_metadata.tsv\n```\n\n----------------------------------------\n\nTITLE: Downloading GEUVADIS Sample Metadata from Zenodo\nDESCRIPTION: Command to download the GEUVADIS_GBR20 sample metadata file from Zenodo repository, which is required as input for the eQTL-Catalogue workflows.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/workflow_execution.md#2025-04-22_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nwget https://zenodo.org/record/6391156/files/GEUVADIS_GBR20_sample_metadata.tsv\n```\n\n----------------------------------------\n\nTITLE: Creating a File of Samples to Remove\nDESCRIPTION: This example shows the format for creating a text file containing sample IDs that need to be removed due to high missingness (>5%).\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncat remove_list.txt\n931 932\n919 920\n913 914\n925 926\n844 845\n```\n\n----------------------------------------\n\nTITLE: Visualizing Colocalisation Posterior Probabilities with ggplot2 in R\nDESCRIPTION: This code creates a histogram of the posterior probabilities of colocalisation (PP.H4.abf) using ggplot2, visually confirming that only one cell type shows strong evidence of colocalisation.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/tabix_use_case.md#2025-04-22_snippet_9\n\nLANGUAGE: r\nCODE:\n```\nggplot(coloc_df, aes(x = PP.H4.abf)) + geom_histogram()\n```\n\n----------------------------------------\n\nTITLE: Verifying Corrected Chromosome Names\nDESCRIPTION: This command checks that the X chromosome has been properly renamed from numerical codes (23, 25) to 'X' after merging PAR and non-PAR regions.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncut -f 1 merged_x.bim | uniq -c\n```\n\n----------------------------------------\n\nTITLE: Sorting Missing Genotype Data to Find Problematic Samples\nDESCRIPTION: This command sorts the output of the missing genotype check by the percentage of missingness (6th column) to identify samples with high levels of missing data.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsort -k6n plink.imiss | tail -n 10\n```\n\n----------------------------------------\n\nTITLE: Merging PAR and Non-PAR X Chromosome Regions\nDESCRIPTION: This command merges the Pseudo-Autosomal Regions (PAR) and non-PAR regions of the X chromosome and renames them to 'X', as required by the eQTL-Catalogue/genimpute workflow.\nSOURCE: https://github.com/eqtl-catalogue/eqtl-catalogue-resources/blob/master/tutorials/plink_check.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nplink -bfile fetal_geno --merge-x --make-bed --output-chr MT --out merged_x\n```"
  }
]