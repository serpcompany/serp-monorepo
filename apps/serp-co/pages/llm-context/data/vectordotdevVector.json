[
  {
    "owner": "vectordotdev",
    "repo": "vector",
    "content": "TITLE: Parsing JSON with VRL in CoffeeScript\nDESCRIPTION: This VRL program parses a JSON string from the `message` field of an event, extracts relevant fields, manipulates timestamps, and converts the message to lowercase. It demonstrates error handling for timestamp parsing using `parse_timestamp` and `to_unix_timestamp`. The example assumes a `message` field containing a JSON string with `status`, `timestamp`, `message`, and `username` fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/_index.md#_snippet_1\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n# Parse the raw string into a JSON object, this way we can manipulate fields.\n. = parse_json!(string!(.message))\n\n# At this point `.` is the following:\n#{{\n#  \"message\": \"SUCCESS\",\n#  \"status\": 200,\n#  \"timestamp\": \"2021-03-01T19:19:24.646170Z\",\n#  \"username\": \"ub40fan4life\"\n#}}\n\n# Attempt to parse the timestamp that was in the original message.\n# Note that `.timestamp` can be `null` if it wasn't present.\nparsed_timestamp, err = parse_timestamp(.timestamp, format: \"%Y-%m-%dT%H:%M:%S.%fZ\")\n\n# Check if the conversion was successful. Note here that all errors must be handled, more on that later.\nif err == null {\n   # Note that the `to_unix_timestamp` expects a `timestamp` argument.\n   # The following will compile because `parse_timestamp` returns a `timestamp`.\n  .timestamp = to_unix_timestamp(parsed_timestamp)\n} else {\n  # Conversion failed, in this case use the current time.\n  .timestamp = to_unix_timestamp(now())\n}\n\n# Convert back to timestamp for this tutorial.\n.timestamp_str = from_unix_timestamp!(.timestamp)\n\n# Remove the `username` field from the final target.\ndel(.username)\n\n# Convert the `message` to lowercase.\n.message = downcase(string!(.message))\n```\n\n----------------------------------------\n\nTITLE: Basic Vector Configuration (YAML)\nDESCRIPTION: This YAML configuration file defines a simple Vector topology with a stdin source and a console sink. It receives data from stdin and prints it to stdout as plain text, demonstrating basic data flow within Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  in:\n    type: \"stdin\"\n\nsinks:\n  out:\n    inputs:\n      - \"in\"\n    type: \"console\"\n    encoding:\n      codec: \"text\"\n```\n\n----------------------------------------\n\nTITLE: Defining Demo Log Sources in Vector\nDESCRIPTION: This snippet defines two demo log sources in Vector, `source_0` and `source_1`. Each source generates logs with specified key-value pairs at a defined interval. These sources emulate incoming events for testing and development purposes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  source_0:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"a\", \"property\": \"foo\" }'\n      - '{ \"key\": \"b\", \"property\": \"bar\" }'\n    interval: 10\n\n  source_1:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"c\", \"property\": \"some\" }'\n      - '{ \"key\": \"d\", \"property\": \"another\" }'\n    interval: 10\n```\n\n----------------------------------------\n\nTITLE: Configuring Kubernetes Log Source and Elasticsearch Sink in Vector\nDESCRIPTION: This TOML configuration snippet defines a Vector pipeline that collects logs from all Kubernetes nodes and sends them to Elasticsearch. It configures the `kubernetes_logs` source and `elasticsearch` sink, specifying the Elasticsearch host and index pattern. This configuration requires Vector to be installed and have access to the Kubernetes API and the Elasticsearch cluster.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/kubernetes-integration.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.k8s_all]\ntype = \"kubernetes_logs\"\n\n[sinks.es_out]\ntype = \"elasticsearch\"\ninputs = [\"k8s_all\"]\nhost = \"http://your-elasticsearch-cluster:9200\"\nindex = \"vector-k8s-%F\"\n```\n\n----------------------------------------\n\nTITLE: Complete Lua Transform Configuration\nDESCRIPTION: This TOML configuration shows the complete `lua` transform, including loading the CSV module, defining the column names based on PostgreSQL's CSV log format, and implementing the parsing logic within the `hooks.process` section. This allows the Vector pipeline to parse the CSV log messages into structured events based on column names.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_6\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.lua]\n  inputs = [\"file\"]\n  type = \"lua\"\n  version = \"2\"\n  source = \"\"\"\n    csv = require(\"csv\") -- load external module for parsing CSV\n    column_names = {  -- a sequence containing CSV column names\n      \"log_time\",\n      \"user_name\",\n      \"database_name\",\n      \"process_id\",\n      \"connection_from\",\n      \"session_id\",\n      \"session_line_num\",\n      \"command_tag\",\n      \"session_start_time\",\n      \"virtual_transaction_id\",\n      \"transaction_id\",\n      \"error_severity\",\n      \"sql_state_code\",\n      \"message\",\n      \"detail\",\n      \"hint\",\n      \"internal_query\",\n      \"internal_query_pos\",\n      \"context\",\n      \"query\",\n      \"query_pos\",\n      \"location\",\n      \"application_name\",\n      -- available only in postgres > 13, to remove for postgres <= 13\n      \"backend_type\",\n      \"leader_pid\",\n      \"query_id\"\n    }\n  \"\"\"\n  hooks.process = \"\"\"\n    function (event, emit)\n      fields = csv.openstring(event.log.message):lines()() -- parse the `message` field\n      event.log.message = nil -- drop the `message` field\n\n      for column, column_name in ipairs(column_names) do -- iterate over column names\n        value = fields[column] -- get field value\n        event.log[column_name] = value -- set the corresponding field in the event\n      end\n\n      emit(event) -- emit the transformed event\n    end\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: VRL: Handling Errors with `err` Variable\nDESCRIPTION: This VRL snippet demonstrates how to handle potential errors from the `parse_common_log` function. If an error occurs (e.g., the log message is malformed), it sets a `.malformed` field to `true`, logs an error message, and avoids further processing.  If parsing succeeds it processes the rest of the code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_11\n\nLANGUAGE: coffee\nCODE:\n```\n., err = parse_common_log(.log)\nif err != null {\n  .malformed = true\n  log(\"Failed to parse common-log: \" + err, level: \"error\")\n} else {\n  .total_bytes = del(.size)\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Remap Transform in Vector\nDESCRIPTION: This snippet configures a `remap` transform in Vector named `transform_0`. It uses the Vector Remap Language (VRL) to parse the JSON message and add a `group` field based on the value of the `key` field.  The transform takes input from the source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  transform_0:\n    type: remap\n    inputs:\n      - source_*\n    source: |\n      . = parse_json!(.message)\n      if .key == \"a\" {\n        .group = 0\n      } else {\n        .group = 1\n      }\n```\n\n----------------------------------------\n\nTITLE: Vector Remap Transform Config (TOML)\nDESCRIPTION: This TOML configuration defines a `remap` transform in Vector to parse the AWS CloudWatch Logs subscription message, unnest the log events, and parse the JSON message within each log event. It uses the parse_aws_cloudwatch_log_subscription_message, unnest, map_values, and parse_json functions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.parse]\n  type = \"remap\"\n  inputs = [\"firehose\"]\n  drop_on_error = false\n  source = '''\n    parsed = parse_aws_cloudwatch_log_subscription_message!(.message)\n    . = unnest(parsed.log_events)\n    . = map_values(.) -> |value| {\n       event = del(value.log_events)\n       value |= event\n       message = del(.message)\n       . |= object!(parse_json!(message))\n    }\n  '''\n```\n\n----------------------------------------\n\nTITLE: Configuring the host_metrics source in TOML\nDESCRIPTION: This TOML configuration block demonstrates how to configure the `host_metrics` source within Vector.  It showcases the required `type` field, optional `collectors` array to specify which metrics to collect, and device/mountpoint filtering options.  It also shows the `scrape_interval_secs` and `namespace` options for customizing the collection frequency and metric namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-26-3191-host-metrics.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"host_metrics\" # required\n  collectors = [ \"all\"] # optional, defaults collecting all metrics.\n  filesystem.mountpoints = [ \"*\" ] # optional, defaults to all mountpoints.\n  disk.devices = [ \"*\" ] # optional, defaults to all to disk devices.\n  network.devices = [ \"*\" ] # optional, defaults to all to network devices.\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"host\" # optional, default is \"host\", namespace to put metrics under\n```\n\n----------------------------------------\n\nTITLE: Remap transform with VRL script for data modification\nDESCRIPTION: This YAML configuration snippet updates the remap transform with a VRL script to perform several modifications. It converts the timestamp to a Unix timestamp, removes the facility and procid fields, replaces the msgid field with a UUID, and sets a critical field based on the presence of a specific phrase in the log message. The VRL script demonstrates error handling and conditional logic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/transformation.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  modify:\n    type: remap\n    inputs:\n      - logs\n    source: |\n      . = parse_syslog!(.message)\n\n      # Convert the timestamp to a Unix timestamp, aborting on error\n      .timestamp = to_unix_timestamp!(.timestamp)\n\n      # Remove the \"facility\" and \"procid\" fields\n      del(.facility)\n      del(.procid)\n\n      # Replace the \"msgid\" field with a unique ID\n      .msgid = uuid_v4()\n\n      # If the log message contains the phrase \"Great Scott!\", set the new field\n      # \"critical\" to true, otherwise set it to false. If the \"contains\" function\n      # errors, log the error (instead of aborting the script, as above).\n      if (is_critical = contains(.message, \"Great Scott!\"); is_critical) {\n        log(\"It contains 'Great Scott!'\", level: \"info\")\n      }\n\n      .critical = is_critical\n```\n\n----------------------------------------\n\nTITLE: Configuring Console Sink - YAML\nDESCRIPTION: This configuration sets up a `console` sink to output data in a readable JSON format.  It takes inputs from `my_source_0` and `my_source_1` and formats the output using a pretty-printed JSON codec.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nmy_console_sink:\n  type: console\n  inputs:\n    - my_source_0\n    - my_source_1\n  encoding:\n    codec: json\n    json:\n      pretty: true\n```\n\n----------------------------------------\n\nTITLE: Remap codec example in TOML\nDESCRIPTION: This example demonstrates how to use a `remap` codec to transform data within a source, using VRL functions to parse JSON and Base64 encoded data. The snippet shows how flexible data transformation can be expressed directly in the source config.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[decoding]\ncodec = \"remap\"\nsrc = \"\"\"\n. = parse_json!(.)\n.nested = parse_json!(.nested)\n.encoded = parse_base64!(.encoded)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Host Metrics Source in TOML\nDESCRIPTION: This snippet shows how to configure the host_metrics source in Vector using TOML. It defines the source type and connects it to a prometheus sink. Other metrics such as apache_metrics, mongodb_metrics, or internal_metrics can be configured similarly.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-10-27-metrics-integrations.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.host_metrics]\ntype = \"host_metrics\" # or apache_metrics, mongodb_metrics, or internal_metrics\n\n# Then connect them to a sink:\n[sinks.prometheus]\ntype = \"prometheus\"\ninputs = [\"host_metrics\"]\n```\n\n----------------------------------------\n\nTITLE: Complete Unit Test Configuration (TOML)\nDESCRIPTION: This configuration demonstrates a complete unit test for a `add_metadata` transform, including source, transform definition, test inputs, and expected outputs with VRL assertions to validate the transform's behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[sources.all_container_services]\ntype = \"docker_logs\"\ndocker_host = \"http://localhost:2375\"\ninclude_images = [\"web_frontend\", \"web_backend\", \"auth_service\"]\n\n# The transform being tested is a Vector Remap Language (VRL) transform that\n# adds two fields to each incoming log event: a timestamp and a unique ID\n[transforms.add_metadata]\ntype = \"remap\"\ninputs = [\"all_container_services\"]\nsource = '''\n.timestamp = now()\n.id = uuid_v4()\n'''\n\n# Here we begin configuring our test suite\n[[tests]]\nname = \"Test for the add_metadata transform\"\n\n# The inputs for the test\n[[tests.inputs]]\ninsert_at = \"add_metadata\" # The transform into which the testing event is inserted\ntype = \"log\"               # The event type (either log or metric)\n\n# The test log event that is passed to the `add_metadata` transform\n[tests.inputs.log_fields]\nmessage = \"successful transaction\"\ncode = 200\n\n# The expected outputs of the test\n[[tests.outputs]]\nextract_from = \"add_metadata\" # The transform from which the resulting event is extracted\n\n# The declaration of what we expect\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert!(is_timestamp(.timestamp))\nassert!(is_string(.id))\nassert_eq!(.message, \"successful transaction\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Logging (Flag)\nDESCRIPTION: This command enables debug logging for Vector by using the `--verbose` flag.  It then runs Vector with the specified configuration file. This will increase the verbosity of the logs. Requires the `vector` binary to be in the system's PATH and access to the configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nvector --verbose --config=/etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Delivering Vector Metrics to Prometheus\nDESCRIPTION: This configuration shows how to deliver Vector's metrics to a Prometheus remote write endpoint using the `internal_metrics` source and the `prometheus_remote_write` sink. It defines a source named `vector_metrics` of type `internal_metrics` and a sink named `prometheus` that sends the metrics to the specified endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/monitoring.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sources.vector_metrics]\ntype = \"internal_metrics\"\n\n[sinks.prometheus]\ntype = [\"prometheus_remote_write\"]\nendpoint = [\"https://localhost:8087/\"]\ninputs = [\"vector_metrics\"]\n```\n\n----------------------------------------\n\nTITLE: Full Vector Configuration with Internal Metrics\nDESCRIPTION: This snippet shows a complete Vector configuration file including API settings, demo log sources, internal metrics source, a remapping transform, and both an HTTP and a console sink.  The console sink is configured to output pretty-printed JSON for the internal metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\n# version 2\napi:\n  enabled: true\n\nsources:\n  source_0:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"a\", \"property\": \"foo\" }'\n      - '{ \"key\": \"b\", \"property\": \"bar\" }'\n    interval: 10\n\n  source_1:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"c\", \"property\": \"some\" }'\n      - '{ \"key\": \"d\", \"property\": \"another\" }'\n    interval: 10\n\n  internal_metrics:\n    type: internal_metrics\n    scrape_interval_secs: 10\n\ntransforms:\n  transform_0:\n    type: remap\n    inputs:\n      - source_*\n    source: |\n      . = parse_json!(.message)\n      if .key == \"a\" {\n        .group = 0\n      } else {\n        .group = 1\n      }\n\nsinks:\n  sink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://localhost:8000/logs\n    encoding:\n      codec: json\n\n  sink_1:\n    type: console\n    inputs:\n      - internal_metrics\n    encoding:\n      codec: json\n      json:\n        pretty: true\n```\n\n----------------------------------------\n\nTITLE: Assigning Metric Tag Values in CoffeeScript\nDESCRIPTION: This code snippet demonstrates how to assign different types of values to metric tags using CoffeeScript within the Vector environment. It shows assigning a single string value, creating a bare tag with a null value, and creating a complex tag with an array of values (including null). This snippet is relevant for `lua` and `remap` components when using the `metric_tag_values` configuration option.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-12-22-enhanced-metric-tags.md#_snippet_0\n\nLANGUAGE: coffeescript\nCODE:\n```\n.tags.host = \"localhost\" # Assign a single string value\n.tags.bare = null # Create a single-valued bare tag\n.tags.complex = [\"remotehost\", null, \"otherhost\"] # Creates three tag values\n```\n\n----------------------------------------\n\nTITLE: Overriding Default Log Schema Fields in TOML\nDESCRIPTION: This TOML configuration overrides the default field names in Vector's log schema.  `host_key`, `message_key`, and `timestamp_key` are redefined to use custom field names for incoming data. This affects all sources, sinks, and transforms unless overridden at a more granular level.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[log_schema]\nhost_key = \"instance\" # default \"host\"\nmessage_key = \"info\" # default \"message\"\ntimestamp_key = \"datetime\" # default \"timestamp\"\n\n# Sources, transforms, and sinks...\n```\n\n----------------------------------------\n\nTITLE: Basic Vector Configuration\nDESCRIPTION: This YAML configuration file defines a simple Vector pipeline that reads input from stdin and outputs it to the console. It demonstrates the basic structure of a Vector configuration, including sources and sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  in:\n    type: stdin\n\nsinks:\n  out:\n    inputs: [\"in\"]\n    type: console\n    encoding:\n      codec: text\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example (YAML)\nDESCRIPTION: This YAML snippet shows a comprehensive Vector configuration. It configures global options, an Apache log source, a Remap Language transform, a data sampler, an Elasticsearch sink, and an AWS S3 archive sink. It utilizes features like globbing for file inclusion, parsing with the Remap Language, sampling to reduce costs, and configuring Elasticsearch indices and S3 bucket details.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Set global options\ndata_dir: \"/var/lib/vector\"\n\n# Vector's API (disabled by default)\n# Enable and try it out with the `vector top` command\n# NOTE: this is _enabled_ for helm chart deployments, see: https://github.com/vectordotdev/helm-charts/blob/develop/charts/vector/examples/datadog-values.yaml#L78-L81\napi:\n  enabled: false\n# address = \"127.0.0.1:8686\"\n\n# Ingest data by tailing one or more files\nsources:\n  apache_logs:\n    type: \"file\"\n    include:\n      - \"/var/log/apache2/*.log\" # supports globbing\n    ignore_older_secs: 86400     # 1 day\n\n# Structure and parse via Vector's Remap Language\ntransforms:\n  apache_parser:\n    inputs:\n      - \"apache_logs\"\n    type: \"remap\"\n    source: \". = parse_apache_log(.message)\"\n\n  # Sample the data to save on cost\n  apache_sampler:\n    inputs:\n      - \"apache_parser\"\n    type: \"sample\"\n    rate: 2 # only keep 50% (1/`rate`)\n\n# Send structured data to a short-term storage\nsinks:\n  es_cluster:\n    inputs:\n      - \"apache_sampler\"       # only take sampled data\n    type: \"elasticsearch\"\n    endpoints:\n      - \"http://79.12.221.222:9200\"\n    bulk:\n      index: \"vector-%Y-%m-%d\" # daily indices\n\n  # Send structured data to a cost-effective long-term storage\n  s3_archives:\n    inputs:\n      - \"apache_parser\" # don't sample for S3\n    type: \"aws_s3\"\n    region: \"us-east-1\"\n    bucket: \"my-log-archives\"\n    key_prefix: \"date=%Y-%m-%d\"   # daily partitions, hive friendly format\n    compression: \"gzip\"           # compress final objects\n    framing:\n      method: \"newline_delimited\" # new line delimited...\n    encoding:\n      codec: \"json\"               # ...JSON\n    batch:\n      max_bytes: 10000000         # 10mb uncompressed\n```\n\n----------------------------------------\n\nTITLE: ClickHouse Sink Configuration with Adaptive Concurrency in Vector (TOML)\nDESCRIPTION: This TOML configuration snippet demonstrates how to enable Adaptive Request Concurrency (ARC) for a ClickHouse sink in Vector. By setting `request.concurrency` to `adaptive`, Vector will automatically manage the concurrency based on the performance of the downstream ClickHouse service. The inputs are defined as log streams.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/adaptive-request-concurrency.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.clickhouse_internal]\n type = \"clickhouse\"\n inputs = [\"log_stream_1\", \"log_stream_2\"]\n host = \"http://clickhouse-prod:8123\"\n table = \"prod-log-data\"\n request.concurrency = \"adaptive\"\n```\n\n----------------------------------------\n\nTITLE: Coercing Data Types in TOML\nDESCRIPTION: This TOML configuration uses a `remap` transform to coerce data types. It converts the `count` field to an integer and the `date` field to a timestamp using the specified format. This is useful when services provide data with incorrect types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_11\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.correct_source_types]\n  type = \"remap\"\n  inputs = [\"source0\"]\n  source = '''\n    .count = int(.count)\n    .date = timestamp(.date, \"%F\")\n  '''\n```\n\n----------------------------------------\n\nTITLE: Pipe 'Hello world!' to Vector (Shell)\nDESCRIPTION: This command pipes the string 'Hello world!' to the Vector process, using the configuration file defined earlier. It demonstrates how to send data to Vector via stdin and observe the output on stdout.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\necho 'Hello world!' | vector\n```\n\n----------------------------------------\n\nTITLE: Complete Vector TOML Configuration\nDESCRIPTION: A complete Vector configuration example showing a syslog source, a remap transform, and a console sink.  This demonstrates a full pipeline setup.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[sources.syslog]\ntype = \"syslog\"\naddress = \"0.0.0.0:514\"\nmax_length = 42000\nmode = \"tcp\"\n\n[transforms.change_fields]\ntype = \"remap\"\ninputs = [\"syslog\"]\nsource = \"\"\"\n.new_field = \\\"some value\\\"\"\n\n[sinks.stdout]\ntype = \"console\"\ninputs = [\"change_fields\"]\ntarget = \"stdout\"\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: GDPR Compliance Pipeline Configuration in TOML\nDESCRIPTION: This TOML configuration demonstrates a Vector pipeline designed to filter data based on GDPR compliance. It filters EU user data based on the `gdpr` field, strips the `email` field from EU user logs, and outputs the results to the console. Key components are a stdin source, remap transform to parse JSON, filter transforms for GDPR and non-GDPR data, and a console sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_6\n\nLANGUAGE: TOML\nCODE:\n```\ndata_dir = \"./data\"\ndns_servers = []\n\n[sources.application]\nmax_length = 102400\ntype = \"stdin\"\n\n[transforms.parse]\ninputs = [\"application\"]\ntype = \"remap\"\nsource = '''\n. = parse_json!(.message)\n'''\n\n[transforms.not_gdpr]\ntype = \"filter\"\ninputs = [\"parse\"]\ncondition = \".gdpr == false\"\n\n[transforms.gdpr_to_strip]\ntype = \"filter\"\ninputs = [\"parse\"]\ncondition = \".gdpr == true\"\n\n[transforms.gdpr_stripped]\ntype = \"remap\"\ninputs = [\"gdpr_to_strip\"]\nsource = \"del(.email)\"\n\n[sinks.console]\nhealthcheck = true\ninputs = [\"not_gdpr\", \"gdpr_stripped\"]\ntype = \"console\"\nencoding.codec = \"json\"\n[sinks.console.buffer]\ntype = \"memory\"\nmax_events = 500\nwhen_full = \"block\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Disk-Based Buffers for At-Least-Once Delivery in Vector\nDESCRIPTION: This code snippet demonstrates how to configure disk-based buffers within a Vector sink to achieve at-least-once delivery. The configuration specifies the buffer type as 'disk', sets the behavior when the buffer is full to 'block', and defines the maximum buffer size. Configuring disk buffers is essential for ensuring data persistence between restarts.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/about/under-the-hood/guarantees.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my_sink_id]\n  [sinks.my_sink_id.buffer]\n    type = \"disk\"\n    when_full = \"block\"\n    max_size = 104900000 # 100MiB\n```\n\n----------------------------------------\n\nTITLE: Handling VRL Type Errors with String Conversion\nDESCRIPTION: This snippet demonstrates how to handle VRL type errors by forcing a value to be a string using the `string` function and providing a default value if the conversion fails. The `??` operator provides a fallback if the conversion results in null.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: coffeescript\nCODE:\n```\nmsg = to_string(msg) ?? \"default\"\nsplit(msg, \" \")\n```\n\n----------------------------------------\n\nTITLE: Defining an HTTP Sink in Vector\nDESCRIPTION: This snippet defines an HTTP sink named `sink_0` in Vector. It sends data from the `transform_0` transform to a specified URI, encoding the data as JSON. This configuration enables Vector to forward processed data to an HTTP endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\nsink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://localhost:8000/logs\n    encoding:\n      codec: json\n```\n\n----------------------------------------\n\nTITLE: HTTP Source with Comma Delimited Framing in Vector\nDESCRIPTION: This code snippet shows how to configure an `http` source in Vector to handle messages delimited by commas instead of newlines. The `framing.method = \"character_delimited\"` and `framing.character_delimited.delimiter = \",\"` settings instruct Vector to parse each comma-delimited element as a new message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-10-06-source-codecs.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.http]\ntype = \"http\"\naddress = \"0.0.0.0:8080\"\nframing.method = \"character_delimited\"\nframing.character_delimited.delimiter = \",\"\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Vector Configs (Bash)\nDESCRIPTION: Demonstrates different ways to run multiple Vector configuration files together, creating a larger topology.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# These three examples run the same two configs together:\nvector -c ./configs/foo.toml -c ./configs/bar.toml\nvector -c ./configs/*.toml\nvector -c ./configs/foo.toml ./configs/bar.toml\n```\n\n----------------------------------------\n\nTITLE: Installing Vector with RPM\nDESCRIPTION: This command installs Vector using the RPM package manager. It downloads the RPM package from the specified URL and installs it. The `{arch}` placeholder needs to be replaced with the appropriate architecture (x86_64, aarch64, or armv7hl).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/rpm.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo rpm -i https://yum.vector.dev/stable/vector-0/{arch}/vector-{{< version >}}-1.{arch}.rpm\n```\n\n----------------------------------------\n\nTITLE: Vector Remap Transform TOML\nDESCRIPTION: This TOML snippet defines a Vector `remap` transform named `enrich_iot_logs`. It parses the `.message` field as JSON, deletes the `.code` field and stores it in a local variable, then uses `get_enrichment_table_record` to look up a row in the `iot_remap` enrichment table based on the `code` value. Finally, it updates the `.message` field with the corresponding message from the CSV, effectively enriching the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-csv-enrichment.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.enrich_iot_logs]\ntype = \"remap\"\ninputs = [\"vector_agents\"]\nsource = '''\n. = parse_json!(.message)\n\ncode = del(.code)\n\nrow = get_enrichment_table_record!(\"iot_remap\", { \"code\":  code })\n.message = row.message\n'''\n```\n\n----------------------------------------\n\nTITLE: Configure Vector with demo_logs, remap, and console\nDESCRIPTION: This configuration sets up a Vector topology with a demo_logs source generating Syslog messages, a remap transform parsing the messages using VRL, and a console sink outputting the results to stdout. The remap transform uses VRL to parse the Syslog message field. The configuration is defined in YAML.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/transformation.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  logs:\n    type: demo_logs\n    format: syslog\n    interval: 0.1\n\ntransforms:\n  modify:\n    type: remap\n    inputs:\n      - logs\n    source: |\n      # Parse Syslog input. The \"!\" means that the script should abort on error.\n      . = parse_syslog!(.message)\n\nsinks:\n  out:\n    type: console\n    inputs:\n      - modify\n    encoding:\n      codec: json\n```\n\n----------------------------------------\n\nTITLE: Using Vector Logs with remap transform and ClickHouse sink\nDESCRIPTION: This configuration demonstrates how to transform Vector's logs using the `remap` transform and Vector Remap Language (VRL) before storing them in ClickHouse. It defines a `remap` transform to reformat the timestamp to Unix time and a `clickhouse` sink to store the transformed logs in a table named `vector-log-data`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/monitoring.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.vector_logs]\ntype = \"internal_logs\"\n\n[transforms.modify]\ntype = \"remap\"\ninputs = [\"vector_logs\"]\n\n# Reformat the timestamp to Unix time\nsource = '''\n  .timestamp = to_unix_timestamp!(to_timestamp!(.timestamp))\n'''\n\n[sinks.database]\ntype = \"clickhouse\"\ninputs = [\"modify\"]\nhost = \"http://localhost:8123\"\ntable = \"vector-log-data\"\n```\n\n----------------------------------------\n\nTITLE: Example of modified log data in JSON format\nDESCRIPTION: This JSON represents the modified log data after applying the VRL script to the syslog messages. It includes a Unix timestamp, a UUID for msgid, a boolean value for the `critical` field, while the `facility` and `procid` fields are removed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/transformation.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"appname\": \"authsvc\",\n  \"hostname\": \"acmecorp.biz\",\n  \"message\": \"Great Scott! We're never gonna reach 88 mph with the flux capacitor in its current state!\",\n  \"msgid\": \"4e4437b6-13e8-43b3-b51e-c37bd46de490\",\n  \"severity\": \"notice\",\n  \"timestamp\": 1611080200,\n  \"critical\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: Generating Multiple Events (TOML)\nDESCRIPTION: This example shows how to configure a `remap` transform to generate multiple log events from a single input.  It assigns an array of objects to the root (`.`), causing the `remap` transform to create a log event for each element in the array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\ninputs = []\nsource = \"\"\"\n. = [{\"message\": \"hello\"}, {\"message\": \"world\"}]\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Vector TOML Config with Unit Test\nDESCRIPTION: Demonstrates adding a unit test to a Vector configuration to inspect the behavior of a transform. The test includes an input value and extracts the output from the transform for inspection.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[[tests]]\n  name = \"check_simple_log\"\n\n  [[tests.inputs]]\n    insert_at = \"foo\"\n    type = \"raw\"\n    value = \"2019-11-28T12:00:00+00:00 info Sorry, I'm busy this week Cecil\"\n\n  [[tests.outputs]]\n    extract_from = \"foo\"\n```\n\n----------------------------------------\n\nTITLE: Configure Lua transform to merge CSV logs\nDESCRIPTION: This TOML configuration sets up a Lua transform in Vector to merge multi-line CSV logs. It loads the `lua-csv` module, defines the expected number of columns, and sets the line separator. The `process` hook contains the Lua code to parse, merge, and emit CSV log lines.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/merge-multiline-logs-with-lua.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  inputs = []\n  type = \"lua\"\n  version = \"2\"\n  source = \"\"\"\n    csv = require(\"csv\") -- load the `lua-csv` module\n    expected_columns = 23 -- expected number of columns in incoming CSV lines\n    line_separator = \"\\\\r\\\\n\" -- note the double escaping required by the TOML format\n  \"\"\"\n  hooks.process = \"\"\"\n    function (event, emit)\n      merged_event = merge(event)\n      if merged_event == nil then -- a global variable containing the merged event\n        merged_event = event -- if it is empty, set it to the current event\n      else -- otherwise, concatenate the line in the stored merged event\n           -- with the next line\n        merged_event.log.message = merged_event.log.message ..\n                                  line_separator .. event.log.message\n      end\n\n      fields = csv.openstring(event.log.message):lines()() -- parse CSV\n      if #fields < expected_columns then\n        return -- not all fields are present in the merged event yet\n      end\n\n      -- do something with the array of the parsed fields\n      merged_event.log.csv_fields = fields -- for example, just store them in an\n                                           -- array field\n\n      emit(merged_event) -- emit the resulting event\n      merged_event = nil -- clear the merged event\n    end\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Multiple VRL Assertions Example (TOML)\nDESCRIPTION: This snippet demonstrates breaking a Vector unit test into multiple VRL `assert` statements to verify various properties of a log event, including the existence, type, and value of specific fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\nsource = '''\nassert!(exists(.message), \"no message field provided\")\nassert!(!is_nullish(.message), \"message field is an empty string\")\nassert!(is_string(.message), \"message field has as unexpected type\")\nassert_eq!(.message, \"success\", \"message field had an unexpected value\")\nassert!(exists(.timestamp), \"no timestamp provided\")\nassert!(is_timestamp(.timestamp), \"timestamp is invalid\")\nassert!(!exists(.other), \"extraneous other field present\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Advanced Vector Configuration with Syslog\nDESCRIPTION: This YAML configuration file demonstrates a more advanced Vector pipeline that generates Syslog data, transforms it using VRL to parse the Syslog messages, and then outputs the parsed data to the console in JSON format. It uses the `demo_logs` source, the `remap` transform, and the `console` sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  generate_syslog:\n    type: demo_logs\n    format: syslog\n    count: 100\n\ntransforms:\n  remap_syslog:\n    inputs: [generate_syslog]\n    type: remap\n    source: |\n      structured = parse_syslog!(.message)\n      . = merge(., structured)\n\nsinks:\n  emit_syslog:\n    inputs: [remap_syslog]\n    type: console\n    encoding:\n      codec: json\n```\n\n----------------------------------------\n\nTITLE: Complex Filtering Condition with VRL in CoffeeScript\nDESCRIPTION: This VRL program specifies a complex filtering condition. It filters out events where the `severity` field is \"info\", the `status_code` field is less than 400, and the `host` field exists. It demonstrates the use of logical AND (`&&`) and the `exists` function for more complex filtering scenarios.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/_index.md#_snippet_4\n\nLANGUAGE: CoffeeScript\nCODE:\n```\ncondition = '.severity != \"info\" && .status_code < 400 && exists(.host)'\n```\n\n----------------------------------------\n\nTITLE: Complete Vector Configuration for Metrics and Logs\nDESCRIPTION: This YAML configuration file shows a complete Vector setup, including demo log sources, an internal metrics source, a transform, and sinks for HTTP, console, and Prometheus exporter.  It includes parsing JSON logs, remapping based on a key, sending logs to an HTTP endpoint, outputting internal metrics to the console, and exposing internal metrics via a Prometheus exporter.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_31\n\nLANGUAGE: yaml\nCODE:\n```\n# Vector config - version 4\napi:\n  enabled: true\n\nsources:\n  source_0:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"a\", \"property\": \"foo\" }'\n      - '{ \"key\": \"b\", \"property\": \"bar\" }'\n    interval: 10\n\n  source_1:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"c\", \"property\": \"some\" }'\n      - '{ \"key\": \"d\", \"property\": \"another\" }'\n    interval: 10\n\n  internal_metrics:\n    type: internal_metrics\n    scrape_interval_secs: 10\n\ntransforms:\n  transform_0:\n    type: remap\n    inputs:\n      - source_*\n    source: |\n      . = parse_json!(.message)\n      if .key == \"a\" {\n        .group = 0\n      } else {\n        .group = 1\n      }\n\nsinks:\n  sink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://host.docker.internal:8000/logs\n    encoding:\n      codec: json\n      json:\n        pretty: true\n    compression: zlib\n    batch:\n      max_events: 4\n\n  sink_1:\n    type: console\n    inputs:\n      - internal_metrics\n    encoding:\n      codec: json\n      json:\n        pretty: true\n\n  sink_2:\n    type: prometheus_exporter\n    inputs:\n      - internal_metrics\n    address: 0.0.0.0:9598\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Removing Fields with del Function in Text\nDESCRIPTION: This snippet demonstrates how to remove a field from the event using the `del` function. This function takes the field path as an argument and removes the corresponding field from the event being transformed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\ndel(.foo)\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example (TOML)\nDESCRIPTION: This TOML snippet demonstrates a Vector configuration file. It defines global options, an Apache log source with file tailing and globbing, a Remap Language transform for parsing logs, a data sampler, and Elasticsearch and S3 sinks for short-term and long-term storage, respectively. Key configurations include data directories, log parsing rules, sampling rates, Elasticsearch endpoints, and S3 bucket details.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n# Set global options\ndata_dir = \"/var/lib/vector\"\n\n# Vector's API (disabled by default)\n# Enable and try it out with the `vector top` command\n[api]\nenabled = false\n# address = \"127.0.0.1:8686\"\n\n# Ingest data by tailing one or more files\n[sources.apache_logs]\ntype              = \"file\"\ninclude           = [\"/var/log/apache2/*.log\"]    # supports globbing\nignore_older_secs = 86400                         # 1 day\n\n# Structure and parse via Vector's Remap Language\n[transforms.apache_parser]\ninputs = [\"apache_logs\"]\ntype   = \"remap\"\nsource = '''\n. = parse_apache_log(.message)\n'''\n\n# Sample the data to save on cost\n[transforms.apache_sampler]\ninputs = [\"apache_parser\"]\ntype   = \"sample\"\nrate   = 2                    # only keep 50% (1/`rate`)\n\n# Send structured data to a short-term storage\n[sinks.es_cluster]\ninputs     = [\"apache_sampler\"]             # only take sampled data\ntype       = \"elasticsearch\"\nendpoints  = [\"http://79.12.221.222:9200\"]  # local or external host\nbulk.index = \"vector-%Y-%m-%d\"              # daily indices\n\n# Send structured data to a cost-effective long-term storage\n[sinks.s3_archives]\ninputs          = [\"apache_parser\"]    # don't sample for S3\ntype            = \"aws_s3\"\nregion          = \"us-east-1\"\nbucket          = \"my-log-archives\"\nkey_prefix      = \"date=%Y-%m-%d\"      # daily partitions, hive friendly format\ncompression     = \"gzip\"               # compress final objects\nframing.method  = \"newline_delimited\"  # new line delimited...\nencoding.codec  = \"json\"               # ...JSON\nbatch.max_bytes = 10000000             # 10mb uncompressed\n```\n\n----------------------------------------\n\nTITLE: Handling VRL Errors with Type Coercion\nDESCRIPTION: Shows how to handle errors during type coercion in VRL. The `to_int` function attempts to convert `.foo` to an integer. If successful, `foo` receives the integer value; otherwise, it defaults to `0`, and `err` contains an error message. The code checks for errors before using `foo` to avoid incorrect results.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/errors.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\n# `.foo` can be `100` or `\"not an int\"`\nfoo, err = to_int(.foo)\n\n# `err` can be `null` or `\"unable to coerce value to integer\"`\nif err == null {\n  # `foo` can be `100` or `0`\n  .result = foo * 5\n}\n```\n\n----------------------------------------\n\nTITLE: Register Function and Macro Wrapper\nDESCRIPTION: These functions and macros provide convenient wrappers for the `register` function in the `RegisterInternalEvent` trait.  They aim to simplify the registration process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nfn register<T: RegisterInternalEvent>(event: E) -> E::Handle {\n    event.register()\n}\n\nmacro_rules! register {\n    ($event:expr) => { vector_core::internal_event::register($event) };\n}\n```\n\n----------------------------------------\n\nTITLE: Defining a Console Sink for Internal Metrics in Vector\nDESCRIPTION: This snippet defines a console sink in Vector named `sink_1`. It takes input from the `internal_metrics` source and outputs the metrics to the console in a pretty-printed JSON format. This allows users to easily view Vector's internal metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nsink_1:\n    type: console\n    inputs:\n      - internal_metrics\n    encoding:\n      codec: json\n      json:\n        pretty: true\n```\n\n----------------------------------------\n\nTITLE: Start Vector using the configuration file\nDESCRIPTION: This command starts the Vector service using the specified configuration file. It reads the YAML configuration and initiates the data pipeline defined within it. Requires Vector to be installed and accessible in the system's PATH.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/transformation.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvector --config /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Configure Vector to Send Logs to CloudWatch\nDESCRIPTION: Configures Vector to read logs from standard input and send them to a CloudWatch Logs group. Requires the LOG_GROUP environment variable to be set.  AWS credentials must be configured for Vector to write to AWS.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\n[sources.stdin]\n  type = \"stdin\"\n[sinks.cloudwatch]\n  type = \"aws_cloudwatch_logs\"\n  inputs = [\"stdin\"]\n  group_name = \"${LOG_GROUP}\"\n  stream_name = \"test\"\n  region = \"us-east-1\"\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Remap Transform for Routing Failed Events - TOML\nDESCRIPTION: This TOML configuration demonstrates how to configure the `remap` transform to route failed events to a separate sink.  It sets `drop_on_error` and `reroute_dropped` to `true`, which enables the `.dropped` output for capturing and rerouting failed events. The `my_remap.dropped` input in the `sinks.bar` configuration specifies that the bar sink will receive the rerouted, failed events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-failed-event-routing.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.in]\n  type = \"demo_logs\"\n  format = \"shuffle\"\n  interval = 1.0\n  lines = [\n    '{ \"message\": \"valid message\", \"foo\": \"bar\"}',\n    '{ \"message\": \"valid message\", \"foo\": \"baz\"}',\n    'invalid message',\n  ]\n\n[transforms.my_remap]\n  type = \"remap\"\n  inputs = [\"in\"]\n  drop_on_error = true\n  drop_on_abort = true\n  reroute_dropped = true\n  source = \"\"\"\n    . |= object!(parse_json!(.message))\n    if .foo == \\\"baz\\\" {\n        abort\n    }\n    .processed = true\n  \"\"\"\n\n[sinks.foo]\n  type = \"console\"\n  inputs = [\"my_remap\"]\n  encoding.codec = \"json\"\n\n[sinks.bar]\n  type = \"console\"\n  inputs = [\"my_remap.dropped\"] # note the new `.dropped` here!\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Example config for using CSV enrichment with datadog logs in toml\nDESCRIPTION: This configuration sets up a Vector pipeline that reads logs from Datadog, enriches them using a CSV file, and applies a remap transform using VRL to add fields from the CSV file to the log events. The enrichment table and datadog logs source are defined in the config, with `enrichment_tables.csv_file` table defined as a csv file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-20-8288-csv-enrichment.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[enrichment_tables.csv_file]\n    type = \"csv\"\n    file = \"/path/to/csv.csv\"\n    delimiter = \",\"\n\n[sources.datadog_logs]\n    type = \"datadog_logs\"\n    address = \"0.0.0.0:80\"\n\n[transforms.simple_enrich]\n    type = \"remap\"\n    inputs = [\"datadog_logs\"]\n    source = '''\n        . = parse_json!(.message)\n\n        result, err = find_table_row(\n            enrichment_tables.csv_file,\n            { \"license_plate\": .license }\n        )\n\n        if is_null(err) {\n            .first_name = result.first_name\n            .last_name = result.last_name\n        }\n   '''\n```\n\n----------------------------------------\n\nTITLE: VRL for Preparing Data for Memory Table (Transform: cache_generator)\nDESCRIPTION: This VRL snippet prepares data to be stored in the memory enrichment table within a transform component named `cache_generator`. It checks if a `user-identifier` exists in the `memory_table`. If not, it creates a new object where the `user-identifier` becomes the key, and the rest of the data becomes the value associated with that key.  This data structure is required to use a memory enrichment table.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_17\n\nLANGUAGE: vrl\nCODE:\n```\nexisting, err = get_enrichment_table_record(\"memory_table\", { \"key\": get!(., path: [\"user-identifier\"])\n})\nif err != null {\n  # We don't have this key cached, so we need to prepare it for the table\n  data = .\n  # Since the memory enrichment table takes in all key value pairs it receives and stores them\n  # We want to produce an object that has the value of \"user-identifier\" as its key and\n  # rest of the object as its value\n  . = set!(value: {}, path: [get!(data, path: [\"user-identifier\"])], data: data)\n} else {\n  . = {}\n}\n```\n\n----------------------------------------\n\nTITLE: Event Emission with the Proposed API\nDESCRIPTION: This snippet illustrates how an event is emitted using the proposed `emit!` macro, which simplifies the instrumentation process. It replaces multiple `trace!` and `counter!` calls with a single line, enhancing code readability and maintainability. The event encapsulates all relevant data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-17-2064-event-driven-observability.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nmessages\n    .map(move |(msg, file): (Bytes, String)| {\n        emit!(FileEventReceived {\n            file: file.as_str(),\n            byte_size: msg.len(),\n        });\n        create_event(msg, file, &host_key, &hostname, &file_key)\n    })\n    .forward(out.sink_map_err(|error| error!(?error)))\n```\n\n----------------------------------------\n\nTITLE: Kafka Source with JSON Decoding in Vector\nDESCRIPTION: This code snippet demonstrates how to configure a `kafka` source in Vector to automatically decode JSON-encoded messages. By setting `decoding.codec = \"json\"`, Vector will handle the JSON decoding process, eliminating the need for a separate `remap` transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-10-06-source-codecs.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.kafka]\ntype = \"kafka\"\nbootstrap_servers = \"localhost:9200\"\ntopics = [\"my_topic\"]\ndecoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Enable Adaptive Concurrency in Vector (TOML)\nDESCRIPTION: This configuration enables adaptive concurrency for HTTP-based sinks in Vector.  It allows Vector to automatically adjust the number of concurrent requests based on the response times and error codes from the sink destination. This is now the default behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-10-06-arc-default.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nrequest.concurrency = \"adaptive\"\n```\n\n----------------------------------------\n\nTITLE: Remapping Fields in TOML\nDESCRIPTION: This TOML configuration uses a `remap` transform to rename the `timestamp` field to `@timestamp`.  It copies the value of `timestamp` to `@timestamp` and then deletes the original `timestamp` field. This is helpful when different parts of the pipeline expect fields to be named differently.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_9\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.rename_timestamp]\n  type = \"remap\"\n  inputs = [\"source0\"]\n  source = '''\n    .\"@timestamp\" = .timestamp\n    del(.timestamp)\n  '''\n```\n\n----------------------------------------\n\nTITLE: Encrypting Data using AES in VRL\nDESCRIPTION: This snippet demonstrates how to encrypt data in VRL using the `encrypt` function with AES. It retrieves the encryption key from an environment variable (base64 encoded), generates an initialization vector (IV), encrypts the plaintext, and encodes the result as base64. It requires the `decode_base64`, `get_env_var`, `encrypt`, and `encode_base64` VRL functions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_0\n\nLANGUAGE: coffeescript\nCODE:\n```\n# The `key` is typically a raw set of bytes matching the expected length for the algorithm so it is common to base64\n# encode it for injection and decode in VRL\nkey = decode_base64!(get_env_var!(\"KEY\")) # with $KEY set to \"c2VjcmV0X19faHVudGVyMg==\" in this example\n\n# we store the iv on the event to use as-needed for decryption\n.iv = \"1234567890123456\" # typically you would call random_bytes(<num bytes expected by algorithm>)\n\nencrypted_message = encrypt!(plaintext, \"AES-128-CBC-PKCS7\", key, iv: iv)\n\n# Often you will want to encode the result of the encryption as base64 so it can be represented as a string\n.encrypted_message = encode_base64(encrypted_message)\n\n# delete original\ndel(.plaintext)\n```\n\n----------------------------------------\n\nTITLE: Vector Stdout Sink TOML Configuration\nDESCRIPTION: A Vector configuration snippet defining a stdout sink, extracted into a separate file. This sink outputs events to the standard output in JSON format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\ntype = \"console\"\ninputs = [\"change_fields\"]\ntarget = \"stdout\"\n```\n\n----------------------------------------\n\nTITLE: Structured Log Event Input (TOML)\nDESCRIPTION: This snippet shows how to specify a structured log event as input to a Vector unit test using the `log_fields` parameter.  This allows testing of transforms that operate on specific fields within log events.  The fields are defined within the `[tests.inputs.log_fields]` section.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n[tests.inputs.log_fields]\nmessage = \"successful transaction\"\ncode = 200\nid = \"38c5b0d0-5e7e-42aa-ae86-2b642ad2d1b8\"\n```\n\n----------------------------------------\n\nTITLE: Vector Remap Transform TOML Configuration\nDESCRIPTION: A Vector configuration snippet defining a remap transform, extracted into a separate file. This snippet adds a new field to the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\ntype = \"remap\"\ninputs = [\"syslog\"]\nsource = \"\"\"\n.new_field = \\\"some value\\\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example TOML\nDESCRIPTION: This TOML configuration defines a source named `foo` of type `stdin` and a sink named `bar` of type `console`. The sink `bar` is configured to receive input from the source `foo` and encode the output as JSON. This example demonstrates how inputs and outputs are declared and connected within the Vector configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/ARCHITECTURE.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.foo]\ntype = \"stdin\"\n\n[sinks.bar]\ntype = \"console\"\ninputs = [\"foo\"]\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration for Remap Transform with unnest\nDESCRIPTION: This TOML configuration defines a `remap` transform that uses the `unnest` VRL function to transform the input event. It specifies that the `events` field should be used to generate multiple output events. The `type` is set to \"remap\", and the `source` contains the VRL code to perform the transformation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\nsource = \"\"\"\n. = unnest(., \"events\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Vector Agent via Helm\nDESCRIPTION: Installs the Vector Agent using the Helm chart, specifying the namespace, creating the namespace if it doesn't exist, and using the provided values.yaml configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nhelm install vector vector/vector \\\n  --namespace vector \\\n  --create-namespace \\\n  --values values.yaml\n```\n\n----------------------------------------\n\nTITLE: Troubleshooting Configuration\nDESCRIPTION: Defines the Vector configuration used for troubleshooting a pipeline. Includes a demo logs source with JSON messages, a remap transform to process the messages, and console/blackhole sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[api]\nenabled = true\n\n[sources.in]\ntype = \"demo_logs\"\nformat = \"shuffle\"\nlines = [\n  '{ \"type\": \"icecream\", \"flavor\": \"strawberry\" }',\n  '{ \"type\": \"icecream\", \"flavor\": \"chocolate\" }',\n  '{ \"type\": \"icecream\", \"flavor\": \"wasabi\" }',\n]\n\n[transforms.picky]\ntype = \"remap\"\ninputs = [\"in\"]\ndrop_on_abort = true\nreroute_dropped = true\nsource = '''\n  if .flavor == \"strawberry\" {\n    .happiness = 10\n  } else if .flavor == \"chocolate\" {\n    .happiness = 5\n  } else {\n    abort\n  }\n'''\n\n[sinks.store]\ntype = \"console\"\ninputs = [\"picky\"]\ntarget = \"stdout\"\nencoding.codec = \"json\"\n\n[sinks.trash]\ntype = \"blackhole\"\ninputs = [\"picky.dropped\"]\n\n```\n\n----------------------------------------\n\nTITLE: Example Log Event\nDESCRIPTION: This is an example log event that demonstrates the data structure used with the template example. It contains a timestamp, application_id, and message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"timestamp\": \"2020-02-14T01:22:23.223Z\",\n  \"application_id\": 1,\n  \"message\": \"Hello world\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using Suffix Argument in truncate - Javascript\nDESCRIPTION: This snippet shows the updated syntax for the `truncate` function using the `suffix` argument instead of the deprecated `ellipsis` argument in VRL. It shows how to truncate a string and add \"...\" as a suffix.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-0-45-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\ntruncate(\"A rather long sentence.\", limit: 11, suffix: \"...\")\n```\n\n----------------------------------------\n\nTITLE: Memory Enrichment Table as Source Example (YAML)\nDESCRIPTION: This configuration shows how to use a memory enrichment table as a source by exporting its stored data periodically. It configures the `memory_table` with `source_config` to export data every 180 seconds. The `source_key` parameter defines the component that will receive the exported data. In this example, a console sink receives the data exported from the enrichment table.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_18\n\nLANGUAGE: yaml\nCODE:\n```\nenrichment_tables:\n  memory_table:\n    type: memory\n    ttl: 60\n    flush_interval: 5\n    inputs: [\"cache_generator\"]\n    source_config:\n       # Export the cache every 3 minutes (100 seconds).\n       export_interval: 180\n       # If set to false (which is the default) it will not remove data from cache after exporting.\n       remove_after_export: false\n       # Source key has to be defined and be different from the main key (\"memory_table\").\n       # This key is then used to define this component as an input to other components\n       source_key: \"memory_table_source\"\n       # export_batch_size can be used to reduce memory usage when handling larger tables.\n       # When set, data will be exported from the table in batches, waiting for downstream components\n       # to process the data\n       # export_batch_size: 10000\n\n\nsources:\n  demo_logs_test:\n    type: \"demo_logs\"\n    format: \"json\"\n\ntransforms:\n  demo_logs_processor:\n    type: \"remap\"\n    inputs: [\"demo_logs_test\"]\n    source: |\n      . = parse_json!(.message)\n      user_id = get!(., path: [\"user-identifier\"])\n\n      # Look for existing value in the table, using \"user-identifier\" as key\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\": user_id })\n\n      if err == null {\n        # Value found, just use the cached value\n        # In this case existing looks like this { \"key\": user_id, \"value\": {}, \"ttl\": 50 }\n        # Where value is the value we cached, ttl is the time left before this value is removed from\n        # the cache and key is the key we queried the table with\n        . = existing.value\n        .source = \"cache\"\n      } else {\n        # Do some processing, because we don't have this value in the table\n        .referer = parse_url!(.referer)\n        .referer.host = encode_punycode!(.referer.host)\n        .source = \"transform\"\n      }\n\n  cache_generator:\n    type: \"remap\"\n    inputs: [\"demo_logs_processor\"]\n    source: |\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\": get!(., path: [\"user-identifier\"])\n})\n      if err != null {\n        # We don't have this key cached, so we need to prepare it for the table\n        data = .\n        # Since the memory enrichment table takes in all key value pairs it receives and stores them\n        # We want to produce an object that has the value of \"user-identifier\" as its key and\n        # rest of the object as its value\n        . = set!(value: {}, path: [get!(data, path: [\"user-identifier\"])], data: data)\n      } else {\n        . = {}\n      }\n\n# We can observe that after some time data will be exported to console from the cache\nsinks:\n  console:\n    inputs: [\"memory_table_source\"]\n    target: \"stdout\"\n    type: \"console\"\n    encoding:\n      codec: \"json\"\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration with WASM Transform\nDESCRIPTION: This TOML configuration file configures Vector to use a WASM transform module. It defines a source (`source0`), a transform (`demo`) using the WASM module, and a sink (`sink0`) that outputs to the console. The `module` parameter in the `[transforms.demo]` section specifies the path to the compiled WASM module.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_7\n\nLANGUAGE: TOML\nCODE:\n```\ndata_dir = \"/var/lib/vector/\"\n\n[sources.source0]\nmax_length = 102400\ntype = \"stdin\"\n\n[transforms.demo]\ninputs = [\"source0\"]\ntype = \"wasm\"\nmodule = \"target/wasm32-wasi/release/echo.wasm\"\n\n[sinks.sink0]\nhealthcheck = true\ninputs = [\"demo\"]\ntype = \"console\"\nencoding.codec = \"json\"\nbuffer.type = \"memory\"\nbuffer.max_events = 500\nbuffer.when_full = \"block\"\n\n[[tests]]\n  name = \"demo-tester\"\n  [tests.input]\n    insert_at = \"demo\"\n    type = \"log\"\n    [tests.input.log_fields]\n      \"message\" = \"foo\"\n  [[tests.outputs]]\n    extract_from = \"demo\"\n    [[tests.outputs.conditions]]\n      \"echo.equals\" = \"foo\"\n```\n\n----------------------------------------\n\nTITLE: Configuring kubernetesLogs Source in Vector Helm Chart\nDESCRIPTION: This YAML snippet shows how to configure a `kubernetes_logs` source using the `customConfig` option within the Helm chart's `values.yaml` file. It defines the `kubernetes_logs` source under the `sources` key. The vector-agent chart automatically mounts hostPaths to access Pod logs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sources:\n  ...\n    kubernetes_logs:\n      type: kubernetes_logs\n  ...\n```\n\n----------------------------------------\n\nTITLE: Remap Transform for Selecting Specific Fields in TOML\nDESCRIPTION: This TOML configuration uses a `remap` transform to keep only specific fields (`.timestamp`, `.message`, `.host`, `.user_id`) and drop the rest. The `only_fields` function is used to achieve this. The input for the transform is `my-source-id`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.strip_personal_details]\ntype = \"remap\"\ninputs = [\"my-source-id\"]\nsource = '''\n  only_fields(.timestamp, .message, .host, .user_id)\n'''\n```\n\n----------------------------------------\n\nTITLE: Configure Dedupe Transform in Vector TOML\nDESCRIPTION: This snippet demonstrates how to configure the `dedupe` transform in Vector's TOML configuration file. It includes the required `type` and `inputs` fields, as well as the optional `fields.match` field for specifying which fields to compare for deduplication. The transform identifies and removes duplicate log events based on the specified criteria.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-10-dedupe-transform.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.my_transform_id]\n  # General\n  type = \"dedupe\" # required\n  inputs = [\"my-source-id\"] # required\n\n  # Fields\n  fields.match = [\"timestamp\", \"host\", \"message\"] # optional, default\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example in TOML\nDESCRIPTION: This snippet showcases a complete Vector configuration in TOML format, including enabling the API, defining a `demo_logs` source, and configuring a `console` sink. It sets up a basic data pipeline for demonstration purposes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[api]\nenabled = true\n\n[sources.demo]\ntype = \"demo_logs\"\nformat = \"json\"\ninterval = 1.0\n\n[sinks.console]\ntype = \"console\"\ninputs = [\"demo\"]\nencoding.codec = \"text\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Global Log Schema in Vector\nDESCRIPTION: This code snippet demonstrates how to configure the global log schema in Vector using the `vector.toml` configuration file. It shows how to set the `host_key`, `message_key`, and `timestamp_key` to custom values, which are `host`, `message`, and `timestamp` by default. These settings allow Vector to adopt existing schemas and enable component coordination.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-14-global-log-schema.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[log_schema]\n  host_key = \"host\" # default\n  message_key = \"message\" # default\n  timestamp_key = \"timestamp\" # default\n```\n\n----------------------------------------\n\nTITLE: Prometheus Configuration for Scraping Vector Metrics\nDESCRIPTION: This Prometheus configuration defines a scrape job to collect metrics from the Vector Prometheus exporter. It configures Prometheus to scrape metrics from the target `host.docker.internal:9598` every 15 seconds.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_32\n\nLANGUAGE: yaml\nCODE:\n```\n# prometheus config\nglobal:\n  scrape_interval: 15s\n\nscrape_configs:\n  - job_name: \"vector\"\n    static_configs:\n      - targets: [\"host.docker.internal:9598\"]\n```\n\n----------------------------------------\n\nTITLE: Implementing Configurable Trait for BatchConfig\nDESCRIPTION: This Rust code snippet showcases a potential implementation of the `Configurable` trait for a `BatchConfig` struct. It includes defining the `fields` function, which is responsible for generating configuration fields with appropriate metadata and overrides. This example shows how to define maximum events, bytes, and timeout for batch processing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\n    }\n\n    fn fields(overrides: Option<Vec<Metadata<Self>>>) -> Option<Vec<Field>> {\n        let shape = Self::shape();\n        let mut required_field_shapes = match shape {\n            Shape::Map(MapShape { required_fields, .. }) => required_fields.clone(),\n            _ => unreachable!(\"SinkConfig is a fixed-field object and cannot be another shape\"),\n        };\n\n        let base_metadata = <Self as Configurable>::metadata();\n        let merged_metadata = merge_metadata_overrides(base_metadata, overrides);\n\n        let max_events_shape = required_field_shapes.remove(\"max_events\").expect(\"shape for `max_events` must exist\");\n        let max_events_override_metadata = merged_metadata.clone()\n            .map_default_value(|default| default.max_events);\n\n        let max_bytes_shape = required_field_shapes.remove(\"max_bytes\").expect(\"shape for `max_bytes` must exist\");\n        let max_bytes_override_metadata = merged_metadata.clone()\n            .map_default_value(|default| default.max_bytes));\n\n        let max_timeout_shape = required_field_shapes.remove(\"max_timeout\").expect(\"shape for `max_timeout` must exist\");\n        let max_timeout_override_metadata = merged_metadata.clone()\n            .map_default_value(|default| default.max_timeout));\n\n        let mut fields = HashMap::new();\n        fields.insert(\"max_events\", Field::new::<Option<u32>>(\n            \"max_events\",\n            \"Maximum number of events per batch.\",\n            max_events_shape,\n            max_events_override_metadata,\n        ));\n        fields.insert(\"max_bytes\", Field::new::<Option<u32>>(\n            \"max_bytes\",\n            \"Maximum number of bytes per batch.\",\n            max_bytes_shape,\n            max_bytes_override_metadata,\n        ));\n        fields.insert(\"max_timeout\", Field::new::<Option<Duration>>(\n            \"max_timeout\",\n            \"Maximum period of time a batch can exist before being forcibly flushed.\",\n            max_timeout_shape,\n            max_timeout_override_metadata,\n        ));\n\n        Some(fields)\n    }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring ZLIB Compression for an HTTP Sink\nDESCRIPTION: This snippet sets the compression type to `zlib` for the HTTP sink. This resolves the compression error by configuring Vector to use the compression format supported by the downstream server.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_20\n\nLANGUAGE: yaml\nCODE:\n```\ncompression: zlib\n```\n\n----------------------------------------\n\nTITLE: Prepare Kustomization File for Vector Aggregator\nDESCRIPTION: This shell script creates a 'kustomization.yaml' file to deploy Vector as an Aggregator. It defines the Kubernetes resources by including the base configuration, overriding the image version, and referencing the namespace file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncat <<-'KUSTOMIZATION' > kustomization.yaml\n---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\n# Override the namespace of all of the resources we manage.\nnamespace: vector\n\nbases:\n  # Include Vector recommended base (from git).\n  - github.com/vectordotdev/vector/tree/master/distribution/kubernetes/vector-aggregator\n\nimages:\n  # Override the Vector image to pin the version used.\n  - name: timberio/vector\n    newName: timberio/vector\n    newTag: {{< version >}}-distroless-libc\n\nresources:\n  # The namespace previously created to keep the resources in.\n  - namespace.yaml\nKUSTOMIZATION\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Config Directory (Bash)\nDESCRIPTION: Shows how to start Vector using the `--config-dir` argument to load configurations from component type folders. This allows for a more organized configuration structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nvector --config-dir /etc/vector\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom DNS Servers in Vector using TOML\nDESCRIPTION: This snippet shows how to configure custom DNS servers in Vector using the `dns_servers` field in the TOML configuration file. When set, Vector will ignore the system configuration and use only the provided DNS servers.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-12-13-custom-dns.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\ndns_servers = [\"0.0.0.0:53\"]\n```\n\n----------------------------------------\n\nTITLE: Vector Apache Logs Source Configuration (YAML)\nDESCRIPTION: This YAML snippet configures the Apache Logs source for Vector to ingest data by tailing files. The configuration uses globbing for file inclusion, and ignores older files based on `ignore_older` setting.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_9\n\nLANGUAGE: yaml\nCODE:\n```\n# Ingest data by tailing one or more files\ntype: \"file\"\ninclude: [\"/var/log/apache2/*.log\"]    # supports globbing\nignore_older: 86400                    # 1 day\n```\n\n----------------------------------------\n\nTITLE: JSON Metric Tag Encoding\nDESCRIPTION: Describes the enhanced JSON encoding for metric tags to allow null values for bare tags and arrays of strings or null for tags with multiple values. This enables representing bare and multi-valued tags in JSON format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"tags\": {\n    \"single_value\":\"value\",\n    \"bare_tag\":null,\n    \"multi_valued_tag\":[\"value1\",\"value2\"],\n    \"complex_tag\":[\"value3\",null]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Run Vector with YAML Configuration (Shell)\nDESCRIPTION: This shell command starts the Vector agent, specifying the YAML configuration file to use. This configuration file defines the behavior of the Vector agent, including data sources, transformations, and sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nvector --config /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Vector aws_kinesis_firehose Source Config (TOML)\nDESCRIPTION: This TOML configuration defines an `aws_kinesis_firehose` source in Vector.  It specifies the address and access key used to receive data from Kinesis Firehose, which needs to be configured in Firehose.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[sources.firehose]\n  type = \"aws_kinesis_firehose\"\n  address = \"0.0.0.0:8080\" # the public URL will be set in the Firehose config\n  access_key = \"my secret key\" # this will also be set in the Firehose config\n```\n\n----------------------------------------\n\nTITLE: Basic Vector tap Usage\nDESCRIPTION: Runs the `vector tap` command without any specific options. This is equivalent to `--outputs-of \"*\"`, which matches all component IDs. This command allows users to see all log output in the Vector pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_4\n\nLANGUAGE: console\nCODE:\n```\n[tap] Pattern \"*\" successfully matched.\n{\"message\":\"test1\",\"source_type\":\"demo_logs\",\"timestamp\":\"2022-02-22T19:20:40.487671258Z\"}\n{\"message\":\"test2\",\"source_type\":\"demo_logs\",\"timestamp\":\"2022-02-22T19:20:41.486858019Z\"}\n...\n```\n\n----------------------------------------\n\nTITLE: CloudWatch Metrics Source Configuration\nDESCRIPTION: Defines the configuration for the `aws_cloudwatch_metrics` source in Vector.  It specifies settings such as AWS authentication (assume_role), endpoints, regions, scraping intervals, request limits, and metric definitions (namespaces, names, dimensions, and statistics). The configuration utilizes the TOML format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-28-cloudwatch-metrics.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.cloudwatch]\n  type = \"aws_cloudwatch_metrics\"\n  assume_role = \"arn:aws:iam::123456789098:role/my_role\" # optional, no default\n  endpoints = [\"127.0.0.0:5000/path/to/service\"] # optional, no default, relevant when regions = []\n  regions = [\"us-east-1\"] # required, required when endpoints unspecified; no default\n\n  period_secs = 300 # period (s) to aggregate metrics over, optional, can be overridden at metric level, default 300\n  delay_secs = 300 # delay collection by value (s), used to avoid collecting data that has not fully been processed by CloudWatch, optional, default 300\n  interval_secs = 300 # interval to scrape metrics; should be a multiple of \"period\"; default 300\n\n  metrics_refresh_interval_secs = 900 # interval to refresh available metrics for queried namespaces if globbing or all metrics are used; default 900\n\n  # Request\n  request.in_flight_limit = 25 # optional, default, requests\n  request.rate_limit_duration_secs = 1 # optional, default, seconds\n  request.rate_limit_num = 25 # optional, default\n  request.retry_attempts = 18446744073709551615 # optional, default\n  request.retry_initial_backoff_secs = 1 # optional, default, seconds\n  request.retry_max_duration_secs = 10 # optional, default, seconds\n  request.timeout_secs = 30 # optional, default, seconds\n\n  [[sources.cloudwatch.metrics]]\n    namespace = \"AWS/EC2\" # optional; supports globbing\n    names = [\"EBSReadOps\", \"EBSReadBytes\", \"Network*\"] # optional; defaults to all metrics in namespace, [\"*\"], (refreshed on interval); supports globbing\n    dimensions.InstanceId = \"i-05517fbc2e6124dfb\" # optional; supported dimensions differ by namespace and metric; supports globbing\n    statistics = [ \"average\", \"sum\", \"minimum\", \"maximum\", \"sample_count\" ] # statistics to collect; can also contain extended statistics like p99; default: [ \"average\", \"sum\", \"minimum\", \"maximum\", \"sample_count\" ]\n    period_secs = 300 # period (s) to aggregate metrics over; defaults to top-level `period` setting; top-level interval should be a multiple of this and any other defined periods\n```\n\n----------------------------------------\n\nTITLE: Filtering Events with VRL in YAML\nDESCRIPTION: This YAML configuration defines a `filter` transform in Vector. It filters out log events where the `severity` field equals \"info\". The `condition` field specifies the VRL expression used for filtering. The input to the transform is defined as `logs`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/_index.md#_snippet_3\n\nLANGUAGE: YAML\nCODE:\n```\ntransforms:\n  filter_out_info:\n    type: filter\n    inputs:\n      - logs\n    condition: '.severity != \"info\"'\n```\n\n----------------------------------------\n\nTITLE: Defining Configurable Structs in Rust\nDESCRIPTION: This code snippet demonstrates the usage of the `Configurable` derive macro to define configuration structs, `SinkConfig` and `BatchConfig`. It includes examples of using `configurable` attributes for defining schema formats, deprecating aliases, applying subfield constraints (range), and enforcing non-zero values. It also shows the use of `serde` attributes for aliasing and default values. This example utilizes the `configurable_component` attribute macro as a string replacement marker for `#[derive(Serialize, Deserialize, Configurable)]`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\n/// Configuration for the sink.\n#[derive(Clone)]\n#[configurable_component]\n#[configurable(metadata(\"status\", \"beta\"))]\nstruct SinkConfig {\n    /// The endpoint to send requests to.\n    #[configurable(format(uri), deprecated(\"url\"))]\n    #[serde(alias = \"url\")]\n    endpoint: String,\n    #[serde(default = default_batch_config_for_sink)]\n    #[configurable(subfield(max_events, range(max = 1000)))]\n    batch: BatchConfig,\n}\n\n/// Controls batching behavior i.e. maximum batch size, the maximum time before a batch is flushed, etc.\n#[derive(Default, Clone)]\n#[configurable_component]\nstruct BatchConfig {\n    /// Maximum number of events per batch.\n    #[configurable(non_zero)]\n    max_events: Option<u32>,\n    #[configurable(non_zero)]\n    /// Maximum number of bytes per batch.\n    max_bytes: Option<u32>,\n    #[configurable(non_zero)]\n    /// Maximum period of time a batch can exist before being forcibly flushed.\n    max_timeout: Option<Duration>,\n}\n```\n\n----------------------------------------\n\nTITLE: De-Dot Keys for Elasticsearch VRL\nDESCRIPTION: This VRL snippet recursively iterates through all keys within the current object and replaces dots (`.`) with underscores (`_`). This is useful for compatibility with systems like Elasticsearch that have restrictions on the characters allowed in field names.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_5\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_keys(., recursive: true) -> |key| { replace(key, \".\", \"_\") }\n```\n\n----------------------------------------\n\nTITLE: Replacing GeoIP with Enrichment Tables and Remap YAML\nDESCRIPTION: This snippet demonstrates how to replace the deprecated `geoip` transform using an enrichment table and a `remap` transform. It defines an enrichment table pointing to a GeoIP database and utilizes the `get_enrichment_table_record!` VRL function within a `remap` transform to achieve the same functionality.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-11-07-0-26-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nenrichment_tables:\n  geoip_table:\n    path: /etc/vector/GeoLite2-City.mmdb\n    type: geoip\n\ntransforms:\n  geoip:\n    type: remap\n    inputs:\n      - with_ip_info\n    source: |-\n      .geoip = get_enrichment_table_record!(\"geoip_table\",\n        {\n          \"ip\": .ip_address\n        }\n      )\n```\n\n----------------------------------------\n\nTITLE: Running Vector Tap Command\nDESCRIPTION: This command allows you to see the input and/or outputs of the Vector components.  The example shows how to tap the outputs of source_0 and transform_0, noting sinks don't have outputs thus we cannot tap them.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nvector tap --outputs-of source_0,transform_0\n```\n\n----------------------------------------\n\nTITLE: Transform IoT Status Code to Message with Remap in Vector TOML\nDESCRIPTION: This TOML configuration defines a Vector transform named 'enrich_iot_status' that enriches data from the 'datadog_agents' input. It uses the `get_enrichment_table_record` function to lookup the status message based on the 'status_code' from the 'iot_status' enrichment table. The result is stored in the '.status' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.enrich_iot_status]\ntype = \"remap\"\ninputs = [\"datadog_agents\"]\nsource = '''\n. = parse_json!(.status_message)\n\nstatus_code = del(.status_code)\n\n# In the case that no row with a matching value is found, the original value of\n# the status code is assigned.\nrow = get_enrichment_table_record(\"iot_status\", {\"status_code\" : status_code}) ?? status_code\n\n.status = row.status_message\n'''\n```\n\n----------------------------------------\n\nTITLE: Defining an Enrichment Table in TOML\nDESCRIPTION: This configuration defines an enrichment table resource in a Vector configuration file. It specifies the type as 'file', encoding codec as 'csv', the path to the CSV file, and the delimiter used to separate fields. The `header_row` parameter indicates whether the first row contains column names.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-20-8288-csv-enrichment.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[enrichment_tables.csv_file]\n  type = \"file\"\n  encoding.codec = \"csv\"\n  path = \"\\path_to_csv\"\n  delimiter = \",\"\n```\n\n----------------------------------------\n\nTITLE: Configure HTTP Request Rate Limit and Concurrency - TOML\nDESCRIPTION: This configuration snippet shows how to configure request rate limit and maximum concurrency on an HTTP-based sink in Vector using TOML. It sets the maximum number of concurrent requests to 5 and limits the rate to 10 requests per second.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-20-rate-limits.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nrequest.concurrency = 5 # limit to 5 in-flight requests\nrequest.rate_limit_num = 10 # limit to 10 requests / second\n```\n\n----------------------------------------\n\nTITLE: Full Custom Vector Configuration in Helm Chart\nDESCRIPTION: This YAML snippet shows an example of a complete Vector configuration using the `customConfig` option in the Helm chart's `values.yaml` file. It includes configurations for various sources, transforms, sinks, healthchecks, api and service settings. It also utilizes Helm templating to dynamically set values, such as port numbers, based on the `service.ports` configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  data_dir: \"/custom-data-dir\"\n  healthchecks:\n    enabled: true\n    require_healthy: true\n  api:\n    enabled: true\n    address: \"0.0.0.0:{{ with index .Values.service.ports 0 }}{{ .port }}{{ end }}\"\n    playground: false\n  sources:\n    internal_logs:\n      type: internal_logs\n    internal_metrics:\n      type: internal_metrics\n    kubernetes_logs:\n      type: kubernetes_logs\n      glob_minimum_cooldown_ms: 1000\n      ingestion_timestamp_field: ingestion_timestamp\n    statsd_metrics:\n      type: statsd\n      address: \"0.0.0.0:{{ with index .Values.service.ports 1 }}{{ .port }}{{ end }}\"\n      mode: tcp\n  transforms:\n    sample:\n      type: sample\n      inputs: [\"*_logs\"]\n      rate: 20\n  sinks:\n    datadog_logs:\n      type: datadog_logs\n      inputs: [\"sample\"]\n      compression: gzip\n      default_api_key: \"${DATADOG_API_KEY}\"\n      encoding:\n        codec: json\n    datadog_metrics:\n      type: datadog_metrics\n      inputs: [\"*_metrics\"]\n      api_key: \"${DATADOG_API_KEY}\"\nservice:\n  enabled: true\n  ports:\n  - name: api\n    port: 8686\n    protocol: TCP\n    targetPort: 8686\n  - name: statsd\n    port: 8000\n    protocol: TCP\n    targetPort: 8000\n```\n\n----------------------------------------\n\nTITLE: Vector TOML Config with Source and Transform\nDESCRIPTION: Illustrates a basic Vector configuration with a `socket` source and a `remap` transform that uses grok parsing. This snippet sets up a pipeline for processing log data received over TCP.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sources.over_tcp]\n  type = \"socket\"\n  mode = \"tcp\"\n  address = \"0.0.0.0:9000\"\n\n[transforms.foo]\n  inputs = [\"over_tcp\"]\n  type = \"remap\"\n  source = '''\n  . = parse_grok!(.message, s'%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}')\n'''\n```\n\n----------------------------------------\n\nTITLE: Configure Kafka sink with `native` codec\nDESCRIPTION: This configuration snippet shows how to configure a `kafka` sink to send events using the `native` codec. It utilizes the same Protocol Buffers-based encoding scheme for Vector-to-Vector communication. The `native` encoding option is available on `kafka` and some other sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-31-native-event-codecs.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.out]\ntype = \"kafka\"\ninputs = [\"...\"]\nbootstrap_servers = \"localhost:9092\"\ntopic = \"vector\"\nencoding.codec = \"native\"\n```\n\n----------------------------------------\n\nTITLE: Buffer Configuration - Block on Full\nDESCRIPTION: This configuration sets the buffer to block when it is full. This means that when the buffer reaches its capacity, backpressure will be applied to the previous components in the pipeline, preventing data loss and ensuring reliable delivery.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/about/concepts.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nbuffer.when_full = block\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Coalescing Fields with Pipe Operator in CoffeeScript-like Syntax\nDESCRIPTION: This snippet demonstrates the use of the pipe operator `|` for coalescing fields. If a field in the path evaluates to null or is missing, the next field in the coalescing expression is selected. This allows for handling cases where fields may be optional or have default values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_3\n\nLANGUAGE: coffeescript\nCODE:\n```\n.foo = .bar.(baz | buz).bev\n```\n\n----------------------------------------\n\nTITLE: Kustomize Configuration YAML\nDESCRIPTION: This YAML file defines the Kustomize configuration for deploying Vector. It specifies the namespace, resources (Vector global, Vector namespaced, and a custom configmap), which are used by `kustomize build` to generate the final Kubernetes manifests.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n# kustomization.yaml\nnamespace: vector\n\nresources:\n  - https://packages.timber.io/vector/latest/kubernetes/vector-global.yaml\n  - https://packages.timber.io/vector/latest/kubernetes/vector-namespaced.yaml\n  - vector-configmap.yaml\n```\n\n----------------------------------------\n\nTITLE: Splunk HEC Source Configuration (TOML)\nDESCRIPTION: Demonstrates the configuration settings for the `splunk_hec` source to enable indexer acknowledgements.  Key parameters include: `acknowledgements.enabled` to turn on the feature, `acknowledgements.max_pending_acks` to limit the total number of pending acknowledgements, `acknowledgements.max_number_of_ack_channel` to configure the maximum number of channels supported, `acknowledgements.max_pending_acks_per_channel` to set the max pending acks per channel,  `acknowledgements.ack_idle_cleanup` to enable channel cleanup after inactivity, and `acknowledgements.max_idle_time` which controls the idle time before removal.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-9465-splunk-hec-indexer-acknowledgements.md#_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.splunk_hec]\ntype = \"splunk_hec\"\n# ...\nacknowledgements.enabled = true\nacknowledgements.max_pending_acks = 10_000_000\nacknowledgements.max_number_of_ack_channel = 1_000_000\nacknowledgements.max_pending_acks_per_channel = 1_000_000\nacknowledgements.ack_idle_cleanup = true\nacknowledgements.max_idle_time = 300\n```\n\n----------------------------------------\n\nTITLE: Multiline Configuration in Vector using TOML\nDESCRIPTION: This configuration snippet shows how to configure the file source in Vector to merge multiple lines into a single event based on defined patterns. It utilizes `start_pattern`, `mode`, `condition_pattern`, and `timeout_ms` to define the merging rules.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-21-file-source-multiline-support.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_file_source]\n  type = \"file\"\n  # ...\n\n  [sources.my_file_source.multiline]\n    start_pattern = \"^[^\\\\s]\"\n    mode = \"continue_through\"\n    condition_pattern = \"^[\\\\s]+from\"\n    timeout_ms = 1000\n```\n\n----------------------------------------\n\nTITLE: Input Log Events\nDESCRIPTION: These are sample input log events that the Reduce transform will aggregate. Each event contains a timestamp, message, request ID, and other relevant fields. The `request_id` field is used to identify events belonging to the same request.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-10-add-reduce-transform.md#_snippet_1\n\nLANGUAGE: log\nCODE:\n```\n{\"timestamp\": \"...\", \"message\": \"Received GET /path\", \"request_id\": \"abcd1234\", \"request_path\": \"/path\", \"request_params\": \"...\"}\n{\"timestamp\": \"...\", \"message\": \"Executed query in 5.2ms\", \"request_id\": \"abcd1234\", \"query\": \"SELECT * FROM table\", \"query_duration_ms\": 5.2}\n{\"timestamp\": \"...\", \"message\": \"Rendered partial _partial.erb in 2.3ms\", \"request_id\": \"abcd1234\", \"template\": \"_partial.erb\", \"render_duration_ms\": 2.3}\n{\"timestamp\": \"...\", \"message\": \"Executed query in 7.8ms\", \"request_id\": \"abcd1234\", \"query\": \"SELECT * FROM table\", \"query_duration_ms\": 7.8}\n{\"timestamp\": \"...\", \"message\": \"Sent 200 in 15.2ms\", \"request_id\": \"abcd1234\", \"response_status\": 200, \"response_duration_ms\": 5.2}\n```\n\n----------------------------------------\n\nTITLE: Agent Resource Limits in Kubernetes\nDESCRIPTION: Defines recommended resource requests and limits for a Vector Agent deployed on Kubernetes. The 'requests' section specifies the minimum resources the pod requires, while 'limits' define the maximum resources the pod can consume. These values should be adjusted based on the complexity of the Vector pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\nresources:\n  requests:\n    memory: \"64Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"1024Mi\"\n    cpu: \"6000m\"\n```\n\n----------------------------------------\n\nTITLE: Example JSON Before IoT Status Enrichment\nDESCRIPTION: This JSON represents the input data before enrichment. It contains fields like 'host', 'timestamp', and 'status_code'. The 'status_code' field is an integer that will be translated to a human-readable status message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"host\":\"my.host.com\",\n  \"timestamp\":\"2019-11-01T21:15:47+00:00\",\n  ...\n  \"status_code\":1,\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration (toml)\nDESCRIPTION: Configures the `aws_kinesis_firehose` source, `remap` transform, and `console` sink in Vector. The `aws_kinesis_firehose` source listens for Firehose messages. The `remap` transform extracts and parses the log events. The `console` sink writes the events to standard out.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.firehose]\n  type = \"aws_kinesis_firehose\"\n  address = \"0.0.0.0:8080\" # the public URL will be set when configuring Firehose\n  access_key = \"${FIREHOSE_ACCESS_KEY} # this will also be set when configuring Firehose\n\n[transforms.parse]\n  type = \"remap\"\n  inputs = [\"firehose\"]\n  drop_on_error = false\n  source = '''\n    parsed = parse_aws_cloudwatch_log_subscription_message!(.message)\n    . = unnest(parsed.log_events)\n    . = map_values(.) -> |value| {\n       event = del(value.log_events)\n       value |= event\n       message = del(.message)\n       . |= object!(parse_json!(message))\n    }\n  '''\n\n# you may want to add more transforms here\n\n[sinks.console]\n  type = \"console\"\n  inputs = [\"parse\"]\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Assert No Output in Vector Unit Test (TOML)\nDESCRIPTION: This configuration demonstrates how to use the `no_outputs_from` parameter to assert that specific transforms produce no output during a unit test. This is useful for verifying that filter transforms are correctly filtering events or that VRL's `abort` function is called when expected.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[[tests]]\nname = \"Ensure no output\"\nno_outputs_from = [\"log_filter\", \"metric_filter\"]\n```\n\n----------------------------------------\n\nTITLE: Validating Vector Configuration Skipping Health Checks\nDESCRIPTION: This command validates a Vector configuration file, skipping health checks for configured endpoints. This is useful when the endpoints are unreachable, for example, when validating from a local workstation, but still running other environment checks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/validating.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nvector validate --skip-healthchecks /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Chained Transforms Unit Test (TOML)\nDESCRIPTION: This configuration tests a chain of three remap transforms: `add_env_metadata`, `sanitize`, and `add_host_metadata`. The test inserts an event at the beginning of the chain and extracts the output from the end, using VRL assertions to verify the final event's structure and content. This demonstrates testing a complete data processing pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_19\n\nLANGUAGE: toml\nCODE:\n```\n[sources.web_backend]\ntype = \"docker_logs\"\ndocker_host = \"http://localhost:2375\"\ninclude_images = [\"web_backend\"]\n\n[transforms.add_env_metadata]\ntype = \"remap\"\ninputs = [\"web_backend\"]\nsource = '''\n.tags.environment = \"production\"\n'''\n\n[transforms.sanitize]\ntype = \"remap\"\ninputs = [\"add_env_metadata\"]\nsource = '''\ndel(.username)\ndel(.email)\n'''\n\n[transforms.add_host_metadata]\ntype = \"remap\"\ninputs = [\"sanitize\"]\nsource = '''\n.tags.host = \"web-backend1.vector-user.biz\"\n'''\n\n[[tests]]\nname = \"Multiple chained remap transforms\"\n\n[[tests.inputs]]\ntype = \"log\"\ninsert_at = \"add_env_metadata\"\n\n[tests.inputs.log_fields]\nmessage = \"image successfully uploaded\"\ncode = 202\nusername = \"tonydanza1337\"\nemail = \"tony@whostheboss.com\"\ntransaction_id = \"bcef6a6a-2b72-4a9a-99a0-97ae89d82815\"\n\n[[tests.outputs]]\nextract_from = \"add_host_metadata\"\n\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert_eq!(.tags.environment, \"production\", \"incorrect environment tag\")\nassert_eq!(.tags.host, \"web-backend1.vector-user.biz\", \"incorrect host tag\")\nassert!(!exists(.username))\nassert!(!exists(.email))\n\nvalid_transaction_id = exists(.transaction_id) &&\n  is_string(.transaction_id) &&\n  length!(.transaction_id) == 36\n\nassert!(valid_transaction_id, \"transaction ID invalid\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Parsing in Lua\nDESCRIPTION: This code snippet presents the Lua code required to parse the CSV log message. It utilizes the csv module that we loaded previously, to parse the message and then transform the log event into a structured event, by assigning the CSV fields values into corresponding event properties.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\nhooks.process = \"\"\"\n  function (event, emit)\n    fields = csv.openstring(event.log.message):lines()() -- parse the `message` field\n    event.log.message = nil -- drop the `message` field\n\n    column_names = {  -- a sequence containing CSV column names\n      -- ...\n    }\n\n    for column, value in ipairs(fields) do -- iterate over CSV columns\n      column_name = column_names[column] -- get column name\n      event.log[column_name] = value -- set the corresponding field in the event\n    end\n\n    emit(event) -- emit the transformed event\n  end\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configure `exec` source with `native_json` codec\nDESCRIPTION: This configuration snippet shows how to configure an `exec` source to receive events via the `native_json` codec. The `exec` source runs a shell command and uses the `native_json` codec to parse the output as Vector events. It allows for receiving metrics directly without needing to pass them through a `log_to_metric` transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-31-native-event-codecs.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.in]\ntype = \"exec\"\nmode = \"scheduled\"\ncommand = [\"./scrape.sh\"]\ndecoding.codec = \"native_json\"\n```\n\n----------------------------------------\n\nTITLE: VRL Program for Parsing Common Log\nDESCRIPTION: This VRL program parses a common log message stored in the `.log` field, extracts the size and renames it to `.total_bytes`, and determines if the host is an internal request based on IP address.  It uses the `parse_common_log!` function to parse the log string, `del()` to delete the size field and `ip_cidr_contains()` to check the IP address.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_6\n\nLANGUAGE: coffee\nCODE:\n```\n. = parse_common_log!(.log)\n.total_bytes = del(.size)\n.internal_request = ip_cidr_contains(\"5.86.0.0/16\", .host) ?? false\n```\n\n----------------------------------------\n\nTITLE: Configuring Secret Backend - TOML\nDESCRIPTION: This snippet shows how to configure a secret backend in Vector using the TOML configuration format.  The type is set to \"exec\", and the command specifies the path to the external process.  The external process will be called to retrieve secrets.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-secrets-management.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[secret.backend_1]\ntype = \"exec\" # exec is the only supported backend as of writing\ncommand = [\"/path/to/cmd1\"]\n```\n\n----------------------------------------\n\nTITLE: Lua Aggregator Transform Configuration (All Code)\nDESCRIPTION: This TOML configuration demonstrates moving all Lua code into the 'source' section for better readability and organization. It defines the 'init', 'process', 'timer_handler', 'shutdown', and 'make_counter' functions within the source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.aggregator]\ntype = \"lua\"\nversion = \"2\"\ninputs = [] # add IDs of the input components here\nhooks.init = \"init\"\nhooks.process = \"process\"\nhooks.shutdown = \"shutdown\"\ntimers = [{interval_seconds = 5, handler = \"timer_handler\"}]\n\nsource = \"\"\"\n  function init()\n    count = 0\n  end\n\n  function process()\n    count = count + 1\n  end\n\n  function timer_handler(emit)\n    emit(make_counter(counter))\n    counter = 0\n  end\n\n  function shutdown(emit)\n    emit(make_counter(counter))\n  end\n\n  function make_counter(value)\n    return metric = {\n      name = \\\"event_counter\\\",\n      kind = \\\"incremental\\\",\n      timestamp = os.date(\\\"!*t\\\"),\n      counter = {\n        value = value\n      }\n    }\n  end\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example (TOML)\nDESCRIPTION: This TOML configuration demonstrates using the `internal_logs` and `internal_metrics` sources in Vector.  It configures shipping Vector's internal logs to Splunk via the `splunk_hec` sink and exposing Vector's internal metrics for Prometheus scraping via the `prometheus` sink. It requires defining `SPLUNK_HEC_TOKEN` as an environment variable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-23-internal-logs-source.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.vector_logs]\ntype = \"internal_logs\"\n\n[sources.vector_metrics]\ntype = \"internal_metrics\"\n\n[sinks.splunk]\ntype = \"splunk_hec\"\ninputs = [\"vector_logs\"]\nendpoint = \"https://my-account.splunkcloud.com\"\ntoken = \"${SPLUNK_HEC_TOKEN}\"\nencoding.codec = \"json\"\n\n[sinks.prometheus]\ntype = \"prometheus\"\ninputs = [\"vector_metrics\"]\naddress = \"0.0.0.0:9090\"\n```\n\n----------------------------------------\n\nTITLE: Custom Timestamp Field in TOML\nDESCRIPTION: This TOML configuration sets a custom timestamp field for all sources, sinks, and transforms. The `timestamp_key` is set to `@timestamp` for the log schema.  A logplex source is also defined using the custom timestamp configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n[log_schema]\n  timestamp_key = \"@timestamp\"  # Applies to all sources, sinks, and transforms!\n\n[sources.my_naming_confused_source]\n  type = \"logplex\"\n  address = \"0.0.0.0:8088\"\n```\n\n----------------------------------------\n\nTITLE: Updating Vector Aggregator via Helm\nDESCRIPTION: Updates an existing Vector Aggregator deployment using Helm, ensuring the repository is up-to-date and reusing the previous values during the upgrade.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nhelm repo update && \\\nhelm upgrade vector vector/vector \\\n  --namespace vector \\\n  --reuse-values\n```\n\n----------------------------------------\n\nTITLE: Backing up Prometheus data with Vector and AWS S3 (TOML)\nDESCRIPTION: This snippet configures Vector to receive Prometheus data via the `prometheus_remote_write` source, converts metrics to logs, and then sends the data to AWS S3 for backup. The `metric_to_log` transform converts the Prometheus metric data into a log format suitable for storage. Replace `aws_s3` with other object storage sinks like `gcp_cloud_storage` for alternative providers.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-11-19-prometheus-remote-integrations.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.prometheus]\n  type = \"prometheus_remote_write\"\n\n[transforms.convert]\n  type = \"metric_to_log\"\n  inputs = [\"prometheus\"]\n\n[sinks.backup]\n  type = \"aws_s3\"\n  inputs = [\"convert\"]\n```\n\n----------------------------------------\n\nTITLE: Updating Route Transform Configuration YAML\nDESCRIPTION: This snippet demonstrates how to update the configuration of the `route` transform by replacing the deprecated `lanes` parameter with `route`. This change is required after upgrading to Vector 0.26.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-11-07-0-26-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  my_route:\n    type: route\n    lanes: # <-- change this to \"route\"\n      route_a: ..\n```\n\n----------------------------------------\n\nTITLE: Creating Vector ConfigMap\nDESCRIPTION: This snippet creates a Kubernetes ConfigMap named 'vector-config' from a 'vector.toml' file, which configures Vector to send container logs from the 'kubernetes' input to an AWS S3 sink. It includes bucket name, compression type, region, and key prefix for the S3 objects.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncat <<-CONFIG > vector.toml\n# Docs: https://vector.dev/docs/\n# Container logs are available from \"kubernetes\" input.\n\n# Send data to one or more sinks!\n[sinks.aws_s3]\n  type = \"aws_s3\"\n  inputs = [\"kubernetes\"]\n  bucket = \"my-bucket\"\n  compression = \"gzip\"\n  region = \"us-east-1\"\n  key_prefix = \"date=%F/\"\nCONFIG\nkubectl create secret generic vector-config --from-file=vector.toml=vector.toml\n```\n\n----------------------------------------\n\nTITLE: Enabling API in Vector Configuration\nDESCRIPTION: This snippet enables the Vector API, which is required for the `vector tap` command. It configures the global settings for the Vector instance, allowing for external interaction and monitoring.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napi:\n  enabled: true\n```\n\n----------------------------------------\n\nTITLE: Swimlanes Transform Configuration Comparison (check_fields vs remap)\nDESCRIPTION: This code snippet demonstrates the configuration of the `swimlanes` transform using both the older `check_fields` method and the newer `remap` method. It shows how to route events into a 'success' lane based on status code and severity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-swimlanes-remap-support.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [transforms.split_events]\n type = \"swimlanes\"\n inputs = [\"http-server-logs\"]\n\n # Using check_fields\n-lanes.success.type = \"check_fields\"\n-lanes.success.status_code.eq = 200\n-lanes.success.severity.eq = \"info\"\n\n # Using remap\n+lanes.success.type = \"remap\"\n+lanes.success.source = '.status_code == 200 && .severity == \"info\"'\n```\n\n----------------------------------------\n\nTITLE: Vector Apache Parser Transform Configuration (YAML)\nDESCRIPTION: This YAML snippet shows the Apache Parser transform configuration. It takes `apache_logs` as input and parses it via Vector Remap Language. \nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_10\n\nLANGUAGE: yaml\nCODE:\n```\n# Structure and parse via Vector Remap Language\ninputs:\n  - \"apache_logs\"\ntype: \"remap\"\nsource: |\n  . = parse_apache_log(.message)\n```\n\n----------------------------------------\n\nTITLE: Installing Vector Agent Helm Chart\nDESCRIPTION: This snippet demonstrates how to install the `vector-agent` chart from the Vector Helm repository using the `helm install` command.  It specifies the release name (`vector`), the chart name (`vector/vector-agent`), and additional flags to create the namespace (`--create-namespace`) and install the chart into the `vector` namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-helm-vector-dev.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nhelm install vector vector/vector-agent \\\n  --namespace vector \\\n  --create-namespace \\\n\n```\n\n----------------------------------------\n\nTITLE: Filtering Events with Vector TOML Configuration\nDESCRIPTION: This configuration snippet demonstrates how to use the `filter` transform in Vector to filter events based on conditions. It filters events where the `level` field is equal to `error` and the `service` field is equal to `haproxy`.  The transform takes input from a source with the ID `my-source-id`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-31-filter-transform.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.haproxy_errors]\n  # General\n  type = \"filter\"\n  inputs = [\"my-source-id\"]\n\n  # Conditions\n  condition.\"level.eq\" = \"error\"\n  condition.\"service.eq\" = \"haproxy\"\n```\n\n----------------------------------------\n\nTITLE: Enable Auto Partial Merge in Docker Logs Source - TOML\nDESCRIPTION: This configuration snippet enables the `auto_partial_merge` option within the `docker_logs` source in Vector. When enabled, Vector automatically merges partial Docker events that Docker splits due to their size exceeding 16kb. It requires Vector version 0.8.0 or later.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-05-merge-partial-docker-events.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"docker_logs\"\n  auto_partial_merge = true\n```\n\n----------------------------------------\n\nTITLE: Enabling Vector API in Helm Chart with Custom Configuration\nDESCRIPTION: This YAML snippet demonstrates how to enable and configure the Vector API using the `customConfig` option in the Helm chart's `values.yaml` file. It sets the `enabled`, `address`, and `playground` options under the `api` key.  You will need to expose the configured port using `extraContainerPorts` or the `service` key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  api:\n    enabled: true\n    address: 0.0.0.0:8686\n    playground: true\n  ...\n```\n\n----------------------------------------\n\nTITLE: Vector Enrichment Table Configuration TOML\nDESCRIPTION: This TOML configuration snippet defines an enrichment table named `iot_remap` in Vector. It configures the table to read from a CSV file, specifying the file path, encoding as CSV, and the schema with `code` as an integer and `message` as a string. This table is used to enrich events with data from the CSV file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-csv-enrichment.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[enrichment_tables.iot_remap]\ntype = \"file\"\n\n[enrichment_tables.iot_remap.file]\npath = \"/etc/vector/iot_remap.csv\"\nencoding = { type = \"csv\" }\n\n[enrichment_tables.iot_remap.schema]\ncode = \"integer\"\nmessage = \"string\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Sink with New Disk Buffer (v2)\nDESCRIPTION: This TOML configuration demonstrates how to switch a Vector sink to use the new `disk_v2` disk buffer implementation. This new implementation is a beta feature and is expected to provide more consistent performance and resource usage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-disk-buffer-v2-beta.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.http]\n# ...\nbuffer.type = \"disk_v2\"\n```\n\n----------------------------------------\n\nTITLE: Update Kafka Sink Bootstrap Servers (TOML)\nDESCRIPTION: This snippet demonstrates the change required in the `vector.toml` configuration file to update the `bootstrap_servers` field in the Kafka sink from an array to a comma-separated string. This change is necessary for Vector v0.7.0 and later. The configuration specifies the Kafka sink settings, including the type, inputs, and bootstrap servers.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-12-use-comma-delim-server-list-instead-of-an-array.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.my_sink_id]\n  type = \"kafka\"\n  inputs = [\"my-source-id\"]\n  bootstrap_servers = \"10.14.22.123:9092,10.14.23.332:9092\"\n```\n\n----------------------------------------\n\nTITLE: Example JSON log entries for GDPR Compliance\nDESCRIPTION: These JSON log entries demonstrate data containing `id`, `gdpr` and `email` fields that need to be processed for GDPR compliance.  The example shows entries with `gdpr` set to either `true` or `false`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{ \"id\": \"user1\", \"gdpr\": false, \"email\": \"us-user1@datadoghq.com\" }\n{ \"id\": \"user2\", \"gdpr\": false, \"email\": \"us-user2@datadoghq.com\" }\n{ \"id\": \"user3\", \"gdpr\": true, \"email\": \"eu-user3@datadoghq.com\" }\n```\n\n----------------------------------------\n\nTITLE: Remap Transform and Metric Event Unit Test (TOML)\nDESCRIPTION: This is a complete example of unit testing a metric through a remap transform. The transform adds an environment tag to the metric, and the test verifies that the tag is correctly added with the expected value using VRL assertions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.add_env_to_metric]\ntype = \"remap\"\ninputs = []\nsource = '''\nenv, err = get_env_var(\"ENV\")\nif err != null {\n  log(err, level: \"error\")\n}\ntags.environment = env\n'''\n\n[[tests]]\nname = \"add_unique_id_test\"\n\n[[tests.inputs]]\ninsert_at = \"add_env_to_metric\"\ntype = \"metric\"\n\n[tests.inputs.metric]\nname = \"website_hits\"\nkind = \"absolute\"\ncounter = { value = 1 }\n\n[[tests.outputs]]\nextract_from = \"add_env_to_metric\"\n\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert_eq!(.name, \"website_hits\")\nassert_eq!(.kind, \"absolute\")\nassert_eq!(.tags.environment, \"production\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Configuration File\nDESCRIPTION: Executes Vector with the specified configuration file and enables watching for changes.  The `-w` flag enables configuration reloading, which is useful for testing `vector tap`'s behavior with dynamic configuration changes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_3\n\nLANGUAGE: console\nCODE:\n```\nvector --config path/to/config.toml -w\n```\n\n----------------------------------------\n\nTITLE: Add Vector YUM Repository\nDESCRIPTION: This command adds the Vector YUM repository to the system. It downloads and executes a script from `https://setup.vector.dev` using `curl` to configure the repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/yum.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbash -c \"$(curl -L https://setup.vector.dev)\"\n```\n\n----------------------------------------\n\nTITLE: Creating Log Event Based on Namespace in Rust\nDESCRIPTION: This code snippet shows how to create a log event based on the configured log namespace. If the namespace is `Vector`, the event is created directly from the message. If it's `Legacy`, a default event is created, and the message is inserted under the `message` key obtained from the log schema. The `log_schema().message_key()` is used to retrieve the correct key for the legacy namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\n    let mut log = match log_namespace {\n        LogNamespace::Vector => LogEvent::from(message),\n        LogNamespace::Legacy => {\n            let mut log = LogEvent::default();\n\n            // Add message\n            log.insert(log_schema().message_key(), message);\n            log\n        }\n    };\n```\n\n----------------------------------------\n\nTITLE: Remap Transform VRL Source Code\nDESCRIPTION: Adds the `parse_json!` function to the VRL source code within the `remap` transform. This parses the JSON payload from the `message` field and makes it available for processing. It solves the issue of the message being the default 'message' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_12\n\nLANGUAGE: coffeescript\nCODE:\n```\n. = parse_json!(.message)\n```\n\n----------------------------------------\n\nTITLE: Pipeline Operator Support\nDESCRIPTION: Illustrates pipeline operator usage for filtering and partitioning IP addresses.  It combines filtering IPs and partitioning the result based on whether they start with \"180.14\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_50\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n.private_and_public_ips = filter(.ip) -> |_, ip| is_ip(ip) |> partition() -> |_, ip| starts_with(ip, \"180.14\")\n```\n\n----------------------------------------\n\nTITLE: Restarting Vector Agent in Kubernetes\nDESCRIPTION: Restarts the Vector agent daemonset in a Kubernetes cluster using kubectl.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nkubectl rollout restart --namespace vector daemonset/vector-agent\n```\n\n----------------------------------------\n\nTITLE: Prepare Kustomization File for Vector Agent\nDESCRIPTION: This shell script creates a 'kustomization.yaml' file that defines how to deploy Vector as an Agent in Kubernetes using Kustomize. It specifies the namespace, includes the base configuration from the Vector repository, overrides the Vector image version, and references the namespace file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncat <<-'KUSTOMIZATION' > kustomization.yaml\n---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\n# Override the namespace of all of the resources we manage.\nnamespace: vector\n\nbases:\n  # Include Vector recommended base (from git).\n  - github.com/vectordotdev/vector/tree/master/distribution/kubernetes/vector-agent\n\nimages:\n  # Override the Vector image to pin the version used.\n  - name: timberio/vector\n    newName: timberio/vector\n    newTag: {{< version >}}-distroless-libc\n\nresources:\n  # The namespace previously created to keep the resources in.\n  - namespace.yaml\nKUSTOMIZATION\n```\n\n----------------------------------------\n\nTITLE: Map Complex Dynamic Object Based on Conditionals VRL\nDESCRIPTION: This VRL snippet maps a complex, dynamic object based on conditional logic. It iterates through nested objects and arrays, applying transformations to specific fields based on their values or existence. It handles specific scenarios like renaming and deleting fields based on condition attributes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_22\n\nLANGUAGE: coffee\nCODE:\n```\n.input = map_values(.input) -> |input| {\n  input.items = map_values(input.items) -> |item| {\n    item.userAttributes = map_values(item.userAttributes) -> |attribute| {\n      if attribute.key == \"Name\" {\n        del(attribute.__type)\n\n        key = del(attribute.key)\n        value = del(attribute.value)\n\n        attribute = set!(attribute, [key], value)\n      } else if attribute.key == \"Address\" {\n        attribute.values = map_values(attribute.values) -> |address| {\n          del(address.city)\n          address\n        }\n      }\n\n      attribute\n    }\n\n    item.userId = map_values(item.userId) -> |id| {\n      del(id.userGroupId)\n\n      id\n    }\n\n    item\n  }\n\n  input\n}\n```\n\n----------------------------------------\n\nTITLE: Send Data to Vector via stdin\nDESCRIPTION: This bash command pipes the string 'Hello World!' to Vector, using the specified configuration file. It demonstrates how to send data to Vector for processing via standard input.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\necho 'Hello World!' | vector --config ./vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Configuring Exclusive Route Transform in Vector\nDESCRIPTION: This configuration example demonstrates how to use the Exclusive Route transform in Vector. It defines two routes, \"foo\" and \"bar\", each with a condition based on the 'origin' field of the event. Events are routed exclusively to one of these routes based on their origin.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-11-07-exclusive_route.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n# Sources section omitted\n\ntransforms:\n  transform0:\n    inputs:\n      - source0\n    type: exclusive_route\n    routes:\n      - name: \"foo\"\n        condition: '.origin == \"foo\"'\n      - name: \"bar\"\n        condition: '.origin == \"bar\"'\n\n# Sinks section omitted\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for AWS Configuration (bash)\nDESCRIPTION: Defines environment variables for AWS account ID, region, Firehose access key, Vector endpoint, log group, Firehose delivery stream name, Firehose log group, Firehose log stream and S3 bucket. These variables are used in subsequent scripts to configure AWS resources.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Update these\nexport AWS_ACCOUNT_ID=\"111111111111\" # your AWS account ID\nexport AWS_REGION=\"us-east-1\" # region that resources exist in\nexport FIREHOSE_ACCESS_KEY=\"my secret key\" # set to a secret value\nexport VECTOR_ENDPOINT=\"https://example.com\" # the endpoint where vector is deployed with the aws_kinesis_firehose source (see Configuring Vector below)\n\n# Update these if needed\nexport LOG_GROUP=\"/test/vector\" # the log group you want to consume with vector\nexport FIREHOSE_DELIVERY_STREAM=\"vector-stream\"\nexport FIREHOSE_LOG_GROUP=\"/aws/kinesisfirehose/vector-stream\" # log group for Kinesis Firehose to log messages to\nexport FIREHOSE_LOG_STREAM=\"HttpEndpointDelivery\" # log stream in DEBUG_LOG_GROUP for Kinesis Firehose to log messages to\nexport FIREHOSE_S3_BUCKET=\"firehose-${AWS_ACCOUNT_ID}\" # a bucket to write events that failed to be forwarded to\n```\n\n----------------------------------------\n\nTITLE: Remap Transform with Unnest Function (TOML)\nDESCRIPTION: This example demonstrates using the `unnest` function in VRL within a `remap` transform. It takes an input event containing an array of events and transforms it into multiple events, each containing an element from the array. The input contains `host` and `events` key, and `events` key is an array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\ninputs = []\nsource = \"\"\"\n. = {\"host\": \"localhost\", \"events\": [{\"message\": \"hello\"}, {\"message\": \"world\"}]} # to represent the incoming event\n\n. = unnest(.events)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Parse Message Using Grok Patterns VRL\nDESCRIPTION: This VRL snippet attempts to parse a message field using a list of Grok patterns until a match is found. It iterates through the patterns using `for_each`, and if a pattern matches without error, the `parsed` result is merged into the root object using the `|=` operator. The `matched` flag ensures that the iteration stops after the first successful match.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_14\n\nLANGUAGE: coffee\nCODE:\n```\npatterns = []\nmatched = false\n\nfor_each(patterns) -> |_index, pattern| {\n  if !matched && (parsed, err = parse_grok(.message, pattern); err == null) {\n    matched = true\n    . |= parsed\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: \"Zip\" Array of Objects into Object VRL\nDESCRIPTION: This VRL snippet \"zips\" an array of objects with `key` and `value` fields into a single object. It iterates through the array using `for_each` and sets properties on the root object based on the `key` and `value` from each element of the array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_11\n\nLANGUAGE: coffee\nCODE:\n```\ndata = [{ \"key\": \"name\", \"value\": \"value\" }, { \"key\": \"key\", \"value\": \"otherValue\" }]\nfor_each(data) -> |_index, value| {\n  . = set(., [value.key], value.value)\n}\n```\n\n----------------------------------------\n\nTITLE: Distribution Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create a distribution metric event. It includes the metric name and a set of values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_23\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_distribution\",\n    distribution = {\n      values = {\"a\", \"b\", \"c\"}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sink Configuration with Default Namespace in TOML\nDESCRIPTION: This example shows a sink configuration with a `default_namespace` option.  This allows the sink to set a namespace for any metrics that do not already have one.  This example specifically uses the `prometheus` sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-02-3684-metric-namespaces.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my_sink_id]\n  type = \"prometheus\"\n  inputs = [\"my_transform_id\"]\n  address = \"0.0.0.0:9598\"\n  default_namespace = \"unknown\"\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Configuration with Remap (Diff)\nDESCRIPTION: This code snippet shows the difference in configuring the `reduce` transform in Vector. It highlights how to use `remap` instead of `check_fields` to specify the conditions for starting a group of events to be reduced. The `starts_when.source` parameter uses a VRL expression to match a regular expression and check the severity level.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-reduce-transform-remap-support.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [transforms.merge_stack_trace]\n type = \"reduce\"\n inputs = [\"jvm-logs\"]\n merge_strategies.message = \"concat_newline\"\n\n # Using check_fields\n-starts_when.type = \"check_fields\"\n-starts_when.message.regex = \"/^\\\\w.*/\"\n-starts_when.severity.eq = \"info\"\n\n # Using remap\n+starts_when.type = \"remap\"\n+starts_when.source = 'match(string!(.message), r'^\\\\w.*') && .severity == \"info\"'\n```\n\n----------------------------------------\n\nTITLE: CLI Option Example: Wildcard in Config File Path\nDESCRIPTION: This example demonstrates how to use wildcards in configuration file paths. Values containing wildcards must be quoted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nvector --config \"*.toml\"\n```\n\n----------------------------------------\n\nTITLE: Output Declaration Example (TOML)\nDESCRIPTION: Illustrates how to declare expected outputs in a Vector unit test, specifying the `extract_from` transform and defining VRL conditions to verify the output.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[[tests.outputs]]\nextract_from = \"add_metadata\"\n\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert!(is_string(.id))\nassert!(exists(.tags))\n'''\n```\n\n----------------------------------------\n\nTITLE: Configuring statsd sink mode in Vector TOML\nDESCRIPTION: This snippet demonstrates how to configure the `statsd` sink with the `mode` option, specifying the protocol to use (UDP in this case).  This is a breaking change in Vector 0.11, requiring the `mode` option to be explicitly set. This example configures the statsd sink to send metrics over UDP.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.statsd]\n  type = \"statsd\"\n+  mode = \"udp\"\n```\n\n----------------------------------------\n\nTITLE: Enabling VRL VM Runtime in Remap Transform (TOML)\nDESCRIPTION: This TOML snippet shows how to enable the new Virtual Machine (VM) runtime for VRL programs within a Remap transform in Vector.  The `runtime = \"vm\"` setting specifies that the VM should be used instead of the default Tree Walking interpreter. This configuration should be added to the `transforms.remap` section in your Vector configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-15-vrl-vm-beta.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\ninputs = [ \"...\" ]\nruntime = \"vm\"\nsource = '''\n...\n'''\n```\n\n----------------------------------------\n\nTITLE: Transforming logfmt_parser with remap\nDESCRIPTION: Replacing the `logfmt_parser` transform with the `remap` transform. Parses logfmt formatted messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.logfmt_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= parse_logfmt!(.message)\n'''\n```\n\n----------------------------------------\n\nTITLE: Syslog processing Vector Configuration (YAML)\nDESCRIPTION: This YAML configuration file defines a Vector topology for processing Syslog events using the `demo_logs` source, `remap` transform, and `console` sink. It generates sample Syslog data, parses it using VRL, and emits the structured event as JSON to stdout.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  generate_syslog:\n    type:   \"demo_logs\"\n    format: \"syslog\"\n    count:  100\n\ntransforms:\n  remap_syslog:\n    inputs:\n      - \"generate_syslog\"\n    type:   \"remap\"\n    source: |\n            structured = parse_syslog!(.message)\n            . = merge(., structured)\n\nsinks:\n  emit_syslog:\n    inputs:\n      - \"remap_syslog\"\n    type: \"console\"\n    encoding:\n      codec: \"json\"\n```\n\n----------------------------------------\n\nTITLE: Reloading Vector on Linux (systemctl)\nDESCRIPTION: Reloads the Vector service using systemctl by sending a HUP signal to the main process. This applies configuration changes without a full restart.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nsystemctl kill -s HUP --kill-who=main vector.service\n```\n\n----------------------------------------\n\nTITLE: Vector Apache Sampler Transform Configuration (YAML)\nDESCRIPTION: This YAML snippet configures the Apache Sampler transform. It takes `apache_parser` as input and uses `sample` type to reduce the cost.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_11\n\nLANGUAGE: yaml\nCODE:\n```\n# Sample the data to save on cost\ninputs:\n  - \"apache_parser\"\ntype: \"sample\"\nrate: 2 # only keep 50% (1/`rate`)\n```\n\n----------------------------------------\n\nTITLE: Syslog Message Example\nDESCRIPTION: This syslog message demonstrates the format of a syslog message with structured data, which is used to illustrate the changes in how structured data is parsed by the `syslog` source and the `parse_syslog` VRL function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_7\n\nLANGUAGE: text\nCODE:\n```\n<1>1 2022-04-25T23:21:45.715740Z Gregorys-MacBook-Pro.local 2d4d9490-794a-4e60-814c-5597bd5b7b7d 79978 - [exampleSDID@32473 foo.baz=\"bar\"] test message\n```\n\n----------------------------------------\n\nTITLE: Configuring Datadog Metrics Sink\nDESCRIPTION: This snippet configures a Datadog Metrics sink in Vector.  It specifies the Datadog API key and the input source as internal_metrics.  The API key should be set as an environment variable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_29\n\nLANGUAGE: yaml\nCODE:\n```\nsinks:\n  sink_2:\n    datadog_metrics:\n      type: datadog_metrics\n      inputs: [\"internal_metrics\"]\n      api_key: \"${DATADOG_API_KEY}\"\n```\n\n----------------------------------------\n\nTITLE: Splunk HEC Ack Request/Response Example (JSONC)\nDESCRIPTION: Illustrates the request and response format for querying Splunk's `/services/collector/ack` endpoint using `ackId`s. The request contains an array of `ackId`s to check. The response provides a boolean status for each `ackId`, indicating whether the associated data has been persisted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-9465-splunk-hec-indexer-acknowledgements.md#_snippet_1\n\nLANGUAGE: JSONC\nCODE:\n```\n// Example request body\n{\n    \"acks\": [0, 1, 2]\n}\n\n// Example response body\n{\n    \"acks\":\n        {\n            \"0\": true,\n            \"1\": false,\n            \"2\": true\n        }\n}\n```\n\n----------------------------------------\n\nTITLE: Dropping Tags in aws_cloudwatch_metrics Sink (VRL)\nDESCRIPTION: This VRL program drops tags when there are more than ten in the `aws_cloudwatch_metrics` sink to maintain the original behavior before the limit of tags was increased from ten to thirty.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-01-17-0-27-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: coffeescript\nCODE:\n```\ncount = 10\ntags = {}\nfor_each(object!(.tags)) ->|key, value| {\n    if count > 0 {\n        count = count - 1\n        tags = set!(tags, [key], value)\n    }\n}\n.tags = tags\n```\n\n----------------------------------------\n\nTITLE: Adding Vector Helm Repository\nDESCRIPTION: This snippet demonstrates how to add the new Vector Helm repository to your Helm configuration.  It uses the `helm repo add` command to specify the repository name (`vector`) and the URL (`https://helm.vector.dev`). The `helm repo update` command refreshes the local index of available charts from the configured repositories.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-helm-vector-dev.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nhelm repo add vector https://helm.vector.dev\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Configure Kafka source with `native` codec\nDESCRIPTION: This configuration snippet shows how to configure a `kafka` source to receive events using the `native` codec. The `native` codec enables Vector to receive events from another Vector instance that is sending events through a `kafka` sink using the `native` codec, utilizing a compact Protocol Buffers-based encoding scheme.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-31-native-event-codecs.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[sources.in]\ntype = \"kafka\"\nbootstrap_servers = \"localhost:9092\"\ntopics = [\"vector\"]\ndecoding.codec = \"native\"\n```\n\n----------------------------------------\n\nTITLE: Raising VRL Errors\nDESCRIPTION: Demonstrates how to raise an error in VRL using the `!` operator. If `parse_json!` fails, the program immediately aborts. This approach should be used with caution, typically for critical operations where failure is unacceptable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/errors.md#_snippet_3\n\nLANGUAGE: coffee\nCODE:\n```\nstructured = parse_json!(\"not json\")\n. = merge(., structured)\n```\n\n----------------------------------------\n\nTITLE: Formatting Timestamp with Remap Transform (TOML)\nDESCRIPTION: This configuration snippet demonstrates how to use the `remap` transform in Vector to format a timestamp field into a specific format using the `timestamp` function and a format string. It takes the `.timestamp` field, parses it using the format string '%Y/%m/%d:%H:%M:%S %z', and assigns the result back to the `.timestamp` field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.format_timestamp]\n  type = \"remap\"\n  source = '''\n    .timestamp = timestamp(.timestamp, \"%Y/%m/%d:%H:%M:%S %z\")\n  '''\n```\n\n----------------------------------------\n\nTITLE: Transforming regex_parser with remap\nDESCRIPTION: Replacing the `regex_parser` transform with the `remap` transform. Parses messages using regular expressions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.regex_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= parse_regex!(.message, [#\"^(?P<host>[\\w\\.]+) - (?P<user>[\\w]+) (?P<bytes_in>[\\d]+) \\[(?P<timestamp>.*)\\] \"(?P<method>[\\w]+) (?P<path>.*)\" (?P<status>[\\d]+) (?P<bytes_out>[\\d]+)$\"#])\n.bytes_in = to_int!(.bytes_in)\n.some_timestamp = parse_timestamp!(.some_timestamp, \"%d/%m/%Y:%H:%M:%S %z\")\n.status = to_int!(.status)\n.bytes_out = to_int!(.bytes_out)\n'''\n```\n\n----------------------------------------\n\nTITLE: Merge Array of Objects Into Single Object VRL\nDESCRIPTION: This VRL snippet merges an array of objects into a single object. It initializes an empty `result` object and then iterates through the array of objects using `for_each`. For each object in the array, it merges the key-value pairs into the `result` object using the `|=` operator.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_23\n\nLANGUAGE: coffee\nCODE:\n```\nresult = {}\nobjects = [\n  { \"foo\": \"bar\" },\n  { \"foo\": \"baz\" },\n  { \"bar\": true },\n  { \"baz\": [{ \"qux\": null, \"quux\": [2,4,6] }] },\n]\n\nfor_each(objects) -> |_, value| { result |= value }\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Source Configuration (YAML)\nDESCRIPTION: This YAML configuration sets up an `opentelemetry` source to receive traces and a `datadog_traces` sink to forward them to Datadog. It demonstrates a minimal setup with the `opentelemetry` source configured to listen on `[::]:8081` using gRPC, and the `datadog_traces` sink using a default API key. The `inputs` field in the `sinks` section define how the sink gets data from the source `otlp` with named output `traces`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  otlp:\n    type: opentelemetry\n    address: \"[::]:8081\"\n    mode: grpc\n\nsinks:\n  dd_trace:\n    type: datadog_traces\n    default_api_key: 12345678abcdef\n    inputs:\n     - otlp.traces # Would exclusively emit traces\n```\n\n----------------------------------------\n\nTITLE: Zero-Downtime Deployment: Final Source Configuration\nDESCRIPTION: This code snippet shows the final step in the zero-downtime deployment process, removing the old v1 source configuration. This completes the transition, leaving only the v2 source active and utilizing the gRPC over HTTP protocol.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-vector-source-sink.md#_snippet_3\n\nLANGUAGE: diff\nCODE:\n```\n- [sources.vector]\n-   address = \"0.0.0.0:9000\"\n-   type = \"vector\"\n-   version = \"1\"\n-\n  [sources.vector]\n    address = \"0.0.0.0:5000\"\n    type = \"vector\"\n    version = \"2\"\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON Events from Explode and Map\nDESCRIPTION: These are the resulting JSON log events after applying both the \"explode\" and \"map\" transforms. The nested `events` field is now merged into the top-level object. `events` key is deleted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{ \"message\": \"hello\", \"host\": \"localhost\" }\n{ \"message\": \"world\", \"host\": \"localhost\" }\n```\n\n----------------------------------------\n\nTITLE: Configure Vector via Downward API using Pod Annotations (YAML)\nDESCRIPTION: This YAML snippet demonstrates how to configure Vector using pod annotations in Kubernetes through the downward API. It defines a pod with a volume that exposes the pod's annotations as a file, which can then be used by Vector to load its configuration. This approach allows for dynamic configuration of Vector based on the pod's metadata.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: kubernetes-downwardapi-volume-example\n  annotations:\n    vector.dev/config: |-\n      [sinks.aws_s3]\n      type = \"aws_s3\"\n      inputs = [\"kubernetes\"]\n      bucket = \"my-bucket\"\n      compression = \"gzip\"\n      region = \"us-east-1\"\n      key_prefix = \"date=%F/\"\nspec:\n  containers:\n    - name: vector\n      image: vector-image\n      command:\n        [\"vector\", \"--k8s-downward-api-config\", \"/etc/podinfo/annotations\"]\n      volumeMounts:\n        - name: podinfo\n          mountPath: /etc/podinfo\n  volumes:\n    - name: podinfo\n      downwardAPI:\n        items:\n          - path: \"annotations\"\n            fieldRef:\n              fieldPath: metadata.annotations\n```\n\n----------------------------------------\n\nTITLE: Map Tags to Objects VRL\nDESCRIPTION: This VRL snippet processes the `tags` field, converting boolean values to objects with an `enabled` field. It uses `map_values` with the `recursive: true` option to traverse the nested structure, ensuring that only boolean values are transformed. This example showcases the transformation from booleans to objects containing the boolean value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_24\n\nLANGUAGE: coffee\nCODE:\n```\n# Once Vector’s \"schema support\" is enabled, this can be removed.\n.tags = object(.tags) ?? {}\n.ips = array(.ips) ?? []\n\n# Recursively map all `.tags` values to their new values.\n#\n# A copy of the object is returned, with the value changes applied.\n.tags = map_values(.tags, recursive: true) { |value|\n    # Recursively iterating values also maps over collection types (objects or\n    # arrays). In this case, we don’t want to mutate those.\n    if is_object(value) || is_array(value) {\n      value\n    } else {\n      # `value` can be a boolean, or any other value. We enforce it to be\n      # a boolean.\n      value = bool!(value) ?? false\n\n      # Change the value to an object.\n      value = { \"enabled\": value }\n\n      # Mapping an object requires you to return any value at the end of the\n      # closure.\n      #\n      # This invariant will be checked at compile-time.\n      value\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Stopping Vector on Linux (systemctl)\nDESCRIPTION: Stops the Vector service using systemctl. This gracefully shuts down the Vector process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl stop vector\n```\n\n----------------------------------------\n\nTITLE: Setup Vector APT repository and add Datadog key (Shell)\nDESCRIPTION: These commands configure the Vector deb repository by creating a new list file and adding the Datadog GPG keys. It adds the repository URL, creates a keyring, sets permissions and imports the Datadog public keys.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\necho \"deb [signed-by=/usr/share/keyrings/datadog-archive-keyring.gpg] https://apt.vector.dev/ stable vector-0\" | sudo tee \"/etc/apt/sources.list.d/vector.list\"\nsudo touch /usr/share/keyrings/datadog-archive-keyring.gpg\nsudo chmod a+r /usr/share/keyrings/datadog-archive-keyring.gpg\ncurl https://keys.datadoghq.com/DATADOG_APT_KEY_CURRENT.public | sudo gpg --no-default-keyring --keyring /usr/share/keyrings/datadog-archive-keyring.gpg --import --batch\ncurl https://keys.datadoghq.com/DATADOG_APT_KEY_F14F620E.public | sudo gpg --no-default-keyring --keyring /usr/share/keyrings/datadog-archive-keyring.gpg --import --batch\ncurl https://keys.datadoghq.com/DATADOG_APT_KEY_C0962C7D.public | sudo gpg --no-default-keyring --keyring /usr/share/keyrings/datadog-archive-keyring.gpg --import --batch\n```\n\n----------------------------------------\n\nTITLE: Transforming concat with remap\nDESCRIPTION: Replacing the `concat` transform with the `remap` transform. Concatenates fields into a single field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.concat]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n.date = join!([.month, .day, .year], \"/\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Delete Field From Array of Objects VRL\nDESCRIPTION: This VRL snippet removes the `ttl` field from each object within the `answers` array. It uses `map_values` to iterate through the array and `del` to remove the specified field from each object.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_6\n\nLANGUAGE: coffee\nCODE:\n```\n. = {\"answers\":[{\"class\":\"IN\",\"ttl\":\"264\"},{\"class\":\"IN\",\"ttl\":\"264\"}],\"other\":\"data\"}\n.answers = map_values(.answers) -> |value| { del(value.ttl); value }\n```\n\n----------------------------------------\n\nTITLE: Implementing Python HTTP Server\nDESCRIPTION: This Python script implements a simple HTTP server that mimics a downstream system for Vector to publish logs to. It supports dynamic status code changes via POST requests, logs request details, and handles zlib-compressed payloads.  It uses the `http.server` and `socketserver` modules, along with `json`, `threading` and `zlib` for functionality.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport http.server\nimport socketserver\nimport json\nimport threading\nimport zlib\nfrom http import HTTPStatus  # Import HTTP status codes\n\n# Global variable for the response code\nresponse_code = HTTPStatus.OK  # Default to 200 OK\n\nclass DebuggingHTTPRequestHandler(http.server.BaseHTTPRequestHandler):\n    \"\"\"\n    HTTP server for debugging.\n\n    - Responds with a dynamically controlled status code (default HTTPStatus.OK).\n    - Supports GET, POST, PUT, DELETE, and other HTTP methods.\n    - Allows changing the response code via a POST request to /set_status.\n    - Logs request headers and JSON payloads (supports zlib-compressed payloads).\n    \"\"\"\n\n    def do_GET(self):\n        \"\"\"Handles GET requests by returning the configured response code.\"\"\"\n        self.send_custom_response()\n\n    def do_POST(self):\n        \"\"\"Handles POST requests. Logs request details before checking the path.\"\"\"\n        json_data = self.log_request_details()\n        if self.path == \"/set_status\":\n            self.set_status(json_data)\n        elif self.path == \"/logs\":\n            self.send_custom_response()\n\n    def do_PUT(self):\n        \"\"\"Handles PUT requests.\"\"\"\n        self.send_custom_response()\n\n    def do_DELETE(self):\n        \"\"\"Handles DELETE requests.\"\"\"\n        self.send_custom_response()\n\n    def send_custom_response(self):\n        \"\"\"Send an HTTP response with the currently configured status code.\"\"\"\n        global response_code\n        self.send_response(response_code)\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        response = {\"status\": response_code, \"message\": f\"Responding with {response_code}\"}\n        self.wfile.write(json.dumps(response).encode())\n\n    def log_request_details(self):\n        \"\"\"Logs headers and JSON payload for all POST requests before processing.\"\"\"\n        content_length = int(self.headers.get('Content-Length', 0))\n        body = self.rfile.read(content_length)\n\n        print(\"\\n📥 Received POST request:\")\n        print(f\"🔗 Path: {self.path}\")\n        print(\"📜 Headers:\")\n        for key, value in self.headers.items():\n            print(f\"   {key}: {value}\")\n\n        if self.headers.get('Content-Encoding') == 'gzip':\n            print(\"❌ Error: Gzip compression is not supported.\")\n            self.send_response(HTTPStatus.BAD_REQUEST)\n            self.send_header(\"Content-type\", \"application/json\")\n            self.end_headers()\n            self.wfile.write(json.dumps({\"error\": \"Gzip compression is not supported.\"}).encode())\n            return None\n\n        if self.headers.get('Content-Encoding') == 'deflate':\n            try:\n                body = zlib.decompress(body)\n                print(\"🗜️ Payload was zlib-compressed. Decompressed successfully.\")\n            except zlib.error:\n                print(\"❌ Error decompressing zlib payload.\")\n                self.send_response(HTTPStatus.BAD_REQUEST)\n                self.send_header(\"Content-type\", \"application/json\")\n                self.end_headers()\n                self.wfile.write(json.dumps({\"error\": \"Invalid zlib-compressed data\"}).encode())\n                return None\n\n        try:\n            json_data = json.loads(body.decode())\n            print(\"📦 JSON Payload:\", json.dumps(json_data, indent=2))\n            return json_data\n        except json.JSONDecodeError:\n            print(\"⚠️  No valid JSON payload received.\")\n            self.send_response(HTTPStatus.BAD_REQUEST)\n            self.send_header(\"Content-type\", \"application/json\")\n            self.end_headers()\n            self.wfile.write(json.dumps({\"error\": \"Invalid zlib-compressed data\"}).encode())\n            return None\n\n    def set_status(self, json_data):\n        \"\"\"Handles POST /set_status to update the response code dynamically.\"\"\"\n        global response_code\n\n        if json_data is None:\n            self.send_response(HTTPStatus.BAD_REQUEST)\n            response = {\"error\": \"Invalid request format. Send JSON with {'status': <code>}.\"}\n        else:\n            try:\n                new_status = int(json_data.get(\"status\", HTTPStatus.OK))\n                if HTTPStatus.CONTINUE <= new_status <= HTTPStatus.NETWORK_AUTHENTICATION_REQUIRED:\n                    response_code = new_status\n                    self.send_response(HTTPStatus.OK)\n                    response = {\"message\": f\"Response code updated to {response_code}\"}\n                else:\n                    self.send_response(HTTPStatus.BAD_REQUEST)\n                    response = {\"error\": \"Invalid status code. Must be between 100 and 599.\"}\n            except ValueError:\n                self.send_response(HTTPStatus.BAD_REQUEST)\n                response = {\"error\": \"Invalid status code format.\"}\n\n        self.send_header(\"Content-type\", \"application/json\")\n        self.end_headers()\n        self.wfile.write(json.dumps(response).encode())\n\ndef run_server(port):\n    \"\"\"Starts the HTTP server on the specified port.\"\"\"\n    handler = DebuggingHTTPRequestHandler\n    with socketserver.TCPServer((\"\", port), handler) as httpd:\n        print(f\"🚀 Serving on port {port}\")\n        httpd.serve_forever()\n\nif __name__ == \"__main__\":\n    port = 8000\n    server_thread = threading.Thread(target=run_server, args=(port,), daemon=True)\n    server_thread.start()\n\n    try:\n        while True:\n            pass\n    except KeyboardInterrupt:\n        print(\"\\n🛑 Server shutting down.\")\n```\n\n----------------------------------------\n\nTITLE: JMX Metrics Source Configuration\nDESCRIPTION: This TOML snippet defines the configuration for a JMX metrics source in Vector. It includes settings for the endpoint, authentication credentials, scrape interval, and namespace. The endpoint specifies the JMX webserver address to scrape.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-28-3642-jmx_rfc.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.my_source_id]\n  type = \"jmx_metrics\" # required\n  endpoint = \"service:jmx:rmi:///jndi/rmi://127.0.0.1:1234/jmxrmi\" # required - address of the JMX webserver to scrape.\n  username = \"user\" # optional - username for any JMX authentication.\n  password = \"password\" # optional - password for any JMX authentication.\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"jmx\" # optional, default is \"jmx\", namespace to put metrics under\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS with Multiple CAs in Vector\nDESCRIPTION: This TOML configuration snippet demonstrates how to enable TLS for a socket source in Vector and specify the path to a `.pem` file containing multiple certificate chains. The `tls.ca_path` option now supports more complex PEM files, simplifying the process of setting up secure communication.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-27-add-support-for-loading-multiple-cas.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.tls]\n  type = \"socket\"\n  address = \"0.0.0.0:6514\"\n  mode = \"tcp\"\n  tls.enabled = true\n  tls.crt_path = \"cert.pfx\"\n  tls.ca_path = \"ca.pem\" # Now supported: More complicated PEMS!\n  tls.verify_certificate = true\n```\n\n----------------------------------------\n\nTITLE: Example Server Error Message (GZIP Compression)\nDESCRIPTION: This snippet showcases a server-side error message indicating that GZIP compression is not supported. The message is displayed when Vector attempts to send data compressed with GZIP to a server that only accepts ZLIB. It provides details about the request and the specific error encountered.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_19\n\nLANGUAGE: text\nCODE:\n```\n📥 Received POST request:\n🔗 Path: /logs\n📜 Headers:\n  content-type: application/json\n  content-encoding: gzip\n  accept-encoding: zstd,gzip,deflate,br\n  user-agent: Vector/0.45.0-custom-bac0c2015 (aarch64-apple-darwin debug=full)\n  host: localhost:8000\n  content-length: 76\n❌ Error: Gzip compression is not supported.\n  127.0.0.1 - - [12/Feb/2025 11:10:22] \"POST /logs HTTP/1.1\" 400 -\n```\n\n----------------------------------------\n\nTITLE: Vector Syslog Source TOML Configuration\nDESCRIPTION: A Vector configuration snippet defining a syslog source, extracted into a separate file.  This demonstrates configuration splitting by component type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\ntype = \"syslog\"\naddress = \"0.0.0.0:514\"\nmax_length = 42000\nmode = \"tcp\"\n```\n\n----------------------------------------\n\nTITLE: VRL Iteration Sneak Preview\nDESCRIPTION: This example provides a sneak preview of the upcoming iteration support in VRL, showcasing the `map` function and how lexical scoping affects variable access within closure blocks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_13\n\nLANGUAGE: coffee\nCODE:\n```\ndata = { ”foo”: 1, ”bar”: 2 }\n\nmap(data) -> |key, value| {\n  new_key = upcase(key)\n\n  [new_key, value + 1]\n}\n\ndata # returns { ”FOO”: 2, ”BAR”: 3 }\n\nnew_key # returns a compile-time error, because ”new_key” is a variable scoped\n        # to the enumeration closure block\n```\n\n----------------------------------------\n\nTITLE: Example JSON Schema Document\nDESCRIPTION: This JSON snippet shows an example of the generated JSON schema for `SinkConfig`. It demonstrates the structure, properties, and constraints that can be defined for configuration types. It highlights features like aliasing, deprecation, field constraints (minimum/maximum values), common definitions, custom metadata, and default values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"$schema\": \"https://json-schema.org/draft/2020-12/schema#\",\n  \"title\": \"SinkConfig\",\n  \"type\": \"object\",\n  \"oneOf\": [\n    { \"required\": [\"endpoint\"] },\n    { \"required\": [\"url\"] }\n  ],\n  \"properties\": {\n    \"endpoint\": {\n      \"description\": \"The endpoint to send requests to.\",\n      \"type\": \"string\",\n      \"format\": \"uri\"\n    },\n    \"url\": {\n      \"description\": \"The endpoint to send requests to.\",\n      \"type\": \"string\",\n      \"format\": \"uri\",\n      \"deprecated\": true\n    },\n    \"batch\": {\n      \"allOf\": [{ \"$ref\": \"#/definitions/BatchSettings\" }],\n      \"properties\": {\n        \"max_events\": {\n          \"type\": [\n            \"null\",\n            \"number\"\n          ],\n          \"maximum\": 1000\n        }\n      },\n      \"default\": {\n        \"max_bytes\": 1048576,\n        \"max_events\": 1000,\n        \"max_timeout\": 60\n      }\n    }\n  },\n  \"_metadata\": {\n    \"status\": \"beta\"\n  },\n  \"definitions\": {\n    \"BatchSettings\": {\n      \"description\": \"Controls batching behavior.\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"max_bytes\": {\n          \"description\": \"Maximum number of bytes per batch.\",\n          \"type\": [\n            \"null\",\n            \"integer\"\n          ],\n          \"minimum\": 1,\n          \"maximum\": 4294967296\n        },\n        \"max_events\": {\n          \"description\": \"Maximum number of events per batch.\",\n          \"type\": [\n            \"null\",\n            \"integer\"\n          ],\n          \"minimum\": 1,\n          \"maximum\": 4294967296\n        },\n        \"max_timeout\": {\n          \"description\": \"Maximum period of time a batch can exist before being forcibly flushed.\",\n          \"anyOf\": [\n            { \"type\": \"null\" },\n            { \"$ref\": \"#/definitions/duration\" }\n          ],\n          \"minimum\": 1\n        }\n      }\n    },\n    \"duration\": {\n      \"type\": \"number\",\n      \"minimum\": 0,\n      \"maximum\": 9007199254740991\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector with a Configuration File\nDESCRIPTION: This command-line instruction shows how to start Vector using a specified configuration file. It allows users to launch Vector with their defined settings, sources, transforms, and sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nvector --config path/to/config.yaml\n```\n\n----------------------------------------\n\nTITLE: Remap transform with `find_table_row` VRL function\nDESCRIPTION: This remap transform uses the `find_table_row` VRL function to enrich events with data from the specified CSV enrichment table. It first parses a JSON message, then attempts to find a row in the `enrichment_tables.csv_file` based on the 'license_plate' field in the event. If a matching row is found, the 'first_name' and 'last_name' fields from the row are added to the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-20-8288-csv-enrichment.md#_snippet_1\n\nLANGUAGE: vrl\nCODE:\n```\n        . = parse_json!(.message)\n\n        result, err = find_table_row(\n            enrichment_tables.csv_file,\n            { \"license_plate\": .license }\n        )\n\n        if is_null(err) {\n            .first_name = result.first_name\n            .last_name = result.last_name\n        }\n```\n\n----------------------------------------\n\nTITLE: Syslog Parsed JSON Example (New)\nDESCRIPTION: This JSON shows the new format of parsed syslog data, where structured data is represented as a flat map of string key / string value under a field with the name of the structured data element.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"appname\": \"2d4d9490-794a-4e60-814c-5597bd5b7b7d\",\n  \"exampleSDID@32473\": {\n    \"foo.baz\": \"bar\"\n  },\n  \"facility\": \"kern\",\n  \"hostname\": \"Gregorys-MacBook-Pro.local\",\n  \"message\": \"test message\",\n  \"procid\": 79978,\n  \"severity\": \"alert\",\n  \"timestamp\": \"2022-04-25T23:21:45.715740Z\",\n  \"version\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Wrong HTTP Config (First Run)\nDESCRIPTION: This snippet executes Vector with a configuration that points to an incorrect HTTP endpoint. It pipes the content of `five-lines-first` to Vector, setting various log levels using the `VECTOR_LOG` environment variable, and using the `config-wrong-http.toml` configuration file. The expected output is Vector attempting to send data to the incorrect endpoint and eventually failing, as shown by the 'Connection refused' errors in the logs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069/\ntotal 0\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-first | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-v0.20.0 -c ./config-wrong-http.toml\n2022-04-06T05:04:13.849578Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\"\n2022-04-06T05:04:13.849653Z  INFO vector::app: Loading configs. paths=[\"config-wrong-http.toml\"]\n2022-04-06T05:04:13.850709Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-04-06T05:04:13.878010Z  INFO vector::topology::running: Running healthchecks.\n2022-04-06T05:04:13.878042Z  INFO vector::topology::running: Starting source. key=stdin\n2022-04-06T05:04:13.878062Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-04-06T05:04:13.878061Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-04-06T05:04:13.878090Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"2a706a3 2022-02-11\"\n2022-04-06T05:04:13.878100Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-04-06T05:04:13.878254Z  INFO vector::shutdown: All sources have finished.\n2022-04-06T05:04:13.878259Z  INFO vector: Vector has stopped.\n2022-04-06T05:04:13.878295Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-04-06T05:04:13.879186Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-04-06T05:04:14.881161Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n...\n2022-04-06T05:04:16.884213Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-04-06T05:04:17.153507Z  INFO vector: Vector has quit.\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069/\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Apr  6 01:04 http_tarpit_id\n```\n\n----------------------------------------\n\nTITLE: Configuring network devices using globbing in TOML (example)\nDESCRIPTION: This TOML snippet shows an example of using globbing for selecting network devices. The network metrics would be gathered from network devices that match the provided pattern (in this example, any device starting with `eth`). This allows for a flexible configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-26-3191-host-metrics.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\nnetwork.devices = [ \"eth*\" ]\n```\n\n----------------------------------------\n\nTITLE: Update regex_parser config in vector.toml\nDESCRIPTION: This code snippet demonstrates how to update the `regex_parser` configuration in the `vector.toml` file to use the `patterns` field instead of the `regex` field. This change is required to avoid a deprecation warning and utilize the new RegexSet functionality for efficient multiple regex processing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-13-add-regexset-support-to-regex.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [transforms.example]\n   type = \"regex_parser\"\n-  regex = \"...\"\n+  patterns = [\n+    \"...\",\n+    # Any new regexes you might want!\n+  ]\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Lock Time Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics to track the amount of time MongoDB databases have held the global lock, measured in microseconds. The metrics are differentiated by database and lock type (read/write).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_5\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_locks_time_locked_global_microseconds_total amount of time in microseconds that any database has held the global lock\n# TYPE mongodb_mongod_locks_time_locked_global_microseconds_total counter\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Collection\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Collection\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Database\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Database\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Global\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Global\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Mutex\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"Mutex\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"ReplicationStateTransition\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"ReplicationStateTransition\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"oplog\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_global_microseconds_total{database=\"oplog\",type=\"write\"} 0\n```\n\n----------------------------------------\n\nTITLE: Example Event Root (With Namespacing) JSON\nDESCRIPTION: This JSON shows the event root (`.`) of a log event from the `datadog_agent` source after log namespacing is enabled. The event root now contains only the event data itself, such as the `foo` and `bar` fields.  Metadata is stored separately.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"foo\": \"foo field\",\n  \"bar\": \"bar field\"\n}\n```\n\n----------------------------------------\n\nTITLE: Upgrading Vector Agent Helm Chart\nDESCRIPTION: This snippet demonstrates how to upgrade the `vector-agent` chart from the Vector Helm repository using the `helm upgrade` command.  It specifies the release name (`vector`), the chart name (`vector/vector-agent`), and additional flags to install the chart into the `vector` namespace and reuse previous values (`--reuse-values`).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-helm-vector-dev.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nhelm upgrade vector vector/vector-agent \\\n  --namespace vector \\\n  --reuse-values\n```\n\n----------------------------------------\n\nTITLE: Remap Transform Configuration in TOML\nDESCRIPTION: This snippet demonstrates a basic configuration for the `remap` transform within a Vector pipeline. It defines an input, the transform type, and a multi-line string containing the mapping logic. The mapping logic assigns values to fields within the event, performs arithmetic, and evaluates boolean expressions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.mapper]\n  inputs = [ \"foo\" ]\n  type = \"remap\"\n  mapping = \"\"\"\n.foo = \\\"hello\\\"\n.bar = .bar + 10\n.baz_is_large = .baz > 10\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Data with VRL Script\nDESCRIPTION: This VRL code snippet demonstrates how to access different parts of an event when log namespacing is enabled. It shows how to access the event root, fields from the event, all metadata, specific tags, and the ingest timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_5\n\nLANGUAGE: coffee\nCODE:\n```\nevent = .\nfield_from_event = .foo\n\nall_metadata = %\ntags = %datadog_agent.ddtags\ntimestamp = %vector.ingest_timestamp\n\n```\n\n----------------------------------------\n\nTITLE: Example JSON Log Data\nDESCRIPTION: This JSON snippet represents a common-log (Apache) coming from Docker.  It includes fields such as time, stream, and the log message. The log field contains data to be parsed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"time\": \"2021-02-03T21:13:54.713161211Z\",\n  \"stream\": \"stdout\",\n  \"log\": \"5.86.210.12 - zieme4647 [03/Feb/2021:21:13:55 -0200] \\\"GET /embrace/supply-chains/dynamic/vertical HTTP/1.0\\\" 201 20574\"\n}\n```\n\n----------------------------------------\n\nTITLE: Alternative Configuration with Dedicated Datadog Sources in TOML\nDESCRIPTION: This TOML configuration demonstrates an alternative approach using dedicated source types for each Datadog data type: `datadog_logs`, `datadog_metrics`, and `datadog_traces`. Each source listens on a separate address and routes data to its corresponding sink. The `inputs` parameter defines the source for each sink, and the `console` sink is used for debugging.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-03-9862-ingest-apm-stats-along-traces-in-dd-agent-source.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sources.dd_in_logs]\n  type = \"datadog_logs\"\n  address = \"[::]:8081\"\n\n[sources.dd_in_metrics]\n  type = \"datadog_metrics\"\n  address = \"[::]:8082\"\n\n[sources.dd_in_traces]\n  type = \"datadog_traces\"\n  address = \"[::]:8083\"\n\n[sinks.dd_traces]\n  type = \"datadog_traces\"\n  inputs = [\"dd_in_traces\" ]\n\n[sinks.dd_out_logs]\n  type = \"datadog_logs\"\n  inputs = [\"dd_in_logs\"]\n\n[sinks.dd_out_metrics]\n  type = \"datadog_metrics\"\n  inputs = [\"dd_in_metrics\"]\n\n[sinks.debug]\n  type = \"console\"\n  inputs = [\"dd_in_*\"]\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Updating Vector Agent via Helm\nDESCRIPTION: Updates an existing Vector Agent deployment using Helm, ensuring the repository is up-to-date and reusing the previous values during the upgrade.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nhelm repo update && \\\nhelm upgrade vector vector/vector \\\n  --namespace vector \\\n  --reuse-values\n```\n\n----------------------------------------\n\nTITLE: Pull Vector Docker image (Shell)\nDESCRIPTION: This command pulls the latest Vector Docker image with the specified version and Debian distribution from Docker Hub. This allows for running Vector in a containerized environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ndocker pull timberio/vector:{{< version >}}-debian\n```\n\n----------------------------------------\n\nTITLE: Run Vector with Syslog Configuration\nDESCRIPTION: This shell command runs Vector with the advanced Syslog configuration, processing the generated Syslog data and outputting it to the console. It assumes the `vector.yaml` file is in the current directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nvector --config ./vector.yaml\n```\n\n----------------------------------------\n\nTITLE: VRL Program Log Event Input (TOML)\nDESCRIPTION: This example demonstrates how to use a VRL program to construct a log event as input to a Vector unit test. This allows for complex and dynamic log event creation based on VRL logic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\n[[tests.inputs]]\n  insert_at = \"canary\"\n  type = \"vrl\"\n  source = \"\"\"\n    . = {\"a\": {\"b\": \"c\"}, \"d\": now()}\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Transforming remove_fields with remap\nDESCRIPTION: Replacing the `remove_fields` transform with the `remap` transform. Removes specified fields from an event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remove_fields]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\ndel(.parent.child)\n'''\n```\n\n----------------------------------------\n\nTITLE: Configuring aws_ec2_metadata Transform in TOML\nDESCRIPTION: This configuration example demonstrates how to use the `aws_ec2_metadata` transform in Vector. It specifies the transform's type, input source, and a whitelist of fields to include from the EC2 metadata. The `fields` option allows for selective enrichment, improving performance and reducing unnecessary data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-12-16-ec2-metadata.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.fill_me_up]\n  type = \"aws_ec2_metadata\"\n  inputs = [\"my-source-id\"]\n  fields = [\n    \"instance-id\",\n    \"local-hostname\",\n    \"public-hostname\",\n    \"public-ipv4\",\n    \"ami-id\",\n    \"availability-zone\",\n    \"region\",\n  ]\n```\n\n----------------------------------------\n\nTITLE: Configuring hostMetrics Source in Vector Helm Chart\nDESCRIPTION: This YAML snippet demonstrates how to configure a `host_metrics` source using the `customConfig` option in the Helm chart's `values.yaml` file. It configures the `host_metrics` source to collect host-level metrics. The `vector-agent` chart automatically sets the `PROCFS_ROOT` and `SYSFS_ROOT` environment variables.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sources:\n    ...\n    host_metrics:\n      type: host_metrics\n      filesystem:\n        devices:\n          excludes: [\"binfmt_misc\"]\n        filesystems:\n          excludes: [\"binfmt_misc\"]\n        mountPoints:\n          excludes: [\"*/proc/sys/fs/binfmt_misc\"]\n  ...\n```\n\n----------------------------------------\n\nTITLE: Configuring prometheusSink in Vector Helm Chart\nDESCRIPTION: This YAML snippet shows how to configure a `prometheus_exporter` sink using the `customConfig` option within the Helm chart's `values.yaml` file. It configures the `prometheus_exporter` sink to expose metrics in Prometheus format.  Also shown is the `extraContainerPorts` configuration required to expose the metrics endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sinks:\n    ...\n    prometheus_sink:\n      type: prometheus_exporter\n      inputs: [\"host_metrics\", \"internal_metrics\"]\n      address: 0.0.0.0:9090\n  ...\nextraContainerPorts:\n  - name: http\n    port: 9090\n    protocol: TCP\n    targetPort: 9090\n```\n\n----------------------------------------\n\nTITLE: Lua Setup Code: Initialization\nDESCRIPTION: This snippet represents the initialization part of a Lua script, executed only once. It uses io.popen to get the hostname.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_2\n\nLANGUAGE: lua\nCODE:\n```\nlocal f = io.popen (\"/bin/hostname\")\nlocal hostname = f:read(\"*a\") or \"\"\nf:close()\nhostname = string.gsub(hostname, \"\\n$\", \"\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Indexed Fields in Splunk HEC Sink TOML\nDESCRIPTION: This code snippet shows how to configure the `splunk_hec` sink to index specific fields using the `indexed_fields` configuration option in the `vector.toml` file. It sets the `indexed_fields` parameter to an array containing the strings \"foo\" and \"bar\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-20-splunk-hec-specify-indexed-fields.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my_sink_id]\n  type = \"splunk_hec\"\n  inputs = [\"my-source-id\"]\n+  indexed_fields = [\"foo\", \"bar\"]\n```\n\n----------------------------------------\n\nTITLE: Tailing Vector Logs (Initd)\nDESCRIPTION: This command is used to tail the Vector log file when Vector is managed by Initd, allowing for real-time monitoring of log messages. It requires `tail` utility to be available and the user to have read permissions on the log file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntail -f /var/log/vector.log\n```\n\n----------------------------------------\n\nTITLE: Using Vector with JSON config\nDESCRIPTION: This command demonstrates how to start Vector using a JSON configuration file. The `--config` flag specifies the path to the configuration file, and Vector infers the format from the file extension.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-11-25-json-yaml-config-formats.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector --config /etc/vector/vector.json\n```\n\n----------------------------------------\n\nTITLE: Vector Buffer Migration Test - v0.18.1 to v0.20.0\nDESCRIPTION: This test simulates a Vector upgrade from version 0.18.1 to a version identified as `vector-pr`, which is likely a development or pull request build, and reports itself as version 0.20.0. It verifies the buffer directory migration from `http_tarpit_buffer` to `http_tarpit_id`. The test uses `create-clean-data-directories.sh` to ensure a consistent starting point. The test also checks that `ls -l` show correct buffer directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-10895$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 0\ntoby@consigliere:~/src/vector/testing/github-10895$ ./vector-v0.18.1 --config config.toml\n2022-01-26T22:20:57.412384Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info\"\n2022-01-26T22:20:57.412428Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T22:20:57.414343Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T22:20:57.447157Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T22:20:57.447189Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T22:20:57.447211Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T22:20:57.447245Z  INFO vector: Vector has started. debug=\"false\" version=\"0.18.1\" arch=\"x86_64\" build_id=\"c4adb60 2021-11-30\"\n2022-01-26T22:20:57.447255Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-01-26T22:20:57.447245Z  INFO vector::topology::builder: Healthcheck: Passed.\n^C2022-01-26T22:20:58.292801Z  INFO vector: Vector has stopped.\n2022-01-26T22:20:58.292844Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T22:20:58.293936Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 26 17:20 http_tarpit_buffer\ntoby@consigliere:~/src/vector/testing/github-10895$ ./vector-pr --config config.toml\n2022-01-26T22:21:06.698724Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-26T22:21:06.698761Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T22:21:06.699272Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T22:21:06.699295Z  INFO vector_buffers::disk: Migrated old buffer data directory from '/tmp/vector/github-10895/http_tarpit_buffer' to '/tmp/vector/github-10895/http_tarpit_id' for 'http_tarpit' sink.\n2022-01-26T22:21:06.728976Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T22:21:06.728997Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T22:21:06.729017Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-26T22:21:06.729027Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T22:21:06.729060Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"none\"\n^C2022-01-26T22:21:07.388780Z  INFO vector: Vector has stopped.\n2022-01-26T22:21:07.388822Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T22:21:07.389894Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 26 17:21 http_tarpit_id\ntoby@consigliere:~/src/vector/testing/github-10895$\n```\n\n----------------------------------------\n\nTITLE: Add Fields to Objects in Array VRL\nDESCRIPTION: This VRL snippet iterates through an array of objects (`items`) and adds the `foo` field from the parent object to each object in the array. It copies `foo` and sets it to each iterated object within the items array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_10\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"foo\": \"bar\", \"items\": [{}, {}] }\n.items = map_values(.items) -> |value| { value.foo = .foo; value }\n```\n\n----------------------------------------\n\nTITLE: MongoDB Op Counters Replication Metrics - Prometheus\nDESCRIPTION: This snippet captures the number of replication operations performed by MongoDB, categorized by type. It is useful for analyzing replication activity and load on replica sets.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_31\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_op_counters_repl_total The opcountersRepl data structure, similar to the opcounters data structure, provides an overview of database replication operations by type and makes it possible to analyze the load on the replica in more granular manner. These values only appear when the current host has replication enabled\n# TYPE mongodb_op_counters_repl_total counter\nmongodb_op_counters_repl_total{type=\"command\"} 0\nmongodb_op_counters_repl_total{type=\"delete\"} 0\nmongodb_op_counters_repl_total{type=\"getmore\"} 0\nmongodb_op_counters_repl_total{type=\"insert\"} 0\nmongodb_op_counters_repl_total{type=\"query\"} 0\nmongodb_op_counters_repl_total{type=\"update\"} 0\n```\n\n----------------------------------------\n\nTITLE: Configuring ACL for GCP Cloud Storage Sink\nDESCRIPTION: This code snippet shows how to explicitly configure the Access Control List (ACL) for the Google Cloud Storage sink in Vector's configuration file. The `acl` option allows you to specify the desired ACL for the objects created in the bucket. Replace `projectPrivate` with the desired ACL value as per GCP documentation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-09-make-acl-optional.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.gcp_cloud_storage]\n  type = \"gcp_cloud_storage\"\n  acl = \"projectPrivate\" # change as desired\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Buffer Size Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus gauge metric representing the current size of the contents of the oplog buffer during replication in MongoDB.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_21\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_buffer_size_bytes sizeBytes reports the current size of the contents of the oplog buffer\n# TYPE mongodb_mongod_metrics_repl_buffer_size_bytes gauge\nmongodb_mongod_metrics_repl_buffer_size_bytes 0\n```\n\n----------------------------------------\n\nTITLE: Example JSON Before IP Alert Enrichment\nDESCRIPTION: This JSON represents the input data before enrichment for the IP alert use case. It contains fields like 'host', 'timestamp', and 'ip'. The 'ip' field contains the IP address that will be used for lookup.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_5\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"host\":\"my.host.com\",\n  \"timestamp\":\"2019-11-01T21:15:47+00:00\",\n  ...\n  \"ip\":\"192.0.2.0\",\n}\n```\n\n----------------------------------------\n\nTITLE: Example Log Events in JSON\nDESCRIPTION: This snippet shows an example of incoming log events in JSON format. These events contain fields like 'host', 'message', and 'timestamp', which can be used with the `throttle` transform to manage event flow.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-12-event-throttle-transform.md#_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n[\n  {\"host\":\"host-1.hostname.com\",\"message\":\"First message\",\"timestamp\":\"2020-10-07T12:33:21.223543Z\"},\n  {\"host\":\"host-1.hostname.com\",\"message\":\"Second message\",\"timestamp\":\"2020-10-07T12:33:21.223543Z\"}\n]\n```\n\n----------------------------------------\n\nTITLE: Convert Object to Specific String Format VRL\nDESCRIPTION: This VRL snippet converts an object to a specific string format by joining key-value pairs. It iterates through the object using `for_each`, encodes each value as JSON using `encode_json`, and combines each `key` and the encoded value into a string using `key + \"=\" + encode_json(value)`. The resulting strings are added to a string array, which are then joined with a comma and enclosed in curly braces.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_20\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"key1\": \"value1\", \"key2\": \"value2\" }\nstrings = []\nfor_each(.) -> |key, value| { strings = push(strings, key + \"=\" + encode_json(value)) }\n\n\"{\" + join(strings, \",\") + \"}\"\n```\n\n----------------------------------------\n\nTITLE: Migrate Vector Helm `values.yaml` Configuration\nDESCRIPTION: This code snippet demonstrates how to migrate configuration from the deprecated `rawConfig` option in Vector Helm charts to the new YAML-based configuration. It involves moving configuration parameters from within the `rawConfig` block to the same level as `type`, `inputs`, etc. The `values.yaml` file is updated to reflect the new configuration structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-06-01-removing-helm-rawconfig.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n   sources:\n     dummy:\n       type: \"generator\"\n-      rawConfig: |\n-        format = \"shuffle\"\n-        lines = [\"Hello world\"]\n-        interval = 60 # once a minute\n+      format: \"shuffle\"\n+      lines: [\"Hello world\"]\n+      interval: 60 # once a minute\n\n   sinks:\n     stdout:\n       type: \"console\"\n       inputs: [\"dummy\"]\n-      rawConfig: |\n-        target = \"stdout\"\n-        encoding.codec = \"json\"\n+      target: \"stdout\"\n+      encoding.codec: \"json\"\n```\n\n----------------------------------------\n\nTITLE: Transforming key_value_parser with remap\nDESCRIPTION: Replacing the `key_value_parser` transform with the `remap` transform. Parses key-value formatted messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.key_value_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= parse_key_value!(.message)\n'''\n```\n\n----------------------------------------\n\nTITLE: Bash script to generate metrics in JSON format\nDESCRIPTION: This bash script generates a JSON payload containing a metric with a random value.  It is used in conjunction with the `exec` source configured to use the `native_json` codec.  The script uses `jq` to format the output into a compact JSON object representing a counter metric.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-31-native-event-codecs.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n#!/usr/bin/env bash\n\necho $RANDOM | jq --raw-input --compact-output \\\n'{\n  metric: {\n    name: \"my_metric\",\n    counter: {\n      value: .|tonumber\n    },\n    kind: \"incremental\",\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Update splunk_hec host field to host key in vector.toml\nDESCRIPTION: This snippet demonstrates the required change in the `vector.toml` configuration file when upgrading to Vector v0.9.0 or later. The `host_field` option under the `splunk_hec` source is replaced with `host_key`. This ensures the host is properly identified by Splunk.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-12-rename-host_field-to-host_key.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.splunk]\n  type = \"splunk_hec\"\n-  host_field = \"host\"\n+  host_key = \"host\"\n```\n\n----------------------------------------\n\nTITLE: Throttle Transform Configuration in TOML\nDESCRIPTION: This snippet demonstrates the configuration of the `throttle` transform in TOML format. It defines the transform's type, input source, threshold (maximum number of events allowed per window), and window duration in seconds. This configuration will limit the number of events from 'my-source-or-transform-id'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-12-event-throttle-transform.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.my_transform_id]\ntype = \"throttle\"\ninputs = [ \"my-source-or-transform-id\" ]\nthreshold = 1\nwindow_secs = 60\n```\n\n----------------------------------------\n\nTITLE: VRL Collection Mapping Examples\nDESCRIPTION: This snippet demonstrates the usage of VRL's new iteration functions (map_keys, map_values, and for_each) for transforming a JSON object. It shows how to upcase keys, convert empty strings to null, and count the frequency of elements in an array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-18-vrl-iteration-support.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\n# 1. Upcase all keys in the object.\n. = map_keys(., recursive: true) -> |key| { upcase(key) }\n\n# 2. Change all empty string values to `null`.\n. = map_values(., recursive: true) -> |value| {\n  if value == ”” { null } else { value }\n}\n\n# 3. Count the frequency of elements in the `qux` array.\n.qux_tally = {}\nfor_each(.qux) -> |_index, value| {\n  tally = int(get!(.qux_tally, [value])) ?? 0\n\n  .qux_tally = set!(.qux_tally, [value], tally + 1)\n}\n```\n\n----------------------------------------\n\nTITLE: Kafka Bootstrap Servers Configuration Change (Diff)\nDESCRIPTION: This diff snippet highlights the modification needed in the `vector.toml` file to reflect the change in the `bootstrap_servers` field of the Kafka sink configuration. It shows the removal of the array format and the addition of the comma-separated string format. The diff includes the surrounding context of sink configuration details, like sink id and type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-12-use-comma-delim-server-list-instead-of-an-array.md#_snippet_1\n\nLANGUAGE: Diff\nCODE:\n```\n [sinks.my_sink_id]\n   type = \"kafka\"\n   inputs = [\"my-source-id\"]\n-  bootstrap_servers = [\"10.14.22.123:9092\", \"10.14.23.332:9092\"]\n+  bootstrap_servers = \"10.14.22.123:9092,10.14.23.332:9092\"\n```\n\n----------------------------------------\n\nTITLE: Map Key/Value Pairs to Object Array VRL\nDESCRIPTION: This VRL snippet transforms an object with key-value pairs into an array of objects, where each object in the array has `key` and `value` fields. It iterates through the original object using `for_each` and pushes a new object with the key and value into the `new_labels` array. Finally, it reassigns `.labels` to hold the `new_labels`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_18\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"labels\": { \"key1\": \"value1\", \"key2\": \"value2\" } }\nnew_labels = []\nfor_each(.labels) -> |key, value| {\n  new_labels = push(new_labels, { \"key\": key, \"value\": value })\n}\n\n.labels = new_labels\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Mcache Inuse Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes in use by mcache structures in Go.  This represents memory usage by the memory allocator.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_55\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.\n# TYPE go_memstats_mcache_inuse_bytes gauge\ngo_memstats_mcache_inuse_bytes 13888\n```\n\n----------------------------------------\n\nTITLE: VRL Function Definition: emit_counter\nDESCRIPTION: This snippet defines the syntax for an `emit_counter` function in VRL. This function will generate metrics, with parameters for namespace, name, timestamp, value, and kind.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_17\n\nLANGUAGE: text\nCODE:\n```\nemit_counter(namespace: String, name: String, timestamp: Timestamp, value: Float, kind: \"absolute\"|\"relative\")\n```\n\n----------------------------------------\n\nTITLE: Remove Prefix From Keys VRL\nDESCRIPTION: This VRL snippet recursively removes a specified prefix (`my_prefix_`) from all keys in an object. It uses the `map_keys` function with the `recursive: true` option and the `replace` function to remove the prefix from each key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_16\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_keys(. ,recursive: true) -> |key| { replace(key, \"my_prefix_\", \"\") }\n```\n\n----------------------------------------\n\nTITLE: Replacing VRL modulo operator\nDESCRIPTION: Demonstrates how to replace the deprecated modulo operator (%) with the mod() function in Vector's VRL. This change is necessary for upgrading to version 0.25.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\nmod(5, 2) == 1\n```\n\n----------------------------------------\n\nTITLE: JSON Example Output After Remap Transform\nDESCRIPTION: This JSON object represents the expected output after applying the `remap` transform with the `unnest` function to the example input. Each object in the original `events` array is now a separate event with the `host` field from the original input event. Each of these objects now becomes its own log event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"localhost\", \"message\": \"foo\" }\n{ \"host\": \"localhost\", \"message\": \"bar\" }\n```\n\n----------------------------------------\n\nTITLE: Component ID Structure - Rust\nDESCRIPTION: Defines the structure used to identify components within Vector, including a name and a scope (Global or Pipeline). This helps avoid naming conflicts between components in different pipelines.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nstruct ComponentId {\n    name: String,\n    scope: ComponentScope,\n}\n\nenum ComponentScope {\n    Global,\n    Pipeline(String),\n}\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration for Remap Transform with unnest (Mixed Types)\nDESCRIPTION: This TOML configuration applies the unnest VRL to extract events from the event array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\nsource = \"\"\"\n. = unnest(., \"events\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Socket Source GELF Configuration (Current) - YAML\nDESCRIPTION: This YAML configuration demonstrates the updated setup for a socket source using the GELF codec in Vector 0.40. It explicitly sets the framing method to 'character_delimited' with a newline delimiter to maintain the previous behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  my_source_id:\n    type: \"socket\"\n    address: \"0.0.0.0:9000\"\n    mode: \"tcp\"\n    decoding:\n      codec: \"gelf\"\n    framing:\n      method: \"character_delimited\"\n    character_delimited:\n      delimiter: \"\\n\"\n```\n\n----------------------------------------\n\nTITLE: Create S3 Bucket for Firehose Events (bash)\nDESCRIPTION: Creates an S3 bucket for Kinesis Firehose to write failed events to. The region is conditionally set if it's not `us-east-1`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ aws s3api create-bucket --bucket ${FIREHOSE_S3_BUCKET} \\\n    $(if [[ ${AWS_REGION} != \"us-east-1\" ]] ; then echo \"--create-bucket-configuration LocationConstraint=${AWS_REGION}\" ; fi)\n```\n\n----------------------------------------\n\nTITLE: Update Vector Sink Configuration TOML\nDESCRIPTION: This code snippet demonstrates how to update a Vector sink configuration from the old `encoding` option to the new `encoding.*` sub-options.  It shows how to set the `encoding.codec`, `encoding.except_fields`, and `encoding.timestamp_format` options within the `vector.toml` configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-04-encoding-only-fields-except-fields.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my-sink]\n  type = \"...\"\n-  encoding = \"json\"\n+  encoding.codec = \"json\"\n+  encoding.except_fields = [\"_meta\"] # optional\n+  encoding.timestamp_format = \"rfc3339\" # optional\n```\n\n----------------------------------------\n\nTITLE: Configuring a Memory Enrichment Table for Caching (YAML)\nDESCRIPTION: This YAML configuration demonstrates how to set up a `memory` enrichment table for caching data in Vector. It includes the table definition, a demo logs source, a transform to process the logs and interact with the cache, and a cache generator transform to populate the cache.  It defines the TTL (time-to-live) and flush interval for the table. Requires Vector to be installed and configured.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-memory_enrichment_table.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nenrichment_tables:\n  memory_table:\n    type: memory\n    ttl: 60\n    flush_interval: 5\n    inputs: [ \"cache_generator\" ]\n\nsources:\n  demo_logs_test:\n    type: \"demo_logs\"\n    format: \"json\"\n\ntransforms:\n  demo_logs_processor:\n    type: \"remap\"\n    inputs: [ \"demo_logs_test\" ]\n    source: |\n      . = parse_json!(.message)\n      user_id = get!(., path: [\"user-identifier\"])\n\n      # Check if we already have a cached value for this user in the enrichment table\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\": user_id })\n\n      if err == null {\n        # A cached value exists; reuse it.\n        # The `existing` object has this structure:\n        # { \"key\": user_id, \"value\": {...}, \"ttl\": 50 }\n        . = existing.value\n        .source = \"cache\"\n      } else {\n        # No cached value found, process the event and prepare new data\n        .referer = parse_url!(.referer)\n        .referer.host = encode_punycode!(.referer.host)\n        .source = \"transform\"\n\n  cache_generator:\n    type: \"remap\"\n    inputs: [ \"demo_logs_processor\" ]\n    source: |\n      # Check if this user is already in the cache\n      key_value = get!(., path: [\"user-identifier\"])\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\":  key_value })\n\n      if err != null {\n        # No cached value found, store the processed data in the enrichment table\n        data = .\n\n        # The memory enrichment table stores all key-value pairs it receives.\n        # To structure it correctly, we create an object where:\n        # - The key is the \"user-identifier\".\n        # - The value is the rest of the processed event data.\n        . = set!(value: {}, path: [get!(data, path: [\"user-identifier\"])], data: data)\n      } else {\n        # Already cached, do nothing\n        . = {}\n      }\n\n# After some time, processed events will start having their \"source\" set to \"cache\",\n# indicating that the data is being retrieved from the enrichment table.\nsinks:\n  console:\n    inputs: [ \"demo_logs_processor\" ]\n    target: \"stdout\"\n    type: \"console\"\n    encoding:\n      codec: \"json\"\n      json:\n        pretty: true\n```\n\n----------------------------------------\n\nTITLE: Migrate TCP Source to Socket Source in Vector TOML\nDESCRIPTION: This snippet shows the changes needed to migrate a TCP source to the new socket source in the Vector configuration file. The 'type' is changed from 'tcp' to 'socket', and the 'mode' is set to 'tcp'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-03-merge-existing-tcp-and-udp-sources-into-a-single-socket-source.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.my_tcp_source]\n-  type = \"tcp\"\n+  type = \"socket\"\n   address = \"0.0.0.0:9000\"\n+  mode = \"tcp\"\n```\n\n----------------------------------------\n\nTITLE: MongoDB Up Status Metric - Prometheus\nDESCRIPTION: This snippet indicates whether the MongoDB server is up and running. A value of 1 signifies that the server is operational.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_33\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_up Whether MongoDB is up.\n# TYPE mongodb_up gauge\nmongodb_up 1\n```\n\n----------------------------------------\n\nTITLE: Adding Encoding Configuration to Vector Sinks\nDESCRIPTION: This code snippet demonstrates the required change to the `vector.toml` file. It adds the `encoding.codec = \"json\"` option to both the `console` and `file` sinks to explicitly specify the encoding format. This configuration ensures that Vector can properly handle the data being written to the console and files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-10-21-require-encoding-option-for-console-and-file-sinks.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.console]\n  type = \"console\"\n+  encoding.codec = \"json\"\n\n[sinks.file]\n  type = \"file\"\n+  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Create IAM Role for CloudWatch Logs\nDESCRIPTION: Creates an IAM role named 'CWLtoKinesisFirehoseRole' that allows CloudWatch Logs to assume the role. This is necessary for CloudWatch Logs to write to a Firehose delivery stream. The AWS_REGION variable needs to be set.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ aws iam create-role \\\n      --role-name CWLtoKinesisFirehoseRole \\\n      --assume-role-policy-document file://<(cat <<EOF\n{\n  \"Statement\": {\n    \"Effect\": \"Allow\",\n    \"Principal\": { \"Service\": \"logs.${AWS_REGION}.amazonaws.com\" },\n    \"Action\": \"sts:AssumeRole\"\n  }\n}\nEOF\n)\n`\n```\n\n----------------------------------------\n\nTITLE: Running Python HTTP Server Command\nDESCRIPTION: This command starts the Python HTTP server implemented in `fake_server.py`. It's used to simulate a downstream system that Vector publishes logs to.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\npython3 fake_server.py\n```\n\n----------------------------------------\n\nTITLE: SinkConfig Implementation of Configurable Trait in Rust\nDESCRIPTION: This code demonstrates how to implement the `Configurable` trait for a custom `SinkConfig` struct in Rust. It defines the `SinkConfig` struct, implements the `Configurable` trait, and provides definitions for the `description`, `shape`, `metadata`, and `fields` methods.  This example shows how to define a configuration struct with nested fields, default values, and metadata.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Serialize, Deserialize, Clone)]\nstruct SinkConfig {\n    endpoint: String,\n    batch: BatchConfig,\n}\n\nimpl<'de> Configurable<'de> for SinkConfig {\n    fn description() -> Option<&'static str> {\n        Some(\"Configuration for the sink.\")\n    }\n\n    fn shape() -> Shape {\n        let mut required_fields = HashMap::new();\n        required_fields.insert(\"endpoint\", <String as Configurable>::shape());\n        required_fields.insert(\"batch\", <BatchConfig as Configurable>::shape());\n\n        Shape::Map(MapShape {\n            required_fields,\n            allowed_unknown_field_shape: None,\n        })\n    }\n\n    fn metadata() -> Metadata<Self> {\n        Metadata {\n            default: Some(SinkConfig {\n                endpoint: String::from(\"foo\"),\n                batch: BatchConfig::default(),\n            }),\n            ..Default::default()\n        }\n    }\n\n    fn fields(overrides: Metadata<Self>) -> Option<Vec<Field>> {\n        let shape = Self::shape();\n        let mut required_field_shapes = match shape {\n            Shape::Map(MapShape { required_fields, .. }) => required_fields.clone(),\n            _ => unreachable!(\"SinkConfig is a fixed-field object and cannot be another shape\"),\n        };\n\n        let base_metadata = <Self as Configurable>::metadata();\n        let merged_metadata = merge_metadata_overrides(base_metadata, overrides);\n\n        let endpoint_shape = required_field_shapes.remove(\"endpoint\").expect(\"shape for `endpoint` must exist\");\n        let endpoint_override_metadata = merged_metadata.clone()\n            .map_default_value(|default| default.endpoint.clone());\n\n        let batch_shape = required_field_shapes.remove(\"batch\").expect(\"shape for `batch` must exist\");\n        let batch_override_metadata = merged_metadata.clone()\n            .map_default_value(|default| default.batch.clone());\n\n        let mut fields = HashMap::new();\n        fields.insert(\"endpoint\", Field::new::<String>(\n            \"endpoint\",\n            \"The endpoint to send requests to.\",\n            endpoint_shape,\n            endpoint_override_metadata,\n        ));\n         fields.insert(\"batch\", Field::new::<BatchConfig>(\n            \"batch\",\n            <BatchConfig as Configurable>::description().expect(\"`BatchConfig` has no defined description, and an override description was not provided.\"),\n            batch_shape,\n            batch_override_metadata,\n        ));\n\n        Some(fields)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Vector S3 Archives Sink Configuration (YAML)\nDESCRIPTION: This YAML snippet shows a sink configuration for S3 Archives. The configuration sets the input to `apache_parser` and uses the `aws_s3` type. It also sets region, bucket, key prefix, compression, framing, encoding, and batch options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\n# Send structured data to a cost-effective long-term storage\ninputs:\n  - \"apache_parser\"           # don't sample for S3\ntype: \"aws_s3\"\nregion: \"us-east-1\"\nbucket: \"my-log-archives\"\nkey_prefix: \"date=%Y-%m-%d\"   # daily partitions, hive-friendly format\ncompression: \"gzip\"           # compress final objects\nframing:\n  method: \"newline_delimited\" # new line delimited...\nencoding:\n  codec: \"json\"               # ...JSON\nbatch:\n  max_bytes: 10000000         # 10mb uncompressed\n```\n\n----------------------------------------\n\nTITLE: Check Vector Version\nDESCRIPTION: This command checks the installed version of Vector, confirming that the installation was successful. It's a simple way to verify that Vector is correctly installed and accessible in your environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nvector --version\n```\n\n----------------------------------------\n\nTITLE: Transforming remove_tags with remap\nDESCRIPTION: Replacing the `remove_tags` transform with the `remap` transform. Removes specified tags from an event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_17\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remove_tags]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\ndel(.tags.some_tag)\n'''\n```\n\n----------------------------------------\n\nTITLE: Prometheus Exporter Metrics\nDESCRIPTION: This snippet defines various MongoDB metrics in Prometheus exposition format. Each metric includes a 'HELP' comment describing the metric, a 'TYPE' comment indicating its type (untyped in this case), and a line with the metric name, labels (host, hostname, version), and its current value.  It is intended to be ingested by a Prometheus collector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_68\n\nLANGUAGE: text\nCODE:\n```\n# TYPE mongodb_total_tickets_reads untyped\nmongodb_total_tickets_reads{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 128\n# HELP mongodb_total_tickets_writes Telegraf collected metric\n# TYPE mongodb_total_tickets_writes untyped\nmongodb_total_tickets_writes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 128\n# HELP mongodb_ttl_deletes Telegraf collected metric\n# TYPE mongodb_ttl_deletes untyped\nmongodb_ttl_deletes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_ttl_deletes_per_sec Telegraf collected metric\n# TYPE mongodb_ttl_deletes_per_sec untyped\nmongodb_ttl_deletes_per_sec{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_ttl_passes Telegraf collected metric\n# TYPE mongodb_ttl_passes untyped\nmongodb_ttl_passes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_ttl_passes_per_sec Telegraf collected metric\n# TYPE mongodb_ttl_passes_per_sec untyped\nmongodb_ttl_passes_per_sec{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_update_command_failed Telegraf collected metric\n# TYPE mongodb_update_command_failed untyped\nmongodb_update_command_failed{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_update_command_total Telegraf collected metric\n# TYPE mongodb_update_command_total untyped\nmongodb_update_command_total{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_updates Telegraf collected metric\n# TYPE mongodb_updates untyped\nmongodb_updates{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_updates_per_sec Telegraf collected metric\n# TYPE mongodb_updates_per_sec untyped\nmongodb_updates_per_sec{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_uptime_ns Telegraf collected metric\n# TYPE mongodb_uptime_ns untyped\nmongodb_uptime_ns{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 4.7167e+10\n# HELP mongodb_vsize_megabytes Telegraf collected metric\n# TYPE mongodb_vsize_megabytes untyped\nmongodb_vsize_megabytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 1547\n# HELP mongodb_wtcache_app_threads_page_read_count Telegraf collected metric\n# TYPE mongodb_wtcache_app_threads_page_read_count untyped\nmongodb_wtcache_app_threads_page_read_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_app_threads_page_read_time Telegraf collected metric\n# TYPE mongodb_wtcache_app_threads_page_read_time untyped\nmongodb_wtcache_app_threads_page_read_time{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_app_threads_page_write_count Telegraf collected metric\n# TYPE mongodb_wtcache_app_threads_page_write_count untyped\nmongodb_wtcache_app_threads_page_write_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_bytes_read_into Telegraf collected metric\n# TYPE mongodb_wtcache_bytes_read_into untyped\nmongodb_wtcache_bytes_read_into{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_bytes_written_from Telegraf collected metric\n# TYPE mongodb_wtcache_bytes_written_from untyped\nmongodb_wtcache_bytes_written_from{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_current_bytes Telegraf collected metric\n# TYPE mongodb_wtcache_current_bytes untyped\nmongodb_wtcache_current_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 28138\n# HELP mongodb_wtcache_internal_pages_evicted Telegraf collected metric\n# TYPE mongodb_wtcache_internal_pages_evicted untyped\nmongodb_wtcache_internal_pages_evicted{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_max_bytes_configured Telegraf collected metric\n# TYPE mongodb_wtcache_max_bytes_configured untyped\nmongodb_wtcache_max_bytes_configured{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 5.06462208e+08\n# HELP mongodb_wtcache_modified_pages_evicted Telegraf collected metric\n# TYPE mongodb_wtcache_modified_pages_evicted untyped\nmongodb_wtcache_modified_pages_evicted{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_pages_evicted_by_app_thread Telegraf collected metric\n# TYPE mongodb_wtcache_pages_evicted_by_app_thread untyped\nmongodb_wtcache_pages_evicted_by_app_thread{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_pages_queued_for_eviction Telegraf collected metric\n# TYPE mongodb_wtcache_pages_queued_for_eviction untyped\nmongodb_wtcache_pages_queued_for_eviction{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_pages_read_into Telegraf collected metric\n# TYPE mongodb_wtcache_pages_read_into untyped\nmongodb_wtcache_pages_read_into{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_pages_requested_from Telegraf collected metric\n# TYPE mongodb_wtcache_pages_requested_from untyped\nmongodb_wtcache_pages_requested_from{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 225\n# HELP mongodb_wtcache_server_evicting_pages Telegraf collected metric\n# TYPE mongodb_wtcache_server_evicting_pages untyped\nmongodb_wtcache_server_evicting_pages{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_tracked_dirty_bytes Telegraf collected metric\n# TYPE mongodb_wtcache_tracked_dirty_bytes untyped\nmongodb_wtcache_tracked_dirty_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 26225\n# HELP mongodb_wtcache_unmodified_pages_evicted Telegraf collected metric\n# TYPE mongodb_wtcache_unmodified_pages_evicted untyped\nmongodb_wtcache_unmodified_pages_evicted{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_wtcache_worker_thread_evictingpages Telegraf collected metric\n# TYPE mongodb_wtcache_worker_thread_evictingpages untyped\nmongodb_wtcache_worker_thread_evictingpages{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n```\n\n----------------------------------------\n\nTITLE: Configure HTTP sink with bearer token authentication - TOML\nDESCRIPTION: This snippet demonstrates how to configure an HTTP sink in Vector to use bearer token authentication.  It sets the auth.strategy to \"bearer\" and provides a hardcoded token. This approach is not recommended for production environments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-20-add-bearer-auth-strategy.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.example]\n   type = \"http\"\n+  auth.strategy = \"bearer\"\n+  auth.token = \"B14CK-L1V35-M4TT4R\"\n```\n\n----------------------------------------\n\nTITLE: Vector Buffer Migration Test - v0.18.1 to v0.19.1\nDESCRIPTION: This test simulates a Vector upgrade from version 0.18.1 to 0.19.1. It checks for the migration of the buffer directory from `http_tarpit_buffer` to `http_tarpit_id`. It relies on the `create-clean-data-directories.sh` script to ensure a clean state before each test run. The test also executes `ls -l` commands to verify the existence and permissions of buffer directories.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-10895$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 0\ntoby@consigliere:~/src/vector/testing/github-10895$ ./vector-v0.18.1 --config config.toml\n2022-01-26T22:20:16.979995Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info\"\n2022-01-26T22:20:16.980039Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T22:20:16.981919Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T22:20:17.010091Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T22:20:17.010121Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T22:20:17.010157Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T22:20:17.010155Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-26T22:20:17.010203Z  INFO vector: Vector has started. debug=\"false\" version=\"0.18.1\" arch=\"x86_64\" build_id=\"c4adb60 2021-11-30\"\n2022-01-26T22:20:17.010213Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n^C2022-01-26T22:20:17.627876Z  INFO vector: Vector has stopped.\n2022-01-26T22:20:17.627922Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T22:20:17.627952Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"stdin, http_tarpit\" time_remaining=\"59 seconds left\"\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 26 17:20 http_tarpit_buffer\ntoby@consigliere:~/src/vector/testing/github-10895$ ./vector-v0.19.1 --config config.toml\n2022-01-26T22:20:28.399808Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-26T22:20:28.399854Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T22:20:28.400532Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T22:20:28.400543Z  INFO buffers::disk: Migrated old buffer data directory from '/tmp/vector/github-10895/http_tarpit_buffer' to '/tmp/vector/github-10895/http_tarpit_id' for 'http_tarpit' sink.\n2022-01-26T22:20:28.430796Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T22:20:28.430824Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T22:20:28.430847Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T22:20:28.430849Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-26T22:20:28.430879Z  INFO vector: Vector has started. debug=\"false\" version=\"0.19.1\" arch=\"x86_64\" build_id=\"3cf70cf 2022-01-25\"\n2022-01-26T22:20:28.430891Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n^C2022-01-26T22:20:29.294516Z  INFO vector: Vector has stopped.\n2022-01-26T22:20:29.294605Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T22:20:29.295668Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\ntoby@consigliere:~/src/vector/testing/github-10895$ ls -l /tmp/vector/github-10895\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 26 17:20 http_tarpit_id\ntoby@consigliere:~/src/vector/testing/github-10895$\n```\n\n----------------------------------------\n\nTITLE: GreptimeDB Logs Sink TOML Configuration\nDESCRIPTION: This TOML configuration example demonstrates how to configure the `greptimedb_logs` sink with the `extra_headers` option. It defines the sink type, inputs, endpoint, table, and database name within the `sinks.greptime_logs` section. The custom headers are specified in a nested `extra_headers` table with the `x-source` header set to \"vector\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/changelog.d/22651_greptimedb_logs_headers.breaking.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.greptime_logs]\ntype = \"greptimedb_logs\"\ninputs = [\"my_source_id\"]\nendpoint = \"http://localhost:4000\"\ntable = \"demo_logs\"\ndbname = \"public\"\n\n[sinks.greptime_logs.extra_headers]\nx-source = \"vector\"\n```\n\n----------------------------------------\n\nTITLE: Updating Datadog Sink Configuration in TOML\nDESCRIPTION: This code snippet demonstrates the necessary change in the `vector.toml` configuration file to rename the `datadog` sink to `datadog_metrics`.  It uses a diff format to highlight the lines that need to be modified. No specific dependencies are required other than a `vector.toml` file using the old sink name.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-12-04-rename-datadog-sink-to-datadog_metrics.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.datadog]\n-  type = \"datadog\"\n+  type = \"datadog_metrics\"\n```\n\n----------------------------------------\n\nTITLE: Stopping Vector in Docker\nDESCRIPTION: Stops the Vector Docker container.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ndocker stop timberio/vector\n```\n\n----------------------------------------\n\nTITLE: Running Multiple Vector Unit Tests (Bash)\nDESCRIPTION: This command executes unit tests across multiple Vector configuration files, treating them as a single, unified configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvector test /etc/vector/pipeline1.toml /etc/vector/pipeline2.toml\n```\n\n----------------------------------------\n\nTITLE: Zero-Downtime Deployment: Sink Configuration Update\nDESCRIPTION: This code snippet illustrates the second step in a zero-downtime deployment, where the sink is updated to point to the new v2 source address and configured to use version 2. The old address is replaced with the new one, and the version is set to \"2\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-vector-source-sink.md#_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n  [sinks.vector]\n-   address = \"127.0.1.2:9000\"\n+   address = \"127.0.1.2:5000\"\n    type = \"vector\"\n+   version = \"2\"\n```\n\n----------------------------------------\n\nTITLE: Filtering with Schema Support\nDESCRIPTION: Demonstrates a simplified filtering example with schema support. The explicit type casting `string(ip)` is removed due to schema guarantees. The example filters `.ips` array, removing any IP address that starts with \"180.14\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_49\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n.ips = filter(.ips) -> |_, ip| !starts_with(ip, \"180.14\")\n```\n\n----------------------------------------\n\nTITLE: Configuring a Basic Vector Sink in Rust\nDESCRIPTION: This code defines the configuration struct for a basic Vector sink using the `configurable_component` attribute.  It includes a configuration option for acknowledgements, which allows the sink to inform upstream sources if events have been successfully delivered. The struct is also designed to be serializable and deserializable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n#[configurable_component(sink(\"basic\"))]\n#[derive(Clone, Debug)]\n/// A basic sink that dumps its output to stdout.\npub struct BasicConfig {\n    #[configurable(derived)]\n    #[serde(\n        default,\n        deserialize_with = \"crate::serde::bool_or_struct\",\n        skip_serializing_if = \"crate::serde::is_default\"\n    )]\n    pub acknowledgements: AcknowledgementsConfig,\n}\n```\n\n----------------------------------------\n\nTITLE: ConcurrencyLimit Service Implementation in Rust\nDESCRIPTION: This code snippet shows the `ConcurrencyLimit` service implementation in Rust. It implements the `Service` trait, managing request concurrency by acquiring permits and polling readiness of the inner service. It emits metrics related to concurrency limits.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nimpl Service<Request> for ConcurrencyLimit {\n    fn poll_ready(&mut self, cx: &mut Context) -> Poll<Result<(), Self::Error>> {\n        match self.limit.permit.poll_acquire(cx, &self.limit.semaphore) {\n            Ready(()) => (),\n            NotReady => {\n                emit!(ConcurrencyLimited);\n                return NotReady;\n            }\n            Err(err) => return Err(err),\n        }\n\n        Poll::Ready(ready!(self.inner.poll_ready(cx)))\n    }\n\n    fn call(&mut self, request: Request) -> Self::Future {\n        let future = self.inner.call(request);\n        ...\n        emit!(ConcurrencyLimit { concurrency: self.limit.maximum() });\n        emit!(ConcurrencyActual { concurrency: self.limit.used() });\n        ResponseFuture::new(future, self.limit.semaphore.clone(), Instant::now())\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Find Table Row with Predicate in CoffeeScript\nDESCRIPTION: This snippet demonstrates using a predicate (closure) to specify search criteria for finding a row in a table. The predicate `|row| row.some_key == .some_field` allows for complex filtering logic beyond simple equality. This functionality is not yet available in VRL and might pose performance challenges due to the difficulty of using indexes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-20-8288-csv-enrichment.md#_snippet_3\n\nLANGUAGE: coffeescript\nCODE:\n```\nfind_table_row(table.csv, |row| row.some_key == .some_field)\n```\n\n----------------------------------------\n\nTITLE: Install Vector Package via APT\nDESCRIPTION: Installs the `vector` package using the APT package manager. Requires the Vector repository to be added first. This command will download and install the latest version of Vector and any dependencies.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/apt.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get install vector\n```\n\n----------------------------------------\n\nTITLE: Configuring Datadog Agent Source and Sinks with Named Outputs in TOML\nDESCRIPTION: This TOML configuration demonstrates how to configure the `datadog_agent` source with named outputs and route different data types (traces, APM stats, logs, metrics) to their respective sinks. It uses the `datadog_traces`, `datadog_logs`, and `datadog_metrics` sinks to handle specific data types and a `console` sink for debugging. The `inputs` parameter specifies which source outputs each sink should receive.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-03-9862-ingest-apm-stats-along-traces-in-dd-agent-source.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.dd_agents]\n  type = \"datadog_agent\"\n  address = \"[::]:8081\"\n\n[sinks.dd_traces]\n  type = \"datadog_traces\"\n  inputs = [\"dd_agents.traces\", \"dd_agents.apm_stats\" ]\n\n[sinks.dd_logs]\n  type = \"datadog_logs\"\n  inputs = [\"dd_agents.logs\"]\n\n[sinks.dd_metrics]\n  type = \"datadog_metrics\"\n  inputs = [\"dd_agents.metrics\"]\n\n[sinks.debug]\n  type = \"console\"\n  # Optionally the non-suffixed name could receive everything, this will be configurable\n  inputs = [\"dd_agents\"]\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Throttle Transform Implementation - Rust\nDESCRIPTION: Implements the `TaskTransform` trait for the `Throttle` struct. This includes the `transform` function that handles the actual rate limiting logic by leveraging the Governor crate.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-09-21-9292-throttle-transform.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nimpl TaskTransform for Throttle {\n    fn transform(\n        self: Box<Self>,\n        mut input_rx: Pin<Box<dyn Stream<Item = Event> + Send>>,\n    ) -> Pin<Box<dyn Stream<Item = Event> + Send>>\n    where\n        Self: 'static,\n    {\n        let lim = RateLimiter::keyed(quota);\n\n        let mut flush_keys = tokio::time::interval(Duration::from_secs(self.window * 2));\n        let mut flush_stream = tokio::time::interval(Duration::from_millis(1000));\n\n        Box::pin(\n            stream! { \n              loop {\n                let mut output = Vec::new();\n                let done = tokio::select! {\n                    _ = flush_stream.tick() => {\n                        false\n                    }\n                    _ = flush_keys.tick() => {\n                      lim.retain_recent();\n                          false\n                    }\n                    maybe_event = input_rx.next() => {\n                        match maybe_event {\n                            None => true,\n                            Some(event) => {\n                    if let Some(condition) = self.exclude_as_ref() {\n                    if condition.check(&event) {\n                        output.push(event);\n                        false\n                    }\n                }\n\n                let value = self\n                    .key_field\n                    .as_ref()\n                    .and_then(|key_field| event.get(key_field))\n                    .map(|v| v.to_string_lossy());\n\n                                match lim.check_key_n(value, size) {\n                                    Ok(()) => {\n                                        output.push(event);\n                                        false\n                                    }\n                                    _ => {\n                                        emit!(EventRateLimited);\n                                        false\n                                    }\n                                }\n                            }\n                        }\n                    }\n                };\n                yield stream::iter(output.into_iter());\n                if done { break }\n              }\n            }\n            .flatten(),\n        )\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Define Protobuf Message for EventWrapper and Metadata\nDESCRIPTION: This protobuf definition extends the event protocol to include the event metadata. It defines messages for `EventWrapper`, `EventMetadata`, and `SourceEvent` to encapsulate event data and associated metadata for transmission or storage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-02-04-5802-event-metadata.md#_snippet_2\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage EventWrapper {\n  oneof event {\n    Log log = 1;\n    Metric metric = 2;\n  }\n  # Reserve 3 for traces\n  EventMetadata metadata = 4;\n}\n\nmessage EventMetadata {\n  google.protobuf.Timestamp first_timestamp = 1;\n  repeated SourceEvent source_events = 2;\n  EventDeliveryStatus status = 3;\n}\n\nmessage SourceEvent {\n  google.protobuf.Timestamp timestamp = 1;\n  string source_name = 2;\n  string event_id = 3;\n}\n\nenum EventDeliveryStatus {\n  …TBD…\n}\n```\n\n----------------------------------------\n\nTITLE: Drop splunk_channel field using remap transform\nDESCRIPTION: This code snippet demonstrates how to use a `remap` transform to drop the `splunk_channel` field from events output by a `splunk_hec` source. This is useful when a `splunk_hec` sink is sending data to a separate `splunk_hec` source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-28-0-19-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.foo]\ntype = \"remap\"\ninputs = [\"bar\"] # where bar is the splunk_hec source\nsource = '''\n  del(.splunk_channel)\n'''\n```\n\n----------------------------------------\n\nTITLE: Configuring Journald Source with Exclude Units - TOML\nDESCRIPTION: This snippet shows how to configure the journald source in Vector using the `exclude_units` option in the `vector.toml` file. It demonstrates how to selectively listen on Journald, ignoring specified units, and also include specific units.  The `type` parameter is required, and the `current_boot_only`, `exclude_units`, and `include_units` are optional.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-05-add-support-for-include-exclude-units.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.my_source_id]\n  type = \"journald\" # required\n  current_boot_only = true # optional, default\n  exclude_units = [\"zulip\"] # optional, default\n  include_units = [\"sshd\", \"ircd\"] # optional, default\n```\n\n----------------------------------------\n\nTITLE: OpenSSL FIPS Provider Configuration\nDESCRIPTION: This configuration file enables the OpenSSL FIPS provider, ensuring that Vector uses only FIPS 140-2 validated algorithms. It includes the FIPS module configuration and sets the default properties to require FIPS compliance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/tls.md#_snippet_2\n\nLANGUAGE: ini\nCODE:\n```\nconfig_diagnostics = 1\nopenssl_conf = openssl_init\n\n.include /path/to/fipsmodule.cnf\n\n[openssl_init]\nproviders = provider_sect\nalg_section = algorithm_sect\n\n[provider_sect]\nfips = fips_sect\nbase = base_sect\n\n[base_sect]\nactivate = 1\n\n[algorithm_sect]\ndefault_properties = fips=yes\n```\n\n----------------------------------------\n\nTITLE: Migrate Splunk HEC Logs sink configuration\nDESCRIPTION: This code snippet demonstrates how to migrate the configuration of a Splunk HEC Logs sink by replacing the deprecated `host` field with the `endpoint` field. It shows the difference between the old and new configurations using a diff format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-28-0-19-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.splunk]\n   type = \"splunk_hec_logs\"\n-  host = \"http://splunk-endpoint\"\n+  endpoint = \"http://splunk-endpoint\"\n   ...\n```\n\n----------------------------------------\n\nTITLE: Adding Vector Helm Repository\nDESCRIPTION: Adds the Vector Helm repository to your Helm configuration and updates the repository list. This allows you to access and install the Vector Helm chart.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nhelm repo add vector https://helm.vector.dev\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration - Memory Buffer\nDESCRIPTION: This TOML snippet demonstrates the configuration of a Vector memory buffer. It sets the buffer type to 'memory' and specifies the maximum number of events to store as 10,000.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/specs/configuration.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nbuffer.type = \"memory\"\nbuffer.memory.max_events = 10_000\n```\n\n----------------------------------------\n\nTITLE: Check Vector version (Shell)\nDESCRIPTION: This command executes the Vector binary with the `--version` flag, displaying the installed Vector version.  It verifies that Vector is installed correctly and provides version information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nvector --version\n```\n\n----------------------------------------\n\nTITLE: Internal Event Emission Example (Current)\nDESCRIPTION: This example demonstrates the current pattern for emitting internal events in Vector, showcasing the use of named parameters and the `emit` macro.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nBytesSent {\n    byte_size: 12345,\n    protocol: \"https\",\n}\n.emit();\n```\n\n----------------------------------------\n\nTITLE: Datadog Agent Secret API Response Example (JSON)\nDESCRIPTION: This is an example of a JSON response that the user-provided executable should return to the Datadog Agent (and Vector). It maps each requested secret to its corresponding value and an optional error message if the secret could not be retrieved. The `value` should be `null` if an error occurred.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-24-11552-dd-agent-style-secret-management.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"secret1\": {\"value\": \"secret_value\", \"error\": null},\n  \"secret2\": {\"value\": null, \"error\": \"could not fetch the secret\"}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Encoding Codec in Vector TOML Configuration\nDESCRIPTION: This code snippet demonstrates how to set the encoding codec to \"json\" in a Vector sink configuration file (TOML).  The `encoding.codec` option specifies the codec used to encode events before they are written to the sink.  This example uses the json codec.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Decrypting Data using AES in VRL\nDESCRIPTION: This snippet demonstrates how to decrypt data in VRL using the `decrypt` function with AES. It retrieves the encryption key from an environment variable (base64 encoded) and the IV from the event. The encrypted message is base64 decoded before decryption. It requires the `decode_base64`, `get_env_var`, and `decrypt` VRL functions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n# The `key` is typically a raw set of bytes matching the expected length for the algorithm so it is common to base64\n# encode it for injection and decode in VRL\nkey = decode_base64!(get_env_var!(\"KEY\")) # with $KEY set to \"c2VjcmV0X19faHVudGVyMg==\"\n\n\n# encrypted message was stored as base64 encoded data\n.message = decrypt!(decode_base64!(.encrypted_message), \"AES-128-CBC-PKCS7\", key, iv: .iv)\n\n# delete originals\ndel(.iv)\ndel(.encrypted_message)\n```\n\n----------------------------------------\n\nTITLE: Parse JSON on Strings in Array VRL\nDESCRIPTION: This VRL snippet parses JSON from multiple strings within an array and emits them as separate events. It splits a message field containing newline-separated JSON strings, parses each string using `parse_json`, handles potential null results with `?? null`, and compacts the resulting array to remove any `null` elements.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_19\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"message\": \"{\\\"name\\\": \\\"Chase\\\"}\\n{\\\"name\\\": \\\"Sky\\\"}\\n\" }\nstrings = split(.message, \"\\n\")\n. = compact(map_values(strings) -> |value| { parse_json(value) ?? null })\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Quoting Paths with Special Characters in CoffeeScript-like Syntax\nDESCRIPTION: This snippet shows how to handle field names containing whitespace or special characters within the remap language. The path sections are enclosed in quotes, allowing for the use of characters that would otherwise be interpreted as delimiters or operators. It also shows how to escape special characters like double quotes and backslashes within the quoted paths.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_2\n\nLANGUAGE: coffeescript\nCODE:\n```\n.foo = .bar.\\\"baz.buz\\\".bev\n\n# Use slash escapes within quotes\n.bar = .buz.\\\"fub\\\\\\\\\\\"fob\\\".fab\n```\n\n----------------------------------------\n\nTITLE: Memory Enrichment Table as Sink Example (YAML)\nDESCRIPTION: This configuration shows how to use a memory enrichment table as a sink and query it from a transform. The `memory_table` enrichment table is configured to accept data from the `cache_generator` transform. The `demo_logs_processor` transform uses `get_enrichment_table_record` to look up values in the table based on the `user-identifier` field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_15\n\nLANGUAGE: yaml\nCODE:\n```\nenrichment_tables:\n  memory_table:\n    type: memory\n    ttl: 60\n    flush_interval: 5\n    inputs: [\"cache_generator\"]\n\nsources:\n  demo_logs_test:\n    type: \"demo_logs\"\n    format: \"json\"\n\ntransforms:\n  demo_logs_processor:\n    type: \"remap\"\n    inputs: [\"demo_logs_test\"]\n    source: |\n      . = parse_json!(.message)\n      user_id = get!(., path: [\"user-identifier\"])\n\n      # Look for existing value in the table, using \"user-identifier\" as key\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\": user_id })\n\n      if err == null {\n        # Value found, just use the cached value\n        # In this case existing looks like this { \"key\": user_id, \"value\": {}, \"ttl\": 50 }\n        # Where value is the value we cached, ttl is the time left before this value is removed from\n        # the cache and key is the key we queried the table with\n        . = existing.value\n        .source = \"cache\"\n      } else {\n        # Do some processing, because we don't have this value in the table\n        .referer = parse_url!(.referer)\n        .referer.host = encode_punycode!(.referer.host)\n        .source = \"transform\"\n      }\n\n  cache_generator:\n    type: \"remap\"\n    inputs: [\"demo_logs_processor\"]\n    source: |\n      existing, err = get_enrichment_table_record(\"memory_table\", { \"key\": get!(., path: [\"user-identifier\"])\n})\n      if err != null {\n        # We don't have this key cached, so we need to prepare it for the table\n        data = .\n        # Since the memory enrichment table takes in all key value pairs it receives and stores them\n        # We want to produce an object that has the value of \"user-identifier\" as its key and\n        # rest of the object as its value\n        . = set!(value: {}, path: [get!(data, path: [\"user-identifier\"])], data: data)\n      } else {\n        . = {}\n      }\n\n# We can observe that after some time that some events have \"source\" set to \"cache\"\nsinks:\n  console:\n    inputs: [\"demo_logs_processor\"]\n    target: \"stdout\"\n    type: \"console\"\n    encoding:\n      codec: \"json\"\n```\n\n----------------------------------------\n\nTITLE: Remap Transform Configuration TOML\nDESCRIPTION: This TOML configuration defines a `remap` transform that uses the `abort` expression in VRL to drop events with a `type` other than `ok`. It includes a generator source that emits events with `message` and `type` fields, and a console sink to output the processed events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-vrl-abort.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.in]\n  type = \"generator\"\n  format = \"shuffle\"\n  interval = 1.0\n  lines = ['{ \"message\": \"valid message\", \"type\": \"ok\"}', '{ \"message\": \"invalid message\", \"type\": \"unknown\"}']\n\n[transforms.remap]\n  type = \"remap\"\n  inputs = [\"in\"]\n  source = \"\"\"\n    . |= object!(parse_json!(string!(.message)))\n    if .type != \\\"ok\\\" {\n      abort # unknown type\n    }\n  \"\"\"\n\n[sinks.out]\n  type = \"console\"\n  inputs = [\"remap\"]\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Configuring network devices in TOML\nDESCRIPTION: This TOML example shows how to configure Vector to collect network metrics from specific network devices using the `network.devices` option. By default, Vector collects from all network devices, but this option allows users to restrict collection to a specific set of devices. Globbing is suggested as a possible extension.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-26-3191-host-metrics.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\nnetwork.devices = [ \"eth0\" ]\n```\n\n----------------------------------------\n\nTITLE: Starting Vector on macOS (Homebrew)\nDESCRIPTION: Starts the Vector service using Homebrew's service manager. This assumes Vector was installed using Homebrew.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nbrew services start vector\n```\n\n----------------------------------------\n\nTITLE: PostgreSQL Metrics Source Configuration (TOML)\nDESCRIPTION: This TOML configuration defines the settings for the 'postgresql_metrics' source in Vector. It specifies the connection endpoint, included and excluded databases, scrape interval, and namespace for the collected metrics. The 'endpoint' is required and defines the PostgreSQL server address.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-27-3603-postgres-metrics.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.my_source_id]\n  type = \"postgresql_metrics\" # required\n  endpoint = \"postgres://postgres@localhost\" # required - address of the PG server.\n  included_databases = [\"production\", \"testing\"] # optional, list of databases to query. Defaults to all if not specified.\n  excluded_databases = [ \"development\" ] # optional, excludes specific databases. If a DB is excluded explicitly but included in `included_databases` then it is excluded.\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"postgresql\" # optional, default is \"postgresql\", namespace to attach to metrics.\n```\n\n----------------------------------------\n\nTITLE: Example Test Case YAML\nDESCRIPTION: This is an example of a basic test case defined in a YAML file.  It includes the name of the test, the expected outcome (success), and a list of simple string events, which are interpreted as log messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\n- name: happy path\n  expectation: success\n  events:\n    - simple message 1\n    - simple message 2\n    - simple message 3\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration for Explode Transform\nDESCRIPTION: This TOML configuration defines an `explode` transform that uses a VRL expression to extract events from the input. The `source` specifies the VRL code to perform this transformation, extracting events from the '.events' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.explode]\ntype = \"explode\"\nsource = \"array!(.events) ?? []\" # will be typechecked at compile-time\n```\n\n----------------------------------------\n\nTITLE: Empty YAML Configuration\nDESCRIPTION: This snippet shows the empty values.yaml configuration used to generate the Kubernetes manifests from the vector/vector Helm chart. The chart version used is 0.42.1. No dependencies are listed as this is just the configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/kubernetes/vector-aggregator/README.md#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n\n```\n\n----------------------------------------\n\nTITLE: Specifying metric collectors in TOML\nDESCRIPTION: This TOML snippet demonstrates how to specify a subset of metric collectors to enable when using the `host_metrics` source. This allows users to limit the metrics being collected to specific classes, such as `cpu`, `memory`, and `network`.  The `collectors` field is an array of strings, each representing a metric collector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-26-3191-host-metrics.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\ncollectors = [ \"cpu\", \"memory\", \"network\" ]\n```\n\n----------------------------------------\n\nTITLE: Add version field to Vector source and sink configuration\nDESCRIPTION: This code snippet demonstrates how to add the `version` field to the Vector source and sink configurations, specifying either version 1 or version 2 of the protocol.  This is necessary because the default version has been removed.  The snippet uses a diff format to highlight the addition of the `version` field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-28-0-19-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n[sinks.vector]\n  type = \"vector\"\n+ version = \"1\"\n\n[sources.vector]\n  type = \"vector\"\n+ version = \"1\"\n```\n\n----------------------------------------\n\nTITLE: Run Vector with Configuration Directory (Shell)\nDESCRIPTION: This shell command starts Vector using the `--config-dir` option. This tells Vector to load configurations from all files within the specified directory. The filenames are used as component IDs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nvector --config-dir /etc/vector\n```\n\n----------------------------------------\n\nTITLE: Log Event Example in Lua\nDESCRIPTION: Example Lua code that creates a log event with a message, nested field, and array. When emitted, Vector will add `timestamp` and `instance_id` fields according to the global schema.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_18\n\nLANGUAGE: lua\nCODE:\n```\nevent = {\n  log = {\n    message = \"example message\",\n    nested = {\n      field = \"example nested field value\"\n    },\n    array = {1, 2, 3},\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB Network Requests Metrics - Prometheus\nDESCRIPTION: This snippet represents the total number of requests received by the MongoDB server. This helps in assessing the overall load and utilization of the database.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_30\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_network_metrics_num_requests_total The numRequests field is a counter of the total number of distinct requests that the server has received. Use this value to provide context for the bytesIn and bytesOut values to ensure that MongoDB’s network utilization is consistent with expectations and application use\n# TYPE mongodb_network_metrics_num_requests_total counter\nmongodb_network_metrics_num_requests_total 14\n```\n\n----------------------------------------\n\nTITLE: Migrating `rename_fields` to `remap` in Vector (TOML)\nDESCRIPTION: This snippet shows how to migrate a `rename_fields` transform configuration to use the `remap` transform in Vector. The old configuration uses the `fields` setting to specify the field renaming, while the new configuration utilizes a VRL expression within the `source` setting to achieve the same effect.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_19\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.rename_fields]\ntype = \"rename_fields\"\ninputs = [\"some_input\"]\nfields.new_name = [\"old_name\"]\n```\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.rename_fields]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\n.new_name = del(.old_name)\n'''\n```\n\n----------------------------------------\n\nTITLE: Internal Metrics Example with `dropped` Output\nDESCRIPTION: Shows the structure of the `component_sent_events_total` metric when a custom named output is used (here, `dropped`). The `output` tag is set to `dropped` for events sent to the `dropped` output of a component (here, a `remap` transform).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-01-19-component-sent-metrics-output-tag.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"counter\":{\"value\":1.0},\"kind\":\"absolute\",\"name\":\"component_sent_events_total\",\"namespace\":\"vector\",\"tags\":{\"component_id\":\"foo\",\"component_kind\":\"transform\",\"component_name\":\"foo\",\"component_type\":\"remap\",\"output\":\"dropped\"}}\n```\n\n----------------------------------------\n\nTITLE: Example Log Event (Without Namespacing) JSON\nDESCRIPTION: This JSON shows the structure of a log event from the `datadog_agent` source before log namespacing is enabled. All data, including event data, source metadata, and Vector metadata, are placed at the root of the event. This can lead to data collisions and makes it difficult to understand the origin of specific fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"ddsource\": \"vector\",\n  \"ddtags\": \"env:prod\",\n  \"hostname\": \"alpha\",\n  \"foo\": \"foo field\",\n  \"service\": \"cernan\",\n  \"source_type\": \"datadog_agent\",\n  \"bar\": \"bar field\",\n  \"status\": \"warning\",\n  \"timestamp\": \"1970-02-14T20:44:57.570Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Lua Transform: Log to Metric (Loadable Module)\nDESCRIPTION: This TOML configuration demonstrates using a loadable Lua module for the log-to-metric transform. It specifies the `search_dirs` and `source` options to load the module and uses the `hooks` section to assign the module functions to the appropriate lifecycle stages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  type = \"lua\"\n  inputs = []\n  version = \"2\"\n  search_dirs = [\"/example/search/dir\"]\n  source = \"require 'example_transform.lua'\"\n  hooks.init = \"init\"\n  hooks.process = \"process\"\n  hooks.shutdown = \"shutdown\"\n  timers = [{interval_seconds = 10, handler = \"timer_handler\"}]\n```\n\n----------------------------------------\n\nTITLE: Emitting EventsSent Internal Event (diff)\nDESCRIPTION: This diff snippet demonstrates how to emit an `EventsSent` internal event to track the number of events sent by the sink. An `EventsSent` event is registered with the output set to `None`. Then the size of the sent event is estimated, and the number of events sent (always `1` in this case) is emitted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_11\n\nLANGUAGE: diff\nCODE:\n```\n    async fn run_inner(self: Box<Self>, mut input: BoxStream<'_, Event>) -> Result<(), ()> {\n        let bytes_sent = register!(BytesSent::from(Protocol(\"console\".into(),)));\n+       let events_sent = register!(EventsSent::from(Output(None)));\n\n        while let Some(mut event) = input.next().await {\n            let bytes = format!(\"{:#?}\", event);\n            println!(\"{}\", bytes);\n            bytes_sent.emit(ByteSize(bytes.len()));\n\n+           let event_byte_size = event.estimated_json_encoded_size_of();\n+           events_sent.emit(CountByteSize(1, event_byte_size));\n\n            let finalizers = event.take_finalizers();\n            finalizers.update_status(EventStatus::Delivered);\n        }\n\n        Ok(())\n    }\n```\n\n----------------------------------------\n\nTITLE: Deploying Vector with Helm v2\nDESCRIPTION: This snippet deploys Vector using Helm version 2.  It upgrades and installs the Vector chart using the 'vector-values.yaml' file and assigns the name 'vector' to the deployment within the specified namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n# Helm v2\nhelm upgrade\n  --install  \\\n  --namespace vector \\\n  --values vector-values.yaml \\\n  --name vector \\\n  vector/vector\n```\n\n----------------------------------------\n\nTITLE: Filter Transform Configuration with Check Fields and Remap - TOML\nDESCRIPTION: This example demonstrates configuring the Vector `filter` transform using both the original `check_fields` and the new `remap` methods. The `check_fields` method compares the values of specified fields against given criteria. The `remap` method utilizes a VRL expression to achieve the same filtering logic. Requires Vector version 0.12.0 or later.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-filter-remap-support.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.filter_out_non_critical]\ntype = \"filter\"\ninputs = [\"http-server-logs\"]f\n\n# Using check_fields\ncondition.type = \"check_fields\"\ncondition.message.status_code.ne = 200\ncondition.message.severity.ne = \"info\"\ncondition.message.severity.ne = \"debug\"\n\n# Using remap\ncondition.type = \"remap\"\ncondition.source = '.status_code != 200 && !includes([\"info\", \"debug\"], .severity)'\n```\n\n----------------------------------------\n\nTITLE: Enabling Vector API in Configuration\nDESCRIPTION: Enables the Vector API for `vector tap` to function.  This configuration is required for `vector tap` to work because it uses the API's `outputEventsByComponentIdPatterns` subscription.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[api]\nenabled = true\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Boolean and Arithmetic Operations in CoffeeScript-like Syntax\nDESCRIPTION: This snippet demonstrates the use of boolean operators and arithmetic operations within the remap language. It shows how to compare values and perform calculations, assigning the results to new fields within the event. This enables conditional logic and data transformations within the mapping process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_5\n\nLANGUAGE: coffeescript\nCODE:\n```\n.is_big = .number > 100\n.multiplied = .number * 7\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example (JSON)\nDESCRIPTION: This JSON snippet represents a comprehensive Vector configuration. It configures a data directory, an Apache log source with file inclusion and an ignore-older setting, data transformation with a Remap Language parser and a sampler, and Elasticsearch and S3 sinks for data storage. Key configurations include endpoints, index patterns, bucket details, and compression settings.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data_dir\": \"/var/lib/vector\",\n  \"sources\": {\n    \"apache_logs\": {\n      \"type\": \"file\",\n      \"include\": [\n        \"/var/log/apache2/*.log\"\n      ],\n      \"ignore_older\": 86400\n    }\n  },\n  \"transforms\": {\n    \"apache_parser\": {\n      \"inputs\": [\n        \"apache_logs\"\n      ],\n      \"type\": \"remap\",\n      \"source\": \". = parse_apache_log(.message)\"\n    },\n    \"apache_sampler\": {\n      \"inputs\": [\n        \"apache_parser\"\n      ],\n      \"type\": \"sample\",\n      \"rate\": 50\n    }\n  },\n  \"sinks\": {\n    \"es_cluster\": {\n      \"inputs\": [\n        \"apache_sampler\"\n      ],\n      \"type\": \"elasticsearch\",\n      \"endpoints\": [\"http://79.12.221.222:9200\"],\n      \"bulk\": {\n        \"index\": \"vector-%Y-%m-%d\"\n      }\n    },\n    \"s3_archives\": {\n      \"inputs\": [\n        \"apache_parser\"\n      ],\n      \"type\": \"aws_s3\",\n      \"region\": \"us-east-1\",\n      \"bucket\": \"my-log-archives\",\n      \"key_prefix\": \"date=%Y-%m-%d\",\n      \"compression\": \"gzip\",\n      \"framing\": {\n        \"method\": \"newline_delimited\"\n      },\n      \"encoding\": {\n        \"codec\": \"json\"\n      },\n      \"batch\": {\n        \"max_bytes\": 10000000\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example TOML\nDESCRIPTION: This configuration defines a GraphQL API endpoint, a generator source named `in` that produces a sequence of \"Hello World\" messages, and a blackhole sink named `out` that consumes the events from the `in` source.  The generator source emits events every 1 second, and the output sink discards incoming events. Enabling the GraphQL API is a prerequisite for using the `vector tap` command.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-vector-tap.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[api]\n  enabled =  true\n[sources.in]\n  type = \"generator\"\n  format = \"shuffle\"\n  interval = 1.0\n  lines = [\"Hello World\"]\n  sequence = true\n\n[sinks.out]\n  type = \"blackhole\"\n  inputs = [\"in\"]\n```\n\n----------------------------------------\n\nTITLE: Setting Role in values.yaml for Helm Chart - YAML\nDESCRIPTION: This YAML snippet configures the `values.yaml` file for the `vector/vector` Helm chart, setting the `role` to `Stateless-Aggregator`. This configuration is used when generating Kubernetes manifests using the Helm chart. The configuration impacts the deployment's behavior by defining its operational role.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/kubernetes/vector-stateless-aggregator/README.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nrole: Stateless-Aggregator\n```\n\n----------------------------------------\n\nTITLE: Enabling Backtraces\nDESCRIPTION: This command enables backtraces for Vector, which are crucial for debugging errors.  It sets the `RUST_BACKTRACE` environment variable to `full` and then runs Vector with the specified configuration file. Requires the `vector` binary to be in the system's PATH and access to the configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nRUST_BACKTRACE=full vector --config=/etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Datadog Span Definition (protobuf)\nDESCRIPTION: Defines the structure of a Span in Datadog's newer trace format using protobuf. It includes fields like service, name, resource, traceID, spanID, parentID, start, duration, error, meta (tags), metrics, type, and meta_struct.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_2\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage Span {\n    string service = 1;\n    string name = 2;\n    string resource = 3;\n    uint64 traceID = 4;\n    uint64 spanID = 5;\n    uint64 parentID = 6;\n    int64 start = 7;\n    int64 duration = 8;\n    int32 error = 9;\n    map<string, string> meta = 10;\n    map<string, double> metrics = 11;\n    string type = 12;\n    map<string, bytes> meta_struct = 13;\n}\n```\n\n----------------------------------------\n\nTITLE: GCP Pub/Sub Sink Encoding Configuration (TOML)\nDESCRIPTION: This TOML configuration sets the `encoding.codec` option to \"json\" for the `gcp_pubsub` sink.  This ensures that logs are encoded as JSON before being published to Google Cloud Pub/Sub.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Concatenating Name Fields in TOML\nDESCRIPTION: This TOML configuration shows how to concatenate `first_name` and `last_name` fields into a single `name` field using a `remap` transform. It also deletes the original `first_name` and `last_name` fields after concatenation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_10\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.moosh_names]\n  type = \"remap\"\n  inputs = [\"source0\"]\n  source = '''\n    .name = .first_name + \" \" + .last_name\n    del(.first_name, .last_name)\n  '''\n```\n\n----------------------------------------\n\nTITLE: Validating Vector Configuration Without Environment Checks\nDESCRIPTION: This command validates a Vector configuration file, skipping environment checks. This is useful when the environment is not available or when environment checks are not desired during validation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/validating.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nvector validate --no-environment /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Annotate Pod for Container Exclusion (YAML)\nDESCRIPTION: This YAML snippet shows how to add a 'vector.dev/exclude-containers' annotation to a Kubernetes Pod.  This annotation instructs Vector to skip logs originating from the specified containers ('container1' and 'container2').\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\nvector.dev/exclude-containers: \"container1,container2\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka SASL Authentication in Vector TOML\nDESCRIPTION: This code snippet demonstrates how to configure SASL authentication for a Kafka source in the `vector.toml` configuration file. It includes settings for enabling SASL, specifying the mechanism, username, and password. Note that this feature is not yet supported on Windows.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-06-27-add-sasl-to-kafka.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n  [sources.source0]\n    type = \"kafka\" # required\n    inputs = [\"...\"] # required\n    bootstrap_servers = \"10.14.22.123:9092,10.14.23.332:9092\" # required\n    group_id = \"consumer-group-name\" # required\n    key_field = \"message_key\" # optional, no default\n    topics = [\"^(prefix1|prefix2)-.+\", \"topic-1\", \"topic-2\"] # required\n+   sasl.enabled = true # optional, default false\n+   sasl.mechanism = \"SCRAM-SHA-512\" # optional, no default\n+   sasl.password = \"password\" # optional, no default\n+   sasl.username = \"username\" # optional, no default\n```\n\n----------------------------------------\n\nTITLE: Docker Compose Configuration for Vector, Prometheus, and Grafana\nDESCRIPTION: This Docker Compose file defines services for Vector, Prometheus, and Grafana. It sets up networking, port mappings, and volume mounts for each service to enable metrics collection and visualization.  Important: Replace `<path to ...>` with the actual paths to the respective configuration files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_33\n\nLANGUAGE: yaml\nCODE:\n```\n# docker-compose.yaml\nservices:\n  vector:\n    image: timberio/vector:0.45.0-debian\n    container_name: vector\n    ports:\n      - \"9598:9598\"\n    volumes:\n      - <path to Vector config here>:/etc/vector/vector.yaml\n    networks:\n      - vector-net\n\n  prometheus:\n    image: prom/prometheus:latest\n    container_name: prometheus\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - - <path to Prometheus config here>:/etc/prometheus/prometheus.yml\n    networks:\n      - vector-net\n\n  grafana:\n    image: grafana/grafana:latest\n    container_name: grafana\n    ports:\n      - \"3000:3000\"\n    networks:\n      - vector-net\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    depends_on:\n      - prometheus\n\nnetworks:\n  vector-net:\n    driver: bridge\n```\n\n----------------------------------------\n\nTITLE: Enabling Vector API in TOML Configuration\nDESCRIPTION: This snippet shows how to enable the Vector GraphQL API by adding an `api` section to the `vector.toml` configuration file. It enables the API and optionally sets the address for the API server.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[api]\n  enabled = true\n  address = \"127.0.0.1:8686\" # optional. Change IP/port if required\n```\n\n----------------------------------------\n\nTITLE: Filter Transform with VRL Condition (Updated) - TOML\nDESCRIPTION: This example shows the updated `filter` transform configuration, replacing `condition.type = \"remap\"` with `condition.type = \"vrl\"`.  This is required for compatibility with Vector 0.15.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.filter_a]\ninputs = [\"stdin\"]\ntype = \"filter\"\ncondition.type = \"vrl\"\ncondition.source = '''\n    message = if exists(.tags) { .tags.message } else { .message }\n    message == \"test filter 1\"\n'''\n```\n\n----------------------------------------\n\nTITLE: Customizing Vector tap Output\nDESCRIPTION: Runs `vector tap` with the `--quiet` and `--format logfmt` options. `--quiet` suppresses notifications, and `--format logfmt` configures the output to be in logfmt format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_6\n\nLANGUAGE: console\nCODE:\n```\nvector tap --quiet --format logfmt\n```\n\n----------------------------------------\n\nTITLE: Configuring GZIP Compression for an HTTP Sink\nDESCRIPTION: This snippet configures gzip compression for the HTTP sink `sink_0`. It specifies the `gzip` compression type for the sink. It is used to demonstrate a scenario where the downstream component does not support GZIP.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\nsinks:\n  sink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://localhost:8000/logs\n    encoding:\n      codec: json\n    compression: gzip\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration Example TOML\nDESCRIPTION: This is an example of a Vector configuration file in TOML format. It defines sources, transforms, and sinks, demonstrating how data flows through the Vector pipeline.  The configuration includes examples of internal metrics, datadog logs, and file sources, a remap transform, and prometheus exporter, datadog logs, and blackhole sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-vector-graph.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.internal_metrics]\ntype = \"internal_metrics\"\n\n[sources.dd_logs]\ntype = \"datadog_logs\" # required\nacknowledgements = false # optional, default\naddress = \"0.0.0.0:8282\" # required\n\n[sources.file_gen]\ntype = \"file\"\ninclude = [\"/var/log/file_gen/**/*.log\"]\nread_from = \"beginning\"\n\n##\n## Transforms\n##\n\n[transforms.remap]\ntype = \"remap\"\ninputs = [\"file_gen\"]\nsource = '''\n.agent_name = \"vector\"\nparsed, err = parse_json(.message)\nif err == null {\n    .message = parsed\n    .format = \"json\"\n} else {\n    .format = \"ascii\"\n}\nmatches = parse_regex!(.file, r'.*/(?P<num>\\d+)-(?P<name>\\w+).log')\n.origin, err = .host + \"/\" + matches.name + \"/\" + matches.num\nif err != null {\n    log(\"Failed to parse origin from file name\", level: \"error\")\n}\n'''\n\n##\n## Sinks\n##\n\n[sinks.prometheus]\ntype = \"prometheus_exporter\"\ninputs = [\"internal_metrics\"]\naddress = \"0.0.0.0:9598\"\n\n[sinks.dd_logs_egress]\ntype = \"datadog_logs\"\ninputs = [\"dd_logs\"]\ndefault_api_key = \"\"\nencoding.codec = \"json\"\nrequest.concurrency = \"adaptive\"\nbatch.max_bytes = 5242880\nrequest.rate_limit_num = 1000\n\n\n[sinks.blackhole]\ntype = \"blackhole\"\ninputs = [\"remap\"]\n\n```\n\n----------------------------------------\n\nTITLE: Generating Client TLS Certificate and Key (mkcert)\nDESCRIPTION: This shell command uses `mkcert` to generate a client certificate and key for NATS with support for localhost, IPv6 localhost, and hostnames used by integration tests.  It also includes an email address.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/tests/data/nats/README.md#_snippet_2\n\nLANGUAGE: Shell Session\nCODE:\n```\n# Now generate the client certificate/key.\n$ mkcert -client -cert-file nats-client.pem -key-file nats-client.key localhost ::1 nats-tls nats-tls-client-cert nats-jwt email@localhost\n```\n\n----------------------------------------\n\nTITLE: Transforming json_parser with remap\nDESCRIPTION: Replacing the `json_parser` transform with the `remap` transform. Parses JSON messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.json_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= object!(parse_json(.message))\n'''\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON Events from Unnest Function\nDESCRIPTION: These are the resulting JSON log events generated by the `unnest` function. Each event now contains the elements from the original array, alongside the other fields. The array of events is expanded into multiple log events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"events\": { \"message\": \"hello\" }, \"host\": \"localhost\" }\n{ \"events\": { \"message\": \"world\" }, \"host\": \"localhost\" }\n```\n\n----------------------------------------\n\nTITLE: Example MongoDB Exporter Output (Prometheus format)\nDESCRIPTION: This snippet provides an example of the output format from a `mongodb_exporter`, specifically in Prometheus exposition format.  It showcases various metrics related to Go runtime statistics like garbage collection, goroutines, and memory allocation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 0\ngo_gc_duration_seconds{quantile=\"0.25\"} 0\ngo_gc_duration_seconds{quantile=\"0.5\"} 0\ngo_gc_duration_seconds{quantile=\"0.75\"} 0\ngo_gc_duration_seconds{quantile=\"1\"} 0\ngo_gc_duration_seconds_sum 0\ngo_gc_duration_seconds_count 0\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 9\n# HELP go_info Information about the Go environment.\n# TYPE go_info gauge\ngo_info{version=\"go1.15\"} 1\n# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.\n# TYPE go_memstats_alloc_bytes gauge\ngo_memstats_alloc_bytes 2.585e+06\n# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.\n# TYPE go_memstats_alloc_bytes_total counter\ngo_memstats_alloc_bytes_total 2.585e+06\n# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.\n# TYPE go_memstats_buck_hash_sys_bytes gauge\ngo_memstats_buck_hash_sys_bytes 1.445082e+06\n# HELP go_memstats_frees_total Total number of frees.\n# TYPE go_memstats_frees_total counter\ngo_memstats_frees_total 2401\n# HELP go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started.\n# TYPE go_memstats_gc_cpu_fraction gauge\ngo_memstats_gc_cpu_fraction 0\n# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.\n# TYPE go_memstats_gc_sys_bytes gauge\ngo_memstats_gc_sys_bytes 4.171848e+06\n```\n\n----------------------------------------\n\nTITLE: Run instrumented Vector and collect profile data\nDESCRIPTION: This command runs the instrumented Vector version with a specified configuration file. It's crucial to let it run for a sufficient duration to gather representative profile data for the target workload.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/tuning/pgo.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncargo pgo run -- -- -c vector.toml\n```\n\n----------------------------------------\n\nTITLE: Test Case Data Structures in Rust\nDESCRIPTION: This Rust code defines the data structures used to represent test cases, events, and expectations. `TestCaseExpectation` defines the possible outcomes of a test. `TestEvent` encapsulates either a passthrough event or a potentially modified event.  `EventData` defines different types of event data, such as log messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n// Expected outcome of a validation test case.\npub enum TestCaseExpectation {\n    /// All events were processed successfully.\n    Success,\n\n    /// All events failed to be processed successfully.\n    Failure,\n\n    /// Some events, but not all, were processed successfully.\n    PartialSuccess,\n}\n\n/// An event used in a test case.\npub enum TestEvent {\n    /// The event is used, as-is, without modification.\n    Passthrough(EventData),\n\n    /// The event is potentially modified by the external resource.\n    Modified { modified: bool, event: EventData },\n}\n\npub enum EventData {\n    /// A log event.\n    Log(String),\n}\n\n/// A validation test case.\npub struct TestCase {\n    pub expectation: TestCaseExpectation,\n    pub events: Vec<TestEvent>,\n}\n```\n\n----------------------------------------\n\nTITLE: Observed RTT Metric Emission in Rust\nDESCRIPTION: This snippet shows how to emit a metric for observed Round Trip Times (RTT). The `timing!` macro is used to record the RTT value, along with the component kind and type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nimpl InternalEvent for ObservedRTT {\n    fn emit_metrics(&self) {\n        timing!(\"observed_rtt\", self.rtt,\n            \"component_kind\" => \"sink\",\n            \"component_type\" => self.component,\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Input and Timeout\nDESCRIPTION: This shell command pipes the content of 'five-lines-first' to the 'vector-v0.19.0' executable, using 'config-wrong-http.toml' as its configuration file, with a timeout of 5 seconds.  It demonstrates how Vector processes input and handles potentially incorrect configurations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ncat five-lines-first | timeout 5s ./vector-v0.19.0 --config config-wrong-http.toml\n```\n\n----------------------------------------\n\nTITLE: Function Signature for with_source_metadata in Rust\nDESCRIPTION: This shows the function signature for `with_source_metadata`. It takes the source name, an optional legacy path, the vector path, the data kind, and an optional meaning. The function updates the schema definition with the specified source metadata.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_13\n\nLANGUAGE: rust\nCODE:\n```\n    pub fn with_source_metadata(\n        self,\n        source_name: &str,\n        legacy_path: Option<LegacyKey<OwnedValuePath>>,\n        vector_path: &OwnedValuePath,\n        kind: Kind,\n        meaning: Option<&str>,\n    ) -> Self\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Alloc Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of heap bytes allocated and still in use by the Go program. It is a key metric for understanding heap memory consumption.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_46\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.\n# TYPE go_memstats_heap_alloc_bytes gauge\ngo_memstats_heap_alloc_bytes 7.146072e+06\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON Events from Remap Transform\nDESCRIPTION: These are the resulting JSON log events that would be generated from the previous TOML configuration. Each object in the array becomes a separate log event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"message\": \"hello\"}\n{\"message\": \"world\"}\n```\n\n----------------------------------------\n\nTITLE: VRL for Memory Table Interaction (Transform: demo_logs_processor)\nDESCRIPTION: This VRL snippet demonstrates how to interact with a memory enrichment table within a transform component. It parses a JSON message, extracts the `user-identifier`, and uses `get_enrichment_table_record` to check if the user ID exists in the `memory_table`. If the user ID is found, it uses the cached value; otherwise, it performs additional processing and updates the `.source` field accordingly. The `existing` variable contains the value, the key and the TTL of the cached data if found.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_16\n\nLANGUAGE: vrl\nCODE:\n```\n. = parse_json!(.message)\nuser_id = get!(., path: [\"user-identifier\"])\n\n# Look for existing value in the table, using \"user-identifier\" as key\nexisting, err = get_enrichment_table_record(\"memory_table\", { \"key\": user_id })\n\nif err == null {\n  # Value found, just use the cached value\n  # In this case existing looks like this { \"key\": user_id, \"value\": {}, \"ttl\": 50 }\n  # Where value is the value we cached, ttl is the time left before this value is removed from\n  # the cache and key is the key we queried the table with\n  . = existing.value\n  .source = \"cache\"\n} else {\n  # Do some processing, because we don't have this value in the table\n  .referer = parse_url!(.referer)\n  .referer.host = encode_punycode!(.referer.host)\n  .source = \"transform\"\n}\n```\n\n----------------------------------------\n\nTITLE: Kinesis Firehose HTTP Request (JSON)\nDESCRIPTION: This is the structure of the HTTP request sent by Kinesis Firehose, containing the requestId, timestamp, and an array of records.  The data field within the records array is base64 encoded and gzip compressed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"requestId\": \"ed1d787c-b9e2-4631-92dc-8e7c9d26d804\",\n  \"timestamp\": 1600110760138,\n  \"records\": [\n    {\n      \"data\": \"H4sIAMeba18AA52TX2/aMBTF3/spUJ4h/h/beUMqYy+TKsGexlSFcGm9JXFqO2Vd1e8+O7AiTUNMy0Ok3HNybN+f7+vNZJK14H31AOuXHrJykt3O1/P7T4vVar5cZNNksIcOXJKwJFpozqQg7Cg19mHp7NAnFX2LQYAC+PAuroKDqk3queyHra+d6YOx3QfTBHA+Gr5EKYq30Wa6KmlZrHz9HbR4hi6cfa/jO0pml8KZKBQrhMJKF4QLRTllBeZMc60YLbBkSlOqlBBEx0dIRaVQHI8bGnOCiW0IVZtOQgqMCcGi0Jjpd8epTWm51022fYkH2mQlLaTC0022qwKkjFjaZISjFfSIYopLQkouSk4mM8wx3mTR+2h9OPqEzAnDOSVFTjQbxRbCo92N8t3n9VjqnQ22ts1Y/Lhe3yGSH5Mc7MGBG4XHEHpfInQ4HPLema42fdXUzno/65sq7K1rc2NRW7nvEDwatuZpMMEO/pT0NMBpWwh+9LAzAVBtu2dwD9DVMLq8HVwN9yFeldHpw850RyVUIUWVDJP4OXhwM7OLzMzenDY422Rv2djNt+k1iEITxTSJHYs4C0q14EwRzNLtw4oUklKhcYRcSHYVIidXIBIpsfxviFjniuSU85wK+ifD5eISQ3qB4QmhiZ33IUIz3sdhmMWJCaaumsSQciTRs3Whav5Cz0cXoP3Q1WmKqib+Bx7ZOG+t+fnPHAWmFzjuATp4IRKrM9A0qjdvN78A1L2XllAEAAA=\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing GenerateConfig for BasicConfig in Rust\nDESCRIPTION: This code implements the `GenerateConfig` trait for the `BasicConfig` struct.  This enables the `vector generate` command to produce a default configuration for the sink.  In this case, the default configuration is an empty TOML string.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nimpl GenerateConfig for BasicConfig {\n    fn generate_config() -> toml::Value {\n        toml::from_str(\"\").unwrap()\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Elasticsearch Integration Tests (yaml)\nDESCRIPTION: This YAML configuration defines the arguments, environment variables, and test matrix for Elasticsearch integration tests. It specifies features, library paths, AWS credentials, and Elasticsearch addresses. The matrix defines the versions and types of Elasticsearch to test against.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-31-15056-tooling-revamp.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nargs:\n- --features\n- es-integration-tests\n- --lib\n- \"::elasticsearch::integration_tests::\"\n\nenv:\n  AWS_ACCESS_KEY_ID: dummy\n  AWS_SECRET_ACCESS_KEY: dummy\n  ELASTICSEARCH_AWS_ADDRESS: http://localstack:4571\n  ELASTICSEARCH_HTTP_ADDRESS: http://elasticsearch:9200\n  ELASTICSEARCH_HTTPS_ADDRESS: https://elasticsearch-secure:9200\n\nmatrix:\n- version: [\"7.13.1\"]\n  type: [\"classic\"]\n```\n\n----------------------------------------\n\nTITLE: Pull Vector Docker Image\nDESCRIPTION: Pulls the Vector Docker image from Timber.io's repository, specifying the Debian distribution and version. Other distributions such as alpine, distroless-libc, and distroless-static are also available.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ndocker pull timberio/vector:{{< version >}}-debian\n```\n\n----------------------------------------\n\nTITLE: Configuring framing and decoding in YAML\nDESCRIPTION: This YAML snippet demonstrates how to configure the `framing` and `decoding` options for a source in the Vector configuration. It uses `character_delimited` framing with a tab delimiter and `json` decoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\n[framing]\nmethod = \"character_delimited\"\ncharacter_delimited.delimiter = \"\\t\"\n\n[decoding]\ncodec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Pipeline Transform Configuration Example - TOML\nDESCRIPTION: Example TOML configuration for a pipeline, showing two transforms (`foo` and `bar`) with their types, inputs, and outputs. The `outputs` option forwards events from inside the pipeline to external components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# /etc/vector/pipelines/pipeline.toml\n[transforms.foo]\ntype = \"remap\"\ninputs = [\"from-root\"]\noutputs = [\"dc1\", \"dc2\"]\n# ...\n\n[transforms.bar]\ntype = \"remap\"\ninputs = [\"foo\"]\noutputs = [\"dc-us\", \"dc-eu\"]\n# ...\n```\n\n----------------------------------------\n\nTITLE: Defining Protobuf Service\nDESCRIPTION: This Protobuf definition outlines a `Dummy` service with various RPC methods, including unary (`Send`), server streaming (`SendStream`), client streaming (`ReceiveStream`), and bidirectional streaming (`Bidirectional`).  It defines the request (`DummyRequest`) and response (`DummyResponse`) message structures. The `syntax` specifies the Protobuf version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_0\n\nLANGUAGE: protobuf\nCODE:\n```\n    syntax = \"proto3\";\n\n    package our_rpc;\n\n    service Dummy {\n      rpc Send (DummyRequest) returns (DummyResponse);\n      rpc SendStream(DummyRequest) returns (stream DummyResponse);\n      rpc ReceiveStream(stream DummyRequest) returns (DummyResponse);\n      rpc Bidirectional(stream DummyRequest) returns (stream DummyResponse);\n    }\n\n    message DummyRequest {\n      string name = 1;\n    }\n\n    // return value\n    message DummyResponse {\n      string message = 1;\n    }\n```\n\n----------------------------------------\n\nTITLE: Handling VRL Type Errors by Aborting on Incorrect Type\nDESCRIPTION: This snippet demonstrates how to handle VRL type errors by aborting if the arguments are not of the correct type. Appending the function name with `!` (e.g., `to_string!(msg)`) will cause the function to abort if the type is incorrect.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: coffeescript\nCODE:\n```\nto_string!(msg)\n```\n\n----------------------------------------\n\nTITLE: VRL String Escaping\nDESCRIPTION: This example shows how to escape `{{` and `}}` characters in VRL strings and how to use raw strings.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: coffee\nCODE:\n```\nassert!(\"\\{{ right here \\}}\" == s'{{ right here }}')\n```\n\n----------------------------------------\n\nTITLE: Go Threads Metric - Prometheus\nDESCRIPTION: This snippet indicates the number of OS threads created by the Go program. It provides insights into the threading model.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_64\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_threads Number of OS threads created.\n# TYPE go_threads gauge\ngo_threads 14\n```\n\n----------------------------------------\n\nTITLE: Migrating to VRL Syntax for Check Fields\nDESCRIPTION: This snippet demonstrates how to migrate from the deprecated `check_fields` syntax to the recommended VRL (Vector Remap Language) syntax for specifying conditions.  This example shows a condition for matching the log level 'error'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n [transforms.route]\n type = \"route\"\n-lanes.errors.\"level.eq\" = \"error\"\n+lanes.errors = '.level = \"error\"'\n```\n\n----------------------------------------\n\nTITLE: Coalescing VRL Errors\nDESCRIPTION: Illustrates how to use the coalesce operator `??` in VRL to handle multiple potential errors efficiently. The code attempts to parse JSON first, then syslog if the JSON parsing fails, and finally defaults to an empty object if both parsing attempts fail. The result is assigned to `structured`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/errors.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\nstructured = parse_json(\"not json\") ?? parse_syslog(\"not syslog\") ?? {}\n. = merge(., structured)\n```\n\n----------------------------------------\n\nTITLE: VRL Script for Log Processing and Cache Interaction\nDESCRIPTION: This VRL script within the `demo_logs_processor` transform parses JSON messages, extracts a user ID, and checks for an existing cached value in the `memory_table`. If a cached value exists, it reuses it; otherwise, it processes the event data and sets the source field. Requires Vector to be installed and configured with the necessary components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-memory_enrichment_table.md#_snippet_1\n\nLANGUAGE: vrl\nCODE:\n```\n. = parse_json!(.message)\nuser_id = get!(., path: [\"user-identifier\"])\n\n# Check if we already have a cached value for this user in the enrichment table\nexisting, err = get_enrichment_table_record(\"memory_table\", { \"key\": user_id })\n\nif err == null {\n  # A cached value exists; reuse it.\n  # The `existing` object has this structure:\n  # { \"key\": user_id, \"value\": {...}, \"ttl\": 50 }\n  . = existing.value\n  .source = \"cache\"\n} else {\n  # No cached value found, process the event and prepare new data\n  .referer = parse_url!(.referer)\n  .referer.host = encode_punycode!(.referer.host)\n  .source = \"transform\"\n```\n\n----------------------------------------\n\nTITLE: VRL map_keys example\nDESCRIPTION: Example usage of the `map_keys` function in VRL to uppercase the keys of a JSON object.  The closure takes the key as input and returns the uppercased key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_29\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_keys(.) -> |key| { upcase(key) }\n```\n\n----------------------------------------\n\nTITLE: Example Input JSON for Decryption\nDESCRIPTION: This is an example JSON input for the decryption process. It contains the base64 encoded encrypted message and the initialization vector (IV).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{ \"encrypted_message\": \"jYn3wFE2ajfd/VpDE/SrLO5+DknxB3hqgjH5+hpnSu4=\", \"iv\": \"1234567890123456\"}\n```\n\n----------------------------------------\n\nTITLE: Dummy HTTP Server Request\nDESCRIPTION: This snippet shows the HTTP request received by a dummy HTTP server. It includes the request method (POST), path (/foo), headers, and body. The body contains five JSON objects in newline delimited JSON (NDJSON) format, each representing a log event with fields like `host`, `message`, `source_type`, and `timestamp`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n┌─Incoming request\n│ POST /foo HTTP/1.1\n│ Accept-Encoding: identity\n│ Content-Length: 635\n│ Content-Type: application/x-ndjson\n│ Host: localhost:7777\n│ User-Agent: Vector/0.21.0 (x86_64-unknown-linux-gnu)\n│ Body:\n│ {\"host\":\"consigliere\",\"message\":\"ONE line one, woohoo\",\"source_type\":\"stdin\",\"timestamp\":\"2022-02-25T01:37:26.485844093Z\"}\n│ {\"host\":\"consigliere\",\"message\":\"ONE line two, yippeee\",\"source_type\":\"stdin\",\"timestamp\":\"2022-02-25T01:37:26.485859923Z\"}\n│ {\"host\":\"consigliere\",\"message\":\"ONE line three, oh my\",\"source_type\":\"stdin\",\"timestamp\":\"2022-02-25T01:37:26.485863163Z\"}\n│ {\"host\":\"consigliere\",\"message\":\"ONE line four, woooooow\",\"source_type\":\"stdin\",\"timestamp\":\"2022-02-25T01:37:26.485866083Z\"}\n│ {\"host\":\"consigliere\",\"message\":\"ONE live five, phew, that was a lot\",\"source_type\":\"stdin\",\"timestamp\":\"2022-02-25T01:37:26.485869063Z\"}\n┌─Outgoing response\n│ HTTP/1.1 200 OK\n│ Body:\n│ dummyhttp\n```\n\n----------------------------------------\n\nTITLE: Deploying Vector with Helm v3\nDESCRIPTION: This snippet deploys Vector using Helm version 3. It creates a namespace named 'vector', then upgrades and installs the Vector chart using the provided 'vector-values.yaml' file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create namespace vector\n\n# Helm v3\nhelm upgrade \\\n  --install \\\n  --namespace vector \\\n  --values vector-values.yaml \\\n  vector \\\n  vector/vector\n```\n\n----------------------------------------\n\nTITLE: Implement MetaDescriptive and Finalizable Traits - Rust\nDESCRIPTION: Implements the `MetaDescriptive` and `Finalizable` traits for the `BasicRequest` struct, providing access to the request metadata and event finalizers, respectively. These traits are necessary for metric emission and acknowledgement guarantees.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nimpl MetaDescriptive for BasicRequest {\n    fn get_metadata(&self) -> &RequestMetadata {\n        &self.metadata\n    }\n\n    fn metadata_mut(&mut self) -> &mut RequestMetadata {\n        &mut self.metadata\n    }\n}\n\nimpl Finalizable for BasicRequest {\n    fn take_finalizers(&mut self) -> EventFinalizers {\n        self.finalizers.take_finalizers()\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Vector in Docker\nDESCRIPTION: Runs Vector in a Docker container, mapping a local configuration file to the container and exposing port 8686. The example uses the alpine variant.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\ndocker run \\\n  -d \\\n  -v ~/vector.yaml:/etc/vector/vector.yaml:ro \\\n  -p 8686:8686 \\\n  timberio/vector:{{< version >}}-alpine\n```\n\n----------------------------------------\n\nTITLE: Vector eval command example\nDESCRIPTION: This bash command shows a potential future usage of the `vector eval` command. This command is not yet implemented, but the example suggests evaluating data from stdin and outputting to console with JSON encoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-04-shutdown-vector-if-all-sources-finish.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nbanana@tree:/$ vector eval stdin//console(encoding=json)\n```\n\n----------------------------------------\n\nTITLE: Specifying Secrets in Configuration - TOML\nDESCRIPTION: This snippet demonstrates how to specify secrets within a Vector configuration using the `SECRET[<backend name>.<secret name>]` syntax. It shows how secrets from a configured backend are used to populate values, such as access keys, within a source configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-secrets-management.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[sources.my_source_id]\ntype = \"aws_sqs\"\nregion = \"us-east-1\"\nqueue_url = \"https://sqs.us-east-2.amazonaws.com/123456789012/MyQueue\"\nauth.access_key_id = \"SECRET[backend_1.aws_access_key_id]\"\nauth.secret_access_key = \"SECRET[backend_1.aws_secret_access_key]\"\n```\n\n----------------------------------------\n\nTITLE: Go GC Duration Seconds Summary - Prometheus\nDESCRIPTION: This snippet provides a summary of the pause duration of garbage collection cycles in Go, including quantiles, sum, and count.  It is essential for understanding the performance impact of garbage collection.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_37\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.\n# TYPE go_gc_duration_seconds summary\ngo_gc_duration_seconds{quantile=\"0\"} 2.8372e-05\ngo_gc_duration_seconds{quantile=\"0.25\"} 2.8372e-05\ngo_gc_duration_seconds{quantile=\"0.5\"} 0.00016285\ngo_gc_duration_seconds{quantile=\"0.75\"} 0.00016426\ngo_gc_duration_seconds{quantile=\"1\"} 0.00016426\ngo_gc_duration_seconds_sum 0.000355482\ngo_gc_duration_seconds_count 3\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Transactions Total Metrics - Prometheus\nDESCRIPTION: This snippet shows the total number of transactions handled by WiredTiger, categorized by type (begins, checkpoints, committed, rolledback). These metrics are crucial for monitoring database transaction activity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_28\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_mongod_wiredtiger_transactions_total The total number of transactions WiredTiger has handled\n# TYPE mongodb_mongod_wiredtiger_transactions_total counter\nmongodb_mongod_wiredtiger_transactions_total{type=\"begins\"} 12\nmongodb_mongod_wiredtiger_transactions_total{type=\"checkpoints\"} 0\nmongodb_mongod_wiredtiger_transactions_total{type=\"committed\"} 6\nmongodb_mongod_wiredtiger_transactions_total{type=\"rolledback\"} 6\n```\n\n----------------------------------------\n\nTITLE: Example of Vector Internal Metrics Output\nDESCRIPTION: This is an example of the JSON output generated by Vector's internal metrics. It includes metrics like component received events count, namespace, tags, timestamp, kind, and aggregated histogram information. This output provides insights into Vector's operational status.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_16\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"component_received_events_count\",\n  \"namespace\": \"vector\",\n  \"tags\": {\n    \"component_id\": \"sink_0\",\n    \"component_kind\": \"sink\",\n    \"component_type\": \"http\",\n    \"host\": \"MY_HOST\"\n  },\n  \"timestamp\": \"2025-02-12T15:58:03.723449Z\",\n  \"kind\": \"absolute\",\n  \"aggregated_histogram\": {\n    \"buckets\": [\n      // ...\n      {\n        \"upper_limit\": 1.0,\n        \"count\": 2\n      },\n      // ...\n      {\n        \"upper_limit\": \"inf\",\n        \"count\": 0\n      }\n    ],\n    \"count\": 2,\n    \"sum\": 2.0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Reduced Event (New Behavior) - JSON\nDESCRIPTION: This JSON represents the reduced event resulting from the reduce transform with the new behavior in Vector 0.40. It demonstrates that the nested field 'message.a.b' now aggregates the values from both input events into an array of arrays.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": 777,\n  \"an_array\": [\n    {\n      \"inner\": 1\n    }\n  ],\n  \"message\": {\n    \"a\": {\n      \"b\": [\n        [1, 2],\n        [3,4]\n      ],\n      \"num\": 3\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Compiled Configuration Example - TOML\nDESCRIPTION: Illustrates how a Vector configuration and a pipeline are compiled into an equivalent configuration. The pipeline's transform (`bar`) is namespaced (`foo#baz`) to avoid conflicts, and the output of the transform is connected to the sink's input.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# /etc/vector/vector.toml\n[sources.in]\n# ...\n\n[sinks.out]\n# ...\n\n# /etc/vector/pipelines/foo.toml\n[transforms.bar]\ninputs = [\"in\"]\noutputs = [\"out\"]\n# ...\n\n# equivalent once compiled\n[sources.in]\n# ...\n\n[transforms.foo#baz]\ninputs = [\"in\"]\n\n[sinks.out]\n# the # notation is just a representation of the pipeline namespace\ninputs = [\"foo#baz\"]\n# ...\n```\n\n----------------------------------------\n\nTITLE: Loading CSV Module in Lua Transform\nDESCRIPTION: This TOML configuration shows how to load the downloaded `csv.lua` module within the `source` section of the `lua` transform.  The `require` function loads the module, making its functions available through the `csv` global variable. This allows the transform to parse CSV formatted messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\nsource = \"\"\"\n  csv = require(\"csv\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Create Vector Docker alias (Shell)\nDESCRIPTION: This command creates an alias for running Vector commands within a Docker container.  It mounts the current directory as a volume for configuration files and removes the container after execution. This simplifies running Vector commands in a Docker environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nalias vector='docker run -i -v $(pwd)/:/etc/vector/ --rm timberio/vector:{{< version >}}-debian'\n```\n\n----------------------------------------\n\nTITLE: Decoded Kinesis Firehose Event (JSON)\nDESCRIPTION: This JSON represents the event after being decoded by the `aws_kinesis_firehose` source.  The `message` field contains a CloudWatch Logs subscription event, which encapsulates the original log events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": \"{\\n  \\\"messageType\\\": \\\"DATA_MESSAGE\\\",\\n  \\\"owner\\\": \\\"111111111111\\\",\\n  \\\"logGroup\\\": \\\"/test\\\",\\n  \\\"logStream\\\": \\\"test\\\",\\n  \\\"subscriptionFilters\\\": [\\n    \\\"Destination\\\"\\n  ],\\n  \\\"logEvents\\\": [\\n    {\\n      \\\"id\\\": \\\"35683658089614582423604394983260738922885519999578275840\\\",\\n      \\\"timestamp\\\": 1600110569039,\\n      \\\"message\\\": \\\"{\\\\\\\"bytes\\\\\\\":26780,\\\\\\\"datetime\\\\\\\":\\\\\\\"14/Sep/2020:11:45:41 -0400\\\\\\\",\\\\\\\"host\\\\\\\":\\\\\\\"157.130.216.193\\\\\\\",\\\\\\\"method\\\\\\\":\\\\\\\"PUT\\\\\\\",\\\\\\\"protocol\\\\\\\":\\\\\\\"HTTP/1.0\\\\\\\",\\\\\\\"referer\\\\\\\":\\\\\\\"https://www.principalcross-platform.io/markets/ubiquitous\\\\\\\",\\\\\\\"request\\\\\\\":\\\\\\\"/expedite/convergence\\\\\\\",\\\\\\\"source_type\\\\\\\":\\\\\\\"stdin\\\\\\\",\\\\\\\"status\\\\\\\":301,\\\\\\\"user-identifier\\\\\\\":\\\\\\\"-\\\\\\\"}\\\"\\n    },\\n    {\\n      \\\"id\\\": \\\"35683658089659183914001456229543810359430816722590236673\\\",\\n      \\\"timestamp\\\": 1600110569041,\\n      \\\"message\\\": \\\"{\\\\\\\"bytes\\\\\\\":17707,\\\\\\\"datetime\\\\\\\":\\\\\\\"14/Sep/2020:11:45:41 -0400\\\\\\\",\\\\\\\"host\\\\\\\":\\\\\\\"109.81.244.252\\\\\\\",\\\\\\\"method\\\\\\\":\\\\\\\"GET\\\\\\\",\\\\\\\"protocol\\\\\\\":\\\\\\\"HTTP/2.0\\\\\\\",\\\\\\\"referer\\\\\\\":\\\\\\\"http://www.investormission-critical.io/24/7/vortals\\\\\\\",\\\\\\\"request\\\\\\\":\\\\\\\"/scale/functionalities/optimize\\\\\\\",\\\\\\\"source_type\\\\\\\":\\\\\\\"stdin\\\\\\\",\\\\\\\"status\\\\\\\":502,\\\\\\\"user-identifier\\\\\\\":\\\\\\\"feeney1708\\\\\\\"}\\\"\\n    }\\n  ]\\n}\\n\",\n  \"request_id\": \"ed1d787c-b9e2-4631-92dc-8e7c9d26d804\",\n  \"source_arn\": \"arn:aws:firehose:us-east-1:111111111111:deliverystream/test\",\n  \"timestamp\": \"2020-09-14T19:12:40.138Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Buffer Max Size Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the maximum size of the oplog buffer during replication in MongoDB. This value is a constant.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_20\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_buffer_max_size_bytes maxSizeBytes reports the maximum size of the buffer. This value is a constant setting in the mongod, and is not configurable\n# TYPE mongodb_mongod_metrics_repl_buffer_max_size_bytes counter\nmongodb_mongod_metrics_repl_buffer_max_size_bytes 0\n```\n\n----------------------------------------\n\nTITLE: VRL Template String Example\nDESCRIPTION: This example demonstrates VRL template string usage. It shows how to insert variable values into a string using `{{..}}`. The variable must resolve to a string.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\nbeverage = \"coffee\"\npreference = \"I love to drink {{ beverage }}!\"\n\nassert!(preference == \"I love to drink coffee!\")\n```\n\n----------------------------------------\n\nTITLE: Upgrade Vector using dpkg\nDESCRIPTION: Upgrades Vector to a new version using dpkg. Requires the .deb package to be downloaded beforehand. Replace `{arch}` with the correct architecture.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/dpkg.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ndpkg -i vector-{{< version >}}-{arch}\n```\n\n----------------------------------------\n\nTITLE: Configuring gcp_stackdriver_metrics (New)\nDESCRIPTION: This is the new configuration for the `gcp_stackdriver_metrics` sink, which simplifies label definition by moving them directly under the `resource` section.  It requires specifying `type`, `inputs`, `credentials_path`, `project_id` and nested `resource`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my_sink_id]\ntype = \"gcp_stackdriver_metrics\"\ninputs = [ \"my-source-or-transform-id\" ]\ncredentials_path = \"/path/to/credentials.json\"\nproject_id = \"vector-123456\"\n\n  [sinks.my_sink_id.resource]\n  type = \"global\"\n  projectId = \"vector-123456\"\n  instanceId = \"Twilight\"\n  zone = \"us-central1-a\"\n```\n\n----------------------------------------\n\nTITLE: Ensuring All Elements Adhere to a Condition\nDESCRIPTION: Demonstrates how to ensure all elements in an array adhere to a specific condition. In this example, a new boolean field `.all_public` is added, which is true if none of the IP addresses in `.ips` start with \"180.14\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_48\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n# Add new `all_public` boolean field.\n.all_public = all(.ips) -> |_index, ip| {\n    ip = string(ip) ?? \"unknown\"\n\n    !starts_with(ip, \"180.14\")\n}\n```\n\n----------------------------------------\n\nTITLE: Set Fixed Concurrency in Vector (TOML)\nDESCRIPTION: This configuration sets a fixed concurrency level for HTTP-based sinks in Vector. It limits the number of concurrent requests to the specified value. This overrides the default adaptive concurrency behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-10-06-arc-default.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nrequest.concurrency = 5\n```\n\n----------------------------------------\n\nTITLE: Implementing Field Coalescing with VRL Conditionals\nDESCRIPTION: This code snippet demonstrates how to achieve field coalescing functionality in Vector's VRL after the removal of the dedicated path coalescing operator. It uses conditional statements to check for the existence of fields and assign the first existing field to a new variable. This approach replicates the previous behavior using VRL's conditional logic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-06-17-0-39-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: vrl\nCODE:\n```\nfield = if exists(.field1) {\n  .field1\n} else if exists(.field2) {\n  .field2\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Frees Total Metric - Prometheus\nDESCRIPTION: This snippet represents the total number of frees performed by the Go program. It provides context for the allocated memory and the effectiveness of memory management.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_43\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_frees_total Total number of frees.\n# TYPE go_memstats_frees_total counter\ngo_memstats_frees_total 32884\n```\n\n----------------------------------------\n\nTITLE: Run Vector with FIPS Provider\nDESCRIPTION: This command sets the OPENSSL_CONF and OPENSSL_MODULES environment variables to point to the FIPS provider configuration file and the FIPS module directory, respectively. It then runs Vector with the specified configuration file, enabling the FIPS OpenSSL provider.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/tls.md#_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nOPENSSL_CONF=/path/to/openssl-fips.cnf \\\nOPENSSL_MODULES=/path/to/fips-modules \\\n    vector --config /path/to/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Build NixOS tests for Vector\nDESCRIPTION: This shell command uses `nix-build` to build the NixOS test suite for Vector. This command can be run with a local copy of the `nixpkgs` repository to test Vector configurations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/operating-systems/nixos.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nnix-build -A nixosTests.vector\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Inuse Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of heap bytes that are in use by the Go program. This provides information about actual memory being used in the heap.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_48\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.\n# TYPE go_memstats_heap_inuse_bytes gauge\ngo_memstats_heap_inuse_bytes 8.830976e+06\n```\n\n----------------------------------------\n\nTITLE: Raw String Log Event Input (TOML)\nDESCRIPTION: This configuration demonstrates how to specify a raw string value as input to a Vector unit test for log events. This is useful for testing transforms that handle unstructured log data, such as parsing syslog messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_14\n\nLANGUAGE: toml\nCODE:\n```\n[[tests.inputs]]\ninsert_at = \"add_metadata\"\nvalue = \"<102>1 2020-12-22T15:22:31.111Z vector-user.biz su 2666 ID389 - Something went wrong\"\n```\n\n----------------------------------------\n\nTITLE: Remap Transform Configuration: emit_root\nDESCRIPTION: This configuration option allows users to control whether the root object (`.`) is emitted after the remap program has run. By default it is set to true, preserving the current behaviour, but can be set to false to suppress.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_18\n\nLANGUAGE: text\nCODE:\n```\nemit_root = true/false # default false\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Released Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of heap bytes released to the OS by the Go program. It indicates how much memory has been returned to the system.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_50\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.\n# TYPE go_memstats_heap_released_bytes gauge\ngo_memstats_heap_released_bytes 5.738496e+07\n```\n\n----------------------------------------\n\nTITLE: Lua Aggregator Transform Configuration (DRY)\nDESCRIPTION: This TOML configuration demonstrates a more DRY (Don't Repeat Yourself) approach to defining the Lua transform. It extracts the metric creation logic into a separate Lua function and reuses it in both the timer handler and the shutdown hook.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.aggregator]\ntype = \"lua\"\nversion = \"2\"\ninputs = [] # add IDs of the input components here\ntimers = [{interval_seconds = 5, handler = \"\"\"\n  function (emit)\n    emit(make_counter(counter))\n    counter = 0\n  end\n\"\"\"}]\n\nhooks.shutdown = \"\"\"\n  function (emit)\n    emit(make_counter(counter))\n  end\n\"\"\"\n\nsource = \"\"\"\n  function make_counter(value)\n    return metric = {\n      name = \\\"event_counter\\\",\n      kind = \\\"incremental\\\",\n      timestamp = os.date(\\\"!*t\\\"),\n      counter = {\n        value = value\n      }\n    }\n  end\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Filter Transform with Remap (VRL) Condition - TOML\nDESCRIPTION: This example shows a `filter` transform using a VRL condition defined inline. This is the shorthand version and doesn't require specifying `type = \"vrl\"`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_3\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.filter_a]\n  inputs = [\"stdin\"]\n  type = \"filter\"\n  condition = '''\n      message = if exists(.tags) { .tags.message } else { .message }\n      message == \"test filter 1\"\n    '''\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the total number of bytes obtained from the system by the Go program. It represents overall memory usage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_63\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_sys_bytes Number of bytes obtained from system.\n# TYPE go_memstats_sys_bytes gauge\ngo_memstats_sys_bytes 7.4268928e+07\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Lock Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics for MongoDB locks, specifically tracking the time spent acquiring global locks. It includes labels for database and lock type (read/write) to provide granular insights into lock contention.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_4\n\nLANGUAGE: Text\nCODE:\n```\n# TYPE mongodb_mongod_locks_time_acquiring_global_microseconds_total counter\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Collection\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Collection\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Database\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Database\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Global\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Global\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Mutex\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"Mutex\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"ReplicationStateTransition\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"ReplicationStateTransition\",type=\"write\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"oplog\",type=\"read\"} 0\nmongodb_mongod_locks_time_acquiring_global_microseconds_total{database=\"oplog\",type=\"write\"} 0\n```\n\n----------------------------------------\n\nTITLE: Defining ValidatableComponent Trait in Rust\nDESCRIPTION: This code snippet defines the `ValidatableComponent` trait in Rust. This trait exposes methods to retrieve component name, type, configuration, and external resource, which are essential for component validation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub trait ValidatableComponent: Send + Sync {\n    /// Gets the name of the component.\n    fn component_name(&self) -> &'static str;\n\n    /// Gets the type of the component.\n    fn component_type(&self) -> ComponentType;\n\n    /// Gets the component configuration.\n    fn component_configuration(&self) -> ComponentConfiguration;\n\n    /// Gets the external resource associated with this component.\n    fn external_resource(&self) -> Option<ExternalResource>;\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Objects Metric - Prometheus\nDESCRIPTION: This snippet shows the number of allocated objects on the heap in the Go program. This is an important metric for understanding heap object density.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_49\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_objects Number of allocated objects.\n# TYPE go_memstats_heap_objects gauge\ngo_memstats_heap_objects 28822\n```\n\n----------------------------------------\n\nTITLE: Add WASM toolchain with Rustup\nDESCRIPTION: Adds the `wasm32-wasi` toolchain to your Rust environment using `rustup`. This allows you to compile Rust code to WebAssembly with WASI support, which is necessary for creating WASM plugins for Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_2\n\nLANGUAGE: Bash\nCODE:\n```\nrustup target add wasm32-wasi\n```\n\n----------------------------------------\n\nTITLE: Migrating Lua Transform from v1 to v2\nDESCRIPTION: Shows how to upgrade a Lua transform configuration from version 1 to version 2, which includes changes to the `version` field and the structure of the Lua source code. Version 1 is deprecated and will be removed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[transform.example]\ntype = \"lua\"\nversion = 2\nhooks.process = \"\"\"\n  function (event, emit)\n    event.log.a = \"some value\"\n    event.log.b = nil\n    emit(event)\n  end\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Tail Vector Aggregator Logs (kubectl)\nDESCRIPTION: This command retrieves and displays the logs from the Vector aggregator running as a StatefulSet within the 'vector' Kubernetes namespace. It's used for monitoring and debugging the aggregator's operation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\n\"kubectl logs -n vector statefulset/vector\"\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output After Parsing\nDESCRIPTION: This JSON snippet represents the output after parsing the Apache log.  It includes the extracted fields like bytes_out, host, method, resource, protocol, status, timestamp, client, and user. The timestamp has been converted to the correct format and the bytes_out and status are numbers.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_4\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"bytes_out\": 20574,\n  \"host\": \"5.86.210.12\",\n  \"method\": \"GET\",\n  \"resource\": \"/embrace/supply-chains/dynamic/vertical\",\n  \"protocol\": \"HTTP/1.0\",\n  \"status\": 201,\n  \"timestamp\": \"2021-02-03T23:13:55Z\",\n  \"client\": \"-\",\n  \"user\": \"zieme4647\"\n}\n```\n\n----------------------------------------\n\nTITLE: Resulting Log Event after Throttling in JSON\nDESCRIPTION: This snippet shows the log event that passes through the `throttle` transform, given the configuration and input events shown in previous examples. Due to the threshold of 1 event per 60 seconds, only the first event is allowed through.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-12-event-throttle-transform.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\"host\":\"host-1.hostname.com\",\"message\":\"First message\",\"timestamp\":\"2020-10-07T12:33:21.223543Z\"}\n```\n\n----------------------------------------\n\nTITLE: Defining MongoDB Prometheus Metrics\nDESCRIPTION: This snippet defines Prometheus metrics for monitoring MongoDB server statistics, including asserts, connections, and memory usage. It uses the HELP directive to provide descriptions for each metric and the TYPE directive to specify the metric type (gauge or counter). The metrics provide insights into the performance and resource utilization of MongoDB instances.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_3\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_asserts_total The asserts document reports the number of asserts on the database. While assert errors are typically uncommon, if there are non-zero values for the asserts, you should check the log file for the mongod process for more information. In many cases these errors are trivial, but are worth investigating.\n# TYPE mongodb_asserts_total counter\nmongodb_asserts_total{type=\"msg\"} 0\nmongodb_asserts_total{type=\"regular\"} 0\nmongodb_asserts_total{type=\"rollovers\"} 0\nmongodb_asserts_total{type=\"user\"} 4\nmongodb_asserts_total{type=\"warning\"} 0\n# HELP mongodb_connections The connections sub document data regarding the current status of incoming connections and availability of the database server. Use these values to assess the current load and capacity requirements of the server\n# TYPE mongodb_connections gauge\nmongodb_connections{state=\"active\"} 2\nmongodb_connections{state=\"available\"} 201\nmongodb_connections{state=\"current\"} 3\n# HELP mongodb_connections_metrics_created_total totalCreated provides a count of all incoming connections created to the server. This number includes connections that have since closed\n# TYPE mongodb_connections_metrics_created_total counter\nmongodb_connections_metrics_created_total 3\n# HELP mongodb_exporter_build_info A metric with a constant '1' value labeled by version, revision, branch, and goversion from which mongodb_exporter was built.\n# TYPE mongodb_exporter_build_info gauge\nmongodb_exporter_build_info{branch=\"\",goversion=\"go1.15\",revision=\"\",version=\"\"} 1\n# HELP mongodb_exporter_last_scrape_duration_seconds Duration of the last scrape of metrics from MongoDB.\n# TYPE mongodb_exporter_last_scrape_duration_seconds gauge\nmongodb_exporter_last_scrape_duration_seconds 0.003769113\n# HELP mongodb_exporter_last_scrape_error Whether the last scrape of metrics from MongoDB resulted in an error (1 for error, 0 for success).\n# TYPE mongodb_exporter_last_scrape_error gauge\nmongodb_exporter_last_scrape_error 0\n# HELP mongodb_exporter_scrape_errors_total Total number of times an error occurred scraping a MongoDB.\n# TYPE mongodb_exporter_scrape_errors_total counter\nmongodb_exporter_scrape_errors_total 0\n# HELP mongodb_exporter_scrapes_total Total number of times MongoDB was scraped for metrics.\n# TYPE mongodb_exporter_scrapes_total counter\nmongodb_exporter_scrapes_total 2\n# HELP mongodb_extra_info_heap_usage_bytes The heap_usage_bytes field is only available on Unix/Linux systems, and reports the total size in bytes of heap space used by the database process\n# TYPE mongodb_extra_info_heap_usage_bytes gauge\nmongodb_extra_info_heap_usage_bytes 0\n# HELP mongodb_extra_info_page_faults_total The page_faults Reports the total number of page faults that require disk operations. Page faults refer to operations that require the database server to access data which isn’t available in active memory. The page_faults counter may increase dramatically during moments of poor performance and may correlate with limited memory environments and larger data sets. Limited and sporadic page faults do not necessarily indicate an issue\n# TYPE mongodb_extra_info_page_faults_total gauge\nmongodb_extra_info_page_faults_total 912\n# HELP mongodb_instance_local_time The localTime value is the current time, according to the server, in UTC specified in an ISODate format.\n# TYPE mongodb_instance_local_time gauge\nmongodb_instance_local_time 1.600833548e+09\n# HELP mongodb_instance_uptime_estimate_seconds uptimeEstimate provides the uptime as calculated from MongoDB's internal course-grained time keeping system.\n# TYPE mongodb_instance_uptime_estimate_seconds counter\nmongodb_instance_uptime_estimate_seconds 35\n# HELP mongodb_instance_uptime_seconds The value of the uptime field corresponds to the number of seconds that the mongos or mongod process has been active.\n# TYPE mongodb_instance_uptime_seconds counter\nmongodb_instance_uptime_seconds 35\n# HELP mongodb_memory The mem data structure holds information regarding the target system architecture of mongod and current memory use\n# TYPE mongodb_memory gauge\nmongodb_memory{type=\"mapped\"} 0\nmongodb_memory{type=\"mapped_with_journal\"} 0\nmongodb_memory{type=\"resident\"} 36\nmongodb_memory{type=\"virtual\"} 6385\n# HELP mongodb_mongod_global_lock_client The activeClients data structure provides more granular information about the number of connected clients and the operation types (e.g. read or write) performed by these clients\n# TYPE mongodb_mongod_global_lock_client gauge\nmongodb_mongod_global_lock_client{type=\"reader\"} 0\nmongodb_mongod_global_lock_client{type=\"writer\"} 0\n# HELP mongodb_mongod_global_lock_current_queue The currentQueue data structure value provides more granular information concerning the number of operations queued because of a lock\n# TYPE mongodb_mongod_global_lock_current_queue gauge\nmongodb_mongod_global_lock_current_queue{type=\"reader\"} 0\nmongodb_mongod_global_lock_current_queue{type=\"writer\"} 0\n# HELP mongodb_mongod_global_lock_ratio The value of ratio displays the relationship between lockTime and totalTime. Low values indicate that operations have held the globalLock frequently for shorter periods of time. High values indicate that operations have held globalLock infrequently for longer periods of time\n# TYPE mongodb_mongod_global_lock_ratio gauge\nmongodb_mongod_global_lock_ratio 0\n# HELP mongodb_mongod_global_lock_total The value of totalTime represents the time, in microseconds, since the database last started and creation of the globalLock. This is roughly equivalent to total server uptime\n# TYPE mongodb_mongod_global_lock_total counter\nmongodb_mongod_global_lock_total 0\n# HELP mongodb_mongod_locks_time_acquiring_global_microseconds_total amount of time in microseconds that any database has spent waiting for the global lock\n```\n\n----------------------------------------\n\nTITLE: Defining EventContainer, LogContainer, MetricContainer traits in Rust\nDESCRIPTION: These traits define a generic interface for iterating over events, logs, and metrics, respectively.  They provide a way for components to work with both single events and arrays of events, ensuring compatibility and flexibility.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\ntrait EventContainer: ByteSizeOf {\n    type Iter: Iterator<Item = Event>;\n    fn into_events(self) -> Self::Iter;\n}\n\nimpl EventContainer for Event { … }\nimpl EventContainer for EventVec { … }\nimpl EventContainer for LogEvent { … }\nimpl EventContainer for LogVec { … }\nimpl EventContainer for Metric { … }\nimpl EventContainer for MetricVec { … }\n\ntrait LogContainer: ByteSizeOf {\n    type Iter;\n    fn into_logs(self) -> Self::Iter;\n}\n\nimpl LogContainer for LogEvent { … }\nimpl LogContainer for LogVec { … }\n\ntrait MetricContainer: ByteSizeOf {\n    type Iter;\n    fn into_metrics(self) -> Self::Iter;\n}\n\nimpl MetricContainer for Metric { … }\nimpl MetricContainer for MetricVec { … }\n```\n\n----------------------------------------\n\nTITLE: Processing Events in WASM Transform Module (Rust)\nDESCRIPTION: This Rust code demonstrates how to process events within a WASM transform module for Vector. It uses `serde_json` for deserializing the event data from a byte slice into a `BTreeMap`, adds new fields to the event, and then uses `hostcall::emit` to send the modified event back to Vector. The `#[no_mangle]` attribute makes the `process` function accessible from C code. The function takes a pointer `data` and a length `length` as arguments, which are used to create a mutable byte slice from the raw memory location. Note that the return value `1` indicates successful processing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_1\n\nLANGUAGE: Rust\nCODE:\n```\nuse vector_wasm::hostcall;\n#[no_mangle]\npub extern \"C\" fn process(data: u64, length: u64) -> usize {\n    let data = unsafe {\n        std::ptr::slice_from_raw_parts_mut(data as *mut u8, length as usize)\n            .as_mut()\n            .unwrap()\n    };\n    let mut event: BTreeMap<String, Value> = serde_json::from_slice(data).unwrap();\n    event.insert(\"new_field\".into(), \"new_value\".into());\n    event.insert(\"new_field_2\".into(), \"new_value_2\".into());\n    hostcall::emit(serde_json::to_vec(&event).unwrap());\n    1\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering messages containing 'error' using 'contains' predicate in Vector\nDESCRIPTION: This code snippet shows how to configure a filter transform in Vector to only process messages that contain the word 'error'. It uses the 'contains' predicate to match the 'message' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-01-more-condition-predicates.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.errors]\n  type = \"filter\"\n  condition.\"message.contain\" = \"error\"\n```\n\n----------------------------------------\n\nTITLE: Complete Rust WASM Module Example\nDESCRIPTION: This Rust code snippet showcases a complete WASM module for Vector. It defines the `init`, `process`, and `shutdown` functions, which are the entry points for Vector to interact with the module. The `init` function registers the module as a transform and sets the WASI flag to true, enabling WASI support. The `process` function processes incoming events, adds new fields, and emits the modified event using `hostcall::emit`. The `shutdown` function is called when the module is unloaded.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_5\n\nLANGUAGE: Rust\nCODE:\n```\nuse serde_json::Value;\nuse std::collections::BTreeMap;\nuse vector_wasm::{hostcall, Registration};\n\n#[no_mangle]\npub extern \"C\" fn init() -> *mut Registration {\n    &mut Registration::transform().set_wasi(true) as *mut Registration\n}\n\n#[no_mangle]\npub extern \"C\" fn process(data: u64, length: u64) -> usize {\n    let data = unsafe {\n        std::ptr::slice_from_raw_parts_mut(data as *mut u8, length as usize)\n            .as_mut()\n            .unwrap()\n    };\n    let mut event: BTreeMap<String, Value> = serde_json::from_slice(data).unwrap();\n    event.insert(\"new_field\".into(), \"new_value\".into());\n    event.insert(\"new_field_2\".into(), \"new_value_2\".into());\n    hostcall::emit(serde_json::to_vec(&event).unwrap());\n    1\n}\n#[no_mangle]\npub extern \"C\" fn shutdown() {\n    ();\n}\n```\n\n----------------------------------------\n\nTITLE: Watching Kubernetes Events using Kubectl\nDESCRIPTION: This command-line instruction demonstrates how to use `kubectl` to watch Kubernetes Events across all namespaces. It's used as a reference point to describe a feature to capture Kubernetes events and process them as Vector events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nkubectl get events --all-namespaces --watch\n```\n\n----------------------------------------\n\nTITLE: Trim Character From All Keys VRL\nDESCRIPTION: This VRL snippet recursively trims a specified character (in this case, `_`) from the beginning of all keys in an object. It uses `map_keys` with the `recursive: true` option and the `trim_start` function to achieve this.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_12\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_keys(., recursive: true) -> |key| { trim_start(key, \"_\") }\n```\n\n----------------------------------------\n\nTITLE: Replacement for ndjson Encoding with framing\nDESCRIPTION: This TOML snippet shows the replacement of the `ndjson` encoding with a combination of `json` encoding and `newline_delimited` framing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_21\n\nLANGUAGE: toml\nCODE:\n```\nframing.method = \"newline_delimited\"\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Operation Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics for specific MongoDB operations (fastmod, idhack, scan_and_order), which provide insights into how MongoDB handles update and query operations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_13\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_operation_total operation is a sub-document that holds counters for several types of update and query operations that MongoDB handles using special operation types\n# TYPE mongodb_mongod_metrics_operation_total counter\nmongodb_mongod_metrics_operation_total{type=\"fastmod\"} 0\nmongodb_mongod_metrics_operation_total{type=\"idhack\"} 0\nmongodb_mongod_metrics_operation_total{type=\"scan_and_order\"} 0\n```\n\n----------------------------------------\n\nTITLE: Initial Vector Configuration - YAML\nDESCRIPTION: This YAML configuration represents an initial Vector configuration with two demo_logs sources, an internal_metrics source, a transform, an http sink, and a console sink. The remap transform adds a 'group' field based on the 'key' field of the logs. The HTTP sink sends data to a local HTTP server and the console sink outputs internal metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\n# version 1\napi:\n  enabled: true\n\nsources:\n  source_0:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"a\", \"property\": \"foo\" }'\n      - '{ \"key\": \"b\", \"property\": \"bar\" }'\n    interval: 10\n\n  source_1:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"c\", \"property\": \"some\" }'\n      - '{ \"key\": \"d\", \"property\": \"another\" }'\n    interval: 10\n\n  internal_metrics:\n    type: internal_metrics\n    scrape_interval_secs: 10\n\ntransforms:\n  transform_0:\n    type: remap\n    inputs:\n      - source_*\n    source: |\n      . = parse_json!(.message)\n      if .key == \"a\" {\n        .group = 0\n      } else {\n        .group = 1\n      }\n\nsinks:\n  sink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://localhost:8000/logs\n    encoding:\n      codec: json\n      json:\n        pretty: true\n\n  sink_1:\n    type: console\n    inputs:\n      - internal_metrics\n    encoding:\n      codec: json\n      json:\n        pretty: true\n```\n\n----------------------------------------\n\nTITLE: Grant Vector access to Caddy logs\nDESCRIPTION: This Nix configuration snippet shows how to grant Vector access to log files belonging to the Caddy web server. It configures a `file` source to read Caddy logs, transforms to parse the timestamp and a systemd service configuration to grant access.  It includes a transformation to parse timestamps from Caddy logs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/operating-systems/nixos.md#_snippet_1\n\nLANGUAGE: Nix\nCODE:\n```\n  services.vector = {\n    enable = true;\n    journaldAccess = true;\n    settings = {\n      sources = {\n        journald.type = \"journald\";\n\n        caddy = {\n          type = \"file\";\n          include = [ \"/var/log/caddy/*.log\" ];\n        };\n\n        vector_metrics.type = \"internal_metrics\";\n      };\n\n      transforms = {\n        caddy_logs_timestamp = {\n          type = \"remap\";\n          inputs = [ \"caddy\" ];\n          source = ''\n            .tmp_timestamp, err = parse_json!(.message).ts * 1000000\n\n            if err != null {\n              log(\"Unable to parse ts value: \" + err, level: \"error\")\n            } else {\n              .timestamp = from_unix_timestamp!(to_int!(.tmp_timestamp), unit: \"microseconds\")\n            }\n\n            del(.tmp_timestamp)\n          '';\n        };\n      };\n\n      sinks = {\n        loki = {\n          type = \"loki\";\n          encoding.codec = \"json\";\n          inputs = [ \"caddy_logs_timestamp\" \"journald\" ];\n          endpoint = \"https://loki.mycompany.com\";\n\n          labels.source = \"vector\";\n        };\n\n        prometheus_exporter = {\n          type = \"prometheus_exporter\";\n          inputs = [ \"vector_metrics\" ];\n          address = \"[::]:9598\";\n        };\n      };\n    };\n  };\n\n  systemd.services.vector.serviceConfig = {\n    SupplementaryGroups = [ \"caddy\" ];\n  };\n```\n\n----------------------------------------\n\nTITLE: CloudWatch Logs Event Example 1\nDESCRIPTION: This JSON object represents a CloudWatch Logs event. It includes fields like status code, timestamp, and subscription filters. The data originates from an AWS service and might be processed by a Vector pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_19\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"status\": 301,\n  \"subscription_filters\": [\n    \"Destination\"\n  ],\n  \"timestamp\": \"2020-09-14T19:09:29.039Z\",\n  \"user-identifier\": \"-\"\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the number of heap bytes obtained from the system by the Go program. This is the total amount of heap space acquired from the OS.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_51\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.\n# TYPE go_memstats_heap_sys_bytes gauge\ngo_memstats_heap_sys_bytes 6.63552e+07\n```\n\n----------------------------------------\n\nTITLE: PushResult Enum and Batch Trait Definition in Rust\nDESCRIPTION: Defines the `PushResult` enum and `Batch` trait in Rust for failable batch insertion. `PushResult` indicates whether pushing an event to the buffer succeeded or resulted in an overflow. The `Batch` trait defines the `push` method, which attempts to push an event into the batch and returns a `PushResult` to indicate success or failure due to overflow. The `#must_use` attribute enforces the handling of the return value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-06-12-2768-batch-and-buffer-rework.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n#[must_use]\nenum PushResult<E> {\n    Ok,\n    Overflow(E),\n}\n\ntrait Batch {\n    fn push(&mut self, event: Self::Input) -> PushResult<Self::Input>;\n}\n```\n\n----------------------------------------\n\nTITLE: Actual Concurrency Metric Emission in Rust\nDESCRIPTION: This snippet demonstrates how to emit a metric for the actual concurrency. The `value!` macro records the current actual concurrency, along with the component kind and type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\nimpl InternalEvent for ConcurrencyActual {\n    fn emit_metrics(&self) {\n        value!(\"concurrency_actual\", self.concurrency,\n            \"component_kind\" => \"sink\",\n            \"component_type\" => self.component,\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Correct HTTP Config\nDESCRIPTION: This snippet demonstrates executing Vector with a configuration that is intended to simulate a correct HTTP setup. It pipes the contents of `five-lines-second` to Vector's stdin, sets the `VECTOR_LOG` environment variable for verbose logging, and specifies the configuration file `config-right-http.toml`. The command aims to test Vector's handling of successful HTTP requests.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-second | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-pr -c ./config-right-http.toml\n```\n\n----------------------------------------\n\nTITLE: CLI Option Example: Multiple Config Files\nDESCRIPTION: This example demonstrates how to specify multiple configuration files using the `--config` option. Values must be comma-separated.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\nvector --config foo.toml,bar.toml\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Session Open Cursors Metrics - Prometheus\nDESCRIPTION: This snippet captures the total number of cursors opened in WiredTiger, the MongoDB storage engine.  This gauge metric is useful for monitoring resource usage within the database.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_24\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_mongod_wiredtiger_session_open_cursors_total The total number of cursors opened in WiredTiger\n# TYPE mongodb_mongod_wiredtiger_session_open_cursors_total gauge\nmongodb_mongod_wiredtiger_session_open_cursors_total 0\n```\n\n----------------------------------------\n\nTITLE: Datadog APM Stats Protobuf Definition\nDESCRIPTION: This Protobuf definition describes the structure of APM stats payloads sent by the Datadog trace-agent. It includes fields for service name, resource, HTTP status code, type, database type, hit counts, error counts, duration, latency summaries, and flags indicating synthetics traffic and top-level spans. These stats represent aggregated information about the performance of instrumented code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-03-9862-ingest-apm-stats-along-traces-in-dd-agent-source.md#_snippet_0\n\nLANGUAGE: protobuf\nCODE:\n```\nstring service = 1;\nstring name = 2;\nstring resource = 3;\nuint32 HTTP_status_code = 4;\nstring type = 5;\nstring DB_type = 6; // db_type might be used in the future to help in the obfuscation step\nuint64 hits = 7; // count of all spans aggregated in the groupedstats\nuint64 errors = 8; // count of error spans aggregated in the groupedstats\nuint64 duration = 9; // total duration in nanoseconds of spans aggregated in the bucket\nbytes okSummary = 10; // ddsketch summary of ok spans latencies encoded in protobuf\nbytes errorSummary = 11; // ddsketch summary of error spans latencies encoded in protobuf\nbool synthetics = 12; // set to true on spans generated by synthetics traffic\nuint64 topLevelHits = 13; // count of top level spans aggregated in the groupedstats\n```\n\n----------------------------------------\n\nTITLE: File Source Pseudocode in Rust\nDESCRIPTION: This pseudocode outlines the current top-level structure of the `file` source in Vector. It shows the main loop which loads checkpoints, finds files, sorts them, reads data from them, removes files if configured, sends data downstream, and handles backoff and shutdown.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-10-15-3480-file-source-rework.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nlet checkpoints = load_checkpoints();\n\n// Find files we're configured to watch\nlet file_list = look_for_files();\n\n// Prioritize files that exist on startup\nsort(file_list);\n\nloop {\n    // Do these things occasionally to avoid burning CPU\n    if its_time() {\n        checkpoints.persist();\n        let current_file_list = look_for_files();\n        reconcile(&mut file_list, current_file_list);\n    }\n\n    for file in file_list {\n        // Don't check inactive files as often\n        if !should_read(file) {\n          continue;\n        }\n\n        // Try to read new data from the files\n        while let Some(line) = file.read_line() {\n          output.push(line)\n          // But not an infinite amount at one time\n          if limit_reached { break }\n        }\n\n        // If configured, rm files when we're done with them\n        maybe_rm(file)\n\n        // Either continue to read the next file, or break to start back at the\n        // beginning of the (prioritized) list\n        if should_not_read_next_file() {\n          break\n        }\n    }\n\n    // Drop handles of deleted files that we've finished reading\n    unwatch_dead(&mut file_list);\n\n    // Send the gathered data downstream\n    emit(output);\n\n    // If we're not seeing any new data, back off to avoid burning CPU\n    maybe_backoff();\n\n    // If Vector is shutting down, stop processing\n    maybe_shutdown();\n}\n```\n\n----------------------------------------\n\nTITLE: VRL Error Message Example (Rust)\nDESCRIPTION: This is an example of the error message that a user might receive if they don't handle a fallible assignment properly in VRL. This error is displayed at compile-time, promoting safer code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_10\n\nLANGUAGE: rust\nCODE:\n```\nerror[E103]: unhandled fallible assignment\n  ┌─ :1:5\n  │\n1 │ . = parse_common_log(.log)\n  │ --- ^^^^^^^^^^^^^^^^^^^^^^\n  │ │   │\n  │ │   this expression is fallible\n  │ │   update the expression to be infallible\n  │ or change this to an infallible assignment:\n  │ ., err = parse_common_log(.log)\n  │\n  = see documentation about error handling at https://errors.vrl.dev/#handling\n  = learn more about error code 103 at https://errors.vrl.dev/103\n  = see language documentation at https://vrl.dev\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Last GC Time Seconds Metric - Prometheus\nDESCRIPTION: This snippet indicates the number of seconds since 1970 of the last garbage collection in the Go program. This helps in understanding GC frequency.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_52\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.\n# TYPE go_memstats_last_gc_time_seconds gauge\ngo_memstats_last_gc_time_seconds 1.599788641219671e+09\n```\n\n----------------------------------------\n\nTITLE: Configuring Blackhole Sink\nDESCRIPTION: Configures a `blackhole` sink to discard all incoming events. The sink takes input from the source named `in`. This allows demonstration of event flow using `vector tap`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.out]\ntype = \"blackhole\"\ninputs = [\"in*\"]\n```\n\n----------------------------------------\n\nTITLE: Transforming add_tags with remap\nDESCRIPTION: Replacing the `add_tags` transform with the `remap` transform. Adds tags to the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.add_tags]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\n.tags.some_tag = \"some_value\"\n'''\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Document Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics for document operations in MongoDB (deleted, inserted, returned, updated). These metrics, when compared to opcounters, offer insights into data access and modification patterns.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_9\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_document_total The document holds a document of that reflect document access and modification patterns and data use. Compare these values to the data in the opcounters document, which track total number of operations\n# TYPE mongodb_mongod_metrics_document_total counter\nmongodb_mongod_metrics_document_total{state=\"deleted\"} 0\nmongodb_mongod_metrics_document_total{state=\"inserted\"} 0\nmongodb_mongod_metrics_document_total{state=\"returned\"} 0\nmongodb_mongod_metrics_document_total{state=\"updated\"} 0\n```\n\n----------------------------------------\n\nTITLE: Nullify Empty Strings VRL\nDESCRIPTION: This VRL snippet recursively iterates through all values within the current object (`.`) and replaces any empty string values with `null`. It uses the `map_values` function with the `recursive: true` option to ensure that nested values are also processed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_3\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_values(., recursive: true) -> |value| { if value == \"\" { null } else { value } }\n```\n\n----------------------------------------\n\nTITLE: Running Clippy Linter\nDESCRIPTION: This command runs the Clippy linter to catch common mistakes in Rust code.  It uses `cargo vdev check rust` with the `--clippy` flag to perform the linting process. This ensures code quality and adherence to best practices.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\ncargo vdev check rust --clippy\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Prometheus Exporter\nDESCRIPTION: This snippet configures Vector to expose its internal metrics via a Prometheus exporter. The exporter listens on address 0.0.0.0:9598. This allows Prometheus to scrape metrics from Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_30\n\nLANGUAGE: yaml\nCODE:\n```\nsinks:\n  sink_2:\n    type: prometheus_exporter\n    inputs:\n      - internal_metrics\n    address: 0.0.0.0:9598\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Mspan Inuse Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes in use by mspan structures in Go.  It reflects memory allocation metadata.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_57\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.\n# TYPE go_memstats_mspan_inuse_bytes gauge\ngo_memstats_mspan_inuse_bytes 124712\n```\n\n----------------------------------------\n\nTITLE: Vector Lua Transform: Log to Metric (Isolated Module)\nDESCRIPTION: This TOML configuration demonstrates using a loadable Lua module with isolated functions for the log-to-metric transform. It loads the module into a variable and uses dot notation to call the functions within the module, ensuring namespace isolation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  type = \"lua\"\n  inputs = []\n  version = \"2\"\n  search_dirs = [\"/example/search/dir\"]\n  source = \"example_transform = require 'example_transform.lua'\"\n  hooks.init = \"example_transform.init\"\n  hooks.process = \"example_transform.process\"\n  hooks.shutdown = \"example_transform.shutdown\"\n  timers = [{interval_seconds = 10, handler = \"example_transform.timer_handler\"}]\n```\n\n----------------------------------------\n\nTITLE: Install Vector using Easy Install Script\nDESCRIPTION: This script detects your platform and determines the best method for installing Vector. It can be customized with the `--prefix` option to specify a custom installation directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/_index.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n{{< easy-install-scripts >}}\n```\n\n----------------------------------------\n\nTITLE: Configure Enrichment Table for IoT Status in Vector TOML\nDESCRIPTION: This TOML configuration sets up an enrichment table named 'iot_status' in Vector, reading from a CSV file. It specifies the file path, encoding as CSV, and the schema defining the data types for 'status_code' and 'status_message' columns.  The file path needs to be adapted to the actual location.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[enrichment_tables.iot_status]\ntype = \"file\"\n\n[enrichment_tables.iot_status.file]\npath = \"/etc/vector/iot_status.csv\"\nencoding = { type = \"csv\" }\n\n[enrichment_tables.iot_status.schema]\nstatus_code = \"integer\"\nstatus_message = \"string\"\n```\n\n----------------------------------------\n\nTITLE: Configure Vector service in NixOS\nDESCRIPTION: This Nix configuration snippet demonstrates how to enable and configure the Vector service in NixOS. It defines sources (journald, internal_metrics), and sinks (loki, prometheus_exporter) with their respective settings, including endpoint, codec, and labels.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/operating-systems/nixos.md#_snippet_0\n\nLANGUAGE: Nix\nCODE:\n```\nservices.vector = {\n  enable = true;\n  journaldAccess = true;\n  settings = {\n    sources = {\n      journald.type = \"journald\";\n\n      vector_metrics.type = \"internal_metrics\";\n    };\n\n    sinks = {\n      loki = {\n        type = \"loki\";\n        inputs = [ \"journald\" ];\n        endpoint = \"https://loki.mycompany.com\";\n        encoding = { codec = \"json\"; };\n\n        labels.source = \"journald\";\n      };\n\n      prometheus_exporter = {\n        type = \"prometheus_exporter\";\n        inputs = [ \"vector_metrics\" ];\n        address = \"[::]:9598\"\n      };\n    };\n  };\n};\n```\n\n----------------------------------------\n\nTITLE: Socket Source Event Example (JSON)\nDESCRIPTION: This is an example event from a socket source (UDP) using the syslog codec. It shows the structure of a typical log event ingested from a socket.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": \"Hello Vector\",\n    \"hostname\": \"localhost\",\n    \"severity\": \"info\",\n    \"facility\": \"facility\",\n    \"appname\": \"Vector Hello World\",\n    \"msgid\": \"238467-435-235-a3478fh\",\n    \"procid\": 13512\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Transaction Checkpoint Metrics - Prometheus\nDESCRIPTION: This snippet presents the time in milliseconds transactions have checkpointed in WiredTiger, providing metrics for min, max and total values. It's a measure of the database's write performance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_26\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds The time in milliseconds transactions have checkpointed in WiredTiger\n# TYPE mongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds gauge\nmongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds{type=\"max\"} 0\nmongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds{type=\"min\"} 0\n# HELP mongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds_total The total time in milliseconds transactions have checkpointed in WiredTiger\n# TYPE mongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds_total counter\nmongodb_mongod_wiredtiger_transactions_checkpoint_milliseconds_total 0\n```\n\n----------------------------------------\n\nTITLE: Source Context and Configuration in Rust\nDESCRIPTION: This code introduces `SourceContext`, a struct to encapsulate context data passed to sources during building, and defines the `SourceConfig` trait with an asynchronous `build` method. This streamlines the configuration process for sources.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-03-26-6517-end-to-end-acknowledgement.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nstruct SourceContext<'a> {\n    name: &'a str,\n    identifier: Box<str>,\n    globals: &'a GlobalOptions,\n    shutdown: ShutdownSignal,\n    out: Pipeline,\n}\n\ntrait SourceConfig {\n    async fn build(&self, context: SourceContext<'_>) -> crate::Result<sources::Source>;\n}\n```\n\n----------------------------------------\n\nTITLE: Profiling Vector with Perf (Shell)\nDESCRIPTION: This command uses `perf` to record performance data from a running Vector process while under load. It records the call graph using the dwarf format for detailed analysis. Requires a running Vector process and socat.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_17\n\nLANGUAGE: sh\nCODE:\n```\nperf record -F99 --call-graph dwarf -p $VECTOR_PID socat -dd OPEN:access.log TCP:localhost:9000\n```\n\n----------------------------------------\n\nTITLE: Create IAM Role for Firehose (bash)\nDESCRIPTION: Creates an IAM role for Kinesis Firehose to write to the S3 bucket and the CloudWatch Logs log group. It includes creating the role, and attaching a policy that grants the required permissions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ aws iam create-role \\\n  --role-name FirehoseVector \\\n  --assume-role-policy-document file://<( cat <<EOF\n{\n  \"Statement\": {\n    \"Effect\": \"Allow\",\n    \"Principal\": {\n      \"Service\": \"firehose.amazonaws.com\"\n    },\n    \"Action\": \"sts:AssumeRole\",\n    \"Condition\": {\n      \"StringEquals\": {\n        \"sts:ExternalId\": \"${AWS_ACCOUNT_ID}\"\n      }\n    }\n  }\n}\nEOF\n)\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ aws iam put-role-policy --role-name FirehoseVector \\\n    --policy-name FirehoseVectorS3 \\\n    --policy-document file://<(cat <<EOF\n{\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"s3:AbortMultipartUpload\",\n        \"s3:GetBucketLocation\",\n        \"s3:GetObject\",\n        \"s3:ListBucket\",\n        \"s3:ListBucketMultipartUploads\",\n        \"s3:PutObject\"\n      ],\n      \"Resource\": [\n        \"arn:aws:s3:::${FIREHOSE_S3_BUCKET}\",\n        \"arn:aws:s3:::${FIREHOSE_S3_BUCKET}/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": [\n        \"arn:aws:logs:${AWS_REGION}:${AWS_ACCOUNT_ID}:log-group:${FIREHOSE_LOG_GROUP}:*\"\n      ]\n    }\n  ]\n}\nEOF\n)\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Buck Hash Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes used by the profiling bucket hash table in Go.  It indicates memory used by runtime structures.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_42\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.\n# TYPE go_memstats_buck_hash_sys_bytes gauge\ngo_memstats_buck_hash_sys_bytes 1.448715e+06\n```\n\n----------------------------------------\n\nTITLE: Map Keys Function Signature in VRL\nDESCRIPTION: This signature shows how to use the `map_keys` function to iterate over an object and change its keys.  The function takes an object as input and a boolean for recursion, returning a string.  Recursion is optional and defaults to false.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\nmap_keys(value: object, recursive: bool) -> |string| { string }\n```\n\n----------------------------------------\n\nTITLE: Defining TaskTransform trait with EventContainer in Rust\nDESCRIPTION: This trait defines the interface for task transforms, which operate asynchronously on streams of events. The `TaskTransform` trait is parameterized by `EventContainer`, enabling it to work with both single events and arrays of events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\ntrait TaskTransform<T: EventContainer>: Send {\n    fn transform(\n        self: Box<Self>,\n        task: Pin<Box<dyn Stream<Item = T> + Send>>,\n    ) -> Pin<Box<dyn Stream<Item = T> + Send>>\n    where\n        Self: 'static;\n}\n\n// Allow existing task transforms to be converted with `.into()`\nimpl<T: TaskTransform<Event>> From<T> for Transform { … }\n```\n\n----------------------------------------\n\nTITLE: Vector Global Configuration (YAML)\nDESCRIPTION: This YAML snippet shows the global options configuration for vector, including data directory and the API settings.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_8\n\nLANGUAGE: yaml\nCODE:\n```\n# Set global options\ndata_dir: \"/var/lib/vector\"\n\n# Vector's API (disabled by default)\n# Enable and try it out with the `vector top` command\napi:\n  enabled: false\n  # address: \"127.0.0.1:8686\"\n```\n\n----------------------------------------\n\nTITLE: Lua Aggregator Transform Configuration (Initial)\nDESCRIPTION: This TOML configuration defines a Lua transform that aggregates events into a counter metric. It includes 'init', 'process', and 'shutdown' hooks, as well as a timer handler for periodic metric emission.  The 'init' hook initializes the counter, the 'process' hook increments it, the timer emits the metric, and the shutdown hook emits a final metric.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.aggregator]\ntype = \"lua\"\nversion = \"2\"\ninputs = [] # add IDs of the input components here\n\nhooks.init = \"\"\"\n  function (emit)\n    count = 0 -- initialize state by setting a global variable\n  end\n\"\"\"\n\nhooks.process = \"\"\"\n  function (event, emit)\n    count = count + 1 -- increment the counter and exit\n  end\n\"\"\"\n\ntimers = [{interval_seconds = 5, handler = \"\"\"\n  function (emit)\n    emit {\n      metric = {\n        name = \"event_counter\",\n        kind = \"incremental\",\n        timestamp = os.date(\"!*t\"),\n        counter = {\n          value = counter\n        }\n      }\n    }\n    counter = 0\n  end\n\"\"\"}]\n\nhooks.shutdown = \"\"\"\n  function (emit)\n    emit {\n      metric = {\n        name = \"event_counter\",\n        kind = \"incremental\",\n        timestamp = os.date(\"!*t\"),\n        counter = {\n          value = counter\n        }\n      }\n    }\n  end\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Define BasicRequest Struct - Rust\nDESCRIPTION: Defines the `BasicRequest` struct containing the payload, event finalizers, and request metadata.  This struct is used to encapsulate all the information needed to send data to the HTTP endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Clone)]\nstruct BasicRequest {\n    payload: Bytes,\n    finalizers: EventFinalizers,\n    metadata: RequestMetadata,\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Vector Source/Sink v2\nDESCRIPTION: This code snippet demonstrates how to enable version 2 of the Vector source and sink by adding the `version = \"2\"` configuration option to both components. This transitions the communication protocol from TCP to gRPC over HTTP.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-vector-source-sink.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n[sinks.vector]\n  type = \"vector\"\n+ version = \"2\"\n\n[sources.vector]\n  type = \"vector\"\n+ version = \"2\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Event Fields\nDESCRIPTION: This example demonstrates accessing nested fields within a log event using the `{{ ... }}` syntax and a VRL path expression.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\noption = \"{{ .parent.child }}\"\n```\n\n----------------------------------------\n\nTITLE: Update BasicSink Struct - Rust\nDESCRIPTION: Updates the `BasicSink` struct to include an `endpoint` string and an `HttpClient` instance. The `new` function initializes the `HttpClient` with TLS settings and clones the endpoint from the configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Debug, Clone)]\nstruct BasicSink {\n    endpoint: String,\n    client: HttpClient,\n}\n\nimpl BasicSink {\n    pub fn new(config: &BasicConfig) -> Self {\n        let tls = TlsSettings::from_options(&None).unwrap();\n        let client = HttpClient::new(tls, &Default::default()).unwrap();\n        let endpoint = config.endpoint.clone();\n\n        Self { client, endpoint }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Lua Timer Handler (Refactored)\nDESCRIPTION: This Lua code defines the timer handler after refactoring. It calls the `make_counter` function to create the metric and then resets the counter.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_3\n\nLANGUAGE: lua\nCODE:\n```\nfunction (emit)\n    emit(make_counter(counter))\n    counter = 0\n  end\n```\n\n----------------------------------------\n\nTITLE: Retrieving Datadog API Key\nDESCRIPTION: This example illustrates how to retrieve the Datadog API key using both the old `get_metadata_field` function and the new `get_secret` function. Both methods will return the same key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-06-07-vrl-metadata-and-secrets.md#_snippet_2\n\nLANGUAGE: coffeescript\nCODE:\n```\nget_metadata_field(\"datadog_api_key\")\nget_secret(\"datadog_api_key\")\n```\n\n----------------------------------------\n\nTITLE: Changing HTTP Return Status using Curl\nDESCRIPTION: This command uses `curl` to send a POST request to the Python HTTP server, changing the HTTP return status code. It's used to simulate different scenarios, like error conditions, for testing Vector's retry mechanism.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://localhost:8000/set_status -H \"Content-Type: application/json\" -d '{\"status\": 404}'\n```\n\n----------------------------------------\n\nTITLE: TOML Dedupe Transform New Syntax\nDESCRIPTION: This TOML snippet shows the new syntax for defining a dedupe transform in Vector. Field names with dashes now require quoting to be correctly parsed. The dot is inside the quotes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.dedupe]\ntype = \"dedupe\"\ninputs = [\"input\"]\nfields.match = [\"message.\\\"user-identifier\\\"\"]\n```\n\n----------------------------------------\n\nTITLE: Lua Module for Aggregation\nDESCRIPTION: This Lua code defines a module named 'aggregator' containing the functions 'init', 'process', 'timer_handler', 'shutdown', and 'make_counter'. This allows for separation of concerns and potential reuse of the aggregation logic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_7\n\nLANGUAGE: lua\nCODE:\n```\nfunction init()\n  count = 0\nend\n\nfunction aggregator.process()\n  count = count + 1\nend\n\nfunction aggregator.timer_handler(emit)\n  emit(make_counter(counter))\n  counter = 0\nend\n\nfunction aggregator.shutdown(emit)\n  emit(make_counter(counter))\nend\n\nfunction aggregator.make_counter(value)\n  return metric = {\n    name = \"event_counter\",\n    kind = \"incremental\",\n    timestamp = os.date(\"!*t\"),\n    counter = {\n      value = value\n    }\n  }\nend\n```\n\n----------------------------------------\n\nTITLE: Creating Clean Data Directories with Shell Script\nDESCRIPTION: This shell script creates clean data directories. It's used to ensure a clean environment for testing Vector's data processing capabilities.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./create-clean-data-directories.sh\n```\n\n----------------------------------------\n\nTITLE: Building Vector with Feature Flags (Bash)\nDESCRIPTION: This command demonstrates how to build a custom version of Vector using the `make build` command with the `FEATURES` environment variable. The `FEATURES` variable specifies the components to include in the build. This example includes the `sources-file`, `transforms-json_parser`, and `sinks-kafka` components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-28-custom-vector-builds.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nFEATURES=\"sources-file,transforms-json_parser,sinks-kafka\" make build\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Metrics for Prometheus\nDESCRIPTION: This snippet defines various metrics related to MongoDB performance and resource usage in a format suitable for Prometheus. Each metric includes a help text describing its purpose and a type declaration specifying its data type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_67\n\nLANGUAGE: text\nCODE:\n```\n# TYPE mongodb_latency_reads untyped\nmongodb_latency_reads{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 368\n# HELP mongodb_latency_reads_count Telegraf collected metric\n# TYPE mongodb_latency_reads_count untyped\nmongodb_latency_reads_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 3\n# HELP mongodb_latency_writes Telegraf collected metric\n# TYPE mongodb_latency_writes untyped\nmongodb_latency_writes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_latency_writes_count Telegraf collected metric\n# TYPE mongodb_latency_writes_count untyped\nmongodb_latency_writes_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_net_in_bytes Telegraf collected metric\n# TYPE mongodb_net_in_bytes untyped\nmongodb_net_in_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 29\n# HELP mongodb_net_in_bytes_count Telegraf collected metric\n# TYPE mongodb_net_in_bytes_count untyped\nmongodb_net_in_bytes_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 1191\n# HELP mongodb_net_out_bytes Telegraf collected metric\n# TYPE mongodb_net_out_bytes untyped\nmongodb_net_out_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 4208\n# HELP mongodb_net_out_bytes_count Telegraf collected metric\n# TYPE mongodb_net_out_bytes_count untyped\nmongodb_net_out_bytes_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 126749\n# HELP mongodb_open_connections Telegraf collected metric\n# TYPE mongodb_open_connections untyped\nmongodb_open_connections{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 1\n# HELP mongodb_operation_scan_and_order Telegraf collected metric\n# TYPE mongodb_operation_scan_and_order untyped\nmongodb_operation_scan_and_order{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_operation_write_conflicts Telegraf collected metric\n# TYPE mongodb_operation_write_conflicts untyped\nmongodb_operation_write_conflicts{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_page_faults Telegraf collected metric\n# TYPE mongodb_page_faults untyped\nmongodb_page_faults{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_percent_cache_dirty Telegraf collected metric\n# TYPE mongodb_percent_cache_dirty untyped\nmongodb_percent_cache_dirty{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_percent_cache_used Telegraf collected metric\n# TYPE mongodb_percent_cache_used untyped\nmongodb_percent_cache_used{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_queries Telegraf collected metric\n# TYPE mongodb_queries untyped\nmongodb_queries{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 1\n# HELP mongodb_queries_per_sec Telegraf collected metric\n# TYPE mongodb_queries_per_sec untyped\nmongodb_queries_per_sec{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_queued_reads Telegraf collected metric\n# TYPE mongodb_queued_reads untyped\nmongodb_queued_reads{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_queued_writes Telegraf collected metric\n# TYPE mongodb_queued_writes untyped\nmongodb_queued_writes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_resident_megabytes Telegraf collected metric\n# TYPE mongodb_resident_megabytes untyped\nmongodb_resident_megabytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 97\n# HELP mongodb_storage_freelist_search_bucket_exhausted Telegraf collected metric\n# TYPE mongodb_storage_freelist_search_bucket_exhausted untyped\nmongodb_storage_freelist_search_bucket_exhausted{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_storage_freelist_search_requests Telegraf collected metric\n# TYPE mongodb_storage_freelist_search_requests untyped\nmongodb_storage_freelist_search_requests{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_storage_freelist_search_scanned Telegraf collected metric\n# TYPE mongodb_storage_freelist_search_scanned untyped\nmongodb_storage_freelist_search_scanned{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_central_cache_free_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_central_cache_free_bytes untyped\nmongodb_tcmalloc_central_cache_free_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 230960\n# HELP mongodb_tcmalloc_current_allocated_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_current_allocated_bytes untyped\nmongodb_tcmalloc_current_allocated_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 8.455176e+07\n# HELP mongodb_tcmalloc_current_total_thread_cache_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_current_total_thread_cache_bytes untyped\nmongodb_tcmalloc_current_total_thread_cache_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 682240\n# HELP mongodb_tcmalloc_heap_size Telegraf collected metric\n# TYPE mongodb_tcmalloc_heap_size untyped\nmongodb_tcmalloc_heap_size{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 8.904704e+07\n# HELP mongodb_tcmalloc_max_total_thread_cache_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_max_total_thread_cache_bytes untyped\nmongodb_tcmalloc_max_total_thread_cache_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 2.60046848e+08\n# HELP mongodb_tcmalloc_pageheap_commit_count Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_commit_count untyped\nmongodb_tcmalloc_pageheap_commit_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 46\n# HELP mongodb_tcmalloc_pageheap_committed_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_committed_bytes untyped\nmongodb_tcmalloc_pageheap_committed_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 8.904704e+07\n# HELP mongodb_tcmalloc_pageheap_decommit_count Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_decommit_count untyped\nmongodb_tcmalloc_pageheap_decommit_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_pageheap_free_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_free_bytes untyped\nmongodb_tcmalloc_pageheap_free_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 3.52256e+06\n# HELP mongodb_tcmalloc_pageheap_reserve_count Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_reserve_count untyped\nmongodb_tcmalloc_pageheap_reserve_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 46\n# HELP mongodb_tcmalloc_pageheap_scavenge_count Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_scavenge_count untyped\nmongodb_tcmalloc_pageheap_scavenge_count{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_pageheap_total_commit_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_total_commit_bytes untyped\nmongodb_tcmalloc_pageheap_total_commit_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 8.904704e+07\n# HELP mongodb_tcmalloc_pageheap_total_decommit_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_total_decommit_bytes untyped\nmongodb_tcmalloc_pageheap_total_decommit_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_pageheap_total_reserve_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_total_reserve_bytes untyped\nmongodb_tcmalloc_pageheap_total_reserve_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 8.904704e+07\n# HELP mongodb_tcmalloc_pageheap_unmapped_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_pageheap_unmapped_bytes untyped\nmongodb_tcmalloc_pageheap_unmapped_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_spinlock_total_delay_ns Telegraf collected metric\n# TYPE mongodb_tcmalloc_spinlock_total_delay_ns untyped\nmongodb_tcmalloc_spinlock_total_delay_ns{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_tcmalloc_thread_cache_free_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_thread_cache_free_bytes untyped\nmongodb_tcmalloc_thread_cache_free_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 682240\n# HELP mongodb_tcmalloc_total_free_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_total_free_bytes untyped\nmongodb_tcmalloc_total_free_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 972720\n# HELP mongodb_tcmalloc_transfer_cache_free_bytes Telegraf collected metric\n# TYPE mongodb_tcmalloc_transfer_cache_free_bytes untyped\nmongodb_tcmalloc_transfer_cache_free_bytes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 59520\n# HELP mongodb_total_available Telegraf collected metric\n# TYPE mongodb_total_available untyped\nmongodb_total_available{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_created Telegraf collected metric\n# TYPE mongodb_total_created untyped\nmongodb_total_created{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_docs_scanned Telegraf collected metric\n# TYPE mongodb_total_docs_scanned untyped\nmongodb_total_docs_scanned{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_in_use Telegraf collected metric\n# TYPE mongodb_total_in_use untyped\nmongodb_total_in_use{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_keys_scanned Telegraf collected metric\n# TYPE mongodb_total_keys_scanned untyped\nmongodb_total_keys_scanned{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_refreshing Telegraf collected metric\n# TYPE mongodb_total_refreshing untyped\nmongodb_total_refreshing{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n# HELP mongodb_total_tickets_reads Telegraf collected metric\n```\n\n----------------------------------------\n\nTITLE: MongoDB Active Writes Metric - Prometheus\nDESCRIPTION: This snippet displays the number of currently active write operations against a MongoDB instance, as collected by Telegraf. Provides server details.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_66\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_active_writes Telegraf collected metric\n# TYPE mongodb_active_writes untyped\nmongodb_active_writes{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 0\n```\n\n----------------------------------------\n\nTITLE: VRL: Specifying Data Types\nDESCRIPTION: This VRL snippet shows how to specify the data type of a field using `to_string!`. This can help differentiate between type errors and parsing errors, allowing for more precise error handling. The error handling now only triggers on malformed *strings* rather than other data types that cannot be parsed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_13\n\nLANGUAGE: coffee\nCODE:\n```\n.log = to_string!(.log)\n\n., err = parse_common_log(.log)\nif err != null {\n  # This error only occurs for malformed *strings*\n  log(\"Failed to parse common-log: \" + err, level: \"error\")\n} else {\n  .total_bytes = del(.size)\n}\n```\n\n----------------------------------------\n\nTITLE: Example Log Event in JSON Format\nDESCRIPTION: This JSON snippet shows a sample log event structure using a `log` object. It typically includes a `message` and a `timestamp` key. The JSON schema is subject to change.  Timestamp fields within log messages will be converted to strings due to limitations with JSON. This example shows the basic expected structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-31-native-event-codecs.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"log\": {\n    \"message\": \"hello world\",\n    \"timestamp\": \"2019-10-12T07:20:50.52Z\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: VRL `parse_regex` with `numeric_groups` Parameter\nDESCRIPTION: This example demonstrates how to use the `numeric_groups` parameter in VRL version 0.13 and later to include numeric capture groups in the output of the `parse_regex` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nparse_regex!(\"hello 123 world\", r'hello (?P<number>\\d+) world', numeric_groups: true)\n```\n\n----------------------------------------\n\nTITLE: Query PostgreSQL Statistics Tables (SQL)\nDESCRIPTION: These SQL queries retrieve performance statistics from PostgreSQL.  They are executed against the PostgreSQL server to collect metrics related to database activity, background writer processes, and conflict resolution. The results are then parsed and converted into metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-27-3603-postgres-metrics.md#_snippet_0\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM pg_stat_database\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM pg_stat_database_conflicts\n```\n\nLANGUAGE: SQL\nCODE:\n```\nSELECT * FROM pg_stat_bgwriter\n```\n\n----------------------------------------\n\nTITLE: Example Input JSON for Encryption\nDESCRIPTION: This is an example JSON input for the encryption process. It contains the plaintext message that will be encrypted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{ \"plaintext\": \"super secret message\" }\n```\n\n----------------------------------------\n\nTITLE: Vector Lua Transform: Field Manipulation\nDESCRIPTION: This TOML configuration defines a Lua transform that adds, modifies, and removes fields within events, demonstrating various operations on nested fields. It uses Lua version 2 and the `hooks.process` hook for event processing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  type = \"lua\"\n  inputs = []\n  version = \"2\"\n  hooks.process = \"\"\"\n    function (event, emit)\n      -- add new field (simple)\n      event.new_field = \"example\"\n      -- add new field (nested, overwriting the content of \\\"nested\\\" map)\n      event.nested = {\n        field = \"example value\"\n      }\n      -- add new field (nested, to already existing map)\n      event.nested.another_field = \"example value\"\n      -- add new field (nested, without assumptions about presence of the parent map)\n      if event.possibly_existing == nil then\n        event.possibly_existing = {}\n      end\n      event.possibly_existing.example_field = \"example value\"\n\n      -- remove field (simple)\n      event.removed_field = nil\n      -- remove field (nested, keep parent maps)\n      event.nested.field = nil\n      -- remove field (nested, if the parent map is empty, the parent map is removed too)\n      event.another_nested.field = nil\n      if next(event.another_nested) == nil then\n        event.another_nested = nil\n      end\n\n      -- rename field from \\\"original_field\\\" to \\\"another_field\\\"\n      event.original_field, event.another_field = nil, event.original_field\n\n      emit(event)\n    end\n  \"\"\"\n  \n```\n\n----------------------------------------\n\nTITLE: Demux Trace Flow based on Metadata (YAML)\nDESCRIPTION: This YAML configuration demonstrates how to demux a trace flow based on a condition evaluated against trace metadata. It uses the `opentelemetry` source to receive traces, a `remap` transform to set metadata based on enrichment table lookup, and a `datadog_traces` sink to emit traces to Datadog. The `inputs` field in the `transforms` and `sinks` sections defines how the transforms and sinks are connected.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n[...]\nsources:\n  otlp:\n    type: opentelemetry\n    address: \"[::]:8081\"\n    mode: grpc\n\ntransforms:\n  set_key:\n    type: remap\n      source: |-\n        if exists!(.tags.user_id) {\n          return\n        }\n        key = get_enrichment_table_record!(\"api_keys\", { \"user\": .tags.user_id })\n        set_metadata_field(\"datadog_api_key\", key)\n      inputs:\n       - otlp.traces # Would exclusively emit traces\n\nsinks:\n  dd_trace:\n    type: datadog_traces\n    default_api_key: 12345678abcdef\n    inputs:\n      - set_key\n```\n\n----------------------------------------\n\nTITLE: Fluentd Configuration for Log Parsing\nDESCRIPTION: This text-based configuration for Fluentd demonstrates parsing an Apache log. It uses a `source` with the `apache2` format, and a `<parse>` block with a regular expression to extract fields from the log message. It then uses a `filter` with `record_transformer` to remove the `time` and `log` fields. It also defines the `code` and `size` fields to be of type integer.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n<source>\n  # ... source options ...\n  format apache2\n  tag apache.access\n</source>\n\n<parse>\n  @type regexp\n  expression /^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \\[(?<time>[^\\]]*)\\] \\\"(?<method>\\S+)(?: +(?<path>[^ ]*) +\\S*)?\\\" (?<code>[^ ]*) (?<size>[^ ]*)(?: \\\"(?<referer>[^\"]*)\\\" \\\"(?<agent>[^\"]*)\\\")?$/\n  time_format %d/%b/%Y:%H:%M:%S %z\n  types code:integer,size:integer\n</parse>\n\n<filter apache.access>\n  @type record_transformer\n  remove_keys time,log\n</filter>\n\n# ... outputs ...\n```\n\n----------------------------------------\n\nTITLE: Run Vector with Legacy Provider\nDESCRIPTION: This command sets the OPENSSL_CONF environment variable to point to the legacy provider configuration file and then runs Vector with the specified configuration file. This enables the legacy OpenSSL provider for Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/tls.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nOPENSSL_CONF=/path/to/openssl-legacy.cnf \\\n    vector --config /path/to/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Generating a Flamegraph from Perf Data (Shell)\nDESCRIPTION: This series of commands processes the `perf.data` file to generate a flamegraph SVG. It uses `perf script` to extract the call stacks, `inferno-collapse-perf` to collapse them, and `inferno-flamegraph` to create the SVG.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_18\n\nLANGUAGE: sh\nCODE:\n```\nperf script | inferno-collapse-perf > stacks.folded\ncat stacks.folded | inferno-flamegraph > flamegraph.svg\n```\n\n----------------------------------------\n\nTITLE: Buffer Configuration - Drop Newest on Full\nDESCRIPTION: This configuration sets the buffer to drop the newest events when it is full.  This approach avoids backpressure, but it can lead to data loss if the sink cannot keep up with the incoming data rate.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/about/concepts.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nbuffer.when_full = drop_newest\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Reduced Event (Old Behavior) - JSON\nDESCRIPTION: This JSON represents the reduced event resulting from the reduce transform with the old behavior. Note how the nested field 'message.a.b' retains the values from only one of the input events due to the 'discard' strategy.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": 777,\n  \"an_array\": [\n    {\n      \"inner\": 2\n    }\n  ],\n  \"message\": {\n    \"a\": {\n      \"b\": [1, 2],\n      \"num\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Observe Vector Logs\nDESCRIPTION: Tails the logs from the Vector Docker container named 'vector' using the `docker logs` command with the `-f` flag to follow the logs in real-time. The `docker ps -aqf \"name=vector\"` command is used to dynamically identify the container ID.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ndocker logs -f $(docker ps -aqf \"name=vector\")\n```\n\n----------------------------------------\n\nTITLE: VRL Lexical Scoping Example\nDESCRIPTION: This example demonstrates the new lexical scoping rules in Vector's VRL (Vector Remap Language). Variables defined within nested blocks are no longer accessible by parent blocks. This change is a preparation for upcoming iteration support.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_9\n\nLANGUAGE: coffee\nCODE:\n```\n# top-level scope\ncount1 = 1\n\n# nested block\n{\n  count2 = 1\n  count1 = count1 + 1\n\n  # nested block\n  {\n    count2 = count2 + 1\n    count1 = count1 + 1\n  }\n}\n\ncount1 # returns ”3”\ncount2 # returns a compile-time error, because ”count2” was defined in a nested block\n```\n\n----------------------------------------\n\nTITLE: Loading Configuration from Directory (Rust)\nDESCRIPTION: This Rust code snippet illustrates how Vector loads configuration files from a directory and its subdirectories. It iterates through the children of a given path, identifies component type directories (e.g., `sinks`), and calls specific loading functions for each component type. It uses the `ConfigBuilder` to accumulate configuration and the error vector for tracking issues. The function processes both files and directories.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-12-9568-automatic-namespacing.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nfn load_builder_from_dir(path: &Path) -> Result<(ConfigBuilder, Vec<String>), Vec<String>> {\n  let mut builder = ConfigBuilder::default();\n  let mut errors = Vec::new();\n  for child in path.children() {\n    if child.is_dir() {\n      match child.name() {\n        // same with other component types like transforms, sources, tests, enrichment_tables\n        \"sinks\" => load_sinks_from_dir(child, &mut builder, &mut errors),\n        other => tracing::debug!(\"ignoring folder {}\", other),\n      }\n    } else {\n      load_builder_from_file(child, &mut builder, &mut errors);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Mspan Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the number of bytes used for mspan structures obtained from the system in Go. This reveals memory usage by the Go runtime.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_58\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.\n# TYPE go_memstats_mspan_sys_bytes gauge\ngo_memstats_mspan_sys_bytes 131072\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Source in Vector Helm Chart\nDESCRIPTION: This YAML snippet shows how to configure a `vector` source using the `customConfig` option within the Helm chart's `values.yaml` file.  It configures a Vector source to receive data. The snippet also shows the service configuration required to expose the port defined in the custom config.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sources:\n  ...\n    vector:\n      type: vector\n      address: 0.0.0.0:9000\n  ...\nservice:\n  ports:\n    - name: http\n      port: 9000\n      protocol: TCP\n      targetPort: 9000\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Specific Configuration (Shell)\nDESCRIPTION: This shell snippet executes the Vector binary with a specific configuration file (`config-wrong-http-big-buffer.toml`). It also sets a detailed logging configuration via the `VECTOR_LOG` environment variable to capture info and trace level logs. This is likely used for debugging and monitoring Vector's behavior under a defined scenario. The version of Vector being tested is v0.20.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ~/go/bin/flog -l | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-v0.20.0 -c ./config-wrong-http-big-buffer.toml\n2022-04-06T17:40:40.693387Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\"\n2022-04-06T17:40:40.693437Z  INFO vector::app: Loading configs. paths=[\"config-wrong-http-big-buffer.toml\"]\n2022-04-06T17:40:40.694227Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-04-06T17:40:40.728626Z  INFO vector::topology::running: Running healthchecks.\n2022-04-06T17:40:40.728662Z  INFO vector::topology::running: Starting source. key=stdin\n2022-04-06T17:40:40.728684Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-04-06T17:40:40.728681Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-04-06T17:40:40.728709Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"2a706a3 2022-02-11\"\n2022-04-06T17:40:40.728718Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-04-06T17:40:41.077849Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n...\n2022-04-06T17:41:01.103461Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-04-06T17:41:05.913348Z  INFO vector: Vector has stopped.\n2022-04-06T17:41:05.914492Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit, stdin\" time_remaining=\"59 seconds left\"\n^C2022-04-06T17:41:06.497154Z  INFO vector: Vector has quit.\n```\n\n----------------------------------------\n\nTITLE: Update Imports - Rust\nDESCRIPTION: Updates the necessary imports for creating an HTTP sink. Includes modules for task management, sink prelude, HTTP client, internal events, configuration telemetry, and byte handling.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nuse std::task::Poll;\n\nuse crate::{\n    sinks::prelude::*,\n    http::HttpClient,\n    internal_events::SinkRequestBuildError,\n};\nuse vector_core::config::telemetry;\nuse bytes::Bytes;\n```\n\n----------------------------------------\n\nTITLE: Implement safe merge function in Lua\nDESCRIPTION: This Lua code defines a `safe_merge` function that checks if the total length of merged lines exceeds a predefined limit (4096 characters). If the length is within the limit, it merges the event messages; otherwise, it returns nil to prevent unbounded growth of the message field. This function is meant to be used within the `source` section of the Lua transform configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/merge-multiline-logs-with-lua.md#_snippet_1\n\nLANGUAGE: lua\nCODE:\n```\nfunction safe_merge(merged_event, event)\n  if #merged_event.log.message + #event.log.message > 4096 then\n    return nil\n  else\n    merged_event.log.message = merged_event.log.message ..\n                               line_separator .. event.log.message\n    return merged_event\n  end\nend\n```\n\n----------------------------------------\n\nTITLE: Telemetry Tags Configuration YAML\nDESCRIPTION: This YAML snippet shows how to configure Vector to emit service and source tags in telemetry metrics. By setting `service` and `source_id` to `true`, Vector will include these tags in metrics, allowing for more detailed querying and analysis of data flow.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2023-05-03-data-volume-metrics.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntelemetry:\n  tags:\n    service: true\n    source_id: true\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB GetLastError WTime Milliseconds Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total time (in milliseconds) spent on getLastError operations with write concern (w > 1), waiting for replica set acknowledgment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_11\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_get_last_error_wtime_total_milliseconds total_millis reports the total amount of time in milliseconds that the mongod has spent performing getLastError operations with write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation (i.e. a w value greater than 1.)\n# TYPE mongodb_mongod_metrics_get_last_error_wtime_total_milliseconds counter\nmongodb_mongod_metrics_get_last_error_wtime_total_milliseconds 0\n```\n\n----------------------------------------\n\nTITLE: Configuring Max Events for Batching\nDESCRIPTION: This snippet sets the `max_events` parameter within the `batch` settings to 4. This reduces the number of events batched together before sending them to the sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_27\n\nLANGUAGE: yaml\nCODE:\n```\nbatch:\n      max_events: 4\n```\n\n----------------------------------------\n\nTITLE: Check llvm version using clang\nDESCRIPTION: This command checks the version of the llvm compiler toolchain using clang. The output shows the version, target architecture, thread model, and installation directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nclang --version\n```\n\n----------------------------------------\n\nTITLE: Vector Graph Output in DOT Format\nDESCRIPTION: This is the DOT representation of the Vector configuration. It defines the nodes (sources, transforms, and sinks) and their connections, forming a directed graph. The `shape` attribute specifies the visual representation of each node.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-vector-graph.md#_snippet_1\n\nLANGUAGE: DOT\nCODE:\n```\ndigraph {\n  \"internal_metrics\" [shape=trapezium]\n  \"dd_logs\" [shape=trapezium]\n  \"file_gen\" [shape=trapezium]\n  \"remap\" [shape=diamond]\n  \"file_gen\" -> \"remap\"\n  \"prometheus\" [shape=invtrapezium]\n  \"internal_metrics\" -> \"prometheus\"\n  \"dd_logs_egress\" [shape=invtrapezium]\n  \"dd_logs\" -> \"dd_logs_egress\"\n  \"blackhole\" [shape=invtrapezium]\n  \"remap\" -> \"blackhole\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Cargo.toml for WASM Plugin\nDESCRIPTION: This TOML configuration file defines the library type and dependencies for a Rust WASM plugin. `crate-type = [\"cdylib\"]` specifies that the crate should be compiled as a dynamically linked C library, which is the format required for WASM modules. The dependencies include `vector-wasm`, which provides the necessary bindings for interacting with Vector, and `serde` for serialization and deserialization.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[lib]\ncrate-type = [\"cdylib\"]\n\n[dependencies]\n# This will be published at a later date.\nvector-wasm = { path = \"/path/to/your/clone/of/vector/lib/vector-wasm\"}\nserde = { version = \"1\", features = [\"derive\"] }\n```\n\n----------------------------------------\n\nTITLE: Pulling and Running Vector Docker Image\nDESCRIPTION: This command pulls a specific version of the Vector Docker image and then runs it. The `X.X.X` should be replaced with the desired version number.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/docker/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull timberio/vector:X.X.X-alpine && \\\n  docker run timberio/vector:X.X.X-alpine\n```\n\n----------------------------------------\n\nTITLE: Example Output JSON after Encryption\nDESCRIPTION: This is an example JSON output after the encryption process. It contains the base64 encoded encrypted message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"encrypted_message\": \"jYn3wFE2ajfd/VpDE/SrLO5+DknxB3hqgjH5+hpnSu4=\" }\n```\n\n----------------------------------------\n\nTITLE: Testing with HTTP Server in Go\nDESCRIPTION: The Vector team used an in-house HTTP server written in Go for testing the Adaptive Request Concurrency (ARC) feature. This server is designed to be highly customizable and straightforward for simulating various HTTP scenarios.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/adaptive-request-concurrency.md#_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\n// No specific code provided in the context, but the document mentions using an in-house HTTP server written in Go for testing.\n// The server is located at [http_test_server]: https://github.com/vectordotdev/http_test_server\n```\n\n----------------------------------------\n\nTITLE: VRL for GeoIP Enrichment Table Lookup\nDESCRIPTION: This Vector Remap Language (VRL) snippet shows how to use the `get_enrichment_table_record!` function to lookup GeoIP information from the enrichment table `geoip_table` using the `ip_address` field from the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_6\n\nLANGUAGE: vrl\nCODE:\n```\n.geoip = get_enrichment_table_record!(\"geoip_table\",\n        {\n          \"ip\": .ip_address\n        }\n```\n\n----------------------------------------\n\nTITLE: CSV Data Example\nDESCRIPTION: This CSV snippet provides an example of the data structure used for enriching IoT device event logs, mapping codes to human-readable messages. It contains two columns, 'code' and 'message', representing the device status code and its corresponding description.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-csv-enrichment.md#_snippet_0\n\nLANGUAGE: csv\nCODE:\n```\ncode,message\n1,\"device battery full\"\n2,\"device battery good\"\n3,\"device battery ok\"\n4,\"device battery low\"\n5,\"device battery critical\"\n```\n\n----------------------------------------\n\nTITLE: Vector Lua Transform: Log to Metric (Inline Functions)\nDESCRIPTION: This TOML configuration demonstrates a log-to-metric transform using inline Lua functions. It initializes a counter, increments it for each event, and emits metric events based on a timer. It utilizes `hooks.init`, `hooks.process`, and `hooks.shutdown` for different lifecycle stages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  type = \"lua\"\n  inputs = []\n  version = \"2\"\n  hooks.init = \"\"\"\n    function init (emit)\n      event_counter = 0\n      emit({\n        log = {\n          message = \"starting up\"\n        }\n      }, \"auxiliary\")\n    end\n  \"\"\"\n  hooks.process = \"\"\"\n    function (event, emit)\n      event_counter = event_counter + 1\n    end\n  \"\"\"\n  hooks.shutdown = \"\"\"\n    function shutdown (emit)\n      emit {\n        metric = {\n          name = \"counter_10s\",\n          counter = {\n            value = event_counter\n          }\n        }\n      }\n\n      emit({\n        log = {\n          message = \"shutting down\"\n        }\n      }, \"auxiliary\")\n    end\n  \"\"\"\n  [[timers]]\n  interval_seconds = 10\n  handler = \"\"\"\n    function (emit)\n      emit {\n        metric = {\n          name = \"counter_10s\",\n          counter = {\n            value = event_counter\n          }\n        }\n      }\n      counter = 0\n    end\n  \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Pipeline Configuration Example in TOML\nDESCRIPTION: This example demonstrates how a pipeline might be configured using the proposed `namespace` field.  It shows a source (`apache_metrics`) setting a namespace, a transform using the namespace, and sinks (`prometheus`, `aws_cloudwatch_metrics`) handling the namespace differently based on their requirements.  It uses the `lua` transform to conditionally modify the metric based on its namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-02-3684-metric-namespaces.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"apache_metrics\"\n  endpoints = [\"http://localhost/server-status?auto\"]\n  namespace = \"apache\"\n\n[transforms.my_transform_id]\n  # General\n  type = \"lua\" # required\n  inputs = [\"my_source_id\"] # required\n  version = \"2\" # required\n\n  # Hooks\n  hooks.process = \"\"\"\n  function (event, emit)\n    if event.metric.namespace == \"apache\" then\n      -- do something\n    end\n\n    emit(event)\n  end\n  \"\"\"\n\n[sinks.prometheus]\n  type = \"prometheus\"\n  inputs = [\"my_transform_id\"]\n  address = \"0.0.0.0:9598\"\n  namespace = \"\"\n\n[sinks.cloudwatch]\n  type = \"aws_cloudwatch_metrics\"\n  inputs = [\"my_transform_id\"]\n  namespace = \"\"\n  region = \"us-east-1\"\n```\n\n----------------------------------------\n\nTITLE: Netcat Output after Vector Fix (HTTP)\nDESCRIPTION: This snippet shows the HTTP POST request sent by Vector version 0.20.0 after the `vector-fix` command is run and data is being output.  The request includes the content-type, user-agent, host, content-length, and the JSON payload.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_10\n\nLANGUAGE: HTTP\nCODE:\n```\nPOST /foo HTTP/1.1\ncontent-type: application/x-ndjson\nuser-agent: Vector/0.20.0 (x86_64-unknown-linux-gnu)\naccept-encoding: identity\nhost: localhost:7777\ncontent-length: 615\n\n{\"host\":\"consigliere\",\"message\":\"line one, woohoo\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-12T20:36:57.451273579Z\"}\n{\"host\":\"consigliere\",\"message\":\"line two, yippeee\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-12T20:36:57.451286459Z\"}\n{\"host\":\"consigliere\",\"message\":\"line three, oh my\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-12T20:36:57.451291089Z\"}\n{\"host\":\"consigliere\",\"message\":\"line four, woooooow\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-12T20:36:57.451294469Z\"}\n{\"host\":\"consigliere\",\"message\":\"live five, phew, that was a lot\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-12T20:36:57.451298419Z\"}\n```\n\n----------------------------------------\n\nTITLE: Example Vector Tap Output JSON\nDESCRIPTION: This JSON output demonstrates the output of the `vector tap in` command when used with the example configuration.  It shows a stream of JSON-formatted events, each containing a \"message\" field with a sequence number and the \"Hello World\" string, along with a \"timestamp\" field indicating when the event was generated. The `vector tap` command requires Vector's GraphQL API to be enabled.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-vector-tap.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"message\":\"13 Hello World\",\"timestamp\":\"2021-04-20T19:40:32.359390Z\"}\n{\"message\":\"14 Hello World\",\"timestamp\":\"2021-04-20T19:40:33.355298Z\"}\n{\"message\":\"15 Hello World\",\"timestamp\":\"2021-04-20T19:40:34.353215Z\"}\n{\"message\":\"16 Hello World\",\"timestamp\":\"2021-04-20T19:40:35.353493Z\"}\n{\"message\":\"17 Hello World\",\"timestamp\":\"2021-04-20T19:40:36.352089Z\"}\n{\"message\":\"18 Hello World\",\"timestamp\":\"2021-04-20T19:40:37.347406Z\"}\n```\n\n----------------------------------------\n\nTITLE: UDM Event Example\nDESCRIPTION: This is an example of a UDM event that conforms to a strict schema required by Google Chronicle.  It includes metadata, network details, and principal/target information.  This JSON demonstrates the expected structure for the `gcp_chronicle_udm` sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-05-17-11532-chronicle-sink.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"metadata\": {\n    \"event_timestamp\": \"2019-10-23T04:00:00.000Z\",\n    \"event_type\": \"NETWORK_HTTP\",\n    \"product_name\": \"Acme Proxy\",\n    \"vendor_name\": \"Acme\"\n  },\n  \"network\": {\n    \"http\": {\n      \"method\": \"GET\",\n      \"response_code\": 200\n    }\n  },\n  \"principal\": {\n    \"hostname\": \"host0\",\n    \"ip\": \"10.1.2.3\",\n    \"port\": 60000\n  },\n  \"target\": {\n    \"hostname\": \"www.altostrat.com\",\n    \"ip\": \"198.51.100.68\",\n    \"port\": 443,\n    \"url\": \"www.altostrat.com/images/logo.png\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Starship Prompt Configuration for vdev\nDESCRIPTION: This TOML snippet configures the Starship prompt to include a custom command that invokes `vdev meta starship`. This allows displaying Vector development-related information in the Starship prompt.  The `when = true` condition ensures that the command is always executed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/vdev/README.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\nformat = \"\"\"\n...\n${custom.vdev}\\ \n...\n$line_break\\ \n...\n$character\"\"\"\n\n# <clipped>\n\n[custom.vdev]\ncommand = \"vdev meta starship\"\nwhen = true\n# Windows\n# shell = [\"cmd\", \"/C\"]\n# Other\n# shell = [\"sh\", \"--norc\"]\n```\n\n----------------------------------------\n\nTITLE: Nginx Stub Status Output Example\nDESCRIPTION: This example shows the format of the output from the Nginx stub_status module, which the proposed Vector source will parse to extract metrics. It provides a basic overview of server activity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3640-nginx-metrics-source.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nActive connections: 1\nserver accepts handled requests\n 1 1 1\nReading: 0 Writing: 1 Waiting: 0\n```\n\n----------------------------------------\n\nTITLE: Updating Sample Transform with Check Fields Condition - TOML\nDESCRIPTION: This example shows how to update the `sample` transform configuration when using the deprecated `check_fields` condition syntax.  It demonstrates adding `type = \"check_fields\"` to the condition to ensure compatibility with Vector 0.15.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.sample]\ntype = \"sample\"\ninputs = [\"in\"]\nrate = 10\nkey_field = \"message\"\nexclude.\"message.contains\" = \"error\"\n```\n\n----------------------------------------\n\nTITLE: Counter Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create a counter metric event.  It includes the metric name and counter value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_20\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_counter\",\n    counter = {\n      value = 10\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector with Wildcards in Component IDs (YAML)\nDESCRIPTION: This configuration demonstrates the use of wildcards in component IDs for defining sinks that consume data from multiple sources. It defines three file sources (app1_logs, app2_logs, system_logs) and two sinks (app_logs and archive) that use wildcards in their inputs to match multiple source components. This simplifies the configuration by allowing a single sink to ingest data from multiple sources based on a naming pattern.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  app1_logs:\n    type: \"file\"\n    includes: [\"/var/log/app1.log\"]\n\n  app2_logs:\n    type: \"file\"\n    includes: [\"/var/log/app.log\"]\n\n  system_logs:\n    type: \"file\"\n    includes: [\"/var/log/system.log\"]\n\nsinks:\n  app_logs:\n    type: \"datadog_logs\"\n    inputs: [\"app*\"]\n\n  archive:\n    type: \"aws_s3\"\n    inputs: [\"app*\", \"system_logs\"]\n```\n\n----------------------------------------\n\nTITLE: Pretty Formatted JSON Output Example\nDESCRIPTION: This is a pretty formatted example of the structured JSON output after the logs have been parsed. The extracted fields from the CSV logs are displayed, providing a clear view of the structured data. The formatting makes it much easier to read and understand.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_8\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"application_name\": \"\",\n  \"backend_type\":\"not initialized\",\n  \"command_tag\": \"\",\n  \"connection_from\": \"\",\n  \"context\": \"\",\n  \"database_name\": \"\",\n  \"detail\": \"\",\n  \"error_severity\": \"LOG\",\n  \"file\": \"log.csv\",\n  \"hint\": \"Future log output will go to log destination \\\"csvlog\\\".\",\n  \"host\": \"localhost\",\n  \"internal_query\": \"\",\n  \"internal_query_pos\": \"\",\n  \"leader_pid\":\"\",\n  \"location\": \"\",\n  \"log_time\": \"2020-04-09 12:48:49.661 UTC\",\n  \"message\": \"ending log output to stderr\",\n  \"process_id\": \"1\",\n  \"query\": \"\",\n  \"query_id\":\"0\",\n  \"query_pos\": \"\",\n  \"session_id\": \"localhost.1\",\n  \"session_line_num\": \"1\",\n  \"session_start_time\": \"2020-04-09 12:48:49 UTC\",\n  \"sql_state_code\": \"00000\",\n  \"timestamp\": \"2020-04-09T19:49:07Z\",\n  \"transaction_id\": \"0\",\n  \"user_name\": \"\",\n  \"virtual_transaction_id\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Final Vector Configuration Example\nDESCRIPTION: This snippet presents a final Vector configuration that addresses the issues of unsupported compression and payload size limitations. The HTTP sink uses ZLIB compression and limits the batch size to 4 events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_28\n\nLANGUAGE: yaml\nCODE:\n```\n# version 3\napi:\n  enabled: true\n\nsources:\n  source_0:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"a\", \"property\": \"foo\" }'\n      - '{ \"key\": \"b\", \"property\": \"bar\" }'\n    interval: 10\n\n  source_1:\n    type: demo_logs\n    format: shuffle\n    lines:\n      - '{ \"key\": \"c\", \"property\": \"some\" }'\n      - '{ \"key\": \"d\", \"property\": \"another\" }'\n    interval: 10\n\n  internal_metrics:\n    type: internal_metrics\n    scrape_interval_secs: 10\n\ntransforms:\n  transform_0:\n    type: remap\n    inputs:\n      - source_*\n    source: |\n      . = parse_json!(.message)\n      if .key == \"a\" {\n        .group = 0\n      } else {\n        .group = 1\n      }\n\nsinks:\n  sink_0:\n    inputs:\n      - transform_0\n    type: http\n    uri: http://localhost:8000/logs\n    encoding:\n      codec: json\n      json:\n        pretty: true\n    compression: zlib\n    batch:\n      max_events: 4\n\n  sink_1:\n    type: console\n    inputs:\n      - internal_metrics\n    encoding:\n      codec: json\n      json:\n        pretty: true\n```\n\n----------------------------------------\n\nTITLE: Sample CloudWatch Log Events (JSON)\nDESCRIPTION: These are sample events published to a CloudWatch Log group, representing HTTP request logs. They contain fields like bytes, datetime, host, method, protocol, referer, request, source_type, status, and user-identifier.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bytes\": 26780,\n  \"datetime\": \"14/Sep/2020:11:45:41 -0400\",\n  \"host\": \"157.130.216.193\",\n  \"method\": \"PUT\",\n  \"protocol\": \"HTTP/1.0\",\n  \"referer\": \"https://www.principalcross-platform.io/markets/ubiquitous\",\n  \"request\": \"/expedite/convergence\",\n  \"source_type\": \"stdin\",\n  \"status\": 301,\n  \"user-identifier\": \"-\"\n}\n{\n  \"bytes\": 17707,\n  \"datetime\": \"14/Sep/2020:11:45:41 -0400\",\n  \"host\": \"109.81.244.252\",\n  \"method\": \"GET\",\n  \"protocol\": \"HTTP/2.0\",\n  \"referer\": \"http://www.investormission-critical.io/24/7/vortals\",\n  \"request\": \"/scale/functionalities/optimize\",\n  \"source_type\": \"stdin\",\n  \"status\": 502,\n  \"user-identifier\": \"feeney1708\"\n}\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Wrong HTTP Disk Config\nDESCRIPTION: This snippet demonstrates executing Vector with a configuration that is intended to simulate an incorrect HTTP setup and disk buffering. It pipes the contents of `five-lines-first` to Vector's stdin, sets the `VECTOR_LOG` environment variable for verbose logging, and specifies the configuration file `config-wrong-http-disk-v2.toml`. The command aims to test Vector's handling of HTTP errors and disk buffer behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069\ntotal 0\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-first | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-v0.20.0 -c ./config-wrong-http-disk-v2.toml\n```\n\n----------------------------------------\n\nTITLE: Updating LALRPOP Grammar for Function Calls - Rust\nDESCRIPTION: This snippet shows the updated LALRPOP grammar to support optional closures for function calls. It includes the original grammar and the modified version, which incorporates parsing logic for `FunctionClosure?`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_34\n\nLANGUAGE: rust\nCODE:\n```\nFunctionCall: FunctionCall = {\n    <ident: Sp<\"function call\">> <abort_on_error: \"!\"?> \"(\"\n        NonterminalNewline*\n        <arguments: CommaMultiline<Sp<FunctionArgument>>?>\n    \")\" => { /* ... */ },\n};\n\nFunctionCall: FunctionCall = {\n    <ident: Sp<\"function call\">> <abort_on_error: \"!\"?> \"(\"\n        NonterminalNewline*\n        <arguments: CommaMultiline<Sp<FunctionArgument>>?>\n    \")\" <closure: FunctionClosure?> => { /* ... */ },\n};\n\n#[inline]\nFunctionClosure: FunctionClosure = {\n    \"{\"\n      \"|\" <variables: CommaList<\"identifier\">?> \"|\" NonterminalNewline*\n      <expressions: Exprs>\n    \"}\" => FunctionClosure { variables, block: Block(expressions) },\n};\n```\n\n----------------------------------------\n\nTITLE: VRL `parse_regex` Example (Before 0.13)\nDESCRIPTION: This example demonstrates the behavior of the `parse_regex` function in VRL before version 0.13. It shows that both named and numeric capture groups were returned by default.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nparse_regex!(\"hello 123 world\", r'hello (?P<number>\\d+) world')\n```\n\n----------------------------------------\n\nTITLE: Reloading Vector on macOS (Homebrew)\nDESCRIPTION: Reloads Vector on macOS by sending a SIGHUP signal using killall. This applies configuration changes without a full restart.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nkillall -S SIGHUP vector\n```\n\n----------------------------------------\n\nTITLE: Setting up Imports for a Vector Sink in Rust\nDESCRIPTION: This snippet shows the necessary imports for creating a Vector sink in Rust. It imports modules for sink prelude, internal events, byte size, bytes sent, events sent, internal event handling, output and protocol.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse crate::sinks::prelude::*;\nuse vector_lib::internal_event::{\n    ByteSize, BytesSent, EventsSent, InternalEventHandle, Output, Protocol,\n};\n```\n\n----------------------------------------\n\nTITLE: BatchConfig Implementation of Configurable Trait in Rust\nDESCRIPTION: This code demonstrates the implementation of the `Configurable` trait for a `BatchConfig` struct in Rust. The struct contains options for configuring batching behavior, such as maximum events, maximum bytes, and maximum timeout. The `Configurable` implementation defines the description, shape, and metadata for the `BatchConfig` struct, providing default values and constraints for the batching options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Serialize, Deserialize, Default, Clone)]\nstruct BatchConfig {\n    max_events: Option<u32>,\n    max_bytes: Option<u32>,\n    max_timeout: Option<Duration>,\n}\n\nimpl<'de> Configurable<'de> for BatchConfig {\n    fn description() -> Option<&'static str> {\n        Some(\"Controls batching behavior i.e. maximum batch size, the maximum time before a batch is flushed, etc.\")\n    }\n\n    fn shape() -> Shape {\n        let mut required_fields = HashMap::new();\n        required_fields.insert(\"max_events\", <Option<u32> as Configurable>::shape());\n        required_fields.insert(\"max_bytes\", <Option<u32> as Configurable>::shape());\n        required_fields.insert(\"max_timeout\", <Option<Duration> as Configurable>::shape());\n\n        Shape::Map(MapShape {\n            required_fields,\n            allowed_unknown_field_shape: None,\n        })\n    }\n\n    fn metadata() -> Option<Vec<Metadata<Self>>> {\n        Some(vec![\n            Metadata::DefaultValue(BatchConfig {\n                max_events: Some(1000),\n                max_bytes: Some(1048576),\n                max_timeout: Some(Duration::from_secs(60)),\n            })\n        ])\n    }\n\n```\n\n----------------------------------------\n\nTITLE: Create Vector Configuration (vector.yaml)\nDESCRIPTION: Creates a Vector configuration file (vector.yaml) that defines a demo_logs source, which generates dummy logs, and a console sink, which outputs the logs to stdout. The configuration also enables the API on address 0.0.0.0:8686.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncat <<-EOF > $PWD/vector.yaml\napi:\n  enabled: true\n  address: 0.0.0.0:8686\nsources:\n  demo_logs:\n    type: demo_logs\n    interval: 1\n    format: json\nsinks:\n  console:\n    inputs:\n      - demo_logs\n    target: stdout\n    type: console\n    encoding:\n      codec: json\nEOF\n```\n\n----------------------------------------\n\nTITLE: Pipeline Transform Structure - Rust\nDESCRIPTION: Defines the structure of a pipeline transform, which contains the inner transform and a list of outputs that specify where the transform events should be redirected.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nstruct PipelineTransform {\n  inner: TransformOuter,\n  outputs: Vec<String>,\n}\n```\n\n----------------------------------------\n\nTITLE: Alternative Generic Event Struct\nDESCRIPTION: Another potential generic event struct definition. It contains fields such as `component_kind`, `component_type`, and `byte_size` to capture general information about event processing across different components. This promotes consistency but might lack specific contextual data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-17-2064-event-driven-observability.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\npub struct EventProcessed {\n    pub component_kind: &'static str,\n    pub component_type: &'static str,\n    pub byte_size: usize,\n}\n```\n\n----------------------------------------\n\nTITLE: Alternative OpCode Representation in Rust\nDESCRIPTION: This code shows an alternative representation for the `OpCode` enum, where the `Constant` variant includes the constant value directly. This approach aims to reduce the number of lookups at runtime but increases the size of the `OpCode` and prevents constant deduplication. The example highlights a trade-off between memory usage and runtime performance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-12-9811-vrl-vm.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nenum OpCode {\n    ...\n    Constant(Box<Value>)\n    ...\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Vector Config Boilerplate (Bash)\nDESCRIPTION: Demonstrates using the `vector generate` subcommand to create boilerplate configuration for a chain of transforms. It takes a comma-separated list of component types as input and outputs a basic configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector generate /remap,filter,reduce > vector.toml\n# Find out more with `vector generate --help`\n```\n\n----------------------------------------\n\nTITLE: Configurable Trait Definition in Rust\nDESCRIPTION: This code defines the `Configurable` trait, which provides a common interface for configuration types in Rust. The trait requires implementing types to define a description, shape, metadata, and fields.  It also requires the types to implement `Serialize`, `Deserialize`, and `Clone`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\npub trait Configurable<'de>: Serialize + Deserialize<'de> + Sized\nwhere\n    Self: Clone,\n{\n    /// Gets the human-readable description of this value, if any.\n    ///\n    /// For standard types, this will be `None`. Commonly, custom types would implement this\n    /// directly, while fields using standard types would provide a field-specific description that\n    /// would be used instead of the default description.\n    fn description() -> Option<&'static str>;\n\n    /// Gets the shape of this value.\n    fn shape() -> Shape;\n\n    /// Gets the metadata for this value.\n    fn metadata() -> Metadata<Self>;\n\n    /// The fields for this value, if any.\n    fn fields(overrides: Metadata<Self>) -> Option<HashMap<&'static str, Field>>;\n}\n```\n\n----------------------------------------\n\nTITLE: Start Vector Docker Container\nDESCRIPTION: Runs the Vector Docker container in detached mode, mounting the vector.yaml configuration file, exposing port 8686, and naming the container 'vector'.  It's important to substitute `debian` if you are using a different Vector distribution.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ndocker run \\\n  -d \\\n  -v $PWD/vector.yaml:/etc/vector/vector.yaml:ro \\\n  -p 8686:8686 \\\n  --name vector \\\n  timberio/vector:{{< version >}}-debian\n```\n\n----------------------------------------\n\nTITLE: Configuring Overflow Buffer in Vector\nDESCRIPTION: This YAML snippet configures a buffer topology in Vector. It uses an in-memory buffer with a maximum capacity of 1000 events that overflows to a disk buffer with a maximum size of 1GiB. When the disk buffer is full, it will drop new events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/about/under-the-hood/architecture/buffering-model.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsinks:\n  overflow_test:\n    type: blackhole\n    buffer:\n    - type: memory\n      max_events: 1000\n      when_full: overflow\n    - type: disk\n      max_size: 1073741824 # 1GiB.\n      when_full: drop_newest\n```\n\n----------------------------------------\n\nTITLE: Protobuf Metric Tag Representation\nDESCRIPTION: Defines the Protobuf representation of metric tags, adding a new `tags_v2` map to support lists of optional strings for tag values. This allows for handling multiple values and bare tags.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_0\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage Metric {\n  …\n  map<string, string> tags_v1 = 3;\n  message Values {\n    message Value {\n      optional string value = 1;\n    }\n    repeated Value values = 1;\n  }\n  map<string, Values> tags_v2 = 20;\n  …\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring internalMetrics Source in Vector Helm Chart\nDESCRIPTION: This YAML snippet shows how to configure an `internal_metrics` source using the `customConfig` option within the Helm chart's `values.yaml` file. It configures the `internal_metrics` source to collect Vector's internal metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sources:\n    ...\n    internal_metrics:\n      type: internal_metrics\n  ...\n```\n\n----------------------------------------\n\nTITLE: Vector generate command example\nDESCRIPTION: This bash command shows a potential future usage of the `vector generate` command, where users can specify options directly from the command line. The example generates a configuration for a `stdin` source and a `console` sink with JSON encoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-04-shutdown-vector-if-all-sources-finish.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbanana@tree:/$ vector generate stdin//console(encoding=json)\n```\n\n----------------------------------------\n\nTITLE: VRL Script for Cache Population\nDESCRIPTION: This VRL script, used in the `cache_generator` transform, checks if a user is already in the cache. If not, it stores the processed data in the enrichment table with the 'user-identifier' as the key and the rest of the event data as the value.  This allows efficient caching of frequently accessed information. Requires Vector to be installed and configured with the necessary components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-memory_enrichment_table.md#_snippet_2\n\nLANGUAGE: vrl\nCODE:\n```\n# Check if this user is already in the cache\nkey_value = get!(., path: [\"user-identifier\"])\nexisting, err = get_enrichment_table_record(\"memory_table\", { \"key\":  key_value })\n\nif err != null {\n  # No cached value found, store the processed data in the enrichment table\n  data = .\n\n  # The memory enrichment table stores all key-value pairs it receives.\n  # To structure it correctly, we create an object where:\n  # - The key is the \"user-identifier\".\n  # - The value is the rest of the processed event data.\n  . = set!(value: {}, path: [get!(data, path: [\"user-identifier\"])], data: data)\n} else {\n  # Already cached, do nothing\n  . = {}\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration (TOML)\nDESCRIPTION: This is the Vector configuration file that defines the data pipeline, including a file source, a JSON parser transform, a Reduce transform, and a file sink. The Reduce transform aggregates events based on the `request_id` field and uses merge strategies to combine the data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-10-add-reduce-transform.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\ndata_dir = \"tmp\"\n\n[sources.source0]\n  include = [\"input.log\"]\n  start_at_beginning = true\n  type = \"file\"\n  fingerprinting.strategy = \"device_and_inode\"\n\n[transforms.transform0]\n  inputs = [\"source0\"]\n  type = \"json_parser\"\n  field = \"message\"\n\n[transforms.transform1]\n  inputs = [\"transform0\"]\n  type = \"reduce\"\n  identifier_fields = [\"request_id\"]\n  ends_when.type = \"check_fields\"\n  ends_when.\"response_status.exists\" = true\n  merge_strategies.message = \"discard\"\n  merge_strategies.query = \"discard\"\n  merge_strategies.template = \"discard\"\n  merge_strategies.query_duration_ms = \"sum\"\n  merge_strategies.render_duration_ms = \"sum\"\n  merge_strategies.response_duration_ms = \"sum\"\n\n[sinks.sink0]\n  healthcheck = true\n  inputs = [\"transform1\"]\n  type = \"file\"\n  path = \"output.log\"\n  encoding = \"ndjson\"\n  buffer.type = \"memory\"\n  buffer.max_events = 500\n  buffer.when_full = \"block\"s\n```\n\n----------------------------------------\n\nTITLE: Vector Secret Configuration Example (TOML)\nDESCRIPTION: This TOML configuration snippet demonstrates how the secret management feature would be integrated into Vector. It defines two secret backends (`local_exec` and `prod_vault`) and shows how secrets can be referenced in other configuration options using the `SECRET[<backend>.<secret_key>]` syntax. It also shows how one secret backend can use another secret backend for its own initialization.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-24-11552-dd-agent-style-secret-management.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[secret.local_exec]\ntype = \"exec\"\npath = \"/path/to/the/command\"\nargument = \"--config foo=bar\"\ntimeout = 5\n\n[secret.prod_vault]\ntype = \"vault\"\naddress = \"https://vault.corp.tld/\"\ntoken = \"SECRET[local_exec.vault_token]\"\ntimeout = 5\n\n[sources.system_logs]\ntype = \"file\"\nincludes = [\"/var/log/system.log\"]\n\n[sinks.app_logs]\ntype = \"datadog_logs\"\ndefault_api_key = \"SECRET[prod_vault.dd_api_2022_02]\"\ninputs = [\"system_logs\"]\n```\n\n----------------------------------------\n\nTITLE: Custom Vector Configuration with commented defaults in YAML\nDESCRIPTION: This YAML example shows how users can provide a custom Vector configuration while also having access to a commented-out default configuration for easy modification.  This provides a convenient way to adjust the default settings without rewriting the entire configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-06-29-7709-helm-update-vector-config-pattern.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\n# Specify custom contents for the Vector config\n## ref: https://vector.dev/docs/reference/configuration/\n## Note a complete and valid configuration is required\ncustomConfig: {}\n  #  data_dir: \"/vector-data-dir\"\n  #  log_schema:\n  #    host_key: host\n  #    message_key: message\n  #    source_type_key: source_type\n  #    timestamp_key: timestamp\n  #  sources:\n  #    host_metrics:\n  #      type: host_metrics\n  #      filesystem:\n  #        devices:\n  #          excludes: [\"binfmt_misc\"]\n  #        filesystems:\n  #          excludes: [\"binfmt_misc\"]\n  #        mountpoints:\n  #          excludes: [\"*/proc/sys/fs/binfmt_misc\"]\n  #    internal_metrics:\n  #      type: internal_metrics\n  #    kubernetes_logs:\n  #      type: kubernetes_logs\n  #  sinks:\n  #    prometheus_sink:\n  #      type: prometheus_exporter\n  #      inputs: [\"host_metrics\", \"internal_metrics\"]\n  #      address: 0.0.0.0:9090\n```\n\n----------------------------------------\n\nTITLE: ConfigMap Template using customConfig in YAML\nDESCRIPTION: This example shows how to use the `customConfig` key to specify a complete Vector configuration, disabling default configurations. If `customConfig` is not provided, the ConfigMap will include a default Vector configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-06-29-7709-helm-update-vector-config-pattern.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n{{- if (empty .Values.existingConfigMap) -}}\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ include \"libvector.configMapName\" . }}\n  labels:\n    {{- include \"libvector.labels\" . | nindent 4 }}\ndata:\n  {{- if .Values.customConfig }}\n  vector.yaml: |\n{{ tpl (toYaml .Values.customConfig) . | indent 4 }}\n  {{- else }}\n  vector.yaml: |\n    # Docs: https://vector.dev/docs/\n    data_dir: \"/vector-data-dir\"\n    log_schema:\n      host_key: host\n      message_key: message\n      source_type_key: source_type\n      timestamp_key: timestamp\n    sources:\n      host_metrics:\n        type: host_metrics\n        filesystem:\n          devices:\n            excludes: [\"binfmt_misc\"]\n          filesystems:\n            excludes: [\"binfmt_misc\"]\n          mountpoints:\n            excludes: [\"*/proc/sys/fs/binfmt_misc\"]\n      internal_metrics:\n        type: internal_metrics\n      kubernetes_logs:\n        type: kubernetes_logs\n    sinks:\n      prometheus_sink:\n        type: prometheus_exporter\n        inputs: [\"host_metrics\", \"internal_metrics\"]\n        address: 0.0.0.0:9090\n  {{- end }}\n{{- end }}\n```\n\n----------------------------------------\n\nTITLE: Program Struct Definition (Extended)\nDESCRIPTION: Extends the `Program` struct to include a `resolves_to` field, allowing the program to define the expected value kinds the final expression should resolve to.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\npub struct Program {\n    pub(crate) resolves_to: ResolveKind.\n    pub(crate) expressions: Vec<Expr>,\n}\n```\n\n----------------------------------------\n\nTITLE: JSON example before http source dedot removal\nDESCRIPTION: This JSON payload represents data before ingestion by the `http` source in versions prior to Vector 0.11. In older versions, the `http` source automatically dedotted JSON keys. The expected output, before Vector 0.11, was for the key 'first.second' to be transformed into nested JSON objects.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"first.second\": \"value\"\n}\n```\n\n----------------------------------------\n\nTITLE: Datadog TracerPayload Definition (protobuf)\nDESCRIPTION: Defines the structure of a TracerPayload in Datadog's newer trace format, representing a payload received from tracers. It includes metadata about the tracer, such as containerID, language, versions, runtimeID, chunks, tags, env, hostname, and appVersion.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_4\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage TracerPayload {\n  // containerID specifies the ID of the container where the tracer is running on.\n  string containerID;\n  // languageName specifies language of the tracer.\n  string languageName;\n  // languageVersion specifies language version of the tracer.\n  string languageVersion = 3 ;\n  // tracerVersion specifies version of the tracer.\n  string tracerVersion = 4;\n  // runtimeID specifies V4 UUID representation of a tracer session.\n  string runtimeID = 5;\n  // chunks specifies list of containing trace chunks.\n  repeated TraceChunk chunks = 6;\n  // tags specifies tags common in all `chunks`.\n  map<string, string> tags = 7;\n  // env specifies `env` tag that set with the tracer.\n  string env = 8;\n  // hostname specifies hostname of where the tracer is running.\n  string hostname = 9;\n  // version specifies `version` tag that set with the tracer.\n  string appVersion = 10;\n}\n```\n\n----------------------------------------\n\nTITLE: Batched Unstructured Log Data Events\nDESCRIPTION: This JSON object represents a batch of unstructured log events, including the `customer_id`, `log_type`, and an array of `entries`. The `log_type` specifies the type of log and must be a valid value from the Chronicle logtypes endpoint.  This format is used by the `gcp_chronicle_unstructured` sink when sending multiple unstructured logs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-05-17-11532-chronicle-sink.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"customer_id\": \"c8c65bfa-5f2c-42d4-9189-64bb7b939f2c\",\n  \"log_type\": \"BIND_DNS\",\n  \"entries\": [...]\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Directory Contents with Shell Command\nDESCRIPTION: This command lists the contents of the specified directory using the 'ls' command with the '-l' flag, providing a detailed listing of files and directories. It helps verify the state of the data directory during testing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-11072/\n```\n\n----------------------------------------\n\nTITLE: Example JSON Log Data\nDESCRIPTION: This JSON snippet shows an example log data structure that Vector operates on by default. It includes `host`, `message`, and `timestamp` fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"host\": \"my.host.com\",\n  \"message\": \"some important content\",\n  \"timestamp\": \"2019-11-01T21:15:47+00:00\"\n}\n```\n\n----------------------------------------\n\nTITLE: Filter Transform Configuration (TOML)\nDESCRIPTION: This TOML configuration defines a filter transform that filters events based on a VRL condition. The condition attempts to mutate the event by setting `.foo` to \"bar\", which will now result in a compile-time error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.filter]\ntype = \"filter\"\ninputs = [ \"input\" ]\ncondition.type = \"vrl\"\ncondition.source = \"\"\"\n.foo = \\\"bar\\\"\ntrue\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Build project with wasm-pack\nDESCRIPTION: This command builds the Rust project into WebAssembly using wasm-pack. The --target web flag specifies that the output should be compatible with web browsers, and --out-dir public/pkg sets the output directory to public/pkg.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nwasm-pack build --target web --out-dir public/pkg\n```\n\n----------------------------------------\n\nTITLE: Simple LogEvent Example (JSON)\nDESCRIPTION: A basic example of a LogEvent represented in JSON format, showcasing simple key-value pairs with string, integer and nested map values.  This illustrates a common, uncomplicated LogEvent structure found in typical Vector usage.  No specific dependencies are required, it's a standard JSON structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": \"I found a potato!\",\n    \"potato_harvester_id\": 123,\n    \"potato_location\": { \"x\": 123, \"y\": 456, }\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration with Unit Test (TOML)\nDESCRIPTION: This TOML configuration demonstrates a Vector pipeline that uses a 'regex_parser' transform to parse log lines and includes a unit test to verify the transform's output. The test defines an input raw log line and asserts that the extracted fields ('timestamp', 'level', 'message') match the expected values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-11-25-unit-testing-vector-config-files.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_logs]\n  type    = \"file\"\n  include = [\"/var/log/my-app.log\"]\n\n[transforms.parser]\n  inputs = [\"my_logs\"]\n  type   = \"regex_parser\"\n  regex  = \"^(?P<timestamp>[\\\\w\\\\-:\\\\+]+) (?P<level>\\\\w+) (?P<message>.*)$\"\n\n[[tests]]\n  name = \"verify_regex\"\n\n  [tests.input]\n    insert_at = \"parser\"\n    type = \"raw\"\n    value = \"2019-11-28T12:00:00+00:00 info Hello world\"\n\n  [[tests.outputs]]\n    extract_from = \"parser\"\n\n    [[tests.outputs.conditions]]\n      type = \"check_fields\"\n      \"timestamp.equals\" = \"2019-11-28T12:00:00+00:00\"\n      \"level.equals\" = \"info\"\n      \"message.equals\" = \"Hello world\"\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: Exploding and Mapping Events (TOML)\nDESCRIPTION: This example demonstrates a combined approach using two `remap` transforms: one to \"explode\" the array of events using `unnest`, and another to \"map\" the nested fields to the top level, effectively merging the nested data. First remap uses `unnest` function, second remap transform pull up the nested field to merge it into the top-level.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-16-remap-multiple.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.explode]\ntype = \"remap\"\ninputs = []\nsource = \"\"\"\n. = {\"host\": \"localhost\", \"events\": [{\"message\": \"hello\"}, {\"message\": \"world\"}]} # to represent the incoming event\n\n. = unnest(.events)\n\"\"\"\n\n[transforms.map]\ntype = \"remap\"\ninputs = [\"explode\"]\nsource = \"\"\"\n# example of pulling up the nested field to merge it into the top-level\n. |= .events\ndel(.events)\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Verifying Disk Buffer v2 Location and Size (Shell)\nDESCRIPTION: After the Vector run that migrates to `disk_v2` buffers, this snippet verifies the new buffer location and its size. It lists the contents of the main data directory to show the `buffer` subdirectory, and then calculates the size of the `http_tarpit` subdirectory within the `v2` buffer directory to confirm the migrated data's storage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069\ntotal 4\ndrwxrwxr-x 3 toby toby 4096 Apr  6 13:41 buffer\ntoby@consigliere:~/src/vector/testing/github-12069$ du -h /tmp/vector/github-12069/buffer/v2/http_tarpit\n1.1G    /tmp/vector/github-12069/buffer/v2/http_tarpit\ntoby@consigliere:~/src/vector/testing/github-12069$\n```\n\n----------------------------------------\n\nTITLE: Datadog Logs Mutated Record\nDESCRIPTION: Demonstrates the modified structure of a log record after mutation for the Datadog Agent protocol.  Reserved keywords that were previously at the root are moved under the 'message' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/changelog.d/datadog_agent_http_header.fix.md#_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"message\" : {\n    \"message\" : \"Hello world\",\n    \"key1\": \"value1\",\n    \"key2\": { \"key2-1\" : \"value2\" }\n  },\n  ... rest of reserved fields\n}\n```\n\n----------------------------------------\n\nTITLE: VRL Template String with Field Access\nDESCRIPTION: This example illustrates accessing fields in VRL for template strings. Since direct path access is not supported, the field value must be assigned to a variable first.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: coffee\nCODE:\n```\nmessage = .message\nmessage = \"The message is {{ message }}!\"\n```\n\n----------------------------------------\n\nTITLE: Secret Request Format - JSON\nDESCRIPTION: This snippet shows the JSON format that Vector sends to the external process on stdin.  It includes the version and a list of the secrets needed by Vector.  The external process must be able to parse this format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-secrets-management.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\"version\": \"1.0\", \"secrets\": [\"aws_access_key_id\", \"aws_secret_access_key\"]}\n```\n\n----------------------------------------\n\nTITLE: Running Vector Tests (Bash)\nDESCRIPTION: Illustrates how to run Vector tests using the `vector test` command, showing the output of a successful test run and the inspection details of the transform's input and output.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n$ vector test ./vector.toml\n```\n\n----------------------------------------\n\nTITLE: Run Makefile Tasks from Outside Environment\nDESCRIPTION: These commands are used to run various `make` tasks from outside the Docker environment, allowing developers to validate code compilation, build, testing, benchmarking, website serving, and code formatting.  The `ENVIRONMENT=true` flag indicates that the tasks should be executed within the Docker environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2685-dev-workflow-simplification.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Validate your code can compile\nmake check ENVIRONMENT=true\n# Validate your code actually does compile (in dev mode)\nmake build-dev ENVIRONMENT=true\n# Validate your test pass\nmake test SCOPE=\"sources::example\" ENVIRONMENT=true\n# Validate tests (that do not require other services) pass\nmake test ENVIRONMENT=true\n# Validate your tests pass (starting required services in Docker)\nmake test-integration SCOPE=\"sources::example\" ENVIRONMENT=true\n# Validate your tests pass against a live service.\nmake test-integration SCOPE=\"sources::example\" AUTOSPAWN=false ENVIRONMENT=true\n# Validate all tests pass (starting required services in Docker)\nmake test-integration ENVIRONMENT=true\n# Run your benchmarks\nmake bench SCOPE=\"transforms::example\" ENVIRONMENT=true\n# Rebuild Vector's metadata\nmake generate ENVIRONMENT=true\n# Serve the website on port 3000\nmake website ENVIRONMENT=true\n# Format your code before pushing!\nmake fmt ENVIRONMENT=true\n```\n\n----------------------------------------\n\nTITLE: Defining Multipart Upload structs in Rust\nDESCRIPTION: This Rust code defines structs for managing multipart uploads to S3. `MultipartUploads` holds a map of `MultipartUpload` states. `MultipartUpload` stores the upload ID, completion time, and a list of uploaded parts. `UploadPart` stores the part number and its ETag. This data is required to assemble the parts when the object is completed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-07-3829-better-support-for-large-aws-s3-batches.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nstruct MultipartUploads {\n    uploads: DashMap<String, MultipartUpload>,\n}\n\n/// Multipart upload state data\nstruct MultipartUpload {\n    /// The identifier for the upload process.\n    upload_id: String,\n    /// The time after which this batch will be completed.\n    completion_time: DateTime<UTC>,\n    /// A list of uploaded parts.\n    parts: Vec<MultipartUploadPart>,\n}\n\nstruct UploadPart {\n    number: i64,\n    e_tag: String,\n}\n```\n\n----------------------------------------\n\nTITLE: Defining PartitionBatcher struct in Rust\nDESCRIPTION: This Rust code defines a `PartitionBatcher` struct that combines the functionalities of a generic batch collection setup with partitioning, allowing events to be encoded before batching to calculate their byte size, and maintaining partition information. This struct is designed to manage batches of data partitioned by a specific key, streaming data from a source, and applying a batch configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-07-3829-better-support-for-large-aws-s3-batches.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub struct PartitionBatcher<S, C, P> {\n    state: C,\n    stream: Fuse<S>,\n    partitioner: P,\n    timer: Maybe<Sleep>,\n}\n\nimpl<S, C, P> Stream for PartitionBatcher<S, C, P>\nwhere\n    S: Stream<Item = P::Item>,\n    C: BatchConfig<S::Item>,\n    P: Partitioner,\n{\n    type Item = (Prt::Key, C::Batch);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing the Sink Trait for BufferSender (Rust)\nDESCRIPTION: This code snippet shows the implementation of the `Sink` trait for the `BufferSender` struct. It defines the `poll_ready` function to check if the buffer is ready to accept a new event and the `start_send` function to send an event to the buffer. If the base buffer is not ready, it attempts to send the event to the overflow buffer if one is configured.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-14-9477-buffer-improvements.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nimpl Sink<Event> for BufferSender {\n  fn poll_ready(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {\n    // Figure out if our base sender is ready, and if not, and we have an overflow sender configured, see if _they're_ ready.\n    match self.base.poll_ready(cx) {\n      Poll::Ready(Ok(())) => self.base_ready = true,\n      _ => if let Some(overflow) = self.overflow {\n        if let Poll::Ready(Ok(())) = overflow.poll_ready(cx) {\n          self.overflow_ready = true;\n        }\n      }\n    }\n\n    // Some logic here to handle dropping the event or blocking.\n\n    // Either our base sender or overflow is ready, so can we proceed.\n    if self.base_ready || self.overflow_ready {\n      Poll::Ready(Ok(()))\n    } else {\n      Poll::Pending\n    }\n  }\n\n  fn start_send(self: Pin<&mut Self>, item: Item) -> Result<(), Self::Error> {\n    let result = if self.base_ready {\n      self.base.start_send(item)\n    } else if self.overflow_ready {\n      match self.overflow {\n        Some(overflow) => overflow.start_send(item),\n        None => Err(\"overflow ready but no overflow configured\")\n      }\n    } else {\n      Err(\"called start_send without ready\")\n    };\n\n    self.base_ready = false;\n    self.overflow_ready = false;\n    result\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining VRL OpCodes in Rust\nDESCRIPTION: This code defines the enum `OpCode` in Rust, which represents the different instructions that the VRL VM will execute. Each variant of the enum corresponds to a specific operation, such as returning, loading a constant, negation, addition, etc.  The code defines `Instruction` as either an Opcode or literal index, and `LiteralIndex` as a wrapper for a usize, which references the constants array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-12-9811-vrl-vm.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Copy, Clone, Debug, PartialEq, Eq)]\npub enum OpCode {\n    Return,\n    Constant,\n    Negate,\n    Add,\n    Subtract,\n    Multiply,\n    Divide,\n    Print,\n    Not,\n    Greater,\n    GreaterEqual,\n    Less,\n    LessEqual,\n    NotEqual,\n    Equal,\n    Pop,\n    JumpIfFalse,\n    Jump,\n    SetPath,\n    GetPath,\n    Call,\n    ...\n}\n\nenum Instruction {\n    Opcode(Opcode),\n    Literal(LiteralIndex),\n}\n\npub struct LiteralIndex(usize);\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Configuration - TOML\nDESCRIPTION: This TOML configuration demonstrates how to configure a reduce transform. It specifies the 'id' field for grouping and defines merge strategies for both the 'id' and a nested field 'a.b[0]'. This configuration is used in conjunction with the JSON examples to illustrate the change in behavior for nested fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\ngroup_by = [ \"id\" ]\nmerge_strategies.id = \"discard\"\nmerge_strategies.\"a.b[0]\" = \"array\"\n```\n\n----------------------------------------\n\nTITLE: Add Endpoint to Config - Rust\nDESCRIPTION: Adds a configurable 'endpoint' field to the BasicConfig struct. This field specifies the HTTP endpoint to send traffic to and includes documentation metadata for generating examples.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n    /// The endpoint to send HTTP traffic to.\n    ///\n    /// This should include the protocol and host, but can also include the port, path, and any other valid part of a URI.\n    #[configurable(metadata(\n        docs::examples = \"http://localhost:3000/\",\n        docs::examples = \"http://example.com/endpoint/\",\n    ))]\n    pub endpoint: String,\n```\n\n----------------------------------------\n\nTITLE: Build Vector (Linux x86_64, Docker)\nDESCRIPTION: This command builds a statically linked binary of Vector for Linux (x86_64) using the 'make' utility and Docker. It utilizes a Docker image with a Rust toolchain for the specified target.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\nmake package-x86_64-unknown-linux-musl-all\n```\n\n----------------------------------------\n\nTITLE: Logging: Basic Usage with Tracing in Rust\nDESCRIPTION: This snippet demonstrates basic logging using the `tracing` crate in Rust. It shows how to log messages at different levels (info, debug, trace, error) with and without formatting, and how to include structured fields in the log events. The messages use a string literal message with no formatting and formatted messages with arguments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/STYLE.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n// Basic string literal message, no formatting:\ninfo!(\"Server has started.\");\n\n// A formatted message, with the same formatting support as `println!`/`format!`:\ndebug!(\"User connected: {}\", username);\n\n// Adding structured fields to the even, mixing and matching the message format:\ntrace!(bytes_sent = 22, \"Sent heartbeat packet to client.\")\nerror!(client_addr = %conn.get_ref().peer_addr, \"Client actor received malformed packet: {}\", parse_err.to_string())\n```\n\n----------------------------------------\n\nTITLE: Install specific Vector version using installer\nDESCRIPTION: This shell command downloads and executes the Vector installation script, specifying a particular version of Vector using the VECTOR_VERSION environment variable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/vector-installer.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSfL https://sh.vector.dev | VECTOR_VERSION=0.34.1 bash\n```\n\n----------------------------------------\n\nTITLE: Setting metric tag using Remap language in Coffeescript\nDESCRIPTION: This snippet shows how to add or modify a tag in a metric's metadata using the Remap language. It assigns the value \"localhost\" to the tag \"host\" within the `.tags` map.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-01-remap-metrics-support.md#_snippet_0\n\nLANGUAGE: coffeescript\nCODE:\n```\n.tags.host = \"localhost\"\n```\n\n----------------------------------------\n\nTITLE: LogEvent API Summary (Rust)\nDESCRIPTION: Summarizes the public API of the `LogEvent` struct, including methods for getting, inserting, removing, and iterating over fields.  Demonstrates the core functionalities for interacting with `LogEvent` data.  Requires the `Atom` type (deprecated, migrate to String).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\n//! Summarized from src/event/mod.rs\nimpl LogEvent {\n    pub fn new() -> Self;\n    pub fn get(&self, key: &Atom) -> Option<&Value>;\n    pub fn get_mut(&mut self, key: &Atom) -> Option<&mut Value>;\n    pub fn contains(&self, key: &Atom) -> bool;\n    pub fn insert<K, V>(&mut self, key: K, value: V) -> Option<Value>\n        where K: AsRef<str>, V: Into<Value>>;\n    pub fn insert_path<V>(&mut self, key: Vec<PathComponent>, value: V) -> Option<Value>\n        where V: Into<Value>>;\n    pub fn insert_flat<K, V>(&mut self, key: K, value: V)\n        where K: Into<String>, V: Into<Value>>;\n    pub fn try_insert<V>(&mut self, key: &Atom, value: V)\n        where  V: Into<Value>>;\n    pub fn remove(&mut self, key: &Atom) -> Option<Value>;\n    pub fn remove_prune(&mut self, key: &Atom, prune: bool) -> Option<Value>;\n    pub fn keys<'a>(&'a self) -> impl Iterator<Item = String> + 'a;\n    pub fn all_fields<'a>(&'a self) -> impl Iterator<\n                Item = (String, &'a Value)\n        > + Serialize;\n    pub fn is_empty(&self) -> bool;\n}\n```\n\n----------------------------------------\n\nTITLE: RegisteredEndpointBytesReceived Implementation\nDESCRIPTION: This example provides a sample implementation of the `RegisterInternalEvent` and `InternalEventHandle` traits for the `RegisteredEndpointBytesReceived` event. It demonstrates how to register the event and emit data using the registered handle.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nuse metrics::Counter;\n\nstruct RegisteredEndpointBytesReceived {\n    bytes_total: Counter,\n    protocol: &'static str,\n    endpoint: String,\n}\n\nstruct EndpointBytesReceivedHandle {\n    bytes_total: Counter,\n    protocol: &'static str,\n    endpoint: String,\n}\n\nimpl RegisterInternalEvent for RegisteredEndpointBytesReceived {\n    type Handle = EndpointBytesReceivedHandle;\n\n    fn register(self) -> Self::Handle {\n        let bytes_total = counter!(\n            \"component_received_bytes_total\",\n            \"protocol\" => self.protocol,\n            \"endpoint\" => self.endpoint.clone(),\n        );\n        Self {\n            bytes_total,\n            protocol: self.protocol,\n            endpoint: self.endpoint,\n        }\n    }\n}\n\nimpl InternalEventHandle for EndpointBytesReceivedHandle {\n    type Data = ByteSize;\n    fn emit(&self, data: ByteSize) {\n        trace!(\n            message = \"Bytes received.\",\n            byte_size = %data.0,\n            protocol = %self.protocol,\n            endpoint = %self.endpoint,\n        );\n        self.bytes_total.add(data.0);\n    }\n}\n\n// In component code:\n\nuse crate::internal_events::{InternalEventHandle, RegisteredEndpointBytesReceived};\n\nlet handle = register!(RegisteredEndpointBytesReceived {\n    protocol = \"https\",\n    endpoint = self.config.endpoint.clone(),\n});\n\nhandle.emit(ByteSize(received.len()));\n```\n\n----------------------------------------\n\nTITLE: Import and use VRL in React component\nDESCRIPTION: This JavaScript code snippet demonstrates how to import and use the 'run_vrl' function from the 'vrl-web-playground' package in a React component. It initializes the WASM module and then executes the VRL code with a given input. The result is then logged to the console.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nimport init, { run_vrl } from 'vrl-web-playground';\n\nexport function VectorExecuteButton() {\n  let vrlInput = {};\n  try {\n    vrlInput = {\n        program: '.something = \"added by vrl!\"\\n.message = \"modified by vrl!\"',\n        event: JSON.parse('{message: \"log message here\"}'),\n    };\n  } catch (error) {\n        console.log('error parsing the event contents as JSON object');\n  }\n\n  return (\n      <button\n        onClick={() => {\n            console.log(\"[DEBUG] Initializing WASM\");\n            init().then(() => {\n                console.log(\"[DEBUG] WASM initialized\");\n                console.log(\"[DEBUG] Attempting to run vrl with input: \", vrlInput);\n\n                let res = run_vrl(vrlInput);\n                console.log(\"[DEBUG] run_vrl() output\", res);\n            });\n        }}\n      />\n  );\n}\n```\n\n----------------------------------------\n\nTITLE: Run Vector with config.toml\nDESCRIPTION: This snippet runs the 'vector-fix' executable with the specified configuration file (config.toml). This likely runs vector in a specific test configuration as part of the debugging or verification process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./vector-fix -c config.toml\n2022-01-13T02:32:58.303181Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-13T02:32:58.303215Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-13T02:32:58.303763Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-13T02:32:58.336135Z  INFO vector::topology::running: Running healthchecks.\n2022-01-13T02:32:58.336157Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-13T02:32:58.336187Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-13T02:32:58.336182Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-13T02:32:58.336211Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"none\"\n^C2022-01-13T02:32:59.845171Z  INFO vector: Vector has stopped.\n2022-01-13T02:32:59.845227Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit, stdin\" time_remaining=\"59 seconds left\"\n2022-01-13T02:32:59.845222Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n```\n\n----------------------------------------\n\nTITLE: Netcat Output from Vector-PR Execution\nDESCRIPTION: This is the output captured from running netcat in listen mode while Vector-PR is running. It shows the HTTP POST request made by Vector, including headers and the JSON payload. The JSON payload contains the log messages Vector processed, including host, message, source_type, and timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11039/test-results.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nPOST /foo HTTP/1.1\ncontent-type: application/x-ndjson\nuser-agent: Vector/0.20.0 (x86_64-unknown-linux-gnu)\naccept-encoding: identity\nhost: localhost:7777\ncontent-length: 615\n\n{\"host\":\"consigliere\",\"message\":\"line one, woohoo\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-26T19:16:16.815899465Z\"}\n{\"host\":\"consigliere\",\"message\":\"line two, yippeee\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-26T19:16:16.815909555Z\"}\n{\"host\":\"consigliere\",\"message\":\"line three, oh my\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-26T19:16:16.815912815Z\"}\n{\"host\":\"consigliere\",\"message\":\"line four, woooooow\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-26T19:16:16.815917085Z\"}\n{\"host\":\"consigliere\",\"message\":\"live five, phew, that was a lot\",\"source_type\":\"stdin\",\"timestamp\":\"2022-01-26T19:16:16.815920305Z\"}\n```\n\n----------------------------------------\n\nTITLE: For Each Function Signature in VRL\nDESCRIPTION: The signature for the `for_each` function is displayed. This function enables iteration over objects and arrays without mutating the data. It accepts an object or array and a boolean value for enabling recursion. The return value is of any type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\nfor_each(value: object|array, recursive: bool) -> |string OR integer, any| { any }\n```\n\n----------------------------------------\n\nTITLE: Examples of `for_each` with closures - Coffee\nDESCRIPTION: These examples illustrate how the `for_each` function can be used with closures on both objects and arrays in VRL, showcasing how the compiler can guarantee variable types based on the input type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_40\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"foo\": true }\n. = for_each(.) -> |key, value| { ... }\n```\n\nLANGUAGE: coffee\nCODE:\n```\n. = [\"foo\", true]\n. = for_each(.) -> |index, value| { ... }\n```\n\n----------------------------------------\n\nTITLE: Implementing the `closure` method for `for_each` - Rust\nDESCRIPTION: This snippet demonstrates the implementation of the `closure` method for the `for_each` function. It defines the expected input types for both Object and Array inputs, specifying the variable types (string for object key, integer for array index, and any for the value).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_39\n\nLANGUAGE: rust\nCODE:\n```\nfn closure(&self) -> Option<closure::Definition> {\n    let field = closure::Variable { kind: kind::String };\n    let index = closure::Variable { kind: kind::Integer };\n    let value = closure::Variable { kind: kind::Any };\n\n    let object = closure::Input {\n        parameter: \"value\",\n        kind: kind::Object,\n        variables: vec![field, value],\n        output: closure::Output::Any,\n    };\n\n    let array = closure::Input {\n        parameter: \"value\",\n        kind: kind::Array,\n        variables: vec![index, value],\n        output: closure::Output::Any,\n    };\n\n    Some(closure::Definition {\n        inputs: vec![object, array],\n    })\n}\n```\n\n----------------------------------------\n\nTITLE: Copy Systemd Service File\nDESCRIPTION: This command copies the Vector service file to the Systemd system directory, enabling Vector to be managed as a service using Systemd.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ncp -av etc/systemd/vector.service /etc/systemd/system\n```\n\n----------------------------------------\n\nTITLE: Transform Model Pseudocode in Rust\nDESCRIPTION: This pseudocode outlines the proposed new model for transforms in Vector. It introduces the `TransformConfig`, `Transform`, `FunctionTransform`, and `TaskTransform` traits/enums to differentiate between different types of transforms based on their capabilities (persistent state, event production). This allows for more intelligent topology construction by treating different transforms differently.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-06-18-2625-architecture-revisit.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\ntrait TransformConfig {\n    async fn build(&self) -> Transform\n}\n\nenum Transform {\n    Function(FunctionTransform),\n    Task(TaskTransform),\n}\n\ntrait FunctionTransform {\n    fn transform(&mut self, output: &mut Vec<Event>, event: Event);\n}\n\ntrait TaskTransform {\n    fn transform(self: Box<Self>, stream: Stream<Event>) -> Stream<Event>;\n}\n```\n\n----------------------------------------\n\nTITLE: Pre-Push Hook Content (Bash)\nDESCRIPTION: This code provides a sample `pre-push` hook script for Vector. It includes checks for licenses, code formatting, lints, component documentation, denied patterns, standard documentation, version consistency, example code, scripts, and changelog fragments. Commented out is the slow `check-component-features` target. The purpose is to validate code before pushing it to the repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n#!/bin/sh\nset -e\necho \"Running pre-push checks...\"\n\n# We recommend always running all the following checks.\nmake check-licenses\nmake check-fmt\nmake check-clippy\nmake check-component-docs\n\n# Some other checks that in our experience rarely fail on PRs.\nmake check-deny\nmake check-docs\nmake check-version\nmake check-examples\nmake check-scripts\n\n./scripts/check_changelog_fragments.sh\n\n# The following check is very slow.\n# make check-component-features\n```\n\n----------------------------------------\n\nTITLE: Define Array with Default Type and Specific Index Type in Rust\nDESCRIPTION: This code demonstrates how to define an array with a default type for all elements and a specific type for an element at a particular index. All array elements are strings, except the element at index 3, which will be a timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_16\n\nLANGUAGE: rust\nCODE:\n```\nKind::array(Collection::empty().with_unknown(Kind::bytes())\n                .with_known(3, Kind::timestamp()))\n```\n\n----------------------------------------\n\nTITLE: Implementing SinkConfig for a Vector Sink in Rust\nDESCRIPTION: This snippet implements the `SinkConfig` trait for the `BasicConfig` struct. It defines how to build the sink, including setting up the healthcheck and creating a `VectorSink` from a `BasicSink`. The `input` function specifies that the sink accepts log events and the `acknowledgements` function returns the acknowledgement configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\n#[async_trait::async_trait]\n#[typetag::serde(name = \"basic\")]\nimpl SinkConfig for BasicConfig {\n    async fn build(&self, _cx: SinkContext) -> crate::Result<(VectorSink, Healthcheck)> {\n        let healthcheck = Box::pin(async move { Ok(()) });\n        let sink = VectorSink::from_event_streamsink(BasicSink);\n\n        Ok((sink, healthcheck))\n    }\n\n    fn input(&self) -> Input {\n        Input::log()\n    }\n\n    fn acknowledgements(&self) -> &AcknowledgementsConfig {\n        &self.acknowledgements\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating event fixtures\nDESCRIPTION: This code snippet details the steps required to generate the event fixtures for testing the native protobuf and JSON codecs. It involves navigating to the `lib/vector-core` directory, creating the `_json` and `proto` directories, and running a specific cargo test.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/codecs/tests/data/native_encoding/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n    $ cd lib/vector-core\n    $ mkdir _json/ proto/\n    $ cargo test event::test::serialization::roundtrip\n```\n\n----------------------------------------\n\nTITLE: Add Vector to PATH (Shell)\nDESCRIPTION: Adds the Vector binary directory to the user's PATH environment variable by modifying the .profile file and sourcing it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\necho \"export PATH=\\\"$(pwd)/vector/bin:\\$PATH\\\"\" >> $HOME/.profile\nsource $HOME/.profile\n```\n\n----------------------------------------\n\nTITLE: Enter Vector Development Environment\nDESCRIPTION: These commands are used to enter a development shell with optimized mounts for interactive processes. Inside the shell, developers can use Vector as if they have a full toolchain. They also demonstrate how to specify a container tool or add extra CLI options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2685-dev-workflow-simplification.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Enter a shell with optimized mounts for interactive processes.\n# Inside here, you can use Vector like you have full toolchain (See below!)\nmake environment\n# Try out a specific container tool. (Docker/Podman)\nmake environment CONTAINER_TOOL=\"podman\"\n# Add extra cli opts\nmake environment CLI_OPTS=\"--publish 3000:2000\"\n```\n\n----------------------------------------\n\nTITLE: Defining Go Memory Statistics Prometheus Metrics\nDESCRIPTION: This snippet defines Prometheus metrics for monitoring various aspects of Go runtime memory statistics, including heap usage, garbage collection, and system allocations.  It uses the HELP directive to provide descriptions for each metric and the TYPE directive to specify the metric type (gauge or counter). The metrics provide insights into memory consumption and garbage collection behavior of Go applications.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_2\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.\n# TYPE go_memstats_heap_alloc_bytes gauge\ngo_memstats_heap_alloc_bytes 2.585e+06\n# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.\n# TYPE go_memstats_heap_idle_bytes gauge\ngo_memstats_heap_idle_bytes 6.2349312e+07\n# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.\n# TYPE go_memstats_heap_inuse_bytes gauge\ngo_memstats_heap_inuse_bytes 4.13696e+06\n# HELP go_memstats_heap_objects Number of allocated objects.\n# TYPE go_memstats_heap_objects gauge\ngo_memstats_heap_objects 17419\n# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.\n# TYPE go_memstats_heap_released_bytes gauge\ngo_memstats_heap_released_bytes 6.2316544e+07\n# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.\n# TYPE go_memstats_heap_sys_bytes gauge\ngo_memstats_heap_sys_bytes 6.6486272e+07\n# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.\n# TYPE go_memstats_last_gc_time_seconds gauge\ngo_memstats_last_gc_time_seconds 0\n# HELP go_memstats_lookups_total Total number of pointer lookups.\n# TYPE go_memstats_lookups_total counter\ngo_memstats_lookups_total 0\n# HELP go_memstats_mallocs_total Total number of mallocs.\n# TYPE go_memstats_mallocs_total counter\ngo_memstats_mallocs_total 19820\n# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.\n# TYPE go_memstats_mcache_inuse_bytes gauge\ngo_memstats_mcache_inuse_bytes 13888\n# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.\n# TYPE go_memstats_mcache_sys_bytes gauge\ngo_memstats_mcache_sys_bytes 16384\n# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.\n# TYPE go_memstats_mspan_inuse_bytes gauge\ngo_memstats_mspan_inuse_bytes 72216\n# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.\n# TYPE go_memstats_mspan_sys_bytes gauge\ngo_memstats_mspan_sys_bytes 81920\n# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.\n# TYPE go_memstats_next_gc_bytes gauge\ngo_memstats_next_gc_bytes 4.473924e+06\n# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.\n# TYPE go_memstats_other_sys_bytes gauge\ngo_memstats_other_sys_bytes 1.052638e+06\n# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.\n# TYPE go_memstats_stack_inuse_bytes gauge\ngo_memstats_stack_inuse_bytes 622592\n# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.\n# TYPE go_memstats_stack_sys_bytes gauge\ngo_memstats_stack_sys_bytes 622592\n# HELP go_memstats_sys_bytes Number of bytes obtained from system.\n# TYPE go_memstats_sys_bytes gauge\ngo_memstats_sys_bytes 7.3876736e+07\n# HELP go_threads Number of OS threads created.\n# TYPE go_threads gauge\ngo_threads 8\n```\n\n----------------------------------------\n\nTITLE: Adding a Second Demo Logs Source\nDESCRIPTION: Adds a second `demo_logs` source (`in-2`) to the Vector configuration. This demonstrates how `vector tap` adapts to configuration changes by re-matching component patterns.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[sources.in-2]\ntype = \"demo_logs\"\nformat = \"shuffle\"\nlines = [\n  \"new test1\",\n  \"new test2\",\n]\n```\n\n----------------------------------------\n\nTITLE: Secret Response Format - JSON\nDESCRIPTION: This snippet demonstrates the expected JSON response format from the external process.  For each requested secret, the response must include a `value` and an `error` field.  If an error is returned, Vector will log the error and stop.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-secrets-management.md#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"aws_access_key_id\": {\"value\": \"AKIAIOSFODNN7EXAMPLE\", \"error\": null},\n  \"aws_secret_access_key\": {\"value\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\", \"error\": null}\n}\n```\n\n----------------------------------------\n\nTITLE: Encode Input Implementation - Rust\nDESCRIPTION: Complete implementation of `encode_input` function, serializes the event to a String and writes the bytes. Also create GroupedCountByteSize object which tracks size of event. The function also creates a [`GroupedCountByteSize`][grouped_count_byte_size] object. This object tracks the size of the event that is sent by the sink, optionally grouped by the source and service that originated the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\n    fn encode_input(\n        &self,\n        input: Event,\n        writer: &mut dyn std::io::Write,\n    ) -> std::io::Result<(usize, GroupedCountByteSize)> {\n        let mut byte_size = telemetry().create_request_count_byte_size();\n        byte_size.add_event(&input, input.estimated_json_encoded_size_of());\n\n        let event = serde_json::to_string(&input).unwrap();\n        write_all(writer, 1, event.as_bytes()).map(|()| (event.len(), byte_size))\n    }\n```\n\n----------------------------------------\n\nTITLE: Simple JSON example\nDESCRIPTION: Basic JSON object used as input for the map_keys example\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_28\n\nLANGUAGE: json\nCODE:\n```\n{ \"foo\": true, \"bar\": false }\n```\n\n----------------------------------------\n\nTITLE: Adding format option to generator source configuration\nDESCRIPTION: This code snippet demonstrates how to add the `format` option to the `generator` source configuration.  The `generator` source is often used for testing and now requires a `format` to be specified (e.g., `apache_common`, `apache_error`, `syslog`).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_3\n\nLANGUAGE: diff\nCODE:\n```\n [sources.generator]\n type = \"generator\"\n+format = \"apache_common\"  # or \"apache_error\" or \"syslog\"\n```\n\n----------------------------------------\n\nTITLE: Initializing gRPC Client with Tonic in Rust\nDESCRIPTION: Establishes a connection to a gRPC server using Tonic and creates a client instance. This snippet initializes a connection to a gRPC server at `http://[::1]:9999`, creates a `DummyClient`, builds a request, sends it, and prints the response. It depends on the `our_rpc_mod` generated code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_3\n\nLANGUAGE: Rust\nCODE:\n```\n    use our_rpc_mod::dummy_client::DummyClient;\n    use our_rpc_mod::DummyRequest;\n\n    mod our_rpc_mod;\n\n    #[tokio::main]\n    async fn main() -> Result<(), Box<dyn std::error::Error>> {\n      // Start a connection channel to the server\n      let channel = tonic::transport::Channel::from_static(\"http://[::1]:9999\")\n        .connect()\n        .await?;\n\n    // Create a gRPC client from the channel\n        let mut client = DummyClient::new(channel);\n\n    // Build ourselves a request\n        let request = tonic::Request::new(\n            DummyRequest {\n               name:String::from(\"eeyun\")\n            },\n        );\n\n    // Send it and wait for response\n        let response = client.send(request).await?.into_inner();\n        println!(\"RESPONSE={:?}\", response);\n        Ok(())\n    }\n```\n\n----------------------------------------\n\nTITLE: Remove existing APT repository (Shell)\nDESCRIPTION: This command removes the existing timber.io repository configuration file for APT package manager. This is the first step in manually migrating to the new vector.dev repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nrm \"/etc/apt/sources.list.d/timber-vector.list\"\n```\n\n----------------------------------------\n\nTITLE: Kubernetes ClusterRole Update (Diff)\nDESCRIPTION: This diff snippet shows how to update the Kubernetes ClusterRole to include access to the 'namespaces' resource, which is required by the `kubernetes_logs` source in Vector 0.16.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-25-0-16-upgrade-guide.md#_snippet_4\n\nLANGUAGE: diff\nCODE:\n```\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: vector-agent\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n+     - namespaces\n      - pods\n    verbs:\n      - watch\n```\n\n----------------------------------------\n\nTITLE: Uninstall Vector using dpkg\nDESCRIPTION: Uninstalls Vector using dpkg.  Replace `{arch}` with the correct architecture used for the install.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/dpkg.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\ndpkg -r vector-{{< version >}}-{arch}\n```\n\n----------------------------------------\n\nTITLE: Flattening Syslog Data (VRL)\nDESCRIPTION: This snippet shows how to achieve the previous `parse_syslog` behavior (where keys had the SDID prefixed) by using the `flatten` function on the result of `parse_syslog`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_11\n\nLANGUAGE: coffeescript\nCODE:\n```\nflatten(parse_syslog!(s'<1>1 2022-04-25T23:21:45.715740Z Gregorys-MacBook-Pro.local 2d4d9490-794a-4e60-814c-5597bd5b7b7d 79978 - [exampleSDID@32473 foo.baz=\"bar\"] test message'))\n```\n\n----------------------------------------\n\nTITLE: VRL Infallible Division (Old)\nDESCRIPTION: Illustrates the old, now incorrect, way to perform division by a literal nonzero number in `VRL`. Previously, all division was considered fallible and required error handling.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-0-20-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: coffeescript\nCODE:\n```\n.zorp = .spog / 43 ?? \"this error can never happen\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Sinks with Wildcard Inputs in TOML\nDESCRIPTION: This TOML configuration demonstrates how to use wildcards in the `inputs` option of sinks. The `app*` wildcard matches component names starting with \"app\".  The `datadog_logs` sink receives inputs from sources like `app1_logs` and `app2_logs`. The `aws_s3` sink receives inputs from any sources starting with \"app\" as well as the `system_logs` source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-01-20-wildcard-identifiers.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.app1_logs]\ntype = \"file\"\nincludes = [\"/var/log/app1.log\"]\n\n[sources.app2_logs]\ntype = \"file\"\nincludes = [\"/var/log/app.log\"]\n\n[sources.system_logs]\ntype = \"file\"\nincludes = [\"/var/log/system.log\"]\n\n[sinks.app_logs]\ntype = \"datadog_logs\"\ninputs = [\"app*\"]\n\n[sinks.archive]\ntype = \"aws_s3\"\ninputs = [\"app*\", \"system_logs\"]\n```\n\n----------------------------------------\n\nTITLE: Defining VectorSink enum and StreamSink trait with EventContainer in Rust\nDESCRIPTION: This snippet defines an enum `VectorSink` to represent both push-style and pull-style sinks, and a trait `StreamSink` for pull-style sinks. Both are designed to work with `EventVec`, allowing them to process arrays of events. Conversions are provided for existing sinks to ease the migration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\nenum VectorSink {\n    Sink(Box<dyn Sink<EventVec, Error = ()> + Send + Unpin>),\n    Stream(Box<dyn StreamSink<EventVec> + Send>),\n}\n\ntrait StreamSink<T: EventContainer> {\n    async fn run(self: Box<Self>, input: BoxStream<'_, T>) -> Result<(), ()>;\n}\n\n// Allow existing sinks be converted with `.into()`\n\nimpl<T: Sink<Event, Error = ()>> From<T> For VectorSink { … }\n\nimpl<T: StreamSink<Event> + Send> From<T> for VectorSink { … }\n```\n\n----------------------------------------\n\nTITLE: VRL expression to join namespace and name for Datadog metrics\nDESCRIPTION: This Vector Remap Language (VRL) expression joins the namespace and name fields of a metric event, separated by a period.  It is used to adapt configurations that previously expected the full metric name, including the namespace, to be in the .name field, before the Datadog agent source started parsing the namespace into its own field. This ensures compatibility with older VRL configurations after the Datadog agent source update.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_17\n\nLANGUAGE: toml\nCODE:\n```\nfull_metric_name = \"\"\"\njoin([.namespace, .name], \".\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Complex LogEvent Example (JSON)\nDESCRIPTION: An example of a more complex LogEvent represented in JSON format, demonstrating the use of null values, boolean values, nested lists, and nested maps. This example covers a wider range of possible data types and structures within a LogEvent. No specific dependencies are required, it's a standard JSON structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n// Note, this does not cover all possibilities!\n{\n    \"nulled\": null, // Ensure a nulled field is not lost.\n    \"basic\": true,  // Maps can contain multiple types.\n    \"list\": [\n        true, // Lists can contain multiple types.\n        null, // A null in a list is totally valid.\n        [true, null, true],\n        {\n            \"basic\": true,\n            \"buddy\": 1.0, // Maps with multiple values are a bit more complex.\n        },\n    ],\n    \"map\": {\n        \"basic\": true,\n        \"list\": [true, null, true],\n        \"map\": {\n            \"basic\": true,\n            \"buddy\": -1,\n        }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example Environment Configuration Payload (json)\nDESCRIPTION: This JSON payload represents the configuration passed to the management CLI for testing the `8.4.3-classic` environment. It includes the type and version information necessary for setting up the test environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-31-15056-tooling-revamp.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"classic\",\n    \"version\": \"8.4.3\"\n}\n```\n\n----------------------------------------\n\nTITLE: Validating CUE Sources with Make\nDESCRIPTION: This command validates CUE sources, ensuring they conform to defined schemas. It's crucial to verify the integrity and correctness of CUE data. The CI flag enables additional format validation and might modify CUE files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DOCUMENTING.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd .. # Change to the repo root directory\nCI=true make check-docs\n```\n\n----------------------------------------\n\nTITLE: JSON-formatted Syslog events (JSON)\nDESCRIPTION: This JSON output shows a sample of JSON-formatted Syslog events processed and emitted by Vector using the `demo_logs` source, `remap` transform with `parse_syslog`, and a console sink with JSON encoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\"appname\":\"benefritz\",\"facility\":\"authpriv\",\"hostname\":\"some.de\",\"message\":\"We're gonna need a bigger boat\",\"msgid\":\"ID191\",\"procid\":9473,\"severity\":\"crit\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n{\"appname\":\"meln1ks\",\"facility\":\"local1\",\"hostname\":\"for.com\",\"message\":\"Take a breath, let it go, walk away\",\"msgid\":\"ID451\",\"procid\":484,\"severity\":\"debug\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n{\"appname\":\"shaneIxD\",\"facility\":\"uucp\",\"hostname\":\"random.com\",\"message\":\"A bug was encountered but not in Vector, which doesn't have bugs\",\"msgid\":\"ID428\",\"procid\":3093,\"severity\":\"alert\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n```\n\n----------------------------------------\n\nTITLE: Datadog Logs Sink Configuration without Encoding (TOML)\nDESCRIPTION: This TOML snippet shows the correct Datadog logs sink configuration after removing the 'encoding.codec' option, as required by Vector 0.16.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-25-0-16-upgrade-guide.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.dd_logs_egress]\ntype = \"datadog_logs\"\ninputs = [\"datadog_agent\"]\n```\n\n----------------------------------------\n\nTITLE: Sink Field Filtering with Kafka in TOML\nDESCRIPTION: This TOML configuration demonstrates how to filter fields at the sink level, specifically for a Kafka sink. It sets the Kafka topic to the value of the `service` field and then removes the `service` field using `encoding.except_fields`, which reduces the size of the message sent to Kafka.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_8\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.output]\n  inputs = [\"demo_logs\"]\n  type = \"kafka\"\n\n  # Put events in the host specific topic.\n  topic = \"{{service}}\"\n  encoding.except_fields = [\"service\"] # Remove this field now and save some bytes\n  # ...\n```\n\n----------------------------------------\n\nTITLE: Build Vector (Linux ARM64, Docker)\nDESCRIPTION: This command builds a statically linked binary of Vector for Linux (ARM64) using the 'make' utility and Docker. It utilizes a Docker image with a Rust toolchain for the specified target.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\nmake package-aarch64-unknown-linux-musl-all\n```\n\n----------------------------------------\n\nTITLE: Migrating from start_at_beginning to ignore_checkpoints and read_from\nDESCRIPTION: This snippet demonstrates how to migrate from the deprecated `start_at_beginning` option of the `file` source to the new `ignore_checkpoints` and `read_from` options. These new options provide more fine-grained control over how the `file` source reads data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_5\n\nLANGUAGE: diff\nCODE:\n```\n [sources.file]\n type = \"file\"\n-start_at_beginning = true\n+ignore_checkpoints = false # default\n+read_from = \"beginning\" # default\n```\n\n----------------------------------------\n\nTITLE: Example CSV Log File\nDESCRIPTION: This is an example CSV log file produced by PostgreSQL's csvlog. It contains several comma-separated fields representing different log attributes, such as timestamp, process ID, message, etc. These logs will be parsed using the lua transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_0\n\nLANGUAGE: CSV\nCODE:\n```\n2020-04-09 12:48:49.661 UTC,,,1,,localhost.1,1,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\"ending log output to stderr\",,\"Future log output will go to log destination \"\"csvlog\"\".\",,,,,,,\"\"\n2020-04-09 12:48:49.669 UTC,,,27,,localhost.1b,1,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\"database system was shut down at 2020-04-09 12:48:25 UTC\",,,,,,,,,\"\"\n2020-04-09 12:48:49.683 UTC,,,1,,localhost.1,2,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\"database system is ready to accept connections\",,,,,,,,,\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining the BasicSink Struct in Rust\nDESCRIPTION: This code defines the `BasicSink` struct, which represents the sink itself. It's a simple struct with no fields, indicating it has no configurable behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\nstruct BasicSink;\n```\n\n----------------------------------------\n\nTITLE: Slice and Type Preservation Example - Text\nDESCRIPTION: This VRL code snippet illustrates how the `slice` function now preserves more type information on array elements. This change removes the need for an explicit type conversion (to_int!) in certain scenarios, enhancing the type safety and clarity of VRL code. The snippet compares the approach prior to v0.22.0 and the newer, more streamlined version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-0-45-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\narr = [3.5, \"str\"]\nsub = slice!(arr, 0, 1)\nfirst = sub[0]\n\n# pre v0.22.0\n#. = to_int!(first)\n\n# Now,the compiler knows that `first` is an float, and we don't need the `!`.\n. = to_int(first)\n```\n\n----------------------------------------\n\nTITLE: Updating Licenses\nDESCRIPTION: These commands install and use `dd-rust-license-tool` to update the `LICENSE-3rdparty.csv` file.  It installs the tool, writes the updated licenses, commits the changes, and pushes the commit to the repository. This ensures that the project's license information is accurate and up-to-date.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\ncargo install dd-rust-license-tool --locked\ndd-rust-license-tool write\ngit commit -am \"dd-rust-license-tool write\"\ngit push\n```\n\n----------------------------------------\n\nTITLE: Installing Vector using Homebrew\nDESCRIPTION: This command adds the vectordotdev/brew tap to Homebrew and then installs the Vector package. It allows users to easily install Vector from the official Homebrew tap.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/homebrew.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nbrew tap vectordotdev/brew && brew install vector\n```\n\n----------------------------------------\n\nTITLE: Running Integration Tests for a Specific Component in Vector\nDESCRIPTION: This command executes integration tests for a specified component. Integration tests require external services to be running, typically within Docker containers. A Makefile entry must exist for the specific component.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nmake test-integration-<name>\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Correct HTTP Config\nDESCRIPTION: This snippet demonstrates the successful execution of Vector using a correct HTTP configuration. It pipes the content of `five-lines-second` to Vector using `vector-pr`, sets the log level, and specifies the `config-right-http.toml` configuration file.  With the corrected endpoint, Vector should successfully send the data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-second | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-pr -c ./config-right-http.toml\n2022-04-06T05:04:49.046963Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\"\n2022-04-06T05:04:49.047005Z  INFO vector::app: Loading configs. paths=[\"config-right-http.toml\"]\n2022-04-06T05:04:49.047691Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-04-06T05:04:49.063511Z  INFO vector::topology::running: Running healthchecks.\n2022-04-06T05:04:49.063545Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-04-06T05:04:49.063615Z  INFO vector: Vector has started. debug=\"false\" version=\"0.21.0\" arch=\"x86_64\" build_id=\"none\"\n2022-04-06T05:04:49.063676Z  INFO vector::shutdown: All sources have finished.\n2022-04-06T05:04:49.063686Z  INFO vector: Vector has stopped.\n2022-04-06T05:04:49.063698Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-04-06T05:04:49.064697Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069/\ntotal 4\ndrwxrwxr-x 3 toby toby 4096 Apr  6 01:04 buffer\n```\n\n----------------------------------------\n\nTITLE: Defining SinkConfig and Sink enum in Rust\nDESCRIPTION: This code defines a `SinkConfig` trait with an asynchronous `build` method that returns a `Sink`. The `Sink` enum represents different types of sinks: StreamingSink, ServiceSink, and a wrapper for an old futures01::Sink. It also includes a `run` method for processing a stream of events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-06-18-2625-architecture-revisit.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\ntrait SinkConfig {\n    async fn build(&self) -> Result<Sink>;\n}\n\nenum Sink {\n    Streaming(StreamingSink),\n    Service(ServiceSink),\n    OldAndBad(futures01::Sink),\n}\n\nimpl Sink {\n    async fn run(self, input: Stream<Event>) -> Result<()> {\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Example Input with Timestamp for Remap Transform\nDESCRIPTION: This JSON object showcases an input with a timestamp field, a host field and an events array, serving as input for the `remap` transform. This input is used to demonstrate the effect of the `only_fields` option in the `unnest` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"timestamp\": \"2020-12-09T16:09:53+00:00\", \"host\": \"localhost\", \"events\": [{ \"message\": \"foo\" }, { \"message\": \"bar\" }] }\n```\n\n----------------------------------------\n\nTITLE: MongoDB Version Info Metric - Prometheus\nDESCRIPTION: This snippet provides the software version information for the MongoDB process, enabling easy identification of the running version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_34\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_version_info Software version information for mongodb process.\n# TYPE mongodb_version_info gauge\nmongodb_version_info{mongodb=\"4.4.0\"} 1\n```\n\n----------------------------------------\n\nTITLE: Example Log Data in JSON\nDESCRIPTION: This JSON snippet represents a common log entry, including timestamp, stream, and the log message itself. It serves as input for the VRL examples to demonstrate data transformation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"time\": \"2021-02-03T21:13:54.713161211Z\",\n  \"stream\": \"stdout\",\n  \"log\": \"5.86.210.12 - zieme4647 [03/Feb/2021:21:13:55 -0200] \\\"GET /embrace/supply-chains/dynamic/vertical HTTP/1.0\\\" 201 20574\"\n}\n```\n\n----------------------------------------\n\nTITLE: Create Kinesis Firehose Delivery Stream (bash)\nDESCRIPTION: Creates a Kinesis Firehose delivery stream with the specified configuration, including the endpoint URL, access key, request configuration, CloudWatch logging options, IAM role ARN, retry options, S3 backup mode, and S3 configuration. This stream sends CloudWatch Logs to the Vector instance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ aws firehose create-delivery-stream --delivery-stream-name ${FIREHOSE_DELIVERY_STREAM} \\\n    --http-endpoint-destination file://<(cat <<EOF\n{\n  \"EndpointConfiguration\": {\n    \"Url\": \"${VECTOR_ENDPOINT}\",\n    \"Name\": \"vector\",\n    \"AccessKey\": \"${FIREHOSE_ACCESS_KEY}\"\n  },\n  \"RequestConfiguration\": {\n    \"ContentEncoding\": \"GZIP\"\n  },\n  \"CloudWatchLoggingOptions\": {\n    \"Enabled\": true,\n    \"LogGroupName\": \"${FIREHOSE_LOG_GROUP}\",\n    \"LogStreamName\": \"${FIREHOSE_LOG_STREAM}\"\n  },\n  \"RoleARN\": \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/FirehoseVector\",\n  \"RetryOptions\": {\n    \"DurationInSeconds\": 300\n  },\n  \"S3BackupMode\": \"FailedDataOnly\",\n  \"S3Configuration\": {\n    \"RoleARN\": \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/FirehoseVector\",\n    \"BucketARN\": \"arn:aws:s3:::${FIREHOSE_S3_BUCKET}\"\n  }\n}\nEOF\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring MongoDB Metrics Source in TOML\nDESCRIPTION: This TOML configuration defines a new source in Vector to collect metrics from a MongoDB server.  It specifies the source type as `mongodb_metrics`, the connection endpoint including credentials, the scrape interval in seconds, and the namespace to be applied to the metrics. TLS settings and MongoDB Authorization guide are also mentioned.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"mongodb_metrics\" # required\n  endpoint = \"mongodb://mongodb_exporter:s3cr3tpassw0rd@localhost:27017\" # required - address of the MongoDBserver.\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"mongodb\" # optional, default is \"mongodb\", namespace to attach to metrics.\n```\n\n----------------------------------------\n\nTITLE: MongoDB Op Counters Metrics - Prometheus\nDESCRIPTION: This snippet shows the total number of operations performed on MongoDB, categorized by type. It provides a granular view of database activity and utilization.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_32\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_op_counters_total The opcounters data structure provides an overview of database operations by type and makes it possible to analyze the load on the database in more granular manner. These numbers will grow over time and in response to database use. Analyze these values over time to track database utilization\n# TYPE mongodb_op_counters_total counter\nmongodb_op_counters_total{type=\"command\"} 17\nmongodb_op_counters_total{type=\"delete\"} 0\nmongodb_op_counters_total{type=\"getmore\"} 0\nmongodb_op_counters_total{type=\"insert\"} 0\nmongodb_op_counters_total{type=\"query\"} 1\nmongodb_op_counters_total{type=\"update\"} 0\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Running Checkpoints Metrics - Prometheus\nDESCRIPTION: This snippet displays the number of currently running checkpoints in WiredTiger. This metric provides insight into the ongoing write activity and the load on the storage engine.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_27\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_mongod_wiredtiger_transactions_running_checkpoints The number of currently running checkpoints in WiredTiger\n# TYPE mongodb_mongod_wiredtiger_transactions_running_checkpoints gauge\nmongodb_mongod_wiredtiger_transactions_running_checkpoints 0\n```\n\n----------------------------------------\n\nTITLE: Defining Decoder struct in Rust\nDESCRIPTION: This struct represents the decoder, holding a boxed framer and a boxed parser.  It implements the decoding logic by first using the framer to produce byte frames, then using the parser to convert those frames into events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Clone)]\npub struct Decoder {\n    framer: BoxedFramer,\n    parser: BoxedParser,\n}\n```\n\n----------------------------------------\n\nTITLE: Fallible Expression Example - Coffee\nDESCRIPTION: This CoffeeScript-like VRL example demonstrates a fallible expression where the `to_string` function is called on a potentially null value `.foo`. This can lead to a runtime error if `.foo` is null.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_9\n\nLANGUAGE: coffee\nCODE:\n```\nto_string(.foo)\n```\n\n----------------------------------------\n\nTITLE: Build Vector (Linux ARMv7, Docker)\nDESCRIPTION: This command builds a statically linked binary of Vector for Linux (ARMv7) using the 'make' utility and Docker. It utilizes a Docker image with a Rust toolchain for the specified target.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\nmake package-armv7-unknown-linux-muslueabihf-all\n```\n\n----------------------------------------\n\nTITLE: Variable Expression resolves_to Implementation\nDESCRIPTION: Shows how the `resolves_to` function is implemented for the `Variable` expression. It fetches the resolve kind of the variable from the `CompilerState`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_10\n\nLANGUAGE: rust\nCODE:\n```\nimpl Expression for Variable {\n    fn resolves_to(&self, state: &CompilerState) -> ResolveKind {\n        state.variable(&self.ident).unwrap_or(ResolveKind::Any)\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining BatchConfig trait in Rust\nDESCRIPTION: This Rust code defines a `BatchConfig` trait and related structs/traits used for configuring the batching process in the Vector data pipeline. It includes methods for checking if a batch is ready to be sent based on minimum size requirements and defines settings related to batch size and minimum part size for multipart uploads.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-07-3829-better-support-for-large-aws-s3-batches.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\ntrait BatchConfig<T> {\n    …\n    /// Returns true if it the batch is full enough to send.\n    fn is_batch_ready(&self) -> bool;\n}\n\nstruct BatcherSettings {\n    …\n    pub size_minimum: usize,\n}\n\ntrait SinkBatchSettings {\n    …\n    const MIN_BYTES: Option<usize>;\n}\n\nstruct BatchConfig<D: SinkBatchSettings, S = Unmerged> {\n    …\n    pub min_part_bytes: Option<usize>,\n}\n```\n\n----------------------------------------\n\nTITLE: Vector Remap Transform Environment Variable Interpolation (YAML)\nDESCRIPTION: This YAML snippet demonstrates environment variable interpolation within a Vector Remap transform. It shows how to access environment variables like `HOSTNAME` and `ENV`, set default values if the variables are not present, and require environment variables to be present using different syntaxes. It also demonstrates escaping environment variables by prefacing them with `$`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  add_host:\n    type: \"remap\"\n    source: |\n      # Basic usage. \"$HOSTNAME\" also works.\n      .host = \"${HOSTNAME}\" # or \"$HOSTNAME\"\n\n      # Setting a default value when not present.\n      .environment = \"${ENV:-development}\"\n\n      # Requiring an environment variable to be present.\n      .tenant = \"${TENANT:?tenant must be supplied}\"\n```\n\n----------------------------------------\n\nTITLE: Initial Vector Configuration TOML\nDESCRIPTION: This TOML configuration file sets up a basic Vector pipeline. It defines a `file` source that reads CSV files, a `lua` transform that currently passes events through unchanged, and a `console` sink that outputs the events as JSON. This config serves as a starting point for adding CSV parsing logic to the lua transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\ndata_dir = \".\"\n\n[sources.file]\n  type = \"file\"\n  include = [\"*.csv\"]\n  ignore_checkpoints = true\n\n[transforms.lua]\n  inputs = [\"file\"]\n  type = \"lua\"\n  version = \"2\"\n  hooks.process = \"\"\"\n    function (event, emit)\n      -- to be expanded\n      emit(event)\n    end\n  \"\"\"\n\n[sinks.console]\n  inputs = [\"lua\"]\n  type = \"console\"\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Cached Metrics Struct Definition Rust\nDESCRIPTION: This Rust code defines a `Cached` struct for caching registered metrics based on tags. It uses an `Arc<RwLock<BTreeMap>>` to store the cache, allowing for thread-safe access and modification. The `register` function is used to create new registered events when they are not found in the cache.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2023-05-03-data-volume-metrics.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nstruct Cached<Tags, Event> {\n  cache: Arc<RwLock<BTreemap<Tags, Registered<Event>>>>,\n  register: Fn(Tags) -> Registered<Event>,\n}\n\nimpl<Tags, Event> Cached<Tags, Event> {\n  fn emit(&mut self, tags: Tags, value: Event) -> {\n    if Some(event) = self.cache.get(tags) {\n      event.emit(value);\n    } else {\n      let event = self.register(tags);\n      event.emit(value);\n      self.cache.insert(tags, event);\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Lua Module: Log to Metric Functions\nDESCRIPTION: This Lua code defines a module with functions for initializing, processing, shutting down, and handling timers in a log-to-metric transform. It increments an event counter and emits metric events based on the counter's value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_7\n\nLANGUAGE: lua\nCODE:\n```\nfunction init (emit)\n  event_counter = 0\n  emit({\n    log = {\n      message = \"starting up\"\n    }\n  }, \"auxiliary\")\nend\n\nfunction process (event, emit)\n  event_counter = event_counter + 1\nend\n\nfunction shutdown (emit)\n  emit {\n    metric = {\n      name = \"counter_10s\",\n      counter = {\n        value = event_counter\n      }\n    }\n  }\n\n  emit({\n    log = {\n      message = \"shutting down\"\n    }\n  }, \"auxiliary\")\nend\n\nfunction timer_handler (emit)\n  emit {\n    metric = {\n      name = \"counter_10s\",\n      counter = {\n        value = event_counter\n      }\n    }\n  }\n  counter = 0\nend\n```\n\n----------------------------------------\n\nTITLE: GraphQL Query for Topology and Metrics\nDESCRIPTION: This GraphQL query retrieves information about the configured Vector topology (sources, transforms, and sinks) along with their associated metrics. It fetches the component ID and metrics such as the total number of events or bytes processed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_3\n\nLANGUAGE: GraphQL\nCODE:\n```\nquery {\n  # Get the first 5 sources.\n  sources(first: 5) {\n    # See https://relay.dev/graphql/connections.htm\n    edges {\n      node {\n        componentId\n        metrics {\n          # Total events that the source has received.\n          receivedEventsTotal {\n            receivedEventsTotal\n          }\n        }\n      }\n    }\n  }\n\n  # Get transforms (defaults to the first 10 when a limit isn't specified)\n  transforms {\n    edges {\n      node {\n        componentId\n        metrics {\n          # Total events that the transform has sent out.\n          sentEventsTotal {\n            sentEventsTotal\n          }\n        }\n      }\n    }\n  }\n\n  # Get the last 3 sinks.\n  sinks(last: 3) {\n    edges {\n      node {\n        componentId\n        metrics {\n          # Total bytes sent by this sink.\n          sentBytesTotal {\n            sentBytesTotal\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setup Vector RPM repository (Shell)\nDESCRIPTION: This command creates the /etc/yum.repos.d/vector.repo file that defines the vector.dev yum repository. It configures the repository with the base URL, enables it, sets gpgcheck options, and specifies the GPG keys to use for verifying package signatures.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\ncat <<EOF > /etc/yum.repos.d/vector.repo\n[vector]\nname = Vector\nbaseurl = https://yum.vector.dev/stable/vector-0/\\$basearch/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://keys.datadoghq.com/DATADOG_RPM_KEY_CURRENT.public\n       https://keys.datadoghq.com/DATADOG_RPM_KEY_B01082D3.public\n       https://keys.datadoghq.com/DATADOG_RPM_KEY_FD4BF915.public\nEOF\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Fields in Lua\nDESCRIPTION: This example demonstrates accessing nested fields using field path notation in Lua. It is a legacy approach which is being improved.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_0\n\nLANGUAGE: lua\nCODE:\n```\nevent[\"nested.field\"] = 5\n```\n\n----------------------------------------\n\nTITLE: Batched UDM Events with customer_id\nDESCRIPTION: This JSON object represents a batch of UDM events along with the `customer_id`, required by the Google Chronicle API. The `events` field contains an array of UDM event objects. This is the format expected for sending multiple UDM events to the `gcp_chronicle_udm` sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-05-17-11532-chronicle-sink.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n\"customer_id\": \"c8c65bfa-5f2c-42d4-9189-64bb7b939f2c\",\n\"events\": [...]\n}\n```\n\n----------------------------------------\n\nTITLE: Wrap EventData with Event Structure in Rust\nDESCRIPTION: This code renames the `Event` enum to `EventData` and introduces a new `Event` struct that wraps `EventData` and includes `EventMetadata`. This allows associating metadata with events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-02-04-5802-event-metadata.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nstruct Event {\n    data: EventData,\n    metadata: EventMetadata,\n}\n\nenum EventData {\n    Log(LogEvent),\n    Metric(Metric),\n}\n```\n\n----------------------------------------\n\nTITLE: Executing a Command with vdev\nDESCRIPTION: This command uses vdev to execute the `ls` command. This is used to test if vdev can be invoked from any working directory after setting the repository path in the vdev configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/vdev/README.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nvdev exec ls\n```\n\n----------------------------------------\n\nTITLE: Route Transform Metrics Change Example\nDESCRIPTION: Illustrates the change in metric tagging for the `route` transform in Vector 0.20. Specific route information is now recorded as a metric tag `output` instead of a separate transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-0-20-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n- {\"counter\":{\"value\":10.0},\"name\":\"events_discarded_total\"... \"tags\":{\"component_id\":\"foo.first\",\"component_kind\":\"transform\",\"component_name\":\"foo.first\",\"component_type\":\"route\"}}\n+ {\"counter\":{\"value\":10.0},\"name\":\"events_discarded_total\"... \"tags\":{\"component_id\":\"foo\",\"component_kind\":\"transform\",\"component_name\":\"foo\",\"component_type\":\"route\",\"output\":\"first\"}}\n```\n\n----------------------------------------\n\nTITLE: Testing Remap Transform with Dropped Output TOML\nDESCRIPTION: This TOML configuration demonstrates how to unit test a `remap` transform's `dropped` output in Vector. It defines a transform named `foo` that drops events and reroutes them to a `dropped` output. The test verifies that the `dropped` output contains the expected event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-01-12-vector-unit-test-improvements.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.foo]\n  type = \"remap\"\n  inputs = []\n  drop_on_abort = true\n  reroute_dropped = true\n  source = \"abort\"\n\n[[tests]]\n  name = \"remap_dropped_output\"\n  no_outputs_from = [ \"foo\" ]\n\n  [[tests.inputs]]\n    insert_at = \"foo\"\n    type = \"log\"\n    [tests.inputs.log_fields]\n      message = \"I will be dropped\"\n\n  [[tests.outputs]]\n    extract_from = \"foo.dropped\"\n\n    [[tests.outputs.conditions]]\n      type = \"vrl\"\n      source = 'assert_eq!(.message, \"I will be dropped\", \"incorrect message\")'\n```\n\n----------------------------------------\n\nTITLE: Example Server Error Message (Payload Too Large)\nDESCRIPTION: This snippet shows an example of a server error message when a payload exceeds the maximum allowed size. It indicates that the server received a compressed JSON payload larger than 8192 bytes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_26\n\nLANGUAGE: text\nCODE:\n```\n📥 Received POST request:\n🔗 Path: /logs\n📜 Headers:\n   content-type: application/json\n   content-encoding: deflate\n   accept-encoding: zstd,gzip,deflate,br\n   user-agent: Vector/0.45.0-custom-bac0c2015 (aarch64-apple-darwin debug=full)\n   host: localhost:8000\n   content-length: 1e+07\n🗜️ Payload was zlib-compressed. Decompressed successfully.\n📦 JSON Payload: [\n  {\n    \"group\": 0,\n    \"key\": \"a\",\n    \"property\": \"foo\"\n  },\n  {\n    \"group\": 0,\n    \"key\": \"a\",\n    \"property\": \"foo\"\n  },\n  // Assume a lot more bytes...\n],\n❌ Error: Maximum payload size exceeded. Rejecting payloads over 8192 bytes.\n```\n\n----------------------------------------\n\nTITLE: Exporting Prometheus data to Datadog with Vector (TOML)\nDESCRIPTION: This snippet configures Vector to receive Prometheus data via the `prometheus_remote_write` source and then sends the data to Datadog using the `datadog_metrics` sink. This setup allows Vector to act as a proxy, forwarding Prometheus metrics to Datadog for monitoring and analysis. This configuration assumes that the Datadog sink is correctly configured with the necessary API keys and endpoint information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-11-19-prometheus-remote-integrations.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.prometheus]\n  type = \"prometheus_remote_write\"\n\n[sinks.datadog]\n  type = \"datadog_metrics\"\n  inputs = [\"prometheus\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring dataDir and logSchema in Vector Helm Chart\nDESCRIPTION: This YAML snippet shows how to configure the `data_dir` and `log_schema` global options within the `customConfig` section of the Helm chart's `values.yaml` file. These options define the directory for storing Vector's data and the schema for log messages, respectively. This configuration replaces the previous method of setting these options directly through TOML-based keys.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  data_dir: \"/vector-data-dir\"\n  log_schema:\n    host_key: host\n    message_key: message\n    source_type_key: source_type\n    timestamp_key: timestamp\n  ...\n```\n\n----------------------------------------\n\nTITLE: Running Vector Commands from Outside Environment\nDESCRIPTION: This section provides examples of how to run `make` commands from outside the Docker/Podman development environment by setting the `ENVIRONMENT=true` flag. These commands include compiling, building, testing, benchmarking, and formatting the code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Validate your code can compile\nmake check ENVIRONMENT=true\n# Validate your code actually does compile (in dev mode)\nmake build-dev ENVIRONMENT=true\n# Validate your test pass\nmake test SCOPE=\"sources::example\" ENVIRONMENT=true\n# Validate tests (that do not require other services) pass\nmake test ENVIRONMENT=true\n# Validate your tests pass (starting required services in Docker)\nmake test-integration SCOPE=\"sources::example\" ENVIRONMENT=true\n# Validate your tests pass against a live service.\nmake test-integration SCOPE=\"sources::example\" AUTOSPAWN=false ENVIRONMENT=true\n# Validate all tests pass (starting required services in Docker)\nmake test-integration ENVIRONMENT=true\n# Run your benchmarks\nmake bench SCOPE=\"transforms::example\" ENVIRONMENT=true\n# Format your code before pushing!\nmake fmt ENVIRONMENT=true\n```\n\n----------------------------------------\n\nTITLE: Inserting Vector Metadata into Log Event in Rust\nDESCRIPTION: This code snippet demonstrates how to insert Vector-specific metadata (ingest timestamp and source type) into a log event using the provided `log_namespace` enum. It utilizes the `insert_vector_metadata` function to add these fields to the appropriate namespace, avoiding naming conflicts. The `path!()` macro constructs value paths.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n  self.log_namespace.insert_vector_metadata(\n      &mut log_event,\n      path!(self.timestamp_key()),\n      path!(\"ingest_timestamp\"),\n      chrono::Utc::now(),\n  );\n\n  self.log_namespace.insert_vector_metadata(\n      &mut log_event,\n      path!(self.source_type_key()),\n      path!(\"source_type\"),\n      DnstapConfig::NAME,\n  );\n```\n\n----------------------------------------\n\nTITLE: Remove existing RPM repository (Shell)\nDESCRIPTION: This command removes the existing timber.io repository configuration file for RPM package manager. This is the first step in manually migrating to the new vector.dev repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nrm \"/etc/yum.repos.d/timber-vector.repo\"\n```\n\n----------------------------------------\n\nTITLE: Modified Event Test Case YAML\nDESCRIPTION: This YAML example shows a test case with a modified event, used to induce failure in the http_server source validation. One of the events is marked as `modified: true`, instructing the external resource to encode the event in a way that causes a failure, like using an incorrect encoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\n- name: one bad apple\n  expectation: partial_success\n  events:\n    - good message 1\n    - modified: true\n      event: bad message 1\n    - good message 2\n```\n\n----------------------------------------\n\nTITLE: Initializing WASM Transform Module in Rust\nDESCRIPTION: This Rust code snippet demonstrates how to initialize a WASM transform module using the `vector-wasm` crate. It registers the module as a transform, allowing Vector to use it as a transform type. It imports the necessary items from the `vector_wasm` crate and defines an `init` function, which is called when the module is loaded. The `#[no_mangle]` attribute ensures that the function is not mangled by the compiler, and `pub extern \"C\"` makes it accessible from C code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_0\n\nLANGUAGE: Rust\nCODE:\n```\nuse vector_wasm::{Registration, roles::Sink;\n\n#[no_mangle]\n// TODO: This is unsafe -- Needs a fix.\npub extern \"C\" fn init() {\n Registration::transform()\n    .register()\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Alloc Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes allocated and still in use by the Go program. It is an important indicator of memory usage and potential memory leaks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_40\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.\n# TYPE go_memstats_alloc_bytes gauge\ngo_memstats_alloc_bytes 7.146072e+06\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: Conditional Mapping with 'if' (Coffee)\nDESCRIPTION: Illustrates conditional mapping using an `if` statement within the `remap` transform. If `.bar` is not null, it assigns the value of `.bar` to `.foo` and then deletes `.bar`. Finally, it assigns a static string to `.baz`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-04-3325-remap-v2.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\nif .bar != null {\n  .foo = .bar\n  del(.bar)\n}\n.baz = \"something static\"\n```\n\n----------------------------------------\n\nTITLE: AWS S3 Source Configuration Example\nDESCRIPTION: This is an example of the configuration for the `aws_s3` source in Vector.  It shows the required and optional parameters for configuring the source, including SQS queue URL, polling interval, visibility timeout, and compression settings.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-29-4155-aws-s3-source.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  # General\n  type = \"aws_s3\" # required\n  compression = \"auto\" # optional; compression format of the objects; one of: [\"auto\", \"none\", \"gzip\" \"lz4\" \"snappy\" \"zstd\"]; default\n\n  strategy = \"sqs\" # optional, default, one of [\"sqs\"]\n\n  sqs.queue_url = \"https://sqs.us-east-1.amazonaws.com/1234/test-s3-queue\"\n  sqs.poll_secs = 30 # minimum poll interval, optional, default\n  sqs.visibility_timeout_secs = 300 # default visibility timeout for SQS message; if vector does not process the message in this time, the SQS message will be available to be reprocessed\n  sqs.delete_message = true # whether to delete the message after processing; false is useful for debugging; default\n```\n\n----------------------------------------\n\nTITLE: Running Tests for a Specific Component (reduce transform) in Rust (with cargo-watch)\nDESCRIPTION: This command utilizes `cargo-watch` to automatically run unit tests for the `reduce` transform whenever changes are detected. It disables default features and targets the specified component. cargo-watch and a compatible version of LLVM are required.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\ncargo watch -s clear -s \\\n  'cargo test --lib --no-default-features --features=transforms-reduce transforms::reduce'\n```\n\n----------------------------------------\n\nTITLE: Filter Transform Unit Test with no_outputs_from (TOML)\nDESCRIPTION: This test configuration defines a filter transform that filters events based on the 'env' field. The unit test asserts that the 'log_filter' transform produces no output when the 'env' field is not 'production'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_11\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.log_filter]\ntype = \"filter\"\ninputs = [\"log_source\"]\ncondition = '.env == \"production\"'\n\n[[tests]]\nname = \"Filter out non-production events\"\nno_outputs_from = [\"log_filter\"]\n\n[[tests.inputs]]\ntype = \"log\"\ninsert_at = \"log_filter\"\n\n[tests.inputs.log_fields]\nmessage = \"success\"\ncode = 202\nendpoint = \"/transactions\"\nmethod = \"POST\"\nenv = \"staging\"\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Cursor Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus gauge metrics for monitoring open cursors in MongoDB. It includes labels for the cursor state (noTimeout, pinned, total) to provide insights into cursor usage and potential issues.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_7\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_cursor_open The open is an embedded document that contains data regarding open cursors\n# TYPE mongodb_mongod_metrics_cursor_open gauge\nmongodb_mongod_metrics_cursor_open{state=\"noTimeout\"} 0\nmongodb_mongod_metrics_cursor_open{state=\"pinned\"} 0\nmongodb_mongod_metrics_cursor_open{state=\"total\"} 0\n```\n\n----------------------------------------\n\nTITLE: Lua Process Hook Example\nDESCRIPTION: This code snippet demonstrates how to define a 'process' hook in Lua, which is called on each incoming event. It shows how to modify the event and emit it to downstream components using the 'emit' function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_0\n\nLANGUAGE: lua\nCODE:\n```\nevent.log.my_field = \"my value\"\nemit(event)\n```\n\n----------------------------------------\n\nTITLE: Tail Vector Agent Logs (kubectl)\nDESCRIPTION: This command retrieves and displays the logs from the Vector agent running as a DaemonSet within the specified Kubernetes namespace. It is used to monitor the health and activity of the Vector agent after deployment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkubectl logs -n vector daemonset/vector\n```\n\n----------------------------------------\n\nTITLE: Compile Root Expressions with Fallible Error Tracking - Rust\nDESCRIPTION: This Rust code snippet demonstrates the updated implementation of the `compile_root_exprs` function, which uses a state variable `fallible_expression_error` to track the specific fallible expression within a chain.  It identifies and reports the innermost fallible expression for better error reporting.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_13\n\nLANGUAGE: rust\nCODE:\n```\nfor expr in root_expressions {\n    self.fallible_expression_error = None;\n\n    let expr = self.compile_expr(expr);\n\n    if let Some(error) = self.fallible_expression_error {\n        self.errors.push(error);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Avro Fixtures using Cargo\nDESCRIPTION: This bash command regenerates the Avro test fixture data files for the Vector project. It uses the cargo run command to execute the 'generate-avro-fixtures' binary within the 'codecs' package.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/codecs/tests/data/avro/README.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncargo run --package codecs --bin generate-avro-fixtures\n```\n\n----------------------------------------\n\nTITLE: Acknowledgement Configuration Options in TOML\nDESCRIPTION: This TOML configuration demonstrates the new `acknowledgements` setting at the global, source, and buffer levels, and the `authoritative` setting at the sink level.  These options control how Vector handles acknowledgements for sources and sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-03-26-6517-end-to-end-acknowledgement.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# Global enable option\n# Defaults to `true`\nacknowledgements = true\n\n[sources.my_source_id]\n  # Enable or disable waiting for acknowledgements for this sink.\n  # Defaults to the global value of `acknowledgements`\n  acknowledgements = true\n\n[sinks.my_sink_id]\n  # Treat this sinks' acknowledgements as authoritative for the event.\n  # Defaults to `false`\n  authoritative = true\n\n  # Enable or disable acknowledging events when they are buffered.\n  # Defaults to `false`\n  buffer.acknowledgements = true\n```\n\n----------------------------------------\n\nTITLE: GraphQL Notification Union Type\nDESCRIPTION: This GraphQL snippet defines the `Notification` union type, which includes specific notification types such as `Matched`, `NotMatched`, and `InvalidMatch`. This union provides a structured way to represent different kinds of notifications with their own specific data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: graphql\nCODE:\n```\nunion Notification = Matched | NotMatched | InvalidMatch\n```\n\n----------------------------------------\n\nTITLE: Existing Observability Instrumentation\nDESCRIPTION: This code snippet demonstrates the current approach to observability using `tracing` and `metrics` crates. It shows how multiple statements are required for a single event, potentially leading to inconsistency and discoverability issues. The snippet is from a hypothetical `file source` component.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-17-2064-event-driven-observability.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nmessages\n    .map(move |(msg, file): (Bytes, String)| {\n        trace!(\n            message = \"Received one event.\",\n            file = file.as_str(),\n            rate_limit_secs = 10\n        );\n        counter!(\"events_processed_total\", 1, \"source\" => \"file\");\n        counter!(\"bytes_processed\", msg.len() as u64, \"source\" => \"file\");\n        create_event(msg, file, &host_key, &hostname, &file_key)\n    })\n    .forward(out.sink_map_err(|error| error!(?error)))\n```\n\n----------------------------------------\n\nTITLE: Configure Enrichment Table for IP Alerts in Vector TOML\nDESCRIPTION: This TOML configuration sets up a Vector transform named 'ip_alert' that enriches data from the 'datadog_agent' input.  It extracts an IP address and uses `get_enrichment_table_record` to look up the 'alert_type' and 'severity' from the 'ip_info' enrichment table, adding them to the output data under the '.alert' field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.ip_alert]\ntype = \"remap\"\ninputs = [\"datadog_agent\"]\nsource = '''\n\n. = parse_json!(.message)\n\nip = del(.ip)\n\nrow = get_enrichment_table_record(\"ip_info\", { \"ip\" : ip }) ?? ip\n\n.alert.type = row.alert_type\n.alert.severity = row.severity\n\n'''\n```\n\n----------------------------------------\n\nTITLE: Inspecting Directory Size after Vector Run (Shell)\nDESCRIPTION: After running Vector, this snippet lists the contents and calculates the disk usage of the `http_tarpit_id` directory within the Vector data directory (`/tmp/vector/github-12069`).  This helps to determine how much data was written by the 'http_tarpit' sink during the Vector execution.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069\ntotal 12\ndrwxr-xr-x 2 toby toby 12288 Apr  6 13:40 http_tarpit_id\ntoby@consigliere:~/src/vector/testing/github-12069$ du -h /tmp/vector/github-12069/http_tarpit_id/\n929M    /tmp/vector/github-12069/http_tarpit_id/\n```\n\n----------------------------------------\n\nTITLE: Find Table Row with File Path in CoffeeScript\nDESCRIPTION: This snippet shows how to directly specify the file path and search criteria within VRL using the `find_table_row` function. This approach simplifies the configuration but may complicate future changes, such as supporting different table types or encryption.  It offers a more straightforward initial implementation by providing an additional VRL function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-20-8288-csv-enrichment.md#_snippet_4\n\nLANGUAGE: coffeescript\nCODE:\n```\nfind_table_row(\"/path/to/file.csv\", criteria)\n```\n\n----------------------------------------\n\nTITLE: Scripting Examples with Coffee\nDESCRIPTION: Demonstrates how to interact with metric tags in scripting languages (Lua and VRL) using the `metric_tag_values` configuration option.  Shows examples for both single and full modes, including assigning single values, bare tags, and arrays of values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_2\n\nLANGUAGE: coffeescript\nCODE:\n```\n# With metric_tag_values = \"single\"\n.tags.single_value = \"value\" # Replace the tag with a single value\n.tags.bare_tag = null        # Replace the tag with a bare tag\n\n# With metric_tag_values = \"full\":\n.tags.multi_valued_tag = [\"value1\", \"value2\"]\n.tags.complex_tag = [\"value3\", null]\n.tags.modified = push(.tags.modified, \"value4\")\n.tags.modified = filter(.tags.modified) -> |_, v| { v != \"remove\" }\n```\n\n----------------------------------------\n\nTITLE: List Vector Directories After Version 0.18.1 Run\nDESCRIPTION: This snippet lists the files and directories created by Vector version 0.18.1 under the /tmp/vector/github-10430/ directory. The output indicates the creation of 'http_tarpit_buffer' and 'http_tarpit_id' directories.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 8\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:33 http_tarpit_buffer\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:32 http_tarpit_id\n```\n\n----------------------------------------\n\nTITLE: Check Xcode Command Line Tools path\nDESCRIPTION: This command checks the path to the Xcode Command Line Tools, which are required for building native extensions on macOS. The output shows the current path, and the xcode-select -s command can be used to change it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nxcode-select -p\n```\n\n----------------------------------------\n\nTITLE: TOML Dedupe Transform Old Syntax\nDESCRIPTION: This TOML snippet shows the old syntax for defining a dedupe transform in Vector, referencing a field with a dash in its name.  The dot is escaped with a backslash.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.dedupe]\ntype = \"dedupe\"\ninputs = [\"input\"]\nfields.match = [\"message.user-identifier\"]\n```\n\n----------------------------------------\n\nTITLE: Expression Trait Definition (with CompilerState)\nDESCRIPTION: Updates the `resolves_to` function in the `Expression` trait to take a reference to the `CompilerState`. This allows expressions to access compile-time information about variables and paths.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_9\n\nLANGUAGE: rust\nCODE:\n```\npub trait Expression: Send + Sync {\n    fn resolves_to(&self, store: &CompilerState) -> ResolveKind;\n}\n```\n\n----------------------------------------\n\nTITLE: Update and install Vector via YUM (Shell)\nDESCRIPTION: These commands update the local YUM cache and install the Vector package from the configured repository. It ensures the system is using the latest package list and installs the Vector application.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nsudo yum makecache\nsudo yum install vector\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Input and Timeout (PR Version)\nDESCRIPTION: This shell command pipes the content of 'five-lines-second' to the 'vector-pr' executable (likely a development or pull request version), using 'config-wrong-http.toml' as its configuration file, with a timeout of 5 seconds. It showcases testing a specific Vector build.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ncat five-lines-second | timeout 5s ./vector-pr --config config-wrong-http.toml\n```\n\n----------------------------------------\n\nTITLE: Download and Unpack Vector Archive (Linux ARMv7)\nDESCRIPTION: Downloads and unpacks the latest or nightly build of Vector for Linux (ARMv7). It creates a 'vector' directory, downloads the archive using curl, and extracts it into the 'vector' directory, stripping the first two directory components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n# Latest ({{< version >}})\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/{{< version >}}/vector-{{< version >}}-armv7-unknown-linux-gnueabihf.tar.gz | \\\n  tar xzf - -C vector --strip-components=2\n\n# Nightly\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/nightly/latest/vector-nightly-armv7-unknown-linux-gnueabihf.tar.gz | \\\n  tar xzf - -C vector --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: LogEvent Internal Structure (Rust)\nDESCRIPTION: Defines the internal structure of the `LogEvent` and `Value` types in Rust. `LogEvent` contains a `BTreeMap` of fields, mapping strings to `Value` enums. `Value` can represent various data types like null, boolean, integer, float, timestamp, bytes, array, and map. Requires the `BTreeMap` and `DateTime<Utc>` types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n//! src/event/mod.rs\n#[derive(PartialEq, Debug, Clone)]\npub struct LogEvent {\n    fields: BTreeMap<String, Value>,\n}\n\n#[derive(PartialEq, Debug, Clone)]\npub enum Value {\n    Null,\n    Boolean(bool),\n    Integer(i64),\n    Float(f64),\n    Timestamp(DateTime<Utc>),\n    Bytes(Bytes),\n    Array(Vec<Value>),\n    Map(BTreeMap<String, Value>)\n}\n```\n\n----------------------------------------\n\nTITLE: Download and Unpack Vector Archive (Linux x86_64)\nDESCRIPTION: Downloads and unpacks the latest or nightly build of Vector for Linux (x86_64). It creates a 'vector' directory, downloads the archive using curl, and extracts it into the 'vector' directory, stripping the first two directory components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_10\n\nLANGUAGE: shell\nCODE:\n```\n# Latest (version {{< version >}})\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/{{< version >}}/vector-{{< version >}}-x86_64-unknown-linux-musl.tar.gz  | \\\n  tar xzf - -C vector --strip-components=2\n\n# Nightly\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/nightly/latest/vector-nightly-x86_64-unknown-linux-musl.tar.gz | \\\n  tar xzf - -C vector --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON after VRL Transformation\nDESCRIPTION: This JSON shows the resulting event structure after applying the VRL program in the previous example. It demonstrates the transformed `message`, `status`, `timestamp`, and `timestamp_str` fields, along with the removal of the `username` field. The `message` field has been converted to lowercase, and the `timestamp` field is represented as a Unix timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/_index.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"message\": \"success\",\n  \"status\": 200,\n  \"timestamp\": 1614644364,\n  \"timestamp_str\": \"2021-03-02T00:19:24Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Generating Server TLS Certificate and Key (mkcert)\nDESCRIPTION: This shell command uses `mkcert` to generate a server certificate and key for NATS with support for localhost, IPv6 localhost, and hostnames used by integration tests. It also generates a root CA.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/tests/data/nats/README.md#_snippet_0\n\nLANGUAGE: Shell Session\nCODE:\n```\n# Make sure to change to the `tests/data/nats` directory first before running these commands.\n\n# Create the server certificate/key. This will also generate a root CA which we'll need to copy as well.\n$ mkcert -cert-file nats-server.pem -key-file nats-server.key localhost ::1 nats-tls nats-tls-client-cert nats-jwt\n```\n\n----------------------------------------\n\nTITLE: Configure Swimlanes Transform in Vector TOML\nDESCRIPTION: This code snippet demonstrates how to configure the `swimlanes` transform in a `vector.toml` file. It creates two lanes, 'errors' and 'not_errors', based on whether the `level` field is equal to or not equal to 'error', respectively.  This allows for conditional routing of events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-24-swimlanes-transform.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.lanes]\n  types = \"swimlanes\"\n\n  [transforms.my_transform_id.lanes.errors]\n    \"level.eq\" = \"error\"\n\n  [transforms.my_transform_id.lanes.not_errors]\n    \"level.neq\" = \"error\"\n```\n\n----------------------------------------\n\nTITLE: Defining Buffer Sender and Receiver Structures (Rust)\nDESCRIPTION: This snippet defines the `BufferSender` and `BufferReceiver` structs in Rust, which are used for sending and receiving events through a buffer. The `BufferSender` includes an optional overflow sender, allowing events to be redirected when the primary buffer is full. `BufferReceiver` includes an optional overflow receiver, such that it will check the overflow receiver first, then the base receiver.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-14-9477-buffer-improvements.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nstruct BufferSender {\n  base: PollSender,\n  base_ready: bool,\n  overflow: Option<BufferSender>,\n  overflow_ready: bool,\n}\n\nstruct BufferReceiver {\n  base: PollReceiver,\n  overflow: Option<BufferReceiver>,\n}\n```\n\n----------------------------------------\n\nTITLE: Example Structured JSON Output\nDESCRIPTION: This is the final structured JSON output after parsing the CSV logs. Each field extracted from the CSV is assigned to a corresponding property of the event.  This represents a transformed event in a structured format, improving downstream processing and analysis.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_7\n\nLANGUAGE: JSON\nCODE:\n```\n{\"application_name\":\"\",\"backend_type\":\"not initialized\",\"command_tag\":\"\",\"connection_from\":\"\",\"context\":\"\",\"database_name\":\"\",\"detail\":\"\",\"error_severity\":\"LOG\",\"file\":\"log.csv\",\"hint\":\"Future log output will go to log destination \\\"csvlog\\\".\",\"host\":\"localhost\",\"internal_query\":\"\",\"internal_query_pos\":\"\",\"leader_pid\":\"\",\"location\":\"\",\"log_time\":\"2020-04-09 12:48:49.661 UTC\",\"message\":\"ending log output to stderr\",\"process_id\":\"1\",\"query\":\"\",\"query_id\":\"0\",\"query_pos\":\"\",\"session_id\":\"localhost.1\",\"session_line_num\":\"1\",\"session_start_time\":\"2020-04-09 12:48:49 UTC\",\"sql_state_code\":\"00000\",\"timestamp\":\"2020-04-09T19:49:07Z\",\"transaction_id\":\"0\",\"user_name\":\"\",\"virtual_transaction_id\":\"\"}\n{\"application_name\":\"\",\"backend_type\":\"not initialized\",\"command_tag\":\"\",\"connection_from\":\"\",\"context\":\"\",\"database_name\":\"\",\"detail\":\"\",\"error_severity\":\"LOG\",\"file\":\"log.csv\",\"hint\":\"\",\"host\":\"localhost\",\"internal_query\":\"\",\"internal_query_pos\":\"\",\"leader_pid\":\"\",\"location\":\"\",\"log_time\":\"2020-04-09 12:48:49.669 UTC\",\"message\":\"database system was shut down at 2020-04-09 12:48:25 UTC\",\"process_id\":\"27\",\"query\":\"\",\"query_id\":\"0\",\"query_pos\":\"\",\"session_id\":\"localhost.1b\",\"session_line_num\":\"1\",\"session_start_time\":\"2020-04-09 12:48:49 UTC\",\"sql_state_code\":\"00000\",\"timestamp\":\"2020-04-09T19:49:07Z\",\"transaction_id\":\"0\",\"user_name\":\"\",\"virtual_transaction_id\":\"\"}\n{\"application_name\":\"\",\"backend_type\":\"not initialized\",\"command_tag\":\"\",\"connection_from\":\"\",\"context\":\"\",\"database_name\":\"\",\"detail\":\"\",\"error_severity\":\"LOG\",\"file\":\"log.csv\",\"hint\":\"\",\"host\":\"localhost\",\"internal_query\":\"\",\"internal_query_pos\":\"\",\"leader_pid\":\"\",\"location\":\"\",\"log_time\":\"2020-04-09 12:48:49.683 UTC\",\"message\":\"database system is ready to accept connections\",\"process_id\":\"1\",\"query\":\"\",\"query_id\":\"0\",\"query_pos\":\"\",\"session_id\":\"localhost.1\",\"session_line_num\":\"2\",\"session_start_time\":\"2020-04-09 12:48:49 UTC\",\"sql_state_code\":\"00000\",\"timestamp\":\"2020-04-09T19:49:07Z\",\"transaction_id\":\"0\",\"user_name\":\"\",\"virtual_transaction_id\":\"\"}\n```\n\n----------------------------------------\n\nTITLE: Pre-Push Hook Setup (Bash)\nDESCRIPTION: This code snippet shows how to create a `.git/hooks/pre-push` script that runs various checks before pushing code, ensuring code quality and adherence to project standards. It utilizes `make` commands for checks like licenses, formatting, clippy, and documentation, along with a script for changelog fragment validation. The script exits immediately if any check fails (`set -e`).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntouch .git/hooks/pre-push\nchmod +x .git/hooks/pre-push\n```\n\n----------------------------------------\n\nTITLE: Develop with Native Toolchain\nDESCRIPTION: These commands are used to perform various development tasks directly on the host system, using the native toolchain. Tasks include code validation, building, testing, benchmarking, metadata rebuilding, website serving, and code formatting using both `cargo` and `make`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2685-dev-workflow-simplification.md#_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Validate your code can compile\ncargo check\nmake check\n# Validate your code actually does compile (in dev mode)\ncargo build\nmake build-dev\n# Validate your test pass\ncargo test sources::example\nmake test SCOPE=\"sources::example\"\n# Validate tests (that do not require other services) pass\ncargo test\nmake test\n# Validate your tests pass (starting required services in Docker)\nmake test-integration SCOPE=\"sources::example\" AUTOSPAWN=true\n# Validate your tests pass against a live service.\nmake test-integration SCOPE=\"sources::example\" AUTOSPAWN=false\ncargo test --features docker sources::example\n# Validate all tests pass (starting required services in Docker)\nmake test-integration\n# Run your benchmarks\nmake bench SCOPE=\"transforms::example\"\ncargo bench transforms::example\n# Rebuild Vector's metadata\nmake generate\n# Serve the website on port 3000\nmake website\n# Format your code before pushing!\nmake fmt\ncargo fmt\n```\n\n----------------------------------------\n\nTITLE: Fallible Expression with Coalescing - Coffee\nDESCRIPTION: This CoffeeScript-like VRL example demonstrates how to make an expression infallible using the `??` operator for error coalescing. If `to_int(.foo)` fails, it will default to `0`, making the entire expression infallible.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_10\n\nLANGUAGE: coffee\nCODE:\n```\nto_int(.foo) ?? 0\n```\n\n----------------------------------------\n\nTITLE: Defining Configuration Shape with Enums and Structs in Rust\nDESCRIPTION: This code defines the `Shape` enum and associated structs like `StringShape`, `NumberShape`, `ArrayShape`, and `MapShape` to represent the structure and constraints of configuration fields. The `Field` struct and `Metadata` struct are also defined to provide additional information about each configurable field, such as its description, shape, and default value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-23-9481-config-schema.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n/// The shape of the field.\n///\n/// This maps similar to the concept of JSON's data types, where types are generalized and have\n/// generalized representations. This allows us to provide general-but-relevant mappings to core\n/// types, such as integers and strings and so on, while providing escape hatches for customized\n/// types that may be encoded and decoded via \"normal\" types but otherwise have specific rules or\n/// requirements.\n///\n/// Additionally, the shape of a field can encode some basic properties about the field to which it\n/// is attached. For example, numbers can be bounded on or the lower or upper end, while strings\n/// could define a minimum length, or even an allowed pattern via regular expressions.\n///\n/// In this way, they describe a more complete shape of the field than simply the data type alone.\n#[derive(Clone)]\npub enum Shape {\n    Null,\n    Boolean,\n    String(StringShape),\n    Number(NumberShape),\n    Array(ArrayShape),\n    Map(MapShape),\n    Composite(Vec<Shape>),\n}\n\n#[derive(Clone, Default)]\npub struct StringShape {\n    minimum_length: Option<usize>,\n    maximum_length: Option<usize>,\n    allowed_pattern: Option<&'static str>,\n}\n\n#[derive(Clone)]\npub enum NumberShape {\n    Unsigned {\n        effective_lower_bound: u128,\n        effective_upper_bound: u128,\n    },\n    Signed {\n        effective_lower_bound: i128,\n        effective_upper_bound: i128,\n    },\n    FloatingPoint {\n        effective_lower_bound: f64,\n        effective_upper_bound: f64,\n    }\n}\n\n#[derive(Clone)]\npub struct ArrayShape {\n    element_shape: Box<Shape>,\n    minimum_length: Option<usize>,\n    maximum_length: Option<usize>,\n}\n\n#[derive(Clone)]\npub struct MapShape {\n    required_fields: HashMap<&'static str, Shape>,\n    allowed_unknown_field_shape: Option<Shape>,\n}\n\npub struct Field {\n    name: &'static str,\n    description: &'static str,\n    shape: Shape,\n    fields: Vec<Field>,\n    metadata: Metadata<Value>,\n}\n\n#[derive(Clone, Default)]\npub struct Metadata<T: Serialize> {\n    default: Option<T>,\n    attributes: Vec<(String, String)>,\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Agent (YAML)\nDESCRIPTION: Example YAML configuration file that sets the Vector role to Agent. This configures Vector to collect data from sources and deliver it to sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\ncat <<-'VALUES' > values.yaml\nrole: Agent\nVALUES\n```\n\n----------------------------------------\n\nTITLE: Compiled VRL Instructions (JSON)\nDESCRIPTION: This JSON snippet shows the compiled instructions for the VRL program when using the Virtual Machine. Each instruction represents a specific operation that the VM will execute. This is a more compact representation compared to the Tree Walking interpreter, allowing for better CPU cache utilization.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-15-vrl-vm-beta.md#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n [\n    \"0000: GetPath\",\n    \"0001: 0\",\n    \"0002: Constant\",\n    \"0003: 0\",\n    \"0004: Equal\",\n    \"0005: JumpIfFalse\",\n    \"0006: 7\",\n    \"0007: Pop\",\n    \"0008: Constant\",\n    \"0009: 1\",\n    \"0010: SetPath\",\n    \"0011: 1\",\n    \"0012: Jump\",\n    \"0013: 5\",\n    \"0014: Pop\",\n    \"0015: Constant\",\n    \"0016: 2\",\n    \"0017: SetPath\",\n    \"0018: 1\",\n    \"0019: Return\",\n]\n```\n\n----------------------------------------\n\nTITLE: JSON object after key transformation\nDESCRIPTION: The output JSON after applying the `map_keys` function with the uppercasing transformation. The keys 'foo' and 'bar' have been converted to 'FOO' and 'BAR', respectively.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_30\n\nLANGUAGE: json\nCODE:\n```\n{ \"FOO\": false, \"BAR\": true }\n```\n\n----------------------------------------\n\nTITLE: Adding `closure` method to Function trait - Rust\nDESCRIPTION: This code defines a new `closure` method within the `Function` trait that allows function definitions to specify details about the closure they accept, such as the number and type of variable names and the required return type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_37\n\nLANGUAGE: rust\nCODE:\n```\nfn closure(&self) -> Option<closure::Definition> {\n    None\n}\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Metadata\nDESCRIPTION: This shows how to retrieve all metadata by using `.` as the argument for the `get_metadata_field` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-06-07-vrl-metadata-and-secrets.md#_snippet_4\n\nLANGUAGE: coffeescript\nCODE:\n```\nget_metadata_field(.)\n```\n\n----------------------------------------\n\nTITLE: Upgrade Vector using YUM\nDESCRIPTION: This command upgrades the Vector package to the latest available version using YUM. `sudo` is needed to run it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/yum.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nsudo yum upgrade vector\n```\n\n----------------------------------------\n\nTITLE: Example of parsed Syslog data in JSON format\nDESCRIPTION: This JSON shows the expected output from the console sink after parsing the Syslog data using the VRL script in the remap transform. It includes fields such as appname, facility, hostname, message, msgid, procid, severity, and timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/transformation.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"appname\": \"authsvc\",\n  \"facility\": \"daemon\",\n  \"hostname\": \"acmecorp.biz\",\n  \"message\": \"#hugops to everyone who has to deal with this\",\n  \"msgid\": \"ID486\",\n  \"procid\": 5265,\n  \"severity\": \"notice\",\n  \"timestamp\": \"2021-01-19T18:16:40.027Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: GraphQL Subscription Query Update\nDESCRIPTION: This diff shows how to update a GraphQL subscription query to use the new `EventNotification` type structure, including querying the `message` field and the specific notification type fields within the `notification` union. This ensures compatibility with the updated API.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_6\n\nLANGUAGE: graphql\nCODE:\n```\n subscription {\n-   outputEventsByComponentIdPatterns(patterns: [...]) {\n+   outputEventsByComponentIdPatterns(outputsPatterns: [...]) {\n     __typename\n     ... on EventNotification {\n-       pattern\n-       notification\n+       message\n+       notification {\n+         __typename\n+         ... on Matched {\n+           pattern\n+         }\n+         ... on NotMatched {\n+           pattern\n+         }\n+         ... on InvalidMatch {\n+           pattern\n+           invalidMatches\n+         }\n+       }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Add Namespace to Metric struct in Rust\nDESCRIPTION: This code snippet shows the proposed change to the `Metric` struct in Vector's Rust code. It adds a `namespace` field of type `Option<String>` to the struct. This allows metric sources to optionally assign a namespace for the metric, which can then be used by sinks to format the metric name appropriately.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-02-3684-metric-namespaces.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub struct Metric {\n  pub name: String,\n  pub namespace: Option<String>, // added\n  pub timestamp: Option<DateTime<Utc>>,\n  pub tags: Option<BTreeMap<String, String>>,\n  pub kind: MetricKind,\n  #[serde(flatten)]\n  pub value: MetricValue,\n}\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: 'if' with 'else' Block (Coffee)\nDESCRIPTION: Demonstrates an `if` statement with an `else` block within the `remap` transform. If `.bar` is not null, it assigns the value of `.bar` to `.foo` and then deletes `.bar`. Otherwise, it assigns the string \"bar doesn't exist\" to `.foo`. Finally, it assigns a static string to `.baz`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-04-3325-remap-v2.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\nif .bar != null {\n  .foo = .bar\n  del(.bar)\n} else {\n  .foo = \"bar doesn't exist\"\n}\n.baz = \"something static\"\n```\n\n----------------------------------------\n\nTITLE: Convert Single Metric to Multiple Metrics VRL\nDESCRIPTION: This VRL snippet transforms a single metric object into multiple metric objects based on the `data` field. It extracts the `data` field, iterates over its key-value pairs using `for_each`, creates a new metric object for each pair, and pushes it into the `metrics` array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_4\n\nLANGUAGE: coffee\nCODE:\n```\n. = { \"id\": \"booster\", \"timestamp\": 123456, \"data\": { \"acceleration\": 10, \"velocity\": 20 } }\n\ndata = del(.data)\nmetrics = []\nfor_each(data) -> |key, value| {\n  metric = set(., [key], value)\n  metrics = push(metrics, metric)\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating Vector `file` Source Configuration\nDESCRIPTION: This code snippet demonstrates how to migrate the `file` source configuration in Vector by replacing the deprecated `start_at_beginning` option with the new `ignore_checkpoints` and `read_from` options. The example shows the default values for the new options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-01-31-file-source-checkpointing.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sources.file]\n type = \"file\"\n-start_at_beginning = true\n+ignore_checkpoints = false # default\n+read_from = \"beginning\" # default\n```\n\n----------------------------------------\n\nTITLE: Generated Vector TOML Configuration\nDESCRIPTION: Shows the TOML output generated by the `vector generate` command.  The generated config includes the `inputs` field for each component, linking them in a linear chain.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.transform0]\n  inputs = [ \"somewhere\" ]\n  type = \"remap\"\n  # etc ...\n\n[transforms.transform1]\n  inputs = [ \"transform0\" ]\n  type = \"filter\"\n  # etc ...\n\n[transforms.transform2]\n  inputs = [ \"transform1\" ]\n  type = \"reduce\"\n  # etc ...\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: Value Assignment with 'if' Expression (Coffee)\nDESCRIPTION: Shows how to use an `if` statement as an expression for assigning a value to a field. If `.type` is equal to \"foo\", the value of `.foo.content` is assigned to `.content`; otherwise, the value of `.bar.body` is assigned to `.content`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-04-3325-remap-v2.md#_snippet_3\n\nLANGUAGE: coffee\nCODE:\n```\n.content = if .type == \"foo\" { .foo.content } else { .bar.body }\n```\n\n----------------------------------------\n\nTITLE: Install Vector using YUM\nDESCRIPTION: This command installs the Vector package using the YUM package manager. It requires root privileges, hence the use of `sudo`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/yum.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo yum install vector\n```\n\n----------------------------------------\n\nTITLE: Socket Source Metadata Example (JSON)\nDESCRIPTION: This is an example of the metadata associated with an event from a socket source (UDP).  It includes information about the source IP, hostname, and Vector's internal source type and ingest timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"socket\": {\n    \"source_ip\": \"192.168.0.1\",\n    \"hostname\": \"localhost\"\n  },\n  \"vector\": {\n    \"source_type\": \"socket\",\n    \"ingest_timestamp\": \"2020-10-15T11:01:46.499555308Z\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: LLVM IR Function Call and Memory Management\nDESCRIPTION: This LLVM IR snippet demonstrates a function call with memory management using lifetime intrinsics and deallocation. It includes calls to llvm.lifetime.end.p0i8, rust_dealloc, and getelementptr, showcasing memory handling and control flow.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-12-20-10517-llvm-backend-for-vrl.md#_snippet_2\n\nLANGUAGE: LLVM IR\nCODE:\n```\ncall void %61(%116* noalias nocapture nonnull sret(%116) dereferenceable(24) %7, {}* nonnull align 1 %55, %74* noalias nonnull readonly align 8 dereferenceable(32) bitcast ([32 x i8]* @16149 to %74*), %135* noalias nocapture nonnull dereferenceable(40) %6) #104, !noalias !99608\ncall void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %58), !noalias !99611\n%62 = getelementptr inbounds %116, %116* %7, i64 0, i32 0\n%63 = load {}*, {}** %62, align 8, !noalias !99611\n%64 = icmp eq {}* %63, null\n%65 = bitcast {}* %63 to i8*\nbr i1 %64, label %71, label %66\n\n66:                                               ; preds = %51\n  %67 = getelementptr inbounds %116, %116* %7, i64 0, i32 1, i64 0\n  %68 = load i64, i64* %67, align 8, !noalias !99611\n  %69 = icmp eq i64 %68, 0\nbr i1 %69, label %71, label %70\n\n70:                                               ; preds = %66\n  call void @__rust_dealloc(i8* nonnull %65, i64 %68, i64 1) #104, !noalias !99608\nbr label %71\n\n71:                                               ; preds = %51, %66, %70\ncall void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %53), !noalias !99611\ncall void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %52), !noalias !99611\nbr label %47\n```\n\n----------------------------------------\n\nTITLE: Configuring Tag Cardinality Limit Transform in Vector\nDESCRIPTION: This TOML configuration demonstrates how to use the `tag_cardinality_limit` transform in a Vector pipeline. It sets the transform type, input source, action when the limit is exceeded, mode of operation (exact or probabilistic), and the maximum number of unique tag values allowed. The configuration example allows for precise control over the tag cardinality.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-11-tag-cardinality-limit-transform.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.tag_protection]\n  type = \"tag_cardinality_limit\"\n  inputs = [\"my-source-id\"]\n  limit_exceeded_action = \"drop_tag\"\n  mode = \"exact\"\n  value_limit = 500\n```\n\n----------------------------------------\n\nTITLE: Vector TOML Config with Regression Test\nDESCRIPTION: Shows how to add conditions to a unit test output to create a regression test. It includes a VRL (Vector Remap Language) expression to assert the value of a field in the output event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-complex-configs.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\n[[tests]]\n  name = \"check_simple_log\"\n\n  [[tests.inputs]]\n    insert_at = \"foo\"\n    type = \"raw\"\n    value = \"2019-11-28T12:00:00+00:00 info Sorry, I'm busy this week Cecil\"\n\n  # This is now a regression test\n  [[tests.outputs]]\n    extract_from = \"foo\"\n    [[tests.outputs.conditions]]\n      type = \"vrl\"\n      source = \"\"\"\n        assert_eq!(.message, \\\"Sorry, I'm busy this week Cecil\\\")\n      \"\"\"\n\n  # And we add a new output without conditions for inspecting\n  # a new transform\n  [[tests.outputs]]\n    extract_from = \"bar\"\n```\n\n----------------------------------------\n\nTITLE: Conditional Field Assignment in VRL\nDESCRIPTION: This VRL code snippet demonstrates how to conditionally assign a value to a field based on the existence of other fields. It uses the `if` and `exists` functions to check for the presence of `.field1` and `.field2`, assigning the value of the first existing field to the `field` variable. This is a replacement for the deprecated path coalescing feature.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-05-07-0-38-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: vrl\nCODE:\n```\nfield = if exists(.field1) {\n  .field1\n} else if exists(.field2) {\n  .field2\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating `tokenizer` to `remap` in Vector (TOML)\nDESCRIPTION: This snippet illustrates migrating a `tokenizer` transform configuration to use the `remap` transform.  The initial configuration used `field_names` and `.types` settings for tokenizing and type assignment. The updated configuration uses a VRL expression with `parse_tokens!` to tokenize the field, then assigns and casts values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_21\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.tokenizer]\ntype = \"tokenizer\"\ninputs = [\"some_input\"]\nfield_names = [\"remote_addr\", \"ident\", \"user_id\", \"timestamp\", \"message\", \"status\", \"bytes\"]\n.types.status = \"int\"\n.types.bytes = \"int\"\n```\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.tokenizer]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\nvalues = parse_tokens!(.message)\n.remote_addr = values[0]\n.user_id = values[1]\n.timestamp = values[2]\n.message = values[3]\n.status = to_int!(values[4])\n.bytes = to_int!(values[5])\n'''\n```\n\n----------------------------------------\n\nTITLE: Zero-Downtime Deployment: Initial Source Configuration\nDESCRIPTION: This code snippet shows the first step in a zero-downtime deployment strategy, configuring both v1 and v2 sources to run concurrently. It involves defining a new source with a different address and the `version = \"2\"` option, while keeping the original v1 source active.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-24-vector-source-sink.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n  [sources.vector]\n    address = \"0.0.0.0:9000\"\n    type = \"vector\"\n+   version = \"1\"\n\n+ [sources.vector]\n+   address = \"0.0.0.0:5000\"\n+   type = \"vector\"\n+   version = \"2\"\n```\n\n----------------------------------------\n\nTITLE: Running Vector with cargo (without vdev)\nDESCRIPTION: This command runs Vector directly using `cargo` without relying on `vdev`. It explicitly sets the required features (sources-stdin, sinks-basic) and specifies the configuration file. This approach allows for more granular control over the build process when `vdev` is not used.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\ncargo run --no-default-features --features \"sources-stdin, sinks-basic\" -- -c ./basic.yml\n```\n\n----------------------------------------\n\nTITLE: Config Struct Field Declaration in Rust\nDESCRIPTION: This code snippet demonstrates how to add a field to the `Config` struct to enable log namespacing.  The `#[configurable]` attribute indicates it can be configured, and `#[serde(default)]` ensures a default value if not specified. The `docs::hidden` metadata attribute hides the option from documentation as it is an unreleased feature.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n    /// The namespace to use for logs. This overrides the global setting.\n    #[configurable(metadata(docs::hidden))]\n    #[serde(default)]\n    pub log_namespace: Option<bool>,\n```\n\n----------------------------------------\n\nTITLE: Merging Empty Strings with Parse Grok Results (VRL)\nDESCRIPTION: This code snippet demonstrates how to merge empty strings into the parsed results of `parse_grok` to preserve the old behavior where empty strings were returned for non-matching pattern names. It merges a map of expected keys with empty string values into the parsed result.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: coffeescript\nCODE:\n```\nparsed = parse_grok!(.message, \"%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}\")\nexpected = { \"timestamp\": \"\", \"level\": \"\", \"message\": \"\"}\nparsed = merge(expected, parsed)\n```\n\n----------------------------------------\n\nTITLE: JSON Example Output with only_fields After Remap Transform\nDESCRIPTION: This JSON output displays the result after applying the `remap` transform with the `only_fields` option. Notice that the `timestamp` field from the input is not present in the output events, as only the `host` field was specified to be kept from the original input event using the `only_fields` option.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"localhost\", \"message\": \"foo\" }\n{ \"host\": \"localhost\", \"message\": \"bar\" }\n```\n\n----------------------------------------\n\nTITLE: Syslog Parsed JSON Example (Old Source)\nDESCRIPTION: This JSON shows the old format of parsed syslog data when using the `syslog` source, where structured data was inserted into nested maps based on the `.` characters in the keys.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"appname\": \"2d4d9490-794a-4e60-814c-5597bd5b7b7d\",\n  \"exampleSDID@32473\": {\n    \"foo\": {\n      \"baz\": \"bar\"\n    }\n  },\n  \"facility\": \"kern\",\n  \"hostname\": \"Gregorys-MacBook-Pro.local\",\n  \"message\": \"test message\",\n  \"procid\": 79978,\n  \"severity\": \"alert\",\n  \"timestamp\": \"2022-04-25T23:21:45.715740Z\",\n  \"version\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Showing Vector Helm Chart Values\nDESCRIPTION: Displays the available configuration options for the Vector Helm chart.  This allows you to customize the deployment of Vector to fit your specific needs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nhelm show values vector/vector\n```\n\n----------------------------------------\n\nTITLE: Log Event Example in JSON\nDESCRIPTION: This JSON snippet shows an example representation of a log event in Vector. It includes fields such as custom, host, message, and timestamp. The timestamp field demonstrates a standard ISO 8601 format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/about/under-the-hood/architecture/data-model/log.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"log\": {\n    \"custom\": \"field\",\n    \"host\": \"my.host.com\",\n    \"message\": \"Hello world\",\n    \"timestamp\": \"2020-11-01T21:15:47+00:00\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating from json_parser transform to remap transform\nDESCRIPTION: This snippet demonstrates migrating from the deprecated `json_parser` transform to the new `remap` transform using VRL. The `remap` transform is more versatile and allows for more complex data transformations.  The example shows how to parse JSON from the `.message` field and merge it into the root of the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\n type = \"remap\"\n source = '''\n. = merge(., parse_json!(.message))\n'''\n```\n\n----------------------------------------\n\nTITLE: Simple VRL program (CoffeeScript)\nDESCRIPTION: This CoffeeScript snippet presents a simple VRL program that checks if a field named `flag` is equal to 42. If it is, it sets the field `field` to 32; otherwise, it sets it to 15. This example is used to illustrate how VRL programs are compiled into a tree of program nodes in the Tree Walking interpreter and how that contrasts with VM execution.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-15-vrl-vm-beta.md#_snippet_1\n\nLANGUAGE: CoffeeScript\nCODE:\n```\nif .flag == 42 {\n  .field = 32\n} else {\n  .field = 15\n}\n```\n\n----------------------------------------\n\nTITLE: Checking Licenses\nDESCRIPTION: This command ensures the `LICENSE-3rdparty.csv` file is up to date with the licenses of Vector's dependencies. It uses `cargo vdev check licenses` to perform this check. Maintaining an accurate license file is crucial for compliance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\ncargo vdev check licenses\n```\n\n----------------------------------------\n\nTITLE: Prometheus Metric Example\nDESCRIPTION: This Prometheus metric example shows the structure of the emitted metric with the `service` and `source_id` tags included. These tags provide context about the origin and type of data being processed by Vector, enabling users to understand data flow and volume.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2023-05-03-data-volume-metrics.md#_snippet_1\n\nLANGUAGE: prometheus\nCODE:\n```\nvector_component_sent_event_bytes_total{component_id=\"out\",component_kind=\"sink\",component_name=\"out\",component_type=\"console\"\n                                        ,host=\"machine\",service=\"potato\",source_id=\"stdin\"} 123\n```\n\n----------------------------------------\n\nTITLE: Reload Vector Configuration\nDESCRIPTION: Reloads the Vector configuration by sending a HUP signal to the Vector process inside the Docker container. This allows updating the configuration without restarting the container.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ndocker kill --signal=HUP vector\n```\n\n----------------------------------------\n\nTITLE: JSON Example Output (Mixed Types) After Remap Transform\nDESCRIPTION: This JSON object shows the output after the remap transform has been applied to the mixed-type input. Objects from the array are extracted as events, and the non-object (number) is coerced to an object with key 'message'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"localhost\", \"message\": \"foo\" }\n{ \"host\": \"localhost\", \"message\": \"bar\" }\n{ \"host\": \"localhost\", \"message\": \"1\" }\n```\n\n----------------------------------------\n\nTITLE: Start Vector (Linux)\nDESCRIPTION: This command starts the compiled Vector binary, specifying the path to the configuration file. Replace <target> with the appropriate target triple for your system (e.g., x86_64-apple-darwin).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntarget/<target>/release/vector --config config/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Building Source with Log Namespace in Rust\nDESCRIPTION: This code shows how to build a Vector source by retrieving and merging the globally configured log namespace with the source-specific setting. The `cx.log_namespace` function handles the merging, and the resulting `LogNamespace` enum is used for setting fields in the emitted log event. `SourceContext` parameter provides the global context.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nimpl SourceConfig for DnstapConfig {\n    async fn build(&self, cx: SourceContext) -> Result<super::Source> {\n        let log_namespace = cx.log_namespace(self.log_namespace);\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Vector with Nix\nDESCRIPTION: This command uninstalls the Vector package from your system using Nix. It removes Vector and its dependencies that were installed through Nix. This assumes Vector was installed via Nix.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/nix.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nnix-env --uninstall vector\n```\n\n----------------------------------------\n\nTITLE: List Vector Directories after Second Run\nDESCRIPTION: This snippet lists the contents of Vector's data directory after the second run of 'vector-fix'. The output shows the creation of 'http_tarpit_buffer_old' and 'http_tarpit_id' directories. This indicates that the previous 'http_tarpit_buffer' directory was archived.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 8\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:33 http_tarpit_buffer_old\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:33 http_tarpit_id\n```\n\n----------------------------------------\n\nTITLE: Migrate Splunk HEC token configuration\nDESCRIPTION: This code snippet demonstrates how to migrate the configuration of a Splunk HEC sink by renaming the deprecated `token` field to `default_token`. It shows the difference between the old and new configurations using a diff format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-28-0-19-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.splunk]\n   type = \"splunk_hec_logs\"\n   endpoint = \"http://splunk-endpoint\"\n-  token = \"MY-TOKEN\"\n+  default_token = \"MY-TOKEN\"\n   ...\n```\n\n----------------------------------------\n\nTITLE: Defining DecodingConfig struct in Rust\nDESCRIPTION: This struct defines the configuration for decoding, including optional framing and parsing configurations. It serves as a common configuration object for sources that expose framing/decoding functionality.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub struct DecodingConfig {\n    framing: Option<FramingConfig>,\n    decoding: Option<ParserConfig>,\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling Compression in vector.toml (Diff)\nDESCRIPTION: This code snippet demonstrates how to enable gzip compression for a sink in the `vector.toml` configuration file using the `compression` option.  It shows the required sink configuration and the addition of the `compression = \"gzip\"` line. The code uses diff format to highlight the changes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-06-add-compression-option-for-aws-sinks.md#_snippet_0\n\nLANGUAGE: Diff\nCODE:\n```\n  [sinks.little-pipe]\n    type = \"aws_cloudwatch_metrics\" # required\n    inputs = [\"big-firehose\"] # required\n    healthcheck = true # optional, default\n    namespace = \"service\" # required\n    region = \"us-east-1\" # required, required when endpoint = \"\"\n+   compression = \"gzip\" # optional, default none\n```\n\n----------------------------------------\n\nTITLE: Create CloudWatch Logs Subscription\nDESCRIPTION: Creates a CloudWatch Logs subscription filter to send logs to the specified Firehose delivery stream.  Environment variables LOG_GROUP, AWS_REGION, AWS_ACCOUNT_ID, and FIREHOSE_DELIVERY_STREAM must be set. The role-arn should be the ARN of the role created earlier.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ aws logs put-subscription-filter \\\n  --log-group-name ${LOG_GROUP} \\\n  --filter-name \"Destination\" \\\n  --filter-pattern \"\" \\\n  --destination-arn \"arn:aws:firehose:${AWS_REGION}:${AWS_ACCOUNT_ID}:deliverystream/${FIREHOSE_DELIVERY_STREAM}\" \\\n  --role-arn \"arn:aws:iam::${AWS_ACCOUNT_ID}:role/CWLtoKinesisFirehoseRole\n```\n\n----------------------------------------\n\nTITLE: Function Signature for insert_source_metadata in Rust\nDESCRIPTION: This code shows the function signature for `insert_source_metadata`. It takes the source name, a mutable reference to the log event, an optional legacy key with conflict resolution strategy, the metadata key as a `ValuePath`, and the value to insert.  This function handles insertion for both legacy and Vector namespaces.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\n    pub fn insert_source_metadata<'a>(\n        &self,\n        source_name: &'a str,\n        log: &mut LogEvent,\n        legacy_key: Option<LegacyKey<impl ValuePath<'a>>>,\n        metadata_key: impl ValuePath<'a>,\n        value: impl Into<Value>,\n    )\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration with only_fields for Remap Transform\nDESCRIPTION: This TOML configuration demonstrates using the `only_fields` option with the `unnest` function in the `remap` transform. It specifies that only the `host` field should be preserved from the original input event when creating new events from the `events` array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.remap]\ntype = \"remap\"\nsource = \"\"\"\n. = unnest(., \"events\", only_fields: [\"host\"])\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Kubernetes ClusterRole Definition for Vector\nDESCRIPTION: This YAML snippet defines a Kubernetes ClusterRole that grants Vector the necessary permissions to list and watch namespaces, nodes, and pods. It is required to enable Vector to annotate Kubernetes pod logs with node labels. This configuration is necessary for custom Vector installations to access Kubernetes API.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_16\n\nLANGUAGE: yaml\nCODE:\n```\n# Permissions to use Kubernetes API.\n# Requires that RBAC authorization is enabled.\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: vector\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n      - namespaces\n      - nodes\n      - pods\n    verbs:\n      - list\n      - watch\n```\n\n----------------------------------------\n\nTITLE: Implementing the run_inner Method for BasicSink in Rust\nDESCRIPTION: This code implements the `run_inner` method for the `BasicSink` struct.  This method consumes a stream of events, pulling each event from the stream and printing its debug representation to standard output. It continues until the input stream is exhausted, and then returns Ok(()).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nimpl BasicSink {\n    async fn run_inner(self: Box<Self>, mut input: BoxStream<'_, Event>) -> Result<(), ()> {\n        while let Some(event) = input.next().await {\n            println!(\"{:?}\", event);\n        }\n\n        Ok(())\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configure HTTP sink with bearer token from environment variable - TOML\nDESCRIPTION: This snippet shows how to configure an HTTP sink to use a bearer token fetched from an environment variable. This is considered a best practice for applications conforming to the 12 Factor App principles, as it avoids hardcoding secrets in the configuration file. It requires the `VECTOR_SINKS_HTTP_example_AUTH_TOKEN` environment variable to be set.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-20-add-bearer-auth-strategy.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.example]\n   type = \"http\"\n+  auth.strategy = \"bearer\"\n+  auth.token = \"${VECTOR_SINKS_HTTP_example_AUTH_TOKEN}\"\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON Output After VRL Transformation\nDESCRIPTION: This JSON snippet showcases the expected output after applying the VRL program to the example log data.  It demonstrates how the VRL program successfully extracts and transforms the data into structured fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"host\": \"5.86.210.12\",\n  \"internal_request\": true,\n  \"user\": \"zieme4647\",\n  \"timestamp\": \"2021-02-03T23:13:55Z\",\n  \"message\": \"GET /embrace/supply-chains/dynamic/vertical HTTP/1.0\",\n  \"method\": \"GET\",\n  \"path\": \"/embrace/supply-chains/dynamic/vertical\",\n  \"protocol\": \"HTTP/1.0\",\n  \"total_bytes\": 20574,\n  \"status\": 201\n}\n```\n\n----------------------------------------\n\nTITLE: Defining LogVec, MetricVec, and EventVec types in Rust\nDESCRIPTION: This snippet defines type aliases for `SmallVec` to hold `LogEvent` and `Metric` types, and an enum `EventVec` to represent either logs or metrics. This is done to optimize for the common case of single events while allowing for arrays.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub type LogVec = SmallVec<[LogEvent; 1]>;\npub type MetricVec = SmallVec<[Metric; 1]>;\n\npub enum EventVec {\n    Logs(LogVec),\n    Metrics(MetricVec),\n}\n```\n\n----------------------------------------\n\nTITLE: BatchConfig Struct Definition in Rust\nDESCRIPTION: Defines the `BatchConfig` struct in Rust for unifying batch size configurations. This struct includes options for maximum bytes, maximum events, maximum size (for backward compatibility), and a timeout in seconds. If both `max_size` and either of `max_bytes` or `max_events` are set, Vector will produce a configuration error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-06-12-2768-batch-and-buffer-rework.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nstruct BatchConfig {\n    max_bytes: Option<usize>,\n    max_events: Option<usize>,\n    max_size: Option<usize>,\n    timeout_secs: Option<u64>,\n}\n```\n\n----------------------------------------\n\nTITLE: Kubernetes Deployment Example with Annotation (YAML)\nDESCRIPTION: This YAML snippet demonstrates a Kubernetes Deployment with a Pod template that includes a specific annotation (`vector.dev/exclude: \"true\"`).  Vector can use this annotation to exclude logs from the Pod from collection. The annotation is applied at the `PodTemplateSpec` level.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_7\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  labels:\n    app: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n      annotations:\n        vector.dev/exclude: \"true\"\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:1.14.2\n          ports:\n            - containerPort: 80\n```\n\n----------------------------------------\n\nTITLE: Internal Metrics Example with `_default` Output\nDESCRIPTION: Illustrates the structure of the `component_sent_events_total` metric when the default output is used. The `output` tag is set to `_default` for events sent to the default output of a component (here, a `remap` transform).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-01-19-component-sent-metrics-output-tag.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"counter\":{\"value\":1.0},\"kind\":\"absolute\",\"name\":\"component_sent_events_total\",\"namespace\":\"vector\",\"tags\":{\"component_id\":\"foo\",\"component_kind\":\"transform\",\"component_name\":\"foo\",\"component_type\":\"remap\",\"output\":\"_default\"}}\n```\n\n----------------------------------------\n\nTITLE: Rust Function to LLVM IR\nDESCRIPTION: This Rust code defines a function `foo` that takes an integer `n` as input, multiplies it by 42, and returns the result. The `#[no_mangle]` attribute prevents name mangling, and `pub extern \"C\"` makes the function callable from C. The example will be compiled to LLVM IR using rustc.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-12-20-10517-llvm-backend-for-vrl.md#_snippet_0\n\nLANGUAGE: Rust\nCODE:\n```\n#[no_mangle]\npub extern \"C\" fn foo(n: i32) -> i32 {\n    n * 42\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB Network Bytes Metrics - Prometheus\nDESCRIPTION: This snippet captures the total network bytes transferred by MongoDB, broken down by state (in_bytes and out_bytes). This metric is important for understanding network bandwidth usage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_29\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_network_bytes_total The network data structure contains data regarding MongoDB’s network use\n# TYPE mongodb_network_bytes_total counter\nmongodb_network_bytes_total{state=\"in_bytes\"} 1981\nmongodb_network_bytes_total{state=\"out_bytes\"} 47869\n```\n\n----------------------------------------\n\nTITLE: Defining GraphQL Object and Subscription with async-graphql in Rust\nDESCRIPTION: This snippet shows how to define a GraphQL object type `Heartbeat` with a `utc` field and a `HealthSubscription` with a `heartbeat` subscription using the `async-graphql` crate in Rust. The `heartbeat` subscription returns a stream of `Heartbeat` objects at a specified interval.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3645-graphql-api.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n#[SimpleObject]\npub struct Heartbeat {  // <-- simple GraphQL object type to provide a `utc` field\n    utc: DateTime<Utc>,\n}\nimpl Heartbeat {\n    fn new() -> Self {\n        Heartbeat { utc: Utc::now() }\n    }\n}\n\n#[derive(Default)]\npub struct HealthSubscription; // <-- 'root' subscription type to merge\n\n#[Subscription]\nimpl HealthSubscription {\n    /// Heartbeat, containing the UTC timestamp of the last server-sent payload\n    async fn heartbeat(\n        &self,\n        #[arg(default = 1000, validator(IntRange(min = \"100\", max = \"60_000\")))] interval: i32,\n        // ^^ `interval` param -- defaults to 1,000ms; validates between 100ms - 60 seconds\n    ) -> impl Stream<Item = Heartbeat> {\n        // Return a stream of heartbeats\n        tokio::time::interval(Duration::from_millis(interval as u64)).map(|_| Heartbeat::new())\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example JSON data structure for VRL iteration\nDESCRIPTION: This JSON object serves as an example input data structure for demonstrating VRL iteration functionalities. It contains a mix of data types, including booleans, nested objects, strings, and arrays, which are used in subsequent VRL examples for key upcasing, value nullification, and element frequency counting.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-18-vrl-iteration-support.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"foo\": true,\n  \"bar\": { \"bar\": \"\" },\n  \"baz\": \"\",\n  \"qux\": [\"a\", \"b\", \"a\", \"c\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Map Values and Parse JSON (Coffee)\nDESCRIPTION: This code snippet uses `map_values` to iterate through the values in the event, extracts the log event details, merges it with the root object, removes the message field, and then parses the JSON from within the message field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_18\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_values(.) -> |value| {\n   event = del(value.log_events)\n   value |= event\n   message = del(.message)\n   . |= object!(parse_json!(message))\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Bidirectional Streaming with Tonic in Rust\nDESCRIPTION: Illustrates how to handle bidirectional streaming with a gRPC server using Tonic. The snippet calls the `bidirectional` method, receives a stream of messages, and prints each message. It depends on the `client` being an instance of `DummyClient` connected to the gRPC server.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_5\n\nLANGUAGE: Rust\nCODE:\n```\n    // calling rpc\n        let mut response = client.bidirectional(request).await?.into_inner();\n    // listening on the response stream\n        while let Some(res) = response.message().await? {\n            println!(\"NOTE = {:?}\", res);\n        }\n        Ok(())\n```\n\n----------------------------------------\n\nTITLE: Attach Policy to IAM Role\nDESCRIPTION: Attaches a policy to the 'CWLtoKinesisFirehoseRole' IAM role, granting it permission to publish to the specified Firehose stream. The AWS_REGION, AWS_ACCOUNT_ID, and FIREHOSE_DELIVERY_STREAM environment variables must be set.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ aws iam put-role-policy --role-name CWLtoKinesisFirehoseRole \\\n    --policy-name Permissions-Policy-For-CWL \\\n    --policy-document file://<( cat <<EOF\n{\n    \"Statement\":[\n      {\n        \"Effect\":\"Allow\",\n        \"Action\":[\"firehose:*\"],\n        \"Resource\":[\"arn:aws:firehose:${AWS_REGION}:${AWS_ACCOUNT_ID}:deliverystream/${FIREHOSE_DELIVERY_STREAM}\"]\n      }\n    ]\n}\nEOF\n)\n```\n\n----------------------------------------\n\nTITLE: Migrating `split` to `remap` in Vector (TOML)\nDESCRIPTION: This snippet demonstrates migrating a `split` transform configuration to use the `remap` transform. The original configuration used `field_names` and `types` settings to split a field and assign types, while the migrated configuration uses a VRL expression to split the field, assign values, and convert types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_20\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.split]\ntype = \"split\"\ninputs = [\"some_input\"]\nfield_names = [\"remote_addr\", \"user_id\", \"timestamp\", \"message\", \"status\", \"bytes\"]\ntypes.status = \"int\"\ntypes.bytes = \"int\"\n```\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.split]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\nvalues = split(.message)\n.remote_addr = values[0]\n.user_id = values[1]\n.timestamp = values[2]\n.message = values[3]\n.status = to_int!(values[4])\n.bytes = to_int!(values[5])\n'''\n```\n\n----------------------------------------\n\nTITLE: VRL: Raising Errors with `!`\nDESCRIPTION: This VRL snippet demonstrates how to raise an error and abort the program if `parse_common_log` fails. The `!` suffix on the function call indicates that the program should terminate upon error. Vector will continue onto the next event, but will also log an error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_12\n\nLANGUAGE: coffee\nCODE:\n```\n. = parse_common_log!(.log)\n.total_bytes = del(.size)\n```\n\n----------------------------------------\n\nTITLE: Adding encoding codec to AWS S3 sink configuration\nDESCRIPTION: This code snippet demonstrates how to add the `encoding.codec` option to an `aws_s3` sink configuration, which is now required in Vector 0.12. The codec specifies the format for encoding data, either `json` for structured data or `text` for plain text.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.backup]\n type = \"aws_s3\"\n inputs = [\"...\"]\n bucket = \"my-bucket\"\n compression = \"gzip\"\n region = \"us-east-1\"\n+encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Lua Shutdown Hook (Refactored)\nDESCRIPTION: This Lua code defines the shutdown hook after refactoring. It calls the `make_counter` function to emit the final counter value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_4\n\nLANGUAGE: lua\nCODE:\n```\nfunction (emit)\n    emit(make_counter(counter))\n  end\n```\n\n----------------------------------------\n\nTITLE: Using Vector with config globs\nDESCRIPTION: This command demonstrates how to start Vector using multiple configuration files specified by a glob pattern. Vector infers the format from the file extensions of the matching files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-11-25-json-yaml-config-formats.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvector --config /etc/vector/*\n```\n\n----------------------------------------\n\nTITLE: ConcurrencyLimited Event Emission in Rust\nDESCRIPTION: This snippet demonstrates how to emit an internal event when a request is limited due to the current concurrency limit. It includes logging a warning message with details about the concurrency and component, and incrementing a counter metric.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nimpl InternalEvent for ConcurrencyLimited {\n    fn emit_logs(&self) {\n        warn!(\n            message = \"Request limited due to current concurrency limit.\",\n            concurrency = %self.concurrency,\n            component = %self.component,\n            rate_limit_secs = 5,\n        );\n    }\n    fn emit_metrics(&self) {\n        counter!(\"concurrency_limit_reached_total\", 1,\n            \"component_kind\" => \"sink\",\n            \"component_type\" => self.component,\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuration for Vector Helm Chart\nDESCRIPTION: This YAML configuration file, 'values.yaml', is used to configure the Vector Helm chart.  It sets the 'role' to 'Agent', indicating that Vector will be deployed as an agent, and disables the service by setting 'service.enabled' to 'false'. This configuration likely minimizes the network exposure of the Vector agent.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/kubernetes/vector-agent/README.md#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\nrole: Agent\nservice:\n  enabled: false\n```\n\n----------------------------------------\n\nTITLE: Building and Testing a Specific Vector Component (console sink) in Rust\nDESCRIPTION: This command builds and runs tests only for the `console` sink, disabling default features to speed up compilation.  It targets a specific component feature. Dependencies must be defined for this specific component in Cargo.toml.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncargo test --lib --no-default-features --features sinks-console sinks::console\n```\n\n----------------------------------------\n\nTITLE: Starting Vector on Linux (systemctl)\nDESCRIPTION: Starts the Vector service using systemctl, the system and service manager on Linux systems. This assumes Vector was installed using a package manager like APT, dpkg, RPM, or YUM.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl start vector\n```\n\n----------------------------------------\n\nTITLE: Restart Vector Docker Container\nDESCRIPTION: Restarts the Vector Docker container named 'vector'. The `docker ps -aqf \"name=vector\"` command finds the container ID.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ndocker restart $(docker ps -aqf \"name=vector\")\n```\n\n----------------------------------------\n\nTITLE: Remap Transform for Stripping Fields in TOML\nDESCRIPTION: This TOML configuration uses a `remap` transform to strip specific fields (`.email`, `.passport_number`) from logs. This is useful for filtering sensitive information or reducing data volume. The input for the transform is `my-source-id`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_3\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.strip_personal_details]\ntype = \"remap\"\ninputs = [\"my-source-id\"]\nsource = '''\n  del(.email, .passport_number)\n'''\n```\n\n----------------------------------------\n\nTITLE: Installing Vector via MSI (Command Line)\nDESCRIPTION: This command installs Vector on Windows using the MSI installer in quiet mode. The `/i` flag specifies the MSI package, and the `/quiet` flag suppresses the GUI during installation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-11-21-windows-support.md#_snippet_0\n\nLANGUAGE: batch\nCODE:\n```\nmsiexec /i vector-x64.msi /quiet\n```\n\n----------------------------------------\n\nTITLE: Run external link checker in Shell\nDESCRIPTION: This shell command runs the htmltest link checker using the `.htmltest.external.yml` configuration, which sets `CheckExternal` to `true`.  This allows for ad hoc external link checks to detect broken external links.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nmake local-production-build\nmake run-external-link-checker\n```\n\n----------------------------------------\n\nTITLE: Diff of Lua Transform Search Directories Configuration\nDESCRIPTION: This diff snippet showcases the change required in the `vector.toml` file to specify a custom search directory for Lua scripts. It highlights the addition of the `search_dirs` option under a specific transform's configuration.  The '+' symbol indicates an addition to the file. The code shows the addition of `search_dirs = \"/my/other/dir\"`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-09-set-search_dirs-to-config-dirs-by-default.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n[transform.my-script]\n   type = \"lua\"\n+  search_dirs = \"/my/other/dir\"\n```\n\n----------------------------------------\n\nTITLE: Alternative: BytesSentHandle Implementation\nDESCRIPTION: This snippet demonstrates the simplest method of providing the registered handles, by just writing new internal event structures that are created through a struct method returning `Self`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_9\n\nLANGUAGE: rust\nCODE:\n```\npub struct BytesSentHandle { … }\n\nimpl BytesSentHandle {\n    fn new(protocol: &str, etc: &str) -> Self { … }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Console Sink with JSON Encoding (TOML)\nDESCRIPTION: This configuration snippet shows how to configure the `console` sink in Vector to output data in JSON format. It sets the `encoding.codec` option to \"json\", which ensures that the sink serializes events to JSON before writing them to standard output.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.print]\n  type = \"console\"\n  inputs = [\"source0\"]\n  target = \"stdout\"\n  encoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Configuring sourcetype in Splunk HEC sink with Vector TOML\nDESCRIPTION: This snippet shows how to explicitly configure the `sourcetype` field in the `splunk_hec` sink.  In Vector 0.11, this field is now explicit.  This option allows informing Splunk about the format of the `message` field. The example provided sets the sourcetype to syslog.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.reduce]\n  type = \"splunk_hec\"\n+  sourcetype = \"syslog\" # only set this if your `message` field is formatted as syslog\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output from Vector\nDESCRIPTION: This JSON snippet showcases the expected output of Vector after processing Syslog data. It includes example parsed syslog messages in JSON format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\"appname\":\"benefritz\",\"facility\":\"authpriv\",\"hostname\":\"some.de\",\"message\":\"We're gonna need a bigger boat\",\"msgid\":\"ID191\",\"procid\":9473,\"severity\":\"crit\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n{\"appname\":\"meln1ks\",\"facility\":\"local1\",\"hostname\":\"for.com\",\"message\":\"Take a breath, let it go, walk away\",\"msgid\":\"ID451\",\"procid\":484,\"severity\":\"debug\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n{\"appname\":\"shaneIxD\",\"facility\":\"uucp\",\"hostname\":\"random.com\",\"message\":\"A bug was encountered but not in Vector, which doesn't have bugs\",\"msgid\":\"ID428\",\"procid\":3093,\"severity\":\"alert\",\"timestamp\":\"2021-01-20T19:38:55.329Z\"}\n```\n\n----------------------------------------\n\nTITLE: Datadog TraceChunk Definition (protobuf)\nDESCRIPTION: Defines the structure of a TraceChunk in Datadog's newer trace format. A TraceChunk contains priority, origin, spans, tags, and a flag indicating whether the trace was dropped.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_3\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage TraceChunk {\n  // priority specifies sampling priority of the trace.\n  int32 priority = 1;\n  // origin specifies origin product (\"lambda\", \"rum\", etc.) of the trace.\n  string origin = 2;\n  // spans specifies list of containing spans.\n  repeated Span spans = 3;\n  // tags specifies tags common in all `spans`.\n  map<string, string> tags = 4;\n  // droppedTrace specifies whether the trace was dropped by samplers or not.\n  bool droppedTrace = 5;\n}\n```\n\n----------------------------------------\n\nTITLE: Download Vector Source (Latest, Linux)\nDESCRIPTION: This snippet creates a directory named 'vector', downloads the latest version of Vector's source code from GitHub as a tarball, and extracts it into the created directory.  It uses curl to download the tarball and tar to extract it, removing the top-level directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://api.github.com/repos/vectordotdev/vector/tarball/v{{< version >}} | \\\n  tar xzf - -C vector --strip-components=1\n```\n\n----------------------------------------\n\nTITLE: Enabling Adaptive Request Concurrency (ARC) in Vector TOML\nDESCRIPTION: This code snippet demonstrates how to enable the Adaptive Request Concurrency (ARC) feature for a sink in Vector's configuration file (TOML). It sets the `request.concurrency` option to \"adaptive\" and removes the `request.rate_limit_*` settings. This configuration allows Vector to dynamically adjust the concurrency based on downstream service responses.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-09-18-adaptive-concurrency.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my-sink]\ntype = \"...\" # any http-based sink\nrequest.concurrency = \"adaptive\"\n# and remove the request.rate_limit_* settings\n```\n\n----------------------------------------\n\nTITLE: Inserting Standard Vector Source Metadata in Rust\nDESCRIPTION: This code snippet shows how to insert both the ingest timestamp and the source type into the Vector namespace using the `insert_standard_vector_source_metadata` utility function. This simplifies the process of adding these common metadata fields. The `KafkaSourceConfig::NAME` provides the source name, and `Utc::now()` provides the timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\n\n  log_namespace.insert_standard_vector_source_metadata(\n      log,\n      KafkaSourceConfig::NAME,\n      Utc::now(),\n  );\n```\n\n----------------------------------------\n\nTITLE: Download Vector Source (Latest, Docker)\nDESCRIPTION: This snippet creates a directory named 'vector', downloads the latest version of Vector's source code from GitHub as a tarball, and extracts it into the created directory.  It uses curl to download the tarball and tar to extract it, removing the top-level directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://api.github.com/repos/vectordotdev/vector/tarball/v{{< version >}} | \\\n  tar xzf - -C vector --strip-components=1\n```\n\n----------------------------------------\n\nTITLE: Metrics Serialization (Old) JSON\nDESCRIPTION: This snippet shows the old JSON format for a counter metric in Vector. The 'type' field is nested within the 'value' object, which specifies the metric type (e.g., 'counter'). The 'value' field within 'value' provides the metric's numerical value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-07-use-external-tagging-for-metrics-serialization.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"login.count\",\n  \"timestamp\": \"2019-11-01T21:15:47+00:00\",\n  \"kind\": \"absolute\",\n  \"tags\": {\n    \"host\": \"my.host.com\"\n  },\n  \"value\": {\n    \"type\": \"counter\", // <-- metric type\n    \"value\": 24.2\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Socket Sink with Length-Delimited JSON\nDESCRIPTION: This code snippet shows how to configure a `socket` sink to send length-delimited JSON-encoded messages.  The `framing.method` parameter is set to \"length_delimited\" and the `encoding.codec` is set to \"json\". The address and mode parameters configure the network connection.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-sink-codecs.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.socket]\ntype = \"socket\"\naddress = \"92.12.333.224:5000\"\nmode = \"tcp\"\nframing.method = \"length_delimited\"\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Install wasm-pack using cargo\nDESCRIPTION: This command installs wasm-pack, a tool used to compile Rust code into WebAssembly. The --locked flag ensures that the exact versions specified in the Cargo.lock file are used, and --version specifies a specific version of wasm-pack.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncargo install --locked --version 0.13.0 wasm-pack\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Log Records Metrics - Prometheus\nDESCRIPTION: This snippet shows the number of log records in WiredTiger, split by compression type (compressed/uncompressed).  It helps in understanding the volume of log data being generated by MongoDB's storage engine.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_23\n\nLANGUAGE: Prometheus\nCODE:\n```\n# TYPE mongodb_mongod_wiredtiger_log_records_total counter\nmongodb_mongod_wiredtiger_log_records_total{type=\"compressed\"} 13\nmongodb_mongod_wiredtiger_log_records_total{type=\"uncompressed\"} 16\n```\n\n----------------------------------------\n\nTITLE: Strftime Specifiers\nDESCRIPTION: This shows the shortcut for injecting strftime specifiers for date and time formatting. These specifiers are evaluated against the event's timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\noption = \"year=%Y/month=%m/day=%d/\"\n```\n\n----------------------------------------\n\nTITLE: Invalid Function Argument Error Output - Text\nDESCRIPTION: This is the error output produced by the compiler when encountering an invalid function argument. It highlights the unknown keyword and the resulting invalid argument type due to the function call resolving to null.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\nerror[E108]: unknown function argument keyword\n  ┌─ :1:17\n  │\n1 │ bar = to_string(invalid: 12)\n  │       --------- ^^^^^^^ unknown keyword\n  │       │\n  │       this function accepts the following keywords: \"value\"\n\nerror[E110]: invalid argument type\n  ┌─ :1:8\n  │\n1 │ upcase(bar)\n  │        ^^^\n  │        │\n  │        this expression resolves to the exact type \"null\"\n  │        but the parameter \"value\" expects the exact type \"string\"\n```\n\n----------------------------------------\n\nTITLE: Download Vector Source (Master, Linux)\nDESCRIPTION: This snippet creates a directory named 'vector', downloads the master branch of Vector's source code from GitHub as a tarball, and extracts it into the created directory. It uses curl to download the tarball and tar to extract it, removing the top-level directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://github.com/vectordotdev/vector/archive/master.tar.gz | \\\n  tar xzf - -C vector --strip-components=1\n```\n\n----------------------------------------\n\nTITLE: GeoIP Enrichment Table Migration YAML\nDESCRIPTION: This YAML configuration demonstrates the migration to GeoIP enrichment tables. It defines an enrichment table named `geoip_table` with the database path and type. It also shows the `remap` transform to apply the enrichment and VRL for accessing the table.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_5\n\nLANGUAGE: yaml\nCODE:\n```\nenrichment_tables:\n  geoip_table:\n    path: /etc/vector/GeoLite2-City.mmdb\n    type: geoip\n\ntransforms:\n  geoip:\n    type: remap\n    inputs:\n      - with_ip_info\n    source: |-\n      .geoip = get_enrichment_table_record!(\"geoip_table\",\n        {\n          \"ip\": .ip_address\n        }\n```\n\n----------------------------------------\n\nTITLE: Download Vector Source (Master, Docker)\nDESCRIPTION: This snippet creates a directory named 'vector', downloads the master branch of Vector's source code from GitHub as a tarball, and extracts it into the created directory. It uses curl to download the tarball and tar to extract it, removing the top-level directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://github.com/vectordotdev/vector/archive/master.tar.gz | \\\n  tar xzf - -C vector --strip-components=1\n```\n\n----------------------------------------\n\nTITLE: Re-introduce only_fields Functionality VRL\nDESCRIPTION: This VRL snippet mimics the `only_fields` functionality using iteration. It iterates through the keys of the current object using `for_each` and removes any keys that are not present in the `only_fields` array. This effectively filters the object to only include the specified fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_21\n\nLANGUAGE: coffee\nCODE:\n```\nonly_fields = [\"some\", \"set\", \"of\", \"fields\"]\nfor_each(.) -> |key, _| {\n  if !includes(only_fields, key) {\n    . = remove(., [key])\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Function Signature for insert_vector_metadata in Rust\nDESCRIPTION: This shows the function signature for `insert_vector_metadata`.  It takes a mutable reference to the `LogEvent`, legacy and metadata keys defined as ValuePaths, and a value to insert. The function inserts the value into the log event at the specified paths depending on whether namespacing is enabled.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n    pub fn insert_vector_metadata<'a>(\n        &self,\n        log: &mut LogEvent,\n        legacy_key: impl ValuePath<'a>,\n        metadata_key: impl ValuePath<'a>,\n        value: impl Into<Value>,\n    )\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Record Moves Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total number of document moves within the on-disk representation of the MongoDB dataset. This occurs when documents increase in size beyond their allocated record size.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_15\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_record_moves_total moves reports the total number of times documents move within the on-disk representation of the MongoDB data set. Documents move as a result of operations that increase the size of the document beyond their allocated record size\n# TYPE mongodb_mongod_metrics_record_moves_total counter\nmongodb_mongod_metrics_record_moves_total 0\n```\n\n----------------------------------------\n\nTITLE: Example Bash Command to Run the GDPR pipeline\nDESCRIPTION: This bash command pipes JSON log data into the Vector pipeline defined in `test.toml`. It uses `cargo run` to execute Vector with the specified configuration and input data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/managing-schemas.md#_snippet_7\n\nLANGUAGE: Bash\nCODE:\n```\n$ cat <<-EOF | cargo run -- --config test.toml\n{ \"id\": \"user1\", \"gdpr\": false, \"email\": \"us-user1@datadoghq.com\" }\n{ \"id\": \"user2\", \"gdpr\": false, \"email\": \"us-user2@datadoghq.com\" }\n{ \"id\": \"user3\", \"gdpr\": true, \"email\": \"eu-user3@datadoghq.com\" }\nEOF\n```\n\n----------------------------------------\n\nTITLE: Configure Lua Transform Search Directories in TOML\nDESCRIPTION: This TOML snippet shows how to configure the `search_dirs` option for a Lua transform in Vector if your Lua scripts are not in the same directory as your Vector configuration file. The `search_dirs` parameter specifies the directories where Vector will search for Lua scripts.  This example adds a line to specify a directory `/my/other/dir` for the Lua transform named `my-script`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-09-set-search_dirs-to-config-dirs-by-default.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transform.my-script]\n   type = \"lua\"\n+  search_dirs = \"/my/other/dir\"\n```\n\n----------------------------------------\n\nTITLE: VRL Assertions Example (Coffee)\nDESCRIPTION: This snippet demonstrates how to use VRL assertions (`assert` and `assert_eq`) with named and positional arguments to verify transform outputs.  It also emphasizes making assertions infallible using the `!` syntax.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\n# Named argument\nassert!(1 == 2, message: \"the rules of arithmetic have been violated\")\nassert_eq!(1, 2, message: \"the rules of arithmetic have been violated\")\n\n# Positional arguments are also valid\nassert!(1 == 2, \"the rules of arithmetic have been violated\")\nassert_eq!(1, 2, \"the rules of arithmetic have been violated\")\n```\n\n----------------------------------------\n\nTITLE: GreptimeDB Logs Sink YAML Configuration\nDESCRIPTION: This YAML configuration example demonstrates how to configure the `greptimedb_logs` sink with the `extra_headers` option. It specifies the sink type, inputs, endpoint, table, database name, and custom headers. The `x-source` header is set to \"vector\" as an example.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/changelog.d/22651_greptimedb_logs_headers.breaking.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsinks:\n  greptime_logs:\n    type: greptimedb_logs\n    inputs: [\"my_source_id\"]\n    endpoint: \"http://localhost:4000\"\n    table: \"demo_logs\"\n    dbname: \"public\"\n    extra_headers:\n      x-source: vector\n```\n\n----------------------------------------\n\nTITLE: Example of disabling components using null in YAML\nDESCRIPTION: This YAML example demonstrates how to disable specific Vector components by setting their configuration to `null`.  This is an alternative approach where users can selectively disable default components if they choose to use the generic sources, transforms, and sinks keys.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-06-29-7709-helm-update-vector-config-pattern.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  kubernetes_logs: null\n  internal_metrics: null\n  host_metrics: null\nsinks:\n  vector_sink: null\n  prometheus_sink: null\n```\n\n----------------------------------------\n\nTITLE: Build Request Implementation - Rust\nDESCRIPTION: Implements the `build_request` function for `BasicRequestBuilder`, constructing the final `BasicRequest` object from the encoded payload and metadata. The resulting request is then passed to a Tower service for actual data transmission.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_12\n\nLANGUAGE: rust\nCODE:\n```\n    fn build_request(\n        &self,\n        metadata: Self::Metadata,\n        request_metadata: RequestMetadata,\n        payload: EncodeResult<Self::Payload>,\n    ) -> Self::Request {\n        BasicRequest {\n            finalizers: metadata,\n            payload: payload.into_payload(),\n            metadata: request_metadata,\n        }\n    }\n```\n\n----------------------------------------\n\nTITLE: Defining SerializerConfig Trait in Rust\nDESCRIPTION: This code snippet defines the `SerializerConfig` trait in Rust. It includes a `build` method that creates a serializer from the configuration and can fail if the configuration is invalid. The trait requires implementors to derive Debug, DynClone, Send, and Sync.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-8621-framing-and-codecs-sinks.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub trait SerializerConfig: Debug + DynClone + Send + Sync {\n    /// Builds a serializer from this configuration.\n    ///\n    /// Fails if the configuration is invalid.\n    fn build(&self) -> crate::Result<BoxedSerializer>;\n}\n```\n\n----------------------------------------\n\nTITLE: Unstructured Log Data Event Example\nDESCRIPTION: This example showcases the structure of an unstructured log event for the `gcp_chronicle_unstructured` sink. It includes the raw log text and a timestamp in epoch microseconds. The `log_text` field contains the plain text log message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-05-17-11532-chronicle-sink.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"log_text\": \"26-Feb-2019 13:35:02.187 client 10.120.20.32#4238: query: altostrat.com IN A + (203.0.113.102)\",\n  \"ts_epoch_microseconds\": 1551188102187000\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Output of `parse_regex` with `numeric_groups`\nDESCRIPTION: This JSON represents the output of the `parse_regex` function in VRL version 0.13 and later when the `numeric_groups` parameter is set to `true`.  It includes the full match at index \"0\", numeric capture groups at index \"1\", and the named capture group \"number\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{ \"0\": \"hello 123 world\", \"1\": \"123\", \"number\": \"123\" }\n```\n\n----------------------------------------\n\nTITLE: Parse Timestamp on Cloudtrail Records VRL\nDESCRIPTION: This VRL snippet iterates through an array of Cloudtrail records and parses the timestamp field (`eventTime`) using `parse_timestamp`. It handles potential parsing errors by using `now()` as a fallback value. It demonstrates how to process an array of objects to parse time based data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_8\n\nLANGUAGE: coffee\nCODE:\n```\n. = [{ ... }, { ... }]\n. = map_values(.) -> |value| {\n  value.timestamp = parse_timestamp(value.eventTime, \"%Y-%m-%dT%H:%M:%SZ\") ?? now()\n  value\n}\n```\n\n----------------------------------------\n\nTITLE: Correct Logging Style Example (Rust)\nDESCRIPTION: This snippet demonstrates the *correct* way to use the Tracing crate for logging in Vector. The message is capitalized, ends with a period, uses `error` instead of `err`, and uses key-value style.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\nwarn!(message = \"Failed to merge value.\", %error);\n```\n\n----------------------------------------\n\nTITLE: HTTP Source Metadata Example (JSON)\nDESCRIPTION: This is an example of the metadata associated with an HTTP source event. It includes information about the HTTP path, headers, query parameters, and Vector's internal source type and ingest timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"http\": {\n    \"path\": \"/foo/bar\",\n    // headers and query params were previously placed directly on the root. This needs to be nested to avoid potential naming conflicts.\n    \"headers\": {\n      \"Content-Type\": \"application/json\"\n    },\n    \"query_params\": {\n      \"page\": 14,\n      \"size\": 3\n    }\n  },\n  \"vector\": {\n    \"source_type\": \"http\",\n    \"ingest_timestamp\": \"2020-10-15T11:01:46.499555308Z\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of Vector Component Errors Metric Output\nDESCRIPTION: This snippet demonstrates an error metric generated by Vector when the downstream component fails due to GZIP compression. It shows the `component_errors_total` metric and associated tags like `error_type`, `component_id`, and `component_type`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_18\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"component_errors_total\",\n  \"namespace\": \"vector\",\n  \"tags\": {\n    \"component_id\": \"sink_0\",\n    \"component_kind\": \"sink\",\n    \"component_type\": \"http\",\n    \"error_type\": \"request_failed\",\n    \"host\": \"MY_HOST\",\n    \"stage\": \"sending\"\n  },\n  \"timestamp\": \"2025-02-12T16:09:51.122851Z\",\n  \"kind\": \"absolute\",\n  \"counter\": {\n    \"value\": 2.0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Extending FunctionCall struct in AST - Rust\nDESCRIPTION: This code snippet demonstrates the modification of the `FunctionCall` struct in the abstract syntax tree (AST) to include an optional closure. It adds a `closure` field of type `Option<FunctionClosure>` to the `FunctionCall` struct and defines the `FunctionClosure` struct itself.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_33\n\nLANGUAGE: rust\nCODE:\n```\npub struct FunctionCall {\n    pub ident: Ident,\n    pub abort_on_error: bool,\n    pub arguments: Vec<FunctionArgument>,\n    pub closure: Option<FunctionClosure>,\n}\n\npub struct FunctionClosure {\n    pub variables: Vec<Ident>,\n    pub block: Block,\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Datadog API Key (Legacy)\nDESCRIPTION: This code snippet shows the existing functionality of setting the Datadog API key using the `set_metadata_field` function. It will continue to work for backward compatibility.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-06-07-vrl-metadata-and-secrets.md#_snippet_0\n\nLANGUAGE: coffeescript\nCODE:\n```\nset_metadata_field(\"datadog_api_key\", \"my secret key\")\n```\n\n----------------------------------------\n\nTITLE: Installing Vector with Nix\nDESCRIPTION: This command installs Vector using the Nix package manager. It downloads the Nix packages repository and installs the Vector package. This command requires Nix to be installed and configured.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/nix.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nnix-env --install \\\n  --file https://github.com/NixOS/nixpkgs/archive/master.tar.gz \\\n  --attr vector\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration for Log Parsing\nDESCRIPTION: This YAML configuration for Vector demonstrates parsing an Apache log without VRL. It uses `regex_parser`, `remove_fields`, and `coercer` transforms. It removes the time and log fields, and coerces the timestamp, status, and bytes_out fields to the correct types. The expected input is the Docker log, and the output is the parsed log with the correct types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_1\n\nLANGUAGE: YAML\nCODE:\n```\n# ... sources ...\n\ntransforms:\n  parse_syslog:\n    type: regex_parser\n    inputs:\n      - parse_docker\n    patterns:\n      - '^(?P<host>\\S+) (?P<client>\\S+) (?P<user>\\S+) \\[(?<timestamp>[\\w:/]+\\s[+\\-]\\d{4})\\] \"(?<method>\\S+) (?<resource>.+?) (?<protocol>\\S+)\" (?<status>\\d{3}) (?<bytes_out>\\S+)$'\n    field: log\n\n  remove_log:\n    type: remove_fields\n    inputs:\n      - parse_syslog\n    fields:\n      - time\n      - log\n\n  coerce_fields:\n    type: coercer\n    inputs:\n      - remove_log\n    types:\n      timestamp: timestamp\n      status: int\n      bytes_out: int\n\n# ... sinks ...\n```\n\n----------------------------------------\n\nTITLE: Handling Requests and Batch Status with Ack IDs in Rust\nDESCRIPTION: This snippet demonstrates how to handle incoming requests, associate data with assigned `ackId`s, and receive status updates using Vector's `BatchNotifier`/`BatchReceiver` system. It showcases the integration of end-to-end acknowledgements for data delivery confirmation. The code uses asynchronous functions and pattern matching for handling different batch statuses.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-9465-splunk-hec-indexer-acknowledgements.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nasync fn handle_request(acknowledgements: bool, events: Vec<Events>, out: Pipeline, ack_id: usize...) {\n        let receiver = acknowledgements.then(|| {\n                let (batch, receiver) = BatchNotifier::new_with_receiver();\n                for event in &mut events {\n                    event.add_batch_notifier(Arc::clone(&batch));\n                }\n                receiver\n            });\n\n            out.send_all(&mut futures::stream::iter(events).map(Ok))\n                ...\n                .and_then(|_| handle_batch_status(ack_id, receiver))\n                .await\n    }\n    ...\n    async fn handle_batch_status(ack_id, receiver) {\n        match receiver.await {\n            BatchStatus::Delivered => // update ackId -> true,\n            BatchStatus::Errored => // leave ackId -> false,\n            BatchStatus::Rejected => // leave ackId -> false,\n        }\n    }\n```\n\n----------------------------------------\n\nTITLE: Unnest Log Events (Coffee)\nDESCRIPTION: This step uses the `unnest` function to extract individual log events from the `log_events` array within the `parsed` variable, creating a separate event for each log event. Each new event will contain the data from a single element of the log_events array, with the other fields copied to the new event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_17\n\nLANGUAGE: coffee\nCODE:\n```\n. = unnest(parsed.log_events)\n```\n\n----------------------------------------\n\nTITLE: Adding Helm Chart Repository\nDESCRIPTION: This snippet adds the Vector Helm chart repository and updates the Helm repositories to ensure the latest chart information is available.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nhelm repo add vector https://charts.vector.dev\nhelm repo update\n```\n\n----------------------------------------\n\nTITLE: Enabling GraphQL API in Vector Configuration (TOML)\nDESCRIPTION: This snippet shows how to enable the GraphQL API in Vector by adding an `api` section to the Vector configuration file. It sets `enabled` to `true` and optionally specifies the `address` for the API endpoint. The default address is used if `address` isn't set.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-23-graphql-api.md#_snippet_0\n\nLANGUAGE: TOML\nCODE:\n```\n[api]\nenabled = true\naddress = \"127.0.0.1:8686\" # optional. Change IP/port if required\n```\n\n----------------------------------------\n\nTITLE: Start Vector (Powershell)\nDESCRIPTION: Starts the Vector process on Windows using the specified configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_9\n\nLANGUAGE: powershell\nCODE:\n```\n.\\bin\\vector --config config\\vector.toml\n```\n\n----------------------------------------\n\nTITLE: String Interpolation Type Requirement (Coffee)\nDESCRIPTION: This snippet illustrates the requirement that only variables resolving to a string type can be directly interpolated. Other types need to be explicitly converted to strings using functions like `to_string()`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\nnumber = 1\n\"{{ number }}\"\n```\n\nLANGUAGE: coffee\nCODE:\n```\nnumber = to_string(1)\n\"{{ number }}\"\n```\n\n----------------------------------------\n\nTITLE: JSON Configuration\nDESCRIPTION: An example of the JSON configuration outputed. Includes type, flavor and message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_11\n\nLANGUAGE: jsonc\nCODE:\n```\n{\"message\":\"{ \\\"type\\\": \\\"icecream\\\", \\\"flavor\\\": \\\"strawberry\\\" } }\"\n```\n\n----------------------------------------\n\nTITLE: Vector tap Output with New Source\nDESCRIPTION: Demonstrates the output of `vector tap` after adding the new `demo_logs` source.  Shows that `tap` automatically includes events from the newly added component.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_9\n\nLANGUAGE: console\nCODE:\n```\n...\n{\"message\":\"new test2\",\"source_type\":\"demo_logs\",\"timestamp\":\"2022-02-22T21:07:50.106793803Z\"}\n{\"message\":\"test1\",\"source_type\":\"demo_logs\",\"timestamp\":\"2022-02-22T21:07:50.490873070Z\"}\n{\"message\":\"new test1\",\"source_type\":\"demo_logs\",\"timestamp\":\"2022-02-22T21:07:51.106744949Z\"}\n...\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration for the Basic Sink (YAML)\nDESCRIPTION: This YAML configuration file sets up a Vector pipeline that connects a `stdin` source to the `basic` sink.  This configuration allows you to type input into the console, which will then be processed by Vector and output by the `basic` sink to standard output.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_12\n\nLANGUAGE: yml\nCODE:\n```\nsources:\n  stdin:\n    type: stdin\n\nsinks:\n  basic:\n    type: basic\n    inputs:\n      - stdin\n```\n\n----------------------------------------\n\nTITLE: Task Structure - Rust\nDESCRIPTION: Defines the structure of a `Task`, which encapsulates a component's execution and tracks internal metrics. The `id` field is changed to `ComponentId` to include pipeline information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\npub struct Task {\n    #[pin]\n    inner: BoxFuture<'static, Result<TaskOutput, ()>>,\n    id: ComponentId,\n    typetag: String,\n}\n\nimpl Task {\n    pub fn new<S, Fut>(id: ComponentId, typetag: S, inner: Fut) -> Self\n    where\n        S: Into<String>,\n        Fut: Future<Output = Result<TaskOutput, ()>> + Send + 'static,\n    {\n        Self {\n            inner: inner.boxed(),\n            id,\n            typetag: typetag.into(),\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of Vector HTTP Client Responses Metric Output\nDESCRIPTION: This snippet showcases a metric that indicates HTTP client responses with a status code of 429. This is emitted when a 429 response is received from the server.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_23\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"http_client_responses_total\",\n  \"namespace\": \"vector\",\n  \"tags\": {\n    \"component_id\": \"sink_0\",\n    \"component_kind\": \"sink\",\n    \"component_type\": \"http\",\n    \"host\": \"MY_HOST\",\n    \"status\": \"429\"\n  },\n  \"timestamp\": \"2025-02-12T19:15:16.377709Z\",\n  \"kind\": \"absolute\",\n  \"counter\": {\n    \"value\": 41.0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Event 2 - JSON\nDESCRIPTION: This JSON represents the second event used in the reduce transform example. Similar to Event 1, it includes fields such as 'id', 'an_array', and a nested 'message' object. This event is combined with Event 1 to illustrate the updated aggregation behavior of nested fields in Vector 0.40.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": 777,\n  \"an_array\": [\n    {\n      \"inner\": 2\n    }\n  ],\n  \"message\": {\n    \"a\": {\n      \"b\": [3, 4],\n      \"num\": 2\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Parser trait in Rust\nDESCRIPTION: This trait defines the interface for parsers, requiring a `parse` method that takes a `Bytes` object and returns a `SmallVec<[Event; 1]>`. This trait is responsible for converting byte frames into structured events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\npub trait Parser: DynClone + Send + Sync {\n    fn parse(&self, bytes: Bytes) -> crate::Result<SmallVec<[Event; 1]>>;\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating GeoIP Transform Configuration YAML\nDESCRIPTION: This snippet shows how to migrate from the deprecated `geoip` transform to a `remap` transform using VRL and enrichment tables. It replaces the `geoip` transform with a combination of an enrichment table and a `remap` transform that uses the `get_enrichment_table_record!` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-11-07-0-26-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  geoip:\n    type: geoip\n    inputs:\n      - with_ip_info\n    database: /etc/vector/GeoLite2-City.mmdb\n    source: ip_address\n    target: geoip\n```\n\n----------------------------------------\n\nTITLE: Shell command to render Vector graph with Graphviz\nDESCRIPTION: This shell command uses the `vector graph` subcommand to generate the DOT representation of the Vector configuration and pipes it to Graphviz's `dot` command for rendering.  It requires Graphviz to be installed and available in the system's PATH. The output is saved as a PNG image.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-vector-graph.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nvector graph --config vector.toml | dot -Tpng > graph.png\n```\n\n----------------------------------------\n\nTITLE: Creating and Listing Data Directories (Shell)\nDESCRIPTION: This shell snippet first executes a script to create clean data directories. It then lists the contents of the `/tmp/vector/github-12069` directory to verify that the directories have been created and are initially empty.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069\ntotal 0\n```\n\n----------------------------------------\n\nTITLE: Splunk HEC Example Response (JSONC)\nDESCRIPTION: This is an example response from a local Splunk instance when indexer acknowledgement is enabled. It includes the 'text', 'code', and 'ackId' fields. The 'ackId' is a unique identifier for the request, allowing the user to query Splunk for its status.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-9465-splunk-hec-indexer-acknowledgements.md#_snippet_0\n\nLANGUAGE: JSONC\nCODE:\n```\n// Example response from local Splunk 7.3.2\n{\n   \"text\": \"Success\",\n   \"code\": 0,\n   \"ackId\": 10\n}\n```\n\n----------------------------------------\n\nTITLE: Running Kubernetes E2E tests (Shell)\nDESCRIPTION: Runs end-to-end tests for Kubernetes integration. Requires setting `CONTAINER_IMAGE_REPO` to the Docker image repository name. Additional parameters like `QUICK_BUILD`, `USE_MINIKUBE_CACHE`, `CONTAINER_IMAGE`, `SKIP_CONTAINER_IMAGE_PUBLISHING`, and `SCOPE` can be used to adjust the test behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_19\n\nLANGUAGE: shell\nCODE:\n```\nCONTAINER_IMAGE_REPO=<your name>/vector-test make test-e2e-kubernetes\n```\n\n----------------------------------------\n\nTITLE: IfStatement Expression resolves_to Implementation\nDESCRIPTION: Demonstrates how the `resolves_to` function is implemented for the `IfStatement` expression. It combines the resolve kinds of the true and false expressions to determine the overall resolve kind of the `IfStatement`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nimpl Expression for IfStatement {\n    fn resolves_to(&self) -> ResolveKind {\n        let true_resolves = self.true_expression.resolves_to();\n        let false_resolves = self.false_expression.resolves_to();\n\n        // return the combined set of true and false resolves.\n    }\n\n    // …\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Server-Side Streaming with Tonic in Rust\nDESCRIPTION: Demonstrates how to receive a server-side stream from a gRPC server using Tonic. The snippet calls the `receive_stream` method on the client and prints the received message. It assumes the `client` is an instance of `DummyClient` connected to the server.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_4\n\nLANGUAGE: Rust\nCODE:\n```\n    // sending stream\n        let response = client.receive_stream(request).await?.into_inner();\n        println!(\"RESPONSE=\\n{}\", response.message);\n```\n\n----------------------------------------\n\nTITLE: Original No-op Function Implementation - Rust\nDESCRIPTION: This is the original, generic implementation of the `noop` function.  It creates a no-op function call with a fixed name and type. The updated version will allow specifying the function name and return type, to mimic the original function call with invalid arguments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nimpl FunctionCall {\n    pub fn noop() -> Self {\n        let expr = Box::new(Noop) as _;\n\n        Self {\n            ident: \"noop\",\n            expr,\n            // ...\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Memory Enrichment Table as a Sink (YAML)\nDESCRIPTION: This YAML configuration shows how to use the `memory_enrichment_table` as a sink in Vector. It defines the sink with its type, inputs, TTL, and flush interval.  It receives data from another source or transform. Requires Vector to be installed and configured.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-memory_enrichment_table.md#_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nmemory_table_sink:\n    inputs: [ \"another_source_or_transform\" ]\n    type: memory_enrichment_table\n    ttl: 60\n    flush_interval: 5\n```\n\n----------------------------------------\n\nTITLE: Lua Aggregator Transform Configuration (Module)\nDESCRIPTION: This TOML configuration shows how to load a Lua module named 'aggregator' using the 'require' function. The 'source' is set to 'require(\\'aggregator\\')', indicating that the module's code will be executed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.aggregator]\ntype = \"lua\"\nversion = \"2\"\ninputs = [] # add IDs of the input components here\nhooks.init = \"init\"\nhooks.process = \"process\"\nhooks.shutdown = \"shutdown\"\ntimers = [{interval_seconds = 5, handler = \"timer_handler\"}]\nsource = \"require('aggregator')\"\n```\n\n----------------------------------------\n\nTITLE: Validator Trait in Rust\nDESCRIPTION: This Rust code defines the `Validator` trait.  Implementations of this trait are used to validate Vector components. The `check_validation` method processes inputs, outputs, and telemetry events to generate validation results.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\npub trait Validator {\n    /// Gets the unique name of this validator.\n    fn name(&self) -> &'static str;\n\n    /// Processes the given set of inputs/outputs, generating the validation results.\n    fn check_validation(\n        &self,\n        component_type: ComponentType,\n        expectation: TestCaseExpectation,\n        inputs: &[TestEvent],\n        outputs: &[Event],\n        telemetry_events: &[Event],\n    ) -> Result<Vec<String>, Vec<String>>;\n\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Kafka Sink for Metrics in Vector TOML\nDESCRIPTION: This configuration snippet shows how to configure the `kafka` sink in Vector to send metrics data. It defines a `host_metrics` source and a `kafka` sink that ingests data from the `host_metrics` source. The `encoding.codec` is set to \"json\" to encode the metrics events as JSON.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-01-10-kafka-sink-metrics.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.host_metrics]\ntype = \"host_metrics\"\n\n[sinks.kafka]\ntype = \"kafka\"\ninputs = [\"host_metrics\"]\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Accessing Vector Logs with internal_logs source\nDESCRIPTION: This configuration shows how to access Vector's logs using the `internal_logs` source and pipe them to the console as plain text. It defines a source named `vector_logs` of type `internal_logs` and a sink named `console` that takes the logs as input and encodes them as text.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/monitoring.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.vector_logs]\ntype = \"internal_logs\"\n\n[sinks.console]\ntype = \"console\"\ninputs = [\"vector_logs\"]\nencoding.codec = \"text\"\n```\n\n----------------------------------------\n\nTITLE: Vector Log Example Showing Retry After Response\nDESCRIPTION: This log entry from Vector indicates that it is retrying a request after receiving a response. It includes information about the component, request, and the reason for the retry (too many requests).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_22\n\nLANGUAGE: text\nCODE:\n```\n2025-02-12T19:10:54.562556Z  WARN sink{component_kind=\"sink\" component_id=sink_0 component_type=http}:request{request_id=19}: vector::sinks::util::retries: Retrying after response. reason=too many requests internal_log_rate_limit=true\n```\n\n----------------------------------------\n\nTITLE: Configuring Demo Logs Source\nDESCRIPTION: Configures a `demo_logs` source for testing. The source generates a predefined list of log messages. The `format` is set to `shuffle`, which means logs are output in random order. This configuration creates the logs that will be observed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.in]\ntype = \"demo_logs\"\nformat = \"shuffle\"\nlines = [\n  \"test1\",\n  \"test2\",\n]\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB GetLastError WTime Number Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus gauge metric representing the total number of getLastError operations with a specified write concern (w > 1) waiting for replica set acknowledgment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_10\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_get_last_error_wtime_num_total num reports the total number of getLastError operations with a specified write concern (i.e. w) that wait for one or more members of a replica set to acknowledge the write operation (i.e. a w value greater than 1.)\n# TYPE mongodb_mongod_metrics_get_last_error_wtime_num_total gauge\nmongodb_mongod_metrics_get_last_error_wtime_num_total 0\n```\n\n----------------------------------------\n\nTITLE: Enabling Gzip Compression for Elasticsearch Sink in Vector (toml)\nDESCRIPTION: This code snippet demonstrates how to explicitly enable Gzip compression for the `elasticsearch` sink in your Vector configuration file (vector.toml). This is necessary after upgrading to Vector 0.9.0, as the default compression setting has been changed to `none`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-05-default-compression-to-none.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.es]\n  type = \"elasticsearch\"\n+  compression = \"gzip\"\n```\n\n----------------------------------------\n\nTITLE: Modify FunctionCall struct to track argument validity in Rust\nDESCRIPTION: This snippet demonstrates the modification of the `FunctionCall` struct in Rust to track arguments with potentially invalid types. Instead of a simple boolean flag, it uses a vector to store details about each argument that might have an invalid type. This allows for more precise error reporting by providing information about the parameter name, argument types, and their span within the source code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_20\n\nLANGUAGE: Rust\nCODE:\n```\nstruct FunctionCall {\n    maybe_fallible_arguments: bool,\n\n    // ...\n}\n```\n\nLANGUAGE: Rust\nCODE:\n```\nstruct FunctionCall {\n    arguments_with_unknown_type_validity: Vec<Node<FunctionArgument>>,\n\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Invalid Function Argument Example - Coffee\nDESCRIPTION: This CoffeeScript-like VRL code snippet shows an example of an invalid function call. `to_string` is called with an invalid keyword argument `invalid: 12` instead of the expected `value`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_14\n\nLANGUAGE: coffee\nCODE:\n```\nbar = to_string(invalid: 12)\nupcase(bar)\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Sink in Vector Helm Chart\nDESCRIPTION: This YAML snippet illustrates how to configure a `vector` sink using the `customConfig` option in the Helm chart's `values.yaml` file.  It configures the Vector sink to send data to another Vector instance. `inputs` specifies which sources will send data to the sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-13-helm-customConfig.md#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ncustomConfig:\n  ...\n  sinks:\n  ...\n    vector_sink:\n      type: vector\n      inputs: [\"kubernetes_logs\"]\n      address: vector:9000\n  ...\n```\n\n----------------------------------------\n\nTITLE: Kafka Source Metadata Example (JSON)\nDESCRIPTION: This is an example of the metadata associated with an event from a Kafka source when using the native codec. The metadata here is specifically from the second Kafka source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"kafka\": {\n    \"key\": \"the key of the message (from the 2nd kafka source)\"\n    \"headers\": {\n      \"header-a-key\": \"header-a-value (from the 2nd kafka source)\",\n      \"header-b-key\": \"header-b-value (from the 2nd kafka source)\"\n    }\n    \"topic\": \"name of topic\",\n    \"partition\": 3,\n    \"offset\": 1829448\n  },\n  \"vector\": {\n    \"source_type\": \"kafka\",\n    \"ingest_timestamp\": \"2022-04-14T19:14:21.899623781Z\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implement Encoder Trait - Rust\nDESCRIPTION: Implements the `Encoder` trait for the `BasicEncoder` struct. The `encode_input` function serializes an `Event` to a String and writes the bytes to the writer, while also tracking the byte size for telemetry.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nimpl encoding::Encoder<Event> for BasicEncoder {\n    fn encode_input(\n        &self,\n        input: Event,\n        writer: &mut dyn std::io::Write,\n    ) -> std::io::Result<(usize, GroupedCountByteSize)> {\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Migrating from new_relic_logs to new_relic sink\nDESCRIPTION: Illustrates the configuration changes required to migrate from the deprecated `new_relic_logs` sink to the `new_relic` sink. This involves changing the sink type, specifying the API as \"logs\", and using a license key with account ID.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.new_relic]\ntype = \"new_relic\"\nlicense_key = \"xxxx\"\naccount_id = \"yyyy\"\napi = \"logs\"\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Apply Batches Milliseconds Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total time (in milliseconds) spent applying operations from the oplog during replication in MongoDB.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_17\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_apply_batches_total_milliseconds total_millis reports the total amount of time the mongod has spent applying operations from the oplog\n# TYPE mongodb_mongod_metrics_repl_apply_batches_total_milliseconds counter\nmongodb_mongod_metrics_repl_apply_batches_total_milliseconds 0\n```\n\n----------------------------------------\n\nTITLE: Prepare Docker Environment (Optional)\nDESCRIPTION: This optional command prepares the Docker environment by building the necessary container images. This step can be done while the developer is waiting, such as making coffee. It avoids the default `docker pull` from GitHub's container registry.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2685-dev-workflow-simplification.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Optional: Only if you want to go make a coffee\nmake environment-prepare\n```\n\n----------------------------------------\n\nTITLE: Remap Transform Configuration in YAML\nDESCRIPTION: This YAML configuration defines a `remap` transform in Vector. It removes the `user_info` field and adds a timestamp to each event. It utilizes the `del` and `now` VRL functions for data transformation. The input to the transform is defined as `logs`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/_index.md#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\ntransforms:\n  modify:\n    type: remap\n    inputs:\n      - logs\n    source: |\n      del(.user_info)\n      .timestamp = now()\n```\n\n----------------------------------------\n\nTITLE: Defining FramingConfig Trait in Rust\nDESCRIPTION: This code snippet defines the `FramingConfig` trait in Rust. It includes a `build` method that creates a framer from this configuration and can fail if the configuration is invalid. The trait requires implementors to derive Debug, DynClone, Send, and Sync.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-8621-framing-and-codecs-sinks.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\npub trait FramingConfig: Debug + DynClone + Send + Sync {\n    /// Builds a framer from this configuration.\n    ///\n    /// Fails if the configuration is invalid.\n    fn build(&self) -> crate::Result<BoxedFramer>;\n}\n```\n\n----------------------------------------\n\nTITLE: map_keys Function Signature in VRL\nDESCRIPTION: This code presents the signature of the `map_keys` function in VRL. It takes an object and a boolean (recursive) as input. It also uses a closure expression to transform keys and returns the modified object. The closure expects a single string argument and returns a string.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_27\n\nLANGUAGE: coffee\nCODE:\n```\nmap_keys(value: OBJECT, recursive: BOOLEAN) -> |<key variable>| { EXPRESSION } -> OBJECT\n```\n\n----------------------------------------\n\nTITLE: Proposed JSON Event Data with Metadata for WASM\nDESCRIPTION: This JSON shows the proposed format for event data passed to WASM transforms, including both log data and event metadata. It includes a log field containing the original event data and a metadata field with information like the first timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-02-04-5802-event-metadata.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"log\": {\n    \"message\": \"Something happened\",\n    \"timestamp\": \"2021-02-08T11:11:11+00:00\"\n  },\n  \"metadata\": {\n    \"first_timestamp\": \"2021-02-08T12:23:34+00:00\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: MongoDB WiredTiger Session Open Sessions Metrics - Prometheus\nDESCRIPTION: This snippet shows the total number of sessions opened in WiredTiger, the MongoDB storage engine. It helps in understanding how many active connections or operations are occurring within the database.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_25\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_mongod_wiredtiger_session_open_sessions_total The total number of sessions opened in WiredTiger\n# TYPE mongodb_mongod_wiredtiger_session_open_sessions_total gauge\nmongodb_mongod_wiredtiger_session_open_sessions_total 15\n```\n\n----------------------------------------\n\nTITLE: JsonSize Newtype Definition Rust\nDESCRIPTION: This Rust code defines a newtype called `JsonSize` that wraps a `usize`. This type is used to ensure that the `EventsSent` metric only accepts estimated JSON sizes, enforcing type safety and preventing accidental use of other byte sizes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2023-05-03-data-volume-metrics.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\npub struct JsonSize(usize);\n```\n\n----------------------------------------\n\nTITLE: Emitting Metrics in Rust\nDESCRIPTION: Demonstrates how to emit counters, gauges, and histograms in Rust using the `metrics` crate.  It shows how to increment counters, set gauges to absolute values or increment/decrement them, and record measurements with histograms, including using `IntoF64` for custom types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/STYLE.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n// Counters can be incremented by an arbitrary amount, or `increment_counter!`\n// can be used to simply increment by one:\ncounter!(\"bytes_sent_total\", 212);\nincrement_counter!(\"requests_processed_total\", \"service\" => \"admin_grpc\");\n\n// Gauges can be set to an absolute value, such as setting it to the latest value of an\n// external measurement, or it can be incremented and decremented by an arbitrary amount:\ngauge!(\"bytes_allocated\", 42.0);\nincrement_gauge!(\"bytes_allocated\", 2048.0, \"table_name\" => self.table_name.to_string());\nincrement_gauge!(\"bytes_allocated\", 512.0, \"table_name\" => self.table_name.to_string());\ndecrement_gauge!(\"bytes_allocated\", 2560.0, \"table_name\" => self.table_name.to_string())\n\n// Histograms simply record a measurement, but there's a fun little trait that `metrics`\n// uses called `IntoF64` that lets custom types provide a way to convert themselves to a\n// `f64`, which there's a default implementation of for `Duration`:\nlet delta = Duration::from_micros(750);\nhistogram!(\"request_duration_ns\", delta);\nhistogram!(\"request_duration_ns\", 742_130, \"endpoint\" => \"frontend\");\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Apply Operations Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total number of oplog operations applied during replication in MongoDB.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_18\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_apply_ops_total ops reports the total number of oplog operations applied\n# TYPE mongodb_mongod_metrics_repl_apply_ops_total counter\nmongodb_mongod_metrics_repl_apply_ops_total 0\n```\n\n----------------------------------------\n\nTITLE: Defining Framer trait in Rust\nDESCRIPTION: This trait defines the interface for framers, requiring implementations to also implement `tokio_util::codec::Decoder` for decoding byte streams into byte frames (`Bytes`).  The error type is a boxed framing error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\npub trait Framer: tokio_util::codec::Decoder<Item = Bytes, Error = BoxedFramingError> + DynClone + Send + Sync {}\n```\n\n----------------------------------------\n\nTITLE: Resulting JSON after VRL Transformations\nDESCRIPTION: This JSON represents the output after applying the VRL transformation rules defined in the previous example.  It demonstrates the results of upcasing keys, changing empty string values to null, and calculating the frequency of elements in the 'qux' array, which are then stored in the 'qux_tally' object.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-18-vrl-iteration-support.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"FOO\": true,\n  \"BAR\": { \"BAR\": null },\n  \"BAZ\": null,\n  \"QUX\": [\"a\", \"b\", \"a\", \"c\"],\n  \"qux_tally\": {\n    \"a\": 2,\n    \"b\": 1,\n    \"c\": 1\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Output of `parse_regex` (0.13 and Later)\nDESCRIPTION: This JSON represents the default output of the `parse_regex` function in VRL version 0.13 and later. It only includes the named capture group \"number\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"number\": \"123\" }\n```\n\n----------------------------------------\n\nTITLE: Starting Vector Executable\nDESCRIPTION: Starts the Vector executable with a specified configuration file. This is applicable when running Vector without a process manager. The configuration can be in YAML or JSON format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector --config /etc/vector/vector.yaml\n\n# Or supply a JSON or YAML config file\n```\n\n----------------------------------------\n\nTITLE: Implementing gRPC Server with Tonic\nDESCRIPTION: This Rust code implements a gRPC server using the Tonic framework. It defines a `MyHandler` struct that implements the `Dummy` service trait generated from the Protobuf definition. The handler includes implementations for streaming and unary RPC calls.  It requires the `tokio`, `tonic` and generated protobuf modules as dependencies.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nuse tokio::sync::mpsc;\nuse tonic::{transport::Server, Request, Response, Status};\n\nuse our_rpc_mod::say_server::{Dummy}, DummyServer};\nuse our_rpc_mod::{DummyRequest, DummyResponse};\n\nmod our_rpc_mod;\n\n#[derive(Default)]\npub struct MyHandler {}\n\n#[tonic::async_trait]\n//Implementation of the traits we need for our various \"services\" defined in our protos.\nimpl Dummy for MyHandler {\n    type SendStreamStream = mpsc::Receiver<Result<DummyResponse, Status>>;\n    async fn send_stream(\n        &self,\n        request: Request<DummyRequest>,\n    ) -> Result<Response<Self::SendStreamStream>, Status> {\n        let (mut tx, rx) = mpsc::channel(4);\n\n        tokio::spawn(async move {\n            for _ in 0..4 {\n                tx.send(Ok(DummyResponse {\n                    message: format!(\"hello\"),\n                }))\n                .await;\n            }\n        });\n\n        Ok(Response::new(rx))\n    }\n\n    type BidirectionalStream = mpsc::Receiver<Result<DummyResponse, Status>>;\n    async fn bidirectional(\n        &self,\n        request: Request<tonic::Streaming<DummyRequest>>,\n    ) -> Result<Response<Self::BidirectionalStream>, Status> {\n        let mut streamer = request.into_inner();\n        let (mut tx, rx) = mpsc::channel(4);\n\n        tokio::spawn(async move {\n            while let Some(req) = streamer.message().await.unwrap(){\n                tx.send(Ok(DummyResponse {\n                    message: format!(\"hello {}\", req.name),\n                }))\n                .await;\n            }\n        });\n\n        Ok(Response::new(rx))\n    }\n\n    async fn receive_stream(\n        &self,\n        request: Request<tonic::Streaming<DummyRequest>>,\n    ) -> Result<Response<DummyResponse>, Status> {\n        let mut stream = request.into_inner();\n        let mut message = String::from(\"\");\n\n        while let Some(req) = stream.message().await? {\n            message.push_str(&format!(\"Hello {}\\n\", req.name))\n        }\n\n        Ok(Response::new(DummyResponse { message }))\n    }\n\n    async fn send(&self, request: Request<DummyRequest>) -> Result<Response<DummyResponse>, Status> {\n        Ok(Response::new(DummyResponse {\n            message: format!(\"hello {}\", request.get_ref().name),\n        }))\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let addr = \"[::1]:9999\".parse().unwrap();\n    let handler = MyHandler::default();\n    println!(\"Server listening on {}\", addr);\n    Server::builder()\n        .add_service(DummyServer::new(handler))\n        .serve(addr)\n        .await?;\n    Ok(())\n}\n```\n\n----------------------------------------\n\nTITLE: Using Vector with JSON config flag\nDESCRIPTION: This command shows how to explicitly specify the JSON format for the configuration file. This is useful in edge cases where the file extension might not be sufficient for Vector to infer the format correctly.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-11-25-json-yaml-config-formats.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nvector --config-json /etc/vector/vector.json\n```\n\n----------------------------------------\n\nTITLE: Set Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create a set metric event. It includes the metric name and a set of values.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_22\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_set\",\n    set = {\n      values = {\"a\", \"b\", \"c\"}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Log Event Creation in Lua\nDESCRIPTION: Creates a log event table in Lua. The `log` field contains the log event structure, with possible nesting of fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_17\n\nLANGUAGE: lua\nCODE:\n```\n{\n  log = {\n    -- ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: GraphQL Subscription for Uptime\nDESCRIPTION: This GraphQL subscription query fetches the uptime of the Vector instance, including the number of seconds since the last restart and the timestamp. The subscription streams updates every second, providing real-time uptime information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_2\n\nLANGUAGE: GraphQL\nCODE:\n```\nsubscription {\n  uptime {\n    seconds\n    timestamp\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Sample Transform to VRL Condition - TOML\nDESCRIPTION: This example shows how to convert the `sample` transform condition to use VRL syntax. This is the recommended approach and provides more powerful condition options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_2\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.sample]\ntype = \"sample\"\ninputs = [\"in\"]\nrate = 10\nkey_field = \"message\"\nexclude = \"\"\"\n  contains!(.message, \\\"error\\\")\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: LLVM IR Output\nDESCRIPTION: This is the LLVM IR generated from the Rust function. It defines a function `@foo` that takes an i32 `%n` as input, multiplies it by 42, and returns the result. The `mul` instruction performs the multiplication.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-12-20-10517-llvm-backend-for-vrl.md#_snippet_1\n\nLANGUAGE: LLVM\nCODE:\n```\ndefine i32 @foo(i32 %n) unnamed_addr #0 !dbg !6 {\n  %0 = mul i32 %n, 42, !dbg !10\n  ret i32 %0, !dbg !11\n}\n```\n\n----------------------------------------\n\nTITLE: Deploying Vector with kubectl\nDESCRIPTION: This snippet deploys Vector in a Kubernetes cluster using kubectl. It creates a namespace named 'vector' and applies the 'vector-configmap.yaml' file along with recommended deployment configurations from specified URLs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create namespace vector\nkubectl apply --namespace vector -f vector-configmap.yaml\nkubectl apply -f https://packages.timber.io/vector/latest/kubernetes/vector-global.yaml\nkubectl apply --namespace vector -f https://packages.timber.io/vector/latest/kubernetes/vector-namespaced.yaml\n```\n\n----------------------------------------\n\nTITLE: Disable Splunk HEC Sink Indexer Acknowledgements (TOML)\nDESCRIPTION: This code snippet shows how to disable indexer acknowledgements in the `splunk_hec` sink. Disabling this feature restores the previous behavior where successful HEC requests are treated as events being acknowledged, potentially leading to weaker delivery guarantees.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-15-splunk-hec-improvements.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nacknowledgements.indexer_acknowledgements_enabled = false\n```\n\n----------------------------------------\n\nTITLE: JSON Example Input for Remap Transform\nDESCRIPTION: This JSON object represents an example input for the `remap` transform.  It contains a host field and an events array. The transform will process this event and potentially create multiple events based on the contents of the `events` array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"localhost\", \"events\": [{ \"message\": \"foo\" }, { \"message\": \"bar\" }] }\n```\n\n----------------------------------------\n\nTITLE: Building Rust WASM Module\nDESCRIPTION: Builds the Rust WASM module using `cargo`. The `+nightly` flag specifies that the nightly toolchain should be used, and the `--target wasm32-wasi` flag specifies that the target architecture is `wasm32-wasi`. The `--release` flag builds the module in release mode, which enables optimizations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_6\n\nLANGUAGE: Bash\nCODE:\n```\ncargo +nightly build --target wasm32-wasi --release\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Literal Values in CoffeeScript-like Syntax\nDESCRIPTION: This snippet shows how to define literal values of different data types within the remap language. It demonstrates the syntax for integers, booleans, strings, and null values, which can be assigned to fields within the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_4\n\nLANGUAGE: coffeescript\nCODE:\n```\n.first = 7\n.second = false\n.third = \\\"string\\\"\n.fourth = null\n```\n\n----------------------------------------\n\nTITLE: Migrating from new_relic_logs to new_relic sink\nDESCRIPTION: Illustrates the configuration changes required to migrate from the deprecated `new_relic_logs` sink to the `new_relic` sink. This involves changing the sink type, specifying the API as \"logs\", and using a license key with account ID.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.new_relic_logs]\ntype = \"new_relic_logs\"\nlicense_key = \"xxxx\"\n```\n\n----------------------------------------\n\nTITLE: Define Object with Known Fields and Types in Rust\nDESCRIPTION: This code defines an object with two specific fields: 'reason' (a string) and 'value' (an integer). The `with_known` method associates the field name with its corresponding data type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_18\n\nLANGUAGE: rust\nCODE:\n```\nKind::object(Collection::empty()\n                .with_known(\"reason\", Kind::bytes())\n                .with_known(\"value\", Kind::integer()))\n```\n\n----------------------------------------\n\nTITLE: Renaming identifier_fields to group_by in Vector TOML\nDESCRIPTION: This snippet shows the renaming of the `identifier_fields` option to `group_by` in the `reduce` transform configuration within a Vector TOML file.  This change enhances clarity and better reflects the intended functionality of grouping data for reduction operations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_5\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.reduce]\n  type = \"reduce\"\n-  identifier_fields = [\"my_field\"]\n+  group_by = [\"my_field\"]\n```\n\n----------------------------------------\n\nTITLE: Example JSON After IoT Status Enrichment\nDESCRIPTION: This JSON represents the output data after enrichment. The 'status_code' field has been replaced by the 'status' field, which now contains the human-readable status message obtained from the 'iot_status' enrichment table.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"host\":\"my.host.com\",\n  \"timestamp\":\"2019-11-01T21:15:47+00:00\",\n  ...\n  \"status\":\"device status transmission complete\",\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Module-Level Doc Comments in Rust\nDESCRIPTION: This code snippet demonstrates how to add module-level documentation comments to a Rust module, explaining the sink's purpose. The comments will be used by Vector to generate documentation. The sink outputs data to standard out for pedagogical purposes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\n//! `Basic` sink.\n//! A sink that will send it's output to standard out for pedagogical purposes.\n```\n\n----------------------------------------\n\nTITLE: Remove and reinstall Xcode Command Line Tools\nDESCRIPTION: These commands remove and reinstall the Xcode Command Line Tools. This can be useful for resolving compilation errors related to missing or corrupted tools. The rm -rf command requires sudo elevation to remove the directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nrm -rf /Library/Developer/CommandLineTools # might require sudo elevation\nxcode-select --install\n```\n\n----------------------------------------\n\nTITLE: Encode JSON on Top-Level Object Fields VRL\nDESCRIPTION: This VRL snippet iterates through the top-level values of an object and encodes any object values into JSON strings. It uses `map_values` to process each value and applies `encode_json` if the value is an object. Non-object values remain unchanged.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_17\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_values(.) -> |value| {\n  if value.is_object() {\n    encode_json(value)\n  } else {\n    value\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: VRL Iteration Example with emit_log\nDESCRIPTION: This VRL code snippet demonstrates how to use a loop to iterate over an array of stooges and emit each stooge as a separate log event using the `emit_log` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_16\n\nLANGUAGE: text\nCODE:\n```\nfor stooge in .stooges\n   emit_log(stooge)\nend\n```\n\n----------------------------------------\n\nTITLE: String Interpolation Fallibility (Coffee)\nDESCRIPTION: This snippet shows how string interpolation can be fallible if the variable used is not a string. This is due to the underlying implementation of expanding to an expression, using the nil coalescing operator `??` to provide a default value if the variable cannot be interpolated.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_3\n\nLANGUAGE: coffee\nCODE:\n```\n> thing = 3\n> \"The number is {{ thing }}\" ?? \"invalid string\"\n\n\"invalid string\"\n```\n\n----------------------------------------\n\nTITLE: Split Input Implementation - Rust\nDESCRIPTION: Implements the `split_input` function for `BasicRequestBuilder`, extracting the metadata (EventFinalizers) from the input event. It returns the finalizers, a request metadata builder, and the event itself.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_11\n\nLANGUAGE: rust\nCODE:\n```\n    fn split_input(\n        &self,\n        mut input: Event,\n    ) -> (Self::Metadata, RequestMetadataBuilder, Self::Events) {\n        let finalizers = input.take_finalizers();\n        let metadata_builder = RequestMetadataBuilder::from_event(&input);\n        (finalizers, metadata_builder, input)\n    }\n```\n\n----------------------------------------\n\nTITLE: AWS S3 Sink Key Prefix Configuration using Template\nDESCRIPTION: This example shows how to use the template syntax in the `key_prefix` option of the `aws_s3` sink to partition data by `application_id` and `date`. It uses direct field references and strftime specifiers.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.backup]\n  type = \"aws_s3\"\n  bucket = \"all_application_logs\"\n  key_prefix = \"application_id={{ application_id }}/date=%F/\"\n```\n\n----------------------------------------\n\nTITLE: ResponseFuture Implementation for Concurrency Control in Rust\nDESCRIPTION: This code implements the `Future` trait for `ResponseFuture`. It polls the inner future, measures the round trip time (RTT), and adjusts the concurrency limit based on the RTT compared to a moving average. It uses an AIMD (Additive Increase Multiplicative Decrease) algorithm to dynamically adjust the concurrency.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nimpl Future for ResponseFuture {\n    fn poll(&mut self, cx: &mut Context) -> Poll<Self::Output> {\n        match self.inner.poll() {\n            Pending => Pending,\n            Ready(output) => {\n                let now = Instant::now();\n                let rtt = now.duration_since(self.start_time);\n                emit!(RTTMeasurement { rtt: rtt.as_millis() });\n\n                let mut controller = self.controller.lock();\n                if now >= controller.next_update {\n                    if rtt > controller.rtt + controller.threshold {\n                        // The `+ 1` prevents this from going to zero\n                        controller.concurrency_limit = (controller.concurrency_limit + 1) / 2;\n                    }\n                    else if controller.concurrency_limit < controller.in_flight_limit\n                        && rtt <= controller.rtt {\n                        controller.concurrency_limit =\n                            min(controller.current_concurrency, controller.concurrency_limit) + 1;\n                    }\n                    controller.next_update = now + controller.measured_rtt.average();\n                }\n                controller.measured_rtt.update(rtt);\n\n                Ready(output)\n            }\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: CUE String Description - Bad Indentation (1)\nDESCRIPTION: This CUE snippet demonstrates incorrect indentation for a multi-line string description. The extra spaces before the closing triple quotes will cause validation errors.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_8\n\nLANGUAGE: cue\nCODE:\n```\ndescription: \"\"\"\n        Here is a long string...\n    \"\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Concurrency Controller in Rust\nDESCRIPTION: The Adaptive Request Concurrency (ARC) feature utilizes a concurrency controller implemented in Rust. This controller is responsible for making the linear up/exponential down decisions within the AIMD algorithm for concurrency adjustment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/adaptive-request-concurrency.md#_snippet_2\n\nLANGUAGE: Rust\nCODE:\n```\n// No specific code is present, but the controller is located at [Controller]: https://github.com/vectordotdev/vector/blob/master/src/sinks/util/adaptive_concurrency/controller.rs#L23-L31\n//The [adaptive_concurrency] module is located at: https://github.com/vectordotdev/vector/tree/master/src/sinks/util/adaptive_concurrency\n```\n\n----------------------------------------\n\nTITLE: Prometheus HTTP Handler Requests Total - Prometheus\nDESCRIPTION: This snippet captures the total number of scrapes by HTTP status code received by the Prometheus HTTP handler. It is used to monitor the success and failure rates of Prometheus scrapes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_36\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.\n# TYPE promhttp_metric_handler_requests_total counter\npromhttp_metric_handler_requests_total{code=\"200\"} 0\npromhttp_metric_handler_requests_total{code=\"500\"} 0\npromhttp_metric_handler_requests_total{code=\"503\"} 0\n```\n\n----------------------------------------\n\nTITLE: Migrating from disk_v1 to disk buffer type\nDESCRIPTION: This code snippet demonstrates how to migrate from the deprecated `disk_v1` buffer type to the new `disk` buffer type in Vector's configuration file.  The change is a direct replacement of the `type` field in the buffer configuration. This change should be transparent.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-02-28-0-28-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n-type = \"disk_v1\"\n+type = \"disk\"\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB GetLastError WTimeouts Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the number of write concern operations that timed out due to the wtimeout threshold of getLastError.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_12\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_get_last_error_wtimeouts_total wtimeouts reports the number of times that write concern operations have timed out as a result of the wtimeout threshold to getLastError.\n# TYPE mongodb_mongod_metrics_get_last_error_wtimeouts_total counter\nmongodb_mongod_metrics_get_last_error_wtimeouts_total 0\n```\n\n----------------------------------------\n\nTITLE: Defining Source Schema Output in Rust\nDESCRIPTION: This code snippet demonstrates how to define the output schema for a Vector source. It merges the global log namespace with the source-specific namespace. The source typically has a decoder to specify the initial schema which is then updated.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_9\n\nLANGUAGE: rust\nCODE:\n```\n    fn outputs(&self, global_log_namespace: LogNamespace) -> Vec<Output> {\n        let log_namespace = global_log_namespace.merge(self.log_namespace);\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration Example (Namespaced)\nDESCRIPTION: This example demonstrates the equivalent configuration using implicit namespacing.  The configuration is placed in a `sinks` directory in a file named `foo.toml`, indicating that it defines the sink component `foo`. The main configuration file is no longer needed for this component.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-12-9568-automatic-namespacing.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\ntype = \"anything\"\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Debug Logging and Timeout\nDESCRIPTION: This shell command runs the 'vector-pr' executable with debug logging enabled (via the LOG environment variable) and using 'config-right-http.toml' as the configuration file, with a timeout of 5 seconds. It demonstrates how to configure Vector for detailed debugging.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nLOG=debug timeout 5s ./vector-pr --config config-right-http.toml\n```\n\n----------------------------------------\n\nTITLE: Install Vector MSI Package using PowerShell\nDESCRIPTION: This snippet downloads the Vector MSI package from the timber.io package repository using Invoke-WebRequest.  The downloaded file is then installed using the msiexec command. Replace {{% version %}} with the desired Vector version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/msi.md#_snippet_0\n\nLANGUAGE: powershell\nCODE:\n```\npowershell Invoke-WebRequest https://packages.timber.io/vector/{{% version %}}/vector-x64.msi -OutFile vector-{{% version %}}-x64.msi\nmsiexec /i vector-{{% version %}}-x64.msi\n```\n\n----------------------------------------\n\nTITLE: Compiling Protobuf Definition and Generating Python Code\nDESCRIPTION: This set of shell commands compiles a protobuf definition file (`test_protobuf3.proto`) into a descriptor file (`test_protobuf3.desc`) and generates Python code from the same protobuf definition. It uses the `protoc` compiler and requires the protobuf library to be installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/codecs/tests/data/protobuf/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nprotoc -I ./ -o test_protobuf3.desc ./test_protobuf3.proto\npip install protobuf\nprotoc --python_out=. ./test_protobuf3.proto\npython generate_example.py\n```\n\n----------------------------------------\n\nTITLE: Kafka Source Event Example (JSON)\nDESCRIPTION: This is an example event from a Kafka source using the Native codec after going through Kafka source (JSON codec), through a Kafka sink (using native codec), and then back out a Kafka source (native codec).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"derivative\": -2.266778047142367e+125,\n  \"integral\": \"13028769352377685187\",\n  \"mineral\": \"H 9 \",\n  \"proportional\": 3673342615,\n  \"vegetable\": -30083\n}\n```\n\n----------------------------------------\n\nTITLE: Parse CloudWatch Log Subscription Message (Coffee)\nDESCRIPTION: This is the first step in the remap transform, using the `parse_aws_cloudwatch_log_subscription_message` function to parse the `.message` field. The result, stored in the `parsed` variable, is a structured representation of the CloudWatch Logs subscription event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_16\n\nLANGUAGE: coffee\nCODE:\n```\nparsed = parse_aws_cloudwatch_log_subscription_message!(.message)\n```\n\n----------------------------------------\n\nTITLE: Define Array with Specific Types at Indexes in Rust\nDESCRIPTION: This example illustrates how to define an array where elements at specific indexes have predefined types.  Index 0 is defined as 'bytes' and index 1 is defined as 'integer'.  Other indices are not defined.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_15\n\nLANGUAGE: rust\nCODE:\n```\nKind::array(Collection::empty()\n                .with_known(0, Kind::bytes())\n                .with_known(1, Kind::integer()))\n```\n\n----------------------------------------\n\nTITLE: Piping Input to Vector (v0.18.1)\nDESCRIPTION: This command pipes the contents of the `five-lines` file to the standard input of the `vector-v0.18.1` binary. The `-c config.toml` flag specifies the configuration file to use.  This is intended to trigger the bug by feeding Vector with some input.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncat five-lines | ./vector-v0.18.1 -c config.toml\n```\n\n----------------------------------------\n\nTITLE: Implementing Sink trait for Pipeline with EventVec in Rust\nDESCRIPTION: This snippet demonstrates how the `Pipeline` structure implements the `Sink` trait for `EventVec`, allowing it to receive arrays of events asynchronously. This is a key part of enabling sources to send arrays of events to the pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nimpl Sink<EventVec> for Pipeline { … }\n```\n\n----------------------------------------\n\nTITLE: Concurrency Limit Metric Emission in Rust\nDESCRIPTION: This snippet shows how to emit a metric for the concurrency limit. The `value!` macro records the current concurrency limit, along with the component kind and type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-06-1858-automatically-adjust-request-limits.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nimpl InternalEvent for ConcurrencyLimit {\n    fn emit_metrics(&self) {\n        value!(\"concurrency_limit\", self.concurrency,\n            \"component_kind\" => \"sink\",\n            \"component_type\" => self.component,\n        );\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Iteration Control-Flow Example\nDESCRIPTION: Illustrates potential control-flow operations inside an iterator. This example uses a hypothetical `map_values` function and demonstrates how to return default values if the value is an object.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_46\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n. = map_values(.) -> |value| {\n  # Return default value pairs if the value is an object.\n  if is_object(value) {\n    return value\n  }\n\n  # ...\n}\n```\n\n----------------------------------------\n\nTITLE: Coercer Transform Enum (Bash)\nDESCRIPTION: Shows the valid enum values for the Coercer transform, including the addition of \"bytes\". Used for configuring the type coercion behavior within Vector's data pipeline. This snippet requires understanding of Vector's configuration schema.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nEnum, must be one of: \"bool\" \"float\" \"int\" \"string\" \"timestamp\", \"bytes\"\n```\n\n----------------------------------------\n\nTITLE: Build instrumented Vector version with cargo-pgo\nDESCRIPTION: This command builds the instrumented version of Vector using cargo-pgo. The instrumented version collects runtime profile data during execution, which is later used for PGO.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/tuning/pgo.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncargo pgo build\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Next GC Bytes Metric - Prometheus\nDESCRIPTION: This snippet indicates the number of heap bytes when the next garbage collection will take place in the Go program. This provides insight into GC scheduling.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_59\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.\n# TYPE go_memstats_next_gc_bytes gauge\ngo_memstats_next_gc_bytes 9.927312e+06\n```\n\n----------------------------------------\n\nTITLE: Example of Kubernetes Annotations file content\nDESCRIPTION: This text snippet shows the content of the annotations file that is exposed by the downward API in Kubernetes. The `vector.dev/config` annotation contains the Vector configuration as a string. This configuration can then be parsed and used to configure Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_9\n\nLANGUAGE: text\nCODE:\n```\nkubernetes.io/config.seen=\"2020-04-15T13:35:27.290739039Z\"\nkubernetes.io/config.source=\"api\"\nvector.dev/config=\"[sinks.aws_s3]\\ntype = \\\"aws_s3\\\"\\ninputs = [\\\"kubernetes\\\"]\\nbucket = \\\"my-bucket\\\"\\ncompression = \\\"gzip\\\"\\nregion = \\\"us-east-1\\\"\\nkey_prefix = \\\"date=%F/\\\"\\n\"\n```\n\n----------------------------------------\n\nTITLE: Displaying vdev Usage Instructions (text)\nDESCRIPTION: This code snippet shows the usage instructions for the `vdev` tool, which is intended to be a unified development tool for Vector. It outlines available commands like `build`, `config`, `exec`, `int`, `meta`, and `status`, along with options for verbosity, quietness, help, and version information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-31-15056-tooling-revamp.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nVector's unified dev tool\n\nUsage: vdev [OPTIONS] <COMMAND>\n\nCommands:\n  build   Build Vector\n  config  Manage the vdev config file\n  exec    Execute a command within the repository\n  int     Manage integrations\n  meta    Collection of useful utilities\n  status  Show information about the current environment\n\nOptions:\n  -v, --verbose...  More output per occurrence\n  -q, --quiet...    Less output per occurrence\n  -h, --help        Print help information\n  -V, --version     Print version information\n```\n\n----------------------------------------\n\nTITLE: Unit Test Configuration Setup (TOML)\nDESCRIPTION: Shows the basic structure for defining unit tests within a Vector configuration file, including the `tests` array and the `name` parameter for each test.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[[tests]]\nname = \"test 1\"\n# Other test config\n\n[[tests]]\nname = \"test_2\"\n# Other test config\n\n# etc.\n```\n\n----------------------------------------\n\nTITLE: Update Vector Sink Configuration TOML\nDESCRIPTION: This code snippet demonstrates how to update the Vector sink configuration file (vector.toml) to reflect the renaming of the `gcp_stackdriver_logging` sink to `gcp_stackdriver_logs`. It uses the diff format to highlight the changes needed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-03-23-rename-gcp_stackdriver_logging-sink-to-gcp_stackdriver_logs.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.stackdriver]\n-  type = \"gcp_stackdriver_logging\"\n+  type = \"gcp_stackdriver_logs\"\n```\n\n----------------------------------------\n\nTITLE: Modify process hook to use safe_merge in Lua\nDESCRIPTION: This Lua code snippet shows how to modify the `process` hook to use the `safe_merge` function, preventing the unbounded growth of the `message` field in case of malformed CSV data. The function is expected to be defined in the `source` section of the transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/merge-multiline-logs-with-lua.md#_snippet_2\n\nLANGUAGE: lua\nCODE:\n```\nmerged_event.log.message = merged_event.log.message ..\n                           line_separator .. event.log.message\n```\n\nLANGUAGE: lua\nCODE:\n```\nmerged_event = safe_merge(merged_event, event)\nif not merged_event then\n  return\nend\n```\n\n----------------------------------------\n\nTITLE: Enable Debug Symbols in Release Mode (TOML)\nDESCRIPTION: This configuration snippet in `Cargo.toml` enables debug symbols for release builds. This ensures human-readable output when profiling, making it easier to identify performance bottlenecks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\n[profile.release]\ndebug = true\n```\n\n----------------------------------------\n\nTITLE: Valid Configuration Validation\nDESCRIPTION: This snippet shows the output when a valid Vector configuration file is validated using the `vector validate` command. It demonstrates the successful validation of the configuration file, topology, component configuration, and health checks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-06-10-consolidate-and-beautify-validate.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvic@sticky-keyboard-macbook:/git/vectordotdev/vector$ vector validate test.toml\n√ Loaded \"test.toml\"\n√ Configuration topology\n√ Component configuration\n√ Health check `sink0`\n-------------------------\n                Validated\n```\n\n----------------------------------------\n\nTITLE: Aggregated Histogram Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create an aggregated histogram metric event. It includes metric name, bucket boundaries, counts, and the total sum.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_24\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_histogram\",\n    aggregated_histogram = {\n      buckets = {1.0, 2.0, 3.0},\n      counts = {30, 20, 10},\n      sum = 1000 -- total sum of all measured values, cannot be inferred from `counts` and `buckets`\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Add Prefix to All Keys VRL\nDESCRIPTION: This VRL snippet recursively adds a prefix (`my_`) to all keys within the current object. The `map_keys` function is used with the `recursive: true` option, and a string concatenation operation adds the prefix to each key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_13\n\nLANGUAGE: coffee\nCODE:\n```\n. = map_keys(., recursive: true) -> |key| { \"my_\" + key }\n```\n\n----------------------------------------\n\nTITLE: Inserting Fields into Log Event in Rust\nDESCRIPTION: This code shows how to insert fields into a log event using the `insert` method.  The `event_path!()` macro generates a value path for the field name. The `value` is converted to a `Value` type before insertion.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\n  log_event.insert(event_path!(\"path\"), value);\n```\n\n----------------------------------------\n\nTITLE: Run Vector with JSON Configuration (Shell)\nDESCRIPTION: This shell command starts Vector, loading its configuration from a JSON file. The `--config` flag specifies the path to the JSON configuration, enabling Vector to ingest, transform, and route data based on the provided settings.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nvector --config /etc/vector/vector.json\n```\n\n----------------------------------------\n\nTITLE: JSON Example Input for Explode Transform (with host)\nDESCRIPTION: This JSON object represents an input with a 'host' and 'events' field, for demonstrating merging top-level fields into sub-events with the explode transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_12\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"foobar\", \"events\": [{ \"message\": \"foo\" }, { \"message\": \"bar\" }] }\n```\n\n----------------------------------------\n\nTITLE: Configuring Internal Metrics Source - YAML\nDESCRIPTION: This configuration shows how to enable and use the `internal_metrics` source to inspect component metrics in detail. It connects the source to a prometheus exporter sink to collect internal metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\ndata_dir: /var/lib/vector/\nsources:\n  source0:\n    type: internal_metrics\n    scrape_interval_secs: 1.0\n\nsinks:\n  sink0:\n    type: prometheus_exporter\n    inputs:\n      - source0\n    address: 0.0.0.0:9598\n```\n\n----------------------------------------\n\nTITLE: VRL If Statement Predicate Error Handling\nDESCRIPTION: Demonstrates how to handle errors in `if` statement predicates in `VRL`.  Previously, unhandled errors would cause a panic. Now, these errors are caught at compile time and must be explicitly handled.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-0-20-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: coffeescript\nCODE:\n```\nif contains(.message, \"true\") {\n  log(\"true\")\n}\n```\n\n----------------------------------------\n\nTITLE: Filtering Example\nDESCRIPTION: Shows how to filter an array using a lambda function. This example removes the element \"180.14.129.174\" from the `.ips` array by checking if the `ip` string starts with \"180.14\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_47\n\nLANGUAGE: CoffeeScript\nCODE:\n```\n# Return a new array with \"180.14.129.174\" removed.\n.ips = filter(.ips) -> |_index, ip| {\n    ip = string(ip) ?? \"unknown\"\n\n    !starts_with(ip, \"180.14\")\n}\n```\n\n----------------------------------------\n\nTITLE: Map Values Function Signature in VRL\nDESCRIPTION: This is the function signature for the `map_values` function, which iterates over an object or array and changes its values. The function accepts an object or array and a boolean for enabling recursion. It returns a value of any type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\nmap_values(value: object|array, recursive: bool) -> |any| { any }\n```\n\n----------------------------------------\n\nTITLE: Incorrect Logging Style Example (Rust)\nDESCRIPTION: This snippet demonstrates an *incorrect* way to use the Tracing crate for logging in Vector. The message is not capitalized, doesn't end with a period, and uses `err` instead of `error`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_7\n\nLANGUAGE: rust\nCODE:\n```\nwarn!(\"Failed to merge value: {}.\", err);\n```\n\n----------------------------------------\n\nTITLE: Logfmt Output Example\nDESCRIPTION: Illustrates the logfmt output format produced by `vector tap` with the `--format logfmt` option.  Shows how events are represented as key-value pairs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_7\n\nLANGUAGE: console\nCODE:\n```\n...\nmessage=test1 source_type=demo_logs timestamp=2022-02-22T20:57:01.430905309Z\nmessage=test1 source_type=demo_logs timestamp=2022-02-22T20:57:02.430987800Z\n...\n```\n\n----------------------------------------\n\nTITLE: Enable Splunk HEC Source Acknowledgements (TOML)\nDESCRIPTION: This code snippet demonstrates how to enable indexer acknowledgements in the `splunk_hec` source. This configuration ensures stronger delivery guarantees by verifying that data has been persisted by Splunk before acknowledging the incoming request.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-12-15-splunk-hec-improvements.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nacknowledgements = true\n```\n\n----------------------------------------\n\nTITLE: VRL map_keys Example with Return Type Requirement\nDESCRIPTION: Demonstrates the correct usage of `map_keys` with a closure that returns a string. The closure uppercases the key and returns it, which then becomes the new key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_32\n\nLANGUAGE: coffee\nCODE:\n```\nmap_keys(.) { |key|\n  key = upcase(key)\n\n  # The string return-value clearly defines the eventual key value. The `key`\n  # variable is no longer ”unused”.\n  key\n}\n```\n\n----------------------------------------\n\nTITLE: Run local HTTP server\nDESCRIPTION: This command starts a simple HTTP server using Python 3 to serve the contents of the public directory. This allows you to access the index.html file in a web browser and test the VRL WASM web playground locally.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncd public\npython3 -m http.server\n```\n\n----------------------------------------\n\nTITLE: Send Logs using flog and Vector\nDESCRIPTION: Uses flog to generate JSON log data and pipes it to Vector for processing based on a specified configuration file. Requires flog and Vector to be installed and the 'config.toml' file to be configured.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nflog -f json | vector --config config.toml\n```\n\n----------------------------------------\n\nTITLE: Example JSON Event Data for WASM Transforms\nDESCRIPTION: This JSON represents the current event data exposed to WASM transforms, including a message and timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-02-04-5802-event-metadata.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": \"Something happened\",\n  \"timestamp\": \"2021-02-08T11:11:11+00:00\"\n}\n```\n\n----------------------------------------\n\nTITLE: Mapping IP Addresses with VRL\nDESCRIPTION: This VRL code snippet maps over an array of IP addresses, enforcing a string type, adding an 'order' field and a 'private' field based on a prefix check.  It demonstrates variable mutation in the outer scope.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_25\n\nLANGUAGE: coffee\nCODE:\n```\norder = 0\n.ips = map_values(.ips) { |ip|\n    # Enforce `ip` to be a string.\n    ip = string(ip) ?? \"unknown\"\n\n    value = {\n      \"address\": ip,\n      \"order\": order,\n      \"private\": starts_with(ip, \"180.14\"),\n    }\n\n    # We can access and mutate outer-scope variables.\n    order = order + 1\n\n    # Mapping an array requires you to return a single value to which the\n    # item-under-iteration will be mapped to.\n    value\n}\n```\n\n----------------------------------------\n\nTITLE: Example Output of Routing Failed Events - JSON\nDESCRIPTION: This JSON output demonstrates the result of running the provided TOML configuration. It shows how valid JSON messages are processed and outputted by the `foo` console sink, while invalid JSON messages and messages aborted due to the `remap` transform logic are routed to the `bar` console sink with additional metadata about the failure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-failed-event-routing.md#_snippet_1\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"foo\": \"bar\",\n  \"message\": \"valid message\",\n  \"processed\": true,\n  \"timestamp\": \"2021-11-09T16:11:47.330713806Z\"\n}\n{\n  \"foo\": \"bar\",\n  \"message\": \"valid message\",\n  \"processed\": true,\n  \"timestamp\": \"2021-11-09T16:11:48.330756592Z\"\n}\n{\n  \"message\": \"invalid message\",\n  \"metadata\": {\n    \"dropped\": {\n      \"component_id\": \"my_remap\",\n      \"component_type\": \"remap\",\n      \"component_kind\": \"transform\",\n      \"message\": \"function call error for \\\"object\\\" at (9:39): function call error for \\\"parse_json\\\" at (17:38): unable to parse json: expected value at line 1 column 1\",\n      \"reason\": \"error\"\n    }\n  },\n  \"timestamp\": \"2021-11-09T16:11:49.330157298Z\"\n}\n{\n  \"message\": \"{ \\\"message\\\": \\\"valid message\\\", \\\"foo\\\": \\\"baz\\\"}\",\n  \"metadata\": {\n    \"dropped\": {\n      \"component_id\": \"my_remap\",\n      \"component_type\": \"remap\",\n      \"component_kind\": \"transform\",\n      \"message\": \"aborted\",\n      \"reason\": \"abort\"\n    }\n  },\n  \"timestamp\": \"2021-11-09T16:11:50.329966720Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Apache Metrics Source Configuration TOML\nDESCRIPTION: This TOML configuration defines the settings for the new `apache_metrics` source in Vector. It includes the source type, endpoints to scrape, scrape interval, and namespace for the metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-21-3092-apache-metrics-source.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"apache_metrics\" # required\n  endpoints = [\"http://localhost/server-status?auto\"] # required, default\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"apache\" # optional, default, namespace to put metrics under\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Alloc Bytes Total Metric - Prometheus\nDESCRIPTION: This snippet shows the total number of bytes allocated by the Go program, even if they have been freed. This metric is a cumulative measure of memory allocation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_41\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.\n# TYPE go_memstats_alloc_bytes_total counter\ngo_memstats_alloc_bytes_total 1.0233104e+07\n```\n\n----------------------------------------\n\nTITLE: Migrate Vector Repository using setup script (Shell)\nDESCRIPTION: This command removes the existing repository and configures the new vector.dev repository using a setup script downloaded from the provided URL. The CSM_MIGRATE environment variable controls whether the existing repository is removed automatically.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nCSM_MIGRATE=true bash -c \"$(curl -L https://setup.vector.dev)\"\n```\n\n----------------------------------------\n\nTITLE: Moving Root CA and Server Certificate/Key\nDESCRIPTION: These commands move the root CA generated by `mkcert` and the server certificate/key to the `tests/data/nats` directory. This ensures the test environment has access to the necessary certificates.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/tests/data/nats/README.md#_snippet_1\n\nLANGUAGE: Shell Session\nCODE:\n```\n# Next, move the mkcert root CA to the correct location, and move the server certificate/key.\n$ mv \"$(mkcert -CAROOT)/rootCA.pem\" tests/data/nats/rootCA.pem\n```\n\n----------------------------------------\n\nTITLE: Test Handling Macro Wrapper\nDESCRIPTION: This macro provides test handling capabilities, including the default handle name. It allows us to add testing magic to our handles.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nstruct DefaultHandleName<E> {\n    pub name: &'static str,\n    pub event: E,\n}\n\n#[cfg(test)]\nmacro_rules! register {\n    ($event:expr) => {\n        vector_core::internal_event::register(\n            vector_core::internal_event::DefaultHandleName {\n                event: $event,\n                name: stringify!($event),\n            }\n        )\n    };\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Stack Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes obtained from the system for the stack allocator in Go. This helps analyze memory acquired for program stacks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_62\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.\n# TYPE go_memstats_stack_sys_bytes gauge\ngo_memstats_stack_sys_bytes 753664\n```\n\n----------------------------------------\n\nTITLE: Extending the `compile` method of the `Function` trait - Rust\nDESCRIPTION: This snippet showcases the updated `compile` method of the `Function` trait to accept an optional `FunctionClosure`. This requires all existing implementations to be updated to handle the new closure parameter.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_36\n\nLANGUAGE: rust\nCODE:\n```\nfn compile(&self, state: &super::State, arguments: ArgumentList, closure: Option<FunctionClosure>) -> Compiled;\n```\n\n----------------------------------------\n\nTITLE: Lua Transform Code: Event Processing\nDESCRIPTION: This snippet shows the part of the Lua script that is executed for each incoming event. It checks if the 'host' field is nil and assigns the hostname if needed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_3\n\nLANGUAGE: lua\nCODE:\n```\nif event[\"host\"] == nil then\n  event[\"host\"] = hostname\nend\n```\n\n----------------------------------------\n\nTITLE: Install Vector using dpkg\nDESCRIPTION: Downloads the Vector .deb package using curl and installs it using dpkg. Requires curl to be installed. Replace `{arch}` with the appropriate architecture (amd64, arm64, or armhf).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/dpkg.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\ncurl \\\n  --proto '=https' \\\n  --tlsv1.2 -O \\\n  https://apt.vector.dev/pool/v/ve/vector_{{< version >}}-1_{arch}.deb\n\nsudo dpkg -i vector_{{< version >}}-1_{arch}.deb\n```\n\n----------------------------------------\n\nTITLE: Init Hook Definition in Lua\nDESCRIPTION: Defines the `init` hook function in Lua, which is called when the transform is created. It takes the `emit` function as an argument, which can be used to produce new events from the hook.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_11\n\nLANGUAGE: lua\nCODE:\n```\nfunction (emit)\n  -- ...\nend\n```\n\n----------------------------------------\n\nTITLE: Running Vector with v2 Buffer and Migration (Shell)\nDESCRIPTION: This shell snippet executes the 'vector-pr' binary, presumably a development or pull request build, with the same configuration and logging setup as before.  The important part of the output shows Vector migrating from a `disk_v1` buffer to a `disk_v2` buffer format for the `http_tarpit` sink. The version of Vector being tested is v0.21.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-pr -c ./config-wrong-http-big-buffer.toml\n2022-04-06T17:41:52.772547Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\"\n2022-04-06T17:41:52.772588Z  INFO vector::app: Loading configs. paths=[\"config-wrong-http-big-buffer.toml\"]\n2022-04-06T17:41:52.773258Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-04-06T17:41:53.809795Z  INFO vector_buffers::variants::disk_v2::v1_migration: Detected old `disk_v1`-based buffer for the `http_tarpit` sink. Automatically migrating to `disk_v2`.\n2022-04-06T17:43:08.244317Z  INFO vector_buffers::variants::disk_v2::v1_migration: Migrated 4560522 records in disk buffer for `http_tarpit` sink. Old disk buffer at '/tmp/vector/github-12069/http_tarpit_id' has been deleted, and the new disk buffer has been created at '/tmp/vector/github-12069/buffer/v2/http_tarpit'.\n2022-04-06T17:43:08.256533Z  INFO vector::topology::running: Running healthchecks.\n2022-04-06T17:43:08.256573Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-04-06T17:43:08.256616Z  INFO vector: Vector has started. debug=\"false\" version=\"0.21.0\" arch=\"x86_64\" build_id=\"none\"\n2022-04-06T17:43:08.523110Z ERROR sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}:http: vector::internal_events::http_client: HTTP error. error=error trying to connect: tcp connect error: Connection refused (os error 111) error_type=\"request_failed\" stage=\"processing\"\n...\n2022-04-06T17:43:15.537528Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-04-06T17:43:17.057250Z  INFO vector: Vector has stopped.\n2022-04-06T17:43:17.057303Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-04-06T17:43:17.058370Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n^C2022-04-06T17:43:18.428485Z  INFO vector: Vector has quit.\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration File Example (After)\nDESCRIPTION: Demonstrates the improved configuration file structure using automatic namespacing, where files are categorized into 'sources', 'transforms', and 'sinks' subdirectories.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-implicit-namespacing.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n/etc/vector/\n└───sources/\n│   │   file001.toml\n│   │   ...\n│   │   file005.toml\n│\n└───transforms/\n│   │   file006.toml\n│   │   ...\n│   │   file016.toml\n│\n└───sinks/\n    │   file017.toml\n    │   file022.toml\n```\n\n----------------------------------------\n\nTITLE: serde_json Value Enum (Rust)\nDESCRIPTION: Shows the structure of the `serde_json::value::Value` enum for comparison to Vector's `Value` enum.  It includes variants for Null, Bool, Number, String, Array, and Object.  Requires the `serde_json` crate.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2692-more-usable-logevents.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n//! serde_json::value::Value\npub enum Value {\n    Null,\n    Bool(bool),\n    Number(Number),\n    String(String),\n    Array(Vec<Value>),\n    Object(Map<String, Value>),\n}\n```\n\n----------------------------------------\n\nTITLE: Including Generated Protobuf Code\nDESCRIPTION: This Rust code includes the generated Protobuf code using the `tonic::include_proto!` macro. The macro takes the package name defined in the Protobuf file as an argument.  This allows access to the generated service and message types within the Rust code. It requires tonic as a dependency.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-01-08-5843-encoding-decoding-format-vector.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n// this allows us to easily include code generated for package our_rpc from the .proto file\ntonic::include_proto!(\"our_rpc\");\n```\n\n----------------------------------------\n\nTITLE: Example Source Metadata (With Namespacing) JSON\nDESCRIPTION: This JSON shows the source metadata (`%datadog_agent`) of a log event from the `datadog_agent` source after log namespacing is enabled. The source metadata contains information provided by the data source, such as `ddsource`, `ddtags`, and `hostname`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"ddsource\": \"vector\",\n  \"ddtags\": \"env:prod\",\n  \"hostname\": \"alpha\",\n  \"service\": \"cernan\",\n  \"status\": \"warning\",\n  \"timestamp\": \"1970-02-14T20:44:57.570Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: VRL Infallible Division (New)\nDESCRIPTION: Shows the correct way to perform division by a literal nonzero number in `VRL` in Vector 0.20. Error handling is no longer required and will result in a compilation error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-0-20-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: coffeescript\nCODE:\n```\n.zorp = .spog / 43\n```\n\n----------------------------------------\n\nTITLE: Vector processing with stdin\nDESCRIPTION: This bash command demonstrates how to pipe data to Vector using stdin, with Vector configured via `test.toml` and running in quiet mode. The command pipes the string \"awk, sed the Vic\" to Vector and outputs the processed JSON to standard output.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-04-shutdown-vector-if-all-sources-finish.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbanana@tree:/$ echo \"awk, sed the Vic\" | vector --config test.toml --quiet\n{\"host\":\"tree\",\"message\":\"awk, sed the Vic\",\"source_type\":\"stdin\",\"timestamp\":\"2020-05-04T20:43:59.522211979Z\"}\n```\n\n----------------------------------------\n\nTITLE: Copy Init.d Service File\nDESCRIPTION: This command copies the Vector service file to the Init.d directory, enabling Vector to be managed as a service using Init.d.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ncp -av etc/init.d/vector /etc/init.d\n```\n\n----------------------------------------\n\nTITLE: Starting Vector Systemd Service (Deb Package)\nDESCRIPTION: This command starts the Vector systemd service without enabling it to run at system startup. The service will only run for the current session and will not start automatically on subsequent reboots.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsystemctl start vector\n```\n\n----------------------------------------\n\nTITLE: Lua: Function to create counter metric.\nDESCRIPTION: This Lua snippet defines a function, make_counter, that creates a metric event with the given value. This function is intended to reduce duplication between the timer handler and the shutdown hook.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/custom-aggregations-with-lua.md#_snippet_2\n\nLANGUAGE: lua\nCODE:\n```\nfunction make_counter(value)\n    return metric = {\n      name = \"event_counter\",\n      kind = \"incremental\",\n      timestamp = os.date(\"!*t\"),\n      counter = {\n        value = value\n      }\n    }\n  end\n```\n\n----------------------------------------\n\nTITLE: JSON Example Input for Explode Transform\nDESCRIPTION: This JSON object is an example input for an `explode` transform demonstrating an alternative approach. It contains an events array that the transform will process to generate multiple events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{ \"events\": [{ \"message\": \"foo\" }, { \"message\": \"bar\" }] }\n```\n\n----------------------------------------\n\nTITLE: Console Sink Configuration in TOML\nDESCRIPTION: Configures a console sink in TOML to read events emitted from a transform on a specific lane.  The `inputs` parameter specifies the transform and lane to listen to.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.example_console]\ntype = \"console\"\ninputs = [\"example_transform.example_lane\"] # would output the event from `example_lane`\nencoding.codec = \"text\"\n```\n\n----------------------------------------\n\nTITLE: Setting CONTAINER_TOOL for Podman\nDESCRIPTION: This optional step sets the `CONTAINER_TOOL` environment variable to `podman` if you prefer to use Podman instead of Docker. It is required if `podman` is your containerization tool of choice.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Optional: Only if you use `podman`\nexport CONTAINER_TOOL=\"podman\"\n```\n\n----------------------------------------\n\nTITLE: Build Vector (Windows)\nDESCRIPTION: This command builds Vector in release mode using Cargo, the Rust package manager. It sets the RUSTFLAGS environment variable to enable static linking and specifies the 'default-msvc' feature.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\nset RUSTFLAGS=-Ctarget-feature=+crt-static\ncargo build --no-default-features --features default-msvc --release\n```\n\n----------------------------------------\n\nTITLE: Template Literal to AST Conversion (Coffee)\nDESCRIPTION: This snippet showcases how the VRL parser will transform a template literal string into an Abstract Syntax Tree (AST) equivalent to string concatenation. This demonstrates the internal implementation detail of how string interpolation is handled.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\n\"The message is {{ message }} and we {{ feeling }} it\"\n```\n\nLANGUAGE: coffee\nCODE:\n```\n\"The message is \" +\nmessage +\n\" and we \" +\nfeeling +\n\" it\"\n```\n\n----------------------------------------\n\nTITLE: sprintf Example (Coffee)\nDESCRIPTION: This snippet shows how the `sprintf` function could be used for string formatting as an alternative to string interpolation. It takes a format string and parameters and formats the parameters according to the tags in the format string.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_4\n\nLANGUAGE: coffee\nCODE:\n```\nsprintf(\"The message is %s created at %t\", .message, .timestamp)\n```\n\nLANGUAGE: coffee\nCODE:\n```\nThe message is the message created at Tue, 27 Jul 2021 10:10:01 +0000\n```\n\n----------------------------------------\n\nTITLE: Migrating Lua Transform from v1 to v2\nDESCRIPTION: Shows how to upgrade a Lua transform configuration from version 1 to version 2, which includes changes to the `version` field and the structure of the Lua source code. Version 1 is deprecated and will be removed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: toml\nCODE:\n```\n[transform.example]\ntype = \"lua\"\nversion = 1\nsource = \"\"\"\n  event[\"a\"] = \"some value\"\n  event[\"b\"] = nil\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Running Vector v0.19.0 (Shell)\nDESCRIPTION: Executes Vector version 0.19.0 with a specified configuration file. The command initializes Vector with the provided config and captures standard input. This version is used as a baseline or comparison point.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n./vector-v0.19.0 -c config.toml\n```\n\n----------------------------------------\n\nTITLE: Running Unit Tests in Rust\nDESCRIPTION: This command executes all unit tests within the Vector project. Unit tests are characterized by their independence from external services, enabling rapid execution. The test must be defined in the corresponding rust code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ncargo test\n```\n\n----------------------------------------\n\nTITLE: Process Hook Definition in Lua\nDESCRIPTION: Defines the `process` hook function in Lua, which is called when a new event arrives at the transform. It takes two arguments: an incoming event and the `emit` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_13\n\nLANGUAGE: lua\nCODE:\n```\nfunction (event, emit)\n  -- ...\nend\n```\n\n----------------------------------------\n\nTITLE: Dynamic Field Assignment Example\nDESCRIPTION: Demonstrates how to dynamically assign fields using iteration. The `for_each` function iterates through an array, assigning the index of each value to a new field named after the value itself.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_52\n\nLANGUAGE: CoffeeScript\nCODE:\n```\nfor_each(.) |index, value| .\"{{value}}\" = index\n```\n\n----------------------------------------\n\nTITLE: Throttle Config Structure - Rust\nDESCRIPTION: Defines the configuration struct for the `throttle` transform. It includes parameters for setting the threshold, window, key template, and exclusion condition.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-09-21-9292-throttle-transform.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub struct ThrottleConfig {\n    threshold: u32, // Throttle only on number of events\n    window: f64,\n    key: Option<String>, // Template string\n    exclude: Option<AnyCondition>,\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector with vdev using cargo\nDESCRIPTION: This command runs Vector using the `vdev` build tool. It specifies the configuration file to be used for the Vector instance, which helps to detect and set relevant features.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\ncargo vdev run ./basic.yml\n```\n\n----------------------------------------\n\nTITLE: GraphQL EventNotification Type Old\nDESCRIPTION: This GraphQL snippet shows the old definition of the `EventNotification` type, which consisted of a `pattern` and an `EventNotificationType` enum. This structure was less extensible for new notification types.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: graphql\nCODE:\n```\ntype EventNotification {\n  pattern: String!\n  notification: EventNotificationType!\n}\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Query Executor Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics for the MongoDB query execution system, tracking the number of scanned and scanned_objects.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_14\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_query_executor_total queryExecutor is a document that reports data from the query execution system\n# TYPE mongodb_mongod_metrics_query_executor_total counter\nmongodb_mongod_metrics_query_executor_total{state=\"scanned\"} 0\nmongodb_mongod_metrics_query_executor_total{state=\"scanned_objects\"} 0\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Buffer Count Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus gauge metric representing the current number of operations in the oplog buffer during replication in MongoDB.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_19\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_buffer_count count reports the current number of operations in the oplog buffer\n# TYPE mongodb_mongod_metrics_repl_buffer_count gauge\nmongodb_mongod_metrics_repl_buffer_count 0\n```\n\n----------------------------------------\n\nTITLE: Rust: Compile Function Call with Error Propagation\nDESCRIPTION: This Rust code utilizes Rust's error propagation (`?`) to exit early if a nested expression should be ignored.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nfn compile_function_call(&mut self, node: Node<ast::FunctionCall>) -> Option<FunctionCall> {\n    // ...\n\n    // stop compiling the function if one of its arguments is invalid.\n    let arguments = arguments\n        .into_iter()\n        .map(|node| self.compile_function_argument(node))\n        .collect::<Option<_>>()?;\n\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: String Interpolation Syntax in VRL (Coffee)\nDESCRIPTION: This snippet demonstrates the basic syntax for string interpolation in VRL using double quotes and curly braces to embed variables. It shows how to escape curly braces and how raw strings can be used to disable templating.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\n\"foo {{bar}}\"\n```\n\nLANGUAGE: coffee\nCODE:\n```\n\"foo \\{{bar\\}}\"\n```\n\nLANGUAGE: coffee\nCODE:\n```\ns'foo {bar}'\n```\n\n----------------------------------------\n\nTITLE: Tapping Input Events of a Component\nDESCRIPTION: Runs `vector tap` to observe the input events of the `out` component (the `blackhole` sink). This allows users to monitor what's being sent to a specific component in the pipeline.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/vector-tap-guide.md#_snippet_5\n\nLANGUAGE: console\nCODE:\n```\nvector tap --inputs-of \"out\"\n```\n\n----------------------------------------\n\nTITLE: Remap Transform for Setting Default Values\nDESCRIPTION: This configures a `remap` transform to set a default value for a missing field. This is a workaround for Vector's lack of built-in fallback values in templates.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_7\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.set_defaults]\n  type = \"remap\"\n  inputs = [\"my-source-id\"]\n  source = '''\n    if !exists(.my_field) {\n      .my_field = \"default\"\n    }\n  '''\n```\n\n----------------------------------------\n\nTITLE: Internal Event Emission Example (with Macro)\nDESCRIPTION: This example shows how the emit macro can wrap the function call. The function is also wrapped in a macro which is conveniently imported everywhere in the main vector library.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nemit!(BytesSent {\n    byte_size: 12345,\n    protocol: \"https\",\n});\n```\n\n----------------------------------------\n\nTITLE: Create AWS CloudWatch Logs Log Group (bash)\nDESCRIPTION: Creates an AWS CloudWatch Logs log group and stream for ingesting logs and another group and stream for Firehose debugging purposes. It utilizes the AWS CLI to create the log group and stream using the environment variables defined earlier.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ aws logs create-log-group --log-group-name ${LOG_GROUP}\n```\n\nLANGUAGE: bash\nCODE:\n```\n$ aws logs create-log-group --log-group-name ${FIREHOSE_LOG_GROUP}\n$ aws logs create-log-stream \\\n    --log-group-name ${FIREHOSE_LOG_GROUP} \\\n    --log-stream-name ${FIREHOSE_LOG_STREAM}\n```\n\n----------------------------------------\n\nTITLE: Copying NATS Credentials (JWT)\nDESCRIPTION: This command creates a copy of the NATS credentials file to be used as 'bad' credentials.  The copy must then be modified to invalidate the credentials.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/tests/data/nats/README.md#_snippet_4\n\nLANGUAGE: Shell Session\nCODE:\n```\n# After that, we make a copy that will act as the \"bad\" credentials.\n#\n# You'll need to open the \"bad\" version and change one of the characters in the seed value in order to actually make them \"bad\". :)\n$ cp tests/data/nats/nats.creds tests/data/nats/nats-bad.creds\n```\n\n----------------------------------------\n\nTITLE: Example Vector Metadata (With Namespacing) JSON\nDESCRIPTION: This JSON shows the Vector metadata (`%vector`) of a log event after log namespacing is enabled. The Vector metadata contains information provided by Vector itself, such as `source_type` and `ingest_timestamp`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"source_type\": \"datadog_agent\",\n  \"ingest_timestamp\": \"1970-02-14T20:44:58.236Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: Reloading Vector Executable\nDESCRIPTION: Reloads the Vector executable by sending a SIGHUP signal to the process. This allows for configuration changes to be applied without a full restart.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nkillall -s SIGHUP vector\n```\n\n----------------------------------------\n\nTITLE: Creating a New Rust Library Module\nDESCRIPTION: Initializes a new Rust library project named `echo` using `cargo`. The `--lib` flag specifies that a library crate should be created, which is required for building a WASM module.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\ncargo init --lib echo\n```\n\n----------------------------------------\n\nTITLE: Renaming TCP sink to Socket sink - TOML\nDESCRIPTION: This code snippet demonstrates how to rename the `tcp` sink to `socket` in a Vector `vector.toml` configuration file. It also shows how to add the `mode = \"tcp\"` option.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-03-move-existing-tcp-sink-into-socket-sink.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_tcp_sink]\n-  type = \"tcp\"\n+  type = \"socket\"\n   address = \"92.12.333.224:5000\"\n+  mode = \"tcp\"\n```\n\n----------------------------------------\n\nTITLE: Set Perl Path (Windows)\nDESCRIPTION: This command adds the Perl binary directory to the system's PATH environment variable. This is necessary for Vector to find Perl during the build process. This command is executed in the context of a Rust/MSVC environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_6\n\nLANGUAGE: powershell\nCODE:\n```\nset PATH=%PATH%;C:\\Strawberry\\perl\\bin\n```\n\n----------------------------------------\n\nTITLE: Deleting metric tag using Remap language in Coffeescript\nDESCRIPTION: This snippet demonstrates how to delete a tag from a metric's metadata using the Remap language. It uses the `del` function to remove the tag \"host\" from the `.tags` map.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-01-remap-metrics-support.md#_snippet_1\n\nLANGUAGE: coffeescript\nCODE:\n```\ndel(.tags.host)\n```\n\n----------------------------------------\n\nTITLE: Starting Vector on Windows\nDESCRIPTION: Starts the Vector executable on Windows with a specified configuration file. This assumes Vector was installed in the default Program Files directory and the configuration file is in TOML or JSON format.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_10\n\nLANGUAGE: powershell\nCODE:\n```\nC:\\Program Files\\Vector\\bin\\vector \\\n  --config C:\\Program Files\\Vector\\config\\vector.yaml\n\n# Or supply a TOML or JSON config file\n```\n\n----------------------------------------\n\nTITLE: Add Vector APT Repository\nDESCRIPTION: Adds the Vector package repository to the system's APT configuration. This allows the system to find and install the Vector package from the Datadog-provided repository. The command downloads and executes a script from `https://setup.vector.dev`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/apt.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nbash -c \"$(curl -L https://setup.vector.dev)\"\n```\n\n----------------------------------------\n\nTITLE: Datadog Logs Source Renaming (Diff)\nDESCRIPTION: This diff snippet illustrates how to rename the `datadog_logs` source to `datadog_agent` in the Vector configuration, which is a breaking change introduced in Vector 0.16.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-25-0-16-upgrade-guide.md#_snippet_3\n\nLANGUAGE: diff\nCODE:\n```\n[sources.datadog]\n-type = \"datadog_logs\"\n+type = \"datadog_agent\"\naddress = \"0.0.0.0:8080\"\nstore_api_key = true\n```\n\n----------------------------------------\n\nTITLE: Expression Trait Definition (Initial)\nDESCRIPTION: Defines the initial `Expression` trait with the `execute` function. This function is used to execute the expression and return a `Value`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\npub trait Expression: Send + Sync {\n    fn execute(&self, state: &mut State, object: &mut dyn Object) -> Result<Option<Value>>;\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats GC Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes used for garbage collection system metadata in Go. This is runtime memory overhead.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_45\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.\n# TYPE go_memstats_gc_sys_bytes gauge\ngo_memstats_gc_sys_bytes 3.57812e+06\n```\n\n----------------------------------------\n\nTITLE: Go Memstats GC CPU Fraction Metric - Prometheus\nDESCRIPTION: This snippet shows the fraction of CPU time used by the garbage collector in the Go program. This is a key indicator of garbage collection overhead.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_44\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_gc_cpu_fraction The fraction of this program's available CPU time used by the GC since the program started.\n# TYPE go_memstats_gc_cpu_fraction gauge\ngo_memstats_gc_cpu_fraction 0.005923686998994504\n```\n\n----------------------------------------\n\nTITLE: Install Vector with Kustomize (kubectl)\nDESCRIPTION: This command applies the Kubernetes resources defined in the current directory using Kustomize.  It deploys Vector based on the configuration specified in the 'kustomization.yaml' file. Prerequisites include a correctly configured kustomization file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkubectl apply -k .\n```\n\n----------------------------------------\n\nTITLE: Configuring Vector Sink with Disk Buffer\nDESCRIPTION: This TOML configuration shows how to configure a Vector sink to use the original disk buffer implementation. It sets the `buffer.type` to `disk`, indicating that data should be buffered on disk.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-disk-buffer-v2-beta.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.http]\n# ...\nbuffer.type = \"disk\"\n```\n\n----------------------------------------\n\nTITLE: Prometheus HTTP Handler Requests In Flight - Prometheus\nDESCRIPTION: This snippet shows the current number of scrapes being served by the Prometheus HTTP handler. This helps in monitoring the load on the Prometheus endpoint itself.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_35\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.\n# TYPE promhttp_metric_handler_requests_in_flight gauge\npromhttp_metric_handler_requests_in_flight 1\n```\n\n----------------------------------------\n\nTITLE: Setting Datadog API Key (New)\nDESCRIPTION: This snippet demonstrates the new recommended way to set secrets using the `set_secret` function. This provides secure storage for arbitrary secrets.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-06-07-vrl-metadata-and-secrets.md#_snippet_1\n\nLANGUAGE: coffeescript\nCODE:\n```\nset_secret(\"datadog_api_key\", \"my secret key\")\n```\n\n----------------------------------------\n\nTITLE: VRL Assertions with Variables Example (TOML)\nDESCRIPTION: This snippet shows how to store a boolean expression in a variable and then use that variable in a VRL assert statement in a Vector unit test.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\nsource = '''\nmessage_field_valid = exists(.message) &&\n  !is_nullish(.message) &&\n  .message == \"success\"\n\nassert!(message_field_valid)\n'''\n```\n\n----------------------------------------\n\nTITLE: Install Vector via Script\nDESCRIPTION: This command downloads and executes the Vector installation script, providing a quick way to install Vector on your system. It uses curl to fetch the script and bash to execute it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/getting-started/getting-started.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSfL https://sh.vector.dev | bash\n```\n\n----------------------------------------\n\nTITLE: VRL Boolean Expression Example (TOML)\nDESCRIPTION: This snippet shows how to use a VRL boolean expression within a Vector unit test to verify the existence and type of specific fields in a log event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert!(is_string(.message) && is_timestamp(.timestamp) && !exists(.other))\n'''\n```\n\n----------------------------------------\n\nTITLE: Pipeline struct definition with EventVec dequeue in Rust\nDESCRIPTION: This code snippet shows the modified `Pipeline` struct, which now includes a `VecDeque` of `EventVec` instead of `Event`. This change allows the pipeline to handle arrays of events, improving performance by processing multiple events at once.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-22-9480-processing-arrays-of-events.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\npub struct Pipeline {\n    inner: mpsc::Sender<Event>,\n    // We really just keep this around in case we need to rebuild.\n    #[derivative(Debug = \"ignore\")]\n    inlines: Vec<Box<dyn FunctionTransform>>,\n    enqueued: VecDeque<EventVec>,\n}\n```\n\n----------------------------------------\n\nTITLE: Updating FunctionCall Expression - Rust\nDESCRIPTION: This code shows the updated `FunctionCall` and `FunctionClosure` structs in the compiler.  A closure field is added to the `FunctionCall` struct.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_35\n\nLANGUAGE: rust\nCODE:\n```\npub struct FunctionCall {\n    expr: Box<dyn Expression>,\n    abort_on_error: bool,\n    maybe_fallible_arguments: bool,\n\n    // new addition\n    closure: Option<FunctionClosure>,\n}\n\npub struct FunctionClosure {\n    variables: Vec<dyn Expression>,\n    block: Block,\n}\n```\n\n----------------------------------------\n\nTITLE: Defining an Internal Metrics Source in Vector\nDESCRIPTION: This snippet defines an internal metrics source in Vector, named `internal_metrics`. It scrapes internal metrics every 10 seconds. This source allows Vector to collect data about its own performance and operation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_14\n\nLANGUAGE: yaml\nCODE:\n```\ninternal_metrics:\n    type: internal_metrics\n    scrape_interval_secs: 10\n```\n\n----------------------------------------\n\nTITLE: Result of Template Expansion\nDESCRIPTION: This shows the expected result of expanding the `key_prefix` option using the provided example log event.  It demonstrates how the `{{ application_id }}` and `%F` specifiers are replaced with values from the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_2\n\nLANGUAGE: raw\nCODE:\n```\napplication_id=1/date=2020-02-14\n```\n\n----------------------------------------\n\nTITLE: Emitting BytesSent Internal Event (diff)\nDESCRIPTION: This diff snippet demonstrates how to emit a `BytesSent` internal event to track the number of bytes sent by the sink. A `BytesSent` event is registered with the protocol as \"console\". The number of bytes is calculated, then a `ByteSize` event is emitted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_10\n\nLANGUAGE: diff\nCODE:\n```\n    async fn run_inner(self: Box<Self>, mut input: BoxStream<'_, Event>) -> Result<(), ()> {\n+       let bytes_sent = register!(BytesSent::from(Protocol(\"console\".into(),)));\n\n        while let Some(mut event) = input.next().await {\n+           let bytes = format!(\"{:#?}\", event);\n+           println!(\"{}\", bytes);\n-           println!(\"{:#?}\", event);\n+           bytes_sent.emit(ByteSize(bytes.len()));\n\n            let finalizers = event.take_finalizers();\n            finalizers.update_status(EventStatus::Delivered);\n        }\n\n        Ok(())\n    }\n```\n\n----------------------------------------\n\nTITLE: Example Log Data (Repeated)\nDESCRIPTION: This JSON snippet repeats the example log entry, including timestamp, stream, and the log message itself. It serves as input for further VRL examples illustrating error handling.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"time\":\"2021-02-03T21:13:54.713161211Z\",\n  \"stream\": \"stdout\",\n  \"log\": \"5.86.210.12 - zieme4647 [03/Feb/2021:21:13:55 -0200] \\\"GET /embrace/supply-chains/dynamic/vertical HTTP/1.0\\\" 201 20574\"\n}\n```\n\n----------------------------------------\n\nTITLE: Defining the VRL VM Struct in Rust\nDESCRIPTION: This code defines the `Vm` struct in Rust, which represents the virtual machine that will execute the VRL bytecode. The struct contains fields for storing instructions, constants, target variables, the stack, parameter stack, errors, and the instruction pointer.  This structure holds the state of the VRL execution.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-12-9811-vrl-vm.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Clone, Debug, Default)]\npub struct Vm {\n    instructions: Vec<Instruction>,\n    constants: Vec<Literal>,\n    targets: Vec<Variable>,\n    stack: Vec<Value>,\n    parameter_stack: Vec<Option<Value>>,\n    error: Option<Error>,\n    instruction_pointer: usize,\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector v0.19.1 with Configuration\nDESCRIPTION: This shell command executes Vector version 0.19.1 with a specified configuration file. The command starts Vector using the 'vector-v0.19.1' executable and loads configurations from 'config.toml'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n./vector-v0.19.1 --config config.toml\n```\n\n----------------------------------------\n\nTITLE: Listing Cargo Features\nDESCRIPTION: This shell command uses `cargo read-manifest`, `jq`, and `wc -l` to list the features defined in the `Cargo.toml` file of the Vector project. It parses the JSON output from `cargo read-manifest`, extracts the keys from the 'features' object using `jq`, and then counts the number of keys using `wc -l`. This provides a count of the top-level features enabled in the project.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-13-7027-core-extraction.md#_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\n> cargo read-manifest | jq \".features\" | jq 'keys' | wc -l\n```\n\n----------------------------------------\n\nTITLE: Socket Source GELF Configuration (Previous) - YAML\nDESCRIPTION: This YAML configuration shows the previous setup for a socket source using the GELF codec without explicit framing settings. It is provided as a reference for understanding the breaking change in Vector 0.40.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\nsources:\n  my_source_id:\n    type: \"socket\"\n    address: \"0.0.0.0:9000\"\n    mode: \"tcp\"\n    decoding:\n      codec: \"gelf\"\n```\n\n----------------------------------------\n\nTITLE: Create Kubernetes Namespace for Vector (kubectl)\nDESCRIPTION: This command creates a Kubernetes namespace named 'vector'. The '--dry-run=client -o yaml' flags are used to generate the YAML configuration without actually creating the namespace. The output is then redirected to a file named 'namespace.yaml'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create namespace --dry-run=client -o yaml vector > namespace.yaml\n```\n\n----------------------------------------\n\nTITLE: Checking Component Docs\nDESCRIPTION: This command ensures that the generated docs for each component are up to date. It runs `make check-component-docs` to perform the check. This ensures that the component documentation stays in sync with the code.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\nmake check-component-docs\n```\n\n----------------------------------------\n\nTITLE: Find Match Against List of Regex VRL\nDESCRIPTION: This VRL snippet attempts to match a message against a list of regular expressions. It iterates through the `patterns` array, and if `match(.message, pattern)` returns true for a specific pattern, the flag `matched` is set to true to prevent further attempts.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_15\n\nLANGUAGE: coffee\nCODE:\n```\nmatched = false\nfor_each(patterns) -> |pattern| {\n  if !matched && match(.message, pattern) {\n    matched = true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Humio Metrics Sink Encoding Configuration (TOML)\nDESCRIPTION: This TOML configuration shows the removed `encoding.codec` option from the `humio_metrics` sink.  The `humio_metrics` sink now always sends metrics in JSON format, so this option is no longer needed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Define Field with Multiple Types in Rust\nDESCRIPTION: This code snippet demonstrates how to define a field that can be either a string or an integer using `or_integer()`. This allows the field to hold either type of value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_19\n\nLANGUAGE: rust\nCODE:\n```\nKind::bytes().or_integer()\n```\n\n----------------------------------------\n\nTITLE: Running Vector in Release Mode (Shell)\nDESCRIPTION: This command runs Vector in release mode with a specified configuration file. The `--release` flag optimizes the build for performance, and `--config` specifies the configuration file to use.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_16\n\nLANGUAGE: sh\nCODE:\n```\ncargo run --release -- --config my_test_config.toml\n```\n\n----------------------------------------\n\nTITLE: Pipeline Structure - Rust\nDESCRIPTION: Defines the overall structure of a pipeline, containing the pipeline ID and a map of transform names to their corresponding PipelineTransform structures. This structure represents a pipeline before the topology is built.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\nstruct Pipeline {\n  id: String,\n  transforms: Map<String, PipelineTransform>,\n}\n```\n\n----------------------------------------\n\nTITLE: Transforming grok_parser with remap\nDESCRIPTION: Replacing the `grok_parser` transform with the `remap` transform. Parses messages using Grok patterns.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_12\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.grok_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= parse_grok!(.message, \"%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}\")\n.timestamp = parse_timestamp!(.timestamp , format: \"%+\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Replacing VRL modulo operator\nDESCRIPTION: Demonstrates how to replace the deprecated modulo operator (%) with the mod() function in Vector's VRL. This change is necessary for upgrading to version 0.25.0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-10-04-0-25-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\n5 % 2 == 1\n```\n\n----------------------------------------\n\nTITLE: Running Vector Fix (Shell)\nDESCRIPTION: Executes the 'vector-fix' binary with a configuration file. This likely represents a version of Vector with a bug fix applied. The intent is to compare its behavior to the standard releases.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n./vector-fix -c config.toml\n```\n\n----------------------------------------\n\nTITLE: De-indexing pages in YAML\nDESCRIPTION: This YAML snippet shows how to prevent a page from being indexed by adding the `noindex: true` to the page's metadata.  This will exclude the page from search indexing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_0\n\nLANGUAGE: YAML\nCODE:\n```\n---\ntitle: Don't index me, bro\nnoindex: true\n---\n```\n\n----------------------------------------\n\nTITLE: Install Vector using installation script (Shell)\nDESCRIPTION: This command downloads and executes the Vector installation script from the official website using curl. It ensures a secure connection via HTTPS and TLS v1.2.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSfL https://sh.vector.dev | bash\n```\n\n----------------------------------------\n\nTITLE: Shutdown Hook Definition in Lua\nDESCRIPTION: Defines the `shutdown` hook function in Lua, which is called when the transform is destroyed, such as on Vector's shutdown.  It takes the `emit` function as an argument.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_12\n\nLANGUAGE: lua\nCODE:\n```\nfunction (emit)\n  -- ...\nend\n```\n\n----------------------------------------\n\nTITLE: Tailing Vector Logs (Systemd)\nDESCRIPTION: This command uses `journalctl` to tail the Vector logs when Vector is managed by Systemd.  It provides a real-time view of the logs and requires `sudo` privileges and the systemd journal to be configured correctly.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo journalctl -fu vector\n```\n\n----------------------------------------\n\nTITLE: Timer Function Definition in Lua\nDESCRIPTION: Defines a timer function in Lua, which is called at predefined time intervals.  It takes the `emit` function as an argument, allowing the timer to produce new events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_14\n\nLANGUAGE: lua\nCODE:\n```\nfunction (emit)\n  -- ...\nend\n```\n\n----------------------------------------\n\nTITLE: Compile Vector (Linux)\nDESCRIPTION: This command compiles Vector from source code using the 'make' utility. The optional 'FEATURES' environment variable can be used to specify which features to include in the build.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\n[FEATURES=\"<flag1>,<flag2>,...\"] make build\n```\n\n----------------------------------------\n\nTITLE: Go Info Metric - Prometheus\nDESCRIPTION: This snippet provides information about the Go environment, including the Go version.  This allows for tracking versions of go across multiple deployments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_39\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_info Information about the Go environment.\n# TYPE go_info gauge\ngo_info{version=\"go1.14.5\"} 1\n```\n\n----------------------------------------\n\nTITLE: Generating Code Documentation\nDESCRIPTION: This command generates the code documentation for the Vector project. It changes the directory to `rust-doc` and then runs `make docs`. This ensures that the docs can be generated without errors (warnings are acceptable).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\ncd rust-doc && make docs\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Executor Event Waiters Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus gauge metric for the number of event waiters in the MongoDB replication executor.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_22\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_executor_event_waiters number of event waiters in the replication executor\n# TYPE mongodb_mongod_metrics_repl_executor_event_waiters gauge\nmongodb_mongod_metrics_repl_executor_event_waiters 0\n```\n\n----------------------------------------\n\nTITLE: Upgrading Vector with Nix\nDESCRIPTION: This command upgrades the Vector package using Nix. It fetches the latest package definitions and upgrades Vector to the newest version. This assumes Vector was previously installed with Nix.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/nix.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nnix-env --upgrade vector \\\n  --file https://github.com/NixOS/nixpkgs/archive/master.tar.gz\n```\n\n----------------------------------------\n\nTITLE: Upgrade Vector Package via APT\nDESCRIPTION: Upgrades the `vector` package to the latest available version using the APT package manager. This command will download and install the newer version while keeping the configuration files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/apt.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt-get upgrade vector\n```\n\n----------------------------------------\n\nTITLE: JSON Example Output After Explode Transform (with Mapping)\nDESCRIPTION: This JSON represents the output for the previous TOML configuration with the explode transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_14\n\nLANGUAGE: json\nCODE:\n```\n{\"host\": \"foobar\", \"message\": \"foo\"}\n{\"host\": \"foobar\", \"message\": \"bar\"}\n```\n\n----------------------------------------\n\nTITLE: VRL Program with Typo\nDESCRIPTION: This VRL program contains a typo in the `to_strng` function call, which leads to an incorrect error message about the type of the `foo` variable in the `upcase` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\nfoo = to_strng(15)\nupcase(foo)\n```\n\n----------------------------------------\n\nTITLE: Optimize Vector with PGO using cargo-pgo\nDESCRIPTION: This command builds Vector with PGO optimization using the profile data collected from the instrumented version. The compiler uses this data to optimize code paths frequently executed during runtime.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/tuning/pgo.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\ncargo pgo optimize\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Lookups Total Metric - Prometheus\nDESCRIPTION: This snippet represents the total number of pointer lookups performed by the Go program. This provides an insight into runtime behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_53\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_lookups_total Total number of pointer lookups.\n# TYPE go_memstats_lookups_total counter\ngo_memstats_lookups_total 0\n```\n\n----------------------------------------\n\nTITLE: Upgrading Vector using Homebrew\nDESCRIPTION: This command updates the Homebrew package list and upgrades the Vector package to the latest version. It ensures that users are running the most recent version of Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/homebrew.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nbrew update && brew upgrade vector\n```\n\n----------------------------------------\n\nTITLE: Emitting Function Definition in Lua\nDESCRIPTION: Defines the emitting function in Lua, which can be passed to a hook or timer. It takes an encoded event and an optional lane parameter.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_15\n\nLANGUAGE: lua\nCODE:\n```\nfunction (event, lane)\n  -- ...\nend\n```\n\n----------------------------------------\n\nTITLE: Running Vector Top Command\nDESCRIPTION: This command is used to display the topology and metrics of the Vector instance in the console. It allows inspecting the number of events produced by sources and how many reach the sinks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nvector top\n```\n\n----------------------------------------\n\nTITLE: VRL If Statement Predicate Error Handling Fixed\nDESCRIPTION: Shows the corrected `VRL` code to handle potential errors in an `if` statement predicate using the nullish coalescing operator (`??`).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-02-08-0-20-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: coffeescript\nCODE:\n```\nif contains(.message, \"true\") ?? false {\n  log(\"true\")\n}\n```\n\n----------------------------------------\n\nTITLE: Deploy Vector with Kustomize\nDESCRIPTION: This shell command deploys Vector to a Kubernetes cluster using Kustomize. It builds the Kubernetes manifests from the `kustomization.yaml` file and applies them using `kubectl`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-04-2221-kubernetes-integration.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nkustomize build . | kubectl apply -f -\n```\n\n----------------------------------------\n\nTITLE: Rust: Compile Function Call (Initial)\nDESCRIPTION: This is the initial Rust code for compiling a function call, where errors are tracked by pushing to a `self.errors` array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nfn compile_function_call(&mut self, node: ast::FunctionCall) -> FunctionCall {\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector PR Build with Configuration\nDESCRIPTION: This shell command executes a Vector Pull Request build with a specified configuration file. The command starts Vector using the 'vector-pr' executable and loads configurations from 'config.toml'.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n./vector-pr --config config.toml\n```\n\n----------------------------------------\n\nTITLE: Clone Vector Repository (Latest, Windows)\nDESCRIPTION: These commands clone the Vector repository from GitHub and check out the latest version using `git`.  The user must have Git installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/vectordotdev/vector\ngit checkout v{{< version >}}\ncd vector\n```\n\n----------------------------------------\n\nTITLE: Transforming coercer with remap\nDESCRIPTION: Replacing the `coercer` transform with the `remap` transform.  Coerces types of fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_10\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.coercer]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\n.some_bool = to_bool!(.some_bool)\n.some_float = to_float!(.some_float)\n.some_int = to_int!(.some_int)\n.some_string = to_string!(.some_string)\n.some_timestamp = to_timestamp!(.some_timestamp)\n'''\n```\n\n----------------------------------------\n\nTITLE: Metric Event Input (TOML)\nDESCRIPTION: This configuration shows how to specify a metric event as input to a Vector unit test. It defines the metric name, kind, and counter value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_16\n\nLANGUAGE: toml\nCODE:\n```\n[[tests.inputs]]\ninsert_at = \"my_metric_transform\"\ntype = \"metric\"\n\n[tests.inputs.metric]\nname = \"count\"\nkind = \"absolute\"\ncounter = { value = 1 }\n```\n\n----------------------------------------\n\nTITLE: Run Vector with configuration (Shell)\nDESCRIPTION: This command executes the Vector process, using the configuration file. Vector will process configured sources, transforms and send data to specified sinks based on the configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/quickstart.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nvector\n```\n\n----------------------------------------\n\nTITLE: Transforming aws_cloudwatch_logs_subscription_parser with remap\nDESCRIPTION: Replacing the `aws_cloudwatch_logs_subscription_parser` transform with the `remap` transform. Parses AWS CloudWatch Logs subscription messages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_9\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.aws_cloudwatch_logs_subscription_parser]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n. |= parse_aws_cloudwatch_log_subscription_message!(.message)\n'''\n```\n\n----------------------------------------\n\nTITLE: Example JSON Output\nDESCRIPTION: This JSON output represents the initial state of the log events after being processed by the basic Vector pipeline. The `message` field contains the raw CSV log line, which will be parsed in subsequent steps. The other standard fields like file, host and timestamp are also included.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_2\n\nLANGUAGE: JSON\nCODE:\n```\n{\"file\":\"log.csv\",\"host\":\"localhost\",\"message\":\"2020-04-09 12:48:49.661 UTC,,,1,,localhost.1,1,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\\\"ending log output to stderr\\\",,\\\"Future log output will go to log destination \\\"\\\"csvlog\\\"\\\".\\\",,,,,,,\\\"\\\"\",\"timestamp\":\"2020-04-09T14:33:28Z\"}\n{\"file\":\"log.csv\",\"host\":\"localhost\",\"message\":\"2020-04-09 12:48:49.669 UTC,,,27,,localhost.1b,1,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\\\"database system was shut down at 2020-04-09 12:48:25 UTC\\\",,,,,,,,,\\\"\\\"\",\"timestamp\":\"2020-04-09T14:33:28Z\"}\n{\"file\":\"log.csv\",\"host\":\"localhost\",\"message\":\"2020-04-09 12:48:49.683 UTC,,,1,,localhost.1,2,,2020-04-09 12:48:49 UTC,,0,LOG,00000,\\\"database system is ready to accept connections\\\",,,,,,,,,\\\"\\\"\",\"timestamp\":\"2020-04-09T14:33:28Z\"}\n```\n\n----------------------------------------\n\nTITLE: Structured Log Event Input with hyphens (YAML)\nDESCRIPTION: This snippet shows how to specify a structured log event as input to a Vector unit test in YAML, including fields with hyphens in their names.  Fields with hyphens require quoting in YAML.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_13\n\nLANGUAGE: yaml\nCODE:\n```\n  - name: hyphens\n    inputs:\n      - insert_at: hyphens\n        type: log\n        log_fields:\n          labels.\"this-has-hyphens\": \"this is a test\"\n```\n\n----------------------------------------\n\nTITLE: Nginx Metrics Source Configuration Example\nDESCRIPTION: This TOML configuration example demonstrates how users will configure the new `nginx_metrics` source in Vector. It showcases the required `type` and `endpoints` options, as well as optional settings such as `scrape_interval_secs` and `namespace`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3640-nginx-metrics-source.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"nginx_metrics\" # required\n  endpoints = [\"http://localhost/basic_status\"] # required, default\n  scrape_interval_secs = 15 # optional, default, seconds\n  namespace = \"nginx\" # optional, default, namespace to put metrics under\n```\n\n----------------------------------------\n\nTITLE: VRL Remainder Operator After (Error Handling)\nDESCRIPTION: This VRL snippet demonstrates how to handle potential division by zero errors when using the remainder operator (%) by providing a default value if the divisor is zero.  This prevents Vector from panicking.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_8\n\nLANGUAGE: coffee\nCODE:\n```\n.remainder = 50 % .value ?? 0\n```\n\n----------------------------------------\n\nTITLE: Subset of Chained Transforms Unit Test (TOML)\nDESCRIPTION: This example demonstrates how to test a subset of a chain of transforms. It tests the first two transforms (`add_env_metadata` and `sanitize`) and extracts the output from the second transform. The VRL assertions are adjusted to reflect the state of the event after the second transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_20\n\nLANGUAGE: toml\nCODE:\n```\n[[tests]]\nname = \"First two transforms\"\n\n[[tests.inputs]]\ntype = \"log\"\ninsert_at = \"add_env_metadata\"\n\n[tests.inputs.log_fields]\nmessage = \"image successfully uploaded\"\ncode = 202\nusername = \"tonydanza1337\"\nemail = \"tony@whostheboss.com\"\ntransaction_id = \"bcef6a6a-2b72-4a9a-99a0-97ae89d82815\"\n\n[[tests.outputs]]\nextract_from = \"sanitize\"\n\n[[tests.outputs.conditions]]\ntype = \"vrl\"\nsource = '''\nassert_eq!(.tags.environment, \"production\", \"incorrect environment tag\")\nassert!(!exists(.tags.host), \"host tag included\")\nassert!(!exists(.username))\nassert!(!exists(.email))\n\nvalid_transaction_id = exists(.transaction_id) &&\n  is_string(.transaction_id) &&\n  length!(.transaction_id) == 36\n\nassert!(valid_transaction_id, \"transaction ID invalid\")\n'''\n```\n\n----------------------------------------\n\nTITLE: Install Vector via script\nDESCRIPTION: This script downloads and executes the Vector installation script from sh.vector.dev, automatically accepting the defaults for installation. It's the recommended way to provision the most up-to-date stable version of Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-09-add-musl-and-glibc-support-to-install-sh.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSfL https://sh.vector.dev | bash -s -- -y\n```\n\n----------------------------------------\n\nTITLE: Run Vector Top CLI\nDESCRIPTION: This command runs the `vector top` command-line tool and specifies the URL of the Vector instance to monitor. The tool interacts with the Vector instance's GraphQL API to display metrics and topology information in a dashboard-style interface.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-23-vector-top.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector top --url https://my-vector-instance.prod.acmecorp.biz\n```\n\n----------------------------------------\n\nTITLE: Example JSON After IP Alert Enrichment\nDESCRIPTION: This JSON represents the output data after enrichment for the IP alert use case. An 'alert' field has been added, containing the 'type' and 'severity' of the alert as retrieved from the 'ip_info' enrichment table, based on the original IP address.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/csv-enrichment-guide.md#_snippet_6\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"host\":\"my.host.com\",\n  \"timestamp\":\"2019-11-01T21:15:47+00:00\",\n  ...\n  \"alert\": {\n    \"type\":\"alert\",\n    \"severity\":\"medium\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Diff showing Journald Unit Configuration Changes\nDESCRIPTION: This diff highlights the changes required in the `vector.toml` file to utilize the `exclude_units` option for the journald source. It shows the removal of the old `units` option and the addition of both `exclude_units` and `include_units` options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-05-05-add-support-for-include-exclude-units.md#_snippet_1\n\nLANGUAGE: Diff\nCODE:\n```\n  [sources.my_source_id]\n    type = \"journald\" # required\n    current_boot_only = true # optional, default\n-    units = [\"sshd\", \"ircd\"]\n+    exclude_units = [\"zulip\"] # optional, default\n+    include_units = [\"sshd\", \"ircd\"] # optional, default\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Wrong HTTP Config (Second Run)\nDESCRIPTION: This snippet executes Vector again with a configuration that points to an incorrect HTTP endpoint using `vector-pr`. This simulates running the new version of Vector. It pipes the content of `five-lines-second` to Vector and also sets various log levels via the `VECTOR_LOG` environment variable. The expected output is Vector attempting to send data to the incorrect endpoint again, triggering a migration from disk_v1 to disk_v2 buffers and failing HTTP requests.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-second | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-pr -c ./config-wrong-http.toml\n2022-04-06T05:04:24.925006Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\"\n2022-04-06T05:04:24.925046Z  INFO vector::app: Loading configs. paths=[\"config-wrong-http.toml\"]\n2022-04-06T05:04:24.925725Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-04-06T05:04:24.954258Z  INFO vector_buffers::variants::disk_v2::v1_migration: Detected old `disk_v1`-based buffer for the `http_tarpit` sink. Automatically migrating to `disk_v2`.\n2022-04-06T05:04:24.954512Z  INFO vector_buffers::variants::disk_v2::v1_migration: Migrated 5 records in disk buffer for `http_tarpit` sink. Old disk buffer at '/tmp/vector/github-12069/http_tarpit_id' has been deleted, and the new disk buffer has been created at '/tmp/vector/github-12069/buffer/v2/http_tarpit'.\n2022-04-06T05:04:24.965194Z  INFO vector::topology::running: Running healthchecks.\n2022-04-06T05:04:24.965227Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-04-06T05:04:24.965266Z  INFO vector: Vector has started. debug=\"false\" version=\"0.21.0\" arch=\"x86_64\" build_id=\"none\"\n2022-04-06T05:04:24.965360Z  INFO vector::shutdown: All sources have finished.\n2022-04-06T05:04:24.965366Z  INFO vector: Vector has stopped.\n2022-04-06T05:04:24.965390Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-04-06T05:04:24.966574Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-04-06T05:04:25.967353Z ERROR sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}:http: vector::internal_events::http_client: HTTP error. error=error trying to connect: tcp connect error: Connection refused (os error 111) error_type=\"request_failed\" stage=\"processing\"\n...\n2022-04-06T05:04:27.970443Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-04-06T05:04:28.341582Z  INFO vector: Vector has quit.\ntoby@consigliere:~/src/vector/testing/github-12069$ ls -l /tmp/vector/github-12069/\ntotal 4\ndrwxrwxr-x 3 toby toby 4096 Apr  6 01:04 buffer\n```\n\n----------------------------------------\n\nTITLE: CloudWatch Metrics Output Format (Prometheus)\nDESCRIPTION: Illustrates the expected output format of the `aws_cloudwatch_metrics` source when metrics are published.  The output is in Prometheus format, showing how metric names, statistics, dimensions, and region tags are structured. It presents a sample output with several metrics.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-28-cloudwatch-metrics.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\naws_ec2_cpu_credit_balance_average{instance_id=\"i-0db9620c0ee32d463\",region=\"us-east-1\"} 576\naws_ec2_cpu_credit_balance_maximum{instance_id=\"i-0db9620c0ee32d463\",region=\"us-east-1\"} 576\naws_ec2_cpu_credit_balance_minimum{instance_id=\"i-0db9620c0ee32d463\",region=\"us-east-1\"} 576\naws_ec2_cpu_credit_balance_sample_count{instance_id=\"i-0db9620c0ee32d463\",region=\"us-east-1\"} 1\naws_ec2_cpu_credit_balance_sum{instance_id=\"i-0db9620c0ee32d463\",region=\"us-east-1\"} 576\n```\n\n----------------------------------------\n\nTITLE: Simplified Sink Configuration (After)\nDESCRIPTION: Illustrates the simplified TOML configuration for a sink after automatic namespacing, where the component type and ID are inferred from the directory structure and filename.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-implicit-namespacing.md#_snippet_3\n\nLANGUAGE: toml\nCODE:\n```\n# /etc/vector/sinks/file017.toml\ntype = \"anything\"\n```\n\n----------------------------------------\n\nTITLE: Update and install Vector via APT (Shell)\nDESCRIPTION: These commands update the local APT repository and install the Vector package from the configured repository. It ensures the system is using the latest package list and installs the Vector application.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nsudo apt-get update\nsudo apt-get install vector\n```\n\n----------------------------------------\n\nTITLE: Enabling Vector Systemd Service (Deb Package)\nDESCRIPTION: This command enables and starts the Vector systemd service after configuring it according to your requirements. This ensures that the service starts automatically on system startup.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsystemctl enable --now vector\n```\n\n----------------------------------------\n\nTITLE: Transforming ansi_stripper with remap\nDESCRIPTION: Replacing the `ansi_stripper` transform with the `remap` transform. Strips ANSI escape codes from a message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.ansi_stripper]\ntype = \"remap\"\ninputs = [\"some_input\"]\ndrop_on_error = false\nsource = '''\n.message = strip_ansi_escape_codes(string!(.message))\n'''\n```\n\n----------------------------------------\n\nTITLE: Retrieving Schema Definition from Decoder in Rust\nDESCRIPTION: This retrieves the initial schema definition from the source's decoder based on the log namespace.  This is used as the basis for the final schema.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_10\n\nLANGUAGE: rust\nCODE:\n```\n  let schema_definition = self\n      .decoding\n      .schema_definition(log_namespace)\n```\n\n----------------------------------------\n\nTITLE: Configuring Prometheus Scrape Source in Vector TOML\nDESCRIPTION: This snippet shows how to configure the `prometheus_scrape` source in Vector using TOML. It specifies the source type, target hosts, and scrape interval.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-07-prometheus-source.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.my_source_id]\n  type = \"prometheus_scrape\"\n  hosts = [\"http://localhost:9090\"]\n  scrape_interval_secs = 1\n```\n\n----------------------------------------\n\nTITLE: Accessing Nested Fields as Lua Structures\nDESCRIPTION: This example shows the desired way to access nested fields as native Lua structures. This is the intended improvement for the Lua transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_1\n\nLANGUAGE: lua\nCODE:\n```\nevent[\"nested\"][\"field\"] = 5\n```\n\n----------------------------------------\n\nTITLE: Example JSON Data for VRL Transformation\nDESCRIPTION: This JSON represents example data containing tags with enabled statuses and an array of IP address objects with associated information. This data can be used as input for VRL transformations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_26\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"tags\": {\n        \"foo\": { \"enabled\": true },\n        \"bar\": { \"enabled\": false },\n        \"baz\": { \"enabled\": false },\n        \"qux\": { \"enabled\": false },\n        \"quux\": {\n            \"one\": { \"enabled\": true },\n            \"two\": { \"enabled\": false }\n        }\n    },\n    \"ips\": [\n        { \"address\": \"180.14.129.174\", \"order\": 0, \"private\": true },\n        { \"address\": \"31.73.200.120\", \"order\": 1, \"private\": false },\n        { \"address\": \"82.35.219.252\", \"order\": 2, \"private\": false },\n        { \"address\": \"113.58.218.2\", \"order\": 3, \"private\": false },\n        { \"address\": \"32.85.172.216\", \"order\": 4, \"private\": false }\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: GraphQL Subscription Query\nDESCRIPTION: This is a GraphQL subscription query to retrieve the `utc` field from the `heartbeat` subscription. The `interval` parameter is set to 1000 milliseconds.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3645-graphql-api.md#_snippet_1\n\nLANGUAGE: gql\nCODE:\n```\nsubscription {\n  heartbeat(interval: 1000) {\n    utc\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Gauge Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create a gauge metric event. It includes the metric name and gauge value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_21\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_gauge\",\n    gauge = {\n      value = 10\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Multiple Config Files (Bash)\nDESCRIPTION: This command demonstrates how to start Vector with multiple configuration files. It uses the `-c` flag to specify each configuration file or a glob pattern to include multiple files from a directory. This allows breaking down large configurations into smaller, manageable chunks.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-07-multi-config-files.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector -c ./configs/first.toml -c ./configs/second.toml -c ./more/*.toml\n```\n\n----------------------------------------\n\nTITLE: InternalEventHandle Trait Definition\nDESCRIPTION: This snippet defines the `InternalEventHandle` trait, which is responsible for emitting a registered event. It enforces that all such events follow a consistent pattern where the input data is consumed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\ntrait InternalEventHandle {\n    type Data;\n    fn emit(&self, data: Data);\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector v0.18.1 with Config (Shell)\nDESCRIPTION: This snippet runs Vector version v0.18.1 with a specified configuration file (`config.toml`) and pipes the contents of the `five-lines` file into the Vector process using `cat`. This simulates input data for Vector to process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ cat five-lines | ./vector-v0.18.1 -c config.toml\n2022-01-13T02:26:45.125553Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info\"\n2022-01-13T02:26:45.125598Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-13T02:26:45.127484Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-13T02:26:45.153710Z  INFO vector::topology::running: Running healthchecks.\n2022-01-13T02:26:45.153742Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-13T02:26:45.153777Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-13T02:26:45.153773Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-13T02:26:45.153813Z  INFO vector: Vector has started. debug=\"false\" version=\"0.18.1\" arch=\"x86_64\" build_id=\"c4adb60 2021-11-30\"\n2022-01-13T02:26:45.153823Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-01-13T02:26:45.153889Z  INFO vector::shutdown: All sources have finished.\n2022-01-13T02:26:45.153892Z  INFO vector: Vector has stopped.\n2022-01-13T02:26:45.153893Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-13T02:26:45.154895Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-01-13T02:26:46.155677Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-13T02:26:47.156971Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-13T02:26:48.158228Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-01-13T02:26:48.544843Z  INFO vector: Vector has quit.\n```\n\n----------------------------------------\n\nTITLE: VRL Assignment Error Message (0.24 and later)\nDESCRIPTION: This text shows the compiler error message that occurs when attempting to query non-collection types on assignment in VRL version 0.24 and later. It explains the cause of the error and suggests solutions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nerror[E642]: parent path segment rejects this mutation\n  ┌─ :1:5\n  │\n1 │ foo.bar = 3.14\n  │ --- ^^^ querying a field of a non-object type is unsupported\n  │ │\n  │ this path resolves to a value of type integer\n  │\n  = try: change parent value to object, before assignment\n  =\n  =     foo = {}\n  =     foo.bar = 3.14\n  =\n  = see documentation about error handling at https://errors.vrl.dev/#handling\n  = see language documentation at https://vrl.dev\n```\n\n----------------------------------------\n\nTITLE: For-Loop Example in VRL\nDESCRIPTION: Demonstrates a potential for-loop syntax in VRL, iterating over keys and values of an object. The example highlights a potential issue where variables defined inside the loop might leak outside its scope. The code is written in CoffeeScript-like syntax used for demonstration purposes within the RFC.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_42\n\nLANGUAGE: CoffeeScript\nCODE:\n```\nfor (key, _value) in . {\n  key = upcase(key)\n}\n```\n\n----------------------------------------\n\nTITLE: Example SQS Bucket Notification Message\nDESCRIPTION: This is an example of the SQS bucket notification message that the `aws_s3` source will receive. It contains information about the S3 object that was created or modified.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-29-4155-aws-s3-source.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n   \"Records\":[\n      {\n         \"eventVersion\":\"2.2\",\n         \"eventSource\":\"aws:s3\",\n         \"awsRegion\":\"us-west-2\",\n         \"eventTime\":\"The time, in ISO-8601 format, for example, 1970-01-01T00:00:00.000Z, when Amazon S3 finished processing the request\",\n         \"eventName\":\"event-type\",\n         \"userIdentity\":{\n            \"principalId\":\"Amazon-customer-ID-of-the-user-who-caused-the-event\"\n         },\n         \"requestParameters\":{\n            \"sourceIPAddress\":\"ip-address-where-request-came-from\"\n         },\n         \"responseElements\":{\n            \"x-amz-request-id\":\"Amazon S3 generated request ID\",\n            \"x-amz-id-2\":\"Amazon S3 host that processed the request\"\n         },\n         \"s3\":{\n            \"s3SchemaVersion\":\"1.0\",\n            \"configurationId\":\"ID found in the bucket notification configuration\",\n            \"bucket\":{\n               \"name\":\"bucket-name\",\n               \"ownerIdentity\":{\n                  \"principalId\":\"Amazon-customer-ID-of-the-bucket-owner\"\n               },\n               \"arn\":\"bucket-ARN\"\n            },\n            \"object\":{\n               \"key\":\"object-key\",\n               \"size\":\"object-size\",\n               \"eTag\":\"object eTag\",\n               \"versionId\":\"object version if bucket is versioning-enabled, otherwise null\",\n               \"sequencer\": \"a string representation of a hexadecimal value used to determine event sequence,\\n                   only used with PUTs and DELETEs\"\n            }\n         },\n         \"glacierEventData\": {\n            \"restoreEventData\": {\n               \"lifecycleRestorationExpiryTime\": \"The time, in ISO-8601 format, for example, 1970-01-01T00:00:00.000Z, of Restore Expiry\",\n               \"lifecycleRestoreStorageClass\": \"Source storage class for restore\"\n            }\n         }\n      }\n   ]\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Standard Vector Source Metadata to Schema in Rust\nDESCRIPTION: This code adds the standard Vector source metadata to the schema definition, ensuring that the schema includes information about the source type and ingest timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_11\n\nLANGUAGE: rust\nCODE:\n```\n      .with_standard_vector_source_metadata()\n```\n\n----------------------------------------\n\nTITLE: GraphQL Query for Hardware Metrics\nDESCRIPTION: This GraphQL query fetches hardware metrics from the Vector instance, including memory usage, CPU usage, network activity, filesystem usage, and more. It provides insight into the resources utilized by Vector on the host system.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_4\n\nLANGUAGE: GraphQL\nCODE:\n```\nquery {\n  hostMetrics {\n    memory {\n      totalBytes\n      freeBytes\n      usedBytes\n      activeBytes\n      availableBytes\n      inactiveBytes\n      buffersBytes\n      cachedBytes\n      sharedBytes\n      wiredBytes\n    }\n    network {\n      receiveBytesTotal\n      receiveErrsTotal\n      receivePacketsTotal\n      transmitBytesTotal\n      transmitErrsTotal\n      transmitPacketsDropTotal\n      transmitPacketsTotal\n    }\n    filesystem {\n      freeBytes\n      totalBytes\n      usedBytes\n    }\n    cpu {\n      cpuSecondsTotal\n    }\n    swap {\n      freeBytes\n      totalBytes\n      usedBytes\n      swappedInBytesTotal\n      swappedOutBytesTotal\n    }\n    loadAverage {\n      load1\n      load5\n      load15\n    }\n    disk {\n      readBytesTotal\n      readsCompletedTotal\n      writtenBytesTotal\n      writesCompletedTotal\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Example Output After Explode Transform\nDESCRIPTION: This JSON object shows the output produced by the `explode` transform when applied to the example input. The output consists of two separate events, each containing a 'message' field from the original events array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\"message\": \"foo\"}\n{\"message\": \"bar\"}\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Cursor Timeout Metrics for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total number of cursors that have timed out in MongoDB since the server process started. Monitoring this metric can help identify application errors if the number is high or growing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_8\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_cursor_timed_out_total timedOut provides the total number of cursors that have timed out since the server process started. If this number is large or growing at a regular rate, this may indicate an application error\n# TYPE mongodb_mongod_metrics_cursor_timed_out_total counter\nmongodb_mongod_metrics_cursor_timed_out_total 0\n```\n\n----------------------------------------\n\nTITLE: Running Vector Debian Docker Image\nDESCRIPTION: This command runs the Vector Docker image based on Debian. Debian is a widely used Linux distribution. This image may be larger than the Alpine variant.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/docker/README.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker run timberio/vector:0.10.0-debian\n```\n\n----------------------------------------\n\nTITLE: Uninstall Vector using YUM\nDESCRIPTION: This command uninstalls the Vector package from the system using the YUM package manager. It requires root privileges and the use of `sudo`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/yum.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nsudo yum remove vector\n```\n\n----------------------------------------\n\nTITLE: Installing Vector Aggregator via Helm\nDESCRIPTION: Installs the Vector Aggregator using the Helm chart, specifying the namespace and creating the namespace if it does not exist. Uses default configuration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nhelm install vector vector/vector \\\n  --namespace vector \\\n  --create-namespace\n```\n\n----------------------------------------\n\nTITLE: Program Struct Definition (Initial)\nDESCRIPTION: Shows the initial definition of the `Program` struct, which contains a list of expressions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\npub struct Program {\n    pub(crate) expressions: Vec<Expr>,\n}\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Vector using Homebrew\nDESCRIPTION: This command removes the Vector package from the system using Homebrew. It is used to completely uninstall Vector from the macOS system.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/homebrew.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nbrew remove vector\n```\n\n----------------------------------------\n\nTITLE: HTTP Source Event Example (JSON)\nDESCRIPTION: This is an example event originating from an HTTP source using the JSON codec.  It shows a simple JSON payload received from an HTTP endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-04-20-12187-log-namespacing.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"mineral\": \"quartz\",\n  \"food\": \"sushi\"\n}\n```\n\n----------------------------------------\n\nTITLE: Validating Vector Code with Cargo and Make\nDESCRIPTION: This section demonstrates common `cargo` and `make` commands used for development. These include checking code, building, running tests (unit and integration), benchmarking, and formatting. These commands assume a properly configured local Rust toolchain.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n# Validate your code can compile\ncargo check\nmake check\n# Validate your code actually does compile (in dev mode)\ncargo build\nmake build-dev\n# Validate your test pass\ncargo test sources::example\nmake test SCOPE=\"sources::example\"\n# Validate tests (that do not require other services) pass\ncargo test\nmake test\n# Validate your tests pass (starting required services in Docker)\nmake test-integration SCOPE=\"sources::example\"\n# Validate your tests pass against a live service.\nmake test-integration SCOPE=\"sources::example\" autospawn=false\ncargo test --features docker sources::example\n# Validate all tests pass (starting required services in Docker)\nmake test-integration\n# Run your benchmarks\nmake bench SCOPE=\"transforms::example\"\ncargo bench transforms::example\n# Format your code before pushing!\nmake fmt\ncargo fmt\n# Build component documentation for the website\ncargo vdev build component-docs\n```\n\n----------------------------------------\n\nTITLE: Validating Vector Configuration\nDESCRIPTION: This command validates a Vector configuration file located at `/etc/vector/vector.yaml`. It checks for syntax errors, missing required fields, and topology issues.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/validating.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector validate /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Escaping Strftime Specifiers\nDESCRIPTION: This shows how to escape strftime specifiers like `%Y` so they are treated literally.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\noption = \"year=\\\\%Y/month=\\\\%m/day=\\\\%d/\"\n```\n\n----------------------------------------\n\nTITLE: Transforming add_fields with remap\nDESCRIPTION: Replacing the `add_fields` transform with the `remap` transform. Adds fields to the event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.add_fields]\ntype = \"remap\"\ninputs = [\"some_input\"]\nsource = '''\n.parent.child2 = \"value2\"\n'''\n```\n\n----------------------------------------\n\nTITLE: Validating Multiple Vector Configuration Files\nDESCRIPTION: This command validates multiple Vector configuration files matching the pattern `/etc/vector/vector*.toml`. It's useful for validating a set of configurations at once.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/validating.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvector validate /etc/vector/vector*.toml\n```\n\n----------------------------------------\n\nTITLE: CLI Option Example: Watch Config\nDESCRIPTION: This example demonstrates the change to the `--watch-config` option. It no longer requires a boolean value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nvector --watch-config\n```\n\n----------------------------------------\n\nTITLE: Uninstall Vector Docker Container\nDESCRIPTION: Removes the Vector Docker container named 'vector'.  This will permanently delete the container and any associated data not stored in volumes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ndocker rm vector\n```\n\n----------------------------------------\n\nTITLE: Example Vector Log Message (JSON)\nDESCRIPTION: This JSON snippet demonstrates the structure of a log message produced by Vector's `internal_logs` source.  It includes fields such as `message`, `metadata` (containing `kind`, `level`, `module_path`, and `target`), and `timestamp`. The `*` field is set to null.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-23-internal-logs-source.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"*\": null,\n  \"message\": \"Vector has started.\",\n  \"metadata\": {\n    \"kind\": \"event\",\n    \"level\": \"TRACE\",\n    \"module_path\": \"vector::internal_events::heartbeat\",\n    \"target\": \"vector\"\n  },\n  \"timestamp\": \"2020-10-10T17:07:36+00:00\"\n}\n```\n\n----------------------------------------\n\nTITLE: Example of resolving the closure within `for_each` - Rust\nDESCRIPTION: This snippet demonstrates how the `resolve` method in the `for_each` function can execute the closure multiple times for each element in an object or array. It includes variable scope management and handling of closure results.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_41\n\nLANGUAGE: rust\nCODE:\n```\nfn resolve(&self, ctx: &mut Context) -> Result<Value, Error> {\n    let run = |key, value| {\n        // TODO: handle variable scope stack\n        ctx.variables.insert(key, value);\n        let closure_value = self.closure.resolve(self)?;\n        ctx.variables.remove(key);\n\n        Ok(closure_value)\n    };\n\n    let result = match self.value.resolve(ctx)? {\n        Value::Object(object) => {\n            let mut result = BTreeMap::default();\n\n            for (key, value) in object.into_iter() {\n                let v = run(key, value)?.try_array()?;\n                result.insert(v[0], v[1]);\n            }\n\n            result.into()\n        }\n        Value::Array(array) => {\n            let mut result = Vec::with_capacity(array.len());\n\n            for (index, value) in array.into_iter().enumerate() {\n                let v = run(index, value)?;\n                result.push(v);\n            }\n\n            result.into()\n        }\n        _ => unreachable!(\"expected object or array\"),\n    };\n\n    Ok(result)\n}\n```\n\n----------------------------------------\n\nTITLE: Desired JSON Output (Repeated)\nDESCRIPTION: This JSON snippet repeats the desired output format after parsing the log data. It's the target structure for the VRL examples focusing on error handling.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"host\": \"5.86.210.12\",\n  \"user\": \"zieme4647\",\n  \"timestamp\": \"2021-02-03T23:13:55Z\",\n  \"message\": \"GET /embrace/supply-chains/dynamic/vertical HTTP/1.0\",\n  \"method\": \"GET\",\n  \"path\": \"/embrace/supply-chains/dynamic/vertical\",\n  \"protocol\": \"HTTP/1.0\",\n  \"total_bytes\": 20574,\n  \"status\": 201\n}\n```\n\n----------------------------------------\n\nTITLE: Diff to add ACL option in vector.toml\nDESCRIPTION: This diff shows the change needed in the `vector.toml` configuration file to explicitly set the `acl` option for the `gcp_cloud_storage` sink. The `+` symbol indicates the addition of the `acl` line with a default value.  The commented part allows users to modify to their access requirements.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-09-make-acl-optional.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.gcp_cloud_storage]\n   type = \"gcp_cloud_storage\"\n+  acl = \"projectPrivate\" # change as desired\n```\n\n----------------------------------------\n\nTITLE: Logstash Configuration for Log Parsing\nDESCRIPTION: This text-based configuration for Logstash demonstrates parsing an Apache log. It uses `grok` to parse the log message using regular expressions, `mutate` to remove fields, and `date` to handle the timestamp. It also uses `mutate` to coerce data types for bytes and status codes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/vector-remap-language.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n# ... inputs ...\n\nfilter {\n  grok {\n    match => { \"message\" => [\"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"%{WORD:[apache2][access][method]} %{DATA:[apache2][access][url]} HTTP/%{NUMBER:[apache2][access][http_version]}\\\" %{NUMBER:[apache2][access][response_code]} %{NUMBER:[apache2][access][body_sent][bytes]}( \\\"%{DATA:[apache2][access][referrer]}\\\")?( \\\"%{DATA:[apache2][access][agent]}\\\")?\",\n      \"%{IPORHOST:[apache2][access][remote_ip]} - %{DATA:[apache2][access][user_name]} \\[%{HTTPDATE:[apache2][access][time]}\\] \\\"-\\\" %{NUMBER:[apache2][access][response_code]} -\"] }\n    remove_field => \"message\"\n  }\n  mutate {\n    remove_field => [ \"time\", \"log\" ]\n  }\n  date {\n    match => [ \"[apache2][access][time]\", \"dd/MMM/YYYY:H:m:s Z\" ]\n    remove_field => \"[apache2][access][time]\"\n  }\n  mutate {\n    coerce => {\n      \"[apache2][access][body_sent][bytes]\" => \"integer\"\n      \"[apache2][access][response_code]\" => \"integer\"\n    }\n  }\n}\n\n# ... outputs ...\n```\n\n----------------------------------------\n\nTITLE: Adding a Feature Flag for the Sink in Cargo.toml (diff)\nDESCRIPTION: This diff snippet shows how to add a feature flag for the basic sink in the `Cargo.toml` file. This allows Vector to be built with only the necessary components.  The flag is added to both the sinks feature list and the sinks-logs feature list.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_8\n\nLANGUAGE: diff\nCODE:\n```\n  sinks-azure_blob = [\"dep:azure_core\", \"dep:azure_identity\", \"dep:azure_storage\", \"dep:azure_storage_blobs\"]\n  sinks-azure_monitor_logs = []\n+ sinks-basic = []\n  sinks-blackhole = []\n  sinks-chronicle = []\n```\n\nLANGUAGE: diff\nCODE:\n```\nsinks-logs = [\n  \"sinks-amqp\",\n  \"sinks-apex\",\n  \"sinks-aws_cloudwatch_logs\",\n  \"sinks-aws_kinesis_firehose\",\n  \"sinks-aws_kinesis_streams\",\n  \"sinks-aws_s3\",\n  \"sinks-aws_sqs\",\n  \"sinks-axiom\",\n  \"sinks-azure_blob\",\n  \"sinks-azure_monitor_logs\",\n+ \"sinks-basic\",\n  \"sinks-blackhole\",\n  \"sinks-chronicle\",\n```\n\n----------------------------------------\n\nTITLE: ResolveKind Enum Definition\nDESCRIPTION: Defines the `ResolveKind` enum, which is used to specify the possible types an expression can resolve to. It includes `Any`, `OneOf`, and `Maybe` variants to represent different scenarios.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\npub enum ResolveKind {\n    /// The expression can resolve to any value at runtime.\n    Any,\n\n    /// The expressions resolves to one of the defined [`ValueKind`]s.\n    OneOf(Vec<ValueKind>),\n\n    /// If the expression succeeds, it might resolve to a value, but doesn't\n    /// have to.\n    Maybe(Box<ResolveKind>),\n}\n```\n\n----------------------------------------\n\nTITLE: Running Vector (PR Version) with Config\nDESCRIPTION: This snippet runs the Vector binary (likely a pull request or development version) with a specified configuration file (config.toml). It demonstrates Vector's initialization and attempts to send data.  Vector is waiting for a netcat response which never comes leading to ctrl-c and retries.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11039/test-results.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-11039$ ./vector-pr --config config.toml\n2022-01-26T19:17:06.436364Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-26T19:17:06.436404Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T19:17:06.436926Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T19:17:06.470017Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T19:17:06.470039Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T19:17:06.470059Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T19:17:06.470057Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-26T19:17:06.470084Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"none\"\n^C2022-01-26T19:17:15.674107Z  INFO vector: Vector has stopped.\n2022-01-26T19:17:15.674177Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T19:17:15.675245Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-01-26T19:17:20.674746Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"54 seconds left\"\n2022-01-26T19:17:22.625121Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: connection closed before message completed\n2022-01-26T19:17:23.626436Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-26T19:17:24.627805Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-01-26T19:17:25.572097Z  INFO vector: Vector has quit.\n```\n\n----------------------------------------\n\nTITLE: Running Vector Tests\nDESCRIPTION: Executes Vector tests using the provided configuration file. It compiles the wasm module to a shared object (if it isn't cached) and then uses that file for testing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-04-15-2341-wasm-plugins.md#_snippet_8\n\nLANGUAGE: Bash\nCODE:\n```\n$ vector test config.toml\n```\n\n----------------------------------------\n\nTITLE: GeoIP Transform Configuration (Deprecated) YAML\nDESCRIPTION: This YAML configuration shows the deprecated `geoip` transform. It defines the type, input, database path, source IP address field, and target field for the GeoIP information.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ntransforms:\n  geoip:\n    type: geoip\n    inputs:\n      - with_ip_info\n    database: /etc/vector/GeoLite2-City.mmdb\n    source: ip_address\n    target: geoip\n```\n\n----------------------------------------\n\nTITLE: Escaping Event Field Syntax\nDESCRIPTION: This shows how to escape the event field syntax `{{ field_name }}` so it is treated literally.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/template-syntax.md#_snippet_5\n\nLANGUAGE: toml\nCODE:\n```\noption = \"\\\\{{ field_name }}\"\n```\n\n----------------------------------------\n\nTITLE: Create Data Directory\nDESCRIPTION: This command creates a directory to be used as the data directory for Vector.  It is recommended that Vector uses a dedicated data directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nmkdir /var/lib/vector\n```\n\n----------------------------------------\n\nTITLE: Change Directory (Linux)\nDESCRIPTION: This command changes the current directory to the 'vector' directory, where Vector's source code has been extracted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ncd vector\n```\n\n----------------------------------------\n\nTITLE: Install Vector using pacman\nDESCRIPTION: Installs the Vector package from the Arch Linux extra repository using pacman. Requires sudo privileges to install system packages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/pacman.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nsudo pacman -Syu vector\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Vector via Helm\nDESCRIPTION: Uninstalls the Vector Helm chart from the specified namespace.  This removes all Kubernetes resources deployed by the chart.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/helm.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\nhelm uninstall vector --namespace vector\n```\n\n----------------------------------------\n\nTITLE: Example Output JSON after Decryption\nDESCRIPTION: This is an example JSON output after the decryption process. It contains the decrypted plaintext message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-24-vrl-encryption.md#_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{ \"message\": \"super secret message\" }\n```\n\n----------------------------------------\n\nTITLE: Checking Internal Metrics\nDESCRIPTION: This command ensures the internal metrics that Vector emits conform to standards. It uses `cargo vdev check events` to validate the metrics. It's important to ensure consistency and adherence to standards.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\ncargo vdev check events\n```\n\n----------------------------------------\n\nTITLE: Disable Core Dumps via systemd: LimitCORE Configuration\nDESCRIPTION: This snippet shows how to disable core dumps for the Vector service using systemd. Setting `LimitCORE=0` in the systemd service unit file prevents core dumps, which could expose in-flight data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/going-to-prod/hardening.md#_snippet_0\n\nLANGUAGE: systemd\nCODE:\n```\nLimitCORE=0\n```\n\n----------------------------------------\n\nTITLE: Renaming LogDNA Sink to Mezmo - Diff\nDESCRIPTION: This code snippet demonstrates the configuration change required to rename the deprecated `logdna` sink to the new `mezmo` sink.  It shows the removal of the old `type` and the addition of the new `type`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-04-11-0-29-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n-type = \"logdna\"\n+type = \"mezmo\"\n```\n\n----------------------------------------\n\nTITLE: Setting Metadata with Path\nDESCRIPTION: This snippet demonstrates the added feature of using paths as keys in the `set_metadata_field` function. It also shows how arbitrary VRL types can be stored as metadata.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-06-07-vrl-metadata-and-secrets.md#_snippet_3\n\nLANGUAGE: coffeescript\nCODE:\n```\nset_metadata_field(.foo.bar, \"my metadata\")\nset_metadata_field(.foo.baz, {\"msg\": \"Any VRL type is supported\"})\n```\n\n----------------------------------------\n\nTITLE: Run Vector with config.toml Again\nDESCRIPTION: This snippet runs the 'vector-fix' executable with the specified configuration file (config.toml) for a second time. This is to test the persistence and handling of data after a previous run of Vector. The 'buffers::disk' message shows archive of old buffer data.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./vector-fix -c config.toml\n2022-01-13T02:33:23.465565Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-13T02:33:23.465605Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-13T02:33:23.466142Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-13T02:33:23.480721Z  INFO buffers::disk: Archived old buffer data directory from '/tmp/vector/github-10430/http_tarpit_buffer' to '/tmp/vector/github-10430/http_tarpit_buffer_old' for 'http_tarpit' sink.\n2022-01-13T02:33:23.503920Z  INFO vector::topology::running: Running healthchecks.\n2022-01-13T02:33:23.503939Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-13T02:33:23.503956Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-13T02:33:23.503962Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-13T02:33:23.504032Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"none\"\n^C2022-01-13T02:33:25.593636Z  INFO vector: Vector has stopped.\n2022-01-13T02:33:25.593691Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-13T02:33:25.594791Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n```\n\n----------------------------------------\n\nTITLE: Datadog Agent Secret API Request Example (JSON)\nDESCRIPTION: This is an example of a JSON request sent to the user-provided executable by the Datadog Agent (and Vector). It specifies the API version and a list of secrets to retrieve. The executable should process this request and return a JSON response containing the values of the requested secrets.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-02-24-11552-dd-agent-style-secret-management.md#_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\"version\": \"1.0\", \"secrets\": [\"secret1\", \"secret2\"]}\n```\n\n----------------------------------------\n\nTITLE: Verify Kustomization File (kubectl)\nDESCRIPTION: This command utilizes kubectl with kustomize to verify the prepared kustomization file. It processes the 'kustomization.yaml' and outputs the resulting Kubernetes resources definitions, allowing review before deployment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/kubernetes.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl kustomize\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration for Explode Transform (with Mapping)\nDESCRIPTION: This TOML configuration for the explode transform will generate the events and map the host field from the root to the events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_13\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.explode]\ntype = \"explode\"\nsource = \"map(array!(.events), |event| event.host = .host) ?? []\"\n```\n\n----------------------------------------\n\nTITLE: Migrate Elasticsearch Sink Configuration in Vector\nDESCRIPTION: This code snippet demonstrates the required changes to the `vector.toml` configuration file when upgrading to a version where the `endpoint` and `region` options are replaced with the `host` option for the Elasticsearch sink.  It shows how to update the configuration to point to the AWS Elasticsearch domain using the `host` parameter.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-02-05-drop-aws-options.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.es]\n  type = \"elasticsearch\"\n-  endpoint = \"http://my-domain.us-east-1.es.amazonaws.com\"\n-  region = \"us-east-1\"\n+  host = \"http://my-domain.us-east-1.es.amazonaws.com\"\n```\n\n----------------------------------------\n\nTITLE: Vector Component Sent Events Metric\nDESCRIPTION: This snippet demonstrates a metric that tracks the total number of events sent by a component (`sink_1`). It includes tags specifying the component's ID, kind, and type, and provides a counter indicating the total number of events sent.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_25\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"component_sent_events_total\",\n  \"namespace\": \"vector\",\n  \"tags\": {\n    \"component_id\": \"sink_1\",\n    \"component_kind\": \"sink\",\n    \"component_type\": \"console\",\n    \"host\": \"MY_HOST\"\n  },\n  \"timestamp\": \"2025-02-12T19:14:56.377942Z\",\n  \"kind\": \"absolute\",\n  \"counter\": {\n    \"value\": 3678.0\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Type Mismatch Example - Coffee\nDESCRIPTION: This CoffeeScript-like VRL example shows a type mismatch error, where a string is added to the result of `to_int(.foo)`, which might be null or a non-integer value, resulting in a potential runtime error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_18\n\nLANGUAGE: coffee\nCODE:\n```\n5 + to_int(.foo)\n```\n\n----------------------------------------\n\nTITLE: Configuring Log Namespacing in Vector (TOML)\nDESCRIPTION: This code snippet demonstrates how to enable log namespacing globally and then disable it for a specific source in Vector's configuration file. This allows for testing the feature on a per-source basis before fully enabling it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/log-namespacing.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\nschema.log_namespace = true\n\n[sources.input_with_log_namespace]\ntype = \"demo_logs\"\nformat = \"shuffle\"\nlines = [\"input_with_log_namespace\"]\ninterval = 1\n\n[sources.input_without_log_namespace]\ntype = \"demo_logs\"\nformat = \"shuffle\"\nlines = [\"input_without_log_namespace\"]\ninterval = 1\nlog_namespace = false\n\n[sinks.console]\ntype = \"console\"\ninputs = [\"input_with_log_namespace\", \"input_without_log_namespace\"]\nencoding.codec = \"json\"\n\n```\n\n----------------------------------------\n\nTITLE: Run Vector Configuration Tests (Shell)\nDESCRIPTION: This shell command executes the unit tests defined within the specified Vector configuration file (vector.toml) using the 'vector test' subcommand. The command outputs the test results, indicating whether each test passed or failed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2019-11-25-unit-testing-vector-config-files.md#_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\n$ vector test ./vector.toml\nRunning ./vector.toml tests\nTest ./vector.toml: verify_regex ... passed\n```\n\n----------------------------------------\n\nTITLE: Extract Vector Archive (Windows)\nDESCRIPTION: Extracts the downloaded Vector archive using PowerShell's Expand-Archive command.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_7\n\nLANGUAGE: powershell\nCODE:\n```\npowershell Expand-Archive vector-nightly-x86_64-pc-windows-msvc.zip .\n```\n\n----------------------------------------\n\nTITLE: VRL Assignment Error Example (Before 0.24)\nDESCRIPTION: This VRL code demonstrates the previously allowed, but now rejected, querying of non-collection types on assignment. It attempts to assign a value to a field of an integer, which is no longer permitted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\nfoo = 42\nfoo.bar = 3.14\n```\n\n----------------------------------------\n\nTITLE: JSON Example (Array)\nDESCRIPTION: A JSON array used as input for the Dynamic Field Assignment example.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_51\n\nLANGUAGE: JSON\nCODE:\n```\n[\"foo\", \"bar\", \"baz\"]\n```\n\n----------------------------------------\n\nTITLE: Stop Vector Docker Container\nDESCRIPTION: Stops the running Vector Docker container named 'vector'.  This gracefully shuts down the Vector process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ndocker stop vector\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry Span Definition (protobuf)\nDESCRIPTION: Defines the structure of a Span in OpenTelemetry using protobuf. It includes fields for trace_id, span_id, parent_span_id, name, kind, start_time_unix_nano, end_time_unix_nano, attributes, events, links and status.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_6\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage Span {\n  bytes trace_id = 1;\n  bytes span_id = 2;\n  string     = 3;\n  bytes parent_span_id = 4;\n  string name = 5;\n\n  enum SpanKind {\n    SPAN_KIND_UNSPECIFIED = 0;\n    SPAN_KIND_INTERNAL = 1;\n    SPAN_KIND_SERVER = 2;\n    SPAN_KIND_CLIENT = 3;\n    SPAN_KIND_PRODUCER = 4;\n    SPAN_KIND_CONSUMER = 5;\n  }\n\n  SpanKind kind = 6;\n  fixed64 start_time_unix_nano = 7;\n  fixed64 end_time_unix_nano = 8;\n  repeated opentelemetry.proto.common.v1.KeyValue attributes = 9;\n  uint32 dropped_attributes_count = 10;\n\n  message Event {\n    fixed64 time_unix_nano = 1;\n    string name = 2;\n    repeated opentelemetry.proto.common.v1.KeyValue attributes = 3;\n    uint32 dropped_attributes_count = 4;\n  }\n\n  repeated Event events = 11;\n  uint32 dropped_events_count = 12;\n\n  message Link {\n    bytes trace_id = 1;\n    bytes span_id = 2;\n    string trace_state = 3;\n    repeated opentelemetry.proto.common.v1.KeyValue attributes = 4;\n    uint32 dropped_attributes_count = 5;\n  }\n\n  repeated Link links = 13;\n  uint32 dropped_links_count = 14;\n  Status status = 15;\n}\n```\n\n----------------------------------------\n\nTITLE: Internal Event Definition and Implementation\nDESCRIPTION: This code defines the `FileEventReceived` struct and implements the `InternalEvent` trait. The `emit_logs` and `emit_metrics` methods specify how the event data is translated into logs and metrics, providing a centralized and consistent approach to instrumentation. This struct would be located in the `internal_events` module.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-17-2064-event-driven-observability.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\npub struct FileEventReceived<'a> {\n    pub file: &'a str,\n    pub byte_size: usize,\n}\n\nimpl InternalEvent for FileEventReceived<'_> {\n    fn emit_logs(&self) {\n        trace!(\n            message = \"Received one event.\",\n            file = self.file,\n            rate_limit_secs = 10\n        );\n    }\n\n    fn emit_metrics(&self) {\n        counter!(\"events_processed_total\", 1, \"source\" => \"file\");\n        counter!(\"bytes_processed\", self.byte_size as u64, \"source\" => \"file\");\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Cleaning and Listing Data Directories (Shell)\nDESCRIPTION: This snippet cleans the existing data directories using `create-clean-data-directories.sh` and lists the contents of the `/tmp/vector/github-10430/` directory using `ls -l`. The commands are executed in a shell environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 0\n```\n\n----------------------------------------\n\nTITLE: Adding type to check_field condition\nDESCRIPTION: This snippet demonstrates the addition of `type = \"check_field\"` to the `check_fields` condition. It is required due to deprecation. The alternative and recommended approach is the VRL syntax.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-02-16-0-12-upgrade-guide.md#_snippet_1\n\nLANGUAGE: diff\nCODE:\n```\n [transforms.route]\n type = \"route\"\n+lanes.errors.type = \"check_field\"\n lanes.errors.\"level.eq\" = \"error\"\n```\n\n----------------------------------------\n\nTITLE: Sink Configuration with Authoritative Flag in Rust\nDESCRIPTION: This code snippet adds an `authoritative` field to the `SinkOuter` struct.  This flag indicates whether a sink's finalization status should be considered authoritative for all sources of an event, influencing the acknowledgement process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-03-26-6517-end-to-end-acknowledgement.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nstruct SinkOuter {\n    // … existing fields …\n\n    #[serde(default)]\n    authoritative: bool,\n}\n```\n\n----------------------------------------\n\nTITLE: Running Kubernetes E2E tests with additional parameters (Shell)\nDESCRIPTION: Runs end-to-end tests for Kubernetes integration with additional parameters to adjust the test behavior, such as skipping the image build or using a cached image in Minikube.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_20\n\nLANGUAGE: shell\nCODE:\n```\nQUICK_BUILD=true USE_MINIKUBE_CACHE=true make test-e2e-kubernetes\n```\n\nLANGUAGE: shell\nCODE:\n```\nQUICK_BUILD=true CONTAINER_IMAGE_REPO=<your name>/vector-test make test-e2e-kubernetes\n```\n\n----------------------------------------\n\nTITLE: Define BasicEncoder Struct - Rust\nDESCRIPTION: Defines an empty `BasicEncoder` struct.  This struct will implement the `Encoder` trait to serialize events into raw bytes for transmission.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(Clone)]\nstruct BasicEncoder;\n```\n\n----------------------------------------\n\nTITLE: Running Vector Alpine Docker Image\nDESCRIPTION: This command runs the Vector Docker image based on Alpine Linux. Alpine is a lightweight Linux distribution, making this image smaller and more efficient.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/distribution/docker/README.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndocker run timberio/vector:0.10.0-alpine\n```\n\n----------------------------------------\n\nTITLE: Commanding the Server to Respond OK\nDESCRIPTION: This command instructs the server to always respond with an HTTP status code of 200 (OK). This command is used to clear the rate limiting simulation.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_24\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://localhost:8000/set_status -H \"Content-Type: application/json\" -d '{\"status\": 200}'\n```\n\n----------------------------------------\n\nTITLE: Invoking Test Harness\nDESCRIPTION: This snippet demonstrates how to invoke the Vector test harness by commenting on a pull request.  The `-t` flag is used to specify the name of the test to run. This command triggers the test harness to execute the specified test.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n/test -t <name>\n```\n\n----------------------------------------\n\nTITLE: Running Vector Unit Tests (Bash)\nDESCRIPTION: This command executes unit tests within a specified Vector configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nvector test /etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Restarting Vector on Linux (systemctl)\nDESCRIPTION: Restarts the Vector service using systemctl. This completely restarts the Vector process.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsudo systemctl restart vector\n```\n\n----------------------------------------\n\nTITLE: Reloading Vector in Docker\nDESCRIPTION: Reloads the Vector configuration in a Docker container by sending a HUP signal.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\ndocker kill --signal=HUP timberio/vector\n```\n\n----------------------------------------\n\nTITLE: Start Vector (Shell)\nDESCRIPTION: Starts the Vector process using the specified configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nvector --config config/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Entering the Vector Development Shell\nDESCRIPTION: This command enters a shell within the Docker/Podman container, providing an optimized environment for Vector development.  The `CONTAINER_TOOL` and `CLI_OPTS` variables can be used to specify the containerization tool and pass extra command-line options.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# Enter a shell with optimized mounts for interactive processes.\n# Inside here, you can use Vector like you have full toolchain (See below!)\nmake environment\n# Try out a specific container tool. (Docker/Podman)\nmake environment CONTAINER_TOOL=\"podman\"\n# Add extra cli opts\nmake environment CLI_OPTS=\"--publish 3000:2000\"\n```\n\n----------------------------------------\n\nTITLE: Restarting Vector on macOS (Homebrew)\nDESCRIPTION: Restarts the Vector service using Homebrew's service manager.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nbrew services restart vector\n```\n\n----------------------------------------\n\nTITLE: Stopping Vector on macOS (Homebrew)\nDESCRIPTION: Stops the Vector service using Homebrew's service manager.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nbrew services stop vector\n```\n\n----------------------------------------\n\nTITLE: MongoDB Active Reads Metric - Prometheus\nDESCRIPTION: This snippet shows the number of currently active read operations against a MongoDB instance, as collected by Telegraf. Includes metadata such as host and version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_65\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP mongodb_active_reads Telegraf collected metric\n# TYPE mongodb_active_reads untyped\nmongodb_active_reads{host=\"mba.local\",hostname=\"127.0.0.1:27017\",version=\"4.4.0\"} 1\n```\n\n----------------------------------------\n\nTITLE: Config File Location (Shell)\nDESCRIPTION: Displays the location of the Vector configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\nconfig/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Replacement for Shortand Encoding Setting in Vector TOML\nDESCRIPTION: This TOML snippet shows the replacement of the shorthand encoding setting.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_19\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Vector Configuration File Example (Before)\nDESCRIPTION: Illustrates the typical configuration file structure before automatic namespacing was introduced, where all TOML files reside in a single directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-implicit-namespacing.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n/etc/vector/\n│   file001.toml\n│   file002.toml\n│   file003.toml\n│   ...\n│   file022.toml\n│   file023.toml\n```\n\n----------------------------------------\n\nTITLE: f-string example (Coffee)\nDESCRIPTION: This snippet demonstrates how comprehensive f-strings would work in VRL, based on Python's f-strings. It shows how to embed VRL expressions within a string using curly braces and how to insert a curly brace character.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_5\n\nLANGUAGE: coffee\nCODE:\n```\nf'The message is { .message } created at { .timestamp }'\n```\n\nLANGUAGE: coffee\nCODE:\n```\nf'Here is a curly brace -> {{'\n```\n\n----------------------------------------\n\nTITLE: For-Loop with Dynamic Path Assignment\nDESCRIPTION: Illustrates an alternative for-loop syntax using dynamic paths for assignment. This approach addresses issues with variable scoping but introduces problems when working with recursive data structures where the path needs to be relative to the current iteration context. The code is written in CoffeeScript-like syntax used for demonstration purposes within the RFC.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_43\n\nLANGUAGE: CoffeeScript\nCODE:\n```\nfor (key, _value) in . {\n  .[upcase(key)] = value\n}\n```\n\n----------------------------------------\n\nTITLE: Component Validation Runner Example in Rust\nDESCRIPTION: This code snippet demonstrates the usage of the `Runner` to validate components. It iterates through a list of validatable components, creates a `Runner` instance, adds validators, and runs the validation process. The snippet handles both successful and failed validation scenarios, providing detailed feedback.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\nfn get_all_validatable_components() -> Vec<&'static dyn ValidatableComponent> {\n    // Collect all validatable components by using the existing component registration mechanism,\n    // `inventory`/`inventory::submit!`, to iterate through sources, transforms, and sinks, collecting\n    // them into a single vector.\n}\n\n#[test]\nasync fn compliance() {\n    let validatable_components = get_all_validatable_components();\n    for validatable_component in validatable_components {\n        let component_name = validatable_component.component_name();\n        let component_type = validatable_component.component_type();\n\n        let mut runner = Runner::from_component(validatable_component);\n        runner.add_validator(StandardValidators::ComponentSpec);\n\n        match runner.run_validation().await {\n            Ok(test_case_results) => {\n                let mut details = Vec::new();\n                let mut had_failures = false;\n\n                for (idx, test_case_result) in test_case_results.into_iter().enumerate() {\n                    for validator_result in test_case_result.validator_results() {\n                        match validator_result {\n                            Ok(success) => {\n                                // A bunch of code to take the success details and format them nicely.\n                            }\n                            Err(failure) => {\n                                had_failures = true;\n\n                                // A bunch of code to take the failure details and format them nicely.\n                            }\n                        }\n                    }\n                }\n\n                if had_failures {\n                    panic!(\"Failed to validate component '{}':\\n{}\", component_name, details.join(\"\"));\n                } else {\n                    info!(\"Successfully validated component '{}':\\n{}\", component_name, details.join(\"\"));\n                }\n            }\n            Err(e) => panic!(\n                \"Failed to complete validation run for component '{}': {}\",\n                component_name, e\n            ),\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration Example\nDESCRIPTION: This example shows how a Vector sink configuration defined in `vector.toml` can be moved to a separate file named `foo.toml` within a `sinks` subdirectory when using automatic configuration namespacing. This simplifies the main configuration file and organizes configurations by type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-12-9568-automatic-namespacing.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.foo]\ntype = \"anything\"\n```\n\n----------------------------------------\n\nTITLE: Vector Elasticsearch Sink Configuration (YAML)\nDESCRIPTION: This YAML snippet configures the Elasticsearch sink. It takes `apache_sampler` as input. It only takes sampled data. The type is set to `elasticsearch`. It sets the index to `vector-%Y-%m-%d`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_12\n\nLANGUAGE: yaml\nCODE:\n```\n# Send structured data to a short-term storage\ninputs:\n  - \"apache_sampler\"             # only take sampled data\ntype: \"elasticsearch\"\nendpoints:\n  - \"http://79.12.221.222:9200\"  # local or external host\nbulk:\n  index: \"vector-%Y-%m-%d\"      # daily indices\n```\n\n----------------------------------------\n\nTITLE: Return BasicEncoder - Rust\nDESCRIPTION: Implements the `encoder` function for `BasicRequestBuilder`, returning a reference to the `BasicEncoder` instance.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_10\n\nLANGUAGE: rust\nCODE:\n```\n    fn encoder(&self) -> &Self::Encoder {\n        &self.encoder\n    }\n```\n\n----------------------------------------\n\nTITLE: Implement RequestBuilder - Rust\nDESCRIPTION: Implementation skeleton of RequestBuilder<Event> trait for the `BasicRequestBuilder` struct. Defines associated types Metadata, Events, Encoder, Payload, Request, and Error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\nimpl RequestBuilder<Event> for BasicRequestBuilder {\n```\n\n----------------------------------------\n\nTITLE: \"Unzip\" Object to Key/Value Arrays VRL\nDESCRIPTION: This VRL snippet \"unzips\" an object into separate arrays for keys and values. It iterates through the object using `for_each` and pushes each key and value into their respective arrays (`keys` and `values`).\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_9\n\nLANGUAGE: coffee\nCODE:\n```\nkeys = []\nvalues = []\n\nfor_each(.) -> |key, value| {\n  keys = push(keys, key)\n  values = push(values, value)\n}\n```\n\n----------------------------------------\n\nTITLE: Download and Unpack Vector Archive (macOS x86_64)\nDESCRIPTION: Downloads and unpacks the latest or nightly build of Vector for macOS (x86_64). It creates a 'vector' directory, downloads the archive using curl, and extracts it into the 'vector' directory, stripping the first two directory components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\n# Latest (version {{< version >}})\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/{{< version >}}/vector-{{< version >}}-x86_64-apple-darwin.tar.gz  | \\\n  tar xzf - -C vector --strip-components=2\n\n# Nightly\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/nightly/latest/vector-nightly-x86_64-apple-darwin.tar.gz  | \\\n  tar xzf - -C vector --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: Configuring gcp_stackdriver_metrics (Old)\nDESCRIPTION: This is the old configuration for the `gcp_stackdriver_metrics` sink. It demonstrates how to define labels within a nested `labels` section. It requires specifying `type`, `inputs`, `credentials_path`, `project_id` and nested `resource` and `resource.labels`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.my_sink_id]\ntype = \"gcp_stackdriver_metrics\"\ninputs = [ \"my-source-or-transform-id\" ]\ncredentials_path = \"/path/to/credentials.json\"\nproject_id = \"vector-123456\"\n\n  [sinks.my_sink_id.resource]\n  type = \"global\"\n\n    [sinks.my_sink_id.resource.labels]\n    projectId = \"vector-123456\"\n    instanceId = \"Twilight\"\n    zone = \"us-central1-a\"\n```\n\n----------------------------------------\n\nTITLE: Restarting Vector in Docker\nDESCRIPTION: Restarts the Vector Docker container.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\ndocker restart -f $(docker ps -aqf \"name=vector\")\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Mallocs Total Metric - Prometheus\nDESCRIPTION: This snippet shows the total number of mallocs performed by the Go program. This is a cumulative measure of memory allocations.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_54\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_mallocs_total Total number of mallocs.\n# TYPE go_memstats_mallocs_total counter\ngo_memstats_mallocs_total 61706\n```\n\n----------------------------------------\n\nTITLE: Running Vector (Fixed Version)\nDESCRIPTION: This command executes the `vector-fix` binary with a configuration file named `config.toml`. This is likely a later version where a fix related to the bug is present. The output logs are captured to monitor Vector's behavior and any warnings or errors.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\n./vector-fix -c config.toml\n```\n\n----------------------------------------\n\nTITLE: Unhandled Error Output Example - Text\nDESCRIPTION: This is the error output produced by the compiler for an unhandled error, specifically for the expression `\"foo\" + .bar + baz[1]`.  It highlights the entire expression as fallible, without pinpointing the exact source of the error.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_19\n\nLANGUAGE: text\nCODE:\n```\nerror[E100]: unhandled error\n  ┌─ :1:1\n  │\n1 │ \"foo\" + .bar + baz[1]\n  │ ^^^^^^^^^^^^^^^^^^^^^\n  │ │\n  │ expression can result in runtime error\n  │ handle the error case to ensure runtime success\n```\n\n----------------------------------------\n\nTITLE: Access Vector Metrics\nDESCRIPTION: Executes the `vector top` command inside the Vector Docker container to access metrics. The command runs interactively (`-ti`) within the container identified by `docker ps -aqf \"name=vector\"`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/platforms/docker.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ndocker exec -ti $(docker ps -aqf \"name=vector\") vector top\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Correct HTTP Config and Debug Logs\nDESCRIPTION: This snippet runs Vector with a correct HTTP configuration (`config-right-http.toml`) and enables debug logging by setting the `LOG` environment variable to `debug`.  It uses `vector-pr` executable and imposes a 5-second timeout. The intention is to verify Vector's functionality when communicating with a valid HTTP endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-11072$ LOG=debug timeout 5s ./vector-pr --config config-right-http.toml\n2022-02-25T01:37:42.964509Z  INFO vector::app: Log level is enabled. level=\"debug\"\n2022-02-25T01:37:42.964543Z  INFO vector::app: Loading configs. paths=[\"config-right-http.toml\"]\n2022-02-25T01:37:42.965087Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-02-25T01:37:42.982001Z DEBUG vector_buffers::variants::disk_v1: Read 5 key(s) from database, with 585 bytes total, comprising 5 events total. first_key=Some(0) last_key=Some(4)\n2022-02-25T01:37:42.997579Z  INFO vector::topology::running: Running healthchecks.\n2022-02-25T01:37:42.997604Z  INFO vector::topology::running: Starting source. key=stdin\n2022-02-25T01:37:42.997625Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-02-25T01:37:42.997622Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-02-25T01:37:42.997648Z  INFO vector: Vector has started. debug=\"false\" version=\"0.21.0\" arch=\"x86_64\" build_id=\"none\"\n2022-02-25T01:37:47.959025Z  INFO vector: Vector has stopped.\n2022-02-25T01:37:47.959100Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\ntoby@consigliere:~/src/vector/testing/github-11072$\n```\n\n----------------------------------------\n\nTITLE: Syslog Parsed JSON Example (Old VRL)\nDESCRIPTION: This JSON shows the old format of parsed syslog data when using VRL's `parse_syslog` function, where structured data keys were prefixed with the name of the structured data element.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"appname\": \"2d4d9490-794a-4e60-814c-5597bd5b7b7d\",\n  \"exampleSDID@32473.foo.baz\": \"bar\",\n  \"facility\": \"kern\",\n  \"hostname\": \"Gregorys-MacBook-Pro.local\",\n  \"message\": \"test message\",\n  \"procid\": 79978,\n  \"severity\": \"alert\",\n  \"timestamp\": \"2022-04-25T23:21:45.715740Z\",\n  \"version\": 1\n}\n```\n\n----------------------------------------\n\nTITLE: Assignment Expression new Function\nDESCRIPTION: Defines the `new` function for the `Assignment` expression.  It calculates the resolve kind of the assigned expression and stores it in the `CompilerState`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_11\n\nLANGUAGE: rust\nCODE:\n```\nimpl Assignment {\n    fn new(ident: String, expression: Box<dyn Expression>, state: &mut CompilerState) -> Self {\n        let resolve = expression.resolves_to(&state);\n        state.variables_mut().insert(ident, resolve);\n\n        Self { ident, expression }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Example of an improved VRL compiler error message\nDESCRIPTION: This snippet shows an example of the enhanced error message that the VRL compiler will generate when a function call receives an argument of an invalid type. The error message clearly indicates the problematic argument, the expected type, and the possible types of the argument at runtime. Additionally, it provides suggestions on how to resolve the issue, such as ensuring an appropriate type at runtime or coercing to an appropriate type with a fallback.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_21\n\nLANGUAGE: Text\nCODE:\n```\nerror[E100]: argument type might be invalid at runtime\n  ┌─ :1:8\n  │\n1 │ upcase(.foo)\n  │        ^^^^\n  │        │\n  │        the parameter \"value\" expects the exact type \"string\"\n  │        but the expression \".foo\" can resolve to either a \"string\" or \"null\" at runtime\n  │\n  = try: ensuring an appropriate type at runtime\n  =\n  =     foo = string!(.foo)\n  =     upcase(.foo)\n  =\n  = try: coercing to an appropriate type and specifying a default value as a fallback in case coercion fails\n  =\n  =     .foo = to_string(.foo) ?? \"default\"\n  =     upcase(.foo)\n  =\n  = see documentation about error handling at https://errors.vrl.dev/#handling\n  = learn more about error code 100 at https://errors.vrl.dev/100\n  = see language documentation at https://vrl.dev\n```\n\n----------------------------------------\n\nTITLE: Defining S3SinkConfig struct in Rust\nDESCRIPTION: This Rust code defines the `S3SinkConfig` struct, which includes a `recover_partials` boolean field. This field determines whether Vector should scan for and reassemble unfinished multipart uploads at startup, which might have been interrupted by crashes or shutdowns. This enables Vector to recover from incomplete uploads and ensure data integrity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-07-3829-better-support-for-large-aws-s3-batches.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\nstruct S3SinkConfig {\n    …\n    pub recover_partials: bool,\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Example (Result)\nDESCRIPTION: The JSON output after the Dynamic Field Assignment is applied.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_53\n\nLANGUAGE: JSON\nCODE:\n```\n{\n    \"foo\": 0,\n    \"bar\": 1,\n    \"baz\": 2\n}\n```\n\n----------------------------------------\n\nTITLE: Download Vector Archive (Windows x86_64)\nDESCRIPTION: Downloads the latest or nightly build of Vector for Windows (x86_64) using PowerShell's Invoke-WebRequest. The downloaded archive is saved as a .zip file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_6\n\nLANGUAGE: powershell\nCODE:\n```\n# Latest (version {{< version >}})\npowershell Invoke-WebRequest https://packages.timber.io/vector/{{< version >}}/vector-{{< version >}}-x86_64-pc-windows-msvc.zip -OutFile vector-{{< version >}}-x86_64-pc-windows-msvc.zip\n\n\n# Nightly\npowershell Invoke-WebRequest https://packages.timber.io/vector/0.12.X/vector-nightly-x86_64-pc-windows-msvc.zip -OutFile vector-nightly-x86_64-pc-windows-msvc.zip\n```\n\n----------------------------------------\n\nTITLE: Updating Sample Transform with Check Fields Condition - TOML\nDESCRIPTION: This example shows the updated `sample` transform configuration with the `check_fields` type explicitly defined. This ensures compatibility with Vector 0.15.0 if the deprecated `check_fields` syntax was previously used.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_1\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.sample]\ntype = \"sample\"\ninputs = [\"in\"]\nrate = 10\nkey_field = \"message\"\nexclude.\"type\" = \"check_fields\"\nexclude.\"message.contains\" = \"error\"\n```\n\n----------------------------------------\n\nTITLE: Install Vector in Docker using Install Script\nDESCRIPTION: This command adds the required Vector binaries to `$PATH` without modifying your profiles, making it suitable for Docker environments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/_index.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n{{< docker-example-install-scripts >}}\n```\n\n----------------------------------------\n\nTITLE: Remap Transform: Basic Mutation Operations (Coffee)\nDESCRIPTION: Demonstrates basic mutation operations within the `remap` transform, including assigning values and deleting fields. This snippet showcases the current capabilities before the proposed changes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-04-3325-remap-v2.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\n.foo = .bar\ndel(.bar)\n.baz = \"something static\"\n```\n\n----------------------------------------\n\nTITLE: VRL Template String with Type Conversion\nDESCRIPTION: This example shows how to use VRL template strings with type conversion. Since variables must be strings, you need to convert non-string variables to string using the `to_string()` function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-05-03-0-22-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: coffee\nCODE:\n```\nstars = to_string(42)\nsky = \"There are {{ stars }} in the sky.\"\n```\n\n----------------------------------------\n\nTITLE: Run Vector with TOML Configuration (Shell)\nDESCRIPTION: This shell command demonstrates how to start the Vector agent with a TOML configuration file. The `--config` flag is used to specify the path to the configuration file, allowing Vector to load and apply the settings defined within.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/_index.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nvector --config /etc/vector/vector.toml\n```\n\n----------------------------------------\n\nTITLE: Running Vector with Wrong HTTP Config\nDESCRIPTION: This snippet executes a shell script to create clean data directories, then runs Vector with a configuration file (`config-wrong-http.toml`) that likely contains an incorrect HTTP endpoint. The input `five-lines-first` is piped to Vector, and a timeout of 5 seconds is enforced. This tests Vector's behavior when the HTTP endpoint is unavailable.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11072/test-results.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-11072$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-11072$ ls -l /tmp/vector/github-11072/\ntotal 0\ntoby@consigliere:~/src/vector/testing/github-11072$ cat five-lines-first | timeout 5s ./vector-v0.19.0 --config config-wrong-http.toml\n2022-02-25T01:37:26.452783Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-02-25T01:37:26.452827Z  INFO vector::app: Loading configs. paths=[\"config-wrong-http.toml\"]\n2022-02-25T01:37:26.453530Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-02-25T01:37:26.485638Z  INFO vector::topology::running: Running healthchecks.\n2022-02-25T01:37:26.485669Z  INFO vector::topology::running: Starting source. key=stdin\n2022-02-25T01:37:26.485699Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-02-25T01:37:26.485693Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-02-25T01:37:26.485727Z  INFO vector: Vector has started. debug=\"false\" version=\"0.19.0\" arch=\"x86_64\" build_id=\"da60b55 2021-12-28\"\n2022-02-25T01:37:26.485738Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-02-25T01:37:26.485878Z  INFO vector::shutdown: All sources have finished.\n2022-02-25T01:37:26.485883Z  INFO vector: Vector has stopped.\n2022-02-25T01:37:26.485887Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-02-25T01:37:26.486866Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-02-25T01:37:27.487708Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-02-25T01:37:28.489158Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-02-25T01:37:29.490469Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-02-25T01:37:31.445678Z  INFO vector: Vector has quit.\ntoby@consigliere:~/src/vector/testing/github-11072$\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Stack Inuse Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the number of bytes in use by the stack allocator in Go. This is important for stack memory management.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_61\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.\n# TYPE go_memstats_stack_inuse_bytes gauge\ngo_memstats_stack_inuse_bytes 753664\n```\n\n----------------------------------------\n\nTITLE: Remap Language: Accessing Nested Fields in CoffeeScript-like Syntax\nDESCRIPTION: This snippet shows how to access nested fields within an event using a dot-separated path. It demonstrates accessing fields in arrays using numeric indices and showcases the basic syntax of the remap language.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-07-21-2744-remap-syntax.md#_snippet_1\n\nLANGUAGE: coffeescript\nCODE:\n```\n.foo = .bar.baz.0.buz\n```\n\n----------------------------------------\n\nTITLE: Define EventMetadata and SourceEvent Structures in Rust\nDESCRIPTION: These structures define the metadata that will be associated with each event in Vector. `EventMetadata` contains a timestamp, source events, and delivery status. `SourceEvent` contains details about the event's origin.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-02-04-5802-event-metadata.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nstruct EventMetadata {\n    first_timestamp: DateTime,\n    source_events: SmallVec<SourceEvent>,\n    status: EventDeliveryStatus,\n}\n\nstruct SourceEvent {\n    timestamp: DateTime,\n    source_name: SmolStr,\n    event_id: SmolStr,\n}\n\nenum EventDeliveryStatus {\n    …TBD…\n}\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Mcache Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the number of bytes used for mcache structures obtained from the system in Go. It indicates allocator memory overhead.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_56\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.\n# TYPE go_memstats_mcache_sys_bytes gauge\ngo_memstats_mcache_sys_bytes 16384\n```\n\n----------------------------------------\n\nTITLE: Update and install dependencies for APT (Shell)\nDESCRIPTION: These commands update the APT package list and install necessary dependencies for using HTTPS repositories. These dependencies include apt-transport-https, curl, and gnupg. This prepares the system to securely download packages from the new repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2023-11-07-new-linux-repos.md#_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nsudo apt-get update\nsudo apt-get install apt-transport-https curl gnupg\n```\n\n----------------------------------------\n\nTITLE: Simplified Sink Configuration (Before)\nDESCRIPTION: Shows the TOML configuration required for a sink before automatic namespacing, where the component type and ID must be explicitly defined.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-11-18-implicit-namespacing.md#_snippet_2\n\nLANGUAGE: toml\nCODE:\n```\n# /etc/vector/file017.toml\n[sinks.foo]\ntype = \"anything\"\n```\n\n----------------------------------------\n\nTITLE: Acknowledging Event Delivery in run_inner (diff)\nDESCRIPTION: This diff snippet shows how to modify the `run_inner` method to acknowledge event delivery. The event is marked as mutable, its finalizers are retrieved, and the event status is updated to `Delivered` to signal successful delivery to the source.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_9\n\nLANGUAGE: diff\nCODE:\n```\n    async fn run_inner(self: Box<Self>, mut input: BoxStream<'_, Event>) -> Result<(), ()> {\n-       while let Some(event) = input.next().await {\n+       while let Some(mut event) = input.next().await {\n            println!(\"{:#?}\", event);\n\n+           let finalizers = event.take_finalizers();\n+           finalizers.update_status(EventStatus::Delivered);\n        }\n\n        Ok(())\n    }\n```\n\n----------------------------------------\n\nTITLE: HecService Call Function with Ack ID Handling in Rust\nDESCRIPTION: This snippet illustrates the `call` function within `HecService`, showcasing the integration with indexer acknowledgements.  If an `ackId` is found in the HEC response, it stores the `ackId` along with retry information in a shared map. Then, it awaits the `EventStatus` from the receiver. If no `ackId` is found, it falls back to determining event status based on the HTTP response status code. This code is part of the implementation for `splunk_hec` sink indexer acknowledgements.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-9465-splunk-hec-indexer-acknowledgements.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\nfn call(&mut self, req: HecRequest) -> Self::Future {\n        let mut http_service = self.batch_service.clone();\n        Box::pin(async move {\n            ...\n\n            // handle response\n            let response = http_service.call(req).await?;\n            // if ack_id is found\n            let (tx, rx) = oneshot::channel::<EventStatus>();\n            self.ack_id_to_status_map.insert(ack_id, (30, tx));\n            let event_status = match rx.await {\n                Ok(EventStatus::Delivered) => EventStatus::Delivered,\n                Ok(_) => EventStatus::Dropped,\n                Err(_) => EventStatus::Rejected,\n            }\n            ...\n\n            // if ack_id is not found, fall back on current behavior\n            let event_status = if response.status().is_success() {\n                EventStatus::Delivered\n            } else if response.status().is_server_error() {\n                EventStatus::Errored\n            } else {\n                EventStatus::Rejected\n            };\n\n            ...\n        })\n    }\n```\n\n----------------------------------------\n\nTITLE: Generating Sample Log Files Using flog\nDESCRIPTION: This command uses the `flog` tool to generate a sample log file of 100MiB in size.  The `flog` tool must be installed. Homebrew can be used on macOS.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_13\n\nLANGUAGE: bash\nCODE:\n```\nflog --bytes $((100 * 1024 * 1024)) > sample.log\n```\n\n----------------------------------------\n\nTITLE: Generating Vector Schema with CLI\nDESCRIPTION: This snippet demonstrates how to generate the Vector schema using the `vector generate-schema` subcommand. The optional first line shows how to retrieve the Vector version to include it in the output file name. The second line executes the schema generation, outputting a JSON file named `vector-v0.45.0-schema.json`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/config-autocompletion.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Optional step: get the Vector version and include it in the file name.\n# vector --version\nvector generate-schema -o vector-v0.45.0-schema.json\n```\n\n----------------------------------------\n\nTITLE: Tailing Vector Logs (Manual)\nDESCRIPTION: This command is used to tail the Vector log file when Vector's output is being redirected to a file, allowing for real-time monitoring of log messages. It requires `tail` utility to be available and the user to have read permissions on the log file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntail /var/log/vector.log\n```\n\n----------------------------------------\n\nTITLE: Erroneous VRL Code with `string!`\nDESCRIPTION: This code snippet shows an attempt to fix the previous error by adding `string!(foo)`, which results in a new error because `to_string` is now valid and returns a string, making `string!(foo)` unnecessary and disallowed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_1\n\nLANGUAGE: coffee\nCODE:\n```\nfoo = to_string(15)\nfoo = string!(foo)\nupcase(foo)\n```\n\n----------------------------------------\n\nTITLE: Executing Vector with Wrong HTTP Config\nDESCRIPTION: This snippet demonstrates executing Vector with a configuration that is intended to simulate an incorrect HTTP setup. It pipes the contents of `five-lines-second` to Vector's stdin, sets the `VECTOR_LOG` environment variable for verbose logging, and specifies the configuration file `config-wrong-http.toml`. The command aims to test Vector's handling of HTTP connection refused errors.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-12069/test-results.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-12069$ cat five-lines-second | VECTOR_LOG=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info,kube=info,vector_buffers=info\" ./vector-pr -c ./config-wrong-http.toml\n```\n\n----------------------------------------\n\nTITLE: Enabling Debug Logging (Env Var)\nDESCRIPTION: This command enables debug logging for Vector by setting the `VECTOR_LOG` environment variable to `debug`.  It then runs Vector with the specified configuration file. This will increase the verbosity of the logs. Requires the `vector` binary to be in the system's PATH and access to the configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nVECTOR_LOG=debug vector --config=/etc/vector/vector.yaml\n```\n\n----------------------------------------\n\nTITLE: Updated No-op Function Implementation - Rust\nDESCRIPTION: This updated Rust code snippet demonstrates the modified `noop` function that takes the function identifier and the value kind as parameters. This allows the no-op function to mimic the signature of the original function call, ensuring type consistency and enabling the compiler to continue without halting.  The `kind` parameter represents the return type of the original function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\n// Compile a no-op function that is defined to return the given value kind, and\n// identifies itself with the given function name.\npub fn noop(ident: &'static str, kind: value::Kind) -> Self {\n    let expr = Box::new(Noop(kind)) as _;\n\n    Self {\n        ident,\n        expr,\n        // ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Inserting Source Metadata into Log Event in Rust\nDESCRIPTION: This code demonstrates how to insert source-specific metadata (e.g., Kafka topic, Syslog severity) into a log event using the `insert_source_metadata` function. It requires the source name, log event, legacy key (if applicable), metadata key, and the value to be inserted.  `LegacyKey::Overwrite` specifies the conflict resolution strategy for the legacy namespace.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\n  log_namespace.insert_source_metadata(\n      SyslogConfig::NAME,\n      log,\n      Some(LegacyKey::Overwrite(\"source_id\")),\n      path!(\"source_id\"),\n      default_host.clone(),\n  );\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Heap Idle Bytes Metric - Prometheus\nDESCRIPTION: This snippet shows the number of heap bytes waiting to be used in the Go program. It represents unused heap capacity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_47\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.\n# TYPE go_memstats_heap_idle_bytes gauge\ngo_memstats_heap_idle_bytes 5.7524224e+07\n```\n\n----------------------------------------\n\nTITLE: Change Directory to Vector (Shell)\nDESCRIPTION: Changes the current directory to the 'vector' directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\ncd vector\n```\n\n----------------------------------------\n\nTITLE: OpenTelemetry InstrumentationLibrarySpans Definition (protobuf)\nDESCRIPTION: Defines the InstrumentationLibrarySpans message in OpenTelemetry, containing the instrumentation library metadata, a list of spans, and the schema URL.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-03-15-11851-ingest-opentelemetry-traces.md#_snippet_5\n\nLANGUAGE: protobuf\nCODE:\n```\nmessage InstrumentationLibrarySpans {\n  opentelemetry.proto.common.v1.InstrumentationLibrary instrumentation_library = 1;\n  repeated Span spans = 2;\n  string schema_url = 3;\n}\n```\n\n----------------------------------------\n\nTITLE: Building Vector Development Environment\nDESCRIPTION: This optional command builds the Docker development environment. It allows you to create your own environment instead of pulling a pre-built image.  This step is useful if you want to customize the development environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# Optional: Only if you want to go make a coffee\nmake environment-prepare\n```\n\n----------------------------------------\n\nTITLE: Lua Module: Log to Metric (Isolated Functions)\nDESCRIPTION: This Lua code defines a module as a table, containing functions for initializing, processing, shutting down, and handling timers. It's designed to avoid name collisions by encapsulating functions within the module table.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_9\n\nLANGUAGE: lua\nCODE:\n```\nlocal example_transform = {}\nlocal event_counter = 0\nfunction example_transform.init (emit)\n  emit({\n    log = {\n      message = \"starting up\"\n    }\n  }, \"auxiliary\")\nend\n\nfunction example_transform.process (event, emit)\n  event_counter = event_counter + 1\nend\n\nfunction example_transform.shutdown (emit)\n  emit {\n    metric = {\n      name = \"counter_10s\",\n      counter = {\n        value = event_counter\n      }\n    }\n  }\n\n  emit({\n    log = {\n      message = \"shutting down\"\n    }\n  }, \"auxiliary\")\nend\n\nfunction example_transform.timer_handler (emit)\n  emit {\n    metric = {\n      name = \"counter_10s\",\n      counter = {\n        value = event_counter\n      }\n    }\n  }\n  counter = 0\nend\n\nreturn example_transform\n```\n\n----------------------------------------\n\nTITLE: Change Directory to Vector (Powershell)\nDESCRIPTION: Navigates to the extracted Vector directory using the cd command in PowerShell.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_8\n\nLANGUAGE: powershell\nCODE:\n```\ncd vector-nightly-x86_64-pc-windows-msvc\n```\n\n----------------------------------------\n\nTITLE: Example JSON Response from GraphQL Subscription\nDESCRIPTION: This is an example JSON response from the GraphQL subscription query.  It shows the `data` field containing the `heartbeat` object with the `utc` timestamp.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3645-graphql-api.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"data\": {\n    \"heartbeat\": {\n      \"utc\": \"2020-08-31T13:10:47.152412+00:00\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Filter Transform with Remap Condition (Deprecated) - TOML\nDESCRIPTION: This example shows a `filter` transform using the deprecated `remap` condition type.  This configuration needs to be updated to use `type = \"vrl\"`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-07-14-0-15-upgrade-guide.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[transforms.filter_a]\ninputs = [\"stdin\"]\ntype = \"filter\"\ncondition.type = \"remap\"\ncondition.source = '''\n    message = if exists(.tags) { .tags.message } else { .message }\n    message == \"test filter 1\"\n'''\n```\n\n----------------------------------------\n\nTITLE: Validating CUE Sources Continuously with watchexec\nDESCRIPTION: This command uses watchexec to continuously validate CUE sources whenever a file is saved. This is a good practice for catching errors early and incrementally as you write CUE, and requires the `watchexec` tool to be installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DOCUMENTING.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# From the root\nwatchexec \"make check-docs\"\n```\n\n----------------------------------------\n\nTITLE: Logging: Preferred Message Formatting in Rust\nDESCRIPTION: This snippet illustrates the preferred order for arguments in `tracing` event macros: fields/message/message arguments. It highlights the recommended way to pass the event message in `tracing` macros. It shows the correct way to log messages with structured fields and message.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/STYLE.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\n// Don't do this:\ninfo!(message = \"Something happened.\");\n// Do this instead:\ninfo!(\"Something happened.\");\n\n// Don't do this:\ndebug!(%client_id, message = \"Client entered authentication phase.\");\ndebug!(message = \"Client entered authentication phase.\", %client_id);\n// Do this instead:\ndebug!(%client_id, \"Client entered authentication phase.\");\n```\n\n----------------------------------------\n\nTITLE: Run the site locally in Shell\nDESCRIPTION: This shell command builds all necessary prerequisites for the site and starts up a local web server.  After executing this command, the site can be viewed at http://localhost:1313.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\nmake serve\n```\n\n----------------------------------------\n\nTITLE: Metric Event Creation in Lua\nDESCRIPTION: Creates a metric event table in Lua. The `metric` field contains the metric data model, and values are tagged externally with respect to the metric type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_19\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    -- ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Compile Function Call with No-op Fallback - Rust\nDESCRIPTION: This Rust code snippet demonstrates how the VRL compiler handles invalid function arguments by compiling a no-op function call as a fallback. This allows the compiler to continue compiling the program and track additional errors, even when a function argument is incorrect.  The no-op call mimics the type definition and name of the original function.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\nfn compile_function_call(&mut self, node: Node<ast::FunctionCall>) -> Option<FunctionCall> {\n    let func = /* ... */;\n\n    // This can return \"none\" if one of the passed in argument expressions fail.\n    let arguments = arguments\n        .into_iter()\n        .map(|node| self.compile_function_argument(node))\n        .collect::<Option<_>>();\n\n    let arguments = match arguments {\n        Some(arguments) => arguments,\n        // If an argument failed to compile, we can still compile the function,\n        // by using a no-op variant, using the same type-def and function name\n        None => return Some(FunctionCall::noop(func.ident, func.type_def)),\n    };\n\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Download and Unpack Vector Archive (Linux ARM64)\nDESCRIPTION: Downloads and unpacks the latest or nightly build of Vector for Linux (ARM64). It creates a 'vector' directory, downloads the archive using curl, and extracts it into the 'vector' directory, stripping the first two directory components.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n# Latest ({{< version >}})\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/{{< version >}}/vector-{{< version >}}-aarch64-unknown-linux-musl.tar.gz | \\\n  tar xzf - -C vector --strip-components=2\n\n# Nightly\nmkdir -p vector && \\\n  curl -sSfL --proto '=https' --tlsv1.2 https://packages.timber.io/vector/nightly/latest/vector-nightly-aarch64-unknown-linux-musl.tar.gz | \\\n  tar xzf - -C vector --strip-components=2\n```\n\n----------------------------------------\n\nTITLE: Install Rust (Linux)\nDESCRIPTION: This command installs Rust using rustup, a tool for managing Rust versions. It downloads and executes the rustup installation script, specifying a stable toolchain and automatically answering 'yes' to prompts.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain stable\n```\n\n----------------------------------------\n\nTITLE: Cargo Deny Vulnerability Check\nDESCRIPTION: This snippet describes Vector's implementation of an automated `cargo deny` check as part of the Rust Security advisory database. This check ensures that the project's dependencies do not have known security vulnerabilities. The configuration for `cargo deny` along with the accepted advisories are maintained in a specific configuration file, and the check is run on every incoming PR.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/SECURITY.md#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\n- Vector implements an automated [`cargo deny` check][urls.cargo_deny]. This\n  is part of the [Rust Security advisory database][urls.rust_sec]. The configuration, and a\n  list of currently accepted advisories, are maintained in the\n  [Cargo Deny configuration][urls.cargo_deny_configuration]. The check is run\n  [on every incoming PR][urls.cargo_deny_schedule] to the Vector project.\n```\n\n----------------------------------------\n\nTITLE: Complex Fallible Expression - Coffee\nDESCRIPTION: This CoffeeScript-like VRL example demonstrates a complex fallible expression involving string concatenation and array access. It is not immediately clear which part of the program might be fallible, making it difficult to debug.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_11\n\nLANGUAGE: coffee\nCODE:\n```\n\"foo\" + .bar + baz[1]\n```\n\n----------------------------------------\n\nTITLE: GraphQL EventNotification Type New\nDESCRIPTION: This GraphQL snippet shows the new definition of the `EventNotification` type, which includes a `message` field and a `Notification` union. The `Notification` union allows for specific notification types with additional details, enhancing extensibility.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_4\n\nLANGUAGE: graphql\nCODE:\n```\ntype EventNotification {\n  notification: Notification!\n  message: String!\n}\n```\n\n----------------------------------------\n\nTITLE: Complex f-string example (Coffee)\nDESCRIPTION: This snippet shows a complex f-string example, illustrating a situation that the authors consider to be contrary to the VRL spirit.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_7\n\nLANGUAGE: coffee\nCODE:\n```\nf'This could { if contains(.thing, \"zonk\") ?? contains(.thunk, \"zork\") ?? false {\n  foreach(.zeek) -> {\n    f'My god what { object!(parse_json!(.zork)).zoog } is going on'\n  }\n  else {\n...\n} be a bit complex'\n```\n\n----------------------------------------\n\nTITLE: Tailing Vector Logs (Homebrew)\nDESCRIPTION: This command tails the Vector log file when Vector is installed via Homebrew.  It requires `tail` utility to be available and the user to have read permissions on the log file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/level-up/troubleshooting.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\ntail -f /usr/local/var/log/vector.log\n```\n\n----------------------------------------\n\nTITLE: Go Goroutines Metric - Prometheus\nDESCRIPTION: This snippet indicates the current number of goroutines that exist in the Go program. It is used to monitor concurrency and potential resource contention.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_38\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_goroutines Number of goroutines that currently exist.\n# TYPE go_goroutines gauge\ngo_goroutines 23\n```\n\n----------------------------------------\n\nTITLE: Output Log Event (Reduced)\nDESCRIPTION: This is the resulting aggregated log event after the Reduce transform has processed the input events.  It combines data from multiple related events into a single event, including summed durations and other relevant fields. The final event contains the `request_id` as identifier.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-10-add-reduce-transform.md#_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"timestamp_start\": \"...\",\n  \"timestamp_end\": \"...\",\n  \"request_id\": \"abcd1234\",\n  \"request_path\": \"/path\",\n  \"request_params\": \"...\",\n  \"query_duration_ms\": 13.0,\n  \"render_duration_ms\": 2.3,\n  \"status\": 200,\n  \"response_duration_ms\": 5.2\n}\n```\n\n----------------------------------------\n\nTITLE: Assigning VRL Errors\nDESCRIPTION: Demonstrates how to assign errors in VRL using the assignment expression. If `parse_json` fails, the error message is assigned to `err`, and `structured` receives the empty object `{}`. The code then logs the error if it's not null, or merges the parsed JSON with the current object.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/vrl/errors.md#_snippet_0\n\nLANGUAGE: coffee\nCODE:\n```\nstructured, err = parse_json(\"not json\")\nif err != null {\n  log(\"Unable to parse JSON: \" + err, level: \"error\")\n} else {\n  . = merge(., structured)\n}\n```\n\n----------------------------------------\n\nTITLE: Bitmask OpCode and Data in Rust\nDESCRIPTION: This code snippet demonstrates how to bitmask the OpCode and data into a single usize. It extracts the OpCode and data by applying a bitmask and shifting bits based on usize::BITS. This approach aims to reduce the memory footprint of the OpCode representation in the Vector VM.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-11-12-9811-vrl-vm.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nOpCode = FromPrimitive::from_usize(instruction && (1_usize << (usize::BITS / 2)) - 1 << (usize::BITS / 2)))\ndata = instruction && (1_usize << (usize::BITS / 2)) - 1\n```\n\n----------------------------------------\n\nTITLE: Define Optional Field in Object in Rust\nDESCRIPTION: This example defines an object with an optional 'reason' field, which, if present, will be a string. The `or_undefined()` makes the field optional, meaning it may not exist in the object.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_20\n\nLANGUAGE: rust\nCODE:\n```\nKind::object(Collection::empty()\n              .with_known(\"reason\", Kind::bytes().or_undefined()))\n```\n\n----------------------------------------\n\nTITLE: JSON example after http source dedot removal\nDESCRIPTION: This JSON payload represents data after ingestion by the `http` source in Vector 0.11 and later. The key `first.second` retains the period.  This reflects the correction in Vector to prevent automatic dedotting of JSON keys. No specific upgrade action is required, but users must understand the change in data structure.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_3\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"first\": {\n    \"second\": \"value\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Uninstall Vector Package via APT\nDESCRIPTION: Removes the `vector` package from the system using the APT package manager. This command will remove the Vector binaries but might leave configuration files.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/apt.md#_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nsudo apt remove vector\n```\n\n----------------------------------------\n\nTITLE: Rust: Compiler State (Initial)\nDESCRIPTION: This Rust code shows the initial state tracking in the compiler, storing variable type definitions in a `HashMap`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\nmod state {\n  pub struct Compiler {\n      /// Stored internal variable type definitions.\n      variables: HashMap<Ident, assignment::Details>,\n\n      // ...\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: CloudWatch Metrics Dimensions Table Configuration (Alternative)\nDESCRIPTION: Presents an alternative TOML configuration for defining dimensions as a table within the `aws_cloudwatch_metrics` source. This snippet demonstrates how dimensions could be structured using a table format, but the RFC indicates that this approach was not adopted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-09-28-cloudwatch-metrics.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[[sources.cloudwatch.metrics.dimensions]]\n  key = \"InstanceId\"\n  value = \"i-05517fbc2e6124dfb\"\n```\n\n----------------------------------------\n\nTITLE: Adding Source Metadata to Schema Definition in Rust\nDESCRIPTION: This code snippet demonstrates how to add source-specific metadata to the schema definition. It specifies the source name, legacy path (if applicable), Vector path, data kind, and meaning. `NatsSourceConfig::NAME` provides the source name, `legacy_subject_key_field` specifies the path for the legacy namespace, `owned_value_path!(\"subject\")` specifies the path for the Vector namespace, `Kind::bytes()` indicates the data type, and `None` indicates no specific meaning.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_12\n\nLANGUAGE: rust\nCODE:\n```\n      .with_source_metadata(\n          NatsSourceConfig::NAME,\n          legacy_subject_key_field,\n          &owned_value_path!(\"subject\"),\n          Kind::bytes(),\n          None,\n      );\n```\n\n----------------------------------------\n\nTITLE: Moving NATS Credentials (JWT)\nDESCRIPTION: This shell command moves the generated NATS credentials to the `tests/data/nats` directory, placing them in the expected location for the test suite.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/tests/data/nats/README.md#_snippet_3\n\nLANGUAGE: Shell Session\nCODE:\n```\n# Now move these credentials to the right location, since they don't just drop into the current directory.\n$ mv ~/.nkeys/creds/memory/A/TA.creds tests/data/nats/nats.creds\n```\n\n----------------------------------------\n\nTITLE: Compile Root Expressions Function - Rust\nDESCRIPTION: This Rust code snippet demonstrates the initial implementation of the `compile_root_exprs` function.  It compiles each root expression and checks if it's fallible, pushing an error if it is.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_12\n\nLANGUAGE: rust\nCODE:\n```\nfn compile_root_exprs(\n    &mut self,\n    nodes: impl IntoIterator<Item = Node<ast::RootExpr>>,\n) -> Vec<Expr> {\n    // ...\n}\n\n```\n\nLANGUAGE: rust\nCODE:\n```\nfor expr in root_expressions {\n    let expr = self.compile_expr(expr);\n\n    if expr.is_fallible() {\n        self.errors.push(ExpressionError);\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: f-string error handling (Coffee)\nDESCRIPTION: This snippet illustrates how errors should be handled in f-strings by handling errors to provide alternative text if needed and by ensuring that the format strings are valid for the given type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-27-7117-vrl-string-interpolation.md#_snippet_6\n\nLANGUAGE: coffee\nCODE:\n```\n\"This is some json {{ parse_json(.thing) ?? \"oops\" }}'\n# This is some json oops\n```\n\nLANGUAGE: coffee\nCODE:\n```\nthing = 2\nf'The date is {thing: %v %R}.'\n```\n\nLANGUAGE: coffee\nCODE:\n```\nf'The date is {timestamp!(thing): %v %R}.'\n```\n\n----------------------------------------\n\nTITLE: Data Directory Configuration (Shell)\nDESCRIPTION: Shows the default data_dir configuration option in the Vector config.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_13\n\nLANGUAGE: shell\nCODE:\n```\ndata_dir = \"/var/lib/vector\" # default\n```\n\n----------------------------------------\n\nTITLE: Metrics Serialization (New) JSON\nDESCRIPTION: This snippet shows the new JSON format for a counter metric in Vector. The 'counter' field is now a top-level field, directly containing the metric's value.  This change simplifies the structure and makes it more explicit.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-04-07-use-external-tagging-for-metrics-serialization.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"login.count\",\n  \"timestamp\": \"2019-11-01T21:15:47+00:00\",\n  \"kind\": \"absolute\",\n  \"tags\": {\n    \"host\": \"my.host.com\"\n  },\n  \"counter\": {\n    // <-- metric type\n    \"value\": 24.2\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Run local preview build in Shell\nDESCRIPTION: This shell command shows how to run the full CI builds locally, including link checking for the preview environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\n# Preview\nmake local-preview-build\n```\n\n----------------------------------------\n\nTITLE: Datadog Logs Original Record\nDESCRIPTION: Illustrates the initial structure of a log record before mutation for the Datadog Agent protocol. Contains key-value pairs, with a potential pre-existing 'message' field, and other fields.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/changelog.d/datadog_agent_http_header.fix.md#_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"key1\": \"value1\",\n  \"key2\": { \"key2-1\" : \"value2\" },\n  \"message\" : \"Hello world\",\n  ... rest of reserved fields\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Lua CSV Module\nDESCRIPTION: This bash command downloads the `lua-csv` module from its GitHub repository.  This module is used for parsing the CSV log entries in the Lua transform. It's saved as `csv.lua` in the same directory as `vector.toml`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/parsing-csv-logs-with-lua.md#_snippet_3\n\nLANGUAGE: Bash\nCODE:\n```\ncurl -o csv.lua https://raw.githubusercontent.com/geoffleyland/lua-csv/d20cd42d61dc52e7f6bcb13b596ac7a7d4282fbf/lua/csv.lua\n```\n\n----------------------------------------\n\nTITLE: Simulating Rate Limiting on the Server\nDESCRIPTION: This shell command simulates rate limiting on the server by setting the HTTP status code to 429 (Too Many Requests).  It is used to trigger retry logic in Vector's HTTP sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/developer/debugging.md#_snippet_21\n\nLANGUAGE: shell\nCODE:\n```\ncurl -X POST http://localhost:8000/set_status -H \"Content-Type: application/json\" -d '{\"status\": 429}'\n```\n\n----------------------------------------\n\nTITLE: Canonical Log Line Example\nDESCRIPTION: This is an example of a canonical log line, demonstrating the concept of aggregating key telemetry into a single log entry. It shows various fields and their corresponding values within a single log line.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-07-10-add-reduce-transform.md#_snippet_0\n\nLANGUAGE: log\nCODE:\n```\n[2019-03-18 22:48:32.999] canonical-log-line alloc_count=9123 auth_type=api_key database_queries=34 duration=0.009 http_method=POST http_path=/v1/charges http_status=200 key_id=mk_123 permissions_used=account_write rate_allowed=true rate_quota=100 rate_remaining=99 request_id=req_123 team=acquiring user_id=usr_123\n```\n\n----------------------------------------\n\nTITLE: Disk Buffer Configuration Seeds\nDESCRIPTION: These lines represent seeds used to configure the disk buffer and its associated actions during testing.  Each line starts with a checksum ('cc') followed by a configuration that defines parameters like data directory, buffer size, file size, record size, write buffer size, flush interval, and a filesystem implementation. The 'actions' part specifies a sequence of operations performed on the buffer during testing, such as writing records, reading records, acknowledging reads, and flushing writes. These seeds are essential for reproducing specific failure scenarios within the disk buffer.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-buffers/proptest-regressions/variants/disk_v2/tests/model/mod.txt#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncc e1f1bcb464e296542db2d646fff85a885f7ac491ccaca7a9ff1a339bafe4b954 # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 64, max_data_file_size: 2, max_record_size: 34498, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 }), ReadRecord, ReadRecord]\ncc 5d5d1f2f1087a02c0f76ed9506cba3e40d0c300340b0a33e719d8bb3e0bc8b1e # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 64, max_data_file_size: 2, max_record_size: 62345, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 61385, event_count: 1 }), ReadRecord, AcknowledgeRead(1), ReadRecord]\ncc 80077436fe364525dcab4e5878d617db14fae6e23a7e79f820ed592ce4614a8d # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 22040, max_data_file_size: 22040, max_record_size: 12465, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 9469, event_count: 1 }), WriteRecord(Record { id: 0, size: 12453, event_count: 1 }), FlushWrites, FlushWrites, WriteRecord(Record { id: 0, size: 0, event_count: 1 })]\ncc 59a105fb23544ce39ad8e81f86628618eca77fb34143ff0c4fdd15640ad37705 # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 154624, max_data_file_size: 2, max_record_size: 42615, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [FlushWrites, WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 })]\ncc 4b521a9a467f44e9cbc30d830624c03605522f0310e3e972409ac7f0c42d20cd # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 64, max_data_file_size: 2, max_record_size: 1714, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 5, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 }), WriteRecord(Record { id: 0, size: 0, event_count: 1 })]\ncc 99f23327ef7e759a9cb6424a3fa3495aaf4f1c7ef23145b5f5d72eb6cc5e0173 # shrinks to config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 64, max_data_file_size: 2, max_record_size: 61398, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 61381, event_count: 1 })]\ncc 54be1ee096dc5169013a1cd8a114f23c5aca7a209a663d783c7f74b4c4ff4746 # shrinks to mut config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 153516, max_data_file_size: 14228, max_record_size: 14214, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { inner: Mutex { data: FilesystemInner { files: {} } } } }, actions = [WriteRecord(Record { id: 0, size: 14163, event_count: 1 })]\ncc d812fdee8da4aae904579f08cadae1b585944da58040cad4f18544a87faf240e # shrinks to mut config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 53736, max_data_file_size: 46808, max_record_size: 28912, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { files: {} } }, actions = [WriteRecord(Record { id: 0, size: 23565, event_count: 1, aligned_len: 23632 }), WriteRecord(Record { id: 0, size: 18445, event_count: 1, aligned_len: 18512 }), WriteRecord(Record { id: 0, size: 11557, event_count: 1, aligned_len: 11616 })]\ncc b08fb47ac81e9148d8dc6a4d3332e92c21751685be9da9bd0c5d962ad7436285 # shrinks to mut config = DiskBufferConfig { data_dir: \"/tmp/vector-disk-v2-model\", max_buffer_size: 69602, max_data_file_size: 2462, max_record_size: 2450, write_buffer_size: 61440, flush_interval: 10s, filesystem: TestFilesystem { files: {} } }, actions = [WriteRecord(Record { id: 0, size: 2389, event_count: 1, archived_len: 2464 })]\n```\n\n----------------------------------------\n\nTITLE: Deprecated Shortand Encoding Setting in Vector TOML\nDESCRIPTION: This TOML snippet shows the deprecated shorthand way to set encoding, which should be replaced by explicitly setting `encoding.codec`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_18\n\nLANGUAGE: toml\nCODE:\n```\nencoding = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Restarting Vector Aggregator in Kubernetes\nDESCRIPTION: Restarts the Vector aggregator statefulset in a Kubernetes cluster using kubectl.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/administration/management.md#_snippet_16\n\nLANGUAGE: shell\nCODE:\n```\nkubectl rollout restart --namespace vector statefulset/vector-aggregator\n```\n\n----------------------------------------\n\nTITLE: Installing and Running Rustfmt\nDESCRIPTION: This code snippet shows how to install `rustfmt` and format the code using `make`. `rustfmt` is used to ensure consistent code style across the project. It requires Rustup to be installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n# To install rustfmt\nrustup component add rustfmt\n\n# To format the code\nmake fmt\n```\n\n----------------------------------------\n\nTITLE: VRL Function Definition: emit_log\nDESCRIPTION: This is the syntax for the definition of the `emit_log` function in VRL. This allows the object passed in to be emitted and flushed downstream and will have metadata copied from the input event.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_15\n\nLANGUAGE: text\nCODE:\n```\nemit_log(value: Object)\n```\n\n----------------------------------------\n\nTITLE: Remap Transform with Dropped Events Routing in Vector (TOML)\nDESCRIPTION: This configuration snippet demonstrates how to route failed events from a `remap` transform to an `aws_s3` sink using Vector's `dropped` output channel. It requires a `datadog_agent` source and a `datadog_logs` sink.  The `reroute_dropped` option must be enabled in the transform.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/going-to-prod/high-availability.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[sources.input]\n    type = \"datadog_agent\"\n\n[transforms.parsing]\n    inputs = [\"input\"]\n    type = \"remap\"\n    reroute_dropped = true\n    source = \"...\"\n\n[sinks.analysis]\n    inputs = [\"parsing\"]\n    type = \"datadog_logs\"\n\n[sinks.backup]\n    inputs = [\"**parsing.dropped**\"] # dropped events from the `parsing` transform\n    type = \"aws_s3\"\n```\n\n----------------------------------------\n\nTITLE: Listing Data Directories After Vector Fix (Shell)\nDESCRIPTION: This snippet lists the contents of the `/tmp/vector/github-10430/` directory after running the `vector-fix` command. It is used to verify the buffer directory has been renamed from `http_tarpit_buffer` to `http_tarpit_id`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_9\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:27 http_tarpit_id\n```\n\n----------------------------------------\n\nTITLE: Running Vector Fix with Config (Shell)\nDESCRIPTION: This snippet runs the `vector-fix` command (assumed to be a specialized executable) with a specified configuration file (`config.toml`). This is likely intended to perform maintenance or repair operations related to the Vector setup, such as buffer directory migration.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./vector-fix -c config.toml\n2022-01-13T02:27:07.943754Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-13T02:27:07.943797Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-13T02:27:07.944311Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-13T02:27:07.944328Z  INFO buffers::disk: Migrated old buffer data directory from '/tmp/vector/github-10430/http_tarpit_buffer' to '/tmp/vector/github-10430/http_tarpit_id' for 'http_tarpit' sink.\n2022-01-13T02:27:07.976821Z  INFO vector::topology::running: Running healthchecks.\n2022-01-13T02:27:07.976842Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-13T02:27:07.976852Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-13T02:27:07.976865Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-13T02:27:07.976894Z  INFO vector: Vector has started. debug=\"false\" version=\"0.20.0\" arch=\"x86_64\" build_id=\"none\"\n2022-01-13T02:27:08.978664Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-13T02:27:09.979975Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-01-13T02:27:10.628838Z  INFO vector: Vector has stopped.\n2022-01-13T02:27:10.628900Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-13T02:27:10.630025Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-01-13T02:27:10.981790Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-01-13T02:27:12.522956Z  INFO vector: Vector has quit.\n```\n\n----------------------------------------\n\nTITLE: Implementing the StreamSink Trait for BasicSink in Rust\nDESCRIPTION: This code implements the `StreamSink` trait for the `BasicSink` struct. It defines the `run` function, which receives a stream of events and calls the `run_inner` method to process them. The `run` function is required to handle lifetime issues that arise from using the `async_trait` crate.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/1_basic_sink.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\n#[async_trait::async_trait]\nimpl StreamSink<Event> for BasicSink {\n    async fn run(\n        self: Box<Self>,\n        input: futures_util::stream::BoxStream<'_, Event>,\n    ) -> Result<(), ()> {\n        self.run_inner(input).await\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Loading Sinks from Directory (Rust)\nDESCRIPTION: This Rust code snippet shows how Vector loads sink configurations from a specific directory.  It iterates through the files in the given directory, attempts to load each file as a sink configuration, and adds the sink to the `ConfigBuilder` along with its input configurations.  Errors during the loading process are added to the error vector. It's called by `load_builder_from_dir` when a \"sinks\" subdirectory is encountered.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-12-9568-automatic-namespacing.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n// same with transforms, sources, tests, enrichment_tables\nfn load_sinks_from_dir(path: &Path, builder: &mut ConfigBuilder, errors: &mut Vec<String>) {\n  for child in path.children() {\n    if child.is_file() {\n      match load_sink_from_file(child) {\n        Ok(sink) => builder.add_sink(child.name(), sink.inputs, sink.inner),\n        Err(msg) => errors.push(msg),\n      };\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: TOML Configuration - Disk Buffer\nDESCRIPTION: This TOML snippet demonstrates configuring a Vector disk buffer.  It sets the buffer type to 'disk' and specifies the maximum number of bytes to use as 1,000,000,000.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/specs/configuration.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\nbuffer.type = \"disk\"\nbuffer.disk.max_bytes = 1_000_000_000\n```\n\n----------------------------------------\n\nTITLE: Define Object with Unknown String Fields in Rust\nDESCRIPTION: This Rust code snippet shows how to define an object where all fields are strings, without specifying the field names. The `with_unknown(Kind::bytes())` indicates that any field in the object will be a byte array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_17\n\nLANGUAGE: rust\nCODE:\n```\nKind::object(Collection::empty().with_unknown(Kind::bytes()))\n```\n\n----------------------------------------\n\nTITLE: Generic Event Struct Example\nDESCRIPTION: This snippet shows a possible implementation of a more generic event struct, which might be an alternative to specific events. Such structs can be easily and consistently used, but can include less contextual information and can be more verbose.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-17-2064-event-driven-observability.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\npub struct EventReceived {\n    pub source_type: &'static str,\n    pub byte_size: usize,\n}\n```\n\n----------------------------------------\n\nTITLE: Install Vector into Systemd (Shell)\nDESCRIPTION: Installs Vector into Systemd by copying the service file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ncp -av etc/systemd/vector.service /etc/systemd/system\n```\n\n----------------------------------------\n\nTITLE: Skipping Tests with ci-condition Label\nDESCRIPTION: This snippet shows the label used to skip tests for changes in Vector. Applying this label to a pull request will prevent the CI from running tests.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nci-condition: skip\n```\n\n----------------------------------------\n\nTITLE: Program Struct new Function\nDESCRIPTION: Defines the `new` function to initialize a program from source code and function definitions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\npub fn new(source: &str, function_definitions: &[Box<dyn Function>]) -> Result<Self>;\n```\n\n----------------------------------------\n\nTITLE: Aggregated Metric Event Input (YAML)\nDESCRIPTION: This YAML configuration shows how to define an aggregated metric event as input to a Vector unit test.  It defines the structure of the aggregated histogram, including buckets, sum, and count.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_17\n\nLANGUAGE: yaml\nCODE:\n```\ntests:\n  inputs:\n    insert_at: my_aggregate_metrics_transform\n    type: metric\n    metric:\n      name: http_rtt\n      kind: incremental\n      aggregated_histogram:\n        buckets: []\n        sum: 0\n        count: 0\n```\n\n----------------------------------------\n\nTITLE: Creating Clean Data Directories\nDESCRIPTION: This shell script creates a clean environment by removing the target directory and recreating it to avoid conflicts with previous runs. It ensures a consistent starting point for the Vector tests.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_11\n\nLANGUAGE: shell\nCODE:\n```\n./create-clean-data-directories.sh\n```\n\n----------------------------------------\n\nTITLE: Uninstall Vector using pacman\nDESCRIPTION: Uninstalls the Vector package using pacman. The `-Rs` flags remove the package and its dependencies that are no longer required. Requires sudo privileges to remove system packages.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/pacman.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo pacman -Rs vector\n```\n\n----------------------------------------\n\nTITLE: JSON Example\nDESCRIPTION: A JSON example showing a nested structure that is used as context for explaining the problems with dynamic paths in recursive for-loops.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_44\n\nLANGUAGE: JSON\nCODE:\n```\n{ \"foo\": { \"bar\": true } }\n```\n\n----------------------------------------\n\nTITLE: External Resource Definitions in Rust\nDESCRIPTION: This code snippet defines the enums and struct used to represent external resource definitions in Vector. It includes `ResourceCodec`, `ResourceDirection`, `ResourceDefinition`, and `ExternalResource`, which specify the codec, direction, definition of the external resource.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-11-04-automatic-component-validation.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\npub enum ResourceCodec {\n    Encoding(EncodingConfig),\n    EncodingWithFraming(EncodingConfigWithFraming),\n    Decoding(DecodingConfig),\n    DecodingWithFraming(DecodingConfig, decoding::FramingConfig),\n}\n\npub enum ResourceDirection {\n    Push,\n    Pull\n}\n\npub enum ResourceDefinition {\n    Http(HttpConfig),\n    Socket(SocketConfig),\n}\n\npub struct ExternalResource {\n    definition: ResourceDefinition,\n    direction: ResourceDirection,\n    codec: ResourceCodec,\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Directory Contents\nDESCRIPTION: The `ls -l` command is used to list the contents of the /tmp/vector/github-10430/ directory. It helps verify the initial state and observe the creation of directories by Vector during its execution, specifically for the `http_tarpit` sink.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10430/\n```\n\n----------------------------------------\n\nTITLE: VRL map Function Example with Closure\nDESCRIPTION: Demonstrates the proposed syntax for using the `map` function with a closure in VRL.  The closure receives a key and a value, and the code returns a new array containing the key and value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_31\n\nLANGUAGE: coffee\nCODE:\n```\nmap(.) -> |k, v| { [k, v] }\n```\n\n----------------------------------------\n\nTITLE: Running Vector Integration Tests\nDESCRIPTION: These commands allow you to start, run, and stop Vector integration tests using the `cargo vdev` tool.  The `start` command initializes the testing environment, the `test` command executes the tests, and the `stop` command cleans up the environment. The `NAME` refers to the test name and `ENVIRONMENT` refers to the specific test environment to run.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/scripts/integration/README.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ncargo vdev integration start NAME ENVIRONMENT\ncargo vdev integration test NAME [ENVIRONMENT]\ncargo vdev integration stop NAME [ENVIRONMENT]\n```\n\n----------------------------------------\n\nTITLE: CUE String Description - Bad Indentation (2)\nDESCRIPTION: This CUE snippet demonstrates incorrect indentation for a multi-line string description. The extra spaces after the opening triple quotes will cause validation errors.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_9\n\nLANGUAGE: cue\nCODE:\n```\ndescription: \"\"\"\n    Here is a long string...\n        \"\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Changelog Fragment Example\nDESCRIPTION: This example demonstrates the structure and content of a changelog fragment file for a breaking change, including the file name and content with line breaks to explain the change.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/changelog.d/README.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n$ cat changelog.d/42_very_good_words.breaking.md\nThis change is so great. It's such a great change that this sentence\nexplaining the change has to span multiple lines of text.\n\nIt even necessitates a line break. It is a breaking change after all.\n```\n\n----------------------------------------\n\nTITLE: Checking Code Formatting\nDESCRIPTION: This command ensures that all code is properly formatted. Code can be run through `rustfmt` using `cargo fmt` to ensure it is properly formatted.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md#_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\ncargo vdev check fmt\n```\n\n----------------------------------------\n\nTITLE: Return Compression::None - Rust\nDESCRIPTION: Implements the `compression` function for `BasicRequestBuilder`, indicating that no compression will be applied to the payload.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/sinks/2_http_sink.md#_snippet_9\n\nLANGUAGE: rust\nCODE:\n```\n    fn compression(&self) -> Compression {\n        Compression::None\n    }\n```\n\n----------------------------------------\n\nTITLE: Defining FramingConfig and ParserConfig traits in Rust\nDESCRIPTION: These traits define the interface for framing and parsing configurations, respectively. They use `typetag` for serialization and deserialization based on the \"method\" (for FramingConfig) and \"codec\" (for ParserConfig) tags, enabling dynamic dispatch of framing and parsing logic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-06-8619-framing-and-codecs-sources.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\npub type BoxedFramer = Box<dyn Framer + Send + Sync>;\n\npub type BoxedParser = Box<dyn Parser + Send + Sync + 'static>;\n\n#[typetag::serde(tag = \"method\")]\npub trait FramingConfig: Debug + DynClone + Send + Sync {\n    fn build(&self) -> BoxedFramer;\n}\n\n#[typetag::serde(tag = \"codec\")]\npub trait ParserConfig: Debug + DynClone + Send + Sync {\n    fn build(&self) -> BoxedParser;\n}\n```\n\n----------------------------------------\n\nTITLE: Use VRL in vanilla JavaScript\nDESCRIPTION: This JavaScript code snippet shows how to import and use the 'run_vrl' function from the './vrl_web_playground.js' module in vanilla JavaScript. It initializes the WASM module and then makes the `run_vrl` function available globally.  The result of executing VRL code with a given input is logged to the console.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nimport init, { run_vrl } from \"./vrl_web_playground.js\";\nlet vrlInput = {};\ntry {\n    vrlInput = {\n        program: '.something = \"added by vrl!\"\\n.message = \"modified by vrl!\"',\n        event: JSON.parse('{message: \"log message here\"}'),\n    };\n} catch (error) {\n    console.log('error parsing the event contents as JSON object');\n}\ninit().then(() => {\n    window.run_vrl = run_vrl;\n    console.log(run_vrl(vrlInput));\n});\n```\n\n----------------------------------------\n\nTITLE: Expression Trait Definition (Extended)\nDESCRIPTION: Extends the `Expression` trait with a `resolves_to` function that describes the possible `ValueKind`s the expression can resolve to at compile-time. This function enables compile-time type checking.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_1\n\nLANGUAGE: rust\nCODE:\n```\npub trait Expression: Send + Sync {\n    fn execute(&self, state: &mut State, object: &mut dyn Object) -> Result<Option<Value>>;\n\n    /// Describes which [`ValueKind`]s the expression can resolve to.\n    ///\n    /// bike-shedding of function and enum names welcome.\n    fn resolves_to(&self) -> ResolveKind;\n}\n```\n\n----------------------------------------\n\nTITLE: Relabeling Vector Source Code for SELinux\nDESCRIPTION: This snippet is required when using SELinux in Enforcing mode.  It relabels the Vector source code directory so the Docker/Podman container has read/write access. The commands update the SELinux file context for the Vector directory and recursively apply the changes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd your/checkout/of/vector/\nsudo semanage fcontext -a \"${PWD}(/.*)?\" -t container_file_t\nsudo restorecon . -R\n```\n\n----------------------------------------\n\nTITLE: Unhandled Error Example - Coffee\nDESCRIPTION: This VRL example written in a CoffeeScript-like syntax shows an example of an unhandled error.  It attempts to parse `.message` with a grok pattern and merge the parsed result, which can result in a runtime error if parsing fails.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_16\n\nLANGUAGE: coffee\nCODE:\n```\nif (parsed  = parse_grok(.message, \"%{GREEDYDATA:parsed}\"); parsed != null) {\n  merge(., parsed)\n}\n```\n\n----------------------------------------\n\nTITLE: Define Event Metadata and Finalizer Structures in Rust\nDESCRIPTION: This code snippet defines the data structures used to manage event finalization, including `EventMetadata`, `EventFinalizer`, `BatchNotifier`, `BatchStatus`, and `EventStatus`. These structures track the status of events and facilitate communication between sources and sinks for acknowledgements.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-03-26-6517-end-to-end-acknowledgement.md#_snippet_0\n\nLANGUAGE: rust\nCODE:\n```\nstruct EventMetadata {\n    // … existing fields …\n    finalizers: Box<[Arc<EventFinalizer>]>,\n}\n\nstruct EventFinalizer {\n    status: EventStatus,\n    source: Arc<BatchNotifier>,\n    identifier: Uuid,\n}\n\nstruct BatchNotifier {\n    status: Mutex<BatchStatus>,\n    notifier: tokio::sync::oneshot::Sender<BatchStatus>,\n    identifier: Uuid,\n}\n\nenum BatchStatus {\n    Delivered,\n    Errored,\n    Failed,\n}\n\nenum EventStatus {\n    Dropped, // default status\n    Delivered,\n    Errored,\n    Failed,\n    Recorded,\n}\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Local Lock Time Metrics for Prometheus\nDESCRIPTION: This snippet defines Prometheus counter metrics for tracking how long MongoDB databases have held the local lock (in microseconds). It includes labels for database and lock type (read/write) for detailed monitoring.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_6\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_locks_time_locked_local_microseconds_total amount of time in microseconds that any database has held the local lock\n# TYPE mongodb_mongod_locks_time_locked_local_microseconds_total counter\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Collection\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Collection\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Database\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Database\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Global\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Global\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Mutex\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"Mutex\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"ParallelBatchWriterMode\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"ReplicationStateTransition\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"ReplicationStateTransition\",type=\"write\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"oplog\",type=\"read\"} 0\nmongodb_mongod_locks_time_locked_local_microseconds_total{database=\"oplog\",type=\"write\"} 0\n```\n\n----------------------------------------\n\nTITLE: Markdown Metadata for Release Notes\nDESCRIPTION: This Markdown snippet defines the metadata required for a release notes file. It includes the title, which should reflect the version, and the weight, which determines the ordering of the releases. Hugo uses the weight for sorting because it can't sort semantic versions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Vector v0.13.0 release notes\nweight: 19\n---\n\n```\n\n----------------------------------------\n\nTITLE: Inspect Vector's Created Directories\nDESCRIPTION: This snippet lists the contents of the Vector's data directory after running 'vector-fix'. This is to determine if any files were created and their names and permissions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_17\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:32 http_tarpit_id\n```\n\n----------------------------------------\n\nTITLE: Setting Framing Method in Vector TOML Configuration\nDESCRIPTION: This code snippet demonstrates how to set the framing method to \"newline_delimited\" in a Vector sink configuration file (TOML). The `framing.method` option specifies how encoded events are separated within a stream or batch. This example uses newline delimiters to separate events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_15\n\nLANGUAGE: toml\nCODE:\n```\nframing.method = \"newline_delimited\"\n```\n\n----------------------------------------\n\nTITLE: Creating Clean Data Directories\nDESCRIPTION: This shell script cleans existing data directories and creates new ones to ensure a clean testing environment for Vector.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n./create-clean-data-directories.sh\n```\n\n----------------------------------------\n\nTITLE: Uninstalling Vector with RPM\nDESCRIPTION: This command uninstalls Vector using the RPM package manager. It removes the Vector package from the system.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/package-managers/rpm.md#_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nsudo rpm -e vector\n```\n\n----------------------------------------\n\nTITLE: Listing Directory Contents\nDESCRIPTION: This shell command lists the contents of a specified directory, providing details about files and directories including permissions, ownership, size, and modification date.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10895/test-results.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10895\n```\n\n----------------------------------------\n\nTITLE: Division by Zero Example - Coffee\nDESCRIPTION: This VRL example in CoffeeScript-like syntax demonstrates an expression that will result in a runtime error because it attempts to divide 1 by 0.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_17\n\nLANGUAGE: coffee\nCODE:\n```\n1 / 0\n```\n\n----------------------------------------\n\nTITLE: Run Vector Version 0.18.1\nDESCRIPTION: This snippet executes a specific version (0.18.1) of Vector, using the 'config.toml' configuration file. The output shows the startup and shutdown logs, and implies an attempt to replicate behavior or a bug from a previous version.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_18\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./vector-v0.18.1 -c config.toml\n2022-01-13T02:33:16.321126Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info\"\n2022-01-13T02:33:16.321171Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-13T02:33:16.323128Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-13T02:33:16.355748Z  INFO vector::topology::running: Running healthchecks.\n2022-01-13T02:33:16.355778Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-13T02:33:16.355809Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-13T02:33:16.355806Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-13T02:33:16.355850Z  INFO vector: Vector has started. debug=\"false\" version=\"0.18.1\" arch=\"x86_64\" build_id=\"c4adb60 2021-11-30\"\n2022-01-13T02:33:16.355860Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n^C2022-01-13T02:33:18.543378Z  INFO vector: Vector has stopped.\n2022-01-13T02:33:18.543427Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-13T02:33:18.544521Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n```\n\n----------------------------------------\n\nTITLE: Check llvm targets built\nDESCRIPTION: This command lists the targets built by llvm. The output should include WebAssembly, indicating that llvm is configured to compile to WebAssembly.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nllvm-config --targets-built # WebAssembly should be in the results\n```\n\n----------------------------------------\n\nTITLE: Clone Vector Repository (Master, Windows)\nDESCRIPTION: These commands clone the Vector repository from GitHub. The user must have Git installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_8\n\nLANGUAGE: shell\nCODE:\n```\ngit clone https://github.com/vectordotdev/vector\ncd vector\n```\n\n----------------------------------------\n\nTITLE: Generating Component Documentation with Make\nDESCRIPTION: This command regenerates Vector's reference documentation from source code comments. It is essential for ensuring that the documentation reflects the latest changes in the codebase. It relies on the make tool.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DOCUMENTING.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmake generate-component-docs\n```\n\n----------------------------------------\n\nTITLE: Running Vector v0.18.1 (Shell)\nDESCRIPTION: Executes Vector version 0.18.1 with a specified configuration file. The command initializes Vector with the provided config and captures standard input. This version is used as a baseline or comparison point.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\n./vector-v0.18.1 -c config.toml\n```\n\n----------------------------------------\n\nTITLE: Define Array of Bytes in Rust\nDESCRIPTION: This code snippet demonstrates how to define an array where all elements are of the 'bytes' kind (string) using the Vector schema definition in Rust. The `Collection::empty()` creates an empty collection, and `with_unknown(Kind::bytes())` specifies that any element in the array will be a byte array.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/tutorials/lognamespacing.md#_snippet_14\n\nLANGUAGE: rust\nCODE:\n```\nKind::array(Collection::empty().with_unknown(Kind::bytes()))\n```\n\n----------------------------------------\n\nTITLE: Install Vector using installer script\nDESCRIPTION: This shell command downloads and executes the Vector installation script. It uses curl to retrieve the script and bash to execute it.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/vector-installer.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\ncurl --proto '=https' --tlsv1.2 -sSfL https://sh.vector.dev | bash\n```\n\n----------------------------------------\n\nTITLE: Check Property on Variable-Sized Array VRL\nDESCRIPTION: This VRL snippet checks if any object in the `array` has a property `a` equal to 2. It iterates through the array using `for_each` and sets the `any_two` variable to `true` if a matching object is found. This demonstrates finding a specific property in a list of objects.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_7\n\nLANGUAGE: coffee\nCODE:\n```\narray =  [{ \"a\": 2}, {\"a\": 3}]\nany_two = false\nfor_each(array) -> |_index, value| { if value == 2 { any_two = true } }\n```\n\n----------------------------------------\n\nTITLE: GraphQL Subscription Argument Update\nDESCRIPTION: This diff shows the renaming of the `patterns` argument to `outputsPatterns` in a GraphQL subscription for retrieving events by component ID patterns. This change aligns naming conventions and improves clarity.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: graphql\nCODE:\n```\n- subscription {\n-  outputEventsByComponentIdPatterns(patterns: [...])\n+ subscription {\n+  outputEventsByComponentIdPatterns(outputsPatterns: [...])\n```\n\n----------------------------------------\n\nTITLE: Storing Registered Event Handles\nDESCRIPTION: This snippet illustrates how to store registered event handles within a struct, showcasing the use of both the internal handle name and the `Handle` data type.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\nstruct RunningSource {\n    bytes_sent_alt1: <RegisteredEndpointBytesSent as RegisterInternalEvent>::Handle,\n    bytes_sent_alt2: EndpointBytesReceivedHandle,\n}\n```\n\n----------------------------------------\n\nTITLE: Invalid Configuration Validation\nDESCRIPTION: This snippet shows the output when an invalid Vector configuration file is validated using the `vector validate` command. It demonstrates the error message displayed when the configuration file fails to parse due to a missing field.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-06-10-consolidate-and-beautify-validate.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nvic@sticky-keyboard-macbook:/git/vectordotdev/vector$ vector validate test.toml\nFailed to parse \"test.toml\"\n---------------------------\nx missing field `type` for key `sinks.sink1`\n```\n\n----------------------------------------\n\nTITLE: Creating a Transform Span - Rust\nDESCRIPTION: Shows how a span is created for a transform task, including the component kind, name, type, and pipeline ID. The `pipeline_id` is optional and populated from the `Task`'s `ComponentId`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-19-8216-multiple-pipelines.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\nlet span = error_span!(\n    \"transform\",\n    component_kind = \"transform\",\n    component_name = %task.name(),\n    component_type = %task.typetag(),\n    pipeline_id = %task.pipeline_id(),\n);\n```\n\n----------------------------------------\n\nTITLE: Running vector top command in Bash\nDESCRIPTION: This bash command executes the `vector top` command, which is a CLI tool powered by the Vector GraphQL API that visualizes the Vector instance in a terminal dashboard. The `--url` parameter can be passed to specify a remote GraphQL endpoint.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/blog/graphql-api.md#_snippet_5\n\nLANGUAGE: Bash\nCODE:\n```\nvector top # pass --url <http://path/to/graphql> for remote observability\n```\n\n----------------------------------------\n\nTITLE: Defining Encoder Struct in Rust\nDESCRIPTION: This code defines the `Encoder` struct in Rust. The `Encoder` combines a `Serializer` and a `Framer` to encode structured events into byte messages. It implements the `tokio_util::codec::Encoder<Event>` trait.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-10-29-8621-framing-and-codecs-sinks.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\n/// An encoder that can encode structured events to byte messages.\npub struct Encoder {\n    serializer: BoxedSerializer,\n    framer: BoxedFramer,\n}\n```\n\n----------------------------------------\n\nTITLE: Expected Output JSON\nDESCRIPTION: This JSON output shows the expected result after applying the `remap` transform with the `abort` expression. Only the events with `type` equal to `ok` are output to the console sink, demonstrating the effect of the `abort` expression in filtering invalid events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-vrl-abort.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\"message\":\"valid message\",\"timestamp\":\"2021-04-20T20:26:05.214875Z\",\"type\":\"ok\"}\n{\"message\":\"valid message\",\"timestamp\":\"2021-04-20T20:26:06.213879Z\",\"type\":\"ok\"}\n{\"message\":\"valid message\",\"timestamp\":\"2021-04-20T20:26:07.214254Z\",\"type\":\"ok\"}\n{\"message\":\"valid message\",\"timestamp\":\"2021-04-20T20:26:08.215219Z\",\"type\":\"ok\"}\n```\n\n----------------------------------------\n\nTITLE: Executing Integration Tests with vdev (text)\nDESCRIPTION: These are example commands for executing integration tests using the `vdev int test` command. The command accepts an integration name, an optional environment name, and arbitrary extra arguments to pass to the test command. If no environment name is provided, all available environments are tested.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-31-15056-tooling-revamp.md#_snippet_4\n\nLANGUAGE: text\nCODE:\n```\nvdev int test elasticsearch\nvdev int test elasticsearch 7.13.1-classic\nvdev int test elasticsearch 8.4.3-classic -- --no-capture\n```\n\n----------------------------------------\n\nTITLE: HAProxy Configuration for Kubernetes Service Discovery\nDESCRIPTION: This HAProxy configuration leverages Kubernetes service discovery using CoreDNS to dynamically resolve downstream Vector instances. It defines a resolver, frontend, and backend for load balancing TCP traffic to Vector aggregators.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-05-17-7469-load-balancing-k8s-aggregators.md#_snippet_0\n\nLANGUAGE: haproxy\nCODE:\n```\nresolvers coredns\n    nameserver dns1 kube-dns.kube-system.svc.cluster.local:53\n    hold timeout         600s\n    hold refused         600s\nfrontend vector\n    bind *:9000\n    default_backend vector_template\nbackend vector_template\n    balance roundrobin\n    option tcp-check\n    server-template srv 10 _vector._tcp.vector-aggregator-headless.vector.svc.cluster.local resolvers coredns check\n```\n\n----------------------------------------\n\nTITLE: React Component using Urql with GraphQL Subscription\nDESCRIPTION: This React component uses the `Urql` library and a generated hook `useHeartbeatSubscription` from GraphQL Code Generator to subscribe to the `heartbeat` subscription and display the `utc` timestamp. The component fetches data every 1000ms.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3645-graphql-api.md#_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport React from \"react\";\n\n// This is generated for us by GraphQL Code Generator\nimport { useHeartbeatSubscription } from \"@/vector/graphql\";\n\n// Example component that consumes it\nconst ExampleComponent: React.FC = () => {\n  const [{ data, fetching }] = useHeartbeatSubscription({\n    variables: { interval: 1000 },\n  });\n  return <pre>{data?.utc}</pre>;\n};\n```\n\n----------------------------------------\n\nTITLE: Extending Elasticsearch Test Support Matrix (yaml)\nDESCRIPTION: This YAML snippet extends the support matrix for Elasticsearch integration tests to include multiple versions and types (classic and opensearch). This configuration indicates that the tests should be run against each combination of version and type defined in the matrix.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-31-15056-tooling-revamp.md#_snippet_2\n\nLANGUAGE: yaml\nCODE:\n```\nmatrix:\n- version: [\"7.13.1\", \"8.4.3\"]\n  type: [\"classic\"]\n\n- version: [\"1.3.6\", \"2.3.0\"]\n  type: [\"opensearch\"]\n```\n\n----------------------------------------\n\nTITLE: Vector Lua Transform: Log to Metric (Single Source)\nDESCRIPTION: This TOML configuration shows an alternative approach to the log-to-metric transform, using a single `source` option to define all Lua functions. It achieves the same functionality as the inline functions example but with a more organized structure. It uses the `hooks` section to specify the functions to be executed during the component lifecycle.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_6\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.lua]\n  type = \"lua\"\n  inputs = []\n  version = \"2\"\n  source = \"\"\"\n    function init (emit)\n      event_counter = 0\n      emit({\n        log = {\n          message = \"starting up\"\n        }\n      }, \\\"auxiliary\\\")\n    end\n\n    function process (event, emit)\n      event_counter = event_counter + 1\n    end\n\n    function shutdown (emit)\n      emit {\n        metric = {\n          name = \"counter_10s\",\n          counter = {\n            value = event_counter\n          }\n        }\n      }\n\n      emit({\n        log = {\n          message = \"shutting down\"\n        }\n      }, \\\"auxiliary\\\")\n    end\n\n    function timer_handler (emit)\n      emit {\n        metric = {\n          name = \"counter_10s\",\n          counter = {\n            value = event_counter\n          }\n        }\n      }\n      counter = 0\n    end\n  \"\"\"\n  hooks.init = \"init\"\n  hooks.process = \"process\"\n  hooks.shutdown = \"shutdown\"\n  timers = [{interval_seconds = 10, handler = \"timer_handler\"}]\n```\n\n----------------------------------------\n\nTITLE: Replacing Ellipsis with Suffix in truncate - Javascript\nDESCRIPTION: This snippet demonstrates how to replace the deprecated `ellipsis` argument with the `suffix` argument in the `truncate` function in VRL. It shows the old and new syntax for truncating a string with a custom suffix.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2025-02-24-0-45-0-upgrade-guide.md#_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\ntruncate(\"A rather long sentence.\", limit: 11, ellipsis: true)\n```\n\n----------------------------------------\n\nTITLE: Deprecated ndjson Encoding Setting in Vector TOML\nDESCRIPTION: This TOML snippet shows the deprecated way to set the `ndjson` encoding.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_20\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"ndjson\"\n```\n\n----------------------------------------\n\nTITLE: Common Unit Structures Definition\nDESCRIPTION: Defines common unit structures, such as `ByteSize`, used for providing the necessary data types when emitting registered events.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_6\n\nLANGUAGE: rust\nCODE:\n```\nstruct ByteSize(usize);\n\nstruct ByteSizeCount(usize, usize);\n```\n\n----------------------------------------\n\nTITLE: Installing vdev using Cargo\nDESCRIPTION: This command installs the vdev tool from the root of the Vector repository using cargo. The `-f` flag forces the installation, and `--path vdev` specifies the path to the vdev package.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/vdev/README.md#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ncargo install -f --path vdev\n```\n\n----------------------------------------\n\nTITLE: VRL `parse_regex` Example (0.13 and Later)\nDESCRIPTION: This example demonstrates the default behavior of the `parse_regex` function in VRL version 0.13 and later. By default, only named capture groups are returned.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_2\n\nLANGUAGE: text\nCODE:\n```\nparse_regex!(\"hello 123 world\", r'hello (?P<number>\\d+) world')\n```\n\n----------------------------------------\n\nTITLE: Component Configuration Example (TOML)\nDESCRIPTION: This TOML snippet shows a component configuration example where the 'parse_nginx' part is considered the ID. The documentation now refers to it as ID.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-25-0-16-upgrade-guide.md#_snippet_0\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.parse_nginx]\ntype = \"remap\"\ninputs = []\nsource = \"\"\n```\n\n----------------------------------------\n\nTITLE: Create and Inspect Vector Data Directories\nDESCRIPTION: This snippet executes a shell script to create clean data directories for Vector, and then lists the contents of the created directory to ensure it is empty.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_15\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 0\n```\n\n----------------------------------------\n\nTITLE: Podman Container Tool Selection (Optional)\nDESCRIPTION: This optional command sets the `CONTAINER_TOOL` environment variable to `podman`, instructing the `make` tasks to use Podman instead of Docker for container operations. It is useful for developers who prefer Podman as their containerization tool.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-05-25-2685-dev-workflow-simplification.md#_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# Optional: Only if you use `podman`\nexport CONTAINER_TOOL=\"podman\"\n```\n\n----------------------------------------\n\nTITLE: Reduce Transform Event 1 - JSON\nDESCRIPTION: This JSON represents the first event used in the reduce transform example. It includes fields such as 'id', 'an_array', and a nested 'message' object containing 'a' and 'b' fields. This example, together with Event 2, demonstrates the change in how nested fields are aggregated.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2024-07-29-0-40-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": 777,\n  \"an_array\": [\n    {\n      \"inner\": 1\n    }\n  ],\n  \"message\": {\n    \"a\": {\n      \"b\": [1, 2],\n      \"num\": 1\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: RegisterInternalEvent Trait Definition\nDESCRIPTION: This snippet defines the `RegisterInternalEvent` trait, which is responsible for registering a metric handle. The trait requires an associated type `Handle` that implements `InternalEventHandle` and a `register` function that consumes the event data and returns the handle.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-07-28-13691-registered-internal-events.md#_snippet_2\n\nLANGUAGE: rust\nCODE:\n```\ntrait RegisterInternalEvent: Sized {\n    type Handle: InternalEventHandle;\n    fn register(self) -> Self::Handle;\n}\n```\n\n----------------------------------------\n\nTITLE: VRL Program Node Graph (mermaid)\nDESCRIPTION: This mermaid code defines a graph representing the tree of program nodes that the VRL compiler generates from the provided VRL code. It illustrates how the Tree Walking interpreter navigates through these nodes to execute the program. The graph showcases the IF, PREDICATE, THEN, and ELSE branches, including the ASSIGN operations and field assignments.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-15-vrl-vm-beta.md#_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n    IF -->PREDICATE\n    PREDICATE -->Equals[==]\n    Equals -->Flag[.flag]\n    Equals -->42\n\n    IF -->THEN\n    THEN -->ASSIGN1[ASSIGN]\n    ASSIGN1 -->Field1[.field]\n    ASSIGN1 -->32\n\n    IF -->ELSE\n    ELSE -->ASSIGN2[ASSIGN]\n    ASSIGN2 -->Field2[.field]\n    ASSIGN2 -->15\n\n```\n\n----------------------------------------\n\nTITLE: JSON Example Input with Mixed Event Types for Remap Transform\nDESCRIPTION: This JSON object illustrates an input event that contains an array of mixed data types for the `events` field (objects and a number). The remap transform will handle this case by treating non-object elements as having a 'message' key.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-07-6330-emitting-multiple-log-events-from-remap-transform.md#_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{ \"host\": \"localhost\", \"events\": [{ \"message\": \"foo\" }, { \"message\": \"bar\" }, 1] }\n```\n\n----------------------------------------\n\nTITLE: CUE String Description - Good Indentation\nDESCRIPTION: This CUE snippet shows the correct indentation for a multi-line string description. Consistent indentation within the triple quotes is crucial for avoiding CUE validation errors.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_7\n\nLANGUAGE: cue\nCODE:\n```\ndescription: \"\"\"\n    Here is a long string...\n    \"\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Migrate Vector Sink Configuration\nDESCRIPTION: This code snippet shows the changes required to update a Vector sink configuration file (vector.toml) to the new format introduced in version 0.7.0. It involves moving `batch_*` options under a `batch` table, replacing `batch_size` with `batch.max_size`, moving `basic_auth` to an `auth` table with a `strategy` field, and moving `request_*` options under a `request` table. Note that `retry_backoff_secs` has been replaced with `retry_initial_backoff_secs` and `retry_max_duration_secs`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-01-12-request-options-refactored.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n [sinks.my_sink_id]\n   type = \"http\"\n   inputs = [\"my-source-id\"]\n   uri = \"https://10.22.212.22:9000/endpoint\"\n\n-  batch_size = 1049000\n+  [sinks.my_sink_id.batch]\n+    max_size = 1049000\n\n-  [sinks.my_sink_id.basic_auth]\n+  [sinks.my_sink_id.auth]\n+    strategy = \"basic\"\n     user = \"${USERNAME_ENV_VAR}\"\n     password = \"${PASSWORD_ENV_VAR}\"\n\n-  request_in_flight_limit = 5\n-  request_retry_backoff_secs = 1\n+  [sinks.my_sink_id.request]\n+    in_flight_limit = 5\n+    retry_initial_backoff_secs = 1\n+    retry_max_duration_secs = 10\n```\n\n----------------------------------------\n\nTITLE: DataDog Manifest Generation Script\nDESCRIPTION: This script is used by DataDog to generate Kubernetes manifests which keeps the raw and kustomize resources in sync with changes to the Helm charts. Vector can leverage a similar script to keep its own resources updated.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-07-23-8447-extract-helm-charts.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nhttps://github.com/DataDog/datadog-agent/blob/main/Dockerfiles/manifests/generate.sh\n```\n\n----------------------------------------\n\nTITLE: Start Vector (Windows)\nDESCRIPTION: This command starts the compiled Vector executable, specifying the path to the configuration file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-source.md#_snippet_10\n\nLANGUAGE: powershell\nCODE:\n```\n.\\target\\release\\vector --config config\\vector.toml\n```\n\n----------------------------------------\n\nTITLE: Definition of `closure::Definition` and related structs - Rust\nDESCRIPTION: This code defines the `closure::Definition`, `Input`, `Variable`, and `Output` structs and enums used to describe the expected input and output types of function closures. It provides a structured way to define the closure's expected behavior.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_38\n\nLANGUAGE: rust\nCODE:\n```\nmod closure {\n    /// The definition of a function-closure block a function expects to\n    /// receive.\n    struct Definition {\n        inputs: Vec<Input>,\n    }\n\n    /// One input variant for a function-closure.\n    ///\n    /// A closure can support different variable input shapes, depending on the\n    /// type of a given parameter of the function.\n    ///\n    /// For example, the `map` function takes either an `Object` or an `Array`\n    /// for the `value` parameter, and the closure it takes either accepts\n    /// `|key, value|`, where \"key\" is always a string, or `|index, value|` where\n    /// \"index\" is always a number, depending on the parameter input type.\n    struct Input {\n        /// The parameter name upon which this closure input variant depends on.\n        parameter: &'static str,\n\n        /// The value kind this closure input expects from the parameter.\n        kind: value::Kind,\n\n        /// The list of variables attached to this closure input type.\n        variables: Vec<Variable>,\n\n        /// The return type this input variant expects the closure to have.\n        output: Output,\n    }\n\n    /// One variable input for a closure.\n    ///\n    /// For example, in `{ |foo, bar| ... }`, `foo` and `bar` are each\n    /// a `ClosureVariable`.\n    struct Variable {\n        /// The value kind this variable will return when called.\n        kind: value::Kind,\n    }\n\n    enum Output {\n        Array {\n            /// The number, and kind of elements expected.\n            elements: Vec<value::Kind>,\n        }\n\n        Object {\n            /// The field names, and value kinds expected.\n            fields: HashMap<&'static str, value::Kind,\n        }\n\n        Scalar {\n            /// The expected scalar kind.\n            kind: value::Kind,\n        }\n\n        Any,\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Tag Struct Definition with MultiIndexMap in Rust\nDESCRIPTION: Defines a `Tag` struct with fields for `name` and `value`, using `multi_index_map` to allow indexing by both fields. This supports ordered access to tags and multiple values for a single tag. It's not clear if there is a way to control for unique values for the same name without also preventing the same value appearing in different tags, nor how those values would be ordered.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_5\n\nLANGUAGE: rust\nCODE:\n```\n#[derive(MultiIndexMap, Clone, Debug)]\nstruct Tag {\n    #[multi_index(ordered_non_unique)]\n    name: String,\n    value: Option<String>,\n}\n\ntype MetricTags = MultiIndexTagMap;\n```\n\n----------------------------------------\n\nTITLE: CompilerState Struct Definition\nDESCRIPTION: Defines the `CompilerState` struct, which acts as a compile-time store for tracking resolve kinds of variables and paths.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_8\n\nLANGUAGE: rust\nCODE:\n```\nstruct CompilerState {\n    variables: HashMap<String, ResolveKind>,\n\n    // …\n}\n```\n\n----------------------------------------\n\nTITLE: MetricTags Type Definition with MultiMap in Rust\nDESCRIPTION: Defines MetricTags as a multimap, which is a wrapper around a HashMap with a Vec in the value position. This allows storing multiple values for the same key, where the key represents a tag name, and the value represents the possible tag values. Note: it does not sort the keys on retrieval, changing the ordering guarantee that BTreeMap is currently providing.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_4\n\nLANGUAGE: rust\nCODE:\n```\ntype MetricTags = multimap::MultiMap<String, Option<String>>;\n```\n\n----------------------------------------\n\nTITLE: CloudWatch Logs Event Example 2\nDESCRIPTION: This JSON object represents another CloudWatch Logs event, containing more detailed information such as bytes transferred, datetime, HTTP method, request path, and user identifier. It also includes fields indicating the source AWS service and associated ARNs.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/guides/advanced/cloudwatch-logs-firehose.md#_snippet_20\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"bytes\": 17707,\n  \"datetime\": \"14/Sep/2020:11:45:41 -0400\",\n  \"host\": \"109.81.244.252\",\n  \"id\": \"35683658089659183914001456229543810359430816722590236673\",\n  \"log_group\": \"/test/vector\",\n  \"log_stream\": \"test\",\n  \"method\": \"GET\",\n  \"owner\": \"071959437513\",\n  \"protocol\": \"HTTP/2.0\",\n  \"referer\": \"http://www.investormission-critical.io/24/7/vortals\",\n  \"request\": \"/scale/functionalities/optimize\",\n  \"request_id\": \"ed1d787c-b9e2-4631-92dc-8e7c9d26d804\",\n  \"source_arn\": \"arn:aws:firehose:us-east-1:071959437513:deliverystream/jesse-test\",\n  \"source_type\": \"stdin\",\n  \"status\": 502,\n  \"subscription_filters\": [\n    \"Destination\"\n  ],\n  \"timestamp\": \"2020-09-14T19:09:29.041Z\",\n  \"user-identifier\": \"feeney1708\"\n}\n```\n\n----------------------------------------\n\nTITLE: Copyright Notice Boilerplate\nDESCRIPTION: This snippet represents the boilerplate copyright notice that should be included in files licensed under Apache 2.0. Replace the bracketed placeholders with the appropriate year and copyright owner name.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/proto/third-party/google/LICENSE-Apache-2.0.txt#_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nCopyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n```\n\n----------------------------------------\n\nTITLE: ValueKind Enum Definition\nDESCRIPTION: Defines the `ValueKind` enum, which lists the concrete value types supported by the Remap language. These types are used by `ResolveKind` to define the possible return types of an expression.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-11-02-remap-language-compile-time-type-checking-v1.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\npub enum ValueKind {\n    String,\n    Integer,\n    Float,\n    Boolean,\n    Timestamp,\n    Map,\n    Array,\n}\n```\n\n----------------------------------------\n\nTITLE: Aggregated Summary Metric Example in Lua\nDESCRIPTION: Minimal Lua code required to create an aggregated summary metric event. It includes metric name, quantiles, values, sum, and count.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-03-06-1999-api-extensions-for-lua-transform.md#_snippet_25\n\nLANGUAGE: lua\nCODE:\n```\n{\n  metric = {\n    name = \"example_summary\",\n    aggregated_summary = {\n      quantiles = {0.25, 0.5, 0.75},\n      values = {1.0, 2.0, 3.0},\n      sum = 200,\n      count = 100\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Recursive For-Loop Example\nDESCRIPTION: Demonstrates a recursive for-loop intended to modify keys within a nested structure, but highlights a problem where dynamic paths resolve to the root of the object, leading to unexpected results.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-29-8381-vrl-iteration-support.md#_snippet_45\n\nLANGUAGE: CoffeeScript\nCODE:\n```\nrecursive for (key, value) in . {\n  .[upcase(key)] = value\n}\n```\n\n----------------------------------------\n\nTITLE: Define MongoDB Repl Apply Batches Number Metric for Prometheus\nDESCRIPTION: This snippet defines a Prometheus counter metric for the total number of batches applied across all databases during replication in MongoDB.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_16\n\nLANGUAGE: Text\nCODE:\n```\n# HELP mongodb_mongod_metrics_repl_apply_batches_num_total num reports the total number of batches applied across all databases\n# TYPE mongodb_mongod_metrics_repl_apply_batches_num_total counter\nmongodb_mongod_metrics_repl_apply_batches_num_total 0\n```\n\n----------------------------------------\n\nTITLE: Setting the Repository Path in vdev Config\nDESCRIPTION: This command sets the repository path in the vdev configuration. Setting the path explicitly allows the application to be used regardless of the current working directory.  The dot (.) represents the current directory, typically the root of the Vector repository.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/vdev/README.md#_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nvdev config set repo .\n```\n\n----------------------------------------\n\nTITLE: VRL Split Function Error Example\nDESCRIPTION: This VRL code snippet and the corresponding error message highlight a common issue encountered after VRL type definition updates. The split function now expects a non-nullable string, and the error message suggests solutions such as ensuring the correct type or providing a default value.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nerror[E110]: invalid argument type\n  ┌─ :1:7\n  │\n1 │ split(msg, \" \")\n  │       ^^^\n  │       │\n  │       this expression resolves to one of string or null\n  │       but the parameter \"value\" expects the exact type string\n  │\n  = try: ensuring an appropriate type at runtime\n  =\n  =     msg = string!(msg)\n  =     split(msg, \" \")\n  =\n  = try: coercing to an appropriate type and specifying a default value as a fallback in case coercion fails\n  =\n  =     msg = to_string(msg) ?? \"default\"\n  =     split(msg, \" \")\n  =\n  = see documentation about error handling at https://errors.vrl.dev/#handling\n  = learn more about error code 110 at https://errors.vrl.dev/110\n  = see language documentation at https://vrl.dev\n  = try your code in the VRL REPL, learn more at https://vrl.dev/examples\n\n```\n\n----------------------------------------\n\nTITLE: Remove dns_servers from vector.toml\nDESCRIPTION: This code snippet shows the diff to remove the `dns_servers` configuration option from the `vector.toml` file. This configuration is no longer supported in Vector 0.10.0 and later.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-06-18-remove-custom-dns-resolution.md#_snippet_0\n\nLANGUAGE: diff\nCODE:\n```\n-  dns_servers = [...]\n```\n\n----------------------------------------\n\nTITLE: VRL Remainder Operator Before\nDESCRIPTION: This VRL snippet demonstrates the use of the remainder operator (%) before the upgrade. If `.value` was zero, Vector would panic.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-03-22-0-21-0-upgrade-guide.md#_snippet_7\n\nLANGUAGE: coffee\nCODE:\n```\n.remainder = 50 % .value\n```\n\n----------------------------------------\n\nTITLE: OpenSSL Legacy Provider Configuration\nDESCRIPTION: This configuration file enables the OpenSSL legacy provider, allowing Vector to use older and potentially insecure algorithms. It defines sections for default and legacy providers, activating both.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/tls.md#_snippet_0\n\nLANGUAGE: ini\nCODE:\n```\nopenssl_conf = openssl_init\n\n[openssl_init]\nproviders = provider_sect\n\n[provider_sect]\ndefault = default_sect\nlegacy = legacy_sect\n\n[default_sect]\nactivate = 1\n\n[legacy_sect]\nactivate = 1\n```\n\n----------------------------------------\n\nTITLE: Listing Data Directories After v0.18.1 (Shell)\nDESCRIPTION: This snippet lists the contents of the `/tmp/vector/github-10430/` directory after running Vector v0.18.1. It's used to check the created directory for the http_tarpit_buffer.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_7\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/bugs/github-10430$ ls -l /tmp/vector/github-10430/\ntotal 4\ndrwxr-xr-x 2 toby toby 4096 Jan 12 21:26 http_tarpit_buffer\n```\n\n----------------------------------------\n\nTITLE: Renaming prometheus sink in Vector TOML\nDESCRIPTION: This snippet illustrates renaming the `prometheus` sink to `prometheus_exporter` in Vector TOML configuration. This change was introduced in Vector 0.11 to differentiate it from the new `prometheus_remote_write` sink. Additionally, it shows renaming the `namespace` option to `default_namespace`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2020-12-01-0-11-upgrade-guide.md#_snippet_4\n\nLANGUAGE: TOML\nCODE:\n```\n[sinks.prometheus]\n-  type = \"prometheus\"\n+  type = \"prometheus_exporter\"\n-  namespace = \"...\"\n+  default_namespace = \"...\"\n```\n\n----------------------------------------\n\nTITLE: Creating Clean Data Directories (Shell)\nDESCRIPTION: This script ensures a clean environment before running Vector. It removes any existing data directories, ensuring a fresh start for each test execution. The output of the script is verified by listing the contents of the created directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n./create-clean-data-directories.sh\n```\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10430/\n```\n\n----------------------------------------\n\nTITLE: VRL Array Assignment Error Example (Before 0.24)\nDESCRIPTION: This VRL code demonstrates another example of querying a non-collection type on assignment, specifically an array index of an integer. This was allowed previously but is now rejected.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-08-16-0-24-0-upgrade-guide.md#_snippet_2\n\nLANGUAGE: coffee\nCODE:\n```\nfoo = 42\nfoo[0] = 3.14\n```\n\n----------------------------------------\n\nTITLE: JSON Output of `parse_regex` (Before 0.13)\nDESCRIPTION: This JSON represents the output of the `parse_regex` function in VRL before version 0.13. It includes the full match at index \"0\", numeric capture groups at index \"1\", and the named capture group \"number\".\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-04-21-0-13-upgrade-guide.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{ \"0\": \"hello 123 world\", \"1\": \"123\", \"number\": \"123\" }\n```\n\n----------------------------------------\n\nTITLE: Running CUE Build with Watchexec\nDESCRIPTION: This shell command uses watchexec to automatically run the CUE build process whenever changes are saved to CUE source files. This allows for incremental validation and faster feedback during CUE development. The command should be run in the 'website' directory.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_6\n\nLANGUAGE: shell\nCODE:\n```\nwatchexec \"make cue-build\"\n\n```\n\n----------------------------------------\n\nTITLE: Datadog Logs Sink Configuration with Encoding (TOML)\nDESCRIPTION: This TOML snippet shows the Datadog logs sink configuration with the 'encoding.codec' option. This option is removed in Vector 0.16.0, requiring users to remove this line.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2021-08-25-0-16-upgrade-guide.md#_snippet_1\n\nLANGUAGE: toml\nCODE:\n```\n[sinks.dd_logs_egress]\ntype = \"datadog_logs\"\ninputs = [\"datadog_agent\"]\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Formatting CUE Sources with cue.sh\nDESCRIPTION: This script formats CUE source files within the Vector project. It ensures that the CUE code adheres to the project's style guidelines, maintaining consistency and readability. This requires the CUE tool to be installed.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DOCUMENTING.md#_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n./website/scripts/cue.sh fmt\n```\n\n----------------------------------------\n\nTITLE: Creating Data Directories and Piping Input to Vector (v0.19.0)\nDESCRIPTION: This snippet creates clean data directories using a shell script. It then pipes the contents of the 'five-lines' file to the Vector binary (version 0.19.0) using a specified configuration file (config.toml). The output demonstrates Vector's initialization, data ingestion, and attempts to send data to the configured sink. It highlights Vector's logging and shutdown processes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-11039/test-results.md#_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ntoby@consigliere:~/src/vector/testing/github-11039$ ./create-clean-data-directories.sh\ntoby@consigliere:~/src/vector/testing/github-11039$ cat five-lines\nline one, woohoo\nline two, yippeee\nline three, oh my\nline four, woooooow\nlive five, phew, that was a lot\ntoby@consigliere:~/src/vector/testing/github-11039$ cat five-lines | ./vector-v0.19.0 --config config.toml\n2022-01-26T19:16:16.785776Z  INFO vector::app: Log level is enabled. level=\"vector=info,codec=info,vrl=info,file_source=info,tower_limit=trace,rdkafka=info,buffers=info\"\n2022-01-26T19:16:16.785818Z  INFO vector::app: Loading configs. paths=[\"config.toml\"]\n2022-01-26T19:16:16.786515Z  INFO vector::sources::stdin: Capturing STDIN.\n2022-01-26T19:16:16.815793Z  INFO vector::topology::running: Running healthchecks.\n2022-01-26T19:16:16.815824Z  INFO vector::topology::running: Starting source. key=stdin\n2022-01-26T19:16:16.815836Z  INFO vector::topology::builder: Healthcheck: Passed.\n2022-01-26T19:16:16.815846Z  INFO vector::topology::running: Starting sink. key=http_tarpit\n2022-01-26T19:16:16.815876Z  INFO vector: Vector has started. debug=\"false\" version=\"0.19.0\" arch=\"x86_64\" build_id=\"da60b55 2021-12-28\"\n2022-01-26T19:16:16.815886Z  INFO vector::app: API is disabled, enable by setting `api.enabled` to `true` and use commands like `vector top`.\n2022-01-26T19:16:16.815939Z  INFO vector::shutdown: All sources have finished.\n2022-01-26T19:16:16.815946Z  INFO vector: Vector has stopped.\n2022-01-26T19:16:16.815944Z  INFO source{component_kind=\"source\" component_id=stdin component_type=stdin component_name=stdin}: vector::sources::stdin: Finished sending.\n2022-01-26T19:16:16.817024Z  INFO vector::topology::running: Shutting down... Waiting on running components. remaining_components=\"http_tarpit\" time_remaining=\"59 seconds left\"\n2022-01-26T19:16:17.817876Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-26T19:16:18.819194Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n2022-01-26T19:16:19.820532Z  WARN sink{component_kind=\"sink\" component_id=http_tarpit component_type=http component_name=http_tarpit}:request{request_id=0}: vector::sinks::util::retries: Retrying after error. error=Failed to make HTTP(S) request: error trying to connect: tcp connect error: Connection refused (os error 111)\n^C2022-01-26T19:16:20.105954Z  INFO vector: Vector has quit.\ntoby@consigliere:~/src/vector/testing/github-11039$ ls -l /tmp/vector/github-11039/http_tarpit_id/\ntotal 20\n-rw-r--r-- 1 toby toby 639 Jan 26 14:16 000005.log\n-rw-r--r-- 1 toby toby  16 Jan 26 14:16 CURRENT\n-rw-r--r-- 1 toby toby   0 Jan 26 14:16 LOCK\n-rw-rw-r-- 1 toby toby 181 Jan 26 14:16 LOG\n-rw-rw-r-- 1 toby toby  60 Jan 26 14:16 LOG.old\n-rw-r--r-- 1 toby toby  50 Jan 26 14:16 MANIFEST-000004\n```\n\n----------------------------------------\n\nTITLE: Run local production build in Shell\nDESCRIPTION: These shell commands show how to run the full CI builds locally, including link checking for the production environment.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/README.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\n# Production\nmake local-production-build\n```\n\n----------------------------------------\n\nTITLE: VRL Mutation Error Message\nDESCRIPTION: This text shows the error message produced when trying to mutate a read-only value in a VRL condition, demonstrating the new compile-time check for mutations in conditions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nerror[E315]: mutation of read-only value\n  ┌─ :1:1\n  │\n1 │ .foo = \"bar\"\n  │ ^^^^^^ mutation of read-only value\n  │\n  = see language documentation at https://vrl.dev\n```\n\n----------------------------------------\n\nTITLE: package.json dependency\nDESCRIPTION: This JSON snippet shows the dependency entry for 'vrl-web-playground' in a package.json file. It specifies that version 0.1.0 of the package should be used.  This version was published for testing purposes.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/lib/vector-vrl/web-playground/README.md#_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n\"dependencies\": {\n    \"vrl-web-playground\": \"0.1.0\"\n}\n```\n\n----------------------------------------\n\nTITLE: Listing Directory Contents (Shell)\nDESCRIPTION: Lists the contents of a specific directory, allowing inspection of created files or directories. This is used to verify the outcome of other commands and observe side effects of Vector execution.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/testing/github-10430/test-results.md#_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10430/\n```\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10430/http_tarpit_buffer/\n```\n\nLANGUAGE: shell\nCODE:\n```\nls -l /tmp/vector/github-10430/http_tarpit_id/\n```\n\n----------------------------------------\n\nTITLE: Example Cargo Features Output\nDESCRIPTION: This is an example of the output generated when listing cargo features. It shows a list of strings, where each string represents a feature defined in the `Cargo.toml` file. These features can be used to conditionally compile code or enable/disable functionality within the Vector project.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-04-13-7027-core-extraction.md#_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n[\n  \"all-integration-tests\",\n  \"all-logs\",\n  \"all-metrics\",\n  \"api\",\n  \"api-client\",\n  \"aws-cloudwatch-logs-integration-tests\",\n  \"aws-cloudwatch-metrics-integration-tests\",\n  \"aws-ec2-metadata-integration-tests\",\n  \"aws-ecs-metrics-integration-tests\",\n  \"aws-integration-tests\",\n  \"aws-kinesis-firehose-integration-tests\",\n  \"aws-kinesis-streams-integration-tests\",\n  \"aws-s3-integration-tests\",\n  \"aws-sqs-integration-tests\",\n  \"benches\",\n  \"cli-tests\",\n  \"clickhouse-integration-tests\",\n  \"default\",\n  \"default-cmake\",\n  \"default-msvc\",\n  \"default-musl\",\n  \"default-no-api-client\",\n  \"default-no-vrl-cli\",\n  \"disable-resolv-conf\",\n  \"docker-logs-integration-tests\",\n  \"es-integration-tests\",\n  \"gcp-cloud-storage-integration-tests\",\n  \"gcp-integration-tests\",\n  \"gcp-pubsub-integration-tests\",\n  \"humio-integration-tests\",\n  \"influxdb-integration-tests\",\n  \"kafka-integration-tests\",\n  \"kubernetes\",\n<SNIP>\n\n```\n\n----------------------------------------\n\nTITLE: Install Vector into Init.d (Shell)\nDESCRIPTION: Installs Vector into init.d by copying the service file.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_14\n\nLANGUAGE: shell\nCODE:\n```\ncp -av etc/init.d/vector /etc/init.d\n```\n\n----------------------------------------\n\nTITLE: Create Data Directory (Shell)\nDESCRIPTION: Creates a data directory for Vector to use.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/setup/installation/manual/from-archives.md#_snippet_12\n\nLANGUAGE: shell\nCODE:\n```\nmkdir /var/lib/vector\n```\n\n----------------------------------------\n\nTITLE: Replacement for ndjson Encoding\nDESCRIPTION: This TOML snippet shows the replacement for the `ndjson` encoding by simply setting `json`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/highlights/2022-07-07-0-23-0-upgrade-guide.md#_snippet_22\n\nLANGUAGE: toml\nCODE:\n```\nencoding.codec = \"json\"\n```\n\n----------------------------------------\n\nTITLE: Rust Tag Representation\nDESCRIPTION: Illustrates the Rust implementation of the tag representation using a newtype wrapper around `indexmap::IndexSet`. It includes methods for inserting, replacing, and removing tag values, with `TagValue` being an optional string to represent bare tags.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2022-10-12-14742-flexible-metric-tags.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\ntype TagValue = Option<String>;\n\nstruct TagValueSet(indexmap::IndexSet<TagValue>);\n\nstruct MetricTags(BTreeMap<String, TagValueSet>);\n\nimpl MetricTags {\n    /// Insert returns the value unchanged if the exact (tag,value) pair already exists,\n    /// otherwise it inserts a new value for the named tag.\n    fn insert(&mut self, name: String, value: TagValue) -> Option<TagValue>;\n\n    /// Replace returns all the existing values when overwriting a tag.\n    fn replace(&mut self, name: String, value: Option<TagValue>) -> Option<TagValueSet>;\n\n    /// Replace an entire tag set with the given value set, returning existing values.\n    fn replace_all(&mut self, name: String, values: TagValueSet) -> Option<TagValueSet>;\n\n    /// Remove a single value of a tag.\n    fn remove(&mut self, name: &str, value: Option<&str>) -> Option<TagValue>;\n\n    /// Remove all values for a tag name.\n    fn remove_all(&mut self, name: &str) -> Option<TagValueSet>;\n}\n```\n\n----------------------------------------\n\nTITLE: Granting Access to Collect Perf Stats (Shell)\nDESCRIPTION: This command modifies the perf_event_paranoid setting to allow collecting performance statistics. It's often necessary to grant access before using perf.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/docs/DEVELOPING.md#_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\necho -1 | sudo tee /proc/sys/kernel/perf_event_paranoid\n```\n\n----------------------------------------\n\nTITLE: Go Memstats Other Sys Bytes Metric - Prometheus\nDESCRIPTION: This snippet captures the number of bytes used for other system allocations in Go. This reflects miscellaneous memory usage.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2020-08-31-3641-mongo-metrics.md#_snippet_60\n\nLANGUAGE: Prometheus\nCODE:\n```\n# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.\n# TYPE go_memstats_other_sys_bytes gauge\ngo_memstats_other_sys_bytes 1.985773e+06\n```\n\n----------------------------------------\n\nTITLE: Rust: Compile Function Call (Modified)\nDESCRIPTION: This is the modified Rust code for compiling a function call.  It changes the return type to `Option<FunctionCall>` so the compiler can ignore invalid expressions.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/rfcs/2021-08-22-7204-vrl-error-diagnostic-improvements.md#_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\nfn compile_function_call(&mut self, node: ast::FunctionCall) -> Option<FunctionCall> {\n    if /* invalid */ {\n        self.errors.push(/* ... */);\n        return None\n    }\n\n    // ...\n}\n```\n\n----------------------------------------\n\nTITLE: Input Declaration Example (TOML)\nDESCRIPTION: Demonstrates how to define input events for a Vector unit test, specifying the `insert_at` transform and providing sample `log_fields`.\nSOURCE: https://github.com/vectordotdev/vector/blob/master/website/content/en/docs/reference/configuration/unit-tests.md#_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[transforms.add_metadata]\n# transform config\n\n[[tests]]\nname = \"Test add_metadata transform\"\n\n[[tests.inputs]]\ninsert_at = \"add_metadata\"\n\n[tests.inputs.log_fields]\nmessage = \"<102>1 2020-12-22T15:22:31.111Z vector-user.biz su 2666 ID389 - Something went wrong\"\n```"
  }
]