[
  {
    "owner": "vapiai",
    "repo": "docs",
    "content": "TITLE: Weather Tool Configuration Example\nDESCRIPTION: Complete example of a weather tool configuration showing customized messages, function parameters, and server endpoint setup.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/custom-tools.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"function\",\n    \"messages\": [\n        {\n            \"type\": \"request-start\",\n            \"content\": \"Checking the weather forecast. Please wait...\"\n        },\n        {\n            \"type\": \"request-complete\",\n            \"content\": \"The weather in location is\"\n        },\n        {\n            \"type\": \"request-failed\",\n            \"content\": \"I couldn't get the weather information right now.\"\n        },\n        {\n            \"type\": \"request-response-delayed\",\n            \"content\": \"It appears there is some delay in communication with the weather API.\",\n            \"timingMilliseconds\": 2000\n        }\n    ],\n    \"function\": {\n        \"name\": \"get_weather\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\"\n                }\n            }\n        },\n        \"description\": \"Retrieves the current weather for a specified location.\"\n    },\n    \"async\": false,\n    \"server\": {\n        \"url\": \"https://your-weather-api.com/weather\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Settings Inline\nDESCRIPTION: Example of starting a call with inline assistant configuration including transcriber, model, and voice settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.start({\n  transcriber: {\n    provider: \"deepgram\",\n    model: \"nova-2\",\n    language: \"en-US\",\n  },\n  model: {\n    provider: \"openai\",\n    model: \"gpt-3.5-turbo\",\n    messages: [\n      {\n        role: \"system\",\n        content: \"You are a helpful assistant.\",\n      },\n    ],\n  },\n  voice: {\n    provider: \"playht\",\n    voiceId: \"jennifer\",\n  },\n  name: \"My Inline Assistant\",\n  ...\n});\n```\n\n----------------------------------------\n\nTITLE: Creating Outbound Call with Vapi API using Python\nDESCRIPTION: Makes an outbound call using Vapi's API by configuring an AI assistant with GPT-3.5-turbo model and custom voice. The script handles authentication, sets up call parameters including phone numbers, and processes the API response. Requires requests library and valid Vapi API authorization token.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-call-python.mdx#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# Your Vapi API Authorization token\nauth_token = '<YOUR AUTH TOKEN>'\n# The Phone Number ID, and the Customer details for the call\nphone_number_id = '<PHONE NUMBER ID FROM DASHBOARD>'\ncustomer_number = \"+14151231234\"\n\n# Create the header with Authorization token\nheaders = {\n    'Authorization': f'Bearer {auth_token}',\n    'Content-Type': 'application/json',\n}\n\n# Create the data payload for the API request\ndata = {\n    'assistant': {\n        \"firstMessage\": \"Hey, what's up?\",\n        \"model\": {\n            \"provider\": \"openai\",\n            \"model\": \"gpt-3.5-turbo\",\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are an assistant.\"\n                }\n            ]\n        },\n        \"voice\": \"jennifer-playht\"\n    },\n    'phoneNumberId': phone_number_id,\n    'customer': {\n        'number': customer_number,\n    },\n}\n\n# Make the POST request to Vapi to create the phone call\nresponse = requests.post(\n    'https://api.vapi.ai/call/phone', headers=headers, json=data)\n\n# Check if the request was successful and print the response\nif response.status_code == 201:\n    print('Call created successfully')\n    print(response.json())\nelse:\n    print('Failed to create call')\n    print(response.text)\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Outbound Call with Vapi\nDESCRIPTION: Basic configuration for making a single outbound call using Vapi API. Requires an assistant ID, phone number ID, and customer phone number.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-outbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"assistantId\": \"assistant-id\",\n    \"phoneNumberId\": \"phone-number-id\",\n    \"customer\": {\n        \"number\": \"+11231231234\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Batch Outbound Calling with Vapi\nDESCRIPTION: Configuration for making multiple outbound calls simultaneously using the customers array parameter. Includes scheduling capability for batch calls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-outbound.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"assistantId\": \"assistant-id\",\n    \"phoneNumberId\": \"phone-number-id\",\n    \"customers\": [\n        {\n            \"number\": \"+11231231234\"\n        },\n        {\n            \"number\": \"+12342342345\"\n        }\n    ],\n    \"schedulePlan\": {\n        \"earliestAt\": \"2025-05-30T00:00:00Z\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Explicit Tool Integration in Voice AI Prompts\nDESCRIPTION: This snippet shows how to specify the use of external tools or APIs in a Voice AI Agent prompt, including referencing tools by name and describing their functions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n```md wordWrap\n[Task]\n...\n3. If the user wants to know about something, use the get_data function with the parameter 'query', which will contain the user's question to initiate the process.\n4. Guide the user through the password reset steps provided by the API....\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Temporary Assistant for Vapi AI Web Call\nDESCRIPTION: This snippet demonstrates how to create a configuration object for a temporary assistant in Vapi AI. It includes settings for the assistant's name, first message, transcription, voice, and language model with a detailed system prompt for a pizza ordering scenario.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/web.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst assistantOptions = {\n  name: \"Vapi's Pizza Front Desk\",\n  firstMessage: \"Vappy's Pizzeria speaking, how can I help you?\",\n  transcriber: {\n    provider: \"deepgram\",\n    model: \"nova-2\",\n    language: \"en-US\",\n  },\n  voice: {\n    provider: \"playht\",\n    voiceId: \"jennifer\",\n  },\n  model: {\n    provider: \"openai\",\n    model: \"gpt-4\",\n    messages: [\n      {\n        role: \"system\",\n        content: `You are a voice assistant for Vappy's Pizzeria, a pizza shop located on the Internet.\n\nYour job is to take the order of customers calling in. The menu has only 3 types\nof items: pizza, sides, and drinks. There are no other types of items on the menu.\n\n1) There are 3 kinds of pizza: cheese pizza, pepperoni pizza, and vegetarian pizza\n(often called \"veggie\" pizza).\n2) There are 3 kinds of sides: french fries, garlic bread, and chicken wings.\n3) There are 2 kinds of drinks: soda, and water. (if a customer asks for a\nbrand name like \"coca cola\", just let them know that we only offer \"soda\")\n\nCustomers can only order 1 of each item. If a customer tries to order more\nthan 1 item within each category, politely inform them that only 1 item per\ncategory may be ordered.\n\nCustomers must order 1 item from at least 1 category to have a complete order.\nThey can order just a pizza, or just a side, or just a drink.\n\nBe sure to introduce the menu items, don't assume that the caller knows what\nis on the menu (most appropriate at the start of the conversation).\n\nIf the customer goes off-topic or off-track and talks about anything but the\nprocess of ordering, politely steer the conversation back to collecting their order.\n\nOnce you have all the information you need pertaining to their order, you can\nend the conversation. You can say something like \"Awesome, we'll have that ready\nfor you in 10-20 minutes.\" to naturally let the customer know the order has been\nfully communicated.\n\nIt is important that you collect the order in an efficient manner (succinct replies\n& direct questions). You only have 1 task here, and it is to collect the customers\norder, then end the conversation.\n\n- Be sure to be kind of funny and witty!\n- Keep all your responses short and simple. Use casual language, phrases like \"Umm...\", \"Well...\", and \"I mean\" are preferred.\n- This is a voice conversation, so keep your responses short, like in a real conversation. Don't ramble for too long.`,\n      },\n    ],\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Setting Variable Values for Vapi AI Assistant in JSON\nDESCRIPTION: This JSON snippet demonstrates how to set variable values when starting a call with a Vapi AI assistant. It shows the structure for passing 'variableValues' within 'assistantOverrides'.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/dynamic-variables.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"variableValues\": {\n    \"name\": \"John\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom LLM Response Generation in TypeScript\nDESCRIPTION: This snippet demonstrates how to set up an endpoint for a Custom LLM to generate conversation responses. It handles incoming requests, prepares API calls to OpenAI, and streams the response back to the client using Server-Sent Events.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\napp.post(\"/chat/completions\", async (req: Request, res: Response) => {\n  // Log the incoming request.\n  logEvent(\"Request received at /chat/completions\", req.body);\n  const payload = req.body;\n\n  // Prepare the API request to OpenAI.\n  const requestArgs: any = {\n    model: payload.model,\n    messages: payload.messages,\n    temperature: payload.temperature ?? 1.0,\n    stream: true,\n    tools: payload.tools || [],\n    tool_choice: \"auto\",\n  };\n\n  // Optionally merge in native tool definitions.\n  const modelTools = payload.tools || [];\n  requestArgs.tools = [...modelTools, ...ourTools];\n\n  logEvent(\"Calling OpenAI API for content generation\");\n  const openAIResponse = await openai.chat.completions.create(requestArgs);\n  logEvent(\"OpenAI API call successful. Streaming response.\");\n\n  // Set up streaming headers.\n  res.setHeader(\"Content-Type\", \"text/event-stream\");\n  res.setHeader(\"Cache-Control\", \"no-cache\");\n  res.setHeader(\"Connection\", \"keep-alive\");\n\n  // Stream the response chunks back.\n  for await (const chunk of openAIResponse as unknown as AsyncIterable<any>) {\n    res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\n  }\n  res.write(\"data: [DONE]\\n\\n\");\n  res.end();\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Web Call with Assistant ID\nDESCRIPTION: Demonstrates how to start a web call using an existing assistant ID. Returns a promise that resolves to a call object with various metadata.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst call = await vapi.start(assistantId);\n// { \"id\": \"bd2184a1-bdea-4d4f-9503-b09ca8b185e6\", \"orgId\": \"6da6841c-0fca-4604-8941-3d5d65f43a17\", \"createdAt\": \"2024-11-13T19:20:24.606Z\", \"updatedAt\": \"2024-11-13T19:20:24.606Z\", \"type\": \"webCall\", ... }\n```\n\n----------------------------------------\n\nTITLE: Initiating a Call to Retrieve Control URLs with Vapi API\nDESCRIPTION: This snippet demonstrates how to make a POST request to initiate a call and retrieve the necessary listenUrl and controlUrl for call control and monitoring.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl 'https://api.vapi.ai/call' \n-H 'authorization: Bearer YOUR_API_KEY' \n-H 'content-type: application/json' \n--data-raw '{\n  \"assistantId\": \"5b0a4a08-133c-4146-9315-0984f8c6be80\",\n  \"customer\": {\n    \"number\": \"+12345678913\"\n  },\n  \"phoneNumberId\": \"42b4b25d-031e-4786-857f-63b346c9580f\"\n}'\n\n```\n\n----------------------------------------\n\nTITLE: Defining Transient Assistant in JSON\nDESCRIPTION: Shows how to define a transient assistant dynamically in response to an assistant request.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"assistant\": {\n    \"firstMessage\": \"Hey Ryan, how are you?\",\n    \"model\": {\n      \"provider\": \"openai\",\n      \"model\": \"gpt-3.5-turbo\",\n      \"messages\": [\n        {\n          \"role\": \"system\",\n          \"content\": \"You're Ryan's assistant...\"\n        }\n      ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Vapi Voice Widget in HTML\nDESCRIPTION: This snippet demonstrates how to initialize the Vapi Voice Widget by inserting a script tag into the HTML. It includes setting up the assistant ID, API key, and button configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/voice-widget.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n  var vapiInstance = null;\n  const assistant = \"<assistant_id>\"; // Substitute with your assistant ID\n  const apiKey = \"<your_public_api_key>\"; // Substitute with your Public key from Vapi Dashboard.\n  const buttonConfig = {}; // Modify this as required\n\n  (function (d, t) {\n    var g = document.createElement(t),\n      s = d.getElementsByTagName(t)[0];\n    g.src =\n      \"https://cdn.jsdelivr.net/gh/VapiAI/html-script-tag@latest/dist/assets/index.js\";\n    g.defer = true;\n    g.async = true;\n    s.parentNode.insertBefore(g, s);\n\n    g.onload = function () {\n      vapiInstance = window.vapiSDK.run({\n        apiKey: apiKey, // mandatory\n        assistant: assistant, // mandatory\n        config: buttonConfig, // optional\n      });\n    };\n  })(document, \"script\");\n\n</script>\n```\n\n----------------------------------------\n\nTITLE: Defining Assistant Configuration in JSON\nDESCRIPTION: This JSON configuration defines the assistant's model, instructions, functions, and initial message for a pizza ordering system.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n          \"role\": \"system\",\n          \"content\": \"You're a pizza ordering assistant. The user will ask for toppings, you'll add them. When they're done, you'll redirect them to checkout.\"\n      }\n    ],\n    \"functions\": [\n      {\n        \"name\": \"addTopping\",\n        \"description\": \"Used to add a topping to the pizza.\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"topping\": {\n              \"type\": \"string\",\n              \"description\": \"The name of the topping. For example, 'pepperoni'.\"\n            }\n          }\n        }\n      },\n       {\n        \"name\": \"goToCheckout\",\n        \"description\": \"Redirects the user to checkout and order their pizza.\",\n        \"parameters\": {\"type\": \"object\", \"properties\": {}}\n      }\n    ]\n  },\n  \"firstMessage\": \"Hi, I'm the pizza ordering assistant. What toppings would you like?\"\n}\n```\n\n----------------------------------------\n\nTITLE: Scheduling Future Outbound Call with Vapi\nDESCRIPTION: Configuration for scheduling a future outbound call with Vapi API using schedulePlan parameter. Includes earliest execution time specification.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-outbound.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"assistantId\": \"assistant-id\",\n    \"phoneNumberId\": \"phone-number-id\",\n    \"customer\": {\n        \"number\": \"+11231231234\"\n    },\n    \"schedulePlan\": {\n        \"earliestAt\": \"2025-05-30T00:00:00Z\"\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring transferCall Tool with Multiple Destinations\nDESCRIPTION: This snippet demonstrates how to configure the transferCall tool with multiple destination phone numbers and corresponding messages. Each destination includes a phone number and a custom message that will be played to the caller when forwarding the call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"tools\": [\n    {\n      \"type\": \"transferCall\",\n      \"destinations\": [\n        {\n          \"type\": \"number\",\n          \"number\": \"+1234567890\",\n          \"message\": \"I am forwarding your call to Department A. Please stay on the line.\"\n        },\n        {\n          \"type\": \"number\",\n          \"number\": \"+0987654321\",\n          \"message\": \"I am forwarding your call to Department B. Please stay on the line.\"\n        },\n        {\n          \"type\": \"number\",\n          \"number\": \"+1122334455\",\n          \"message\": \"I am forwarding your call to Department C. Please stay on the line.\"\n        }\n      ],\n      \"function\": {\n        \"name\": \"transferCall\",\n        \"description\": \"Use this function to transfer the call. Only use it when following instructions that explicitly ask you to use the transferCall function. DO NOT call this function unless you are instructed to do so.\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"destination\": {\n              \"type\": \"string\",\n              \"enum\": [\"+1234567890\", \"+0987654321\", \"+1122334455\"],\n              \"description\": \"The destination to transfer the call to.\"\n            }\n          },\n          \"required\": [\"destination\"]\n        }\n      },\n      \"messages\": [\n        {\n          \"type\": \"request-start\",\n          \"content\": \"I am forwarding your call to Department A. Please stay on the line.\",\n          \"conditions\": [\n            {\n              \"param\": \"destination\",\n              \"operator\": \"eq\",\n              \"value\": \"+1234567890\"\n            }\n          ]\n        },\n        {\n          \"type\": \"request-start\",\n          \"content\": \"I am forwarding your call to Department B. Please stay on the line.\",\n          \"conditions\": [\n            {\n              \"param\": \"destination\",\n              \"operator\": \"eq\",\n              \"value\": \"+0987654321\"\n            }\n          ]\n        },\n        {\n          \"type\": \"request-start\",\n          \"content\": \"I am forwarding your call to Department C. Please stay on the line.\",\n          \"conditions\": [\n            {\n              \"param\": \"destination\",\n              \"operator\": \"eq\",\n              \"value\": \"+1122334455\"\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Calendar Tools in Vapi Assistant\nDESCRIPTION: Example configuration showing how to set up Google Calendar tools in a Vapi assistant. Includes system messages for handling scheduling and appointment booking, along with tool configurations for checking availability and creating events.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/google-calendar.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a scheduling assistant. When users want to schedule an appointment, first check their availability using the Check Availability tool, then use the Create Event tool to schedule the event if they're available.\\n\\n- Gather date and time range to check availability.\\n- To book an appointment, gather the purpose of the appointment, ex: general checkup, dental cleaning and etc.\\n\\nNotes\\n- Use the purpose as summary for booking appointment.\\n- Current date: {{date}}\\n- Current time: {{time}}\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"google.calendar.availability.check\",\n        \"name\": \"checkAvailability\",\n        \"description\": \"Use this tool to check calendar availability and use the America/Los_Angeles as default timezone.\"\n      },\n      {\n        \"type\": \"google.calendar.event.create\",\n        \"name\": \"scheduleAppointment\",\n        \"description\": \"Use this tool to schedule appointments and create calendar events. Notes: - Use America/Los_Angeles as default timezone - All appointments are 30 mins.\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring MCP Tool for Vapi Assistant (JSON)\nDESCRIPTION: This JSON snippet demonstrates how to configure an MCP tool in a Vapi assistant's configuration. It includes the assistant's model settings, system message, and the MCP tool configuration with a server URL.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/mcp.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful personal assistant named Alex. You can help users with various tasks through voice commands. You have access to tools that allow you to perform actions on the user's behalf.\\n\\nWhen a user requests an action, check if any of the available tools can help accomplish that task.\\n\\nCommon tasks you can help with include:\\n- Scheduling appointments and meetings\\n- Sending messages or emails\\n- Creating or updating documents\\n- Managing to-do lists and reminders\\n- Searching for information\\n- Making reservations\\n- Ordering food or services\\n- Checking account balances or transaction history\\n- Controlling smart home devices\\n\\nAlways be polite, professional, and helpful. If a tool fails or isn't available, explain the situation to the user and suggest alternatives if possible.\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"mcp\",\n        \"name\": \"mcpTools\",\n        \"server\": {\n            \"url\": \"https://actions.zapier.com/mcp/actions/\"\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Transferring a Call to Another Number with Vapi\nDESCRIPTION: This control API call transfers the ongoing conversation to a different phone number, with an optional message to inform the caller about the transfer.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST 'https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control' \n-H 'content-type: application/json' \n--data-raw '{\n  \"type\": \"transfer\",\n  \"destination\": {\n    \"type\": \"number\",\n    \"number\": \"+1234567890\"\n  },\n  \"content\": \"Transferring your call now\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Structuring Voice AI Agent Prompt with Markdown\nDESCRIPTION: This snippet demonstrates how to structure a system prompt for a Voice AI Agent using Markdown formatting. It includes sections for identity, style, response guidelines, and task breakdown.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```md wordWrap\n[Identity]\nYou are a helpful and knowledgeable virtual assistant for a travel booking platform.\n \n[Style]\n- Be informative and comprehensive.\n- Maintain a professional and polite tone.\n- Be concise, as you are currently operating as a Voice Conversation.\n \n[Response Guideline]\n- Present dates in a clear format (e.g., January 15, 2024).\n- Offer up to three travel options based on user preferences.\n \n[Task]\n1. Greet the user and inquire about their desired travel destination.\n2. Ask about travel dates and preferences (e.g., budget, interests).\n3. Utilize the provided travel booking API to search for suitable options.\n4. Present the top three options to the user, highlighting key features.\n```\n```\n\n----------------------------------------\n\nTITLE: Advanced Vapi Integration With Tools\nDESCRIPTION: Extended configuration for Vapi integration including both transferCall and processOrder tools. Includes complete model setup, tool definitions, and system instructions for handling multiple functions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH https://api.vapi.ai/assistant/insert-your-assistant-id-here \\\n     -H \"Authorization: Bearer insert-your-private-key-here\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"model\": {\n    \"provider\": \"custom-llm\",\n    \"model\": \"gpt-4o\",\n    \"url\": \"https://custom-llm-url/chat/completions\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"[TASK] Ask the user if they want to transfer the call; if they agree, trigger the transferCall tool; if not, continue the conversation. Also, if the user asks about the custom function processOrder, trigger that tool.\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"transferCall\",\n        \"destinations\": [\n          {\n            \"type\": \"number\",\n            \"number\": \"+xxxxxx\",\n            \"numberE164CheckEnabled\": false,\n            \"message\": \"Transferring Call To Customer Service Department\"\n          }\n        ]\n      },\n      {\n        \"type\": \"function\",\n        \"async\": false,\n        \"function\": {\n          \"name\": \"processOrder\",\n          \"description\": \"it\\'s a custom tool function named processOrder according to vapi.ai custom tools guide\"\n        },\n        \"server\": {\n          \"url\": \"https://custom-llm-url/chat/completions/custom-tool\"\n        }\n      }\n    ]\n  },\n  \"transcriber\": {\n    \"provider\": \"azure\",\n    \"language\": \"en-CA\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Vapi AI Assistant for Outbound Sales\nDESCRIPTION: Configuration for creating a sales assistant with GPT-4 integration, custom voice settings, and appointment booking functionality. Includes transcriber settings, model configuration, voice settings, and call handling parameters.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"transcriber\":{\n    \"provider\": \"deepgram\",\n    \"keywords\": [\"Bicky:1\"]\n  },\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n          \"role\": \"system\",\n          \"content\": \"You're a sales agent for a Bicky Realty. You're calling a list of leads to schedule appointments to show them houses...\"\n      }\n    ],\n    \"functions\": [\n      {\n        \"name\": \"bookAppointment\",\n        \"description\": \"Used to book the appointment.\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"datetime\": {\n              \"type\": \"string\",\n              \"description\": \"The date and time of the appointment in ISO format.\"\n            }\n          }\n        }\n      }\n    ]\n  },\n  \"voice\": {\n    \"provider\": \"openai\",\n    \"voiceId\": \"onyx\"\n  },\n  \"forwardingPhoneNumber\": \"+16054440129\",\n  \"voicemailMessage\": \"Hi, this is Jennifer from Bicky Realty. We were just calling to let you know...\",\n  \"firstMessage\": \"Hi, this Jennifer from Bicky Realty. We're calling to schedule an appointment to show you a house. When would be a good time for you?\",\n  \"endCallMessage\": \"Thanks for your time.\",\n  \"endCallFunctionEnabled\": true,\n  \"recordingEnabled\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Vapi AI Assistant with Previous Conversation Context\nDESCRIPTION: This JSON configuration demonstrates how to set up a Vapi AI assistant with context from a previous conversation. It includes the model configuration with a system message containing the context of where the conversation left off.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/inbound-support.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"assistant\": {\n        ...\n        \"model\": {\n            \"provider\": \"openai\",\n            \"model\": \"gpt-4\",\n            \"messages\": [\n              {\n                \"role\": \"system\",\n                \"content\": \"You're a technical support assistant. Here's where we left off: ...\"\n              }\n            ]\n        },\n        ...\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Conference Room TwiML Generator\nDESCRIPTION: Endpoint that generates TwiML for placing callers into a conference room with specific configuration options.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\napp.post(\"/conference\", (req, res) => {\n  const VoiceResponse = twilio.twiml.VoiceResponse;\n  const twiml = new VoiceResponse();\n\n  // Put the caller(s) into a conference\n  const dial = twiml.dial();\n  dial.conference(\n    {\n      startConferenceOnEnter: true,\n      endConferenceOnExit: true,\n    },\n    \"my_conference_room\"\n  );\n\n  return res.type(\"text/xml\").send(twiml.toString());\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Customer Feedback Assistant with Google Sheets Integration\nDESCRIPTION: Example configuration for a customer feedback assistant that uses Google Sheets integration to record feedback. The setup includes system prompts for collecting feedback and tool configuration for adding rows to a spreadsheet.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/google-sheets.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a customer feedback assistant. After each customer service call, collect feedback using the following process:\\n\\n1. Ask the customer if they would like to provide feedback\\n2. If yes, ask for their rating (1-5 stars)\\n3. Ask for specific comments about their experience\\n4. Ask for any suggestions for improvement\\n5. Confirm the feedback before adding it to the spreadsheet\\n\\nUse the Add Row tool to record the feedback with the following columns:\\n- Timestamp\\n- Rating (1-5)\\n- Comments\\n- Suggestions\\n\\nAlways be polite and thank the customer for their feedback.\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"google.sheets.row.append\",\n        \"name\": \"addFeedback\",\n        \"description\": \"Use this tool to add customer feedback to the feedback spreadsheet. Collect all required information (rating, comments, suggestions) before adding the row.\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Requesting Assistant in JSON\nDESCRIPTION: Shows the structure of a message sent to request an assistant for inbound phone calls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"assistant-request\",\n    \"call\": { Call Object },\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Native LLM Tool Calls in TypeScript\nDESCRIPTION: This code snippet shows how to implement native LLM tool calls within a Custom LLM integration. It processes streaming chunks, detects tool calls, executes native functions, and handles follow-up responses.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\n// Variables to accumulate tool call information.\nlet argumentsStr = \"\";\nlet toolCallInfo: { name?: string; id?: string } | null = null;\n\n// Process streaming chunks.\nfor await (const chunk of openAIResponse as unknown as AsyncIterable<any>) {\n  const choice = chunk.choices && chunk.choices[0];\n  const delta = choice?.delta || {};\n  const toolCalls = delta.tool_calls;\n\n  if (toolCalls && toolCalls.length > 0) {\n    for (const toolCall of toolCalls) {\n      const func = toolCall.function;\n      if (func && func.name) {\n        toolCallInfo = { name: func.name, id: toolCall.id };\n      }\n      if (func && func.arguments) {\n        argumentsStr += func.arguments;\n      }\n    }\n  }\n\n  const finishReason = choice?.finish_reason;\n  if (finishReason === \"tool_calls\" && toolCallInfo) {\n    let parsedArgs = {};\n    try {\n      parsedArgs = JSON.parse(argumentsStr);\n    } catch (err) {\n      console.error(\"Failed to parse arguments:\", err);\n    }\n    if (tool_functions[toolCallInfo.name!]) {\n      const result = await tool_functions[toolCallInfo.name!](parsedArgs);\n      const functionMessage = {\n        role: \"function\",\n        name: toolCallInfo.name,\n        content: JSON.stringify(result)\n      };\n\n      const followUpResponse = await openai.chat.completions.create({\n        model: requestArgs.model,\n        messages: [...requestArgs.messages, functionMessage],\n        temperature: requestArgs.temperature,\n        stream: true,\n        tools: requestArgs.tools,\n        tool_choice: \"auto\"\n      });\n\n      for await (const followUpChunk of followUpResponse) {\n        res.write(`data: ${JSON.stringify(followUpChunk)}\\n\\n`);\n      }\n      argumentsStr = \"\";\n      toolCallInfo = null;\n      continue;\n    }\n  }\n  res.write(`data: ${JSON.stringify(chunk)}\\n\\n`);\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Appointment Setter AI Assistant in Markdown\nDESCRIPTION: This snippet defines the role, context, response handling, and conversation flow for an AI assistant named Susan. It includes detailed instructions for booking appointments, handling errors, and closing calls for auto accident cases.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n[Role]\nYou're Susan, an AI assistant for xxx. Your primary task is to interact with the customer, ask questions, and gather information for appointment booking.\n\n[Context]\nYou're engaged with the customer to book an appointment. Stay focused on this context and provide relevant information. Once connected to a customer, proceed to the Conversation Flow section. Do not invent information not drawn from the context. Answer only questions related to the context.\n\n[Response Handling]\nWhen asking any question from the 'Conversation Flow' section, evaluate the customer's response to determine if it qualifies as a valid answer. Use context awareness to assess relevance and appropriateness. If the response is valid, proceed to the next relevant question or instructions. Avoid infinite loops by moving forward when a clear answer cannot be obtained.\n\n[Warning]\nDo not modify or attempt to correct user input parameters or user input, Pass them directly into the function or tool as given.\n\n[Response Guidelines]\nKeep responses brief.\nAsk one question at a time, but combine related questions where appropriate.\nMaintain a calm, empathetic, and professional tone.\nAnswer only the question posed by the user.\nBegin responses with direct answers, without introducing additional data.\nIf unsure or data is unavailable, ask specific clarifying questions instead of a generic response.\nPresent dates in a clear format (e.g., January Twenty Four) and Do not mention years in dates.\nPresent time in a clear format (e.g. Four Thirty PM) like: 11 pm can be spelled: eleven pee em\nSpeak dates gently using English words instead of numbers.\nNever say the word 'function' nor 'tools' nor the name of the Available functions.\nNever say ending the call.\nIf you think you are about to transfer the call, do not send any text response. Simply trigger the tool silently. This is crucial for maintaining a smooth call experience.\n\n[Error Handling]\nIf the customer's response is unclear, ask clarifying questions. If you encounter any issues, inform the customer politely and ask to repeat.\n\n[Conversation Flow]\n1. Ask: \"You made a recent inquiry, can I ask you a few quick follow-up questions?\"\n- if response indicates interest: Proceed to step 2.\n- if response indicates no interest: Proceed to 'Call Closing'.\n2. Ask: \"You connected with us in regard to an auto accident. Is this something you would still be interested in pursuing?\"\n- If response indicates interest: Proceed to step 3.\n- If response indicates no interest: Proceed to 'Call Closing'.\n3. Ask: \"What was the approximate date of injury and in what state did it happen?\"\n- Proceed to step 4.\n4. Ask: \"On a scale of 1 to 3, would you rate the injury? 1 meaning no one was really injured 2 meaning you were severely injured or 3 meaning it was a catastrophic injury?\"\n- If response indicates injury level above 1: Proceed to step 5.\n- If response indicates no injury or minor injury: Proceed to 'Call Closing'.\n5. Ask: \"Can you describe in detail your injury and if anyone else in the car was injured and their injuries?\"\n- Proceed to step 6.\n6. Ask: \"Did the police issue a ticket?\"\n- Proceed to step 7.\n7. Ask: \"Did the police say whose fault it was and was the accident your fault?\"\n- If response indicates not at fault(e.g. \"no\", \"not my fault\", etc.):Proceed to step 8.\n- If response indicates at fault(e.g. \"yes\", \"my fault\", etc.): Proceed to 'Call Closing'.\n8. Ask: \"Do you have an attorney representing you in this case?\" \n- If response confirms no attorney: Proceed to step 9.\n- If response indicates they have an attorney: Proceed to 'Call Closing'.\n9. Ask: \"Would you like to speak with an attorney now or book an appointment?\"\n- If the response indicates \"speak now\": Proceed to 'Transfer Call'\n- if the response indicates \"book appointment\": Proceed to 'Book Appointment'\n10. After receiving response, proceed to the 'Call Closing' section.\n\n[Book Appointment]\n1. Ask: \"To make sure I have everything correct, could you please confirm your first name for me?\"\n2. Ask: \"And your last name, please?\"\n3. Ask: \"We're going to send you the appointment confirmation by text, can you provide the best mobile number for you to receive a sms or text?\" \n4. Trigger the 'fetchSlots' tool and map the result to {{available_slots}}.\n5. Ask: \"I have two slots available, {{available_slots}}. Would you be able to make one of those times work?\"\n6. <wait for user response>\n7. Set the {{selectedSlot}} variable to the user's response.\n8. If {{selectedSlot}} is one of the available slots (positive response): \n   - Trigger the 'bookSlot' tool with the {{selectedSlot}}.\n   - <wait for 'bookSlot' tool result>\n   - Inform the user of the result of the 'bookSlot' tool.\n   - Proceed to the 'Call Closing' section.\n9. If {{selectedSlot}} is not one of the available slots (negative response):\n   - Proceed to the 'Suggest Alternate Slot' section.\n\n[Suggest Alternate Slot]\n1. Ask: \"If none of these slots work for you, could you please suggest a different time that suits you?\"\n2. <wait for user response>\n3. Set the {{selectedSlot}} variable to the user's response.\n4. Trigger the 'bookSlot' tool with the {{selectedSlot}}.\n5. <wait for 'bookSlot' tool result>\n6. If the {{selectedSlot}} is available:\n   - Inform the user of the result.\n7. If the {{selectedSlot}} is not available:\n   - Trigger the 'fetchSlots' tool, provide the user {{selectedSlot}} as input and map the result to {{available_slots}}.\n   - Say: \"That time is unavailable but here are some other times we can do {{available_slots}}.\"\n   - Ask: \"Do either of those times work?\"\n   - <wait for user response>\n   - If the user agrees to one of the new suggested slots:\n        - Set the {{selectedSlot}} variable to the user's response.\n        - Trigger the 'bookSlot' tool with the {{selectedSlot}}.\n        - <wait for 'bookSlot' tool result>\n        - Inform the user of the result.\n   - If the user rejects the new suggestions:\n        - Proceed to the 'Last Message' section.\n\n[Last Message]\n - Respond: \"Looks like this is taking longer than expected. Let me have one of our appointment specialists get back to you to make this process simple and easy.\"\n- Proceed to the 'Call Closing' section.\n\n[Call Closing]\n- Trigger the endCall Function.\n```\n\n----------------------------------------\n\nTITLE: Configuring Vapi AI Assistant for Apple Technical Support\nDESCRIPTION: This JSON configuration sets up a Vapi AI assistant for Apple technical support. It defines the transcriber settings, model configuration, forwarding phone number, initial message, and enables call recording.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/inbound-support.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"transcriber\":{\n    \"provider\": \"deepgram\",\n    \"keywords\": [\"iPhone:1\", \"MacBook:1.5\", \"iPad:1\", \"iMac:0.8\", \"Watch:1\", \"TV:1\", \"Apple:2\"],\n  },\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n          \"role\": \"system\",\n          \"content\": \"You're a technical support assistant. You're helping a customer troubleshoot their Apple device. You can ask the customer questions, and you can use the following troubleshooting guides to help the customer solve their issue: ...\"\n      }\n    ]\n  },\n  \"forwardingPhoneNumber\": \"+16054440129\",\n  \"firstMessage\": \"Hey, I'm an A.I. assistant for Apple. I can help you troubleshoot your Apple device. What's the issue?\",\n  \"recordingEnabled\": true,\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Prompt for Knowledge Base Usage in Markdown\nDESCRIPTION: This snippet demonstrates how to instruct an AI assistant to use the knowledge base when relevant by adding an appropriate prompt in the assistant's configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/knowledge-base.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```\nWhen users ask about our products, services, or company information, use the knowledge base to provide accurate details.\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Multiple Knowledge Bases in Vapi AI (JSON)\nDESCRIPTION: This JSON snippet demonstrates how to configure multiple knowledge bases within a single query tool. It includes separate configurations for product documentation and troubleshooting guide knowledge bases.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/using-query-tool.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"knowledgeBases\": [\n    {\n        \"provider\": \"google\",\n        \"name\": \"product-documentation\",\n        \"description\": \"Use this knowledge base for product specifications and features\",\n        \"fileIds\": [\"file-id-1\", \"file-id-2\"]\n    },\n    {\n        \"provider\": \"google\",\n        \"name\": \"troubleshooting-guide\",\n        \"description\": \"Use this knowledge base for troubleshooting and support questions\",\n        \"fileIds\": [\"file-id-3\", \"file-id-4\"]\n    }\n]\n```\n\n----------------------------------------\n\nTITLE: Basic Tool Structure Configuration in JSON\nDESCRIPTION: Demonstrates the basic structure of a function-type tool configuration including type, messages, function definition, async flag, and server settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/custom-tools.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"type\": \"function\",\n    \"messages\": [ ... ],\n    \"function\": { ... },\n    \"async\": false,\n    \"server\": { ... }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Dial Keypad (DTMF) Function for Vapi Assistant (JSON)\nDESCRIPTION: This example demonstrates the configuration of the dtmf function for a Vapi voice assistant. It includes the model setup, system message, and the dtmf tool for keypad input.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/default-tools.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant at a law firm. When you hit a menu, use the dtmf function to enter the digits.\"\n      }\n    ],\n    \"tools\": [\n      {\n          \"type\": \"dtmf\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Hook for Call Transfer on Pipeline Error (Phone Number)\nDESCRIPTION: This cURL command updates an assistant to add a hook that transfers the call to a phone number when a pipeline error occurs during call ending. It demonstrates how to structure the hook with filters and transfer action.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/assistant-hooks.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \"https://api.vapi.ai/assistant/<id>\" \\\n     -H \"Authorization: Bearer <auth>\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"hooks\": [{\n    \"on\": \"call.ending\",\n    \"filters\": [{\n      \"type\": \"oneOf\",\n      \"key\": \"call.endedReason\",\n      \"oneOf\": [\"pipeline-error\"]\n    }],\n    \"do\": [{\n      \"type\": \"transfer\",\n      \"destination\": {\n        \"type\": \"number\",\n        \"number\": \"+1234567890\",\n        \"callerId\": \"+1987654321\"\n      }\n    }]\n  }]\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating a Query Tool for Knowledge Base in Vapi AI (Bash)\nDESCRIPTION: This code snippet shows how to create a query tool that references knowledge base files using the Vapi AI API. It sends a POST request with JSON data specifying the tool type, function name, and knowledge base details.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/using-query-tool.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/tool/' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n    \"type\": \"query\",\n    \"function\": {\n        \"name\": \"product-query\"\n    },\n    \"knowledgeBases\": [\n        {\n            \"provider\": \"google\",\n            \"name\": \"product-kb\",\n            \"description\": \"Use this knowledge base when the user asks or queries about the product or services\",\n            \"fileIds\": [\n                \"41a2bd44-d13c-4914-bbf7-b19807dd2cf4\",\n                \"ef82ae15-21b2-47bd-bde4-dea3922c1e49\"\n            ]\n        }\n    ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Uploading Files for Knowledge Base via Vapi AI API (Bash)\nDESCRIPTION: This snippet demonstrates how to upload files to create a knowledge base using the Vapi AI API. It uses a curl command to send a POST request with the file as form data.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/using-query-tool.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/file' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--form 'file=@\"<PATH_TO_YOUR_FILE>\"'\n```\n\n----------------------------------------\n\nTITLE: Configuring Inbound Call Squad JSON\nDESCRIPTION: JSON configuration for handling inbound calls with Squad members. Demonstrates setting up a transient assistant with full configuration and referencing a pre-existing assistant using an Assistant ID. Includes configuration for call transfers between assistants.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads-example.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"squad\": {\n        \"members\": [\n            {\n                \"assistant\": { \n                    \"name\": \"Emma\", \n                    \"model\": { \"model\": \"gpt-4o\", \"provider\": \"openai\" },\n                    \"voice\": { \"voiceId\": \"emma\", \"provider\": \"azure\" },\n                    \"transcriber\": { \"provider\": \"deepgram\" },\n                    \"firstMessage\": \"Hi, I am Emma, what is your name?\",\n                    \"firstMessageMode\": \"assistant-speaks-first\"\n                },\n                \"assistantDestinations\": [ \n                    {\n                        \"type\": \"assistant\",\n                        \"assistantName\": \"Mary\", \n                        \"message\": \"Please hold on while I transfer you to our appointment booking assistant Mary.\",\n                        \"description\": \"Transfer the user to the appointment booking assistant.\"\n                    }\n                ]\n            },\n            {\n                \"assistantId\": \"your-assistant-id\" \n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Vapi-Attached Tools in TypeScript\nDESCRIPTION: This code snippet demonstrates how to handle Vapi-attached tools, specifically the 'transferCall' function. It detects the tool call and immediately sends a function call payload back to Vapi with the destination information.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nif (functionName === \"transferCall\" && payload.destination) {\n  const functionCallPayload = {\n    function_call: {\n      name: \"transferCall\",\n      arguments: {\n        destination: payload.destination,\n      },\n    },\n  };\n  logEvent(\"Special handling for transferCall\", { functionCallPayload });\n  res.write(`data: ${JSON.stringify(functionCallPayload)}\\n\\n`);\n  // Skip further processing for this chunk.\n  continue;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Transfer Call Function for Vapi Assistant (JSON)\nDESCRIPTION: This snippet demonstrates how to configure the transferCall function for a Vapi voice assistant. It includes setting up the model provider, messages, and the transferCall tool with a destination number.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/default-tools.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant at a law firm. When the user asks to be transferred, use the transferCall function.\"\n      }\n    ],\n    \"tools\": [\n      {\n          \"type\": \"transferCall\",\n          \"destinations\" : {\n            {\n              \"type\": \"number\",\n              \"number\": \"+16054440129\"\n            }\n          }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Updating Assistant with Knowledge Base Integration\nDESCRIPTION: This snippet demonstrates how to update an existing assistant to integrate a Knowledge Base. It uses a PATCH request to update the assistant's configuration, including the Knowledge Base ID, model settings, and system prompt.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/knowledgebase.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request PATCH 'https://api.vapi.ai/assistant/<ASSISTANT_ID>' \\\n--header 'Content-Type: text/plain' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n  \"model\": {\n    \"knowledgeBaseId\": \"<KNOWLEDGE_BASE_ID>\",\n    \"temperature\": 0.2,\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"content\": \"You are a smart assistant who responds to user queries using the information you know, or information supplied by outside context.\",\n        \"role\": \"system\"\n      }\n    ]\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Sending Messages During Call\nDESCRIPTION: Demonstrates how to send intermediate messages to the assistant during an active call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.send({\n  type: \"add-message\",\n  message: {\n    role: \"system\",\n    content: \"The user has pressed the button, say peanuts\",\n  },\n});\n```\n\n----------------------------------------\n\nTITLE: Attaching Query Tool to Assistant in Vapi AI (Bash)\nDESCRIPTION: This snippet illustrates how to attach a created query tool to an assistant using the Vapi AI API. It sends a PATCH request to update the assistant's configuration, including the model settings and tool IDs.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/using-query-tool.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request PATCH 'https://api.vapi.ai/assistant/ASSISTANT_ID' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n    \"model\": {\n        \"temperature\": 0.2,\n        \"provider\": \"openai\",\n        \"model\": \"gpt-4o\",\n        \"toolIds\": [\n            \"9441840b-6f2f-4b0f-a0fc-de8512549a0c\"\n        ]\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Adding a Knowledge Base to a Vapi Assistant using cURL\nDESCRIPTION: This code snippet shows how to add a Knowledge Base to an existing Vapi assistant using the PATCH endpoint. It also includes configuration for the assistant's model and system prompt.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledgebase.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location --request PATCH 'https://api.vapi.ai/assistant/<ASSISTANT_ID>' \\\n--header 'Content-Type: text/plain' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n  \"model\": {\n    \"knowledgeBaseId\": \"<KNOWLEDGE_BASE_ID>\",\n    \"temperature\": 0.2,\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"content\": \"You are a smart assistant who responds to user queries using the information you know, or information supplied by outside context.\",\n        \"role\": \"system\"\n      }\n    ]\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Tool Call Request Format\nDESCRIPTION: Example of the request format sent by Vapi when making a tool call, including message structure, tool details, and call metadata.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/custom-tools.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": {\n        \"timestamp\": 1678901234567,\n        \"type\": \"tool-calls\",\n        \"toolCallList\": [\n            {\n                \"id\": \"toolu_01DTPAzUm5Gk3zxrpJ969oMF\",\n                \"name\": \"get_weather\",\n                \"arguments\": {\n                    \"location\": \"San Francisco\"\n                }\n            }\n        ],\n        \"toolWithToolCallList\": [\n            {\n                \"type\": \"function\",\n                \"name\": \"get_weather\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": {\n                            \"type\": \"string\"\n                        }\n                    }\n                },\n                \"description\": \"Retrieves the current weather for a specified location\"\n            },\n            \"server\": {\n                \"url\": \"https://your-api-server.com/weather\"\n            },\n            \"messages\": [],\n            \"toolCall\": {\n                \"id\": \"toolu_01DTPAzUm5Gk3zxrpJ969oMF\",\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"get_weather\",\n                    \"parameters\": {\n                        \"location\": \"San Francisco\"\n                    }\n                }\n            }\n        ],\n        \"artifact\": {\n            \"messages\": []\n        },\n        \"assistant\": {\n            \"name\": \"Weather Assistant\",\n            \"description\": \"An assistant that provides weather information\",\n            \"model\":{},\n            \"voice\":{},\n            \"artifactPlans\":{},\n            \"startSpeakingPlan\":{}\n        },\n        \"call\": {\n            \"id\": \"call-uuid\",\n            \"orgId\": \"org-uuid\",\n            \"type\": \"webCall\",\n            \"assistant\": {}\n        }\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Default Structured Data Prompt for Call Analysis\nDESCRIPTION: The default prompt used to extract structured data from a call according to a JSON Schema. This data is stored in call.analysis.structuredData.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_3\n\nLANGUAGE: text\nCODE:\n```\nYou are an expert data extractor. You will be given a transcript of a call. Extract structured data per the JSON Schema.\n```\n\n----------------------------------------\n\nTITLE: Defining a Customer Support Workflow in JSON\nDESCRIPTION: This snippet demonstrates how to create a customer support workflow using the new Workflows API. It includes nodes for greeting, menu options, and transfers to different departments, connected by edges with conditional logic.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-13.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Customer Support Workflow\",\n  \"nodes\": [\n    {\n      \"id\": \"greeting\",\n      \"type\": \"Say\",\n      \"text\": \"Hello, welcome to customer support. Do you need help with billing or technical issues?\"\n    },\n    {\n      \"id\": \"menu\",\n      \"type\": \"Gather\",\n      \"options\": [\"billing\", \"technical\", \"other\"]\n    },\n    {\n      \"id\": \"billing\",\n      \"type\": \"Say\",\n      \"text\": \"I'll connect you with our billing department.\"\n    },\n    {\n      \"id\": \"technical\",\n      \"type\": \"Say\",\n      \"text\": \"I'll connect you with our technical support team.\"\n    },\n    {\n      \"id\": \"transfer_billing\",\n      \"type\": \"Transfer\",\n      \"destination\": {\n        \"type\": \"number\",\n        \"number\": \"+1234567890\"\n      }\n    },\n    {\n      \"id\": \"transfer_technical\",\n      \"type\": \"Transfer\",\n      \"destination\": {\n        \"type\": \"number\",\n        \"number\": \"+1987654321\"\n      }\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": \"greeting\",\n      \"to\": \"menu\"\n    },\n    {\n      \"from\": \"menu\",\n      \"to\": \"billing\",\n      \"condition\": {\n        \"type\": \"logic\",\n        \"liquid\": \"{% if input == 'billing' %} true {% endif %}\"\n      }\n    },\n    {\n      \"from\": \"menu\",\n      \"to\": \"technical\",\n      \"condition\": {\n        \"type\": \"logic\",\n        \"liquid\": \"{% if input == 'technical' %} true {% endif %}\"\n      }\n    },\n    {\n      \"from\": \"billing\",\n      \"to\": \"transfer_billing\"\n    },\n    {\n      \"from\": \"technical\",\n      \"to\": \"transfer_technical\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Overriding Vapi AI Assistant Settings and Variables\nDESCRIPTION: This code shows how to override assistant settings and set template variables when starting a Vapi AI web call. It includes customizing the transcriber, disabling recording, and setting a variable value.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/web.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst assistantOverrides = {\n  transcriber: {\n    provider: \"deepgram\",\n    model: \"nova-2\",\n    language: \"en-US\",\n  },\n  recordingEnabled: false,\n  variableValues: {\n    name: \"John\",\n  },\n};\n\nvapi.start(\"79f3XXXX-XXXX-XXXX-XXXX-XXXXXXXXce48\", assistantOverrides);\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Headers Authentication in Vapi\nDESCRIPTION: Configuration example for setting up custom headers authentication, including Authorization and custom header values.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/server-authentication.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"server\": {\n    \"url\": \"https://your-server.com/webhook\",\n    \"headers\": {\n      \"Authorization\": \"Bearer your-api-key\",\n      \"Custom-Header\": \"custom-value\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Generating a Private JWT Token in JavaScript\nDESCRIPTION: This snippet demonstrates how to generate a private JWT token for Vapi API authentication. It includes defining the payload with organization ID and token scope, retrieving the private key from environment variables, setting token options, and generating the token.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/jwt-authentication.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// Define the payload\nconst payload = {\n  orgId: process.env.ORG_ID,\n  token: {\n    // This is the scope of the token\n    tag: \"private\",\n  },\n};\n\n// Get the private key from environment variables\nconst key = process.env.PRIVATE_KEY;\n\n// Define token options\nconst options = {\n  expiresIn: \"1h\",\n};\n\n// Generate the token using a JWT library or built-in functionality\nconst token = generateJWT(payload, key, options);\n```\n\n----------------------------------------\n\nTITLE: Configuring Handoff Step in Vapi AI - JSON Configuration\nDESCRIPTION: Example configuration of a handoff step that handles user order collection. The step includes input requirements for name and email, conditional destinations based on order provision, and detailed input/output schema definitions for conversation handling.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/blocks/steps.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n  {\n  \"type\": \"handoff\",\n  \"name\": \"get_user_order\",\n  \"input\": {\n    \"name\": \"John Doe\",\n    \"email\": \"johndoe@example.com\"\n  },\n  \"destinations\": [\n    {\n      \"type\": \"step\",\n      \"stepName\": \"confirm_order\",\n      \"conditions\": [\n        {\n          \"type\": \"model-based\",\n          \"instruction\": \"If the user has provided an order\"\n        }\n      ]\n    }\n  ],\n  \"block\": {\n    \"name\": \"ask_for_order\",\n    \"type\": \"conversation\",\n    \"inputSchema\": {\n      \"type\": \"object\",\n      \"required\": [\"name\", \"email\"],\n      \"properties\": {\n        \"name\": { \"type\": \"string\", \"description\": \"The customer's name\" },\n        \"email\": { \"type\": \"string\", \"description\": \"The customer's email\" }\n      }\n    },\n    \"instruction\": \"Greet the customer and ask for their name and email. Then ask them what they'd like to order.\",\n    \"outputSchema\": {\n      \"type\": \"object\",\n      \"required\": [\"orders\", \"name\"],\n      \"properties\": {\n        \"orders\": {\n          \"type\": \"string\",\n          \"description\": \"The customer's order, e.g., 'burger with fries'\"\n        },\n        \"name\": { \n          \"type\": \"string\",\n          \"description\": \"The customer's name\"\n        }\n      }\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Sending Call Status Update in JSON\nDESCRIPTION: Shows the structure of a call status update message sent to the Server URL.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"status-update\",\n    \"call\": { Call Object },\n    \"status\": \"ended\",\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Default Summary Prompt for Call Analysis\nDESCRIPTION: The default prompt used to generate a concise 2-3 sentence summary of a call. This summary is stored in call.analysis.summary.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nYou are an expert note-taker. You will be given a transcript of a call. Summarize the call in 2-3 sentences, if applicable.\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Tool Endpoint in TypeScript\nDESCRIPTION: This code snippet shows how to set up a dedicated endpoint for custom tools. It processes incoming tool call requests, specifically handling a 'processOrder' function with a hardcoded result.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\napp.post(\"/chat/completions/custom-tool\", async (req: Request, res: Response) => {\n  logEvent(\"Received request at /chat/completions/custom-tool\", req.body);\n  // Expect the payload to have a \"message\" with a \"toolCallList\" array.\n  const vapiPayload = req.body.message;\n\n  // Process tool call.\n  for (const toolCall of vapiPayload.toolCallList) {\n    if (toolCall.function?.name === \"processOrder\") {\n      const hardcodedResult = \"CustomTool processOrder With CustomLLM Always Works\";\n      logEvent(\"Returning hardcoded result for 'processOrder'\", { toolCallId: toolCall.id });\n      return res.json({\n        results: [\n          {\n            toolCallId: toolCall.id,\n            result: hardcodedResult,\n          },\n        ],\n      });\n    }\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring End Call Function for Vapi Assistant (JSON)\nDESCRIPTION: This snippet shows how to set up the endCall function for a Vapi voice assistant. It includes the model configuration, system message, and the endCall tool.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/default-tools.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant at a law firm. If the user is being mean, use the endCall function.\"\n      }\n    ],\n    \"tools\": [\n      {\n          \"type\": \"endCall\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring a Squad with Multiple Assistants in JSON\nDESCRIPTION: This JSON snippet demonstrates how to create a squad with multiple assistants, including transfer destinations. It shows the structure for defining squad members, their IDs or full configurations, and transfer rules between assistants.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"squad\": {\n        \"members\": [\n            {\n                \"assistantId\": \"information-gathering-assistant-id\",\n                \"assistantDestinations\": [{\n                    \"type\": \"assistant\",\n                    \"assistantName\": \"Appointment Booking\",\n                    \"message\": \"Please hold on while I transfer you to our appointment booking assistant.\",\n                    \"description\": \"Transfer the user to the appointment booking assistant after they say their name.\"\n                }],\n            },\n            {\n                \"assistant\": {\n                    \"name\": \"Appointment Booking\",\n                    ...\n                },\n            }\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing Vapi Web SDK in JavaScript\nDESCRIPTION: This snippet demonstrates how to import and initialize the Vapi Web SDK using a public key obtained from the Vapi Dashboard.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport Vapi from '@vapi-ai/web';\n\nconst vapi = new Vapi('your-web-token');\n```\n\n----------------------------------------\n\nTITLE: Adding a Message to Conversation History in Vapi Call\nDESCRIPTION: This control command adds a new message to the conversation history and optionally triggers the assistant to respond to it, useful for dynamic conversation modification.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST 'https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control' \n-H 'content-type: application/json' \n--data-raw '{\n  \"type\": \"add-message\",\n  \"message\": {\n    \"role\": \"system\",\n    \"content\": \"New message added to conversation\"\n  },\n  \"triggerResponseEnabled\": true\n}'\n```\n\n----------------------------------------\n\nTITLE: Responding with Error Message in JSON\nDESCRIPTION: Demonstrates how to respond with an error message instead of an assistant.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{ \"error\": \"Sorry, not enough credits on your account, please refill.\" }\n```\n\n----------------------------------------\n\nTITLE: Generating a Public JWT Token in JavaScript\nDESCRIPTION: This snippet shows how to create a public JWT token for Vapi API authentication. It includes a payload with organization ID, token scope set to public, and additional restrictions such as allowed origins and assistant IDs.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/jwt-authentication.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n// Define the payload\nconst payload = {\n  orgId: process.env.ORG_ID,\n  // This is the scope of the token\n  token: {\n    tag: \"public\",\n    restrictions: {\n      enabled: true,\n      allowedOrigins: [\"https://example.vapi.ai\"],\n      allowedAssistantIds: [\"1cbf8c70-5fd7-4f61-a220-376ab35be1b0\"],\n      allowTransientAssistant: false,\n    },\n  },\n};\n\n// Get the private key from environment variables\nconst key = process.env.PRIVATE_KEY;\n\n// Define token options\nconst options = {\n  expiresIn: \"1h\",\n};\n\n// Generate the token using a JWT library or built-in functionality\nconst token = generateJWT(payload, key, options);\n```\n\n----------------------------------------\n\nTITLE: Configuring Twilio Voicemail Detection in Vapi Assistant\nDESCRIPTION: Configuration object that enables Twilio's voicemail detection with various detection types and timing parameters. This setup identifies when a call is answered by a voicemail system rather than a human.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/voicemail-detection.mdx#2025-04-14_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\nvoicemailDetection: {\n  provider: \"twilio\",\n  voicemailDetectionTypes: [\n    \"machine_start\",\n    \"machine_end_beep\",\n    \"machine_end_silence\",\n    \"unknown\",\n    \"machine_end_other\"\n  ],\n  enabled: true,\n  machineDetectionTimeout: 15,\n  machineDetectionSpeechThreshold: 2500,\n  machineDetectionSpeechEndThreshold: 2050,\n  machineDetectionSilenceTimeout: 2000\n}\n```\n\n----------------------------------------\n\nTITLE: Warm Transfer with Summary Configuration\nDESCRIPTION: This snippet shows how to configure a warm transfer with a summary. The summaryPlan generates a summary of the call that will be provided to the recipient before the call is transferred, using the transcript of the conversation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n\"transferPlan\": {\n  \"mode\": \"warm-transfer-with-summary\",\n  \"summaryPlan\": {\n    \"enabled\": true,\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"Please provide a summary of the call.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Server Response Format Examples\nDESCRIPTION: Shows the expected response format for tool calls, including basic structure and a weather-specific example.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/custom-tools.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"results\": [\n        {\n            \"toolCallId\": \"X\",\n            \"result\": \"Y\"\n        }\n    ]\n}\n```\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"results\": [\n    {\n      \"toolCallId\": \"call_VaJOd8ZeZgWCEHDYomyCPfwN\",\n      \"result\": \"San Francisco's weather today is 62C, partly cloudy.\"\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Ending a Call Programmatically with Vapi API\nDESCRIPTION: This simple control command terminates the ongoing call immediately, providing a clean way to end conversations programmatically.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST 'https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control' \n-H 'content-type: application/json' \n--data-raw '{\n  \"type\": \"end-call\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Handling Function Call Events in JavaScript\nDESCRIPTION: This code handles function call events from the assistant, allowing the application to add toppings to the pizza or redirect to checkout based on the user's input.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on('message', (msg) => {\n  if (msg.type !== \"function-call\") return;\n\n  if (msg.functionCall.name === \"addTopping\") {\n    const topping = msg.functionCall.parameters.topping;\n    // Add the topping to the pizza\n  }\n\n  if (msg.functionCall.name === \"goToCheckout\") {\n    // Redirect the user to checkout\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom LLM in Vapi using cURL\nDESCRIPTION: This curl command demonstrates how to update a Vapi assistant with a custom LLM configuration for basic response generation without tool calls. It includes setting the model provider, URL, and system message.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH https://api.vapi.ai/assistant/insert-your-assistant-id-here \\\n     -H \"Authorization: Bearer insert-your-private-key-here\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"model\": {\n    \"provider\": \"custom-llm\",\n    \"model\": \"gpt-4o\",\n    \"url\": \"https://custom-llm-url/chat/completions\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"[TASK] Ask the user if they want to transfer the call; if not, continue the conversation.\"\n      }\n    ]\n  },\n  \"transcriber\": {\n    \"provider\": \"azure\",\n    \"language\": \"en-CA\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Responding to Function Call with Simple Result in JSON\nDESCRIPTION: Shows how to respond to a function call with a simple string result.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"result\": \"Your email has been sent.\" }\n```\n\n----------------------------------------\n\nTITLE: Customizing Structured Data Prompt with JSON Configuration\nDESCRIPTION: JSON configuration to customize the structured data prompt that extracts specific information from calls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"structuredDataPrompt\": \"Custom structured data prompt text\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Knowledge Base with Trieve Dataset in Vapi\nDESCRIPTION: This JSON payload is used to create a knowledge base in Vapi using a Trieve dataset. It specifies the name, provider, search plan, and creation plan for the knowledge base.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/integrating-with-trieve.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"trieve-dataset\",\n  \"provider\": \"trieve\",\n  \"searchPlan\": {\n    \"scoreThreshold\": 0.2,\n    \"searchType\": \"semantic\"\n  },\n  \"createPlan\": {\n    \"type\": \"import\",\n    \"providerId\": \"<Your Trieve Dataset ID>\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Event Handling Setup\nDESCRIPTION: Examples of setting up event listeners for various call events including speech start/end, call status, volume levels, and error handling.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"speech-start\", () => {\n  console.log(\"Assistant speech has started.\");\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"speech-end\", () => {\n  console.log(\"Assistant speech has ended.\");\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"call-start\", () => {\n  console.log(\"Call has started.\");\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"call-end\", () => {\n  console.log(\"Call has ended.\");\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"volume-level\", (volume) => {\n  console.log(`Assistant volume level: ${volume}`);\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"message\", (message) => {\n  console.log(message);\n});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"error\", (e) => {\n  console.error(e);\n});\n```\n\n----------------------------------------\n\nTITLE: Handling Transcription Events in JavaScript\nDESCRIPTION: This snippet demonstrates how to handle transcription events, updating the UI with partial and final transcripts of the user's speech.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on(\"message\", (msg) => {\n  if (msg.type !== \"transcript\") return;\n\n  if (msg.transcriptType === \"partial\") {\n    // Update UI to show the live partial transcript\n  }\n\n  if (msg.transcriptType === \"final\") {\n    // Update UI to show the final transcript\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Adding Event Listeners to Vapi Instance in JavaScript\nDESCRIPTION: This code snippet shows how to add event listeners to the Vapi instance for various events such as speech start/end, call start/end, volume level changes, and error handling.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/voice-widget.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nvapiInstance.on('speech-start', () => {\n  console.log('Speech has started');\n});\n\nvapiInstance.on('speech-end', () => {\n  console.log('Speech has ended');\n});\n\nvapiInstance.on('call-start', () => {\n  console.log('Call has started');\n});\n\nvapiInstance.on('call-end', () => {\n  console.log('Call has stopped');\n});\n\nvapiInstance.on('volume-level', (volume) => {\n  console.log(`Assistant volume level: ${volume}`);\n});\n\n// Function calls and transcripts will be sent via messages\nvapiInstance.on('message', (message) => {\n  console.log(message);\n});\n\nvapiInstance.on('error', (e) => {\n  console.error(e)\n});\n```\n\n----------------------------------------\n\nTITLE: Using Vapi Tool Call with Updated Schema\nDESCRIPTION: Example of the new ToolCall schema using the function property with id and function details, replacing the older tool and toolBody properties.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-29.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"function\": {\n    \"id\": \"function_id\",\n    \"function\": {\n      \"name\": \"function_name\",\n      \"parameters\": {}\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Complete Warm Transfer with Summary Example\nDESCRIPTION: This snippet provides a complete example of a transferCall configuration using the warm transfer with summary mode. It includes the destination phone number and the summary plan that will generate a call summary for the recipient.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"transferCall\",\n  \"messages\": [\n    {\n      \"type\": \"request-start\",\n      \"content\": \"I'll transfer you to someone who can help.\"\n    }\n  ],\n  \"destinations\": [\n    {\n      \"type\": \"number\",\n      \"number\": \"+918936850777\",\n      \"description\": \"Transfer the call\",\n      \"transferPlan\": {\n        \"mode\": \"warm-transfer-with-summary\",\n        \"summaryPlan\": {\n          \"enabled\": true,\n          \"messages\": [\n            {\n              \"role\": \"system\",\n              \"content\": \"Please provide a summary of the call.\"\n            },\n            {\n              \"role\": \"user\",\n              \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\"\n            }\n          ]\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Capturing Real-Time Audio from a Vapi Call with Node.js\nDESCRIPTION: This Node.js script connects to the WebSocket listenUrl to stream and save audio data from a live call, capturing the raw PCM audio buffer for later analysis or playback.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_7\n\nLANGUAGE: jsx\nCODE:\n```\nconst WebSocket = require('ws');\nconst fs = require('fs');\n\nlet pcmBuffer = Buffer.alloc(0);\n\nconst ws = new WebSocket(\"wss://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/transport\");\n\nws.on('open', () => console.log('WebSocket connection established'));\n\nws.on('message', (data, isBinary) => {\n  if (isBinary) {\n    pcmBuffer = Buffer.concat([pcmBuffer, data]);\n    console.log(`Received PCM data, buffer size: ${pcmBuffer.length}`);\n  } else {\n    console.log('Received message:', JSON.parse(data.toString()));\n  }\n});\n\nws.on('close', () => {\n  if (pcmBuffer.length > 0) {\n    fs.writeFileSync('audio.pcm', pcmBuffer);\n    console.log('Audio data saved to audio.pcm');\n  }\n});\n\nws.on('error', (error) => console.error('WebSocket error:', error));\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Claude 3.7 Sonnet with Thinking Feature\nDESCRIPTION: JSON configuration for enabling the Claude 3.7 Sonnet model with the new thinking feature. Allows setting budget tokens between 1024 and 100000 for enhanced processing capabilities.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-02.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": \"claude-3-7-sonnet-20250219\",\n  \"provider\": \"anthropic\",\n  \"thinking\": {\n    \"type\": \"enabled\",\n    \"budgetTokens\": 5000 // min 1024, max 100000\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Injecting a Say Message During a Live Call with Vapi\nDESCRIPTION: This curl command uses the Call Control API to make the assistant speak a specified message during an ongoing call, with an option to end the call afterward.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST 'https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control' \n-H 'content-type: application/json' \n--data-raw '{\n  \"type\": \"say\",\n  \"content\": \"Welcome to Vapi, this message was injected during the call.\",\n  \"endCallAfterSpoken\": false\n}'\n```\n\n----------------------------------------\n\nTITLE: Adding Call Control Buttons in HTML and JavaScript\nDESCRIPTION: This code adds start and stop call buttons to the HTML and sets up event listeners to control the Vapi assistant.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<button id=\"start-call\">Start Call</button>\n<button id=\"stop-call\">Stop Call</button>\n```\n\nLANGUAGE: javascript\nCODE:\n```\nconst startCallButton = document.getElementById('start-call');\n\nstartCallButton.addEventListener('click', async () => {\n  await vapi.start('your-assistant-id');\n});\n\nconst stopCallButton = document.getElementById('stop-call');\n\nstopCallButton.addEventListener('click', async () => {\n  await vapi.stop();\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Vapi Assistant in JavaScript\nDESCRIPTION: This code snippet shows how to configure a Vapi assistant directly in JavaScript, including setting the AI model, voice provider, and initial greeting message.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/voice-widget.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst assistant = {\n  model: {\n    provider: \"openai\",\n    model: \"gpt-3.5-turbo\",\n    systemPrompt:\n      \"You're a versatile AI assistant named Vapi who is fun to talk with.\",\n  },\n  voice: {\n    provider: \"11labs\",\n    voiceId: \"paula\",\n  },\n  firstMessage: \"Hi, I am Vapi how can I assist you today?\",\n};\n```\n\n----------------------------------------\n\nTITLE: Custom Tool Calling Implementation with ProcessOrder\nDESCRIPTION: Example of making a custom tool call to process an order using the custom LLM endpoint. The request includes a tool call list with function parameters and expects a response with tool call results.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://custom-llm-url/chat/completions/custom-tool \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"message\": {\n          \"toolCallList\": [\n            {\n              \"id\": \"12345\",\n              \"function\": {\n                \"name\": \"processOrder\",\n                \"arguments\": {\n                  \"param\": \"value\"\n                }\n              }\n            }\n          ]\n        }\n      }'\n```\n\n----------------------------------------\n\nTITLE: Sending Function Call Message in JSON\nDESCRIPTION: Illustrates the structure of a function call message sent to the Server URL. It includes the call object and function call details.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"function-call\",\n    \"call\": { Call Object },\n    \"functionCall\": {\n      \"name\": \"sendEmail\",\n      \"parameters\": \"{ \\\"emailAddress\\\": \\\"john@example.com\\\"}\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Latest OpenAI Model\nDESCRIPTION: Shows how to configure an assistant to use the latest OpenAI model. The gpt-4o-2024-11-20 model has been added as an option for both primary and fallback models.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-24.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n\"gpt-4o-2024-11-20\"\n```\n\n----------------------------------------\n\nTITLE: Creating SIP Assistant Configuration\nDESCRIPTION: JSON configuration for creating a new assistant that can handle SIP calls using the POST /assistant endpoint\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"name\": \"My SIP Assistant\",\n\t\"firstMessage\": \"Hello {{first_name}}, you've reached me over SIP.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Hook for Call Transfer on Pipeline Error (SIP)\nDESCRIPTION: This cURL command updates an assistant to add a hook that transfers the call to a SIP destination when a pipeline error occurs during call ending. It shows how to structure the hook with filters and SIP transfer action.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/assistant-hooks.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH \"https://api.vapi.ai/assistant/<id>\" \\\n     -H \"Authorization: Bearer <auth>\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"hooks\": [{\n    \"on\": \"call.ending\",\n    \"filters\": [{\n      \"type\": \"oneOf\",\n      \"key\": \"call.endedReason\",\n      \"oneOf\": [\"pipeline-error\"]\n    }],\n    \"do\": [{\n      \"type\": \"transfer\",\n      \"destination\": {\n        \"type\": \"sip\",\n        \"sipUri\": \"sip:user@domain.com\"\n      }\n    }]\n  }]\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating SIP Trunk Credential in Vapi\nDESCRIPTION: API call to create a new SIP trunk credential in Vapi using Zadarma as an example. Configures gateway settings and authentication details for the trunk connection.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-trunk.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"https://api.vapi.ai/credential\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_VAPI_PRIVATE_KEY\" \\\n  -d '{\n    \"provider\": \"byo-sip-trunk\",\n    \"name\": \"Zadarma Trunk\",\n    \"gateways\": [{\n      \"ip\": \"sip.zadarma.com\"\n    }],\n    \"outboundLeadingPlusEnabled\": true,\n    \"outboundAuthenticationPlan\": {\n      \"authUsername\": \"YOUR_SIP_NUMBER\",\n      \"authPassword\": \"YOUR_SIP_PASSWORD\"\n    }\n  }'\n```\n\n----------------------------------------\n\nTITLE: Initiating a Phone Call with Dynamic Variables in Vapi AI\nDESCRIPTION: This JSON payload illustrates how to start a phone call using Vapi AI with dynamic variables. It includes the assistant ID, variable values, customer phone number, and phone number ID.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/dynamic-variables.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"assistantId\": \"your-assistant-id\",\n  \"assistantOverrides\": {\n    \"variableValues\": {\n      \"name\": \"John\"\n    }\n  },\n  \"customer\": {\n    \"number\": \"+1xxxxxxxxxx\"\n  },\n  \"phoneNumberId\": \"your-phone-id\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Knowledge Base with Trieve in Vapi using cURL\nDESCRIPTION: This code snippet demonstrates how to create a Knowledge Base in Vapi by importing a Trieve dataset. It includes configuration options for the search plan and import process.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledgebase.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/knowledge-base' \\\n--header 'Content-Type: text/plain' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n    \"name\": \"trieve-dataset\",\n    \"provider\": \"trieve\",\n    \"searchPlan\": {\n        \"searchType\": \"semantic\",\n        \"topK\": 3,\n        \"removeStopWords\": true,\n        \"scoreThreshold\": 0.7\n    },\n    \"createPlan\": {\n        \"type\": \"import\",\n        \"providerId\": \"<YOUR_TRIEVE_DATASET_ID>\"\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Call Transfer Modes in Vapi\nDESCRIPTION: Two new call transfer modes have been added that allow waiting for an operator to speak first before providing a transfer message or summary when transferring calls to a new destination with TransferPlan.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-13.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n'warm-transfer-wait-for-operator-to-speak-first-and-then-say-message'\n```\n\nLANGUAGE: javascript\nCODE:\n```\n'warm-transfer-wait-for-operator-to-speak-first-and-then-say-summary'\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant with Function Calling in JSON\nDESCRIPTION: Shows how to configure an assistant with OpenAI's function calling API. It includes the assistant's name, model details, and function definitions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"Ryan's Assistant\",\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"functions\": [\n      {\n        \"name\": \"sendEmail\",\n        \"description\": \"Used to send an email to a client.\",\n        \"parameters\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"color\": { \"type\": \"string\" }\n          }\n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Function Call Request Example\nDESCRIPTION: Example of the incoming function call request to the server endpoint when the assistant attempts to book an appointment.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"function-call\",\n    \"call\": { \"Call Object\" },\n    \"functionCall\": {\n      \"name\": \"bookAppointment\",\n      \"parameters\": \"{ \\\"datetime\\\": \\\"2023-09-29T21:44:37.946Z\\\"}\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Enabling HIPAA Compliance in Vapi Assistant Configuration\nDESCRIPTION: This JSON snippet shows how to enable HIPAA compliance in the Vapi assistant settings. Setting 'hipaaEnabled' to true ensures that no call logs, recordings, or transcriptions are stored during or after calls, aligning with HIPAA standards.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/security-and-privacy/hipaa.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"hipaaEnabled\": true\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Voice Fallback Plan in Vapi AI\nDESCRIPTION: JSON configuration example showing how to set up a voice fallback plan with multiple provider voices. The configuration includes a primary OpenAI voice with two fallback options from Cartesia and PlayHT providers.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/voice-fallback-plan.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"voice\": {\n    \"provider\": \"openai\",\n    \"voiceId\": \"shimmer\",\n    \"fallbackPlan\": {\n        \"voices\": [\n            {\n                \"provider\": \"cartesia\",\n                \"voiceId\": \"248be419-c632-4f23-adf1-5324ed7dbf1d\"\n            },\n            {\n                \"provider\": \"playht\",\n                \"voiceId\": \"jennifer\"\n            }\n        ]\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Transfer Tool with cURL in Bash\nDESCRIPTION: API request to create a transfer tool with an empty destinations array, which acts as a placeholder for dynamic destinations defined at runtime. This tool will be used to handle call transfers based on context.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/tool \\\n     -H \"Authorization: Bearer insert-private-key-here\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"type\": \"transferCall\",\n  \"destinations\": [],\n  \"function\": {\n    \"name\": \"dynamicDestinationTransferCall\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom LLM Server with Flask and OpenAI API\nDESCRIPTION: This Python script sets up a Flask server that acts as an intermediary between Vapi and the OpenAI API. It handles incoming POST requests from Vapi, processes them, sends requests to the OpenAI API, and returns formatted responses back to Vapi.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/using-your-server.mdx#2025-04-14_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom flask import Flask, request, jsonify\nimport openai\n\napp = Flask(__name__)\nopenai.api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual API key\n\n@app.route(\"/chat/completions\", methods=[\"POST\"])\ndef chat_completions():\n    data = request.get_json()\n    # Extract relevant information from data (e.g., prompt, conversation history)\n    # ...\n    \n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo-instruct\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            # ... (Add messages from conversation history and current prompt)\n        ]\n    )\n    # Format response according to Vapi's structure\n    # ...\n    return jsonify(formatted_response)\n\nif __name__ == \"__main__\":\n    app.run(debug=True, port=5000)  # You can adjust the port if needed\n```\n\n----------------------------------------\n\nTITLE: Customizing Vapi Button Configuration in JavaScript\nDESCRIPTION: This snippet demonstrates how to customize the Vapi button's appearance and behavior for different states (idle, loading, active) using JavaScript configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/voice-widget.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst buttonConfig = {\n  position: \"bottom-right\", // \"bottom\" | \"top\" | \"left\" | \"right\" | \"top-right\" | \"top-left\" | \"bottom-left\" | \"bottom-right\"\n  offset: \"40px\", // decide how far the button should be from the edge\n  width: \"50px\", // min-width of the button\n  height: \"50px\", // height of the button\n  idle: { // button state when the call is not active.\n    color: `rgb(93, 254, 202)`, \n    type: \"pill\", // or \"round\"\n    title: \"Have a quick question?\", // only required in case of Pill\n    subtitle: \"Talk with our AI assistant\", // only required in case of pill\n    icon: `https://unpkg.com/lucide-static@0.321.0/icons/phone.svg`,\n  },\n  loading: { // button state when the call is connecting\n    color: `rgb(93, 124, 202)`,\n    type: \"pill\", // or \"round\"\n    title: \"Connecting...\", // only required in case of Pill\n    subtitle: \"Please wait\", // only required in case of pill\n    icon: `https://unpkg.com/lucide-static@0.321.0/icons/loader-2.svg`,\n  },\n  active: { // button state when the call is in progress or active.\n    color: `rgb(255, 0, 0)`,\n    type: \"pill\", // or \"round\"\n    title: \"Call is in progress...\", // only required in case of Pill\n    subtitle: \"End the call.\", // only required in case of pill\n    icon: `https://unpkg.com/lucide-static@0.321.0/icons/phone-off.svg`,\n  },\n};\n```\n\n----------------------------------------\n\nTITLE: Testing Vapi-Attached Tool Calling with cURL\nDESCRIPTION: This curl command shows how to test Vapi-attached tool calling, specifically the 'transferCall' function, by sending a POST request to the custom LLM endpoint with the necessary tool configuration and destination information.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://custom-llm-url/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"model\": \"gpt-3.5-turbo\",\n        \"messages\": [\n          {\"role\": \"user\", \"content\": \"Please transfer my call.\"}\n        ],\n        \"temperature\": 0.7,\n        \"tools\": [\n          {\n            \"type\": \"function\",\n            \"function\": {\n              \"name\": \"transferCall\",\n              \"description\": \"Transfer call to a specified destination\",\n              \"parameters\": {}\n            }\n          }\n        ],\n        \"destination\": \"555-1234\"\n      }'\n```\n\n----------------------------------------\n\nTITLE: Basic Vapi Integration Without Tools\nDESCRIPTION: Configuration for integrating a custom LLM with Vapi without tool support. Includes model configuration, system messages, and transcriber settings for basic response generation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X PATCH https://api.vapi.ai/assistant/insert-your-assistant-id-here \\\n     -H \"Authorization: Bearer insert-your-private-key-here\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"model\": {\n    \"provider\": \"custom-llm\",\n    \"model\": \"gpt-4o\",\n    \"url\": \"https://custom-llm-url/chat/completions\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"[TASK] Ask the user if they want to transfer the call; if not, continue chatting.\"\n      }\n    ]\n  },\n  \"transcriber\": {\n    \"provider\": \"azure\",\n    \"language\": \"en-CA\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring PCI Compliance for Vapi Assistant in JSON\nDESCRIPTION: This JSON snippet demonstrates how to enable PCI compliance for a Vapi assistant. The 'pciEnabled' flag is set to true within the 'compliancePlan' object, which aligns the assistant with PCI DSS standards by ensuring secure data transmission without storage on Vapi's systems.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/security-and-privacy/PCI.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n{\n  \"compliancePlan\": {\n    \"pciEnabled\": true\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Vapi Assistant with Keyword Boosting via cURL\nDESCRIPTION: This bash script demonstrates how to create a Vapi assistant with Deepgram's keyword boosting feature enabled. The request includes configuration for the assistant's name, model, voice settings, and transcriber settings with a custom keyword 'snuffleupagus' and an intensifier value.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-keywords.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl \\\n  --request POST \\\n  --header 'Authorization: Bearer <token>' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"name\": \"Emma\",\n    \"model\": {\n        \"model\": \"gpt-4o\",\n        \"provider\": \"openai\"\n    },\n    \"voice\": {\n        \"voiceId\": \"emma\",\n        \"provider\": \"azure\"\n    },\n    \"transcriber\": {\n        \"provider\": \"deepgram\",\n        \"model\": \"nova-2\",\n        \"language\": \"bg\",\n        \"smartFormat\": true,\n        \"keywords\": [\n            \"snuffleupagus:1\"\n        ]\n    },\n    \"firstMessage\": \"Hi, I am Emma, what is your name?\",\n    \"firstMessageMode\": \"assistant-speaks-first\"\n  }' \\\n  https://api.vapi.ai/assistant\n```\n\n----------------------------------------\n\nTITLE: Handling Speaking Events in JavaScript\nDESCRIPTION: This code sets up event listeners for speech start and end events, allowing the UI to be updated when the assistant is speaking.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on('speech-start', () => {\n  // Update UI to show that the assistant is speaking\n});\n\nvapi.on('speech-end', () => {\n// Update UI to show that the assistant is done speaking\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Spanish Voice Assistant with Azure\nDESCRIPTION: Example configuration for setting up a Spanish-speaking voice assistant using Azure's text-to-speech service. The configuration specifies the voice provider and a Spanish voice ID.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/multilingual.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"voice\": {\n    \"provider\": \"azure\",\n    \"voiceId\": \"es-ES-ElviraNeural\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Background Message Logger in JavaScript\nDESCRIPTION: JavaScript function that uses Vapi SDK to silently add a system message to the chat history. Demonstrates the use of vapi.send() method with message type and content configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/background-messages.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nfunction logUserAction() {\n  // Function to log the user action\n  vapi.send({\n    type: \"add-message\",\n    message: {\n      role: \"system\",\n      content: \"The user has pressed the button, say peanuts\",\n    },\n  });\n}\n```\n\n----------------------------------------\n\nTITLE: Sample Transfer Destination Request Payload in JSON\nDESCRIPTION: Example of the payload sent to your server when a transfer is requested. Contains call details including messages, transcript, and other contextual information needed for deciding the transfer destination.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"transfer-destination-request\",\n  \"artifact\": {\n    \"messages\": [...],\n    \"transcript\": \"Hello, how can I help you?\",\n    \"messagesOpenAIFormatted\": [...]\n  },\n  \"assistant\": { \"id\": \"assistant123\" },\n  \"phoneNumber\": \"+14155552671\",\n  \"customer\": { \"id\": \"customer456\" },\n  \"call\": { \"id\": \"call789\", \"status\": \"ongoing\" }\n}\n```\n\n----------------------------------------\n\nTITLE: Adding Zadarma SIP Credentials to Vapi.ai Using API\nDESCRIPTION: This curl command adds Zadarma SIP trunk credentials to Vapi.ai. It requires your Vapi private key, a name for the trunk, Zadarma server address, SIP number, and SIP password. The request creates a credential that will be used when adding a virtual phone number.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-zadarma.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L 'https://api.vapi.ai/credential' \\\n-H 'Content-Type: application/json' \\\n-H 'Authorization: Bearer YOUR_PRIVATE_KEY' \\\n-d '{\n  \"provider\": \"byo-sip-trunk\",\n  \"name\": \"Zadarma Trunk\",\n  \"gateways\": [\n    { \"ip\": \"sip.zadarma.com\" }\n  ],\n  \"outboundLeadingPlusEnabled\": true,\n  \"outboundAuthenticationPlan\": {\n    \"authUsername\": \"YOUR_SIP_NUMBER\",\n    \"authPassword\": \"YOUR_SIP_PASSWORD\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: Managing Call Controls\nDESCRIPTION: Collection of methods for basic call control like stopping, checking mute status, and speaking messages.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.stop();\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.isMuted();\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.isMuted(); // false\nvapi.setMuted(true);\nvapi.isMuted(); // true\n```\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.say(\"Our time's up, goodbye!\", true)\n```\n\n----------------------------------------\n\nTITLE: Sending End-of-Call Report in JSON\nDESCRIPTION: Illustrates the structure of an end-of-call report message sent to the Server URL. It includes details like recording URL, summary, transcript, and message history.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"end-of-call-report\",\n    \"endedReason\": \"hangup\",\n    \"call\": { Call Object },\n    \"recordingUrl\": \"https://vapi-public.s3.amazonaws.com/recordings/1234.wav\",\n    \"summary\": \"The user picked up the phone then asked about the weather...\",\n    \"transcript\": \"AI: How can I help? User: What's the weather? ...\",\n    \"messages\":[\n      {\n        \"role\": \"assistant\",\n        \"message\": \"How can I help?\",\n      },\n      {\n        \"role\": \"user\",\n        \"message\": \"What's the weather?\"\n      },\n      ...\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Voice for Vapi Assistant in JSON\nDESCRIPTION: This JSON snippet demonstrates how to update the 'voice' property in the assistant configuration to use a custom voice. It specifies the provider (in this case, 'deepgram') and the custom voice ID.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-voices/custom-voice.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"voice\": {\n    \"provider\": \"deepgram\",\n    \"voiceId\": \"your-voice-id\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring the Query Tool with Knowledge Base Integration in JSON\nDESCRIPTION: Example configuration for creating a Query Tool that allows assistants to search through knowledge bases. The configuration includes the tool type, server URL, function definition with parameters, and knowledge base details including provider and associated file IDs.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-06.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"query\",\n  \"async\": false,\n  \"server\": {\n    \"url\": \"https://api.example.com/query-handler\"\n  },\n  \"function\": {\n    \"name\": \"query_knowledge\",\n    \"description\": \"Query knowledge bases for information\",\n    \"parameters\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"query\": {\n          \"type\": \"string\",\n          \"description\": \"The query to search for\"\n        }\n      },\n      \"required\": [\"query\"]\n    }\n  },\n  \"knowledgeBases\": [\n    {\n      \"name\": \"Product Documentation\",\n      \"model\": \"gemini-1.5-flash\",\n      \"provider\": \"google\",\n      \"description\": \"Contains all product manuals\",\n      \"fileIds\": [\"file-123\", \"file-456\"]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating Custom LLM Assistant\nDESCRIPTION: Configuration for creating an assistant using a custom OpenAI-compatible endpoint.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/fine-tuned-openai-models.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"My Assistant\",\n  \"model\": {\n    \"provider\": \"custom-llm\",\n    \"url\": \"<YOUR OPENAI COMPATIBLE ENDPOINT BASE URL>\",\n    \"model\": \"my-cool-model\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant.\"\n      }\n    ],\n    \"temperature\": 0.7\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting System Prompt for Vapi AI Pizza Ordering Assistant\nDESCRIPTION: This code block defines the system prompt for the AI assistant, outlining its role, the menu items, ordering rules, and conversation guidelines for a pizza ordering scenario.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/outbound.mdx#2025-04-14_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nYou are a voice assistant for Vappy's Pizzeria,\na pizza shop located on the Internet.\n\nYour job is to take the order of customers calling in. The menu has only 3 types\nof items: pizza, sides, and drinks. There are no other types of items on the menu.\n\n1) There are 3 kinds of pizza: cheese pizza, pepperoni pizza, and vegetarian pizza\n(often called \"veggie\" pizza).\n2) There are 3 kinds of sides: french fries, garlic bread, and chicken wings.\n3) There are 2 kinds of drinks: soda, and water. (if a customer asks for a\nbrand name like \"coca cola\", just let them know that we only offer \"soda\")\n\nCustomers can only order 1 of each item. If a customer tries to order more\nthan 1 item within each category, politely inform them that only 1 item per\ncategory may be ordered.\n\nCustomers must order 1 item from at least 1 category to have a complete order.\nThey can order just a pizza, or just a side, or just a drink.\n\nBe sure to introduce the menu items, don't assume that the caller knows what\nis on the menu (most appropriate at the start of the conversation).\n\nIf the customer goes off-topic or off-track and talks about anything but the\nprocess of ordering, politely steer the conversation back to collecting their order.\n\nOnce you have all the information you need pertaining to their order, you can\nend the conversation. You can say something like \"Awesome, we'll have that ready\nfor you in 10-20 minutes.\" to naturally let the customer know the order has been\nfully communicated.\n\nIt is important that you collect the order in an efficient manner (succinct replies\n& direct questions). You only have 1 task here, and it is to collect the customers\norder, then end the conversation.\n\n- Be sure to be kind of funny and witty!\n- Keep all your responses short and simple. Use casual language, phrases like \"Umm...\", \"Well...\", and \"I mean\" are preferred.\n- This is a voice conversation, so keep your responses short, like in a real conversation. Don't ramble for too long.\n\nYou are calling back a customer after the call got disconnected while they were\nordering. Your job is to help them complete their order.\n```\n\n----------------------------------------\n\nTITLE: Creating SIP Trunk Credentials in Vapi.ai with Telnyx\nDESCRIPTION: This API call creates SIP trunk credentials in Vapi.ai by sending a POST request with Telnyx gateway details and authentication information. It requires your Vapi private key and SIP authentication credentials from Telnyx.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-telnyx.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/credential \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_VAPI_PRIVATE_KEY\" \\\n  -d '{\n    \"provider\": \"byo-sip-trunk\",\n    \"name\": \"Telnyx Trunk\",\n    \"gateways\": [\n      {\n        \"ip\": \"sip.telnyx.com\"\n      }\n    ],\n    \"outboundAuthenticationPlan\": {\n      \"authUsername\": \"YOUR_SIP_USERNAME\",\n      \"authPassword\": \"YOUR_SIP_PASSWORD\",\n\t  \"sipRegisterPlan\": {\n            \"realm\": \"sip.telnyx.com\"\n        }\n    }\n  }'\n```\n\n----------------------------------------\n\nTITLE: Sample Response from Vapi's Call Initiation API\nDESCRIPTION: This JSON response contains the call details including the crucial monitor object with listenUrl and controlUrl needed for call control and audio streaming.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"7420f27a-30fd-4f49-a995-5549ae7cc00d\",\n  \"assistantId\": \"5b0a4a08-133c-4146-9315-0984f8c6be80\",\n  \"phoneNumberId\": \"42b4b25d-031e-4786-857f-63b346c9580f\",\n  \"type\": \"outboundPhoneCall\",\n  \"createdAt\": \"2024-09-10T11:14:12.339Z\",\n  \"updatedAt\": \"2024-09-10T11:14:12.339Z\",\n  \"orgId\": \"eb166faa-7145-46ef-8044-589b47ae3b56\",\n  \"cost\": 0,\n  \"customer\": {\n    \"number\": \"+12345678913\"\n  },\n  \"status\": \"queued\",\n  \"phoneCallProvider\": \"twilio\",\n  \"phoneCallProviderId\": \"CA4c6793d069ef42f4ccad69a0957451ec\",\n  \"phoneCallTransport\": \"pstn\",\n  \"monitor\": {\n    \"listenUrl\": \"wss://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/transport\",\n    \"controlUrl\": \"<https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control>\"\n  }\n}\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Keypad Input for Phone Calls\nDESCRIPTION: JSON configuration for enabling DTMF touch-tone keypad inputs during phone calls. Options include enabling the feature, setting delimiters, and configuring timeout duration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-02-27.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"keypadInputPlan\": {\n    \"enabled\": true,               // Default: false\n    \"delimiters\": \"#\",             // Options: \"#\", \"*\", or \"\" (empty string)\n    \"timeoutSeconds\": 2            // Range: 0.5-10 seconds, Default: 2\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring DeepSeek Language Models with Custom Credentials in Vapi AI\nDESCRIPTION: This code snippet demonstrates how to configure assistants to use DeepSeek language models by providing custom credentials. It shows the JSON payload structure for specifying the API key, credential name, and model configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-11.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"credentials\": [\n    {\n      \"provider\": \"deep-seek\",\n      \"apiKey\": \"YOUR_API_KEY\",\n      \"name\": \"YOUR_CREDENTIAL_NAME\"\n    }\n  ],\n  \"model\": {\n    \"provider\": \"deep-seek\",\n    \"model\": \"deepseek-chat\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Express Server with WebSocket Transcription Service\nDESCRIPTION: Sets up an Express server with WebSocket endpoint for handling real-time audio transcription. Integrates with Deepgram API and includes error handling, logging, and event management.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nconst express = require(\"express\");\nconst http = require(\"http\");\nconst TranscriptionService = require(\"./transcriptionService\");\nconst FileLogger = require(\"./fileLogger\");\nrequire(\"dotenv\").config();\n\nconst app = express();\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\n\napp.get(\"/\", (req, res) => {\n  res.send(\"Custom Transcriber Service is running\");\n});\n\nconst server = http.createServer(app);\n\nconst config = {\n  DEEPGRAM_API_KEY: process.env.DEEPGRAM_API_KEY,\n  PORT: process.env.PORT || 3001,\n};\n\nconst logger = new FileLogger();\nconst transcriptionService = new TranscriptionService(config, logger);\n\ntranscriptionService.setupWebSocketServer = function (server) {\n  const WebSocketServer = require(\"ws\").Server;\n  const wss = new WebSocketServer({ server, path: \"/api/custom-transcriber\" });\n  wss.on(\"connection\", (ws) => {\n    logger.logDetailed(\n      \"INFO\",\n      \"New WebSocket client connected on /api/custom-transcriber\",\n      \"Server\"\n    );\n    ws.on(\"message\", (data, isBinary) => {\n      if (!isBinary) {\n        try {\n          const msg = JSON.parse(data.toString());\n          if (msg.type === \"start\") {\n            logger.logDetailed(\n              \"INFO\",\n              \"Received start message from client\",\n              \"Server\",\n              { sampleRate: msg.sampleRate, channels: msg.channels }\n            );\n          }\n        } catch (err) {\n          logger.error(\"JSON parse error\", err, \"Server\");\n        }\n      } else {\n        transcriptionService.send(data);\n      }\n    });\n    ws.on(\"close\", () => {\n      logger.logDetailed(\"INFO\", \"WebSocket client disconnected\", \"Server\");\n      if (\n        transcriptionService.deepgramLive &&\n        transcriptionService.deepgramLive.getReadyState() === 1\n      ) {\n        transcriptionService.deepgramLive.finish();\n      }\n    });\n    ws.on(\"error\", (error) => {\n      logger.error(\"WebSocket error\", error, \"Server\");\n    });\n    transcriptionService.on(\"transcription\", (text, channel) => {\n      const response = {\n        type: \"transcriber-response\",\n        transcription: text,\n        channel,\n      };\n      ws.send(JSON.stringify(response));\n      logger.logDetailed(\"INFO\", \"Sent transcription to client\", \"Server\", {\n        channel,\n        text,\n      });\n    });\n    transcriptionService.on(\"transcriptionerror\", (err) => {\n      ws.send(\n        JSON.stringify({ type: \"error\", error: \"Transcription service error\" })\n      );\n      logger.error(\"Transcription service error\", err, \"Server\");\n    });\n  });\n};\n\ntranscriptionService.setupWebSocketServer(server);\n\nserver.listen(config.PORT, () => {\n  console.log(`Server is running on http://localhost:${config.PORT}`);\n});\n```\n\n----------------------------------------\n\nTITLE: Configuring Assistant Hooks for Call Ending Events in JavaScript\nDESCRIPTION: This snippet demonstrates how to set up AssistantHooks to handle call.ending events, including the ability to trigger transfer actions. It shows the structure for defining hooks with customizable filters and actions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-02-17.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  \"hooks\": [{\n    \"on\": \"call.ending\",\n    \"do\": [{\n      \"type\": \"transfer\",\n      \"destination\": {\n        // Your transfer configuration\n      }\n    }]\n  }]\n}\n```\n\n----------------------------------------\n\nTITLE: Dataset Configuration Parameters\nDESCRIPTION: Configuration values for optimal dataset chunking and search performance, including token sizes, BM25 boost values, and embedding model thresholds.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/integrating-with-trieve.mdx#2025-04-14_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nTarget chunk sizes: 200-1000 tokens\nBM25 boost = 0.3\nScore thresholds:\n- text-embedding-3-small: 0.2\n- text-embedding-3-large: 0.25\n```\n\n----------------------------------------\n\nTITLE: Formatting Date and Time with LiquidJS in Vapi AI\nDESCRIPTION: This Liquid template snippet demonstrates how to format the current date and time for a specific timezone (New York) using the LiquidJS 'date' filter in Vapi AI.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/dynamic-variables.mdx#2025-04-14_snippet_2\n\nLANGUAGE: liquid\nCODE:\n```\n{{\"now\" | date: \"%b %d, %Y, %I:%M %p\", \"America/New_York\"}}\n```\n\n----------------------------------------\n\nTITLE: Complete TransferCall Implementation with TwiML\nDESCRIPTION: Full example of a transferCall payload implementing warm transfer with TwiML, including message configuration, destination settings, and transfer plan details.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"transferCall\",\n  \"messages\": [\n    {\n      \"type\": \"request-start\",\n      \"content\": \"I'll transfer you to someone who can help.\"\n    }\n  ],\n  \"destinations\": [\n    {\n      \"type\": \"number\",\n      \"number\": \"+14155551234\",\n      \"description\": \"Transfer to customer support\",\n      \"transferPlan\": {\n        \"mode\": \"warm-transfer-with-twiml\",\n        \"twiml\": \"<Say>Hello, this is an incoming call from a customer.</Say><Pause length=\\\"1\\\"/><Say>They have questions about their recent order.</Say><Pause length=\\\"1\\\"/><Say>Connecting you now.</Say>\",\n        \"sipVerb\": \"refer\"\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: SIP Destination Response Payload in JSON\nDESCRIPTION: Response payload for transferring a call to a SIP URI. Includes options for custom SIP headers and a message to inform the user about the transfer.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"destination\": {\n    \"type\": \"sip\",\n    \"message\": \"Connecting your call via SIP.\",\n    \"sipUri\": \"sip:customer-support@domain.com\",\n    \"sipHeaders\": {\n      \"X-Custom-Header\": \"value\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Task Breakdown for Technical Support Voice AI Agent\nDESCRIPTION: This snippet shows how to break down a complex task into step-by-step instructions for a technical support Voice AI Agent. It includes conditional logic to guide the agent's responses based on user input.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```md wordWrap\n[Task]\n1. Welcome the user to the technical support service.\n2. Inquire about the nature of the technical issue.\n3. If the issue is related to software, ask about the specific software and problem details.\n4. If the issue is hardware-related, gather information about the device and symptoms.\n5. Based on the collected information, provide troubleshooting steps or escalate to a human technician if necessary.\n```\n```\n\n----------------------------------------\n\nTITLE: Warm Transfer with Wait and Say Message Configuration\nDESCRIPTION: This snippet shows how to configure a warm transfer where Vapi waits for the recipient to speak first before delivering a custom message. This provides a more natural transfer experience for both parties.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n\"transferPlan\": {\n  \"mode\": \"warm-transfer-wait-for-operator-to-speak-first-and-then-say-message\",\n  \"message\": \"Hey, this call has been forwarded through Vapi.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Conditional Assistant Hooks with Filters in JSON\nDESCRIPTION: This JSON snippet shows how to set up conditional execution of Assistant hooks using filters. It demonstrates how to trigger different hooks based on specific call end reasons, such as system errors or customer actions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-02-17.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"assistant\": {\n    \"hooks\": [{\n        \"filters\": [{\n          \"type\": \"oneOf\",\n          \"key\": \"call.endedReason\",\n          \"oneOf\": [\"pipeline-error-custom-llm-500-server-error\", \"pipeline-error-custom-llm-llm-failed\"]\n        }]\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Knowledge Base with Trieve Provider\nDESCRIPTION: This snippet shows how to create a Knowledge Base using the Trieve provider. It includes configuration options for search plans and chunk plans, allowing customization of search behavior and content chunking.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/knowledgebase.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'http://localhost:3001/knowledge-base' \\\n--header 'Content-Type: text/plain' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--data '{\n    \"name\": \"v2\",\n    \"provider\": \"trieve\",\n    \"searchPlan\": {\n        \"searchType\": \"semantic\",\n        \"topK\": 3,\n        \"removeStopWords\": true,\n        \"scoreThreshold\": 0.7\n    },\n    \"createPlan\": {\n        \"type\": \"create\",\n        \"chunkPlans\": [\n            {\n                \"fileIds\": [\"<FILE_ID_1>\", \"<FILE_ID_2>\"],\n                \"websites\": [\"<WEBSITE_1>\", \"<WEBSITE_2>\"],\n                \"targetSplitsPerChunk\": 50,\n                \"splitDelimiters\": [\".!?\\n\"],\n                \"rebalanceChunks\": true\n            }\n        ]\n    }\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Secret Token Authentication in Vapi\nDESCRIPTION: Configuration example for implementing secret token authentication using the X-Vapi-Signature header.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/server-authentication.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"server\": {\n    \"url\": \"https://your-server.com/webhook\",\n    \"secret\": \"your-secret-token\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring DeepSeek Reasoner Model in Vapi AI Assistant\nDESCRIPTION: This snippet demonstrates how to select the new deepseek-reasoner model option for an assistant in Vapi AI. It uses a nested object structure to specify the model choice.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-22.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nAssistant.model[\"deep-seek\"].model[\"deepseek-reasoner\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring HPMA Assistant for Silent Transfers\nDESCRIPTION: JSON configuration for the Main Assistant (HPMA) in a silent transfer setup. It defines the assistant's properties including voice settings, model configuration, and first message settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads/silent-transfers.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"HPMA\",\n  \"voice\": {\n    \"voiceId\": \"248be419-c632-4f23-adf1-5324ed7dbf1d\",\n    \"provider\": \"cartesia\",\n    \"fillerInjectionEnabled\": false\n  },\n  \"createdAt\": \"2024-11-04T17:15:08.980Z\",\n  \"updatedAt\": \"2024-11-30T13:04:58.401Z\",\n  \"model\": {\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"[Identity]\\nYou are the Main Assistant...\"\n      }\n    ],\n    \"provider\": \"openai\",\n    \"maxTokens\": 50,\n    \"temperature\": 0.3\n  },\n  \"firstMessage\": \"\",\n  \"transcriber\": {\n    \"model\": \"nova-2\",\n    \"language\": \"en\",\n    \"provider\": \"deepgram\"\n  },\n  \"backchannelingEnabled\": false,\n  \"backgroundDenoisingEnabled\": false,\n  \"isServerUrlSecretSet\": false\n}\n```\n\n----------------------------------------\n\nTITLE: Error Handling in Voice AI Prompts\nDESCRIPTION: This snippet demonstrates how to include fallback options and error-handling mechanisms in Voice AI Agent prompts to ensure graceful handling of unexpected inputs or system errors.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n```md wordWrap\n[Error Handling]\nIf the customer's response is unclear, ask clarifying questions. If you encounter any issues, inform the customer politely and ask to repeat.\n```\n```\n\n----------------------------------------\n\nTITLE: Controlling Assistant Behavior During a Vapi Call\nDESCRIPTION: This command allows modification of the assistant's behavior during a call, with options to mute, unmute, or trigger the initial message.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-features.mdx#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST 'https://aws-us-west-2-production1-phone-call-websocket.vapi.ai/7420f27a-30fd-4f49-a995-5549ae7cc00d/control' \n-H 'content-type: application/json' \n--data-raw '{\n  \"type\": \"control\",\n  \"control\": \"mute-assistant\"  // Options: \"mute-assistant\", \"unmute-assistant\", \"say-first-message\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Starting Call with Simple Assistant ID\nDESCRIPTION: Shows how to initialize a call using a pre-existing assistant ID string.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.start(\"79f3XXXX-XXXX-XXXX-XXXX-XXXXXXXXce48\");\n```\n\n----------------------------------------\n\nTITLE: Initiating Vapi AI Call with Custom Transcriber\nDESCRIPTION: CURL command to initiate a call using Vapi AI with custom transcriber configuration. Includes setup for phone numbers and WebSocket connection.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/call \\\n     -H \"Authorization: Bearer YOUR_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n  \"phoneNumberId\": \"YOUR_PHONE_NUMBER_ID\",\n  \"customer\": {\n    \"number\": \"CUSTOMER_PHONE_NUMBER\"\n  },\n  \"assistant\": {\n    \"transcriber\": {\n      \"provider\": \"custom-transcriber\",\n      \"server\": {\n        \"url\": \"wss://your-server.ngrok.io/api/custom-transcriber\"\n      },\n      \"secret\": \"your_optional_secret_value\"\n    },\n    \"firstMessage\": \"Hello! I am using a custom transcriber with Deepgram.\"\n  },\n  \"name\": \"CustomTranscriberTest\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Customizing Summary Prompt with JSON Configuration\nDESCRIPTION: JSON configuration to customize the summary prompt that extracts call information. Setting to an empty string or \"off\" will disable the summary generation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"summaryPrompt\": \"Custom summary prompt text\"\n}\n```\n\n----------------------------------------\n\nTITLE: Basic Output Schema Definition in JSX\nDESCRIPTION: Demonstrates how to define an output schema for the API request that maps response fields to workflow variables with their respective types and descriptions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/workflows/nodes/api-request.mdx#2025-04-14_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\n{\n  ...\n  \"output\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"type\": \"string\",\n        \"description\": \"name of the user\",\n      },\n      \"age\": {\n        \"type\": \"number\",\n        \"description\": \"age of the user\",\n      },\n      \"isActive\": {\n        \"type\": \"boolean\",\n        \"description\": \"whether the user is active\",\n      }\n    }\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Send Text (SMS) Function for Vapi Assistant (JSON)\nDESCRIPTION: This snippet illustrates the configuration of the sms function for a Vapi voice assistant. It includes the model setup, system message, and the sms tool with metadata for the sender's phone number.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/default-tools.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant. When the user asks you to send a text message, use the sms function.\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"sms\",\n        \"metadata\": {\n          \"from\": \"+15551234567\" \n        }\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Making Outbound Calls via Vapi API with SIP Integration\nDESCRIPTION: This API call initiates an outbound call using the configured SIP phone number and Vapi assistant. It specifies the destination number and disables E164 format checking to support various phone number formats.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-twilio.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/call/phone' \\\n--header 'Authorization: Bearer YOUR_VAPI_API_KEY' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"assistantId\": \"YOUR_ASSISTANT_ID\",\n  \"customer\": {\n    \"number\": \"DESTINATION_PHONE_NUMBER\",\n    \"numberE164CheckEnabled\": false\n  },\n  \"phoneNumberId\": \"YOUR_PHONE_NUMBER_ID\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Controlling Response Timing in Voice AI Prompts\nDESCRIPTION: This snippet demonstrates how to control the timing of responses in a Voice AI Agent prompt by explicitly indicating when to wait for user input before proceeding to the next step.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/prompting-guide.mdx#2025-04-14_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n```md wordWrap\n[Task]\n1. Inform the user about the purpose of the call.\n2. Ask for the user's name and account information.\n<wait for user response>\n3. Inquire about the reason for the call and offer assistance options....\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Vapi Assistant with Slack Integration in JSON\nDESCRIPTION: This JSON configuration demonstrates how to set up a Vapi assistant with the Slack integration tool. It includes system messages for a customer service assistant and defines a Slack tool for sending urgent notifications to a support team channel.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/slack.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": {\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a customer service assistant. When a customer requests a callback or needs urgent attention, use the Slack tool to notify the support team in the #customer-support channel. Include the following information in your message:\\n\\n- Customer name\\n- Phone number\\n- Reason for callback/urgent attention\\n- Any specific time constraints\\n\\nAlways be professional and concise in your Slack messages.\"\n      }\n    ],\n    \"tools\": [\n      {\n        \"type\": \"slack.message.send\",\n        \"name\": \"notifySupport\",\n        \"description\": \"Use this tool to send urgent notifications to the support team in the #customer-support channel. Only use this when a customer needs immediate attention or requests a callback.\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Create Phone Call Request\nDESCRIPTION: Request payload for initiating an outbound phone call to a lead using the Create Phone Call endpoint.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"phoneNumberId\": \"c86b5177-5cd8-447f-9013-99e307a8a7bb\",\n  \"assistantId\": \"d87b5177-5cd8-447f-9013-99e307a8a7bb\",\n  \"customer\": {\n    \"number\": \"+11234567890\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring TwiML Transfer Plan in JSON\nDESCRIPTION: Basic configuration example showing how to set up a warm transfer with TwiML using the transferPlan object. Demonstrates the required mode setting and TwiML string format.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n\"transferPlan\": {\n  \"mode\": \"warm-transfer-with-twiml\",\n  \"twiml\": \"<Say>Hello, transferring a customer to you.</Say><Pause length=\\\"2\\\"/><Say>They called about billing questions.</Say>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Twilio Voicemail Detection\nDESCRIPTION: Configuration example for Twilio voicemail detection settings using the TwilioVoicemailDetectionPlan schema. Includes options for enabling detection, setting timeout, and specifying detection types.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-09.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n// Twilio configuration example\n{\n  \"provider\": \"twilio\",\n  \"enabled\": true,\n  \"machineDetectionTimeout\": 30,  // Range: 3-59 seconds\n  \"voicemailDetectionTypes\": [\"machine_end_beep\", \"machine_end_silence\"]\n}\n```\n\n----------------------------------------\n\nTITLE: Overriding Assistant Configuration\nDESCRIPTION: Shows how to override assistant settings and set template variables when starting a call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdk/web.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst assistantOverrides = {\n  transcriber: {\n    provider: \"deepgram\",\n    model: \"nova-2\",\n    language: \"en-US\",\n  },\n  recordingEnabled: false,\n  variableValues: {\n    name: \"Alice\",\n  },\n};\n\nvapi.start(\"79f3XXXX-XXXX-XXXX-XXXX-XXXXXXXXce48\", assistantOverrides);\n```\n\n----------------------------------------\n\nTITLE: Making Outbound Calls through Telnyx SIP with Vapi.ai\nDESCRIPTION: This API call initiates an outbound call using the Telnyx SIP trunk through Vapi.ai. It requires your Vapi private key, assistant ID, customer phone number, and phone ID to connect the AI assistant with the specified customer.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-telnyx.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/call/phone' \\\n  --header 'Authorization: Bearer YOUR_VAPI_PRIVATE_KEY' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"assistantId\": \"YOUR_ASSISTANT_ID\",\n    \"customer\": {\n      \"number\": \"CUSTOMER_PHONE_NUMBER\",\n      \"numberE164CheckEnabled\": false\n    },\n    \"phoneNumberId\": \"YOUR_PHONE_ID\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Adding a Phone Number to Vapi.ai for Telnyx Integration\nDESCRIPTION: This API call associates a phone number with your SIP trunk in Vapi.ai by sending a POST request with phone number details and the credential ID from the previous step. It requires your Vapi private key and the credential ID received after creating the SIP trunk.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-telnyx.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/phone-number \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_VAPI_PRIVATE_KEY\" \\\n  -d '{\n    \"provider\": \"byo-phone-number\",\n    \"name\": \"Telnyx SIP Number\",\n    \"number\": \"YOUR_PHONE_NUMBER\",\n    \"numberE164CheckEnabled\": false,\n    \"credentialId\": \"YOUR_CREDENTIAL_ID\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Setting up OAuth2 Authentication in Vapi\nDESCRIPTION: Configuration example for OAuth2 authentication including client credentials, token URL, and optional scope specification.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/server-authentication.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"server\": {\n    \"url\": \"https://your-server.com/webhook\"\n  },\n  \"credentials\": {\n    \"webhook\": {\n      \"type\": \"oauth2\",\n      \"clientId\": \"your-client-id\",\n      \"clientSecret\": \"your-client-secret\",\n      \"tokenUrl\": \"https://your-server.com/oauth/token\",\n      \"scope\": \"optional, only needed to specify which scopes to request access for\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring HP Payment Squad With SubAgent for Silent Transfers\nDESCRIPTION: JSON configuration for a squad with multiple assistants set up for silent transfers. It defines the squad members, their IDs, and transfer destinations.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads/silent-transfers.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"members\": [\n    {\n      \"assistantId\": \"2d8e0d13-1b3c-4358-aa72-cf6204d6244e\",\n      \"assistantDestinations\": [\n        {\n          \"message\": \" \",\n          \"description\": \"Transfer call to the payment agent\",\n          \"type\": \"assistant\",\n          \"assistantName\": \"HPPA\"\n        }\n      ]\n    },\n    {\n      \"assistantId\": \"ad1c5347-bc32-4b31-8bb7-6ff5fcb131f4\",\n      \"assistantDestinations\": [\n        {\n          \"message\": \" \",\n          \"description\": \"Transfer call to the main sub agent\",\n          \"type\": \"assistant\",\n          \"assistantName\": \"HPMA-SA\"\n        }\n      ]\n    },\n    {\n      \"assistantId\": \"f1c258bc-4c8b-4c51-9b44-883ab5e40b2f\",\n      \"assistantDestinations\": []\n    }\n  ],\n  \"name\": \"HP Payment Squad With SubAgent\"\n}\n```\n\n----------------------------------------\n\nTITLE: Associating Phone Number with SIP Trunk\nDESCRIPTION: API request to link an external phone number (DID) to the previously created SIP trunk credential in Vapi.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-trunk.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST \"https://api.vapi.ai/phone-number\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer YOUR_VAPI_PRIVATE_KEY\" \\\n  -d '{\n    \"provider\": \"byo-phone-number\",\n    \"name\": \"Zadarma Number\",\n    \"number\": \"15551234567\",\n    \"numberE164CheckEnabled\": false,\n    \"credentialId\": \"YOUR_CREDENTIAL_ID\"\n  }'\n```\n\n----------------------------------------\n\nTITLE: Using the Unified Server Configuration in Assistants\nDESCRIPTION: The server property replaces the old serverUrl and serverUrlSecret properties for configuring webhook settings in assistants, including URL, secret, custom headers, and timeout.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-13.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nAssistant.server\n```\n\nLANGUAGE: javascript\nCODE:\n```\nAssistantOverrides.server\n```\n\n----------------------------------------\n\nTITLE: Event Handling in Vapi SDKs\nDESCRIPTION: Lists the core events available across all Vapi SDKs for handling speech recognition, volume levels, and message processing. These events enable client-side animations and real-time transcription display.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/sdks.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- `speech-start`, `speech-end`, and `volume-level` for creating animations.\n- `message` for receiving messages sent to the Server URL locally on the client, so you can show live transcriptions and use function calls to perform actions on the client.\n```\n\n----------------------------------------\n\nTITLE: Express Server Setup with Twilio and Vapi Configuration\nDESCRIPTION: Initial Express.js server setup with required dependencies and environment variable configuration for Twilio and Vapi integration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nconst express = require(\"express\");\nconst bodyParser = require(\"body-parser\");\nconst axios = require(\"axios\");\nconst twilio = require(\"twilio\");\n\nconst app = express();\napp.use(bodyParser.urlencoded({ extended: true }));\napp.use(bodyParser.json());\n\n// Load important env vars\nconst {\n  TWILIO_ACCOUNT_SID,\n  TWILIO_AUTH_TOKEN,\n  FROM_NUMBER,\n  TO_NUMBER,\n  VAPI_BASE_URL,\n  PHONE_NUMBER_ID,\n  ASSISTANT_ID,\n  PRIVATE_API_KEY,\n} = process.env;\n\n// Create a Twilio client\nconst client = twilio(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN);\n\n// We'll store the inbound call SID here for simplicity\nlet globalCallSid = \"\";\n```\n\n----------------------------------------\n\nTITLE: Defining First Message for Vapi AI Assistant\nDESCRIPTION: This snippet shows the first message to be spoken by the AI assistant when a call connects. It introduces the assistant and explains the purpose of the call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/outbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nHi this is Jennifer from Vappy's Pizzeria giving you a call back since we got disconnected. Would you like to finish your order with us?\n```\n\n----------------------------------------\n\nTITLE: Customizing Structured Data Schema with JSON Configuration\nDESCRIPTION: JSON configuration to define a custom schema for structured data extraction. This defines the format and required fields for the extracted data.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"structuredDataSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"field1\": { \"type\": \"string\" },\n      \"field2\": { \"type\": \"number\" }\n    },\n    \"required\": [\"field1\", \"field2\"]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Using the transferCall Function\nDESCRIPTION: This snippet shows how the assistant makes a call to the transferCall function with a specific destination phone number. This is the actual implementation of forwarding a call to a particular destination.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"function\": {\n    \"name\": \"transferCall\",\n    \"parameters\": {\n      \"destination\": \"+1234567890\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Variable Renaming in Output Schema JSX\nDESCRIPTION: Shows how to use the target option in the output schema to rename variables for use in the workflow, specifically renaming 'name' to 'user_name'.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/workflows/nodes/api-request.mdx#2025-04-14_snippet_2\n\nLANGUAGE: jsx\nCODE:\n```\n{\n  ...\n  \"output\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"type\": \"string\",\n        \"description\": \"name of the user\",\n        \"target\": \"user_name\" // renamed \"name\" to \"user_name\"\n      },\n      ...\n    }\n  },\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom Assistant for SIP Calls\nDESCRIPTION: JSON configuration for updating a phone number to use a custom assistant URL using the PATCH /phone-number/:id endpoint\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"assistantId\": null,\n\t\"serverUrl\": \"https://your_server_url\"\n}\n```\n\n----------------------------------------\n\nTITLE: Customizing Messages for Call Forwarding\nDESCRIPTION: This snippet demonstrates how to customize the message that is played to the caller when forwarding to a specific destination. The conditions array specifies when this message should be used based on the destination parameter.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"messages\": [\n    {\n      \"type\": \"request-start\",\n      \"content\": \"I am forwarding your call to Department A. Please stay on the line.\",\n      \"conditions\": [\n        {\n          \"param\": \"destination\",\n          \"operator\": \"eq\",\n          \"value\": \"+1234567890\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Phone Number for Inbound Calls with Vapi\nDESCRIPTION: This JSON response shows the result of creating a phone number for inbound calls using the Vapi Phone Numbers API. It includes details such as the number ID, organization ID, provider, and timestamps.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/inbound-support.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"c86b5177-5cd8-447f-9013-99e307a8a7bb\",\n  \"orgId\": \"aa4c36ba-db21-4ce0-9c6e-99e307a8a7bb\",\n  \"provider\": \"vapi\",\n  \"number\": \"+11234567890\",\n  \"createdAt\": \"2023-09-29T21:44:37.946Z\",\n  \"updatedAt\": \"2023-12-08T00:57:24.706Z\",\n}\n```\n\n----------------------------------------\n\nTITLE: Making an Authenticated API Request in JavaScript\nDESCRIPTION: This example demonstrates how to use a generated JWT token to make an authenticated API request to the Vapi API. It includes setting up the request headers with the token and making a GET request to retrieve assistants.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/jwt-authentication.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nasync function getAssistants() {\n  const response = await fetch(\"https://api.vapi.ai/assistant\", {\n    method: \"GET\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      Authorization: `Bearer ${token}`,\n    },\n  });\n\n  const data = await response.json();\n  console.log(data);\n}\n\nfetchData().catch(console.error);\n```\n\n----------------------------------------\n\nTITLE: Combining Twilio and Vapi Voicemail Detection Methods\nDESCRIPTION: Configuration that combines both Twilio's detection system and Vapi's LLM-powered tool for improved accuracy. This approach provides redundancy to catch voicemails that one method might miss.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/voicemail-detection.mdx#2025-04-14_snippet_2\n\nLANGUAGE: jsx\nCODE:\n```\n{\n  ...yourExistingSettings,\n  voicemailDetection: {\n    provider: \"twilio\",\n    voicemailDetectionTypes: [\n      \"machine_start\",\n      \"machine_end_beep\",\n      \"unknown\"\n    ],\n    enabled: true,\n    machineDetectionTimeout: 15\n  },\n  model: {\n    tools: [{ type: \"voicemail\" }]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring gemini-2.0-flash-lite Model\nDESCRIPTION: Configuration path for using the new gemini-2.0-flash-lite model in Assistant settings. This model offers reduced latency and lower cost with a 1 million token context window.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-15.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\nAssistant.model[provider=\"google\"].model[model=\"gemini-2.0-flash-lite\"]\n```\n\n----------------------------------------\n\nTITLE: Using Vapi Web Client with Public JWT Token in JavaScript\nDESCRIPTION: This snippet shows how to initialize and use the Vapi Web Client with a public JWT token. It demonstrates importing the Vapi module, creating a new instance with the token, and starting an assistant.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/jwt-authentication.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport Vapi from '@vapi-ai/web';\n\nconst vapi = new Vapi({\n  token: 'your-jwt-token',\n});\n\nvapi.start('your-assistant-id');\n```\n\n----------------------------------------\n\nTITLE: Creating SIP Phone Number Configuration\nDESCRIPTION: JSON configuration for setting up a SIP phone number using the POST /phone-number endpoint with a unique SIP URI\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"provider\": \"vapi\",\n\t\"sipUri\": \"sip:your_unique_user_name@sip.vapi.ai\",\n\t\"assistantId\": \"your_assistant_id\"\n}\n```\n\n----------------------------------------\n\nTITLE: Structuring Server Event Message in JSON\nDESCRIPTION: Demonstrates the general structure of a message sent to the Server URL. It includes the message type, call object, and other relevant properties.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"function-call\",\n    \"call\": { Call Object },\n    ...other message properties\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Warm Transfer with Message Configuration\nDESCRIPTION: This snippet demonstrates how to configure a warm transfer with a custom message. Instead of generating a summary, a predefined message will be relayed to the recipient before the call is transferred.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n\"transferPlan\": {\n  \"mode\": \"warm-transfer-with-message\",\n  \"message\": \"Hey, this call has been forwarded through Vapi.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating OpenRouter Assistant\nDESCRIPTION: Configuration for creating an assistant using OpenRouter with the Dolphin Mixtral model.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/fine-tuned-openai-models.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"My Assistant\",\n  \"model\": {\n    \"provider\": \"openrouter\",\n    \"model\": \"cognitivecomputations/dolphin-mixtral-8x7b\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are an assistant.\"\n      }\n    ],\n    \"temperature\": 0.7\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Setting System Prompt for Pizza Order Assistant\nDESCRIPTION: Comprehensive system prompt that defines the assistant's role, menu options, ordering rules, and conversation style for a pizza ordering system. Includes specific instructions about menu limitations and conversation handling.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/quickstart/dashboard/assistant-setup-inbound.mdx#2025-04-14_snippet_1\n\nLANGUAGE: text\nCODE:\n```\nYou are a voice assistant for Vappy's Pizzeria,\na pizza shop located on the Internet.\n\nYour job is to take the order of customers calling in. The menu has only 3 types\nof items: pizza, sides, and drinks. There are no other types of items on the menu.\n\n1) There are 3 kinds of pizza: cheese pizza, pepperoni pizza, and vegetarian pizza\n(often called \"veggie\" pizza).\n2) There are 3 kinds of sides: french fries, garlic bread, and chicken wings.\n3) There are 2 kinds of drinks: soda, and water. (if a customer asks for a\nbrand name like \"coca cola\", just let them know that we only offer \"soda\")\n\nCustomers can only order 1 of each item. If a customer tries to order more\nthan 1 item within each category, politely inform them that only 1 item per\ncategory may be ordered.\n\nCustomers must order 1 item from at least 1 category to have a complete order.\nThey can order just a pizza, or just a side, or just a drink.\n\nBe sure to introduce the menu items, don't assume that the caller knows what\nis on the menu (most appropriate at the start of the conversation).\n\nIf the customer goes off-topic or off-track and talks about anything but the\nprocess of ordering, politely steer the conversation back to collecting their order.\n\nOnce you have all the information you need pertaining to their order, you can\nend the conversation. You can say something like \"Awesome, we'll have that ready\nfor you in 10-20 minutes.\" to naturally let the customer know the order has been\nfully communicated.\n\nIt is important that you collect the order in an efficient manner (succinct replies\n& direct questions). You only have 1 task here, and it is to collect the customers\norder, then end the conversation.\n\n- Be sure to be kind of funny and witty!\n- Keep all your responses short and simple. Use casual language, phrases like \"Umm...\", \"Well...\", and \"I mean\" are preferred.\n- This is a voice conversation, so keep your responses short, like in a real conversation. Don't ramble for too long.\n```\n\n----------------------------------------\n\nTITLE: Google Gemini Models for Knowledge Base Integration\nDESCRIPTION: Available Google Gemini model options for knowledge base integration within the KnowledgeBase schema. These models can be used in assistant configurations for query tools.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-09.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"model\": {\n  \"enum\": [\n    \"gemini-2.0-flash-thinking-exp\",\n    \"gemini-2.0-pro-exp-02-05\",\n    \"gemini-2.0-flash\",\n    \"gemini-2.0-flash-lite-preview-02-05\",\n    \"gemini-2.0-flash-exp\",\n    \"gemini-2.0-flash-realtime-exp\",\n    \"gemini-1.5-flash\",\n    \"gemini-1.5-flash-002\",\n    \"gemini-1.5-pro\",\n    \"gemini-1.5-pro-002\",\n    \"gemini-1.0-pro\"\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Call Status Events in JavaScript\nDESCRIPTION: This snippet sets up event listeners for call start and end events, allowing the UI to be updated accordingly.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/pizza-website.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.on('call-start', () => {\n  // Update UI to show that the call has started\n});\n\nvapi.on('call-end', () => {\n  // Update UI to show that the call has ended\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Multilingual Tool Messages\nDESCRIPTION: Demonstrates how to use the contents property for providing multilingual variants in tool messages.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-25.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  ToolMessageStart: { contents: [] },\n  ToolMessageFailed: { contents: [] },\n  ToolMessageDelayed: { contents: [] },\n  ToolMessageComplete: { contents: [] }\n}\n```\n\n----------------------------------------\n\nTITLE: Warm Transfer with Wait and Say Summary Configuration\nDESCRIPTION: This snippet demonstrates how to configure a warm transfer where Vapi waits for the recipient to speak first before delivering a summary of the call. This mode combines waiting for acknowledgment with providing detailed context.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n\"transferPlan\": {\n  \"mode\": \"warm-transfer-wait-for-operator-to-speak-first-and-then-say-summary\",\n  \"summaryPlan\": {\n    \"enabled\": true,\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"Please provide a summary of the call.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Here is the transcript:\\n\\n{{transcript}}\\n\\n\"\n      }\n    ]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Number Destination Response Payload in JSON\nDESCRIPTION: Response payload for transferring a call to a phone number. Includes options for caller ID and extensions, with a message to inform the user about the transfer.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"destination\": {\n    \"type\": \"number\",\n    \"message\": \"Connecting you to our support line.\",\n    \"number\": \"+14155552671\",\n    \"numberE164CheckEnabled\": true,\n    \"callerId\": \"+14155551234\",\n    \"extension\": \"101\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Voice IDs with gpt-4o-realtime-preview model\nDESCRIPTION: This snippet shows how to specify voice IDs when configuring OpenAIVoice for the gpt-4o-realtime-preview-2024-10-01 model. The new voice options include 'ash', 'ballad', 'coral', 'sage', and 'verse', which are exclusively available with this model.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-15.mdx#2025-04-14_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nvoiceId: \"ash\" // Other options: \"ballad\", \"coral\", \"sage\", \"verse\"\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Function for Vapi Assistant (JSON)\nDESCRIPTION: This example shows how to define a custom function (bookAppointment) for a Vapi assistant. It includes the function name, description, and parameters. Note that custom functions are being deprecated in favor of Tools.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/tools/default-tools.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"functions\": [\n    {\n      \"name\": \"bookAppointment\",\n      \"description\": \"Used to book the appointment.\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"datetime\": {\n            \"type\": \"string\",\n            \"description\": \"The date and time of the appointment in ISO format.\"\n          }\n        }\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Language for PlayHTVoice\nDESCRIPTION: Shows how to specify the desired language for speech synthesis when using PlayHTVoice. This property allows customization of the language used for voice output.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-24.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"assistant.voice.language\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Outbound Call Squad JSON\nDESCRIPTION: JSON configuration for initiating outbound calls with Squad members. Includes customer phone number and provider details along with the same Squad configuration as inbound calls. Requires phoneNumberId from the provider.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads-example.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"squad\": {\n        \"members\": [\n            {\n                \"assistant\": { \n                    \"name\": \"Emma\", \n                    \"model\": { \"model\": \"gpt-4o\", \"provider\": \"openai\" },\n                    \"voice\": { \"voiceId\": \"emma\", \"provider\": \"azure\" },\n                    \"transcriber\": { \"provider\": \"deepgram\" },\n                    \"firstMessage\": \"Hi, I am Emma, what is your name?\",\n                    \"firstMessageMode\": \"assistant-speaks-first\"\n                },\n                \"assistantDestinations\": [ \n                    {\n                        \"type\": \"assistant\",\n                        \"assistantName\": \"Mary\", \n                        \"message\": \"Please hold on while I transfer you to our appointment booking assistant Mary.\",\n                        \"description\": \"Transfer the user to the appointment booking assistant.\"\n                    }\n                ]\n            },\n            {\n                \"assistantId\": \"your-assistant-id\" \n            }\n        ]\n    },\n    \"customer\": {\n        \"number\": \"your-phone-number\" \n    },\n    \"phoneNumberId\": \"your-phone-number-id\" \n}\n```\n\n----------------------------------------\n\nTITLE: Sending Hang Notification in JSON\nDESCRIPTION: Shows the structure of a hang notification message sent when the assistant fails to respond for 5+ seconds.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_11\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"message\": {\n    \"type\": \"hang\",\n    \"call\": { Call Object },\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Vapi's LLM-Based Voicemail Detection Tool\nDESCRIPTION: Configuration snippet that enables Vapi's built-in LLM-powered voicemail detection tool. This approach recognizes voicemail by analyzing transcribed audio for typical voicemail greetings and patterns.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/voicemail-detection.mdx#2025-04-14_snippet_1\n\nLANGUAGE: jsx\nCODE:\n```\n{\n  ...yourExistingSettings,\n  \"model\": {\n    \"tools\": [{ type: \"voicemail\" }]\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Creating OAuth2 Webhook Credentials in Vapi.ai\nDESCRIPTION: Example showing how to create webhook credentials using OAuth2 authentication. The payload includes OAuth2 configuration parameters like token URL, client ID, and client secret.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-12-05.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"provider\": \"webhook\",\n    \"authenticationPlan\": {\n        \"type\": \"oauth2\",\n        \"url\": \"https://your-url.com/your/path/token\",\n        \"clientId\": \"your-client-id\",\n        \"clientSecret\": \"your-client-secret\"\n    },\n    \"name\": \"your-credential-name-between-1-and-40-characters\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Custom Transcriber Implementation\nDESCRIPTION: Bash commands to create a new Node.js project and install required dependencies including WebSocket, Express, dotenv for environment variables, and the Deepgram SDK.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir vapi-custom-transcriber\ncd vapi-custom-transcriber\nnpm init -y\nnpm install ws express dotenv @deepgram/sdk\n```\n\n----------------------------------------\n\nTITLE: Configuring Voice Fallback Plan in Vapi AI\nDESCRIPTION: Demonstrates how to enhance an assistant's reliability by defining fallback voice providers. If the primary voice provider fails, the assistant can switch to alternative voices specified in the fallback plan.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-24.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"assistant.voice.fallbackPlan.voices\"\n```\n\n----------------------------------------\n\nTITLE: Inbound Call Handler for Vapi Integration\nDESCRIPTION: Endpoint that handles incoming calls by storing the call SID and initiating Vapi.ai interaction for AI-driven conversation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\napp.post(\"/inbound_call\", async (req, res) => {\n  try {\n    globalCallSid = req.body.CallSid;\n    const caller = req.body.Caller;\n\n    // Example: We call Vapi.ai to get initial TwiML\n    const response = await axios.post(\n      `${VAPI_BASE_URL || \"https://api.vapi.ai\"}/call`,\n      {\n        phoneNumberId: PHONE_NUMBER_ID,\n        phoneCallProviderBypassEnabled: true,\n        customer: { number: caller },\n        assistantId: ASSISTANT_ID,\n      },\n      {\n        headers: {\n          Authorization: `Bearer ${PRIVATE_API_KEY}`,\n          \"Content-Type\": \"application/json\",\n        },\n      }\n    );\n\n    const returnedTwiml = response.data.phoneCallProviderDetails.twiml;\n    return res.type(\"text/xml\").send(returnedTwiml);\n  } catch (err) {\n    return res.status(500).send(\"Internal Server Error\");\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Defining HPPA (Payment Assistant) Prompt for Silent Transfers\nDESCRIPTION: Plain text prompt for the Payment Assistant (HPPA) in a silent transfer setup. It outlines the assistant's identity, context, style, response guidelines, and specific tasks for handling payment information securely.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads/silent-transfers.mdx#2025-04-14_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n[Identity]\nYou are the Payment Assistant, operating in secure mode to collect payment information from customers safely and confidentially.\n\n[Context]\nYou're engaged with the customer to collect payment details. Stay focused\non this context and provide relevant information.\nDo not invent information not drawn from the context.\nAnswer only questions related to the context.\nOnce connected to a customer, proceed to the Task section without\nany greetings or small talk.\n\n[Style]\n- Be professional and reassuring.\n- Maintain confidentiality at all times.\n- Speak clearly and calmly.\n\n[Response Guidelines]\n- Collect the customer's credit card number, expiration date, and CVV.\n- Confirm each piece of information after it is provided.\n- Ensure the customer feels secure during the transaction.\n- Do not record or log any information.\n- Never say the word 'function' nor 'tools' nor the name of the\n  Available functions.\n- Never say ending the call.\n- Never say transferring.\n\n[Task]\n1. Ask for the credit card number.\n   - Wait for the customer's response.\n2. Ask for the expiration date of the card.\n   - Wait for the customer's response.\n3. Ask for the CVV number.\n   - Wait for the customer's response.\n4. Confirm that the payment has been processed successfully.\n   - trigger the transferCall tool with Payment `HPMA-SA` Assistant.\n```\n\n----------------------------------------\n\nTITLE: Default Success Evaluation Prompt for Call Analysis\nDESCRIPTION: The default prompt used to evaluate if a call was successful based on the system prompt objectives. This evaluation is stored in call.analysis.successEvaluation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_6\n\nLANGUAGE: text\nCODE:\n```\nYou are an expert call evaluator. You will be given a transcript of a call and the system prompt of the AI participant. Determine if the call was successful based on the objectives inferred from the system prompt.\n```\n\n----------------------------------------\n\nTITLE: Fine-Tuning Twilio Voicemail Detection Parameters\nDESCRIPTION: Example of adjusting Twilio's voicemail detection threshold parameters to optimize detection performance. This configuration uses shorter timeouts and custom speech/silence thresholds.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/voicemail-detection.mdx#2025-04-14_snippet_3\n\nLANGUAGE: jsx\nCODE:\n```\n{\n  \"provider\": \"twilio\",\n  \"enabled\": true,\n  \"machineDetectionTimeout\": 5,\n  \"machineDetectionSpeechThreshold\": 2400,\n  \"machineDetectionSpeechEndThreshold\": 1000,\n  \"machineDetectionSilenceTimeout\": 3000\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Provider Credentials\nDESCRIPTION: Example of setting up API credentials for an OpenRouter provider using the /credential endpoint.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/fine-tuned-openai-models.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"provider\": \"openrouter\",\n  \"apiKey\": \"<YOUR OPENROUTER KEY>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Initializing WebSocket Connection from Vapi to Custom Transcriber\nDESCRIPTION: JSON payload sent by Vapi to initialize a WebSocket connection with your custom transcriber endpoint. It specifies the audio encoding, container format, sample rate, and number of channels.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"start\",\n  \"encoding\": \"linear16\",\n  \"container\": \"raw\",\n  \"sampleRate\": 16000,\n  \"channels\": 2\n}\n```\n\n----------------------------------------\n\nTITLE: Creating SIP Trunk Credential in Vapi\nDESCRIPTION: API call to create a SIP trunk credential in Vapi using the Plivo Termination SIP Domain. Requires Vapi API key for authentication.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-plivo.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/credential \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer your-vapi-private-api-key\" \\\n-d '{\n  \"provider\": \"byo-sip-trunk\",\n  \"name\": \"PLIVO Trunk\",\n  \"gateways\": [\n    {\n      \"ip\": \"1270066835XXXXXXXXX.zt.plivo.com\"\n    }\n  ]\n}'\n```\n\n----------------------------------------\n\nTITLE: Outbound Call Test Configuration\nDESCRIPTION: JSON payload for testing outbound calls through the configured SIP trunk using Vapi's API.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-trunk.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"assistantId\": \"YOUR_ASSISTANT_ID\",\n  \"customer\": {\n    \"number\": \"15557654321\",\n    \"numberE164CheckEnabled\": false\n  },\n  \"phoneNumberId\": \"YOUR_PHONE_NUMBER_ID\"\n}\n```\n\n----------------------------------------\n\nTITLE: Participant Status Handler\nDESCRIPTION: Endpoint that handles status callbacks for specialist calls, managing scenarios where the specialist is unavailable.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\napp.post(\"/participant-status\", async (req, res) => {\n  const callStatus = req.body.CallStatus;\n  if ([\"no-answer\", \"busy\", \"failed\"].includes(callStatus)) {\n    console.log(\"Specialist did not pick up:\", callStatus);\n    // Additional logic: schedule an appointment, ephemeral call, etc.\n  }\n  return res.sendStatus(200);\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a SIP Trunk Credential with Vapi API\nDESCRIPTION: This API call creates a SIP trunk credential in Vapi, linking to your Twilio Termination SIP URI. The credential includes necessary gateway information and enables outbound leading plus for phone numbers.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-twilio.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/credential \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer YOUR_VAPI_API_KEY\" \\\n-d '{\n  \"provider\": \"byo-sip-trunk\",\n  \"name\": \"Twilio Trunk\",\n  \"gateways\": [\n    {\n      \"ip\": \"YOUR_TWILIO_GATEWAY_ID\"\n    }\n  ],\n  \"outboundLeadingPlusEnabled\": true\n}'\n```\n\n----------------------------------------\n\nTITLE: Setting Custom LLM Credentials\nDESCRIPTION: Example of setting up API credentials for a custom LLM server using the /credential endpoint.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/fine-tuned-openai-models.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"provider\": \"custom-llm\",\n  \"apiKey\": \"<YOUR SERVER API KEY>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Response Format from Custom Transcriber to Vapi\nDESCRIPTION: JSON payload structure that your custom transcriber sends back to Vapi with the transcription result. It includes the transcribed text and the channel identification (customer or assistant).\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"transcriber-response\",\n  \"transcription\": \"The transcribed text\",\n  \"channel\": \"customer\" // or \"assistant\"\n}\n```\n\n----------------------------------------\n\nTITLE: Using Alternative Voice Providers in Fallback Plan\nDESCRIPTION: Shows various alternative voice providers that can be configured as fallbacks when the primary voice provider fails. These include LMNT, Azure, Neets, Tavus, and OpenAI voice options.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-24.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"FallbackLMNTVoice\", \"FallbackAzureVoice\", \"FallbackNeetsVoice\", \"FallbackTavusVoice\", \"FallbackOpenAIVoice\"\n```\n\n----------------------------------------\n\nTITLE: Starting a Vapi AI Web Call with Persistent Assistant\nDESCRIPTION: This snippet demonstrates how to start a Vapi AI web call using a persistent assistant's ID. The ID is obtained from the Vapi Dashboard and passed to the 'start' method.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/web.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.start(\"79f3XXXX-XXXX-XXXX-XXXX-XXXXXXXXce48\");\n```\n\n----------------------------------------\n\nTITLE: Defining HPMA-SA (Main Sub Assistant) Prompt for Silent Transfers\nDESCRIPTION: Plain text prompt for the Main Sub Assistant (HPMA-SA) in a silent transfer setup. It outlines the assistant's identity, context, style, response guidelines, and specific tasks for finalizing the order and shipping details.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads/silent-transfers.mdx#2025-04-14_snippet_4\n\nLANGUAGE: plaintext\nCODE:\n```\n[Identity]\nYou are the Main Assistant, a friendly and helpful agent assisting customers\nin purchasing widgets over the phone.\n\n[Context]\nYou're engaged with the customer to book an appointment.\nStay focused on this context and provide relevant information.\nDo not invent information not drawn from the context.\nAnswer only questions related to the context.\nOnce connected to a customer, proceed to the Task section without any greetings\nor small talk.\n\n[Style]\n- Be professional and reassuring.\n- Maintain confidentiality at all times.\n- Speak clearly and calmly.\n\n[Response Guidelines]\n- Collect the customer's credit card number, expiration date, and CVV.\n- Confirm each piece of information after it is provided.\n- Ensure the customer feels secure during the transaction.\n- Do not record or log any information.\n- Never say the word 'function' nor 'tools' nor the name of the\n  Available functions.\n- Never say ending the call.\n- Never say transferring.\n\n[Task]\n1.Ask for the customer's shipping address to deliver the widgets.\n   - Wait for the customer's response.\n2.Confirm the shipping address and provide an estimated delivery date.\n3.Ask if the customer has any additional questions or needs further assistance.\n    - Wait for the customer's response.\n4.Provide any additional information or assistance as needed.\n5.Thank the customer for their purchase and end the call politely.\n```\n\n----------------------------------------\n\nTITLE: Defining HPMA (Main Assistant) Prompt for Silent Transfers\nDESCRIPTION: Plain text prompt for the Main Assistant (HPMA) in a silent transfer setup. It outlines the assistant's identity, context, style, response guidelines, and specific tasks to perform during the call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/squads/silent-transfers.mdx#2025-04-14_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n[Identity]\nYou are the Main Assistant, a friendly and helpful agent assisting customers\nin purchasing widgets over the phone.\n\n[Context]\nYou're engaged with the customer to book an appointment.\nStay focused on this context and provide relevant information.\nOnce connected to a customer, proceed to the Task section.\nDo not invent information not drawn from the context.\nAnswer only questions related to the context.\n\n[Style]\n- Be polite and professional.\n- Use a conversational and engaging tone.\n- Keep responses concise and clear.\n\n[Response Guidelines]\n- Ask one question at a time and wait for the customer's response before\n  proceeding.\n- Confirm the customer's responses when appropriate.\n- Use simple language that is easy to understand.\n- Never say the word 'function' nor 'tools' nor the name of the\n  Available functions.\n- Never say ending the call.\n- Never say transferring.\n\n[Task]\n1.Greet the customer and ask if they are interested in purchasing widgets.\n   - Wait for the customer's response.\n2. If the customer is interested, ask for their name.\n   - Wait for the customer's response.\n3.Ask how many widgets the customer would like to purchase.\n   - Wait for the customer's response.\n4.Confirm the order details with the customer.\n   - trigger the transferCall tool with Payment `HPPA` Assistant.\n```\n\n----------------------------------------\n\nTITLE: Uploading Files to Vapi Knowledge Base via API\nDESCRIPTION: This snippet demonstrates how to upload files to Vapi's Knowledge Base using a cURL command. It requires the user's API key and the path to the file being uploaded.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/knowledgebase.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/file' \\\n--header 'Authorization: Bearer <YOUR_API_KEY>' \\\n--form 'file=@\"<PATH_TO_YOUR_FILE>\"'\n```\n\n----------------------------------------\n\nTITLE: Creating Secure SIP Phone Number with Authentication - Bash\nDESCRIPTION: Example of creating a secure SIP phone number with digest authentication using username, password and realm. The request is made to Vapi's API endpoint to create a new phone number with authentication credentials.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-07.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/phone-number' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer {}API_KEY}}' \\\n--data-raw '{\n  \"provider\": \"vapi\",\n  \"sipUri\": \"sip:{{USERNAME}}@sip.vapi.ai\",\n  \"assistantId\": \"{{ASSISTANT_ID}}\",\n  \"name\": \"example phone number label for your reference\",\n  \"authentication\": {\n    \"realm\": \"sip.vapi.ai\",\n    \"username\": \"test@example.com\",\n    \"password\": \"example_password\"\n  }\n}'\n```\n\n----------------------------------------\n\nTITLE: End-of-Call Report JSON Structure for Vapi AI Assistant\nDESCRIPTION: This JSON structure represents the end-of-call report sent by Vapi AI. It includes details about the call, such as the reason it ended, a summary of the conversation, and the full transcript with messages exchanged between the assistant and the user.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/inbound-support.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": {\n        \"type\": \"end-of-call-report\",\n        \"endedReason\": \"hangup\",\n        \"call\": { \"Call Object\" },\n        \"recordingUrl\": \"https://vapi-public.s3.amazonaws.com/recordings/1234.wav\",\n        \"summary\": \"The user mentioned they were having an issue with their iPhone restarting randomly. They restarted their phone, but the issue persisted. They mentioned they were using an iPhone 12 Pro Max. They mentioned they were using iOS 15.\",\n        \"transcript\": \"Hey, I'm an A.I. assistant for Apple...\",\n        \"messages\":[\n        {\n            \"role\": \"assistant\",\n            \"message\": \"Hey, I'm an A.I. assistant for Apple. I can help you troubleshoot your Apple device. What's the issue?\",\n        },\n        {\n            \"role\": \"user\",\n            \"message\": \"Yeah I'm having an issue with my iPhone restarting randomly.\",\n        },\n        ...\n        ]\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Specialist Connection Handler with Conference Setup\nDESCRIPTION: Endpoint that manages putting users on hold and initiating calls to specialists using Twilio's conference feature.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\napp.post(\"/connect\", async (req, res) => {\n  try {\n    const protocol =\n      req.headers[\"x-forwarded-proto\"] === \"https\" ? \"https\" : \"http\";\n    const baseUrl = `${protocol}://${req.get(\"host\")}`;    const conferenceUrl = `${baseUrl}/conference`;\n\n    // 1) Update inbound call to fetch TwiML from /conference\n    await client.calls(globalCallSid).update({\n      url: conferenceUrl,\n      method: \"POST\",\n    });\n\n    // 2) Dial the specialist\n    const statusCallbackUrl = `${baseUrl}/participant-status`;\n\n    await client.calls.create({\n      to: TO_NUMBER,\n      from: FROM_NUMBER,\n      url: conferenceUrl,\n      method: \"POST\",\n      statusCallback: statusCallbackUrl,\n      statusCallbackMethod: \"POST\",\n    });\n\n    return res.json({ status: \"Specialist call initiated\" });\n  } catch (err) {\n    return res.status(500).json({ error: \"Failed to connect specialist\" });\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Starting a Vapi AI Web Call with Temporary Assistant\nDESCRIPTION: This code snippet shows how to initiate a Vapi AI web call using a temporary assistant configuration. The 'start' method is called with the previously defined assistant options.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/web.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nvapi.start(assistantOptions);\n```\n\n----------------------------------------\n\nTITLE: Disabling Voice Formatting in Assistant Settings\nDESCRIPTION: Code snippet showing how to turn off the Voice Input Formatted function by setting the appropriate flags in the assistant's voice provider settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/voice-formatting-plan.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nvoice.chunkPlan.enabled = false;\n// or\nvoice.chunkPlan.formatPlan.enabled = false;\n```\n\n----------------------------------------\n\nTITLE: Configuring Billing Support Test Script in Markdown\nDESCRIPTION: This snippet demonstrates how to write a test script for simulating a customer calling about a billing discrepancy. It includes steps for expressing anger, seeking explanation, and ending the call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Script\" wordWrap\n1. Express anger over an unexpected charge and the current bill appearing unusually high.\n2. Try to get a detailed explanation, confirming whether an overcharge occurred, and understanding the steps for resolution.\n3. End the call.\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI GPT-4.5 Preview Model\nDESCRIPTION: JSON configuration for using the GPT-4.5 preview model from OpenAI as either a primary model or fallback option in the assistant configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-02.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"model\": \"gpt-4.5-preview\",\n  \"provider\": \"openai\"\n}\n```\n\n----------------------------------------\n\nTITLE: Prompt to Trigger Transfer Tool\nDESCRIPTION: A simple prompt that can be used to trigger the dynamicDestinationTransferCall tool during a conversation with the assistant.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n[TASK]\ntrigger the dynamicDestinationTransferCall tool\n```\n\n----------------------------------------\n\nTITLE: Example Input for Voice Formatting\nDESCRIPTION: A sample text input demonstrating various elements that the Voice Input Formatted function processes, including HTML tags, markdown symbols, dates, times, and special formats.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/voice-formatting-plan.mdx#2025-04-14_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nHello <tag> world\n**Wanted** to say *hi*\nWe have NASA and .NET here,\ncall me at 123-456-7890,\nprice: $42.50\nand the date is 2023 05 10\nand time is 14:00\nDistance is 5km\nWe might see 9999\nthe address is 320 ST 21 RD\nmy email is JOHN.DOE@example.COM\n\n```\n\n----------------------------------------\n\nTITLE: Configuring LiveKit Wait Function for Smart Endpointing\nDESCRIPTION: Mathematical function for determining wait time based on the probability of user speaking completion. Maps probability values (0-1) to milliseconds, with 0 indicating user has stopped speaking and 1 indicating active speech.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/speech-configuration.mdx#2025-04-14_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nwaitFunction: \"200 + 8000 * x\"\n```\n\n----------------------------------------\n\nTITLE: Configuring First Message for Pizza Assistant\nDESCRIPTION: Sample first message configuration for the pizza ordering assistant that will be spoken when a call connects, is picked up, or dialed out.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/quickstart/dashboard/assistant-setup-inbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nVappy's Pizzeria speaking, how can I help you?\n```\n\n----------------------------------------\n\nTITLE: Configuring OAuth2 Authentication with Scope\nDESCRIPTION: JSON configuration for OAuth2 authentication including the new scope property. This enhances permission control when integrating with OAuth2-based services.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-02-27.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"credentials\": [\n    {\n      \"authenticationPlan\": {\n        \"type\": \"oauth2\",\n        \"url\": \"https://example.com/oauth2/token\",\n        \"clientId\": \"your-client-id\",\n        \"clientSecret\": \"your-client-secret\",\n        \"scope\": \"read:data\"  // New property, max length: 1000 characters\n      }\n    }\n  ]\n}\n```\n\n----------------------------------------\n\nTITLE: Defining Account Inquiry Test Rubric in Markdown\nDESCRIPTION: This snippet presents a rubric for evaluating the voice agent's response to an account inquiry. It includes criteria for assessing the presentation of account information and addressing customer concerns.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Rubric\" wordWrap\n1. The voice agent clearly presents the current account balance.\n2. The voice agent provides a detailed breakdown of recent transactions.\n3. The response addresses the customer's concerns in a calm and informative manner.\n```\n```\n\n----------------------------------------\n\nTITLE: Creating Inbound SIP Trunk Credential in Vapi\nDESCRIPTION: API call to create an inbound SIP trunk credential in Vapi for receiving calls from Plivo.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-plivo.mdx#2025-04-14_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/credential \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer your-vapi-private-api-key\" \\\n-d '{\n  \"provider\": \"byo-sip-trunk\",\n  \"name\": \"PLIVO Inbound Trunk\",\n  \"type\": \"inbound\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Stop Speaking Plan Parameters\nDESCRIPTION: JSON configuration for controlling when the assistant stops speaking. Includes parameters for word count threshold (numWords), voice activity duration (voiceSeconds), and pause duration before resuming (backoffSeconds).\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/speech-configuration.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"stopSpeakingPlan\": {\n    \"numWords\": 0,\n    \"voiceSeconds\": 0.2,\n    \"backoffSeconds\": 1                                                                \n  }\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini 2.0 Model Selection\nDESCRIPTION: Demonstrates how to specify Gemini 2.0 models in the Assistant configuration, including the new experimental flash models for real-time capabilities.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-07.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nAssistant.model[model='GoogleModel']\n```\n\n----------------------------------------\n\nTITLE: Testing Native Tool Calling with cURL\nDESCRIPTION: This curl command demonstrates how to test native tool calling, specifically the 'get_payment_link' function, by sending a POST request to the custom LLM endpoint with appropriate parameters and tool configurations.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-llm/tool-calling-integration.mdx#2025-04-14_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://custom-llm-url/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n        \"model\": \"gpt-3.5-turbo\",\n        \"messages\": [\n          {\"role\": \"user\", \"content\": \"I need a payment link.\"}\n        ],\n        \"temperature\": 0.7,\n        \"tools\": [\n          {\n            \"type\": \"function\",\n            \"function\": {\n              \"name\": \"get_payment_link\",\n              \"description\": \"Get a payment link\",\n              \"parameters\": {}\n            }\n          }\n        ]\n      }'\n```\n\n----------------------------------------\n\nTITLE: Responding to Function Call with Object Result in JSON\nDESCRIPTION: Demonstrates how to respond to a function call with a more complex object result.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"result\": \"{ \\\"message\\\": \\\"Your email has been sent.\\\", \\\"email\\\": \\\"test@email.com\\\" }\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Cartesia Voice Experimental Controls in JSON\nDESCRIPTION: Configuration example for Cartesia voice provider showing how to set speed and emotional range parameters. The speed can be set from 'slowest' to 'fastest', and emotions can be configured with intensity levels from 'lowest' to 'highest' for different emotional aspects like anger, positivity, surprise, sadness, and curiosity.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-02-25.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"speed\": \"fast\",\n    \"emotion\": [\n        \"anger:lowest\",\n        \"curiosity:high\"\n    ]\n}\n```\n\n----------------------------------------\n\nTITLE: Rendering Vapi SDK Integration Cards with React\nDESCRIPTION: This code snippet defines a React component called SdkCards that renders a group of cards, each representing a different Vapi SDK integration option. It uses the CardGroup and Card components to structure the layout, and accepts an iconColor prop for styling.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/sdk.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nexport const SdkCards = ({ iconColor }) => (\n  <CardGroup cols={3}>\n    <Card title=\"Vapi Web\" icon=\"window\" iconType=\"duotone\" color={iconColor} href=\"/sdk/web\">\n      Add a Vapi assistant to your web application.\n    </Card>\n    <Card\n      title=\"Vapi iOS\"\n      icon=\"mobile-notch\"\n            color={iconColor}\n      href=\"https://github.com/VapiAI/ios\"\n    >\n      Add a Vapi assistant to your iOS app.\n    </Card>\n    <Card\n      title=\"Vapi Flutter\"\n      icon=\"mobile-notch\"\n            color={iconColor}\n      href=\"https://github.com/VapiAI/flutter\"\n    >\n      Add a Vapi assistant to your Flutter app.\n    </Card>\n    <Card\n      title=\"Vapi React Native\"\n      icon=\"mobile-notch\"\n            color={iconColor}\n      href=\"https://github.com/VapiAI/react-native-sdk\"\n    >\n      Add a Vapi assistant to your React Native app.\n    </Card>\n    <Card\n      title=\"Vapi Python\"\n      icon=\"fa-brands fa-python\"\n            color={iconColor}\n      href=\"https://github.com/VapiAI/python\"\n    >\n      Multi-platform. Mac, Windows, and Linux.\n    </Card>\n  </CardGroup>\n);\n```\n\n----------------------------------------\n\nTITLE: Registering a Phone Number with Vapi for SIP Integration\nDESCRIPTION: This API call registers your Twilio phone number with Vapi and associates it with the previously created SIP trunk credential. The number registration disables E164 format checking to accommodate various number formats.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-twilio.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/phone-number \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer YOUR_VAPI_API_KEY\" \\\n-d '{\n  \"provider\": \"byo-phone-number\",\n  \"name\": \"Twilio SIP Number\",\n  \"number\": \"YOUR_SIP_PHONE_NUMBER\",\n  \"numberE164CheckEnabled\": false,\n  \"credentialId\": \"YOUR_CREDENTIAL_ID\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Phone Number Creation Response\nDESCRIPTION: Response object from the Phone Numbers API showing the created phone number details including provider information and timestamps.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"id\": \"c86b5177-5cd8-447f-9013-99e307a8a7bb\",\n  \"orgId\": \"aa4c36ba-db21-4ce0-9c6e-99e307a8a7bb\",\n  \"provider\": \"vapi\",\n  \"number\": \"+11234567890\",\n  \"createdAt\": \"2023-09-29T21:44:37.946Z\",\n  \"updatedAt\": \"2023-12-08T00:57:24.706Z\"\n}\n```\n\n----------------------------------------\n\nTITLE: JSON Output with Regex Validation\nDESCRIPTION: Example of using regex validation in JSON outputs node for validating conversation and tool call data.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-29.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"field\": {\n      \"type\": \"string\",\n      \"regex\": \"^[A-Za-z0-9]+$\"\n    }\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Transcription Service with Deepgram Integration\nDESCRIPTION: A Node.js service that connects to Deepgram, processes incoming audio, detects channels (customer vs assistant), handles transcript events with debouncing, and emits final transcriptions back to the caller.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_4\n\nLANGUAGE: js\nCODE:\n```\nconst { createClient, LiveTranscriptionEvents } = require(\"@deepgram/sdk\");\nconst EventEmitter = require(\"events\");\n\nconst PUNCTUATION_TERMINATORS = [\".\", \"!\", \"?\"];\nconst MAX_RETRY_ATTEMPTS = 3;\nconst DEBOUNCE_DELAY_IN_SECS = 3;\nconst DEBOUNCE_DELAY = DEBOUNCE_DELAY_IN_SECS * 1000;\nconst DEEPGRAM_API_KEY = process.env[\"DEEPGRAM_API_KEY\"] || \"\";\n\nclass TranscriptionService extends EventEmitter {\n  constructor(config, logger) {\n    super();\n    this.config = config;\n    this.logger = logger;\n    this.flowLogger = require(\"./fileLogger\").createNamedLogger(\n      \"transcriber-flow.log\"\n    );\n    if (!DEEPGRAM_API_KEY) {\n      throw new Error(\"Missing Deepgram API Key\");\n    }\n    this.deepgramClient = createClient(DEEPGRAM_API_KEY);\n    this.logger.logDetailed(\n      \"INFO\",\n      \"Initializing Deepgram live connection\",\n      \"TranscriptionService\",\n      {\n        model: \"nova-2\",\n        sample_rate: 16000,\n        channels: 2,\n      }\n    );\n    this.deepgramLive = this.deepgramClient.listen.live({\n      encoding: \"linear16\",\n      channels: 2,\n      sample_rate: 16000,\n      model: \"nova-2\",\n      smart_format: true,\n      interim_results: true,\n      endpointing: 800,\n      language: \"en\",\n      multichannel: true,\n    });\n    this.finalResult = { customer: \"\", assistant: \"\" };\n    this.audioBuffer = [];\n    this.retryAttempts = 0;\n    this.lastTranscriptionTime = Date.now();\n    this.pcmBuffer = Buffer.alloc(0);\n\n    this.deepgramLive.addListener(LiveTranscriptionEvents.Open, () => {\n      this.logger.logDetailed(\n        \"INFO\",\n        \"Deepgram connection opened\",\n        \"TranscriptionService\"\n      );\n      this.deepgramLive.on(LiveTranscriptionEvents.Close, () => {\n        this.logger.logDetailed(\n          \"INFO\",\n          \"Deepgram connection closed\",\n          \"TranscriptionService\"\n        );\n        this.emitTranscription();\n        this.audioBuffer = [];\n      });\n      this.deepgramLive.on(LiveTranscriptionEvents.Metadata, (data) => {\n        this.logger.logDetailed(\n          \"DEBUG\",\n          \"Deepgram metadata received\",\n          \"TranscriptionService\",\n          data\n        );\n      });\n      this.deepgramLive.on(LiveTranscriptionEvents.Transcript, (event) => {\n        this.handleTranscript(event);\n      });\n      this.deepgramLive.on(LiveTranscriptionEvents.Error, (err) => {\n        this.logger.logDetailed(\n          \"ERROR\",\n          \"Deepgram error received\",\n          \"TranscriptionService\",\n          { error: err }\n        );\n        this.emit(\"transcriptionerror\", err);\n      });\n    });\n  }\n\n  send(payload) {\n    if (payload instanceof Buffer) {\n      this.pcmBuffer =\n        this.pcmBuffer.length === 0\n          ? payload\n          : Buffer.concat([this.pcmBuffer, payload]);\n    } else {\n      this.logger.warn(\"TranscriptionService: Received non-Buffer data chunk.\");\n    }\n    if (this.deepgramLive.getReadyState() === 1 && this.pcmBuffer.length > 0) {\n      this.sendBufferedData(this.pcmBuffer);\n      this.pcmBuffer = Buffer.alloc(0);\n    }\n  }\n\n  sendBufferedData(bufferedData) {\n    try {\n      this.logger.logDetailed(\n        \"INFO\",\n        \"Sending buffered data to Deepgram\",\n        \"TranscriptionService\",\n        { bytes: bufferedData.length }\n      );\n      this.deepgramLive.send(bufferedData);\n      this.audioBuffer = [];\n      this.retryAttempts = 0;\n    } catch (error) {\n      this.logger.logDetailed(\n        \"ERROR\",\n        \"Error sending buffered data\",\n        \"TranscriptionService\",\n        { error }\n      );\n      this.retryAttempts++;\n      if (this.retryAttempts <= MAX_RETRY_ATTEMPTS) {\n        setTimeout(() => {\n          this.sendBufferedData(bufferedData);\n        }, 1000);\n      } else {\n        this.logger.logDetailed(\n          \"ERROR\",\n          \"Max retry attempts reached, discarding data\",\n          \"TranscriptionService\"\n        );\n        this.audioBuffer = [];\n        this.retryAttempts = 0;\n      }\n    }\n  }\n\n  handleTranscript(transcription) {\n    if (!transcription.channel || !transcription.channel.alternatives?.[0]) {\n      this.logger.logDetailed(\n        \"WARN\",\n        \"Invalid transcript format\",\n        \"TranscriptionService\",\n        { transcription }\n      );\n      return;\n    }\n    const text = transcription.channel.alternatives[0].transcript.trim();\n    if (!text) return;\n    const currentTime = Date.now();\n    const channelIndex = transcription.channel_index\n      ? transcription.channel_index[0]\n      : 0;\n    const channel = channelIndex === 0 ? \"customer\" : \"assistant\";\n    this.logger.logDetailed(\n      \"INFO\",\n      \"Received transcript\",\n      \"TranscriptionService\",\n      { channel, text }\n    );\n    if (transcription.is_final || transcription.speech_final) {\n      this.finalResult[channel] += ` ${text}`;\n      this.emitTranscription();\n    } else {\n      this.finalResult[channel] += ` ${text}`;\n      if (currentTime - this.lastTranscriptionTime >= DEBOUNCE_DELAY) {\n        this.logger.logDetailed(\n          \"INFO\",\n          `Emitting transcript after ${DEBOUNCE_DELAY_IN_SECS}s inactivity`,\n          \"TranscriptionService\"\n        );\n        this.emitTranscription();\n      }\n    }\n    this.lastTranscriptionTime = currentTime;\n  }\n\n  emitTranscription() {\n    for (const chan of [\"customer\", \"assistant\"]) {\n      if (this.finalResult[chan].trim()) {\n        const transcript = this.finalResult[chan].trim();\n        this.logger.logDetailed(\n          \"INFO\",\n          \"Emitting transcription\",\n          \"TranscriptionService\",\n          { channel: chan, transcript }\n        );\n        this.emit(\"transcription\", transcript, chan);\n        this.finalResult[chan] = \"\";\n      }\n    }\n  }\n}\n\nmodule.exports = TranscriptionService;\n```\n\n----------------------------------------\n\nTITLE: Responding with Existing Assistant ID in JSON\nDESCRIPTION: Illustrates how to respond to an assistant request with an existing assistant ID.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/events.mdx#2025-04-14_snippet_6\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"assistantId\": \"your-saved-assistant-id\"\n}\n```\n\n----------------------------------------\n\nTITLE: Adding a Virtual Phone Number to Vapi.ai\nDESCRIPTION: This curl command associates a Zadarma virtual number with the previously created SIP trunk in Vapi.ai. It requires your Vapi private key, a name for the virtual number, the Zadarma virtual number in international format, and the credential ID obtained from the previous request.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-zadarma.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -L 'https://api.vapi.ai/phone-number' \\\n-H 'Content-Type: application/json' \\\n-H 'Authorization: Bearer YOUR_PRIVATE_KEY' \\\n-d '{\n  \"provider\": \"byo-phone-number\",\n  \"name\": \"Zadarma Number\",\n  \"number\": \"YOUR_VIRTUAL_NUMBER\",\n  \"numberE164CheckEnabled\": false,\n  \"credentialId\": \"YOUR_CREDENTIAL_ID\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Card with JSX/React\nDESCRIPTION: JSX code for creating an interactive card component using a CardGroup and Card structure. The card includes a title, icon, and link to a form where users can submit their own videos.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_5\n\nLANGUAGE: jsx\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Importing Vapi Web SDK\nDESCRIPTION: Imports the Vapi web SDK package using ES6 module syntax.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/sdks/web/import-web-sdk.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport Vapi from \"@vapi-ai/web\";\n```\n\n----------------------------------------\n\nTITLE: Using LiquidJS Template Variables in AssistantOverrides\nDESCRIPTION: Examples of template variable syntax using LiquidJS in AssistantOverrides.variableValues for dynamic content and date formatting.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-30.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n{{ name }}\n```\n\nLANGUAGE: javascript\nCODE:\n```\n{\"now\" | date: \"%b %d, %Y, %I:%M %p\", \"America/New_York\"}\n```\n\n----------------------------------------\n\nTITLE: Function Call Success Response\nDESCRIPTION: Success response format for the function call endpoint when appointment booking is successful.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{ \"result\": \"The appointment was booked successfully.\" }\n```\n\n----------------------------------------\n\nTITLE: SIP REFER Transfer Configuration\nDESCRIPTION: JSON configuration for setting up call transfers using SIP REFER functionality, specifying the transfer destination.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-trunk.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n      \"type\": \"transferCall\",\n      \"destinations\": [\n        {\n          \"type\": \"sip\",\n          \"sipUri\": \"sip:14039932200@sip.telnyx.com\"\n        }\n      ]\n    }\n```\n\n----------------------------------------\n\nTITLE: Initializing Vapi Instance\nDESCRIPTION: Creates a new instance of the Vapi class using either a public key from the dashboard or a generated JWT token for authentication.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/sdks/web/import-web-sdk.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nconst vapi = new Vapi(\"your-public-key-or-jwt\");\n```\n\n----------------------------------------\n\nTITLE: Accessing Transport Details and Costs in Vapi API\nDESCRIPTION: Demonstrates how to access transport provider details and costs using the call.transport property. The property includes information about the provider type and video settings for web calls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-03.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\ncall.transport // Access details about the provider (twilio, vonage, vapi, or daily)\ncall.transport.assistantVideoEnabled // Check if assistant's video is enabled for web calls\ncall.costs[type=transport].provider // View which provider contributed to the transport cost\n```\n\n----------------------------------------\n\nTITLE: Resources Table HTML Structure\nDESCRIPTION: HTML table structure defining the Vapi AI ecosystem resources including SDKs, examples, and documentation links organized by category.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/resources.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<table>\n<thead><tr><th colSpan=\"2\">Vapi AI Ecosystem</th></tr></thead>\n<tbody>\n<tr><td>Real-time SDKs</td><td><a target=\"_blank\" href=\"https://github.com/VapiAI/web\">Web</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/flutter\">Flutter</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/react-native-sdk\">React Native</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/ios\">iOS</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/python\">Python</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/html-script-tag\">Vanilla</a></td></tr>\n<tr><td>Client Examples</td><td><a target=\"_blank\" href=\"https://github.com/VapiAI/client-side-example-javascript-next\">Next.js</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/client-side-example-javascript-react\">React</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/flutter/tree/main/example\">Flutter</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/client-side-example-react-native\">React Native</a></td></tr>\n<tr><td>Server Examples</td><td><a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-serverless-vercel\">Vercel</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-serverless-cloudflare\">Cloudflare</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-serverless-supabase\">Supabase</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-javascript-node\">Node</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-javascript-bun\">Bun</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-javascript-deno\">Deno</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-python-flask\">Flask</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-php-laravel\">Laravel</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-go-gin\">Go</a>  <a target=\"_blank\" href=\"https://github.com/VapiAI/server-side-example-rust-actix\">Rust</a></td></tr>\n<tr><td>Resources</td><td><a target=\"_blank\" href=\"https://docs.vapi.ai/\">Official Docs</a>  <a target=\"_blank\" href=\"https://api.vapi.ai/api\">API Reference</a></td></tr>\n<tr><td>Community</td><td><a target=\"_blank\" href=\"/community/videos\">Videos</a> . <a target=\"_blank\" href=\"https://www.vapiblocks.com/\">UI Library</a></td></tr>\n</tbody>\n</table>\n```\n\n----------------------------------------\n\nTITLE: Customizing Success Evaluation Prompt with JSON Configuration\nDESCRIPTION: JSON configuration to customize the success evaluation prompt that determines if a call achieved its objectives.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_7\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"successEvaluationPrompt\": \"Custom success evaluation prompt text\"\n}\n```\n\n----------------------------------------\n\nTITLE: Conference Announcement Handler\nDESCRIPTION: Optional endpoint for making announcements to conference participants using ephemeral calls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\napp.post(\"/announce\", (req, res) => {\n  const VoiceResponse = twilio.twiml.VoiceResponse;\n  const twiml = new VoiceResponse();\n  twiml.say(\"Specialist is not available. Ending call now.\");\n\n  // Join the conference, then end it.\n  twiml.dial().conference(\n    {\n      startConferenceOnEnter: true,\n      endConferenceOnExit: true,\n    },\n    \"my_conference_room\"\n  );\n\n  return res.type(\"text/xml\").send(twiml.toString());\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Knowledge Base Description in Vapi AI (JSON)\nDESCRIPTION: This JSON snippet shows how to write a clear and specific description for a knowledge base. It helps the assistant understand when to use this particular knowledge base for user queries.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/using-query-tool.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n\"description\": \"Use this knowledge base when the user asks about pricing, subscription plans, or billing information\"\n```\n\n----------------------------------------\n\nTITLE: Registering Phone Number with Vapi SIP Trunk\nDESCRIPTION: API call to associate a Plivo phone number with the created SIP trunk in Vapi. Requires the credential ID from the previous step.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-plivo.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/phone-number \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer your-vapi-private-api-key\" \\\n-d '{\n  \"provider\": \"byo-phone-number\",\n  \"name\": \"PLIVO SIP Number\",\n  \"number\": \"1833684XXXX\",\n  \"numberE164CheckEnabled\": false,\n  \"credentialId\": \"a2c815b8-03f4-40f5-813c-xxxxxxxxxxxx\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Multilingual Message Contents\nDESCRIPTION: Shows implementation of multilingual content for custom messages and block messages with automatic translation support.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-25.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n{\n  CustomMessage: { contents: [] },\n  BlockStartMessage: { contents: [] },\n  BlockCompleteMessage: { contents: [] }\n}\n```\n\n----------------------------------------\n\nTITLE: Combining Success Evaluation Prompt and Rubric in JSON Configuration\nDESCRIPTION: JSON configuration that combines a custom success evaluation prompt with a specific rubric type (Checklist) to create detailed evaluation instructions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_10\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"successEvaluationPrompt\": \"Evaluate the call based on these criteria:...\",\n  \"successEvaluationRubric\": \"Checklist\"\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video Player with Security Settings\nDESCRIPTION: HTML iframe code for embedding a YouTube video player with specific security and functionality parameters including referrer policy and allowances for various browser features.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/ghl.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    src=\"https://www.youtube.com/embed/PVP1P2nak4M?si=vGGAMZVI3Fzzik9X\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Crafting Appointment Scheduling Test Script in Markdown\nDESCRIPTION: This snippet demonstrates a detailed script for simulating a customer scheduling an appointment. It includes identity, personality, goals, and interaction style for the test agent to follow.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Script\" wordWrap\nSimulate a customer trying to schedule an appointment with a hint of urgency due to previous delays.  \n\n[Identity]\nYou are an organized customer who values efficiency and punctuality.\n\n[Personality]\nWhile generally courteous and friendly, you are anxious due to previous delays in scheduling appointments, and your tone conveys urgency.\n\n[Goals]\nYour goal is to secure an appointment at your preferred time, while remaining flexible enough to consider alternative timings if your desired slot is unavailable.\n\n[Interaction Style]\nBegin the call by stating your need for an appointment, specifying a preferred date and time (e.g., next Monday at 3 PM). Request clear confirmation of your slot, and if unavailable, ask for suitable alternatives.\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Tavus Voice Properties\nDESCRIPTION: Shows how to configure Tavus voice provider settings including language, recording options, and transcription settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-25.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nassistant.voice.properties = {\n  language: \"string\",\n  recording: {},\n  transcription: {}\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Background Sound Configuration\nDESCRIPTION: JSON configuration for specifying background sound handling. Controls how the system handles ambient noise during conversations.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/speech-configuration.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n\"backgroundSound\": \"off\"\n```\n\n----------------------------------------\n\nTITLE: Defining Billing Support Test Rubric in Markdown\nDESCRIPTION: This snippet shows how to create a rubric for evaluating the voice agent's response to a billing inquiry. It focuses on the agent's acknowledgment and handling of the customer's concern.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Rubric\" wordWrap\nThe voice agent acknowledges the billing discrepancy respectfully without dismissing the concern.\n```\n```\n\n----------------------------------------\n\nTITLE: CartesiaVoice Language Options\nDESCRIPTION: New language options available for CartesiaVoice.language parameter including Hindi, Italian, Korean, Dutch, Polish, Russian, Swedish, and Turkish.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-30.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nCartesiaVoice.language = 'hi' // Hindi\nCartesiaVoice.language = 'it' // Italian\nCartesiaVoice.language = 'ko' // Korean\nCartesiaVoice.language = 'nl' // Dutch\nCartesiaVoice.language = 'pl' // Polish\nCartesiaVoice.language = 'ru' // Russian\nCartesiaVoice.language = 'sv' // Swedish\nCartesiaVoice.language = 'tr' // Turkish\n```\n\n----------------------------------------\n\nTITLE: Defining Appointment Scheduling Test Rubric in Markdown\nDESCRIPTION: This snippet outlines a rubric for evaluating the voice agent's performance in scheduling an appointment. It focuses on confirmation accuracy, clarity, and providing a definitive booking message.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Rubric\" wordWrap\n1. The voice agent confirms the requested appointment time clearly and accurately.\n2. The agent reiterates the appointment details to ensure clarity.\n3. The scheduling process ends with a definitive confirmation message of the booked appointment.\n```\n```\n\n----------------------------------------\n\nTITLE: Slack RSS Feed Subscribe Command\nDESCRIPTION: Command to subscribe to Vapi's RSS feed in a Slack channel using the Slack RSS app.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/rss-feed.mdx#2025-04-14_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n/feed subscribe https://status.vapi.ai/feed.rss\n```\n\n----------------------------------------\n\nTITLE: Installing @vapi-ai/web Package with Yarn\nDESCRIPTION: This command installs the @vapi-ai/web package using Yarn package manager. It adds the package to your project's dependencies.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/sdks/web/install-web-sdk.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nyarn add @vapi-ai/web\n```\n\n----------------------------------------\n\nTITLE: Error Response Payload in JSON\nDESCRIPTION: Response payload for when a transfer cannot be completed. Provides a clear reason for the failure that can be relayed to the user or used for debugging.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-dynamic-transfers.mdx#2025-04-14_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"error\": \"Invalid destination specified.\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Text Generation Parameters\nDESCRIPTION: Shows the available hyperparameters for fine-tuning text generation behavior in Gemini 2.0 models.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-07.mdx#2025-04-14_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\ntopK\ntopP\npresencePenalty\nfrequencyPenalty\n```\n\n----------------------------------------\n\nTITLE: Search Optimization Parameters\nDESCRIPTION: Recommended settings for optimizing search relevance, including BM25 to semantic search ratio and chunk overlap configurations.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/integrating-with-trieve.mdx#2025-04-14_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\nBM25 vs semantic weights ratio: 0.3:0.7\nChunk boundary overlap: 15-20%\nChunk size variance: max 20%\nBatch operations: max 100 chunks/request\n```\n\n----------------------------------------\n\nTITLE: Making Outbound Calls via Vapi API\nDESCRIPTION: API call to initiate outbound calls using the configured Vapi assistant and phone number. Requires assistant ID and phone number ID from previous setup.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-plivo.mdx#2025-04-14_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl --location 'https://api.vapi.ai/call/phone' \\\n--header 'Authorization: Bearer your-vapi-private-api-key' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"assistantId\": \"29d47d31-ba3c-451c-86ce-xxxxxxxxx\",\n  \"customer\": {\n    \"number\": \"9199437XXXXX\",\n    \"numberE164CheckEnabled\": false\n  },\n  \"phoneNumberId\": \"eba2fb13-259f-4123-abfa-xxxxxxxxxxx\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Creating Account Inquiry Test Script in Markdown\nDESCRIPTION: This snippet illustrates a more free-form script for simulating a customer inquiring about their account status. It provides context and objectives for the test agent to follow during the interaction.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/test/test-suites.mdx#2025-04-14_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n```md title=\"Script\" wordWrap\nSimulate a customer inquiring about their account status with growing concern as unexplained charges appear in their statement.  \n\nYour primary objective is to clarify several unexplained charges by requesting a detailed breakdown of your recent transactions and ensuring your account balance is accurate.\n\nBegin the call by stating your name and expressing concern over unexpected charges. Ask straightforward questions and press for more details if the explanation is not satisfactory.\n```\n```\n\n----------------------------------------\n\nTITLE: Updating Vapi Documentation on Hosted URL with Fern\nDESCRIPTION: Command to update documentation on a hosted URL using Fern generate. Requires fern-api to be installed globally via npm.\nSOURCE: https://github.com/VapiAI/docs/blob/main/README.md#2025-04-14_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# npm install -g fern-api\nfern generate --docs\n```\n\n----------------------------------------\n\nTITLE: Installing @vapi-ai/web Package with npm\nDESCRIPTION: This command installs the @vapi-ai/web package using npm (Node Package Manager). It adds the package to your project's dependencies.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/sdks/web/install-web-sdk.mdx#2025-04-14_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm install @vapi-ai/web\n```\n\n----------------------------------------\n\nTITLE: Workflow Node with Extended Properties\nDESCRIPTION: Example of a workflow node with extended character limits (80 chars) for name, to, and from properties, plus the new metadata field.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-29.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"descriptive_workflow_name\",\n  \"to\": \"destination_identifier\",\n  \"from\": \"source_identifier\",\n  \"metadata\": {\n    \"customField\": \"value\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Assistant Request JSON Structure for Vapi AI\nDESCRIPTION: This JSON structure represents the assistant request sent by Vapi AI when a call is received. It includes the message type and the call object containing details about the incoming call.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/inbound-support.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"message\": {\n        \"type\": \"assistant-request\",\n        \"call\": { \"Call Object\" },\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: API Response Example in JSX\nDESCRIPTION: Example of a typical JSON response structure from an API containing user information including name, age, and active status.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/workflows/nodes/api-request.mdx#2025-04-14_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n{\n    \"name\": \"Jaden Dearsley\",\n    \"age\": 25,\n    \"isActive\": true,\n}\n```\n\n----------------------------------------\n\nTITLE: Registering Inbound Phone Number with Vapi\nDESCRIPTION: API call to register a phone number for inbound calls with the created inbound SIP trunk credential in Vapi.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/advanced/sip/sip-plivo.mdx#2025-04-14_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://api.vapi.ai/phone-number \\\n-H \"Content-Type: application/json\" \\\n-H \"Authorization: Bearer your-vapi-private-api-key\" \\\n-d '{\n  \"provider\": \"byo-phone-number\",\n  \"name\": \"PLIVO SIP Inbound Number\",\n  \"number\": \"1833684XXXX\",\n  \"numberE164CheckEnabled\": false,\n  \"credentialId\": \"a2c815b8-03f4-40f5-813c-xxxxxxxxxxxx\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Starting Ngrok HTTP Tunnel in Bash\nDESCRIPTION: This command starts an ngrok HTTP tunnel to forward internet traffic to a local server running on port 8080. The ngrok agent must be installed and the local server should be running on the specified port.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/developing-locally.mdx#2025-04-14_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nngrok http 8080\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for Deployment\nDESCRIPTION: Command to update the documentation on a hosted URL. This generates the final documentation files for production deployment.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\nfern generate --docs\n```\n\n----------------------------------------\n\nTITLE: Defining a Food Ordering Prompt Without Using Blocks in JSX\nDESCRIPTION: An example of a traditional prompt for a food truck ordering assistant that defines the bot's identity and sequential tasks in a single prompt without using the Blocks feature.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/blocks.mdx#2025-04-14_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n[Identity]\nYou are a friendly and efficient assistant for a food truck that serves burgers, fries, and drinks.\n\n[Task]\n1. Greet the customer warmly and inquire about their main order.\n2. Offer suggestions for the main order if needed.\n3. If they choose a burger, suggest upgrading to a combo with fries and a drink, offering clear options (e.g., regular or special fries, different drink choices).\n4. Confirm the entire order to ensure accuracy.\n5. Suggest any additional items like desserts or sauces.\n6. Thank the customer and let them know when their order will be ready.\n```\n\n----------------------------------------\n\nTITLE: Configuring PlayHT Voice Engine Models\nDESCRIPTION: Configuration options for selecting which PlayHT voice model to use for voice generation, with choices between PlayHT2.0, PlayHT2.0-turbo, and Play3.0-mini.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-13.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nPlayHT2.0\n```\n\nLANGUAGE: javascript\nCODE:\n```\nPlayHT2.0-turbo\n```\n\nLANGUAGE: javascript\nCODE:\n```\nPlay3.0-mini\n```\n\n----------------------------------------\n\nTITLE: Configuring Google Voicemail Detection\nDESCRIPTION: Configuration example for Google voicemail detection using the GoogleVoicemailDetectionPlan schema. Allows setting the expected voicemail duration in seconds within a range of 5-60 seconds.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-03-09.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n// Google configuration example\n{\n  \"provider\": \"google\",\n  \"voicemailExpectedDurationSeconds\": 15  // Range: 5-60 seconds\n}\n```\n\n----------------------------------------\n\nTITLE: Slack RSS Feed List Command\nDESCRIPTION: Command to list all RSS feeds subscribed in a Slack channel.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/rss-feed.mdx#2025-04-14_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\n/feed list\n```\n\n----------------------------------------\n\nTITLE: Configuring Destination with Extension\nDESCRIPTION: This snippet shows how to specify an extension parameter when configuring a call forwarding destination. This is useful when forwarding calls to phone systems that use extensions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/call-forwarding.mdx#2025-04-14_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n    \"destinations\": [\n        {\n            \"type\": \"number\",\n            \"number\": \"+1234567890\",\n            \"extension\": \"4603\",\n            \"message\": \"I am forwarding your call to Department A. Please stay on the line.\"\n        }\n    ]\n```\n\n----------------------------------------\n\nTITLE: Installing Fern API CLI\nDESCRIPTION: Command to install the Fern API CLI globally using npm. This CLI tool is a prerequisite for working with the Vapi API configuration.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\nnpm install -g fern-api\n```\n\n----------------------------------------\n\nTITLE: Disabling Summary Prompt with JSON Configuration\nDESCRIPTION: JSON configuration to disable the summary prompt by setting it to an empty string.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_2\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"summaryPrompt\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Function Call Error Response\nDESCRIPTION: Error response format for the function call endpoint when appointment booking fails.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/examples/outbound-sales.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{ \"result\": \"The appointment time is unavailable, please try another time.\" }\n```\n\n----------------------------------------\n\nTITLE: Creating OAuth2 Webhook Credential for Custom LLM\nDESCRIPTION: Example JSON payload for creating a webhook credential using CreateCustomLLMCredentialDTO. The credential includes OAuth2 authentication configuration with client credentials and authentication plan details.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-12-06.mdx#2025-04-14_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n    \"provider\": \"custom-llm\",\n    \"apiKey\": \"your-api-key-max-10000-characters\",\n    \"authenticationPlan\": {\n        \"type\": \"oauth2\",\n        \"url\": \"https://your-url.com/your/path/token\",\n        \"clientId\": \"your-client-id\",\n        \"clientSecret\": \"your-client-secret\"\n    },\n    \"name\": \"your-credential-name-between-1-and-40-characters\"\n}\n```\n\n----------------------------------------\n\nTITLE: Vapi RSS Feed URL\nDESCRIPTION: The URL endpoint for Vapi's incident RSS feed that provides latest status updates.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/rss-feed.mdx#2025-04-14_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nhttps://status.vapi.ai/feed.rss\n```\n\n----------------------------------------\n\nTITLE: Configuring Gemini Real-time Settings\nDESCRIPTION: Shows how to access and configure real-time settings for the Gemini 2.0 Multimodal Live API for enhanced control over generation capabilities.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-07.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nAssistant.model[model='GoogleModel'].realtimeConfig\n```\n\n----------------------------------------\n\nTITLE: Validating OpenAPI Specifications\nDESCRIPTION: Command to validate the API specification using Fern's check functionality. This ensures the API definition is correctly formatted before deployment.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\nfern check\n```\n\n----------------------------------------\n\nTITLE: Slack RSS Feed Remove Command\nDESCRIPTION: Command to unsubscribe from an RSS feed in a Slack channel using the feed ID.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/rss-feed.mdx#2025-04-14_snippet_3\n\nLANGUAGE: plaintext\nCODE:\n```\n/feed remove <feed_id>\n```\n\n----------------------------------------\n\nTITLE: Disabling Success Evaluation Prompt with JSON Configuration\nDESCRIPTION: JSON configuration to disable the success evaluation prompt by setting it to an empty string or \"off\".\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"successEvaluationPrompt\": \"\"\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Realtime Model\nDESCRIPTION: Model identifier for enabling OpenAI's Realtime speech-to-speech capability in Vapi assistants. This configuration supports direct audio-to-audio processing with OpenAI voices.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/openai-realtime.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\ngpt-4o-realtime-preview-2024-12-17\n```\n\n----------------------------------------\n\nTITLE: Starting the Transcription Server\nDESCRIPTION: Command to start the custom transcription server using Node.js.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnode server.js\n```\n\n----------------------------------------\n\nTITLE: Audio Recording Naming Convention for PCI-Compliant Storage\nDESCRIPTION: This code snippet illustrates the naming convention used for audio recordings when stored in PCI-compliant cloud storage. It includes the call UUID, timestamp, a generated UUID, and the audio type, all separated by hyphens and ending with a .wav extension.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/security-and-privacy/PCI.mdx#2025-04-14_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\n<call_UUID>-<timestamp>-<generated_UUID>-<audio_type>.wav\n```\n\n----------------------------------------\n\nTITLE: Implementing Email Subscription Form in React JSX\nDESCRIPTION: A form component that validates email addresses and submits to CustomerIO. Features include styled input field, submit button, dark mode support, and form validation with regex pattern matching. Includes responsive design and hover/focus states.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/overview.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<Card\n  title={<div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem', cursor: 'pointer', color: 'inherit' }} onClick={() => document.querySelector('input[type=\"email\"]').focus()}>Get the (almost) daily changelog</div>}\n  icon=\"envelope\"\n  iconType=\"solid\"\n>\n  <form\n    method=\"POST\"\n    action=\"https://customerioforms.com/forms/submit_action?site_id=5f95a74ff6539f0bc48f&form_id=01jk7tf2khhf5satn62531qe25&success_url=https://docs.vapi.ai/changelog\"\n    className=\"subscribe-form\"\n    style={{margin: '1rem 0'}}\n    onSubmit={(e) => {\n      const emailInput = document.getElementById('email_input');\n      const emailValue = emailInput.value;\n      const emailPattern = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n      if (!emailPattern.test(emailValue)) {\n        e.preventDefault();\n        alert('Please enter a valid email address.');\n      }\n    }}\n  >\n    <div className=\"flex gap-2\" style={{ paddingLeft: '0.5rem' }}>\n      <label htmlFor=\"email_input\" style={{ display: 'none' }}>E-mail address</label>\n      <input\n        id=\"email_input\"\n        type=\"email\"\n        name=\"email\"\n        placeholder=\"Enter your email\"\n        required\n        style={{\n          border: '1px solid #e2e8f0',\n          borderRadius: '0.375rem',\n          padding: '0.5rem 1rem',\n          width: '100%',\n          fontSize: '0.875rem',\n          outline: 'none',\n          transition: 'border-color 0.2s ease-in-out',\n          color: '#1f2937',\n          ':focus': {\n            borderColor: '#4f46e5',\n            boxShadow: '0 0 0 1px #4f46e5'\n          },\n          '@media (prefers-color-scheme: dark)': {\n            backgroundColor: '#374151',\n            borderColor: '#4b5563',\n            color: '#f3f4f6',\n            '::placeholder': {\n              color: '#9ca3af'\n            },\n            ':focus': {\n              borderColor: '#6366f1',\n              boxShadow: '0 0 0 1px #6366f1'\n            }\n          }\n        }}\n      />\n      <button\n        type=\"submit\"\n        style={{\n          backgroundColor: '#37aa9d',\n          color: 'white',\n          fontWeight: 500,\n          padding: '0.5rem 1rem',\n          borderRadius: '0.375rem',\n          border: 'none',\n          cursor: 'pointer',\n          transition: 'all 0.2s ease-in-out',\n          ':hover': {\n            backgroundColor: '#2e8b7d',\n            transform: 'translateY(-1px)'\n          },\n          ':active': {\n            transform: 'translateY(0)'\n          },\n          '@media (prefers-color-scheme: dark)': {\n            backgroundColor: '#94ffd2',\n            color: '#1f2937',\n            ':hover': {\n              backgroundColor: '#7cd9b0'\n            }\n          }\n        }}\n      >\n        Submit\n      </button>\n    </div>\n  </form>\n</Card>\n```\n\n----------------------------------------\n\nTITLE: Configuring Speech and Voice Settings\nDESCRIPTION: Demonstrates the configuration of speech and voice settings for Gemini Multimodal Live APIs, including voice selection options.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-07.mdx#2025-04-14_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nspeechConfig\nvoiceConfig\n```\n\n----------------------------------------\n\nTITLE: Express Server Initialization\nDESCRIPTION: Server startup configuration for the Express application.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\napp.listen(3000, () => {\n  console.log(\"Server running on port 3000\");\n});\n```\n\n----------------------------------------\n\nTITLE: Setting Success Evaluation Rubric with JSON Configuration\nDESCRIPTION: JSON configuration to set a specific rubric type for success evaluation. This example uses the NumericScale rubric which evaluates on a scale of 1 to 10.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/call-analysis.mdx#2025-04-14_snippet_9\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"successEvaluationRubric\": \"NumericScale\"\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Locally Generated Python SDK\nDESCRIPTION: Command to install the locally generated Python SDK in development mode. This allows for testing SDK changes without requiring a full release.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\npip install -e /fern/.preview/fern-python-sdk\n```\n\n----------------------------------------\n\nTITLE: OAuth2 Token Response Format Example\nDESCRIPTION: Example of the expected JSON response format for OAuth2 token requests, including access token and optional fields.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/server-authentication.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n  \"token_type\": \"Bearer\",\n  \"expires_in\": 3600,\n  \"refresh_token\": \"tGzv3JOkF0XG5Qx2TlKWIA\",\n  \"scope\": \"read write\"\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding PlayHT Video Tutorial - HTML iframe\nDESCRIPTION: HTML iframe code for embedding a Loom video player that demonstrates the PlayHT integration process. The video is embedded with specific security settings and responsive dimensions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-voices/playht.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    src=\"https://www.loom.com/embed/45a6e43ae03945a783385f771ea9203d?sid=268071d7-d37f-43aa-843a-13c221af3ed5\"\n    title=\"Loom video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    width=\"100%\"\n    height=\"400px\"\n    allowfullscreen\n  />\n```\n\n----------------------------------------\n\nTITLE: Rendering Welcome Page Layout with Card Navigation\nDESCRIPTION: MDX/JSX layout component that creates a welcome page with a grid of navigation cards linking to key Vapi resources. Uses CardGroup and Card components to create a 2-column grid of clickable cards with icons and descriptions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/welcome.mdx#2025-04-14_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Quickstart (<5 minutes)\"\n    icon=\"clock\"\n    href=\"/quickstart/dashboard\"\n  >\n    Get started now with the Vapi Dashboard. \n  </Card>\n\n  <Card title=\"Documentation\" icon=\"book\" href=\"introduction\">\n    Learn how to use Vapi's Voice AI platform. \n  </Card>\n\n  <Card title=\"Discord\" icon=\"fa-brands fa-discord\" href=\"https://discord.gg/pUFNcf2WmH\">\n    Connect with 11,833 other Vapi developers.\n  </Card>\n\n  <Card title=\"GitHub\" icon=\"fa-brands fa-github\" href=\"https://github.com/VapiAI\">\n    Check out our public SDKs. \n  </Card>\n\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in HTML\nDESCRIPTION: This HTML code embeds a YouTube video titled 'Improve AI Voice Agent Accuracy with Query Tools | Vapi Tutorial' into the page, providing visual content related to knowledge base usage.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/knowledge-base/knowledge-base.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<Frame>\n  <div class=\"video-embed-wrapper\">\n    <iframe\n      src=\"https://www.youtube.com/embed/6QZHIiEaoco?si=H4lBlHy4W3TDtmh1\"\n      title='An embedded YouTube video titled \"Improve AI Voice Agent Accuracy with Query Tools | Vapi Tutorial\"'\n      frameborder=\"0\"\n      allow=\"fullscreen; accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n      allowfullscreen\n      referrerpolicy=\"strict-origin-when-cross-origin\"\n    />\n  </div>\n</Frame>\n```\n\n----------------------------------------\n\nTITLE: Configuring AssemblyAI Transcriber\nDESCRIPTION: Demonstrates how to set AssemblyAI as the transcription service for converting speech to text in a Vapi assistant. This provides an alternative option for transcription services.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-11-24.mdx#2025-04-14_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n\"Assistant.transcriber\": \"AssemblyAITranscriber\"\n```\n\n----------------------------------------\n\nTITLE: Running Documentation Development Server\nDESCRIPTION: Command to start a local development server for documentation with hot-reloading. This enables real-time preview of documentation changes.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nfern docs dev\n```\n\n----------------------------------------\n\nTITLE: OAuth2 Error Response Format\nDESCRIPTION: Example of the OAuth2 error response format, showing how authentication errors should be structured.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/server-url/server-authentication.mdx#2025-04-14_snippet_4\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"error\": \"invalid_client\",\n  \"error_description\": \"Invalid client credentials\"\n}\n```\n\n----------------------------------------\n\nTITLE: Handling Final Transcripts in Vapi AI Server Messages\nDESCRIPTION: This code snippet shows the format for accessing final transcripts in server messages. It uses a specific string pattern to identify and process end-of-conversation transcripts.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2025-01-22.mdx#2025-04-14_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n'transcript[transcriptType=\"final\"]'\n```\n\n----------------------------------------\n\nTITLE: Markdown Link to Swagger Documentation\nDESCRIPTION: Markdown link element directing users to Vapi's hosted Swagger API interface at api.vapi.ai/api\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/api-reference/swagger.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[https://api.vapi.ai/api](https://api.vapi.ai/api)\n```\n\n----------------------------------------\n\nTITLE: Creating Card Group Component for User Action\nDESCRIPTION: Markdown and component code for displaying a call-to-action card that encourages users to submit their own Vapi videos. Uses the CardGroup and Card components with specific styling and link parameters.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/special-mentions.mdx#2025-04-14_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Environment Variables Configuration for Custom Transcriber\nDESCRIPTION: Environment variables setup in a .env file to store the Deepgram API key and the port number for the custom transcriber server.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_3\n\nLANGUAGE: env\nCODE:\n```\nDEEPGRAM_API_KEY=your_deepgram_api_key\nPORT=3001\n```\n\n----------------------------------------\n\nTITLE: Deploying Python SDK\nDESCRIPTION: Command to generate and deploy the Python SDK using Fern. This is run by the 'Release Python SDK' GitHub Action with the desired version parameter.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nfern generate --api api --group python-sdk\n```\n\n----------------------------------------\n\nTITLE: Configuring API Traffic Channel\nDESCRIPTION: Demonstrates how to specify the channel (cluster) for API traffic routing between daily and weekly options through organization settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-25.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nchannel: \"daily\" | \"weekly\"\n```\n\n----------------------------------------\n\nTITLE: Creating Card Components for Expert Directory Using HTML/CSS\nDESCRIPTION: This code snippet demonstrates how to create a card component for the Expert Directory using HTML and CSS. Each card displays a company logo, name, and description with styling for consistent presentation across the directory.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/expert-directory.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<Card\n  href=\"https://www.qonvo.co/\"\n  className=\"ed-card\"\n  style={{\n    alignItems: \"center\",\n    display: \"flex\",\n    flexDirection: \"column\",\n    width: \"auto\",\n  }}\n>\n  <img\n    className=\"card-img bg:white\"\n    noZoom\n    src=\"https://i.imgur.com/ZkhLOBl.png\"\n  />\n  <div className=\"card-content\">\n    <h3>Qonvo</h3>\n    <p>Qonvo is the best way to stop wasting your time on the phone for repetitive tasks and low-value added inbound requests. Allow your self to better invest your time thanks custom-build Vocal AI agents.</p>\n  </div>\n</Card>\n```\n\n----------------------------------------\n\nTITLE: Creating a Card Link for Video Submissions in Markdown\nDESCRIPTION: Markdown code using a CardGroup component with a nested Card element to create a submission link for community videos. The card includes a title, icon, and href attribute pointing to a Tally form.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/conferences.mdx#2025-04-14_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Example Transcription Response Format\nDESCRIPTION: JSON structure showing the expected format of transcription responses from the custom transcriber.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-transcriber.mdx#2025-04-14_snippet_8\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"type\": \"transcriber-response\",\n  \"transcription\": \"The transcribed text\",\n  \"channel\": \"customer\"\n}\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Videos in a Grid Layout with JSX/HTML\nDESCRIPTION: This code snippet demonstrates how to embed multiple YouTube videos in a responsive grid layout using JSX/HTML iframe elements. Each iframe loads a YouTube video with standardized attributes for security and user experience.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/outbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<div class=\"video-grid\">\n    <iframe\n        src=\"https://www.youtube.com/embed/gi5Qa0Z2iqQ?si=l1FLFu5TvuTxYyIc\"\n        title=\"YouTube video player\"\n        frameborder=\"0\"\n        allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n        referrerpolicy=\"strict-origin-when-cross-origin\"\n        allowfullscreen\n    />\n    <iframe\n        src=\"https://www.youtube.com/embed/IbgPEG8l09Y?si=jIFLBN_SKPShurfy\"\n        title=\"YouTube video player\"\n        frameborder=\"0\"\n        allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n        referrerpolicy=\"strict-origin-when-cross-origin\"\n        allowfullscreen\n    />\n    <iframe\n        src=\"https://www.youtube.com/embed/jJjD5UsO46o?si=ATafEm5RDmt-f13I\"\n        title=\"YouTube video player\"\n        frameborder=\"0\"\n        allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n        referrerpolicy=\"strict-origin-when-cross-origin\"\n        allowfullscreen\n    />\n\n{\" \"}\n\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/Sj-OOK11Nac?si=laIZ3JasRWIF1vKh\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/t_35BMnOTDY?si=SO4m9QEqg4sxT9BY\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n\n    <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/BMjSnRfcL7g?si=5ZW1Qr1tEecBCNgt\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n\n/>\n\n<iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/d7OQJ83XsBE?si=ebPYoX04ImtZl92U\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n\n/>\n\n  </div>\n```\n\n----------------------------------------\n\nTITLE: Adding Button HTML Element for Message Trigger\nDESCRIPTION: HTML code to create a button that triggers the background message logging function when clicked.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/assistants/background-messages.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<button id=\"log-action\" onClick=\"logUserAction()\">Log Action</button>\n```\n\n----------------------------------------\n\nTITLE: Implementing a Call-to-Action Card using Markdown and HTML\nDESCRIPTION: This code creates a card-based call-to-action section encouraging users to submit their own videos. It uses a CardGroup component with a single Card that includes a title, icon, and link to a submission form.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/usecase.mdx#2025-04-14_snippet_1\n\nLANGUAGE: Markdown\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with iframe in HTML\nDESCRIPTION: HTML code for embedding a YouTube video that showcases Vapi functionality. The iframe is configured with specific attributes including source URL, title, and various permissions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/podcast.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/kOhr047QFFA?si=8-2uY09fni5195tx&amp;start=1245\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Interactive Card Component for Video Submission\nDESCRIPTION: A card component that provides users with a link to submit their own videos for consideration. Uses the CardGroup and Card components with specific styling and icon properties.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/guide.mdx#2025-04-14_snippet_1\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Testing Commands for API Endpoints\nDESCRIPTION: cURL commands for testing the various endpoints of the application.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/calls/call-handling-with-vapi-and-twilio.mdx#2025-04-14_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://<public-url>/inbound_call \\\n  -F \"CallSid=CA12345\" \\\n  -F \"Caller=+15551112222\"\n\ncurl -X POST https://<public-url>/connect \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{}\"\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Vapi Showcase in HTML\nDESCRIPTION: HTML iframe code for embedding a YouTube video that showcases Vapi capabilities. The video starts at the 415-second mark and includes standard YouTube embed parameters for security and functionality.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/conferences.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/jag7NjaROck?si=OLFbkgF9YDBw0ufs&amp;start=415\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Partner Directory Card Components in React/JSX\nDESCRIPTION: A series of Card components that display partner company information including logos, titles, and descriptions. Each card is styled consistently with flexbox layout and links to the partner's website.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/expert-directory.mdx#2025-04-14_snippet_1\n\nLANGUAGE: JSX\nCODE:\n```\n<Card\n  href=\"https://otakusolutions.io/\"\n  className=\"ed-card\"\n  style={{\n    alignItems: \"center\",\n    display: \"flex\",\n    flexDirection: \"column\",\n    width: \"auto\",\n  }}\n>\n  <img\n    className=\"card-img bg:white\"\n    noZoom\n    src=\"https://storage.googleapis.com/msgsndr/dBaRxB72IyESkQWGMkmq/media/669a84c7b9609d1964adbae7.jpeg\"\n  />\n  <div className=\"card-content\">\n    <h3>Otaku Solutions</h3>\n    <p>\n      Handle the creation of voice assistants, automations, tracking, and\n      training.\n    </p>\n  </div>\n</Card>\n```\n\n----------------------------------------\n\nTITLE: Implementing Card Group for Video Submission CTA in JSX\nDESCRIPTION: This code snippet creates a call-to-action section using a CardGroup component with a Card that encourages users to submit their own Vapi showcase videos. The card includes a title, icon, and link to a submission form.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/outbound.mdx#2025-04-14_snippet_1\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video iframes in HTML\nDESCRIPTION: HTML markup for embedding multiple YouTube videos showing Vapi demonstrations. Each iframe includes standard YouTube embedding parameters and security settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/appointment-scheduling.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/hCJb11EOdME?si=nMmUXuOnT6psbNBP\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video Grid in HTML\nDESCRIPTION: HTML structure for displaying a grid of responsive YouTube video embeds with security and feature parameters\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/comparisons.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"video-grid\">\n  <iframe\n    src=\"https://www.youtube.com/embed/KloYd6cANkM?si=ssM9ouDeCeyFe1hv\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n```\n\n----------------------------------------\n\nTITLE: Creating a YouTube Video Grid with iframes in HTML\nDESCRIPTION: This code creates a responsive grid layout for displaying multiple YouTube videos using iframe elements. Each iframe is configured with proper YouTube embedding parameters including security attributes.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/usecase.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"video-grid\">\n  <iframe\n    src=\"https://www.youtube.com/embed/WS4QJF9Bn7U?si=yrK1ErRpFZAKbpYW\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    src=\"https://www.youtube.com/embed/ZvPQU1VKmi8?si=neKdm1K8T-Tex56r\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    src=\"https://www.youtube.com/embed/CvhonBxoJ00?si=POAHHoKAvKQx7__O\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    src=\"https://www.youtube.com/embed/lmHMAJxlD0I?si=sHfjjxJxTah21VTR\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    src=\"https://www.youtube.com/embed/5ElOMT7cyJM?si=Pc_XE9CLAZs5qfkZ\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    src=\"https://www.youtube.com/embed/VVKyogARy6A?si=KbKsdCact_ucdKQB\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n</div>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Videos with iframes in HTML\nDESCRIPTION: This snippet demonstrates how to embed multiple YouTube videos using iframe elements within a div container. It includes necessary attributes for video playback and security.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/demos.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"video-grid\">\n  <iframe\n    src=\"https://www.youtube.com/embed/H6qym392wFg?si=GC2anHDMMbPcG7xF\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n\n  <iframe\n    src=\"https://www.youtube.com/embed/Gda0Le__n8g?si=jNEMbdr7WIbf_PQk\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n\n</div>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Videos in HTML Grid\nDESCRIPTION: HTML code for embedding multiple YouTube videos in a responsive grid layout, showcasing Vapi community content. Each iframe contains proper YouTube embedding parameters including width, height, security attributes, and player controls.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/special-mentions.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"video-grid\">\n  <iframe\n    src=\"https://www.youtube.com/embed/WCYf2Agml-s?si=dAMT_Xf7vPHmjqKJ&amp;start=929\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/rc0XGjI4QKM\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/1VzKEEbTYUQ?si=rZjcTPNe4Ro1leQ9\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n\n<iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/nYKFuI6sagw?si=oh9pcwKVnUamEIdV\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n</div>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in HTML\nDESCRIPTION: This code snippet shows how to embed a YouTube video using an iframe in HTML. It includes various attributes for security and functionality.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/inbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/e7q4p8Gg1Tg?si=ZvFumklEMubfbZi7\"\n  title='An embedded YouTube video titled \"Quickstart: Inbound Calling\"'\n  frameborder=\"0\"\n  allow=\"fullscreen; accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  allowfullscreen\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n/>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video for Vapi Showcase in HTML\nDESCRIPTION: This HTML snippet embeds a YouTube video player into the page, showcasing a community-created video about Vapi. The iframe is configured with specific attributes for security and functionality.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/television.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/pRUddK6sxDg?si=pvlgT0ban0lkvHTL\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Responsive YouTube Video Container with Dimensions\nDESCRIPTION: HTML iframe with explicit width and height parameters for responsive video embedding\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/comparisons.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/rc0XGjI4QKM\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n```\n\n----------------------------------------\n\nTITLE: Accessing Call Cost Type in Vapi AI\nDESCRIPTION: Shows how to access the subType property of call costs to determine if a cost is normal or overage\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/changelog/2024-10-09.mdx#2025-04-14_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\ncall.costs[type=vapi].subType\n```\n\n----------------------------------------\n\nTITLE: Creating a Card Group with Links in HTML\nDESCRIPTION: This snippet shows how to create a card group with a single card using custom HTML elements. The card includes a title, icon, and a link to a form for video submissions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/demos.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in HTML\nDESCRIPTION: HTML code for embedding a Langfuse integration tutorial video from YouTube with security and accessibility settings.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/providers/observability/langfuse.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/V4ybHNWvu90?si=QDCINdagfM47Exn4\"\n  title='An embedded YouTube video titled \"Langfuse Integration with Vapi\"'\n  frameborder=\"0\"\n  allow=\"fullscreen; accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  allowfullscreen\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n/>\n```\n\n----------------------------------------\n\nTITLE: Embedding Sized YouTube Video Player\nDESCRIPTION: HTML iframe code for embedding a YouTube video player with specific dimensions (100% width and 315px height) and security parameters.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/ghl.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/DpnC8NX4tas\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Rendering Card Component for Video Submission\nDESCRIPTION: JSX component code for rendering a card interface that links to a video submission form, including an icon and descriptive text.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/ghl.mdx#2025-04-14_snippet_2\n\nLANGUAGE: jsx\nCODE:\n```\n<Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n>\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n</Card>\n```\n\n----------------------------------------\n\nTITLE: Video Embed Wrapper Component\nDESCRIPTION: HTML wrapper div for styling and containing the YouTube video iframe component.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/dashboard.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<div class=\"video-embed-wrapper\">\n  <!-- iframe content here -->\n</div>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in Dashboard\nDESCRIPTION: HTML iframe code for embedding a Vapi Dashboard quickstart video from YouTube with security and functionality parameters.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/quickstart/dashboard.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  src=\"https://www.youtube.com/embed/sFXaTsmMR8s?si=aV-mAdjwkpHchHfT\"\n  title='An embedded YouTube video titled \"Quickstart: Vapi Dashboard\"'\n  frameborder=\"0\"\n  allow=\"fullscreen; accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  allowfullscreen\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n/>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Videos in HTML\nDESCRIPTION: This snippet demonstrates how to embed multiple YouTube videos using iframe elements in HTML. It includes attributes for responsive design, security, and user interaction.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/squads.mdx#2025-04-14_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<div class=\"video-grid\">\n  <iframe\n    src=\"https://www.youtube.com/embed/uT7mW61H0nw?si=eN_n2c2umNNRtxIw\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/n8oFkp0_2qE?si=Egsv56Nfx-Dkl_b4\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/uJ52-EqBscQ?si=GeJJCUcptinCqRRg\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/V308U_5syiA?si=DQycim7-WhzVOsQp\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n\n  <iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/gdNkUESKC5k?si=13psOtVhyjWd6Ww8\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n  />\n  </div>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video in HTML with iframe\nDESCRIPTION: HTML iframe code for embedding YouTube videos on a webpage. The code includes standard YouTube embedding parameters such as width, height, source URL, and various permissions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n        src=\"https://www.youtube.com/embed/ai32iXHj8fc?si=z8PKMD8Dklpg_j0B\"\n        title=\"YouTube video player\"\n        frameborder=\"0\"\n        allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n        referrerpolicy=\"strict-origin-when-cross-origin\"\n        allowfullscreen\n    />\n```\n\n----------------------------------------\n\nTITLE: Rendering Accordion-style FAQ in JSX\nDESCRIPTION: This code snippet demonstrates how to create an accordion-style FAQ section using JSX. It utilizes custom components like AccordionGroup and Accordion to structure the content. Each accordion item contains a question as the title and detailed explanations in the body.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/snippets/faq-snippet.mdx#2025-04-14_snippet_0\n\nLANGUAGE: jsx\nCODE:\n```\n<AccordionGroup>\n  <Accordion title=\"Is Vapi right for my usecase?\" icon=\"hammer\" iconType=\"regular\" defaultOpen={true}>\n\nIf you are **a developer building a voice AI application simulating human conversation** (w/ LLMs  to whatever degree of application complexity)  Vapi is built for you.\n\nWhether you are building for a completely \"turn-based\" use case (like appointment setting), all the way to robust agentic voice applications (like virtual assistants), Vapi is tooled to solve for your voice AI workflow.\n\nVapi runs on any platform: the web, mobile, or even embedded systems (given network access).\n\n  </Accordion>\n  <Accordion title=\"Sounds good, but I'm building a custom X for Y...\" icon=\"face-monocle\" iconType=\"solid\" defaultOpen={false}>\n\nNot a problem, we can likely already support it. Vapi is designed to be modular at every level of the voice pipeline: Text-to-speech, LLM, Speech-to-text.\n\nYou can bring your own custom models for any part of the pipeline.\n\n- **If they're hosted with one of our providers:** you just need to add your [provider keys](customization/provider-keys), then specify the custom model in your API requests.\n- **If they are hosted elsewhere:** you can use the `Custom LLM` provider and specify the [URL to your model](customization/custom-llm/fine-tuned-openai-models) in your API request.\n\nEverything is interchangeable, mix & match to suit your usecase.\n\n  </Accordion>\n  <Accordion title=\"Couldn't I build this myself and save money?\" icon=\"piggy-bank\" iconType=\"solid\" defaultOpen={false}>\n\nYou could (and the person writing this right now did, from scratch)  but there are good reasons for not doing so.\n\nWriting a great realtime voice AI application from scratch is a fairly challenging task (more on those challenges [here](/challenges-of-realtime-conversation)). Most of these challenges are not apparent until you face them, then you realize you are 3 weeks into a rabbit hole that may take months to properly solve out of.\n\nThink of Vapi as hiring a software engineering team for this hard problem, while you focus on what uniquely generates value for your voice AI application.\n\n---\n\nBut to address cost, the vast majority of cost in running your application will come from provider cost (Speect-to-text, LLM, Text-to-speech) direct with vendors (Deepgram, OpenAI, ElevenLabs, etc)  where we add no fee (vendor cost passes-through). These would have to be incurred anyway.\n\nVapi only charges its small fee on top of these for the continuous maintenance & improvement of these hardest components of your system (which would have costed you time to write/maintain).\n\nNo matter what, some cost is inescapable (in money, time, etc) to solve this challenging technical problem.\n\nOur focus is solely on foundational Voice AI orchestration, & it's what we put our full time and resources into.\n\nTo learn more about Vapi's pricing, you can visit our [pricing page](/pricing).\n\n  </Accordion>\n  <Accordion title=\"Is it going to be hard to set up?\" icon=\"gear\" iconType=\"solid\" defaultOpen={false}>\n\n    No  in fact, the setup could not be easier:\n    - **Web Dashboard:** It can take minutes to get up & running with our [dashboard](https://dashboard.vapi.ai/).\n    - **Client SDKs:** You can start calls with 1 line of code with any of our [client SDKs](/sdks).\n\n    For more advanced features like function calling, you will have to set up a [Server URL](/server-url) to receive and respond to messages.\n\n  </Accordion>\n  <Accordion title=\"How is Vapi different from other Voice AI services?\" icon=\"bowling-pins\" iconType=\"solid\" defaultOpen={false}>\n\n    Vapi focuses on developers. Giving developers modular, simple, & robust tooling to build any voice AI application imaginable.\n\n    Vapi also has some of the lowest latency & (equally important) highest reliability amongst any other voice AI platform built for developers.\n\n  </Accordion>\n</AccordionGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Videos with React/JSX Components\nDESCRIPTION: A series of iframe components for embedding YouTube videos with standardized security and display settings. Each iframe includes cross-origin policies, playback controls, and responsive dimensions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/guide.mdx#2025-04-14_snippet_0\n\nLANGUAGE: JSX\nCODE:\n```\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/video_id\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Generating Python SDK for Local Development\nDESCRIPTION: Command to generate the Python SDK locally for development and testing purposes. This creates a preview version with detailed logging for debugging.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nfern generate --api api --group python-sdk --preview --log-level debug\n```\n\n----------------------------------------\n\nTITLE: Creating Responsive Card Group Layout in Markdown\nDESCRIPTION: Markdown code for creating a card group with a call-to-action card that encourages users to submit their videos showcasing Vapi. The card includes a title, icon, and link to a submission form.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/podcast.mdx#2025-04-14_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Embedding Tavus Tutorial Video with HTML iframe\nDESCRIPTION: HTML iframe code for embedding a Loom video tutorial that demonstrates the Tavus integration process. The iframe includes security attributes and responsive dimensions.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-voices/tavus.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    src=\"https://www.loom.com/embed/f3f8a6f3ec0d46c79874ee9e032ae332?sid=981ef281-a30b-46e3-ac19-1a2b2b176511\"\n    title=\"Loom video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    width=\"100%\"\n    height=\"400px\"\n    allowfullscreen\n  />\n```\n\n----------------------------------------\n\nTITLE: Displaying Terms of Service Link in Markdown\nDESCRIPTION: Markdown code that creates a section with a link to Vapi AI's Terms of Service using a custom Check component wrapper.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/security-and-privacy/tos.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n<Check>\n  Our Terms of Service is hosted at\n  [https://vapi.ai/terms-of-service](https://vapi.ai/terms-of-service)\n</Check>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Width and Height Specifications\nDESCRIPTION: HTML iframe code for embedding YouTube videos with specific width and height parameters. The code sets the video to display at 100% width and 315 pixels height.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/mPC-YOmidqE\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Pricing Page Frontmatter in Markdown\nDESCRIPTION: Markdown frontmatter defining the page metadata including title, subtitle, and slug for the pricing documentation page.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/pricing.mdx#2025-04-14_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n---\ntitle: Startup Pricing\nsubtitle: This is an overview of our pricing for developers and startups. For Enterprise pricing, please contact sales.\nslug: pricing\n---\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Query Parameters\nDESCRIPTION: HTML iframe code for embedding YouTube videos that includes additional query parameters in the source URL. This example uses the 'si' parameter for tracking or session identification.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_3\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/NCjdEREIyR8?si=bKiyp65Qisbbq_4r\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Interactive Card Component in Markdown\nDESCRIPTION: Markdown/MDX card component for displaying a call-to-action to submit videos\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/comparisons.mdx#2025-04-14_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Previewing Documentation\nDESCRIPTION: Command to generate and preview the documentation before deployment. This creates a preview version that can be reviewed before publishing.\nSOURCE: https://github.com/VapiAI/docs/blob/main/advanced.md#2025-04-14_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nfern generate --docs --preview\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Different Query Parameter\nDESCRIPTION: HTML iframe code with an alternative query parameter value in the YouTube embed URL. This demonstrates another variation of the YouTube embedding code with a different video ID and tracking parameter.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_4\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n  width=\"100%\"\n  height=\"315\"\n  src=\"https://www.youtube.com/embed/Kg1sOISqKiE?si=kdpFMfFq6w13c__Z\"\n  title=\"YouTube video player\"\n  frameborder=\"0\"\n  allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n  referrerpolicy=\"strict-origin-when-cross-origin\"\n  allowfullscreen\n/>\n```\n\n----------------------------------------\n\nTITLE: Embedding YouTube Video with Alternative Formatting\nDESCRIPTION: HTML iframe code with different indentation for embedding YouTube videos. This demonstrates another formatting style while maintaining the same functionality for video embedding.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/inbound.mdx#2025-04-14_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    width=\"100%\"\n    height=\"315\"\n    src=\"https://www.youtube.com/embed/xsDc8ALGaeE\"\n    title=\"YouTube video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    allowfullscreen\n\n/>\n```\n\n----------------------------------------\n\nTITLE: Card Component Implementation\nDESCRIPTION: MDX/JSX markup for rendering a card component that contains a link to submit community videos. Uses a CardGroup container with specific styling properties.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/community/appointment-scheduling.mdx#2025-04-14_snippet_1\n\nLANGUAGE: JSX\nCODE:\n```\n<CardGroup cols={2}>\n  <Card\n    title=\"Send Us Your Video\"\n    icon=\"video-arrow-up-right\"\n    iconType=\"solid\"\n    href=\"https://tally.so/r/3yD9Wx\"\n  >\n    Send us your video showcasing what Vapi can do, we'd like to feature it.\n  </Card>\n</CardGroup>\n```\n\n----------------------------------------\n\nTITLE: Running Local Development Server with Fern for Vapi Documentation\nDESCRIPTION: Command to start a local development server with hot-reloading for working on Vapi documentation.\nSOURCE: https://github.com/VapiAI/docs/blob/main/README.md#2025-04-14_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nfern docs dev\n```\n\n----------------------------------------\n\nTITLE: Embedding Elevenlabs Tutorial Video with HTML iframe\nDESCRIPTION: HTML iframe code for embedding a Loom video tutorial that demonstrates the Elevenlabs voice integration process. The iframe includes necessary attributes for security, responsiveness, and cross-origin resource sharing.\nSOURCE: https://github.com/VapiAI/docs/blob/main/fern/customization/custom-voices/elevenlabs.mdx#2025-04-14_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<iframe\n    src=\"https://www.loom.com/embed/91568c17289740889c278f458f0d291c?sid=a0c812fa-5809-4ffa-8391-6a578c3e0608\"\n    title=\"Loom video player\"\n    frameborder=\"0\"\n    allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"\n    referrerpolicy=\"strict-origin-when-cross-origin\"\n    width=\"100%\"\n    height=\"400px\"\n    allowfullscreen\n  />\n```\n\n----------------------------------------\n\nTITLE: Previewing Vapi Documentation Changes with Fern\nDESCRIPTION: Command to preview documentation changes before publishing. Creates a preview link to review updates before they go live.\nSOURCE: https://github.com/VapiAI/docs/blob/main/README.md#2025-04-14_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n# npm install -g fern-api\nfern generate --docs --preview\n```"
  }
]