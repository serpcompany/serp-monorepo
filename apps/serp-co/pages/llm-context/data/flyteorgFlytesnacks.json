[
  {
    "owner": "flyteorg",
    "repo": "flytesnacks",
    "content": "TITLE: DataFrame Validation Using Pandera Schema\nDESCRIPTION: Example demonstrating how to define and use a Pandera schema for validating pandas DataFrame columns with type constraints and custom validation rules. The code shows schema definition, data processing function, and successful execution with valid data.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/pandera_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport pandera as pa\nfrom pandera.typing import DataFrame, Series\n\nclass Schema(pa.SchemaModel):\n    column_1: Series[int] = pa.Field(ge=0)\n    column_2: Series[float] = pa.Field(gt=0, lt=100)\n    column_3: Series[str] = pa.Field(str_startswith=\"prefix\")\n\n    @pa.check(\"column_3\")\n    def check_str_length(cls, series):\n        return series.str.len() > 5\n\n@pa.check_types\ndef processing_fn(df: DataFrame[Schema]) -> DataFrame[Schema]:\n    df[\"column_1\"] = df[\"column_1\"] * 2\n    df[\"column_2\"] = df[\"column_2\"] * 0.5\n    df[\"column_3\"] = df[\"column_3\"] + \"_suffix\"\n    return df\n\nraw_df = pd.DataFrame({\n   \"column_1\": [1, 2, 3],\n   \"column_2\": [1.5, 2.21, 3.9],\n   \"column_3\": [\"prefix_a\", \"prefix_b\", \"prefix_c\"],\n})\nprocessed_df = processing_fn(raw_df)\nprint(processed_df)\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Flyte Tasks and Workflow\nDESCRIPTION: Creates simple task and workflow definitions with string inputs and outputs\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import task, workflow\n\n@task\ndef hello(name: str) -> str:\n    return f\"Hello {name}!\"\n\n@task\ndef world(pre: str) -> str:\n    return f\"{pre} Welcome to the Jupyter Notebook!\"\n\n@workflow\ndef wf(name: str) -> str:\n    return world(pre=hello(name=name))\n```\n\n----------------------------------------\n\nTITLE: Training and Evaluating GradientBoostingRegressor Model in Python\nDESCRIPTION: Instantiates and evaluates a GradientBoostingRegressor model with the previously defined hyperparameters. The model is evaluated using 10-fold cross-validation, and the mean absolute error (MAE) is calculated and displayed.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngb_model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_split=min_samples_split, random_state=random_state)\n\nmae_score = cross_validate(gb_model, 10, X_train, y_train)\nprint(\"MAE Score: \", mae_score)\n```\n\n----------------------------------------\n\nTITLE: Creating Cross-Validation Function for Regression Metrics in Python\nDESCRIPTION: Defines a cross-validation function that evaluates model performance using mean absolute error (MAE). The function utilizes scikit-learn's cross_val_score and returns the mean MAE across all folds.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold, cross_val_score\n\n\ndef cross_validate(model, nfolds, feats, targets):\n    score = -1 * (cross_val_score(model, feats, targets, cv=nfolds, scoring='neg_mean_absolute_error'))\n    return np.mean(score)\n```\n\n----------------------------------------\n\nTITLE: Workflow Execution and Monitoring\nDESCRIPTION: Demonstrates workflow execution with remote interface and output monitoring\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n# Execute the workflow and wait for it to complete\nexe = remote.execute(wf, inputs={\"name\": \"world\"})\n\n# Wait for the task to complete\nexe = exe.wait(poll_interval=1)\n\n# Print the outputs\nprint(exe.outputs)\n```\n\n----------------------------------------\n\nTITLE: Profiling Data with WhyLogs in Flyte\nDESCRIPTION: This snippet shows how to create a Flyte task that profiles a pandas DataFrame using whylogs and returns a DatasetProfileView.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef profiling_task(data: pd.DataFrame) -> DatasetProfileView:\n    results = why.log(data)\n    return results.view()\n```\n\n----------------------------------------\n\nTITLE: Defining Workflow with Map Task\nDESCRIPTION: Creates a workflow using map_task to process lists of inputs in parallel\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import task, workflow, map_task\nfrom functools import partial\n\n@task\ndef fn(x: int, y: int) -> int:\n    return x + y + 2\n\n@workflow\ndef workflow_with_maptask(data: list[int], y: int) -> list[int]:\n    partial_fn = partial(fn, y=y)\n    return map_task(partial_fn)(x=data)\n```\n\n----------------------------------------\n\nTITLE: Generating Predictions with Trained Model\nDESCRIPTION: Uses the trained model to generate predictions on the features retrieved from the online store, demonstrating model deployment capabilities.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_10\n\nLANGUAGE: python\nCODE:\n```\npredict(model_ser=model, features=inference_point)\n```\n\n----------------------------------------\n\nTITLE: Consuming WhyLogs Profile View in Flyte\nDESCRIPTION: This snippet demonstrates how to create a Flyte task that consumes a DatasetProfileView and converts it back to a pandas DataFrame.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@task\ndef consume_profile_view(profile_view: DatasetProfileView) -> pd.DataFrame:\n    return profile_view.to_pandas()\n```\n\n----------------------------------------\n\nTITLE: Specifying GPU Requirements for PyTorch Tasks in Flyte\nDESCRIPTION: This code snippet demonstrates how to request GPU resources for a Flyte task. It uses the Resources class to specify both requests and limits for GPU allocation, which is essential for deep learning tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mnist_classifier/README.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task\n\n@task(requests=Resources(gpu=\"1\"), limits=Resources(gpu=\"1\"))\ndef my_deep_learning_task():\n    ...\n```\n\n----------------------------------------\n\nTITLE: Markdown Overview of Advanced Flytekit Features\nDESCRIPTION: A markdown heading and description introducing advanced composition features in the Flytekit Python SDK, including conditions, subworkflows, dynamic workflows, map tasks, and gate nodes.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/advanced_composition/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Advanced Composition\n\nThese examples introduce the advanced features of the Flytekit Python SDK.\nThey cover more complex aspects of Flyte, including conditions, subworkflows,\ndynamic workflows, map tasks, gate nodes and more.\n```\n\n----------------------------------------\n\nTITLE: Model Training Examples Table in Markdown\nDESCRIPTION: List table showing various machine learning examples with their descriptions, including diabetes classification, house price prediction, MNIST classification, NLP processing, and sales forecasting.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/model_training/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Diabetes Classification </auto_examples/pima_diabetes/index>`\n  - Train an XGBoost model on the Pima Indians Diabetes Dataset.\n* - {doc}`House Price Regression </auto_examples/house_price_prediction/index>`\n  - Use dynamic workflows to train a multiregion house price prediction model using XGBoost.\n* - {doc}`MNIST Classification </auto_examples/mnist_classifier/index>`\n  - Train a neural network on MNIST with PyTorch and W&B\n* - {doc}`NLP Processing with Gensim </auto_examples/nlp_processing/index>`\n  - Word embedding and topic modelling on lee background corpus with Gensim\n* - {doc}`Forecast Sales Using Rossmann Store Sales </auto_examples/forecasting_sales/index>`\n  - Forecast sales data with data-parallel distributed training using Horovod on Spark.\n```\n\n----------------------------------------\n\nTITLE: Feature Scaling with RobustScaler in Python\nDESCRIPTION: Scales the training and test datasets using RobustScaler to normalize feature values. RobustScaler is chosen here because it's more robust to outliers compared to StandardScaler.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nscaler = RobustScaler()\n\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train) \nX_test = scaler.transform(X_test)\n\nX_train[:5, :5]\n```\n\n----------------------------------------\n\nTITLE: Setting Hyperparameters for GradientBoostingRegressor in Python\nDESCRIPTION: Defines the hyperparameters for the GradientBoostingRegressor model, including number of estimators, maximum depth, feature selection method, minimum samples for split, and random state for reproducibility.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nn_estimators=150\nmax_depth=3\nmax_features='sqrt'\nmin_samples_split=4\nrandom_state=2\n```\n\n----------------------------------------\n\nTITLE: Creating a Snowflake Query Task in Python\nDESCRIPTION: Demonstrates how to create a Snowflake query task using a custom SnowflakeTask class. This task can be used within a Flyte workflow to execute SQL queries and return results as a pandas DataFrame.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/extending/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nquery_task = SnowflakeTask(\n    query=\"Select * from x where x.time < {{.inputs.time}}\",\n    inputs=kwtypes(time=datetime),\n    output_schema_type=pandas.DataFrame,\n)\n\n@workflow\ndef my_wf(t: datetime) -> ...:\n    df = query_task(time=t)\n    return process(df=df)\n```\n\n----------------------------------------\n\nTITLE: Loading and Splitting Supermarket Sales Dataset in Python\nDESCRIPTION: Loads the supermarket sales dataset from a JSON string, extracts the target variable, and splits the data into training and test sets. The target variable is 'Product_Supermarket_Sales', and the test set size is set to 30%.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndataset = pd.DataFrame.from_dict(json.loads(dataset))\ny_target = dataset['Product_Supermarket_Sales']\ndataset.drop(['Product_Supermarket_Sales'], axis=1, inplace=True)\n\nX_train, X_test, y_train, y_test = train_test_split(dataset, y_target, test_size = 0.3)\n\nprint(\"Training data is\", X_train.shape)\nprint(\"Training target is\", y_train.shape)\nprint(\"test data is\", X_test.shape)\nprint(\"test target is\", y_test.shape)\n```\n\n----------------------------------------\n\nTITLE: Recording Model Performance Metrics with Flyte Papermill Plugin in Python\nDESCRIPTION: Uses Flyte's papermill plugin to record the model's MAE score as a float value. This allows the metric to be tracked and used in the Flyte workflow system.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekitplugins.papermill import record_outputs\nrecord_outputs(mae_score=float(mae_score))\n```\n\n----------------------------------------\n\nTITLE: Defining Input Parameters in Papermill Notebook\nDESCRIPTION: The cell with the 'parameters' tag defines the input parameters to the notebook that can be injected by Papermill during execution.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/papermill_plugin/papermill_plugin/nb_simple.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nv = 3.14\n```\n\n----------------------------------------\n\nTITLE: Implementing MLflow Autolog with Flyte Task\nDESCRIPTION: Python code showing how to add MLflow autologging to a Flyte task using the @mlflow_autolog decorator, which automatically logs metrics and parameters to Flyte deck.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mlflow_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@task(enable_deck=True)\n@mlflow_autolog(framework=mlflow.keras)\ndef train_model(epochs: int):\n...\n```\n\n----------------------------------------\n\nTITLE: Setting up Flyte Remote Connection\nDESCRIPTION: Configures connection to Flyte backend using FlyteRemote with sandbox configuration and interactive mode enabled\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit.remote import FlyteRemote\nfrom flytekit.configuration import Config\n\n# The `for_sandbox` method instantiates a connection to the demo cluster.\nremote = FlyteRemote(\n    Config.for_sandbox(), \n    default_project=\"flytesnacks\", \n    default_domain=\"development\", \n    interactive_mode_enabled=True,  # This is not necessary if you are in a notebook.\n)\n```\n\n----------------------------------------\n\nTITLE: Testing MMCloud Agent Locally with AsyncAgentExecutorMixin\nDESCRIPTION: Guidance for local testing of the MMCloud agent by creating a class that inherits from AsyncAgentExecutorMixin. This approach allows flytekit to mimic FlytePropeller's behavior when calling the agent.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mmcloud_agent/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Example implementation would inherit from AsyncAgentExecutorMixin\n# from flytekit.extend.backend.base_agent import AsyncAgentExecutorMixin\n# \n# class MyMMCloudAgent(AsyncAgentExecutorMixin):\n#     ...\n```\n\n----------------------------------------\n\nTITLE: Configuring MLflow Remote Server in Flyte\nDESCRIPTION: YAML configuration for setting up the MLFLOW_TRACKING_URI environment variable in the Flyte Propeller ConfigMap to enable logging to a remote MLflow server.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mlflow_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  k8s:\n    default-cpus: 100m\n    default-env-vars:\n    - MLFLOW_TRACKING_URI: postgresql+psycopg2://postgres:@postgres.flyte.svc.cluster.local:5432/flyteadmin\n```\n\n----------------------------------------\n\nTITLE: Submitting Ray Job to Existing Cluster in Python\nDESCRIPTION: Python code snippet demonstrating how to submit a Ray job to an existing cluster using Flyte. It includes a remote Ray function and a Flyte task with RayJobConfig.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/ray_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport ray\nfrom flytekit import task\nfrom flytekitplugins.ray import RayJobConfig\n\n@ray.remote\ndef f(x):\n    return x * x\n\n@task(\n    task_config=RayJobConfig(\n        address=<RAY_CLUSTER_ADDRESS>\n        runtime_env={\"pip\": [\"numpy\", \"pandas\"]}\n    )\n)\ndef ray_task() -> typing.List[int]:\n    futures = [f.remote(i) for i in range(5)]\n    return ray.get(futures)\n```\n\n----------------------------------------\n\nTITLE: Installing PyTorch ONNX Plugin for Flytekit\nDESCRIPTION: Command to install the Flytekit plugin for converting PyTorch models to ONNX format. This plugin enables interoperability between PyTorch and other ML frameworks through the ONNX standard.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/onnx_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-onnxpytorch\n```\n\n----------------------------------------\n\nTITLE: Creating Ray Cluster Managed by Flyte in Python\nDESCRIPTION: Python code snippet showing how to create a Ray cluster managed by Flyte and run a Ray job on it. It uses RayJobConfig with WorkerNodeConfig to specify cluster configuration.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/ray_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport ray\nfrom flytekit import task\nfrom flytekitplugins.ray import RayJobConfig, WorkerNodeConfig, HeadNodeConfig\n\n@task(task_config=RayJobConfig(worker_node_config=[WorkerNodeConfig(group_name=\"test-group\", replicas=10)]))\ndef ray_task() -> typing.List[int]:\n    futures = [f.remote(i) for i in range(5)]\n    return ray.get(futures)\n```\n\n----------------------------------------\n\nTITLE: Installing ScikitLearn ONNX Plugin for Flytekit\nDESCRIPTION: Command to install the Flytekit plugin for converting ScikitLearn models to ONNX format. This plugin enables interoperability between ScikitLearn and other ML frameworks through the ONNX standard.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/onnx_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-onnxpytorch\n```\n\n----------------------------------------\n\nTITLE: Creating WhyLogs Constraints Report in Flyte\nDESCRIPTION: This snippet demonstrates how to create a Constraints Report using WhylogsConstraintsRenderer, add constraints, and display the report in a Flyte Deck.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom whylogs.core.constraints.factories import greater_than_number\n\n@task\ndef constraints_report(profile_view: DatasetProfileView) -> bool:\n    builder = ConstraintsBuilder(dataset_profile_view=profile_view)\n    builder.add_constraint(greater_than_number(column_name=\"my_column\", number=10.0))\n\n    constraints = builder.build()\n\n    renderer = WhylogsConstraintsRenderer()\n    flytekit.Deck(\"constraints\", renderer.to_html(constraints=constraints))\n\n    return constraints.validate()\n```\n\n----------------------------------------\n\nTITLE: Configuring an AWS Batch Task in Flyte\nDESCRIPTION: Example showing how to configure and create an AWS Batch task in Flyte. This includes setting parameters, platform capabilities, tag propagation, retry strategy, custom tags, and timeouts.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/aws_batch_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekitplugins.awsbatch import AWSBatchConfig\n\nconfig = AWSBatch(\n    parameters={\"codec\": \"mp4\"},\n    platformCapabilities=\"EC2\",\n    propagateTags=True,\n    retryStrategy={\"attempts\": 10},\n    tags={\"hello\": \"world\"},\n    timeout={\"attemptDurationSeconds\": 60},\n)\n\n@task(task_config=config)\ndef t1(a: int) -> str:\n    return str(a)\n```\n\n----------------------------------------\n\nTITLE: Syncing Workflow Execution Results\nDESCRIPTION: Synchronizes with the completed workflow execution to retrieve outputs and intermediate node results, then prints the execution status.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit.models.core.execution import WorkflowExecutionPhase\n\nsynced_execution = remote.sync(execution, sync_nodes=True)\nprint(f\"Execution {synced_execution.id.name} is in {WorkflowExecutionPhase.enum_to_string(synced_execution.closure.phase)} phase\")\n```\n\n----------------------------------------\n\nTITLE: Loading Features from Online Feature Store\nDESCRIPTION: Retrieves features from the online feature store using the repository configuration and specific data point ID for inference.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom feast_workflow import predict, FEAST_FEATURES, retrieve_online\n\ninference_point = retrieve_online(\n    repo_config=repo_config,\n    online_store=synced_execution.node_executions[\"n4\"].outputs[\"o0\"],\n    data_point=533738,\n)\ninference_point\n```\n\n----------------------------------------\n\nTITLE: Running FileSensor Example on Flyte Cluster\nDESCRIPTION: Command to run the file sensor example on a remote Flyte cluster. It uses pyflyte to execute a workflow defined in a Python script hosted on GitHub.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/sensor/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote \\\n  https://raw.githubusercontent.com/flyteorg/flytesnacks/master/examples/sensor/sensor/file_sensor_example.py wf\n```\n\n----------------------------------------\n\nTITLE: PyTorch Dockerfile with GPU Support\nDESCRIPTION: This Dockerfile uses an NVIDIA GPU image as base and installs the necessary dependencies for running PyTorch with GPU support. It's designed for deploying PyTorch models in a GPU-enabled environment.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mnist_classifier/README.md#2025-04-16_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\nFROM nvidia/cuda:11.0.3-base-ubuntu20.04\n\nWORKDIR /root\nENV DEBIAN_FRONTEND=noninteractive\n\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    cmake \\\n    wget \\\n    curl \\\n    git \\\n    python3.8 \\\n    python3.8-dev \\\n    python3.8-venv \\\n    python3-pip \\\n    --no-install-recommends \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\nRUN python3.8 -m pip install --upgrade pip && \\\n    ln -s /usr/bin/python3.8 /usr/bin/python\n\nWORKDIR /root\nCOPY ml_training/requirements.txt /root/\n\nRUN pip install -r /root/requirements.txt\n# Install flytekit and extras\nARG FLYTEKIT_VERSION=\"0.18.0\"\nRUN pip install flytekitplugins-deck-standard flytekit==${FLYTEKIT_VERSION}\n\nWORKDIR /root\n```\n\n----------------------------------------\n\nTITLE: Local Testing Approach for Databricks Agent\nDESCRIPTION: Guidance for local testing of the Databricks agent by creating a class that inherits from AsyncAgentExecutorMixin. This approach allows flytekit to simulate FlytePropeller's behavior when calling the agent.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/databricks_agent/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Note: This is a conceptual implementation, not actual code\n# Create a class for agent task that inherits from AsyncAgentExecutorMixin\n# Example: class MyDatabricksTask(AsyncAgentExecutorMixin): ...\n```\n\n----------------------------------------\n\nTITLE: Adjusting Resource Requests for MPI Workers\nDESCRIPTION: Code snippet showing how to adjust CPU and memory resource requests for MPI worker pods to prevent scheduling failures due to resource constraints.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfmpi_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nrequests=Resources(cpu=\"<your_cpu_request>\", mem=\"<your_mem_request>\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Labels and Annotations for Dask Workflows\nDESCRIPTION: Python code showing how to set labels and annotations in a launch plan that will be inherited by all components of the Dask job, including pods for the job runner, scheduler, and workers.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task, workflow, Labels, Annotations\nfrom flytekitplugins.dask import Dask\n\n@task(task_config=Dask())\ndef my_dask_task():\n   ...\n\n@workflow\ndef my_dask_workflow():\n   my_dask_task()\n\n# Labels and annotations will be passed on to all dask cluster components\nmy_launch_plan = my_dask_workflow.create_launch_plan(\n  labels=Labels({\"myexecutionlabel\": \"bar\", ...}),\n  annotations=Annotations({\"region\": \"SEA\", ...}),\n)\n```\n\n----------------------------------------\n\nTITLE: Pip Requirements Dependencies List\nDESCRIPTION: Comprehensive list of Python package dependencies with pinned versions, generated via pip-compile from dev-requirements.in. Includes packages for AWS, Azure, Google Cloud, data processing, and development tools.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/dev-requirements.txt#2025-04-16_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\nadlfs==2024.7.0\naiobotocore==2.15.1\naiohappyeyeballs==2.4.3\naiohttp==3.10.8\naioitertools==0.12.0\naiosignal==1.3.1\nattrs==24.2.0\nautoflake==2.3.1\nazure-core==1.31.0\nazure-datalake-store==0.0.53\nazure-identity==1.18.0\nazure-storage-blob==12.23.1\nbotocore==1.35.23\ncachetools==5.5.0\ncertifi==2024.8.30\ncffi==1.17.1\ncfgv==3.4.0\ncharset-normalizer==3.3.2\nclick==8.1.7\ncloudpickle==3.0.0\ncodespell==2.3.0\ncoverage==7.6.1\ncroniter==3.0.3\ncryptography==43.0.1\ndask[array,dataframe]==2024.9.1\ndask-expr==1.1.15\ndataclasses-json==0.5.9\ndecorator==5.1.1\ndiskcache==5.6.3\ndistlib==0.3.8\ndocker==7.1.0\ndocstring-parser==0.16\nfilelock==3.16.1\nflyteidl==1.13.4\nflytekit==1.13.7\n```\n\n----------------------------------------\n\nTITLE: Pandera Schema Validation Error Example\nDESCRIPTION: Example showing how Pandera handles invalid data validation with detailed error messages. The code demonstrates the validation failure when passing invalid data that violates the schema constraints.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/pandera_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ninvalid_df = pd.DataFrame({\n   \"column_1\": [-1, 2, -3],\n   \"column_2\": [1.5, 2.21, 3.9],\n   \"column_3\": [\"prefix_a\", \"prefix_b\", \"prefix_c\"],\n})\nprocessing_fn(invalid_df)\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte OpenAI Plugin for ChatGPT Agent in Bash\nDESCRIPTION: Command to install the Flyte plugin for OpenAI which enables ChatGPT agent functionality. This pip command adds the necessary dependencies to use OpenAI's models within Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/chatgpt_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-openai\n```\n\n----------------------------------------\n\nTITLE: Running Distributed PyTorch Training Workflow in Flyte\nDESCRIPTION: This command executes a distributed PyTorch training workflow on a remote Flyte cluster using the pytorch_mnist.py script.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfpytorch_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote pytorch_mnist.py pytorch_training_wf\n```\n\n----------------------------------------\n\nTITLE: Python Dependencies List with Version Requirements\nDESCRIPTION: A requirements.txt style file listing package dependencies with pinned versions and their dependency relationships. Each package is specified with an exact version and includes comments indicating which packages require it as a dependency.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs-requirements.txt#2025-04-16_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\naccessible-pygments==0.0.5\n    # via pydata-sphinx-theme\nadlfs==2024.7.0\n    # via flytekit\naiobotocore==2.15.1\n    # via s3fs\naiohappyeyeballs==2.4.3\n    # via aiohttp\naiohttp==3.10.8\n    # via\n    #   adlfs\n    #   aiobotocore\n    #   gcsfs\n    #   s3fs\n```\n\n----------------------------------------\n\nTITLE: Running Horovod Training Workflow on Flyte Cluster\nDESCRIPTION: Command to execute a Horovod training workflow on a remote Flyte cluster. It uses a pre-built Docker image and references the workflow definition file from the GitHub repository.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfmpi_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote \\\n  --image ghcr.io/flyteorg/flytecookbook:kfmpi_plugin-latest \\\n  https://raw.githubusercontent.com/flyteorg/flytesnacks/master/examples/kfmpi_plugin/kfmpi_plugin/mpi_mnist.py \\\n  horovod_training_wf\n```\n\n----------------------------------------\n\nTITLE: Setting AWS Environment Variables for Flytekit\nDESCRIPTION: Configures the AWS environment variables required for Flytekit to connect to a local MinIO instance, which serves as the S3-compatible storage for Feast and Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nos.environ[\"FLYTE_AWS_ENDPOINT\"] = os.environ[\"FEAST_S3_ENDPOINT_URL\"] = \"http://localhost:30084/\"\nos.environ[\"FLYTE_AWS_ACCESS_KEY_ID\"] = os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\nos.environ[\"FLYTE_AWS_SECRET_ACCESS_KEY\"] = os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"miniostorage\"\n```\n\n----------------------------------------\n\nTITLE: Running PyTorch Lightning Training Workflow in Flyte\nDESCRIPTION: This command runs a PyTorch Lightning training workflow on a remote Flyte cluster using the pytorch_lightning_mnist_autoencoder.py script.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfpytorch_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote pytorch_lightning_mnist_autoencoder.py train_workflow\n```\n\n----------------------------------------\n\nTITLE: Running DataFrame Passing Example Remotely\nDESCRIPTION: Command to execute the DataFrame passing example remotely on a Flyte cluster using the pyflyte CLI tool.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_spark_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote dataframe_passing.py \\\n  my_smart_structured_dataset\n```\n\n----------------------------------------\n\nTITLE: Generating pip-compiled requirements file for Flytesnacks documentation using Python 3.12\nDESCRIPTION: This comment block documents how the requirements file was automatically generated using pip-compile with Python 3.12, specifying the input file as docs-requirements.in.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs-requirements.txt#2025-04-16_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n#\n# This file is autogenerated by pip-compile with Python 3.12\n# by the following command:\n#\n#    pip-compile docs-requirements.in\n```\n\n----------------------------------------\n\nTITLE: Installing Horovod with TensorFlow and Spark Support\nDESCRIPTION: Command to install Horovod with MPI, TensorFlow, and Spark integration. The installation enables the MPI environment and TensorFlow support necessary for distributed training.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/forecasting_sales/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nHOROVOD_WITH_MPI=1 HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod[spark,tensorflow]==0.22.1\n```\n\n----------------------------------------\n\nTITLE: Executing Map Task Workflow\nDESCRIPTION: Shows how to execute and monitor a workflow containing a map_task\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n# Execute the workflow with map_task and wait for it to complete\nout = remote.execute(workflow_with_maptask, inputs={\"data\": [1, 2, 3], \"y\": 4})\n\n# Wait for the task to complete\nout = out.wait(poll_interval=1)\n\n# Print the outputs\nprint(out.outputs)\n```\n\n----------------------------------------\n\nTITLE: Table of Contents Structure for Databricks Plugin Documentation in Markdown\nDESCRIPTION: Defines a hidden table of contents structure that links to the databricks_plugin_example page. This is used to organize the documentation section for the deprecated Databricks plugin.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/databricks_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:hidden:\n\ndatabricks_plugin_example\n```\n```\n\n----------------------------------------\n\nTITLE: Executing and Monitoring Flyte Task\nDESCRIPTION: Demonstrates task execution with remote interface, including URL printing and output monitoring\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Execute the task\nexe = remote.execute(hello, inputs={\"name\": \"Flyte\"})\n\n# This will print the URL to the console\nprint(exe.execution_url)\n\n# Wait for the task to complete\nexe = exe.wait(poll_interval=1)\n\n# Print the outputs\nprint(exe.outputs)\n```\n\n----------------------------------------\n\nTITLE: Running TensorFlow MNIST Example Workflow\nDESCRIPTION: Command to execute the MNIST TensorFlow workflow example remotely on a Flyte cluster.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kftensorflow_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote tf_mnist.py \\\n  mnist_tensorflow_workflow\n```\n\n----------------------------------------\n\nTITLE: Running Ray Example on Flyte Cluster\nDESCRIPTION: Command to run the Ray example on a Flyte cluster using pyflyte. This command executes the ray_workflow function from the ray_example.py file with a parameter n set to 10.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/ray_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote ray_example.py \\\n    ray_workflow --n 10\n```\n\n----------------------------------------\n\nTITLE: Executing the Feast Workflow\nDESCRIPTION: Executes the Feast workflow with specified input parameters using FlyteRemote. The wait parameter ensures the operation blocks until completion.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nexecution = remote.execute(\n    lp,\n    inputs={\"num_features_univariate\": 5},\n    wait=True\n)\n```\n\n----------------------------------------\n\nTITLE: Installing MMCloud Agent for Flyte\nDESCRIPTION: Command to install the MMCloud agent plugin for Flyte using pip. This installs the necessary dependencies to integrate Flyte with Memory Machine Cloud.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mmcloud_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-mmcloud\n```\n\n----------------------------------------\n\nTITLE: Enabling Backend Plugins in FlytePropeller Configuration\nDESCRIPTION: This YAML configuration demonstrates how to enable backend plugins in FlytePropeller by specifying the plugin IDs in the 'enabled-plugins' list under the 'tasks > task-plugins' section.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\ntasks:\n  task-plugins:\n    enabled-plugins:\n      - container\n      - sidecar\n      - k8s-array\n    default-for-task-types:\n      container: container\n      sidecar: sidecar\n      container_array: k8s-array\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte MLflow Plugin\nDESCRIPTION: Command to install the Flytekitplugins-mlflow package which enables MLflow integration with Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mlflow_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-mlflow\n```\n\n----------------------------------------\n\nTITLE: Dockerfile Configuration for MPI and Horovod\nDESCRIPTION: Dockerfile setup that includes the installation of MPI and Horovod components needed for distributed training. The highlighted sections show the specific MPI and Horovod installation steps.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfmpi_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: docker\nCODE:\n```\n# This is a reference to the complete Dockerfile content, with emphasis on lines 40-51 and 66 which contain MPI and Horovod installation instructions\n```\n\n----------------------------------------\n\nTITLE: Configuring Table of Contents in Markdown for Feature Engineering Documentation\nDESCRIPTION: Sets up a hidden table of contents with links to feature engineering examples, including exploratory data analysis and Feast integration pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/feature_engineering/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:caption: Contents\n:hidden:\n\n/auto_examples/exploratory_data_analysis/index\n/auto_examples/feast_integration/index\n```\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Task Configuration in Python\nDESCRIPTION: Example of using a custom task configuration with the @task decorator in Flyte. This allows specifying plugin-specific configurations for task execution.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/extending/README.md#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@task(task_config=MyContainerExecutionTask(\n    plugin_specific_config_a=...,\n    plugin_specific_config_b=...,\n    ...\n))\ndef foo(...) -> ...:\n    ...\n```\n\n----------------------------------------\n\nTITLE: Installing Ray Plugin for Flyte\nDESCRIPTION: Command to install the Ray plugin for Flyte using pip. This is necessary to enable Ray functionality in Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/ray_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-ray\n```\n\n----------------------------------------\n\nTITLE: Installing Modin Plugin for Flyte\nDESCRIPTION: Command to install the Modin plugin for Flyte using pip. This plugin allows the use of Modin DataFrames in Flyte tasks and workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/modin_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-modin\n```\n\n----------------------------------------\n\nTITLE: Configuring Flyte-Comet ML Integration\nDESCRIPTION: YAML configuration to enable linking from Flyte's side panel to Comet ML. This configures two types of links: one based on execution ID and another using custom experiment keys.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/comet_ml_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  logs:\n    dynamic-log-links:\n      - comet-ml-execution-id:\n          displayName: Comet\n          templateUris: \"{{ .taskConfig.host }}/{{ .taskConfig.workspace }}/{{ .taskConfig.project_name }}/{{ .executionName }}{{ .nodeId }}{{ .taskRetryAttempt }}{{ .taskConfig.link_suffix }}\"\n      - comet-ml-custom-id:\n          displayName: Comet\n          templateUris: \"{{ .taskConfig.host }}/{{ .taskConfig.workspace }}/{{ .taskConfig.project_name }}/{{ .taskConfig.experiment_key }}\"\n```\n\n----------------------------------------\n\nTITLE: Example Comment Structure for Sphinx-Gallery\nDESCRIPTION: Demonstrates the proper comment format for FlyteSnacks examples using the Sphinx-Gallery convention. Shows how to start a documentation section with '# %%' and maintain proper spacing in multiline comments.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/README.md#2025-04-16_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\n# %%\n# my very important comment\n#\n# some other stuff\ndef foo():\n  ...\n```\n\n----------------------------------------\n\nTITLE: Installing Kubeflow TensorFlow Plugin\nDESCRIPTION: Command to install the Kubeflow TensorFlow plugin using pip package manager.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kftensorflow_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-kftensorflow\n```\n\n----------------------------------------\n\nTITLE: Installing Dolt Plugin and CLI for Flyte\nDESCRIPTION: Commands to install the Flyte Dolt plugin via pip and the Dolt command line tool using the official installer script.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dolt_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins.dolt\nsudo bash -c 'curl -L https://github.com/dolthub/dolt/releases/latest/download/install.sh | sudo bash'\n```\n\n----------------------------------------\n\nTITLE: Generating FlyteSnacks Documentation with Make\nDESCRIPTION: Command to generate HTML documentation for FlyteSnacks after installing the development requirements.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmake html\n```\n\n----------------------------------------\n\nTITLE: Running Snowflake Example on Flyte Cluster\nDESCRIPTION: Command to run a Snowflake example workflow on a remote Flyte cluster. It uses pyflyte to execute a workflow from a GitHub raw file, passing a parameter for the nation_key.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/snowflake_plugin/snowflake_plugin.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote \\\n  https://raw.githubusercontent.com/flyteorg/flytesnacks/master/examples/snowflake_plugin/snowflake_plugin/snowflake.py \\\n  snowflake_wf --nation_key 10\n```\n\n----------------------------------------\n\nTITLE: Configuring Dask Task with Component-Specific Resources\nDESCRIPTION: Python code demonstrating how to specify different resource limits for individual components of a Dask job, such as the scheduler and worker groups.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task\nfrom flytekitplugins.dask import Dask, Scheduler, WorkerGroup\n\n@task(\n  task_config=Dask(\n      scheduler=Scheduler(\n          limits=Resources(cpu=\"1\", mem=\"2Gi\"),  # Applied to the job pod\n      ),\n      workers=WorkerGroup(\n          limits=Resources(cpu=\"4\", mem=\"10Gi\"), # Applied to the scheduler and worker pods\n      ),\n  ),\n)\ndef my_dask_task():\n   ...\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Papermill Plugin\nDESCRIPTION: Command to install the Flyte Papermill plugin using pip. This plugin allows integration of Jupyter notebooks into Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-papermill\n```\n\n----------------------------------------\n\nTITLE: Starting Flyte demo cluster\nDESCRIPTION: Command to start a local Flyte demo cluster using flytectl. This sets up a Kubernetes environment for running Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nflytectl demo start\n```\n\n----------------------------------------\n\nTITLE: Installing Kubeflow PyTorch Plugin for Flyte\nDESCRIPTION: This command installs the Kubeflow PyTorch plugin for Flyte, which is necessary for using PyTorch distributed training capabilities.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfpytorch_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-kfpytorch\n```\n\n----------------------------------------\n\nTITLE: Validating WhyLogs Constraints\nDESCRIPTION: This snippet shows how to build and validate constraints using WhyLogs, returning a report of passed and failed constraints.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nconstraints = builder.build()\nconstraints.report()\n\n>> [('my_column greater than number 10.0', 0, 1)]\n```\n\n----------------------------------------\n\nTITLE: Installing Ollama Plugin for Flyte\nDESCRIPTION: Command to install the Flyte inference plugins package which includes Ollama support. This package is required to use Ollama functionality within Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/ollama_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-inference\n```\n\n----------------------------------------\n\nTITLE: Displaying Flyte Example Project Structure using Bash Tree Command\nDESCRIPTION: This code snippet shows the typical directory structure of a Flyte example project using a tree-like representation. It includes the main project files and the Python package structure containing individual example scripts.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexample_project\n├── README.md  # High-level description of the example project\n├── Dockerfile  # Dockerfile for packaging up the project requirements\n├── requirements.in  # Minimal python requirements for the project\n├── requirements.txt  # Compiled python requirements using pip-compile\n└── example_project  # Python package containing examples with the same name as the project\n    ├── __init__.py\n    ├── example_01.py\n    ├── example_02.py\n    ├── ...\n    └── example_n.py\n```\n\n----------------------------------------\n\nTITLE: Performing Computation in Papermill Notebook\nDESCRIPTION: This snippet demonstrates a simple computation using the input parameter and prints the result.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/papermill_plugin/papermill_plugin/nb_simple.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nsquare = v*v\nprint(square)\n```\n\n----------------------------------------\n\nTITLE: Configuring Spark Logs in Flyte\nDESCRIPTION: YAML configuration for different types of Spark logs in Flyte, including mixed logs, user logs, system logs, and all-user logs, with CloudWatch and Kubernetes integration options.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_spark_plugin/README.md#2025-04-16_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  spark:\n    logs:\n      user:\n        kubernetes-enabled: true\n        kubernetes-url: <the existing k8s url you have in the main logs section>\n      mixed:\n        cloudwatch-enabled: true\n        cloudwatch-template-uri: \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=<LogGroupName>;prefix=var.log.containers.{{.podName}};streamFilter=typeLogStreamPrefix\"\n      system:\n        cloudwatch-enabled: true\n        cloudwatch-template-uri: \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=<LogGroupName>;prefix=system_log.var.log.containers.{{.podName}};streamFilter=typeLogStreamPrefix\"\n      all-user:\n        cloudwatch-enabled: true\n        cloudwatch-template-uri: \"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=<LogGroupName>;prefix=var.log.containers.{{.podName}};streamFilter=typeLogStreamPrefix\"\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Spark Plugin\nDESCRIPTION: Command to install the Flyte plugin for Apache Spark integration. This plugin enables Flyte to execute Spark jobs natively on a Kubernetes cluster.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/forecasting_sales/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-spark\n```\n\n----------------------------------------\n\nTITLE: Installing Airflow Provider for Flyte using pip\nDESCRIPTION: Command to install the airflow-provider-flyte package using pip. This package provides an operator, sensor, and hook for integrating Flyte into Apache Airflow.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/airflow_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install airflow-provider-flyte\n```\n\n----------------------------------------\n\nTITLE: Creating a list-table in Markdown for Feature Engineering Examples\nDESCRIPTION: Creates a formatted table with links to examples of feature engineering in Flyte, including EDA with Papermill and data cleaning with Feast.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/feature_engineering/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`EDA and Feature Engineering With Papermill </auto_examples/exploratory_data_analysis/index>`\n  - How to use Jupyter notebook within Flyte\n* - {doc}`Data Cleaning and Feature Serving With Feast </auto_examples/feast_integration/index>`\n  - How to use Feast to serve data in Flyte\n```\n```\n\n----------------------------------------\n\nTITLE: Recording Outputs with Flyte's Papermill Plugin\nDESCRIPTION: This code uses the Flyte Papermill plugin to record outputs from the notebook so they can be serialized and passed to downstream tasks in a Flyte workflow.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/papermill_plugin/papermill_plugin/nb_simple.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekitplugins.papermill  import record_outputs\n\nrecord_outputs(square=square)\n```\n\n----------------------------------------\n\nTITLE: Installing Flytekit DuckDB Plugin\nDESCRIPTION: Command to install the Flytekit DuckDB plugin package using pip package manager. This plugin enables DuckDB integration with Flytekit workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/duckdb_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-duckdb\n```\n\n----------------------------------------\n\nTITLE: Fetching Latest Launch Plan Version\nDESCRIPTION: Retrieves the latest version of the workflow launch plan from the remote Flyte server to prepare for execution.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nlp = remote.fetch_launch_plan(name=\"feast_integration.feast_workflow.feast_workflow\")\nlp.id.version\n```\n\n----------------------------------------\n\nTITLE: Running the Workflow with Custom Image\nDESCRIPTION: Command to execute the Rossman sales forecasting workflow on a remote Flyte cluster using a custom Docker image that contains all the necessary dependencies for Spark and Horovod.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/forecasting_sales/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote forecasting_sales/keras_spark_rossmann_estimator.py horovod_spark_wf --image ghcr.io/flyteorg/flytecookbook:spark_horovod-latest\n```\n\n----------------------------------------\n\nTITLE: Installing TensorFlow ONNX Plugin for Flytekit\nDESCRIPTION: Command to install the Flytekit plugin for converting TensorFlow models to ONNX format. This plugin enables interoperability between TensorFlow and other ML frameworks through the ONNX standard.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/onnx_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-onnxtensorflow\n```\n\n----------------------------------------\n\nTITLE: Installing dbt-postgres adapter\nDESCRIPTION: Command to install the dbt-postgres adapter, which includes dbt-core and the Postgres-specific adapter. This is necessary for working with Postgres databases in dbt.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install dbt-postgres\n```\n\n----------------------------------------\n\nTITLE: Installing AWS Batch Plugin for Flyte\nDESCRIPTION: Command to install the AWS Batch plugin for Flytekit using pip.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/aws_batch_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-awsbatch\n```\n\n----------------------------------------\n\nTITLE: Markdown Toctree Directive for Hidden Navigation\nDESCRIPTION: A Markdown toctree directive that defines hidden navigation links to tutorial category pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:hidden:\n\nModel Training <model_training/index>\nFeature engineering <feature_engineering/index>\nBioinformatics <bioinformatics/index>\nFlytelab <flytelab/index>\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Spark Plugin for Databricks Integration\nDESCRIPTION: Command to install the Spark plugin which includes the Databricks agent functionality. This pip installation is required before using Databricks with Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/databricks_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-spark\n```\n\n----------------------------------------\n\nTITLE: Installing Neptune Plugin for Flyte\nDESCRIPTION: Command to install the Flyte Neptune plugin using pip. This allows seamless integration of Neptune experiment tracking within Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/neptune_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-neptune\n```\n\n----------------------------------------\n\nTITLE: Running dbt example from cloned repository\nDESCRIPTION: Series of commands to clone the flytesnacks repository, navigate to the dbt example directory, and run the example workflow using pyflyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://github.com/flyteorg/flytesnacks\ncd flytesnacks/examples/dbt_example\npyflyte run --remote \\\n    --image ghcr.io/flyteorg/flytecookbook:dbt_example-latest \\\n    dbt_plugin/dbt_example.py wf\n```\n\n----------------------------------------\n\nTITLE: Generating WhyLogs Summary Drift Report in Flyte\nDESCRIPTION: This snippet shows how to create a Summary Drift Report using WhylogsSummaryDriftRenderer and display it in a Flyte Deck.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nrenderer = WhylogsSummaryDriftRenderer()\nreport = renderer.to_html(target_data=new_data, reference_data=reference_data)\nflytekit.Deck(\"summary drift\", report)\n```\n\n----------------------------------------\n\nTITLE: Configuring Spark History Server in Flyte\nDESCRIPTION: YAML configuration to set up the Spark history server URL in the Flyteplugins configuration, enabling access to Spark execution history through the Flyte Console.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_spark_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  spark:\n    spark-history-server-url: <root-url-forspark-history server>\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte NIM Plugin\nDESCRIPTION: Command to install the Flyte plugin required for NVIDIA NIM integration. This plugin enables interaction with NIM services from Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/nim_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-inference\n```\n\n----------------------------------------\n\nTITLE: Installing Airflow Agent Plugin for Flyte\nDESCRIPTION: Command to install the Airflow agent plugin for Flyte using pip. This plugin enables the use of Airflow tasks within Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/airflow_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-airflow\n```\n\n----------------------------------------\n\nTITLE: Installing Great Expectations Flyte Plugin\nDESCRIPTION: Command to install the Great Expectations plugin for Flyte using pip package manager.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/greatexpectations_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-great_expectations\n```\n\n----------------------------------------\n\nTITLE: Sample Cluster Role YAML for Dask Kubernetes Operator\nDESCRIPTION: YAML configuration for a Kubernetes ClusterRole that grants the necessary permissions for Dask operations. This role allows managing Dask clusters, worker groups, jobs, and autoscalers.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\napiVersion: <http://rbac.authorization.k8s.io/v1|rbac.authorization.k8s.io/v1>\nkind: ClusterRole\nmetadata:\n  name: dask-dask-kubernetes-operator-role-cluster\n  labels:\n    <http://app.kubernetes.io/managed-by|app.kubernetes.io/managed-by>: Helm\n  annotations:\n    <http://meta.helm.sh/release-name|meta.helm.sh/release-name>: dask\n    <http://meta.helm.sh/release-namespace|meta.helm.sh/release-namespace>: dask\nrules:\n  - verbs:\n      - list\n      - watch\n    apiGroups:\n      - <http://apiextensions.k8s.io|apiextensions.k8s.io>\n    resources:\n      - customresourcedefinitions\n  - verbs:\n      - get\n      - list\n      - watch\n      - patch\n      - create\n      - delete\n    apiGroups:\n      - <http://kubernetes.dask.org|kubernetes.dask.org>\n    resources:\n      - daskclusters\n      - daskworkergroups\n      - daskjobs\n      - daskjobs/status\n      - daskautoscalers\n      - daskworkergroups/scale\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Hive Plugin using pip\nDESCRIPTION: Command to install the flytekitplugins-hive package via pip package manager. This plugin enables Hive query capabilities in Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/hive_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-hive\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte's Comet ML Plugin\nDESCRIPTION: Command to install the Flyte plugin for Comet ML integration using pip. This is the first step to enable connectivity between Flyte workflows and Comet ML.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/comet_ml_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-comet-ml\n```\n\n----------------------------------------\n\nTITLE: Checking Pod Logs for MPI Worker Errors\nDESCRIPTION: Kubernetes command to check logs of worker pods for troubleshooting errors related to resource allocation or worker communication issues.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfmpi_plugin/README.md#2025-04-16_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nkubectl logs <pod-name> -n <namespace>\n```\n\n----------------------------------------\n\nTITLE: Registering Workflow Script with FlyteRemote\nDESCRIPTION: Registers the feast_workflow script with Flyte, specifying the container image, version, source path, and module name for execution.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit.configuration import ImageConfig\n\nfrom feast_workflow import feast_workflow\n\nwf = remote.register_script(\n    feast_workflow,\n    image_config=ImageConfig.from_images(\n        \"ghcr.io/flyteorg/flytecookbook:feast_integration-latest\"\n    ),\n    version=\"v2\",\n    source_path=\"../\",\n    module_name=\"feast_workflow\",\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Snowflake Plugin with pip\nDESCRIPTION: Command to install the Flyte Snowflake agent plugin using pip. This package enables Flyte to interact with Snowflake services.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/snowflake_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-snowflake\n```\n\n----------------------------------------\n\nTITLE: Retrieving Repository Configuration\nDESCRIPTION: Extracts the repository configuration from a specific node execution, which is required for feature retrieval.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nrepo_config = synced_execution.node_executions[\"n0\"].outputs[\"o0\"]\n```\n\n----------------------------------------\n\nTITLE: Configuring Dask Task with Custom Images\nDESCRIPTION: Python code showing how to specify custom Docker images for different components of a Dask job. While possible, using different images for different components is not recommended.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task\nfrom flytekitplugins.dask import Dask, Scheduler, WorkerGroup\n\n@task(\n  task_config=Dask(\n      scheduler=Scheduler(\n          image=\"my_image:0.1.0\",  # Will be used by the job pod\n      ),\n      workers=WorkerGroup(\n          image=\"my_image:0.1.0\", # Will be used by the scheduler and worker pods\n      ),\n  ),\n)\ndef my_dask_task():\n   ...\n```\n\n----------------------------------------\n\nTITLE: ClusterRole Binding Command for Flyte Dask\nDESCRIPTION: Command to create a Kubernetes ClusterRoleBinding that associates the Dask cluster role with the Flyte service account, enabling Flyte to manage Dask resources.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkubectl create clusterrolebinding flyte-dask-cluster-role-binding --clusterrole=dask-dask-kubernetes-operator-role-cluster --serviceaccount=<flyte-service-account>\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Batch Agent Dependencies\nDESCRIPTION: Command to install the required plugin package for using OpenAI Batch agent functionality in Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/openai_batch_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-openai\n```\n\n----------------------------------------\n\nTITLE: Installing Flytekitplugins-pod Package\nDESCRIPTION: Command to install the Flytekit pod plugin which enables Kubernetes pod customization capabilities in Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_pod_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-pod\n```\n\n----------------------------------------\n\nTITLE: Installing WhyLogs Flyte Plugin\nDESCRIPTION: This snippet provides the command to install the WhyLogs plugin for Flyte using pip.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/whylogs_plugin/README.md#2025-04-16_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-whylogs\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Kubeflow MPI Plugin\nDESCRIPTION: Command to install the Flyte Kubeflow MPI plugin using pip. This plugin enables integration with the Kubeflow training operator for distributed training.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/kfmpi_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-kfmpi\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Slurm Agent Package\nDESCRIPTION: Command to install the Slurm agent plugin for Flytekit using pip. This package enables integration with Slurm workload managers for high-performance computing tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/slurm_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-slurm\n```\n\n----------------------------------------\n\nTITLE: Configuring Dynamic Log Links for Neptune in Flyte\nDESCRIPTION: YAML configuration to enable dynamic log links for Neptune in Flyte's configuration file. This setup allows direct access to Neptune experiment logs from the Flyte UI.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/neptune_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: yaml\nCODE:\n```\nplugins:\n  logs:\n    dynamic-log-links:\n      - neptune-run-id:\n          displayName: Neptune\n          templateUris: \"{{ .taskConfig.host }}/{{ .taskConfig.project }}?query=(%60flyte%2Fexecution_id%60%3Astring%20%3D%20%22{{ .executionName }}-{{ .nodeId }}-{{ .taskRetryAttempt }}%22)&lbViewUnpacked=true\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Dolt User Information\nDESCRIPTION: Commands to set up global user configuration for Dolt with email and name, required before initializing a Dolt database.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dolt_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndolt config --global --add user.email <email>\ndolt config --global --add user.name <name>\n```\n\n----------------------------------------\n\nTITLE: Editing Flyte Propeller ConfigMap\nDESCRIPTION: Command to edit the Flyte propeller ConfigMap in Kubernetes to configure MLflow integration.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/mlflow_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nkubectl edit cm flyte-propeller-config\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Spark Plugin with pip\nDESCRIPTION: Command to install the Flyte Spark plugin package using pip, which is required to use Spark functionality with Flyte.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_spark_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-spark\n```\n\n----------------------------------------\n\nTITLE: Installing BigQuery Agent with pip\nDESCRIPTION: Command to install the BigQuery agent plugin using pip package manager. This installation only requires the plugin as SQL is portable and doesn't need a Docker container.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/bigquery_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-bigquery\n```\n\n----------------------------------------\n\nTITLE: Referencing flytekit.testing Module in Markdown\nDESCRIPTION: This code snippet provides a markdown link to the flytekit.testing module in the API reference for more detailed information on testing Flyte tasks and workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/testing/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[`flytekit.testing`](https://docs.flyte.org/en/latest/api/flytekit/testing.html)\n```\n\n----------------------------------------\n\nTITLE: Installing Pandera Plugin for Flytekit\nDESCRIPTION: Command to install the Pandera plugin for Flytekit using pip package manager.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/pandera_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-pandera\n```\n\n----------------------------------------\n\nTITLE: Running PySpark Pi Example Remotely\nDESCRIPTION: Command to execute the PySpark Pi calculation example remotely on a Flyte cluster using the pyflyte CLI tool.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_spark_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote pyspark_pi.py my_spark\n```\n\n----------------------------------------\n\nTITLE: Accessing Model Object\nDESCRIPTION: Accesses the serialized model object from the workflow execution outputs. The model is available as a JobLibSerialized file.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nmodel\n```\n\n----------------------------------------\n\nTITLE: Creating List Table for Bioinformatics Examples in Markdown\nDESCRIPTION: A Markdown/Sphinx list table that displays a link to a BLASTX example for querying nucleotide sequences against protein databases.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/bioinformatics/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Nucleotide Sequence Querying with BLASTX </auto_examples/blast/index>`\n  - Use BLASTX to Query a Nucleotide Sequence Against a Local Protein Database\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Papermill Plugin\nDESCRIPTION: Command to install the Flyte Papermill plugin using pip package manager. This plugin enables running Jupyter notebooks as Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/papermill_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-papermill\n```\n\n----------------------------------------\n\nTITLE: Running Diabetes XGBoost Workflow with Flyte\nDESCRIPTION: Command to execute the diabetes classification workflow remotely using pyflyte with a custom Docker image. The command targets the 'diabetes_xgboost_model' workflow in the diabetes.py file.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/pima_diabetes/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote --image ghcr.io/flyteorg/flytecookbook:pima_diabetes-latest diabetes.py diabetes_xgboost_model\n```\n\n----------------------------------------\n\nTITLE: Running dbt example workflow in Flyte\nDESCRIPTION: Command to execute the dbt example workflow using pyflyte. It runs the workflow remotely using the pre-built Docker image.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote \\\n    --image ghcr.io/flyteorg/flytecookbook:dbt_example-latest \\\n    dbt_plugin/dbt_example.py wf\n```\n\n----------------------------------------\n\nTITLE: Configuring Docker Image for BLAST Analysis with Flyte\nDESCRIPTION: A Dockerfile that sets up an environment for running BLAST analyses with Flyte. It installs BLAST+ tools, Python packages for bioinformatics including Biopython, and configures the necessary dependencies for sequence analysis workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/blast/README.md#2025-04-16_snippet_0\n\nLANGUAGE: docker\nCODE:\n```\nFROM python:3.8-slim-buster\n\nWORKDIR /root\nENV VENV /opt/venv\nENV LANG C.UTF-8\nENV LC_ALL C.UTF-8\nENV PYTHONPATH /root\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install pipenv\nRUN pip3 install pipenv\n\n# Install apt packages\nRUN apt-get update && apt-get install -y --no-install-recommends make build-essential libssl-dev curl\n\n# Install the AWS cli separately to prevent issues with boto being compiled from source\nRUN pip3 install awscli\n\n# Install BLAST\nRUN apt-get update && apt-get install -y --no-install-recommends ncbi-blast+\n\n# Set up a virtual environment\nRUN python -m venv ${VENV}\nRUN ${VENV}/bin/pip install wheel\n\n# Upgrade pip\nRUN ${VENV}/bin/pip install -U pip\n\n# Unfortunately pip install is the only way to install dependencies of extensions\nCOPY requirements.txt /root\nRUN ${VENV}/bin/pip install -r /root/requirements.txt\n\n# Update gRPC libraries - these are required to support new error types, and the remote data configuration.\nRUN ${VENV}/bin/pip install grpcio==1.51.1 grpcio-status==1.51.1 grpcio-reflection==1.51.1 grpcio-health-checking==1.51.1\n\n# Set flyte at the latest version\nRUN ${VENV}/bin/pip install flytekit\n\n# Install useful packages\nRUN ${VENV}/bin/pip install pandas\nRUN ${VENV}/bin/pip install notebook\nRUN ${VENV}/bin/pip install matplotlib\nRUN ${VENV}/bin/pip install scipy\nRUN ${VENV}/bin/pip install scikit-learn\n\n# Install BLAST packages\nRUN ${VENV}/bin/pip install biopython\nRUN ${VENV}/bin/pip install seaborn\nRUN ${VENV}/bin/pip install matplotlib-venn\n\n# Let's now get the rest of the code\nCOPY . /root\n\n# This tag is supplied by the build script and will be used to determine the version\n# when registering tasks, workflows, and launch plans\nARG tag\nENV FLYTE_INTERNAL_IMAGE \"$tag\"\n\n# Copy over the helper script that the SDK relies on\nENV FLYTEKIT_INSTALL_ALL_PLUGINS \"True\"\n\n# For spark we need a specific entrypoint and extra dependencies\nCOPY in_container.py /root/\n\nENV WORKERS=1\nEXPOSE 8080\n\n# Install BLAST packages\nRUN ${VENV}/bin/pip install biopython\nRUN ${VENV}/bin/pip install seaborn\nRUN ${VENV}/bin/pip install matplotlib-venn\n\n# This will use the flytekit.bin executable. The flytekit-fast.bin shim, just executes flytekit.bin. Retained for compatibility\nENTRYPOINT [\"flytekit_venv\", \"/opt/venv\", \"python\", \"/root/in_container.py\"]\n```\n\n----------------------------------------\n\nTITLE: Generating Automatic Table of Contents for Flyte Examples in Markdown\nDESCRIPTION: A directive to auto-generate a table of contents for Flyte example code. This uses a special Sphinx directive to automatically include a table of contents for the 'example' directory.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/_example_template/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{auto-examples-toc}\nexample\n```\n\n----------------------------------------\n\nTITLE: Creating a New Dolt Database\nDESCRIPTION: Commands to create and initialize a new Dolt database named 'foo'. This creates the directory structure and initializes the Dolt repository.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dolt_plugin/README.md#2025-04-16_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmkdir foo\ncd foo\ndolt init\n```\n\n----------------------------------------\n\nTITLE: Installing Flyte Athena Plugin via pip\nDESCRIPTION: Command to install the AWS Athena plugin for Flyte using pip. This plugin enables integration with AWS Athena service for querying data using SQL.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/athena_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-athena\n```\n\n----------------------------------------\n\nTITLE: Installing Snowflake Plugin for Flyte\nDESCRIPTION: Command to install the Snowflake plugin for Flyte using pip. This is required to use the Snowflake functionality in Flyte projects.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/snowflake_plugin/snowflake_plugin.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-snowflake\n```\n\n----------------------------------------\n\nTITLE: Displaying Warning Message in Markdown\nDESCRIPTION: This code snippet uses Markdown syntax to create a warning message. It informs users that the example code uses a legacy implementation of the BigQuery integration and recommends using the BigQuery agent instead.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/bigquery_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{warning}\nThis example code uses the legacy implementation of the BigQuery integration. We recommend using the [BigQuery agent](https://docs.flyte.org/en/latest/flytesnacks/examples/bigquery_agent/index.html) instead.\n```\n```\n\n----------------------------------------\n\nTITLE: Markdown List Table for Feature Engineering Tutorials\nDESCRIPTION: A Markdown list-table directive showing available feature engineering tutorials with links to respective documentation pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`EDA and Feature Engineering With Papermill </auto_examples/exploratory_data_analysis/index>`\n  - How to use Jupyter notebook within Flyte\n* - {doc}`Data Cleaning and Feature Serving With Feast </auto_examples/feast_integration/index>`\n  - How to use Feast to serve data in Flyte\n```\n```\n\n----------------------------------------\n\nTITLE: Importing flytekit Module in Python\nDESCRIPTION: Code snippet showing the import of the flytekit module, which is a Python SDK for developing Flyte workflows and tasks. It can be used for stateful computation and allows workflows and tasks to run locally unless advanced backend functionality is needed.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[`flytekit`](https://docs.flyte.org/en/latest/api/flytekit/docs_index.html)\n```\n\n----------------------------------------\n\nTITLE: List Table for Airflow Integration\nDESCRIPTION: Markdown table showing Airflow integration capability for triggering Flyte executions\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Airflow </auto_examples/airflow_plugin/index>`\n  - Trigger Flyte executions from Airflow.\n```\n\n----------------------------------------\n\nTITLE: Great Expectations Validation Error Example\nDESCRIPTION: Example of error message displayed on Flyte UI when data validation fails, showing failed expectations for different columns.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/greatexpectations_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nTraceback (most recent call last)...\ngreat_expectations.marshmallow__shade.exceptions.ValidationError: Validation failed!\nCOLUMN          FAILED EXPECTATION\npassenger_count -> expect_column_min_to_be_between\npassenger_count -> expect_column_mean_to_be_between\npassenger_count -> expect_column_quantile_values_to_be_between\npassenger_count -> expect_column_values_to_be_in_set\npassenger_count -> expect_column_proportion_of_unique_values_to_be_between\ntrip_distance -> expect_column_max_to_be_between\ntrip_distance -> expect_column_mean_to_be_between\ntrip_distance -> expect_column_median_to_be_between\ntrip_distance -> expect_column_quantile_values_to_be_between\ntrip_distance -> expect_column_proportion_of_unique_values_to_be_between\nrate_code_id -> expect_column_max_to_be_between\nrate_code_id -> expect_column_mean_to_be_between\nrate_code_id -> expect_column_proportion_of_unique_values_to_be_between\n```\n\n----------------------------------------\n\nTITLE: Configuring Sphinx Documentation Tags for SQL Integration\nDESCRIPTION: ReStructuredText directive that adds documentation tags for the SQL integration content, categorizing it as Integration, Data, SQL, and Intermediate level.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/sql_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. tags:: Integration, Data, SQL, Intermediate\n```\n\n----------------------------------------\n\nTITLE: SDK TOC\nDESCRIPTION: Table of contents for SDKs used in writing tasks and workflows\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: SDKs for writing tasks and workflows\n\nflytekit <https://github.com/flyteorg/flytekit>\nflytekit-java <https://github.com/flyteorg/flytekit-java>\n\n```\n\n----------------------------------------\n\nTITLE: Initializing FlyteRemote Connection\nDESCRIPTION: Creates a FlyteRemote instance to interact with the Flyte backend, targeting the sandbox environment with the specified project and domain.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit.remote import FlyteRemote\nfrom flytekit.configuration import Config\n\n# The `for_sandbox` method instantiates a connection to the demo cluster.\nremote = FlyteRemote(\n    config=Config.for_sandbox(),\n    default_project=\"flytesnacks\",\n    default_domain=\"development\"\n)\n```\n\n----------------------------------------\n\nTITLE: Flyte Agents TOC\nDESCRIPTION: Table of contents for Flyte agents including various service integrations like Airflow, AWS Sagemaker, BigQuery, etc.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: Flyte agents\n\nAirflow agent </auto_examples/airflow_agent/index>\nAWS Sagemaker inference agent </auto_examples/sagemaker_inference_agent/index>\nBigQuery agent </auto_examples/bigquery_agent/index>\nChatGPT agent </auto_examples/chatgpt_agent/index>\nDatabricks agent </auto_examples/databricks_agent/index>\nMemory Machine Cloud agent </auto_examples/mmcloud_agent/index>\nOpenAI batch agent </auto_examples/openai_batch_agent/index>\nPERIAN Job Platform agent </auto_examples/perian_agent/index>\nSensor agent </auto_examples/sensor/index>\nSlurm agent </auto_examples/slurm_agent/index>\nSnowflake agent </auto_examples/snowflake_agent/index>\n```\n\n----------------------------------------\n\nTITLE: Markdown List Table for Bioinformatics Tutorials\nDESCRIPTION: A Markdown list-table directive displaying available bioinformatics tutorials with links to respective documentation pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Nucleotide Sequence Querying with BLASTX </auto_examples/blast/index>`\n  - Use BLASTX to Query a Nucleotide Sequence Against a Local Protein Database\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Memray Plugin for Flyte\nDESCRIPTION: Command to install the Memray plugin for Flyte using pip. This package enables memory tracking for Flyte tasks and visualization through Flyte Deck.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/memray_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-memray\n```\n\n----------------------------------------\n\nTITLE: Markdown List Table for Flytelab Projects\nDESCRIPTION: A Markdown list-table directive showing available Flytelab projects with links to respective documentation pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Weather Forecasting <flytelab/weather_forecasting>`\n  - Build an online weather forecasting application.\n```\n```\n\n----------------------------------------\n\nTITLE: Table of Contents Configuration\nDESCRIPTION: Hidden toctree configuration for organizing the documentation structure of model training examples.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/model_training/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:caption: Contents\n:hidden:\n\n/auto_examples/pima_diabetes/index\n/auto_examples/house_price_prediction/index\n/auto_examples/mnist_classifier/index\n/auto_examples/nlp_processing/index\n/auto_examples/forecasting_sales/index\n```\n\n----------------------------------------\n\nTITLE: Installing FlyteInteractive Plugin with pip\nDESCRIPTION: Command to install the FlyteInteractive plugin using pip. This allows users to add interactive development capabilities to their Flyte workflows.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/flyteinteractive_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-flyteinteractive\n```\n\n----------------------------------------\n\nTITLE: Using Prompt Directive in Documentation\nDESCRIPTION: Shows how to use the prompt directive in RST to display bash commands in the documentation with proper formatting.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/README.md#2025-04-16_snippet_2\n\nLANGUAGE: rst\nCODE:\n```\n.. prompt::bash\n\n   flytectl --version\n```\n\n----------------------------------------\n\nTITLE: Markdown List Table for Model Training Tutorials\nDESCRIPTION: A Markdown list-table directive displaying available model training tutorials with links to respective documentation pages.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Diabetes Classification </auto_examples/pima_diabetes/index>`\n  - Train an XGBoost model on the Pima Indians Diabetes Dataset.\n* - {doc}`House Price Regression </auto_examples/house_price_prediction/index>`\n  - Use dynamic workflows to train a multiregion house price prediction model using XGBoost.\n* - {doc}`MNIST Classification </auto_examples/mnist_classifier/index>`\n  - Train a neural network on MNIST with PyTorch and W&B\n* - {doc}`NLP Processing with Gensim </auto_examples/nlp_processing/index>`\n  - Word embedding and topic modelling on lee background corpus with Gensim\n* - {doc}`Sales Forecasting </auto_examples/forecasting_sales/index>`\n  - Use the Rossmann Store data to forecast sales with distributed training using Horovod on Spark.\n```\n```\n\n----------------------------------------\n\nTITLE: RST Tags Definition\nDESCRIPTION: ReStructuredText tags defining the document categories and complexity level for documentation purposes.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/house_price_prediction/README.md#2025-04-16_snippet_0\n\nLANGUAGE: rst\nCODE:\n```\n.. tags:: Data, MachineLearning, DataFrame, Intermediate\n```\n\n----------------------------------------\n\nTITLE: Configuring Auto-Generated Table of Contents for SQL Examples\nDESCRIPTION: ReStructuredText directive that generates a table of contents for SQL integration examples, specifically linking to sqlite3_integration and sql_alchemy documentation sections.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/sql_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\nauto-examples-toc\nsqlite3_integration\nsql_alchemy\n```\n\n----------------------------------------\n\nTITLE: Configuring TOC Structure in Sphinx Documentation\nDESCRIPTION: A toctree directive that sets up the hidden navigation structure for the Flytesnacks documentation, with links to the Tutorials and Integrations sections. The maxdepth is set to -1 to control the depth of the table of contents.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:hidden:\n\nTutorials <tutorials/index>\nIntegrations <integrations/index>\n```\n```\n\n----------------------------------------\n\nTITLE: Pulling pre-built Docker image for dbt example\nDESCRIPTION: Command to pull a pre-built Docker image containing the necessary dependencies and example files for the dbt integration demo.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ndocker pull ghcr.io/flyteorg/flytecookbook:dbt_example-latest\n```\n\n----------------------------------------\n\nTITLE: External Service Backend Plugins TOC\nDESCRIPTION: Table of contents for external service backend plugins including AWS services and Hive\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: External service backend plugins\n\nAWS Athena </auto_examples/athena_plugin/index>\nAWS Batch </auto_examples/aws_batch_plugin/index>\nFlyte Interactive </auto_examples/flyteinteractive_plugin/index>\nHive </auto_examples/hive_plugin/index>\n\n```\n\n----------------------------------------\n\nTITLE: Retrieving Model and Prediction Outputs\nDESCRIPTION: Fetches the trained model and its prediction outputs from the completed workflow execution.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/feast_integration/feast_integration/feast_flyte_remote.ipynb#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nmodel = synced_execution.outputs[\"o0\"]\nprediction = synced_execution.outputs[\"o1\"]\nprediction\n```\n\n----------------------------------------\n\nTITLE: Auto-Generated Examples TOC\nDESCRIPTION: ReStructuredText directive for automatically generating a table of contents for example files.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/house_price_prediction/README.md#2025-04-16_snippet_1\n\nLANGUAGE: rst\nCODE:\n```\nhouse_price_predictor\nmultiregion_house_price_predictor\n```\n\n----------------------------------------\n\nTITLE: Native Backend Plugins TOC\nDESCRIPTION: Table of contents for native backend plugins including Kubeflow, Kubernetes cluster jobs, and Ray\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: Native backend plugins\n\nKubeflow PyTorch </auto_examples/kfpytorch_plugin/index>\nKubeflow TensorFlow </auto_examples/kftensorflow_plugin/index>\nKubernetes cluster Dask jobs </auto_examples/k8s_dask_plugin/index>\nKubernetes cluster Spark jobs </auto_examples/k8s_spark_plugin/index>\nMPI Operator </auto_examples/kfmpi_plugin/index>\nRay </auto_examples/ray_plugin/index>\n```\n\n----------------------------------------\n\nTITLE: Installing Weights & Biases Plugin for Flyte\nDESCRIPTION: Command to install the Flyte Weights & Biases plugin using pip. This plugin enables integration between Flyte workflows and the Weights & Biases MLOps platform for experiment tracking and visualization.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/wandb_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-wandb\n```\n\n----------------------------------------\n\nTITLE: TOC Configuration in Markdown\nDESCRIPTION: Sphinx/MyST markdown configuration for table of contents, hiding the TOC and setting max depth to -1 for the snowflake plugin example.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/snowflake_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n\nsnowflake_plugin_example\n```\n\n----------------------------------------\n\nTITLE: Flytekit Plugins TOC\nDESCRIPTION: Table of contents for Flytekit plugins including integrations with various tools like Comet, DBT, DuckDB, etc.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: Flytekit plugins\n\nComet </auto_examples/comet_ml_plugin/index>\nDBT </auto_examples/dbt_plugin/index>\nDolt </auto_examples/dolt_plugin/index>\nDuckDB </auto_examples/duckdb_plugin/index>\nGreat Expectations </auto_examples/greatexpectations_plugin/index>\nMemray </auto_examples/memray_plugin/index>\nMLFlow </auto_examples/mlflow_plugin/index>\nModin </auto_examples/modin_plugin/index>\nNeptune </auto_examples/neptune_plugin/index>\nNIM </auto_examples/nim_plugin/index>\nOllama </auto_examples/ollama_plugin/index>\nONNX </auto_examples/onnx_plugin/index>\nPandera </auto_examples/pandera_plugin/index>\nPapermill </auto_examples/papermill_plugin/index>\nSQL </auto_examples/sql_plugin/index>\nWeights & Biases </auto_examples/wandb_plugin/index>\nWhyLogs </auto_examples/whylogs_plugin/index>\n```\n\n----------------------------------------\n\nTITLE: Recording Outputs in Jupyter Notebook for Flyte\nDESCRIPTION: Python code snippet demonstrating how to record outputs in a Jupyter notebook for use in Flyte workflows. This is placed in the 'outputs' cell of the notebook.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/README.md#2025-04-16_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekitplugins.papermill import record_outputs\nrecord_outputs(variable_name=variable_name)\n```\n\n----------------------------------------\n\nTITLE: Flyte Operators TOC\nDESCRIPTION: Table of contents for Flyte operators, specifically Airflow integration\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: Flyte operators\n\nAirflow </auto_examples/airflow_plugin/index>\n```\n\n----------------------------------------\n\nTITLE: Markdown Note Syntax for Tutorial Contribution Guide\nDESCRIPTION: Markdown code block using the 'note' directive to reference the contribution guide for tutorials and integration examples.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{note}\nWant to contribute a tutorial? Check out the {ref}`Tutorials and integration examples contribution guide <contribute_examples>`.\n```\n```\n\n----------------------------------------\n\nTITLE: Installing flytekitplugins-dbt via pip\nDESCRIPTION: Command to install the flytekitplugins-dbt package using pip. This plugin is required to use dbt functionality within Flyte tasks.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/dbt_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-dbt\n```\n\n----------------------------------------\n\nTITLE: Deprecated Integrations TOC\nDESCRIPTION: Table of contents for deprecated integrations including BigQuery, Databricks, and Snowflake plugins\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/integrations/index.md#2025-04-16_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n{toctree}\n:maxdepth: -1\n:hidden:\n:caption: Deprecated integrations\n\nBigQuery plugin </auto_examples/bigquery_plugin/index>\nDatabricks plugin </auto_examples/databricks_plugin/index>\nKubernetes pods </auto_examples/k8s_pod_plugin/index>\nSnowflake plugin </auto_examples/snowflake_plugin/index>\n```\n\n----------------------------------------\n\nTITLE: Creating Hidden Table of Contents in Markdown\nDESCRIPTION: This code snippet creates a hidden table of contents for the Flytelab documentation, with links to project documentation pages including the weather forecasting project.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/flytelab/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:caption: Contents\n:hidden:\n\nweather_forecasting\n```\n```\n\n----------------------------------------\n\nTITLE: Installing AWS SageMaker Inference Agent Plugin for Flyte\nDESCRIPTION: Command to install the AWS SageMaker inference agent plugin for Flyte using pip. This plugin allows users to deploy models, create and trigger inference endpoints, and manage SageMaker deployments.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/sagemaker_inference_agent/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-awssagemaker\n```\n\n----------------------------------------\n\nTITLE: Initializing Empty Dataset in Python\nDESCRIPTION: Creates an empty string variable called 'dataset' that will be used to store the dataset for the regression model.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/exploratory_data_analysis/exploratory_data_analysis/supermarket_regression_2.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndataset = \"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Table of Contents in Sphinx Documentation\nDESCRIPTION: A Sphinx toctree directive that configures the table of contents for bioinformatics documentation, specifically hiding the contents section and linking to the BLAST example.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/bioinformatics/index.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:caption: Contents\n:hidden:\n\n/auto_examples/blast/index\n```\n```\n\n----------------------------------------\n\nTITLE: Configuring Dask Task with Global Resource Limits\nDESCRIPTION: Python code showing how to configure a Dask task with resource limits that apply to all components of the Dask job, including the job runner, scheduler, and worker pods.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task\nfrom flytekitplugins.dask import Dask\n\n@task(\n  task_config=Dask(),\n  limits=Resources(cpu=\"1\", mem=\"10Gi\")  # Applied to all components\n)\ndef my_dask_task():\n   ...\n```\n\n----------------------------------------\n\nTITLE: Running a Dask Example on Flyte Cluster via Command Line\nDESCRIPTION: This command demonstrates how to run a Dask example named 'dask_example.py' on a Flyte cluster using the pyflyte CLI tool. It executes the 'hello_dask' function with a size parameter of 1000.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\npyflyte run --remote dask_example.py \\\n   hello_dask --size 1000\n```\n\n----------------------------------------\n\nTITLE: Creating List Table for Flytelab Projects in Markdown\nDESCRIPTION: This code snippet creates a formatted table listing available projects in Flytelab, specifically featuring a Weather Forecasting application with a link to its documentation.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/docs/tutorials/flytelab/index.md#2025-04-16_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n```{list-table}\n:header-rows: 0\n:widths: 20 30\n\n* - {doc}`Weather Forecasting <weather_forecasting>`\n  - Build an online weather forecasting application.\n```\n```\n\n----------------------------------------\n\nTITLE: Defining an Interruptible Dask Task in Python\nDESCRIPTION: This snippet demonstrates how to create an interruptible Dask task using Flyte decorators. It uses the Dask task config and sets the interruptible flag to True.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task, workflow, Labels, Annotations\nfrom flytekitplugins.dask import Dask\n\n@task(\n  task_config=Dask(),\n  interruptible=True,\n)\ndef my_dask_task():\n   ...\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Dask Tasks\nDESCRIPTION: Python code demonstrating how to configure environment variables for a Dask task. These variables will be propagated to all components of the Dask job.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom flytekit import Resources, task\nfrom flytekitplugins.dask import Dask\n\n@task(\n  task_config=Dask(),\n  env={\"FOO\": \"BAR\"}  # Will be applied to all components\n)\ndef my_dask_task():\n   ...\n```\n\n----------------------------------------\n\nTITLE: Creating Hidden Table of Contents in Markdown\nDESCRIPTION: This code snippet uses Markdown syntax to create a hidden table of contents. It includes a single entry 'bigquery_plugin_example' with maximum depth set to -1.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/bigquery_plugin/README.md#2025-04-16_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n```{toctree}\n:maxdepth: -1\n:hidden:\n\nbigquery_plugin_example\n```\n```\n\n----------------------------------------\n\nTITLE: Direct Task Execution with Wait\nDESCRIPTION: Shows how to execute a task with immediate waiting for completion\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n# Execute the workflow and wait for it to complete\nexe = remote.execute(hello, inputs={\"name\": \"world\"}, wait=True)\n\n# Print the outputs\nprint(exe.outputs)\n```\n\n----------------------------------------\n\nTITLE: Installing the Dask Plugin for Flyte\nDESCRIPTION: Command to install the Flyte Dask plugin using pip. This plugin enables Flyte to work with Dask for distributed computing.\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/k8s_dask_plugin/README.md#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install flytekitplugins-dask\n```\n\n----------------------------------------\n\nTITLE: Installing Flytekit Package\nDESCRIPTION: Command to install or upgrade flytekit to version 1.14.0 using pip\nSOURCE: https://github.com/flyteorg/flytesnacks/blob/master/examples/basics/basics/basic_interactive_mode.ipynb#2025-04-16_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install flytekit==1.14.0\n```"
  }
]