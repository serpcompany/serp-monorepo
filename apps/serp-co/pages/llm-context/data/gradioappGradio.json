[
  {
    "owner": "gradio-app",
    "repo": "gradio",
    "content": "TITLE: Creating Multimodal Chatbot with Gradio\nDESCRIPTION: Builds an advanced chatbot supporting text, images, audio, and video files using MultimodalTextbox. Includes markdown formatting and media file handling capabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/04_creating-a-custom-chatbot-with-blocks.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\ndef bot(history):\n    bot_message = random.choice(\n        [\n            \"Here's a random image!\",\n            {\"path\": \"https://gradio-builds.s3.amazonaws.com/demo-files/cheetah1.jpg\"},\n            \"I'm not sure what to say...\"\n        ]\n    )\n    history.append({\"role\": \"assistant\", \"content\": bot_message})\n    return history\n\ndef add_message(history, message):\n    for x in message[\"files\"]:\n        history.append({\"role\": \"user\", \"content\": {\"path\": x}})\n    if message[\"text\"] is not None:\n        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n    return history\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(height=400)\n    msg = gr.MultimodalTextbox(\n        placeholder=\"Type a message...\", file_types=[\"image\", \"audio\", \"video\"]\n    )\n    clear = gr.ClearButton([msg, chatbot])\n\n    msg.submit(add_message, [chatbot, msg], [chatbot]).then(\n        bot, chatbot, chatbot\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Processing Chatbot Response and Citations with Claude API - Python\nDESCRIPTION: Defines the chatbot response handler, generating answers using Claude's API and properly attaching user sources as citations in a collapsible Gradio-compatible format. Depends on 'client.messages.create', 'format_message_history', and presumes correct chat history and feature toggling inputs. Returns updated chat history with potential error handling if the Claude API call fails. Outputs both messages and citation summaries using Gradio's 'metadata' key for expandable display.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ndef bot_response(\\n    history: list,\\n    enable_citations: bool,\\n    doc_type: str,\\n    text_input: str,\\n    pdf_file: str\\n) -> List[Dict[str, Any]]:\\n    try:\\n        messages = format_message_history(history, enable_citations, doc_type, text_input, pdf_file)\\n        response = client.messages.create(model=\\\"claude-3-5-sonnet-20241022\\\", max_tokens=1024, messages=messages)\\n        \\n        # Initialize main response and citations\\n        main_response = \\\"\\\"\\n        citations = []\\n        \\n        # Process each content block\\n        for block in response.content:\\n            if block.type == \\\"text\\\":\\n                main_response += block.text\\n                if enable_citations and hasattr(block, 'citations') and block.citations:\\n                    for citation in block.citations:\\n                        if citation.cited_text not in citations:\\n                            citations.append(citation.cited_text)\\n        \\n        # Add main response\\n        history.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": main_response})\\n        \\n        # Add citations in a collapsible section\\n        if enable_citations and citations:\\n            history.append({\\n                \\\"role\\\": \\\"assistant\\\",\\n                \\\"content\\\": \\\"\\\\n\\\".join([f\\\"\\u2022 {cite}\\\" for cite in citations]),\\n                \\\"metadata\\\": {\\\"title\\\": \\\"\\ud83d\\udcda Citations\\\"}\\n            })\\n        \\n        return history\\n            \\n    except Exception as e:\\n        history.append({\\n            \\\"role\\\": \\\"assistant\\\",\\n            \\\"content\\\": \\\"I apologize, but I encountered an error while processing your request.\\\"\\n        })\\n        return history\n```\n\n----------------------------------------\n\nTITLE: Implementing a LangChain Chatbot with Gradio Interface in Python\nDESCRIPTION: This Python script sets up a chatbot using LangChain with OpenAI's `gpt-4o-mini` model. It defines a `predict` function that takes the user message and chat history, converts the history into LangChain's message format (HumanMessage, AIMessage), invokes the OpenAI model, and returns the generated response. A `gradio.ChatInterface` is configured to use this `predict` function, providing a user-friendly chat UI. The script requires the `OPENAI_API_KEY` environment variable to be set before execution. The application is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_langchain/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple general-purpose chatbot built on top of LangChain and Gradio.\n# Before running this, make sure you have exported your OpenAI API key as an environment variable:\n# export OPENAI_API_KEY=\"your-openai-api-key\"\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain.schema import AIMessage, HumanMessage\nimport gradio as gr\n\nmodel = ChatOpenAI(model=\"gpt-4o-mini\")\n\ndef predict(message, history):\n    history_langchain_format = []\n    for msg in history:\n        if msg['role'] == \"user\":\n            history_langchain_format.append(HumanMessage(content=msg['content']))\n        elif msg['role'] == \"assistant\":\n            history_langchain_format.append(AIMessage(content=msg['content']))\n    history_langchain_format.append(HumanMessage(content=message))\n    gpt_response = model.invoke(history_langchain_format)\n    return gpt_response.content\n\ndemo = gr.ChatInterface(\n    predict,\n    type=\"messages\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Chicago Bikeshare Dashboard with Gradio\nDESCRIPTION: This snippet creates a Gradio application that visualizes Chicago bike share data. It connects to a PostgreSQL database, retrieves data about ride types and popular stations, and displays this information using bar plots. The code also includes functions to query the database and set up the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chicago-bikeshare-dashboard/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport gradio as gr\nimport pandas as pd\n\nDB_USER = os.getenv(\"DB_USER\")\nDB_PASSWORD = os.getenv(\"DB_PASSWORD\")\nDB_HOST = os.getenv(\"DB_HOST\")\nPORT = 8080\nDB_NAME = \"bikeshare\"\n\nconnection_string = (\n    f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}?port={PORT}&dbname={DB_NAME}\"\n)\n\ndef get_count_ride_type():\n    df = pd.read_sql(\n        \"\"\"\n        SELECT COUNT(ride_id) as n, rideable_type\n        FROM rides\n        GROUP BY rideable_type\n        ORDER BY n DESC\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\ndef get_most_popular_stations():\n\n    df = pd.read_sql(\n        \"\"\"\n    SELECT COUNT(ride_id) as n, MAX(start_station_name) as station\n    FROM RIDES\n    WHERE start_station_name is NOT NULL\n    GROUP BY start_station_id\n    ORDER BY n DESC\n    LIMIT 5\n    \"\"\",\n        con=connection_string,\n    )\n    return df\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n    # Chicago Bike Share Dashboard\n    \n    This demo pulls Chicago bike share data for March 2022 from a postgresql database hosted on AWS.\n    This demo uses psycopg2 but any postgresql client library (SQLAlchemy)\n    is compatible with gradio.\n    \n    Connection credentials are handled by environment variables\n    defined as secrets in the Space.\n\n    If data were added to the database, the plots in this demo would update\n    whenever the webpage is reloaded.\n    \n    This demo serves as a starting point for your database-connected apps!\n    \"\"\"\n    )\n    with gr.Row():\n        bike_type = gr.BarPlot(\n            x=\"rideable_type\",\n            y='n',\n            title=\"Number of rides per bicycle type\",\n            y_title=\"Number of Rides\",\n            x_title=\"Bicycle Type\",\n            vertical=False,\n            tooltip=['rideable_type', \"n\"],\n            height=300,\n            width=300,\n        )\n        station = gr.BarPlot(\n            x='station',\n            y='n',\n            title=\"Most Popular Stations\",\n            y_title=\"Number of Rides\",\n            x_title=\"Station Name\",\n            vertical=False,\n            tooltip=['station', 'n'],\n            height=300,\n            width=300\n        )\n\n    demo.load(get_count_ride_type, inputs=None, outputs=bike_type)\n    demo.load(get_most_popular_stations, inputs=None, outputs=station)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining Basic Gradio Blocks with Event Listener in Python\nDESCRIPTION: Demonstrates the fundamental structure of a Gradio Blocks application using Python. It shows how to define components (Textbox, Button) within a `gr.Blocks()` context and link them using a `.click()` event listener attached to a button. This listener triggers a function (`greet`) with specified inputs (`name`) and outputs (`output`) when the button (`greet_btn`) is clicked.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n$code_hello_blocks\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio-based Agent Chatbot with Image Generation\nDESCRIPTION: This code snippet sets up a Gradio chatbot interface using a React Code Agent with an image generation tool. It defines the agent's functionality, interaction method, and launches the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/agent_chatbot/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom dataclasses import asdict\nfrom transformers import Tool, ReactCodeAgent  # type: ignore\nfrom transformers.agents import stream_to_gradio, HfApiEngine  # type: ignore\n\n# Import tool from Hub\nimage_generation_tool = Tool.from_space(  # type: ignore\n    space_id=\"black-forest-labs/FLUX.1-schnell\",\n    name=\"image_generator\",\n    description=\"Generates an image following your prompt. Returns a PIL Image.\",\n    api_name=\"/infer\",\n)\n\nllm_engine = HfApiEngine(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n# Initialize the agent with both tools and engine\nagent = ReactCodeAgent(tools=[image_generation_tool], llm_engine=llm_engine)\n\n\ndef interact_with_agent(prompt, history):\n    messages = []\n    yield messages\n    for msg in stream_to_gradio(agent, prompt):\n        messages.append(asdict(msg))  # type: ignore\n        yield messages\n    yield messages\n\n\ndemo = gr.ChatInterface(\n    interact_with_agent,\n    chatbot= gr.Chatbot(\n        label=\"Agent\",\n        type=\"messages\",\n        avatar_images=(\n            None,\n            \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\",\n        ),\n    ),\n    examples=[\n        [\"Generate an image of an astronaut riding an alligator\"],\n        [\"I am writing a children's book for my daughter. Can you help me with some illustrations?\"],\n    ],\n    type=\"messages\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Magic 8 Ball with Parler-TTS (Python)\nDESCRIPTION: This Python script implements the full Magic 8 Ball application using Gradio. It imports necessary libraries, configures the device (CPU/GPU/MPS), loads the Parler-TTS model (`ylacombe/parler-tts-mini-jenny-30H`), tokenizer, feature extractor, and initializes an InferenceClient for ASR and LLM calls. Key functions include `numpy_to_mp3` for audio conversion, `generate_response` for transcribing audio and getting an answer from Mistral, and `read_response` for streaming TTS generation using Parler-TTS. The script defines a Gradio interface with audio input/output and text display, linking user interaction (stopping recording) to the processing pipeline, and launches the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/magic_8_ball/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport io\nfrom threading import Thread\nimport random\nimport os\n\nimport numpy as np\nimport spaces\nimport gradio as gr\nimport torch\n\nfrom parler_tts import ParlerTTSForConditionalGeneration\nfrom pydub import AudioSegment\nfrom transformers import AutoTokenizer, AutoFeatureExtractor, set_seed\nfrom huggingface_hub import InferenceClient\nfrom streamer import ParlerTTSStreamer\nimport time\n\n\ndevice = (\n    \"cuda:0\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\ntorch_dtype = torch.float16 if device != \"cpu\" else torch.float32\n\nrepo_id = \"parler-tts/parler_tts_mini_v0.1\"\n\njenny_repo_id = \"ylacombe/parler-tts-mini-jenny-30H\"\n\nmodel = ParlerTTSForConditionalGeneration.from_pretrained(\n    jenny_repo_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n).to(device)\n\nclient = InferenceClient(token=os.getenv(\"HF_TOKEN\"))\n\ntokenizer = AutoTokenizer.from_pretrained(repo_id)\nfeature_extractor = AutoFeatureExtractor.from_pretrained(repo_id)\n\nSAMPLE_RATE = feature_extractor.sampling_rate\nSEED = 42\n\n\ndef numpy_to_mp3(audio_array, sampling_rate):\n    # Normalize audio_array if it's floating-point\n    if np.issubdtype(audio_array.dtype, np.floating):\n        max_val = np.max(np.abs(audio_array))\n        audio_array = (audio_array / max_val) * 32767  # Normalize to 16-bit range\n        audio_array = audio_array.astype(np.int16)\n\n    # Create an audio segment from the numpy array\n    audio_segment = AudioSegment(\n        audio_array.tobytes(),\n        frame_rate=sampling_rate,\n        sample_width=audio_array.dtype.itemsize,\n        channels=1,\n    )\n\n    # Export the audio segment to MP3 bytes - use a high bitrate to maximise quality\n    mp3_io = io.BytesIO()\n    audio_segment.export(mp3_io, format=\"mp3\", bitrate=\"320k\")\n\n    # Get the MP3 bytes\n    mp3_bytes = mp3_io.getvalue()\n    mp3_io.close()\n\n    return mp3_bytes\n\n\nsampling_rate = model.audio_encoder.config.sampling_rate\nframe_rate = model.audio_encoder.config.frame_rate\n\n\ndef generate_response(audio):\n    gr.Info(\"Transcribing Audio\", duration=5)\n    question = client.automatic_speech_recognition(audio).text  # type: ignore\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are a magic 8 ball.\"\n                \"Someone will present to you a situation or question and your job \"\n                \"is to answer with a cryptic addage or proverb such as \"\n                \"'curiosity killed the cat' or 'The early bird gets the worm'.\"\n                \"Keep your answers short and do not include the phrase 'Magic 8 Ball' in your response. If the question does not make sense or is off-topic, say 'Foolish questions get foolish answers.'\"\n                \"For example, 'Magic 8 Ball, should I get a dog?', 'A dog is ready for you but are you ready for the dog?'\"\n            ),\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"Magic 8 Ball please answer this question -  {question}\",\n        },\n    ]\n\n    response = client.chat_completion( # type: ignore\n        messages,\n        max_tokens=64,\n        seed=random.randint(1, 5000),\n        model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n    )\n    response = response.choices[0].message.content.replace(\"Magic 8 Ball\", \"\")  # type: ignore\n    return response, None, None\n\n\n@spaces.GPU\ndef read_response(answer):\n    play_steps_in_s = 2.0\n    play_steps = int(frame_rate * play_steps_in_s)\n\n    description = \"Jenny speaks at an average pace with a calm delivery in a very confined sounding environment with clear audio quality.\"\n    description_tokens = tokenizer(description, return_tensors=\"pt\").to(device)\n\n    streamer = ParlerTTSStreamer(model, device=device, play_steps=play_steps)\n    prompt = tokenizer(answer, return_tensors=\"pt\").to(device)\n\n    generation_kwargs = dict( # noqa: C408\n        input_ids=description_tokens.input_ids,\n        prompt_input_ids=prompt.input_ids,\n        streamer=streamer,\n        do_sample=True,\n        temperature=1.0,\n        min_new_tokens=10,\n    )\n\n    set_seed(SEED)\n    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n    thread.start()\n    start = time.time()\n    for new_audio in streamer:\n        print(\n            f\"Sample of length: {round(new_audio.shape[0] / sampling_rate, 2)} seconds after {time.time() - start} seconds\"\n        )\n        yield answer, numpy_to_mp3(new_audio, sampling_rate=sampling_rate)\n\n\nwith gr.Blocks() as demo:\n    gr.HTML(\n        \"\"\"\n        <h1 style='text-align: center;'> Magic 8 Ball 🎱 </h1>\n        <h3 style='text-align: center;'> Ask a question and receive wisdom </h3>\n        <p style='text-align: center;'> Powered by <a href=\"https://github.com/huggingface/parler-tts\"> Parler-TTS</a>\n        \"\"\"\n    )\n    with gr.Group():\n        with gr.Row():\n            audio_out = gr.Audio(\n                label=\"Spoken Answer\", streaming=True, autoplay=True, loop=False\n            )\n            answer = gr.Textbox(label=\"Answer\")\n            state = gr.State()\n        with gr.Row():\n            gr.Markdown(\n                \"Example questions: 'Should I get a dog?', 'What is the meaning of life?'\"\n            )\n            audio_in = gr.Audio(\n                label=\"Speak you question\", sources=\"microphone\", type=\"filepath\"\n            )\n    with gr.Row():\n        gr.HTML(\n            \"\"\"<h3 style='text-align: center;'> Examples: 'What is the meaning of life?', 'Should I get a dog?' </h3>\"\"\"\n        )\n    audio_in.stop_recording(\n        generate_response, audio_in, [state, answer, audio_out]\n    ).then(fn=read_response, inputs=state, outputs=[answer, audio_out])\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Complete Gradio-Integrated Slack Bot\nDESCRIPTION: Full implementation of a Slack bot that integrates with a Gradio app, handling both text and image inputs, with response processing and formatting\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/07_creating-a-slack-bot-from-a-gradio-app.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom slack_bolt import App\nfrom slack_bolt.adapter.socket_mode import SocketModeHandler\n\nSLACK_BOT_TOKEN = # PASTE YOUR SLACK BOT TOKEN HERE\nSLACK_APP_TOKEN = # PASTE YOUR SLACK APP TOKEN HERE\n\napp = App(token=SLACK_BOT_TOKEN)\ngradio_client = Client(\"abidlabs/gradio-playground-bot\")\n\ndef download_image(url, filename):\n    headers = {\"Authorization\": f\"Bearer {SLACK_BOT_TOKEN}\"}\n    response = httpx.get(url, headers=headers)\n    image_path = f\"./images/{filename}\"\n    os.makedirs(\"./images\", exist_ok=True)\n    with open(image_path, \"wb\") as f:\n        f.write(response.content)\n    return image_path\n\ndef slackify_message(message):   \n    pattern = r'\\[(.*?)\\]\\((.*?)\\)'\n    cleaned = re.sub(pattern, r'<\\2|\\1>', message)\n    cleaned = re.sub(r'```\\w+\\n', '```', cleaned)\n    return cleaned.strip()\n\n@app.event(\"app_mention\")\ndef handle_app_mention_events(body, say):\n    text = body[\"event\"][\"text\"]\n    bot_user_id = body[\"authorizations\"][0][\"user_id\"]\n    clean_message = text.replace(f\"<@{bot_user_id}>\", \"\").strip()\n    \n    files = []\n    if \"files\" in body[\"event\"]:\n        for file in body[\"event\"][\"files\"]:\n            if file[\"filetype\"] in [\"png\", \"jpg\", \"jpeg\", \"gif\", \"webp\"]:\n                image_path = download_image(file[\"url_private_download\"], file[\"name\"])\n                files.append(handle_file(image_path))\n                break\n    \n    for response in gradio_client.submit(\n        message={\"text\": clean_message, \"files\": files},\n    ):\n        cleaned_response = slackify_message(response[-1])\n        say(cleaned_response)\n\nif __name__ == \"__main__\":\n    handler = SocketModeHandler(app, SLACK_APP_TOKEN)\n    handler.start()\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Audio Transcription with Gradio and Transformers (Python)\nDESCRIPTION: This Python script sets up and runs a Gradio web interface for real-time audio transcription. It utilizes the Hugging Face `transformers` library to load a pre-trained automatic speech recognition model. The `transcribe` function processes streaming audio input from a microphone, appends the transcribed text to a persistent state, and updates the Gradio interface live. The interface requires `gradio`, `torch`, and `transformers` libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_wav2vec/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import pipeline\nimport gradio as gr\nimport time\n\np = pipeline(\"automatic-speech-recognition\")\n\ndef transcribe(audio, state=\"\"):\n    time.sleep(2)\n    text = p(audio)[\"text\"]  # type: ignore\n    state += text + \" \" # type: ignore\n    return state, state\n\ndemo = gr.Interface(\n    fn=transcribe,\n    inputs=[\n        gr.Audio(sources=[\"microphone\"], type=\"filepath\", streaming=True),\n        \"state\"\n    ],\n    outputs=[\n        \"textbox\",\n        \"state\"\n    ],\n    live=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Concurrency Limit for Event Listener in Gradio (Python)\nDESCRIPTION: This snippet demonstrates how to set a concurrency limit for an event listener in a Gradio application. It creates a block with a textbox, image, and button, and sets the concurrency limit to 5 for the image generation function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/01_queuing.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    prompt = gr.Textbox()\n    image = gr.Image()\n    generate_btn = gr.Button(\"Generate Image\")\n    generate_btn.click(image_gen, prompt, image, concurrency_limit=5)\n```\n\n----------------------------------------\n\nTITLE: Langchain Agent Setup\nDESCRIPTION: Setup for a Langchain agent with search capability using OpenAI and SerpAPI.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom langchain import hub\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent, load_tools\nfrom langchain_openai import ChatOpenAI\nfrom gradio import ChatMessage\nimport gradio as gr\n\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nmodel = ChatOpenAI(temperature=0, streaming=True)\n\ntools = load_tools([\"serpapi\"])\n\nprompt = hub.pull(\"hwchase17/openai-tools-agent\")\nagent = create_openai_tools_agent(\n    model.with_config({\"tags\": [\"agent_llm\"]}), tools, prompt\n)\nagent_executor = AgentExecutor(agent=agent, tools=tools).with_config(\n    {\"run_name\": \"Agent\"}\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Text-to-Speech with Parler TTS Streaming\nDESCRIPTION: Sets up Parler TTS model for audio generation with streaming capability. Uses Jenny fine-tuned voice model for consistent output and implements custom audio streaming functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/01_streaming-ai-generated-audio.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom streamer import ParlerTTSStreamer\nfrom transformers import AutoTokenizer, AutoFeatureExtractor, set_seed\nimport numpy as np\nimport spaces\nimport torch\nfrom threading import Thread\n\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\ntorch_dtype = torch.float16 if device != \"cpu\" else torch.float32\n\nrepo_id = \"parler-tts/parler_tts_mini_v0.1\"\n\njenny_repo_id = \"ylacombe/parler-tts-mini-jenny-30H\"\n\nmodel = ParlerTTSForConditionalGeneration.from_pretrained(\n    jenny_repo_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n).to(device)\n\ntokenizer = AutoTokenizer.from_pretrained(repo_id)\nfeature_extractor = AutoFeatureExtractor.from_pretrained(repo_id)\n\nsampling_rate = model.audio_encoder.config.sampling_rate\nframe_rate = model.audio_encoder.config.frame_rate\n\n@spaces.GPU\ndef read_response(answer):\n\n    play_steps_in_s = 2.0\n    play_steps = int(frame_rate * play_steps_in_s)\n\n    description = \"Jenny speaks at an average pace with a calm delivery in a very confined sounding environment with clear audio quality.\"\n    description_tokens = tokenizer(description, return_tensors=\"pt\").to(device)\n\n    streamer = ParlerTTSStreamer(model, device=device, play_steps=play_steps)\n    prompt = tokenizer(answer, return_tensors=\"pt\").to(device)\n\n    generation_kwargs = dict(\n        input_ids=description_tokens.input_ids,\n        prompt_input_ids=prompt.input_ids,\n        streamer=streamer,\n        do_sample=True,\n        temperature=1.0,\n        min_new_tokens=10,\n    )\n\n    set_seed(42)\n    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n    thread.start()\n\n    for new_audio in streamer:\n        print(f\"Sample of length: {round(new_audio.shape[0] / sampling_rate, 2)} seconds\")\n        yield answer, numpy_to_mp3(new_audio, sampling_rate=sampling_rate)\n```\n\n----------------------------------------\n\nTITLE: SambaNova Cloud API Integration with Gradio\nDESCRIPTION: Implementation showing how to use SambaNova Cloud API with Gradio to access full-precision open-source models like Llama.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_sambanova\n```\n\n----------------------------------------\n\nTITLE: Defining ChatMessage Schema for Advanced Messages - Gradio (Python)\nDESCRIPTION: This code snippet outlines the data class structure for `ChatMessage`, which enables advanced message formatting with metadata and options within Gradio chat interfaces. It provides the detailed schemas for ChatMessage, as well as associated MetadataDict and OptionDict typed dictionaries, using Python dataclasses and type hints. The snippet is illustrative—meant to inform developers of available fields for customizing chat messages (with content, metadata such as title, IDs, status, and preset options).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass ChatMessage:\n    content: str | Component\n    metadata: MetadataDict = None\n    options: list[OptionDict] = None\n\nclass MetadataDict(TypedDict):\n    title: NotRequired[str]\n    id: NotRequired[int | str]\n    parent_id: NotRequired[int | str]\n    log: NotRequired[str]\n    duration: NotRequired[float]\n    status: NotRequired[Literal[\"pending\", \"done\"]]\n\nclass OptionDict(TypedDict):\n    label: NotRequired[str]\n    value: str\n```\n\n----------------------------------------\n\nTITLE: Creating a Standard Gradio Demo for Image Filtering in Python\nDESCRIPTION: This snippet demonstrates how to create a standard Gradio demo with separate input and output components. It implements a simple sepia filter for images using the `gradio.Interface` class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/05_four-kinds-of-interfaces.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189], \n        [0.349, 0.686, 0.168], \n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ndemo = gr.Interface(\n    fn=sepia,\n    inputs=gr.Image(shape=(200, 200)),\n    outputs=\"image\",\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface for Image Classification (Python)\nDESCRIPTION: This snippet uses Gradio to create an interactive web interface for the `predict` function. It requires the `gradio` package and that the `predict` function is defined as shown previously. The input is an image (PIL format), and the output is a label display showing the top 3 classes. Example images are preloaded. Launching the interface allows browser-based interaction with the classifier.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-pytorch.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\n```\n\n----------------------------------------\n\nTITLE: Calculator Interface with Examples\nDESCRIPTION: Creates a calculator interface that demonstrates how to include example inputs using the examples parameter. Shows how to provide multiple sets of example data for testing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/00_the-interface-class.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\ngr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    examples=[[5, \"add\", 3], [4, \"divide\", 2], [-4, \"multiply\", 2.5]],\n    title=\"Calculator\",\n    description=\"Here's a simple calculator\"\n)\n```\n\n----------------------------------------\n\nTITLE: Anthropic Claude Integration for 20 Questions Game\nDESCRIPTION: Implementation of a 20 questions game using Anthropic's Claude API with Gradio's ChatInterface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_claude\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic Textbox Interface with Gradio\nDESCRIPTION: Builds a Gradio interface that lets users add textboxes dynamically, then merge their contents with a button. Uses gr.State to track the number of boxes, gr.render decorator for dynamic rendering, and a merge function to join text from all boxes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_merge_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    text_count = gr.State(1)\n    add_btn = gr.Button(\"Add Box\")\n    add_btn.click(lambda x: x + 1, text_count, text_count)\n\n    @gr.render(inputs=text_count)\n    def render_count(count):\n        boxes = []\n        for i in range(count):\n            box = gr.Textbox(key=i, label=f\"Box {i}\")\n            boxes.append(box)\n\n        def merge(*args):\n            return \" \".join(args)\n\n        merge_btn.click(merge, boxes, output)\n\n    merge_btn = gr.Button(\"Merge\")\n    output = gr.Textbox(label=\"Merged Output\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Horizontal Rows in Gradio Blocks (Python)\nDESCRIPTION: Demonstrates how to arrange components horizontally using gr.Row() in a Gradio Blocks application. It shows basic row creation and how to set equal height for row elements.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/02_controlling-layout.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn1 = gr.Button(\"Button 1\")\n        btn2 = gr.Button(\"Button 2\")\n```\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    with gr.Row(equal_height=True):\n        textbox = gr.Textbox()\n        btn2 = gr.Button(\"Button 2\")\n```\n\n----------------------------------------\n\nTITLE: Generating Random Bokeh Plot of Car Data in Python\nDESCRIPTION: This function creates a Bokeh plot showing car class vs highway MPG with quintile ranges. It uses the autompg2 dataset and includes error whiskers for the 20th and 80th percentiles.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef random_bokeh_plot():\n    from bokeh.models import ColumnDataSource, Whisker\n    from bokeh.plotting import figure\n    from bokeh.sampledata.autompg2 import autompg2 as df\n    from bokeh.transform import factor_cmap, jitter\n\n    classes = sorted(df[\"class\"].unique())\n\n    p = figure(\n        height=400,\n        x_range=classes,\n        background_fill_color=\"#efefef\",\n        title=\"Car class vs HWY mpg with quintile ranges\",\n    )\n    p.xgrid.grid_line_color = None\n\n    g = df.groupby(\"class\")\n    upper = g.hwy.quantile(0.80)\n    lower = g.hwy.quantile(0.20)\n    source = ColumnDataSource(data=dict(base=classes, upper=upper, lower=lower))\n\n    error = Whisker(\n        base=\"base\",\n        upper=\"upper\",\n        lower=\"lower\",\n        source=source,\n        level=\"annotation\",\n        line_width=2,\n    )\n    error.upper_head.size = 20\n    error.lower_head.size = 20\n    p.add_layout(error)\n\n    p.circle(\n        jitter(\"class\", 0.3, range=p.x_range),\n        \"hwy\",\n        source=df,\n        alpha=0.5,\n        size=13,\n        line_color=\"white\",\n        color=factor_cmap(\"class\", \"Light6\", classes),\n    )\n    return p\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks Interface with Random Sliders\nDESCRIPTION: Builds a Gradio Blocks interface with multiple sliders, some initialized with random values. The interface includes a function that multiplies the first slider value by 5 and adds the second slider value, displaying the result when a button is clicked.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_random_slider/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef func(slider_1, slider_2):\n    return slider_1 * 5 + slider_2\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(minimum=-10.2, maximum=15, label=\"Random Slider (Static)\", randomize=True)\n    slider_1 = gr.Slider(minimum=100, maximum=200, label=\"Random Slider (Input 1)\", randomize=True)\n    slider_2 = gr.Slider(minimum=10, maximum=23.2, label=\"Random Slider (Input 2)\", randomize=True)\n    slider_3 = gr.Slider(value=3, label=\"Non random slider\")\n    btn = gr.Button(\"Run\")\n    btn.click(func, inputs=[slider_1, slider_2], outputs=gr.Number())\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Adding Type Hints to `__init__` Method Parameters (Python)\nDESCRIPTION: Provides an example of a Gradio component's `__init__` method signature, demonstrating the use of Python type hints (e.g., `str | None`, `Literal[\"upload\", \"microphone\"]`, `Timer | float | None`) for its parameters. These hints are essential for the `gradio cc docs` tool to automatically generate accurate API documentation, including parameter types and default values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_1\n\nLANGUAGE: py\nCODE:\n```\ndef __init__(\n  self,\n  value: str | None = None,\n  *,\n  sources: Literal[\"upload\", \"microphone\"] = \"upload,\n  every: Timer | float | None = None,\n  ...\n):\n  ...\n```\n\n----------------------------------------\n\nTITLE: Hyperbolic AI API Integration with Gradio\nDESCRIPTION: Example demonstrating integration of Hyperbolic AI API with Gradio for accessing open-source models including the Llama family.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_hyperbolic\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Llama Index RAG Chatbot Interface with Gradio in Python\nDESCRIPTION: This snippet implements the full logic for a Retrieval-Augmented Generation chatbot using Llama Index for document search and OpenAI's GPT via Gradio UI. It defines a function 'answer', which processes chat history and uploaded files, builds an index over the documents, and generates answers to user queries. File uploads of PDF or TXT formats are supported, and OPENAI_API_KEY must be set as an environment variable prior to launching. The Gradio ChatInterface is instantiated with file support and launched as an interactive web app, returning string answers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_llamaindex/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple RAG chatbot built on top of Llama Index and Gradio. It allows you to upload any text or PDF files and ask questions about them!\n# Before running this, make sure you have exported your OpenAI API key as an environment variable:\n# export OPENAI_API_KEY=\"your-openai-api-key\"\n\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nimport gradio as gr\n\ndef answer(message, history):\n    files = []\n    for msg in history:\n        if msg['role'] == \"user\" and isinstance(msg['content'], tuple):\n            files.append(msg['content'][0])\n    for file in message[\"files\"]:\n        files.append(file)\n\n    documents = SimpleDirectoryReader(input_files=files).load_data()\n    index = VectorStoreIndex.from_documents(documents)\n    query_engine = index.as_query_engine()\n    return str(query_engine.query(message[\"text\"]))\n\ndemo = gr.ChatInterface(\n    answer,\n    type=\"messages\",\n    title=\"Llama Index RAG Chatbot\",\n    description=\"Upload any text or pdf files and ask questions about them!\",\n    textbox=gr.MultimodalTextbox(file_types=[\".pdf\", \".txt\"]),\n    multimodal=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Gradio Interface in Python\nDESCRIPTION: This code snippet demonstrates how to create a basic Gradio interface with a text input, a slider, and a text output. It defines a greeting function and wraps it with a Gradio Interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/01_getting-started/01_quickstart.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name, intensity):\n    return f\"Hello {name}!\" * intensity\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Image Classification with Gradio and Comet Integration\nDESCRIPTION: Complete example of setting up an image classification model with ResNet18, creating a Gradio interface, and logging it to Comet.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport comet_ml\n\nimport requests\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\n\ntorch.hub.download_url_to_file(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nmodel = torch.hub.load(\"pytorch/vision:v0.6.0\", \"resnet18\", pretrained=True).eval()\nmodel = model.to(device)\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\n\ndef predict(inp):\n    inp = Image.fromarray(inp.astype(\"uint8\"), \"RGB\")\n    inp = transforms.ToTensor()(inp).unsqueeze(0)\n    with torch.no_grad():\n        prediction = torch.nn.functional.softmax(model(inp.to(device))[0], dim=0)\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\n\ninputs = gr.Image()\noutputs = gr.Label(num_top_classes=3)\n\nio = gr.Interface(\n    fn=predict, inputs=inputs, outputs=outputs, examples=[\"dog.jpg\"]\n)\nio.launch(inline=False, share=True)\n\nexperiment = comet_ml.Experiment()\nexperiment.add_tag(\"image-classifier\")\n\nio.integrate(comet_ml=experiment)\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio Chat Interface with HF Transformers (Python)\nDESCRIPTION: This Python script initializes and runs a Gradio chat interface using the Hugging Face `transformers` library. It loads the `HuggingFaceTB/SmolLM2-135M-Instruct` model and its corresponding tokenizer, configuring them to run on the specified device ('cpu' or 'cuda'). The `predict` function handles the chat logic: it takes the user message and conversation history, formats them using the chat template, generates a response using the loaded language model (`model.generate`), extracts the assistant's reply, and returns it. Finally, it creates a `gr.ChatInterface` instance linked to the `predict` function and launches the web application when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hf_transformers/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nimport gradio as gr\n\ncheckpoint = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\ndevice = \"cpu\"  # \"cuda\" or \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)\n\ndef predict(message, history):\n    history.append({\"role\": \"user\", \"content\": message})\n    input_text = tokenizer.apply_chat_template(history, tokenize=False)\n    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)  # type: ignore\n    outputs = model.generate(inputs, max_new_tokens=100, temperature=0.2, top_p=0.9, do_sample=True)\n    decoded = tokenizer.decode(outputs[0])\n    response = decoded.split(\"<|im_start|>assistant\\n\")[-1].split(\"<|im_end|>\")[0]\n    return response\n\ndemo = gr.ChatInterface(predict, type=\"messages\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Building the Gradio WebRTC Streaming Interface (Python)\nDESCRIPTION: This code defines the Gradio Blocks interface that uses the WebRTC custom component for live video streaming and real-time object detection visualization. It includes a confidence threshold slider and processes the webcam stream via the `detection` function with a 10-second time limit per stream. The layout leverages custom CSS to center components. Dependencies include Gradio 5.0+, `gradio_webrtc`, and the previously defined `detection` function. Input is a live video stream, and output is the processed annotated stream.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/02_object-detection-from-webcam-with-webrtc.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\nfrom gradio_webrtc import WebRTC\\n\\ncss = \"\"\".my-group {max-width: 600px !important; max-height: 600px !important;}\\n         .my-column {display: flex !important; justify-content: center !important; align-items: center !important;}\"\"\"\\n\\nwith gr.Blocks(css=css) as demo:\\n    gr.HTML(\\n        \"\"\"\\n        <h1 style='text-align: center'>\\n        YOLOv10 Webcam Stream (Powered by WebRTC ⚡️)\\n        </h1>\\n        \"\"\"\\n    )\\n    with gr.Column(elem_classes=[\"my-column\"]):\\n        with gr.Group(elem_classes=[\"my-group\"]):\\n            image = WebRTC(label=\"Stream\", rtc_configuration=rtc_configuration)\\n            conf_threshold = gr.Slider(\\n                label=\"Confidence Threshold\",\\n                minimum=0.0,\\n                maximum=1.0,\\n                step=0.05,\\n                value=0.30,\\n            )\\n\\n        image.stream(\\n            fn=detection, inputs=[image, conf_threshold], outputs=[image], time_limit=10\\n        )\\n\\nif __name__ == \"__main__\":\\n    demo.launch()\\n\n```\n\n----------------------------------------\n\nTITLE: Basic SQLite Query Visualization in Gradio\nDESCRIPTION: Demonstrates how to connect to a SQLite database and create a line plot visualization using Gradio. Uses SQLAlchemy to query data and converts it to a pandas DataFrame.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/04_connecting-to-a-database.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom sqlalchemy import create_engine\nimport pandas as pd\n\nengine = create_engine('sqlite:///your_database.db')\n\nwith gr.Blocks() as demo:\n    gr.LinePlot(pd.read_sql_query(\"SELECT time, price from flight_info;\", engine), x=\"time\", y=\"price\")\n```\n\n----------------------------------------\n\nTITLE: Basic Chatbot Implementation\nDESCRIPTION: Simple example showing how to create a Gradio chatbot with message metadata for displaying thoughts.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(\n        type=\"messages\",\n        value=[\n            gr.ChatMessage(\n                role=\"user\", \n                content=\"What is the weather in San Francisco?\"\n            ),\n            gr.ChatMessage(\n                role=\"assistant\", \n                content=\"I need to use the weather API tool?\",\n                metadata={\"title\":  \"🧠 Thinking\"}\n        ]\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio Tabbed Interface for TTS and STT\nDESCRIPTION: This Python script utilizes the Gradio library to create and launch a web interface showcasing Text-to-Speech (TTS) and Speech-to-Text (STT). It imports Gradio, loads pre-trained TTS ('facebook/fastspeech2-en-ljspeech') and STT ('facebook/wav2vec2-base-960h') models from Hugging Face Hub using `gr.load`, providing specific configurations like examples, descriptions, and input types (microphone for STT). The two interfaces are then combined into a `gr.TabbedInterface` and the application is launched using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stt_or_tts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ntts_examples = [\n    \"I love learning machine learning\",\n    \"How do you do?\",\n]\n\ntts_demo = gr.load(\n    \"huggingface/facebook/fastspeech2-en-ljspeech\",\n    title=None,\n    examples=tts_examples,\n    description=\"Give me something to say!\",\n    cache_examples=False\n)\n\nstt_demo = gr.load(\n    \"huggingface/facebook/wav2vec2-base-960h\",\n    title=None,\n    inputs=gr.Microphone(type=\"filepath\"),\n    description=\"Let me try to guess what you're saying!\",\n    cache_examples=False\n)\n\ndemo = gr.TabbedInterface([tts_demo, stt_demo], [\"Text-to-speech\", \"Speech-to-text\"])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Defining and Running an OpenAI Chatbot with Gradio in Python\nDESCRIPTION: This snippet defines a simple chatbot using OpenAI's API with a Gradio chat interface. It requires the environment variable 'OPENAI_API_KEY' to authenticate with OpenAI. The 'predict' function appends user messages to the conversation history, streams completions from the OpenAI GPT-4o-mini model, and yields incremental outputs for real-time UI updates. Gradio's ChatInterface is used to create an interactive UI, which is launched if the script is run as the main module. Inputs are user messages and conversation history; outputs are text responses streamed from the model. Ensure dependencies are installed and a valid API key is configured before running.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_openai/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple general-purpose chatbot built on top of OpenAI API. \n# Before running this, make sure you have exported your OpenAI API key as an environment variable:\n# export OPENAI_API_KEY=\"your-openai-api-key\"\n\nfrom openai import OpenAI\nimport gradio as gr\n\nclient = OpenAI()\n\ndef predict(message, history):\n    history.append({\"role\": \"user\", \"content\": message})\n    stream = client.chat.completions.create(messages=history, model=\"gpt-4o-mini\", stream=True)\n    chunks = []\n    for chunk in stream:\n        chunks.append(chunk.choices[0].delta.content or \"\")\n        yield \"\".join(chunks)\n\ndemo = gr.ChatInterface(predict, type=\"messages\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Counter and List Generator\nDESCRIPTION: Creates an interactive Gradio interface with two functions: a counter that yields numbers with delays and a list generator. Uses Blocks API to create a UI with number input, buttons, and text output. The counter function yields numbers with 0.5 second delays, while the list function returns a complete range of numbers instantly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/count_generator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef count(n):\n    for i in range(int(n)):\n        time.sleep(0.5)\n        yield i\n\ndef show(n):\n    return str(list(range(int(n))))\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        num = gr.Number(value=10)\n        with gr.Row():\n            count_btn = gr.Button(\"Count\")\n            list_btn = gr.Button(\"List\")\n    with gr.Column():\n        out = gr.Textbox()\n\n    count_btn.click(count, num, out)\n    list_btn.click(show, num, out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Prediction UI with Gradio Dataframe Component in Python\nDESCRIPTION: This Python snippet creates an interactive Gradio interface for making failure predictions using a data science model. It loads a pre-trained model via joblib, sets up input/output components as dynamic Dataframes, and returns predictions through an inference function. Dependencies include gradio, pandas, joblib, and huggingface datasets. The input is a flexible dataframe, and output is a predictions dataframe; examples help users quickly test the UI. The model must be serialized as \\\"model.pkl\\\"; user must ensure column match between input, model, and headers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-for-tabular-workflows.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\nimport pandas as pd\\nimport joblib\\nimport datasets\\n\\n\\ninputs = [gr.Dataframe(row_count = (2, \\\"dynamic\\\"), col_count=(4,\\\"dynamic\\\"), label=\\\"Input Data\\\", interactive=1)]\\n\\noutputs = [gr.Dataframe(row_count = (2, \\\"dynamic\\\"), col_count=(1, \\\"fixed\\\"), label=\\\"Predictions\\\", headers=[\\\"Failures\\\"])]\\n\\nmodel = joblib.load(\\\"model.pkl\\\")\\n\\n# we will give our dataframe as example\\ndf = datasets.load_dataset(\\\"merve/supersoaker-failures\\\")\\ndf = df[\\\"train\\\"].to_pandas()\\n\\ndef infer(input_dataframe):\\n  return pd.DataFrame(model.predict(input_dataframe))\\n\\ngr.Interface(fn = infer, inputs = inputs, outputs = outputs, examples = [[df.head(2)]]).launch()\n```\n\n----------------------------------------\n\nTITLE: Image Processing Interface\nDESCRIPTION: Example of creating an interface for image processing, specifically a sepia filter. Shows how to handle image inputs and outputs using NumPy arrays and the Image component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/00_the-interface-class.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189], \n        [0.349, 0.686, 0.168], \n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ngr.Interface(fn=sepia, inputs=gr.Image(), outputs=gr.Image())\n```\n\n----------------------------------------\n\nTITLE: Defining a Gradio App with Session State\nDESCRIPTION: Provides a Python example of creating a Gradio application using `gr.Blocks` that utilizes session state via `gr.State`. The app takes a word input, counts its occurrences in a persistent list stored in the state, updates the state with the new word, and displays the count. This demonstrates how stateful behavior can be implemented in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef count(word, list_of_words):\n    return list_of_words.count(word), list_of_words + [word]\n\nwith gr.Blocks() as demo:\n    words = gr.State([])\n    textbox = gr.Textbox()\n    number = gr.Number()\n    textbox.submit(count, inputs=[textbox, words], outputs=[number, words])\n    \ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Streaming Video with Gradio\nDESCRIPTION: Demonstrates how to create a Gradio interface that streams video by repeatedly yielding a video file. It uses a webcam input and a video output component with streaming enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/02_streaming-outputs.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom time import sleep\n\ndef keep_repeating(video_file):\n    for _ in range(10):\n        sleep(0.5)\n        yield video_file\n\ngr.Interface(keep_repeating,\n             gr.Video(sources=[\"webcam\"], format=\"mp4\"),\n             gr.Video(streaming=True, autoplay=True)\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_canvas_size/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Controlling Component Widths in Gradio Rows (Python)\nDESCRIPTION: Illustrates how to control the widths of elements in a Gradio Row using the scale parameter. It shows how different scale values affect the expansion of components within the row.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/02_controlling-layout.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    with gr.Row():\n        btn0 = gr.Button(\"Button 0\", scale=0)\n        btn1 = gr.Button(\"Button 1\", scale=1)\n        btn2 = gr.Button(\"Button 2\", scale=2)\n```\n\n----------------------------------------\n\nTITLE: Implementing XGBoost Income Prediction with SHAP Explainability in Gradio\nDESCRIPTION: This code snippet sets up a Gradio interface for income prediction using XGBoost. It includes data loading, preprocessing, model training, prediction function, interpretation function using SHAP values, and the Gradio UI components for user input and result display.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/xgboost-income-prediction-with-explainability/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# type: ignore\nimport gradio as gr\nimport random\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport shap\nimport xgboost as xgb\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"scikit-learn/adult-census-income\")\nX_train = dataset[\"train\"].to_pandas()\n_ = X_train.pop(\"fnlwgt\")\n_ = X_train.pop(\"race\")\ny_train = X_train.pop(\"income\")\ny_train = (y_train == \">50K\").astype(int)\ncategorical_columns = [\n    \"workclass\",\n    \"education\",\n    \"marital.status\",\n    \"occupation\",\n    \"relationship\",\n    \"sex\",\n    \"native.country\",\n]\nX_train = X_train.astype({col: \"category\" for col in categorical_columns})\ndata = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\nmodel = xgb.train(params={\"objective\": \"binary:logistic\"}, dtrain=data)\nexplainer = shap.TreeExplainer(model)\n\ndef predict(*args):\n    df = pd.DataFrame([args], columns=X_train.columns)\n    df = df.astype({col: \"category\" for col in categorical_columns})\n    pos_pred = model.predict(xgb.DMatrix(df, enable_categorical=True))\n    return {\">50K\": float(pos_pred[0]), \"<=50K\": 1 - float(pos_pred[0])}\n\ndef interpret(*args):\n    df = pd.DataFrame([args], columns=X_train.columns)\n    df = df.astype({col: \"category\" for col in categorical_columns})\n    shap_values = explainer.shap_values(xgb.DMatrix(df, enable_categorical=True))\n    scores_desc = list(zip(shap_values[0], X_train.columns))\n    scores_desc = sorted(scores_desc)\n    fig_m = plt.figure(tight_layout=True)\n    plt.barh([s[1] for s in scores_desc], [s[0] for s in scores_desc])\n    plt.title(\"Feature Shap Values\")\n    plt.ylabel(\"Shap Value\")\n    plt.xlabel(\"Feature\")\n    plt.tight_layout()\n    return fig_m\n\nunique_class = sorted(X_train[\"workclass\"].unique())\nunique_education = sorted(X_train[\"education\"].unique())\nunique_marital_status = sorted(X_train[\"marital.status\"].unique())\nunique_relationship = sorted(X_train[\"relationship\"].unique())\nunique_occupation = sorted(X_train[\"occupation\"].unique())\nunique_sex = sorted(X_train[\"sex\"].unique())\nunique_country = sorted(X_train[\"native.country\"].unique())\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"\"\"\n    **Income Classification with XGBoost 💰**:  This demo uses an XGBoost classifier predicts income based on demographic factors, along with Shapley value-based *explanations*. The [source code for this Gradio demo is here](https://huggingface.co/spaces/gradio/xgboost-income-prediction-with-explainability/blob/main/app.py).\n    \"\"\")\n    with gr.Row():\n        with gr.Column():\n            age = gr.Slider(label=\"Age\", minimum=17, maximum=90, step=1, randomize=True)\n            work_class = gr.Dropdown(\n                label=\"Workclass\",\n                choices=unique_class,\n                value=lambda: random.choice(unique_class),\n            )\n            education = gr.Dropdown(\n                label=\"Education Level\",\n                choices=unique_education,\n                value=lambda: random.choice(unique_education),\n            )\n            years = gr.Slider(\n                label=\"Years of schooling\",\n                minimum=1,\n                maximum=16,\n                step=1,\n                randomize=True,\n            )\n            marital_status = gr.Dropdown(\n                label=\"Marital Status\",\n                choices=unique_marital_status,\n                value=lambda: random.choice(unique_marital_status),\n            )\n            occupation = gr.Dropdown(\n                label=\"Occupation\",\n                choices=unique_occupation,\n                value=lambda: random.choice(unique_occupation),\n            )\n            relationship = gr.Dropdown(\n                label=\"Relationship Status\",\n                choices=unique_relationship,\n                value=lambda: random.choice(unique_relationship),\n            )\n            sex = gr.Dropdown(\n                label=\"Sex\", choices=unique_sex, value=lambda: random.choice(unique_sex)\n            )\n            capital_gain = gr.Slider(\n                label=\"Capital Gain\",\n                minimum=0,\n                maximum=100000,\n                step=500,\n                randomize=True,\n            )\n            capital_loss = gr.Slider(\n                label=\"Capital Loss\", minimum=0, maximum=10000, step=500, randomize=True\n            )\n            hours_per_week = gr.Slider(\n                label=\"Hours Per Week Worked\", minimum=1, maximum=99, step=1\n            )\n            country = gr.Dropdown(\n                label=\"Native Country\",\n                choices=unique_country,\n                value=lambda: random.choice(unique_country),\n            )\n        with gr.Column():\n            label = gr.Label()\n            plot = gr.Plot()\n            with gr.Row():\n                predict_btn = gr.Button(value=\"Predict\")\n                interpret_btn = gr.Button(value=\"Explain\")\n            predict_btn.click(\n                predict,\n                inputs=[\n                    age,\n                    work_class,\n                    education,\n                    years,\n                    marital_status,\n                    occupation,\n                    relationship,\n                    sex,\n                    capital_gain,\n                    capital_loss,\n                    hours_per_week,\n                    country,\n                ],\n                outputs=[label],\n            )\n            interpret_btn.click(\n                interpret,\n                inputs=[\n                    age,\n                    work_class,\n                    education,\n                    years,\n                    marital_status,\n                    occupation,\n                    relationship,\n                    sex,\n                    capital_gain,\n                    capital_loss,\n                    hours_per_week,\n                    country,\n                ],\n                outputs=[plot],\n            )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Filters with Event Listeners in Gradio Dashboard\nDESCRIPTION: Implementation example showing how to add interactive filters using event listeners in a Gradio dashboard. The code demonstrates filtering functionality through standard Gradio form components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/03_filters-tables-and-stats.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n$code_plot_guide_filters_events\n```\n\n----------------------------------------\n\nTITLE: Implementing YOLOv10 Inference Function (Python)\nDESCRIPTION: This code sets up the YOLOv10 model for inference by downloading the ONNX file from Hugging Face and initializing a custom YOLOv10 class. The `detection` function receives a numpy image, resizes it, and uses the model to perform object detection by confidence threshold. It returns an annotated image as a numpy array. Required dependencies include `huggingface_hub`, an `inference.py` module with `YOLOv10` implementation, OpenCV, and a suitable ONNX Runtime. Expects access to a GPU unless using CPU-compatible runtime.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/02_object-detection-from-webcam-with-webrtc.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import hf_hub_download\\nfrom inference import YOLOv10\\n\\nmodel_file = hf_hub_download(\\n    repo_id=\"onnx-community/yolov10n\", filename=\"onnx/model.onnx\"\\n)\\n\\nmodel = YOLOv10(model_file)\\n\\ndef detection(image, conf_threshold=0.3):\\n    image = cv2.resize(image, (model.input_width, model.input_height))\\n    new_image = model.detect_objects(image, conf_threshold)\\n    return new_image\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing English to German Translation with Gradio Interface\nDESCRIPTION: This code creates a Gradio interface for translating English text to German. It uses a pre-trained T5 model from Hugging Face Transformers for translation. The interface includes input and output text boxes, a translate button, and example inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/english_translator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"t5-base\")\n\ndef translate(text):\n    return pipe(text)[0][\"translation_text\"]  # type: ignore\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            english = gr.Textbox(label=\"English text\")\n            translate_btn = gr.Button(value=\"Translate\")\n        with gr.Column():\n            german = gr.Textbox(label=\"German Text\")\n\n    translate_btn.click(translate, inputs=english, outputs=german, api_name=\"translate-to-german\")\n    examples = gr.Examples(examples=[\"I went to the supermarket yesterday.\", \"Helen is a good swimmer.\"],\n                           inputs=[english])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Complete Gradio Discord Bot Implementation\nDESCRIPTION: Full implementation of a Discord bot that integrates with a Gradio application, handling messages, images, and streaming responses.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/06_creating-a-discord-bot-from-a-gradio-app.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport discord\nfrom gradio_client import Client, handle_file\nimport httpx\nimport os\n\nTOKEN = #PASTE YOUR DISCORD BOT TOKEN HERE\n\nintents = discord.Intents.default()\nintents.message_content = True\n\nclient = discord.Client(intents=intents)\ngradio_client = Client(\"abidlabs/gradio-playground-bot\")\n\ndef download_image(attachment):\n    response = httpx.get(attachment.url)\n    image_path = f\"./images/{attachment.filename}\"\n    os.makedirs(\"./images\", exist_ok=True)\n    with open(image_path, \"wb\") as f:\n        f.write(response.content)\n    return image_path\n\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')\n\n@client.event\nasync def on_message(message):\n    # Ignore messages from the bot itself\n    if message.author == client.user:\n        return\n\n    # Check if the bot is mentioned in the message and reply\n    if client.user in message.mentions:\n        # Extract the message content without the bot mention\n        clean_message = message.content.replace(f\"<@{client.user.id}>\", \"\").strip()\n\n        # Handle images (only the first image is used)\n        files = []\n        if message.attachments:\n            for attachment in message.attachments:\n                if any(attachment.filename.lower().endswith(ext) for ext in ['png', 'jpg', 'jpeg', 'gif', 'webp']):\n                    image_path = download_image(attachment)\n                    files.append(handle_file(image_path))\n                    break\n        \n        # Stream the responses to the channel\n        for response in gradio_client.submit(\n            message={\"text\": clean_message, \"files\": files},\n        ):\n            await message.channel.send(response[-1])\n\nclient.run(TOKEN)\n```\n\n----------------------------------------\n\nTITLE: Real-Time DataFrame and LinePlot Visualization with Gradio - Python\nDESCRIPTION: This snippet defines a Gradio UI using Blocks to display the fetched Google Sheets data as both a table (DataFrame) and a line plot (LinePlot), updating every 5 seconds. It uses the previously defined get_data function as a data source, demonstrates basic layout with rows and columns, and highlights the use of timer-based refreshing. Requires 'gradio' and 'pandas' libraries, and expects get_data to return up-to-date DataFrames. Main parameters include refresh frequency, plot axes, and dimension settings. This pattern is repeated for both public and private sheet access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# \\ud83d\\udcc8 Real-Time Line Plot\")\n    with gr.Row():\n        with gr.Column():\n            gr.DataFrame(get_data, every=gr.Timer(5))\n        with gr.Column():\n            gr.LinePlot(get_data, every=gr.Timer(5), x=\"Date\", y=\"Sales\", y_title=\"Sales ($ millions)\", overlay_point=True, width=500, height=500)\n\ndemo.queue().launch()  # Run the demo with queuing enabled\n```\n\n----------------------------------------\n\nTITLE: Chaining Model Outputs in Gradio Blocks (Speech-to-Text to Sentiment) using Python\nDESCRIPTION: Presents a multi-step Gradio application in Python where the output of one process (simulated speech-to-text) serves as the input for another (sentiment analysis). This demonstrates how Blocks can orchestrate complex workflows by chaining event listeners and data flows between components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n$code_blocks_speech_text_sentiment\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Chat Interface with Gradio\nDESCRIPTION: This code creates a Gradio ChatInterface with a slow echo function that simulates typing. It includes time-based character output, manual flagging options, and chat history saving.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_streaming_echo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport gradio as gr\n\ndef slow_echo(message, history):\n    for i in range(len(message)):\n        time.sleep(0.05)\n        yield \"You typed: \" + message[: i + 1]\n\ndemo = gr.ChatInterface(\n    slow_echo,\n    type=\"messages\",\n    flagging_mode=\"manual\",\n    flagging_options=[\"Like\", \"Spam\", \"Inappropriate\", \"Other\"],\n    save_history=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Chatbot with Zephyr Model\nDESCRIPTION: Creates a full chatbot implementation using Gradio and the Hugging Face Zephyr model. Features include streaming responses, undo/retry functionality, and like/dislike feedback. The chatbot uses the HuggingFaceH4/zephyr-7b-beta model for generating responses and implements a user-friendly interface with custom avatar.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_retry_undo_like/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import InferenceClient\nimport gradio as gr\n\nclient = InferenceClient()\n\ndef respond(\n    prompt: str,\n    history,\n):\n    if not history:\n        history = [{\"role\": \"system\", \"content\": \"You are a friendly chatbot\"}]\n    history.append({\"role\": \"user\", \"content\": prompt})\n\n    yield history\n\n    response = {\"role\": \"assistant\", \"content\": \"\"}\n    for message in client.chat_completion( # type: ignore\n        history,\n        temperature=0.95,\n        top_p=0.9,\n        max_tokens=512,\n        stream=True,\n        model=\"HuggingFaceH4/zephyr-7b-beta\"\n    ):\n        response[\"content\"] += message.choices[0].delta.content or \"\"\n        yield history + [response]\n\n\ndef handle_undo(history, undo_data: gr.UndoData):\n    return history[:undo_data.index], history[undo_data.index]['content']\n\ndef handle_retry(history, retry_data: gr.RetryData):\n    new_history = history[:retry_data.index]\n    previous_prompt = history[retry_data.index]['content']\n    yield from respond(previous_prompt, new_history)\n\n\ndef handle_like(data: gr.LikeData):\n    if data.liked:\n        print(\"You upvoted this response: \", data.value)\n    else:\n        print(\"You downvoted this response: \", data.value)\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Chat with Hugging Face Zephyr 7b 🤗\")\n    chatbot = gr.Chatbot(\n        label=\"Agent\",\n        type=\"messages\",\n        avatar_images=(\n            None,\n            \"https://em-content.zobj.net/source/twitter/376/hugging-face_1f917.png\",\n        ),\n    )\n    prompt = gr.Textbox(max_lines=1, label=\"Chat Message\")\n    prompt.submit(respond, [prompt, chatbot], [chatbot])\n    prompt.submit(lambda: \"\", None, [prompt])\n    chatbot.undo(handle_undo, chatbot, [chatbot, prompt])\n    chatbot.retry(handle_retry, chatbot, [chatbot])\n    chatbot.like(handle_like, None, None)\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Text Autocomplete Application with Gradio and GPT-2\nDESCRIPTION: Creates a text autocomplete application using Gradio Blocks and the GPT-2 XL model from Hugging Face. The code loads the model as an interface, creates a single textbox that acts as both input and output, and implements a button to trigger text completion.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/autocomplete/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\n# save your HF API token from https:/hf.co/settings/tokens as an env variable to avoid rate limiting\nhf_token = os.getenv(\"hf_token\")\n\n# load a model from https://hf.co/models as an interface, then use it as an api\n# you can remove the hf_token parameter if you don't care about rate limiting.\napi = gr.load(\"huggingface/gpt2-xl\", hf_token=hf_token)\n\ndef complete_with_gpt(text):\n    return text[:-50] + api(text[-50:])\n\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox(placeholder=\"Type here...\", lines=4)\n    btn = gr.Button(\"Autocomplete\")\n\n    # define what will run when the button is clicked, here the textbox is used as both an input and an output\n    btn.click(fn=complete_with_gpt, inputs=textbox, outputs=textbox, queue=False)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Client Securely with Gradio - Python\nDESCRIPTION: This snippet demonstrates importing essential libraries and initializing the Groq API client securely using an environment variable to access the API key. It raises an error if the API key is not provided, ensuring safe operation. Dependencies include the 'groq', 'gradio', 'soundfile', 'dataclasses', and 'os' modules, with the key parameter being the 'GROQ_API_KEY' in environment variables. The output is an authenticated Groq client object, and the code must run in an environment where the API key is set.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport groq\nimport gradio as gr\nimport soundfile as sf\nfrom dataclasses import dataclass, field\nimport os\n\n# Initialize Groq client securely\napi_key = os.environ.get(\"GROQ_API_KEY\")\nif not api_key:\n    raise ValueError(\"Please set the GROQ_API_KEY environment variable.\")\nclient = groq.Client(api_key=api_key)\n```\n\n----------------------------------------\n\nTITLE: Local Chatbot with Hugging Face Transformers\nDESCRIPTION: Example of creating a local chatbot using SmolLM2-135M-Instruct model via Hugging Face Transformers library and Gradio's ChatInterface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_hf_transformers\n```\n\n----------------------------------------\n\nTITLE: Triggering Gradio Events on Input Change in Python\nDESCRIPTION: Demonstrates using the `.change()` event listener in Gradio Blocks with Python. This listener triggers the associated function (`welcome`) whenever the value of the input component (`inp` Textbox) changes (e.g., user types), enabling real-time updates based on user input.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n$code_blocks_hello\n```\n\n----------------------------------------\n\nTITLE: Simple Webcam Streaming in Gradio\nDESCRIPTION: Demonstrates the simplest streaming app that returns the webcam stream unmodified. It uses gr.Image for input and output, with the stream event to process input.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/03_streaming-inputs.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef identity(img):\n    return img\n\ndemo = gr.Interface(\n    identity,\n    gr.Image(source=\"webcam\", streaming=True),\n    \"image\",\n    live=True\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Updating Gradio Component Configuration Dynamically in Python\nDESCRIPTION: Illustrates how to dynamically change a Gradio component's configuration (e.g., visibility, interactivity) within an event listener function in Python. Instead of just returning a value, the function returns a new instance of the component (`gr.Textbox(...)`) with updated properties like `visible=True`, `interactive=True`, and optionally a new `value`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n$code_blocks_essay_simple\n```\n\n----------------------------------------\n\nTITLE: Implementing EfficientNet-Lite4 Image Classification with ONNX and Gradio\nDESCRIPTION: Complete implementation of an image classification demo using EfficientNet-Lite4 ONNX model with Gradio interface. The code handles model loading, image preprocessing, inference, and creates an interactive web interface. Includes image resizing, normalization, and label mapping functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-ONNX-on-Hugging-Face.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nimport cv2\nimport json\nimport gradio as gr\nfrom huggingface_hub import hf_hub_download\nfrom onnx import hub\nimport onnxruntime as ort\n\n# loads ONNX model from ONNX Model Zoo\nmodel = hub.load(\"efficientnet-lite4\")\n# loads the labels text file\nlabels = json.load(open(\"labels_map.txt\", \"r\"))\n\n# sets image file dimensions to 224x224 by resizing and cropping image from center\ndef pre_process_edgetpu(img, dims):\n    output_height, output_width, _ = dims\n    img = resize_with_aspectratio(img, output_height, output_width, inter_pol=cv2.INTER_LINEAR)\n    img = center_crop(img, output_height, output_width)\n    img = np.asarray(img, dtype='float32')\n    # converts jpg pixel value from [0 - 255] to float array [-1.0 - 1.0]\n    img -= [127.0, 127.0, 127.0]\n    img /= [128.0, 128.0, 128.0]\n    return img\n\n# resizes the image with a proportional scale\ndef resize_with_aspectratio(img, out_height, out_width, scale=87.5, inter_pol=cv2.INTER_LINEAR):\n    height, width, _ = img.shape\n    new_height = int(100. * out_height / scale)\n    new_width = int(100. * out_width / scale)\n    if height > width:\n        w = new_width\n        h = int(new_height * height / width)\n    else:\n        h = new_height\n        w = int(new_width * width / height)\n    img = cv2.resize(img, (w, h), interpolation=inter_pol)\n    return img\n\n# crops the image around the center based on given height and width\ndef center_crop(img, out_height, out_width):\n    height, width, _ = img.shape\n    left = int((width - out_width) / 2)\n    right = int((width + out_width) / 2)\n    top = int((height - out_height) / 2)\n    bottom = int((height + out_height) / 2)\n    img = img[top:bottom, left:right]\n    return img\n\n\nsess = ort.InferenceSession(model)\n\ndef inference(img):\n  img = cv2.imread(img)\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n  img = pre_process_edgetpu(img, (224, 224, 3))\n\n  img_batch = np.expand_dims(img, axis=0)\n\n  results = sess.run([\"Softmax:0\"], {\"images:0\": img_batch})[0]\n  result = reversed(results[0].argsort()[-5:])\n  resultdic = {}\n  for r in result:\n      resultdic[labels[str(r)]] = float(results[0][r])\n  return resultdic\n\ntitle = \"EfficientNet-Lite4\"\ndescription = \"EfficientNet-Lite 4 is the largest variant and most accurate of the set of EfficientNet-Lite model. It is an integer-only quantized model that produces the highest accuracy of all of the EfficientNet models. It achieves 80.4% ImageNet top-1 accuracy, while still running in real-time (e.g. 30ms/image) on a Pixel 4 CPU.\"\nexamples = [['catonnx.jpg']]\ngr.Interface(inference, gr.Image(type=\"filepath\"), \"label\", title=title, description=description, examples=examples).launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Matrix Transpose Demo in Python\nDESCRIPTION: Defines and launches a Gradio interface for transposing numeric matrices using NumPy. It imports dependencies (NumPy and Gradio), defines a function to transpose matrices, and sets up an interface with a dataframe input (default 5x3, editable and supports fullscreen), various preset example matrices, and disables example caching. Upon execution as the main module, it launches the app. Inputs are expected as NumPy arrays of numbers; outputs are transposed NumPy arrays. Dependencies include NumPy and Gradio, and it requires Python execution within an environment supporting these libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/matrix_transpose/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nimport gradio as gr\n\ndef transpose(matrix):\n    return matrix.T\n\ndemo = gr.Interface(\n    transpose,\n    gr.Dataframe(type=\"numpy\", datatype=\"number\", row_count=5, col_count=3, show_fullscreen_button=True),\n    \"numpy\",\n    examples=[\n        [np.zeros((30, 30)).tolist()],\n        [np.ones((2, 2)).tolist()],\n        [np.random.randint(0, 10, (3, 10)).tolist()],\n        [np.random.randint(0, 10, (10, 3)).tolist()],\n        [np.random.randint(0, 10, (10, 10)).tolist()],\n    ],\n    cache_examples=False\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Chatbot Interface for Gemini Thinking in Python\nDESCRIPTION: Defines the Gradio application interface using `gr.Blocks`. It sets up a chatbot display (`gr.Chatbot`), a user input box (`gr.Textbox`), and connects them with event handlers using `.submit()` and `.then()`. When the user submits a message via the `input_box`, it first stores the message, clears the input, then calls an assumed `user_message` function (not provided in the snippet) to add the user's message to the `chatbot` display, and finally calls the `stream_gemini_response` function (defined previously) to fetch and display the Gemini model's thoughts and final response stream in the `chatbot` component. The `demo.launch()` command starts the Gradio web server, making the chatbot accessible. Depends on `gradio` and the `stream_gemini_response` function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Chat with Gemini 2.0 Flash and See its Thoughts 💭\")\n    \n    chatbot = gr.Chatbot(\n        type=\"messages\",\n        label=\"Gemini2.0 'Thinking' Chatbot\",\n        render_markdown=True,\n    )\n    \n    input_box = gr.Textbox(\n        lines=1,\n        label=\"Chat Message\",\n        placeholder=\"Type your message here and press Enter...\"\n    )\n    \n    # Set up event handlers\n    msg_store = gr.State(\"\")  # Store for preserving user message\n    \n    input_box.submit(\n        lambda msg: (msg, msg, \"\"),  # Store message and clear input\n        inputs=[input_box],\n        outputs=[msg_store, input_box, input_box],\n        queue=False\n    ).then(\n        user_message,  # Add user message to chat\n        inputs=[msg_store, chatbot],\n        outputs=[input_box, chatbot],\n        queue=False\n    ).then(\n        stream_gemini_response,  # Generate and stream response\n        inputs=[msg_store, chatbot],\n        outputs=chatbot\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Custom UI Implementation with Gradio and Transformers.js\nDESCRIPTION: Advanced implementation showing how to customize the Gradio interface with manual UI definition and JSON output formatting for sentiment analysis results.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/06_gradio-lite-and-transformers-js.md#2025-04-23_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n\t<body>\n\t\t<gradio-lite>\nimport gradio as gr\nfrom transformers_js_py import pipeline\n\npipe = await pipeline('sentiment-analysis')\n\nasync def fn(text):\n\tresult = await pipe(text)\n\treturn result\n\ndemo = gr.Interface(\n\tfn=fn,\n\tinputs=gr.Textbox(),\n\toutputs=gr.JSON(),\n)\n\ndemo.launch()\n\n\t\t\t<gradio-requirements>\ntransformers-js-py\n\t\t\t</gradio-requirements>\n\t\t</gradio-lite>\n\t</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Binding Multiple Triggers to a Gradio Function using gr.on in Python\nDESCRIPTION: Shows how to use `gr.on()` in Python to attach multiple event triggers (submit button's `click` event and textbox's `submit` event) to the same handler function (`greet`). This avoids code duplication by centralizing the logic for different user interactions that should result in the same action.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n$code_on_listener_basic\n```\n\n----------------------------------------\n\nTITLE: Implementing Depth Estimation and 3D Model Generation\nDESCRIPTION: Complete implementation of depth estimation using DPT model and 3D model generation using Open3D. Includes image processing, depth prediction, point cloud generation, and mesh creation functions, wrapped in a Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/depth_estimation/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import DPTFeatureExtractor, DPTForDepthEstimation\nimport torch\nimport numpy as np\nfrom PIL import Image\nimport open3d as o3d\nfrom pathlib import Path\n\nfeature_extractor = DPTFeatureExtractor.from_pretrained(\"Intel/dpt-large\")\nmodel = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-large\")\n\ndef process_image(image_path):\n    image_path = Path(image_path)\n    image_raw = Image.open(image_path)\n    image = image_raw.resize(\n        (800, int(800 * image_raw.size[1] / image_raw.size[0])),\n        Image.Resampling.LANCZOS)\n\n    # prepare image for the model\n    encoding = feature_extractor(image, return_tensors=\"pt\")  # type: ignore\n\n    # forward pass\n    with torch.no_grad():\n        outputs = model(**encoding)  # type: ignore\n        predicted_depth = outputs.predicted_depth\n\n    # interpolate to original size\n    prediction = torch.nn.functional.interpolate(\n        predicted_depth.unsqueeze(1),\n        size=image.size[::-1],\n        mode=\"bicubic\",\n        align_corners=False,\n    ).squeeze()\n    output = prediction.cpu().numpy()\n    depth_image = (output * 255 / np.max(output)).astype('uint8')\n    try:\n        gltf_path = create_3d_obj(np.array(image), depth_image, image_path)\n        img = Image.fromarray(depth_image)\n        return [img, gltf_path, gltf_path]\n    except Exception:\n        gltf_path = create_3d_obj(\n            np.array(image), depth_image, image_path, depth=8)\n        img = Image.fromarray(depth_image)\n        return [img, gltf_path, gltf_path]\n    except:\n        print(\"Error reconstructing 3D model\")\n        raise Exception(\"Error reconstructing 3D model\")\n\ndef create_3d_obj(rgb_image, depth_image, image_path, depth=10):\n    depth_o3d = o3d.geometry.Image(depth_image)\n    image_o3d = o3d.geometry.Image(rgb_image)\n    rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n        image_o3d, depth_o3d, convert_rgb_to_intensity=False)\n    w = int(depth_image.shape[1])\n    h = int(depth_image.shape[0])\n\n    camera_intrinsic = o3d.camera.PinholeCameraIntrinsic()\n    camera_intrinsic.set_intrinsics(w, h, 500, 500, w/2, h/2)\n\n    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n        rgbd_image, camera_intrinsic)\n\n    print('normals')\n    pcd.normals = o3d.utility.Vector3dVector(\n        np.zeros((1, 3)))  # invalidate existing normals\n    pcd.estimate_normals(\n        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.01, max_nn=30))\n    pcd.orient_normals_towards_camera_location(\n        camera_location=np.array([0., 0., 1000.]))\n    pcd.transform([[1, 0, 0, 0],\n                   [0, -1, 0, 0],\n                   [0, 0, -1, 0],\n                   [0, 0, 0, 1]])\n    pcd.transform([[-1, 0, 0, 0],\n                   [0, 1, 0, 0],\n                   [0, 0, 1, 0],\n                   [0, 0, 0, 1]])\n\n    print('run Poisson surface reconstruction')\n    with o3d.utility.VerbosityContextManager(o3d.utility.VerbosityLevel.Debug):\n        mesh_raw, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n            pcd, depth=depth, width=0, scale=1.1, linear_fit=True)\n\n    voxel_size = max(mesh_raw.get_max_bound() - mesh_raw.get_min_bound()) / 256\n    print(f'voxel_size = {voxel_size:e}')\n    mesh = mesh_raw.simplify_vertex_clustering(\n        voxel_size=voxel_size,\n        contraction=o3d.geometry.SimplificationContraction.Average)\n\n    bbox = pcd.get_axis_aligned_bounding_box()\n    mesh_crop = mesh.crop(bbox)\n    gltf_path = f'./{image_path.stem}.gltf'\n    o3d.io.write_triangle_mesh(\n        gltf_path, mesh_crop, write_triangle_uvs=True)\n    return gltf_path\n\ntitle = \"Demo: zero-shot depth estimation with DPT + 3D Point Cloud\"\ndescription = \"This demo is a variation from the original <a href='https://huggingface.co/spaces/nielsr/dpt-depth-estimation' target='_blank'>DPT Demo</a>. It uses the DPT model to predict the depth of an image and then uses 3D Point Cloud to create a 3D object.\"\nexamples = [[\"examples/1-jonathan-borba-CgWTqYxHEkg-unsplash.jpg\"]]\n\niface = gr.Interface(fn=process_image,\n                     inputs=[gr.Image(\n                         type=\"filepath\", label=\"Input Image\")],\n                     outputs=[gr.Image(label=\"predicted depth\", type=\"pil\"),\n                              gr.Model3D(label=\"3d mesh reconstruction\", clear_color=(\n                                                 1.0, 1.0, 1.0, 1.0)),\n                              gr.File(label=\"3d gLTF\")],\n                     title=title,\n                     description=description,\n                     examples=examples,\n                     flagging_mode=\"never\",\n                     cache_examples=False)\n\niface.launch(debug=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Flight Data Visualization with Gradio\nDESCRIPTION: Builds a Gradio interface with filtering controls (origin dropdown, destination dropdown, and price slider) and displays filtered flight data as a scatter plot. The interface allows users to dynamically filter flight data based on origin, destination, and maximum price.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        origin = gr.Dropdown([\"All\", \"DFW\", \"DAL\", \"HOU\"], value=\"All\", label=\"Origin\")\n        destination = gr.Dropdown([\"All\", \"JFK\", \"LGA\", \"EWR\"], value=\"All\", label=\"Destination\")\n        max_price = gr.Slider(0, 1000, value=1000, label=\"Max Price\")\n\n    def filtered_data(origin, destination, max_price):\n        _df = df[df[\"price\"] <= max_price]\n        if origin != \"All\":\n            _df = _df[_df[\"origin\"] == origin]\n        if destination != \"All\":\n            _df = _df[_df[\"destination\"] == destination]\n        return _df\n\n    gr.ScatterPlot(filtered_data, x=\"time\", y=\"price\", inputs=[origin, destination, max_price])\n    \nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Text Chatbot with Gradio\nDESCRIPTION: Creates a simple chatbot interface with a chat history display, text input, and clear button. The bot randomly responds with predefined messages and includes a 1-second delay for demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/04_creating-a-custom-chatbot-with-blocks.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"Today is a great day\", \"I'm very hungry\"])\n        chat_history.append((message, bot_message))\n        time.sleep(1)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building LangChain Chatbot with Gradio\nDESCRIPTION: Implementation of a general-purpose chatbot using LangChain with OpenAI backend and Gradio's ChatInterface. Shows chat model initialization and message handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_langchain\n```\n\n----------------------------------------\n\nTITLE: Implementing Google OAuth Authentication with FastAPI and Gradio\nDESCRIPTION: A comprehensive example showing how to add Google OAuth authentication to a Gradio application. It includes session management, login/logout functionality, and conditional access to different Gradio apps based on authentication status.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom authlib.integrations.starlette_client import OAuth, OAuthError\nfrom fastapi import FastAPI, Depends, Request\nfrom starlette.config import Config\nfrom starlette.responses import RedirectResponse\nfrom starlette.middleware.sessions import SessionMiddleware\nimport uvicorn\nimport gradio as gr\n\napp = FastAPI()\n\n# Replace these with your own OAuth settings\nGOOGLE_CLIENT_ID = \"...\"\nGOOGLE_CLIENT_SECRET = \"...\"\nSECRET_KEY = \"...\"\n\nconfig_data = {'GOOGLE_CLIENT_ID': GOOGLE_CLIENT_ID, 'GOOGLE_CLIENT_SECRET': GOOGLE_CLIENT_SECRET}\nstarlette_config = Config(environ=config_data)\noauth = OAuth(starlette_config)\noauth.register(\n    name='google',\n    server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',\n    client_kwargs={'scope': 'openid email profile'},\n)\n\nSECRET_KEY = os.environ.get('SECRET_KEY') or \"a_very_secret_key\"\napp.add_middleware(SessionMiddleware, secret_key=SECRET_KEY)\n\n# Dependency to get the current user\ndef get_user(request: Request):\n    user = request.session.get('user')\n    if user:\n        return user['name']\n    return None\n\n@app.get('/')\ndef public(user: dict = Depends(get_user)):\n    if user:\n        return RedirectResponse(url='/gradio')\n    else:\n        return RedirectResponse(url='/login-demo')\n\n@app.route('/logout')\nasync def logout(request: Request):\n    request.session.pop('user', None)\n    return RedirectResponse(url='/')\n\n@app.route('/login')\nasync def login(request: Request):\n    redirect_uri = request.url_for('auth')\n    # If your app is running on https, you should ensure that the\n    # `redirect_uri` is https, e.g. uncomment the following lines:\n    #\n    # from urllib.parse import urlparse, urlunparse\n    # redirect_uri = urlunparse(urlparse(str(redirect_uri))._replace(scheme='https'))\n    return await oauth.google.authorize_redirect(request, redirect_uri)\n\n@app.route('/auth')\nasync def auth(request: Request):\n    try:\n        access_token = await oauth.google.authorize_access_token(request)\n    except OAuthError:\n        return RedirectResponse(url='/')\n    request.session['user'] = dict(access_token)[\"userinfo\"]\n    return RedirectResponse(url='/')\n\nwith gr.Blocks() as login_demo:\n    gr.Button(\"Login\", link=\"/login\")\n\napp = gr.mount_gradio_app(app, login_demo, path=\"/login-demo\")\n\ndef greet(request: gr.Request):\n    return f\"Welcome to Gradio, {request.username}\"\n\nwith gr.Blocks() as main_demo:\n    m = gr.Markdown(\"Welcome to Gradio!\")\n    gr.Button(\"Logout\", link=\"/logout\")\n    main_demo.load(greet, None, m)\n\napp = gr.mount_gradio_app(app, main_demo, path=\"/gradio\", auth_dependency=get_user)\n\nif __name__ == '__main__':\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Implementing Question-Answering Interface with Gradio and Transformers in Python\nDESCRIPTION: Creates a web interface using Gradio that leverages a pre-trained RoBERTa model from Hugging Face Transformers for question-answering. The implementation loads the model, defines a prediction function, and sets up the interface with context and question inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/question-answering/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nfrom transformers import pipeline\n\nmodel_name = \"deepset/roberta-base-squad2\"\n\nnlp = pipeline(\"question-answering\", model=model_name, tokenizer=model_name)\n\ncontext = \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\nquestion = \"Which continent is the Amazon rainforest in?\"\n\ndef predict(context, question):\n    res = nlp({\"question\": question, \"context\": context})\n    return res[\"answer\"], res[\"score\"]  # type: ignore\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Textbox(lines=7, value=context, label=\"Context Paragraph\"),\n        gr.Textbox(lines=2, value=question, label=\"Question\"),\n    ],\n    outputs=[gr.Textbox(label=\"Answer\"), gr.Textbox(label=\"Score\")],\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing YOLOv10 Webcam Stream Demo with Gradio and WebRTC\nDESCRIPTION: This snippet sets up a Gradio demo for real-time object detection using YOLOv10 on webcam streams. It includes WebRTC integration for low-latency video streaming, Twilio for ICE servers, and allows users to adjust the confidence threshold for object detection. The demo uses an ONNX model from Hugging Face Hub.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/yolov10_webcam_stream/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport cv2\nfrom huggingface_hub import hf_hub_download\nfrom gradio_webrtc import WebRTC  # type: ignore\nfrom twilio.rest import Client  # type: ignore\nimport os\nfrom inference import YOLOv10  # type: ignore\n\nmodel_file = hf_hub_download(\n    repo_id=\"onnx-community/yolov10n\", filename=\"onnx/model.onnx\"\n)\n\nmodel = YOLOv10(model_file)\n\naccount_sid = os.environ.get(\"TWILIO_ACCOUNT_SID\")\nauth_token = os.environ.get(\"TWILIO_AUTH_TOKEN\")\n\nif account_sid and auth_token:\n    client = Client(account_sid, auth_token)\n\n    token = client.tokens.create()\n\n    rtc_configuration = {\n        \"iceServers\": token.ice_servers,\n        \"iceTransportPolicy\": \"relay\",\n    }\nelse:\n    rtc_configuration = None\n\n\ndef detection(image, conf_threshold=0.3):\n    image = cv2.resize(image, (model.input_width, model.input_height))\n    new_image = model.detect_objects(image, conf_threshold)\n    return cv2.resize(new_image, (500, 500))\n\n\ncss = \"\"\".my-group {max-width: 600px !important; max-height: 600 !important;}\n                      .my-column {display: flex !important; justify-content: center !important; align-items: center !important};\"\"\"\n\n\nwith gr.Blocks(css=css) as demo:\n    gr.HTML(\n        \"\"\"\n    <h1 style='text-align: center'>\n    YOLOv10 Webcam Stream (Powered by WebRTC ⚡️)\n    </h1>\n    \"\"\"\n    )\n    gr.HTML(\n        \"\"\"\n        <h3 style='text-align: center'>\n        <a href='https://arxiv.org/abs/2405.14458' target='_blank'>arXiv</a> | <a href='https://github.com/THU-MIG/yolov10' target='_blank'>github</a>\n        </h3>\n        \"\"\"\n    )\n    with gr.Column(elem_classes=[\"my-column\"]):\n        with gr.Group(elem_classes=[\"my-group\"]):\n            image = WebRTC(label=\"Stream\", rtc_configuration=rtc_configuration)\n            conf_threshold = gr.Slider(\n                label=\"Confidence Threshold\",\n                minimum=0.0,\n                maximum=1.0,\n                step=0.05,\n                value=0.30,\n            )\n\n        image.stream(\n            fn=detection, inputs=[image, conf_threshold], outputs=[image], time_limit=10\n        )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Image Editor Interface\nDESCRIPTION: Implements a full-featured image editor interface using Gradio Blocks with multiple tabs, custom brush settings, layer management, and various image editing templates. Includes interactive controls for brush size, opacity, color, and eraser settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_many/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Tab(\"Default ImageEditor\"):\n        im = gr.ImageEditor(value=\"./cheetah.jpg\", interactive=True, fixed_canvas=True)\n    with gr.Tab(\"Brush Options\"):\n        with gr.Row():\n            with gr.Column():\n                image_editor = gr.ImageEditor(\n                    value=\"./cheetah.jpg\",\n                    interactive=True,\n                    fixed_canvas=True,\n                    brush=gr.Brush(\n                        default_size=10,\n                        default_color=\"#000000\",\n                        colors=[\n                            \"#FFA50050\",\n                            \"#FF0000\",\n                            (\"#00FF00\", 0.5),\n                            (\"rgba(255, 255, 0, 0.5)\", 0.5),\n                            \"rgba(255, 0, 0, 0.5)\",\n                            \"pink\",\n                            \"hsla(300, 100%, 50%, 0.5)\",\n                            (\"hsl(300, 100%, 50%)\", 0.8),\n                            (\"crimson\", 0.5),\n                            (\"#000080\", 1),\n                        ],\n                    ),\n                    eraser=gr.Eraser(default_size=10),\n                )\n                image_editor.apply(fn=lambda x: print(x), inputs=[image_editor])\n            with gr.Column():\n                with gr.Group():\n                    brush_size = gr.Slider(\n                        minimum=1,\n                        maximum=100,\n                        value=10,\n                        label=\"Brush Size\",\n                    )\n                    brush_opacity = gr.Slider(\n                        minimum=0,\n                        maximum=100,\n                        value=50,\n                        label=\"Brush Opacity\",\n                    )\n                    brush_color = gr.ColorPicker(value=\"#000000\", label=\"Brush Color\")\n\n                with gr.Group():\n                    eraser_size = gr.Slider(\n                        minimum=1,\n                        maximum=100,\n                        value=10,\n                        label=\"Eraser Size\",\n                    )\n\n                update_btn = gr.Button(\"Apply Settings\")\n\n                status_msg = gr.Markdown(\n                    value=\"**Adjust settings and click Apply.**\",\n                )\n\n        def update_editor_settings(size, opacity, color, e_size):\n\n            return (\n                gr.ImageEditor(\n                    brush=gr.Brush(\n                        default_size=size,\n                        default_color=(color, opacity / 100),\n                        colors=[\n                            \"#FFA50050\",\n                            \"#FF0000\",\n                            (\"#00FF00\", 0.5),\n                            (\"rgba(255, 255, 0, 0.5)\", 0.5),\n                            \"rgba(255, 0, 0, 0.5)\",\n                            \"pink\",\n                            \"hsla(300, 100%, 50%, 0.5)\",\n                            (\"hsl(300, 100%, 50%)\", 0.8),\n                            (\"crimson\", 0.5),\n                            (\"#000080\", 1),\n                        ],\n                    ),\n                    eraser=gr.Eraser(default_size=e_size),\n                ),\n                f'### Settings applied:\\n\\n- `Brush.default_size={size}`\\n- `Brush.default_color=\"{color}\", {opacity / 100})`\\n- `Eraser.default_size={e_size}`',\n            )\n\n        update_btn.click(\n            update_editor_settings,\n            inputs=[brush_size, brush_opacity, brush_color, eraser_size],\n            outputs=[image_editor, status_msg],\n        )\n\n        def update_status(size=None, opacity=None, color=None, e_size=None):\n            changes = []\n            if size is not None:\n                changes.append(f\"`Brush.default_size={size}`\")\n            if opacity is not None:\n                changes.append(f\"`Brush.default_color=('{color}', {opacity / 100})`\")\n            if color is not None:\n                if opacity is not None:\n                    changes.append(f\"`Brush.default_color=('{color}', {opacity / 100})`\")\n                else:\n                    changes.append(f\"`Brush.default_color='{color}'`\")\n            if e_size is not None:\n                changes.append(f\"`Eraser.default_size={e_size}`\")\n\n            if changes:\n                return (\n                    \"Settings changed:\\n\\n\"\n                    + \"- \"\n                    + \"\\n- \".join(changes)\n                    + \"\\n\\n**Click Apply to update.**\"\n                )\n            return \"\"\n\n        brush_size.change(\n            fn=update_status,\n            inputs=[brush_size, brush_opacity, brush_color, eraser_size],\n            outputs=status_msg,\n        )\n        brush_opacity.change(\n            fn=update_status,\n            inputs=[brush_size, brush_opacity, brush_color, eraser_size],\n            outputs=status_msg,\n        )\n        brush_color.change(\n            fn=update_status,\n            inputs=[brush_size, brush_opacity, brush_color, eraser_size],\n            outputs=status_msg,\n        )\n        eraser_size.change(\n            fn=update_status,\n            inputs=[brush_size, brush_opacity, brush_color, eraser_size],\n            outputs=status_msg,\n        )\n    with gr.Tab(\"Layer Options\"):\n        with gr.Row():\n            with gr.Column():\n                im = gr.ImageEditor(\n                    value=\"./cheetah.jpg\",\n                    interactive=True,\n                    layers=gr.LayerOptions(\n                        allow_additional_layers=False, layers=[\"Mask\"]\n                    ),\n                )\n            with gr.Column():\n                disable_layers = gr.Checkbox(value=False, label=\"Disable Layers\")\n                allow_additional_layers = gr.Checkbox(\n                    value=True, label=\"Allow Additional Layers\"\n                )\n                layer = gr.Dropdown(\n                    choices=[\"Mask\", \"Mask 2\"],\n                    value=\"Mask\",\n                    label=\"Layer\",\n                    multiselect=True,\n                    interactive=True,\n                    allow_custom_value=True,\n                )\n                gr.Checkbox(value=True, label=\"Allow Additional Layers\")\n                update_layer_btn = gr.Button(\"Update Layer Options\")\n                status_msg = gr.Markdown(value=\"**Adjust settings and click Apply.**\")\n\n                def update_layer_options(\n                    disable_layers, allow_additional_layers, layer\n                ):\n                    print(\n                        \"update_layer_options\",\n                        disable_layers,\n                        allow_additional_layers,\n                        layer,\n                    )\n                    return (\n                        gr.ImageEditor(\n                            value=\"./cheetah.jpg\",\n                            interactive=True,\n                            layers=(\n                                False\n                                if disable_layers\n                                else gr.LayerOptions(\n                                    allow_additional_layers=allow_additional_layers,\n                                    layers=layer,\n                                )\n                            ),\n                        ),\n                        f\"### Settings applied:\\n\\n- `LayerOptions=False`\\n- `LayerOptions.allow_additional_layers={allow_additional_layers}`\\n- `LayerOptions.layers={layer}`\",\n                    )\n\n                update_layer_btn.click(\n                    update_layer_options,\n                    inputs=[disable_layers, allow_additional_layers, layer],\n                    outputs=[im, status_msg],\n                )\n\n\n    with gr.Tab(\"ImageEditor Templates\"):\n        gr.ImageMask(value=\"./cheetah.jpg\", interactive=True)\n        gr.Paint(interactive=True)\n        gr.Sketchpad(interactive=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Automatic Speech Recognition with Gradio and Whisper\nDESCRIPTION: Creates a Gradio interface that uses the Whisper model to transcribe audio input. The code processes audio data, handles both mono and stereo inputs, normalizes the audio, and returns the transcribed text.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/asr/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(audio):\n    sr, y = audio\n    \n    # Convert to mono if stereo\n    if y.ndim > 1:\n        y = y.mean(axis=1)\n        \n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]  # type: ignore\n\ndemo = gr.Interface(\n    transcribe,\n    gr.Audio(sources=\"microphone\"),\n    \"text\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Application with Flagging Functionality\nDESCRIPTION: Implements a complete Gradio application that applies a sepia filter to images with adjustable strength. It demonstrates how to set up the CSVLogger for flagging data points, create a responsive UI with the Blocks API, and handle user interactions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flag/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img, strength):\n    sepia_filter = strength * np.array(\n        [[0.393, 0.769, 0.189], [0.349, 0.686, 0.168], [0.272, 0.534, 0.131]]\n    ) + (1-strength) * np.identity(3)\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ncallback = gr.CSVLogger()\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            img_input = gr.Image()\n            strength = gr.Slider(0, 1, 0.5)\n        img_output = gr.Image()\n    with gr.Row():\n        btn = gr.Button(\"Flag\")\n\n    # This needs to be called at some point prior to the first call to callback.flag()\n    callback.setup([img_input, strength, img_output], \"flagged_data_points\")\n\n    img_input.change(sepia, [img_input, strength], img_output)\n    strength.change(sepia, [img_input, strength], img_output)\n\n    # We can choose which components to flag -- in this case, we'll flag all of them\n    btn.click(lambda *args: callback.flag(list(args)), [img_input, strength, img_output], None, preprocess=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Flashcard Application using Gradio in Python\nDESCRIPTION: This code snippet creates a complete flashcard application using Gradio. It includes functionality for creating flashcards, practicing them, and viewing results. The application uses Gradio's Blocks interface to create a multi-tab UI with interactive elements.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flashcards/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"Load the flashcards in the table below, then use the Practice tab to practice.\"\n    )\n\n    with gr.Tabs() as tabs:\n        with gr.Tab(\"Word Bank\"):\n            flashcards_table = gr.Dataframe(headers=[\"front\", \"back\"], type=\"array\")\n            flashcards_table.change(fn=lambda: print(flashcards_table.value))\n            practice_btn = gr.Button(\"Start Practice\")\n        with gr.Tab(\"Practice\", interactive=False, id=1) as practice_tab:\n            with gr.Row():\n                with gr.Column():\n                    front = gr.Textbox(label=\"Prompt\")\n                    with gr.Row():\n                        new_btn = gr.Button(\"New Card\")\n                        flip_btn = gr.Button(\"Flip Card\")\n                with gr.Column(visible=False) as answer_col:\n                    back = gr.Textbox(label=\"Answer\")\n                    selected_card = gr.State()\n                with gr.Row():\n                    correct_btn = gr.Button(\"Correct\")\n                    incorrect_btn = gr.Button(\"Incorrect\")\n\n            def start_practice(flashcards):\n                # if no cards entered into dataframe yet, return\n                if len(flashcards) == 0:\n                    practice_tab = gr.Tab(\"Practice\", interactive=False, id=1)\n                    raise gr.Error(\"Please enter word prompts into the table.\")\n                    return [practice_tab, tabs]\n                else:\n                    practice_tab = gr.Tab(\"Practice\", interactive=True, id=1)\n                    new_tabs = gr.Tabs(selected=1)\n                    return [practice_tab, new_tabs]\n\n        with gr.Tab(\"Results\", visible=False) as results_tab:\n            results = gr.State(value={})\n            correct_field = gr.Markdown(\"# Correct: 0\")\n            incorrect_field = gr.Markdown(\"# Incorrect: 0\")\n            gr.Markdown(\"Card Statistics: \")\n            results_table = gr.Dataframe(headers=[\"Card\", \"Correct\", \"Incorrect\"])\n        practice_btn.click(start_practice, inputs=[flashcards_table], outputs=[practice_tab, tabs])\n\n        def load_new_card(flashcards):\n            card = random.choice(flashcards)\n            return (\n                card,\n                card[0],\n                gr.Column(visible=False),\n            )\n\n        new_btn.click(\n            load_new_card,\n            [flashcards_table],\n            [selected_card, front, answer_col],\n        )\n\n        def flip_card(card):\n            return card[1], gr.Column(visible=True)\n\n        flip_btn.click(flip_card, [selected_card], [back, answer_col])\n\n        def mark_correct(card, results):\n            if card[0] not in results:\n                results[card[0]] = [0, 0]\n            results[card[0]][0] += 1\n            correct_count = sum(result[0] for result in results.values())\n            return (\n                results,\n                f\"# Correct: {correct_count}\",\n                [[front, scores[0], scores[1]] for front, scores in results.items()],\n            )\n\n        def mark_incorrect(card, results):\n            if card[0] not in results:\n                results[card[0]] = [\n                    0, 0]\n            results[card[0]][1] += 1\n            incorrect_count = sum(result[1] for result in results.values())\n            return (\n                results,\n                f\"# Inorrect: {incorrect_count}\",\n                [[front, scores[0], scores[1]] for front, scores in results.items()],\n            )\n\n        def toggle_results_tab():\n            return gr.Tab(\"Results\", visible=True)\n\n        correct_btn.click(\n            mark_correct,\n            [selected_card, results],\n            [results, correct_field, results_table],\n        )\n\n        incorrect_btn.click(mark_incorrect, [selected_card, results], [results, incorrect_field, results_table])\n\n        # set results tab to visible when correct or incorrect button is clicked\n        correct_btn.click(fn=toggle_results_tab, outputs=[results_tab])\n        incorrect_btn.click(fn=toggle_results_tab, outputs=[results_tab])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Interface for Stable Diffusion Image Generation in Python\nDESCRIPTION: This Python script sets up and launches a Gradio application for text-to-image generation using the Stable Diffusion v1.4 model ('CompVis/stable-diffusion-v1-4'). It handles model loading from Hugging Face (requiring an 'HF_TOKEN' environment variable), defines an `infer` function to generate images based on user prompts and parameters (number of samples, inference steps, guidance scale, seed), includes a basic NSFW filter replacing potentially unsafe images with a placeholder ('unsafe.png'), and builds an interactive web UI using Gradio Blocks with input fields, sliders for advanced options, and an image gallery output. The UI elements are connected to the inference logic, and the application is launched using `block.launch()`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stable-diffusion/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\nfrom diffusers import StableDiffusionPipeline  # type: ignore\nfrom PIL import Image\nimport os\n\nauth_token = os.getenv(\"HF_TOKEN\")\nif not auth_token:\n    print(\n        \"ERROR: No Hugging Face access token found.\\n\"\n        \"Please define an environment variable 'auth_token' before running.\\n\"\n        \"Example:\\n\"\n        \"  export HF_TOKEN=XXXXXXXX\\n\"\n    )\n\nmodel_id = \"CompVis/stable-diffusion-v1-4\"\ndevice = \"cpu\"\npipe = StableDiffusionPipeline.from_pretrained(\n    model_id, token=auth_token, variant=\"fp16\", torch_dtype=torch.float16,\n)\npipe = pipe.to(device)\n\n\ndef infer(prompt, samples, steps, scale, seed):\n    generator = torch.Generator(device=device).manual_seed(seed)\n    images_list = pipe(  # type: ignore\n        [prompt] * samples,\n        num_inference_steps=steps,\n        guidance_scale=scale,\n        generator=generator,\n    )\n    images = []\n    safe_image = Image.open(r\"unsafe.png\")\n    for i, image in enumerate(images_list[\"sample\"]):  # type: ignore\n        if images_list[\"nsfw_content_detected\"][i]:  # type: ignore\n            images.append(safe_image)\n        else:\n            images.append(image)\n    return images\n\n\nblock = gr.Blocks()\n\nwith block:\n    with gr.Group():\n        with gr.Row():\n            text = gr.Textbox(\n                label=\"Enter your prompt\",\n                max_lines=1,\n                placeholder=\"Enter your prompt\",\n                container=False,\n            )\n            btn = gr.Button(\"Generate image\")\n        gallery = gr.Gallery(\n            label=\"Generated images\",\n            show_label=False,\n            elem_id=\"gallery\",\n            columns=[2],\n        )\n\n        advanced_button = gr.Button(\"Advanced options\", elem_id=\"advanced-btn\")\n\n        with gr.Row(elem_id=\"advanced-options\"):\n            samples = gr.Slider(label=\"Images\", minimum=1, maximum=4, value=4, step=1)\n            steps = gr.Slider(label=\"Steps\", minimum=1, maximum=50, value=45, step=1)\n            scale = gr.Slider(\n                label=\"Guidance Scale\", minimum=0, maximum=50, value=7.5, step=0.1\n            )\n            seed = gr.Slider(\n                label=\"Seed\",\n                minimum=0,\n                maximum=2147483647,\n                step=1,\n                randomize=True,\n            )\n        gr.on(\n            [text.submit, btn.click],\n            infer,\n            inputs=[text, samples, steps, scale, seed],\n            outputs=gallery,\n        )\n        advanced_button.click(\n            None,\n            [],\n            text,\n        )\n\nblock.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Copy Events Demo\nDESCRIPTION: Creates a Gradio interface that demonstrates copy functionality across different components (Markdown, Chatbot, and Textbox). Implements a callback function to handle copy events and display copied content in a separate textbox.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/copy_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nmd = \"This is **bold** text.\"\n\ndef copy_callback(copy_data: gr.CopyData):\n    return copy_data.value\n\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox(label=\"Copied text\")\n    with gr.Row():\n        markdown = gr.Markdown(value=md, header_links=True, height=400, show_copy_button=True)\n        chatbot = gr.Chatbot([(\"Hello\", \"World\"), (\"Goodbye\", \"World\")], show_copy_button=True)\n        textbox2 = gr.Textbox(\"Write something here\", interactive=True, show_copy_button=True)\n\n        gr.on(\n            [markdown.copy, chatbot.copy, textbox2.copy],\n            copy_callback,\n            outputs=textbox\n        )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Loading a Pretrained ResNet-18 Model in PyTorch (Python)\nDESCRIPTION: This snippet demonstrates how to load a pretrained ResNet-18 model from PyTorch Hub and set it to evaluation mode. It requires the `torch` library to be installed. The loaded model, set via `.eval()`, is used for inference and is essential for running image classification tasks in subsequent steps.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-pytorch.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport torch\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\n```\n\n----------------------------------------\n\nTITLE: Streaming Chatbot Implementation\nDESCRIPTION: Example of a streaming chatbot that gradually reveals the response using yield\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport gradio as gr\n\ndef slow_echo(message, history):\n    for i in range(len(message)):\n        time.sleep(0.3)\n        yield \"You typed: \" + message[: i+1]\n\ngr.ChatInterface(\n    fn=slow_echo, \n    type=\"messages\"\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages gradio and huggingface_hub using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_retry_undo_like/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio huggingface_hub\n```\n\n----------------------------------------\n\nTITLE: Creating Simple Gradio Blocks Demo with PDF Component in Python\nDESCRIPTION: This snippet shows how to use the custom PDF component in a simple Gradio Blocks application, demonstrating its integration with other Gradio components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_20\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_pdf import PDF\n\nwith gr.Blocks() as demo:\n    pdf = PDF(label=\"Upload a PDF\", interactive=True)\n    name = gr.Textbox()\n    pdf.upload(lambda f: f, pdf, name)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Upload Button Components\nDESCRIPTION: This code creates a Gradio interface with UploadButton components for single and multiple file uploads. It demonstrates how to handle upload and click events, and display the uploaded files and event counts.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_button_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n\n    with gr.Row():\n        with gr.Column():\n            upload_btn = gr.UploadButton(label=\"Upload Single File\", file_count=\"single\")\n        with gr.Column():\n            output_file_1 = gr.File(label=\"Upload Single File Output\", file_count=\"single\")\n            num_load_btn_1 = gr.Number(label=\"# Load Upload Single File\", value=0)\n            output_click_1 = gr.Number(label=\"# Click Upload Single File Output\", value=0)\n            upload_btn.upload(lambda s,n: (s, n + 1), [upload_btn, num_load_btn_1], [output_file_1, num_load_btn_1])\n            upload_btn.click(lambda n: (n + 1), output_click_1, [output_click_1])\n    with gr.Row():\n        with gr.Column():\n            upload_btn_multiple = gr.UploadButton(label=\"Upload Multiple Files\", file_count=\"multiple\")\n        with gr.Column():\n            output_file_2 = gr.File(label=\"Upload Multiple Files Output\", file_count=\"multiple\")\n            num_load_btn_2 = gr.Number(label=\"# Load Upload Multiple Files\", value=0)\n            output_click_2 = gr.Number(label=\"# Click Upload Multiple Files Output\", value=0)\n            upload_btn_multiple.upload(lambda s,n: (s, n + 1), [upload_btn_multiple, num_load_btn_2], [output_file_2, num_load_btn_2])\n            upload_btn_multiple.click(lambda n: (n + 1), output_click_2, [output_click_2])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Component Event Handlers\nDESCRIPTION: Creates a Gradio interface with two image components and multiple number counters to track different events. Implements handlers for upload, input, change, clear, and select events. The interface includes event counting for both input and output image components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef test_select_is_defined(n, evt: gr.SelectData):\n    assert isinstance(evt.index, list)\n    assert isinstance(evt.index[0], int)\n    return n + 1\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_img = gr.Image(type=\"filepath\", label=\"Input Image\", sources=[\"upload\", \"clipboard\"])\n        with gr.Column():\n            output_img = gr.Image(type=\"filepath\", label=\"Output Image\", sources=[\"upload\", \"clipboard\"])\n        with gr.Column():\n            num_change = gr.Number(label=\"# Change Events\", value=0)\n            num_input = gr.Number(label=\"# Input Events\", value=0)\n            num_load = gr.Number(label=\"# Upload Events\", value=0)\n            num_change_o = gr.Number(label=\"# Change Events Output\", value=0)\n            num_clear = gr.Number(label=\"# Clear Events\", value=0)\n            num_select = gr.Number(label=\"# Select Events\", value=0)\n\n        input_img.upload(lambda s, n: (s, n + 1), [input_img, num_load], [output_img, num_load])\n        input_img.input(lambda n: n + 1, num_input, num_input)\n        input_img.change(lambda n: n + 1, num_change, num_change)\n        input_img.clear(lambda n: n + 1, num_clear, num_clear)\n        output_img.change(lambda n: n + 1, num_change_o, num_change_o)\n        output_img.select(test_select_is_defined, num_select, num_select)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Interface with Dynamic Lambda Examples\nDESCRIPTION: Creates a chat interface that generates random lambda function examples and processes user responses. The bot provides example code with random numbers and allows users to respond with predefined options. Uses Gradio's ChatInterface and ChatMessage components for structured interactions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_options/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\nexample_code = \"\"\"\nHere's an example Python lambda function:\n\nlambda x: x + {}\n\nIs this correct?\n\"\"\"\n\ndef chat(message, history):\n    if message == \"Yes, that's correct.\":\n        return \"Great!\"\n    else:\n        return gr.ChatMessage(\n            content=example_code.format(random.randint(1, 100)),\n            options=[\n                {\"value\": \"Yes, that's correct.\", \"label\": \"Yes\"},\n                {\"value\": \"No\"}\n            ]\n        )\n\ndemo = gr.ChatInterface(\n    chat,\n    type=\"messages\",\n    examples=[\"Write an example Python lambda function.\"]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multiple Files in Gradio-Lite\nDESCRIPTION: This snippet shows how to create a Gradio-lite app with multiple Python files. It uses the <gradio-file> tag to define separate files and specifies the entrypoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/lite/README.md#2025-04-23_snippet_2\n\nLANGUAGE: HTML\nCODE:\n```\n<gradio-lite>\n\n<gradio-file name=\"app.py\" entrypoint>\nimport gradio as gr\nfrom utils import add\n\ndemo = gr.Interface(fn=add, inputs=[\"number\", \"number\"], outputs=\"number\")\n\ndemo.launch()\n</gradio-file>\n\n<gradio-file name=\"utils.py\" >\ndef add(a, b):\n\treturn a + b\n</gradio-file>\n\n</gradio-lite>\t\t\n```\n\n----------------------------------------\n\nTITLE: Implementing Calculator with Gradio Blocks Interface\nDESCRIPTION: Creates a calculator web interface using Gradio Blocks that supports addition, subtraction, multiplication, and division operations. The implementation includes input fields for numbers, operation selection, and example calculations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_blocks/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            num_1 = gr.Number(value=4)\n            operation = gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"])\n            num_2 = gr.Number(value=0)\n            submit_btn = gr.Button(value=\"Calculate\")\n        with gr.Column():\n            result = gr.Number()\n\n    submit_btn.click(\n        calculator, inputs=[num_1, operation, num_2], outputs=[result], api_name=False\n    )\n    examples = gr.Examples(\n        examples=[\n            [5, \"add\", 3],\n            [4, \"divide\", 2],\n            [-4, \"multiply\", 2.5],\n            [0, \"subtract\", 1.2],\n        ],\n        inputs=[num_1, operation, num_2],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch(show_api=False)\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Bar Plot Dashboard with Gradio\nDESCRIPTION: Creates an interactive dashboard with multiple bar plots using Gradio and Pandas. Features include temporal data visualization of temperature/humidity readings and food ratings analysis. The dashboard supports dynamic filtering, grouping, aggregation, and sorting capabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot_demo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom random import randint, random\nimport gradio as gr\n\n\ntemp_sensor_data = pd.DataFrame(\n    {\n        \"time\": pd.date_range(\"2021-01-01\", end=\"2021-01-05\", periods=200),\n        \"temperature\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"humidity\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"location\": [\"indoor\", \"outdoor\"] * 100,\n    }\n)\n\nfood_rating_data = pd.DataFrame(\n    {\n        \"cuisine\": [[\"Italian\", \"Mexican\", \"Chinese\"][i % 3] for i in range(100)],\n        \"rating\": [random() * 4 + 0.5 * (i % 3) for i in range(100)],\n        \"price\": [randint(10, 50) + 4 * (i % 3) for i in range(100)],\n        \"wait\": [random() for i in range(100)],\n    }\n)\n\nwith gr.Blocks() as bar_plots:\n    with gr.Row():\n        start = gr.DateTime(\"2021-01-01 00:00:00\", label=\"Start\")\n        end = gr.DateTime(\"2021-01-05 00:00:00\", label=\"End\")\n        apply_btn = gr.Button(\"Apply\", scale=0)\n    with gr.Row():\n        group_by = gr.Radio([\"None\", \"30m\", \"1h\", \"4h\", \"1d\"], value=\"None\", label=\"Group by\")\n        aggregate = gr.Radio([\"sum\", \"mean\", \"median\", \"min\", \"max\"], value=\"sum\", label=\"Aggregation\")\n\n    temp_by_time = gr.BarPlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n    )\n    temp_by_time_location = gr.BarPlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n        color=\"location\",\n    )\n\n    time_graphs = [temp_by_time, temp_by_time_location]\n    group_by.change(\n        lambda group: [gr.BarPlot(x_bin=None if group == \"None\" else group)] * len(time_graphs),\n        group_by,\n        time_graphs\n    )\n    aggregate.change(\n        lambda aggregate: [gr.BarPlot(y_aggregate=aggregate)] * len(time_graphs),\n        aggregate,\n        time_graphs\n    )\n\n    def rescale(select: gr.SelectData):\n        return select.index\n    rescale_evt = gr.on([plot.select for plot in time_graphs], rescale, None, [start, end])\n\n    for trigger in [apply_btn.click, rescale_evt.then]:\n        trigger(\n            lambda start, end: [gr.BarPlot(x_lim=[start, end])] * len(time_graphs), [start, end], time_graphs\n        )\n\n    with gr.Row():\n        price_by_cuisine = gr.BarPlot(\n            food_rating_data,\n            x=\"cuisine\",\n            y=\"price\",\n        )\n        with gr.Column(scale=0):\n            gr.Button(\"Sort $ > $$$\").click(lambda: gr.BarPlot(sort=\"y\"), None, price_by_cuisine)\n            gr.Button(\"Sort $$$ > $\").click(lambda: gr.BarPlot(sort=\"-y\"), None, price_by_cuisine)\n            gr.Button(\"Sort A > Z\").click(lambda: gr.BarPlot(sort=[\"Chinese\", \"Italian\", \"Mexican\"]), None, price_by_cuisine)\n\n    with gr.Row():\n        price_by_rating = gr.BarPlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n            x_bin=1,\n        )\n        price_by_rating_color = gr.BarPlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n            color=\"cuisine\",\n            x_bin=1,\n            color_map={\"Italian\": \"red\", \"Mexican\": \"green\", \"Chinese\": \"blue\"},\n        )\n\nif __name__ == \"__main__\":\n    bar_plots.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface for GPT-2 Text Generation in Python\nDESCRIPTION: This code creates a Gradio interface for text generation using the GPT-2 XL model. It defines a function to complete text using the last 50 characters as context, and sets up a Gradio Blocks interface with a textbox and a generate button.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_gpt/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\napi = gr.load(\"huggingface/gpt2-xl\")\n\ndef complete_with_gpt(text):\n    # Use the last 50 characters of the text as context\n    return text[:-50] + api(text[-50:])\n\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox(placeholder=\"Type here and press enter...\", lines=4)\n    btn = gr.Button(\"Generate\")\n\n    btn.click(complete_with_gpt, textbox, textbox)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing RT-DETR Object Detection with Gradio Interface\nDESCRIPTION: Creates a Gradio web interface that processes uploaded videos through RT-DETR model for object detection. The implementation includes batching frames for efficient processing on GPU, drawing bounding boxes on detected objects, and streaming the output video with adjustable confidence threshold.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rt-detr-object-detection/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# type: ignore\nimport spaces\nimport gradio as gr\nimport cv2\nfrom PIL import Image\nimport torch\nimport time\nimport numpy as np\nimport uuid\n\nfrom transformers import RTDetrForObjectDetection, RTDetrImageProcessor  # type: ignore\n\nfrom draw_boxes import draw_bounding_boxes\n\nimage_processor = RTDetrImageProcessor.from_pretrained(\"PekingU/rtdetr_r50vd\")\nmodel = RTDetrForObjectDetection.from_pretrained(\"PekingU/rtdetr_r50vd\").to(\"cuda\")\n\n\nSUBSAMPLE = 2\n\n\n@spaces.GPU\ndef stream_object_detection(video, conf_threshold):\n    cap = cv2.VideoCapture(video)\n\n    video_codec = cv2.VideoWriter_fourcc(*\"mp4v\")  # type: ignore\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    desired_fps = fps // SUBSAMPLE\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) // 2\n\n    iterating, frame = cap.read()\n\n    n_frames = 0\n\n    name = f\"output_{uuid.uuid4()}.mp4\"\n    segment_file = cv2.VideoWriter(name, video_codec, desired_fps, (width, height))  # type: ignore\n    batch = []\n\n    while iterating:\n        frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        if n_frames % SUBSAMPLE == 0:\n            batch.append(frame)\n        if len(batch) == 2 * desired_fps:\n            inputs = image_processor(images=batch, return_tensors=\"pt\").to(\"cuda\")\n\n            print(f\"starting batch of size {len(batch)}\")\n            start = time.time()\n            with torch.no_grad():\n                outputs = model(**inputs)\n            end = time.time()\n            print(\"time taken for inference\", end - start)\n\n            start = time.time()\n            boxes = image_processor.post_process_object_detection(\n                outputs,\n                target_sizes=torch.tensor([(height, width)] * len(batch)),\n                threshold=conf_threshold,\n            )\n\n            for _, (array, box) in enumerate(zip(batch, boxes)):\n                pil_image = draw_bounding_boxes(\n                    Image.fromarray(array), box, model, conf_threshold\n                )\n                frame = np.array(pil_image)\n                # Convert RGB to BGR\n                frame = frame[:, :, ::-1].copy()\n                segment_file.write(frame)\n\n            batch = []\n            segment_file.release()\n            yield name\n            end = time.time()\n            print(\"time taken for processing boxes\", end - start)\n            name = f\"output_{uuid.uuid4()}.mp4\"\n            segment_file = cv2.VideoWriter(\n                name, video_codec, desired_fps, (width, height)\n            )  # type: ignore\n\n        iterating, frame = cap.read()\n        n_frames += 1\n\n\nwith gr.Blocks() as demo:\n    gr.HTML(\n        \"\"\"\n    <h1 style='text-align: center'>\n    Video Object Detection with <a href='https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365' target='_blank'>RT-DETR</a>\n    </h1>\n    \"\"\"\n    )\n    with gr.Row():\n        with gr.Column():\n            video = gr.Video(label=\"Video Source\")\n            conf_threshold = gr.Slider(\n                label=\"Confidence Threshold\",\n                minimum=0.0,\n                maximum=1.0,\n                step=0.05,\n                value=0.30,\n            )\n        with gr.Column():\n            output_video = gr.Video(\n                label=\"Processed Video\", streaming=True, autoplay=True\n            )\n\n    video.upload(\n        fn=stream_object_detection,\n        inputs=[video, conf_threshold],\n        outputs=[output_video],\n    )\n\n    gr.Examples(\n        examples=[\"3285790-hd_1920_1080_30fps.mp4\"],\n        inputs=[video],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Dataframe Streaming Demo with Gradio in Python\nDESCRIPTION: This code creates a Gradio demo for streaming updates to a dataframe. It includes functions for updating the dataframe, summing its values, and a Gradio interface with various components like buttons, numbers, and the dataframe itself. The demo tracks change and input events on the dataframe.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_streaming/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport time\n\ndef update_dataframe(df):\n    df.iloc[:, :] = 1\n    yield df, 1\n    time.sleep(0.1)\n    df.iloc[:, :] = 2\n    yield df, 2\n\ndef sum_values(df):\n    return pd.to_numeric(df.values.flatten(), errors='coerce').sum() # type: ignore\n\ninitial_df = pd.DataFrame(0, index=range(5), columns=range(5))\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        button = gr.Button(\"Update DataFrame\")\n        number = gr.Number(value=0, label=\"Number\")\n    dataframe = gr.Dataframe(value=initial_df, label=\"Dataframe\")\n\n    button.click(fn=update_dataframe, inputs=dataframe, outputs=[dataframe, number])\n    with gr.Row():\n        change_events = gr.Number(label=\"Change events\")\n        input_events = gr.Number(label=\"Input events\")\n        sum_of_values = gr.Number(label=\"Sum of values\")\n\n    dataframe.change(lambda x:x+1, inputs=change_events, outputs=change_events)\n    dataframe.input(lambda x:x+1, inputs=input_events, outputs=input_events)\n    dataframe.change(sum_values, inputs=dataframe, outputs=sum_of_values)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring Multimodal Chat Interface - Gradio (Python)\nDESCRIPTION: This snippet sets up a multimodal chat interface where users can upload images in addition to text messages. It demonstrates customizing the input textbox with image and microphone capabilities and specifies an input function that counts uploaded images. Dependencies include the Gradio library and the `gr.ChatInterface` class. The chat function takes in a dictionary with keys 'text' and 'files', and a history list. It outputs a message summarizing the number of images uploaded, both in the current message and cumulatively in history.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef count_images(message, history):\n    num_images = len(message[\"files\"])\n    total_images = 0\n    for message in history:\n        if isinstance(message[\"content\"], tuple):\n            total_images += 1\n    return f\"You just uploaded {num_images} images, total uploaded: {total_images+num_images}\"\n\ndemo = gr.ChatInterface(\n    fn=count_images, \n    type=\"messages\", \n    examples=[\n        {\"text\": \"No files\", \"files\": []}\n    ], \n    multimodal=True,\n    textbox=gr.MultimodalTextbox(file_count=\"multiple\", file_types=[\"image\"], sources=[\"upload\", \"microphone\"])\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Tax Calculator in Python\nDESCRIPTION: Defines a tax calculator function and sets up a Gradio web interface for user interaction. Dependencies include Gradio, and inputs are user income, marital status (as a radio selection), and a dataframe of assets. The function computes tax based on custom brackets and marital status adjustments, allowing users to input sample data or use provided examples. Outputs the calculated tax as a number; limitations include static tax brackets and basic marital status handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tax_calculator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef tax_calculator(income, marital_status, assets):\n    tax_brackets = [(10, 0), (25, 8), (60, 12), (120, 20), (250, 30)]\n    total_deductible = sum(assets[\"Cost\"])\n    taxable_income = income - total_deductible\n\n    total_tax = 0\n    for bracket, rate in tax_brackets:\n        if taxable_income > bracket:\n            total_tax += (taxable_income - bracket) * rate / 100\n\n    if marital_status == \"Married\":\n        total_tax *= 0.75\n    elif marital_status == \"Divorced\":\n        total_tax *= 0.8\n\n    return round(total_tax)\n\ndemo = gr.Interface(\n    tax_calculator,\n    [\n        \"number\",\n        gr.Radio([\"Single\", \"Married\", \"Divorced\"]),\n        gr.Dataframe(\n            headers=[\"Item\", \"Cost\"],\n            datatype=[\"str\", \"number\"],\n            label=\"Assets Purchased this Year\",\n        ),\n    ],\n    \"number\",\n    examples=[\n        [10000, \"Married\", [[\"Suit\", 5000], [\"Laptop\", 800], [\"Car\", 1800]]],\n        [80000, \"Single\", [[\"Suit\", 800], [\"Watch\", 1800], [\"Car\", 800]]],\n    ],\n)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Multimodal Chatbot\nDESCRIPTION: Main implementation of the chatbot featuring message handling, bot responses with streaming text, and UI setup using Gradio Blocks. Includes support for multiple input types and like/dislike functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_multimodal/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\n\ndef print_like_dislike(x: gr.LikeData):\n    print(x.index, x.value, x.liked)\n\n\ndef add_message(history, message):\n    for x in message[\"files\"]:\n        history.append({\"role\": \"user\", \"content\": {\"path\": x}})\n    if message[\"text\"] is not None:\n        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n    return history, gr.MultimodalTextbox(value=None, interactive=False)\n\n\ndef bot(history: list):\n    response = \"**That's cool!**\"\n    history.append({\"role\": \"assistant\", \"content\": \"\"})\n    for character in response:\n        history[-1][\"content\"] += character\n        time.sleep(0.05)\n        yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(elem_id=\"chatbot\", bubble_full_width=False, type=\"messages\")\n\n    chat_input = gr.MultimodalTextbox(\n        interactive=True,\n        file_count=\"multiple\",\n        placeholder=\"Enter message or upload file...\",\n        show_label=False,\n        sources=[\"microphone\", \"upload\"],\n    )\n\n    chat_msg = chat_input.submit(\n        add_message, [chatbot, chat_input], [chatbot, chat_input]\n    )\n    bot_msg = chat_msg.then(bot, chatbot, chatbot, api_name=\"bot_response\")\n    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n\n    chatbot.like(print_like_dislike, None, None, like_user_message=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Executing Gradio Events Consecutively using .then() in Python\nDESCRIPTION: Demonstrates chaining Gradio event listeners using the `.then()` method in Python. This allows defining a sequence of actions triggered by a single event; here, a chatbot interface first updates with the user message (`add_text`) and then, after that completes, updates with the bot's response (`bot`), simulating sequential processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n$code_chatbot_consecutive\n```\n\n----------------------------------------\n\nTITLE: Implementing a 10-Questions Game with Gradio and Anthropic Claude API in Python\nDESCRIPTION: This Python script sets up and runs a Gradio chat interface for a '10 Questions' game. It imports `anthropic` and `gradio`, initializes the Anthropic client (requires `ANTHROPIC_API_KEY` environment variable), and defines a `predict` function. The `predict` function formats the conversation history, sends it to the Claude 3.5 Sonnet model via the `client.messages.create` method with specific system instructions, and returns the model's response formatted for the Gradio interface. Finally, it configures and launches the `gr.ChatInterface`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_claude/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple 20 questions-style game built on top of the Anthropic API.\n# Before running this, make sure you have exported your Anthropic API key as an environment variable:\n# export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n\nimport anthropic\nimport gradio as gr\n\nclient = anthropic.Anthropic()\n\ndef predict(message, history):\n    keys_to_keep = [\"role\", \"content\"]\n    history = [{k: d[k] for k in keys_to_keep if k in d} for d in history]\n    history.append({\"role\": \"user\", \"content\": message})\n    if len(history) > 20:\n        history.append({\"role\": \"user\", \"content\": \"DONE\"})\n    output = client.messages.create(\n        messages=history,  # type: ignore\n        model=\"claude-3-5-sonnet-20241022\",\n        max_tokens=1000,\n        system=\"You are guessing an object that the user is thinking of. You can ask 10 yes/no questions. Keep asking questions until the user says DONE\"\n    )\n    return {\n        \"role\": \"assistant\",\n        \"content\": output.content[0].text,  # type: ignore\n        \"options\": [{\"value\": \"Yes\"}, {\"value\": \"No\"}]\n    }\n\nplaceholder = \"\"\"\n<center><h1>10 Questions</h1><br>Think of a person, place, or thing. I'll ask you 10 yes/no questions to try and guess it.\n</center>\n\"\"\"\n\ndemo = gr.ChatInterface(\n    predict,\n    examples=[\"Start!\"],\n    chatbot=gr.Chatbot(placeholder=placeholder),\n    type=\"messages\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Making API Predictions with Gradio Client\nDESCRIPTION: Example showing how to make predictions by calling an API endpoint using the predict method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n----------------------------------------\n\nTITLE: Defining the Tool Interface for Pluggable Image Editor Tools - TypeScript\nDESCRIPTION: This TypeScript interface outlines the contract every editor tool must follow within the pluggable tool system. Tools must provide a name, a setup method that receives the editor context and tool selection, cleanup and tool switching methods. This enables dynamic tool management, resource cleanup, and flexible integration with the main editor. Dependencies include the ImageEditorContext and tool/subtool types, and input/output consist of tool initialization and side effects for editor state management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/IMAGE_EDITOR_OVERVIEW.md#2025-04-23_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Tool {\n  name: string;\n  setup(context: ImageEditorContext, tool: ToolbarTool, subtool: Subtool): Promise<void>;\n  cleanup(): void;\n  set_tool(tool: ToolbarTool, subtool: Subtool): void;\n}\n```\n\n----------------------------------------\n\nTITLE: Integrating LlamaIndex with Gradio ChatInterface\nDESCRIPTION: Example showing how to create a RAG chatbot using LlamaIndex with OpenAI backend and Gradio's ChatInterface. Demonstrates document loading, index creation, and query engine setup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/02_chatinterface-examples.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n$code_llm_llamaindex\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Chat Interface with Prefill Functionality in Python\nDESCRIPTION: This code creates a Gradio application with a chat interface that can be prefilled based on user selection. It includes functions for prefilling the chat and generating random responses, and sets up the Gradio interface with radio buttons and a chat component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_prefill/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\ndef prefill_chatbot(choice):\n    if choice == \"Greeting\":\n        return [\n            {\"role\": \"user\", \"content\": \"Hi there!\"},\n            {\"role\": \"assistant\", \"content\": \"Hello! How can I assist you today?\"}\n        ]\n    elif choice == \"Complaint\":\n        return [\n            {\"role\": \"user\", \"content\": \"I'm not happy with the service.\"},\n            {\"role\": \"assistant\", \"content\": \"I'm sorry to hear that. Can you please tell me more about the issue?\"}\n        ]\n    else:\n        return []\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio([\"Greeting\", \"Complaint\", \"Blank\"])\n    chat = gr.ChatInterface(random_response, type=\"messages\")\n    radio.change(prefill_chatbot, radio, chat.chatbot_value)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing and Launching a spaCy Text Analysis Gradio Interface in Python\nDESCRIPTION: This Python script imports necessary libraries (`gradio`, `os`, `spacy`, `displacy`), downloads the `en_core_web_sm` spaCy English model, and defines a function `text_analysis`. This function takes text input, processes it with spaCy to generate POS tags and a dependency parse visualization (HTML via displacy), and calculates character/token counts. Finally, it creates and launches a `gradio.Interface` configured with a textbox input and outputs for highlighted text (POS tags), JSON (counts), and HTML (dependency parse). Example inputs are provided for demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/text_analysis/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\nos.system('python -m spacy download en_core_web_sm')\nimport spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef text_analysis(text):\n    doc = nlp(text)\n    html = displacy.render(doc, style=\"dep\", page=True)\n    html = (\n        \"<div style='max-width:100%; max-height:360px; overflow:auto'>\"\n        + html\n        + \"</div>\"\n    )\n    pos_count = {\n        \"char_count\": len(text),\n        \"token_count\": 0,\n    }\n    pos_tokens = []\n\n    for token in doc:\n        pos_tokens.extend([(token.text, token.pos_), (\" \", None)])\n\n    return pos_tokens, pos_count, html\n\ndemo = gr.Interface(\n    text_analysis,\n    gr.Textbox(placeholder=\"Enter sentence here...\"),\n    [\"highlight\", \"json\", \"html\"],\n    examples=[\n        [\"What a beautiful morning for a walk!\"],\n        [\"It was the best of times, it was the worst of times.\"],\n    ],\n)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing a Streaming Echo ChatInterface with History and User Feedback\nDESCRIPTION: Creates a ChatInterface with streaming capabilities, persistent chat history, and user feedback options. The example demonstrates how to configure flagging options and save history in the browser's local storage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n$code_chatinterface_streaming_echo\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Addition and Management with Canvas and Layers using TypeScript\nDESCRIPTION: This set of TypeScript classes and functions forms the backend logic for the Image Tool, handling the addition of images (from uploads, clipboard, or webcam), aspect-ratio-preserving scaling, dynamic canvas resizing, and background/layer integration. The 'ImageTool' class provides the high-level interface, while 'AddImageCommand' enables undo/redo via the command pattern. Helper functions manage image fitting and background color overlays. Dependencies include PIXI.js and the editor state management interfaces. Key parameters affect image source, scaling mode, and canvas context integration; inputs include image Blobs/Files and flags for fixed sizing. Outputs include state changes in canvas and editor, updated image/layer properties, and optional background generation. Limitations include possible performance impacts with large images and the requirement for proper resource management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/image/IMAGE.md#2025-04-23_snippet_0\n\nLANGUAGE: TypeScript\nCODE:\n```\n// This code is described in the documentation for js/imageeditor/shared/image/image.ts and related files.\n//\n// Class: ImageTool\n// Implements Tool interface for handling background image addition and management on a canvas.\n//\n// Key Methods:\n// - setup(context, tool, subtool): Initializes tool with editor context and sets up listeners.\n// - cleanup(): Removes resources or event bindings set up by this tool.\n// - add_image(image: Blob | File, fixed_canvas: boolean): Adds an image, optionally scaling or resizing canvas.\n// - set_tool(tool, subtool): Changes the current tool/subtool mode.\n\nclass ImageTool implements Tool {\n  setup(context: ImageEditorContext, tool: ToolType, subtool: SubtoolType): void { /* ... */ }\n  cleanup(): void { /* ... */ }\n  add_image(image: Blob | File, fixed_canvas: boolean): void { /* ... */ }\n  set_tool(tool: ToolType, subtool: SubtoolType): void { /* ... */ }\n}\n\n// Class: AddImageCommand\n// Implements the command pattern for image addition, supporting undo/redo.\nclass AddImageCommand implements Command {\n  constructor(/* ... */) { /* ... */ }\n  start(): void { /* Converts input to bitmap, creates texture, prepares dimensions and sprites */ }\n  execute(): void { /* Adds the image to the canvas, manages layers, updates editor context */ }\n  undo(): void { /* Removes the image from the canvas */ }\n}\n\n// Helper: fit_image_to_canvas\n// Calculates aspect-ratio preserving dimensions of an image fitting into the canvas.\nfunction fit_image_to_canvas(image_width: number, image_height: number, canvas_width: number, canvas_height: number): { width: number, height: number, x: number, y: number } {\n  // ...\n}\n\n// Helper: add_bg_color\n// Adds a solid color background behind canvas elements.\nfunction add_bg_color(container: PIXI.Container, renderer: PIXI.Renderer, color: string, width: number, height: number, resize: boolean): void {\n  // ...\n}\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Global State Counter in Gradio\nDESCRIPTION: This snippet demonstrates how to use global state in a Gradio application to count and display the total number of visitors. It uses a shared variable outside of functions to maintain the count across all users.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/03_state-in-blocks.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n# Shared between all users\nvisitor_count = 0\n\ndef increment_counter():\n    global visitor_count\n    visitor_count += 1\n    return visitor_count\n\nwith gr.Blocks() as demo:    \n    number = gr.Textbox(label=\"Total Visitors\", value=\"Counting...\")\n    demo.load(increment_counter, inputs=None, outputs=number)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Gradio UI Implementation for Audio Chatbot\nDESCRIPTION: Creates the Gradio interface with audio recording, chatbot display, and streaming playback components. Implements event handlers for recording, response generation, and conversation management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/04_conversational-chatbot.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef start_recording_user(state: AppState):\n    if not state.stopped:\n        return gr.Audio(recording=True)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_audio = gr.Audio(\n                label=\"Input Audio\", sources=\"microphone\", type=\"numpy\"\n            )\n        with gr.Column():\n            chatbot = gr.Chatbot(label=\"Conversation\", type=\"messages\")\n            output_audio = gr.Audio(label=\"Output Audio\", streaming=True, autoplay=True)\n    state = gr.State(value=AppState())\n\n    stream = input_audio.stream(\n        process_audio,\n        [input_audio, state],\n        [input_audio, state],\n        stream_every=0.5,\n        time_limit=30,\n    )\n    respond = input_audio.stop_recording(\n        response,\n        [state],\n        [output_audio, state]\n    )\n    respond.then(lambda s: s.conversation, [state], [chatbot])\n\n    restart = output_audio.stop(\n        start_recording_user,\n        [state],\n        [input_audio]\n    )\n    cancel = gr.Button(\"Stop Conversation\", variant=\"stop\")\n    cancel.click(lambda: (AppState(stopped=True), gr.Audio(recording=False)), None,\n                [state, input_audio], cancels=[respond, restart])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Multiple Input/Output Interface\nDESCRIPTION: Shows how to create an interface with multiple inputs (string, boolean, number) and multiple outputs (string and number). Demonstrates handling multiple components in both inputs and outputs lists.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/00_the-interface-class.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef greet(name, is_morning, temperature):\n    greeting = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = f\"{greeting}, {name}! It is {temperature} degrees today\"\n    celsius = (temperature - 32) * 5/9\n    return greeting, round(celsius, 2)\n\ngr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n    outputs=[\"text\", \"number\"]\n)\n```\n\n----------------------------------------\n\nTITLE: Defining the Image Prediction Function with PyTorch (Python)\nDESCRIPTION: This snippet defines a function to process an input image and return class confidence probabilities using the pretrained model. Dependencies include `torch`, `requests`, `PIL`, and `torchvision.transforms`, and the model variable must be defined from earlier. The function takes a PIL Image, preprocesses it, computes predictions with softmax, and returns a dictionary mapping class labels (loaded over HTTP) to their associated probabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-pytorch.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nfrom PIL import Image\nfrom torchvision import transforms\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\n----------------------------------------\n\nTITLE: Running Gradio App with CLI Auto-Reload in Terminal (Bash)\nDESCRIPTION: This Bash snippet displays the monitored directories and running URL when using the `gradio` CLI for auto-reloading scripts. It’s representative output, showing developers that file changes in watched directories will cause the app to restart. Intended as informative output, not an executable command.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nWatching: '/Users/freddy/sources/gradio/gradio', '/Users/freddy/sources/gradio/demo/'\n\nRunning on local URL:  http://127.0.0.1:7860\n```\n\n----------------------------------------\n\nTITLE: Implementing Preprocess and Postprocess Methods\nDESCRIPTION: Core methods for converting between frontend and backend data formats in Gradio components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/04_backend.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n    def preprocess(self, x: Any) -> Any:\n        \"\"\"\n        Convert from the web-friendly (typically JSON) value in the frontend to the format expected by the python function.\n        \"\"\"\n        return x\n\n    def postprocess(self, y):\n        \"\"\"\n        Convert from the data returned by the python function to the web-friendly (typically JSON) value expected by the frontend.\n        \"\"\"\n        return y\n```\n\n----------------------------------------\n\nTITLE: Creating White Noise Video with Gradio Interface\nDESCRIPTION: This code creates a function to generate a white noise video, then sets up a Gradio interface to display and download the video. It uses NumPy for random number generation, OpenCV for video writing, and Gradio for the user interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/white_noise_vid_not_playable/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport gradio as gr\nimport numpy as np\n\ndef gif_maker():\n    img_array = []\n    height, width = 50, 50\n    for i in range(30):\n        img_array.append(np.random.randint(0, 255, size=(height, width, 3)).astype(np.uint8))\n    output_file = \"test.mp4\"\n    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'mp4v'), 15, (height, width))  # type: ignore\n    for i in range(len(img_array)):\n        out.write(img_array[i])\n    out.release()\n    return output_file, output_file\n\ndemo = gr.Interface(gif_maker, inputs=None, outputs=[gr.Video(), gr.File()])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Subtitle Demo with Gradio\nDESCRIPTION: Creates a Gradio interface for adding subtitles to videos. It defines paths for sample files, implements a function to handle video and subtitle inputs, and sets up the Gradio interface with appropriate inputs, outputs, and examples.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_subtitle/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\na = os.path.join(os.path.abspath(''), \"files/a.mp4\")  # Video\nb = os.path.join(os.path.abspath(''), \"files/b.mp4\")  # Video\ns1 = os.path.join(os.path.abspath(''), \"files/s1.srt\")  # Subtitle\ns2 = os.path.join(os.path.abspath(''), \"files/s2.vtt\")  # Subtitle\n\ndef video_demo(video, subtitle=None):\n    if subtitle is None:\n        return video\n\n    return [video, subtitle.name]\n\ndemo = gr.Interface(\n    fn=video_demo,\n    inputs=[\n        gr.Video(label=\"In\", interactive=True),\n        gr.File(label=\"Subtitle\", file_types=[\".srt\", \".vtt\"]),\n    ],\n    outputs=gr.Video(label=\"Out\"),\n    examples=[\n        [a, s1],\n        [b, s2],\n        [a, None],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Speaker Verification with Gradio Interface\nDESCRIPTION: Creates a complete speaker verification application using Microsoft's UniSpeech-SAT model. The code sets up audio processing, embedding extraction, similarity calculation, and a Gradio interface for user interaction with visual feedback on whether two speakers are the same person.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/same-person-or-different/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\nfrom torchaudio.sox_effects import apply_effects_file\nfrom transformers import AutoFeatureExtractor, AutoModelForAudioXVector\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nOUTPUT_OK = (\n    \"\"\"\n    <div class=\"container\">\n        <div class=\"row\"><h1 style=\"text-align: center\">The speakers are</h1></div>\n        <div class=\"row\"><h1 class=\"display-1 text-success\" style=\"text-align: center\">{:.1f}%</h1></div>\n        <div class=\"row\"><h1 style=\"text-align: center\">similar</h1></div>\n        <div class=\"row\"><h1 class=\"text-success\" style=\"text-align: center\">Welcome, human!</h1></div>\n        <div class=\"row\"><small style=\"text-align: center\">(You must get at least 85% to be considered the same person)</small><div class=\"row\">\n    </div>\n\"\"\"\n)\nOUTPUT_FAIL = (\n    \"\"\"\n    <div class=\"container\">\n        <div class=\"row\"><h1 style=\"text-align: center\">The speakers are</h1></div>\n        <div class=\"row\"><h1 class=\"display-1 text-danger\" style=\"text-align: center\">{:.1f}%</h1></div>\n        <div class=\"row\"><h1 style=\"text-align: center\">similar</h1></div>\n        <div class=\"row\"><h1 class=\"text-danger\" style=\"text-align: center\">You shall not pass!</h1></div>\n        <div class=\"row\"><small style=\"text-align: center\">(You must get at least 85% to be considered the same person)</small><div class=\"row\">\n    </div>\n\"\"\"\n)\n\nEFFECTS = [\n    [\"remix\", \"-\"],\n    [\"channels\", \"1\"],\n    [\"rate\", \"16000\"],\n    [\"gain\", \"-1.0\"],\n    [\"silence\", \"1\", \"0.1\", \"0.1%\", \"-1\", \"0.1\", \"0.1%\"],\n    [\"trim\", \"0\", \"10\"],\n]\n\nTHRESHOLD = 0.85\n\nmodel_name = \"microsoft/unispeech-sat-base-plus-sv\"\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\nmodel = AutoModelForAudioXVector.from_pretrained(model_name).to(device)\ncosine_sim = torch.nn.CosineSimilarity(dim=-1)\n\ndef similarity_fn(path1, path2):\n    if not (path1 and path2):\n        return '<b style=\"color:red\">ERROR: Please record audio for *both* speakers!</b>'\n\n    wav1, _ = apply_effects_file(path1, EFFECTS)\n    wav2, _ = apply_effects_file(path2, EFFECTS)\n    print(wav1.shape, wav2.shape)\n\n    input1 = feature_extractor(wav1.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n    input2 = feature_extractor(wav2.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n\n    with torch.no_grad():\n        emb1 = model(input1).embeddings\n        emb2 = model(input2).embeddings\n    emb1 = torch.nn.functional.normalize(emb1, dim=-1).cpu()\n    emb2 = torch.nn.functional.normalize(emb2, dim=-1).cpu()\n    similarity = cosine_sim(emb1, emb2).numpy()[0]\n\n    if similarity >= THRESHOLD:\n        output = OUTPUT_OK.format(similarity * 100)\n    else:\n        output = OUTPUT_FAIL.format(similarity * 100)\n\n    return output\n\ninputs = [\n    gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speaker #1\"),\n    gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speaker #2\"),\n]\noutput = gr.HTML(label=\"\")\n\ndescription = (\n    \"This demo from Microsoft will compare two speech samples and determine if they are from the same speaker. \"\n    \"Try it with your own voice!\"\n)\narticle = (\n    \"<p style='text-align: center'>\"\n    \"<a href='https://huggingface.co/microsoft/unispeech-sat-large-sv' target='_blank'>🎙️ Learn more about UniSpeech-SAT</a> | \"\n    \"<a href='https://arxiv.org/abs/2110.05752' target='_blank'>📚 UniSpeech-SAT paper</a> | \"\n    \"<a href='https://www.danielpovey.com/files/2018_icassp_xvectors.pdf' target='_blank'>📚 X-Vector paper</a>\"\n    \"</p>\"\n)\nexamples = [\n    [\"samples/cate_blanch.mp3\", \"samples/cate_blanch_2.mp3\"],\n    [\"samples/cate_blanch.mp3\", \"samples/heath_ledger.mp3\"],\n]\n\ninterface = gr.Interface(\n    fn=similarity_fn,\n    inputs=inputs,\n    outputs=output,\n    layout=\"horizontal\",\n    flagging_mode=\"never\",\n    live=False,\n    examples=examples,\n    cache_examples=False\n)\ninterface.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing PDF Component Backend in Python\nDESCRIPTION: This snippet shows the complete backend implementation of the PDF component, including necessary imports, class definition, and methods for preprocessing and postprocessing data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\nfrom typing import Any, Callable, TYPE_CHECKING\n\nfrom gradio.components.base import Component\nfrom gradio.data_classes import FileData\nfrom gradio import processing_utils\nif TYPE_CHECKING:\n    from gradio.components import Timer\n\nclass PDF(Component):\n\n    EVENTS = [\"change\", \"upload\"]\n\n    data_model = FileData\n\n    def __init__(self, value: Any = None, *,\n                 height: int | None = None,\n                 label: str | None = None, info: str | None = None,\n                 show_label: bool | None = None,\n                 container: bool = True,\n                 scale: int | None = None,\n                 min_width: int | None = None,\n                 interactive: bool | None = None,\n                 visible: bool = True,\n                 elem_id: str | None = None,\n                 elem_classes: list[str] | str | None = None,\n                 render: bool = True,\n                 load_fn: Callable[..., Any] | None = None,\n                 every: Timer | float | None = None):\n        super().__init__(value, label=label, info=info,\n                         show_label=show_label, container=container,\n                         scale=scale, min_width=min_width,\n                         interactive=interactive, visible=visible,\n                         elem_id=elem_id, elem_classes=elem_classes,\n                         render=render, load_fn=load_fn, every=every)\n        self.height = height\n\n    def preprocess(self, payload: FileData) -> str:\n        return payload.path\n\n    def postprocess(self, value: str | None) -> FileData:\n        if not value:\n            return None\n        return FileData(path=value)\n\n    def example_payload(self):\n        return \"https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/fw9.pdf\"\n\n    def example_value(self):\n        return \"https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/fw9.pdf\"\n```\n\n----------------------------------------\n\nTITLE: Building a Multi-Page Gradio UI in Python\nDESCRIPTION: This snippet defines the main multipage interactive web demo with Gradio, including event bindings, routing, and custom callback logic. The primary page contains textboxes, buttons, and row layouts, and it demonstrates dynamic outputs, chained triggers, and side-effect rendering such as spelling out words. Additional routes demonstrate a numeric increment/decrement workflow and an image identity interface using Gradio's Interface class. Routing is managed via 'with' blocks, and events are bound using decorators and click handlers. Dependencies include Gradio, random, and time. Inputs and outputs are typically text or number fields or images. Limitations may include the need for a suitable browser or Jupyter environment and the pip-installed Gradio version. The main entry point launches the app upon execution.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/multipage/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    @gr.on([greet_btn.click, name.submit], inputs=name, outputs=output)\n    def greet(name):\n        return \"Hello \" + name + \"!\"\n    \n    @gr.render(inputs=name, triggers=[output.change])\n    def spell_out(name):\n        with gr.Row():\n            for letter in name:\n                gr.Textbox(letter)\n\nwith demo.route(\"Up\") as incrementer_demo:\n    num = gr.Number()\n    incrementer_demo.load(lambda: time.sleep(1) or random.randint(10, 40), None, num)\n\n    with gr.Row():\n        inc_btn = gr.Button(\"Increase\")\n        dec_btn = gr.Button(\"Decrease\")\n    inc_btn.click(fn=lambda x: x + 1, inputs=num, outputs=num, api_name=\"increment\")\n    dec_btn.click(fn=lambda x: x - 1, inputs=num, outputs=num, api_name=\"decrement\")\n    for i in range(100):\n        gr.Textbox()\n\ndef wait(x):\n    time.sleep(2)\n    return x\n\nidentity_iface = gr.Interface(wait, \"image\", \"image\")\n\nwith demo.route(\"Interface\") as incrementer_demo:\n    identity_iface.render()\n    gr.Interface(lambda x, y: x * y, [\"number\", \"number\"], \"number\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Custom Layout using Gradio Blocks API\nDESCRIPTION: Constructs a complex UI layout using Gradio's Blocks API with nested Rows and Columns. The example includes various UI components like Image, Textbox, Number, Radio, and Button with different scaling properties and arrangements.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_layout/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Blocks()\n\nwith demo:\n    with gr.Row():\n        gr.Image(interactive=True, scale=2)\n        gr.Image()\n    with gr.Row():\n        gr.Textbox(label=\"Text\")\n        gr.Number(label=\"Count\", scale=2)\n        gr.Radio(choices=[\"One\", \"Two\"])\n    with gr.Row():\n        gr.Button(\"500\", scale=0, min_width=500)\n        gr.Button(\"A\", scale=0)\n        gr.Button(\"grow\")\n    with gr.Row():\n        gr.Textbox()\n        gr.Textbox()\n        gr.Button()\n    with gr.Row():\n        with gr.Row():\n            with gr.Column():\n                gr.Textbox(label=\"Text\")\n                gr.Number(label=\"Count\")\n                gr.Radio(choices=[\"One\", \"Two\"])\n            gr.Image()\n            with gr.Column():\n                gr.Image(interactive=True)\n                gr.Image()\n    gr.Image()\n    gr.Textbox(label=\"Text\")\n    gr.Number(label=\"Count\")\n    gr.Radio(choices=[\"One\", \"Two\"])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Audio Identification Model and Interface - Python\nDESCRIPTION: This main code snippet loads dependencies, downloads pretrained model weights and example audio files, defines a prediction function that preprocesses audio and runs instrument inference, and launches a Gradio interface. Requires all listed dependencies and that 'data_setups.py' is previously downloaded; inputs are file paths to audio clips and outputs are predicted instrument probabilities and prediction latency in seconds. The demo is configured to display top 11 instrument class scores, handles file management, and employs device-aware inference (CPU/CUDA when available).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/musical_instrument_identification/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\nimport torchaudio\nfrom timeit import default_timer as timer\nfrom data_setups import audio_preprocess, resample\nimport gdown\n\nurl = 'https://drive.google.com/uc?id=1X5CR18u0I-ZOi_8P0cNptCe5JGk9Ro0C'\noutput = 'piano.wav'\ngdown.download(url, output, quiet=False)\nurl = 'https://drive.google.com/uc?id=1W-8HwmGR5SiyDbUcGAZYYDKdCIst07__'\noutput= 'torch_efficientnet_fold2_CNN.pth'\ngdown.download(url, output, quiet=False)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nSAMPLE_RATE = 44100\nAUDIO_LEN = 2.90\nmodel = torch.load(\"torch_efficientnet_fold2_CNN.pth\", map_location=torch.device('cpu'))\nLABELS = [\n    \"Cello\", \"Clarinet\", \"Flute\", \"Acoustic Guitar\", \"Electric Guitar\", \"Organ\", \"Piano\", \"Saxophone\", \"Trumpet\", \"Violin\", \"Voice\"\n]\nexample_list = [\n    [\"piano.wav\"]\n]\n\ndef predict(audio_path):\n    start_time = timer()\n    wavform, sample_rate = torchaudio.load(audio_path)\n    wav = resample(wavform, sample_rate, SAMPLE_RATE)\n    if len(wav) > int(AUDIO_LEN * SAMPLE_RATE):\n        wav = wav[:int(AUDIO_LEN * SAMPLE_RATE)]\n    else:\n        print(f\"input length {len(wav)} too small!, need over {int(AUDIO_LEN * SAMPLE_RATE)}\")\n        return\n    img = audio_preprocess(wav, SAMPLE_RATE).unsqueeze(0)\n    model.eval()\n    with torch.inference_mode():\n        pred_probs = torch.softmax(model(img), dim=1)\n    pred_labels_and_probs = {LABELS[i]: float(pred_probs[0][i]) for i in range(len(LABELS))}\n    pred_time = round(timer() - start_time, 5)\n    return pred_labels_and_probs, pred_time\n\ndemo = gr.Interface(fn=predict,\n                    inputs=gr.Audio(type=\"filepath\"),\n                    outputs=[gr.Label(num_top_classes=11, label=\"Predictions\"),\n                             gr.Number(label=\"Prediction time (s)\")],\n                    examples=example_list,\n                    cache_examples=False\n                    )\n\ndemo.launch(debug=False)\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Sine Curve Plot with Gradio and Plotly (Python)\nDESCRIPTION: This Python script defines a function `get_plot` that generates sine wave data using NumPy based on a given period and plots it using Plotly Express. It maintains a global `plot_end` variable to shift the plot window over time. A Gradio `Blocks` interface is constructed, featuring a slider (`period`) to adjust the sine wave's period and a plot component (`plot`) to display the visualization. The `demo.load` function initializes the plot and sets it to update every second. The `period.change` function links the slider's value to the `get_plot` function, updating the plot whenever the slider changes (debounced to every second) and cancelling the automatic load updates. Finally, the script launches the Gradio application if run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sine_curve/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport math\nimport gradio as gr\nimport plotly.express as px\nimport numpy as np\n\nplot_end = 2 * math.pi\n\ndef get_plot(period=1):\n    global plot_end\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\n    y = np.sin(2*math.pi*period * x)\n    fig = px.line(x=x, y=y)\n    plot_end += 2 * math.pi\n    if plot_end > 1000:\n        plot_end = 2 * math.pi\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"Change the value of the slider to automatically update the plot\")\n            period = gr.Slider(label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1)\n            plot = gr.Plot(label=\"Plot (updates every half second)\")\n\n    dep = demo.load(get_plot, None, plot, every=1)\n    period.change(get_plot, period, plot, every=1, cancels=[dep])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Live Calculator Interface with Gradio\nDESCRIPTION: Creates a calculator application using Gradio that performs basic arithmetic operations (add, subtract, multiply, divide) between two numbers. The interface updates results live as inputs change, featuring number inputs and radio buttons for operation selection.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_live/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\n        \"number\",\n        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n        \"number\"\n    ],\n    \"number\",\n    live=True,\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Streaming Chatbot with Gradio\nDESCRIPTION: Implements a streaming chatbot that shows immediate user messages and streams bot responses character by character. Uses chained events for better user experience.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/04_creating-a-custom-chatbot-with-blocks.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def user(message, history):\n        return \"\", history + [[message, None]]\n\n    def bot(history):\n        bot_message = random.choice([\"How are you?\", \"I'm doing great!\", \"I love you!\"])\n        history[-1][1] = \"\"\n        for character in bot_message:\n            history[-1][1] += character\n            time.sleep(0.05)\n            yield history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained ResNet18 and Running Gradio Image Classifier Interface - Python\nDESCRIPTION: This snippet imports required libraries, loads a pre-trained ResNet18 model using torch.hub, fetches human-readable ImageNet labels, and defines a prediction function. The Gradio interface is configured to accept image uploads, process them through the model, and display the top 3 predicted classes. Dependencies: torch, torchvision, requests, Pillow (PIL), and gradio. The 'predict' function expects a NumPy array input representing the image, and the output is a dictionary of class probabilities. Limitations: requires internet access for model and label downloads.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_2/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport requests\nimport torch\nfrom PIL import Image\nfrom torchvision import transforms\n\nimport gradio as gr\n\nmodel = torch.hub.load(\"pytorch/vision:v0.6.0\", \"resnet18\", pretrained=True).eval()\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n    inp = Image.fromarray(inp.astype(\"uint8\"), \"RGB\")\n    inp = transforms.ToTensor()(inp).unsqueeze(0)\n    with torch.no_grad():\n        prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\ninputs = gr.Image()\noutputs = gr.Label(num_top_classes=3)\n\ndemo = gr.Interface(fn=predict, inputs=inputs, outputs=outputs)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio File Explorer Interface\nDESCRIPTION: Creates a Gradio interface with multiple FileExplorer components demonstrating different configurations. Includes examples of multiple file selection and single file viewing with code display. Uses path handling for file access and implements file content retrieval functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom pathlib import Path\n\ncurrent_file_path = Path(__file__).resolve()\nrelative_path = \"path/to/file\"\nabsolute_path = (current_file_path.parent / \"..\" / \"..\" / \"gradio\").resolve()\n\ndef get_file_content(file):\n    return (file,)\n\nwith gr.Blocks() as demo:\n    gr.Markdown('### `FileExplorer` to `FileExplorer` -- `file_count=\"multiple\"`')\n    submit_btn = gr.Button(\"Select\")\n    with gr.Row():\n        file = gr.FileExplorer(\n            glob=\"**/components/*.py\",\n            # value=[\"themes/utils\"],\n            root_dir=absolute_path,\n            ignore_glob=\"**/__init__.py\",\n        )\n\n        file2 = gr.FileExplorer(\n            glob=\"**/components/**/*.py\",\n            root_dir=absolute_path,\n            ignore_glob=\"**/__init__.py\",\n        )\n    submit_btn.click(lambda x: x, file, file2)\n\n    gr.Markdown(\"---\")\n    gr.Markdown('### `FileExplorer` to `Code` -- `file_count=\"single\"`')\n    with gr.Group():\n        with gr.Row():\n            file_3 = gr.FileExplorer(\n                scale=1,\n                glob=\"**/components/**/*.py\",\n                value=[\"themes/utils\"],\n                file_count=\"single\",\n                root_dir=absolute_path,\n                ignore_glob=\"**/__init__.py\",\n                elem_id=\"file\",\n            )\n\n            code = gr.Code(lines=30, scale=2, language=\"python\")\n\n    file_3.change(get_file_content, file_3, code)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Interface for GPT-2 XL Text Generation in Python\nDESCRIPTION: This snippet creates a Gradio interface for text generation using the GPT-2 XL model. It sets up a textbox component, loads the GPT-2 XL model from Hugging Face, defines the generation function, and launches the interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gpt2_xl_unified/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ncomponent = gr.Textbox(lines=5, label=\"Text\")\napi = gr.load(\"huggingface/gpt2-xl\")\n\ndemo = gr.Interface(\n    fn=lambda x: x[:-50] + api(x[-50:]),\n    inputs=component,\n    outputs=component,\n    title=\"gpt2-xl\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Streaming Chat Interface (Python)\nDESCRIPTION: This Python code defines a simple streaming chat application using Gradio. It includes a `slow_echo` function that takes a message and history, yields the response character by character prefixed with a run counter, demonstrating streaming output. A global variable `runs` tracks function calls and is reset using `reset_runs` when the demo unloads. The `gr.ChatInterface` is instantiated with the `slow_echo` function and embedded within `gr.Blocks` before being launched.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_streaming_echo/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nruns = 0\n\ndef reset_runs():\n    global runs\n    runs = 0\n\ndef slow_echo(message, history):\n    global runs  # i didn't want to add state or anything to this demo\n    runs = runs + 1\n    for i in range(len(message)):\n        yield f\"Run {runs} - You typed: \" + message[: i + 1]\n\nchat = gr.ChatInterface(slow_echo, fill_height=True, editable=True)\n\nwith gr.Blocks() as demo:\n    chat.render()\n    # We reset the global variable to minimize flakes\n    # this works because CI runs only one test at at time\n    # need to use gr.State if we want to parallelize this test\n    # currently chatinterface does not support that\n    demo.unload(reset_runs)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Complete CryptoPunks GAN Generator with Gradio Interface\nDESCRIPTION: Complete implementation of a CryptoPunks generator using a pre-trained GAN model loaded from Hugging Face Hub, with a Gradio interface. The code includes the Generator neural network architecture, model loading, prediction function, and Gradio interface configuration with sliders for seed and number of punks parameters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom torch import nn\nfrom huggingface_hub import hf_hub_download\nfrom torchvision.utils import save_image\nimport gradio as gr\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10),\n    ],\n    outputs=\"image\",\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True)\n```\n\n----------------------------------------\n\nTITLE: Adding Additional Inputs to ChatInterface - Gradio (Python)\nDESCRIPTION: This snippet demonstrates how to include extra customizable input components (textbox and slider) in a chat interface, using the 'additional_inputs' parameter of Gradio's ChatInterface within a Blocks context. The function 'echo' uses the chat message, system prompt, and token count to generate and stream incremental responses, making use of Python's generator/yield pattern for streaming. Required dependencies are Gradio and the time module. Components are created and positioned in the layout, then passed as additional_inputs for flexible UI arrangement.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef echo(message, history, system_prompt, tokens):\n    response = f\"System prompt: {system_prompt}\\n Message: {message}.\"\n    for i in range(min(len(response), int(tokens))):\n        time.sleep(0.05)\n        yield response[: i+1]\n\nwith gr.Blocks() as demo:\n    system_prompt = gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\")\n    slider = gr.Slider(10, 100, render=False)\n\n    gr.ChatInterface(\n        echo, additional_inputs=[system_prompt, slider], type=\"messages\"\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Simple Chatbot Interface\nDESCRIPTION: Creates a chatbot interface using Gradio Blocks that responds with random messages. The implementation includes a chat history, message input box, and clear button. The bot responds after a 2-second delay with one of three predefined messages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(type=\"messages\")\n    msg = gr.Textbox()\n    clear = gr.ClearButton([msg, chatbot])\n\n    def respond(message, chat_history):\n        bot_message = random.choice([\"How are you?\", \"Today is a great day\", \"I'm very hungry\"])\n        chat_history.append({\"role\": \"user\", \"content\": message})\n        chat_history.append({\"role\": \"assistant\", \"content\": bot_message})\n        time.sleep(2)\n        return \"\", chat_history\n\n    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Dashboard with Gradio and Plotly\nDESCRIPTION: This snippet defines the main functionality of the dashboard. It imports required libraries, defines plot creation functions, and sets up the Gradio interface with various input components and output plots.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport plotly.express as px\nfrom helpers import retrieve_pip_installs, retrieve_stars, retrieve_issues\n\nLIBRARIES = [\"accelerate\", \"datasets\", \"diffusers\", \"evaluate\", \"gradio\", \"hub_docs\",\n             \"huggingface_hub\", \"optimum\", \"pytorch_image_models\", \"tokenizers\", \"transformers\"]\n\ndef create_pip_plot(libraries, pip_choices):\n    if \"Pip\" not in pip_choices:\n        return gr.Plot(visible=False)\n    output = retrieve_pip_installs(libraries, \"Cumulated\" in pip_choices)\n    df = pd.DataFrame(output).melt(id_vars=\"day\")\n    plot = px.line(df, x=\"day\", y=\"value\", color=\"variable\",\n                   title=\"Pip installs\")\n    plot.update_layout(legend=dict(x=0.5, y=0.99),  title_x=0.5, legend_title_text=\"\")\n    return gr.Plot(value=plot, visible=True)\n\ndef create_star_plot(libraries, star_choices):\n    if \"Stars\" not in star_choices:\n        return gr.Plot(visible=False)\n    output = retrieve_stars(libraries, \"Week over Week\" in star_choices)\n    df = pd.DataFrame(output).melt(id_vars=\"day\")\n    plot = px.line(df, x=\"day\", y=\"value\", color=\"variable\",\n                   title=\"Number of stargazers\")\n    plot.update_layout(legend=dict(x=0.5, y=0.99),  title_x=0.5, legend_title_text=\"\")\n    return gr.Plot(value=plot, visible=True)\n\ndef create_issue_plot(libraries, issue_choices):\n    if \"Issue\" not in issue_choices:\n        return gr.Plot(visible=False)\n    output = retrieve_issues(libraries,\n                             exclude_org_members=\"Exclude org members\" in issue_choices,\n                             week_over_week=\"Week over Week\" in issue_choices)\n    df = pd.DataFrame(output).melt(id_vars=\"day\")\n    plot = px.line(df, x=\"day\", y=\"value\", color=\"variable\",\n                   title=\"Cumulated number of issues, PRs, and comments\",\n                   )\n    plot.update_layout(legend=dict(x=0.5, y=0.99),  title_x=0.5, legend_title_text=\"\")\n    return gr.Plot(value=plot, visible=True)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"## Select libraries to display\")\n            libraries = gr.CheckboxGroup(choices=LIBRARIES, show_label=False)\n        with gr.Column():\n            gr.Markdown(\"## Select graphs to display\")\n            pip = gr.CheckboxGroup(choices=[\"Pip\", \"Cumulated\"], show_label=False)\n            stars = gr.CheckboxGroup(choices=[\"Stars\", \"Week over Week\"], show_label=False)\n            issues = gr.CheckboxGroup(choices=[\"Issue\", \"Exclude org members\", \"week over week\"], show_label=False)\n    with gr.Row():\n        fetch = gr.Button(value=\"Fetch\")\n    with gr.Row():\n        with gr.Column():\n            pip_plot = gr.Plot(visible=False)\n            star_plot = gr.Plot(visible=False)\n            issue_plot = gr.Plot(visible=False)\n\n    fetch.click(create_pip_plot, inputs=[libraries, pip], outputs=pip_plot)\n    fetch.click(create_star_plot, inputs=[libraries, stars], outputs=star_plot)\n    fetch.click(create_issue_plot, inputs=[libraries, issues], outputs=issue_plot)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Interactive Stock Forecast Demo with Gradio - Python\nDESCRIPTION: This code defines an interactive Gradio interface for visualizing projected stock trends. The main function 'plot_forecast' generates a synthetic forecast plot using user-selected companies, target years, noise levels, and style options, leveraging matplotlib for plotting and numpy for numeric operations. It builds the Gradio interface with input controls (radio, checkboxes, sliders, dropdowns) and returns a PNG plot; dependencies include gradio, numpy, and matplotlib, and the app can be run directly as a script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stock_forecast/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport gradio as gr\n\ndef plot_forecast(final_year, companies, noise, show_legend, point_style):\n    start_year = 2020\n    x = np.arange(start_year, final_year + 1)\n    year_count = x.shape[0]\n    plt_format = ({\"cross\": \"X\", \"line\": \"-\", \"circle\": \"o--\"})[point_style]\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    for i, company in enumerate(companies):\n        series = np.arange(0, year_count, dtype=float)\n        series = series**2 * (i + 1)\n        series += np.random.rand(year_count) * noise\n        ax.plot(x, series, plt_format)\n    if show_legend:\n        plt.legend(companies)\n    return fig\n\ndemo = gr.Interface(\n    plot_forecast,\n    [\n        gr.Radio([2025, 2030, 2035, 2040], label=\"Project to:\"),\n        gr.CheckboxGroup([\"Google\", \"Microsoft\", \"Gradio\"], label=\"Company Selection\"),\n        gr.Slider(1, 100, label=\"Noise Level\"),\n        gr.Checkbox(label=\"Show Legend\"),\n        gr.Dropdown([\"cross\", \"line\", \"circle\"], label=\"Style\"),\n    ],\n    gr.Plot(label=\"forecast\", format=\"png\"),\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Document QA Demo with Custom PDF Component in Python\nDESCRIPTION: This snippet demonstrates how to create a Gradio interface using the custom PDF component for document question-answering with HuggingFace transformers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_18\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_pdf import PDF\nfrom pdf2image import convert_from_path\nfrom transformers import pipeline\nfrom pathlib import Path\n\ndir_ = Path(__file__).parent\n\np = pipeline(\n    \"document-question-answering\",\n    model=\"impira/layoutlm-document-qa\",\n)\n\ndef qa(question: str, doc: str) -> str:\n    img = convert_from_path(doc)[0]\n    output = p(img, question)\n    return sorted(output, key=lambda x: x[\"score\"], reverse=True)[0]['answer']\n\n\ndemo = gr.Interface(\n    qa,\n    [gr.Textbox(label=\"Question\"), PDF(label=\"Document\")],\n    gr.Textbox(),\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining an Initial Prediction Function for GAN Image Generation in Python\nDESCRIPTION: Defines a function `predict` that takes a `seed` value as input to generate a fixed number (4) of CryptoPunk images. It uses the provided seed to ensure reproducibility with `torch.manual_seed`, generates a random noise tensor `z`, passes it through the pre-loaded `model`, and saves the resulting images as 'punks.png' using `torchvision.utils.save_image`. The function returns the path to the saved image file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom torchvision.utils import save_image\n\ndef predict(seed):\n    num_punks = 4\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Classification with Gradio Interface\nDESCRIPTION: Creates a Gradio interface for image classification using a pre-trained ResNet18 model. The implementation includes loading the model, processing input images, making predictions, and displaying top 3 classification results with confidence scores.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classification/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\nimport requests\nfrom torchvision import transforms\n\nmodel = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True).eval()\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef predict(inp):\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\n  with torch.no_grad():\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n\ndemo = gr.Interface(fn=predict,\n             inputs=gr.Image(type=\"pil\"),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[[\"cheetah.jpg\"]],\n             )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Tab Groups with Gradio Blocks in Python\nDESCRIPTION: This snippet constructs a Gradio Blocks interface featuring two sets of tabs, each containing ten sub-tabs with markdown content and textboxes. It allows transferring submitted text between paired tabs, and includes buttons for dynamic tab visibility and interactivity control. The interface also supports tab selection via a number input and event handling for tab selection, dependent on having Gradio installed and ensuring execution in an environment that supports Python GUI interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabs/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Tabs():\n        with gr.Tab(\"Set 1\"):\n            with gr.Tabs(selected=\"a3\") as tabs_1:\n                tabset_1 = []\n                textset_1 = []\n                for i in range(10):\n                    with gr.Tab(f\"Tab {i+1}\", id=f\"a{i+1}\") as tab:\n                        gr.Markdown(f\"Text {i+1}!\")\n                        textbox = gr.Textbox(label=f\"Input {i+1}\")\n                        tabset_1.append(tab)\n                        textset_1.append(textbox)\n        with gr.Tab(\"Set 2\"):\n            tabset_2 = []\n            textset_2 = []\n            for i in range(10):\n                with gr.Tab(f\"Tab {i+11}\") as tab:\n                    gr.Markdown(f\"Text {i+11}!\")\n                    textbox = gr.Textbox(label=f\"Input {i+11}\")\n                    tabset_2.append(tab)\n                    textset_2.append(textbox)\n\n        for text1, text2 in zip(textset_1, textset_2):\n            text1.submit(lambda x: x, text1, text2)\n\n    selected = gr.Textbox(label=\"Selected Tab\")\n    with gr.Row():\n        hide_odd_btn = gr.Button(\"Hide Odd Tabs\")\n        show_all_btn = gr.Button(\"Show All Tabs\")\n        make_even_uninteractive_btn = gr.Button(\"Make Even Tabs Uninteractive\")\n        make_all_interactive_btn = gr.Button(\"Make All Tabs Interactive\")\n\n    select_tab_num = gr.Number(label=\"Select Tab #\", value=1)\n\n    hide_odd_btn.click(lambda: [gr.Tab(visible=i % 2 == 1) for i, _ in enumerate(tabset_1 + tabset_2)], outputs=(tabset_1 + tabset_2))\n    show_all_btn.click(lambda: [gr.Tab(visible=True) for tab in tabset_1 + tabset_2], outputs=(tabset_1 + tabset_2))\n    make_even_uninteractive_btn.click(lambda: [gr.Tab(interactive=i % 2 == 0) for i, _ in enumerate(tabset_1 + tabset_2)], outputs=(tabset_1 + tabset_2))\n    make_all_interactive_btn.click(lambda: [gr.Tab(interactive=True) for tab in tabset_1 + tabset_2], outputs=(tabset_1 + tabset_2))\n    select_tab_num.submit(lambda x: gr.Tabs(selected=f\"a{x}\"), inputs=select_tab_num, outputs=tabs_1)\n\n    def get_selected_index(evt: gr.SelectData):\n        return evt.value\n    gr.on([tab.select for tab in tabset_1 + tabset_2], get_selected_index, outputs=selected)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Audio Streaming Demo in Python\nDESCRIPTION: Defines and launches a Gradio application demonstrating two methods for streaming audio output. The first method (`stream_file`) uses `pydub` to chunk the input audio, saves each chunk to a temporary file (WAV or MP3 format selected by the user), and yields the file path for streaming. The second method (`stream_bytes`) reads the input audio file in binary mode and yields raw byte chunks. The interface includes input audio selection, format choice (for file streaming), buttons to trigger streaming, output audio components configured for streaming, and example usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio_out/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom pydub import AudioSegment\nfrom time import sleep\nimport os\nimport tempfile\nfrom pathlib import Path\n\nwith gr.Blocks() as demo:\n    input_audio = gr.Audio(label=\"Input Audio\", type=\"filepath\", format=\"mp3\")\n    with gr.Row():\n        with gr.Column():\n            stream_as_file_btn = gr.Button(\"Stream as File\")\n            format = gr.Radio([\"wav\", \"mp3\"], value=\"wav\", label=\"Format\")\n            stream_as_file_output = gr.Audio(streaming=True, elem_id=\"stream_as_file_output\", autoplay=True, visible=False)\n\n            def stream_file(audio_file, format):\n                audio = AudioSegment.from_file(audio_file)\n                i = 0\n                chunk_size = 1000\n                while chunk_size * i < len(audio):\n                    chunk = audio[chunk_size * i : chunk_size * (i + 1)]\n                    i += 1\n                    if chunk:\n                        file = Path(tempfile.gettempdir()) / \"stream_audio_demo\" / f\"{i}.{format}\"\n                        file.parent.mkdir(parents=True, exist_ok=True)\n                        chunk.export(str(file), format=format)\n                        yield file\n                        sleep(0.5)\n\n            stream_as_file_btn.click(\n                stream_file, [input_audio, format], stream_as_file_output\n            )\n\n            gr.Examples(\n                [[os.path.join(os.path.abspath(''), \"audio/cantina.wav\"), \"wav\"],\n                 [os.path.join(os.path.abspath(''), \"audio/cantina.wav\"), \"mp3\"]],\n                [input_audio, format],\n                fn=stream_file,\n                outputs=stream_as_file_output,\n                cache_examples=False,\n            )\n\n        with gr.Column():\n            stream_as_bytes_btn = gr.Button(\"Stream as Bytes\")\n            stream_as_bytes_output = gr.Audio(streaming=True, elem_id=\"stream_as_bytes_output\", autoplay=True)\n\n            def stream_bytes(audio_file):\n                chunk_size = 20_000\n                with open(audio_file, \"rb\") as f:\n                    while True:\n                        chunk = f.read(chunk_size)\n                        if chunk:\n                            yield chunk\n                            sleep(1)\n                        else:\n                            break\n            stream_as_bytes_btn.click(stream_bytes, input_audio, stream_as_bytes_output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Streaming Gemini Thoughts and Responses in Python\nDESCRIPTION: Defines the `stream_gemini_response` function which handles the interaction with the configured Gemini model. It takes the user's message (`user_message`) and the current list of chat messages (`messages`), initiates a streaming request to the Gemini model using `model.generate_content(stream=True)`, and processes the incoming chunks. The function distinguishes between the model's 'thoughts' and final 'responses', updating the chat history list with appropriate `ChatMessage` objects (including metadata for thoughts) and yielding the updated list at each step to enable real-time display in the Gradio UI. Depends on the initialized `model` and `gradio.ChatMessage`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef stream_gemini_response(user_message: str, messages: list) -> Iterator[list]:\n    \"\"\"\n    Streams both thoughts and responses from the Gemini model.\n    \"\"\"\n    # Initialize response from Gemini\n    response = model.generate_content(user_message, stream=True)\n    \n    # Initialize buffers\n    thought_buffer = \"\"\n    response_buffer = \"\"\n    thinking_complete = False\n    \n    # Add initial thinking message\n    messages.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"\",\n            metadata={\"title\": \"⏳Thinking: *The thoughts produced by the Gemini2.0 Flash model are experimental\"}\n        )\n    )\n    \n    for chunk in response:\n        parts = chunk.candidates[0].content.parts\n        current_chunk = parts[0].text\n        \n        if len(parts) == 2 and not thinking_complete:\n            # Complete thought and start response\n            thought_buffer += current_chunk\n            messages[-1] = ChatMessage(\n                role=\"assistant\",\n                content=thought_buffer,\n                metadata={\"title\": \"⏳Thinking: *The thoughts produced by the Gemini2.0 Flash model are experimental\"}\n            )\n            \n            # Add response message\n            messages.append(\n                ChatMessage(\n                    role=\"assistant\",\n                    content=parts[1].text\n                )\n            )\n            thinking_complete = True\n            \n        elif thinking_complete:\n            # Continue streaming response\n            response_buffer += current_chunk\n            messages[-1] = ChatMessage(\n                role=\"assistant\",\n                content=response_buffer\n            )\n            \n        else:\n            # Continue streaming thoughts\n            thought_buffer += current_chunk\n            messages[-1] = ChatMessage(\n                role=\"assistant\",\n                content=thought_buffer,\n                metadata={\"title\": \"⏳Thinking: *The thoughts produced by the Gemini2.0 Flash model are experimental\"}\n            )\n        \n        yield messages\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Random Sliders\nDESCRIPTION: Implements a Gradio interface with multiple slider inputs demonstrating various configurations including randomization, different ranges, and step values. The function takes slider inputs and returns a calculation based on the first two sliders.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_random_slider/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef func(slider_1, slider_2, *args):\n    return slider_1 + slider_2 * 5\n\ndemo = gr.Interface(\n    func,\n    [\n        gr.Slider(minimum=1.5, maximum=250000.89, randomize=True, label=\"Random Big Range\"),\n        gr.Slider(minimum=-1, maximum=1, randomize=True, step=0.05, label=\"Random only multiple of 0.05 allowed\"),\n        gr.Slider(minimum=0, maximum=1, randomize=True, step=0.25, label=\"Random only multiples of 0.25 allowed\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, step=3, label=\"Random between -100 and 100 step 3\"),\n        gr.Slider(minimum=-100, maximum=100, randomize=True, label=\"Random between -100 and 100\"),\n        gr.Slider(value=0.25, minimum=5, maximum=30, step=-1),\n    ],\n    \"number\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Multimodal Chatbot Implementation\nDESCRIPTION: Implements a Gradio chatbot with support for multiple response types including text, images, gallery, video, audio, and HTML. Features include message handling, bot responses, and like/dislike functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components_simple/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n\ncolor_map = {\n    \"harmful\": \"crimson\",\n    \"neutral\": \"gray\",\n    \"beneficial\": \"green\",\n}\n\ndef html_src(harm_level):\n    return f\"\"\"\n<div style=\"display: flex; gap: 5px;\">\n  <div style=\"background-color: {color_map[harm_level]}; padding: 2px; border-radius: 5px;\">\n  {harm_level}\n  </div>\n</div>\n\"\"\"\n\ndef print_like_dislike(x: gr.LikeData):\n    print(x.index, x.value, x.liked)\n\ndef add_message(history, message):\n    for x in message[\"files\"]:\n        history.append(((x,), None))\n    if message[\"text\"] is not None:\n        history.append((message[\"text\"], None))\n    return history, gr.MultimodalTextbox(value=None, interactive=False)\n\ndef bot(history, response_type):\n    if response_type == \"gallery\":\n        history[-1][1] = gr.Gallery(\n            [\n                \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\",\n                \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\",\n            ]\n        )\n    elif response_type == \"image\":\n        history[-1][1] = gr.Image(\n            \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\"\n        )\n    elif response_type == \"video\":\n        history[-1][1] = gr.Video(\n            \"https://github.com/gradio-app/gradio/raw/main/demo/video_component/files/world.mp4\"\n        )\n    elif response_type == \"audio\":\n        history[-1][1] = gr.Audio(\n            \"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\"\n        )\n    elif response_type == \"html\":\n        history[-1][1] = gr.HTML(\n            html_src(random.choice([\"harmful\", \"neutral\", \"beneficial\"]))\n        )\n    else:\n        history[-1][1] = \"Cool!\"\n    return history\n\nwith gr.Blocks(fill_height=True) as demo:\n    chatbot = gr.Chatbot(\n        elem_id=\"chatbot\",\n        bubble_full_width=False,\n        scale=1,\n    )\n    response_type = gr.Radio(\n        [\n            \"image\",\n            \"text\",\n            \"gallery\",\n            \"video\",\n            \"audio\",\n            \"html\",\n        ],\n        value=\"text\",\n        label=\"Response Type\",\n    )\n\n    chat_input = gr.MultimodalTextbox(\n        interactive=True,\n        placeholder=\"Enter message or upload file...\",\n        show_label=False,\n    )\n\n    chat_msg = chat_input.submit(\n        add_message, [chatbot, chat_input], [chatbot, chat_input]\n    )\n    bot_msg = chat_msg.then(\n        bot, [chatbot, response_type], chatbot, api_name=\"bot_response\"\n    )\n    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n\n    chatbot.like(print_like_dislike, None, None)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: FastAPI Backend Implementation\nDESCRIPTION: FastAPI application setup with routes for serving the web interface and handling video uploads\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom fastapi import FastAPI, File, UploadFile, Request\nfrom fastapi.responses import HTMLResponse, RedirectResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\n\napp = FastAPI()\nos.makedirs(\"static\", exist_ok=True)\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\nvideos = []\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def home(request: Request):\n    return templates.TemplateResponse(\n        \"home.html\", {\"request\": request, \"videos\": videos})\n\n@app.post(\"/uploadvideo/\")\nasync def upload_video(video: UploadFile = File(...)):\n    video_path = video.filename\n    with open(video_path, \"wb+\") as fp:\n        fp.write(video.file.read())\n\n    new_video = process_video(video.filename)\n    videos.append(new_video)\n    return RedirectResponse(url='/', status_code=303)\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio ParamViewer Component - Python\nDESCRIPTION: Creates a web interface using Gradio Blocks, displaying Markdown for the round() function and a ParamViewer component describing its parameters. Requires the gradio package, and defines two function parameters (number and ndigits) with their types, descriptions, and defaults. By running the script, an interactive Gradio demo is launched with all UI elements as described; expected input is launching from the main entry point.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/paramviewer_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"The `round()` function in Python takes two parameters\")\n    gr.ParamViewer(\n        {\n           \"number\": {\n             \"type\": \"int | float\",\n             \"description\": \"The number to round\",\n             \"default\": None\n            },\n            \"ndigits\": {\n             \"type\": \"int\",\n             \"description\": \"The number of digits to round to\",\n             \"default\": \"0\"\n            }\n         }\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Loading MobileNetV2 Model using TensorFlow/Keras (Python)\nDESCRIPTION: This snippet imports the TensorFlow library and loads the pre-trained MobileNetV2 image classification model using `tf.keras.applications.MobileNetV2()`. This automatically downloads the model architecture and weights if they are not already present.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-tensorflow.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport tensorflow as tf\n\ninception_net = tf.keras.applications.MobileNetV2()\n```\n\n----------------------------------------\n\nTITLE: Creating Synchronized Interactive Plots with Gradio\nDESCRIPTION: Builds a Gradio interface with two synchronized plots (line plot and bar plot) that share zoom functionality. When a region is selected in one plot, both plots zoom to the same x-axis range. Double-clicking resets the zoom on all plots.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom_sync/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    plt1 = gr.LinePlot(df, x=\"weight\", y=\"height\")\n    plt2 = gr.BarPlot(df, x=\"weight\", y=\"age\", x_bin=10)\n    plots = [plt1, plt2]\n\n    def select_region(selection: gr.SelectData):\n        min_w, max_w = selection.index\n        return [gr.LinePlot(x_lim=(min_w, max_w))] * len(plots) # type: ignore\n\n    for plt in plots:\n        plt.select(select_region, None, plots)\n        plt.double_click(lambda: [gr.LinePlot(x_lim=None)] * len(plots), None, plots)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Mixer with Gradio Blocks\nDESCRIPTION: Creates a dynamic audio mixing interface using Gradio Blocks. The application allows users to add multiple audio tracks, adjust volume for each track, and merge them into a single output. It features dynamic UI rendering based on the number of tracks and handles audio merging with proper volume adjustments.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_mixer/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    track_count = gr.State(1)\n    add_track_btn = gr.Button(\"Add Track\")\n\n    add_track_btn.click(lambda count: count + 1, track_count, track_count)\n\n    @gr.render(inputs=track_count)\n    def render_tracks(count):\n        audios = []\n        volumes = []\n        with gr.Row():\n            for i in range(count):\n                with gr.Column(variant=\"panel\", min_width=200):\n                    gr.Textbox(placeholder=\"Track Name\", key=f\"name-{i}\", show_label=False)\n                    track_audio = gr.Audio(label=f\"Track {i}\", key=f\"track-{i}\")\n                    track_volume = gr.Slider(0, 100, value=100, label=\"Volume\", key=f\"volume-{i}\")\n                    audios.append(track_audio)\n                    volumes.append(track_volume)\n\n            def merge(data):\n                sr, output = None, None\n                for audio, volume in zip(audios, volumes):\n                    sr, audio_val = data[audio]\n                    volume_val = data[volume]\n                    final_track = audio_val * (volume_val / 100)\n                    if output is None:\n                        output = final_track\n                    else:\n                        min_shape = tuple(min(s1, s2) for s1, s2 in zip(output.shape, final_track.shape))\n                        trimmed_output = output[:min_shape[0], ...][:, :min_shape[1], ...] if output.ndim > 1 else output[:min_shape[0]]\n                        trimmed_final = final_track[:min_shape[0], ...][:, :min_shape[1], ...] if final_track.ndim > 1 else final_track[:min_shape[0]]\n                        output += trimmed_output + trimmed_final\n                return (sr, output)\n\n            merge_btn.click(merge, set(audios + volumes), output_audio)\n\n    merge_btn = gr.Button(\"Merge Tracks\")\n    output_audio = gr.Audio(label=\"Output\", interactive=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Tabbed Gradio Interface for Image Classification in Python\nDESCRIPTION: This script demonstrates loading a pre-trained image classifier (`google/vit-base-patch16-224`) using `gr.load` and integrating it into a Gradio UI. It defines paths for local example images, loads the model specifying these examples, creates a custom function `func` that uses the classifier alongside text input, builds an interface (`using_img_classifier_as_function`) around this custom function, and finally launches a `gr.TabbedInterface` combining the custom interface and the directly loaded model interface. Requires Gradio, pathlib, and the previously downloaded image files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_interface_load/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pathlib\n\ncurrent_dir = pathlib.Path(__file__).parent\n\nimages = [str(current_dir / \"cheetah1.jpeg\"), str(current_dir / \"cheetah1.jpg\"), str(current_dir / \"lion.jpg\")]\n\nimg_classifier = gr.load(\n    \"models/google/vit-base-patch16-224\", examples=images, cache_examples=False\n)\n\ndef func(img, text):\n    return img_classifier(img), text\n\nusing_img_classifier_as_function = gr.Interface(\n    func,\n    [gr.Image(type=\"filepath\"), \"text\"],\n    [\"label\", \"text\"],\n    examples=[\n        [str(current_dir / \"cheetah1.jpeg\"), None],\n        [str(current_dir / \"cheetah1.jpg\"), \"cheetah\"],\n        [str(current_dir / \"lion.jpg\"), \"lion\"],\n    ],\n    cache_examples=False,\n)\ndemo = gr.TabbedInterface([using_img_classifier_as_function, img_classifier])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Interactive SQLite Query Visualization with Filters\nDESCRIPTION: Shows how to create an interactive visualization with a dropdown filter that modifies the SQL query dynamically. Combines Gradio UI elements with database queries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/04_connecting-to-a-database.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom sqlalchemy import create_engine\nimport pandas as pd\n\nengine = create_engine('sqlite:///your_database.db')\n\nwith gr.Blocks() as demo:\n    origin = gr.Dropdown([\"DFW\", \"DAL\", \"HOU\"], value=\"DFW\", label=\"Origin\")\n\n    gr.LinePlot(lambda origin: pd.read_sql_query(f\"SELECT time, price from flight_info WHERE origin = {origin};\", engine), inputs=origin, x=\"time\", y=\"price\")\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Bokeh Visualizations with Gradio Interface\nDESCRIPTION: Implements a Gradio interface to display different types of Bokeh plots (map, whisker, and scatter). The code defines a function to generate different plots based on user selection and creates a simple UI with radio buttons to switch between visualization types.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bokeh_plot/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# type: ignore\nimport gradio as gr\nimport xyzservices.providers as xyz\nfrom bokeh.models import ColumnDataSource, Whisker\nfrom bokeh.plotting import figure\nfrom bokeh.sampledata.autompg2 import autompg2 as df\nfrom bokeh.sampledata.penguins import data\nfrom bokeh.transform import factor_cmap, jitter, factor_mark\n\ndef get_plot(plot_type):\n    if plot_type == \"map\":\n        plot = figure(\n            x_range=(-2000000, 6000000),\n            y_range=(-1000000, 7000000),\n            x_axis_type=\"mercator\",\n            y_axis_type=\"mercator\",\n        )\n        plot.add_tile(xyz.OpenStreetMap.Mapnik)  # type: ignore\n        return plot\n    elif plot_type == \"whisker\":\n        classes = sorted(df[\"class\"].unique())\n\n        p = figure(\n            height=400,\n            x_range=classes,\n            background_fill_color=\"#efefef\",\n            title=\"Car class vs HWY mpg with quintile ranges\",\n        )\n        p.xgrid.grid_line_color = None\n\n        g = df.groupby(\"class\")\n        upper = g.hwy.quantile(0.80)\n        lower = g.hwy.quantile(0.20)\n        source = ColumnDataSource(data=dict(base=classes, upper=upper, lower=lower))\n\n        error = Whisker(\n            base=\"base\",\n            upper=\"upper\",\n            lower=\"lower\",\n            source=source,\n            level=\"annotation\",\n            line_width=2,\n        )\n        error.upper_head.size = 20\n        error.lower_head.size = 20\n        p.add_layout(error)\n\n        p.circle(\n            jitter(\"class\", 0.3, range=p.x_range),\n            \"hwy\",\n            source=df,\n            alpha=0.5,\n            size=13,\n            line_color=\"white\",\n            color=factor_cmap(\"class\", \"Light6\", classes),\n        )\n        return p\n    elif plot_type == \"scatter\":\n\n        SPECIES = sorted(data.species.unique())\n        MARKERS = [\"hex\", \"circle_x\", \"triangle\"]\n\n        p = figure(title=\"Penguin size\", background_fill_color=\"#fafafa\")\n        p.xaxis.axis_label = \"Flipper Length (mm)\"\n        p.yaxis.axis_label = \"Body Mass (g)\"\n\n        p.scatter(\n            \"flipper_length_mm\",\n            \"body_mass_g\",\n            source=data,\n            legend_group=\"species\",\n            fill_alpha=0.4,\n            size=12,\n            marker=factor_mark(\"species\", MARKERS, SPECIES),\n            color=factor_cmap(\"species\", \"Category10_3\", SPECIES),\n        )\n\n        p.legend.location = \"top_left\"\n        p.legend.title = \"Species\"\n        return p\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        plot_type = gr.Radio(value=\"scatter\", choices=[\"scatter\", \"whisker\", \"map\"])\n        plot = gr.Plot()\n    plot_type.change(get_plot, inputs=[plot_type], outputs=[plot])\n    demo.load(get_plot, inputs=[plot_type], outputs=[plot])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing ChatInterface with Nested Thoughts in Python using Gradio\nDESCRIPTION: This snippet defines a function to generate responses with nested thoughts, simulating a weather-checking process. It uses Gradio's ChatInterface and ChatMessage classes to create a structured chat bot that displays its thinking process, including API calls and error handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_nested_thoughts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\nsleep_time = 0.1\nlong_sleep_time = 1\n\ndef generate_response(message, history):\n    start_time = time.time()\n    responses = [\n        ChatMessage(\n            content=\"In order to find the current weather in San Francisco, I will need to use my weather tool.\",\n        )\n    ]\n    yield responses\n    time.sleep(sleep_time)\n\n    main_thought = ChatMessage(\n            content=\"\",\n            metadata={\"title\": \"Using Weather Tool\", \"id\": 1, \"status\": \"pending\"},\n        )\n\n    responses.append(main_thought)\n\n    yield responses\n    time.sleep(long_sleep_time)\n    responses[-1].content = \"Will check: weather.com and sunny.org\"\n    yield responses\n    time.sleep(sleep_time)\n    responses.append(\n        ChatMessage(\n            content=\"Received weather from weather.com.\",\n            metadata={\"title\": \"Checking weather.com\", \"parent_id\": 1, \"id\": 2, \"duration\": 0.05},\n        )\n    )\n    yield responses\n\n    sunny_start_time = time.time()\n    time.sleep(sleep_time)\n    sunny_thought = ChatMessage(\n            content=\"API Error when connecting to sunny.org 💥\",\n            metadata={\"title\": \"Checking sunny.org\", \"parent_id\": 1, \"id\": 3, \"status\": \"pending\"},\n        )\n\n    responses.append(sunny_thought)\n    yield responses\n\n    time.sleep(sleep_time)\n    responses.append(\n        ChatMessage(\n            content=\"Failed again\",\n            metadata={\"title\": \"I will try again\", \"id\": 4, \"parent_id\": 3, \"duration\": 0.1},\n\n        )\n    )\n    sunny_thought.metadata[\"status\"] = \"done\"\n    sunny_thought.metadata[\"duration\"] = time.time() - sunny_start_time\n\n    main_thought.metadata[\"status\"] = \"done\"\n    main_thought.metadata[\"duration\"] = time.time() - start_time\n\n    yield responses\n\n    time.sleep(long_sleep_time)\n\n    responses.append(\n        ChatMessage(\n            content=\"Based on the data only from weather.com, the current weather in San Francisco is 60 degrees and sunny.\",\n        )\n    )\n    yield responses\n\ndemo = gr.ChatInterface(\n    generate_response,\n    type=\"messages\",\n    title=\"Nested Thoughts Chat Interface\",\n    examples=[\"What is the weather in San Francisco right now?\"]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom StableDiffusion Tool\nDESCRIPTION: Example implementation of a custom Gradio tool for Stable Diffusion. Shows how to implement the required methods including create_job and postprocess.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/04_gradio-and-llm-agents.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_tool import GradioTool\nimport os\n\nclass StableDiffusionTool(GradioTool):\n    \"\"\"Tool for calling stable diffusion from llm\"\"\"\n\n    def __init__(\n        self,\n        name=\"StableDiffusion\",\n        description=(\n            \"An image generator. Use this to generate images based on \"\n            \"text input. Input should be a description of what the image should \"\n            \"look like. The output will be a path to an image file.\"\n        ),\n        src=\"gradio-client-demos/stable-diffusion\",\n        hf_token=None,\n    ) -> None:\n        super().__init__(name, description, src, hf_token)\n\n    def create_job(self, query: str) -> Job:\n        return self.client.submit(query, \"\", 9, fn_index=1)\n\n    def postprocess(self, output: str) -> str:\n        return [os.path.join(output, i) for i in os.listdir(output) if not i.endswith(\"json\")][0]\n\n    def _block_input(self, gr) -> \"gr.components.Component\":\n        return gr.Textbox()\n\n    def _block_output(self, gr) -> \"gr.components.Component\":\n        return gr.Image()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Upload Button with 'upload' Event Trigger in Python\nDESCRIPTION: This code snippet demonstrates how to create a Gradio interface with an upload button that triggers an action upon file upload. It defines a function to handle the uploaded file and sets up the interface with the upload button component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_button/DESCRIPTION.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef handle_upload(file):\n    return f\"Uploaded {file.name}\"\n\ndemo = gr.Interface(\n    fn=handle_upload,\n    inputs=gr.File(label=\"Upload a file\"),\n    outputs=\"text\",\n    title=\"Upload Button Demo\",\n    description=\"Upload a file to see its name.\"\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multimodal Chatbot with Gradio in Python\nDESCRIPTION: This extensive code snippet implements a multimodal chatbot using Gradio. It includes functions for handling messages, examples, and responses, as well as setting up the Gradio interface with a chatbot, input box, and example messages. The chatbot supports text, audio, and image inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_examples/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n# Multimodal Chatbot demo that shows support for examples (example messages shown within the chatbot).\n\ndef print_like_dislike(x: gr.LikeData):\n    print(x.index, x.value, x.liked)\n\ndef add_message(history, message):\n    for x in message[\"files\"]:\n        history.append(((x,), None))\n    if message[\"text\"] is not None:\n        history.append((message[\"text\"], None))\n    return history, gr.MultimodalTextbox(value=None, interactive=False)\n\ndef append_example_message(x: gr.SelectData, history):\n    if x.value[\"text\"] is not None:\n        history.append((x.value[\"text\"], None))\n    if \"files\" in x.value:\n        if isinstance(x.value[\"files\"], list):\n            for file in x.value[\"files\"]:\n                history.append((file, None))\n        else:\n            history.append((x.value[\"files\"], None))\n    return history\n\ndef respond(history):\n    history[-1][1] = \"Cool!\"\n    return history\n\nwith gr.Blocks(fill_height=True) as demo:\n    chatbot = gr.Chatbot(\n        elem_id=\"chatbot\",\n        bubble_full_width=False,\n        scale=1,\n        placeholder='<h1 style=\"font-weight: bold; color: #FFFFFF; text-align: center; font-size: 48px; font-family: Arial, sans-serif;\">Welcome to Gradio!</h1>',\n        examples=[{\"icon\": os.path.join(os.path.abspath(''), \"files/avatar.png\"), \"display_text\": \"Display Text Here!\", \"text\": \"Try this example with this audio.\", \"files\": [os.path.join(os.path.abspath(''), \"files/cantina.wav\")]},\n                     {\"text\": \"Try this example with this image.\", \"files\": [os.path.join(os.path.abspath(''), \"files/avatar.png\")]},\n                     {\"text\": \"This is just text, no files!\"},\n                     {\"text\": \"Try this example with this image.\", \"files\": [os.path.join(os.path.abspath(''), \"files/avatar.png\"), os.path.join(os.path.abspath(''), \"files/avatar.png\")]},\n                     {\"text\": \"Try this example with this Audio.\", \"files\": [os.path.join(os.path.abspath(''), \"files/cantina.wav\")]}]\n    )\n\n    chat_input = gr.MultimodalTextbox(interactive=True,\n                                      file_count=\"multiple\",\n                                      placeholder=\"Enter message or upload file...\", show_label=False)\n\n    chat_msg = chat_input.submit(add_message, [chatbot, chat_input], [chatbot, chat_input])\n    bot_msg = chat_msg.then(respond, chatbot, chatbot, api_name=\"bot_response\")\n    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n\n    chatbot.like(print_like_dislike, None, None)\n    chatbot.example_select(append_example_message, [chatbot], [chatbot]).then(respond, chatbot, chatbot, api_name=\"respond\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Synchronizing X-Axes Across Multiple Gradio Plots in Python\nDESCRIPTION: Demonstrates how to use event listeners (like `.select()` or `.double_click()`) on one plot to update the `x_lim` property of multiple other plots. This ensures that the x-axes of different plots stay synchronized when zooming or panning. Requires gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_zoom_sync\n```\n\n----------------------------------------\n\nTITLE: Creating a Hello World Blocks Interface in Gradio\nDESCRIPTION: Creates a Gradio Blocks interface with a welcome function that takes a name input and returns a personalized greeting. The interface includes markdown text, an input textbox, and an output textbox with a change event handler.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_hello/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    # Hello World!\n    Start typing below to see the output.\n    \"\"\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Downloading Helper Functions for Gradio Dashboard\nDESCRIPTION: This snippet downloads a helper Python file containing functions for retrieving data from HuggingFace Hub datasets.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/dashboard/helpers.py\n```\n\n----------------------------------------\n\nTITLE: Building an Event-Driven Gradio UI with Blocks in Python\nDESCRIPTION: This code defines a Gradio interface using the Blocks API, featuring textboxes for user input and output, a button, and event-based behavior. The greet function handles input from both a textbox submission and a button click, using event data to customize outputs. A secondary function clears the name field after greeting. Dependencies include the Gradio Python package; expects string input for a name and outputs a greeting and information on the triggered UI component. To run, save as a Python script and execute with Gradio installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_basic/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    trigger = gr.Textbox(label=\"Trigger Box\")\n\n    def greet(name, evt_data: gr.EventData):\n        return \"Hello \" + name + \"!\", evt_data.target.__class__.__name__\n\n    def clear_name(evt_data: gr.EventData):\n        return \"\"\n\n    gr.on(\n        triggers=[name.submit, greet_btn.click],\n        fn=greet,\n        inputs=name,\n        outputs=[output, trigger],\n    ).then(clear_name, outputs=[name])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Reading Public Google Sheet Data with Pandas - Python\nDESCRIPTION: This Python snippet shows how to directly access a public Google Sheet CSV export using pandas. It modifies the shareable sheet URL to request CSV format, then defines a function to fetch and return the sheet as a DataFrame. Requires the 'pandas' library and a public Google Sheet. The key parameter is the URL; the output is a pandas DataFrame representing the sheet data. The pattern relies on Google Sheets' public CSV export feature and will not work for private sheets.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\n\nURL = \"https://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\"\ncsv_url = URL.replace('/edit#gid=', '/export?format=csv&gid=')\n\ndef get_data():\n    return pd.read_csv(csv_url)\n```\n\n----------------------------------------\n\nTITLE: To-Do List Application using Gradio Render Decorator\nDESCRIPTION: This snippet demonstrates a complete to-do list application using the @gr.render decorator. It allows adding tasks, marking them as done, and deleting them, showcasing complex interactions and state management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/04_dynamic-apps-with-render-decorator.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    tasks = gr.State([])\n    with gr.Row():\n        task_input = gr.Textbox(placeholder=\"Enter a task...\")\n        add_btn = gr.Button(\"Add\")\n    task_list = gr.Row()\n\n    def add_task(task, task_list):\n        task_list.append([task, False])\n        return task_list, \"\"\n\n    add_btn.click(add_task, [task_input, tasks], [tasks, task_input])\n\n    @gr.render()\n    def render_list(task_list):\n        if not task_list:\n            return gr.Markdown(\"No tasks yet!\")\n        \n        task_boxes = []\n        for i, (task, done) in enumerate(task_list):\n            with gr.Row() as task_box:\n                gr.Markdown(\"✓\" if done else \"☐\", scale=1)\n                gr.Markdown(task, scale=10, elem_classes=[\"done\"] if done else [])\n                done_btn = gr.Button(\"Done\" if not done else \"Undo\")\n                delete_btn = gr.Button(\"Delete\")\n            task_boxes.append(task_box)\n\n            def mark_done(task_list, i=i, task=task):\n                task_list[i][1] = not task_list[i][1]\n                return task_list\n\n            def delete(task_list, i=i):\n                del task_list[i]\n                return task_list\n\n            done_btn.click(mark_done, tasks, tasks)\n            delete_btn.click(delete, tasks, tasks)\n\n        return task_boxes\n\n    tasks.change(render_list, tasks, task_list)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Using Decorators for Gradio Event Listeners in Python\nDESCRIPTION: Illustrates an alternative way to define event listeners in Gradio Blocks using Python decorators (`@greet_btn.click(...)`). This syntax directly associates the function (`greet`) with the event trigger (`greet_btn.click`), inputs (`name`), and outputs (`output`), eliminating the need for the `fn` argument in the listener call.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n$code_hello_blocks_decorator\n```\n\n----------------------------------------\n\nTITLE: Using the new ImageEditor component in Python\nDESCRIPTION: This snippet demonstrates how to use the new ImageEditor component in Gradio. It shows how to configure the component with custom sources, crop settings, transforms, and brush options. The function also explains how to access different parts of the edited image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/icons/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Creating a Sentiment Analysis Web App using Gradio and NLTK in Python\nDESCRIPTION: This snippet imports Gradio and NLTK, downloads the necessary VADER lexicon, and uses the SentimentIntensityAnalyzer to compute sentiment scores for input text. The sentiment_analysis function returns polarity scores (positive, negative, neutral), and a Gradio Interface is configured to accept text and display the sentiment label. Inputs require a string (user sentence), and outputs are labels, with an example provided. This code creates and launches a web app for real-time sentiment analysis and depends on 'gradio' and 'nltk' being installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sentiment_analysis/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nnltk.download(\"vader_lexicon\")\nsid = SentimentIntensityAnalyzer()\n\ndef sentiment_analysis(text):\n    scores = sid.polarity_scores(text)\n    del scores[\"compound\"]\n    return scores\n\ndemo = gr.Interface(\n    fn=sentiment_analysis,\n    inputs=gr.Textbox(placeholder=\"Enter a positive or negative sentence here...\"),\n    outputs=\"label\",\n    examples=[[\"This is wonderful!\"]])\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming ASR with Gradio and Transformers (Python)\nDESCRIPTION: This Python script sets up and runs a Gradio interface for real-time speech recognition. It imports necessary libraries, initializes a Hugging Face Transformers ASR pipeline using the 'openai/whisper-base.en' model. The `transcribe` function takes the current audio stream state and a new audio chunk, converts the chunk to mono if necessary, normalizes it, appends it to the stream, and then uses the pipeline to transcribe the entire accumulated stream. The Gradio `Interface` is configured to take streaming audio input from the microphone (`gr.Audio(sources=[\"microphone\"], streaming=True)`) and updates the state and a text output box live. The script launches the Gradio demo when run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_asr/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\nimport numpy as np\n\ntranscriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n\ndef transcribe(stream, new_chunk):\n    sr, y = new_chunk\n    \n    # Convert to mono if stereo\n    if y.ndim > 1:\n        y = y.mean(axis=1)\n        \n    y = y.astype(np.float32)\n    y /= np.max(np.abs(y))\n\n    if stream is not None:\n        stream = np.concatenate([stream, y])\n    else:\n        stream = y\n    return stream, transcriber({\"sampling_rate\": sr, \"raw\": stream})[\"text\"]  # type: ignore\n\ndemo = gr.Interface(\n    transcribe,\n    [\"state\", gr.Audio(sources=[\"microphone\"], streaming=True)],\n    [\"state\", \"text\"],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Multiple Inputs\nDESCRIPTION: Implements a Gradio interface with a text input, slider, and image input that simulates an image generation function. The interface returns both text output and a dummy image URL. The function accepts a prompt, seed value, and optional initial image as inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_with_additional_inputs/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef generate_fake_image(prompt, seed, initial_image=None):\n    return f\"Used seed: {seed}\", \"https://dummyimage.com/300/09f.png\"\n\ndemo = gr.Interface(\n    generate_fake_image,\n    inputs=[\"textbox\"],\n    outputs=[\"textbox\", \"image\"],\n    additional_inputs=[\n        gr.Slider(0, 1000),\n        \"image\"\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Querying BigQuery and Processing Results with Pandas in Python\nDESCRIPTION: Defines a Python function `run_query` that executes a predefined SQL query against a public BigQuery COVID-19 dataset. The function fetches the top 20 counties by confirmed cases for the latest date, converts the result to a pandas DataFrame, selects relevant columns (`confirmed_cases`, `deaths`, `county`, `state_name`), and ensures numeric columns are cast to standard numpy integer types. This function requires an authenticated `client` object and the `numpy` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_3\n\nLANGUAGE: py\nCODE:\n```\nimport numpy as np\n\nQUERY = (\n    'SELECT * FROM `bigquery-public-data.covid19_nyt.us_counties` '\n    'ORDER BY date DESC,confirmed_cases DESC '\n    'LIMIT 20')\n\ndef run_query():\n    query_job = client.query(QUERY)\n    query_result = query_job.result()\n    df = query_result.to_dataframe()\n    # Select a subset of columns\n    df = df[[\"confirmed_cases\", \"deaths\", \"county\", \"state_name\"]]\n    # Convert numeric columns to standard numpy types\n    df = df.astype({\"deaths\": np.int64, \"confirmed_cases\": np.int64})\n    return df\n```\n\n----------------------------------------\n\nTITLE: Implementing PyPi Download Stats and Prophet Forecasting in Gradio\nDESCRIPTION: This code creates a Gradio interface for displaying PyPi download statistics and forecasts. It fetches data using pypistats, processes it with pandas, and uses Prophet for forecasting. The interface allows users to select a library and time range, updating the chart dynamically.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timeseries-forecasting-with-prophet/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pypistats\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\nimport pandas as pd\nfrom prophet import Prophet\npd.options.plotting.backend = \"plotly\"\n\ndef get_forecast(lib, time):\n\n    data = pypistats.overall(lib, total=True, format=\"pandas\")\n    data = data.groupby(\"category\").get_group(\"with_mirrors\").sort_values(\"date\")\n    start_date = date.today() - relativedelta(months=int(time.split(\" \")[0]))\n    df = data[(data['date'] > str(start_date))]\n\n    df1 = df[['date','downloads']]\n    df1.columns = ['ds','y']\n\n    m = Prophet()\n    m.fit(df1)\n    future = m.make_future_dataframe(periods=90)\n    forecast = m.predict(future)\n    fig1 = m.plot(forecast)\n    return fig1\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    \"\"\"\n    **Pypi Download Stats 📈 with Prophet Forecasting**: see live download stats for popular open-source libraries 🤗 along with a 3 month forecast using Prophet. The [ source code for this Gradio demo is here](https://huggingface.co/spaces/gradio/timeseries-forecasting-with-prophet/blob/main/app.py).\n    \"\"\")\n    with gr.Row():\n        lib = gr.Dropdown([\"pandas\", \"scikit-learn\", \"torch\", \"prophet\"], label=\"Library\", value=\"pandas\")\n        time = gr.Dropdown([\"3 months\", \"6 months\", \"9 months\", \"12 months\"], label=\"Downloads over the last...\", value=\"12 months\")\n\n    plt = gr.Plot()\n\n    lib.change(get_forecast, [lib, time], plt, queue=False)\n    time.change(get_forecast, [lib, time], plt, queue=False)\n    demo.load(get_forecast, [lib, time], plt, queue=False)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Returning Files and Gradio Components in ChatInterface - Gradio (Python)\nDESCRIPTION: This example implements a chat function that returns either a Gradio Audio component or a string message based on user input, showcasing how to provide multimedia responses in a chat context. The function 'music' takes message text and history, returning a Gradio Audio component if the input is non-empty, or a prompt message otherwise. The ChatInterface uses a custom textbox placeholder to guide user queries. Key dependency is Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef music(message, history):\n    if message.strip():\n        return gr.Audio(\"https://github.com/gradio-app/gradio/raw/main/test/test_files/audio_sample.wav\")\n    else:\n        return \"Please provide the name of an artist\"\n\ngr.ChatInterface(\n    music,\n    type=\"messages\",\n    textbox=gr.Textbox(placeholder=\"Which artist's music do you want to listen to?\", scale=7),\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Gradio Interface Demo\nDESCRIPTION: Python code that creates a simple web interface for a greeting function, demonstrating how to use the gr.Interface class with text input, slider input, and text output components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello, \" + name + \"!\" * int(intensity)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Formatting Messages and Encoding Documents for Claude Citations - Python\nDESCRIPTION: Contains functions for converting uploaded PDFs to base64 and formatting the Gradio chat history into the Anthropic message structure, supporting both plain text and PDF documents. Dependencies include base64 for encoding, and relies on Anthropic API message format conventions. Inputs include chat history, citation enablement, document type, content, and file objects; outputs are lists ready for Claude API calls. Properly prepares messages to include document attachments for citation-enabled queries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ndef encode_pdf_to_base64(file_obj) -> str:\\n    \\\"\\\"\\\"Convert uploaded PDF file to base64 string.\\\"\\\"\\\"\\n    if file_obj is None:\\n        return None\\n    with open(file_obj.name, 'rb') as f:\\n        return base64.b64encode(f.read()).decode('utf-8')\\n\\ndef format_message_history(\\n    history: list, \\n    enable_citations: bool,\\n    doc_type: str,\\n    text_input: str,\\n    pdf_file: str\\n) -> List[Dict]:\\n    \\\"\\\"\\\"Convert Gradio chat history to Anthropic message format.\\\"\\\"\\\"\\n    formatted_messages = []\\n    \\n    # Add previous messages\\n    for msg in history[:-1]:\\n        if msg[\\\"role\\\"] == \\\"user\\\":\\n            formatted_messages.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": msg[\\\"content\\\"]})\\n    \\n    # Prepare the latest message with document\\n    latest_message = {\\\"role\\\": \\\"user\\\", \\\"content\\\": []}\\n    \\n    if enable_citations:\\n        if doc_type == \\\"plain_text\\\":\\n            latest_message[\\\"content\\\"].append({\\n                \\\"type\\\": \\\"document\\\",\\n                \\\"source\\\": {\\n                    \\\"type\\\": \\\"text\\\",\\n                    \\\"media_type\\\": \\\"text/plain\\\",\\n                    \\\"data\\\": text_input.strip()\\n                },\\n                \\\"title\\\": \\\"Text Document\\\",\\n                \\\"citations\\\": {\\\"enabled\\\": True}\\n            })\\n        elif doc_type == \\\"pdf\\\" and pdf_file:\\n            pdf_data = encode_pdf_to_base64(pdf_file)\\n            if pdf_data:\\n                latest_message[\\\"content\\\"].append({\\n                    \\\"type\\\": \\\"document\\\",\\n                    \\\"source\\\": {\\n                        \\\"type\\\": \\\"base64\\\",\\n                        \\\"media_type\\\": \\\"application/pdf\\\",\\n                        \\\"data\\\": pdf_data\\n                    },\\n                    \\\"title\\\": pdf_file.name,\\n                    \\\"citations\\\": {\\\"enabled\\\": True}\\n                })\\n    \\n    # Add the user's question\\n    latest_message[\\\"content\\\"].append({\\\"type\\\": \\\"text\\\", \\\"text\\\": history[-1][\\\"content\\\"]})\\n    \\n    formatted_messages.append(latest_message)\\n    return formatted_messages\n```\n\n----------------------------------------\n\nTITLE: Video Processing Function Implementation\nDESCRIPTION: Function to process video files by extracting audio, removing music, and recombining with the original video\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport subprocess\n\ndef process_video(video_path):\n    old_audio = os.path.basename(video_path).split(\".\")[0] + \".m4a\"\n    subprocess.run(['ffmpeg', '-y', '-i', video_path, '-vn', '-acodec', 'copy', old_audio])\n\n    new_audio = acapellify(old_audio)\n\n    new_video = f\"acap_{video_path}\"\n    subprocess.call(['ffmpeg', '-y', '-i', video_path, '-i', new_audio, '-map', '0:v', '-map', '1:a', '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental', f\"static/{new_video}\"])\n    return new_video\n```\n\n----------------------------------------\n\nTITLE: Basic Audio Transcription with Gradio Client\nDESCRIPTION: Example showing how to transcribe an audio file using the Gradio client by connecting to a Whisper model Space and processing the audio file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client, handle_file } from \"@gradio/client\";\n\nconst response = await fetch(\n\t\"https://github.com/audio-samples/audio-samples.github.io/raw/master/samples/wav/ted_speakers/SalmanKhan/sample-1.wav\"\n);\nconst audio_file = await response.blob();\n\nconst app = await Client.connect(\"abidlabs/whisper\");\nconst transcription = await app.predict(\"/predict\", [handle_file(audio_file)]);\n\nconsole.log(transcription.data);\n// [ \"I said the same phrase 30 times.\" ]\n```\n\n----------------------------------------\n\nTITLE: Implementing File Zipping Function and Gradio Interface in Python\nDESCRIPTION: This code defines a Python function `zip_files` that takes a list of file objects (uploaded via Gradio), creates a zip archive named \"tmp.zip\", adds each file to the archive using its base name, and returns the path to the created zip file. It then uses the `gradio` library to create a web interface (`gr.Interface`) that uses this `zip_files` function. The interface accepts multiple files (text, JSON, CSV), provides an example using the downloaded `titanic.csv`, enables example caching, and launches the demo server if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/zip_files/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\ndef zip_files(files):\n    with ZipFile(\"tmp.zip\", \"w\") as zipObj:\n        for idx, file in enumerate(files):\n            zipObj.write(file.name, file.name.split(\"/\")[-1])\n    return \"tmp.zip\"\n\ndemo = gr.Interface(\n    zip_files,\n    gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"]),\n    \"file\",\n    examples=[[[os.path.join(os.path.abspath(''),\"files/titanic.csv\"),\n    os.path.join(os.path.abspath(''),\"files/titanic.csv\"),\n    os.path.join(os.path.abspath(''),\"files/titanic.csv\")]]],\n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating DALL·E mini Simulation with Gradio\nDESCRIPTION: This snippet creates a Gradio interface that simulates DALL·E mini functionality. It includes a text input for prompts, a button to generate images, and a gallery to display results. The actual image generation is simulated by returning multiple copies of a cheetah image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_joined/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom time import sleep\nimport gradio as gr\nimport os\n\ncheetah = os.path.join(os.path.abspath(''), \"files/cheetah1.jpg\")\n\ndef img(text):\n    sleep(3)\n    return [\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n        cheetah,\n    ]\n\nwith gr.Blocks(css=\".container { max-width: 800px; margin: auto; }\") as demo:\n    gr.Markdown(\"<h1><center>DALL·E mini</center></h1>\")\n    gr.Markdown(\n        \"DALL·E mini is an AI model that generates images from any prompt you give!\"\n    )\n    with gr.Group():\n        with gr.Row(equal_height=True):\n            text = gr.Textbox(\n                label=\"Enter your prompt\",\n                max_lines=1,\n                container=False,\n            )\n            btn = gr.Button(\"Run\", scale=0)\n        gallery = gr.Gallery(\n            label=\"Generated images\",\n            show_label=False,\n            columns=(1, 3),\n            height=\"auto\",\n        )\n    btn.click(img, inputs=text, outputs=gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n# margin = (TOP, RIGHT, BOTTOM, LEFT)\n# rounded = (TOPLEFT, TOPRIGHT, BOTTOMRIGHT, BOTTOMLEFT)\n```\n\n----------------------------------------\n\nTITLE: Langchain Agent UI Implementation\nDESCRIPTION: Creation of the Gradio interface for the Langchain agent with async streaming and thought display.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync def interact_with_langchain_agent(prompt, messages):\n    messages.append(ChatMessage(role=\"user\", content=prompt))\n    yield messages\n    async for chunk in agent_executor.astream(\n        {\"input\": prompt}\n    ):\n        if \"steps\" in chunk:\n            for step in chunk[\"steps\"]:\n                messages.append(ChatMessage(role=\"assistant\", content=step.action.log,\n                                  metadata={\"title\": f\"🛠️ Used tool {step.action.tool}\"}))\n                yield messages\n        if \"output\" in chunk:\n            messages.append(ChatMessage(role=\"assistant\", content=chunk[\"output\"]))\n            yield messages\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Chat with a LangChain Agent 🦜⛓️ and see its thoughts 💭\")\n    chatbot = gr.Chatbot(\n        type=\"messages\",\n        label=\"Agent\",\n        avatar_images=(\n            None,\n            \"https://em-content.zobj.net/source/twitter/141/parrot_1f99c.png\",\n        ),\n    )\n    input = gr.Textbox(lines=1, label=\"Chat Message\")\n    input.submit(interact_with_langchain_agent, [input_2, chatbot_2], [chatbot_2])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chatbot with Weather Tool using Gradio\nDESCRIPTION: Creates a Gradio chatbot interface that simulates a conversation about the weather in San Francisco. It includes functions for generating responses, handling user likes, and setting up the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_with_tools/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\ndef generate_response(history):\n    history.append(\n        ChatMessage(\n            role=\"user\", content=\"What is the weather in San Francisco right now?\"\n        )\n    )\n    yield history\n    time.sleep(0.25)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"In order to find the current weather in San Francisco, I will need to use my weather tool.\",\n        )\n    )\n    yield history\n    time.sleep(0.25)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"API Error when connecting to weather service.\",\n            metadata={\"title\": \"💥 Error using tool 'Weather'\"},\n        )\n    )\n    yield history\n    time.sleep(0.25)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"I will try again\",\n        )\n    )\n    yield history\n    time.sleep(0.25)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"Weather 72 degrees Fahrenheit with 20% chance of rain.\",\n            metadata={\"title\": \"🛠️ Used tool 'Weather'\"},\n        )\n    )\n    yield history\n    time.sleep(0.25)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"Now that the API succeeded I can complete my task.\",\n        )\n    )\n    yield history\n    time.sleep(0.25)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"It's a sunny day in San Francisco with a current temperature of 72 degrees Fahrenheit and a 20% chance of rain. Enjoy the weather!\",\n        )\n    )\n    yield history\n\ndef like(evt: gr.LikeData):\n    print(\"User liked the response\")\n    print(evt.index, evt.liked, evt.value)\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(type=\"messages\", height=500, show_copy_button=True)\n    button = gr.Button(\"Get San Francisco Weather\")\n    button.click(generate_response, chatbot, chatbot)\n    chatbot.like(like)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Data Visualization with Gradio\nDESCRIPTION: Builds an interactive dashboard with Gradio that displays scatter and line plots. The visualization allows filtering data by ethnicity and maximum age using dropdown and slider components, dynamically updating both plots based on user selections.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_interactive/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        ethnicity = gr.Dropdown([\"all\", \"white\", \"black\", \"asian\"], value=\"all\")\n        max_age = gr.Slider(18, 65, value=65)\n\n    def filtered_df(ethnic, age):\n        _df = df if ethnic == \"all\" else df[df[\"ethnicity\"] == ethnic]\n        _df = _df[_df[\"age\"] < age]\n        return _df\n\n    gr.ScatterPlot(filtered_df, inputs=[ethnicity, max_age], x=\"weight\", y=\"height\", title=\"Weight x Height\")\n    gr.LinePlot(filtered_df, inputs=[ethnicity, max_age], x=\"age\", y=\"height\", title=\"Age x Height\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Gradio Blocks-Based User Interface for Multimodal Chat - Python\nDESCRIPTION: This snippet uses Gradio's Blocks API to define a custom chat interface, featuring a microphone audio input, a message-based chatbot, and app state management. Key parameters include 'theme', 'js', and custom waveform color. It expects a previously defined 'AppState' class and requires Gradio as a dependency. The UI components are arranged in rows, and the audio input defaults to non-streaming operation for compatibility with VAD.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=theme, js=js) as demo:\n    with gr.Row():\n        input_audio = gr.Audio(\n            label=\"Input Audio\",\n            sources=[\"microphone\"],\n            type=\"numpy\",\n            streaming=False,\n            waveform_options=gr.WaveformOptions(waveform_color=\"#B83A4B\"),\n        )\n    with gr.Row():\n        chatbot = gr.Chatbot(label=\"Conversation\", type=\"messages\")\n    state = gr.State(value=AppState())\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake Diffusion Model and Gradio Interface\nDESCRIPTION: This code defines a fake diffusion function that generates random images iteratively, and sets up a Gradio interface to demonstrate the process. The function yields intermediate images at each step and a final colored image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef fake_diffusion(steps):\n    rng = np.random.default_rng()\n    for i in range(steps):\n        time.sleep(1)\n        image = rng.random(size=(600, 600, 3))\n        yield image\n    image = np.ones((1000,1000,3), np.uint8)\n    image[:] = [255, 124, 0]\n    yield image\n\ndemo = gr.Interface(fake_diffusion,\n                    inputs=gr.Slider(1, 10, 3, step=1),\n                    outputs=\"image\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech-to-Text and Sentiment Analysis with Gradio\nDESCRIPTION: This code creates a Gradio interface for speech recognition and sentiment analysis. It uses Hugging Face pipelines for automatic speech recognition and text classification. The interface allows users to upload audio, convert it to text, and then analyze the sentiment of the text.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_speech_text_sentiment/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import pipeline\n\nimport gradio as gr\n\nasr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\nclassifier = pipeline(\"text-classification\")\n\ndef speech_to_text(speech):\n    text = asr(speech)[\"text\"]  # type: ignore\n    return text\n\ndef text_to_sentiment(text):\n    return classifier(text)[0][\"label\"]  # type: ignore\n\ndemo = gr.Blocks()\n\nwith demo:\n    audio_file = gr.Audio(type=\"filepath\")\n    text = gr.Textbox()\n    label = gr.Label()\n\n    b1 = gr.Button(\"Recognize Speech\")\n    b2 = gr.Button(\"Classify Sentiment\")\n\n    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n    b2.click(text_to_sentiment, inputs=text, outputs=label)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake Diffusion with GIF Creation in Python\nDESCRIPTION: This code implements a fake diffusion process using Gradio. It generates random images, creates a GIF from them, and displays a final predefined image. The script includes functions for creating GIFs, simulating the diffusion process, and setting up the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion_with_gif/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport time\nimport os\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n\ndef create_gif(images):\n    pil_images = []\n    for image in images:\n        if isinstance(image, str):\n            response = requests.get(image)\n            image = Image.open(BytesIO(response.content))\n        else:\n            image = Image.fromarray((image * 255).astype(np.uint8))\n        pil_images.append(image)\n    fp_out = os.path.join(os.path.abspath(''), \"image.gif\")\n    img = pil_images.pop(0)\n    img.save(fp=fp_out, format='GIF', append_images=pil_images,\n            save_all=True, duration=400, loop=0)\n    return fp_out\n\ndef fake_diffusion(steps):\n    rng = np.random.default_rng()\n    images = []\n    for _ in range(steps):\n        time.sleep(1)\n        image = rng.random((600, 600, 3))\n        images.append(image)\n        yield image, gr.Image(visible=False)\n\n    time.sleep(1)\n    image = \"https://gradio-builds.s3.amazonaws.com/diffusion_image/cute_dog.jpg\"\n    images.append(image)\n    gif_path = create_gif(images)\n\n    yield image, gr.Image(value=gif_path, visible=True)\n\ndemo = gr.Interface(fake_diffusion,\n                    inputs=gr.Slider(1, 10, 3, step=1),\n                    outputs=[\"image\", gr.Image(label=\"All Images\", visible=False)])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Selecting Regions in a Gradio Plot in Python\nDESCRIPTION: Illustrates how to use the `.select()` event listener on a Gradio plot component (e.g., `gr.ScatterPlot`). This allows capturing coordinates or data points corresponding to a user-selected region (by clicking and dragging) on the plot. Requires gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_selection\n```\n\n----------------------------------------\n\nTITLE: Implementing English to German Translation with Gradio Blocks\nDESCRIPTION: This snippet creates a Gradio Blocks app for translating English text to German using the Helsinki-NLP/opus-mt-en-de model. It defines the translation function and sets up the user interface with input and output text areas.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/07_using-blocks-like-functions.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\n\ntranslator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-de\")\n\ndef translate(text):\n    return translator(text)[0][\"translation_text\"]\n\nwith gr.Blocks() as demo:\n    english = gr.Textbox(label=\"English text\")\n    german = gr.Textbox(label=\"German text\")\n    translate_btn = gr.Button(\"Translate\")\n    translate_btn.click(translate, inputs=english, outputs=german, api_name=\"translate-to-german\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting Up FastAPI Backend Routes\nDESCRIPTION: Code that creates a FastAPI application with routes for displaying the home page with processed videos and handling video uploads. Includes file storage setup and template configuration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom fastapi import FastAPI, File, UploadFile, Request\nfrom fastapi.responses import HTMLResponse, RedirectResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\n\napp = FastAPI()\nos.makedirs(\"static\", exist_ok=True)\napp.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"templates\")\n\nvideos = []\n\n@app.get(\"/\", response_class=HTMLResponse)\nasync def home(request: Request):\n    return templates.TemplateResponse(\n        \"home.html\", {\"request\": request, \"videos\": videos})\n\n@app.post(\"/uploadvideo/\")\nasync def upload_video(video: UploadFile = File(...)):\n    new_video = process_video(video.filename)\n    videos.append(new_video)\n    return RedirectResponse(url='/', status_code=303)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing Data with Gradio ScatterPlot Components\nDESCRIPTION: Creates two sample datasets (temperature sensor data and food rating data) and builds an interactive Gradio interface with multiple scatter plots. The interface includes controls for filtering by time range, grouping data, and selecting aggregation methods.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatter_plot_demo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom random import randint, random\nimport gradio as gr\n\n\ntemp_sensor_data = pd.DataFrame(\n    {\n        \"time\": pd.date_range(\"2021-01-01\", end=\"2021-01-05\", periods=200),\n        \"temperature\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"humidity\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"location\": [\"indoor\", \"outdoor\"] * 100,\n    }\n)\n\nfood_rating_data = pd.DataFrame(\n    {\n        \"cuisine\": [[\"Italian\", \"Mexican\", \"Chinese\"][i % 3] for i in range(100)],\n        \"rating\": [random() * 4 + 0.5 * (i % 3) for i in range(100)],\n        \"price\": [randint(10, 50) + 4 * (i % 3) for i in range(100)],\n        \"wait\": [random() for i in range(100)],\n    }\n)\n\nwith gr.Blocks() as scatter_plots:\n    with gr.Row():\n        start = gr.DateTime(\"2021-01-01 00:00:00\", label=\"Start\")\n        end = gr.DateTime(\"2021-01-05 00:00:00\", label=\"End\")\n        apply_btn = gr.Button(\"Apply\", scale=0)\n    with gr.Row():\n        group_by = gr.Radio([\"None\", \"30m\", \"1h\", \"4h\", \"1d\"], value=\"None\", label=\"Group by\")\n        aggregate = gr.Radio([\"sum\", \"mean\", \"median\", \"min\", \"max\"], value=\"sum\", label=\"Aggregation\")\n\n    temp_by_time = gr.ScatterPlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n    )\n    temp_by_time_location = gr.ScatterPlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n        color=\"location\",\n    )\n\n    time_graphs = [temp_by_time, temp_by_time_location]\n    group_by.change(\n        lambda group: [gr.ScatterPlot(x_bin=None if group == \"None\" else group)] * len(time_graphs),\n        group_by,\n        time_graphs\n    )\n    aggregate.change(\n        lambda aggregate: [gr.ScatterPlot(y_aggregate=aggregate)] * len(time_graphs),\n        aggregate,\n        time_graphs\n    )\n\n    price_by_cuisine = gr.ScatterPlot(\n        food_rating_data,\n        x=\"cuisine\",\n        y=\"price\",\n    )\n    with gr.Row():\n        price_by_rating = gr.ScatterPlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n            color=\"wait\",\n            show_actions_button=True,\n        )\n        price_by_rating_color = gr.ScatterPlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n            color=\"cuisine\",\n        )\n\nif __name__ == \"__main__\":\n    scatter_plots.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Tables and Statistics in Gradio Dashboard\nDESCRIPTION: Example showing how to integrate DataFrame displays and numerical statistics using gr.DataFrame and gr.Label components for data visualization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/03_filters-tables-and-stats.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n$code_plot_guide_tables_stats\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Browser State Demo Application\nDESCRIPTION: Creates a Gradio Blocks application that demonstrates browser state persistence. The application includes username and password fields that are saved to local storage, a button to generate random credentials, and feedback messages showing when data is saved.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/browserstate/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport string\nimport gradio as gr\nimport time\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Your Username and Password will get saved in the browser's local storage. \"\n                \"If you refresh the page, the values will be retained.\")\n    username = gr.Textbox(label=\"Username\")\n    password = gr.Textbox(label=\"Password\", type=\"password\")\n    btn = gr.Button(\"Generate Randomly\")\n    local_storage = gr.BrowserState([\"\", \"\"])\n    saved_message = gr.Markdown(\"✅ Saved to local storage\", visible=False)\n\n    @btn.click(outputs=[username, password])\n    def generate_randomly():\n        u = \"\".join(random.choices(string.ascii_letters + string.digits, k=10))\n        p = \"\".join(random.choices(string.ascii_letters + string.digits, k=10))\n        return u, p\n\n    @demo.load(inputs=[local_storage], outputs=[username, password])\n    def load_from_local_storage(saved_values):\n        print(\"loading from local storage\", saved_values)\n        return saved_values[0], saved_values[1]\n\n    @gr.on([username.change, password.change], inputs=[username, password], outputs=[local_storage])\n    def save_to_local_storage(username, password):\n        return [username, password]\n\n    @gr.on(local_storage.change, outputs=[saved_message])\n    def show_saved_message():\n        timestamp = time.strftime(\"%I:%M:%S %p\")\n        return gr.Markdown(\n            f\"✅ Saved to local storage at {timestamp}\",\n            visible=True\n        )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Custom Theme\nDESCRIPTION: This code creates a Gradio interface with custom theme settings, input components, and a function to repeat text. It demonstrates how to set up a Gradio application with various interactive elements and theme customization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\nwith gr.Blocks(theme=gr.themes.Default(spacing_size=\"sm\", radius_size=\"none\")) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Loading Hugging Face Model via Inference Endpoints in Gradio\nDESCRIPTION: Demonstrates how to create a Gradio demo using Hugging Face's Serverless Inference Endpoints by loading a translation model directly from the Model Hub.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/01_using-hugging-face-integrations.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.load(\"Helsinki-NLP/opus-mt-en-es\", src=\"models\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: PDF Highlighting and UI Implementation\nDESCRIPTION: Implements a Gradio interface with PDF highlighting functionality. Features include text search, highlighting matches in PDFs, and an interactive viewer. Uses PyMuPDF for PDF manipulation and Gradio for the web interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlight_pdf/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_pdf import PDF\nimport pymupdf\nimport os\nfrom pathlib import Path\n\ncurrent_dir = Path(os.path.abspath(''))\n\ndef highlight_text_in_pdf(pdf_file: Path, highlight_text: str):\n    page_number = 0\n    doc = pymupdf.open(pdf_file)\n    for page in doc:\n        text_instances = page.search_for(highlight_text)\n        if len(text_instances) > 0:\n            page_number = page.number\n        for inst in text_instances:\n            page.add_highlight_annot(inst)\n\n    new_pdf_file = str(pdf_file.parents[0]) + \"/new_\" + pdf_file.name\n    doc.save(new_pdf_file)\n\n    if page_number is None:\n        page_number = 0\n    \n    return new_pdf_file, page_number + 1\n\ndef ask(query): \n    result = f\"Something about : {query}\"\n    sources = \"Document 1\"\n    pdf_path = current_dir / \"Lorem_ipsum.pdf\"\n    pdf_name = \"Document 1\"\n    context_to_highlight = \"Ut velit mauris\"\n\n    pdf, page_number = highlight_text_in_pdf(pdf_path, context_to_highlight)\n    return result, sources + f\" - Page {page_number}\", PDF(pdf, label=pdf_name, starting_page=page_number, interactive=True)  # type: ignore\n\n\nif __name__ == \"__main__\":\n    with gr.Blocks() as demo:\n        title = gr.HTML(f\"<center><h1>Bot</h1></center>\")\n        with gr.Row():\n            with gr.Column(scale=2):\n                input = gr.Textbox(label=\"Question\", autofocus=True, interactive=True)\n                btn = gr.Button(\"Ask\", variant=\"primary\")\n                output = gr.Markdown(label=\"Anwser\")\n            with gr.Column(scale=2):\n                srcs = gr.Textbox(label=\"Sources\", interactive=False)\n                pdf = PDF(label=\"Document\")\n            \n        btn.click(fn=ask, inputs=input, outputs=[output, srcs, pdf])\n\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: OpenAI-API Compatible Endpoint Integration\nDESCRIPTION: Example of using Gradio with an OpenAI-API compatible endpoint like Ollama\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.load_chat(\"http://localhost:11434/v1/\", model=\"llama3.2\", token=\"***\").launch()\n```\n\n----------------------------------------\n\nTITLE: Building Interactive UI with Gradio Blocks\nDESCRIPTION: Creates a complex interactive UI using Gradio's Blocks API. The interface includes a radio selector for essay type, dynamic textboxes, numerical inputs with min/max constraints, country-city dropdowns with dependencies, and various interactive buttons.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_essay/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ncountries_cities_dict = {\n    \"USA\": [\"New York\", \"Los Angeles\", \"Chicago\"],\n    \"Canada\": [\"Toronto\", \"Montreal\", \"Vancouver\"],\n    \"Pakistan\": [\"Karachi\", \"Lahore\", \"Islamabad\"],\n}\n\ndef change_textbox(choice):\n    if choice == \"short\":\n        return gr.Textbox(lines=2, visible=True), gr.Button(interactive=True)\n    elif choice == \"long\":\n        return gr.Textbox(lines=8, visible=True, value=\"Lorem ipsum dolor sit amet\"), gr.Button(interactive=True)\n    else:\n        return gr.Textbox(visible=False), gr.Button(interactive=False)\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n    )\n    text = gr.Textbox(lines=2, interactive=True, show_copy_button=True)\n\n    with gr.Row():\n        num = gr.Number(minimum=0, maximum=100, label=\"input\")\n        out = gr.Number(label=\"output\")\n    minimum_slider = gr.Slider(0, 100, 0, label=\"min\")\n    maximum_slider = gr.Slider(0, 100, 100, label=\"max\")\n    submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n\n    with gr.Row():\n        country = gr.Dropdown(list(countries_cities_dict.keys()), label=\"Country\")\n        cities = gr.Dropdown([], label=\"Cities\")\n    @country.change(inputs=country, outputs=cities)\n    def update_cities(country):\n        cities = list(countries_cities_dict[country])\n        return gr.Dropdown(choices=cities, value=cities[0], interactive=True)\n\n    def reset_bounds(minimum, maximum):\n        return gr.Number(minimum=minimum, maximum=maximum)\n\n    radio.change(fn=change_textbox, inputs=radio, outputs=[text, submit_btn])\n    gr.on(\n        [minimum_slider.change, maximum_slider.change],\n        reset_bounds,\n        [minimum_slider, maximum_slider],\n        outputs=num,\n    )\n    num.submit(lambda x: x, num, out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Interactive Image Editor UI with Gradio Blocks - Python\nDESCRIPTION: This large snippet creates a full-featured interactive Gradio application for layered image editing. It imports Gradio and pathlib, defines a prediction function for layer counting, and constructs a UI using the Blocks API with components for editing images, managing layers, displaying previews, and running examples. The application initializes with several buttons and event handlers to set backgrounds, layers, and composites, uses the Gradio ImageEditor component, and wires input/output flows between widgets. Dependencies include gradio and pathlib; the code requires the previously downloaded assets to function fully and expects image and layer data structures as input.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_layers/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nimport gradio as gr\nfrom pathlib import Path\n\ndir_ = Path(__file__).parent\n\n\ndef predict(im):\n    print(im)\n    return im, len(im[\"layers\"])\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        im = gr.ImageEditor(\n            type=\"numpy\",\n            interactive=True,\n        )\n        im_preview = gr.ImageEditor(\n            interactive=True,\n        )\n\n    layer_updates = gr.Textbox(value=\"\", label=\"Layer Updates\")\n    num_layers = gr.Number(value=0, label=\"Num Layers\")\n    example_ran = gr.Number(value=0, label=\"Example Ran\")\n\n    set_background = gr.Button(\"Set Background\")\n    set_background.click(\n        lambda: {\n            \"background\": str(dir_ / \"cheetah.jpg\"),\n            \"layers\": None,\n            \"composite\": None,\n        },\n        None,\n        im,\n        show_progress=\"hidden\",\n    )\n    set_layers = gr.Button(\"Set Layers\")\n    set_layers.click(\n        lambda: {\n            \"background\": None,\n            \"layers\": [\n                \"https://nationalzoo.si.edu/sites/default/files/animals/cheetah-003.jpg\"\n            ],\n            \"composite\": None,\n        },\n        None,\n        im,\n        show_progress=\"hidden\",\n    )\n    im.change(\n        lambda x: len(x[\"layers\"]),\n        inputs=im,\n        outputs=layer_updates,\n    )\n    set_composite = gr.Button(\"Set Composite\")\n    set_composite.click(\n        lambda: {\n            \"background\": None,\n            \"layers\": None,\n            \"composite\": \"https://nationalzoo.si.edu/sites/default/files/animals/cheetah-003.jpg\",\n        },\n        None,\n        im,\n        show_progress=\"hidden\",\n    )\n    get_layers = gr.Button(\"Get Layers\")\n\n    get_layers.click(\n        predict,\n        outputs=[im_preview, num_layers],\n        inputs=im,\n    )\n\n    gr.Examples(\n        examples=[\n            \"https://upload.wikimedia.org/wikipedia/commons/0/09/TheCheethcat.jpg\",\n            {\n                \"background\": str(dir_ / \"cheetah.jpg\"),\n                \"layers\": [str(dir_ / \"layer1.png\")],\n                \"composite\": None,\n            },\n        ],\n        inputs=im,\n        outputs=[example_ran],\n        fn=lambda x: 1,\n        run_on_click=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Interface for Image Classification (Python)\nDESCRIPTION: This snippet uses the Gradio library to create a web interface for the `classify_image` function. It defines an `Image` input component (resized to 224x224) and a `Label` output component displaying the top 3 predicted classes. It also includes example images and launches the interactive web application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-tensorflow.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.Interface(fn=classify_image,\n             inputs=gr.Image(width=224, height=224),\n             outputs=gr.Label(num_top_classes=3),\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Editor Sketchpad with Pixel Analysis\nDESCRIPTION: Creates a Gradio interface with a sketchpad that calculates the percentage of selected pixels in real-time. Uses numpy for pixel calculations and displays results through a label component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_sketchpad/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef percent_of_pixels_selected(image):\n    mask = image[\"layers\"][0]\n    mask_bool = mask[:,:,3] > 0\n    return f\"{round(np.sum(mask_bool) / mask_bool.size * 100, 2)}%\"\n\nimage_editor = gr.Sketchpad(\n    type=\"numpy\",\n)\noutput_image = gr.Label(\n    label=\"Percent of Pixels Selected\"\n)\n\ndemo = gr.Interface(\n    fn=percent_of_pixels_selected,\n    inputs=image_editor,\n    outputs=output_image,\n    live=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Thinking Chatbot with Gradio\nDESCRIPTION: Creates a chatbot interface that simulates an AI's thinking process by progressively displaying thoughts before giving a final answer. Uses Gradio's Blocks and ChatMessage components to create an interactive chat interface with markdown support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_thoughts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\ndef simulate_thinking_chat(message: str, history: list):\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"\",\n            metadata={\"title\": \"Thinking... \", \"log\": \"Starting analysis\"}\n        )\n    )\n    time.sleep(0.5)\n    yield history\n\n    thoughts = [\n        \"First, I need to understand the core aspects of the query...\",\n        \"Now, considering the broader context and implications...\",\n        \"Analyzing potential approaches to formulate a comprehensive answer...\",\n        \"Finally, structuring the response for clarity and completeness...\"\n    ]\n\n    accumulated_thoughts = \"\"\n\n    for i, thought in enumerate(thoughts):\n        time.sleep(0.5)\n\n        accumulated_thoughts += f\"- {thought}\\n\\n\"\n\n        history[-1] = ChatMessage(\n            role=\"assistant\",\n            content=accumulated_thoughts.strip(),\n            metadata={\n                \"title\": \"Thinking...\",\n                \"log\": f\"Step {i+1} completed.\",\n                \"duration\": 0.5 * (i + 1)\n            }\n        )\n        yield history\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"Based on my thoughts and analysis above, my response is: This dummy repro shows how thoughts of a thinking LLM can be progressively shown before providing its final answer.\"\n        )\n    )\n    yield history\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Thinking LLM Demo 🤔\")\n    chatbot = gr.Chatbot(type=\"messages\", render_markdown=True)\n    msg = gr.Textbox(placeholder=\"Type your message...\")\n\n    msg.submit(\n        lambda m, h: (m, h + [ChatMessage(role=\"user\", content=m)]),\n        [msg, chatbot],\n        [msg, chatbot]\n    ).then(\n        simulate_thinking_chat,\n        [msg, chatbot],\n        chatbot\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Medical Diagnosis Form with Gradio Blocks\nDESCRIPTION: Builds an interactive medical diagnosis form using Gradio's Blocks API. The form collects patient information (name, age, symptoms), processes it when submitted, and displays a diagnosis and patient summary. It also demonstrates conditional visibility of UI components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_form/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name_box = gr.Textbox(label=\"Name\")\n    age_box = gr.Number(label=\"Age\", minimum=0, maximum=100)\n    symptoms_box = gr.CheckboxGroup([\"Cough\", \"Fever\", \"Runny Nose\"])\n    submit_btn = gr.Button(\"Submit\")\n\n    with gr.Column(visible=False) as output_col:\n        diagnosis_box = gr.Textbox(label=\"Diagnosis\")\n        patient_summary_box = gr.Textbox(label=\"Patient Summary\")\n\n    def submit(name, age, symptoms):\n        return {\n            submit_btn: gr.Button(visible=False),\n            output_col: gr.Column(visible=True),\n            diagnosis_box: \"covid\" if \"Cough\" in symptoms else \"flu\",\n            patient_summary_box: f\"{name}, {age} y/o\",\n        }\n\n    submit_btn.click(\n        submit,\n        [name_box, age_box, symptoms_box],\n        [submit_btn, diagnosis_box, patient_summary_box, output_col],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Visibility Control in Gradio Tabs Interface\nDESCRIPTION: Creates a Gradio interface with two tabs, each containing a hidden textbox and a button that makes the textbox visible when clicked. This demonstrates dynamic visibility control of UI components in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_visibility/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\n\nwith gr.Blocks() as demo:\n    with gr.Tabs():\n        with gr.TabItem(\"Tab 1\"):\n            t = gr.Textbox(\"Some value\", label=\"Name\", visible=False)\n            btn = gr.Button(\"Show\")\n            btn.click(lambda: gr.Textbox(visible=True), inputs=None, outputs=t)\n        with gr.TabItem(\"Tab 2\"):\n            t2 = gr.Textbox(\"Some other value\", label=\"Name\", visible=False)\n            btn2 = gr.Button(\"Show\")\n            btn2.click(lambda: gr.Textbox(visible=True), inputs=None, outputs=t2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Linking Recording Events and Response Generation in Gradio (Python)\nDESCRIPTION: This snippet sets up event handlers for starting and stopping audio recording on a Gradio component. It binds the recording events to functions: upon recording start, 'process_audio' is invoked with the audio input and state; upon stop, the 'response' function is called with state and the recorded input to update the chatbot. Dependencies include Gradio components for audio and state management, as well as implementation of the 'process_audio' and 'response' functions. Inputs include the user's voice (captured via the input_audio component) and any relevant state data; outputs are updates to UI components such as the chatbot display and state holders. Requires correct event signature matching for event functions and proper Gradio setup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n    stream = input_audio.start_recording(\n        process_audio,\n        [input_audio, state],\n        [input_audio, state],\n    )\n    respond = input_audio.stop_recording(\n        response, [state, input_audio], [state, chatbot]\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Processing and Gradio Streaming UI (Python)\nDESCRIPTION: Defines the main application logic for processing and streaming video using Gradio and OpenCV. It includes a function to process video frames (flip vertically), segment the video into chunks (MP4 or TS based on input), and yield segments for streaming. A Gradio interface is constructed with input/output video components, a format selection checkbox, a processing button, and example usage. Cleanup logic using 'atexit' ensures generated video files are deleted on script exit.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_video_out/run.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport cv2\nimport os\nfrom pathlib import Path\nimport atexit\n\ncurrent_dir = Path(__file__).resolve().parent\n\n\ndef delete_files():\n    for p in Path(current_dir).glob(\"*.ts\"):\n        p.unlink()\n    for p in Path(current_dir).glob(\"*.mp4\"):\n        p.unlink()\n\n\natexit.register(delete_files)\n\n\ndef process_video(input_video, stream_as_mp4):\n    cap = cv2.VideoCapture(input_video)\n\n    video_codec = cv2.VideoWriter_fourcc(*\"mp4v\") if stream_as_mp4 else cv2.VideoWriter_fourcc(*\"x264\")  # type: ignore\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n    iterating, frame = cap.read()\n\n    n_frames = 0\n    n_chunks = 0\n    name = str(current_dir / f\"output_{n_chunks}{'.mp4' if stream_as_mp4 else '.ts'}\")\n    segment_file = cv2.VideoWriter(name, video_codec, fps, (width, height))  # type: ignore\n\n    while iterating:\n\n        # flip frame vertically\n        frame = cv2.flip(frame, 0)\n        display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        segment_file.write(display_frame)\n        n_frames += 1\n        if n_frames == 3 * fps:\n            n_chunks += 1\n            segment_file.release()\n            n_frames = 0\n            yield name\n            name = str(\n                current_dir / f\"output_{n_chunks}{'.mp4' if stream_as_mp4 else '.ts'}\"\n            )\n            segment_file = cv2.VideoWriter(name, video_codec, fps, (width, height))  # type: ignore\n\n        iterating, frame = cap.read()\n\n    segment_file.release()\n    yield name\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Video Streaming Out \\U0001f4f9\")\n    with gr.Row():\n        with gr.Column():\n            input_video = gr.Video(label=\"input\")\n            checkbox = gr.Checkbox(label=\"Stream as MP4 file?\", value=False)\n        with gr.Column():\n            processed_frames = gr.Video(\n                label=\"stream\",\n                streaming=True,\n                autoplay=True,\n                elem_id=\"stream_video_output\",\n            )\n    with gr.Row():\n        process_video_btn = gr.Button(\"process video\")\n\n    process_video_btn.click(process_video, [input_video, checkbox], [processed_frames])\n\n    gr.Examples(\n        [\n            [\n                os.path.join(\n                    os.path.abspath(''),\n                    \"video/compliment_bot_screen_recording_3x.mp4\",\n                ),\n                False,\n            ],\n            [\n                os.path.join(\n                    os.path.abspath(''),\n                    \"video/compliment_bot_screen_recording_3x.mp4\",\n                ),\n                True,\n            ],\n        ],\n        [input_video, checkbox],\n        fn=process_video,\n        outputs=processed_frames,\n        cache_examples=False,\n    )\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Gradio Block Interface with JavaScript Animation\nDESCRIPTION: Creates a Gradio interface that combines a Python welcome message function with custom JavaScript animation. The JS code creates an animated welcome message that appears letter by letter at the top of the interface, while the Python code handles the input/output functionality for a personalized greeting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_js_load/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef welcome(name):\n    return f\"Welcome to Gradio, {name}!\"\n\njs = \"\"\"\nfunction createGradioAnimation() {\n    var container = document.createElement('div');\n    container.id = 'gradio-animation';\n    container.style.fontSize = '2em';\n    container.style.fontWeight = 'bold';\n    container.style.textAlign = 'center';\n    container.style.marginBottom = '20px';\n\n    var text = 'Welcome to Gradio!';\n    for (var i = 0; i < text.length; i++) {\n        (function(i){\n            setTimeout(function(){\n                var letter = document.createElement('span');\n                letter.style.opacity = '0';\n                letter.style.transition = 'opacity 0.5s';\n                letter.innerText = text[i];\n\n                container.appendChild(letter);\n\n                setTimeout(function() {\n                    letter.style.opacity = '1';\n                }, 50);\n            }, i * 250);\n        })(i);\n    }\n\n    var gradioContainer = document.querySelector('.gradio-container');\n    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n\n    return 'Animation created';\n}\n\"\"\"\nwith gr.Blocks(js=js) as demo:\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n    inp.change(welcome, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Scatter Plot with Pandas DataFrame in Python\nDESCRIPTION: Illustrates creating a `gr.ScatterPlot` with a pandas DataFrame. This example highlights the consistent API across different Gradio plot types (`gr.LinePlot`, `gr.ScatterPlot`, `gr.BarPlot`), using the same `x` and `y` arguments to specify axes columns. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_scatter\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio App for Visualizing PyPI Download Statistics\nDESCRIPTION: Implements a Gradio application that fetches and displays download statistics for Hugging Face libraries. The application allows users to select from different libraries and time periods, and uses the pypistats package to retrieve download data which is then visualized using line plots.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_multiple_event_triggers/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pypistats\nfrom datetime import date\nfrom dateutil.relativedelta import relativedelta\nimport pandas as pd\n\ndef get_plot(lib, time):\n    data = pypistats.overall(lib, total=True, format=\"pandas\")\n    data = data.groupby(\"category\").get_group(\"with_mirrors\").sort_values(\"date\")\n    start_date = date.today() - relativedelta(months=int(time.split(\" \")[0]))\n    data = data[(data['date'] > str(start_date))]\n    data.date = pd.to_datetime(pd.to_datetime(data.date))\n    return gr.LinePlot(value=data, x=\"date\", y=\"downloads\",\n                              tooltip=['date', 'downloads'],\n                              title=f\"Pypi downloads of {lib} over last {time}\",\n                              overlay_point=True,\n                              height=400,\n                              width=900)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n        ## Pypi Download Stats 📈\n        See live download stats for all of Hugging Face's open-source libraries 🤗\n        \"\"\")\n    with gr.Row():\n        lib = gr.Dropdown([\"transformers\", \"datasets\", \"huggingface-hub\", \"gradio\", \"accelerate\"],\n                          value=\"gradio\", label=\"Library\")\n        time = gr.Dropdown([\"3 months\", \"6 months\", \"9 months\", \"12 months\"],\n                           value=\"3 months\", label=\"Downloads over the last...\")\n\n    plt = gr.LinePlot()\n    # You can add multiple event triggers in 2 lines like this\n    for event in [lib.change, time.change, demo.load]:\n        event(get_plot, [lib, time], [plt])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Adding Page Navigation Functions in TypeScript\nDESCRIPTION: Implements functions to navigate between PDF pages. The next_page and prev_page functions update the current page and trigger the render_page function to display the new page.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { BaseButton } from \"@gradio/button\";\n\n...\n\nfunction next_page() {\n    if (currentPage >= numPages) {\n        return;\n    }\n    currentPage++;\n    render_page();\n}\n\nfunction prev_page() {\n    if (currentPage == 1) {\n        return;\n    }\n    currentPage--;\n    render_page();\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Chat Interface with Deep Link\nDESCRIPTION: Creates a chat interface using Gradio that responds with random greetings. Includes a deep link button for sharing specific states of the application. The interface uses a simple random response function and is configured with a title and description.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/deep_link/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\ndef random_response(message, history):\n    return random.choice([\"Hi!\", \"Hello!\", \"Greetings!\"])\n\nwith gr.Blocks() as demo:\n    gr.ChatInterface(\n        random_response,\n        title=\"Greeting Bot\",\n        description=\"Ask anything and receive a nice greeting!\",\n    )\n    gr.DeepLinkButton()\n\nif __name__ == \"__main__\":\n    demo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Implementing Text-to-Image Generation with Batching\nDESCRIPTION: Sets up a Gradio interface with batch processing capability for text-to-image generation using the CompVis/ldm-text2im-large-256 model. The implementation includes GPU support and configurable batch size.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport torch\nfrom diffusers import DiffusionPipeline  # type: ignore\nimport gradio as gr\n\ngenerator = DiffusionPipeline.from_pretrained(\"CompVis/ldm-text2im-large-256\")\n# move to GPU if available\nif torch.cuda.is_available():\n    generator = generator.to(\"cuda\")\n\ndef generate(prompts):\n  images = generator(list(prompts)).images  # type: ignore\n  return [images]\n\ndemo = gr.Interface(generate,\n             \"textbox\",\n             \"image\",\n             batch=True,\n             max_batch_size=4  # Set the batch size based on your CPU/GPU memory\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Demo (Bash)\nDESCRIPTION: This command uses pip, the Python package installer, to install the necessary libraries: `gradio` for building the web interface, `opencv-python` for image processing functionalities, and `numpy` for numerical operations, particularly array handling for images. The `-q` flag ensures a quiet installation, minimizing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_filter/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio opencv-python numpy \n```\n\n----------------------------------------\n\nTITLE: Titanic Survival Prediction Model and Gradio Interface\nDESCRIPTION: This comprehensive snippet includes data preprocessing, model training, and a Gradio interface for predicting Titanic passenger survival. It uses a Random Forest classifier and creates an interactive demo with various input fields.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/titanic_survival/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport gradio as gr\n\ncurrent_dir = os.path.dirname(os.path.realpath(__file__))\ndata = pd.read_csv(os.path.join(current_dir, \"files/titanic.csv\"))\n\ndef encode_age(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    categories = pd.cut(df.Age, bins, labels=False)\n    df.Age = categories\n    return df\n\ndef encode_fare(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 1000)\n    categories = pd.cut(df.Fare, bins, labels=False)\n    df.Fare = categories\n    return df\n\ndef encode_df(df):\n    df = encode_age(df)\n    df = encode_fare(df)\n    sex_mapping = {\"male\": 0, \"female\": 1}\n    df = df.replace({\"Sex\": sex_mapping})\n    embark_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n    df = df.replace({\"Embarked\": embark_mapping})\n    df.Embarked = df.Embarked.fillna(0)\n    df[\"Company\"] = 0\n    df.loc[(df[\"SibSp\"] > 0), \"Company\"] = 1\n    df.loc[(df[\"Parch\"] > 0), \"Company\"] = 2\n    df.loc[(df[\"SibSp\"] > 0) & (df[\"Parch\"] > 0), \"Company\"] = 3\n    df = df[\n        [\n            \"PassengerId\",\n            \"Pclass\",\n            \"Sex\",\n            \"Age\",\n            \"Fare\",\n            \"Embarked\",\n            \"Company\",\n            \"Survived\",\n        ]\n    ]\n    return df\n\ntrain = encode_df(data)\n\nX_all = train.drop([\"Survived\", \"PassengerId\"], axis=1)\ny_all = train[\"Survived\"]\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(\n    X_all, y_all, test_size=num_test, random_state=23\n)\n\nclf = RandomForestClassifier()\nclf.fit(X_train, y_train)\npredictions = clf.predict(X_test)\n\ndef predict_survival(passenger_class, is_male, age, company, fare, embark_point):\n    if passenger_class is None or embark_point is None:\n        return None\n    df = pd.DataFrame.from_dict(\n        {\n            \"Pclass\": [passenger_class + 1],\n            \"Sex\": [0 if is_male else 1],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embark_point + 1],\n            \"Company\": [\n                (1 if \"Sibling\" in company else 0) + (2 if \"Child\" in company else 0)\n            ]\n        }\n    )\n    df = encode_age(df)\n    df = encode_fare(df)\n    pred = clf.predict_proba(df)[0]\n    return {\"Perishes\": float(pred[0]), \"Survives\": float(pred[1])}\n\ndemo = gr.Interface(\n    predict_survival,\n    [\n        gr.Dropdown([\"first\", \"second\", \"third\"], type=\"index\"),\n        \"checkbox\",\n        gr.Slider(0, 80, value=25),\n        gr.CheckboxGroup([\"Sibling\", \"Child\"], label=\"Travelling with (select all)\"),\n        gr.Number(value=20),\n        gr.Radio([\"S\", \"C\", \"Q\"], type=\"index\"),\n    ],\n    \"label\",\n    examples=[\n        [\"first\", True, 30, [], 50, \"S\"],\n        [\"second\", False, 40, [\"Sibling\", \"Child\"], 10, \"Q\"],\n        [\"third\", True, 30, [\"Child\"], 20, \"S\"],\n    ],\n    live=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Cancelling Gradio Jobs with Iterative Outputs\nDESCRIPTION: Demonstrates cancelling a Gradio job that produces iterative outputs (a generator). The client connects to 'abidlabs/test-yield', submits a job, pauses briefly using `time.sleep(3)`, and then calls `job.cancel()`. The cancellation request stops the job after the currently running iteration finishes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\nimport time\n\nclient = Client(\"abidlabs/test-yield\")\njob = client.submit(\"abcdef\")\ntime.sleep(3)\njob.cancel()  # job cancels after 2 iterations\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Image Filters with Gradio and OpenCV (Python)\nDESCRIPTION: This Python script defines a function `transform_cv2` that applies image transformations ('cartoon', 'edges', 'flip') to input frames using OpenCV (cv2). It then creates a Gradio Blocks interface featuring a webcam input (`gr.Image`), a dropdown (`gr.Dropdown`) to select the transformation, and a streaming image output (`gr.Image(streaming=True)`). The `input_img.stream()` method connects these components, continuously applying the selected transformation function to the webcam feed and updating the output image. The script launches the Gradio application when run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_filter/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport cv2\n\ndef transform_cv2(frame, transform):\n    if transform == \"cartoon\":\n        # prepare color\n        img_color = cv2.pyrDown(cv2.pyrDown(frame))\n        for _ in range(6):\n            img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n        img_color = cv2.pyrUp(cv2.pyrUp(img_color))\n\n        # prepare edges\n        img_edges = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n        img_edges = cv2.adaptiveThreshold(\n            cv2.medianBlur(img_edges, 7),\n            255,\n            cv2.ADAPTIVE_THRESH_MEAN_C,\n            cv2.THRESH_BINARY,\n            9,\n            2,\n        )\n        img_edges = cv2.cvtColor(img_edges, cv2.COLOR_GRAY2RGB)\n        # combine color and edges\n        img = cv2.bitwise_and(img_color, img_edges)\n        return img\n    elif transform == \"edges\":\n        # perform edge detection\n        img = cv2.cvtColor(cv2.Canny(frame, 100, 200), cv2.COLOR_GRAY2BGR)\n        return img\n    else:\n        return np.flipud(frame)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            transform = gr.Dropdown(choices=[\"cartoon\", \"edges\", \"flip\"],\n                                    value=\"flip\", label=\"Transformation\")\n            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\")\n        with gr.Column():\n            output_img = gr.Image(streaming=True)\n        dep = input_img.stream(transform_cv2, [input_img, transform], [output_img],\n                                time_limit=30, stream_every=0.1, concurrency_limit=30)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Timer Demo Interface\nDESCRIPTION: Builds a Gradio interface with various timer-based components. It includes a continuous timestamp display, a start/stop timer, and a random number generator with adjustable intervals and controls.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timer/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n  timer = gr.Timer(1)\n  timestamp = gr.Number(label=\"Time\")\n  timer.tick(lambda: round(time.time()), outputs=timestamp)\n  gr.Number(lambda: round(time.time()), label=\"Time 2\", every=1)\n\n  with gr.Row():\n    timestamp_3 = gr.Number()\n    start_btn = gr.Button(\"Start\")\n    stop_btn = gr.Button(\"Stop\")\n\n    time_3 = start_btn.click(lambda: round(time.time()), None, timestamp_3, every=1)\n    stop_btn.click(fn=None, cancels=time_3)\n\n  with gr.Row():\n    min = gr.Number(1, label=\"Min\")\n    max = gr.Number(10, label=\"Max\")\n  timer2 = gr.Timer(1)\n  number = gr.Number(lambda a, b: random.randint(a, b), inputs=[min, max], every=timer2, label=\"Random Number\")\n  with gr.Row():\n    gr.Button(\"Start\").click(lambda: gr.Timer(active=True), None, timer2)\n    gr.Button(\"Stop\").click(lambda: gr.Timer(active=False), None, timer2)\n    gr.Button(\"Go Fast\").click(lambda: 0.2, None, timer2)\n    gr.Button(\"Go Slow\").click(lambda: 2, None, timer2)\n\nif __name__ == \"__main__\":\n  demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Custom Theme in Python\nDESCRIPTION: Sets up a Gradio interface with a custom Seafoam theme. It includes a textbox for name input, a slider for count, submit and clear buttons, and an output textbox. The interface defines a function to repeat the input name based on the count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_1/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio.themes.base import Base\nimport time\n\nclass Seafoam(Base):\n    pass\n\nseafoam = Seafoam()\n\nwith gr.Blocks(theme=seafoam) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Dynamic UI Rendering with Gradio\nDESCRIPTION: Demonstrates Gradio's dynamic rendering capabilities using the @gr.render decorator. The code showcases real-time updates, event handling with EventData and SelectData, conditional UI rendering, and various Gradio components including textboxes, sliders, buttons, and chatbots.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_tests/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import datetime\n\nimport gradio as gr\n\ndef update_log():\n    return datetime.now().timestamp()\n\ndef get_target(evt: gr.EventData):\n    return evt.target\n\ndef get_select_index(evt: gr.SelectData):\n    return evt.index\n\nwith gr.Blocks() as demo:\n    gr.Textbox(value=update_log, every=0.2, label=\"Time\")\n    \n    slider = gr.Slider(1, 10, step=1)\n    @gr.render(inputs=[slider])\n    def show_log(s):\n        with gr.Row():\n            for i in range(s):\n                gr.Textbox(value=update_log, every=0.2, label=f\"Render {i + 1}\")\n\n    slider2 = gr.Slider(1, 10, step=1, label=\"Box Count\")\n    btn = gr.Button(\"Create Boxes\")\n    @gr.render(inputs=[slider2], triggers=[btn.click])\n    def show_log_2(s):\n        for i in range(s):\n            gr.Textbox(value=str(i), label=f\"Count {i + 1}\")\n\n    with gr.Row():\n        selected_btn = gr.Textbox(label=\"Selected Button\")\n        selected_chat = gr.Textbox(label=\"Selected Chat\")\n    @gr.render(inputs=[slider])\n    def show_buttons(s):\n        with gr.Row():\n            with gr.Column():\n                for i in range(s):\n                    btn = gr.Button(f\"Button {i + 1}\")\n                    btn.click(get_target, None, selected_btn)\n            chatbot = gr.Chatbot([[\"Hello\", \"Hi\"], [\"How are you?\", \"I'm good.\"]])\n            chatbot.select(get_select_index, None, selected_chat)\n\n    selectable_chat = gr.Chatbot([[\"chat1\", \"chat2\"], [\"chat3\", \"chat4\"]])\n \n    @gr.render(triggers=[selectable_chat.select])\n    def show_selected_chat(selection: gr.SelectData):\n        gr.Textbox(label=\"Trigger Index\", value=selection.index)\n\n    @gr.render()\n    def examples_in_interface():\n        gr.Interface(lambda x:x, gr.Textbox(label=\"input\"), gr.Textbox(), examples=[[\"test\"]])\n\n    @gr.render()\n    def examples_in_blocks():\n        a = gr.Textbox(label=\"little textbox\")\n        gr.Examples([[\"abc\"], [\"def\"]], [a])\n\n\nif __name__ == '__main__':\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Chatbot Interface\nDESCRIPTION: Creates a chatbot interface using Gradio Blocks with a message input, chat history display, and clear button. The bot responds with random predefined messages after a 2-second delay. Uses queue management for message handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_consecutive/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox()\n    clear = gr.Button(\"Clear\")\n\n    def user(user_message, history):\n        return \"\", history + [[user_message, None]]\n\n    def bot(history):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        time.sleep(2)\n        history[-1][1] = bot_message\n        return history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-tab Gradio Audio Debugger Interface\nDESCRIPTION: Creates a Gradio application with multiple tabs for different audio functionalities. The tabs include basic audio playback, an audio interface, streaming audio, and a console tab for command execution. It also demonstrates getting the user's IP address using Gradio's Request object.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_debugger/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport subprocess\nimport os\n\naudio_file = os.path.join(os.path.abspath(''), \"cantina.wav\")\n\nwith gr.Blocks() as demo:\n    with gr.Tab(\"Audio\"):\n        gr.Audio(audio_file)\n    with gr.Tab(\"Interface\"):\n        gr.Interface(\n            lambda x: x, \"audio\", \"audio\", examples=[audio_file], cache_examples=True\n        )\n    with gr.Tab(\"Streaming\"):\n        gr.Interface(\n            lambda x: x,\n            gr.Audio(streaming=True),\n            \"audio\",\n            examples=[audio_file],\n            cache_examples=True,\n        )\n    with gr.Tab(\"console\"):\n        ip = gr.Textbox(label=\"User IP Address\")\n        gr.Interface(\n            lambda cmd: subprocess.run([cmd], capture_output=True, shell=True, check=False)\n            .stdout.decode(\"utf-8\")\n            .strip(),\n            \"text\",\n            \"text\",\n        )\n\n    def get_ip(request: gr.Request):\n        return request.client.host\n\n    demo.load(get_ip, None, ip)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing UniSpeech-SAT Speaker Verification with Gradio Interface\nDESCRIPTION: This code implements the speaker verification functionality using UniSpeech-SAT and X-Vectors, and creates a Gradio interface for the demo. It includes audio processing, model inference, and similarity calculation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unispeech-speaker-verification/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\nfrom torchaudio.sox_effects import apply_effects_file\nfrom transformers import AutoFeatureExtractor, AutoModelForAudioXVector\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nSTYLE = \"\"\"\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" integrity=\"sha256-YvdLHPgkqJ8DVUxjjnGVlMMJtNimJ6dYkowFFvp4kKs=\" crossorigin=\"anonymous\">\n\"\"\"\nOUTPUT_OK = (\n    STYLE\n    + \"\"\"\n    <div class=\"container\">\n        <div class=\"row\"><h1 style=\"text-align: center\">The speakers are</h1></div>\n        <div class=\"row\"><h1 class=\"display-1 text-success\" style=\"text-align: center\">{:.1f}%</h1></div>\n        <div class=\"row\"><h1 style=\"text-align: center\">similar</h1></div>\n        <div class=\"row\"><h1 class=\"text-success\" style=\"text-align: center\">Welcome, human!</h1></div>\n        <div class=\"row\"><small style=\"text-align: center\">(You must get at least 85% to be considered the same person)</small><div class=\"row\">\n    </div>\n\"\"\"\n)\nOUTPUT_FAIL = (\n    STYLE\n    + \"\"\"\n    <div class=\"container\">\n        <div class=\"row\"><h1 style=\"text-align: center\">The speakers are</h1></div>\n        <div class=\"row\"><h1 class=\"display-1 text-danger\" style=\"text-align: center\">{:.1f}%</h1></div>\n        <div class=\"row\"><h1 style=\"text-align: center\">similar</h1></div>\n        <div class=\"row\"><h1 class=\"text-danger\" style=\"text-align: center\">You shall not pass!</h1></div>\n        <div class=\"row\"><small style=\"text-align: center\">(You must get at least 85% to be considered the same person)</small><div class=\"row\">\n    </div>\n\"\"\"\n)\n\nEFFECTS = [\n    [\"remix\", \"-\"],\n    [\"channels\", \"1\"],\n    [\"rate\", \"16000\"],\n    [\"gain\", \"-1.0\"],\n    [\"silence\", \"1\", \"0.1\", \"0.1%\", \"-1\", \"0.1\", \"0.1%\"],\n    [\"trim\", \"0\", \"10\"],\n]\n\nTHRESHOLD = 0.85\n\nmodel_name = \"microsoft/unispeech-sat-base-plus-sv\"\nfeature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\nmodel = AutoModelForAudioXVector.from_pretrained(model_name).to(device)\ncosine_sim = torch.nn.CosineSimilarity(dim=-1)\n\ndef similarity_fn(path1, path2):\n    if not (path1 and path2):\n        return '<b style=\"color:red\">ERROR: Please record audio for *both* speakers!</b>'\n    wav1, _ = apply_effects_file(path1, EFFECTS)\n    wav2, _ = apply_effects_file(path2, EFFECTS)\n    print(wav1.shape, wav2.shape)\n\n    input1 = feature_extractor(wav1.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n    input2 = feature_extractor(wav2.squeeze(0), return_tensors=\"pt\", sampling_rate=16000).input_values.to(device)\n\n    with torch.no_grad():\n        emb1 = model(input1).embeddings\n        emb2 = model(input2).embeddings\n    emb1 = torch.nn.functional.normalize(emb1, dim=-1).cpu()\n    emb2 = torch.nn.functional.normalize(emb2, dim=-1).cpu()\n    similarity = cosine_sim(emb1, emb2).numpy()[0]\n\n    if similarity >= THRESHOLD:\n        output = OUTPUT_OK.format(similarity * 100)\n    else:\n        output = OUTPUT_FAIL.format(similarity * 100)\n\n    return output\n\ninputs = [\n    gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speaker #1\"),\n    gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speaker #2\"),\n]\noutput = gr.HTML(label=\"\")\n\ndescription = (\n    \"This demo will compare two speech samples and determine if they are from the same speaker. \"\n    \"Try it with your own voice!\"\n)\narticle = (\n    \"<p style='text-align: center'>\"\n    \"<a href='https://huggingface.co/microsoft/unispeech-sat-large-sv' target='_blank'>🎙️ Learn more about UniSpeech-SAT</a> | \"\n    \"<a href='https://arxiv.org/abs/2110.05752' target='_blank'>📚 UniSpeech-SAT paper</a> | \"\n    \"<a href='https://www.danielpovey.com/files/2018_icassp_xvectors.pdf' target='_blank'>📚 X-Vector paper</a>\"\n    \"</p>\"\n)\nexamples = [\n    [\"samples/cate_blanch.mp3\", \"samples/cate_blanch_2.mp3\"],\n    [\"samples/cate_blanch.mp3\", \"samples/cate_blanch_3.mp3\"],\n    [\"samples/cate_blanch_2.mp3\", \"samples/cate_blanch_3.mp3\"],\n    [\"samples/heath_ledger.mp3\", \"samples/heath_ledger_2.mp3\"],\n    [\"samples/cate_blanch.mp3\", \"samples/kirsten_dunst.wav\"],\n]\n\ndemo = gr.Interface(\n    fn=similarity_fn,\n    inputs=inputs,\n    outputs=output,\n    title=\"Voice Authentication with UniSpeech-SAT + X-Vectors\",\n    description=description,\n    article=article,\n    flagging_mode=\"never\",\n    live=False,\n    examples=examples,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_random_slider/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Line Plot with Zoom Functionality\nDESCRIPTION: Creates a Gradio Blocks application with an interactive line plot that allows users to select regions to zoom in and double-click to reset the view. The plot displays height versus weight data from the imported dataset.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    plt = gr.LinePlot(df, x=\"weight\", y=\"height\")\n\n    def select_region(selection: gr.SelectData):\n        min_w, max_w = selection.index\n        return gr.LinePlot(x_lim=(min_w, max_w)) # type: ignore\n\n    plt.select(select_region, None, plt)\n    plt.double_click(lambda: gr.LinePlot(x_lim=None), None, plt)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Upload and Download Functionality with Gradio\nDESCRIPTION: Creates a Gradio application that allows users to upload a file and then download it. The app uses UploadButton and DownloadButton components, and toggles their visibility based on user actions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_and_download/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nimport gradio as gr\n\ndef upload_file(filepath):\n    name = Path(filepath).name\n    return [gr.UploadButton(visible=False), gr.DownloadButton(label=f\"Download {name}\", value=filepath, visible=True)]\n\ndef download_file():\n    return [gr.UploadButton(visible=True), gr.DownloadButton(visible=False)]\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"First upload a file and and then you'll be able download it (but only once!)\")\n    with gr.Row():\n        u = gr.UploadButton(\"Upload a file\", file_count=\"single\")\n        d = gr.DownloadButton(\"Download the file\", visible=False)\n\n    u.upload(upload_file, u, [u, d])\n    d.click(download_file, None, [u, d])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Tone Generation and Gradio Interface in Python\nDESCRIPTION: This code defines a function to generate audio tones based on musical parameters and creates a Gradio interface for user interaction. It uses NumPy for audio signal generation and Gradio for the web interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_tone/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\nnotes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\ndef generate_tone(note, octave, duration):\n    sr = 48000\n    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n    duration = int(duration)\n    audio = np.linspace(0, duration, duration * sr)\n    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n    return sr, audio\n\ndemo = gr.Interface(\n    generate_tone,\n    [\n        gr.Dropdown(notes, type=\"index\"),\n        gr.Slider(4, 6, step=1),\n        gr.Textbox(value=\"1\", label=\"Duration in seconds\"),\n    ],\n    \"audio\",\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Scatter Plots with Gradio\nDESCRIPTION: Builds a complete Gradio application that displays interactive scatter plots for either the cars or iris dataset. The code loads data, defines a function to render appropriate scatter plots based on user selection, and creates a UI with a dropdown menu for dataset selection.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatter_plot/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom vega_datasets import data\n\ncars = data.cars()\niris = data.iris()\n\n# # Or generate your own fake data\n\n# import pandas as pd\n# import random\n\n# cars_data = {\n#     \"Name\": [\"car name \" + f\" {int(i/10)}\" for i in range(400)],\n#     \"Miles_per_Gallon\": [random.randint(10, 30) for _ in range(400)],\n#     \"Origin\": [random.choice([\"USA\", \"Europe\", \"Japan\"]) for _ in range(400)],\n#     \"Horsepower\": [random.randint(50, 250) for _ in range(400)],\n# }\n\n# iris_data = {\n#     \"petalWidth\": [round(random.uniform(0, 2.5), 2) for _ in range(150)],\n#     \"petalLength\": [round(random.uniform(0, 7), 2) for _ in range(150)],\n#     \"species\": [\n#         random.choice([\"setosa\", \"versicolor\", \"virginica\"]) for _ in range(150)\n#     ],\n# }\n\n# cars = pd.DataFrame(cars_data)\n# iris = pd.DataFrame(iris_data)\n\ndef scatter_plot_fn(dataset):\n    if dataset == \"iris\":\n        return gr.ScatterPlot(\n            value=iris,\n            x=\"petalWidth\",\n            y=\"petalLength\",\n            color=\"species\",\n            title=\"Iris Dataset\",\n            color_legend_title=\"Species\",\n            x_title=\"Petal Width\",\n            y_title=\"Petal Length\",\n            tooltip=[\"petalWidth\", \"petalLength\", \"species\"],\n            caption=\"\",\n        )\n    else:\n        return gr.ScatterPlot(\n            value=cars,\n            x=\"Horsepower\",\n            y=\"Miles_per_Gallon\",\n            color=\"Origin\",\n            tooltip=[\"Name\"],\n            title=\"Car Data\",\n            y_title=\"Miles per Gallon\",\n            color_legend_title=\"Origin of Car\",\n            caption=\"MPG vs Horsepower of various cars\",\n        )\n\nwith gr.Blocks() as scatter_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(choices=[\"cars\", \"iris\"], value=\"cars\")\n        with gr.Column():\n            plot = gr.ScatterPlot()\n    dataset.change(scatter_plot_fn, inputs=dataset, outputs=plot)\n    scatter_plot.load(fn=scatter_plot_fn, inputs=dataset, outputs=plot)\n\nif __name__ == \"__main__\":\n    scatter_plot.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multimodal Chat Interface\nDESCRIPTION: Creates a chat interface using Gradio that handles both text messages and file uploads. The interface saves chat history and responds with a message indicating the text content and number of files uploaded.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_save_history/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef echo_multimodal(message, history):\n    response = \"You wrote: '\" + message[\"text\"] + \"' and uploaded: \" + str(len(message[\"files\"])) + \" files\"\n    return response\n\ndemo = gr.ChatInterface(\n    echo_multimodal,\n    type=\"messages\",\n    multimodal=True,\n    textbox=gr.MultimodalTextbox(file_count=\"multiple\"),\n    save_history=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Thinking Chat Interface with Gradio\nDESCRIPTION: Creates a chat interface that simulates an LLM's thinking process by showing progressive thoughts before delivering a final answer. Uses Gradio's ChatInterface and ChatMessage components to display incremental thinking steps with metadata tracking.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_thoughts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\nsleep_time = 0.5\n\ndef simulate_thinking_chat(message, history):\n    start_time = time.time()\n    response = ChatMessage(\n        content=\"\",\n        metadata={\"title\": \"_Thinking_ step-by-step\", \"id\": 0, \"status\": \"pending\"}\n    )\n    yield response\n\n    thoughts = [\n        \"First, I need to understand the core aspects of the query...\",\n        \"Now, considering the broader context and implications...\",\n        \"Analyzing potential approaches to formulate a comprehensive answer...\",\n        \"Finally, structuring the response for clarity and completeness...\"\n    ]\n\n    accumulated_thoughts = \"\"\n    for thought in thoughts:\n        time.sleep(sleep_time)\n        accumulated_thoughts += f\"- {thought}\\n\\n\"\n        response.content = accumulated_thoughts.strip()\n        yield response\n\n    response.metadata[\"status\"] = \"done\"\n    response.metadata[\"duration\"] = time.time() - start_time\n    yield response\n\n    response = [\n        response,\n        ChatMessage(\n            content=\"Based on my thoughts and analysis above, my response is: This dummy repro shows how thoughts of a thinking LLM can be progressively shown before providing its final answer.\"\n        )\n    ]\n    yield response\n\n\ndemo = gr.ChatInterface(\n    simulate_thinking_chat,\n    title=\"Thinking LLM Chat Interface 🤔\",\n    type=\"messages\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Loading Authenticated Hugging Face Model and Launching Gradio App (Python)\nDESCRIPTION: This Python script imports the Gradio library and uses `gr.load` to load the 'meta-llama/Meta-Llama-3-8B-Instruct' model from Hugging Face models (`src='models'`). It requires a Hugging Face PRO token for access, indicated by `accept_token=True`. The script then launches the Gradio demo interface using `demo.launch()` when executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/load_model_with_token/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n# This demo requires a Hugging Face PRO token.\ndemo = gr.load(\"meta-llama/Meta-Llama-3-8B-Instruct\", src=\"models\", accept_token=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Building a Gradio Interface for Map Filtering in Python\nDESCRIPTION: This snippet constructs a Gradio application using `gr.Blocks`. It sets up input components: two `gr.Number` inputs for minimum and maximum price, and a `gr.CheckboxGroup` for selecting boroughs. An output `gr.Plot` component is defined to display the map. A `gr.Button` triggers updates. The `demo.load` method calls the `filter_map` function when the app loads, and `btn.click` links the button click event to the same function, passing the input values and updating the map plot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/plot-component-for-maps.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n```\n\n----------------------------------------\n\nTITLE: Implementing Nested Thoughts Chatbot\nDESCRIPTION: Creates a Gradio chatbot interface that demonstrates nested conversation threads with simulated API calls and error handling. The implementation includes timed responses, metadata for message threading, and a visual hierarchy of thought processes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_nested_thoughts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\nsleep_time = 0.1\nlong_sleep_time = 1\n\ndef generate_response(history):\n    history.append(\n        ChatMessage(\n            role=\"user\", content=\"What is the weather in San Francisco right now?\"\n        )\n    )\n    yield history\n    time.sleep(sleep_time)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"In order to find the current weather in San Francisco, I will need to use my weather tool.\",\n        )\n    )\n    yield history\n    time.sleep(sleep_time)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"\",\n            metadata={\"title\": \"Gathering Weather Websites\", \"id\": 1},\n        )\n    )\n    yield history\n    time.sleep(long_sleep_time)\n    history[-1].content = \"Will check: weather.com and sunny.org\"\n    yield history\n    time.sleep(sleep_time)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"Received weather from weather.com.\",\n            metadata={\"title\": \"API Success ✅\", \"parent_id\": 1, \"id\": 2},\n        )\n    )\n    yield history\n    time.sleep(sleep_time)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"API Error when connecting to sunny.org.\",\n            metadata={\"title\": \"API Error 💥 \", \"parent_id\": 1, \"id\": 3},\n        )\n    )\n    yield history\n    time.sleep(sleep_time)\n\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"I will try yet again\",\n            metadata={\"title\": \"I will try again\", \"id\": 4, \"parent_id\": 3},\n        )\n    )\n    yield history\n\n    time.sleep(sleep_time)\n    history.append(\n        ChatMessage(\n            role=\"assistant\",\n            content=\"Failed again\",\n            metadata={\"title\": \"Failed again\", \"id\": 6, \"parent_id\": 4},\n        )\n    )\n    yield history\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(type=\"messages\", height=500, show_copy_button=True)\n    demo.load(generate_response, chatbot, chatbot)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Live Gradio Updates with gr.on and 'change' Events in Python\nDESCRIPTION: Demonstrates creating 'live' updates using `gr.on` in Python by binding to the `change` events of input components. When no specific triggers are provided to `gr.on`, it automatically listens to the `change` event of all applicable input components (like Textbox), triggering the function (`greet`) on every modification.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n$code_on_listener_live\n```\n\n----------------------------------------\n\nTITLE: Displaying User-Specific Content After Authentication in Gradio Python\nDESCRIPTION: Shows how to personalize content based on the authenticated user in a Gradio `Blocks` app. It accesses the logged-in username via the `gr.Request` object (retrieved by type-hinting in the `update_message` function) and updates a Markdown component using `demo.load`. The app is launched with multiple allowed username/password pairs provided as a list of tuples to the `auth` parameter. Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef update_message(request: gr.Request):\n    return f\"Welcome, {request.username}\"\n\nwith gr.Blocks() as demo:\n    m = gr.Markdown()\n    demo.load(update_message, None, m)\n\ndemo.launch(auth=[(\"Abubakar\", \"Abubakar\"), (\"Ali\", \"Ali\")])\n```\n\n----------------------------------------\n\nTITLE: Building a Gradio App Docker Image with Dockerfile\nDESCRIPTION: This Dockerfile configures the container environment for running the provided Gradio app. It uses the official python:3.10-slim image as a base, sets the working directory, copies the application source code, installs the gradio library via pip, exposes port 7860 (the Gradio default), and sets GRADIO_SERVER_NAME to '0.0.0.0' for external access. The CMD directive launches the Python app. All requirements should be installed at build time for production use, and port 7860 must be mapped to access the app externally.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/deploying-gradio-with-docker.md#2025-04-23_snippet_1\n\nLANGUAGE: dockerfile\nCODE:\n```\nFROM python:3.10-slim\\n\\nWORKDIR /usr/src/app\\nCOPY . .\\nRUN pip install --no-cache-dir gradio\\nEXPOSE 7860\\nENV GRADIO_SERVER_NAME=\\\"0.0.0.0\\\"\\n\\nCMD [\\\"python\\\", \\\"app.py\\\"]\n```\n\n----------------------------------------\n\nTITLE: Processing Audio Input in Python with NumPy\nDESCRIPTION: Function to process incoming audio chunks, detect speech pauses, and manage recording state. Uses NumPy for audio stream concatenation and implements pause detection logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/04_conversational-chatbot.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nfrom utils import determine_pause\n\ndef process_audio(audio: tuple, state: AppState):\n    if state.stream is None:\n        state.stream = audio[1]\n        state.sampling_rate = audio[0]\n    else:\n        state.stream = np.concatenate((state.stream, audio[1]))\n\n    pause_detected = determine_pause(state.stream, state.sampling_rate, state)\n    state.pause_detected = pause_detected\n\n    if state.pause_detected and state.started_talking:\n        return gr.Audio(recording=False), state\n    return None, state\n```\n\n----------------------------------------\n\nTITLE: Initializing NER Pipeline with Transformers in Python\nDESCRIPTION: This snippet initializes a Hugging Face transformers pipeline for named-entity recognition and demonstrates querying it with a sample sentence. It requires the 'transformers' Python package. The created 'ner_pipeline' can then be used to process text and obtain lists of entity dictionaries, each containing information such as entity label, word, and character offsets. The output of this pipeline is suited for integration with Gradio's HighlightedText component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/named-entity-recognition.md#2025-04-23_snippet_0\n\nLANGUAGE: py\nCODE:\n```\nfrom transformers import pipeline\\nner_pipeline = pipeline(\"ner\")\\nner_pipeline(\"Does Chicago have any Pakistani restaurants\")\n```\n\n----------------------------------------\n\nTITLE: Making a Prediction with a File URL\nDESCRIPTION: Shows how to make a prediction using an audio file URL as input to the Whisper speech recognition model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/whisper\")\nclient.predict(\"https://audio-samples.github.io/samples/mp3/blizzard_unconditional/sample-0.mp3\")\n\n>> \"My thought I have nobody by a beauty and will as you poured. Mr. Rochester is serve in that so don't find simpus, and devoted abode, to at might in a r—\"\n```\n\n----------------------------------------\n\nTITLE: Implementing a Gradio Chatbot with SambaNova API in Python\nDESCRIPTION: This Python script creates a general-purpose chatbot using Gradio and the SambaNova API. It first imports required libraries (`os`, `gradio`, `openai`). It retrieves the SambaNova API key from the `SAMBANOVA_API_KEY` environment variable. An OpenAI client is initialized, configured to use the SambaNova API endpoint and the retrieved key. The `predict` function handles the chat logic: it appends the user's message to the history and uses the client to stream responses from the `Meta-Llama-3.1-70B-Instruct-8k` model via the SambaNova API. Finally, it creates a Gradio `ChatInterface` using the `predict` function and launches the web application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_sambanova/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple general-purpose chatbot built on top of SambaNova API. \n# Before running this, make sure you have exported your SambaNova API key as an environment variable:\n# export SAMBANOVA_API_KEY=\"your-sambanova-api-key\"\n\nimport os\nimport gradio as gr\nfrom openai import OpenAI\n\napi_key = os.getenv(\"SAMBANOVA_API_KEY\")\n\nclient = OpenAI(\n    base_url=\"https://api.sambanova.ai/v1/\",\n    api_key=api_key,\n)\n\ndef predict(message, history):\n    history.append({\"role\": \"user\", \"content\": message})\n    stream = client.chat.completions.create(messages=history, model=\"Meta-Llama-3.1-70B-Instruct-8k\", stream=True)\n    chunks = []\n    for chunk in stream:\n        chunks.append(chunk.choices[0].delta.content or \"\")\n        yield \"\".join(chunks)\n\ndemo = gr.ChatInterface(predict, type=\"messages\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple State-Managed Shopping Cart UI with Gradio in Python\nDESCRIPTION: This code builds an interactive Gradio app where users can add selected items to a shopping cart and see the cart size in real time. It defines a 'State' to track cart contents, uses a 'CheckboxGroup' for item selection, and a 'Button' to trigger addition of selected items. The 'cart.change' handler updates the displayed count whenever the cart changes. Dependencies include Gradio version 3.0 or newer. Inputs are item selections; outputs are cart state and its size. Must be run as a main module.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/simple_state/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    cart = gr.State([])\n    items_to_add = gr.CheckboxGroup([\"Cereal\", \"Milk\", \"Orange Juice\", \"Water\"])\n\n    def add_items(new_items, previous_cart):\n        cart = previous_cart + new_items\n        return cart\n\n    gr.Button(\"Add Items\").click(add_items, [items_to_add, cart], cart)\n\n    cart_size = gr.Number(label=\"Cart Size\")\n    cart.change(lambda cart: len(cart), cart, cart_size)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Reading Private Google Sheet Data with gspread and Pandas - Python\nDESCRIPTION: This Python snippet uses the gspread library to authenticate with a Google Sheets service account and fetch the contents of a private Google Sheet as a pandas DataFrame. It initializes the gspread client with your credentials JSON, opens the sheet by URL, retrieves all values, and constructs the DataFrame. Requires 'gspread', 'pandas', and a service account JSON file. The get_data() function outputs a DataFrame. You must ensure the service account has appropriate sheet access, and the file path and sheet URL must be correctly set.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport gspread\nimport pandas as pd\n\n# Authenticate with Google and get the sheet\nURL = 'https://docs.google.com/spreadsheets/d/1_91Vps76SKOdDQ8cFxZQdgjTJiz23375sAT7vPvaj4k/edit#gid=0'\n\ngc = gspread.service_account(\"path/to/key.json\")\nsh = gc.open_by_url(URL)\nworksheet = sh.sheet1\n\ndef get_data():\n    values = worksheet.get_all_values()\n    df = pd.DataFrame(values[1:], columns=values[0])\n    return df\n\n```\n\n----------------------------------------\n\nTITLE: Defining ChatMessage Schema\nDESCRIPTION: Dataclass definition for ChatMessage type used in Gradio's chatbot component, including metadata and options structures.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass ChatMessage:\n    content: str | Component\n    role: Literal[\"user\", \"assistant\"]\n    metadata: MetadataDict = None\n    options: list[OptionDict] = None\n\nclass MetadataDict(TypedDict):\n    title: NotRequired[str]\n    id: NotRequired[int | str]\n    parent_id: NotRequired[int | str]\n    log: NotRequired[str]\n    duration: NotRequired[float]\n    status: NotRequired[Literal[\"pending\", \"done\"]]\n\nclass OptionDict(TypedDict):\n    label: NotRequired[str]\n    value: str\n```\n\n----------------------------------------\n\nTITLE: Implementing Webcam Image Processing Interface\nDESCRIPTION: Creates a Gradio interface that captures webcam input and processes images by flipping them vertically using NumPy. The interface takes an image input from webcam and returns the processed image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_webcam/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\n\nimport gradio as gr\n\ndef snap(image):\n    return np.flipud(image)\n\ndemo = gr.Interface(snap, gr.Image(sources=[\"webcam\"]), \"image\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Cancel Events Demo\nDESCRIPTION: Creates a Gradio interface with multiple components demonstrating cancellable operations. Features include a fake diffusion process, long-running calculations, and various ways to trigger cancellation events. The interface uses queuing and includes webcam inputs with cancel triggers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/cancel_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport gradio as gr\nimport atexit\nimport pathlib\n\nlog_file = pathlib.Path(__file__).parent / \"cancel_events_output_log.txt\"\n\ndef fake_diffusion(steps):\n    log_file.write_text(\"\")\n    for i in range(steps):\n        print(f\"Current step: {i}\")\n        with log_file.open(\"a\") as f:\n            f.write(f\"Current step: {i}\\n\")\n        time.sleep(0.2)\n        yield str(i)\n\ndef long_prediction(*args, **kwargs):\n    time.sleep(4)\n    return 42, 42\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            n = gr.Slider(1, 10, value=9, step=1, label=\"Number Steps\")\n            run = gr.Button(value=\"Start Iterating\")\n            output = gr.Textbox(label=\"Iterative Output\")\n            stop = gr.Button(value=\"Stop Iterating\")\n        with gr.Column():\n            textbox = gr.Textbox(label=\"Prompt\")\n            loading_box = gr.Textbox(label=\"Loading indicator for expensive calculation\")\n            loading_box2 = gr.Textbox(label=\"Loading indicator for expensive calculation\")\n            prediction = gr.Number(label=\"Expensive Calculation\")\n            prediction2 = gr.Number(label=\"Expensive Calculation\")\n            run_pred = gr.Button(value=\"Run Expensive Calculation\")\n        with gr.Column():\n            cancel_on_change = gr.Textbox(\n                label=\"Cancel Iteration and Expensive Calculation on Change\"\n            )\n            cancel_on_submit = gr.Textbox(\n                label=\"Cancel Iteration and Expensive Calculation on Submit\"\n            )\n            echo = gr.Textbox(label=\"Echo\")\n    with gr.Row():\n        with gr.Column():\n            image = gr.Image(\n                sources=[\"webcam\"], label=\"Cancel on clear\", interactive=True\n            )\n        with gr.Column():\n            video = gr.Video(\n                sources=[\"webcam\"], label=\"Cancel on start recording\", interactive=True\n            )\n\n    click_event = run.click(fake_diffusion, n, output)\n    stop.click(fn=None, inputs=None, outputs=None, cancels=[click_event])\n    pred_event = run_pred.click(\n        fn=long_prediction, inputs=[textbox], outputs=[prediction, prediction2], show_progress_on=[loading_box, loading_box2]\n    )\n\n    cancel_on_change.change(None, None, None, cancels=[click_event, pred_event])\n    cancel_on_submit.submit(\n        lambda s: s, cancel_on_submit, echo, cancels=[click_event, pred_event]\n    )\n    image.clear(None, None, None, cancels=[click_event, pred_event])\n    video.start_recording(None, None, None, cancels=[click_event, pred_event])\n\n    demo.queue(max_size=20)\n    atexit.register(lambda: log_file.unlink())\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Fraud Detection Interface with Gradio in Python\nDESCRIPTION: This snippet defines the fraud detection function and creates a Gradio interface for it. The function simulates fraud detection based on card activity and user inputs. The interface includes checkboxes for category selection, a sensitivity slider, and displays results as a dataframe and label.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fraud_detector/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport os\nimport gradio as gr\n\ndef fraud_detector(card_activity, categories, sensitivity):\n    activity_range = random.randint(0, 100)\n    drop_columns = [\n        column for column in [\"retail\", \"food\", \"other\"] if column not in categories\n    ]\n    if len(drop_columns):\n        card_activity.drop(columns=drop_columns, inplace=True)\n    return (\n        card_activity,\n        card_activity,\n        {\"fraud\": activity_range / 100.0, \"not fraud\": 1 - activity_range / 100.0},\n    )\n\ndemo = gr.Interface(\n    fraud_detector,\n    [\n        gr.CheckboxGroup(\n            [\"retail\", \"food\", \"other\"], value=[\"retail\", \"food\", \"other\"]\n        ),\n        gr.Slider(1, 3),\n    ],\n    [\n        \"dataframe\",\n        gr.Label(label=\"Fraud Level\"),\n    ],\n    examples=[\n        [os.path.join(os.path.abspath(''), \"fraud.csv\"), [\"retail\", \"food\", \"other\"], 1.0],\n    ],\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Real-time Audio Streaming with Gradio\nDESCRIPTION: This Python script utilizes the Gradio library to create an interactive web application for streaming audio. It defines a function `add_to_stream` which takes the current audio chunk and the accumulated stream, concatenates them using NumPy after a 1-second delay, and returns the updated stream. A Gradio `Blocks` interface is constructed with an `Audio` input configured for microphone streaming, an `Audio` output to display the concatenated stream, a `State` variable to hold the stream data between calls, and a 'Clear' button to reset the process. The `inp.stream()` method connects the microphone input to the processing function, updating the output and state continuously. The `clear.click()` method resets the input, output, and stream state. The demo is launched using `demo.launch()` when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport time\n\ndef add_to_stream(audio, instream):\n    time.sleep(1)\n    if audio is None:\n        return gr.Audio(), instream\n    if instream is None:\n        ret = audio\n    else:\n        ret = (audio[0], np.concatenate((instream[1], audio[1])))\n    return ret, ret\n\nwith gr.Blocks() as demo:\n    inp = gr.Audio(sources=[\"microphone\"])\n    out = gr.Audio()\n    stream = gr.State()\n    clear = gr.Button(\"Clear\")\n\n    inp.stream(add_to_stream, [inp, stream], [out, stream])\n    clear.click(lambda: [None, None, None], None, [inp, out, stream])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Dynamic Character Splitter with Gradio in Python\nDESCRIPTION: This Python script defines and launches a Gradio interface using `gr.Blocks`. It features an input Textbox (`input_text`). The `show_split` function, decorated with `@gr.render(inputs=input_text)`, is triggered whenever the input text changes. This function dynamically generates UI components: if the input `text` is empty, it displays a Markdown message; otherwise, it iterates through the input `text` and creates a new `gr.Textbox` for each character. The `demo.launch()` method starts the Gradio web server, making the application accessible.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_split_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    input_text = gr.Textbox(label=\"input\")\n\n    @gr.render(inputs=input_text)\n    def show_split(text):\n        if len(text) == 0:\n            gr.Markdown(\"## No Input Provided\")\n        else:\n            for letter in text:\n                gr.Textbox(letter)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Custom CSS\nDESCRIPTION: Creates a Gradio interface with custom CSS styling including animations, responsive design, custom fonts, and dark mode support. The interface contains markdown elements with custom styling and animations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/custom_css/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ncss = \"\"\"\n/* CSSKeyframesRule for animation */\n@keyframes animation {\n    from {background-color: red;}\n    to {background-color: blue;}\n}\n\n.cool-col {\n    background-color: red;\n    animation-name: animation;\n    animation-duration: 4s;\n    animation-delay: 2s;\n    animation-iteration-count: infinite;\n    border-radius: 10px;\n    padding: 20px;\n}\n\n/* CSSStyleRule */\n.markdown {\n    background-color: lightblue;\n    padding: 20px;\n}\n\n.markdown p {\n    color: royalblue;\n}\n\n/* CSSMediaRule */\n@media screen and (max-width: 600px) {\n    .markdown {\n        background: blue;\n    }\n    .markdown p {\n        color: lightblue;\n    }\n}\n\n.dark .markdown {\n    background: pink;\n}\n\n.darktest h3 {\n    color: black;\n}\n\n.dark .darktest h3 {\n    color: yellow;\n}\n\n/* CSSFontFaceRule */\n@font-face {\n    font-family: \\\"test-font\\\";\n    src: url(\\\"https://mdn.github.io/css-examples/web-fonts/VeraSeBd.ttf\\\") format(\\\"truetype\\\");\n}\n\n.cool-col {\n    font-family: \\\"test-font\\\";\n}\n\n/* CSSImportRule */\n@import url(\\\"https://fonts.googleapis.com/css2?family=Protest+Riot&display=swap\\\");\n\n.markdown {\n  font-family: \\\"Protest Riot\\\", sans-serif;\n}\n\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=\"cool-col\"):\n        gr.Markdown(\"### Gradio Demo with Custom CSS\", elem_classes=\"darktest\")\n        gr.Markdown(\n            elem_classes=\"markdown\",\n            value=\"Resize the browser window to see the CSS media query in action.\",\n        )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Progress Bars in Gradio (Python)\nDESCRIPTION: This code snippet demonstrates how to create and update a custom progress bar in a Gradio application. It shows both manual progress updates and automatic tracking using the tqdm library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/05_progress-bars.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef my_function(progress=gr.Progress()):\n    for i in range(20):\n        time.sleep(0.1)\n        progress(i/20)\n    return \"Done!\"\n\nwith gr.Blocks() as demo:\n    btn = gr.Button(\"Start Processing\")\n    output = gr.Textbox()\n    btn.click(my_function, outputs=output)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Editor Interface\nDESCRIPTION: Creates an interactive image editor interface using Gradio's Blocks API. Includes image editing capabilities with custom brush colors, file handling, and automated testing integration. The interface allows users to edit images and save the composite result.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_story/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom pathlib import Path\nimport subprocess\n\n\ndef predict(im):\n    path = str(Path(__file__).parent / \"output-image.png\")\n    with open(path, \"wb\") as f:\n        f.write(Path(im[\"composite\"]).read_bytes())\n    print(\"Writing to \", path)\n    return path\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            im = gr.ImageEditor(interactive=True, elem_id=\"image_editor\",\n                                canvas_size=(800, 600),\n                                brush=gr.Brush(colors=[\"#ff0000\", \"#00ff00\", \"#0000ff\"]),\n                                type=\"filepath\",\n                            value={\"background\": \"https://gradio-builds.s3.amazonaws.com/demo-files/ghepardo-primo-piano.jpg\",\n                                   \"layers\": [],\n                                   \"composite\": None})\n            get = gr.Button(\"Get\")\n\n        with gr.Column():\n            output = gr.Image(value=None, elem_id=\"output\")\n\n        get.click(predict, inputs=im, outputs=output)\n\nif __name__ == \"__main__\":\n    app, _, _ = demo.launch(prevent_thread_lock=True)\n    subprocess.call([\"node\", \"js/storybook/ie_automation.js\"])\n    demo.close()\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Character-by-Character ChatInterface in Gradio with Python\nDESCRIPTION: This snippet defines a streaming chatbot function that yields the entered message one character at a time for demonstration purposes, and creates a Gradio ChatInterface using this function. It provides a couple of example prompts, disables example caching, and specifies that message data is handled as a list of messages. The snippet ends with a conditional block that launches the interface, with expected input as user message strings and output as incremental responses, and assumes that the Gradio package is installed in the environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_examples/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef generate(\n    message: str,\n    chat_history: list[dict],\n):\n\n    output = \"\"\n    for character in message:\n        output += character\n        yield output\n\n\ndemo = gr.ChatInterface(\n    fn=generate,\n    examples=[\n        [\"Hey\"],\n        [\"Can you explain briefly to me what is the Python programming language?\"],\n    ],\n    cache_examples=False,\n    type=\"messages\",\n)\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing and Launching a Gradio Webcam Streaming App in Python\nDESCRIPTION: Defines a Python function `flip` that uses NumPy to vertically flip an image array. It then creates a Gradio `Interface` configured to take streaming input from a webcam (`gr.Image(sources=[\"webcam\"], streaming=True)`), apply the `flip` function, and display the resulting image (`\"image\"`). The `live=True` parameter enables real-time updates. Finally, it launches the Gradio demo application if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_frames/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef flip(im):\n    return np.flipud(im)\n\ndemo = gr.Interface(\n    flip,\n    gr.Image(sources=[\"webcam\"], streaming=True),\n    \"image\",\n    live=True\n)\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Building a Gradio Interface with Rapid Generation Demo\nDESCRIPTION: Creates a Gradio interface with a chatbot and number components that rapidly generate content and increment values. The interface uses chained events to simulate rapid generation when a button is clicked, demonstrating how to build complex event chains in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rapid_generation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(elem_id=\"chatbot\")\n\n    with gr.Row():\n        num1 = gr.Number(label=\"a\")\n        num2 = gr.Number(label=\"b\")\n    with gr.Row():\n        num3 = gr.Number(label=\"c\")\n        num4 = gr.Number(label=\"d\")\n\n    btn = gr.Button(\"Start\")\n\n    def add_user(history):\n        new_response = [\"\", None]\n        history.append(new_response)\n        for i in range(100):\n            new_response[0] += f\"{len(history)} \"\n            yield history\n\n    def add_bot(history):\n        last_response = history[-1]\n        last_response[1] = \"\"\n        for i in range(100):\n            last_response[1] += f\"{len(history)} \"\n            yield history\n\n    chat_evt = btn.click(add_user, chatbot, chatbot).then(add_bot, chatbot, chatbot)\n    for i in range(25):\n        chat_evt = chat_evt.then(add_user, chatbot, chatbot).then(add_bot, chatbot, chatbot)\n\n    increase = lambda x: x + 1\n\n    btn_evt = btn.click(increase, num1, num2).then(increase, num2, num1)\n    btn_evt2 = btn.click(increase, num3, num4).then(increase, num4, num3)\n    for i in range(25):\n        btn_evt = btn_evt.then(increase, num1, num2).then(increase, num2, num1)\n        btn_evt2 = btn_evt2.then(increase, num3, num4).then(increase, num4, num3)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring Text Generation Parameters for a Transformer Model in Python\nDESCRIPTION: Sets the text generation hyperparameters for a transformer model, including sampling settings, maximum length, temperature, top-k filtering, and n-gram repetition prevention. The model is then moved to the specified device.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n# set text-generation params under task_specific_params\nmodel.config.task_specific_params[\"text-generation\"] = {\n    \"do_sample\": True,\n    \"max_length\": 50,\n    \"temperature\": 0.7,\n    \"top_k\": 50,\n    \"no_repeat_ngram_size\": 2,\n}\nmodel = model.to(device)\n```\n\n----------------------------------------\n\nTITLE: Implementing Event Attachment Logic in Application Class Python\nDESCRIPTION: Defines the `_attach_event` method for the `Application` class. It aggregates all Gradio blocks from all child layouts into a single `block_dict` using `child.global_children_dict`. Then, within the main application block's context (`with self.app:`), it iterates through the children again, calling each child's `attach_event` method (passing the `block_dict`) to set up event listeners. The `with` context is crucial for triggering Gradio's internal event setup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n    # other Application implementations\n\n    def _attach_event(self):\n        block_dict: Dict[str, Block] = {}\n\n        for child in self.children:\n            block_dict.update(child.global_children_dict)\n\n        with self.app:\n            for child in self.children:\n                try:\n                    child.attach_event(block_dict=block_dict)\n                except NotImplementedError:\n                    print(f\"{child.name}'s attach_event is not implemented\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Interface for GPT-2 Text Generation\nDESCRIPTION: This code sets up a Gradio interface for text generation using the GPT-2 model. It defines a function to generate text based on a given prompt, creates a Gradio interface with input and output text boxes, and launches the demo. The generated text is limited to 30 tokens and returns 5 sequences, of which the first one is displayed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unified_demo_text_generation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\n\ngenerator = pipeline('text-generation', model = 'gpt2')\n\ndef generate_text(text_prompt):\n  response = generator(text_prompt, max_length = 30, num_return_sequences=5)\n  return response[0]['generated_text']  # type: ignore\n\ntextbox = gr.Textbox()\n\ndemo = gr.Interface(generate_text, textbox, textbox)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Color Generator with Gradio Interface in Python\nDESCRIPTION: This code snippet defines functions for color conversion, random color generation, and creates a Gradio interface for a color generator application. It allows users to generate random light or dark colors and displays them in various formats.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_generator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport cv2\nimport numpy as np\nimport random\n\n# Convert decimal color to hexadecimal color\ndef RGB_to_Hex(rgb):\n    color = \"#\"\n    for i in rgb:\n        num = int(i)\n        color += str(hex(num))[-2:].replace(\"x\", \"0\").upper()\n    return color\n\n# Randomly generate light or dark colors\ndef random_color(is_light=True):\n    return (\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n        random.randint(0, 127) + int(is_light) * 128,\n    )\n\ndef switch_color(color_style):\n    is_light = color_style == \"light\"\n    back_color_ = random_color(is_light)  # Randomly generate colors\n    back_color = RGB_to_Hex(back_color_)  # Convert to hexadecimal\n\n    # Draw color pictures.\n    w, h = 50, 50\n    img = np.zeros((h, w, 3), np.uint8)\n    cv2.rectangle(img, (0, 0), (w, h), back_color_, thickness=-1)\n\n    return back_color, back_color, img\n\ninputs = [gr.Radio([\"light\", \"dark\"], value=\"light\")]\n\noutputs = [\n    gr.ColorPicker(label=\"color\"),\n    gr.Textbox(label=\"hexadecimal color\"),\n    gr.Image(type=\"numpy\", label=\"color picture\"),\n]\n\ntitle = \"Color Generator\"\ndescription = (\n    \"Click the Submit button, and a dark or light color will be randomly generated.\"\n)\n\ndemo = gr.Interface(\n    fn=switch_color,\n    inputs=inputs,\n    outputs=outputs,\n    title=title,\n    description=description,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building a Gradio Interface for Text Generation Explanation in Python\nDESCRIPTION: Creates a Gradio interface with blocks for starting experiments, inputting text, and viewing SHAP explanations. The interface connects UI components to the experiment creation and prediction functions for interactive use.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    start_experiment_btn = gr.Button(\"Start New Experiment\")\n    experiment_status = gr.Markdown()\n\n    # Log a message to the Experiment to provide more context\n    experiment_message = gr.Textbox(label=\"Experiment Message\")\n    experiment = gr.State()\n\n    input_text = gr.Textbox(label=\"Input Text\", lines=5, interactive=True)\n    submit_btn = gr.Button(\"Submit\")\n\n    output = gr.HTML(interactive=True)\n\n    start_experiment_btn.click(\n        start_experiment, outputs=[experiment, experiment_status]\n    )\n    submit_btn.click(\n        predict, inputs=[input_text, experiment, experiment_message], outputs=[output]\n    )\n```\n\n----------------------------------------\n\nTITLE: Implementing File Upload with Gradio UploadButton\nDESCRIPTION: This code creates a Gradio interface with an UploadButton component. It defines a function to handle file uploads, sets up the interface components, and launches the demo. The UploadButton is configured to accept multiple image or video files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/uploadbutton_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef upload_file(files):\n    file_paths = [file.name for file in files]\n    return file_paths\n\nwith gr.Blocks() as demo:\n    file_output = gr.File()\n    upload_button = gr.UploadButton(\"Click to Upload an Image or Video File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\n    upload_button.upload(upload_file, upload_button, file_output)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Pitch Detection and Gradio Interface in Python\nDESCRIPTION: Defines the core Python logic for audio pitch detection and sets up the Gradio interface. It imports necessary modules, defines musical constants (A4, C0, note names), implements a `get_pitch` function to map frequency to a note name, and a `main_note` function that takes audio data, performs FFT using `scipy.fftpack.fft`, calculates the relative volume for each detected pitch, and returns a dictionary mapping pitches to their normalized volume. Finally, it creates a `gradio.Interface` with audio input (microphone enabled) and label output, providing example audio files, and launches the interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/main_note/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom math import log2, pow\nimport os\n\nimport numpy as np\nfrom scipy.fftpack import fft\n\nimport gradio as gr\n\nA4 = 440\nC0 = A4 * pow(2, -4.75)\nname = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n\ndef get_pitch(freq):\n    h = round(12 * log2(freq / C0))\n    n = h % 12\n    return name[n]\n\ndef main_note(audio):\n    rate, y = audio\n    if len(y.shape) == 2:\n        y = y.T[0]\n    N = len(y)\n    T = 1.0 / rate\n    yf = fft(y)\n    yf2 = 2.0 / N * np.abs(yf[0 : N // 2])\n    xf = np.linspace(0.0, 1.0 / (2.0 * T), N // 2)\n\n    volume_per_pitch = {}\n    total_volume = np.sum(yf2)\n    for freq, volume in zip(xf, yf2):\n        if freq == 0:\n            continue\n        pitch = get_pitch(freq)\n        if pitch not in volume_per_pitch:\n            volume_per_pitch[pitch] = 0\n        volume_per_pitch[pitch] += 1.0 * volume / total_volume\n    volume_per_pitch = {k: float(v) for k, v in volume_per_pitch.items()}\n    return volume_per_pitch\n\ndemo = gr.Interface(\n    main_note,\n    gr.Audio(sources=[\"microphone\"]),\n    gr.Label(num_top_classes=4),\n    examples=[\n        [os.path.join(os.path.abspath(''),\"audio/recording1.wav\")],\n        [os.path.join(os.path.abspath(''),\"audio/cantina.wav\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Dataset Demo\nDESCRIPTION: Sets up a Gradio interface with multiple Dataset components to showcase various input types including audio, checkbox, checkbox group, color picker, dataframe, dropdown, file, HTML, image, markdown, 3D model, number, radio, slider, textbox, and video.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\nimport numpy as np\n\ntxt = \"the quick brown fox\"\nnum = 10\n\nimg = os.path.join(os.path.abspath(''), \"files/cheetah1.jpg\")\nvid = os.path.join(os.path.abspath(''), \"files/world.mp4\")\naudio = os.path.join(os.path.abspath(''), \"files/cantina.wav\")\ncsv = os.path.join(os.path.abspath(''), \"files/time.csv\")\nmodel = os.path.join(os.path.abspath(''), \"files/Bunny.obj\")\n\ndataframe = [[1, 2, 3, 4], [4, 5, 6, 7], [8, 9, 1, 2], [3, 4, 5, 6]]\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Dataset previews\")\n    a = gr.Audio(visible=False)\n    gr.Dataset(\n        components=[a],\n        label=\"Audio\",\n        samples=[\n            [audio],\n            [audio],\n            [audio],\n            [audio],\n            [audio],\n            [audio],\n        ],\n    )\n    c = gr.Checkbox(visible=False)\n    gr.Dataset(\n        label=\"Checkbox\",\n        components=[c],\n        samples=[[True], [True], [False], [True], [False], [False]],\n    )\n\n    c_2 = gr.CheckboxGroup(visible=False, choices=['a', 'b', 'c'])\n    gr.Dataset(\n        label=\"CheckboxGroup\",\n        components=[c_2],\n        samples=[\n            [[\"a\"]],\n            [[\"a\", \"b\"]],\n            [[\"a\", \"b\", \"c\"]],\n            [[\"b\"]],\n            [[\"c\"]],\n            [[\"a\", \"c\"]],\n        ],\n    )\n    c_3 = gr.ColorPicker(visible=False)\n    gr.Dataset(\n        label=\"ColorPicker\",\n        components=[c_3],\n        samples=[\n            [\"#FFFFFF\"],\n            [\"#000000\"],\n            [\"#FFFFFF\"],\n            [\"#000000\"],\n            [\"#FFFFFF\"],\n            [\"#000000\"],\n        ],\n    )\n    d = gr.DataFrame(visible=False)\n    gr.Dataset(\n        components=[d],\n        label=\"Dataframe\",\n        samples=[\n            [np.zeros((3, 3)).tolist()],\n            [np.ones((2, 2)).tolist()],\n            [np.random.randint(0, 10, (3, 10)).tolist()],\n            [np.random.randint(0, 10, (10, 3)).tolist()],\n            [np.random.randint(0, 10, (10, 10)).tolist()],\n        ],\n    )\n    d_2 = gr.Dropdown(visible=False, choices=[\"one\", \"two\", \"three\"])\n    gr.Dataset(\n        components=[d_2],\n        label=\"Dropdown\",\n        samples=[[\"one\"], [\"two\"], [\"three\"], [\"one\"], [\"two\"], [\"three\"]],\n    )\n    f = gr.File(visible=False)\n    gr.Dataset(\n        components=[f],\n        label=\"File\",\n        samples=[\n            [csv],\n            [csv],\n            [csv],\n            [csv],\n            [csv],\n            [csv],\n        ],\n    )\n    h = gr.HTML(visible=False)\n    gr.Dataset(\n        components=[h],\n        label=\"HTML\",\n        samples=[\n            [\"<h1>hi</h2>\"],\n            [\"<h1>hi</h2>\"],\n            [\"<h1>hi</h2>\"],\n            [\"<h1>hi</h2>\"],\n            [\"<h1>hi</h2>\"],\n            [\"<h1>hi</h2>\"],\n        ],\n    )\n    i = gr.Image(visible=False)\n    gr.Dataset(\n        components=[i],\n        label=\"Image\",\n        samples=[[img], [img], [img], [img], [img], [img]],\n    )\n    m = gr.Markdown(visible=False)\n    gr.Dataset(\n        components=[m],\n        label=\"Markdown\",\n        samples=[\n            [\"# hi\"],\n            [\"# hi\"],\n            [\"# hi\"],\n            [\"# hi\"],\n            [\"# hi\"],\n            [\"# hi\"],\n        ],\n    )\n    m_2 = gr.Model3D(visible=False)\n    gr.Dataset(\n        components=[m_2],\n        label=\"Model3D\",\n        samples=[[model], [model], [model], [model], [model], [model]],\n    )\n    n = gr.Number(visible=False)\n    gr.Dataset(\n        label=\"Number\",\n        components=[n],\n        samples=[[1], [1], [1], [1], [1], [1]],\n    )\n    r = gr.Radio(visible=False, choices=[\"one\", \"two\", \"three\"])\n    gr.Dataset(\n        components=[r],\n        label=\"Radio\",\n        samples=[[\"one\"], [\"two\"], [\"three\"], [\"one\"], [\"two\"], [\"three\"]],\n    )\n    s = gr.Slider(visible=False)\n    gr.Dataset(\n        label=\"Slider\",\n        components=[s],\n        samples=[[1], [1], [1], [1], [1], [1]],\n    )\n    t = gr.Textbox(visible=False)\n    gr.Dataset(\n        label=\"Textbox\",\n        components=[t],\n        samples=[\n            [\"Some value\"],\n            [\"Some value\"],\n            [\"Some value\"],\n            [\"Some value\"],\n            [\"Some value\"],\n            [\"Some value\"],\n        ],\n    )\n    v = gr.Video(visible=False)\n    gr.Dataset(\n        components=[v],\n        label=\"Video\",\n        samples=[[vid], [vid], [vid], [vid], [vid], [vid]],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Interactive Dataframe Demo with Gradio\nDESCRIPTION: Creates a comprehensive demo showcasing Gradio's dataframe capabilities including interactive tables, event handling, and dynamic updates. Features multiple dataframe views with different configurations, event counters, and cell selection tracking.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport numpy as np\n\ndef update_dataframe():\n    regular_df = pd.DataFrame(np.random.randint(1, 10, size=(5, 5)), columns=pd.Index([str(i) for i in range(5)]))\n    wide_df = pd.DataFrame([\n        [5, 22, 91, 17, 73, 38, 84, 46, 65, 10, 155, 122, 11, 144, 133],\n        [81, 42, 13, 97, 33, 77, 59, 100, 29, 61, 213, 195, 142, 118, 127],\n        [37, 71, 63, 102, 28, 94, 19, 55, 88, 44, 116, 139, 122, 150, 147],\n        [104, 52, 49, 26, 83, 67, 31, 92, 79, 18, 241, 115, 159, 123, 137],\n        [16, 95, 74, 68, 43, 101, 27, 85, 39, 57, 129, 148, 132, 111, 156]\n    ], columns=pd.Index([f\"col_{i}\" for i in range(15)]))\n    return regular_df, wide_df\n\ndef clear_dataframes():\n    regular_empty_df = pd.DataFrame([], columns=pd.Index([str(i) for i in range(5)]))\n    wide_empty_df = pd.DataFrame([], columns=pd.Index([f\"col_{i}\" for i in range(15)]))\n    return regular_empty_df, wide_empty_df\n\ndef increment_select_counter(evt: gr.SelectData, count):\n    count_val = 1 if count is None else count + 1\n    return count_val, evt.index, evt.value\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column(scale=1):\n            initial_regular_df = pd.DataFrame(np.zeros((5, 5), dtype=int), columns=pd.Index([str(i) for i in range(5)]))\n\n            df = gr.Dataframe(\n                value=initial_regular_df,\n                interactive=True,\n                label=\"Interactive Dataframe\",\n                show_label=True,\n                elem_id=\"dataframe\",\n                show_search=\"filter\",\n                show_copy_button=True,\n                show_row_numbers=True,\n                static_columns=[4]\n            )\n\n        with gr.Column(scale=1):\n            initial_wide_df = pd.DataFrame(np.zeros((5, 15), dtype=int), columns=pd.Index([f\"col_{i}\" for i in range(15)]))\n\n            df_view = gr.Dataframe(\n                value=initial_wide_df,\n                interactive=False,\n                label=\"Non-Interactive View (Scroll Horizontally)\",\n                show_label=True,\n                show_search=\"search\",\n                elem_id=\"non-interactive-dataframe\",\n                show_copy_button=True,\n                show_row_numbers=True,\n                show_fullscreen_button=True,\n            )\n\n    tall_df_value = [\n        [\"DeepSeek Coder\", 79.3],\n        [\"Llama 3.3\", 68.9],\n        [\"Qwen 2.5\", 61.9],\n        [\"Gemma 2\", 59.5],\n        [\"GPT 2\", 18.3],\n    ]\n\n    def get_display_value(values):\n        display_values = []\n        medals = [\"🥇\", \"🥈\", \"🥉\"]\n        for i, row in enumerate(values):\n            if i < 3:\n                display_values.append([f\"{medals[i]} {row[0]}\", row[1]])\n            else:\n                display_values.append([row[0], row[1]])\n        return display_values\n\n    display_value = get_display_value(tall_df_value)\n\n    tall_df_value = {\n        \"data\": tall_df_value,\n        \"headers\": [\"Model\", \"% Correct (LeetCode Hard)\"],\n        \"metadata\": {\n            \"display_value\": display_value\n        }\n    }\n\n    with gr.Row():\n        with gr.Column():\n            df_tall = gr.Dataframe(\n                value=tall_df_value,\n                interactive=False,\n                label=\"Tall Dataframe (Scroll Vertically)\",\n                max_height=200,\n                show_label=True,\n                elem_id=\"dataframe_tall\",\n                show_copy_button=True,\n                show_row_numbers=True,\n                show_search=\"search\",\n            )\n\n            df_tall_selected_cell_index = gr.Textbox(\n                label=\"Tall dataframe selected cell index\", elem_id=\"tall_selected_cell_index\"\n            )\n            df_tall_selected_cell_value = gr.Textbox(\n                label=\"Tall dataframe selected cell value\", elem_id=\"tall_selected_cell_value\"\n            )\n\n    with gr.Row():\n        with gr.Column():\n            update_btn = gr.Button(\"Update dataframe\", elem_id=\"update_btn\")\n            clear_btn = gr.Button(\"Clear dataframe\", elem_id=\"clear_btn\")\n\n    with gr.Row():\n        change_events = gr.Number(\n            value=0, label=\"Change events\", elem_id=\"change_events\"\n        )\n        input_events = gr.Number(value=0, label=\"Input events\", elem_id=\"input_events\")\n        select_events = gr.Number(\n            value=0, label=\"Select events\", elem_id=\"select_events\"\n        )\n\n    with gr.Row():\n        selected_cell_index = gr.Textbox(\n            label=\"Selected cell index\", elem_id=\"selected_cell_index\"\n        )\n        selected_cell_value = gr.Textbox(\n            label=\"Selected cell value\", elem_id=\"selected_cell_value\"\n        )\n\n    update_btn.click(fn=update_dataframe, outputs=[df, df_view])\n    clear_btn.click(fn=clear_dataframes, outputs=[df, df_view, df_tall])\n    df.change(fn=lambda x: x + 1, inputs=[change_events], outputs=[change_events])\n    df.input(fn=lambda x: x + 1, inputs=[input_events], outputs=[input_events])\n    df.select(\n        fn=increment_select_counter,\n        inputs=[select_events],\n        outputs=[select_events, selected_cell_index, selected_cell_value],\n    )\n\n    df_tall.select(\n        fn=increment_select_counter,\n        inputs=[select_events],\n        outputs=[select_events, df_tall_selected_cell_index, df_tall_selected_cell_value],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Line Plots with Gradio\nDESCRIPTION: Implements a complete Gradio application that creates interactive line plots from different datasets. The code includes data loading, a plot generation function that handles different dataset types, and UI setup with Gradio Blocks. The application allows users to switch between different datasets through a dropdown menu.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom vega_datasets import data\n\nstocks = data.stocks()\ngapminder = data.gapminder()\ngapminder = gapminder.loc[\n    gapminder.country.isin([\"Argentina\", \"Australia\", \"Afghanistan\"])\n]\nclimate = data.climate()\nseattle_weather = data.seattle_weather()\n\ndef line_plot_fn(dataset):\n    if dataset == \"stocks\":\n        return gr.LinePlot(\n            stocks,\n            x=\"date\",\n            y=\"price\",\n            color=\"symbol\",\n            color_legend_position=\"bottom\",\n            title=\"Stock Prices\",\n            tooltip=[\"date\", \"price\", \"symbol\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"climate\":\n        return gr.LinePlot(\n            climate,\n            x=\"DATE\",\n            y=\"HLY-TEMP-NORMAL\",\n            y_lim=[250, 500],\n            title=\"Climate\",\n            tooltip=[\"DATE\", \"HLY-TEMP-NORMAL\"],\n            height=300,\n            width=500,\n        )\n    elif dataset == \"seattle_weather\":\n        return gr.LinePlot(\n            seattle_weather,\n            x=\"date\",\n            y=\"temp_min\",\n            tooltip=[\"weather\", \"date\"],\n            overlay_point=True,\n            title=\"Seattle Weather\",\n            height=300,\n            width=500,\n        )\n    elif dataset == \"gapminder\":\n        return gr.LinePlot(\n            gapminder,\n            x=\"year\",\n            y=\"life_expect\",\n            color=\"country\",\n            title=\"Life expectancy for countries\",\n            stroke_dash=\"cluster\",\n            x_lim=[1950, 2010],\n            tooltip=[\"country\", \"life_expect\"],\n            stroke_dash_legend_title=\"Country Cluster\",\n            height=300,\n            width=500,\n        )\n\nwith gr.Blocks() as line_plot:\n    with gr.Row():\n        with gr.Column():\n            dataset = gr.Dropdown(\n                choices=[\"stocks\", \"climate\", \"seattle_weather\", \"gapminder\"],\n                value=\"stocks\",\n            )\n        with gr.Column():\n            plot = gr.LinePlot()\n    dataset.change(line_plot_fn, inputs=dataset, outputs=plot)\n    line_plot.load(fn=line_plot_fn, inputs=dataset, outputs=plot)\n\nif __name__ == \"__main__\":\n    line_plot.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating an Interactive Gradio Dashboard with Plots in Python\nDESCRIPTION: Illustrates building an interactive dashboard where Gradio plots are dynamically updated based on the values of other input components (like sliders or dropdowns). Event listeners trigger functions that filter data and update the plot components. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_interactive\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Widget HTML and CSS Structure\nDESCRIPTION: Defines the HTML structure and CSS styling for a floating chat widget interface. Includes button controls, message container, input area, and responsive styling for a professional appearance.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/08_creating-a-website-widget-from-a-gradio-chatbot.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<div id=\"chat-widget\" class=\"chat-widget\">\n    <button id=\"chat-toggle\" class=\"chat-toggle\">💬</button>\n    <div id=\"chat-container\" class=\"chat-container hidden\">\n        <div id=\"chat-header\">\n            <h3>Gradio Assistant</h3>\n            <button id=\"close-chat\">×</button>\n        </div>\n        <div id=\"chat-messages\"></div>\n        <div id=\"chat-input-area\">\n            <input type=\"text\" id=\"chat-input\" placeholder=\"Ask a question...\">\n            <button id=\"send-message\">Send</button>\n        </div>\n    </div>\n</div>\n\n<style>\n.chat-widget {\n    position: fixed;\n    bottom: 20px;\n    right: 20px;\n    z-index: 1000;\n}\n\n.chat-toggle {\n    width: 50px;\n    height: 50px;\n    border-radius: 50%;\n    background: #007bff;\n    border: none;\n    color: white;\n    font-size: 24px;\n    cursor: pointer;\n}\n\n.chat-container {\n    position: fixed;\n    bottom: 80px;\n    right: 20px;\n    width: 300px;\n    height: 400px;\n    background: white;\n    border-radius: 10px;\n    box-shadow: 0 0 10px rgba(0,0,0,0.1);\n    display: flex;\n    flex-direction: column;\n}\n\n.chat-container.hidden {\n    display: none;\n}\n\n#chat-header {\n    padding: 10px;\n    background: #007bff;\n    color: white;\n    border-radius: 10px 10px 0 0;\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n}\n\n#chat-messages {\n    flex-grow: 1;\n    overflow-y: auto;\n    padding: 10px;\n}\n\n#chat-input-area {\n    padding: 10px;\n    border-top: 1px solid #eee;\n    display: flex;\n}\n\n#chat-input {\n    flex-grow: 1;\n    padding: 8px;\n    border: 1px solid #ddd;\n    border-radius: 4px;\n    margin-right: 8px;\n}\n\n.message {\n    margin: 8px 0;\n    padding: 8px;\n    border-radius: 4px;\n}\n\n.user-message {\n    background: #e9ecef;\n    margin-left: 20px;\n}\n\n.bot-message {\n    background: #f8f9fa;\n    margin-right: 20px;\n}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Implementing Single-User Password Authentication in Gradio Python\nDESCRIPTION: Demonstrates setting up basic password authentication for a Gradio app using the `auth` parameter in the `launch()` method. This example restricts access to a single user (\"admin\") with a specific password (\"pass1234\"). Assumes `demo` is a pre-defined Gradio app instance (either `Interface` or `Blocks`). Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndemo.launch(auth=(\"admin\", \"pass1234\"))\n```\n\n----------------------------------------\n\nTITLE: Creating a Shareable Gradio Demo\nDESCRIPTION: Python code that creates a simple greeting function interface and enables public sharing with a unique URL. This demonstrates Gradio's ability to make demos accessible to others without requiring hosting setup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter 🚀\n```\n\n----------------------------------------\n\nTITLE: Highlighting Maximum Value in Pandas DataFrame - Python\nDESCRIPTION: This snippet shows how to create a Pandas DataFrame and apply the highlight_max styling method to emphasize the maximum value in each row with a light green background. Dependencies: pandas. The key parameter is axis (=0 for column-wise maximum). The output is a Styler object that can be visualized in Gradio or Jupyter environments. Inputs are columnar numeric data; output is a stylized Pandas Styler for further rendering.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd \n\n# Creating a sample dataframe\ndf = pd.DataFrame({\n    \"A\" : [14, 4, 5, 4, 1], \n    \"B\" : [5, 2, 54, 3, 2], \n    \"C\" : [20, 20, 7, 3, 8], \n    \"D\" : [14, 3, 6, 2, 6], \n    \"E\" : [23, 45, 64, 32, 23]\n}) \n\n# Applying style to highlight the maximum value in each row\nstyler = df.style.highlight_max(color = 'lightgreen', axis = 0)\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake GAN Text-to-Image Generation with Gradio in Python\nDESCRIPTION: This code snippet demonstrates how to create a text-to-image interface using Gradio and a simulated GAN. It includes a fake image generation function and sets up a Gradio interface for user interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan/DESCRIPTION.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport gradio as gr\nimport random\n\ndef fake_gan(text):\n    # In reality, you would have your model generate an image here\n    # For this demo, we'll just return a random image\n    return f\"https://picsum.photos/seed/{random.randint(0, 1000)}/300/300\"\n\ndemo = gr.Interface(\n    fake_gan,\n    gr.Textbox(placeholder=\"Enter a description of the image you want to generate\"),\n    gr.Image(shape=(300, 300)),\n    title=\"Fake GAN\",\n    description=\"This is a fake GAN that shows how to create a text-to-image interface.\"\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Flight Data Visualization with Filtering Controls\nDESCRIPTION: Builds a Gradio application with filter controls (origin, destination, price) that updates a scatter plot of flight data. The application allows users to filter flight data by selecting origin airports, destination airports, and setting a maximum price.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters_events/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        origin = gr.Dropdown([\"All\", \"DFW\", \"DAL\", \"HOU\"], value=\"All\", label=\"Origin\")\n        destination = gr.Dropdown([\"All\", \"JFK\", \"LGA\", \"EWR\"], value=\"All\", label=\"Destination\")\n        max_price = gr.Slider(0, 1000, value=1000, label=\"Max Price\")\n\n    plt = gr.ScatterPlot(df, x=\"time\", y=\"price\", inputs=[origin, destination, max_price])\n\n    @gr.on(inputs=[origin, destination, max_price], outputs=plt)\n    def filtered_data(origin, destination, max_price):\n        _df = df[df[\"price\"] <= max_price]\n        if origin != \"All\":\n            _df = _df[_df[\"origin\"] == origin]\n        if destination != \"All\":\n            _df = _df[_df[\"destination\"] == destination]\n        return _df\n\n    \nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Using Gradio Client in Flask Server with Gevent\nDESCRIPTION: This example shows how to integrate the Gradio client into a Flask server using gevent for concurrency. It sets up an endpoint that generates an image using a diffusion model and returns it.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom gevent import monkey\nmonkey.patch_all()\n\nfrom gradio_client import Client\nfrom flask import Flask, send_file\nimport time\n\napp = Flask(__name__)\n\nimageclient = Client(\"gradio/diffusion_model\")\n\n@app.route(\"/gen\")\ndef gen():\n      result = imageclient.predict(\n                \"A cute cat\",\n                api_name=\"/predict\"\n              )\n      return send_file(result)\n\nif __name__ == \"__main__\":\n      app.run(host=\"0.0.0.0\", port=5000)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Button Component Demo\nDESCRIPTION: Creates a Gradio interface demonstrating various button configurations including primary, secondary, and stop variants with different sizes, icons, and interactive states. The demo shows buttons arranged in rows and groups with combinations of styling options.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/button_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nicon = \"https://cdn.icon-icons.com/icons2/2620/PNG/512/among_us_player_red_icon_156942.png\"\nwith gr.Blocks() as demo:\n   with gr.Row():\n      gr.Button(variant=\"primary\")\n      gr.Button(variant=\"secondary\")\n      gr.Button(variant=\"stop\")\n   with gr.Row():\n      gr.Button(variant=\"primary\", size=\"sm\")\n      gr.Button(variant=\"secondary\", size=\"sm\")\n      gr.Button(variant=\"stop\", size=\"sm\")\n   with gr.Row():\n      gr.Button(variant=\"primary\", icon=icon)\n      gr.Button(variant=\"secondary\", icon=icon)\n      gr.Button(variant=\"stop\", icon=icon)\n\n   with gr.Row():\n      gr.Button(variant=\"primary\", size=\"sm\", icon=icon)\n      gr.Button(variant=\"secondary\", size=\"sm\", icon=icon)\n      gr.Button(variant=\"stop\", size=\"sm\", icon=icon)\n\n   with gr.Row():\n      gr.Button(variant=\"primary\", icon=icon, interactive=False)\n      gr.Button(variant=\"secondary\", icon=icon, interactive=False)\n      gr.Button(variant=\"stop\", icon=icon, interactive=False)\n\n   with gr.Row():\n      gr.Button(variant=\"primary\", size=\"sm\", icon=icon, interactive=False)\n      gr.Button(variant=\"secondary\", size=\"sm\", icon=icon, interactive=False)\n      gr.Button(variant=\"stop\", size=\"sm\", icon=icon, interactive=False)\n\n   with gr.Row():\n      gr.Button(variant=\"primary\", interactive=False)\n      gr.Button(variant=\"secondary\", interactive=False)\n      gr.Button(variant=\"stop\", interactive=False)\n\n   with gr.Row():\n      gr.Button(variant=\"primary\", size=\"sm\",  interactive=False)\n      gr.Button(variant=\"secondary\", size=\"sm\", interactive=False)\n      gr.Button(variant=\"stop\", size=\"sm\", interactive=False)\n\n   with gr.Group():\n      gr.Button(variant=\"primary\")\n      gr.Button(variant=\"primary\")\n      gr.Button(variant=\"secondary\")\n      gr.Button(variant=\"secondary\")\n      gr.Button(variant=\"stop\")\n      gr.Button(variant=\"stop\")\n\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Accessing Network Request Details in Gradio Python\nDESCRIPTION: Shows how to retrieve network request details like headers, client IP address, and query parameters within a Gradio function by adding a parameter type-hinted as `gr.Request`. It includes a crucial check (`if request:`) to handle cases where the request might be `None`, such as during example caching or direct API calls, preventing potential errors. Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef echo(text, request: gr.Request):\n    if request:\n        print(\"Request headers dictionary:\", request.headers)\n        print(\"IP address:\", request.client.host)\n        print(\"Query parameters:\", dict(request.query_params))\n    return text\n\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Real-time Webcam Filter with Gradio and OpenCV (Python)\nDESCRIPTION: This Python script sets up a Gradio application for real-time webcam video filtering. It imports required libraries (Gradio, NumPy, OpenCV). A function `transform_cv2` applies selected image transformations ('cartoon', 'edges', 'flip') to input frames using OpenCV. The Gradio interface (`gr.Blocks`) includes a dropdown for selecting the transformation and an Image component configured for streaming webcam input (`sources=[\"webcam\"]`, `streaming=True`). The `input_img.stream()` method continuously calls `transform_cv2` with the latest frame and selected transform, updating the output image component every 0.1 seconds.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_filter_unified/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport cv2\n\ndef transform_cv2(frame, transform):\n    if transform == \"cartoon\":\n        # prepare color\n        img_color = cv2.pyrDown(cv2.pyrDown(frame))\n        for _ in range(6):\n            img_color = cv2.bilateralFilter(img_color, 9, 9, 7)\n        img_color = cv2.pyrUp(cv2.pyrUp(img_color))\n\n        # prepare edges\n        img_edges = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n        img_edges = cv2.adaptiveThreshold(\n            cv2.medianBlur(img_edges, 7),\n            255,\n            cv2.ADAPTIVE_THRESH_MEAN_C,\n            cv2.THRESH_BINARY,\n            9,\n            2,\n        )\n        img_edges = cv2.cvtColor(img_edges, cv2.COLOR_GRAY2RGB)\n        # combine color and edges\n        img = cv2.bitwise_and(img_color, img_edges)\n        return img\n    elif transform == \"edges\":\n        # perform edge detection\n        img = cv2.cvtColor(cv2.Canny(frame, 100, 200), cv2.COLOR_GRAY2BGR)\n        return img\n    else:\n        return np.flipud(frame)\n\n\ncss=\"\"\".my-group {max-width: 500px !important; max-height: 500px !important;}\n            .my-column {display: flex !important; justify-content: center !important; align-items: center !important};\"\"\"\n\nwith gr.Blocks(css=css) as demo:\n    with gr.Column(elem_classes=[\"my-column\"]):\n        with gr.Group(elem_classes=[\"my-group\"]):\n            transform = gr.Dropdown(choices=[\"cartoon\", \"edges\", \"flip\"],\n                                    value=\"flip\", label=\"Transformation\")\n            input_img = gr.Image(sources=[\"webcam\"], type=\"numpy\", streaming=True)\n    input_img.stream(transform_cv2, [input_img, transform], [input_img], time_limit=30, stream_every=0.1)\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Leaderboard Data and Gradio UI Blocks - Python\nDESCRIPTION: Defines all logic for reading JSON leaderboard data, initializing filter/search parameters, implementing filtering/searching helpers, and constructing the Gradio web application. Requires the downloaded JSON asset, Gradio, and pandas. Handles update callbacks for filtering models by type, size, or precision, and uses the Gradio Blocks API to create a dynamic UI. Inputs include user queries and filter selections; output is an updated visible leaderboard table. Not suitable for headless environments due to UI dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/mini_leaderboard/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n```python\\n# type: ignore\\nimport gradio as gr\\nimport pandas as pd\\nfrom pathlib import Path\\n\\nabs_path = Path(__file__).parent.absolute()\\n\\ndf = pd.read_json(str(abs_path / \"assets/leaderboard_data.json\"))\\ninvisible_df = df.copy()\\n\\nCOLS = [\\n    \"T\",\\n    \"Model\",\\n    \"Average \\u2B06\\uFE0F\",\\n    \"ARC\",\\n    \"HellaSwag\",\\n    \"MMLU\",\\n    \"TruthfulQA\",\\n    \"Winogrande\",\\n    \"GSM8K\",\\n    \"Type\",\\n    \"Architecture\",\\n    \"Precision\",\\n    \"Merged\",\\n    \"Hub License\",\\n    \"#Params (B)\",\\n    \"Hub \\u2764\\uFE0F\",\\n    \"Model sha\",\\n    \"model_name_for_query\",\\n]\\nON_LOAD_COLS = [\\n    \"T\",\\n    \"Model\",\\n    \"Average \\u2B06\\uFE0F\",\\n    \"ARC\",\\n    \"HellaSwag\",\\n    \"MMLU\",\\n    \"TruthfulQA\",\\n    \"Winogrande\",\\n    \"GSM8K\",\\n    \"model_name_for_query\",\\n]\\nTYPES = [\\n    \"str\",\\n    \"markdown\",\\n    \"number\",\\n    \"number\",\\n    \"number\",\\n    \"number\",\\n    \"number\",\\n    \"number\",\\n    \"number\",\\n    \"str\",\\n    \"str\",\\n    \"str\",\\n    \"str\",\\n    \"bool\",\\n    \"str\",\\n    \"number\",\\n    \"number\",\\n    \"bool\",\\n    \"str\",\\n    \"bool\",\\n    \"bool\",\\n    \"str\",\\n]\\nNUMERIC_INTERVALS = {\\n    \"?\": pd.Interval(-1, 0, closed=\"right\"),\\n    \"~1.5\": pd.Interval(0, 2, closed=\"right\"),\\n    \"~3\": pd.Interval(2, 4, closed=\"right\"),\\n    \"~7\": pd.Interval(4, 9, closed=\"right\"),\\n    \"~13\": pd.Interval(9, 20, closed=\"right\"),\\n    \"~35\": pd.Interval(20, 45, closed=\"right\"),\\n    \"~60\": pd.Interval(45, 70, closed=\"right\"),\\n    \"70+\": pd.Interval(70, 10000, closed=\"right\"),\\n}\\nMODEL_TYPE = [str(s) for s in df[\"T\"].unique()]\\nPrecision = [str(s) for s in df[\"Precision\"].unique()]\\n\\n# Searching and filtering\\ndef update_table(\\n    hidden_df: pd.DataFrame,\\n    columns: list,\\n    type_query: list,\\n    precision_query: str,\\n    size_query: list,\\n    query: str,\\n):\\n    filtered_df = filter_models(hidden_df, type_query, size_query, precision_query)  # type: ignore\\n    filtered_df = filter_queries(query, filtered_df)\\n    df = select_columns(filtered_df, columns)\\n    return df\\n\\ndef search_table(df: pd.DataFrame, query: str) -> pd.DataFrame:\\n    return df[(df[\"model_name_for_query\"].str.contains(query, case=False))]  # type: ignore\\n\\ndef select_columns(df: pd.DataFrame, columns: list) -> pd.DataFrame:\\n    # We use COLS to maintain sorting\\n    filtered_df = df[[c for c in COLS if c in df.columns and c in columns]]\\n    return filtered_df  # type: ignore\\n\\ndef filter_queries(query: str, filtered_df: pd.DataFrame) -> pd.DataFrame:\\n    final_df = []\\n    if query != \"\":\\n        queries = [q.strip() for q in query.split(\";\")]\\n        for _q in queries:\\n            _q = _q.strip()\\n            if _q != \"\":\\n                temp_filtered_df = search_table(filtered_df, _q)\\n                if len(temp_filtered_df) > 0:\\n                    final_df.append(temp_filtered_df)\\n        if len(final_df) > 0:\\n            filtered_df = pd.concat(final_df)\\n            filtered_df = filtered_df.drop_duplicates(  # type: ignore\\n                subset=[\"Model\", \"Precision\", \"Model sha\"]\\n            )\\n\\n    return filtered_df\\n\\ndef filter_models(\\n    df: pd.DataFrame,\\n    type_query: list,\\n    size_query: list,\\n    precision_query: list,\\n) -> pd.DataFrame:\\n    # Show all models\\n    filtered_df = df\\n\\n    type_emoji = [t[0] for t in type_query]\\n    filtered_df = filtered_df.loc[df[\"T\"].isin(type_emoji)]\\n    filtered_df = filtered_df.loc[df[\"Precision\"].isin(precision_query + [\"None\"]) ]\\n\\n    numeric_interval = pd.IntervalIndex(\\n        sorted([NUMERIC_INTERVALS[s] for s in size_query])  # type: ignore\\n    )\\n    params_column = pd.to_numeric(df[\"#Params (B)\"], errors=\"coerce\")\\n    mask = params_column.apply(lambda x: any(numeric_interval.contains(x)))  # type: ignore\\n    filtered_df = filtered_df.loc[mask]\\n\\n    return filtered_df\\n\\ndemo = gr.Blocks(css=str(abs_path / \"assets/leaderboard_data.json\"))\\nwith demo:\\n    gr.Markdown(\"\"\"Test Space of the LLM Leaderboard\"\"\", elem_classes=\"markdown-text\")\\n\\n    with gr.Tabs(elem_classes=\"tab-buttons\") as tabs:\\n        with gr.TabItem(\"\\ud83c\\udfc5 LLM Benchmark\", elem_id=\"llm-benchmark-tab-table\", id=0):\\n            with gr.Row():\\n                with gr.Column():\\n                    with gr.Row():\\n                        search_bar = gr.Textbox(\\n                            placeholder=\" \\ud83d\\udd0d Search for your model (separate multiple queries with `;`) and press ENTER...\",\\n                            show_label=False,\\n                            elem_id=\"search-bar\",\\n                        )\\n                    with gr.Row():\\n                        shown_columns = gr.CheckboxGroup(\\n                            choices=COLS,\\n                            value=ON_LOAD_COLS,\\n                            label=\"Select columns to show\",\\n                            elem_id=\"column-select\",\\n                            interactive=True,\\n                        )\\n                with gr.Column(min_width=320):\\n                    filter_columns_type = gr.CheckboxGroup(\\n                        label=\"Model types\",\\n                        choices=MODEL_TYPE,\\n                        value=MODEL_TYPE,\\n                        interactive=True,\\n                        elem_id=\"filter-columns-type\",\\n                    )\\n                    filter_columns_precision = gr.CheckboxGroup(\\n                        label=\"Precision\",\\n                        choices=Precision,\\n                        value=Precision,\\n                        interactive=True,\\n                        elem_id=\"filter-columns-precision\",\\n                    )\\n                    filter_columns_size = gr.CheckboxGroup(\\n                        label=\"Model sizes (in billions of parameters)\",\\n                        choices=list(NUMERIC_INTERVALS.keys()),\\n                        value=list(NUMERIC_INTERVALS.keys()),\\n                        interactive=True,\\n                        elem_id=\"filter-columns-size\",\\n                    )\\n\\n            leaderboard_table = gr.components.Dataframe(\\n                value=df[ON_LOAD_COLS],  # type: ignore\\n                headers=ON_LOAD_COLS,\\n                datatype=TYPES,\\n                elem_id=\"leaderboard-table\",\\n                interactive=False,\\n                visible=True,\\n                column_widths=[\"2%\", \"33%\"],\\n            )\\n\\n            # Dummy leaderboard for handling the case when the user uses backspace key\\n            hidden_leaderboard_table_for_search = gr.components.Dataframe(\\n                value=invisible_df[COLS],  # type: ignore\\n                headers=COLS,\\n                datatype=TYPES,\\n                visible=False,\\n            )\\n            search_bar.submit(\\n                update_table,\\n                [\\n                    hidden_leaderboard_table_for_search,\\n                    shown_columns,\\n                    filter_columns_type,\\n                    filter_columns_precision,\\n                    filter_columns_size,\\n                    search_bar,\\n                ],\\n                leaderboard_table,\\n            )\\n            for selector in [\\n                shown_columns,\\n                filter_columns_type,\\n                filter_columns_precision,\\n                filter_columns_size,\\n            ]:\\n                selector.change(\\n                    update_table,\\n                    [\\n                        hidden_leaderboard_table_for_search,\\n                        shown_columns,\\n                        filter_columns_type,\\n                        filter_columns_precision,\\n                        filter_columns_size,\\n                        search_bar,\\n                    ],\\n                    leaderboard_table,\\n                    queue=True,\\n                )\\n\\nif __name__ == \"__main__\":\\n    demo.queue(default_concurrency_limit=40).launch()\\n\\n```\n```\n\n----------------------------------------\n\nTITLE: Building a Tabbed Interface with Dynamic Visibility in Gradio using Python\nDESCRIPTION: This snippet defines a Gradio Blocks interface with several Tab components, some of which are initially hidden via the 'visible=False' argument. A button triggers the 'click' event, which sets the visibility of hidden tabs to True using a lambda function. To run this app, Gradio must be installed; the main interface is launched if the script is executed directly, and the button manipulates the UI so users can reveal additional tabs without reloading the app.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabs_visibility/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Tab(\"abc\"):\n        gr.Textbox(label=\"abc\")\n    with gr.Tab(\"def\", visible=False) as t:\n        gr.Textbox(label=\"def\")\n    with gr.Tab(\"ghi\"):\n        gr.Textbox(label=\"ghi\")\n    with gr.Tab(\"jkl\", visible=False) as t2:\n        gr.Textbox(label=\"jkl\")\n    with gr.Tab(\"mno\"):\n        gr.Textbox(label=\"mno\")\n    with gr.Tab(\"pqr\", visible=False) as t3:\n        gr.Textbox(label=\"pqr\")\n    with gr.Tab(\"stu\"):\n        gr.Textbox(label=\"stu\")\n    with gr.Tab(\"vwx\", visible=False) as t4:\n        gr.Textbox(label=\"vwx\")\n    with gr.Tab(\"yz\"):\n        gr.Textbox(label=\"yz\")\n    b = gr.Button(\"Make visible\")\n\n    b.click(\n        lambda: [\n            gr.Tab(visible=True),\n            gr.Tab(visible=True),\n            gr.Tab(visible=True),\n            gr.Tab(visible=True),\n        ],\n        inputs=None,\n        outputs=[t, t2, t3, t4],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Applying a Prebuilt Theme in Gradio - Python\nDESCRIPTION: Demonstrates how to apply a prebuilt theme to a Gradio app by passing the theme argument to the Blocks constructor. The snippet uses the gr.themes.Soft theme. This example requires Gradio to be installed and imported as 'gr'. The usage of 'with gr.Blocks ... as demo' is typical for building UI layouts in Gradio. The ellipsis ('...') indicates where UI components can be placed. No external configuration is needed beyond Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Soft()) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Unified Image Streaming Demo in Gradio\nDESCRIPTION: Demonstrates a unified image streaming demo where the input and output are displayed in a single component. It applies filters to the webcam stream and updates the same image component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/03_streaming-inputs.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport numpy as np\nimport gradio as gr\n\ndef apply_filter(img, filter):\n    if filter == \"edge_detection\":\n        return cv2.Canny(img, 100, 200)\n    elif filter == \"cartoon\":\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        gray = cv2.medianBlur(gray, 5)\n        edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)\n        color = cv2.bilateralFilter(img, 9, 300, 300)\n        return cv2.bitwise_and(color, color, mask=edges)\n    elif filter == \"vertical_flip\":\n        return cv2.flip(img, 0)\n    else:\n        return img\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        image = gr.Image(source=\"webcam\", streaming=True)\n        filter = gr.Radio([\"none\", \"edge_detection\", \"cartoon\", \"vertical_flip\"])\n    image.stream(apply_filter, inputs=[image, filter], outputs=image)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing ColorPicker Python Class in Gradio\nDESCRIPTION: This code defines the ColorPicker component class that inherits from Changeable, Submittable, and IOComponent. It includes initialization, configuration, processing methods, and serialization functions for handling color values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/creating-a-new-component.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n@document()\nclass ColorPicker(Changeable, Submittable, IOComponent):\n    \"\"\"\n    创建一个颜色选择器，用户可以选择颜色作为字符串输入。\n    预处理：将选择的颜色值作为{str}传递给函数。\n    后处理：期望从函数中返回一个{str}，并将颜色选择器的值设置为它。\n    示例格式：表示颜色的十六进制{str}，例如红色的\"#ff0000\"。\n    演示：color_picker，color_generator\n    \"\"\"\n\n    def __init__(\n        self,\n        value: str = None,\n        *,\n        label: Optional[str] = None,\n        show_label: bool = True,\n        interactive: Optional[bool] = None,\n        visible: bool = True,\n        elem_id: Optional[str] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Parameters:\n        \"\"\"\n        Parameters:\n            value: default text to provide in color picker.\n            label: component name in interface.\n            show_label: if True, will display label.\n            interactive: if True, will be rendered as an editable color picker; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.\n            visible: If False, component will be hidden.\n            elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.\n        \"\"\"\n        self.value = self.postprocess(value)\n        self.cleared_value = \"#000000\"\n        self.test_input = value\n        IOComponent.__init__(\n            self,\n            label=label,\n            show_label=show_label,\n            interactive=interactive,\n            visible=visible,\n            elem_id=elem_id,\n            **kwargs,\n        )\n\n    def get_config(self):\n        return {\n            \"value\": self.value,\n            **IOComponent.get_config(self),\n        }\n\n    @staticmethod\n    def update(\n        value: Optional[Any] = None,\n        label: Optional[str] = None,\n        show_label: Optional[bool] = None,\n        visible: Optional[bool] = None,\n        interactive: Optional[bool] = None,\n    ):\n        return {\n            \"value\": value,\n            \"label\": label,\n            \"show_label\": show_label,\n            \"visible\": visible,\n            \"interactive\": interactive,\n            \"__type__\": \"update\",\n        }\n\n    # 输入功能\n    def preprocess(self, x: str | None) -> Any:\n        \"\"\"\n        Any preprocessing needed to be performed on function input.\n        Parameters:\n        x (str): text\n        Returns:\n        (str): text\n        \"\"\"\n        if x is None:\n            return None\n        else:\n            return str(x)\n\n    def preprocess_example(self, x: str | None) -> Any:\n        \"\"\"\n        在传递给主函数之前，对示例进行任何预处理。\n        \"\"\"\n        if x is None:\n            return None\n        else:\n            return str(x)\n\n    # 输出功能\n    def postprocess(self, y: str | None):\n        \"\"\"\n        Any postprocessing needed to be performed on function output.\n        Parameters:\n        y (str | None): text\n        Returns:\n        (str | None): text\n        \"\"\"\n        if y is None:\n            return None\n        else:\n            return str(y)\n\n    def deserialize(self, x):\n        \"\"\"\n        将从调用接口的序列化输出（例如base64表示）转换为输出的人类可读版本（图像的路径等）\n        \"\"\"\n        return x\n```\n\n----------------------------------------\n\nTITLE: Returning Output Updates as a Dictionary in Gradio Python\nDESCRIPTION: Demonstrates returning a dictionary from a Gradio event listener function (`eat`) in Python to update output components. Keys in the dictionary (`{food_box: ..., status_box: ...}`) are the component objects, and values are their new states. This allows selective or conditional updates, as shown by only updating `status_box` when `food` is zero or less.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    food_box = gr.Number(value=10, label=\"Food Count\")\n    status_box = gr.Textbox()\n\n    def eat(food):\n        if food > 0:\n            return {food_box: food - 1, status_box: \"full\"}\n        else:\n            return {status_box: \"hungry\"}\n\n    gr.Button(\"Eat\").click(\n        fn=eat,\n        inputs=food_box,\n        outputs=[food_box, status_box]\n    )\n```\n\n----------------------------------------\n\nTITLE: Directly Binding a Gradio Component's Value to a Function (Shorthand) in Python\nDESCRIPTION: Shows a shorthand syntax in Gradio Blocks (Python) for making a component's value (`product`) directly dependent on others (`num1`, `num2`). By passing a lambda function and `inputs` directly to the `gr.Number` constructor, the `product` component automatically updates whenever `num1` or `num2` changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n  num1 = gr.Number()\n  num2 = gr.Number()\n  product = gr.Number(lambda a, b: a * b, inputs=[num1, num2])\n```\n\n----------------------------------------\n\nTITLE: Scheduling and Executing Periodic Database Backups - Python\nDESCRIPTION: This snippet defines a periodic background task to back up the local SQLite database to the HuggingFace dataset every 60 seconds using AdvancedPythonScheduler's BackgroundScheduler. The backup function copies the database file, exports reviews to CSV via pandas, and pushes updates to the remote dataset repo asynchronously. Dependencies are `APScheduler`, `sqlite3`, `shutil`, `pandas`, `huggingface_hub`, and `datetime`. It uses global constants previously defined in the guide, and assumes prior repository initialization and database setup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-background-tasks.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom apscheduler.schedulers.background import BackgroundScheduler\n\ndef backup_db():\n    shutil.copyfile(DB_FILE, \"./data/reviews.db\")\n    db = sqlite3.connect(DB_FILE)\n    reviews = db.execute(\"SELECT * FROM reviews\").fetchall()\n    pd.DataFrame(reviews).to_csv(\"./data/reviews.csv\", index=False)\n    print(\"updating db\")\n    repo.push_to_hub(blocking=False, commit_message=f\"Updating data at {datetime.datetime.now()}\")\n\n\nscheduler = BackgroundScheduler()\nscheduler.add_job(func=backup_db, trigger=\"interval\", seconds=60)\nscheduler.start()\n```\n\n----------------------------------------\n\nTITLE: Retrieving All Outputs from Gradio Generator Endpoints\nDESCRIPTION: Illustrates how to handle Gradio endpoints that yield multiple outputs (generators). It connects to a 'count_generator' app, submits a job, waits until the job is complete using a `while not job.done()` loop with `time.sleep`, and then retrieves all generated outputs at once using `job.outputs()`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(src=\"gradio/count_generator\")\njob = client.submit(3, api_name=\"/count\")\nwhile not job.done():\n    time.sleep(0.1)\njob.outputs()\n\n>> ['0', '1', '2']\n```\n\n----------------------------------------\n\nTITLE: Defining a PyTorch GAN Generator Model in Python\nDESCRIPTION: Defines the neural network architecture for the GAN Generator using PyTorch's `nn.Module`. It outlines a sequence of transposed convolutional layers (`nn.ConvTranspose2d`), batch normalization (`nn.BatchNorm2d`), and activation functions (`nn.ReLU`, `nn.Tanh`) to transform a noise vector (`nz`) into an image (`nc` channels). Key parameters `nc`, `nz`, and `ngf` control the number of output channels, size of the latent vector, and generator feature map size, respectively.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom torch import nn\n\nclass Generator(nn.Module):\n    # Refer to the link below for explanations about nc, nz, and ngf\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\n    def __init__(self, nc=4, nz=100, ngf=64):\n        super(Generator, self).__init__()\n        self.network = nn.Sequential(\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh(),\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output\n```\n\n----------------------------------------\n\nTITLE: Building a Minimal Data Visualization Dashboard with Gradio and Matplotlib in Python\nDESCRIPTION: This Python snippet shows how to construct a simple profiling dashboard using Gradio that visualizes tabular data with matplotlib and seaborn. It loads a sample dataframe, produces scatter plots, a bar chart, and a heatmap, saves them as images, and displays the results in a Gradio Gallery component. Dependencies are gradio, matplotlib, seaborn, pandas, and huggingface datasets. Inputs are user-provided or example dataframes; output is an image gallery with charts. The code expects numerical columns named as in the example dataset; all image files are saved to disk.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-for-tabular-workflows.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\nimport pandas as pd\\nimport datasets\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\ndf = datasets.load_dataset(\\\"merve/supersoaker-failures\\\")\\ndf = df[\\\"train\\\"].to_pandas()\\ndf.dropna(axis=0, inplace=True)\\n\\ndef plot(df):\\n  plt.scatter(df.measurement_13, df.measurement_15, c = df.loading,alpha=0.5)\\n  plt.savefig(\\\"scatter.png\\\")\\n  df['failure'].value_counts().plot(kind='bar')\\n  plt.savefig(\\\"bar.png\\\")\\n  sns.heatmap(df.select_dtypes(include=\\\"number\\\").corr())\\n  plt.savefig(\\\"corr.png\\\")\\n  plots = [\\\"corr.png\\\",\\\"scatter.png\\\", \\\"bar.png\\\"]\\n  return plots\\n\\ninputs = [gr.Dataframe(label=\\\"Supersoaker Production Data\\\")]\\noutputs = [gr.Gallery(label=\\\"Profiling Dashboard\\\", columns=(1,3))]\\n\\ngr.Interface(plot, inputs=inputs, outputs=outputs, examples=[df.head(100)], title=\\\"Supersoaker Failures Analysis Dashboard\\\").launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio Interface with Batch Processing\nDESCRIPTION: Example showing how to set up a Gradio Interface with batch processing enabled. Uses batch=True and max_batch_size=16 to process up to 16 requests in parallel.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/06_batch-functions.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndemo = gr.Interface(\n    fn=trim_words, \n    inputs=[\"textbox\", \"number\"], \n    outputs=[\"output\"],\n    batch=True, \n    max_batch_size=16\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Gradio UI with Chained Events\nDESCRIPTION: Creates a Gradio interface using Blocks API that demonstrates various event handling patterns including success, failure, warning and info events. The demo includes multiple buttons and textboxes to showcase event chaining and status messages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_chained_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef failure():\n    raise gr.Error(\"This should fail!\")\n\ndef exception():\n    raise ValueError(\"Something went wrong\")\n\ndef success():\n    return True\n\ndef warning_fn():\n    gr.Warning(\"This is a warning!\")\n\ndef info_fn():\n    gr.Info(\"This is some info\")\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Used in E2E tests of success event trigger. The then event covered in chatbot E2E tests.\"\n                \" Also testing that the status modals show up.\")\n    with gr.Row():\n        result = gr.Textbox(label=\"Result\")\n        result_2 = gr.Textbox(label=\"Consecutive Event\")\n    with gr.Row():\n        success_btn = gr.Button(value=\"Trigger Success\")\n        success_btn_2 = gr.Button(value=\"Trigger Consecutive Success\")\n        failure_btn = gr.Button(value=\"Trigger Failure\")\n        failure_exception = gr.Button(value=\"Trigger Failure With ValueError\")\n    with gr.Row():\n        trigger_warning = gr.Button(value=\"Trigger Warning\")\n        trigger_info = gr.Button(value=\"Trigger Info\")\n\n        success_btn_2.click(success, None, None).success(lambda: \"First Event Trigered\", None, result).success(lambda: \"Consecutive Event Triggered\", None, result_2)\n        success_btn.click(success, None, None).success(lambda: \"Success event triggered\", inputs=None, outputs=result)\n        failure_btn.click(failure, None, None).success(lambda: \"Should not be triggered\", inputs=None, outputs=result)\n        failure_exception.click(exception, None, None)\n        trigger_warning.click(warning_fn, None, None)\n        trigger_info.click(info_fn, None, None)\n\nif __name__ == \"__main__\":\n    demo.launch(show_error=True)\n```\n\n----------------------------------------\n\nTITLE: Launching a Gradio App with Share Link (Python)\nDESCRIPTION: Demonstrates how to launch a Gradio application with a publicly accessible share link by using the \\'share=True\\' parameter in the .launch() method. No explicit dependencies beyond Gradio itself are needed, but the FRP Client will be downloaded if necessary. The core parameters include the Gradio Blocks context and the optional share flag; output is the launch of a web app accessible via a \\'gradio.live\\' URL. This enables instant sharing and remote access to local ML applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/understanding-gradio-share-links.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    ...\\n\\ndemo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Audio Mixer Application using Gradio Render Decorator\nDESCRIPTION: This complex example demonstrates an audio mixer application using the @gr.render decorator. It allows users to add multiple audio tracks, adjust their volumes, and mix them together, showcasing advanced usage of dynamic components and event listeners.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/04_dynamic-apps-with-render-decorator.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    tracks = gr.State([])\n    with gr.Row():\n        add_track = gr.Button(\"Add Track\")\n        mix_btn = gr.Button(\"Mix\")\n    track_list = gr.Column()\n    output_audio = gr.Audio()\n\n    def add_new_track(track_list):\n        track_list.append([None, 1.0])  # [audio, volume]\n        return track_list\n\n    add_track.click(add_new_track, tracks, tracks)\n\n    @gr.render()\n    def render_tracks(track_list):\n        components = set()\n        for i, (audio, volume) in enumerate(track_list):\n            with gr.Row() as track:\n                audio_comp = gr.Audio(value=audio, key=f\"audio_{i}\")\n                slider = gr.Slider(value=volume, minimum=0, maximum=1, key=f\"volume_{i}\")\n            components.add(audio_comp)\n            components.add(slider)\n\n        def mix(inputs):\n            mixed = None\n            for i in range(len(track_list)):\n                audio = inputs[f\"audio_{i}\"]\n                if audio is None:\n                    continue\n                volume = inputs[f\"volume_{i}\"]\n                audio_array = audio[1]\n                if len(audio_array.shape) > 1:\n                    audio_array = np.mean(audio_array, axis=1)\n                if mixed is None:\n                    mixed = audio_array * volume\n                else:\n                    mixed += audio_array * volume\n            if mixed is None:\n                return None\n            return (audio[0], mixed)\n\n        mix_btn.click(mix, inputs=components, outputs=output_audio)\n\n        return track_list\n\n    tracks.change(render_tracks, tracks, track_list)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining File Handling Utility Functions in JavaScript/TypeScript\nDESCRIPTION: This snippet showcases function signatures and one implementation for utility functions within the `@gradio/upload` package. It includes overloaded signatures for `normalise_file` (which adjusts file data based on server/proxy URLs), `get_fetchable_url_or_file` (to get a usable URL), `upload` (to handle the upload process), and the implementation of `prepare_files` (which converts browser `File` objects into `FileData` objects). These functions are essential for processing and managing files before and during upload.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport function normalise_file(\n\tfile: FileData | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): FileData | null;\n\nexport function normalise_file(\n\tfile: FileData[] | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): FileData[] | null;\n\nexport function normalise_file(\n\tfile: FileData[] | FileData | null,\n\tserver_url: string, // root: string,\n\tproxy_url: string | null // root_url: string | null\n): FileData[] | FileData | null;\n\nexport function normalise_file(\n\tfile: FileData[] | FileData | null,\n\tserver_url: string, // root: string,\n\tproxy_url: string | null // root_url: string | null\n): FileData[] | FileData | null;\n\nexport function get_fetchable_url_or_file(\n\tpath: string | null,\n\tserver_url: string,\n\tproxy_url: string | null\n): string\n\nexport async function upload(\n\tfile_data: FileData[],\n\troot: string,\n\tupload_fn: typeof upload_files = upload_files\n): Promise<(FileData | null)[] | null>\n\nexport async function prepare_files(\n\tfiles: File[],\n\tis_stream?: boolean\n): Promise<FileData[]> {\n\treturn files.map(\n\t\t(f, i) =>\n\t\t\tnew FileData({\n\t\t\t\tpath: f.name,\n\t\t\t\torig_name: f.name,\n\t\t\t\tblob: f,\n\t\t\t\tsize: f.size,\n\t\t\t\tmime_type: f.type,\n\t\t\t\tis_stream\n\t\t\t})\n\t);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Clear Components Demo for Gradio\nDESCRIPTION: This extensive code snippet creates a Gradio interface with various components, including textboxes, sliders, checkboxes, and more. It demonstrates how to initialize these components with random or dynamic values, and provides functionality to clear, hide, and reveal them.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/clear_components/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom datetime import datetime\nimport os\nimport random\nimport string\nimport pandas as pd\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef random_plot():\n    start_year = 2020\n    x = np.arange(start_year, start_year + 5)\n    year_count = x.shape[0]\n    plt_format = \"-\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    series = np.arange(0, year_count, dtype=float)\n    series = series**2\n    series += np.random.rand(year_count)\n    ax.plot(x, series, plt_format)\n    return fig\n\nimages = [\n    \"https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=387&q=80\",\n    \"https://images.unsplash.com/photo-1554151228-14d9def656e4?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=386&q=80\",\n    \"https://images.unsplash.com/photo-1542909168-82c3e7fdca5c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8aHVtYW4lMjBmYWNlfGVufDB8fDB8fA%3D%3D&w=1000&q=80\",\n]\nfile_dir = os.path.join(os.path.abspath(''), \"..\", \"kitchen_sink\", \"files\")\nmodel3d_dir = os.path.join(os.path.abspath(''), \"..\", \"model3D\", \"files\")\nhighlighted_text_output_1 = [\n    {\n        \"entity\": \"I-LOC\",\n        \"score\": 0.9988978,\n        \"index\": 2,\n        \"word\": \"Chicago\",\n        \"start\": 5,\n        \"end\": 12,\n    },\n    {\n        \"entity\": \"I-MISC\",\n        \"score\": 0.9958592,\n        \"index\": 5,\n        \"word\": \"Pakistani\",\n        \"start\": 22,\n        \"end\": 31,\n    },\n]\nhighlighted_text_output_2 = [\n    {\n        \"entity\": \"I-LOC\",\n        \"score\": 0.9988978,\n        \"index\": 2,\n        \"word\": \"Chicago\",\n        \"start\": 5,\n        \"end\": 12,\n    },\n    {\n        \"entity\": \"I-LOC\",\n        \"score\": 0.9958592,\n        \"index\": 5,\n        \"word\": \"Pakistan\",\n        \"start\": 22,\n        \"end\": 30,\n    },\n]\n\nhighlighted_text = \"Does Chicago have any Pakistani restaurants\"\n\ndef random_model3d():\n    model_3d = random.choice(\n        [os.path.join(model3d_dir, model) for model in os.listdir(model3d_dir) if model != \"source.txt\"]\n    )\n    return model_3d\n\ncomponents = [\n    gr.Textbox(value=lambda: datetime.now(), label=\"Current Time\"),\n    gr.Number(value=lambda: random.random(), label=\"Random Percentage\"),\n    gr.Slider(minimum=0, maximum=100, randomize=True, label=\"Slider with randomize\"),\n    gr.Slider(\n        minimum=0,\n        maximum=1,\n        value=lambda: random.random(),\n        label=\"Slider with value func\",\n    ),\n    gr.Checkbox(value=lambda: random.random() > 0.5, label=\"Random Checkbox\"),\n    gr.CheckboxGroup(\n        choices=[\"a\", \"b\", \"c\", \"d\"],\n        value=lambda: random.choice([\"a\", \"b\", \"c\", \"d\"]),\n        label=\"Random CheckboxGroup\",\n    ),\n    gr.Radio(\n        choices=list(string.ascii_lowercase),\n        value=lambda: random.choice(string.ascii_lowercase),\n    ),\n    gr.Dropdown(\n        choices=[\"a\", \"b\", \"c\", \"d\", \"e\"],\n        value=lambda: random.choice([\"a\", \"b\", \"c\"]),\n    ),\n    gr.Image(\n        value=lambda: random.choice(images)\n    ),\n    gr.Video(value=lambda: os.path.join(file_dir, \"world.mp4\")),\n    gr.Audio(value=lambda: os.path.join(file_dir, \"cantina.wav\")),\n    gr.File(\n        value=lambda: random.choice(\n            [os.path.join(file_dir, img) for img in os.listdir(file_dir)]\n        )\n    ),\n    gr.Dataframe(\n        value=lambda: pd.DataFrame({\"random_number_rows\": range(5)}, columns=[\"one\", \"two\", \"three\"])  # type: ignore\n    ),\n    gr.ColorPicker(value=lambda: random.choice([\"#000000\", \"#ff0000\", \"#0000FF\"])),\n    gr.Label(value=lambda: random.choice([\"Pedestrian\", \"Car\", \"Cyclist\"])),\n    gr.HighlightedText(\n        value=lambda: random.choice(\n            [\n                {\"text\": highlighted_text, \"entities\": highlighted_text_output_1},\n                {\"text\": highlighted_text, \"entities\": highlighted_text_output_2},\n            ]\n        ),\n    ),\n    gr.JSON(value=lambda: random.choice([{\"a\": 1}, {\"b\": 2}])),\n    gr.HTML(\n        value=lambda: random.choice(\n            [\n                '<p style=\"color:red;\">I am red</p>',\n                '<p style=\"color:blue;\">I am blue</p>',\n            ]\n        )\n    ),\n    gr.Gallery(\n        value=lambda: images\n    ),\n    gr.Model3D(value=random_model3d),\n    gr.Plot(value=random_plot),\n    gr.Markdown(value=lambda: f\"### {random.choice(['Hello', 'Hi', 'Goodbye!'])}\"),\n]\n\ndef evaluate_values(*args):\n    are_false = []\n    for a in args:\n        if isinstance(a, (pd.DataFrame, np.ndarray)):\n            are_false.append(not a.any().any())  # type: ignore\n        elif isinstance(a, str) and a.startswith(\"#\"):\n            are_false.append(a == \"#000000\")\n        else:\n            are_false.append(not a)\n    return all(are_false)\n\nwith gr.Blocks() as demo:\n    for i, component in enumerate(components):\n        component.label = f\"component_{str(i).zfill(2)}\"\n        component.render()\n    clear = gr.ClearButton(value=\"Clear\", components=components)\n    result = gr.Textbox(label=\"Are all cleared?\")\n    hide = gr.Button(value=\"Hide\")\n    reveal = gr.Button(value=\"Reveal\")\n    clear_button_and_components = components + [clear]\n    hide.click(\n        lambda: [c.__class__(visible=False) for c in clear_button_and_components],\n        inputs=[],\n        outputs=clear_button_and_components\n    )\n    reveal.click(\n        lambda: [c.__class__(visible=True) for c in clear_button_and_components],\n        inputs=[],\n        outputs=clear_button_and_components\n    )\n    get_value = gr.Button(value=\"Get Values\")\n    get_value.click(evaluate_values, components, result)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks Interface with Text and Image Components\nDESCRIPTION: Creates a Gradio Blocks interface with text combination and image mirroring functionality. The interface includes text inputs, image components, and examples for both functionalities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_inputs/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef combine(a, b):\n    return a + \" \" + b\n\ndef mirror(x):\n    return x\n\nwith gr.Blocks() as demo:\n\n    txt = gr.Textbox(label=\"Input\", lines=2)\n    txt_2 = gr.Textbox(label=\"Input 2\")\n    txt_3 = gr.Textbox(value=\"\", label=\"Output\")\n    btn = gr.Button(value=\"Submit\")\n    btn.click(combine, inputs=[txt, txt_2], outputs=[txt_3])\n\n    with gr.Row():\n        im = gr.Image()\n        im_2 = gr.Image()\n\n    btn = gr.Button(value=\"Mirror Image\")\n    btn.click(mirror, inputs=[im], outputs=[im_2])\n\n    gr.Markdown(\"## Text Examples\")\n    gr.Examples(\n        [[\"hi\", \"Adam\"], [\"hello\", \"Eve\"]],\n        [txt, txt_2],\n        txt_3,\n        combine,\n        cache_examples=True,\n    )\n    gr.Markdown(\"## Image Examples\")\n    gr.Examples(\n        examples=[os.path.join(os.path.abspath(''), \"lion.jpg\")],\n        inputs=im,\n        outputs=im_2,\n        fn=mirror,\n        cache_examples=True,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Tabbed Gradio Plot Demo in Python\nDESCRIPTION: This Python script constructs and launches a Gradio application. It imports the `gradio` library and specific plot modules downloaded previously. Using `gr.Blocks()`, it creates a UI layout containing `gr.Tabs()`. Each `gr.TabItem` is dedicated to a plot type (Line, Scatter, Bar) and calls the respective `render()` function from the imported modules to display the plots. The `if __name__ == \"__main__\":` block ensures the application is launched using `demo.launch()` only when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/native_plots/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nfrom scatter_plot_demo import scatter_plots\nfrom line_plot_demo import line_plots\nfrom bar_plot_demo import bar_plots\n\nwith gr.Blocks() as demo:\n    with gr.Tabs():\n        with gr.TabItem(\"Line Plot\"):\n            line_plots.render()\n        with gr.TabItem(\"Scatter Plot\"):\n            scatter_plots.render()\n        with gr.TabItem(\"Bar Plot\"):\n            bar_plots.render()\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Editor Events Demo\nDESCRIPTION: Creates an interactive Gradio application with an image editor component that tracks various events (upload, change, input, apply) and displays their counts. Includes image preview functionality and a clear button with verification.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\n\ndef predict(im):\n    return im[\"composite\"]\n\n\ndef verify_clear(im):\n    print(im)\n    return int(not np.any(im[\"composite\"])), im[\"composite\"]\n\n\nwith gr.Blocks() as demo:\n    with gr.Group():\n        with gr.Row():\n            im = gr.ImageEditor(\n                type=\"numpy\",\n                crop_size=\"1:1\",\n                elem_id=\"image_editor\",\n            )\n            im_preview = gr.Image()\n    with gr.Group():\n        with gr.Row():\n\n            n_upload = gr.Label(\n                0,\n                label=\"upload\",\n                elem_id=\"upload\",\n            )\n            n_change = gr.Label(\n                0,\n                label=\"change\",\n                elem_id=\"change\",\n            )\n            n_input = gr.Label(\n                0,\n                label=\"input\",\n                elem_id=\"input\",\n            )\n            n_apply = gr.Label(\n                0,\n                label=\"apply\",\n                elem_id=\"apply\",\n            )\n            cleared_properly = gr.Number(label=\"cleared properly\")\n    clear_btn = gr.Button(\"Clear Button\", elem_id=\"clear\")\n\n    im.upload(\n        lambda x: int(x) + 1, outputs=n_upload, inputs=n_upload, show_progress=\"hidden\"\n    )\n    im.change(\n        lambda x: int(x) + 1, outputs=n_change, inputs=n_change, show_progress=\"hidden\"\n    )\n    im.input(\n        lambda x: int(x) + 1, outputs=n_input, inputs=n_input, show_progress=\"hidden\"\n    )\n    im.apply(\n        lambda x: int(x) + 1, outputs=n_apply, inputs=n_apply, show_progress=\"hidden\"\n    )\n    im.change(predict, outputs=im_preview, inputs=im, show_progress=\"hidden\")\n    clear_btn.click(\n        lambda: None,\n        None,\n        im,\n    ).then(verify_clear, inputs=im, outputs=[cleared_properly, im])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio-Lite Hello World Implementation\nDESCRIPTION: Complete HTML implementation of a simple Gradio hello world application using gradio-lite tags and Python code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/05_gradio-lite.md#2025-04-23_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n\t<body>\n\t\t<gradio-lite>\n\t\timport gradio as gr\n\n\t\tdef greet(name):\n\t\t\treturn \"Hello, \" + name + \"!\"\n\n\t\tgr.Interface(greet, \"textbox\", \"textbox\").launch()\n\t\t</gradio-lite>\n\t</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Implementing Dynamic Textbox Visibility with Gradio Slider (Python)\nDESCRIPTION: This Python script defines a Gradio application using the `Blocks` interface. It creates a Slider (`s`) and a fixed number (`max_textboxes`) of Textbox components. A function `variable_outputs` takes the Slider's value (`k`) and returns a list of Gradio update objects, setting the first `k` Textboxes to visible and the remaining ones to hidden. The `s.change()` method connects the Slider's value change event to the `variable_outputs` function, dynamically updating the `textboxes` list based on user interaction. The application is launched using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/variable_outputs/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nmax_textboxes = 10\n\ndef variable_outputs(k):\n    k = int(k)\n    return [gr.Textbox(visible=True)]*k + [gr.Textbox(visible=False)]*(max_textboxes-k)\n\nwith gr.Blocks() as demo:\n    s = gr.Slider(1, max_textboxes, value=max_textboxes, step=1, label=\"How many textboxes to show:\")\n    textboxes = []\n    for i in range(max_textboxes):\n        t = gr.Textbox(f\"Textbox {i}\")\n        textboxes.append(t)\n\n    s.change(variable_outputs, s, textboxes)\n\nif __name__ == \"__main__\":\n   demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks Interface for Chat Application\nDESCRIPTION: This code block sets up the Gradio Blocks interface for the chat application. It includes a chatbot component, response type selector, and input box. It also defines the submission and response generation logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(fill_height=True) as demo:\n    chatbot = gr.Chatbot(\n        elem_id=\"chatbot\",\n        type=\"messages\",\n        bubble_full_width=False,\n        scale=1,\n        show_copy_button=True,\n        avatar_images=(\n            None,  # os.path.join(\"files\", \"avatar.png\"),\n            os.path.join(\"files\", \"avatar.png\"),\n        ),\n    )\n    response_type = gr.Radio(\n        [\n            \"audio_file\",\n            \"image_file\",\n            \"video_file\",\n            \"txt_file\",\n            \"plot\",\n            \"matplotlib_plot\",\n            \"bokeh_plot\",\n            \"image\",\n            \"text\",\n            \"gallery\",\n            \"dataframe\",\n            \"video\",\n            \"audio\",\n            \"html\",\n        ],\n        value=\"text\",\n        label=\"Response Type\",\n    )\n\n    chat_input = gr.MultimodalTextbox(\n        interactive=True,\n        placeholder=\"Enter message or upload file...\",\n        show_label=False,\n    )\n\n    chat_msg = chat_input.submit(\n        add_message, [chatbot, chat_input], [chatbot, chat_input]\n    )\n    bot_msg = chat_msg.then(\n        bot, [chatbot, response_type], chatbot, api_name=\"bot_response\"\n    )\n    bot_msg.then(lambda: gr.MultimodalTextbox(interactive=True), None, [chat_input])\n\n    chatbot.like(print_like_dislike, None, None)\n```\n\n----------------------------------------\n\nTITLE: Customized ChatInterface Implementation\nDESCRIPTION: Advanced example showing various customization options for the chat interface including themes, examples, and component customization\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef yes_man(message, history):\n    if message.endswith(\"?\"):\n        return \"Yes\"\n    else:\n        return \"Ask me anything!\"\n\ngr.ChatInterface(\n    yes_man,\n    type=\"messages\",\n    chatbot=gr.Chatbot(height=300),\n    textbox=gr.Textbox(placeholder=\"Ask me a yes or no question\", container=False, scale=7),\n    title=\"Yes Man\",\n    description=\"Ask Yes Man any question\",\n    theme=\"ocean\",\n    examples=[\"Hello\", \"Am I cool?\", \"Are tomatoes vegetables?\"],\n    cache_examples=True,\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Interface with State Management\nDESCRIPTION: Creates a Gradio interface that stores message history using State components. The interface accepts text input and maintains a list of previous messages, displaying both current and historical messages in JSON format.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_state/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef store_message(message: str, history: list[str]):  # type: ignore\n    output = {\n        \"Current messages\": message,\n        \"Previous messages\": history[::-1]\n    }\n    history.append(message)\n    return output, history\n\ndemo = gr.Interface(fn=store_message,\n                    inputs=[\"textbox\", gr.State(value=[])],\n                    outputs=[\"json\", gr.State()])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building the Gradio User Interface for Feedback Collection - Python\nDESCRIPTION: This code uses the Gradio Blocks API to create an interactive feedback form, binding UI elements to backend logic. It defines input fields for name, rating, and comments, a submit button, and an output Dataframe and Number for displaying recent reviews and their count. The submit event is linked to the `add_review` function; the UI loads the latest data via the `load_data` function. Dependencies include Gradio and the previously defined data functions, and the UI is reactive.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-background-tasks.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            name = gr.Textbox(label=\"Name\", placeholder=\"What is your name?\")\n            review = gr.Radio(label=\"How satisfied are you with using gradio?\", choices=[1, 2, 3, 4, 5])\n            comments = gr.Textbox(label=\"Comments\", lines=10, placeholder=\"Do you have any feedback on gradio?\")\n            submit = gr.Button(value=\"Submit Feedback\")\n        with gr.Column():\n            data = gr.Dataframe(label=\"Most recently created 10 rows\")\n            count = gr.Number(label=\"Total number of reviews\")\n    submit.click(add_review, [name, review, comments], [data, count])\n    demo.load(load_data, None, [data, count])\n```\n\n----------------------------------------\n\nTITLE: Audio Response Generation and Streaming\nDESCRIPTION: Handles conversion of audio formats, manages conversation history, and streams chatbot responses. Uses pydub for audio processing and implements a generator pattern for streaming.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/04_conversational-chatbot.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport io\nimport tempfile\nfrom pydub import AudioSegment\n\ndef response(state: AppState):\n    if not state.pause_detected and not state.started_talking:\n        return None, AppState()\n    \n    audio_buffer = io.BytesIO()\n\n    segment = AudioSegment(\n        state.stream.tobytes(),\n        frame_rate=state.sampling_rate,\n        sample_width=state.stream.dtype.itemsize,\n        channels=(1 if len(state.stream.shape) == 1 else state.stream.shape[1]),\n    )\n    segment.export(audio_buffer, format=\"wav\")\n\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n        f.write(audio_buffer.getvalue())\n    \n    state.conversation.append({\"role\": \"user\",\n                                \"content\": {\"path\": f.name,\n                                \"mime_type\": \"audio/wav\"}})\n    \n    output_buffer = b\"\"\n\n    for mp3_bytes in speaking(audio_buffer.getvalue()):\n        output_buffer += mp3_bytes\n        yield mp3_bytes, state\n\n    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as f:\n        f.write(output_buffer)\n    \n    state.conversation.append({\"role\": \"assistant\",\n                    \"content\": {\"path\": f.name,\n                                \"mime_type\": \"audio/mp3\"}})\n    yield None, AppState(conversation=state.conversation)\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio App with LoginButton (Python)\nDESCRIPTION: This Python script imports the Gradio library (as 'gr'), creates a Gradio Blocks interface, adds a `gr.LoginButton()` component to the interface, and then launches the web application using `demo.launch()`. This demonstrates the basic structure for creating a Gradio app and incorporating the login button.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/loginbutton_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.LoginButton()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Flask Server Integration with Gradio Client\nDESCRIPTION: Example showing how to use the Gradio client within a Flask server using gevent. Demonstrates creating an endpoint that generates images using a diffusion model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom gevent import monkey\nmonkey.patch_all()\n\nfrom gradio_client import Client\nfrom flask import Flask, send_file\nimport time\n\napp = Flask(__name__)\n\nimageclient = Client(\"gradio/diffusion_model\")\n\n@app.route(\"/gen\")\ndef gen():\n      result = imageclient.predict(\n                \"A cute cat\",\n                api_name=\"/predict\"\n              )\n      return send_file(result)\n\nif __name__ == \"__main__\":\n      app.run(host=\"0.0.0.0\", port=5000)\n```\n\n----------------------------------------\n\nTITLE: Defining Gradio Blocks with State Cleanup Demo\nDESCRIPTION: This code snippet demonstrates how to define a Gradio Blocks interface with automatic state cleanup when users disconnect. It includes an image generation demo with user-specific directories that are deleted on page unload.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    gr.Markdown(\n\"\"\"# State Cleanup Demo\n🖼️ Images are saved in a user-specific directory and deleted when the users closes the page via demo.unload.\n\"\"\")\n    with gr.Row():\n        with gr.Column(scale=1):\n            with gr.Row():\n                img = gr.Image(label=\"Generated Image\", height=300, width=300)\n            with gr.Row():\n                gen = gr.Button(value=\"Generate\")\n            with gr.Row():\n                history = gr.Gallery(label=\"Previous Generations\", height=500, columns=10)\n                state = gr.State(value=[], delete_callback=lambda v: print(\"STATE DELETED\"))\n\n    demo.load(generate_random_img, [state], [img, state, history]) \n    gen.click(generate_random_img, [state], [img, state, history])\n    demo.unload(delete_directory)\n\n\ndemo.launch(auth=lambda user,pwd: True,\n            auth_message=\"Enter any username and password to continue\")\n```\n\n----------------------------------------\n\nTITLE: Displaying and Filtering AirBnB Locations on Interactive Map with Gradio and Plotly - Python\nDESCRIPTION: Implements a Gradio Blocks-based web app that displays an interactive map of AirBnB locations in NYC using Plotly. Loads the dataset from HuggingFace, converts it to a Pandas DataFrame, and filters entries by selectable boroughs and user-input price range. The interface allows users to select boroughs via checkboxes, set minimum and maximum price via input fields, and updates the map upon loading or button click. Dependencies include gradio, plotly, and datasets. Inputs are Filter criteria, and the output is a Plotly map with AirBnB locations as markers, where each marker shows property name and price on hover. The code is intended for demonstration purposes and should be run in an environment where required packages are installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/map_airbnb/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# type: ignore\nimport gradio as gr\nimport plotly.graph_objects as go\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n\n    filtered_df = df[(df['neighbourhood_group'].isin(boroughs)) &\n          (df['price'] > min_price) & (df['price'] < max_price)]\n    names = filtered_df[\"name\"].tolist()\n    prices = filtered_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n    fig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=filtered_df['latitude'].tolist(),\n            lon=filtered_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='<b>Name</b>: %{customdata[0]}<br><b>Price</b>: $%{customdata[1]}'\n        ))\n\n    fig.update_layout(\n        mapbox_style=\"open-street-map\",\n        hovermode='closest',\n        mapbox=dict(\n            bearing=0,\n            center=go.layout.mapbox.Center(\n                lat=40.67,\n                lon=-73.90\n            ),\n            pitch=0,\n            zoom=9\n        ),\n    )\n\n    return fig\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        with gr.Row():\n            min_price = gr.Number(value=250, label=\"Minimum Price\")\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\n        btn = gr.Button(value=\"Update Filter\")\n        map = gr.Plot()\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Interface with Basic Manual Flagging (Python)\nDESCRIPTION: Defines a simple calculator function and creates a Gradio Interface (`gr.Interface`) for it. It configures basic flagging by setting `flagging_mode` to `\"manual\"`, which adds a 'Flag' button to the UI. When clicked, input and output data are saved.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    flagging_mode=\"manual\"\n)\n\niface.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing State Cleanup in Gradio Blocks\nDESCRIPTION: This code snippet demonstrates how to use the new Blocks.unload() event to clean up state when users disconnect. It generates random images, saves them to a user-specific directory, and deletes the directory when the user closes the page.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    gr.Markdown(\n\"\"\"# State Cleanup Demo\n🖼️ Images are saved in a user-specific directory and deleted when the users closes the page via demo.unload.\n\"\"\")\n    with gr.Row():\n        with gr.Column(scale=1):\n            with gr.Row():\n                img = gr.Image(label=\"Generated Image\", height=300, width=300)\n            with gr.Row():\n                gen = gr.Button(value=\"Generate\")\n            with gr.Row():\n                history = gr.Gallery(label=\"Previous Generations\", height=500, columns=10)\n                state = gr.State(value=[], delete_callback=lambda v: print(\"STATE DELETED\"))\n\n    demo.load(generate_random_img, [state], [img, state, history]) \n    gen.click(generate_random_img, [state], [img, state, history])\n    demo.unload(delete_directory)\n\n\ndemo.launch(auth=lambda user,pwd: True,\n            auth_message=\"Enter any username and password to continue\")\n```\n\n----------------------------------------\n\nTITLE: Loading Multiple Spaces in Gradio Tabs\nDESCRIPTION: Demonstrates how to combine multiple existing Gradio demos from Hugging Face Spaces into a single interface with tabs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/01_using-hugging-face-integrations.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n  with gr.Tab(\"Translate to Spanish\"):\n    gr.load(\"gradio/en2es\", src=\"spaces\")\n  with gr.Tab(\"Translate to French\"):\n    gr.load(\"abidlabs/en2fr\", src=\"spaces\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Application State Management with Dataclass\nDESCRIPTION: Defines the application state structure using Python's dataclass to track audio stream, sampling rate, conversation status, and history.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/04_conversational-chatbot.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\n@dataclass\nclass AppState:\n    stream: np.ndarray | None = None\n    sampling_rate: int = 0\n    pause_detected: bool = False\n    stopped: bool = False\n    conversation: list = []\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Line Plot with Selection Feature in Gradio\nDESCRIPTION: Implements a Gradio Blocks interface with a line plot visualization that allows users to select regions on the plot and calculates the sum of weights in the selected region. The interface displays the total weight of the selection in a Number component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_selection/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    plt = gr.LinePlot(df, x=\"weight\", y=\"height\")\n    selection_total = gr.Number(label=\"Total Weight of Selection\")\n\n    def select_region(selection: gr.SelectData):\n        min_w, max_w = selection.index\n        return df[(df[\"weight\"] >= min_w) & (df[\"weight\"] <= max_w)][\"weight\"].sum()\n\n    plt.select(select_region, None, selection_total)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing BlockContext Component in Python\nDESCRIPTION: Example showing how to create a Row component by inheriting from BlockContext with ComponentMeta metaclass.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/04_backend.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio.blocks import BlockContext\nfrom gradio.component_meta import ComponentMeta\n\n\n\n@document()\nclass Row(BlockContext, metaclass=ComponentMeta):\n    pass\n```\n\n----------------------------------------\n\nTITLE: Initializing Whisper ASR Model with Transformers\nDESCRIPTION: Sets up a speech recognition pipeline using the Whisper base model from Hugging Face transformers library for English language processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/05_real-time-speech-recognition.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import pipeline\n\np = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface with Various Progress Tracking Methods\nDESCRIPTION: Creates a complete Gradio interface demonstrating different progress tracking methods including tracking lists, nested lists, iterables of unknown length, manual progress updates, and tqdm integration. The demo includes multiple buttons that trigger different progress tracking scenarios.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\nimport tqdm\nfrom datasets import load_dataset\nimport shutil\nfrom uuid import uuid4\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text = gr.Textbox()\n        textb = gr.Textbox()\n    with gr.Row():\n        load_set_btn = gr.Button(\"Load Set\")\n        load_nested_set_btn = gr.Button(\"Load Nested Set\")\n        load_random_btn = gr.Button(\"Load Random\")\n        clean_imgs_btn = gr.Button(\"Clean Images\")\n        wait_btn = gr.Button(\"Wait\")\n        do_all_btn = gr.Button(\"Do All\")\n        track_tqdm_btn = gr.Button(\"Bind TQDM\")\n        bind_internal_tqdm_btn = gr.Button(\"Bind Internal TQDM\")\n\n    text2 = gr.Textbox()\n\n    # track list\n    def load_set(text, text2, progress=gr.Progress()):\n        imgs = [None] * 24\n        for img in progress.tqdm(imgs, desc=\"Loading from list\"):\n            time.sleep(0.1)\n        return \"done\"\n    load_set_btn.click(load_set, [text, textb], text2)\n\n    # track nested list\n    def load_nested_set(text, text2, progress=gr.Progress()):\n        imgs = [[None] * 8] * 3\n        for img_set in progress.tqdm(imgs, desc=\"Nested list\"):\n            time.sleep(2)\n            for img in progress.tqdm(img_set, desc=\"inner list\"):\n                time.sleep(0.1)\n        return \"done\"\n    load_nested_set_btn.click(load_nested_set, [text, textb], text2)\n\n    # track iterable of unknown length\n    def load_random(data, progress=gr.Progress()):\n        def yielder():\n            for i in range(0, random.randint(15, 20)):\n                time.sleep(0.1)\n                yield None\n        for img in progress.tqdm(yielder()):\n            pass\n        return \"done\"\n    load_random_btn.click(load_random, {text, textb}, text2)\n\n    # manual progress\n    def clean_imgs(text, progress=gr.Progress()):\n        progress(0.2, desc=\"Collecting Images\")\n        time.sleep(1)\n        progress(0.5, desc=\"Cleaning Images\")\n        time.sleep(1.5)\n        progress(0.8, desc=\"Sending Images\")\n        time.sleep(1.5)\n        return \"done\"\n    clean_imgs_btn.click(clean_imgs, text, text2)\n\n    # no progress\n    def wait(text):\n        time.sleep(4)\n        return \"done\"\n    wait_btn.click(wait, text, text2)\n\n    # multiple progressions\n    def do_all(data, progress=gr.Progress()):\n        load_set(data[text], data[textb], progress)\n        load_random(data, progress)\n        clean_imgs(data[text], progress)\n        progress(None)\n        wait(text)\n        return \"done\"\n    do_all_btn.click(do_all, {text, textb}, text2)\n\n    def track_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        for i in tqdm.tqdm(range(5), desc=\"outer\"):\n            for j in tqdm.tqdm(range(4), desc=\"inner\"):\n                time.sleep(1)\n        return \"done\"\n    track_tqdm_btn.click(track_tqdm, {text, textb}, text2)\n\n    def bind_internal_tqdm(data, progress=gr.Progress(track_tqdm=True)):\n        outdir = \"__tmp/\" + str(uuid4())\n        load_dataset(\"beans\", split=\"train\", cache_dir=outdir)\n        shutil.rmtree(outdir)\n        return \"done\"\n    bind_internal_tqdm_btn.click(bind_internal_tqdm, {text, textb}, text2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Gradio App with Markdown Component\nDESCRIPTION: This Python snippet imports the Gradio library, defines a Gradio Blocks interface named `demo`, adds a Markdown component initialized with the content of the `md` variable (defined in a previous snippet), and launches the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.Blocks() as demo:\n    gr.Markdown(value=md)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building Sentence Generator with Gradio Blocks and JavaScript Methods\nDESCRIPTION: Creates a Gradio app using Blocks interface with various UI components for generating and manipulating sentences. Demonstrates how to use JavaScript functions alongside Python functions for client-side processing of inputs before sending to the server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_js_methods/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nblocks = gr.Blocks()\n\nwith blocks as demo:\n    subject = gr.Textbox(placeholder=\"subject\")\n    verb = gr.Radio([\"ate\", \"loved\", \"hated\"])\n    object = gr.Textbox(placeholder=\"object\")\n\n    with gr.Row():\n        btn = gr.Button(\"Create sentence.\")\n        reverse_btn = gr.Button(\"Reverse sentence.\")\n        foo_bar_btn = gr.Button(\"Append foo\")\n        reverse_then_to_the_server_btn = gr.Button(\n            \"Reverse sentence and send to server.\"\n        )\n\n    def sentence_maker(w1, w2, w3):\n        return f\"{w1} {w2} {w3}\"\n\n    output1 = gr.Textbox(label=\"output 1\")\n    output2 = gr.Textbox(label=\"verb\")\n    output3 = gr.Textbox(label=\"verb reversed\")\n    output4 = gr.Textbox(label=\"front end process and then send to backend\")\n\n    btn.click(sentence_maker, [subject, verb, object], output1)\n    reverse_btn.click(\n        None, [subject, verb, object], output2, js=\"(s, v, o) => o + ' ' + v + ' ' + s\"\n    )\n    verb.change(lambda x: x, verb, output3, js=\"(x) => [...x].reverse().join('')\")\n    foo_bar_btn.click(None, [], subject, js=\"(x) => x + ' foo'\")\n\n    reverse_then_to_the_server_btn.click(\n        sentence_maker,\n        [subject, verb, object],\n        output4,\n        js=\"(s, v, o) => [s, v, o].map(x => [...x].reverse().join(''))\",\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Real-time Data Visualization with Timer in Gradio\nDESCRIPTION: Demonstrates how to create real-time plots using gr.Timer() to periodically update multiple plots with new data. Shows two methods: using timer.tick() and the 'every' parameter shorthand.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/02_time-plots.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    timer = gr.Timer(5)\n    plot1 = gr.BarPlot(x=\"time\", y=\"price\")\n    plot2 = gr.BarPlot(x=\"time\", y=\"price\", color=\"origin\")\n\n    timer.tick(lambda: [get_data(), get_data()], outputs=[plot1, plot2])\n```\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    timer = gr.Timer(5)\n    plot1 = gr.BarPlot(get_data, x=\"time\", y=\"price\", every=timer)\n    plot2 = gr.BarPlot(get_data, x=\"time\", y=\"price\", color=\"origin\", every=timer)\n```\n\n----------------------------------------\n\nTITLE: Activating Voice Activity Detection (VAD) with ONNX and vad-web - JavaScript\nDESCRIPTION: This asynchronous JavaScript function loads ONNX Runtime and vad-web libraries, then configures microphone voice activity detection (VAD) in the browser. On speech start, it simulates a click on the record button; on speech end, it triggers the stop button. This enables automatic hands-free recording for the Gradio UI. Prerequisites: HTML UI must have elements with '.record-button' and '.stop-button' classes. CDN libraries are loaded dynamically, and error handling should be considered for production.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\nasync function main() {\n  const script1 = document.createElement(\"script\");\n  script1.src = \"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js\";\n  document.head.appendChild(script1)\n  const script2 = document.createElement(\"script\");\n  script2.onload = async () =>  {\n    console.log(\"vad loaded\");\n    var record = document.querySelector('.record-button');\n    record.textContent = \"Just Start Talking!\"\n    \n    const myvad = await vad.MicVAD.new({\n      onSpeechStart: () => {\n        var record = document.querySelector('.record-button');\n        var player = document.querySelector('#streaming-out')\n        if (record != null && (player == null || player.paused)) {\n          record.click();\n        }\n      },\n      onSpeechEnd: (audio) => {\n        var stop = document.querySelector('.stop-button');\n        if (stop != null) {\n          stop.click();\n        }\n      }\n    })\n    myvad.start()\n  }\n  script2.src = \"https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js\";\n}\n```\n\n----------------------------------------\n\nTITLE: Multi-File Gradio-Lite Implementation\nDESCRIPTION: Example showing how to structure a Gradio-Lite application with multiple Python files using gradio-file tags.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/05_gradio-lite.md#2025-04-23_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<gradio-lite>\n\n<gradio-file name=\"app.py\" entrypoint>\nimport gradio as gr\nfrom utils import add\n\ndemo = gr.Interface(fn=add, inputs=[\"number\", \"number\"], outputs=\"number\")\n\ndemo.launch()\n</gradio-file>\n\n<gradio-file name=\"utils.py\" >\ndef add(a, b):\n\treturn a + b\n</gradio-file>\n\n</gradio-lite>\n```\n\n----------------------------------------\n\nTITLE: Implementing a Unified Gradio Demo for Text Generation in Python\nDESCRIPTION: This snippet shows how to create a unified Gradio demo where the input and output components are the same. It demonstrates a text generation model using the `gradio.Interface` class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/05_four-kinds-of-interfaces.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef complete_text(text):\n    return text + \" and they lived happily ever after.\"\n\ndemo = gr.Interface(\n    fn=complete_text,\n    inputs=\"text\",\n    outputs=\"text\",\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Calculator Interface with Gradio\nDESCRIPTION: Creates a calculator interface using Gradio with support for addition, subtraction, multiplication, and division operations. Includes error handling for division by zero and example calculations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        if num2 == 0:\n            raise gr.Error(\"Cannot divide by zero!\")\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\n        \"number\",\n        gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]),\n        \"number\"\n    ],\n    \"number\",\n    examples=[\n        [45, \"add\", 3],\n        [3.14, \"divide\", 2],\n        [144, \"multiply\", 2.5],\n        [0, \"subtract\", 1.2],\n    ],\n    title=\"Toy Calculator\",\n    description=\"Here's a sample toy calculator.\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Editable Chatbot Interface with Gradio in Python\nDESCRIPTION: This code creates a Gradio interface with two chatbots, buttons for adding messages, and text displays. It demonstrates the use of Gradio's Blocks, Chatbot, Button, and Textbox components. The interface allows for adding messages to the chatbots and editing existing messages, with the changes reflected in the text displays.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_editable/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        chatbot = gr.Chatbot(value=[], type=\"messages\", editable=\"user\")\n        chatbot2 = gr.Chatbot(value=[], type=\"tuples\", editable=\"user\")\n    add_message_btn = gr.Button(\"Add Message\")\n\n    with gr.Row():\n        concatenated_text1 = gr.Textbox(label=\"Concatenated Chat 1\")\n        concatenated_text2 = gr.Textbox(label=\"Concatenated Chat 2\")\n        edited_messages = gr.Textbox(label=\"Edited Message\")\n\n    def add_message(history: list, history2: list[list[str]]):\n        usr_msg = \"I'm a user\"\n        bot_msg = \"I'm a bot\"\n        history.append({\"role\": \"user\", \"content\": usr_msg})\n        history.append({\"role\": \"assistant\", \"content\": bot_msg})\n        history2.append([usr_msg, bot_msg])\n        return history, history2\n    \n    add_message_btn.click(add_message, [chatbot, chatbot2], [chatbot, chatbot2])\n    chatbot.change(lambda m: \"|\".join(m[\"content\"] for m in m), chatbot, concatenated_text1)\n    chatbot2.change(lambda m: \"|\".join(\"|\".join(m) for m in m), chatbot2, concatenated_text2)\n\n    def edit_message(edited_message: gr.EditData):\n        return f\"from {edited_message.previous_value} to {edited_message.value} at {edited_message.index}\"\n    \n    chatbot.edit(edit_message, None, edited_messages)\n    chatbot2.edit(edit_message, None, edited_messages)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Managing Non-Deepcopyable Objects in Gradio Session State\nDESCRIPTION: This code shows how to handle objects that cannot be deepcopied in Gradio's session state. It uses a global dictionary to store user-specific instances of a non-deepcopyable class, managing initialization and cleanup for each session.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/03_state-in-blocks.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nclass NonDeepCopyable:\n    def __init__(self):\n        from threading import Lock\n        self.counter = 0\n        self.lock = Lock()  # Lock objects cannot be deepcopied\n    \n    def increment(self):\n        with self.lock:\n            self.counter += 1\n            return self.counter\n\n# Global dictionary to store user-specific instances\ninstances = {}\n\ndef initialize_instance(request: gr.Request):\n    instances[request.session_hash] = NonDeepCopyable()\n    return \"Session initialized!\"\n\ndef cleanup_instance(request: gr.Request):\n    if request.session_hash in instances:\n        del instances[request.session_hash]\n\ndef increment_counter(request: gr.Request):\n    if request.session_hash in instances:\n        instance = instances[request.session_hash]\n        return instance.increment()\n    return \"Error: Session not initialized\"\n\nwith gr.Blocks() as demo:\n    output = gr.Textbox(label=\"Status\")\n    counter = gr.Number(label=\"Counter Value\")\n    increment_btn = gr.Button(\"Increment Counter\")\n    increment_btn.click(increment_counter, inputs=None, outputs=counter)\n    \n    # Initialize instance when page loads\n    demo.load(initialize_instance, inputs=None, outputs=output)    \n    # Clean up instance when page is closed/refreshed\n    demo.close(cleanup_instance)    \n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Upload and Save Interface with No Output\nDESCRIPTION: Creates a Gradio interface that accepts an image upload, generates a random filename, saves the image with that filename, and prints a confirmation message. The interface has no output component, only handling the file saving operation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/save_file_no_output/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport string\nimport gradio as gr\n\ndef save_image_random_name(image):\n    random_string = ''.join(random.choices(string.ascii_letters, k=20)) + '.png'\n    image.save(random_string)\n    print(f\"Saved image to {random_string}!\")\n\ndemo = gr.Interface(\n    fn=save_image_random_name,\n    inputs=gr.Image(type=\"pil\"),\n    outputs=None,\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Country Display Demo with Gradio\nDESCRIPTION: Creates an interactive Gradio interface that displays countries with various controls including a slider for country count, alphabetical ordering option, random country selection with timer, and start/stop controls for the timer functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/function_values/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\ncountries = [\n    \"Algeria\", \"Argentina\", \"Australia\", \"Brazil\", \"Canada\", \"China\", \"Democratic Republic of the Congo\", \"Greenland (Denmark)\", \"India\", \"Kazakhstan\", \"Mexico\", \"Mongolia\", \"Peru\", \"Russia\", \"Saudi Arabia\", \"Sudan\", \"United States\"\n]\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        count = gr.Slider(1, 10, step=1, label=\"Country Count\")\n        alpha_order = gr.Checkbox(True, label=\"Alphabetical Order\")\n\n    gr.JSON(lambda count, alpha_order: countries[:count] if alpha_order else countries[-count:], inputs=[count, alpha_order])\n    timer = gr.Timer(1)\n    with gr.Row():\n        gr.Textbox(lambda: random.choice(countries), label=\"Random Country\", every=timer)\n        gr.Textbox(lambda count: \", \".join(random.sample(countries, count)), inputs=count, label=\"Random Countries\", every=timer)\n    with gr.Row():\n        gr.Button(\"Start\").click(lambda: gr.Timer(active=True), None, timer)\n        gr.Button(\"Stop\").click(lambda: gr.Timer(active=False), None, timer)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Gallery with Selection Controls\nDESCRIPTION: Creates a Gradio interface with an image gallery that supports image generation, selection, and manipulation. The demo generates random colored images, allows selecting individual images, and provides functionality to darken selected images and deselect all images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_selections/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    imgs = gr.State()\n    gallery = gr.Gallery(allow_preview=False)\n\n    def deselect_images():\n        return gr.Gallery(selected_index=None)\n\n    def generate_images():\n        images = []\n        for _ in range(9):\n            image = np.ones((100, 100, 3), dtype=np.uint8) * np.random.randint(\n                0, 255, 3\n            )  # image is a solid single color\n            images.append(image)\n        return images, images\n\n    demo.load(generate_images, None, [gallery, imgs])\n\n    with gr.Row():\n        selected = gr.Number(show_label=False)\n        darken_btn = gr.Button(\"Darken selected\")\n    deselect_button = gr.Button(\"Deselect\")\n\n    deselect_button.click(deselect_images, None, gallery)\n\n    def get_select_index(evt: gr.SelectData):\n        return evt.index\n\n    gallery.select(get_select_index, None, selected)\n\n    def darken_img(imgs, index):\n        index = int(index)\n        imgs[index] = np.round(imgs[index] * 0.8).astype(np.uint8)\n        return imgs, imgs\n\n    darken_btn.click(darken_img, [imgs, selected], [imgs, gallery])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing English-German Text Generation with Gradio\nDESCRIPTION: This code creates a Gradio interface for generating English text from a seed phrase and translating it to German. It uses the distilgpt2 model for text generation and a pre-trained English-to-German translator.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_english_german/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nfrom transformers import pipeline\n\nenglish_translator = gr.load(name=\"spaces/gradio/english_translator\")\nenglish_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n\ndef generate_text(text):\n    english_text = english_generator(text)[0][\"generated_text\"]  # type: ignore\n    german_text = english_translator(english_text)\n    return english_text, german_text\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            seed = gr.Text(label=\"Input Phrase\")\n        with gr.Column():\n            english = gr.Text(label=\"Generated English Text\")\n            german = gr.Text(label=\"Generated German Text\")\n    btn = gr.Button(\"Generate\")\n    btn.click(generate_text, inputs=[seed], outputs=[english, german])\n    gr.Examples([\"My name is Clara and I am\"], inputs=[seed])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Blocks Interface with Scroll Control\nDESCRIPTION: Creates a Gradio Blocks interface that demonstrates scroll control functionality. It includes two buttons: one that triggers scrolling to the output after processing, and another that maintains the current scroll position, with a large HTML element in between to demonstrate the scrolling effect.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_scroll/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Blocks()\n\nwith demo:\n    inp = gr.Textbox(placeholder=\"Enter text.\")\n    scroll_btn = gr.Button(\"Scroll\")\n    no_scroll_btn = gr.Button(\"No Scroll\")\n    big_block = gr.HTML(\"\"\"\n    <div style='height: 800px; width: 100px; background-color: pink;'></div>\n    \"\"\")\n    out = gr.Textbox()\n\n    scroll_btn.click(lambda x: x,\n               inputs=inp,\n               outputs=out,\n                scroll_to_output=True)\n    no_scroll_btn.click(lambda x: x,\n               inputs=inp,\n               outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Gallery with Event Handling in Gradio\nDESCRIPTION: Creates a Gradio interface with two interactive galleries (input and output), along with various event handlers for upload, change, preview, and selection events. Includes counters for monitoring different interaction types and displays selected file information.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    files = [\n        \"https://gradio-builds.s3.amazonaws.com/assets/cheetah-003.jpg\",\n        \"https://gradio-static-files.s3.amazonaws.com/world.mp4\",\n        \"https://gradio-builds.s3.amazonaws.com/assets/TheCheethcat.jpg\",\n    ]\n    with gr.Row():\n        with gr.Column():\n            gal = gr.Gallery(columns=4, interactive=True, label=\"Input Gallery\")\n            btn = gr.Button()\n        with gr.Column():\n            output_gal = gr.Gallery(columns=4, interactive=True, label=\"Output Gallery\")\n    with gr.Row():\n        textbox = gr.Json(label=\"uploaded files\")\n        num_upload = gr.Number(value=0, label=\"Num Upload\")\n        num_change = gr.Number(value=0, label=\"Num Change\")\n        preview_open = gr.Number(value=0, label=\"Preview Open?\")\n        select_output = gr.Textbox(label=\"Select Data\")\n        gal.upload(lambda v,n: (v, v, n+1), [gal, num_upload], [textbox, output_gal, num_upload])\n        gal.change(lambda v,n: (v, v, n+1), [gal, num_change], [textbox, output_gal, num_change])\n        output_gal.preview_open(lambda: 1, inputs=None, outputs=preview_open)\n        output_gal.preview_close(lambda: 0, inputs=None, outputs=preview_open)\n\n    btn.click(lambda: files, None, [output_gal])\n\n    def select(select_data: gr.SelectData):\n        return select_data.value['image']['url'] if 'image' in select_data.value else select_data.value['video']['url']\n\n    output_gal.select(select, None, select_output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Processing Function in Python\nDESCRIPTION: A sample batch function that processes lists of words and lengths, trimming each word according to its corresponding length. Includes an artificial delay to demonstrate parallel processing benefits.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/06_batch-functions.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\ndef trim_words(words, lens):\n    trimmed_words = []\n    time.sleep(5)\n    for w, l in zip(words, lens):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Event Triggers\nDESCRIPTION: Implements a Gradio interface with multiple tabs demonstrating various component interactions and event handling. It includes text changes, video controls, image selection, and file handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/event_trigger/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# %%\nimport gradio as gr\n\nTEST_VIDEO_A = \"mp4/a.mp4\"\nTEST_VIDEO_B = \"mp4/b.mp4\"\n\nTEST_IMAGE_A = \"img/a.jpg\"\nTEST_IMAGE_B = \"img/b.jpg\"\n\ndef alert_change(component, value):\n    print(f\"Detected {component} change, {type(value)}\")\n\n    if type(value) == list or type(value) == str:\n        print(value)\n\ndef change_interactive(state):\n    return gr.Video(interactive=not state), not state\n\nwith gr.Blocks() as demo:\n    with gr.Tab(label=\"Text change\"):\n        with gr.Row():\n            with gr.Column():\n                textbox1 = gr.Textbox()\n                textbox2 = gr.Textbox(interactive=True)\n\n            with gr.Column():\n                btn = gr.Button()\n\n        def btn_click(state):\n            return state\n\n        def text_change(value):\n            print(\"text_change\", value)\n\n        btn.click(fn=btn_click, inputs=textbox1, outputs=textbox2)\n        textbox2.change(fn=alert_change, inputs=[gr.State(\"Text\"), textbox2])\n\n    with gr.Tab(label=\"Video change, play, pause\"):\n        with gr.Row():\n            with gr.Column():\n                radio1 = gr.Radio(\n                    choices=[TEST_VIDEO_A, TEST_VIDEO_B],\n                    interactive=True,\n                    type=\"index\",\n                )\n\n                video_btn = gr.Button(\"Change interactive\")\n\n            with gr.Column():\n                video1 = gr.Video(value=TEST_VIDEO_A, interactive=False)\n                video1_interactive = gr.State(value=False)\n\n        def change_video(index):\n            if index == 0:\n                return TEST_VIDEO_A\n            elif index == 1:\n                return TEST_VIDEO_B\n\n        def video_play():\n            print(\"video_play\")\n\n        def video_pause():\n            print(\"video_pause\")\n\n        def video_stop():\n            print(\"video_stop\")\n\n        def video_end():\n            print(\"video_end\")\n\n        video1.play(fn=video_play)\n        video1.pause(fn=video_pause)\n        video1.stop(fn=video_stop)\n        video1.end(fn=video_end)\n\n        radio1.change(fn=change_video, inputs=radio1, outputs=video1)\n        video1.change(fn=alert_change, inputs=[gr.State(\"Video\"), video1])\n\n        video_btn.click(\n            fn=change_interactive,\n            inputs=video1_interactive,\n            outputs=[video1, video1_interactive],\n        )\n\n    with gr.Tab(label=\"Image change\"):\n        with gr.Row():\n            with gr.Column():\n                radio2 = gr.Radio(\n                    choices=[TEST_IMAGE_A, TEST_IMAGE_B],\n                    interactive=True,\n                    type=\"index\",\n                )\n\n            with gr.Column():\n                image1 = gr.Image(value=TEST_IMAGE_A, interactive=True)\n\n        def change_image(index):\n            if index == 0:\n                return TEST_IMAGE_A\n            elif index == 1:\n                return TEST_IMAGE_B\n\n        radio2.change(fn=change_image, inputs=radio2, outputs=image1)\n        image1.change(fn=alert_change, inputs=[gr.State(\"Image\"), image1])\n\n    with gr.Tab(label=\"File\"):\n        with gr.Row():\n            with gr.Column():\n                radio3 = gr.Radio(\n                    choices=[\"A\", \"B\", \"AB\"],\n                    interactive=True,\n                    type=\"index\",\n                )\n\n                file_btn = gr.Button(\"Change interactive\")\n\n            with gr.Column():\n                file1 = gr.File(\n                    value=[TEST_IMAGE_A, TEST_IMAGE_B],\n                    interactive=False,\n                    file_count=\"multiple\",\n                )\n                file1_interactive = gr.State(value=False)\n\n        def change_file(index):\n            if index == 0 or index == 1:\n                return [TEST_IMAGE_A]\n            elif index == 2:\n                return [TEST_IMAGE_A, TEST_IMAGE_B]\n\n        radio3.change(fn=change_file, inputs=radio3, outputs=file1)\n        file1.change(fn=alert_change, inputs=[gr.State(\"File\"), file1])\n\n        file_btn.click(\n            fn=change_interactive,\n            inputs=file1_interactive,\n            outputs=[file1, file1_interactive],\n        )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating an Interactive Sum Calculator with Gradio Event Listeners in Python\nDESCRIPTION: This Python snippet constructs a Gradio app featuring three slider inputs and a numeric output that displays their sum. The @gr.on decorator registers a callback that updates the output whenever any input changes. Dependencies include the Gradio package, and key parameters are the slider values controlled by the user. The app is launched with demo.launch(), responding in real time to user input, and is intended for direct execution as a script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_live/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        num1 = gr.Slider(1, 10)\n        num2 = gr.Slider(1, 10)\n        num3 = gr.Slider(1, 10)\n    output = gr.Number(label=\"Sum\")\n\n    @gr.on(inputs=[num1, num2, num3], outputs=output)\n    def sum(a, b, c):\n        return a + b + c\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Adding a Logout Button to an Authenticated Gradio App in Python\nDESCRIPTION: Explains how to add logout functionality to an authenticated Gradio `Blocks` app. It utilizes `gr.Button` with the `link` parameter set to `\"/logout\"`. Clicking this button redirects the user to Gradio's built-in logout endpoint, which clears session cookies and logs the user out. The example also includes user-specific content display and authentication setup. Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef update_message(request: gr.Request):\n    return f\"Welcome, {request.username}\"\n\nwith gr.Blocks() as demo:\n    m = gr.Markdown()\n    logout_button = gr.Button(\"Logout\", link=\"/logout\")\n    demo.load(update_message, None, m)\n\ndemo.launch(auth=[(\"Pete\", \"Pete\"), (\"Dawood\", \"Dawood\")])\n```\n\n----------------------------------------\n\nTITLE: Implementing Live Calculator Interface in Python using Gradio\nDESCRIPTION: This code snippet demonstrates how to create a live calculator interface using Gradio. The interface automatically recalculates as soon as the user input changes, without requiring a submit button.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/04_reactive-interfaces.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\ndemo = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    live=True\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting Component Dimensions in Gradio Blocks (Python)\nDESCRIPTION: Demonstrates how to set specific dimensions for components in Gradio Blocks. This example uses viewport width (vw) to set the width of an ImageEditor component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/02_controlling-layout.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    im = gr.ImageEditor(width=\"50vw\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Generating Bot Response in Gradio Chat Interface\nDESCRIPTION: This function generates a bot response based on the specified response type. It supports various content types including plots, images, audio, video, and more, using Gradio components to render the content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef bot(history, response_type):\n    msg = {\"role\": \"assistant\", \"content\": \"\"}\n    if response_type == \"plot\":\n        content = gr.Plot(random_plot())\n    elif response_type == \"bokeh_plot\":\n        content = gr.Plot(random_bokeh_plot())\n    elif response_type == \"matplotlib_plot\":\n        content =  gr.Plot(random_matplotlib_plot())\n    elif response_type == \"gallery\":\n        content = gr.Gallery(\n            [os.path.join(\"files\", \"avatar.png\"), os.path.join(\"files\", \"avatar.png\")]\n        )\n    elif response_type == \"dataframe\":\n        content = gr.Dataframe(\n            interactive=True,\n            headers=[\"One\", \"Two\", \"Three\"],\n            col_count=(3, \"fixed\"),\n            row_count=(3, \"fixed\"),\n            value=[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n            label=\"Dataframe\",\n        )\n    elif response_type == \"image\":\n       content = gr.Image(os.path.join(\"files\", \"avatar.png\"))\n    elif response_type == \"video\":\n       content = gr.Video(os.path.join(\"files\", \"world.mp4\"))\n    elif response_type == \"audio\":\n        content = gr.Audio(os.path.join(\"files\", \"audio.wav\"))\n    elif response_type == \"audio_file\":\n        content = {\"path\": os.path.join(\"files\", \"audio.wav\"), \"alt_text\": \"description\"}\n    elif response_type == \"image_file\":\n        content = {\"path\": os.path.join(\"files\", \"avatar.png\"), \"alt_text\": \"description\"}\n    elif response_type == \"video_file\":\n        content = {\"path\": os.path.join(\"files\", \"world.mp4\"), \"alt_text\": \"description\"}\n    elif response_type == \"txt_file\":\n        content = {\"path\": os.path.join(\"files\", \"sample.txt\"), \"alt_text\": \"description\"}\n    elif response_type == \"html\":\n        content = gr.HTML(\n            html_src(random.choice([\"harmful\", \"neutral\", \"beneficial\"]))\n        )\n    else:\n        content = txt\n    msg[\"content\"] = content # type: ignore\n    history.append(msg)\n    return history\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio and Llama Index in Python\nDESCRIPTION: This snippet installs the necessary Python packages: gradio, openai, and llama-index via pip. These libraries are required to run the chatbot, with gradio providing the UI, openai connecting to GPT endpoints, and llama-index managing documents. Run this command in your terminal or notebook before using the chatbot; no user-specific parameters are needed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_llamaindex/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio openai llama-index \n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with ClearButton\nDESCRIPTION: Creates a Gradio interface with a Textbox component initialized with default text and adds a ClearButton component to reset the textbox content. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/clearbutton_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    textbox = gr.Textbox(value=\"This is some text\")\n    gr.ClearButton(textbox)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Enhanced Dynamic Textboxes with Gradio Render Decorator\nDESCRIPTION: This snippet expands on the previous example by adding more complexity. It includes options to split the input text by words or characters and demonstrates custom triggering of the render function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/04_dynamic-apps-with-render-decorator.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    input_text = gr.Textbox(label=\"Input Text\")\n    split_type = gr.Radio([\"Characters\", \"Words\"], label=\"Split by\", value=\"Characters\")\n    output_row = gr.Row()\n\n    @gr.render(triggers=[input_text.submit])\n    def create_textboxes(text, split):\n        if split == \"Characters\":\n            return [gr.Textbox(value=letter, label=f\"Letter {i}\") for i, letter in enumerate(text)]\n        else:\n            return [gr.Textbox(value=word, label=f\"Word {i}\") for i, word in enumerate(text.split())]\n\n    input_text.submit(create_textboxes, [input_text, split_type], output_row)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating an Audio Reversal Gradio Interface\nDESCRIPTION: Defines a function to reverse audio data and creates a Gradio interface that accepts microphone input and returns the reversed audio. The function receives audio as a tuple of sample rate and data, flips the data, and returns the same format.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef reverse_audio(audio):\n    sr, data = audio\n    return (sr, np.flipud(data))\n\ndemo = gr.Interface(fn=reverse_audio,\n                    inputs=\"microphone\",\n                    outputs=\"audio\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Video Component Events Demo\nDESCRIPTION: Sets up a Gradio interface with input and output video components, along with counters for various video events. It demonstrates how to handle upload, change, play, and pause events for the video component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component_events/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_video = gr.Video(label=\"Input Video\")\n        with gr.Column():\n            output_video = gr.Video(label=\"Output Video\")\n        with gr.Column():\n            num_change = gr.Number(label=\"# Change Events\", value=0)\n            num_load = gr.Number(label=\"# Upload Events\", value=0)\n            num_play = gr.Number(label=\"# Play Events\", value=0)\n            num_pause = gr.Number(label=\"# Pause Events\", value=0)\n        input_video.upload(lambda s, n: (s, n + 1), [input_video, num_load], [output_video, num_load])\n        input_video.change(lambda n: n + 1, num_change, num_change)\n        input_video.play(lambda n: n + 1, num_play, num_play)\n        input_video.pause(lambda n: n + 1, num_pause, num_pause)\n        input_video.change(lambda n: n + 1, num_change, num_change)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Making a Basic Text Prediction\nDESCRIPTION: Shows a simple example of making a prediction to an English-to-French translation model, passing a string as input.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/en2fr\")\nclient.predict(\"Hello\")\n\n>> Bonjour\n```\n\n----------------------------------------\n\nTITLE: Implementing Pet Name Generator with Gradio in Python\nDESCRIPTION: This code creates a Gradio application for generating pet names. It defines a function to generate names based on animal type and personality, and sets up a user interface with a sidebar for inputs and a main area for displaying the generated name.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_sidebar/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\ndef generate_pet_name(animal_type, personality):\n    cute_prefixes = [\"Fluffy\", \"Ziggy\", \"Bubbles\", \"Pickle\", \"Waffle\", \"Mochi\", \"Cookie\", \"Pepper\"]\n    animal_suffixes = {\n        \"Cat\": [\"Whiskers\", \"Paws\", \"Mittens\", \"Purrington\"],\n        \"Dog\": [\"Woofles\", \"Barkington\", \"Waggins\", \"Pawsome\"],\n        \"Bird\": [\"Feathers\", \"Wings\", \"Chirpy\", \"Tweets\"],\n        \"Rabbit\": [\"Hops\", \"Cottontail\", \"Bouncy\", \"Fluff\"]\n    }\n\n    prefix = random.choice(cute_prefixes)\n    suffix = random.choice(animal_suffixes[animal_type])\n\n    if personality == \"Silly\":\n        prefix = random.choice([\"Sir\", \"Lady\", \"Captain\", \"Professor\"]) + \" \" + prefix\n    elif personality == \"Royal\":\n        suffix += \" the \" + random.choice([\"Great\", \"Magnificent\", \"Wise\", \"Brave\"])\n\n    return f\"{prefix} {suffix}\"\n\nwith gr.Blocks(theme=gr.themes.Soft()) as demo:\n    with gr.Sidebar(position=\"left\"):\n        gr.Markdown(\"# 🐾 Pet Name Generator\")\n        gr.Markdown(\"Use the options below to generate a unique pet name!\")\n\n        animal_type = gr.Dropdown(\n            choices=[\"Cat\", \"Dog\", \"Bird\", \"Rabbit\"],\n            label=\"Choose your pet type\",\n            value=\"Cat\"\n        )\n        personality = gr.Radio(\n            choices=[\"Normal\", \"Silly\", \"Royal\"],\n            label=\"Personality type\",\n            value=\"Normal\"\n        )\n\n    name_output = gr.Textbox(label=\"Your pet's fancy name:\", lines=2)\n    generate_btn = gr.Button(\"Generate Name! 🎲\", variant=\"primary\")\n    generate_btn.click(\n        fn=generate_pet_name,\n        inputs=[animal_type, personality],\n        outputs=name_output\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Changing Font Colors in Gradio DataFrame using Pandas Styler - Python\nDESCRIPTION: This example demonstrates using a custom function to dynamically set text colors by column in a Pandas DataFrame via Styler.apply, resulting in different color treatments per column. The code then displays this in the Gradio DataFrame component. Dependencies: pandas and gradio. The highlight_cols function applies purple font color globally but uses green for specific columns ('B', 'C', 'E'). Input is a DataFrame; output is styled text in the Gradio table.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd \nimport gradio as gr\n\n# Creating a sample dataframe\ndf = pd.DataFrame({\n    \"A\" : [14, 4, 5, 4, 1], \n    \"B\" : [5, 2, 54, 3, 2], \n    \"C\" : [20, 20, 7, 3, 8], \n    \"D\" : [14, 3, 6, 2, 6], \n    \"E\" : [23, 45, 64, 32, 23]\n}) \n\n# Function to apply text color\ndef highlight_cols(x): \n    df = x.copy() \n    df.loc[:, :] = 'color: purple'\n    df[['B', 'C', 'E']] = 'color: green'\n    return df \n\n# Applying the style function\ns = df.style.apply(highlight_cols, axis = None)\n\n# Displaying the styled dataframe in Gradio\nwith gr.Blocks() as demo:\n    gr.DataFrame(s)\n    \ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Second Page Implementation\nDESCRIPTION: Example of a secondary page implementation (second_page.py) with a textbox component and loading functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/09_multipage-apps.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    t = gr.Textbox()\n    demo.load(lambda : \"Loaded\", None, t)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface for Greeting Application\nDESCRIPTION: This snippet defines a greeting function and creates a Gradio interface. It uses text input for the name, a slider for intensity, and a text box for output. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello, \" + name + \"!\" * intensity\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", gr.Slider(value=2, minimum=1, maximum=10, step=1)],\n    outputs=[gr.Textbox(label=\"greeting\", lines=3)],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Required Plotting Libraries - Python\nDESCRIPTION: This snippet installs the necessary Python packages, including gradio for UI, and numpy, matplotlib, bokeh, plotly, and altair for data handling and plotting. These dependencies are required to operate the Gradio demo and support interactive plotting across different backends. Running this cell ensures all subsequent code has the proper libraries available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/outbreak_forecast/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy matplotlib bokeh plotly altair \n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Gradio Interface for 3D Models in Python\nDESCRIPTION: This Python script demonstrates creating a minimal Gradio interface using the `Model3D` component. It defines a placeholder function `load_mesh` that simply returns the input file path. The `gr.Interface` is configured with `gr.Model3D()` for both input and output, showcasing how to accept and display 3D files. It also demonstrates setting the background `clear_color` for the output component and providing a list of `examples` using different 3D file formats (.obj, .glb, .gltf). Requires the `gradio` and `os` libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/how-to-use-3D-model-component.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\n    examples=[\n        [os.path.join(os.path.dirname(__file__), \"files/Bunny.obj\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Duck.glb\")],\n        [os.path.join(os.path.dirname(__file__), \"files/Fox.gltf\")],\n        [os.path.join(os.path.dirname(__file__), \"files/face.obj\")],\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Progress Bar with Gradio for a Text Reversal Function\nDESCRIPTION: Creates a Gradio interface with a progress bar that shows the status of a slow text reversal operation. The function includes multiple progress update methods including initial progress, manual percentage updates, and a tqdm iterator for character-by-character processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef slowly_reverse(word, progress=gr.Progress()):\n    progress(0, desc=\"Starting\")\n    time.sleep(1)\n    progress(0.05)\n    new_string = \"\"\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\n        time.sleep(0.25)\n        new_string = letter + new_string  # type: ignore\n    return new_string\n\ndemo = gr.Interface(slowly_reverse, gr.Text(), gr.Text())\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Discord Bot from Gradio ChatInterface\nDESCRIPTION: Example code showing how to create a Discord bot from a Gradio ChatInterface application using gradio_client library. This connects to a Llama 2 model and deploys it as a discord bot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport gradio_client as grc\ngrc.Client(\"ysharma/Explore_llamav2_with_TGI\").deploy_discord(to_id=\"llama2-70b-discord-bot\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Pre/Postprocessing with Gradio Image Component (Python)\nDESCRIPTION: Shows an example of preprocessing and postprocessing using a `gr.Interface` with `gr.Image` components. A Python function `sepia` takes a NumPy array (preprocessed from an uploaded image file) and returns a processed NumPy array. Gradio automatically handles the conversion from uploaded file path to NumPy array (`preprocess`) before calling the function and converts the returned NumPy array back to a displayable image format (`postprocess`) for the frontend. Requires `gradio` and `numpy` libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/02_key-component-concepts.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189], \n        [0.349, 0.686, 0.168], \n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ndemo = gr.Interface(sepia, gr.Image(width=200, height=200), \"image\")\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Batch Processing with Gradio Blocks\nDESCRIPTION: Alternative implementation using Gradio Blocks API, providing more flexible layout control while maintaining batch processing capabilities. Shows how to create a custom interface with textbox inputs and batch processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/06_batch-functions.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        word = gr.Textbox(label=\"word\")\n        leng = gr.Number(label=\"leng\")\n        output = gr.Textbox(label=\"Output\")\n    with gr.Row():\n        run = gr.Button()\n\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Gradio Interface with Dynamic Rendering\nDESCRIPTION: Creates a Gradio Blocks interface that takes text input and dynamically renders each character as either a textbox or button based on user selection. The render decorator is used to handle the dynamic component creation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_split/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    input_text = gr.Textbox(label=\"input\")\n    mode = gr.Radio([\"textbox\", \"button\"], value=\"textbox\")\n\n    @gr.render(inputs=[input_text, mode], triggers=[input_text.submit])\n    def show_split(text, mode):\n        if len(text) == 0:\n            gr.Markdown(\"## No Input Provided\")\n        else:\n            for letter in text:\n                if mode == \"textbox\":\n                    gr.Textbox(letter)\n                else:\n                    gr.Button(letter)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Translation Demo with Transformers\nDESCRIPTION: This code sets up a translation demo using Gradio and the Transformers library. It loads a pre-trained model, defines a translation function, and creates a Gradio interface for user interaction. The demo supports translation between multiple languages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/translation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\nimport torch\n\n# this model was loaded from https://hf.co/models\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\ntokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\ndevice = 0 if torch.cuda.is_available() else -1\nLANGS = [\"ace_Arab\", \"eng_Latn\", \"fra_Latn\", \"spa_Latn\"]\n\ndef translate(text, src_lang, tgt_lang):\n    \"\"\"\n    Translate the text from source lang to target lang\n    \"\"\"\n    translation_pipeline = pipeline(\"translation\", model=model, tokenizer=tokenizer, src_lang=src_lang, tgt_lang=tgt_lang, max_length=400, device=device)\n    result = translation_pipeline(text)\n    return result[0]['translation_text']  # type: ignore\n\ndemo = gr.Interface(\n    fn=translate,\n    inputs=[\n        gr.components.Textbox(label=\"Text\"),\n        gr.components.Dropdown(label=\"Source Language\", choices=LANGS),\n        gr.components.Dropdown(label=\"Target Language\", choices=LANGS),\n    ],\n    outputs=[\"text\"],\n    examples=[[\"Building a translation demo with Gradio is so easy!\", \"eng_Latn\", \"spa_Latn\"]],\n    cache_examples=False,\n    title=\"Translation Demo\",\n    description=\"This demo is a simplified version of the original [NLLB-Translator](https://huggingface.co/spaces/Narrativaai/NLLB-Translator) space\"\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: File Response Data Structure\nDESCRIPTION: Python dictionary format representing a file returned from a Gradio endpoint, showing the structure with file path, URL, and metadata.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n{\n    \"orig_name\": \"example.jpg\",\n    \"path\": \"/path/in/server.jpg\",\n    \"url\": \"https:/example.com/example.jpg\",\n    \"meta\": {\"_type\": \"gradio.FileData\"}\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Reversible Flow Interface with Gradio\nDESCRIPTION: Implements a Gradio interface with bidirectional data flow between two number inputs. The interface includes two buttons that increase the value of one input and display the result in the other, demonstrating how to create reversible flows between components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reversible_flow/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef increase(num):\n    return num + 1\n\nwith gr.Blocks() as demo:\n    a = gr.Number(label=\"a\")\n    b = gr.Number(label=\"b\")\n    atob = gr.Button(\"a > b\")\n    btoa = gr.Button(\"b > a\")\n    atob.click(increase, a, b)\n    btoa.click(increase, b, a)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Chatbot Component with Gradio\nDESCRIPTION: Creates a simple Gradio interface with a Chatbot component that displays predefined messages including text and emojis. Uses the Blocks API to create the interface and launches it as a web application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Chatbot(value=[[\"Hello World\",\"Hey Gradio!\"],[\"❤️\",\"😍\"],[\"🔥\",\"🤗\"]])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio UI with Different Grouping Options\nDESCRIPTION: Demonstrates various ways to organize UI elements in Gradio using gr.Group, gr.Row, and gr.Column containers. The code includes examples of different layouts and container configurations, showing how the container property affects the appearance of elements.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_group/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"### This is a couple of elements without any gr.Group. Form elements naturally group together anyway.\")\n    gr.Textbox(\"A\")\n    gr.Number(3)\n    gr.Button()\n    gr.Image()\n    gr.Slider()\n\n    gr.Markdown(\"### This is the same set put in a gr.Group.\")\n    with gr.Group():\n        gr.Textbox(\"A\")\n        gr.Number(3)\n        gr.Button()\n        gr.Image()\n        gr.Slider()\n\n    gr.Markdown(\"### Now in a Row, no group.\")\n    with gr.Row():\n        gr.Textbox(\"A\")\n        gr.Number(3)\n        gr.Button()\n        gr.Image()\n        gr.Slider()\n\n    gr.Markdown(\"### Now in a Row in a group.\")\n    with gr.Group():\n        with gr.Row():\n            gr.Textbox(\"A\")\n            gr.Number(3)\n            gr.Button()\n            gr.Image()\n            gr.Slider()\n\n    gr.Markdown(\"### Several rows grouped together.\")\n    with gr.Group():\n        with gr.Row():\n            gr.Textbox(\"A\")\n            gr.Number(3)\n            gr.Button()\n        with gr.Row():\n            gr.Image()\n            gr.Audio()\n\n    gr.Markdown(\"### Several columns grouped together. If columns are uneven, there is a gray group background.\")\n    with gr.Group():\n        with gr.Row():\n            with gr.Column():\n                name = gr.Textbox(label=\"Name\")\n                btn = gr.Button(\"Hello\")\n                gr.Dropdown([\"a\", \"b\", \"c\"], interactive=True)\n                gr.Number()\n                gr.Textbox()\n            with gr.Column():\n                gr.Image()\n                gr.Dropdown([\"a\", \"b\", \"c\"], interactive=True)\n                with gr.Row():\n                    gr.Number(scale=2)\n                    gr.Textbox()\n\n    gr.Markdown(\"### container=False removes label, padding, and block border, placing elements 'directly' on background.\")\n    gr.Radio([1,2,3], container=False)\n    gr.Textbox(container=False)\n    gr.Image(\"https://picsum.photos/id/237/200/300\", container=False, height=200)\n\n    gr.Markdown(\"### Textbox, Dropdown, and Number input boxes takes up full space when within a group without a container.\")\n\n    with gr.Group():\n        name = gr.Textbox(label=\"Name\")\n        output = gr.Textbox(show_label=False, container=False)\n        greet_btn = gr.Button(\"Greet\")\n        with gr.Row():\n            gr.Dropdown([\"a\", \"b\", \"c\"], interactive=True, container=False)\n            gr.Textbox(container=False)\n            gr.Number(container=False)\n            gr.Image(height=100)\n    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n\n    gr.Markdown(\"### More examples\")\n\n    with gr.Group():\n        gr.Chatbot()\n        with gr.Row():\n            name = gr.Textbox(label=\"Prompot\", container=False)\n            go = gr.Button(\"go\", scale=0)\n\n    with gr.Column():\n        gr.Radio([1,2,3], container=False)\n        gr.Slider(0, 20, container=False)\n\n    with gr.Group():\n        with gr.Row():\n            gr.Dropdown([\"a\", \"b\", \"c\"], interactive=True, container=False, elem_id=\"here2\")\n            gr.Number(container=False)\n            gr.Textbox(container=False)\n\n    with gr.Row():\n        with gr.Column():\n            gr.Dropdown([\"a\", \"b\", \"c\"], interactive=True, container=False, elem_id=\"here2\")\n        with gr.Column():\n           gr.Number(container=False)\n        with gr.Column():\n            gr.Textbox(container=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: PostgreSQL Database Connection Setup\nDESCRIPTION: Example of creating a connection engine for PostgreSQL database using SQLAlchemy.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/04_connecting-to-a-database.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nengine = create_engine('postgresql://username:password@host:port/database_name')\n```\n\n----------------------------------------\n\nTITLE: Generating and Displaying Spectrograms with Gradio in Python\nDESCRIPTION: This Python script defines a function `spectrogram` that accepts an audio input (tuple of sample rate and data array). It handles potential stereo audio by averaging channels, calculates the spectrogram using `scipy.signal.spectrogram`, and plots it using `matplotlib.pyplot.pcolormesh`. Finally, it creates and launches a Gradio interface (`gr.Interface`) that uses this function, taking 'audio' input and producing a 'plot' output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/spectogram/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import signal\n\nimport gradio as gr\n\ndef spectrogram(audio):\n    sr, data = audio\n    if len(data.shape) == 2:\n        data = np.mean(data, axis=0)\n    frequencies, times, spectrogram_data = signal.spectrogram(\n        data, sr, window=\"hamming\"\n    )\n    plt.pcolormesh(times, frequencies, np.log10(spectrogram_data))\n    return plt\n\ndemo = gr.Interface(spectrogram, \"audio\", \"plot\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for DataFrame Generation\nDESCRIPTION: This code creates a Gradio interface that generates a pandas DataFrame with various data types. It defines a function to create the DataFrame and sets up the Gradio interface with input and output components. The interface allows users to specify the number of periods for the DataFrame.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_datatype/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport numpy as np\n\ndef make_dataframe(n_periods):\n    rng = np.random.default_rng()\n    return pd.DataFrame({\"date_1\": pd.date_range(\"2021-01-01\", periods=n_periods),\n                         \"date_2\": pd.date_range(\"2022-02-15\", periods=n_periods).strftime('%B %d, %Y, %r'),\n                         \"number\": rng.random(n_periods).astype(np.float64),\n                         \"number_2\": rng.integers(0, 100, n_periods).astype(np.int32),\n                         \"bool\": [True] * n_periods,\n                         \"markdown\": [\"# Hello\"] * n_periods})\n\ndemo = gr.Interface(make_dataframe,\n             gr.Number(precision=0),\n             gr.Dataframe(datatype=[\"date\", \"date\", \"number\", \"number\", \"bool\", \"markdown\"]))\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic Textboxes with Gradio Render Decorator\nDESCRIPTION: This snippet demonstrates how to use the @gr.render decorator to create a variable number of textboxes based on user input. It splits the input text into individual characters and creates a textbox for each.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/04_dynamic-apps-with-render-decorator.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    input_text = gr.Textbox(label=\"Input Text\")\n    output_row = gr.Row()\n\n    @gr.render()\n    def create_textboxes(text):\n        return [gr.Textbox(value=letter) for letter in text]\n\n    input_text.change(create_textboxes, input_text, output_row)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Naming Gradio Blocks API Endpoints in Python\nDESCRIPTION: Demonstrates how to assign a specific API endpoint name (e.g., `/api/addition/`) to a Gradio `Blocks` event listener using the `api_name` argument in the `.click()` method. This is recommended for creating a well-documented and predictable API when using `Blocks`. Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nbtn.click(add, [num1, num2], output, api_name=\"addition\")\n```\n\n----------------------------------------\n\nTITLE: Implementing GIF Maker with Gradio Interface\nDESCRIPTION: Creates a Gradio interface for converting multiple image files into a video animation. Uses OpenCV to read images and create a video file, with support for multiple file uploads and video output display.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gif_maker/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport gradio as gr\n\ndef gif_maker(img_files):\n    img_array = []\n    size = (1, 1)\n    for filename in img_files:\n        img = cv2.imread(filename.name)\n        height, width, _ = img.shape\n        size = (width,height)\n        img_array.append(img)\n    output_file = \"test.mp4\"\n    out = cv2.VideoWriter(output_file,cv2.VideoWriter_fourcc(*'h264'), 15, size)  # type: ignore\n    for i in range(len(img_array)):\n        out.write(img_array[i])\n    out.release()\n    return output_file\n\ndemo = gr.Interface(gif_maker, inputs=gr.File(file_count=\"multiple\"), outputs=gr.Video())\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Calculator Demo with Gradio Blocks\nDESCRIPTION: Creates a calculator demo using Gradio's Blocks interface. The demo includes input fields for numbers and operation selection, a calculate button, and a result display. It also includes cached examples for quick testing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_blocks_cached/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            num_1 = gr.Number()\n            operation = gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"])\n            num_2 = gr.Number()\n            submit_btn = gr.Button(value=\"Calculate\")\n        with gr.Column():\n            result = gr.Number()\n\n    submit_btn.click(calculator, inputs=[num_1, operation, num_2], outputs=[result])\n    examples = gr.Examples(examples=[[5, \"add\", 3],\n                                     [4, \"divide\", 2],\n                                     [-4, \"multiply\", 2.5],\n                                     [0, \"subtract\", 1.2]],\n                           inputs=[num_1, operation, num_2],\n                           outputs=[result],\n                           fn=calculator,\n                           cache_examples=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Retry Event Handler in Gradio Chatbot\nDESCRIPTION: Implements retry functionality that regenerates responses for previous user messages using gr.RetryData.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef handle_retry(history, retry_data: gr.RetryData):\n    new_history = history[:retry_data.index]\n    previous_prompt = history[retry_data.index]['content']\n    yield from respond(previous_prompt, new_history)\n\nchatbot.retry(handle_retry, chatbot, chatbot)\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Multimodal Gradio Chat Interface (Python)\nDESCRIPTION: This Python script defines and launches a Gradio ChatInterface. It first sets up paths to local image and audio files. An `echo` function is defined to process user messages, returning a string acknowledging the text and the number of uploaded files. A `gr.ChatInterface` instance is created, configured to use the `echo` function, handle multimodal input (`type=\"messages\"`, `multimodal=True`), and display predefined examples containing text, image, and audio files. The interface is launched using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_multimodal_examples/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nimport gradio as gr\n\nimage = str(Path(__file__).parent / \"files\" / \"avatar.png\")\naudio = str(Path(__file__).parent / \"files\" / \"cantina.wav\")\n\ndef echo(message, history):\n    return f\"You wrote: {message['text']} and uploaded {len(message['files'])} files.\"\n\ndemo = gr.ChatInterface(\n    fn=echo,\n    type=\"messages\",\n    examples=[{\"text\": \"hello\"}, {\"text\": \"hola\", \"files\": [image]}, {\"text\": \"merhaba\", \"files\": [image, audio]}],\n    title=\"Echo Bot\",\n    multimodal=True,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Neural Instrument Cloning Demo with Gradio Blocks\nDESCRIPTION: Creates a Gradio Blocks demo for Neural Instrument Cloning. It includes multiple interfaces for different instruments, audio playback, and simulated model interactions. The demo uses placeholder functions to simulate ML model behavior.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_neural_instrument_coding/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# A Blocks implementation of https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6\n\nimport datetime\nimport os\nimport random\n\nimport gradio as gr\nfrom gradio.components import Markdown as m\n\ndef get_time():\n    now = datetime.datetime.now()\n    return now.strftime(\"%m/%d/%Y, %H:%M:%S\")\n\ndef generate_recording():\n    return random.choice([\"new-sax-1.mp3\", \"new-sax-1.wav\"])\n\ndef reconstruct(audio):\n    return random.choice([\"new-sax-1.mp3\", \"new-sax-1.wav\"])\n\nio1 = gr.Interface(\n    lambda x, y, z: os.path.join(os.path.abspath(''),\"sax.wav\"),\n    [\n        gr.Slider(label=\"pitch\"),\n        gr.Slider(label=\"loudness\"),\n        gr.Audio(label=\"base audio file (optional)\"),\n    ],\n    gr.Audio(),\n)\n\nio2 = gr.Interface(\n    lambda x, y, z: os.path.join(os.path.abspath(''),\"flute.wav\"),\n    [\n        gr.Slider(label=\"pitch\"),\n        gr.Slider(label=\"loudness\"),\n        gr.Audio(label=\"base audio file (optional)\"),\n    ],\n    gr.Audio(),\n)\n\nio3 = gr.Interface(\n    lambda x, y, z: os.path.join(os.path.abspath(''),\"trombone.wav\"),\n    [\n        gr.Slider(label=\"pitch\"),\n        gr.Slider(label=\"loudness\"),\n        gr.Audio(label=\"base audio file (optional)\"),\n    ],\n    gr.Audio(),\n)\n\nio4 = gr.Interface(\n    lambda x, y, z: os.path.join(os.path.abspath(''),\"sax2.wav\"),\n    [\n        gr.Slider(label=\"pitch\"),\n        gr.Slider(label=\"loudness\"),\n        gr.Audio(label=\"base audio file (optional)\"),\n    ],\n    gr.Audio(),\n)\n\ndemo = gr.Blocks(title=\"Neural Instrument Cloning\")\n\nwith demo.clear():\n    m(\n        \"\"\"\n    ## Neural Instrument Cloning from Very Few Samples\n    <center><img src=\"https://media.istockphoto.com/photos/brass-trombone-picture-id490455809?k=20&m=490455809&s=612x612&w=0&h=l9KJvH_25z0QTLggHrcH_MsR4gPLH7uXwDPUAZ_C5zk=\" width=\"400px\"></center>\"\"\"\n    )\n    m(\n        \"\"\"\n    This Blocks implementation is an adaptation [a report written](https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6) by Nicolas Jonason and Bob L.T. Sturm.\n    \n    I've implemented it in Blocks to show off some cool features, such as embedding live ML demos. More on that ahead...\n    \n    ### What does this machine learning model do?\n    It combines techniques from neural voice cloning with musical instrument synthesis. This makes it possible to produce neural instrument synthesisers from just seconds of target instrument audio.\n    \n    ### Audio Examples\n    Here are some **real** 16 second saxophone recordings:\n    \"\"\"\n    )\n    gr.Audio(os.path.join(os.path.abspath(''),\"sax.wav\"), label=\"Here is a real 16 second saxophone recording:\")\n    gr.Audio(os.path.join(os.path.abspath(''),\"sax.wav\"))\n\n    m(\n        \"\"\"\\n\n        Here is a **generated** saxophone recordings:\"\"\"\n    )\n    a = gr.Audio(os.path.join(os.path.abspath(''),\"new-sax.wav\"))\n\n    gr.Button(\"Generate a new saxophone recording\")\n\n    m(\n        \"\"\"\n    ### Inputs to the model\n    The inputs to the model are:\n    * pitch\n    * loudness\n    * base audio file\n    \"\"\"\n    )\n\n    m(\n        \"\"\"\n    Try the model live!\n    \"\"\"\n    )\n\n    gr.TabbedInterface(\n        [io1, io2, io3, io4], [\"Saxophone\", \"Flute\", \"Trombone\", \"Another Saxophone\"]\n    )\n\n    m(\n        \"\"\"\n    ### Using the model for cloning\n    You can also use this model a different way, to simply clone the audio file and reconstruct it \n    using machine learning. Here, we'll show a demo of that below:\n    \"\"\"\n    )\n\n    a2 = gr.Audio()\n    a2.change(reconstruct, a2, a2)\n\n    m(\n        \"\"\"\n    Thanks for reading this! As you may have realized, all of the \"models\" in this demo are fake. They are just designed to show you what is possible using Blocks 🤗.\n    \n    For details of the model, read the [original report here](https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6).\n    \n    *Details for nerds*: this report was \"launched\" on:\n    \"\"\"\n    )\n\n    t = gr.Textbox(label=\"timestamp\")\n\n    demo.load(get_time, [], t)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Generating Conversational AI Replies with Groq Llama-3.2 - Python\nDESCRIPTION: This function composes a message history with a guiding system prompt and invokes the Groq LLM to generate the next message for the chatbot, aiming for one-question conversational exchanges about calories/macronutrients. Inputs are the authenticated Groq client and user message history; output is the next AI-generated conversational reply. Dependencies include a valid LLM API endpoint and carefully composed message dictionaries. Errors during API calls are caught and returned as strings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef generate_chat_completion(client, history):\n    messages = []\n    messages.append(\n        {\n            \"role\": \"system\",\n            \"content\": \"In conversation with the user, ask questions to estimate and provide (1) total calories, (2) protein, carbs, and fat in grams, (3) fiber and sugar content. Only ask *one question at a time*. Be conversational and natural.\",\n        }\n    )\n\n    for message in history:\n        messages.append(message)\n\n    try:\n        completion = client.chat.completions.create(\n            model=\"llama-3.2-11b-vision-preview\",\n            messages=messages,\n        )\n        return completion.choices[0].message.content\n    except Exception as e:\n        return f\"Error in generating chat completion: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Dashboard\nDESCRIPTION: Code to create a Gradio dashboard with two bar plots showing prices and inventory counts, updating every 60 seconds\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-supabase-data.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as dashboard:\n    with gr.Row():\n        gr.BarPlot(read_data, x=\"product_id\", y=\"price\", title=\"Prices\", every=gr.Timer(60))\n        gr.BarPlot(read_data, x=\"product_id\", y=\"inventory_count\", title=\"Inventory\", every=gr.Timer(60))\n\ndashboard.queue().launch()\n```\n\n----------------------------------------\n\nTITLE: Main Application Router\nDESCRIPTION: Main application file (app.py) that combines multiple pages using imports and the render() method to create a complete multipage application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/09_multipage-apps.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nimport main_page, second_page\n\nwith gr.Blocks() as demo:\n    main_page.demo.render()\nwith demo.route(\"Second Page\"):\n    second_page.demo.render()\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio BarPlot for Aggregated Quantitative Data\nDESCRIPTION: Creates a Gradio application with a BarPlot component that visualizes the relationship between weight and height. The plot bins the weight into 10 groups and aggregates the height values using the sum function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_quantitative/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.BarPlot(df, x=\"weight\", y=\"height\", x_bin=10, y_aggregate=\"sum\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Temporal Data Visualizations with Gradio\nDESCRIPTION: Demonstrates how to create line and scatter plots with time-based data in Gradio. The code generates sample flight data with timestamps, prices, and airport codes, then displays this data in both a line plot and a scatter plot with color coding.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_temporal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport numpy as np\nimport random\n\nfrom datetime import datetime, timedelta\nnow = datetime.now()\n\ndf = pd.DataFrame({\n    'time': [now - timedelta(minutes=5*i) for i in range(25)],\n    'price': np.random.randint(100, 1000, 25),\n    'origin': [random.choice([\"DFW\", \"DAL\", \"HOU\"]) for _ in range(25)],\n    'destination': [random.choice([\"JFK\", \"LGA\", \"EWR\"]) for _ in range(25)],\n})\n\nwith gr.Blocks() as demo:\n    gr.LinePlot(df, x=\"time\", y=\"price\")\n    gr.ScatterPlot(df, x=\"time\", y=\"price\", color=\"origin\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring and Using Gradio ImageEditor Component in Python\nDESCRIPTION: This code snippet demonstrates how to set up and use the new ImageEditor component in Gradio. It shows various configuration options including input sources, crop settings, transformations, and brush customization. The function 'fn' illustrates how to access different parts of the edited image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: W&B Report Integration in Gradio\nDESCRIPTION: Demonstrates how to embed W&B reports within a Gradio application using HTML iframes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef wandb_report(url):\n    iframe = f'<iframe src={url} style=\"border:none;height:1024px;width:100%\">'\n    return gr.HTML(iframe)\n\nwith gr.Blocks() as demo:\n    report_url = 'https://wandb.ai/_scott/pytorch-sweeps-demo/reports/loss-22-10-07-16-00-17---VmlldzoyNzU2NzAx'\n    report = wandb_report(report_url)\n\ndemo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Dataset Component Demo\nDESCRIPTION: This code creates a Gradio Blocks interface with a Dataset component. The dataset contains text samples and uses a hidden Textbox component. The demo is then launched for interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Dataset(components=[gr.Textbox(visible=False)],\n        label=\"Text Dataset\",\n        samples=[\n            [\"The quick brown fox jumps over the lazy dog\"],\n            [\"Build & share delightful machine learning apps\"],\n            [\"She sells seashells by the seashore\"],\n            [\"Supercalifragilisticexpialidocious\"],\n            [\"Lorem ipsum\"],\n            [\"That's all folks!\"]\n        ],\n    )\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Alerts in Gradio Functions (Python)\nDESCRIPTION: This code snippet demonstrates how to use gr.Error, gr.Warning, and gr.Info in a Gradio function to display different types of alerts. It shows the proper usage of each alert type and their effects on function execution.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/04_alerts.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef start_process(name):\n    gr.Info(\"Starting process\")\n    if name is None:\n        gr.Warning(\"Name is empty\")\n    ...\n    if success == False:\n        raise gr.Error(\"Process failed\")\n```\n\n----------------------------------------\n\nTITLE: Creating File Component Demo\nDESCRIPTION: Creates a minimal Gradio interface that displays a File component using the Blocks API. The demo creates a simple UI with just a file upload component and launches the interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.File()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Streaming Webcam Frames in Python using Gradio\nDESCRIPTION: This code snippet shows how to implement a streaming interface that captures frames from a webcam and applies image processing. It uses the Gradio Image component in webcam mode with streaming enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/04_reactive-interfaces.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\ndef stream_process(video):\n    # Simulate processing on the video frame\n    # Here we're just inverting the colors\n    return 255 - video\n\ndemo = gr.Interface(\n    stream_process,\n    gr.Image(source=\"webcam\", streaming=True),\n    \"image\",\n    live=True\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Concurrent Gradio Interface\nDESCRIPTION: Creates a Gradio interface with a textbox input and output, featuring a 5-second delay to demonstrate concurrent processing. The interface is launched with a maximum of 41 concurrent threads.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/concurrency_without_queue/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef say_hello(name):\n  time.sleep(5)\n  return f\"Hello {name}!\"\n\nwith gr.Blocks() as demo:\n  inp = gr.Textbox()\n  outp = gr.Textbox()\n  button = gr.Button()\n  button.click(say_hello, inp, outp)\n\n  demo.launch(max_threads=41)\n```\n\n----------------------------------------\n\nTITLE: Using Transformers Pipeline with Gradio Interface\nDESCRIPTION: Shows how to create a Gradio demo using the transformers pipeline API with a custom prediction function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/01_using-hugging-face-integrations.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nfrom transformers import pipeline\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndef predict(text):\n  return pipe(text)[0][\"translation_text\"]\n\ndemo = gr.Interface(\n  fn=predict,\n  inputs='text',\n  outputs='text',\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Segmentation with Gradio\nDESCRIPTION: Creates a Gradio interface for image segmentation with customizable boxes and segments. The application includes sliders for controlling the number of boxes and segments, displays both input and annotated output images, and allows section selection with color-coded annotations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_segmentation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nimport random\n\nwith gr.Blocks() as demo:\n    section_labels = [\n        \"apple\",\n        \"banana\",\n        \"carrot\",\n        \"donut\",\n        \"eggplant\",\n        \"fish\",\n        \"grapes\",\n        \"hamburger\",\n        \"ice cream\",\n        \"juice\",\n    ]\n\n    with gr.Row():\n        num_boxes = gr.Slider(0, 5, 2, step=1, label=\"Number of boxes\")\n        num_segments = gr.Slider(0, 5, 1, step=1, label=\"Number of segments\")\n\n    with gr.Row():\n        img_input = gr.Image()\n        img_output = gr.AnnotatedImage(\n            color_map={\"banana\": \"#a89a00\", \"carrot\": \"#ffae00\"}\n        )\n\n    section_btn = gr.Button(\"Identify Sections\")\n    selected_section = gr.Textbox(label=\"Selected Section\")\n\n    def section(img, num_boxes, num_segments):\n        sections = []\n        for a in range(num_boxes):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            w = random.randint(0, img.shape[1] - x)\n            h = random.randint(0, img.shape[0] - y)\n            sections.append(((x, y, x + w, y + h), section_labels[a]))\n        for b in range(num_segments):\n            x = random.randint(0, img.shape[1])\n            y = random.randint(0, img.shape[0])\n            r = random.randint(0, min(x, y, img.shape[1] - x, img.shape[0] - y))\n            mask = np.zeros(img.shape[:2])\n            for i in range(img.shape[0]):\n                for j in range(img.shape[1]):\n                    dist_square = (i - y) ** 2 + (j - x) ** 2\n                    if dist_square < r**2:\n                        mask[i, j] = round((r**2 - dist_square) / r**2 * 4) / 4\n            sections.append((mask, section_labels[b + num_boxes]))\n        return (img, sections)\n\n    section_btn.click(section, [img_input, num_boxes, num_segments], img_output)\n\n    def select_section(evt: gr.SelectData):\n        return section_labels[evt.index]\n\n    img_output.select(select_section, None, selected_section)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Live Gradio Dashboard with Real-Time Updates (Python)\nDESCRIPTION: This Python script builds a live interactive dashboard using the Gradio library. It defines functions `get_time` to fetch the current time and `get_plot` to generate sine wave data for plotting. The Gradio interface (`gr.Blocks`) is structured with rows and columns, containing a real-time clock, a controllable sine wave plot via a slider, and a simple greeting input/output. The `demo.load` and `period.change` methods utilize the `every` parameter to schedule automatic updates for the time display and the plot, creating a dynamic dashboard experience. The script launches the Gradio application when run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/live_dashboard/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport math\n\nimport pandas as pd\n\nimport gradio as gr\nimport datetime\nimport numpy as np\n\ndef get_time():\n    return datetime.datetime.now()\n\nplot_end = 2 * math.pi\n\ndef get_plot(period=1):\n    global plot_end\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\n    y = np.sin(2 * math.pi * period * x)\n    update = gr.LinePlot(\n        value=pd.DataFrame({\"x\": x, \"y\": y}),\n        x=\"x\",\n        y=\"y\",\n        title=\"Plot (updates every second)\",\n        width=600,\n        height=350,\n    )\n    plot_end += 2 * math.pi\n    if plot_end > 1000:\n        plot_end = 2 * math.pi\n    return update\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            c_time2 = gr.Textbox(label=\"Current Time refreshed every second\")\n            gr.Textbox(\n                \"Change the value of the slider to automatically update the plot\",\n                label=\"\",\n            )\n            period = gr.Slider(\n                label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1\n            )\n            plot = gr.LinePlot(show_label=False)\n        with gr.Column():\n            name = gr.Textbox(label=\"Enter your name\")\n            greeting = gr.Textbox(label=\"Greeting\")\n            button = gr.Button(value=\"Greet\")\n            button.click(lambda s: f\"Hello {s}\", name, greeting)\n\n    demo.load(lambda: datetime.datetime.now(), None, c_time2, every=1)\n    dep = demo.load(get_plot, None, plot, every=1)\n    period.change(get_plot, period, plot, every=1, cancels=[dep])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio UI with File Upload Components\nDESCRIPTION: Builds a Gradio interface with various file upload components including Image, Gallery, File, Model3D, MultimodalTextbox, UploadButton, Video, and Audio. Each component is limited to a maximum file size of 15kb.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_file_limit_test/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"\"\"\n    # ⬆️📁 max_file_size test\n    The demo has a max file size of 15kb. The error modal should pop up when a file larger than that is uploaded.          \n    \"\"\")\n    with gr.Row():\n        with gr.Column():\n            gr.Image(label=\"Image\", interactive=True)\n            gr.Gallery(label=\"Gallery\", interactive=True)\n            gr.File(label=\"Single File\", interactive=True, file_count=\"single\")\n        with gr.Column():\n            gr.Model3D(label=\"Model 3D\", interactive=True,)\n            gr.MultimodalTextbox(label=\"Multimodal Textbox\", interactive=True)\n            gr.UploadButton(label=\"Upload Button\", interactive=True)\n        with gr.Column():\n            gr.Video(label=\"Video\", interactive=True)\n            gr.Audio(label=\"Audio\", interactive=True)\n            gr.File(label=\"Multiple Files\", interactive=True, file_count=\"multiple\")\n\nif __name__ == \"__main__\":\n    # The upload limit is set in playwright_setup.js\n    # since the e2e tests use mount_gradio_app\n    demo.launch(max_file_size=\"15kb\")\n```\n\n----------------------------------------\n\nTITLE: Implementing State Management in a Gradio Application (Python)\nDESCRIPTION: Defines a Gradio Blocks interface demonstrating various uses of `gr.State`. It shows state initialization (integers, lists, dicts, sets, custom classes), updates via button clicks (`.click()`), reactive updates via state changes (`.change()`, `gr.on()`), dynamic UI rendering (`gr.render()`), handling different state data types, asynchronous state updates (`async def`), and chaining state changes. Requires the Gradio library to be installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_change/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n\n    with gr.Row():\n        state_a = gr.State(0)\n        btn_a = gr.Button(\"Increment A\")\n        value_a = gr.Number(label=\"Number A\")\n        btn_a.click(lambda x: x + 1, state_a, state_a)\n        state_a.change(lambda x: x, state_a, value_a)\n    with gr.Row():\n        state_b = gr.State(0)\n        btn_b = gr.Button(\"Increment B\")\n        value_b = gr.Number(label=\"Number B\")\n        btn_b.click(lambda x: x + 1, state_b, state_b)\n\n        @gr.on(inputs=state_b, outputs=value_b)\n        def identity(x):\n            return x\n\n    @gr.render(inputs=[state_a, state_b])\n    def render(a, b):\n        for x in range(a):\n            with gr.Row():\n                for y in range(b):\n                    gr.Button(f\"Button {x}, {y}\")\n\n    list_state = gr.State([])\n    dict_state = gr.State(dict())\n    nested_list_state = gr.State([])\n    set_state = gr.State(set())\n\n    def transform_list(x):\n        return {n: n for n in x}, [x[:] for _ in range(len(x))], set(x)\n\n    list_state.change(\n        transform_list,\n        inputs=list_state,\n        outputs=[dict_state, nested_list_state, set_state],\n    )\n\n    all_textbox = gr.Textbox(label=\"Output\")\n    click_count = gr.Number(label=\"Clicks\")\n    change_count = gr.Number(label=\"Changes\")\n    gr.on(\n        inputs=[change_count, dict_state, nested_list_state, set_state],\n        triggers=[dict_state.change, nested_list_state.change, set_state.change],\n        fn=lambda x, *args: (x + 1, \"\\n\".join(str(arg) for arg in args)),\n        outputs=[change_count, all_textbox],\n    )\n\n    count_to_3_btn = gr.Button(\"Count to 3\")\n    count_to_3_btn.click(lambda: [1, 2, 3], outputs=list_state)\n    zero_all_btn = gr.Button(\"Zero All\")\n    zero_all_btn.click(lambda x: [0] * len(x), inputs=list_state, outputs=list_state)\n\n    gr.on(\n        [count_to_3_btn.click, zero_all_btn.click],\n        lambda x: x + 1,\n        click_count,\n        click_count,\n    )\n\n    async def increment(x):\n        yield x + 1\n\n    n_text = gr.State(0)\n    add_btn = gr.Button(\"Iterator State Change\")\n    add_btn.click(increment, n_text, n_text)\n\n    @gr.render(inputs=n_text)\n    def render_count(count):\n        for i in range(int(count)):\n            gr.Markdown(value = f\"Success Box {i} added\", key=i)\n    \n    class CustomState():\n        def __init__(self, val):\n            self.val = val\n\n        def __hash__(self) -> int:\n            return self.val\n\n    custom_state = gr.State(CustomState(5))\n    with gr.Row():\n        btn_10 = gr.Button(\"Set State to 10\")\n        custom_changes = gr.Number(0, label=\"Custom State Changes\")\n        custom_clicks = gr.Number(0, label=\"Custom State Clicks\")\n\n    custom_state.change(increment, custom_changes, custom_changes)\n    def set_to_10(cs: CustomState):\n        cs.val = 10\n        return cs\n\n    btn_10.click(set_to_10, custom_state, custom_state).then(\n        increment, custom_clicks, custom_clicks\n    )\n\n    @gr.render()\n    def render_state_changes():\n        with gr.Row():\n            box1 = gr.Textbox(label=\"Start State\")\n            state1 = gr.State()\n            box2 = gr.Textbox()\n            state2 = gr.State()\n            box3 = gr.Textbox(label=\"End State\")\n\n            iden = lambda x: x\n            box1.change(iden, box1, state1)\n            state1.change(iden, state1, box2)\n            box2.change(iden, box2, state2)\n            state2.change(iden, state2, box3)\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum File Upload Size in Gradio (Python)\nDESCRIPTION: This Python code demonstrates initializing a simple Gradio Interface and launching it with a maximum file size limit for uploads using the `max_file_size` parameter. It shows two methods for specifying the limit: using a string representation (e.g., \"5mb\") or an integer value combined with the `gr.FileSize` enum (e.g., `5 * gr.FileSize.MB`). This feature requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n```\n\n----------------------------------------\n\nTITLE: Referencing Other Theme Variables in Gradio\nDESCRIPTION: This example shows how to reference other theme variables for efficient styling. It uses the asterisk prefix to make multiple variables reference the first one, simplifying theme management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default().set(\n    button_primary_background_fill=\"#FF0000\",\n    button_primary_background_fill_hover=\"*button_primary_background_fill\",\n    button_primary_border=\"*button_primary_background_fill\",\n)\n```\n\n----------------------------------------\n\nTITLE: Importing PDF.js and Setting Worker Source in TypeScript\nDESCRIPTION: Sets up the PDF.js library by importing it and configuring the worker script source from a CDN. This is essential for the PDF rendering functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport pdfjsLib from \"pdfjs-dist\";\n    ...\n    pdfjsLib.GlobalWorkerOptions.workerSrc =  \"https://cdn.bootcss.com/pdf.js/3.11.174/pdf.worker.js\";\n```\n\n----------------------------------------\n\nTITLE: Creating and Displaying a Colorful Dataframe with Gradio\nDESCRIPTION: This code creates a pandas DataFrame, applies styling to highlight maximum values in each column, and displays it using Gradio's Dataframe component. The demo is launched if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_colorful/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport gradio as gr\n\ndf = pd.DataFrame(\n    {\n        \"A\": [14, 4, 5, 4, 1],\n        \"B\": [5, 2, 54, 3, 2],\n        \"C\": [20, 20, 7, 3, 8],\n        \"D\": [14, 3, 6, 2, 6],\n        \"E\": [23, 45, 64, 32, 23],\n    }\n)\n\nt = df.style.highlight_max(color=\"lightgreen\", axis=0)\n\nwith gr.Blocks() as demo:\n    gr.Dataframe(t)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing RT-DETR Model\nDESCRIPTION: Loading the RT-DETR model and image processor from Hugging Face Hub for object detection\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/03_object-detection-from-video.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import RTDetrForObjectDetection, RTDetrImageProcessor\n\nimage_processor = RTDetrImageProcessor.from_pretrained(\"PekingU/rtdetr_r50vd\")\nmodel = RTDetrForObjectDetection.from_pretrained(\"PekingU/rtdetr_r50vd\").to(\"cuda\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Interactive and Static Image Components in Gradio (Python)\nDESCRIPTION: Illustrates the creation of two `gr.Image` components using `gr.Blocks`. The `interactive=True` version provides UI for uploading images or using a webcam, whereas the `interactive=False` version only displays images and lacks upload/capture functionality. Depends on the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/02_key-component-concepts.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n   gr.Image(interactive=True)\n   gr.Image(interactive=False)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Soft Theme\nDESCRIPTION: Sets up a Gradio interface with various components using the Soft theme. It includes a textbox for name input, a slider for count, submit and clear buttons, and an output textbox. The interface is linked to a function that repeats the input name based on the count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_soft/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\nwith gr.Blocks(theme=gr.themes.Soft()) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building a Sound-Alert Gradio Interface in Python\nDESCRIPTION: Constructs a Gradio app that greets users and plays an MP3 sound after specific interactions. Defines a JavaScript function to play the audio file and a Python function that returns a greeting after a delay. The UI consists of two textboxes, with event-driven logic to trigger both Python and JS functions based on user actions. Dependencies include Gradio, time, the previously installed audio file, and standard Python environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sound_alert/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport gradio as gr\n\njs_function = \"() => {new Audio('file=beep.mp3').play();}\"\n\ndef task(x):\n    time.sleep(2)\n    return \"Hello, \" + x\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"name\")\n    greeting = gr.Textbox(label=\"greeting\")\n    name.blur(task, name, greeting)\n    greeting.change(None, [], [], js=js_function)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Authenticating BigQuery Client using Service Account Key in Python\nDESCRIPTION: Demonstrates how to initialize the Google BigQuery client in Python using a service account key file. It imports the necessary `bigquery` class and uses the `from_service_account_json` method, passing the path to the downloaded JSON credentials file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_2\n\nLANGUAGE: py\nCODE:\n```\nfrom google.cloud import bigquery\n\nclient = bigquery.Client.from_service_account_json(\"path/to/key.json\")\n```\n\n----------------------------------------\n\nTITLE: Implementing Sales Projections Prediction with Gradio Interface\nDESCRIPTION: Creates a Gradio interface that takes employee sales data for January through March, performs polynomial regression to project sales for the rest of the year, and returns the input data, a visualization plot, and regression coefficients.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sales_projections/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport gradio as gr\n\ndef sales_projections(employee_data):\n    sales_data = employee_data.iloc[:, 1:4].astype(\"int\").to_numpy()\n    regression_values = np.apply_along_axis(\n        lambda row: np.array(np.poly1d(np.polyfit([0, 1, 2], row, 2))), 0, sales_data\n    )\n    projected_months = np.repeat(\n        np.expand_dims(np.arange(3, 12), 0), len(sales_data), axis=0\n    )\n    projected_values = np.array(\n        [\n            month * month * regression[0] + month * regression[1] + regression[2]\n            for month, regression in zip(projected_months, regression_values)\n        ]\n    )\n    plt.plot(projected_values.T)\n    plt.legend(employee_data[\"Name\"])\n    return employee_data, plt.gcf(), regression_values\n\ndemo = gr.Interface(\n    sales_projections,\n    gr.Dataframe(\n        headers=[\"Name\", \"Jan Sales\", \"Feb Sales\", \"Mar Sales\"],\n        value=[[\"Jon\", 12, 14, 18], [\"Alice\", 14, 17, 2], [\"Sana\", 8, 9.5, 12]],\n    ),\n    [\"dataframe\", \"plot\", \"numpy\"],\n    description=\"Enter sales figures for employees to predict sales trajectory over year.\",\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining TypeScript Types\nDESCRIPTION: TypeScript type definitions for frontend message handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nexport type FileMessage = {\n\tfile: FileData;\n\talt_text?: string;\n};\n\n\nexport type MultimodalMessage = {\n\ttext: string;\n\tfiles?: FileMessage[];\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a ChatInterface with Prefilled Conversations using Radio Buttons\nDESCRIPTION: Demonstrates how to modify chatbot values using a Radio component to prefill the chatbot with different conversation templates. This example shows how to interact with chatbot_value directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n$code_chatinterface_prefill\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Code Handling and Display\nDESCRIPTION: Sets up a Gradio interface with functionality for selecting programming languages, inputting code, displaying output, and loading code from a file. It includes functions for setting language, loading file content, and handling code input/output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/code/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\nfrom time import sleep\n\ncss_file = os.path.join(os.path.abspath(''), \"file.css\")\n\ndef set_lang(language):\n    print(language)\n    return gr.Code(language=language)\n\ndef set_lang_from_path():\n    sleep(1)\n    return gr.Code(open(css_file).read(), language=\"css\")\n\ndef code(language, code):\n    return gr.Code(code, language=language)\n\nio = gr.Interface(lambda x: x, \"code\", \"code\")\n\nwith gr.Blocks() as demo:\n    lang = gr.Dropdown(value=\"python\", choices=gr.Code.languages)\n    with gr.Row():\n        code_in = gr.Code(\n            language=\"python\",\n            label=\"Input\",\n            value='def all_odd_elements(sequence):\\n    \"\"\"Returns every odd element of the sequence.\"\"\"',\n            show_line_numbers = False\n        )\n        code_out = gr.Code(label=\"Output\", show_line_numbers = True)\n    btn = gr.Button(\"Run\")\n    btn_two = gr.Button(\"Load File\")\n\n    lang.change(set_lang, inputs=lang, outputs=code_in)\n    btn.click(code, inputs=[lang, code_in], outputs=code_out)\n    btn_two.click(set_lang_from_path, inputs=None, outputs=code_out)\n    io.render()\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Controlling Brush Preview via API (TypeScript)\nDESCRIPTION: Shows or hides the brush preview feature, which typically displays the current brush size and color in the center of the editor canvas. It accepts a boolean `show` parameter (`true` to show, `false` to hide). This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\npreview_brush(show)\n```\n\n----------------------------------------\n\nTITLE: Defining Outbreak Forecasting Interface and Logic with Gradio - Python\nDESCRIPTION: This snippet defines the core outbreak forecasting logic and sets up the Gradio interface. It includes a function 'outbreak' that generates forecasts for selected countries and months, optionally adjusting the forecast based on social distancing. Outputs are dynamically rendered using user-specified plotting libraries (Matplotlib, Plotly, Altair, Bokeh). The snippet configures input components, output visualization, provides example scenarios, and launches the interface as an interactive demo. Dependencies include gradio, numpy, pandas, and all supported plotting libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/outbreak_forecast/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\nfrom math import sqrt\\nimport numpy as np\\nimport pandas as pd\\n\\ndef outbreak(plot_type, r, month, countries, social_distancing):\\n    months = [\\\"January\\\", \\\"February\\\", \\\"March\\\", \\\"April\\\", \\\"May\\\"]\\n    m = months.index(month)\\n    start_day = 30 * m\\n    final_day = 30 * (m + 1)\\n    x = np.arange(start_day, final_day + 1)\\n    pop_count = {\\\"USA\\\": 350, \\\"Canada\\\": 40, \\\"Mexico\\\": 300, \\\"UK\\\": 120}\\n    if social_distancing:\\n        r = sqrt(r)\\n    df = pd.DataFrame({\\\"day\\\": x})\\n    for country in countries:\\n        df[country] = x ** (r) * (pop_count[country] + 1)\\n\\n    if plot_type == \\\"Matplotlib\\\":\\n        import matplotlib.pyplot as plt\\n\\n        fig = plt.figure()\\n        plt.plot(df[\\\"day\\\"], df[countries].to_numpy())\\n        plt.title(\\\"Outbreak in \\\" + month)\\n        plt.ylabel(\\\"Cases\\\")\\n        plt.xlabel(\\\"Days since Day 0\\\")\\n        plt.legend(countries)\\n        return fig\\n    elif plot_type == \\\"Plotly\\\":\\n        import plotly.express as px\\n\\n        fig = px.line(df, x=\\\"day\\\", y=countries)\\n        fig.update_layout(\\n            title=\\\"Outbreak in \\\" + month,\\n            xaxis_title=\\\"Cases\\\",\\n            yaxis_title=\\\"Days Since Day 0\\\",\\n        )\\n        return fig\\n    elif plot_type == \\\"Altair\\\":\\n        import altair\\n\\n        df = df.melt(id_vars=\\\"day\\\").rename(columns={\\\"variable\\\": \\\"country\\\"})\\n        fig = altair.Chart(df).mark_line().encode(x=\\\"day\\\", y=\\\"value\\\", color=\\\"country\\\")\\n        return fig\\n    elif plot_type == \\\"Bokeh\\\":\\n        from bokeh.plotting import figure\\n        from bokeh.models import ColumnDataSource\\n\\n        source = ColumnDataSource(df)\\n        fig = figure(title=\\\"Outbreak in \\\" + month, x_axis_label=\\\"Days since Day 0\\\", y_axis_label=\\\"Cases\\\")\\n        for country in countries:\\n            fig.line(\\\"day\\\", country, source=source, legend_label=country)\\n        return fig\\n    else:\\n        raise ValueError(\\\"A plot type must be selected\\\")\\n\\ninputs = [\\n    gr.Dropdown([\\\"Matplotlib\\\", \\\"Plotly\\\", \\\"Altair\\\", \\\"Bokeh\\\"], label=\\\"Plot Type\\\", value=\\\"Matplotlib\\\"),\\n    gr.Slider(1, 4, 3.2, label=\\\"R\\\"),\\n    gr.Dropdown([\\\"January\\\", \\\"February\\\", \\\"March\\\", \\\"April\\\", \\\"May\\\"], label=\\\"Month\\\", value=\\\"March\\\"),\\n    gr.CheckboxGroup(\\n        [\\\"USA\\\", \\\"Canada\\\", \\\"Mexico\\\", \\\"UK\\\"], label=\\\"Countries\\\", value=[\\\"USA\\\", \\\"Canada\\\"]\\n    ),\\n    gr.Checkbox(label=\\\"Social Distancing?\\\"),\\n]\\noutputs = gr.Plot()\\n\\ndemo = gr.Interface(\\n    fn=outbreak,\\n    inputs=inputs,\\n    outputs=outputs,\\n    examples=[\\n        [\\\"Matplotlib\\\", 2, \\\"March\\\", [\\\"Mexico\\\", \\\"UK\\\"], True],\\n        [\\\"Altair\\\", 2, \\\"March\\\", [\\\"Mexico\\\", \\\"Canada\\\"], True],\\n        [\\\"Plotly\\\", 3.6, \\\"February\\\", [\\\"Canada\\\", \\\"Mexico\\\", \\\"UK\\\"], False],\\n        [\\\"Bokeh\\\", 3.2, \\\"April\\\", [\\\"Canada\\\", \\\"UK\\\"], False],\\n    ],\\n    cache_examples=True,\\n)\\n\\nif __name__ == \\\"__main__\\\":\\n    demo.launch()\\n\n```\n\n----------------------------------------\n\nTITLE: Initializing SQLite Database and CRUD Operations - Python\nDESCRIPTION: This snippet initializes a SQLite database and defines core functions for inserting and retrieving user reviews, including table creation logic guarded by an exception handler in case the table does not yet exist. It provides methods to add new reviews and fetch the 10 most recent, with pandas used for data manipulation and schema formatting. Dependencies are `sqlite3` and `pandas`, with important parameters like reviewer's name, rating, and comments. The code expects a local './reviews.db' database and is intended for use as backend logic in a feedback application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-background-tasks.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nDB_FILE = \"./reviews.db\"\ndb = sqlite3.connect(DB_FILE)\n\n# Create table if it doesn't already exist\ntry:\n    db.execute(\"SELECT * FROM reviews\").fetchall()\n    db.close()\nexcept sqlite3.OperationalError:\n    db.execute(\n        '''\n        CREATE TABLE reviews (id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\n                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,\n                              name TEXT, review INTEGER, comments TEXT)\n        ''')\n    db.commit()\n    db.close()\n\ndef get_latest_reviews(db: sqlite3.Connection):\n    reviews = db.execute(\"SELECT * FROM reviews ORDER BY id DESC limit 10\").fetchall()\n    total_reviews = db.execute(\"Select COUNT(id) from reviews\").fetchone()[0]\n    reviews = pd.DataFrame(reviews, columns=[\"id\", \"date_created\", \"name\", \"review\", \"comments\"])\n    return reviews, total_reviews\n\n\ndef add_review(name: str, review: int, comments: str):\n    db = sqlite3.connect(DB_FILE)\n    cursor = db.cursor()\n    cursor.execute(\"INSERT INTO reviews(name, review, comments) VALUES(?,?,?)\", [name, review, comments])\n    db.commit()\n    reviews, total_reviews = get_latest_reviews(db)\n    db.close()\n    return reviews, total_reviews\n```\n\n----------------------------------------\n\nTITLE: Synchronizing Data with HuggingFace Dataset Repository - Python\nDESCRIPTION: This snippet demonstrates initializing a HuggingFace dataset repository and updating the local data store by pulling the latest backup from the remote. It accesses the HuggingFace authentication token from the environment, clones or pulls the dataset, and synchronizes the SQLite file locally. Dependencies include `huggingface_hub`, `os`, and `shutil`. Parameters require valid repository details and an access token stored as the 'HUB_TOKEN' environment variable. The code assumes both local and remote datasets are compatible.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-background-tasks.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nTOKEN = os.environ.get('HUB_TOKEN')\nrepo = huggingface_hub.Repository(\n    local_dir=\"data\",\n    repo_type=\"dataset\",\n    clone_from=\"<name-of-your-dataset>\",\n    use_auth_token=TOKEN\n)\nrepo.git_pull()\n\nshutil.copyfile(\"./data/reviews.db\", DB_FILE)\n```\n\n----------------------------------------\n\nTITLE: Reading Data from Supabase\nDESCRIPTION: Function to read data from Supabase Product table and convert it to a pandas DataFrame\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-supabase-data.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport supabase\nimport pandas as pd\n\nclient = supabase.create_client('SUPABASE_URL', 'SUPABASE_SECRET_KEY')\n\ndef read_data():\n    response = client.table('Product').select(\"*\").execute()\n    df = pd.DataFrame(response.data)\n    return df\n```\n\n----------------------------------------\n\nTITLE: GradioTool Abstract Base Class Definition\nDESCRIPTION: Abstract base class definition for creating custom Gradio tools. Requires implementation of create_job and postprocess methods.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/04_gradio-and-llm-agents.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass GradioTool(BaseTool):\n\n    def __init__(self, name: str, description: str, src: str) -> None:\n\n    @abstractmethod\n    def create_job(self, query: str) -> Job:\n        pass\n\n    @abstractmethod\n    def postprocess(self, output: Tuple[Any] | Any) -> str:\n        pass\n```\n\n----------------------------------------\n\nTITLE: Implementing Svelte Frontend Rendering\nDESCRIPTION: Svelte template code for rendering multimodal messages with text and media files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_5\n\nLANGUAGE: svelte\nCODE:\n```\n<Markdown\n    message={message.text}\n    {latex_delimiters}\n    {sanitize_html}\n    {render_markdown}\n    {line_breaks}\n    on:load={scroll}\n/>\n{#each message.files as file, k}\n    {#if file !== null && file.file.mime_type?.includes(\"audio\")}\n        <audio\n            data-testid=\"chatbot-audio\"\n            controls\n            preload=\"metadata\"\n            src={file.file?.url}\n            title={file.alt_text}\n            on:play\n            on:pause\n            on:ended\n        />\n    {:else if message !== null && file.file?.mime_type?.includes(\"video\")}\n        <video\n            data-testid=\"chatbot-video\"\n            controls\n            src={file.file?.url}\n            title={file.alt_text}\n            preload=\"auto\"\n            on:play\n            on:pause\n            on:ended\n        >\n            <track kind=\"captions\" />\n        </video>\n    {:else if message !== null && file.file?.mime_type?.includes(\"image\")}\n        <img\n            data-testid=\"chatbot-image\"\n            src={file.file?.url}\n            alt={file.alt_text}\n        />\n    {:else if message !== null && file.file?.url !== null}\n        <a\n            data-testid=\"chatbot-file\"\n            href={file.file?.url}\n            target=\"_blank\"\n            download={window.__is_colab__\n                ? null\n                : file.file?.orig_name || file.file?.path}\n        >\n            {file.file?.orig_name || file.file?.path}\n        </a>\n    {:else if pending_message && j === 1}\n        <Pending {layout} />\n    {/if}\n{/each}\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Time Series Plots with DateTimeRange\nDESCRIPTION: Implements a Gradio interface with DateTimeRange component bound to two line plots. The interface allows users to filter time series data by selecting a date range, with the plots updating accordingly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetimerange/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_datetimerange import DateTimeRange\nfrom data import df\n\nwith gr.Blocks() as demo:\n    daterange = DateTimeRange([\"now - 24h\", \"now\"])\n    plot1 = gr.LinePlot(df, x=\"time\", y=\"price\")\n    plot2 = gr.LinePlot(df, x=\"time\", y=\"price\", color=\"origin\")\n    daterange.bind([plot1, plot2])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Segment Selection with Gradio\nDESCRIPTION: Creates an interactive Gradio interface for selecting image segments based on color similarity. The implementation uses a flood-fill algorithm to identify connected pixels with similar colors within a specified tolerance range. The selected segment is highlighted while the rest of the image is dimmed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_selections/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    tolerance = gr.Slider(label=\"Tolerance\", info=\"How different colors can be in a segment.\", minimum=0, maximum=256*3, value=50)\n    with gr.Row():\n        input_img = gr.Image(label=\"Input\")\n        output_img = gr.Image(label=\"Selected Segment\")\n\n    def get_select_coords(img, tolerance, evt: gr.SelectData):\n        visited_pixels = set()\n        pixels_in_queue = set()\n        pixels_in_segment = set()\n        start_pixel = img[evt.index[1], evt.index[0]]\n        pixels_in_queue.add((evt.index[1], evt.index[0]))\n        while len(pixels_in_queue) > 0:\n            pixel = pixels_in_queue.pop()\n            visited_pixels.add(pixel)\n            neighbors = []\n            if pixel[0] > 0:\n                neighbors.append((pixel[0] - 1, pixel[1]))\n            if pixel[0] < img.shape[0] - 1:\n                neighbors.append((pixel[0] + 1, pixel[1]))\n            if pixel[1] > 0:\n                neighbors.append((pixel[0], pixel[1] - 1))\n            if pixel[1] < img.shape[1] - 1:\n                neighbors.append((pixel[0], pixel[1] + 1))\n            for neighbor in neighbors:\n                if neighbor in visited_pixels:\n                    continue\n                neighbor_pixel = img[neighbor[0], neighbor[1]]\n                if np.abs(neighbor_pixel - start_pixel).sum() < tolerance:\n                    pixels_in_queue.add(neighbor)\n                    pixels_in_segment.add(neighbor)\n\n        out = img.copy() * 0.2\n        out = out.astype(np.uint8)\n        for pixel in pixels_in_segment:\n            out[pixel[0], pixel[1]] = img[pixel[0], pixel[1]]\n        return out\n\n    input_img.select(get_select_coords, [input_img, tolerance], output_img)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing ImageEditor Component with Custom Configuration in Python\nDESCRIPTION: Example demonstrating how to use the new ImageEditor component with various configuration options including source selection, crop size constraints, transformations, and brush customization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Server Block Configuration for Gradio via Nginx - Bash\nDESCRIPTION: This snippet provides a ready-to-use Nginx server block for proxying requests from a specific subpath (e.g., /gradio-demo/) to a local Gradio Python app. It sets necessary headers for WebSocket upgrades and forwarding, disables proxy buffering and redirects, and demonstrates how to expose the app via a subpath. 'server_name' and port values should be updated as needed. This should be placed in a file under /etc/nginx/sites-available/ and symlinked from sites-enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-gradio-on-your-web-server-with-nginx.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nserver {\n    listen 80;\n    server_name example.com www.example.com;  # Change this to your domain name\n\n    location /gradio-demo/ {  # Change this if you'd like to server your Gradio app on a different path\n        proxy_pass http://127.0.0.1:7860/; # Change this if your Gradio app will be running on a different port\n        proxy_buffering off;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Host $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Building Interactive DateTime-Filtered Plot in Gradio\nDESCRIPTION: Creates a Gradio interface with datetime inputs to filter a line plot. The UI includes start and end datetime pickers and an apply button that updates the plot based on the selected time range. The plot displays price data over time from the imported DataFrame.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetime/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        start = gr.DateTime(\"now - 24h\")\n        end = gr.DateTime(\"now\")\n        apply_btn = gr.Button(\"Apply\")\n    plot = gr.LinePlot(df, x=\"time\", y=\"price\")\n\n    apply_btn.click(lambda start, end: gr.BarPlot(x_lim=[start, end]), [start, end], plot)\n    \nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Command to install the necessary Python packages gradio and discord.py for building the Discord bot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/06_creating-a-discord-bot-from-a-gradio-app.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npip install --upgrade gradio discord.py~=2.0\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio ImageEditor Component\nDESCRIPTION: Example showing how to configure and use the ImageEditor component with customized settings for sources, crop size, transforms, and brush properties. The component supports image upload, webcam input, clipboard paste, cropping with ratios, painting layers, and customizable brush settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Webcam Interface\nDESCRIPTION: This code creates a Gradio interface for capturing images and videos from a webcam. It defines a function 'snap' that returns the captured image and video, and sets up the interface with appropriate input and output components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/webcam/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef snap(image, video):\n    return [image, video]\n\ndemo = gr.Interface(\n    snap,\n    [gr.Image(sources=[\"webcam\"]), gr.Video(sources=[\"webcam\"])],\n    [\"image\", \"video\"],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Directory Structure Overview\nDESCRIPTION: Shows the directory structure created for a new custom component, including backend, frontend, demo folders and configuration files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/01_custom-components-in-five-minutes.md#2025-04-23_snippet_1\n\nLANGUAGE: directory\nCODE:\n```\n- backend/ <- The python code for your custom component\n- frontend/ <- The javascript code for your custom component\n- demo/ <- A sample app using your custom component. Modify this to develop your component!\n- pyproject.toml <- Used to build the package and specify package metadata.\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio App with Dropdown Component\nDESCRIPTION: This snippet creates a simple Gradio app with a dropdown component. It imports Gradio, defines a Blocks interface with a Dropdown, and launches the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dropdown_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Dropdown(choices=[\"First Choice\", \"Second Choice\", \"Third Choice\"])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring ImageEditor Component in Python\nDESCRIPTION: Demonstrates how to configure and use the ImageEditor component with various options like image sources, crop settings, brush properties and eraser tools. The component provides access to composite images, background and individual layers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Connecting to Private Spaces - Python\nDESCRIPTION: Example of connecting to a private Hugging Face Space using authentication token.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/my-private-space\", hf_token=\"...\")\n```\n\n----------------------------------------\n\nTITLE: Initializing Anthropic Client with Gradio Dependencies - Python\nDESCRIPTION: This snippet imports required dependencies and initializes the Anthropic API client for later use in message handling and response generation. Dependencies include gradio, anthropic, base64, and typing for type hints. It assumes the ANTHROPIC_API_KEY environment variable is set, providing a ready-to-use client object.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\nimport anthropic\\nimport base64\\nfrom typing import List, Dict, Any\\n\\nclient = anthropic.Anthropic()\n```\n\n----------------------------------------\n\nTITLE: Type Hinting `preprocess` Return and `postprocess` Input (Python)\nDESCRIPTION: Shows example signatures for `preprocess` and `postprocess` methods within a Gradio component. It specifically highlights the required type hints for the `preprocess` return value (`tuple[int, str] | str | None`) and the `postprocess` input parameter (`tuple[int, str] | None`). These particular type hints define the data types passed to and returned from the user's prediction function and are crucial for generating correct documentation about the component's data handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_2\n\nLANGUAGE: py\nCODE:\n```\ndef preprocess(\n  self, payload: FileData | None # input is optional\n) -> tuple[int, str] | str | None:\n\n# user function input  is the preprocess return ▲\n# user function output is the postprocess input ▼\n\ndef postprocess(\n  self, value: tuple[int, str] | None\n) -> FileData | bytes | None: # return is optional\n  ...\n```\n\n----------------------------------------\n\nTITLE: Displaying a Static Conversation with Gradio MultimodalChatbot - Python\nDESCRIPTION: This snippet demonstrates how to build a static conversation between a user and a bot using Gradio's Blocks API and a custom MultimodalChatbot component in Python. It requires the 'gradio', 'gradio_multimodalchatbot', and 'gradio.data_classes' libraries. User and bot messages are structured as dictionaries containing text and optional file attachments, with files represented via 'FileData' instances referencing local or remote file paths. The conversation is an array of message pairs rendered in Gradio Blocks, and launching the demo creates an interactive UI that shows the sample exchanges. Expected inputs are file paths and texts; the output is an interactive web interface. Limitations include the necessity for file paths to be accessible to the app (especially in development environments).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_multimodalchatbot import MultimodalChatbot\nfrom gradio.data_classes import FileData\n\nuser_msg1 = {\"text\": \"Hello, what is in this image?\",\n             \"files\": [{\"file\": FileData(path=\"https://gradio-builds.s3.amazonaws.com/diffusion_image/cute_dog.jpg\")}]\n             }\nbot_msg1 = {\"text\": \"It is a very cute dog\",\n            \"files\": []}\n\nuser_msg2 = {\"text\": \"Describe this audio clip please.\",\n             \"files\": [{\"file\": FileData(path=\"cantina.wav\")}]}\nbot_msg2 = {\"text\": \"It is the cantina song from Star Wars\",\n            \"files\": []}\n\nuser_msg3 = {\"text\": \"Give me a video clip please.\",\n             \"files\": []}\nbot_msg3 = {\"text\": \"Here is a video clip of the world\",\n            \"files\": [{\"file\": FileData(path=\"world.mp4\")},\n                      {\"file\": FileData(path=\"cantina.wav\")}]} \n\nconversation = [[user_msg1, bot_msg1], [user_msg2, bot_msg2], [user_msg3, bot_msg3]]\n\nwith gr.Blocks() as demo:\n    MultimodalChatbot(value=conversation, height=800)\n\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Bar Plot with Aggregated Data in Gradio\nDESCRIPTION: Creates a Gradio interface that displays a bar plot visualizing mean height grouped by ethnicity. The code imports the dataframe from the downloaded data file and uses Gradio's BarPlot component with mean aggregation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_nominal/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.BarPlot(df, x=\"ethnicity\", y=\"height\", y_aggregate=\"mean\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Bar Plot Visualizations with Gradio\nDESCRIPTION: Builds an interactive Gradio application that demonstrates different types of bar plots. The code generates sample data using Pandas, defines a function to create various bar plot types (simple, stacked, grouped) in both vertical and horizontal orientations, and creates a UI with a dropdown for selecting plot types.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport random\n\nsimple = pd.DataFrame(\n    {\n        \"a\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"b\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nfake_barley = pd.DataFrame(\n    {\n        \"site\": [\n            random.choice(\n                [\n                    \"University Farm\",\n                    \"Waseca\",\n                    \"Morris\",\n                    \"Crookston\",\n                    \"Grand Rapids\",\n                    \"Duluth\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"yield\": [random.randint(25, 75) for _ in range(120)],\n        \"variety\": [\n            random.choice(\n                [\n                    \"Manchuria\",\n                    \"Wisconsin No. 38\",\n                    \"Glabron\",\n                    \"No. 457\",\n                    \"No. 462\",\n                    \"No. 475\",\n                ]\n            )\n            for _ in range(120)\n        ],\n        \"year\": [\n            random.choice(\n                [\n                    \"1931\",\n                    \"1932\",\n                ]\n            )\n            for _ in range(120)\n        ],\n    }\n)\n\ndef bar_plot_fn(display):\n    if display == \"simple\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n        )\n    elif display == \"simple-horizontal\":\n        return gr.BarPlot(\n            simple,\n            x=\"a\",\n            y=\"b\",\n            x_title=\"Variable A\",\n            y_title=\"Variable B\",\n            title=\"Simple Bar Plot with made up data\",\n            tooltip=[\"a\", \"b\"],\n            vertical=False,\n            y_lim=[20, 100],\n        )\n    elif display == \"stacked-horizontal\":\n        return gr.BarPlot(\n            fake_barley,\n            x=\"variety\",\n            y=\"yield\",\n            color=\"site\",\n            title=\"Barley Yield Data\",\n            vertical=False,\n            tooltip=[\"variety\", \"site\"],\n        )\n    elif display == \"grouped-horizontal\":\n        return gr.BarPlot(\n            fake_barley.astype({\"year\": str}),\n            x=\"year\",\n            y=\"yield\",\n            color=\"year\",\n            group=\"site\",\n            title=\"Barley Yield by Year and Site\",\n            group_title=\"\",\n            tooltip=[\"yield\", \"site\", \"year\"],\n            vertical=False,\n        )\n\nwith gr.Blocks() as bar_plot:\n    with gr.Row():\n        with gr.Column():\n            display = gr.Dropdown(\n                choices=[\n                    \"simple\",\n                    \"stacked\",\n                    \"grouped\",\n                    \"simple-horizontal\",\n                    \"stacked-horizontal\",\n                    \"grouped-horizontal\",\n                ],\n                value=\"simple\",\n                label=\"Type of Bar Plot\",\n            )\n        with gr.Column():\n            plot = gr.BarPlot()\n    display.change(bar_plot_fn, inputs=display, outputs=plot)\n    bar_plot.load(fn=bar_plot_fn, inputs=display, outputs=plot)\n\nbar_plot.launch()\n```\n\n----------------------------------------\n\nTITLE: Importing @gradio/upload Components and Functions in Svelte\nDESCRIPTION: This snippet demonstrates importing the `Upload` and `ModifyUpload` Svelte components, along with utility functions `normalise_file`, `get_fetchable_url_or_file`, `upload`, and `prepare_files` from the `@gradio/upload` package within a Svelte script tag.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { Upload, ModifyUpload, normalise_file, get_fetchable_url_or_file, upload, prepare_files } from \"@gradio/upload\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Creating a Comprehensive Gradio UI Demo with Various Components\nDESCRIPTION: This code demonstrates how to create a Gradio interface with multiple UI components. It defines a function to generate markdown content and creates a Blocks interface with components like textboxes, checkboxes, sliders, audio inputs, videos, images, dataframes, and more. The demo includes interactive dataframes with different configurations and a button that updates a dataframe with markdown content when clicked.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_outputs/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef make_markdown():\n    return [\n        [\n            \"# hello again\",\n            \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n            '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n        ],\n        [\n            \"## hello again again\",\n            \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n            '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n        ],\n        [\n            \"### hello thrice\",\n            \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n            '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n        ],\n    ]\n\nwith gr.Blocks() as demo:\n    with gr.Column():\n        txt = gr.Textbox(label=\"Small Textbox\", lines=1, show_label=False)\n        txt = gr.Textbox(label=\"Large Textbox\", lines=5, show_label=False)\n        num = gr.Number(label=\"Number\", show_label=False)\n        check = gr.Checkbox(label=\"Checkbox\", show_label=False)\n        check_g = gr.CheckboxGroup(\n            label=\"Checkbox Group\", choices=[\"One\", \"Two\", \"Three\"], show_label=False\n        )\n        radio = gr.Radio(\n            label=\"Radio\", choices=[\"One\", \"Two\", \"Three\"], show_label=False\n        )\n        drop = gr.Dropdown(\n            label=\"Dropdown\", choices=[\"One\", \"Two\", \"Three\"], show_label=False\n        )\n        slider = gr.Slider(label=\"Slider\", show_label=False)\n        audio = gr.Audio(show_label=False)\n        file = gr.File(show_label=False)\n        video = gr.Video(show_label=False)\n        image = gr.Image(show_label=False)\n        df = gr.Dataframe(show_label=False)\n        html = gr.HTML(show_label=False)\n        json = gr.JSON(show_label=False)\n        md = gr.Markdown(show_label=False)\n        label = gr.Label(show_label=False)\n        highlight = gr.HighlightedText(show_label=False)\n        gr.Dataframe(interactive=True, col_count=(3, \"fixed\"), label=\"Dataframe\")\n        gr.Dataframe(interactive=True, col_count=4, label=\"Dataframe\")\n        gr.Dataframe(\n            interactive=True, headers=[\"One\", \"Two\", \"Three\", \"Four\"], label=\"Dataframe\"\n        )\n        gr.Dataframe(\n            interactive=True,\n            headers=[\"One\", \"Two\", \"Three\", \"Four\"],\n            col_count=(4, \"fixed\"),\n            row_count=(7, \"fixed\"),\n            value=[[0, 0, 0, 0]],\n            label=\"Dataframe\",\n        )\n        gr.Dataframe(\n            interactive=True, headers=[\"One\", \"Two\", \"Three\", \"Four\"], col_count=4\n        )\n        df = gr.DataFrame(\n            [\n                [\n                    \"# hello\",\n                    \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n                    '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n                ],\n                [\n                    \"## hello\",\n                    \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n                    '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n                ],\n                [\n                    \"### hello\",\n                    \"Hello my name is frank, I am liking the small turtle you have there. It would be a shame if it went missing.\",\n                    '<img src=\"https://images.unsplash.com/photo-1574613362884-f79513a5128c?fit=crop&w=500&q=80\"/>',\n                ],\n            ],\n            headers=[\"One\", \"Two\", \"Three\"],\n            wrap=True,\n            datatype=[\"markdown\", \"markdown\", \"html\"],\n            interactive=True,\n        )\n        btn = gr.Button(\"Run\")\n        btn.click(fn=make_markdown, inputs=None, outputs=df)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with gradio_client - Python\nDESCRIPTION: This Python code snippet demonstrates how to use the gradio_client library to programmatically interact with a Gradio Space for audio transcription. After importing the Client class and initializing it with the app name, the predict() method sends an audio file to the remote app and retrieves the transcription. Dependencies: gradio_client installed, valid Gradio Space URI, and an accessible audio file. The input is a path to a WAV audio file, and the output is the corresponding transcribed string; the snippet assumes the model is deployed and accessible.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/whisper\")\nclient.predict(\"audio_sample.wav\")\n\n>> \"This is a test of the whisper speech recognition model.\"\n\n```\n\n----------------------------------------\n\nTITLE: Handling Generator Endpoints in JavaScript\nDESCRIPTION: Demonstrates how to work with endpoints that return a series of values instead of a single result. The code iterates through the generated values as they become available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_10\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"gradio/count_generator\");\nconst job = app.submit(0, [9]);\n\nfor await (const message of job) {\n\tconsole.log(message.data);\n}\n```\n\n----------------------------------------\n\nTITLE: Implementing Shared Queue for Multiple Event Listeners in Gradio (Python)\nDESCRIPTION: This example shows how to create a shared queue for multiple event listeners in a Gradio app. It sets up three buttons for different image generation models, all sharing a queue with a concurrency limit of 2, identified by 'gpu_queue'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/01_queuing.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    prompt = gr.Textbox()\n    image = gr.Image()\n    generate_btn_1 = gr.Button(\"Generate Image via model 1\")\n    generate_btn_2 = gr.Button(\"Generate Image via model 2\")\n    generate_btn_3 = gr.Button(\"Generate Image via model 3\")\n    generate_btn_1.click(image_gen_1, prompt, image, concurrency_limit=2, concurrency_id=\"gpu_queue\")\n    generate_btn_2.click(image_gen_2, prompt, image, concurrency_id=\"gpu_queue\")\n    generate_btn_3.click(image_gen_3, prompt, image, concurrency_id=\"gpu_queue\")\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Client for Music Separation\nDESCRIPTION: Code that initializes the Gradio client to connect to a Hugging Face Space that performs music separation, and defines a function to extract vocals from audio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/music-separation\")\n\ndef acapellify(audio_path):\n    result = client.predict(audio_path, api_name=\"/predict\")\n    return result[0]\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Model3D Interface in Python\nDESCRIPTION: This Python script defines a simple Gradio interface using `gr.Interface`. It uses a basic function `load_mesh`, which simply returns the input filename, to handle input from a `gr.Model3D` component. The output is displayed in another `gr.Model3D` component configured with a transparent background (`clear_color`) and `wireframe` display mode. Several example file paths (local and remote URLs for .obj, .glb, .gltf, .stl, .splat, .ply files) are provided. The interface is launched using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3D/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef load_mesh(mesh_file_name):\n    return mesh_file_name\n\ndemo = gr.Interface(\n    fn=load_mesh,\n    inputs=gr.Model3D(),\n    outputs=gr.Model3D(\n            clear_color=(0.0, 0.0, 0.0, 0.0),  label=\"3D Model\", display_mode=\"wireframe\"),\n    examples=[\n        [os.path.join(os.path.abspath(''), \"files/Bunny.obj\")],\n        [os.path.join(os.path.abspath(''), \"files/Duck.glb\")],\n        [os.path.join(os.path.abspath(''), \"files/Fox.gltf\")],\n        [os.path.join(os.path.abspath(''), \"files/face.obj\")],\n        [os.path.join(os.path.abspath(''), \"files/sofia.stl\")],\n        [\"https://huggingface.co/datasets/dylanebert/3dgs/resolve/main/bonsai/bonsai-7k-mini.splat\"],\n        [\"https://huggingface.co/datasets/dylanebert/3dgs/resolve/main/luigi/luigi.ply\"],\n    ],\n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Gradio Interface for GAN Prediction in Python\nDESCRIPTION: Sets up a simple Gradio interface using `gr.Interface`. It connects the `predict` function (the initial version taking only a seed) to a user interface consisting of a slider input (`gr.Slider`) for the seed value (0-1000, default 42) and an image output component (`outputs=\"image\"`). Calling `.launch()` starts the Gradio web server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Using the `gradio cc docs` CLI Command (Bash)\nDESCRIPTION: Demonstrates how to invoke the `gradio cc docs` command from the terminal. It lists optional arguments like `path`, `--demo-dir`, `--demo-name`, `--space-url`, `--generate-space`, `--no-generate-space`, `--readme-path`, `--generate-readme`, `--no-generate-readme`, and `--suppress-demo-check` which allow customization of the documentation generation process for a Gradio custom component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc docs\n  path # The directory of the custom component.\n  --demo-dir # Path to the demo directory.\n  --demo-name # Name of the demo file\n  --space-url # URL of the Hugging Face Space to link to\n  --generate-space # create a documentation space.\n  --no-generate-space # do not create a documentation space\n  --readme-path # Path to the README.md file.\n  --generate-readme # create a REAMDE.md file\n  --no-generate-readme # do not create a README.md file\n  --suppress-demo-check # suppress validation checks and warnings\n```\n\n----------------------------------------\n\nTITLE: Styling Gradio DataFrame with Pandas Styler - Python\nDESCRIPTION: This complete example demonstrates how to use a Pandas Styler object to highlight the maximum value in each row of a DataFrame and display the result using Gradio's DataFrame component. Dependencies include gradio and pandas, both installed via pip. The main parameters include the DataFrame, styling options passed to Styler (here, coloring max values), and the Blocks API for building the interface. Input: a Pandas DataFrame; Output: a styled, visually enhanced data table in a Gradio web app. The code must be run in an environment with GUI/browser access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd \nimport gradio as gr\n\n# Creating a sample dataframe\ndf = pd.DataFrame({\n    \"A\" : [14, 4, 5, 4, 1], \n    \"B\" : [5, 2, 54, 3, 2], \n    \"C\" : [20, 20, 7, 3, 8], \n    \"D\" : [14, 3, 6, 2, 6], \n    \"E\" : [23, 45, 64, 32, 23]\n}) \n\n# Applying style to highlight the maximum value in each row\nstyler = df.style.highlight_max(color = 'lightgreen', axis = 0)\n\n# Displaying the styled dataframe in Gradio\nwith gr.Blocks() as demo:\n    gr.DataFrame(styler)\n    \ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Blocks Interface with Flip Functions\nDESCRIPTION: Creates a Gradio interface with text and image flipping capabilities using Blocks API. Includes two tabs for text and image manipulation, an accordion section with a slider, and event handlers for flip operations. The interface provides separate buttons for flipping text and images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flipper/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\ndef flip_text(x):\n    return x[::-1]\n\ndef flip_image(x):\n    return np.fliplr(x)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\", open=False):\n        gr.Markdown(\"Look at me...\")\n        temp_slider = gr.Slider(\n            0, 1,\n            value=0.1,\n            step=0.1,\n            interactive=True,\n            label=\"Slide me\",\n        )\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Multi-Tab Gradio Interface with Text Demos\nDESCRIPTION: Builds a Gradio interface with three tabs containing different text-based demos. It includes a text identity function, a text input form, and a static text output. The code also implements tab switching functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_plug/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef change_tab():\n    return gr.Tabs(selected=2)\n\nidentity_demo, input_demo, output_demo = gr.Blocks(), gr.Blocks(), gr.Blocks()\n\nwith identity_demo:\n    gr.Interface(lambda x: x, \"text\", \"text\")\n\nwith input_demo:\n    t = gr.Textbox(label=\"Enter your text here\")\n    with gr.Row():\n        btn = gr.Button(\"Submit\")\n        clr = gr.ClearButton(t)\n\nwith output_demo:\n    gr.Textbox(\"This is a static output\")\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Three demos in one!\")\n    with gr.Tabs(selected=1) as tabs:\n        with gr.TabItem(\"Text Identity\", id=0) as tab0:\n            tab0.select(lambda: gr.Tabs(selected=0), None, tabs)\n            identity_demo.render()\n        with gr.TabItem(\"Text Input\", id=1) as tab1:\n            tab1.select(lambda: gr.Tabs(selected=1), None, tabs)\n            input_demo.render()\n        with gr.TabItem(\"Text Static\", id=2) as tab2:\n            tab2.select(lambda: gr.Tabs(selected=2), None, tabs)\n            output_demo.render()\n    btn = gr.Button(\"Change tab\")\n    btn.click(inputs=None, outputs=tabs, fn=change_tab)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Session State in Gradio Interface (Python)\nDESCRIPTION: This code snippet shows how to use session state in a Gradio interface to maintain user-specific data across multiple submissions. It creates a chat-like interface that stores and displays previous user inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/03_interface-state.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef chat(message, history):\n    history = history or []\n    history.append(message)\n    return history, history\n\ndemo = gr.Interface(\n    fn=chat,\n    inputs=[\"text\", \"state\"],\n    outputs=[\"text\", \"state\"],\n    allow_flagging=\"never\",\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Line Plot with Gradio\nDESCRIPTION: Creates an interactive line plot using Gradio's LinePlot component. The plot displays stock price data over time, with different stocks represented by different colors. Includes customization of dimensions, tooltips, and legend placement.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/lineplot_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom vega_datasets import data\n\nwith gr.Blocks() as demo:\n    gr.LinePlot(\n        data.stocks(),\n        x=\"date\",\n        y=\"price\",\n        color=\"symbol\",\n        color_legend_position=\"bottom\",\n        title=\"Stock Prices\",\n        tooltip=[\"date\", \"price\", \"symbol\"],\n        height=300,\n        width=300,\n        container=False,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Deploying a Gradio ChatInterface App as a Discord Bot using Gradio Client in Python\nDESCRIPTION: This Python code snippet demonstrates how to deploy a Gradio application, specifically one using `gr.ChatInterface` (like the example Llama 2 app `ysharma/Explore_llamav2_with_TGI`), as a Discord bot. It uses the `gradio_client` library (version 0.3.0+) to connect to the Gradio app via `grc.Client` and then calls the `deploy_discord` method, specifying a desired bot ID. The `gradio_client` library is a prerequisite.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport gradio_client as grc\ngrc.Client(\"ysharma/Explore_llamav2_with_TGI\").deploy_discord(to_id=\"llama2-70b-discord-bot\")\n```\n```\n\n----------------------------------------\n\nTITLE: Implementing Color Picker Interface with Gradio\nDESCRIPTION: Creates a Gradio interface that allows users to upload an icon and select a color to modify the icon. The implementation includes a color changing function that preserves transparency and applies the selected color to non-transparent pixels.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_picker/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\nfrom PIL import Image, ImageColor\n\ndef change_color(icon, color):\n\n    \"\"\"\n    Function that given an icon in .png format changes its color\n    Args:\n        icon: Icon whose color needs to be changed.\n        color: Chosen color with which to edit the input icon.\n    Returns:\n        edited_image: Edited icon.\n    \"\"\"\n    img = icon.convert(\"LA\")\n    img = img.convert(\"RGBA\")\n    image_np = np.array(icon)\n    _, _, _, alpha = image_np.T\n    mask = alpha > 0\n    image_np[..., :-1][mask.T] = ImageColor.getcolor(color, \"RGB\")\n    edited_image = Image.fromarray(image_np)\n    return edited_image\n\ninputs = [\n    gr.Image(label=\"icon\", type=\"pil\", image_mode=\"RGBA\"),\n    gr.ColorPicker(label=\"color\"),\n]\noutputs = gr.Image(label=\"colored icon\")\n\ndemo = gr.Interface(\n    fn=change_color,\n    inputs=inputs,\n    outputs=outputs\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with LaTeX Markdown\nDESCRIPTION: Creates a Gradio Blocks interface that displays markdown text containing LaTeX mathematical expressions. The demo includes various examples of mathematical formulas including fractions, square roots, integrals, and regular text with dollar signs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/latex/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n    r\"\"\"\n    # Hello World! $\\frac{\\sqrt{x + y}}{4}$ is today's lesson\n\n    ## the $\\sqrt{x + y}$ is first\n\n    Start with $\\frac{\\frac{x+1}{x+2}}{x+3}$ then we get $ 2+x $ and $3$.\n    \n    There are three formulas to know:\n    \n    the first is $\\gamma^2 + \\theta^2 = \\omega^2$\n    \n    $\\sqrt{x^2+1}$ is next\n    \n    Integral $\\int_{a}^{b} x^2 \\,dx$ is last\n\n    Start typing below to see the output.\n\n    I spent $5 at the grocery store. Then I bought a $2.50 ice cream cone.\n    \"\"\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks with Audio Component\nDESCRIPTION: Creates a simple Gradio application using the Blocks API and adds an Audio component to it. The demo is then launched to display the interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Audio()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing PDF Example View Component in Svelte\nDESCRIPTION: Creates an example view component for displaying PDF previews in the Gradio interface. This component renders the first page of a PDF at a smaller scale suitable for example displays.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_15\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n\timport pdfjsLib from \"pdfjs-dist\";\n\tpdfjsLib.GlobalWorkerOptions.workerSrc =  \"https://cdn.bootcss.com/pdf.js/3.11.174/pdf.worker.js\";\n\t\n\tlet pdfDoc;\n\tlet canvasRef;\n\n\tasync function get_doc(url: string) {\n\t\tconst loadingTask = pdfjsLib.getDocument(url);\n\t\tpdfDoc = await loadingTask.promise;\n\t\trenderPage();\n\t\t}\n\n\tfunction renderPage() {\n\t\t// Render a specific page of the PDF onto the canvas\n\t\t\tpdfDoc.getPage(1).then(page => {\n\t\t\t\tconst ctx  = canvasRef.getContext('2d')\n\t\t\t\tctx.clearRect(0, 0, canvasRef.width, canvasRef.height);\n\t\t\t\t\n\t\t\t\tconst viewport = page.getViewport({ scale: 0.2 });\n\t\t\t\t\n\t\t\t\tconst renderContext = {\n\t\t\t\t\tcanvasContext: ctx,\n\t\t\t\t\tviewport\n\t\t\t\t};\n\t\t\t\tcanvasRef.width = viewport.width;\n\t\t\t\tcanvasRef.height = viewport.height;\n\t\t\t\tpage.render(renderContext);\n\t\t\t});\n\t\t}\n\t\n\t$: get_doc(value);\n</script>\n\n<div\n\tclass:table={type === \"table\"}\n\tclass:gallery={type === \"gallery\"}\n\tclass:selected\n\tstyle=\"justify-content: center; align-items: center; display: flex; flex-direction: column;\"\n>\n\t<canvas bind:this={canvasRef}></canvas>\n</div>\n\n<style>\n\t.gallery {\n\t\tpadding: var(--size-1) var(--size-2);\n\t}\n</style>\n```\n\n----------------------------------------\n\nTITLE: PDF Upload Component Implementation\nDESCRIPTION: Example of creating a PDF upload interface using existing Gradio components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_5\n\nLANGUAGE: svelte\nCODE:\n```\n<script>\n\timport { type FileData, Upload, ModifyUpload } from \"@gradio/upload\";\n\timport { Empty, UploadText, BlockLabel } from \"@gradio/atoms\";\n</script>\n\n<BlockLabel Icon={File} label={label || \"PDF\"} />\n{#if value === null && interactive}\n    <Upload\n        filetype=\"application/pdf\"\n        on:load={handle_load}\n        {root}\n        >\n        <UploadText type=\"file\" i18n={gradio.i18n} />\n    </Upload>\n{:else if value !== null}\n    {#if interactive}\n        <ModifyUpload i18n={gradio.i18n} on:clear={handle_clear}/>\n    {/if}\n    <iframe title={value.orig_name || \"PDF\"} src={value.data} height=\"{height}px\" width=\"100%\"></iframe>\n{:else}\n    <Empty size=\"large\"> <File/> </Empty>\t\n{/if}\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Scatter Plot Demo\nDESCRIPTION: Creates a Gradio Blocks interface with a scatter plot visualization that displays the relationship between weight and height, colored by age. The demo is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_quantitative/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.ScatterPlot(df, x=\"weight\", y=\"height\", color=\"age\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Identity Function with Gradio Interface\nDESCRIPTION: Creates a Gradio interface that accepts a video input and returns it as a playable video. The video_identity function simply returns the input video unchanged, demonstrating basic video handling in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_identity_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef video_identity(video):\n    return video\n\ndemo = gr.Interface(video_identity,\n                    gr.Video(),\n                    \"playable_video\",\n                    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits in Gradio using Python\nDESCRIPTION: Demonstrates how to set a maximum file upload size limit when launching a Gradio interface using the `max_file_size` parameter in `demo.launch()`. It shows two ways to specify the limit: using a string representation (e.g., \"5mb\") or using the `gr.FileSize` enum (e.g., `5 * gr.FileSize.MB`). This feature requires the Gradio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/fallback/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Launching a Live Stateful Interface with Gradio - Python\nDESCRIPTION: This Python snippet builds and launches a Gradio interface with two inputs ('textbox' and 'state') and two outputs, running in live mode. It defines a lambda function that sums x and y (or returns x if y is None), demonstrating stateful input/output coupling. It requires Gradio as a dependency and should be executed as a standalone Python script (with the __main__ guard). Inputs are text and state; outputs are updated text and state values. The interface launches a web app when run.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/live_with_vars/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(\n    lambda x, y: (x + y if y is not None else x, x + y if y is not None else x),\n    [\"textbox\", \"state\"],\n    [\"textbox\", \"state\"], live=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio UI Components for Magic 8 Ball\nDESCRIPTION: Sets up the Gradio interface with audio input/output components and text display. Configures streaming audio output with autoplay and microphone input capture.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/01_streaming-ai-generated-audio.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as block:\n    gr.HTML(\n        f\"\"\"\n        <h1 style='text-align: center;'> Magic 8 Ball 🎱 </h1>\n        <h3 style='text-align: center;'> Ask a question and receive wisdom </h3>\n        <p style='text-align: center;'> Powered by <a href=\\\"https://github.com/huggingface/parler-tts\\\"> Parler-TTS</a>\n        \"\"\"\n    )\n    with gr.Group():\n        with gr.Row():\n            audio_out = gr.Audio(label=\"Spoken Answer\", streaming=True, autoplay=True)\n            answer = gr.Textbox(label=\"Answer\")\n            state = gr.State()\n        with gr.Row():\n            audio_in = gr.Audio(label=\"Speak your question\", sources=\"microphone\", type=\"filepath\")\n\n    audio_in.stop_recording(generate_response, audio_in, [state, answer, audio_out])\\\n        .then(fn=read_response, inputs=state, outputs=[answer, audio_out])\n\nblock.launch()\n```\n\n----------------------------------------\n\nTITLE: Enabling DOM Copy Action in Svelte - JavaScript\nDESCRIPTION: Defines a function that enables copy actions on HTMLDivElements for Svelte components. Intended to facilitate user interaction by allowing the contents of a node to be programmatically copied, using Svelte's action signature. The function expects a DOM node and returns an ActionReturn for Svelte's use, with external dependencies determined by the consuming app's configuration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/utils/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport function copy(node: HTMLDivElement): ActionReturn\n```\n\n----------------------------------------\n\nTITLE: Loading and Launching a Vision Transformer with Gradio in Python\nDESCRIPTION: This snippet demonstrates how to load a pre-trained vision transformer (ViT) model from the Hugging Face Hub and instantly deploy it as a web demo via Gradio using Python. It relies on the gradio package (install separately), and auto-infers input/output based on the model tag, so no custom data processing is required. The examples parameter specifies sample images for demonstration; inputs are user-uploaded images and outputs are predicted classes, with all processing handled by Gradio and Hugging Face APIs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-with-vision-transformers.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.Interface.load(\n             \"huggingface/google/vit-base-patch16-224\",\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Gradio NER Pipeline Interface (Python)\nDESCRIPTION: This script imports the `pipeline` function from `transformers` and the `gradio` library. It initializes a default Named Entity Recognition (NER) pipeline. A function `ner(text)` is defined to take text input, process it through the `ner_pipeline`, and return a dictionary containing the original text and the identified entities. Finally, it creates a Gradio Interface (`gr.Interface`) mapping the `ner` function to a text input box (`gr.Textbox`) and a highlighted text output (`gr.HighlightedText`), providing example usage. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/ner_pipeline/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import pipeline\n\nimport gradio as gr\n\nner_pipeline = pipeline(\"ner\")\n\nexamples = [\n    \"Does Chicago have any stores and does Joe live here?\",\n]\n\ndef ner(text):\n    output = ner_pipeline(text)\n    return {\"text\": text, \"entities\": output}\n\ndemo = gr.Interface(ner,\n             gr.Textbox(placeholder=\"Enter sentence here...\"),\n             gr.HighlightedText(),\n             examples=examples)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Loading and Launching a Gradio Space in Python\nDESCRIPTION: This Python script imports the Gradio library as 'gr'. It then utilizes the `gr.load()` function to fetch and instantiate a Gradio application identified by 'gradio/test-gr-load' from Hugging Face Spaces (specified by `src=\"spaces\"`). The loaded application interface is stored in the 'demo' variable. The conditional `if __name__ == \"__main__\":` ensures that the `demo.launch()` method, which starts the local web server for the Gradio interface, is only called when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/load_space/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.load(\"gradio/test-gr-load\", src=\"spaces\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Chatbot with Gradio\nDESCRIPTION: This code creates a Gradio interface for a chatbot with streaming responses. It defines user input handling, bot response generation with character-by-character streaming, and a clear button functionality. The bot's responses are randomly selected from a predefined list.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_streaming/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n    chatbot = gr.Chatbot(type=\"messages\")\n    msg = gr.Textbox()\n    clear = gr.Button(\"Clear\")\n\n    def user(user_message, history: list):\n        return \"\", history + [{\"role\": \"user\", \"content\": user_message}]\n\n    def bot(history: list):\n        bot_message = random.choice([\"How are you?\", \"I love you\", \"I'm very hungry\"])\n        history.append({\"role\": \"assistant\", \"content\": \"\"})\n        for character in bot_message:\n            history[-1]['content'] += character\n            time.sleep(0.05)\n            yield history\n\n    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n        bot, chatbot, chatbot\n    )\n    clear.click(lambda: None, None, chatbot, queue=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Training StyleGAN with W&B Experiment Tracking\nDESCRIPTION: Code for fine-tuning StyleGAN with Weights & Biases experiment tracking. This snippet sets up the training process, logs metrics and images to W&B dashboard at specified intervals.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nalpha =  1.0\nalpha = 1-alpha\n\npreserve_color = True\nnum_iter = 100\nlog_interval = 50\n\nsamples = []\n   column_names = [\"Reference (y)\", \"Style Code(w)\", \"Real Face Image(x)\"]\n\nwandb.init(project=\"JoJoGAN\")\nconfig = wandb.config\nconfig.num_iter = num_iter\nconfig.preserve_color = preserve_color\nwandb.log(\n{\"Style reference\": [wandb.Image(transforms.ToPILImage()(target_im))]},\nstep=0)\n\n# 加载判别器用于感知损失\ndiscriminator = Discriminator(1024, 2).eval().to(device)\nckpt = torch.load('models/stylegan2-ffhq-config-f.pt', map_location=lambda storage, loc: storage)\ndiscriminator.load_state_dict(ckpt[\"d\"], strict=False)\n\n# 重置生成器\ndel generator\ngenerator = deepcopy(original_generator)\n\ng_optim = optim.Adam(generator.parameters(), lr=2e-3, betas=(0, 0.99))\n\n# 用于生成一族合理真实图像-> 假图像的更换图层\nif preserve_color:\n    id_swap = [9,11,15,16,17]\nelse:\n    id_swap = list(range(7, generator.n_latent))\n\nfor idx in tqdm(range(num_iter)):\n    mean_w = generator.get_latent(torch.randn([latents.size(0), latent_dim]).to(device)).unsqueeze(1).repeat(1, generator.n_latent, 1)\n    in_latent = latents.clone()\n    in_latent[:, id_swap] = alpha*latents[:, id_swap] + (1-alpha)*mean_w[:, id_swap]\n\n    img = generator(in_latent, input_is_latent=True)\n\n    with torch.no_grad():\n        real_feat = discriminator(targets)\n    fake_feat = discriminator(img)\n\n    loss = sum([F.l1_loss(a, b) for a, b in zip(fake_feat, real_feat)])/len(fake_feat)\n\n    wandb.log({\"loss\": loss}, step=idx)\n    if idx % log_interval == 0:\n        generator.eval()\n        my_sample = generator(my_w, input_is_latent=True)\n        generator.train()\n        my_sample = transforms.ToPILImage()(utils.make_grid(my_sample, normalize=True, range=(-1, 1)))\n        wandb.log(\n        {\"Current stylization\": [wandb.Image(my_sample)]},\n        step=idx)\n    table_data = [\n            wandb.Image(transforms.ToPILImage()(target_im)),\n            wandb.Image(img),\n            wandb.Image(my_sample),\n        ]\n    samples.append(table_data)\n\n    g_optim.zero_grad()\n    loss.backward()\n    g_optim.step()\n\nout_table = wandb.Table(data=samples, columns=column_names)\nwandb.log({\" 当前样本数 \": out_table})\n```\n\n----------------------------------------\n\nTITLE: Asynchronous Prediction - Python\nDESCRIPTION: Example of running predictions asynchronously using submit() and callbacks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\ndef print_result(x):\n    print(\"The translated result is: {x}\")\n\nclient = Client(space=\"abidlabs/en2fr\")\n\njob = client.submit(\"Hello\", api_name=\"/predict\", result_callbacks=[print_result])\n\n# Do something else\n\n>> The translated result is: Bonjour\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface for a Rust Image Filter using Subprocess in Python\nDESCRIPTION: This Python script creates a Gradio interface for the compiled Rust sepia filter program. The `apply_sepia` function takes an input image file path, uses `subprocess.Popen` to run the Rust executable (`./target/release/sepia`) with the input path and a fixed output path (`output.png`), waits for the process to finish using `process.wait()`, and then returns the path to the generated output image. The `gr.Interface` uses `gr.Image` components for both input and output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport subprocess\n\ndef apply_sepia(input_path):\n    output_path = \"output.png\"\n    \n    process = subprocess.Popen(\n        ['./target/release/sepia', input_path, output_path], \n        stdout=subprocess.PIPE, \n        stderr=subprocess.PIPE\n    )\n    process.wait()\n    \n    return output_path\n\ndemo = gr.Interface(\n    fn=apply_sepia, \n    inputs=gr.Image(type=\"filepath\", label=\"Input Image\"), \n    outputs=gr.Image(label=\"Sepia Image\")\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Using Named Arguments in Python Client\nDESCRIPTION: Example showing how to use the same keyword arguments as the original Gradio app in the Python client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"http://127.0.0.1:7860/\")\nresult = client.predict(\n\t\tmessage=\"Hello!!\",\n\t\tsystem_prompt=\"You are helpful AI.\",\n\t\ttokens=10,\n\t\tapi_name=\"/chat\"\n)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: JavaScript Gradio Client Connection\nDESCRIPTION: Example showing how to initialize a connection to a Gradio app using the JavaScript client. The client provides methods for submitting jobs, making predictions, viewing API info and duplicating spaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconst app = await Client.connect(\"gradio/whisper\")\n```\n\n----------------------------------------\n\nTITLE: Creating HTML Component in Gradio Blocks\nDESCRIPTION: Creates a Gradio interface that displays formatted HTML content including styled text, emphasis, bold text, and a hyperlink\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/html_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.HTML(value=\"<p style='margin-top: 1rem, margin-bottom: 1rem'>This <em>example</em> was <strong>written</strong> in <a href='https://en.wikipedia.org/wiki/HTML' _target='blank'>HTML</a> </p>\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Sepia Image Filter in Rust\nDESCRIPTION: A Rust program (`sepia.rs`) that applies a sepia filter to an image using the `image` crate. It defines a `sepia_filter` function that reads an image, iterates through its pixels, applies the sepia transformation formula to the RGB values, and saves the modified image. The `main` function handles command-line arguments, expecting an input file path and an output file path.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_3\n\nLANGUAGE: rust\nCODE:\n```\n// sepia.rs\nextern crate image;\n\nuse image::{GenericImageView, ImageBuffer, Rgba};\n\nfn sepia_filter(input: &str, output: &str) {\n    let img = image::open(input).unwrap();\n    let (width, height) = img.dimensions();\n    let mut img_buf = ImageBuffer::new(width, height);\n\n    for (x, y, pixel) in img.pixels() {\n        let (r, g, b, a) = (pixel[0] as f32, pixel[1] as f32, pixel[2] as f32, pixel[3]);\n        let tr = (0.393 * r + 0.769 * g + 0.189 * b).min(255.0);\n        let tg = (0.349 * r + 0.686 * g + 0.168 * b).min(255.0);\n        let tb = (0.272 * r + 0.534 * g + 0.131 * b).min(255.0);\n        img_buf.put_pixel(x, y, Rgba([tr as u8, tg as u8, tb as u8, a]));\n    }\n\n    img_buf.save(output).unwrap();\n}\n\nfn main() {\n    let args: Vec<String> = std::env::args().collect();\n    if args.len() != 3 {\n        eprintln!(\"Usage: sepia <input_file> <output_file>\");\n        return;\n    }\n    sepia_filter(&args[1], &args[2]);\n}\n```\n\n----------------------------------------\n\nTITLE: Queue-based Worker Implementation with FastAPI\nDESCRIPTION: FastAPI implementation using queues and worker threads for token streaming. Provides both WebSocket and SSE endpoints, designed to compare performance with Gradio's implementation approach.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# Reference to workers.py:\n# - FastAPI with queues and worker threads\n# - WS and SSE endpoints\n# - Streams 500 tokens\n# - Rate: 100 tokens/sec\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Greeting Function\nDESCRIPTION: This snippet defines a greeting function and creates a Gradio Interface for it. The interface accepts a name as input and returns a greeting message. It demonstrates how to set up a basic Gradio demo with text input and output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Cancelling Queued Gradio Jobs with Python Client\nDESCRIPTION: Demonstrates submitting two jobs to a Gradio application ('abidlabs/whisper') using the `gradio_client.Client`. It then attempts to cancel both jobs using the `.cancel()` method. The method returns `False` if the job has already started processing and `True` if the job was successfully cancelled while still in the queue.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nclient = Client(\"abidlabs/whisper\")\njob1 = client.submit(handle_file(\"audio_sample1.wav\"))\njob2 = client.submit(handle_file(\"audio_sample2.wav\"))\njob1.cancel()  # will return False, assuming the job has started\njob2.cancel()  # will return True, indicating that the job has been canceled\n```\n\n----------------------------------------\n\nTITLE: Building a Skip, Clear, and Random UI with Gradio Blocks (Python)\nDESCRIPTION: This Python snippet creates a Gradio Blocks application with a UI consisting of buttons to clear, skip, or randomize two numeric inputs. Dependencies include the 'gradio' library and Python's 'random' module, and the app launches via 'demo.launch()'. Button click events are bound to actions: 'Clear' sets both numbers to None, 'Skip' uses Gradio's skip token to ignore update for each number, and 'Random' assigns each input a random integer from 0 to 100. Inputs are not validated, and the demo assumes Gradio v3+ with skip support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/skip/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        clear_button = gr.Button(\"Clear\")\n        skip_button = gr.Button(\"Skip\")\n        random_button = gr.Button(\"Random\")\n    numbers = [gr.Number(), gr.Number()]\n\n    clear_button.click(lambda : (None, None), outputs=numbers)\n    skip_button.click(lambda : [gr.skip(), gr.skip()], outputs=numbers)\n    random_button.click(lambda : (random.randint(0, 100), random.randint(0, 100)), outputs=numbers)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Streaming with Gradio\nDESCRIPTION: Demonstrates how to create a Gradio interface that streams audio output in chunks using generators. The code loads an MP3 file, splits it into 3-second chunks, and streams them sequentially. Requires pydub for audio processing and gradio with streaming support enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom pydub import AudioSegment\n\ndef stream_audio(audio_file):\n    audio = AudioSegment.from_mp3(audio_file)\n    i = 0\n    chunk_size = 3000\n\n    while chunk_size*i < len(audio):\n        chunk = audio[chunk_size*i:chunk_size*(i+1)]\n        i += 1\n        if chunk:\n            file = f\"/tmp/{i}.mp3\"\n            chunk.export(file, format=\"mp3\")\n            yield file\n\ndemo = gr.Interface(\n    fn=stream_audio,\n    inputs=gr.Audio(type=\"filepath\", label=\"Audio file to stream\"),\n    outputs=gr.Audio(autoplay=True, streaming=True),\n)\n\ndemo.queue().launch()\n```\n\n----------------------------------------\n\nTITLE: Enabling Progressive Web App (PWA) in Gradio\nDESCRIPTION: Example showing how to enable Progressive Web App (PWA) functionality for a Gradio application by setting the pwa parameter to True in the launch() method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n\ndemo.launch(pwa=True)  # Launch your app as a PWA\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Editor with Webcam\nDESCRIPTION: Creates a Gradio interface with an image editor component that includes webcam support and a live preview. The interface uses a 1024x1024 fixed canvas size and updates the preview automatically when changes are made to the image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_webcam/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef predict(im):\n    return im[\"composite\"]\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        im = gr.ImageEditor(\n            canvas_size=(1024, 1024),\n            fixed_canvas=True,\n            webcam_options=gr.WebcamOptions(\n                constraints={\"video\": {\"width\": 1024, \"height\": 1024}}\n            ),\n        )\n        im_preview = gr.Image()\n    im.change(predict, outputs=im_preview, inputs=im, show_progress=\"hidden\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Rotation Interface\nDESCRIPTION: Creates a Gradio interface that provides image rotation functionality. The interface includes example images, flagging options, and a button to update the example dataset. The main function rotates input images by 45 degrees.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef image_mod(image):\n    return image.rotate(45)\n\nnew_samples = [\n    [os.path.join(os.path.abspath(''), \"images/logo.png\")],\n    [os.path.join(os.path.abspath(''), \"images/tower.jpg\")],\n]\n\nwith gr.Blocks() as demo:\n    interface = gr.Interface(\n        image_mod,\n        gr.Image(type=\"pil\"),\n        \"image\",\n        flagging_options=[\"blurry\", \"incorrect\", \"other\"],\n        examples=[\n            os.path.join(os.path.abspath(''), \"images/cheetah1.jpg\"),\n            os.path.join(os.path.abspath(''), \"images/lion.jpg\"),\n        ],\n    )\n\n    btn = gr.Button(\"Update Examples\")\n    btn.click(lambda : gr.Dataset(samples=new_samples), None, interface.examples_handler.dataset)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing ZIP to JSON Conversion with Gradio Interface in Python\nDESCRIPTION: This code defines a function to convert ZIP file contents to JSON format and creates a Gradio interface for it. It uses the zipfile module to extract information from the ZIP file and returns a list of dictionaries containing file details.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/zip_to_json/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom zipfile import ZipFile\n\nimport gradio as gr\n\ndef zip_to_json(file_obj):\n    files = []\n    with ZipFile(file_obj.name) as zfile:\n        for zinfo in zfile.infolist():\n            files.append(\n                {\n                    \"name\": zinfo.filename,\n                    \"file_size\": zinfo.file_size,\n                    \"compressed_size\": zinfo.compress_size,\n                }\n            )\n    return files\n\ndemo = gr.Interface(zip_to_json, \"file\", \"json\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with pip for Gradio WebRTC and YOLOv10 (Bash)\nDESCRIPTION: This snippet specifies the required dependencies for real-time object detection, including OpenCV for image handling, Gradio/WebRTC for interactive streaming, and ONNX Runtime for model inference. Add these to a `requirements.txt` file and install via `pip` to ensure all Python packages are available before running the app. GPU acceleration is recommended with `onnxruntime-gpu`, otherwise substitute with `onnxruntime` for CPU-only environments.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/02_object-detection-from-webcam-with-webrtc.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nopencv-python\\ntwilio\\ngradio>=5.0\\ngradio-webrtc\\nonnxruntime-gpu\\n\n```\n\n----------------------------------------\n\nTITLE: Controlling Resource Reload with gr.NO_RELOAD in Gradio Python App\nDESCRIPTION: This snippet uses the `gr.NO_RELOAD` sentinel to avoid re-executing expensive or stateful resource initialization during Gradio reload cycles. For instance, it ensures a Hugging Face Transformers pipeline is loaded only once, circumventing potential issues with C/Rust-compiled libs. Interfaces or Block instances are constructed outside the guarded block, using pre-initialized models safely. Requires the `transformers` and `gradio` packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nif gr.NO_RELOAD:\n\tfrom transformers import pipeline\n\tpipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n\ndemo = gr.Interface(lambda s: pipe(s), gr.Textbox(), gr.Label())\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Extracting Client Information Using Gradio Request Object\nDESCRIPTION: Creates a Gradio interface that demonstrates how to access client information like IP address, user agent, and request headers from the gr.Request object passed to the prediction function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/request_ip_headers/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef predict(text, request: gr.Request):\n    headers = request.headers\n    host = request.client.host\n    user_agent = request.headers[\"user-agent\"]\n    return {\n        \"ip\": host,\n        \"user_agent\": user_agent,\n        \"headers\": headers,\n    }\n\ngr.Interface(predict, \"text\", \"json\").launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Scatter Plot Component in Gradio\nDESCRIPTION: Creates a Gradio Block with a ScatterPlot component that visualizes car data. The scatter plot shows the relationship between horsepower and miles per gallon, with points colored by the car's origin and hover tooltips showing the car name.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatterplot_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom vega_datasets import data\n\ncars = data.cars()\n\nwith gr.Blocks() as demo:\n    gr.ScatterPlot(\n        value=cars,\n        x=\"Horsepower\",\n        y=\"Miles_per_Gallon\",\n        color=\"Origin\",\n        tooltip=[\"Name\"],\n        title=\"Car Data\",\n        y_title=\"Miles per Gallon\",\n        color_legend_title=\"Origin of Car\",\n        container=False,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating the Gradio Chatbot Interface with Citation and File Upload Support - Python\nDESCRIPTION: Builds a complete Gradio interface with a chatbot, message box, citation toggle, document type selector, content textbox, and PDF file upload. Uses event-driven logic to submit user input and trigger the Claude response handler. Requires Gradio for UI, assumes previous snippet functions' existence, and organizes components to allow users to upload documents or enter reference text, enabling real-time citation-enhanced chat.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\\n    gr.Markdown(\\\"# Chat with Citations\\\")\\n    \\n    with gr.Row(scale=1):\\n        with gr.Column(scale=4):\\n            chatbot = gr.Chatbot(type=\\\"messages\\\", bubble_full_width=False, show_label=False, scale=1)\\n            msg = gr.Textbox(placeholder=\\\"Enter your message here...\\\", show_label=False, container=False)\\n            \\n        with gr.Column(scale=1):\\n            enable_citations = gr.Checkbox(label=\\\"Enable Citations\\\", value=True, info=\\\"Toggle citation functionality\\\" )\\n            doc_type_radio = gr.Radio( choices=[\\\"plain_text\\\", \\\"pdf\\\"], value=\\\"plain_text\\\", label=\\\"Document Type\\\", info=\\\"Choose the type of document to use\\\")\\n            text_input = gr.Textbox(label=\\\"Document Content\\\", lines=10, info=\\\"Enter the text you want to reference\\\")\\n            pdf_input = gr.File(label=\\\"Upload PDF\\\", file_types=[\\\".pdf\\\"], file_count=\\\"single\\\", visible=False)\\n    \\n    # Handle message submission\\n    msg.submit(\\n        user_message,\\n        [msg, chatbot, enable_citations, doc_type_radio, text_input, pdf_input],\\n        [msg, chatbot]\\n    ).then(\\n        bot_response,\\n        [chatbot, enable_citations, doc_type_radio, text_input, pdf_input],\\n        chatbot\\n    )\\n\\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Adding Mermaid.js Support in Markdown\nDESCRIPTION: Feature addition to support mermaid.js in the Markdown component and other components that use Markdown, such as gr.Chatbot. This allows for the creation of diagrams and flowcharts within Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10854](https://github.com/gradio-app/gradio/pull/10854) [`1649b00`](https://github.com/gradio-app/gradio/commit/1649b0038482402d7f0ccdbf86ba65d82b4a12c9) - Add support for `mermaid.js` in `Markdown` component (as well as components like `gr.Chatbot` that use Markdown).\n```\n\n----------------------------------------\n\nTITLE: Oracle Database Connection Setup\nDESCRIPTION: Example of creating a connection engine for Oracle database using SQLAlchemy.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/04_connecting-to-a-database.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nengine = create_engine('oracle://username:password@host:port/database_name')\n```\n\n----------------------------------------\n\nTITLE: Applying Theme to Gradio Interface\nDESCRIPTION: Demonstrates how to apply a pre-built Monochrome theme to a Gradio Interface instance using the theme parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/12_themes.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndemo = gr.Interface(..., theme=gr.themes.Monochrome())\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio-Lite JS and CSS\nDESCRIPTION: Basic HTML setup for importing the required JavaScript and CSS files for Gradio-Lite from CDN.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/05_gradio-lite.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Implementing an Output-Only Gradio Demo for Image Generation in Python\nDESCRIPTION: This code snippet shows how to create an output-only Gradio demo for a mock image generation model. It sets the `inputs` parameter to `None` in the `gradio.Interface` class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/05_four-kinds-of-interfaces.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef fake_gan():\n    return np.random.randint(0, 256, size=(512, 512, 3))\n\ndemo = gr.Interface(\n    fn=fake_gan,\n    inputs=None,\n    outputs=\"image\",\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio App with Model3D Events\nDESCRIPTION: Imports the Gradio library and defines a web interface using `gr.Blocks`. It includes input and output `gr.Model3D` components, along with `gr.Number` components to count `upload`, `change`, and `clear` events, and a `gr.Textbox` to show the clear value. Event listeners are attached: `upload` copies the input model to the output and increments the upload counter, `change` increments the change counter, and `clear` updates the clear counter and a textbox. Finally, the Gradio demo is launched using `demo.launch()` if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3d_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_3d = gr.Model3D(label=\"Input Model3D\")\n        with gr.Column():\n            output_3d = gr.Model3D(label=\"Output Model3D\")\n        with gr.Column():\n            num_change = gr.Number(label=\"# Change Events\", value=0)\n            num_load = gr.Number(label=\"# Upload Events\", value=0)\n            num_clear = gr.Number(label=\"# Clear Events\", value=0)\n            clear_value = gr.Textbox(label=\"Clear Value\", value=\"\")\n        input_3d.upload(lambda s, n: (s, n + 1), [input_3d, num_load], [output_3d, num_load])\n        input_3d.change(lambda n: n + 1, num_change, num_change)\n        input_3d.clear(lambda s, n: (s, n + 1), [input_3d, num_clear], [clear_value, num_clear])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Plot Demo using pip\nDESCRIPTION: This command utilizes the `pip` package installer to install the necessary Python libraries: `gradio` for building the web interface, `vega_datasets` for sample data, and `pandas` for data manipulation. The `-q` flag ensures a quiet installation process, minimizing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/native_plots/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio vega_datasets pandas\n```\n\n----------------------------------------\n\nTITLE: Generating Random Matplotlib Plot of Outbreak Data in Python\nDESCRIPTION: This function creates a Matplotlib plot showing simulated outbreak data for different countries over time. It generates exponential growth curves for each country and plots them on a single figure.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef random_matplotlib_plot():\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n\n    countries = [\"USA\", \"Canada\", \"Mexico\", \"UK\"]\n    months = [\"January\", \"February\", \"March\", \"April\", \"May\"]\n    m = months.index(\"January\")\n    r = 3.2\n    start_day = 30 * m\n    final_day = 30 * (m + 1)\n    x = np.arange(start_day, final_day + 1)\n    pop_count = {\"USA\": 350, \"Canada\": 40, \"Mexico\": 300, \"UK\": 120}\n    df = pd.DataFrame({\"day\": x})\n    for country in countries:\n        df[country] = x ** (r) * (pop_count[country] + 1)\n\n    fig = plt.figure()\n    plt.plot(df[\"day\"], df[countries].to_numpy())\n    plt.title(\"Outbreak in \" + \"January\")\n    plt.ylabel(\"Cases\")\n    plt.xlabel(\"Days since Day 0\")\n    plt.legend(countries)\n    return fig\n```\n\n----------------------------------------\n\nTITLE: Adding User Message to Chat History in Python\nDESCRIPTION: This function adds a user message to the chat history. It handles both text messages and file uploads, appending them to the history list with appropriate formatting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef add_message(history, message):\n    for x in message[\"files\"]:\n        history.append({\"role\": \"user\", \"content\": {\"path\": x}})\n    if message[\"text\"] is not None:\n        history.append({\"role\": \"user\", \"content\": message[\"text\"]})\n    return history, gr.MultimodalTextbox(value=None, interactive=False)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with DataFrames and Labels\nDESCRIPTION: Creates a Gradio interface that displays flight statistics (total count and cheapest price) and a data table. The interface uses Blocks to organize components in a layout with rows.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_tables_stats/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        gr.Label(len(df), label=\"Flight Count\")\n        gr.Label(f\"${df['price'].min()}\", label=\"Cheapest Flight\")\n    gr.DataFrame(df)\n\n    \nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Record Filter Interface\nDESCRIPTION: Creates a Gradio interface that takes a dataframe and gender selection as input, and returns filtered records. The interface includes a dataframe input with name, age, and gender columns, and a dropdown for gender selection with options 'M', 'F', and 'O'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/filter_records/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef filter_records(records, gender):\n    return records[records[\"gender\"] == gender]\n\ndemo = gr.Interface(\n    filter_records,\n    [\n        gr.Dataframe(\n            headers=[\"name\", \"age\", \"gender\"],\n            datatype=[\"str\", \"number\", \"str\"],\n            row_count=5,\n            col_count=(3, \"fixed\"),\n        ),\n        gr.Dropdown([\"M\", \"F\", \"O\"]),\n    ],\n    \"dataframe\",\n    description=\"Enter gender as 'M', 'F', or 'O' for other.\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Cancelling a Gradio Submission\nDESCRIPTION: Example showing how to cancel an ongoing submission to stop an API from issuing additional updates.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_13\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", { name: \"Chewbacca\" })\n\n\n// later\n\nsubmission.cancel();\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files for YOLOv10 Webcam Stream\nDESCRIPTION: This snippet downloads the necessary Python files (inference.py and utils.py) from the Gradio GitHub repository for the YOLOv10 webcam stream demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/yolov10_webcam_stream/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/yolov10_webcam_stream/inference.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/yolov10_webcam_stream/utils.py\n```\n\n----------------------------------------\n\nTITLE: Validating File Extensions in Python for Gradio\nDESCRIPTION: This function checks if a given file extension is allowed based on a list of permitted extensions. It handles both lowercase and uppercase extensions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir1/foo.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef is_valid_url(possible_url: str) -> bool:\n    try:\n        result = urlparse(possible_url)\n        return all([result.scheme, result.netloc])\n    except ValueError:\n        return False\n\n\ndef is_valid_file_extension(filename: str, allowed_extensions: List[str]) -> bool:\n    \"\"\"Check if a filename has an extension in a list of allowed extensions.\"\"\"\n    if not isinstance(filename, str):\n        return False\n    file_extension = os.path.splitext(filename)[1].lower()\n    return file_extension.lower() in map(lambda x: x.lower(), allowed_extensions)\n```\n\n----------------------------------------\n\nTITLE: Enhancing Gradio Interface with Number of Punks Control in Python\nDESCRIPTION: Updates the Gradio interface to allow users to control the number of generated CryptoPunks. A second `gr.Slider` is added to the `inputs` list, allowing the user to select the number of punks between 4 and 64 (default 10). This requires modifying the `predict` function to accept this new parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ngr.Interface(\n    predict,\n    inputs=[\n        gr.Slider(0, 1000, label='Seed', default=42),\n        gr.Slider(4, 64, label='Number of Punks', step=1, default=10), # Adding another slider!\n    ],\n    outputs=\"image\",\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Gradio-Lite App in HTML\nDESCRIPTION: This example demonstrates how to create a simple 'Hello World' Gradio app using @gradio/lite. It includes the necessary HTML structure and the Python code for the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/lite/README.md#2025-04-23_snippet_1\n\nLANGUAGE: HTML\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n\t<body>\n\t\t<gradio-lite>\n\t\timport gradio as gr\n\n\t\tdef greet(name):\n\t\t\treturn \"Hello, \" + name + \"!\"\n\t\t\n\t\tgr.Interface(greet, \"textbox\", \"textbox\").launch()\n\t\t</gradio-lite>\n\t</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Input Components and Event Handling\nDESCRIPTION: Sets up a Gradio interface with multiple columns of input components, including text, number, slider, checkbox, radio, dropdown, color picker, code, dataframe, image, audio, and video inputs. It demonstrates how to handle input, upload, and change events for each component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/change_vs_input/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    set_button = gr.Button(\"Set Values\")\n    with gr.Row():\n        with gr.Column(min_width=200):\n            gr.Markdown(\"# Enter Here\")\n            text = gr.Textbox()\n            num = gr.Number()\n            slider = gr.Slider()\n            checkbox = gr.Checkbox()\n            checkbox_group = gr.CheckboxGroup([\"a\", \"b\", \"c\"])\n            radio = gr.Radio([\"a\", \"b\", \"c\"])\n            dropdown = gr.Dropdown([\"a\", \"b\", \"c\"])\n            colorpicker = gr.ColorPicker()\n            code = gr.Code()\n            dataframe = gr.Dataframe()\n            image = gr.Image(elem_id=\"image-original\")\n            audio = gr.Audio(elem_id=\"audio-original\")\n            video = gr.Video(elem_id=\"video-original\")\n\n        with gr.Column(min_width=200):\n            gr.Markdown(\"# ON:INPUT/UPLOAD\")\n            text_in = gr.Textbox()\n            num_in = gr.Number()\n            slider_in = gr.Slider()\n            checkbox_in = gr.Checkbox()\n            checkbox_group_in = gr.CheckboxGroup([\"a\", \"b\", \"c\"])\n            radio_in = gr.Radio([\"a\", \"b\", \"c\"])\n            dropdown_in = gr.Dropdown([\"a\", \"b\", \"c\"])\n            colorpicker_in = gr.ColorPicker()\n            code_in = gr.Code()\n            dataframe_in = gr.Dataframe()\n            image_up = gr.Image(elem_id=\"image-upload\")\n            audio_up = gr.Audio(elem_id=\"audio-upload\")\n            video_up = gr.Video(elem_id=\"video-upload\")\n\n        with gr.Column(min_width=200):\n            gr.Markdown(\"# ON:CHANGE\")\n            text_ch = gr.Textbox()\n            num_ch = gr.Number()\n            slider_ch = gr.Slider()\n            checkbox_ch = gr.Checkbox()\n            checkbox_group_ch = gr.CheckboxGroup([\"a\", \"b\", \"c\"])\n            radio_ch = gr.Radio([\"a\", \"b\", \"c\"])\n            dropdown_ch = gr.Dropdown([\"a\", \"b\", \"c\"])\n            colorpicker_ch = gr.ColorPicker()\n            code_ch = gr.Code()\n            dataframe_ch = gr.Dataframe()\n            image_ch = gr.Image(elem_id=\"image-change\")\n            audio_ch = gr.Audio(elem_id=\"audio-change\")\n            video_ch = gr.Video(elem_id=\"video-change\")\n\n        with gr.Column(min_width=200):\n            gr.Markdown(\"# ON:CHANGE x2\")\n            text_ch2 = gr.Textbox()\n            num_ch2 = gr.Number()\n            slider_ch2 = gr.Slider()\n            checkbox_ch2 = gr.Checkbox()\n            checkbox_group_ch2 = gr.CheckboxGroup([\"a\", \"b\", \"c\"])\n            radio_ch2 = gr.Radio([\"a\", \"b\", \"c\"])\n            dropdown_ch2 = gr.Dropdown([\"a\", \"b\", \"c\"])\n            colorpicker_ch2 = gr.ColorPicker()\n            code_ch2 = gr.Code()\n            dataframe_ch2 = gr.Dataframe()\n            image_ch2 = gr.Image(elem_id=\"image-change-2\")\n            audio_ch2 = gr.Audio(elem_id=\"audio-change-2\")\n            video_ch2 = gr.Video(elem_id=\"video-change-2\")\n\n    counter = gr.Number(label=\"Change counter\")\n\n    lion = os.path.join(os.path.abspath(''), \"files/lion.jpg\")\n    cantina = os.path.join(os.path.abspath(''), \"files/cantina.wav\")\n    world = os.path.join(os.path.abspath(''), \"files/world.mp4\")\n\n    set_button.click(\n        lambda: [\"asdf\", 555, 12, True, [\"a\", \"c\"], \"b\", \"b\", \"#FF0000\", \"import gradio as gr\", [[\"a\", \"b\", \"c\", \"d\"], [\"1\", \"2\", \"3\", \"4\"]], lion, cantina, world],\n        None,\n        [text, num, slider, checkbox, checkbox_group, radio, dropdown, colorpicker, code, dataframe, image, audio, video])\n\n    text.input(lambda x:x, text, text_in)\n    num.input(lambda x:x, num, num_in)\n    slider.input(lambda x:x, slider, slider_in)\n    checkbox.input(lambda x:x, checkbox, checkbox_in)\n    checkbox_group.input(lambda x:x, checkbox_group, checkbox_group_in)\n    radio.input(lambda x:x, radio, radio_in)\n    dropdown.input(lambda x:x, dropdown, dropdown_in)\n    colorpicker.input(lambda x:x, colorpicker, colorpicker_in)\n    code.input(lambda x:x, code, code_in)\n    dataframe.input(lambda x:x, dataframe, dataframe_in)\n    image.upload(lambda x:x, image, image_up)\n    audio.upload(lambda x:x, audio, audio_up)\n    video.upload(lambda x:x, video, video_up)\n\n    text.change(lambda x,y:(x,y+1), [text, counter], [text_ch, counter])\n    num.change(lambda x,y:(x, y+1), [num, counter], [num_ch, counter])\n    slider.change(lambda x,y:(x, y+1), [slider, counter], [slider_ch, counter])\n    checkbox.change(lambda x,y:(x, y+1), [checkbox, counter], [checkbox_ch, counter])\n    checkbox_group.change(lambda x,y:(x, y+1), [checkbox_group, counter], [checkbox_group_ch, counter])\n    radio.change(lambda x,y:(x, y+1), [radio, counter], [radio_ch, counter])\n    dropdown.change(lambda x,y:(x, y+1), [dropdown, counter], [dropdown_ch, counter])\n    colorpicker.change(lambda x,y:(x, y+1), [colorpicker, counter], [colorpicker_ch, counter])\n    code.change(lambda x,y:(x, y+1), [code, counter], [code_ch, counter])\n    dataframe.change(lambda x,y:(x, y+1), [dataframe, counter], [dataframe_ch, counter])\n    image.change(lambda x,y:(x, y+1), [image, counter], [image_ch, counter])\n    audio.change(lambda x,y:(x, y+1), [audio, counter], [audio_ch, counter])\n    video.change(lambda x,y:(x, y+1), [video, counter], [video_ch, counter])\n\n    text_ch.change(lambda x:x, text_ch, text_ch2)\n    num_ch.change(lambda x:x, num_ch, num_ch2)\n    slider_ch.change(lambda x:x, slider_ch, slider_ch2)\n    checkbox_ch.change(lambda x:x, checkbox_ch, checkbox_ch2)\n    checkbox_group_ch.change(lambda x:x, checkbox_group_ch, checkbox_group_ch2)\n    radio_ch.change(lambda x:x, radio_ch, radio_ch2)\n    dropdown_ch.change(lambda x:x, dropdown_ch, dropdown_ch2)\n    colorpicker_ch.change(lambda x:x, colorpicker_ch, colorpicker_ch2)\n    code_ch.change(lambda x:x, code_ch, code_ch2)\n    dataframe_ch.change(lambda x:x, dataframe_ch, dataframe_ch2)\n    image_ch.change(lambda x:x, image_ch, image_ch2)\n    audio_ch.change(lambda x:x, audio_ch, audio_ch2)\n    video_ch.change(lambda x:x, video_ch, video_ch2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining MarkdownCode Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the MarkdownCode component. It includes options for chatbot mode, message content, HTML sanitization, LaTeX delimiters, Markdown rendering, and line breaks. This component is specifically designed for rendering code within Markdown.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let chatbot = true;\nexport let message: string;\nexport let sanitize_html = true;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[] = [];\nexport let render_markdown = true;\nexport let line_breaks = true;\n```\n\n----------------------------------------\n\nTITLE: Launching Gradio Number Component Demo - Python\nDESCRIPTION: This snippet imports Gradio and creates a simple interactive web demo using the Blocks API, showcasing the Number component. The 'demo' object initializes a Block context and adds a single Number input, then launches the web interface. Dependencies include the Gradio library being installed. Users interact by entering a number; no additional parameters are required and there are no return values or advanced logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/number_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Number()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Scatter Plot with Nominal X-Axis in Python\nDESCRIPTION: Shows how to create a `gr.ScatterPlot` where the x-axis column in the pandas DataFrame contains nominal data (strings, categories, or datetimes). The y-axis column must be numeric. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_scatter_nominal\n```\n\n----------------------------------------\n\nTITLE: Dynamic Event Listeners with Gradio Render Decorator\nDESCRIPTION: This example showcases how to create dynamic event listeners using the @gr.render decorator. It allows users to add multiple textboxes and merge their contents into a single output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/04_dynamic-apps-with-render-decorator.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    text_count = gr.State(value=1)\n    with gr.Row():\n        add_btn = gr.Button(\"Add Textbox\")\n        merge_btn = gr.Button(\"Merge\")\n    output = gr.Textbox(label=\"Output\")\n    text_row = gr.Row()\n    \n    def increment(count):\n        return count + 1\n    \n    add_btn.click(increment, text_count, text_count)\n    \n    @gr.render()\n    def create_textboxes(count):\n        text_boxes = [gr.Textbox(label=f\"Text {i}\", key=f\"text_{i}\") for i in range(count)]\n        \n        def merge(*texts):\n            return \" \".join(texts)\n        \n        merge_btn.click(merge, text_boxes, output)\n        \n        return text_boxes\n    \n    text_count.change(create_textboxes, text_count, text_row)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing and Launching a Gradio Interface for Longest Word Calculation in Python\nDESCRIPTION: This Python script defines a function `longest_word` that takes a string, splits it into words, calculates the length of each word, and returns the maximum length. It then uses `gradio.Interface` to create a web UI for this function, taking text input and displaying the result as a label. An example input is provided. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/longest_word/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef longest_word(text):\n    words = text.split(\" \")\n    lengths = [len(word) for word in words]\n    return max(lengths)\n\nex = \"The quick brown fox jumped over the lazy dog.\"\n\ndemo = gr.Interface(\n    longest_word, \"textbox\", \"label\", examples=[[ex]]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Application with Download Button\nDESCRIPTION: This code creates a Gradio application using Blocks. It includes a DownloadButton component that allows users to download a file when clicked. The button is configured with a label and a URL pointing to an image file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/downloadbutton_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DownloadButton(\"📂 Click to download file\", value=\"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Dropdown with KeyUp Handler\nDESCRIPTION: Creates a Gradio interface with a dropdown component that handles key up events. The dropdown allows custom values and returns component value, input value, and pressed key information through a JSON display component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dropdown_key_up/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef test(value, key_up_data: gr.KeyUpData):\n    return {\n        \"component value\": value,\n        \"input value\": key_up_data.input_value,\n        \"key\": key_up_data.key\n    }\n\nwith gr.Blocks() as demo:\n    d = gr.Dropdown([\"abc\", \"def\"], allow_custom_value=True)\n    t = gr.JSON()\n    d.key_up(test, d, t)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Video Interface\nDESCRIPTION: Sets up a Gradio interface that accepts video input and returns video output. The interface includes three example videos and implements caching for the examples. The function simply returns the input video unchanged.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\na = os.path.join(os.path.abspath(''), \"files/world.mp4\")  # Video\nb = os.path.join(os.path.abspath(''), \"files/a.mp4\")  # Video\nc = os.path.join(os.path.abspath(''), \"files/b.mp4\")  # Video\n\ndemo = gr.Interface(\n    fn=lambda x: x,\n    inputs=gr.Video(),\n    outputs=gr.Video(),\n    examples=[\n        [a],\n        [b],\n        [c],\n    ],\n    cache_examples=True\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Interface for Sorting DataFrames in Python\nDESCRIPTION: This Python script defines a function `sort_records` that takes a Polars DataFrame as input and returns a new DataFrame sorted by the 'Quantity' column. It then configures and creates a Gradio Interface (`gr.Interface`) using this function. The input component is a `gr.Dataframe` specifically configured for Polars data types, with defined headers, row count, and fixed column count. The output is also a DataFrame. The script concludes by launching the Gradio application locally when run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sort_records/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef sort_records(records):\n    return records.sort(\"Quantity\")\n\ndemo = gr.Interface(\n    sort_records,\n    gr.Dataframe(\n        headers=[\"Item\", \"Quantity\"],\n        datatype=[\"str\", \"number\"],\n        row_count=3,\n        col_count=(2, \"fixed\"),\n        type=\"polars\"\n    ),\n    \"dataframe\",\n    description=\"Sort by Quantity\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Shareable Gradio Demo with share parameter\nDESCRIPTION: Simple example showing how to create a basic Gradio interface with a greeting function and enable public sharing using the share parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n\ndemo.launch(share=True)  # Share your demo with just 1 extra parameter 🚀\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple Inputs in Gradio Event Listeners (List vs Dict) in Python\nDESCRIPTION: Compares two ways to handle multiple inputs in Gradio event listeners using Python. The `add_btn` listener passes inputs as a list, mapping to function arguments by position (`add(num1, num2)`). The `sub_btn` listener passes inputs as a set, resulting in a single dictionary argument (`sub(data)`) keyed by component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n$code_calculator_list_and_dict\n```\n\n----------------------------------------\n\nTITLE: Implementing Audio Events Demo Interface\nDESCRIPTION: Creates a Gradio interface with audio components and event counters. The implementation includes input and output audio components, along with numerical indicators for tracking various events like play, pause, stop, and recording. Each event increments its respective counter when triggered.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_audio = gr.Audio(type=\"filepath\", label=\"Input Audio\", sources=[\"upload\", \"microphone\"])\n        with gr.Column():\n            output_audio = gr.Audio(label=\"Output Audio\", sources=[\"upload\", \"microphone\"])\n\n    with gr.Row():\n        with gr.Column():\n            input_num_change = gr.Number(label=\"# Input Change Events\", value=0)\n            input_num_input = gr.Number(label=\"# Input Input Events\", value=0)\n            input_num_load = gr.Number(label=\"# Input Upload Events\", value=0)\n            input_num_play = gr.Number(label=\"# Input Play Events\", value=0)\n            input_num_pause = gr.Number(label=\"# Input Pause Events\", value=0)\n\n        with gr.Column():\n            input_record = gr.Number(label=\"# Input Start Recording Events\", value=0)\n            input_pause = gr.Number(label=\"# Input Pause Recording Events\", value=0)\n            input_stop = gr.Number(label=\"# Input Stop Recording Events\", value=0)\n\n        with gr.Column():\n            output_num_play = gr.Number(label=\"# Output Play Events\", value=0)\n            output_num_pause = gr.Number(label=\"# Output Pause Events\", value=0)\n            output_num_stop = gr.Number(label=\"# Output Stop Events\", value=0)\n\n            input_audio.upload(lambda s, n: (s, n + 1), [input_audio, input_num_load], [output_audio, input_num_load])\n            input_audio.change(lambda n: n + 1, input_num_change, input_num_change)\n            input_audio.play(lambda n: n + 1, input_num_play, input_num_play)\n            input_audio.pause(lambda n: n + 1, input_num_pause, input_num_pause)\n            input_audio.change(lambda n: n + 1, input_num_change, input_num_change)\n            input_audio.input(lambda n: n + 1, input_num_input, input_num_input)\n\n            input_audio.start_recording(lambda n: n + 1, input_record, input_record)\n            input_audio.pause_recording(lambda n: n + 1, input_pause, input_pause)\n            input_audio.stop_recording(lambda n: n + 1, input_stop, input_stop)\n\n            output_audio.play(lambda n: n + 1, output_num_play, output_num_play)\n            output_audio.pause(lambda n: n + 1, output_num_pause, output_num_pause)\n            output_audio.stop(lambda n: n + 1, output_num_stop, output_num_stop)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio and Plotly Demo - Python\nDESCRIPTION: Installs the Python packages 'gradio', 'plotly', and 'datasets' with pip. This is a prerequisite step before running the main application to ensure all dependencies are available. The '-q' flag is used for quiet installation with minimal output. This step must be executed in an environment where pip is available, such as a Jupyter notebook or a shell with Python installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/map_airbnb/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio plotly datasets \n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Text-to-Speech Interface in Python\nDESCRIPTION: This Python script sets up and launches a Gradio web interface for text-to-speech conversion using the `neon-tts-plugin-coqui` library. It initializes the CoquiTTS engine, defines a function `tts` to handle the conversion process by saving the output to a temporary WAV file, configures input (Textbox, Radio buttons for language) and output (Audio player) components, and launches the interactive demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/neon-tts-plugin-coqui/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport tempfile\nimport gradio as gr\nfrom neon_tts_plugin_coqui import CoquiTTS\n\nLANGUAGES = list(CoquiTTS.langs.keys())\ncoquiTTS = CoquiTTS()\n\ndef tts(text: str, language: str):\n    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as fp:\n        coquiTTS.get_tts(text, fp, speaker = {\"language\" : language})\n        return fp.name\n\ninputs = [gr.Textbox(label=\"Input\", value=CoquiTTS.langs[\"en\"][\"sentence\"], max_lines=3),\n            gr.Radio(label=\"Language\", choices=LANGUAGES, value=\"en\")]\noutputs = gr.Audio(label=\"Output\")\n\ndemo = gr.Interface(fn=tts, inputs=inputs, outputs=outputs)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio JSON Component Interface\nDESCRIPTION: Creates a Gradio interface with JSON input and output components, demonstrating various JSON data types including nested objects, arrays, numbers, booleans, null values, and NumPy arrays. The interface includes a submit button that passes the input JSON directly to the output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/json_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\nwith gr.Blocks() as demo:\n    inp = gr.JSON(\n        label=\"InputJSON\",\n        value={\n            \"Key 1\": \"Value 1\",\n            \"Key 2\": {\"Key 3\": \"Value 2\", \"Key 4\": \"Value 3\"},\n            \"Key 5\": [\"Item 1\", \"Item 2\", \"Item 3\"],\n            \"Key 6\": 123,\n            \"Key 7\": 123.456,\n            \"Key 8\": True,\n            \"Key 9\": False,\n            \"Key 10\": None,\n            \"Key 11\": np.array([1, 2, 3]),\n        }\n    )\n    out = gr.JSON(label=\"OutputJSON\")\n    btn = gr.Button(\"Submit\")\n    btn.click(lambda x: x, inp, out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Scatter Mapbox Figure with Plotly in Python\nDESCRIPTION: This snippet demonstrates creating an interactive map using Plotly's `graph_objects`. It generates a `go.Figure` containing a `go.Scattermapbox` plot. The plot uses latitude and longitude from the filtered DataFrame (`new_df`) to place markers. Custom data (`text_list` containing names and prices) is attached to markers for display on hover, configured using `hovertemplate`. The `update_layout` method sets the map style to 'open-street-map', configures the initial view (center coordinates, zoom level), and hover behavior.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/plot-component-for-maps.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport plotly.graph_objects as go\n\nfig = go.Figure(go.Scattermapbox(\n            customdata=text_list,\n            lat=new_df['latitude'].tolist(),\n            lon=new_df['longitude'].tolist(),\n            mode='markers',\n            marker=go.scattermapbox.Marker(\n                size=6\n            ),\n            hoverinfo=\"text\",\n            hovertemplate='<b>Name</b>: %{customdata[0]}<br><b>Price</b>: $%{customdata[1]}'\n        ))\n\nfig.update_layout(\n    mapbox_style=\"open-street-map\",\n    hovermode='closest',\n    mapbox=dict(\n        bearing=0,\n        center=go.layout.mapbox.Center(\n            lat=40.67,\n            lon=-73.90\n        ),\n        pitch=0,\n        zoom=9\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files for Chatbot Initialization in Python\nDESCRIPTION: This snippet leverages Python's os module and uses wget via shell command to download a sample text file (paul_graham.txt) from the Gradio demo repository. The downloaded file can be used for initial document ingestion by the chatbot. Ensure network access is available before running, and that wget is installed in the environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_llamaindex/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/llm_llamaindex/paul_graham.txt\n```\n\n----------------------------------------\n\nTITLE: Alternating Response Chatbot\nDESCRIPTION: Chatbot that alternates between agreeing and disagreeing based on conversation history\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef alternatingly_agree(message, history):\n    if len([h for h in history if h['role'] == \"assistant\"]) % 2 == 0:\n        return f\"Yes, I do think that: {message}\"\n    else:\n        return \"I don't think so\"\n\ngr.ChatInterface(\n    fn=alternatingly_agree, \n    type=\"messages\"\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Converting Pipeline to Gradio Demo Directly\nDESCRIPTION: Demonstrates the simplified approach of converting a transformers pipeline directly to a Gradio interface using from_pipeline method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/01_using-hugging-face-integrations.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom transformers import pipeline\nimport gradio as gr\n\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n\ndemo = gr.Interface.from_pipeline(pipe)\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Using HuggingFaceDatasetSaver Callback for Crowdsourced Data Collection in Python\nDESCRIPTION: This code demonstrates how to use the HuggingFaceDatasetSaver callback to send flagged data to a Hugging Face dataset. It requires a Hugging Face token and creates a crowdsourced dataset from the calculator examples that users flag.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/using-flagging.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nHF_TOKEN = os.getenv('HF_TOKEN')\nhf_writer = gr.HuggingFaceDatasetSaver(HF_TOKEN, \"crowdsourced-calculator-demo\")\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    description=\"Check out the crowd-sourced dataset at: [https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo)\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"],\n    flagging_callback=hf_writer\n)\n\niface.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing and Launching a Sepia Filter Gradio App in Python\nDESCRIPTION: This Python script defines a `sepia` function using NumPy to apply a sepia filter to an input image represented as a NumPy array. It then creates a Gradio interface (`gr.Interface`) that uses this function, accepting an image input and displaying the sepia-toned image as output. Finally, it launches the Gradio web application when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sepia_filter/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189],\n        [0.349, 0.686, 0.168],\n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ndemo = gr.Interface(sepia, gr.Image(), \"image\")\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Configuring the BaseFileUpload Component in Gradio Svelte (JavaScript)\nDESCRIPTION: Defines props for the BaseFileUpload Svelte component, controlling label display, accepted file types, selection logic, multiple or single file upload, and localization. Dependencies include FileData types and I18nFormatter for translation. Accepts file data or arrays, with configurable file type and quantity restrictions; outputs controlled internal state for upload operations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: null | FileData | FileData[];\\n\\texport let label: string;\\n\\texport let show_label = true;\\n\\texport let file_count = \"single\";\\n\\texport let file_types: string[] | null = null;\\n\\texport let selectable = false;\\n\\texport let root: string;\\n\\texport let height: number | undefined = undefined;\\n\\texport let i18n: I18nFormatter;\\n\n```\n\n----------------------------------------\n\nTITLE: Getting API Information with Gradio Client\nDESCRIPTION: Example demonstrating how to retrieve detailed information about the API endpoints of a connected Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_14\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst api_info = await app.view_api();\n\nconsole.log(api_info);\n```\n\n----------------------------------------\n\nTITLE: Gradio 4.x HTTP Request Implementation\nDESCRIPTION: Implements a request function for Gradio 4.x using HTTP POST and streaming responses. Measures duration and message count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef request():\n\tstart_time = time.time()\n\tsession_hash = uuid.uuid4().hex\n\tpayload = {\"data\": [\"test\"], \"fn_index\": 0, \"session_hash\": session_hash}\n\turl = f\"http://{URL}/\"\n\tresp = requests.post(f\"{url}queue/join\", json=payload, timeout=5)\n\tassert resp.status_code == 200\n\n\tmessage_count = 0\n\toutput = \"\"\n\twith requests.get(f\"{url}queue/data?session_hash={session_hash}\", stream=True) as response:\n\t\tresponse.raise_for_status()\n\t\tfor line in response.iter_lines():\n\t\t\tif line:\n\t\t\t\tdecoded_line = line.decode('utf-8')\n\t\t\t\tif decoded_line.startswith(\"data:\"):\n\t\t\t\t\tdata = decoded_line.replace(\"data: \", \"\")\n\t\t\t\t\tif \"close_stream\" in data:\n\t\t\t\t\t\tbreak\n\t\t\t\t\toutput = data\n\t\t\t\t\tmessage_count += 1\n\t\n\tend_time = time.time()\n\tduration = end_time - start_time\n\treturn (duration, message_count, json.loads(output)[\"output\"][\"data\"])\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Custom Theme in Python\nDESCRIPTION: This code creates a Gradio interface with a custom theme, multiple input components (textbox, slider, buttons), and an output textbox. It defines a function to repeat text based on user input and links it to the interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_3/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\nwith gr.Blocks(\n    theme=gr.themes.Default(\n        font=[gr.themes.GoogleFont(\"Inconsolata\"), \"Arial\", \"sans-serif\"]\n    )\n) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Line Plot from Random Data\nDESCRIPTION: Creates a Gradio web interface that displays a line plot visualization. The code generates a random dataset with height, weight, age, and ethnicity fields using NumPy and Pandas, then renders this data as a line plot showing the relationship between weight and height.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_line/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport numpy as np\nimport random\n\ndf = pd.DataFrame({\n    'height': np.random.randint(50, 70, 25),\n    'weight': np.random.randint(120, 320, 25),\n    'age': np.random.randint(18, 65, 25),\n    'ethnicity': [random.choice([\"white\", \"black\", \"asian\"]) for _ in range(25)]\n})\n\nwith gr.Blocks() as demo:\n    gr.LinePlot(df, x=\"weight\", y=\"height\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Projectile Motion Calculator and Visualization with Gradio\nDESCRIPTION: Creates a Gradio interface that visualizes projectile motion. The code defines a trajectory calculation function based on physics equations, then builds a UI with sliders for initial velocity and angle, and displays the resulting trajectory in a line plot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_kinematics/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport numpy as np\n\nimport gradio as gr\n\ndef plot(v, a):\n    g = 9.81\n    theta = a / 180 * 3.14\n    tmax = ((2 * v) * np.sin(theta)) / g\n    timemat = tmax * np.linspace(0, 1, 40)\n\n    x = (v * timemat) * np.cos(theta)\n    y = ((v * timemat) * np.sin(theta)) - ((0.5 * g) * (timemat**2))\n    df = pd.DataFrame({\"x\": x, \"y\": y})\n    return df\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        r\"Let's do some kinematics! Choose the speed and angle to see the trajectory. Remember that the range $R = v_0^2 \\cdot \\frac{\\sin(2\\theta)}{g}$\"\n    )\n\n    with gr.Row():\n        speed = gr.Slider(1, 30, 25, label=\"Speed\")\n        angle = gr.Slider(0, 90, 45, label=\"Angle\")\n    output = gr.LinePlot(\n        x=\"x\",\n        y=\"y\",\n        overlay_point=True,\n        tooltip=[\"x\", \"y\"],\n        x_lim=[0, 100],\n        y_lim=[0, 60],\n        width=350,\n        height=300,\n    )\n    btn = gr.Button(value=\"Run\")\n    btn.click(plot, [speed, angle], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits Using Gradio Interface - Python\nDESCRIPTION: This snippet demonstrates how to set a maximum file size for uploads to a Gradio server by passing the max_file_size parameter (as a string or an integer in bytes) to the launch() method of a Gradio Interface. Dependencies include Gradio, and the snippet shows an image-accepting interface where uploaded files exceeding 5 megabytes are rejected. Inputs are image files from the user, and outputs are images passed through an identity function. Requires gradio and, for explicit byte calculations, gr.FileSize constants; the snippet is limited to per-file size, not total request size.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/html/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Initializing and Launching a Gradio State Component Demo - Python\nDESCRIPTION: Creates and launches a minimal Gradio application using Python's gradio (gr) library. After importing gradio, it initializes a Blocks container and adds a State component, then starts the web demo with demo.launch(). Requires gradio to be installed, and intended for prototyping apps that need persistent state; no inputs or outputs are defined in this basic usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.State()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Initializing Basic Gradio Chatbot with HuggingFace Integration\nDESCRIPTION: Sets up a basic chatbot UI using Gradio and HuggingFace InferenceClient. Implements the core chat functionality with streaming responses using the Zephyr-7b model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import InferenceClient\nimport gradio as gr\n\nclient = InferenceClient()\n\ndef respond(\n    prompt: str,\n    history,\n):\n    if not history:\n        history = [{\"role\": \"system\", \"content\": \"You are a friendly chatbot\"}]\n    history.append({\"role\": \"user\", \"content\": prompt})\n\n    yield history\n\n    response = {\"role\": \"assistant\", \"content\": \"\"}\n    for message in client.chat_completion(\n        history,\n        temperature=0.95,\n        top_p=0.9,\n        max_tokens=512,\n        stream=True,\n        model=\"HuggingFaceH4/zephyr-7b-beta\"\n    ):\n        response[\"content\"] += message.choices[0].delta.content or \"\"\n\n        yield history + [response]\n\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Chat with Hugging Face Zephyr 7b 🤗\")\n    chatbot = gr.Chatbot(\n        label=\"Agent\",\n        type=\"messages\",\n        avatar_images=(\n            None,\n            \"https://em-content.zobj.net/source/twitter/376/hugging-face_1f917.png\",\n        ),\n    )\n    prompt = gr.Textbox(max_lines=1, label=\"Chat Message\")\n    prompt.submit(respond, [prompt, chatbot], [chatbot])\n    prompt.submit(lambda: \"\", None, [prompt])\n\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks Interface for Square Numbers\nDESCRIPTION: This code creates a Gradio Blocks interface for generating and displaying square numbers. It includes a button to generate the next square, a number display, and a JSON table for tracking history. The interface uses custom CSS for styling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_simple_squares/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Blocks(css=\"\"\"#btn {color: red} .abc {font-family: \"Comic Sans MS\", \"Comic Sans\", cursive !important}\"\"\")\n\nwith demo:\n    default_json = {\"a\": \"a\"}\n\n    num = gr.State(value=0)\n    squared = gr.Number(value=0)\n    btn = gr.Button(\"Next Square\", elem_id=\"btn\", elem_classes=[\"abc\", \"def\"])\n\n    stats = gr.State(value=default_json)\n    table = gr.JSON()\n\n    def increase(var, stats_history):\n        var += 1\n        stats_history[str(var)] = var**2\n        return var, var**2, stats_history, stats_history\n\n    btn.click(increase, [num, stats], [num, squared, stats, table])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Like Event Handler in Gradio Chatbot\nDESCRIPTION: Adds like/dislike functionality to chat messages using gr.LikeData to track user feedback.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef handle_like(data: gr.LikeData):\n    if data.liked:\n        print(\"You upvoted this response: \", data.value)\n    else:\n        print(\"You downvoted this response: \", data.value)\n\nchatbot.like(vote, None, None)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with FileExplorer Component\nDESCRIPTION: Sets up a Gradio interface with a FileExplorer component, dropdown for root directory selection, checkboxes for file filtering, and event handlers for various interactions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom pathlib import Path\n\nbase_root = Path(__file__).parent.resolve()\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        dd = gr.Dropdown(label=\"Select File Explorer Root\",\n                        value=str(base_root / \"dir1\"),\n                        choices=[str(base_root / \"dir1\"), str(base_root / \"dir2\"),\n                                 str(base_root / \"dir3\")])\n        with gr.Group():\n            txt_only_glob = gr.Checkbox(label=\"Show only text files\", value=False)\n            ignore_txt_in_glob = gr.Checkbox(label=\"Ignore text files in glob\", value=False)\n\n    fe = gr.FileExplorer(root_dir=str(base_root / \"dir1\"),\n                         glob=\"**/*\", interactive=True)\n    textbox = gr.Textbox(label=\"Selected Directory\")\n    run = gr.Button(\"Run\")\n    total_changes = gr.Number(0, elem_id=\"total-changes\")\n\n    txt_only_glob.select(lambda s: gr.FileExplorer(glob=\"*.txt\" if s else \"*\") ,\n                         inputs=[txt_only_glob], outputs=[fe])\n    ignore_txt_in_glob.select(lambda s: gr.FileExplorer(ignore_glob=\"*.txt\" if s else None),\n                            inputs=[ignore_txt_in_glob], outputs=[fe])\n\n    dd.select(lambda s: gr.FileExplorer(root_dir=s), inputs=[dd], outputs=[fe])\n    run.click(lambda s: \",\".join(s) if isinstance(s, list) else s, inputs=[fe], outputs=[textbox])\n    fe.change(lambda num: num + 1, inputs=total_changes, outputs=total_changes)\n\n    with gr.Row():\n        a = gr.Textbox(elem_id=\"input-box\")\n        a.change(lambda x: x, inputs=[a])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating PDF Component with Gradio CLI\nDESCRIPTION: Command to create a new custom PDF component using Gradio's component creation tool\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc create PDF\n```\n\n----------------------------------------\n\nTITLE: Installing the Gradio Library using Pip in Bash (MacOS/Linux)\nDESCRIPTION: Uses the pip package installer to download and install the latest version of the Gradio library and its dependencies into the currently active Python virtual environment on MacOS/Linux. Requires an active internet connection and the virtual environment to be activated.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npip install gradio\n```\n\n----------------------------------------\n\nTITLE: Gradio Chat Application with Token Streaming\nDESCRIPTION: A simple Gradio chat application that streams 500 tokens at a rate of 100 tokens per second. Compatible with both Gradio 3.x and later versions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/README.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Reference to gradio.py:\n# - Streams 500 tokens\n# - Rate: 100 tokens/sec\n# - Compatible with gradio 3.x+\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio Client Connection and Prediction\nDESCRIPTION: Simple example of connecting to a Gradio space API and making a prediction using the Client class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst result = await app.predict(\"/predict\");\n```\n\n----------------------------------------\n\nTITLE: Extending Gradio Theme Core Colors Using Color Objects - Python\nDESCRIPTION: Demonstrates customizing the primary and secondary hues of a Gradio app by directly providing gradio.themes.colors.Color objects. This approach provides more control and allows for creation of entirely custom color palettes. Requires Gradio to be imported as 'gr', and uses explicit references to color objects. Place your UI components inside the 'with gr.Blocks ...' block. No additional dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Default(primary_hue=gr.themes.colors.red, secondary_hue=gr.themes.colors.pink)) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: WebSocket Connection Request Handler\nDESCRIPTION: Establishes a WebSocket connection, sends a test message, and receives up to 500 messages. Tracks duration and message count with proper connection cleanup.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef request():\n    start_time = time.time()\n    url = f\"ws://{URL}/\"\n    output = None\n    message_count = 0\n    start_time = time.time()\n    try:\n        ws = websocket.create_connection(f\"{url}ws\")\n        ws.send(\"test\")\n\n        while True:\n            message = ws.recv()  # Wait and receive incoming message\n            message_count += 1\n            output = message\n            if message_count == 500:\n                break\n        \n\n    finally:\n        ws.close()  # Ensure the connection is closed properly\n        \n    duration = time.time() - start_time\n    return duration, message_count, output\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Textbox Demo in Python\nDESCRIPTION: This code creates a simple Gradio interface with a textbox component and launches the demo. It uses the Blocks API to create a flexible layout.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/textbox_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Textbox()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Video Components\nDESCRIPTION: Implements video components including a static video viewer, video upload interface, and base player component. Uses imports from @gradio/button and @gradio/upload packages. Supports features like autoplay, webcam mirroring, and audio inclusion.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/video/README.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n<script>\n\timport { BaseInteractiveVideo, BaseStaticVideo, BasePlayer } from \"@gradio/button\";\n\timport type { FileData } from \"@gradio/upload\";\n\timport type { Gradio } from \"@gradio/utils\";\n\texport let _video: FileData;\n</script>\n\n<StaticVideo\n\tvalue={_video}\n\t{label}\n\t{show_label}\n\t{autoplay}\n\t{show_share_button}\n\ti18n={gradio.i18n}\n/>\n\n<Video\n\tvalue={_video}\n\t{label}\n\t{show_label}\n\tsource={\"upload\"}\n\t{mirror_webcam}\n\t{include_audio}\n\t{autoplay}\n\ti18n={gradio.i18n}\n>\n\t<p>Upload Video Here</p>\n</Video>\n\n<BasePlayer\n\tsrc={value.data}\n\t{autoplay}\n\ton:play\n\ton:pause\n\ton:stop\n\ton:end\n\tmirror={false}\n\t{label}\n/>\n```\n\n----------------------------------------\n\nTITLE: Creating Hugging Face Space Programmatically\nDESCRIPTION: Shows how to programmatically create a Hugging Face Space using the huggingface_hub client library, including creating a repo and uploading files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/01_using-hugging-face-integrations.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import (\n    create_repo,\n    get_full_repo_name,\n    upload_file,\n)\ncreate_repo(name=target_space_name, token=hf_token, repo_type=\"space\", space_sdk=\"gradio\")\nrepo_name = get_full_repo_name(model_id=target_space_name, token=hf_token)\nfile_url = upload_file(\n    path_or_fileobj=\"file.txt\",\n    path_in_repo=\"app.py\",\n    repo_id=repo_name,\n    repo_type=\"space\",\n    token=hf_token,\n)\n```\n\n----------------------------------------\n\nTITLE: FastAPI Streaming Implementation\nDESCRIPTION: A basic FastAPI implementation providing both WebSocket and Server-Sent Events endpoints for streaming 500 tokens at 100 tokens per second. Used as a baseline for comparing raw streaming performance.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Reference to simple.py:\n# - FastAPI implementation\n# - WS and SSE endpoints\n# - Streams 500 tokens\n# - Rate: 100 tokens/sec\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic User Authentication with FastAPI and Gradio\nDESCRIPTION: A simple example showing how to implement user authentication in a Gradio app by mounting it within a FastAPI application. The authentication function checks for a 'user' header in the request.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom fastapi import FastAPI, Request\nimport gradio as gr\n\napp = FastAPI()\n\ndef get_user(request: Request):\n    return request.headers.get(\"user\")\n\ndemo = gr.Interface(lambda s: f\"Hello {s}!\", \"textbox\", \"textbox\")\n\napp = gr.mount_gradio_app(app, demo, path=\"/demo\", auth_dependency=get_user)\n\nif __name__ == '__main__':\n    uvicorn.run(app)\n```\n\n----------------------------------------\n\nTITLE: Implementing Edit Event Handler in Gradio Chatbot\nDESCRIPTION: Enables message editing functionality with gr.EditData to modify chat history and handle subsequent message removal.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef handle_edit(history, edit_data: gr.EditData):\n    new_history = history[:edit_data.index]\n    new_history[-1]['content'] = edit_data.value\n    return new_history\n\nchatbot.edit(handle_edit, chatbot, chatbot)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks App Using Jupyter Notebook Magic Command in Python\nDESCRIPTION: This Jupyter notebook-oriented Python snippet leverages the `%%blocks` magic command to build and display a Gradio Blocks app interactively. Designed for rapid iteration in notebook environments, it eliminates the need to manually launch the demo. The code defines a standard interactive UI with Markdown, input and output text boxes, and a simple passthrough callback. Requires the Gradio notebook extension to be loaded via `%load_ext gradio` at the notebook start.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n%%blocks\n\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(f\"# Greetings {args.name}!\")\n    inp = gr.Textbox()\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: x, inputs=inp, outputs=out)\n```\n\n----------------------------------------\n\nTITLE: Authenticated Client Connection - Python\nDESCRIPTION: Example of connecting to a Gradio app that requires username and password authentication.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nClient(\n  space_name,\n  auth=[username, password]\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Image Flip Functionality\nDESCRIPTION: Creates a Gradio interface with input and output image components, a flip button, and example images. The interface allows users to flip images 180 degrees and includes pre-loaded examples.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/examples_component/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef flip(i):\n    return i.rotate(180)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            img_i = gr.Image(label=\"Input Image\", type=\"pil\")\n        with gr.Column():\n            img_o = gr.Image(label=\"Output Image\")\n    with gr.Row():\n        btn = gr.Button(value=\"Flip Image\")\n    btn.click(flip, inputs=[img_i], outputs=[img_o])\n\n    gr.Examples(\n        [\n            os.path.join(os.path.abspath(''), \"images/cheetah1.jpg\"),\n            os.path.join(os.path.abspath(''), \"images/lion.jpg\"),\n        ],\n        img_i,\n        img_o,\n        flip,\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Breaking Out Scatter Plot Series by Nominal Color in Python\nDESCRIPTION: Demonstrates using the `color` argument in `gr.ScatterPlot` to differentiate plot series based on a nominal (categorical) column in the DataFrame. Specific colors can be assigned using the `color_map` argument. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_series_nominal\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake GAN Demo Interface\nDESCRIPTION: Creates a Gradio interface that simulates a GAN by randomly selecting pre-downloaded images based on text input. Includes error handling for NSFW content and implements a processing queue with a maximum size of 3.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan_2/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\nimport time\n\nimport gradio as gr\n\ndef fake_gan(desc):\n    if desc == \"NSFW\":\n        raise gr.Error(\"NSFW - banned content.\")\n    if desc == \"error\":\n        raise ValueError(\"error\")\n    time.sleep(9)\n    image = random.choice(\n        [\n            \"files/cheetah1.jpg\",\n            \"files/elephant.jpg\",\n            \"files/tiger.jpg\",\n            \"files/zebra.jpg\",\n        ]\n    )\n    return image\n\ndemo = gr.Interface(\n    fn=fake_gan,\n    inputs=gr.Textbox(),\n    outputs=gr.Image(label=\"Generated Image\"),\n    title=\"FD-GAN\",\n    description=\"This is a fake demo of a GAN. In reality, the images are randomly chosen from Unsplash.\",\n)\ndemo.queue(max_size=3)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Adding Custom Flagging Options to a Calculator Interface in Python\nDESCRIPTION: This code enhances the calculator interface with custom flagging options that users can select when flagging examples. The options include 'wrong sign', 'off by one', and 'other' to classify the reason for flagging.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/using-flagging.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"]\n)\n\niface.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Gradio Events with Documentation (Python)\nDESCRIPTION: Illustrates how to define a custom event for a Gradio component using `EventListener` from `gradio.events`. To ensure the event is documented correctly, it's crucial to provide a human-readable description via the `doc` parameter (e.g., `doc=\"This listener is triggered when the user does a bingbong.\"`) within the `EventListener` constructor. This description will be included in the generated documentation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_6\n\nLANGUAGE: py\nCODE:\n```\nfrom gradio.events import Events, EventListener\n\nclass ParamViewer(Component):\n  ...\n\n  EVENTS = [\n    Events.change,\n    EventListener(\n        \"bingbong\",\n        doc=\"This listener is triggered when the user does a bingbong.\"\n      )\n  ]\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio AnnotatedImage Component Visualization\nDESCRIPTION: Creates a Gradio interface that demonstrates the AnnotatedImage component. The code loads a base image from a URL and a building mask from another URL, then displays them together as an annotated image with the buildings highlighted and labeled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/annotatedimage_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np \nimport requests \nfrom io import BytesIO\nfrom PIL import Image\n\nbase_image = \"https://gradio-docs-json.s3.us-west-2.amazonaws.com/base.png\"\nbuilding_image = requests.get(\"https://gradio-docs-json.s3.us-west-2.amazonaws.com/buildings.png\")\nbuilding_image = np.asarray(Image.open(BytesIO(building_image.content)))[:, :, -1] > 0\n\nwith gr.Blocks() as demo:\n    gr.AnnotatedImage(\n        value=(base_image, [(building_image, \"buildings\")]),\n        height=500,\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Blocks App with Custom Demo Name in Python\nDESCRIPTION: This Python example is similar to the previous snippet but assigns the Blocks instance to a variable named `my_demo` instead of the default `demo`. This pattern supports specifying a custom demo variable name when running the app in reload mode, requiring the `--demo-name` CLI argument. All dependencies and input-output behaviors are the same, but the launch process adapts to custom variable usage. The file should be run with `gradio run.py --demo-name=my_demo` for correct auto-reloading.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as my_demo:\n    gr.Markdown(\"# Greetings from Gradio!\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: f\"Welcome, {x}!\",\n               inputs=inp,\n               outputs=out)\n\nif __name__ == \"__main__\":\n    my_demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Upload Button Demo\nDESCRIPTION: This code creates a Gradio interface with an upload button for multiple image or video files. It defines a function to process uploaded files and displays the file paths using a File output component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_button/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef upload_file(files):\n    file_paths = [file.name for file in files]\n    return file_paths\n\nwith gr.Blocks() as demo:\n    file_output = gr.File()\n    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\n    upload_button.upload(upload_file, upload_button, file_output)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio Demo with Markdown Component\nDESCRIPTION: Imports the Gradio library, defines a Gradio interface using `gr.Blocks`, adds a `gr.Markdown` component to display formatted text, and launches the interactive demo. The Markdown content includes italics, bold text, a Markdown link, and an HTML anchor tag.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        value=\"This _example_ was **written** in [Markdown](https://en.wikipedia.org/wiki/Markdown)\\n <a onclick='stoof' href='https://en.wikipedia.org/wiki/Markdown'>Markdown</a>\"\n    )\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio in Python\nDESCRIPTION: This snippet installs the Gradio library using pip in a Jupyter or notebook environment. The !pip install command ensures that Gradio is available for subsequent use in the script. Use this before importing Gradio to ensure all required dependencies are met.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/multipage/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Simulating Default Gradio Rendering Manually Python\nDESCRIPTION: Illustrates how the custom `LayoutBase.render` method simulates the default Gradio rendering process. It explicitly calls the `render()` method of child components (`left_textbox`, `right_textbox`) within the `with self.main_layout:` block, mirroring the implicit rendering that happens in standard Gradio usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# self.main_layout -> Row()\nwith self.main_layout:\n    left_textbox.render()\n    right_textbox.render()\n```\n\n----------------------------------------\n\nTITLE: Running the FastAPI Application with Uvicorn\nDESCRIPTION: Command to start the FastAPI application using Uvicorn server, which will make the web application accessible at http://127.0.0.1:8000.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ uvicorn main:app\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface in Python\nDESCRIPTION: This Python snippet defines a simple Gradio web app with a single text input that greets the user. It depends on the gradio library, which must be installed in the environment. The function greet(name) takes a string input and returns a formatted greeting, which is then served by gr.Interface. The app runs on default settings and is intended to be accessible once the container is started. Key parameters include the input ('name' as text) and the output (greeting as text).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/deploying-gradio-with-docker.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\ndef greet(name):\\n    return f\\\"Hello {name}!\\\"\\n\\niface = gr.Interface(fn=greet, inputs=\\\"text\\\", outputs=\\\"text\\\").launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Hello World Interface\nDESCRIPTION: Implements a Gradio interface that takes a name input and intensity slider to generate a customized greeting. The greeting is created by repeating exclamation marks based on the intensity value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_4/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello, \" + name + \"!\" * int(intensity)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum File Upload Size in Gradio\nDESCRIPTION: Shows how to configure maximum file upload size limits in a Gradio application using either string notation or FileSize constant.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/08_file-access.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: BaseColorPicker Component Props\nDESCRIPTION: Defines the props available for the BaseColorPicker component, including value, value_is_output, label, info, disabled, and show_label, with their types and default values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/colorpicker/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value = \"#000000\";\n\texport let value_is_output = false;\n\texport let label: string;\n\texport let info: string | undefined = undefined;\n\texport let disabled = false;\n\texport let show_label = true;\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Gradio Image Interface\nDESCRIPTION: Creates a simple Gradio interface with an Image component using the Blocks API. The interface is initialized and launched without any processing callbacks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Image()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Loading Pre-trained GAN Generator Weights from Hugging Face Hub in Python\nDESCRIPTION: Instantiates the `Generator` model defined previously and loads pre-trained weights from the Hugging Face Hub. It uses `hf_hub_download` to fetch the 'generator.pth' file from the 'nateraw/cryptopunks-gan' repository and then loads these weights into the model using `torch.load_state_dict`. The `map_location` parameter ensures compatibility whether running on CPU or GPU.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nmodel = Generator()\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\n```\n\n----------------------------------------\n\nTITLE: Implementing Speech Recognition Interface\nDESCRIPTION: Creates a Gradio interface that loads the wav2vec2 speech recognition model from Hugging Face. The interface captures audio from the microphone and transcribes it to text. Includes optional API token handling to avoid rate limiting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/automatic-speech-recognition/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\n# save your HF API token from https:/hf.co/settings/tokens as an env variable to avoid rate limiting\nhf_token = os.getenv(\"hf_token\")\n\n# automatically load the interface from a HF model\n# you can remove the hf_token parameter if you don't care about rate limiting.\ndemo = gr.load(\n    \"huggingface/facebook/wav2vec2-base-960h\",\n    title=\"Speech-to-text\",\n    inputs=\"mic\",\n    description=\"Let me try to guess what you're saying!\",\n    hf_token=hf_token\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining BaseRadio Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseRadio component, including display value, internal value, disabled state, element ID, and selected value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/radio/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let display_value: string;\nexport let internal_value: string | number;\nexport let disabled = false;\nexport let elem_id = \"\";\nexport let selected: string | number | null = null;\n```\n\n----------------------------------------\n\nTITLE: Extending Gradio Theme Core Colors in Constructor - Python (String Shortcuts)\nDESCRIPTION: Illustrates how to extend the core theme colors of a Gradio app by passing string shortcuts for 'primary_hue' and 'secondary_hue' to the gr.themes.Default() constructor. The modified theme is applied through the Blocks context manager. The ellipsis indicates where UI logic goes. This approach allows quick customization using predefined color names. Dependency: Gradio installed and imported as 'gr'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Default(primary_hue=\\\"red\\\", secondary_hue=\\\"pink\\\")) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Gradio Chatbot Tool Usage Display in Python\nDESCRIPTION: This Python code demonstrates how to display tool usage steps within a Gradio Chatbot using the 'messages' format. It defines a generator function `generate_response` that simulates a conversation, appending `ChatMessage` objects to the history. Specific assistant messages representing tool actions (e.g., API calls, errors, successes) include a `metadata` dictionary with a `title` key, causing them to be displayed in expandable boxes. The example sets up a Gradio Blocks interface with a Chatbot and a Button to trigger the simulation. Dependencies include the `gradio` library (specifically `gr`, `ChatMessage`) and the `time` module for simulating delays.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/_website/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\ndef generate_response(history):\n    history.append(ChatMessage(role=\"user\", content=\"What is the weather in San Francisco right now?\"))\n    yield history\n    time.sleep(0.25)\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"In order to find the current weather in San Francisco, I will need to use my weather tool.\")\n                               )\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"API Error when connecting to weather service.\",\n                              metadata={\"title\": \"💥 Error using tool 'Weather'\"})\n                  )\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"I will try again\",\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"Weather 72 degrees Fahrenheit with 20% chance of rain.\",\n                                metadata={\"title\": \"🛠️ Used tool 'Weather'\"}\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"Now that the API succeeded I can complete my task.\",\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"It's a sunny day in San Francisco with a current temperature of 72 degrees Fahrenheit and a 20% chance of rain. Enjoy the weather!\",\n                              ))\n    yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot  = gr.Chatbot(type=\"messages\")\n    button = gr.Button(\"Get San Francisco Weather\")\n    button.click(generate_response, chatbot, chatbot)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive DataFrame Demo with Gradio Blocks\nDESCRIPTION: Creates a Gradio interface with a slider control, interactive DataFrame, and button. When clicked, the button generates rows of data based on the slider value. The DataFrame is configured with two fixed columns labeled 'A' and 'B'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_block-ui-test/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    count = gr.Slider(minimum=1, maximum=10, step=1, label=\"count\")\n    data = gr.DataFrame(\n        headers=[\"A\", \"B\"], col_count=(2, \"fixed\"), type=\"array\", interactive=True\n    )\n    btn = gr.Button(value=\"click\")\n    btn.click(\n        fn=lambda cnt: [[str(2 * i), str(2 * i + 1)] for i in range(int(cnt))],\n        inputs=[count],\n        outputs=[data],\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Temporal Bar Plot with Gradio\nDESCRIPTION: Creates a Gradio application with a bar plot that visualizes temporal data with adjustable time binning. The demo includes a radio button control that allows users to change the aggregation bin size between 10 minutes, 30 minutes, and 1 hour.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_temporal/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    plot = gr.BarPlot(df, x=\"time\", y=\"price\", x_bin=\"10m\")\n\n    bins = gr.Radio([\"10m\", \"30m\", \"1h\"], label=\"Bin Size\")\n    bins.change(lambda bins: gr.BarPlot(x_bin=bins), bins, plot)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Event Triggers\nDESCRIPTION: Example showing how to add event triggers to a custom component using the EVENTS class attribute.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/04_backend.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio.events import Events\nfrom gradio.components import FormComponent\n\nclass MyComponent(FormComponent):\n\n    EVENTS = [\n        \"text_submit\",\n        \"file_upload\",\n        Events.change\n    ]\n```\n\n----------------------------------------\n\nTITLE: File Upload Handler Implementation\nDESCRIPTION: Example implementation of file upload handling using Gradio's upload utilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_4\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n    import { upload, prepare_files, type FileData } from \"@gradio/client\";\n    export let root;\n    export let value;\n    let uploaded_files;\n\n    async function handle_upload(file_data: FileData[]): Promise<void> {\n        await tick();\n        uploaded_files = await upload(file_data, root);\n    }\n\n    async function loadFiles(files: FileList): Promise<void> {\n        let _files: File[] = Array.from(files);\n        if (!files.length) {\n            return;\n        }\n        if (file_count === \"single\") {\n            _files = [files[0]];\n        }\n        let file_data = await prepare_files(_files);\n        await handle_upload(file_data);\n    }\n\n    async function loadFilesFromUpload(e: Event): Promise<void> {\n\t\tconst target = e.target;\n\n\t\tif (!target.files) return;\n\t\tawait loadFiles(target.files);\n\t}\n</script>\n\n<input\n    type=\"file\"\n    on:change={loadFilesFromUpload}\n    multiple={true}\n/>\n```\n\n----------------------------------------\n\nTITLE: Implementing PDF Loading and Page Rendering Functions in TypeScript\nDESCRIPTION: Defines functions to load a PDF document and render a specific page to a canvas. The get_doc function loads the PDF file while render_page handles the viewport scaling and actual rendering.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nasync function get_doc(value: FileData) {\n    const loadingTask = pdfjsLib.getDocument(value.url);\n    pdfDoc = await loadingTask.promise;\n    numPages = pdfDoc.numPages;\n    render_page();\n}\n\nfunction render_page() {\n// Render a specific page of the PDF onto the canvas\n    pdfDoc.getPage(currentPage).then(page => {\n        const ctx  = canvasRef.getContext('2d')\n        ctx.clearRect(0, 0, canvasRef.width, canvasRef.height);\n        let viewport = page.getViewport({ scale: 1 });\n        let scale = height / viewport.height;\n        viewport = page.getViewport({ scale: scale });\n\n        const renderContext = {\n            canvasContext: ctx,\n            viewport,\n        };\n        canvasRef.width = viewport.width;\n        canvasRef.height = viewport.height;\n        page.render(renderContext);\n    });\n}\n\n// If the value changes, render the PDF of the currentPage\n$: if(JSON.stringify(old_value) != JSON.stringify(_value)) {\n    if (_value){\n        get_doc(_value);\n    }\n    old_value = _value;\n    gradio.dispatch(\"change\");\n}\n```\n\n----------------------------------------\n\nTITLE: Building and Launching a Gradio App Entirely in R\nDESCRIPTION: An R script demonstrating how to build a Gradio application using the `reticulate` package. It defines a simple R function `greeting` that takes a name and returns a greeting string. It then uses the imported `gradio` object (`gr`) to create a `gr$Interface`, mapping the R function to the interface, defining text input and output components, and setting a title. Finally, `app$launch` starts the Gradio web server on localhost port 3000.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_8\n\nLANGUAGE: r\nCODE:\n```\ngreeting <- \\(name) paste(\"Hello\", name)\n\napp <- gr$Interface(\n  fn = greeting,\n  inputs = gr$Text(label = \"Name\"),\n  outputs = gr$Text(label = \"Greeting\"),\n  title = \"Hello! &#128515 &#128075\"\n)\n\napp$launch(server_name = \"localhost\", \n           server_port = as.integer(3000))\n```\n\n----------------------------------------\n\nTITLE: Building and Launching a Gradio Webcam Streaming App in Python\nDESCRIPTION: This Python script defines and launches a Gradio web application using the `Blocks` interface. It sets up two columns: one for webcam input (`gr.Image` with `sources=\"webcam\"`) and one for displaying the streamed output (`gr.Image`). The `input_img.stream()` method configures the streaming behavior: it calls the provided lambda function (`lambda s: s`, an identity function simply passing the input stream `s` through) to update the `output_img` component. Streaming happens every 0.1 seconds (`stream_every=0.1`), has a time limit of 15 seconds (`time_limit=15`), and allows up to 30 concurrent streams (`concurrency_limit=30`). The `if __name__ == \"__main__\":` block ensures the `demo.launch()` method is called only when the script is executed directly, starting the Gradio server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            input_img = gr.Image(label=\"Input\", sources=\"webcam\")\n        with gr.Column():\n            output_img = gr.Image(label=\"Output\")\n        input_img.stream(lambda s: s, input_img, output_img, time_limit=15, stream_every=0.1, concurrency_limit=30)\n\nif __name__ == \"__main__\":\n\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio App for Queue Testing (Python)\nDESCRIPTION: This Python script defines a Gradio application using the Blocks interface. It sets up four buttons that all call the `get_random_number` function, which simulates a 5-second delay and returns a random number. Crucially, it tracks the number of calls and intentionally raises a `gr.Error` on the second call to test error handling within the queue. The application queue is configured with a `max_size` of 2 to simulate and test behavior when the queue is full. The `concurrency_id=\"f\"` ensures these button clicks share the same queue worker pool. Finally, it launches the Gradio application if the script is run as the main program.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/queue_full_e2e_test/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\nimport random\n\nn_calls = 0\n\ndef get_random_number():\n    global n_calls\n    if n_calls == 1:\n        n_calls += 1\n        raise gr.Error(\"This is a gradio error\")\n    n_calls += 1\n    time.sleep(5)\n    return random.randrange(1, 10)\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            first = gr.Button(\"First Call\")\n            second = gr.Button(\"Second Call\")\n            third = gr.Button(\"Third Call\")\n            fourth = gr.Button(\"Fourth Call\")\n        with gr.Column():\n            first_o = gr.Number(label=\"First Result\")\n            second_o = gr.Number(label=\"Second Result\")\n            third_o = gr.Number(label=\"Third Result\")\n            fourth_o = gr.Number(label=\"Fourth Result\")\n\n    first.click(get_random_number, None, first_o, concurrency_id=\"f\")\n    second.click(get_random_number, None, second_o, concurrency_id=\"f\")\n    third.click(get_random_number, None, third_o, concurrency_id=\"f\")\n    fourth.click(get_random_number, None, fourth_o, concurrency_id=\"f\")\n\ndemo.queue(max_size=2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with DateTime Components\nDESCRIPTION: This snippet creates a Gradio interface with three DateTime components, buttons, and text outputs. It demonstrates different configurations of DateTime inputs and sets up event handlers for clicks, changes, and submissions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/datetimes/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    date1 = gr.DateTime(include_time=True, label=\"Date and Time\", type=\"datetime\", elem_id=\"date1\")\n    date2 = gr.DateTime(include_time=False, label=\"Date Only\", type=\"string\", elem_id=\"date2\")\n    date3 = gr.DateTime(elem_id=\"date3\", timezone=\"Europe/Paris\")\n\n    with gr.Row():\n        btn1 = gr.Button(\"Load Date 1\")\n        btn2 = gr.Button(\"Load Date 2\")\n        btn3 = gr.Button(\"Load Date 3\")\n\n    click_output = gr.Textbox(label=\"Last Load\")\n    change_output = gr.Textbox(label=\"Last Change\")\n    submit_output = gr.Textbox(label=\"Last Submit\")\n\n    btn1.click(lambda x:x, date1, click_output)\n    btn2.click(lambda x:x, date2, click_output)\n    btn3.click(lambda x:x, date3, click_output)\n\n    for item in [date1, date2, date3]:\n        item.change(lambda x:x, item, change_output)\n        item.submit(lambda x:x, item, submit_output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for File Upload and Delete Operations in Python\nDESCRIPTION: This code creates a Gradio interface with various file upload components and a delete function. It demonstrates single and multiple file uploads, specific file type uploads, and file deletion. Each component is paired with an output display and a counter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef delete_file(n: int, file: gr.DeletedFileData):\n    return [file.file.path, n + 1]\n\nwith gr.Blocks() as demo:\n\n    with gr.Row():\n        with gr.Column():\n            file_component = gr.File(label=\"Upload Single File\", file_count=\"single\")\n        with gr.Column():\n            output_file_1 = gr.File(\n                label=\"Upload Single File Output\", file_count=\"single\"\n            )\n            num_load_btn_1 = gr.Number(label=\"# Load Upload Single File\", value=0)\n            file_component.upload(\n                lambda s, n: (s, n + 1),\n                [file_component, num_load_btn_1],\n                [output_file_1, num_load_btn_1],\n            )\n    with gr.Row():\n        with gr.Column():\n            file_component_multiple = gr.File(\n                label=\"Upload Multiple Files\", file_count=\"multiple\"\n            )\n        with gr.Column():\n            output_file_2 = gr.File(\n                label=\"Upload Multiple Files Output\", file_count=\"multiple\"\n            )\n            num_load_btn_2 = gr.Number(label=\"# Load Upload Multiple Files\", value=0)\n            file_component_multiple.upload(\n                lambda s, n: (s, n + 1),\n                [file_component_multiple, num_load_btn_2],\n                [output_file_2, num_load_btn_2],\n            )\n    with gr.Row():\n        with gr.Column():\n            file_component_specific = gr.File(\n                label=\"Upload Multiple Files Image/Video\",\n                file_count=\"multiple\",\n                file_types=[\"image\", \"video\"],\n            )\n        with gr.Column():\n            output_file_3 = gr.File(\n                label=\"Upload Multiple Files Output Image/Video\", file_count=\"multiple\"\n            )\n            num_load_btn_3 = gr.Number(\n                label=\"# Load Upload Multiple Files Image/Video\", value=0\n            )\n            file_component_specific.upload(\n                lambda s, n: (s, n + 1),\n                [file_component_specific, num_load_btn_3],\n                [output_file_3, num_load_btn_3],\n            )\n    with gr.Row():\n        with gr.Column():\n            file_component_pdf = gr.File(label=\"Upload PDF File\", file_types=[\".pdf\"])\n        with gr.Column():\n            output_file_4 = gr.File(label=\"Upload PDF File Output\")\n            num_load_btn_4 = gr.Number(label=\"# Load Upload PDF File\", value=0)\n            file_component_pdf.upload(\n                lambda s, n: (s, n + 1),\n                [file_component_pdf, num_load_btn_4],\n                [output_file_4, num_load_btn_4],\n            )\n    with gr.Row():\n        with gr.Column():\n            file_component_invalid = gr.File(\n                label=\"Upload File with Invalid file_types\",\n                file_types=[\"invalid file_type\"],\n            )\n        with gr.Column():\n            output_file_5 = gr.File(label=\"Upload File with Invalid file_types Output\")\n            num_load_btn_5 = gr.Number(\n                label=\"# Load Upload File with Invalid file_types\", value=0\n            )\n            file_component_invalid.upload(\n                lambda s, n: (s, n + 1),\n                [file_component_invalid, num_load_btn_5],\n                [output_file_5, num_load_btn_5],\n            )\n    with gr.Row():\n        with gr.Column():\n            del_file_input = gr.File(label=\"Delete File\", file_count=\"multiple\")\n        with gr.Column():\n            del_file_data = gr.Textbox(label=\"Delete file data\")\n            num_load_btn_6 = gr.Number(label=\"# Deleted File\", value=0)\n            del_file_input.delete(\n                delete_file,\n                [num_load_btn_6],\n                [del_file_data, num_load_btn_6],\n            )\n    # f = gr.File(label=\"Upload many File\", file_count=\"multiple\")\n    # # f.delete(delete_file)\n    # f.delete(delete_file, inputs=None, outputs=None)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating an Image Inpainting Demo with Gradio and NumPy in Python\nDESCRIPTION: This snippet defines the core functionality of the Gradio image inpainting demo. It imports Gradio and NumPy, defines a function to replace masked regions with average pixel colors, and constructs the interactive UI with Gradio Blocks. Expects layered image input (with background and mask) in numpy format and returns the background with the masked region averaged. Key dependencies are Gradio and NumPy, and the application is started if run as the main module.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_inpainting/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport numpy as np\n\ndef average_inpainting_colors(image):\n    mask = image[\"layers\"][0]\n    img = image[\"background\"]\n    mask_bool = mask[:,:,3] > 0\n    if not np.any(mask_bool):\n        return img\n    selected_pixels = img[mask_bool]\n    avg_color = np.mean(selected_pixels, axis=0)\n    result = img.copy()\n    result[mask_bool] = avg_color\n    return result\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        image_editor = gr.ImageEditor(\n            type=\"numpy\",\n            label=\"Input Image with Inpainting Layers\",\n            interactive=True,\n            show_fullscreen_button=True\n        )\n\n        output_image = gr.Image(\n            type=\"numpy\",\n            label=\"Averaged Inpainting Layers\"\n        )\n\n        image_editor.change(fn=average_inpainting_colors, inputs=image_editor, outputs=output_image)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building and Launching a Gradio Text Generation Demo with GPT-2 in Python\nDESCRIPTION: This snippet imports Gradio and the Transformers pipeline, initializes the GPT-2 text generation model, and defines a function for generating text from a user prompt. It provides two example text prompts and creates a Gradio interface with input and output textboxes. Required dependencies are gradio and transformers, and users interact via a browser UI. The function receives a string input and returns generated text from the GPT-2 model with a maximum length of 30 tokens and one output sequence.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/text_generation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\n\ngenerator = pipeline('text-generation', model='gpt2')\n\ndef generate(text):\n    result = generator(text, max_length=30, num_return_sequences=1)\n    return result[0][\"generated_text\"]  # type: ignore\n\nexamples = [\n    [\"The Moon's orbit around Earth has\"],\n    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"],\n]\n\ndemo = gr.Interface(\n    fn=generate,\n    inputs=gr.Textbox(lines=5, label=\"Input Text\"),\n    outputs=gr.Textbox(label=\"Generated Text\"),\n    examples=examples\n)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Transformers Agent UI Implementation\nDESCRIPTION: Creation of the Gradio chat interface for the transformers agent with streaming capability.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef interact_with_agent(prompt, history):\n    messages = []\n    yield messages\n    for msg in stream_to_gradio(agent, prompt):\n        messages.append(asdict(msg))\n        yield messages\n    yield messages\n\n\ndemo = gr.ChatInterface(\n    interact_with_agent,\n    chatbot= gr.Chatbot(\n        label=\"Agent\",\n        type=\"messages\",\n        avatar_images=(\n            None,\n            \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\",\n        ),\n    ),\n    examples=[\n        [\"Generate an image of an astronaut riding an alligator\"],\n        [\"I am writing a children's book for my daughter. Can you help me with some illustrations?\"],\n    ],\n    type=\"messages\",\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Demo for Unload Event Testing\nDESCRIPTION: Creates a Gradio demo to test the unload event. It includes functions for incrementing a number, logging actions, and handling unload events. The demo uses a file to log various actions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unload_event_test/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n\"\"\"This demo is only meant to test the unload event.\nIt will write to a file when the unload event is triggered.\nMay not work as expected if multiple people are using it.\n\"\"\"\nimport gradio as gr\nfrom pathlib import Path\n\nlog_file = (Path(__file__).parent / \"output_log.txt\").resolve()\n\ndef test_fn(x):\n    with open(log_file, \"a\") as f:\n        f.write(f\"incremented {x}\\n\")\n    return x + 1, x + 1\n\ndef delete_fn(v):\n    with log_file.open(\"a\") as f:\n        f.write(f\"deleted {v}\\n\")\n\ndef unload_fn():\n   with log_file.open(\"a\") as f:\n      f.write(\"unloading\\n\")\n\nwith gr.Blocks() as demo:\n    n1 = gr.Number(value=0, label=\"Number\")\n    state = gr.State(value=0, delete_callback=delete_fn)\n    button = gr.Button(\"Increment\")\n    button.click(test_fn, [state], [n1, state], api_name=\"increment\")\n    demo.unload(unload_fn)\n    demo.load(lambda: log_file.write_text(\"\"))\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Importing Atom Components in Svelte\nDESCRIPTION: Imports various UI components from the @gradio/atoms package for use in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script lang=\"ts\">\n\timport { Block, BlockTitle, BlockLabel, IconButton, Empty, Info, ShareButton, UploadText} from \"@gradio/atoms\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Editor Canvas Demo\nDESCRIPTION: Creates a Gradio interface with multiple ImageEditor components featuring different canvas configurations. The demo includes default, custom-sized, and fixed-size canvases, along with functionality to retrieve and display image dimensions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_canvas_size/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        with gr.Column():\n            image = gr.ImageEditor(label=\"Default Canvas. Not fixed\", elem_id=\"default\")\n            get_image = gr.Button(\"Get Default\")\n        with gr.Column():\n            custom_canvas = gr.ImageEditor(label=\"Custom Canvas, not fixed\", canvas_size=(300, 300),\n                                           elem_id=\"small\")\n            get_small = gr.Button(\"Get Small\")\n        with gr.Column():\n            custom_canvas_fixed = gr.ImageEditor(label=\"Custom Canvas,fixed\", canvas_size=(500, 500), fixed_canvas=True,\n                                                 elem_id=\"fixed\")\n            get_fixed = gr.Button(\"Get Fixed\")\n        with gr.Column():\n            width = gr.Number(label=\"Width\")\n            height = gr.Number(label=\"Height\")\n\n    get_image.click(lambda x: x[\"composite\"].shape, outputs=[height, width], inputs=image)\n    get_small.click(lambda x: x[\"composite\"].shape, outputs=[height, width], inputs=custom_canvas)\n    get_fixed.click(lambda x: x[\"composite\"].shape, outputs=[height, width], inputs=custom_canvas_fixed)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Scatter Plot Demo\nDESCRIPTION: Installs the necessary Python packages for running the scatter plot demo, including Gradio for the UI components, vega_datasets for sample data, and pandas for data manipulation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatter_plot/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio vega_datasets pandas\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Block Interface with Page Load Handler\nDESCRIPTION: Creates a Gradio interface using Blocks API that displays a welcome message on page load. The interface contains two textboxes - one for name input with default value 'Frank' and another for output. The load event handler prints a welcome message using the input name.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_page_load/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef print_message(n):\n    return \"Welcome! This page has loaded for \" + n\n\nwith gr.Blocks() as demo:\n    t = gr.Textbox(\"Frank\", label=\"Name\")\n    t2 = gr.Textbox(label=\"Output\")\n    demo.load(print_message, t, t2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio in Python\nDESCRIPTION: This snippet installs the Gradio library using pip, preparing the environment for running Gradio-based applications. It must be run before importing and using Gradio in the project. No input parameters or outputs are expected, as it serves only as a package installation step. Limitations: only works in environments with pip available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/no_input/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Cancelling Queued Jobs in JavaScript\nDESCRIPTION: Shows how to cancel Gradio jobs that are in the queue. This example creates two jobs and then immediately cancels them, which will prevent them from running if they haven't started processing yet.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_9\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"abidlabs/en2fr\");\nconst job_one = app.submit(\"/predict\", [\"Hello\"]);\nconst job_two = app.submit(\"/predict\", [\"Friends\"]);\n\njob_one.cancel();\njob_two.cancel();\n```\n\n----------------------------------------\n\nTITLE: Gradio Interface Setup\nDESCRIPTION: Creates a Gradio interface for the JoJoGAN model with image input and output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ntitle = \"JoJoGAN\"\ndescription = \"Gradio Demo for JoJoGAN: One Shot Face Stylization. To use it, simply upload your image, or click one of the examples to load them. Read more at the links below.\"\n\ndemo = gr.Interface(\n    inference,\n    gr.Image(type=\"pil\"),\n    gr.Image(type=\"file\"),\n    title=title,\n    description=description\n)\n\ndemo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio Translation Demo\nDESCRIPTION: This code snippet installs the necessary packages for the translation demo, including Gradio, Transformers, and PyTorch.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/translation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio git+https://github.com/huggingface/transformers gradio torch\n```\n\n----------------------------------------\n\nTITLE: Building a Stateful Image Generation and Cleanup App with Gradio in Python\nDESCRIPTION: Defines and launches a Python Gradio Blocks application that allows users to generate random color images and maintain a session-specific gallery. User images and state are stored in dedicated directories, and a cleanup function deletes user data when the session ends. Requires gradio, numpy, Pillow, secrets, pathlib, and shutil. Key parameters include session state, user session hash, and the incoming Gradio request, with expected outputs being displayed images and their state in the UI; directories are removed upon session closure. Limitations include filesystem access and compatibility with the gradio environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_cleanup/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\nimport gradio as gr\nimport numpy as np\nfrom PIL import Image\nfrom pathlib import Path\nimport secrets\nimport shutil\n\ncurrent_dir = Path(__file__).parent\n\ndef generate_random_img(history: list[Image.Image], request: gr.Request):\n    \"\"\"Generate a random red, green, blue, orange, yellor or purple image.\"\"\"\n    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 165, 0), (255, 255, 0), (128, 0, 128)]\n    color = colors[np.random.randint(0, len(colors))]\n    img = Image.new('RGB', (100, 100), color)\n\n    user_dir: Path = current_dir / str(request.session_hash)\n    user_dir.mkdir(exist_ok=True)\n    path = user_dir / f\"{secrets.token_urlsafe(8)}.webp\"\n\n    img.save(path)\n    history.append(img)\n\n    return img, history, history\n\ndef delete_directory(req: gr.Request):\n    if not req.username:\n        return\n    user_dir: Path = current_dir / req.username\n    shutil.rmtree(str(user_dir))\n\nwith gr.Blocks(delete_cache=(60, 3600)) as demo:\n    gr.Markdown(\"\"\"# State Cleanup Demo\n                🖼️ Images are saved in a user-specific directory and deleted when the users closes the page via demo.unload.\n                \"\"\")\n    with gr.Row():\n        with gr.Column(scale=1):\n            with gr.Row():\n                img = gr.Image(label=\"Generated Image\", height=300, width=300)\n            with gr.Row():\n                gen = gr.Button(value=\"Generate\")\n            with gr.Row():\n                history = gr.Gallery(label=\"Previous Generations\", height=500, columns=10)\n                state = gr.State(value=[], delete_callback=lambda v: print(\"STATE DELETED\"))\n\n    demo.load(generate_random_img, [state], [img, state, history])\n    gen.click(generate_random_img, [state], [img, state, history])\n    demo.unload(delete_directory)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Hangman Game with Gradio UI\nDESCRIPTION: Creates a web-based Hangman game interface using Gradio Blocks. Features include letter input, guess button, display for the current word state, and used letters tracking. The game uses 'gradio' as the secret word.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hangman/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nsecret_word = \"gradio\"\n\nwith gr.Blocks() as demo:\n    used_letters_var = gr.State([])\n    with gr.Row() as row:\n        with gr.Column():\n            input_letter = gr.Textbox(label=\"Enter letter\")\n            btn = gr.Button(\"Guess Letter\")\n        with gr.Column():\n            hangman = gr.Textbox(\n                label=\"Hangman\",\n                value=\"_\"*len(secret_word)\n            )\n            used_letters_box = gr.Textbox(label=\"Used Letters\")\n\n    def guess_letter(letter, used_letters):\n        used_letters.append(letter)\n        answer = \"\".join([\n            (letter if letter in used_letters else \"_\")\n            for letter in secret_word\n        ])\n        return {\n            used_letters_var: used_letters,\n            used_letters_box: \", \".join(used_letters),\n            hangman: answer\n        }\n    btn.click(\n        guess_letter,\n        [input_letter, used_letters_var],\n        [used_letters_var, used_letters_box, hangman]\n        )\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Main Page Implementation\nDESCRIPTION: Example of a main page implementation in a separate file (main_page.py). Creates a simple Gradio interface with an image component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/09_multipage-apps.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Image()\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining Custom Seafoam Theme and Creating Gradio Application\nDESCRIPTION: Defines a custom Seafoam theme class inheriting from Gradio's Base theme, and creates a Gradio application using this theme. The application includes a textbox, slider, buttons, and an output field, with a function to repeat the input text based on the slider value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\nfrom typing import Iterable\nimport gradio as gr\nfrom gradio.themes.base import Base\nfrom gradio.themes.utils import colors, fonts, sizes\nimport time\n\nclass Seafoam(Base):\n    def __init__(\n        self,\n        *,\n        primary_hue: colors.Color | str = colors.emerald,\n        secondary_hue: colors.Color | str = colors.blue,\n        neutral_hue: colors.Color | str = colors.gray,\n        spacing_size: sizes.Size | str = sizes.spacing_md,\n        radius_size: sizes.Size | str = sizes.radius_md,\n        text_size: sizes.Size | str = sizes.text_lg,\n        font: fonts.Font\n        | str\n        | Iterable[fonts.Font | str] = (\n            fonts.GoogleFont(\"Quicksand\"),\n            \"ui-sans-serif\",\n            \"sans-serif\",\n        ),\n        font_mono: fonts.Font\n        | str\n        | Iterable[fonts.Font | str] = (\n            fonts.GoogleFont(\"IBM Plex Mono\"),\n            \"ui-monospace\",\n            \"monospace\",\n        ),\n    ):\n        super().__init__(\n            primary_hue=primary_hue,\n            secondary_hue=secondary_hue,\n            neutral_hue=neutral_hue,\n            spacing_size=spacing_size,\n            radius_size=radius_size,\n            text_size=text_size,\n            font=font,\n            font_mono=font_mono,\n        )\n\nseafoam = Seafoam()\n\nwith gr.Blocks(theme=seafoam) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating an Input-Only Gradio Demo for Image Saving in Python\nDESCRIPTION: This example demonstrates an input-only Gradio demo that saves uploaded images to disk. It sets the `outputs` parameter to `None` in the `gradio.Interface` class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/05_four-kinds-of-interfaces.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef save_image(image):\n    os.makedirs(\"images\", exist_ok=True)\n    image.save(f\"images/{hash(image)}.png\")\n    \ndemo = gr.Interface(\n    fn=save_image, \n    inputs=\"image\", \n    outputs=None,\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Full-Height Gradio Blocks Application (Python)\nDESCRIPTION: Shows how to create a Gradio Blocks application that takes the full height of the browser. It uses fill_height=True and applies scale to components to control their expansion.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/02_controlling-layout.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks(fill_height=True) as demo:\n    gr.Chatbot(scale=1)\n    gr.Textbox(scale=0)\n```\n\n----------------------------------------\n\nTITLE: Creating Custom-Styled Dataframe with Gradio in Python\nDESCRIPTION: This code creates a Gradio demo that displays a custom-styled dataframe. It includes functions for applying background gradients based on performance scores and adding medal emojis for top performers. The dataframe shows model performance on LeetCode Hard problems.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_custom_styling/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndata = [\n    [\"DeepSeek Coder\", 79.3],\n    [\"Llama 3.3\", 68.9],\n    [\"Qwen 2.5\", 61.9],\n    [\"Gemma 2\", 59.5],\n    [\"GPT 2\", 18.3],\n]\n\nheaders = [\"Model\", \"% Correct (LeetCode Hard)\"]\n\ndef get_styling(values):\n    return [[\"\", f\"background: linear-gradient(90deg, rgba(220, 242, 220) {row[1]}%, transparent {row[1]}%)\"] for row in values]\n\ndef get_display_value(values):\n    display_values = []\n    medals = [\"🥇\", \"🥈\", \"🥉\"]\n    for i, row in enumerate(values):\n        if i < 3:\n            display_values.append([f\"{medals[i]} {row[0]}\", row[1]])\n        else:\n            display_values.append([row[0], row[1]])\n    return display_values\n\nstyling = get_styling(data)\ndisplay_value = get_display_value(data)\n\n\nvalue = {\n    \"data\": data,\n    \"headers\": headers,\n    \"metadata\": {\n        \"styling\": styling,\n        \"display_value\": display_value,\n    },\n}\n\nwith gr.Blocks() as demo:\n    gr.Dataframe(value, show_search=\"search\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: BaseExample Component Props Definition\nDESCRIPTION: Defines the props for the BaseExample component which handles code examples. Supports different display types (gallery or table) and selection state.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Processing Buffer Objects with handle_file\nDESCRIPTION: Demonstrates how to handle Buffer objects using the handle_file utility in Gradio client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_24\n\nLANGUAGE: typescript\nCODE:\n```\nimport { handle_file } from \"@gradio/client\";\nimport { readFileSync } from \"fs\";\n\n// not uploaded yet\nconst buffer_ref = handle_file(readFileSync(\"file.png\"));\n\nconst app = await Client.connect(\"user/space-name\");\n\n// upload happens here\nconst result = await app.predict(\"/predict\", {\n\tbuffer: buffer_ref,\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing a Gradio app with progress indicator\nDESCRIPTION: Creates a Gradio application that demonstrates the progress component. The app has a 'Load' button that triggers a function which simulates loading a set of items with a progress bar. The progress is displayed using Gradio's Progress component with tqdm integration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef load_set(progress=gr.Progress()):\n    imgs = [None] * 24\n    for img in progress.tqdm(imgs, desc=\"Loading...\"):\n        time.sleep(0.1)\n    return \"Loaded\"\n\nwith gr.Blocks() as demo:\n    load = gr.Button(\"Load\")\n    label = gr.Label(label=\"Loader\")\n    load.click(load_set, outputs=label)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Skipping Component Updates in Gradio Event Listeners with gr.skip() in Python\nDESCRIPTION: Explains the use of `gr.skip()` within a Gradio event listener function in Python. Returning `gr.skip()` prevents the corresponding output component's value from being changed, which is useful for conditional updates or maintaining the current state. This contrasts with returning `None`, which typically clears or resets the component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n$code_skip\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Render Logic in LayoutBase Python\nDESCRIPTION: Defines the `render` method within the `LayoutBase` class. This method manually controls the rendering process by iterating through child `renderables` and calling their respective `render` methods within the context of the `main_layout` (a Gradio layout component). Finally, it calls `render` on the `main_layout` itself to integrate it into the parent layout, mimicking Gradio's default nested rendering behavior.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# other LayoutBase implementations\n\ndef render(self) -> None:\n    with self.main_layout:\n        for renderable in self.renderables:\n            renderable.render()\n\n    self.main_layout.render()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Custom Theme and Multiple Components\nDESCRIPTION: This code creates a Gradio interface with a custom theme, textbox, slider, buttons, and output. It defines a function to repeat the input text based on the slider value and launches the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_1/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\nwith gr.Blocks(theme=gr.themes.Default(primary_hue=\"red\", secondary_hue=\"pink\")) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: ImageEditor Component Usage Example in Python\nDESCRIPTION: Example code demonstrating how to configure and use the new ImageEditor component, including customization of sources, crop settings, and brush properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Aggregating Scatter Plot Values with Quantitative X-Axis Binning in Python\nDESCRIPTION: Shows how to aggregate data in a `gr.ScatterPlot` when the x-axis is numeric. The `x_bin` argument creates histogram-style bins, and `y_aggregate` specifies the aggregation method (e.g., 'mean', 'count'). Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_aggregate_quantitative\n```\n\n----------------------------------------\n\nTITLE: Connecting with Status Event Monitoring in TypeScript\nDESCRIPTION: Shows how to instantiate a Gradio client with event options to monitor job status. The client connects to a specific model and listens for both status and data events.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"abidlabs/en2fr\", {\n\tevents: [\"status\", \"data\"]\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio ScatterPlot with Nominal Color Series\nDESCRIPTION: Creates a Gradio application that displays a scatter plot of weight vs height data, with ethnicity used as a categorical color dimension. The example loads data from an external file and launches a web interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_nominal/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.ScatterPlot(df, x=\"weight\", y=\"height\", color=\"ethnicity\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building an Image Generation Demo with Gradio Blocks in Python\nDESCRIPTION: This comprehensive snippet defines and launches a Gradio Blocks-based app for generating and displaying images based on user-provided prompts. It uses Gradio, Pillow, and OS/path utilities to define an 'infer' function that selects and resizes images, sets up input widgets (Textbox, Gallery, Slider), provides example inputs, and manages submission handling and concurrency. Inputs include a text prompt and guidance scale, producing a gallery of images and repeating the prompt. The application requires previous installation of gradio and Pillow and expects the cheetah.jpg and frog.jpg files to be present in the script's directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sub_block_render/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\nfrom pathlib import Path\n\nfrom PIL import Image\n\nroot = Path(os.path.abspath(''))\n\ndef infer(\n    text,\n    guidance_scale,\n):\n\n    img = (\n        Image.open(root / \"cheetah.jpg\")\n        if text == \"Cheetah\"\n        else Image.open(root / \"frog.jpg\")\n    )\n    img = img.resize((224, 224))\n\n    return ([img, img, img, img], \"image\")\n\nblock = gr.Blocks()\n\nexamples = [\n    [\"A serious capybara at work, wearing a suit\", 7],\n    [\"A Squirtle fine dining with a view to the London Eye\", 7],\n    [\"A tamale food cart in front of a Japanese Castle\", 7],\n    [\"a graffiti of a robot serving meals to people\", 7],\n    [\"a beautiful cabin in Attersee, Austria, 3d animation style\", 7],\n]\n\nwith block as demo:\n    with gr.Row(elem_id=\"prompt-container\", equal_height=True):\n        text = gr.Textbox(\n            label=\"Enter your prompt\",\n            show_label=False,\n            max_lines=1,\n            placeholder=\"Enter your prompt\",\n            elem_id=\"prompt-text-input\",\n        )\n\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\", rows=2, columns=2\n    )\n    out_txt = gr.Textbox(\n        label=\"Prompt\",\n        placeholder=\"Enter a prompt to generate an image\",\n        lines=3,\n        elem_id=\"prompt-text-input\",\n    )\n\n    guidance_scale = gr.Slider(\n        label=\"Guidance Scale\", minimum=0, maximum=50, value=7.5, step=0.1\n    )\n\n    ex = gr.Examples(\n        examples=examples,\n        fn=infer,\n        inputs=[text, guidance_scale],\n        outputs=[gallery, out_txt],\n        cache_examples=True,\n    )\n\n    text.submit(\n        infer,\n        inputs=[text, guidance_scale],\n        outputs=[gallery, out_txt],\n        concurrency_id=\"infer\",\n        concurrency_limit=8,\n    )\n\nwith gr.Blocks() as demo:\n    block.render()\n\nif __name__ == \"__main__\":\n    demo.queue(max_size=10, api_open=False).launch(show_api=False)\n\n```\n\n----------------------------------------\n\nTITLE: Creating Bar Plot with Gradio\nDESCRIPTION: Creates a simple bar plot visualization using Gradio's BarPlot component. Uses a Pandas DataFrame with inventory data and displays it as a bar chart with item names on x-axis and inventory counts on y-axis.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/barplot_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\n\nsimple = pd.DataFrame(\n    {\n        \"item\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"],\n        \"inventory\": [28, 55, 43, 91, 81, 53, 19, 87, 52],\n    }\n)\n\nwith gr.Blocks() as demo:\n    gr.BarPlot(\n        value=simple,\n        x=\"item\",\n        y=\"inventory\",\n        title=\"Simple Bar Plot\",\n        container=False,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing BrowserState Component in Gradio Blocks\nDESCRIPTION: Creates a minimal Gradio Blocks application that includes the BrowserState component. This component allows tracking of browser state within Gradio applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/browser_state_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.BrowserState()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Auto-Refreshing Gradio DataFrame Dashboard in Python\nDESCRIPTION: Shows how to create a basic Gradio dashboard using `gr.Blocks`. It utilizes the `gr.DataFrame` component to display the output of the `run_query` function. The `every=gr.Timer(60*60)` argument makes the dashboard automatically call `run_query` and refresh the displayed data every hour. The application is launched using `demo.launch()`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_4\n\nLANGUAGE: py\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DataFrame(run_query, every=gr.Timer(60*60))\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Blocks Interface for Greeting Application\nDESCRIPTION: This code creates a Gradio application using the Blocks interface. It sets up input and output text boxes, a greeting button, and defines a function to generate a personalized greeting. The application is launched if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_blocks_decorator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n\n    @greet_btn.click(inputs=name, outputs=output)\n    def greet(name):\n        return \"Hello \" + name + \"!\"\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Using a Theme from Hugging Face Hub in Gradio\nDESCRIPTION: This snippet demonstrates how to load and use a theme from the Hugging Face Hub in a Gradio application using the from_hub method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nmy_theme = gr.Theme.from_hub(\"gradio/seafoam\")\n\nwith gr.Blocks(theme=my_theme) as demo:\n    ....\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseExample component, including options for value, type (gallery or table), selection state, HTML sanitization, line breaks, and LaTeX delimiters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\nexport let sanitize_html: boolean;\nexport let line_breaks: boolean;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[];\n```\n\n----------------------------------------\n\nTITLE: Implementing Lazy Loading for Component Variants in Gradio\nDESCRIPTION: Implements lazy loading for interactive or static variants of components individually, improving performance for many applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#5215](https://github.com/gradio-app/gradio/pull/5215) [`fbdad78a`](https://github.com/gradio-app/gradio/commit/fbdad78af4c47454cbb570f88cc14bf4479bbceb) - Lazy load interactive or static variants of a component individually, rather than loading both variants regardless. This change will improve performance for many applications. Thanks [@pngwn](https://github.com/pngwn)!\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for UniSpeech-SAT Speaker Verification\nDESCRIPTION: This snippet installs the required packages for the demo, including Gradio, Transformers, and Torchaudio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unispeech-speaker-verification/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio git+https://github.com/huggingface/transformers torchaudio\n```\n\n----------------------------------------\n\nTITLE: Creating Calculator UI with Gradio Blocks\nDESCRIPTION: Implements a calculator interface using Gradio Blocks with two number inputs (a and b), addition and subtraction buttons, and an output field. Shows two different ways of handling inputs - using lists and dictionaries for the click events.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_list_and_dict/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    a = gr.Number(label=\"a\")\n    b = gr.Number(label=\"b\")\n    with gr.Row():\n        add_btn = gr.Button(\"Add\")\n        sub_btn = gr.Button(\"Subtract\")\n    c = gr.Number(label=\"sum\")\n\n    def add(num1, num2):\n        return num1 + num2\n    add_btn.click(add, inputs=[a, b], outputs=c)\n\n    def sub(data):\n        return data[a] - data[b]\n    sub_btn.click(sub, inputs={a, b}, outputs=c)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Client - Bash\nDESCRIPTION: Command to install the gradio_client package using pip. Requires Python 3.10 or higher.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install --upgrade gradio_client\n```\n\n----------------------------------------\n\nTITLE: Returning Multiple Output Values as a List in Gradio Python\nDESCRIPTION: Shows how a Gradio event listener function (`eat`) in Python can update multiple output components (`food_box`, `status_box`) by returning a list or tuple of values. The order of returned values (`food - 1`, `\"full\"`) corresponds to the order of components specified in the `outputs` list (`[food_box, status_box]`) of the `.click()` listener.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    food_box = gr.Number(value=10, label=\"Food Count\")\n    status_box = gr.Textbox()\n\n    def eat(food):\n        if food > 0:\n            return food - 1, \"full\"\n        else:\n            return 0, \"hungry\"\n\n    gr.Button(\"Eat\").click(\n        fn=eat,\n        inputs=food_box,\n        outputs=[food_box, status_box]\n    )\n```\n\n----------------------------------------\n\nTITLE: Integrating Gradio Demo with W&B Dashboard\nDESCRIPTION: Simple code to integrate the Gradio demo with Weights & Biases dashboard. This allows the interactive demo to be embedded directly in W&B reports.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndemo.integrate(wandb=wandb)\n```\n\n----------------------------------------\n\nTITLE: Installing TailwindCSS for Gradio Components\nDESCRIPTION: Command to install TailwindCSS and its Vite plugin for use with Gradio custom components. This uses the prerelease version 4 of TailwindCSS.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nnpm install tailwindcss@next @tailwindcss/vite@next\n```\n\n----------------------------------------\n\nTITLE: Interactive Line Plot Demo with Gradio\nDESCRIPTION: Creates an interactive dashboard with multiple line plots using Gradio. Features include time series visualization of temperature data with grouping and aggregation controls, and food rating analysis with price comparisons across cuisines. The code demonstrates data preparation, UI layout creation, and event handling for plot interactions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot_demo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nfrom random import randint, random\nimport gradio as gr\n\n\ntemp_sensor_data = pd.DataFrame(\n    {\n        \"time\": pd.date_range(\"2021-01-01\", end=\"2021-01-05\", periods=200),\n        \"temperature\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"humidity\": [randint(50 + 10 * (i % 2), 65 + 15 * (i % 2)) for i in range(200)],\n        \"location\": [\"indoor\", \"outdoor\"] * 100,\n    }\n)\n\nfood_rating_data = pd.DataFrame(\n    {\n        \"cuisine\": [[\"Italian\", \"Mexican\", \"Chinese\"][i % 3] for i in range(100)],\n        \"rating\": [random() * 4 + 0.5 * (i % 3) for i in range(100)],\n        \"price\": [randint(10, 50) + 4 * (i % 3) for i in range(100)],\n        \"wait\": [random() for i in range(100)],\n    }\n)\n\nwith gr.Blocks() as line_plots:\n    with gr.Row():\n        start = gr.DateTime(\"2021-01-01 00:00:00\", label=\"Start\")\n        end = gr.DateTime(\"2021-01-05 00:00:00\", label=\"End\")\n        apply_btn = gr.Button(\"Apply\", scale=0)\n    with gr.Row():\n        group_by = gr.Radio([\"None\", \"30m\", \"1h\", \"4h\", \"1d\"], value=\"None\", label=\"Group by\")\n        aggregate = gr.Radio([\"sum\", \"mean\", \"median\", \"min\", \"max\"], value=\"sum\", label=\"Aggregation\")\n\n    temp_by_time = gr.LinePlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n    )\n    temp_by_time_location = gr.LinePlot(\n        temp_sensor_data,\n        x=\"time\",\n        y=\"temperature\",\n        color=\"location\",\n    )\n\n    time_graphs = [temp_by_time, temp_by_time_location]\n    group_by.change(\n        lambda group: [gr.LinePlot(x_bin=None if group == \"None\" else group)] * len(time_graphs),\n        group_by,\n        time_graphs\n    )\n    aggregate.change(\n        lambda aggregate: [gr.LinePlot(y_aggregate=aggregate)] * len(time_graphs),\n        aggregate,\n        time_graphs\n    )\n\n    def rescale(select: gr.SelectData):\n        return select.index\n    rescale_evt = gr.on([plot.select for plot in time_graphs], rescale, None, [start, end])\n\n    for trigger in [apply_btn.click, rescale_evt.then]:\n        trigger(\n            lambda start, end: [gr.LinePlot(x_lim=[start, end])] * len(time_graphs), [start, end], time_graphs\n        )\n\n    price_by_cuisine = gr.LinePlot(\n        food_rating_data,\n        x=\"cuisine\",\n        y=\"price\",\n    )\n    with gr.Row():\n        price_by_rating = gr.LinePlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n        )\n        price_by_rating_color = gr.LinePlot(\n            food_rating_data,\n            x=\"rating\",\n            y=\"price\",\n            color=\"cuisine\",\n            color_map={\"Italian\": \"red\", \"Mexican\": \"green\", \"Chinese\": \"blue\"},\n        )\n\nif __name__ == \"__main__\":\n    line_plots.launch()\n```\n\n----------------------------------------\n\nTITLE: TypeScript Client Predict Example\nDESCRIPTION: Example showing how to use the predict method with the TypeScript/JavaScript client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"http://127.0.0.1:7860/\");\nconst result = await client.predict(\"/chat\", { \t\t\n\t\tmessage: \"Hello!!\", \t\t\n\t\tsystem_prompt: \"Hello!!\", \t\t\n\t\ttokens: 10, \n});\n\nconsole.log(result.data);\n```\n\n----------------------------------------\n\nTITLE: Parallel WebSocket Test with 250 Workers\nDESCRIPTION: Runs WebSocket requests in parallel with 250 workers and calculates average duration and message count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\noutput = run_in_parallel(request, 250)\navg_duration = sum(o[0] for o in output) / len(output)\navg_msg = sum(o[1] for o in output) / len(output)\nprint(avg_duration, avg_msg)\n```\n\n----------------------------------------\n\nTITLE: NPM Package Installation Command\nDESCRIPTION: Command to install the Gradio client package via npm for Node.js projects version 18.0.0 or higher.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm i @gradio/client\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits with Gradio Interface (Python)\nDESCRIPTION: Demonstrates how to use the new max_file_size parameter in gr.Interface.launch() to restrict the size of files users can upload. This snippet requires the gradio Python package and introduces both string ('5mb') and computed (5 * gr.FileSize.MB) methods for file size specification. The main input/output is an image, and the upload size limit applies per file; files exceeding the specified size will be rejected.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n\n```\n\n----------------------------------------\n\nTITLE: Extending Gradio Theme via .set() for CSS Variable Overrides - Python\nDESCRIPTION: Demonstrates post-constructor customization of a Gradio theme by overriding specific CSS variables with the .set() method. In this example, loader_color and slider_color are both set to red (#FF0000), irrespective of the theme's palette. The theme is then applied to a Gradio Blocks interface. This method allows for fine-grained adjustments of CSS variables after initial theme instantiation. Requires Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default(primary_hue=\\\"blue\\\").set(\n    loader_color=\\\"#FF0000\\\",\n    slider_color=\\\"#FF0000\\\",\n)\n\nwith gr.Blocks(theme=theme) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Basic Multipage Gradio App Structure\nDESCRIPTION: Demonstrates the basic structure of a multipage Gradio application using Blocks.route(). Shows how to create a new page with a separate URL route.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/09_multipage-apps.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    ...\nwith demo.route(\"Test\", \"/test\"):\n    num = gr.Number()\n    ...\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Parallel WebSocket Test with 5 Workers\nDESCRIPTION: Runs WebSocket requests in parallel with 5 workers and calculates average duration and message count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\noutput = run_in_parallel(request, 5)\navg_duration = sum(o[0] for o in output) / len(output)\navg_msg = sum(o[1] for o in output) / len(output)\nprint(avg_duration, avg_msg)\n```\n\n----------------------------------------\n\nTITLE: Implementing Todo List Application with Gradio\nDESCRIPTION: This code creates a Gradio interface for a todo list application. It allows adding new tasks, marking tasks as complete, and deleting tasks. The interface dynamically updates to show incomplete and complete tasks separately.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/todo_list/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n\n    tasks = gr.State([])\n    new_task = gr.Textbox(label=\"Task Name\", autofocus=True)\n\n    def add_task(tasks, new_task_name):\n        return tasks + [{\"name\": new_task_name, \"complete\": False}], \"\"\n\n    new_task.submit(add_task, [tasks, new_task], [tasks, new_task])\n\n    @gr.render(inputs=tasks)\n    def render_todos(task_list):\n        complete = [task for task in task_list if task[\"complete\"]]\n        incomplete = [task for task in task_list if not task[\"complete\"]]\n        gr.Markdown(f\"### Incomplete Tasks ({len(incomplete)})\")\n        for task in incomplete:\n            with gr.Row():\n                gr.Textbox(task['name'], show_label=False, container=False)\n                done_btn = gr.Button(\"Done\", scale=0)\n                def mark_done(task=task):\n                    task[\"complete\"] = True\n                    return task_list\n                done_btn.click(mark_done, None, [tasks])\n\n                delete_btn = gr.Button(\"Delete\", scale=0, variant=\"stop\")\n                def delete(task=task):\n                    task_list.remove(task)\n                    return task_list\n                delete_btn.click(delete, None, [tasks])\n\n        gr.Markdown(f\"### Complete Tasks ({len(complete)})\")\n        for task in complete:\n            gr.Textbox(task['name'], show_label=False, container=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Launching the Theme Builder Tool - Gradio - Python\nDESCRIPTION: Shows how to launch the Theme Builder locally using Gradio\\'s API in Python. Requires importing Gradio as 'gr'. The 'gr.themes.builder()' method launches the theme builder UI, enabling users to interactively design custom themes. No parameters are required. The main output is a running theme builder app in the local environment. Dependencies: Gradio installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ngr.themes.builder()\n\n```\n\n----------------------------------------\n\nTITLE: Setting Theme with Gradio Block\nDESCRIPTION: Shows how to apply a pre-built Soft theme to a Gradio Block context using the theme parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/12_themes.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Block(theme=gr.themes.Soft()):\n    ...\n```\n\n----------------------------------------\n\nTITLE: Setting Interactivity Property on Gradio DataFrame - Python\nDESCRIPTION: This code demonstrates explicitly disabling the interactive mode of a Gradio DataFrame to ensure custom styling is applied. This is essential because Gradio ignores custom styling arrays if the component is interactive. The main parameter is 'interactive', which is set to False. Input: any styled object or data; output: a statically rendered DataFrame with custom formatting or visual effects. Dependencies: gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nc = gr.DataFrame(styler, interactive=False)\n```\n\n----------------------------------------\n\nTITLE: Defining BaseUploadButton Properties in Gradio (JavaScript)\nDESCRIPTION: Outlines the configurable properties and type annotations for the BaseUploadButton component. Dependencies include a compatible TypeScript/JavaScript environment that supports type annotations, and potentially FileData types from Gradio. Key parameters include the element ID, CSS classes, label, value (file(s)), supported file types, UI display options (e.g., size, variant), and control flags such as visibility and disabled. Inputs include user-selected files, and outputs would be emitted via Svelte component events. Constraints include correct type assignments and enums for specific properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let elem_id = \"\";\\n\texport let elem_classes: string[] = [];\\n\texport let visible = true;\\n\texport let label: string;\\n\texport let value: null | FileData | FileData[];\\n\texport let file_count: string;\\n\texport let file_types: string[] = [];\\n\texport let root: string;\\n\texport let size: \"sm\" | \"lg\" = \"lg\";\\n\texport let scale: number | null = null;\\n\texport let min_width: number | undefined = undefined;\\n\texport let variant: \"primary\" | \"secondary\" | \"stop\" = \"secondary\";\\n\texport let disabled = false;\n```\n\n----------------------------------------\n\nTITLE: Updating Prediction Function to Accept Number of Punks in Python\nDESCRIPTION: Modifies the `predict` function to accept a second parameter, `num_punks`, alongside the `seed`. This allows the function to generate a variable number of images based on user input from the enhanced Gradio interface. The `num_punks` value is used to determine the batch size of the noise tensor `z` passed to the GAN model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef predict(seed, num_punks):\n    torch.manual_seed(seed)\n    z = torch.randn(num_punks, 100, 1, 1)\n    punks = model(z)\n    save_image(punks, \"punks.png\", normalize=True)\n    return 'punks.png'\n```\n\n----------------------------------------\n\nTITLE: Monitoring Job Status Events in JavaScript\nDESCRIPTION: Demonstrates how to log status updates for a Gradio job. The code connects to a translation model, submits a job, and then processes status messages as they arrive.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_8\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nfunction log_status(status) {\n\tconsole.log(\n\t\t`The current status for this job is: ${JSON.stringify(status, null, 2)}.`\n\t);\n}\n\nconst app = await Client.connect(\"abidlabs/en2fr\", {\n\tevents: [\"status\", \"data\"]\n});\nconst job = app.submit(\"/predict\", [\"Hello\"]);\n\nfor await (const message of job) {\n\tif (message.type === \"status\") {\n\t\tlog_status(message);\n\t}\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface with Textbox and Number Inputs in Python\nDESCRIPTION: This code defines a greeting function and creates a Gradio interface with a textbox (limited to 2-4 lines) and a number input. The output is displayed in a textarea. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_textbox_max_lines/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name: str, repeat: float):\n    return \"Hello \" + name * int(repeat) + \"!!\"\n\ndemo = gr.Interface(\n    fn=greet, inputs=[gr.Textbox(lines=2, max_lines=4), gr.Number()], outputs=\"textarea\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Random Response Chatbot Implementation\nDESCRIPTION: Simple chatbot function that randomly responds with Yes or No, including the interface setup\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\nimport gradio as gr\n\ngr.ChatInterface(\n    fn=random_response, \n    type=\"messages\"\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Processing Whisper Transcription Results for Voice Detection - Python\nDESCRIPTION: This function analyzes the Whisper model transcription response to determine if meaningful speech was detected based on a 'no_speech_prob' threshold. If actual speech is present (probability <= 0.7), it returns the stripped text; otherwise, it returns None. Requires a properly structured Whisper response object and expects segments with 'no_speech_prob' values. Limitation: if the response format is not as expected, output will always be None.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef process_whisper_response(completion):\n    \"\"\"\n    Process Whisper transcription response and return text or null based on no_speech_prob\n    \n    Args:\n        completion: Whisper transcription response object\n        \n    Returns:\n        str or None: Transcribed text if no_speech_prob <= 0.7, otherwise None\n    \"\"\"\n    if completion.segments and len(completion.segments) > 0:\n        no_speech_prob = completion.segments[0].get('no_speech_prob', 0)\n        print(\"No speech prob:\", no_speech_prob)\n\n        if no_speech_prob > 0.7:\n            return None\n            \n        return completion.text.strip()\n    \n    return None\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Image Interface\nDESCRIPTION: Creates a Gradio interface with image input and output components. The interface allows users to select an image and display it using a button trigger. Uses Gradio's Blocks API for layout and interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image-simple/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef image(im):\n    return im\n\nwith gr.Blocks() as demo:\n    im = gr.Image()\n    im2 = gr.Image()\n    btn = gr.Button()\n    btn.click(lambda x: x, outputs=im2, inputs=im)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for PyPi Stats and Prophet Forecasting\nDESCRIPTION: This snippet installs the necessary Python packages for the Gradio demo, including gradio, holidays, prophet, pandas, pypistats, and plotly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timeseries-forecasting-with-prophet/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio holidays==0.24 prophet==1.1.2 pandas pypistats plotly\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic Textbox Interface with Gradio Blocks\nDESCRIPTION: Builds a Gradio interface that dynamically changes a textbox based on user selection from a radio button. The textbox can be short (2 lines), long (8 lines with preset text), or hidden entirely depending on the user's choice.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_essay_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef change_textbox(choice):\n    if choice == \"short\":\n        return gr.Textbox(lines=2, visible=True)\n    elif choice == \"long\":\n        return gr.Textbox(lines=8, visible=True, value=\"Lorem ipsum dolor sit amet\")\n    else:\n        return gr.Textbox(visible=False)\n\nwith gr.Blocks() as demo:\n    radio = gr.Radio(\n        [\"short\", \"long\", \"none\"], label=\"What kind of essay would you like to write?\"\n    )\n    text = gr.Textbox(lines=2, interactive=True, show_copy_button=True)\n    radio.change(fn=change_textbox, inputs=radio, outputs=text)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Basic Client-Side Row Hiding in Gradio\nDESCRIPTION: Demonstrates a simple client-side function that hides a row in the UI without server roundtrip using js=True flag. The function updates the visibility property of a Row component when a button is clicked.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/13_client-side-functions.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row() as row:\n        btn = gr.Button(\"Hide this row\")\n    \n    # This function runs in the browser without a server roundtrip\n    btn.click(\n        lambda: gr.Row(visible=False), \n        None, \n        row, \n        js=True\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Tabbed Interface with DataFrame\nDESCRIPTION: Creates a Gradio interface with two tabs - one containing HTML content and another displaying a DataFrame with sequential numbers. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_tab/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Tab():\n        gr.HTML(\"<p>hi</p>\")\n    with gr.Tab():\n        gr.Dataframe(\n            value=[[i + 1] for i in range(10)],\n        )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Size Limits in Gradio Python API\nDESCRIPTION: Demonstrates how to set maximum file size limits for file uploads using the launch() method. The limit can be specified either as a string (e.g. '5mb') or as an integer number of bytes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Importing Audio Components in Svelte\nDESCRIPTION: Imports the base audio components from the @gradio/audio package for use in Svelte components. These include components for static audio display, interactive audio recording/uploading, audio playback, and example handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/audio/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { BaseStaticAudio, BaseInteractiveAudio, BasePlayer, BaseExample } from \"@gradio/audio\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Configuring Event Types for Gradio Client\nDESCRIPTION: Example showing how to specify which event types to listen for when instantiating the Gradio client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\", {\n\tevents: [\"data\", \"status\"]\n});\n```\n\n----------------------------------------\n\nTITLE: Implementing Streaming Speech Recognition\nDESCRIPTION: Referenced but not shown in text. Creates a streaming ASR interface with state management for continuous audio processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/05_real-time-speech-recognition.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# Code referenced as $code_stream_asr but not provided in the text\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Client for Music Separation\nDESCRIPTION: Basic setup of Gradio client to connect to a music separation model and process audio files\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client, handle_file\n\nclient = Client(\"abidlabs/music-separation\")\n\ndef acapellify(audio_path):\n    result = client.predict(handle_file(audio_path), api_name=\"/predict\")\n    return result[0]\n```\n\n----------------------------------------\n\nTITLE: Duplicating a Space for Private Use\nDESCRIPTION: Demonstrates using the Client.duplicate() method to create a private copy of a public Space for unlimited usage without rate limiting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client.duplicate(\"abidlabs/whisper\")\nclient.predict(\"audio_sample.wav\")\n\n>> \"This is a test of the whisper speech recognition model.\"\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio JavaScript Client via npm\nDESCRIPTION: Instructions for installing the Gradio JavaScript client package from npm using the command line.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\nnpm i @gradio/client\n```\n\n----------------------------------------\n\nTITLE: Valid Client-Side Property Updates in Gradio\nDESCRIPTION: Shows various examples of valid client-side functions that can work with js=True flag. Includes examples of simple property updates, multiple component updates, and using gr.update() for property changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/13_client-side-functions.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Simple property updates\nlambda: gr.Textbox(lines=4)\n\n# Multiple component updates\nlambda: [gr.Textbox(lines=4), gr.Button(interactive=False)]\n\n# Using gr.update() for property changes\nlambda: gr.update(visible=True, interactive=False)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Image Segmentation in Python\nDESCRIPTION: This code creates a Gradio interface for the image segmentation demo. It sets up input and output components, specifies the segmentation function, and launches the interface. The demo allows users to upload an image and view the segmentation result.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/gradio/test_data/flagged_no_log/a.txt#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndemo = gr.Interface(\n    segment,\n    gr.Image(type=\"pil\"),\n    gr.Image(type=\"numpy\", plot=True),\n    examples=[\"images/cheetah1.jpg\"],\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Displaying CSV Content for Calculator Interface Flagging\nDESCRIPTION: Demonstrates the content of the logs.csv file created when flagging occurs in a calculator interface. It shows the structure of logged data including input parameters and output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/02_flagging.md#2025-04-23_snippet_1\n\nLANGUAGE: csv\nCODE:\n```\nnum1,operation,num2,Output\n5,add,7,12\n6,subtract,1.5,4.5\n```\n\n----------------------------------------\n\nTITLE: Building an Animal Generator with Dynamic UI Updates in Gradio\nDESCRIPTION: Creates an interactive Animal Generator application using Gradio Blocks. The interface dynamically updates based on user selections, including showing/hiding components, filtering options, and adjusting UI element properties based on the selected animal.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_update/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\n        \"\"\"\n    # Animal Generator\n    Once you select a species, the detail panel should be visible.\n    \"\"\"\n    )\n\n    species = gr.Radio(label=\"Animal Class\", choices=[\"Mammal\", \"Fish\", \"Bird\"])\n    animal = gr.Dropdown(label=\"Animal\", choices=[])\n\n    with gr.Column(visible=False) as details_col:\n        weight = gr.Slider(0, 20)\n        details = gr.Textbox(label=\"Extra Details\")\n        generate_btn = gr.Button(\"Generate\")\n        output = gr.Textbox(label=\"Output\")\n\n    species_map = {\n        \"Mammal\": [\"Elephant\", \"Giraffe\", \"Hamster\"],\n        \"Fish\": [\"Shark\", \"Salmon\", \"Tuna\"],\n        \"Bird\": [\"Chicken\", \"Eagle\", \"Hawk\"],\n    }\n\n    def filter_species(species):\n        return gr.Dropdown(\n            choices=species_map[species], value=species_map[species][1]\n        ), gr.Column(visible=True)\n\n    species.change(filter_species, species, [animal, details_col])\n\n    def filter_weight(animal):\n        if animal in (\"Elephant\", \"Shark\", \"Giraffe\"):\n            return gr.Slider(maximum=100)\n        else:\n            return gr.Slider(maximum=20)\n\n    animal.change(filter_weight, animal, weight)\n    weight.change(lambda w: gr.Textbox(lines=int(w / 10) + 1), weight, details)\n\n    generate_btn.click(lambda x: x, details, output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Greeting and Temperature Conversion\nDESCRIPTION: Defines a greeting function that takes a name, time of day, and temperature as inputs. It then creates a Gradio interface for this function with text, checkbox, and slider inputs, and text and number outputs. The interface is launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_3/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name, is_morning, temperature):\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n    celsius = (temperature - 32) * 5 / 9\n    return greeting, round(celsius, 2)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n    outputs=[\"text\", \"number\"],\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Streaming from Gradio App in Python\nDESCRIPTION: Example showing how to stream results from a Gradio app using the Python client's submit method\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/llm_stream\")\n\nfor result in client.submit(\"What's the best UI framework in Python?\"):\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Gradio Theme and Demo Application\nDESCRIPTION: This code defines a custom 'Seafoam' theme class extending Gradio's Base theme, and creates a demo application using this theme. The demo includes a text input, slider, buttons for submission and clearing, and an output display. It also implements a simple function to repeat the input text based on the slider value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_3/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\nfrom typing import Iterable\nimport gradio as gr\nfrom gradio.themes.base import Base\nfrom gradio.themes.utils import colors, fonts, sizes\nimport time\n\nclass Seafoam(Base):\n    def __init__(\n        self,\n        *,\n        primary_hue: colors.Color | str = colors.emerald,\n        secondary_hue: colors.Color | str = colors.blue,\n        neutral_hue: colors.Color | str = colors.blue,\n        spacing_size: sizes.Size | str = sizes.spacing_md,\n        radius_size: sizes.Size | str = sizes.radius_md,\n        text_size: sizes.Size | str = sizes.text_lg,\n        font: fonts.Font\n        | str\n        | Iterable[fonts.Font | str] = (\n            fonts.GoogleFont(\"Quicksand\"),\n            \"ui-sans-serif\",\n            \"sans-serif\",\n        ),\n        font_mono: fonts.Font\n        | str\n        | Iterable[fonts.Font | str] = (\n            fonts.GoogleFont(\"IBM Plex Mono\"),\n            \"ui-monospace\",\n            \"monospace\",\n        ),\n    ):\n        super().__init__(\n            primary_hue=primary_hue,\n            secondary_hue=secondary_hue,\n            neutral_hue=neutral_hue,\n            spacing_size=spacing_size,\n            radius_size=radius_size,\n            text_size=text_size,\n            font=font,\n            font_mono=font_mono,\n        )\n        super().set(\n            body_background_fill=\"repeating-linear-gradient(45deg, *primary_200, *primary_200 10px, *primary_50 10px, *primary_50 20px)\",\n            body_background_fill_dark=\"repeating-linear-gradient(45deg, *primary_800, *primary_800 10px, *primary_900 10px, *primary_900 20px)\",\n            button_primary_background_fill=\"linear-gradient(90deg, *primary_300, *secondary_400)\",\n            button_primary_background_fill_hover=\"linear-gradient(90deg, *primary_200, *secondary_300)\",\n            button_primary_text_color=\"white\",\n            button_primary_background_fill_dark=\"linear-gradient(90deg, *primary_600, *secondary_800)\",\n            slider_color=\"*secondary_300\",\n            slider_color_dark=\"*secondary_600\",\n            block_title_text_weight=\"600\",\n            block_border_width=\"3px\",\n            block_shadow=\"*shadow_drop_lg\",\n            button_primary_shadow=\"*shadow_drop_lg\",\n            button_large_padding=\"32px\",\n        )\n\nseafoam = Seafoam()\n\nwith gr.Blocks(theme=seafoam) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Building an Enhanced Real-Time Gradio Dashboard with DataFrame and Scatter Plot in Python\nDESCRIPTION: Demonstrates constructing a more comprehensive Gradio dashboard for displaying BigQuery results. It uses `gr.Blocks` and `gr.Row` for layout, includes a title with `gr.Markdown`, displays raw data using `gr.DataFrame`, and visualizes cases vs. deaths with `gr.ScatterPlot`. Both the DataFrame and ScatterPlot use the `run_query` function as their data source and are configured to refresh automatically every hour using `every=gr.Timer(60*60)`. Queuing is enabled with `demo.queue().launch()` for better handling of concurrent users or long-running queries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_5\n\nLANGUAGE: py\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# \\U0001f489 Covid Dashboard (Updated Hourly)\")\n    with gr.Row():\n        gr.DataFrame(run_query, every=gr.Timer(60*60))\n        gr.ScatterPlot(run_query, every=gr.Timer(60*60), x=\"confirmed_cases\",\n                        y=\"deaths\", tooltip=\"county\", width=500, height=500)\n\ndemo.queue().launch()  # Run the demo with queuing enabled\n```\n\n----------------------------------------\n\nTITLE: Python Client Predict Example\nDESCRIPTION: Example demonstrating how to use keyword arguments with the Python client's predict method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"http://127.0.0.1:7860/\")\nresult = client.predict(\n\t\tmessage=\"Hello!!\",\n\t\tsystem_prompt=\"You are helpful AI.\",\n\t\ttokens=10,\n\t\tapi_name=\"/chat\"\n)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Event Handling with Iterative Endpoints\nDESCRIPTION: Example showing how to handle events and process multiple responses from iterative endpoints.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nfunction log_result(payload) {\n\tconst {\n\t\tdata: [translation]\n\t} = payload;\n\n\tconsole.log(`The translated result is: ${translation}`);\n}\n\nconst app = await Client.connect(\"abidlabs/en2fr\");\nconst job = app.submit(\"/predict\", [\"Hello\"]);\n\nfor await (const message of job) {\n\tlog_result(message);\n}\n```\n\n----------------------------------------\n\nTITLE: Checking File Existence in Python\nDESCRIPTION: This function checks if a file exists at the given path. It returns a boolean value indicating the file's existence.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir3/dir4/dir5/dir5_foo.txt#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef file_exists(file_path):\n    return os.path.exists(file_path)\n```\n\n----------------------------------------\n\nTITLE: File Handling in Python Client\nDESCRIPTION: Example showing how to handle file uploads in the Python client using handle_file\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client, handle_file\n\nclient = Client(\"gradio/image_captioner\")\nclient.predict(handle_file(\"cute_cat.jpg\"))\n```\n\n----------------------------------------\n\nTITLE: Using a Custom Function for Gradio Authentication in Python\nDESCRIPTION: Illustrates using a custom Python function to handle authentication logic in a Gradio app. The function (`same_auth`) receives username and password, returning `True` for successful authentication (in this case, if username equals password). This function is passed to the `auth` parameter of the `launch()` method. Assumes `demo` is a pre-defined Gradio app instance. Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ndef same_auth(username, password):\n    return username == password\ndemo.launch(auth=same_auth)\n```\n\n----------------------------------------\n\nTITLE: Launching the Gradio Application (Python)\nDESCRIPTION: Standard Python entry point pattern. This block checks if the script is being run directly (not imported as a module) and, if so, launches the Gradio interface defined earlier in the `demo` variable using the `demo.launch()` method. This makes the Gradio application accessible via a web browser.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_change/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Required Structure for `demo/app.py` Launch Command (Python)\nDESCRIPTION: Shows the mandatory structure for the `demo/app.py` file, which is used by the documentation generator to create a live demo and code snippet. The `demo.launch()` call must be enclosed within an `if __name__ == \"__main__\":` conditional block. This prevents the demo from launching when the file is imported by the documentation tool and allows the tool to correctly identify and potentially execute the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_7\n\nLANGUAGE: py\nCODE:\n```\nif __name__ == \"__main__\":\n  demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio File Components in Svelte (HTML)\nDESCRIPTION: Imports key file-related components (BaseFile, BaseFileUpload, FilePreview, BaseExample) from the @gradio/file package for use within a Svelte application. This snippet is required to enable the use of these components elsewhere, serving as the foundational import logic. No direct inputs or outputs, but enables further file management capabilities in downstream code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n\\timport { BaseFile, BaseFileUpload, FilePreview, BaseExample } from \"@gradio/file\";\\n<\\/script>\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Undo Event Handler in Gradio Chatbot\nDESCRIPTION: Adds undo functionality to the chatbot that restores previous user messages and removes subsequent responses using gr.UndoData.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef handle_undo(history, undo_data: gr.UndoData):\n    return history[:undo_data.index], history[undo_data.index]['content']\n\nchatbot.undo(handle_undo, chatbot, [chatbot, prompt])\n```\n\n----------------------------------------\n\nTITLE: Implementing Score Tracker Application with Gradio\nDESCRIPTION: Creates a Gradio application that tracks user-submitted scores and displays the top three highest scores. The application uses a Number input component for score submission and a JSON output component to display the results.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/score_tracker/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nscores = []\n\ndef track_score(score):\n    scores.append(score)\n    top_scores = sorted(scores, reverse=True)[:3]\n    return top_scores\n\ndemo = gr.Interface(\n    track_score,\n    gr.Number(label=\"Score\"),\n    gr.JSON(label=\"Top Scores\")\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Illustrating Default Gradio Component Rendering Python\nDESCRIPTION: Demonstrates the standard way Gradio components are rendered within a layout using the `with` statement. When `Textbox` instances are created within the `Row()` context, their `render` methods are implicitly called due to the default `render=True` parameter in Gradio blocks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nwith Row():\n    left_textbox = Textbox(value=\"left_textbox\")\n    right_textbox = Textbox(value=\"right_textbox\")\n```\n\n----------------------------------------\n\nTITLE: Processing Submission Events with Gradio Client\nDESCRIPTION: Example demonstrating how to process both data and status events during a submission using async iterators.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_12\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst submission = app\n\t.submit(\"/predict\", { name: \"Chewbacca\" })\n\n\tfor await (const msg of submission) {\n\t\tif (msg.type === \"data\") {\n\t\t\tconsole.log(msg.data);\n\t\t}\n\n\t\tif (msg.type === \"status\") {\n\t\t\tconsole.log(msg);\n\t\t}\n\t}\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Application with Delayed Response in Python\nDESCRIPTION: This snippet creates a Gradio application with a text input, output, and a button. It defines a function 'say_hello' that introduces a 5-second delay before returning a greeting. The application demonstrates concurrency handling in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/concurrency_with_queue/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef say_hello(name):\n  time.sleep(5)\n  return f\"Hello {name}!\"\n\nwith gr.Blocks() as demo:\n  inp = gr.Textbox()\n  outp = gr.Textbox()\n  button = gr.Button()\n  button.click(say_hello, inp, outp)\n\n  demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio Client Usage - Python\nDESCRIPTION: Simple example of using Gradio client to transcribe audio using a Whisper model Space.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client, handle_file\n\nclient = Client(\"abidlabs/whisper\")\n\nclient.predict(\n    audio=handle_file(\"audio_sample.wav\")\n)\n\n>> \"This is a test of the whisper speech recognition model.\"\n```\n\n----------------------------------------\n\nTITLE: Transformers Agent Setup\nDESCRIPTION: Implementation of a Gradio interface using transformers.agents with a text-to-image tool.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nfrom transformers import Tool, ReactCodeAgent\nfrom transformers.agents import stream_to_gradio, HfApiEngine\n\nimage_generation_tool = Tool.from_space(\n    space_id=\"black-forest-labs/FLUX.1-schnell\",\n    name=\"image_generator\",\n    description=\"Generates an image following your prompt. Returns a PIL Image.\",\n    api_name=\"/infer\",\n)\n\nllm_engine = HfApiEngine(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\nagent = ReactCodeAgent(tools=[image_generation_tool], llm_engine=llm_engine)\n```\n\n----------------------------------------\n\nTITLE: Including Gradio JavaScript Client via CDN\nDESCRIPTION: Example of how to include the Gradio JavaScript client directly in HTML using the jsDelivr CDN.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n<script src=\"https://cdn.jsdelivr.net/npm/@gradio/client/dist/index.min.js\"></script>\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio ImageEditor Interface\nDESCRIPTION: Creates a Gradio interface with an ImageEditor component using the Blocks API. Sets up a basic interface and launches the demo server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/imageeditor_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.ImageEditor()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Handling File Uploads in Gradio Python Client 1.0\nDESCRIPTION: This snippet demonstrates the new way to handle file uploads in Gradio Python Client version 1.0, using the handle_file method to wrap filepaths.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client, handle_file\n\nclient = Client(\"gradio/image_captioner\")\nclient.predict(handle_file(\"cute_cat.jpg\"))\n```\n\n----------------------------------------\n\nTITLE: Basic cURL POST Request to Gradio API\nDESCRIPTION: Shows how to make a basic POST request to translate text from English to French using a Gradio app endpoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST https://abidlabs-en2fr.hf.space/call/predict -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Hello, my friend.\"] \n}'\n\n>> {\"event_id\": $EVENT_ID}\n```\n\n----------------------------------------\n\nTITLE: Making a Prediction with Multiple Parameters\nDESCRIPTION: Demonstrates making a prediction to a calculator app that requires multiple input parameters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/calculator\")\nclient.predict(4, \"add\", 5)\n\n>> 9.0\n```\n\n----------------------------------------\n\nTITLE: Example Component Implementation\nDESCRIPTION: Implementation of Example.svelte showing how to handle example displays in both gallery and table formats.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_3\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n</script>\n\n<div\n\tclass:table={type === \"table\"}\n\tclass:gallery={type === \"gallery\"}\n\tclass:selected\n>\n\t{value}\n</div>\n\n<style>\n\t.gallery {\n\t\tpadding: var(--size-1) var(--size-2);\n\t}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Connecting to Gradio App with JavaScript Client 1.0\nDESCRIPTION: This example shows how to connect to a Gradio app using the redesigned JavaScript client in version 1.0. It uses the new class-based structure and async connect method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconst app = await Client.connect(\"gradio/whisper\")\n```\n\n----------------------------------------\n\nTITLE: Adding Requirements in Gradio-Lite\nDESCRIPTION: This example demonstrates how to include additional Python package requirements in a Gradio-lite app. It uses the <gradio-requirements> tag to specify dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/lite/README.md#2025-04-23_snippet_3\n\nLANGUAGE: HTML\nCODE:\n```\n<gradio-lite>\n\n<gradio-requirements>\ntransformers_js_py\n</gradio-requirements>\n\n<gradio-file name=\"app.py\" entrypoint>\nfrom transformers_js import import_transformers_js\nimport gradio as gr\n\ntransformers = await import_transformers_js()\npipeline = transformers.pipeline\npipe = await pipeline('sentiment-analysis')\n\nasync def classify(text):\n\treturn await pipe(text)\n\ndemo = gr.Interface(classify, \"textbox\", \"json\")\ndemo.launch()\n</gradio-file>\n\n</gradio-lite>\t\n```\n\n----------------------------------------\n\nTITLE: Writing Data to Supabase Table\nDESCRIPTION: Python script to initialize Supabase client and insert random product data into the Product table. Creates 10 sample products with random inventory counts and prices.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-supabase-data.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport supabase\n\n# Initialize the Supabase client\nclient = supabase.create_client('SUPABASE_URL', 'SUPABASE_SECRET_KEY')\n\n# Define the data to write\nimport random\n\nmain_list = []\nfor i in range(10):\n    value = {'product_id': i,\n             'product_name': f\"Item {i}\",\n             'inventory_count': random.randint(1, 100),\n             'price': random.random()*100\n            }\n    main_list.append(value)\n\n# Write the data to the table\ndata = client.table('Product').insert(main_list).execute()\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum File Upload Size in Gradio (Python)\nDESCRIPTION: This Python snippet demonstrates how to configure the maximum allowed size for individual file uploads within a Gradio interface. It utilizes the `max_file_size` parameter in the `launch()` method, showcasing two ways to specify the limit: using a string representation (e.g., \"5mb\") or by performing a calculation with `gr.FileSize.MB`. This functionality requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/utils/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Downloading Data File for Plot Demo\nDESCRIPTION: Downloads the data.py file from the Gradio GitHub repository, which contains the dataset used for the line plot demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_selection/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_selection/data.py\n```\n\n----------------------------------------\n\nTITLE: IconButton Component Props Definition\nDESCRIPTION: Defines the available props for the IconButton component, which displays a button with an icon and optional label, with support for a pending state.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let Icon: any;\n\texport let label = \"\";\n\texport let show_label = false;\n\texport let pending = false;\n```\n\n----------------------------------------\n\nTITLE: Setting Max File Size in Gradio Launch (Python)\nDESCRIPTION: This Python code demonstrates how to set a maximum file size limit for uploads when launching a Gradio application. It initializes a simple interface and uses the `max_file_size` parameter within the `launch()` method, showcasing both string ('5mb') and `gr.FileSize` enum (5 * gr.FileSize.MB) methods for specifying the limit. This feature was highlighted in version 0.2.0.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n```\n\n----------------------------------------\n\nTITLE: Downloading Test Case Files using Wget (Shell)\nDESCRIPTION: This snippet downloads several Python files (`.py`) containing test cases from the Gradio GitHub repository using the `wget` command. The `-q` flag ensures the download process is quiet. These files are likely dependencies for testing the chat interface functionality demonstrated in the main Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_streaming_echo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_streaming_echo/messages_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_streaming_echo/multimodal_messages_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_streaming_echo/multimodal_non_stream_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_streaming_echo/multimodal_tuples_testcase.py\n```\n\n----------------------------------------\n\nTITLE: Implementing Zoom Functionality on a Gradio Plot in Python\nDESCRIPTION: Shows how to combine the `.select()` and `.double_click()` event listeners to create zoom-in and zoom-out effects on a Gradio plot. The event handlers update the `x_lim` property (and potentially `y_lim`) of the plot to change the displayed axis bounds. Requires gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_zoom\n```\n\n----------------------------------------\n\nTITLE: Creating Label Component with Gradio Blocks\nDESCRIPTION: Creates a Gradio interface using Blocks API that displays a Label component with three labels and their corresponding probability values. The label component shows a dictionary of label-probability pairs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/label_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Label(value={\"First Label\": 0.7, \"Second Label\": 0.2, \"Third Label\": 0.1})\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Text Generation Model Setup with Transformers\nDESCRIPTION: Configuration of a GPT-2 text generation model using the transformers library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport comet_ml\nimport gradio as gr\nimport shap\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\n\nMODEL_NAME = \"gpt2\"\n\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n\n# set model decoder to true\nmodel.config.is_decoder = True\n```\n\n----------------------------------------\n\nTITLE: Setting Max File Size Limit in Gradio (Python)\nDESCRIPTION: This Python code demonstrates how to configure the maximum allowed size for uploaded files in a Gradio application. It initializes a simple `gr.Interface` and uses the `max_file_size` parameter within the `launch()` method, showing both string ('5mb') and `gr.FileSize` constant methods to set the limit to 5 megabytes. This feature requires the Gradio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/multimodaltextbox/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Adding Examples to Gradio Interface for CryptoPunks Generator\nDESCRIPTION: Code snippet showing how to add example inputs to a Gradio interface using the examples parameter and enabling caching with cache_examples. The examples provide sample seed and number of punks combinations for users to try.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/create-your-own-friends-with-a-gan.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ngr.Interface(\n    # ...\n    # keep everything as it is, and then add\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\n).launch(cache_examples=True) # cache_examples is optional\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Stream Object Detection\nDESCRIPTION: Main function for processing video frames, detecting objects, and streaming results. Includes frame processing, model inference, and video output generation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/03_object-detection-from-video.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport spaces\nimport cv2\nfrom PIL import Image\nimport torch\nimport time\nimport numpy as np\nimport uuid\n\nfrom draw_boxes import draw_bounding_boxes\n\nSUBSAMPLE = 2\n\n@spaces.GPU\ndef stream_object_detection(video, conf_threshold):\n    cap = cv2.VideoCapture(video)\n\n    # This means we will output mp4 videos\n    video_codec = cv2.VideoWriter_fourcc(*\"mp4v\") # type: ignore\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n\n    desired_fps = fps // SUBSAMPLE\n    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) // 2\n\n    iterating, frame = cap.read()\n\n    n_frames = 0\n\n    # Use UUID to create a unique video file\n    output_video_name = f\"output_{uuid.uuid4()}.mp4\"\n\n    # Output Video\n    output_video = cv2.VideoWriter(output_video_name, video_codec, desired_fps, (width, height)) # type: ignore\n    batch = []\n\n    while iterating:\n        frame = cv2.resize( frame, (0,0), fx=0.5, fy=0.5)\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        if n_frames % SUBSAMPLE == 0:\n            batch.append(frame)\n        if len(batch) == 2 * desired_fps:\n            inputs = image_processor(images=batch, return_tensors=\"pt\").to(\"cuda\")\n\n            with torch.no_grad():\n                outputs = model(**inputs)\n\n            boxes = image_processor.post_process_object_detection(\n                outputs,\n                target_sizes=torch.tensor([(height, width)] * len(batch)),\n                threshold=conf_threshold)\n            \n            for i, (array, box) in enumerate(zip(batch, boxes)):\n                pil_image = draw_bounding_boxes(Image.fromarray(array), box, model, conf_threshold)\n                frame = np.array(pil_image)\n                # Convert RGB to BGR\n                frame = frame[:, :, ::-1].copy()\n                output_video.write(frame)\n\n            batch = []\n            output_video.release()\n            yield output_video_name\n            output_video_name = f\"output_{uuid.uuid4()}.mp4\"\n            output_video = cv2.VideoWriter(output_video_name, video_codec, desired_fps, (width, height)) # type: ignore\n\n        iterating, frame = cap.read()\n        n_frames += 1\n```\n\n----------------------------------------\n\nTITLE: Setting Storybook Page Title using Meta Component\nDESCRIPTION: Uses the imported Meta component to set the title of the Storybook page to 'Introduction'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/storybook/Introduction.mdx#2025-04-23_snippet_1\n\nLANGUAGE: HTML\nCODE:\n```\n<Meta title=\"Introduction\" />\n```\n\n----------------------------------------\n\nTITLE: Configuring the BaseFile Component in Gradio Svelte (JavaScript)\nDESCRIPTION: Declares exported properties for the BaseFile Svelte component, enabling customization of file value, labeling, selection state, height, and localization. Requires FileData types and an I18nFormatter for translations. Inputs are file data or arrays thereof; outputs are managed internal states; main constraints are optionality and type flexibility for height and value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: FileData | FileData[] | null = null;\\n\\texport let label: string;\\n\\texport let show_label = true;\\n\\texport let selectable = false;\\n\\texport let height: number | undefined = undefined;\\n\\texport let i18n: I18nFormatter;\\n\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits in Gradio Launch Function\nDESCRIPTION: Code snippet demonstrating how to set maximum file size limits when launching a Gradio interface. The limit can be specified either as a string or as an integer representing bytes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/checkboxgroup/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio App with Slider Release Event in Python\nDESCRIPTION: Defines a Gradio interface with a slider whose release event triggers a callback function named 'identity'. The function increments a state value, and updates outputs in response to slider interactions. Dependencies: Gradio (imported as gr). Key parameters: slider range (0 to 100, step 0.1), state initial value (0), outputs include the slider value and event count. The app is launched with demo.launch(), and displays the dynamically assigned server port. Intended to be run as a standalone script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/slider_release/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef identity(x, state):\n    state += 1\n    return x, state, state\n\nwith gr.Blocks() as demo:\n    slider = gr.Slider(0, 100, step=0.1)\n    state = gr.State(value=0)\n    with gr.Row():\n        number = gr.Number(label=\"On release\")\n        number2 = gr.Number(label=\"Number of events fired\")\n    slider.release(identity, inputs=[slider, state], outputs=[number, state, number2], api_name=\"predict\")\n\nif __name__ == \"__main__\":\n    print(\"here\")\n    demo.launch()\n    print(demo.server_port)\n\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Gradio Client for Audio Transcription\nDESCRIPTION: Demonstrates how to use the gradio_client library to connect to a Whisper speech recognition model hosted as a Hugging Face Space and transcribe an audio file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/whisper\")\nclient.predict(\"audio_sample.wav\")\n\n>> \"This is a test of the whisper speech recognition model.\"\n```\n\n----------------------------------------\n\nTITLE: BaseStaticAudio Component Properties\nDESCRIPTION: Defines the properties for the BaseStaticAudio component, which displays audio in a non-editable format. It includes properties for the audio value, display settings, and internationalization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/audio/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let name: string;\n\texport let show_label = true;\n\texport let autoplay: boolean;\n\texport let show_download_button = true;\n\texport let show_share_button = false;\n\texport let i18n: I18nFormatter;\n\texport let waveform_settings = {};\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio-Lite and Transformers.js Integration\nDESCRIPTION: A basic HTML template showing how to integrate Gradio-Lite with Transformers.js for sentiment analysis. Demonstrates the minimal setup required to create a serverless ML application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/06_gradio-lite-and-transformers-js.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n\t<body>\n\t\t<gradio-lite>\nimport gradio as gr\nfrom transformers_js_py import pipeline\n\npipe = await pipeline('sentiment-analysis')\n\ndemo = gr.Interface.from_pipeline(pipe)\n\ndemo.launch()\n\n\t\t\t<gradio-requirements>\ntransformers-js-py\n\t\t\t</gradio-requirements>\n\t\t</gradio-lite>\n\t</body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Formatting Number Precision in Gradio DataFrame with Pandas Styler - Python\nDESCRIPTION: This example demonstrates formatting floating point numbers in a Gradio DataFrame to two decimal places using the Pandas Styler's format method. The sample DataFrame includes floating numbers; formatting is applied globally using '{:.2f}'. Dependencies: pandas and gradio. Key parameters: the formatting string and the DataFrame. Output is a styled table with concise decimal values for better readability.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport pandas as pd\nimport gradio as gr\n\n# Creating a sample dataframe with floating numbers\ndf = pd.DataFrame({\n    \"A\" : [14.12345, 4.23456, 5.34567, 4.45678, 1.56789], \n    \"B\" : [5.67891, 2.78912, 54.89123, 3.91234, 2.12345], \n    # ... other columns\n}) \n\n# Setting the precision of numbers to 2 decimal places\ns = df.style.format(\"{:.2f}\")\n\n# Displaying the styled dataframe in Gradio\nwith gr.Blocks() as demo:\n    gr.DataFrame(s)\n    \ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Interface for Fake GAN in Python\nDESCRIPTION: This code creates a Gradio interface that simulates a GAN. It defines a function 'fake_gan' that returns predefined image URLs, sets up the interface with no inputs and a gallery output, and launches the demo. The interface is titled 'FD-GAN' and includes a description explaining it's a fake demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan_no_input/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport time\n\nimport gradio as gr\n\ndef fake_gan():\n    time.sleep(1)\n    images = [\n            \"https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=387&q=80\",\n            \"https://images.unsplash.com/photo-1554151228-14d9def656e4?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=386&q=80\",\n            \"https://images.unsplash.com/photo-1542909168-82c3e7fdca5c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxzZWFyY2h8MXx8aHVtYW4lMjBmYWNlfGVufDB8fDB8fA%3D%3D&w=1000&q=80\",\n    ]\n    return images\n\ndemo = gr.Interface(\n    fn=fake_gan,\n    inputs=None,\n    outputs=gr.Gallery(label=\"Generated Images\", columns=[2]),\n    title=\"FD-GAN\",\n    description=\"This is a fake demo of a GAN. In reality, the images are randomly chosen from Unsplash.\",\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Gradio W&B Integration\nDESCRIPTION: Integrates the Gradio demo with W&B dashboard using a single line of code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndemo.integrate(wandb=wandb)\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Application with Custom Theme in Python\nDESCRIPTION: This code creates a Gradio application with a custom theme and interactive components. It defines a textbox, slider, buttons, and output, and includes a function to repeat the input text based on the slider value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_4/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ntheme = gr.themes.Default(primary_hue=\"blue\").set(\n    loader_color=\"#FF0000\",\n    slider_color=\"#FF0000\",\n)\n\nwith gr.Blocks(\n    theme=theme\n) as demo:\n    textbox = gr.Textbox(label=\"Name\")\n    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n    with gr.Row():\n        button = gr.Button(\"Submit\", variant=\"primary\")\n        clear = gr.Button(\"Clear\")\n    output = gr.Textbox(label=\"Output\")\n\n    def repeat(name, count):\n        time.sleep(3)\n        return name * count\n\n    button.click(repeat, [textbox, slider], output)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Basic Prediction Examples - Python\nDESCRIPTION: Examples of making predictions using the Gradio client with different input types.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/en2fr\", api_name='/predict')\nclient.predict(\"Hello\")\n\n>> Bonjour\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Image Components (HTML)\nDESCRIPTION: This snippet imports four image-related components (BaseImageUploader, BaseStaticImage, Webcam, and BaseExample) from the @gradio/image library using a script tag. These imports are prerequisite for using the underlying Svelte components to handle image input, webcam capture, and example gallery functionalities. The script must be run in a Svelte-compatible build environment where @gradio/image is installed as a dependency.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n\\timport { BaseImageUploader, BaseStaticImage, Webcam, BaseExample } from \"@gradio/image\";\\n<\\/script>\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface with Datetime Component\nDESCRIPTION: This code creates a simple Gradio interface that includes a Datetime component. It imports Gradio, sets up a Blocks interface, adds a Datetime component, and launches the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/datetime_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DateTime()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Embedding Gradio App with Web Components\nDESCRIPTION: Code snippet showing how to embed a Gradio app using Web Components, including the required script import and gradio-app element.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<script\n\ttype=\"module\"\n\tsrc=\"https://gradio.s3-us-west-2.amazonaws.com/{GRADIO_VERSION}/gradio.js\"\n></script>\n```\n\nLANGUAGE: html\nCODE:\n```\n<gradio-app src=\"https://$your_space_host.hf.space\"></gradio-app>\n```\n\n----------------------------------------\n\nTITLE: Using Status Callback with Gradio Client\nDESCRIPTION: Example demonstrating how to use the status_callback option to monitor space status changes when connecting to a Gradio space.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client, type SpaceStatus } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\", {\n\t// The space_status parameter does not need to be manually annotated, this is just for illustration.\n\tspace_status: (space_status: SpaceStatus) => console.log(space_status)\n});\n```\n\n----------------------------------------\n\nTITLE: JavaScript Client Initialization\nDESCRIPTION: Example showing how to initialize the JavaScript client using the new class-based API\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\nconst app = await Client.connect(\"gradio/whisper\")\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio Server Name\nDESCRIPTION: Defines the host name for the Gradio server. Use 0.0.0.0 to make it accessible from any IP address.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GRADIO_SERVER_NAME=\"0.0.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Image Assets - Python\nDESCRIPTION: This code imports the os module and downloads two image files for use in the Gradio demo, using wget commands to fetch assets from a GitHub repository. It demonstrates a typical pattern for preparing external resources needed in the application. The snippet relies on network access and requires wget to be available in the runtime environment; failure to download will impact demo behavior.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_layers/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_editor_layers/cheetah.jpg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_editor_layers/layer1.png\n```\n\n----------------------------------------\n\nTITLE: Creating DuplicateButton Demo\nDESCRIPTION: Creates a simple Gradio interface using Blocks that implements a DuplicateButton component. The button is created within a Blocks context and the interface is launched for interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/duplicatebutton_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.DuplicateButton()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining Batch-Processing Function in Python for Gradio\nDESCRIPTION: This snippet presents a Python function `trim_words` adapted for batch processing within Gradio. It takes lists of `words` and `lengths` as input, processes them element-wise using `zip`, and returns a list containing a single list of the results. This structure is required by Gradio when `batch=True` is set for an event listener, allowing the function to handle multiple requests concurrently for potentially better performance, especially with models optimized for batch inference.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/setting-up-a-demo-for-maximum-performance.md#2025-04-23_snippet_2\n\nLANGUAGE: py\nCODE:\n```\nimport time\n\ndef trim_words(words, lengths):\n    trimmed_words = []\n    for w, l in zip(words, lengths):\n        trimmed_words.append(w[:int(l)])\n    return [trimmed_words]\n\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the data.py file from the Gradio GitHub repository which contains the dataset used in the bar plot demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_nominal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_aggregate_nominal/data.py\n```\n\n----------------------------------------\n\nTITLE: Referencing Dark Mode Variables in Gradio Themes\nDESCRIPTION: This snippet demonstrates how dark mode variables automatically reference each other in Gradio themes. It shows how dark mode border colors automatically reference the dark mode background fill.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_12\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default().set(\n    button_primary_background_fill=\"#FF0000\",\n    button_primary_background_fill_dark=\"#AAAAAA\",\n    button_primary_border=\"*button_primary_background_fill\",\n    button_primary_border_dark=\"*button_primary_background_fill_dark\",\n)\n```\n\n----------------------------------------\n\nTITLE: Defining StatusTracker Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the StatusTracker component. It includes various options for controlling the display of status information, such as ETA, queue position, and progress indicators.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let i18n: I18nFormatter;\nexport let eta: number | null = null;\nexport let queue = false;\nexport let queue_position: number | null;\nexport let queue_size: number | null;\nexport let status: \"complete\" | \"pending\" | \"error\" | \"generating\";\nexport let scroll_to_output = false;\nexport let timer = true;\nexport let show_progress: \"full\" | \"minimal\" | \"hidden\" = \"full\";\nexport let message: string | null = null;\nexport let progress: LoadingStatus[\"progress\"] | null | undefined = null;\nexport let variant: \"default\" | \"center\" = \"default\";\nexport let loading_text = \"Loading...\";\nexport let absolute = true;\nexport let translucent = false;\nexport let border = false;\nexport let autoscroll: boolean;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and DateTimeRange Extension\nDESCRIPTION: Installation of the Gradio library and the Gradio DateTimeRange extension package via pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetimerange/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio gradio_datetimerange\n```\n\n----------------------------------------\n\nTITLE: Implementing Image Classification Interface with Gradio\nDESCRIPTION: Creates a Gradio interface for image classification using TensorFlow's MobileNetV2 model. The implementation includes model loading, image preprocessing, prediction function, and interface setup with example images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport os\nimport requests\nimport tensorflow as tf\n\nimport gradio as gr\n\ninception_net = tf.keras.applications.MobileNetV2()  # load the model\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n    inp = inp.reshape((-1, 224, 224, 3))\n    inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n    prediction = inception_net.predict(inp).flatten()\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\n\nimage = gr.Image()\nlabel = gr.Label(num_top_classes=3)\n\ndemo = gr.Interface(\n    fn=classify_image,\n    inputs=image,\n    outputs=label,\n    examples=[\n        os.path.join(os.path.abspath(''), \"images/cheetah1.jpg\"),\n        os.path.join(os.path.abspath(''), \"images/lion.jpg\")\n        ]\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio UI Interface\nDESCRIPTION: Setting up the Gradio interface with video input/output components and confidence threshold control\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/03_object-detection-from-video.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as app:\n    gr.HTML(\n        \"\"\"\n    <h1 style='text-align: center'>\n    Video Object Detection with <a href='https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365' target='_blank'>RT-DETR</a>\n    </h1>\n    \"\"\")\n    with gr.Row():\n        with gr.Column():\n            video = gr.Video(label=\"Video Source\")\n            conf_threshold = gr.Slider(\n                label=\"Confidence Threshold\",\n                minimum=0.0,\n                maximum=1.0,\n                step=0.05,\n                value=0.30,\n            )\n        with gr.Column():\n            output_video = gr.Video(label=\"Processed Video\", streaming=True, autoplay=True)\n\n    video.upload(\n        fn=stream_object_detection,\n        inputs=[video, conf_threshold],\n        outputs=[output_video],\n    )\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio File for Gradio Demo in Python/Bash\nDESCRIPTION: Creates an 'audio' directory using Python's 'os' module and then downloads a sample WAV file ('cantina.wav') from a GitHub repository using the 'wget' command-line utility. This file serves as input for the audio streaming demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio_out/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('audio')\n!wget -q -O audio/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/stream_audio_out/audio/cantina.wav\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Video Watermarking\nDESCRIPTION: This snippet defines a function to apply a watermark to a video and creates a Gradio interface for it. The interface allows users to upload a video and a watermark file, then displays the result. It also includes example inputs using the downloaded sample files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_watermark/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\na = os.path.join(os.path.abspath(''), \"files/a.mp4\")\nb = os.path.join(os.path.abspath(''), \"files/b.mp4\")\nw1 = os.path.join(os.path.abspath(''), \"files/w1.jpg\")\nw2 = os.path.join(os.path.abspath(''), \"files/w2.png\")\n\ndef generate_video(original_video, watermark):\n    return gr.Video(original_video, watermark=watermark)\n\n\ndemo = gr.Interface(generate_video, [gr.Video(), gr.File()], gr.Video(),\n                    examples=[[a, w1], [b, w2]])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Multimodal Echo Chat Interface with Gradio\nDESCRIPTION: This code creates a Gradio chat interface that echoes both text and file inputs. It defines a custom echo function that handles multimodal inputs and sets up the ChatInterface with multimodal support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_echo_multimodal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef echo_multimodal(message, history):\n    response = []\n    response.append(\"You wrote: '\" + message[\"text\"] + \"' and uploaded:\")\n    if message.get(\"files\"):\n        for file in message[\"files\"]:\n            response.append(gr.File(value=file))\n    return response\n\ndemo = gr.ChatInterface(\n    echo_multimodal,\n    type=\"messages\",\n    multimodal=True,\n    textbox=gr.MultimodalTextbox(file_count=\"multiple\"),\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Render Logic in Application Class Python\nDESCRIPTION: Defines the `_render` method for the main `Application` class. Similar to `LayoutBase.render`, it iterates through its child layout components (`self.children`), calls their `render` methods within the main application block's context (`self.app`), and finally calls `render` on the application block itself (`self.app.render()`) to finalize the UI structure.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n    # other Application implementations\n\n    def _render(self):\n        with self.app:\n            for child in self.children:\n                child.render()\n\n        self.app.render()\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Gradio Interface with Radio Component in Python\nDESCRIPTION: This Python code demonstrates the creation of a simple Gradio interface using the `Blocks` layout. It imports the `gradio` library as `gr`, defines a `Blocks` context named `demo`, adds a `gr.Radio` component with three specified string choices, and then launches the Gradio application using `demo.launch()`, making it accessible locally.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/radio_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Radio(choices=[\"First Choice\", \"Second Choice\", \"Third Choice\"])\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Documenting Bug Fix in Markdown Changelog\nDESCRIPTION: This snippet shows how a bug fix is documented in the changelog, including a pull request reference and description of the fix.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n### Fixes\n\n- [#5944](https://github.com/gradio-app/gradio/pull/5944) [`465f58957`](https://github.com/gradio-app/gradio/commit/465f58957f70c7cf3e894beef8a117b28339e3c1) - Show empty JSON icon when `value` is `null`. Thanks [@hannahblair](https://github.com/hannahblair)!\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Gradio Generator Endpoint Outputs\nDESCRIPTION: Shows an alternative method for handling generator endpoints by iterating directly over the `Job` object returned by `client.submit()`. This allows processing each output as it becomes available, rather than waiting for the entire sequence to complete. The example prints each number yielded by the 'count_generator' endpoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(src=\"gradio/count_generator\")\njob = client.submit(3, api_name=\"/count\")\n\nfor o in job:\n    print(o)\n\n>> 0\n>> 1\n>> 2\n```\n\n----------------------------------------\n\nTITLE: Initializing Default Gradio Queue in Python\nDESCRIPTION: This snippet demonstrates how to enable the built-in Gradio queuing system for an `Interface` object using the `.queue()` method with its default parameters. It requires the `gradio` library. Calling `.queue()` modifies the `app` instance to handle requests sequentially or concurrently based on default queue settings before the app is launched with `app.launch()`. This setup is fundamental for managing multiple user requests.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/setting-up-a-demo-for-maximum-performance.md#2025-04-23_snippet_0\n\nLANGUAGE: py\nCODE:\n```\nimport gradio as gr\n\napp = gr.Interface(lambda x:x, \"image\", \"image\")\napp.queue()  # <-- Sets up a queue with default parameters\napp.launch()\n```\n\n----------------------------------------\n\nTITLE: Handling Multiple File Types with handle_file Utility\nDESCRIPTION: Demonstrates the versatile usage of handle_file utility for processing different types of file inputs including local files, URLs, blobs, and buffers in various nested structures.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_20\n\nLANGUAGE: typescript\nCODE:\n```\nimport { handle_file } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst result = await app.predict(\"/predict\", {\n\tsingle: handle_file(file),\n\tflat: [handle_file(url), handle_file(buffer)],\n\tnested: {\n\t\timage: handle_file(url),\n\t\tlayers: [handle_file(buffer)]\n\t},\n\tdeeply_nested: {\n\t\timage: handle_file(url),\n\t\tlayers: [{\n\t\t\tlayer1: handle_file(buffer),\n\t\t\tlayer2: handle_file(buffer)\n\t\t}]\n\t}\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for RT-DETR Object Detection\nDESCRIPTION: Installs necessary Python packages including Gradio, safetensors, OpenCV, PyTorch, Transformers, and Pillow to run the object detection demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rt-detr-object-detection/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio safetensors==0.4.3 opencv-python torch transformers>=4.43.0 Pillow \n```\n\n----------------------------------------\n\nTITLE: Pyodide Package Management\nDESCRIPTION: Implements automatic loading of imported modules with pyodide.loadPackagesFromImports and handles package installation retry logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_2\n\n\n\n----------------------------------------\n\nTITLE: Initializing and Launching a Gradio Interface in Python\nDESCRIPTION: This snippet defines a simple list of positive sentences, a function that selects one randomly, and creates a Gradio interface with no input components and a text output. It imports required modules, constructs the interface with 'gr.Interface', and launches the Gradio app via 'demo.launch()'. Inputs: none (the interface has no input components). Outputs: one of the predefined text strings. Dependencies: gradio, random. Designed to be run as the main module.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/no_input/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\nsentence_list = [\n    \"Good morning!\",\n    \"Prayers are with you, have a safe day!\",\n    \"I love you!\"\n]\n\ndef random_sentence():\n    return sentence_list[random.randint(0, 2)]\n\ndemo = gr.Interface(fn=random_sentence, inputs=None, outputs=\"text\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Random Response Chat Interface\nDESCRIPTION: Creates a Gradio chat interface that responds to user messages with random Yes/No answers. Uses the ChatInterface class with disabled autofocus and message-type interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_random_response/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport random\nimport gradio as gr\n\ndef random_response(message, history):\n    return random.choice([\"Yes\", \"No\"])\n\ndemo = gr.ChatInterface(random_response, type=\"messages\", autofocus=False)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Referencing Core Size Variables in Gradio Themes in Python\nDESCRIPTION: This example shows how to reference core size variables in a Gradio theme using the asterisk prefix. It sets the button border radius to use a predefined radius size value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default(radius_size=\"md\").set(\n    button_primary_border_radius=\"*radius_xl\",\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Demo with Authentication\nDESCRIPTION: This code creates a Gradio demo with a greeting, text input, and output. It uses command-line arguments to customize the greeting and implements basic authentication for the demo launch.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_login/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport argparse\nimport sys\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--name\", type=str, default=\"User\")\nargs, unknown = parser.parse_known_args()\nprint(sys.argv)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(f\"# Greetings {args.name}!\")\n    inp = gr.Textbox()\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: x, inputs=inp, outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch(auth=(\"admin\", \"admin\"))\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface with Markdown and Mermaid (Python)\nDESCRIPTION: Imports the Gradio library, creates a `Blocks` interface, and adds a `gr.Markdown` component. This component renders a multi-line string containing standard Markdown formatting and embedded Mermaid diagrams (graph LR, sequenceDiagram, flowchart TD, stateDiagram-v2) to visualize different aspects of a system, such as architecture, user journeys, decision processes, and state transitions. The script launches the Gradio application if run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_with_mermaid/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Markdown(\n        \"\"\"\n        # Project Documentation with Mermaid Diagrams\n        \n        This example demonstrates how to combine regular Markdown with Mermaid diagrams for better visualization.\n        \n        ## System Architecture\n        \n        Below is an overview of our system's architecture:\n        \n        ```mermaid\n        graph LR\n            User[User] --> Frontend[Web Frontend]\n            Frontend --> API[API Gateway]\n            API --> Auth[Authentication Service]\n            API --> DataService[Data Processing Service]\n            DataService --> DB[(Database)]\n            DataService --> ML[Machine Learning Engine]\n            ML --> Model[(Model Storage)]\n            \n            style User fill:#f9f,stroke:#333,stroke-width:2px\n            style Frontend fill:#bbf,stroke:#333,stroke-width:2px\n            style API fill:#bfb,stroke:#333,stroke-width:2px\n            style DataService fill:#fbb,stroke:#333,stroke-width:2px\n        ```\n        \n        ## Data Processing Workflow\n        \n        The data goes through the following steps before reaching the end user:\n        \n        1. Collection from various sources\n        2. Cleaning and preprocessing\n        3. Feature extraction\n        4. Analysis and model application\n        5. Results formatting\n        \n        ## User Journey\n        \n        ```mermaid\n        sequenceDiagram\n            participant U as User\n            participant F as Frontend\n            participant A as API\n            participant D as Database\n            \n            U->>F: Login Request\n            F->>A: Authenticate\n            A->>D: Verify Credentials\n            D-->>A: User Validated\n            A-->>F: Auth Token\n            F-->>U: Login Success\n            \n            U->>F: Request Data\n            F->>A: Get Data (with token)\n            A->>D: Query Data\n            D-->>A: Return Results\n            A-->>F: Formatted Data\n            F-->>U: Display Results\n        ```\n        \n        ## Decision Process\n        \n        When handling requests, our system follows this decision tree:\n        \n        ```mermaid\n        flowchart TD\n            A[New Request] --> B{Authenticated?}\n            B -->|Yes| C{Request Type}\n            B -->|No| D[Return 401]\n            \n            C -->|Data Query| E[Process Query]\n            C -->|Update| F{Has Permission?}\n            C -->|Delete| G{Is Admin?}\n            \n            F -->|Yes| H[Apply Update]\n            F -->|No| I[Return 403]\n            \n            G -->|Yes| J[Execute Delete]\n            G -->|No| K[Return 403]\n            \n            E --> L[Return Data]\n            H --> M[Return Success]\n            J --> N[Return Success]\n            \n            style A fill:#98fb98,stroke:#333\n            style D fill:#ff9999,stroke:#333\n            style I fill:#ff9999,stroke:#333\n            style K fill:#ff9999,stroke:#333\n            style M fill:#98fb98,stroke:#333\n            style N fill:#98fb98,stroke:#333\n        ```\n        \n        ## State Diagram\n        \n        Our application transitions through these states:\n        \n        ```mermaid\n        stateDiagram-v2\n            [*] --> Initialization\n            Initialization --> Ready\n            \n            Ready --> Processing: New Request\n            Processing --> Error: Exception\n            Processing --> Complete: Success\n            \n            Error --> Ready: Reset\n            Complete --> Ready: Reset\n            \n            Ready --> Shutdown: Exit Command\n            Shutdown --> [*]\n        ```\n        \n        ## Additional Resources\n        \n        For more information about our system, please check:\n        \n        - [API Documentation](https://example.com/api-docs)\n        - [User Guide](https://example.com/user-guide)\n        - [Admin Dashboard](https://example.com/admin)\n        \"\"\"\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Initializing PDF Viewer State Variables in TypeScript\nDESCRIPTION: Declares variables to track the PDF document, page counts, current page, and canvas reference. These variables maintain the state of the PDF viewer component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\nlet pdfDoc;\nlet numPages = 1;\nlet currentPage = 1;\nlet canvasRef;\n```\n\n----------------------------------------\n\nTITLE: Defining BaseModel3D Component in Gradio\nDESCRIPTION: This snippet defines the properties for the BaseModel3D component. It includes options for setting the 3D model value, clear color, label, zoom speed, and camera position. The component is used for displaying 3D models in Gradio interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/model3D/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: FileData | null;\nexport let clear_color: [number, number, number, number] = [0, 0, 0, 0];\nexport let label = \"\";\nexport let show_label: boolean;\nexport let i18n: I18nFormatter;\nexport let zoom_speed = 1;\n\n// alpha, beta, radius\nexport let camera_position: [number | null, number | null, number | null] = [\n\tnull,\n\tnull,\n\tnull\n];\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Gradio Chatbot Demo\nDESCRIPTION: This code creates a 'files' directory and downloads sample audio, image, text, and video files from the Gradio GitHub repository for use in the chatbot demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/audio.wav https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components/files/audio.wav\n!wget -q -O files/avatar.png https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components/files/avatar.png\n!wget -q -O files/sample.txt https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components/files/sample.txt\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Creating Dynamic UI with Gradio Render Decorator\nDESCRIPTION: Builds a Gradio interface that dynamically renders a variable number of textboxes based on slider input. The demo includes functionality to merge textbox contents, clear all textboxes, and populate textboxes with sequential numbers, demonstrating dynamic component creation and event handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_merge/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    text_count = gr.Slider(1, 5, step=1, label=\"Textbox Count\")\n\n    @gr.render(inputs=text_count)\n    def render_count(count):\n        boxes = []\n        for i in range(count):\n            box = gr.Textbox(key=i, label=f\"Box {i}\")\n            boxes.append(box)\n\n        def merge(*args):\n            return \" \".join(args)\n\n        merge_btn.click(merge, boxes, output)\n\n        def clear():\n            return [\"\"] * count\n\n        clear_btn.click(clear, None, boxes)\n\n        def countup():\n            return [i for i in range(count)]\n\n        count_btn.click(countup, None, boxes, queue=False)\n\n    with gr.Row():\n        merge_btn = gr.Button(\"Merge\")\n        clear_btn = gr.Button(\"Clear\")\n        count_btn = gr.Button(\"Count\")\n\n    output = gr.Textbox()\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Global State in Gradio Interface (Python)\nDESCRIPTION: This snippet demonstrates how to use global state in a Gradio interface to track scores across all users. It defines a function that adds a score to a global list and returns the top 3 scores.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/03_interface-state.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nscores = []\n\ndef track_scores(score):\n    global scores\n    scores.append(score)\n    scores.sort(reverse=True)\n    return scores[:3]\n\ndemo = gr.Interface(\n    fn=track_scores,\n    inputs=\"number\",\n    outputs=\"text\",\n    title=\"Score Tracker\"\n)\n```\n\n----------------------------------------\n\nTITLE: Adding Minimize/Maximize Button to Image Components\nDESCRIPTION: Addition of minimize/maximize functionality to gr.Image and gr.Gallery components in version 0.7.0, as implemented in pull request #8964.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#8964](https://github.com/gradio-app/gradio/pull/8964) [`bf6bbd9`](https://github.com/gradio-app/gradio/commit/bf6bbd971acddbf78f03bea431ed7d1e0003ccf9) - Add min/max-imize button to gr.Image and gr.Gallery.  Thanks @hannahblair!\n```\n\n----------------------------------------\n\nTITLE: Model Saving, Loading and Inference with StyleGAN\nDESCRIPTION: Code for saving, downloading, and loading the trained StyleGAN model. It includes the inference function that processes input images through the model to generate stylized outputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom PIL import Image\nimport torch\ntorch.backends.cudnn.benchmark = True\nfrom torchvision import transforms, utils\nfrom util import *\nimport math\nimport random\nimport numpy as np\nfrom torch import nn, autograd, optim\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\nimport lpips\nfrom model import *\nfrom e4e_projection import projection as e4e_projection\n\nfrom copy import deepcopy\nimport imageio\n\nimport os\nimport sys\nimport torchvision.transforms as transforms\nfrom argparse import Namespace\nfrom e4e.models.psp import pSp\nfrom util import *\nfrom huggingface_hub import hf_hub_download\nfrom google.colab import files\ntorch.save({\"g\": generator.state_dict()}, \"your-model-name.pt\")\n\nfiles.download('your-model-name.pt')\n\nlatent_dim = 512\ndevice=\"cuda\"\nmodel_path_s = hf_hub_download(repo_id=\"akhaliq/jojogan-stylegan2-ffhq-config-f\", filename=\"stylegan2-ffhq-config-f.pt\")\noriginal_generator = Generator(1024, latent_dim, 8, 2).to(device)\nckpt = torch.load(model_path_s, map_location=lambda storage, loc: storage)\noriginal_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\nmean_latent = original_generator.mean_latent(10000)\n\ngenerator = deepcopy(original_generator)\n\nckpt = torch.load(\"/content/JoJoGAN/your-model-name.pt\", map_location=lambda storage, loc: storage)\ngenerator.load_state_dict(ckpt[\"g\"], strict=False)\ngenerator.eval()\n\nplt.rcParams['figure.dpi'] = 150\n\ntransform = transforms.Compose(\n    [\n        transforms.Resize((1024, 1024)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ]\n)\n\ndef inference(img):\n    img.save('out.jpg')\n    aligned_face = align_face('out.jpg')\n\n    my_w = e4e_projection(aligned_face, \"out.pt\", device).unsqueeze(0)\n    with torch.no_grad():\n        my_sample = generator(my_w, input_is_latent=True)\n\n    npimage = my_sample[0].cpu().permute(1, 2, 0).detach().numpy()\n    imageio.imwrite('filename.jpeg', npimage)\n    return 'filename.jpeg'\n```\n\n----------------------------------------\n\nTITLE: Enabling App Sharing\nDESCRIPTION: Controls whether the Gradio app can be shared.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_8\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_SHARE=\"True\"\n```\n\n----------------------------------------\n\nTITLE: Defining Props for the Upload Component in JavaScript/TypeScript\nDESCRIPTION: This snippet defines exported properties (props) for a potential `Upload` component, likely written in JavaScript or TypeScript for use within a Svelte component. It includes properties like `filetype`, `dragging`, `boundedheight`, `center`, `flex`, `file_count`, `disable_click`, `root`, and `hidden` to configure the appearance and behavior of the file upload interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let filetype: string | null = null;\nexport let dragging = false;\nexport let boundedheight = true;\nexport let center = true;\nexport let flex = true;\nexport let file_count = \"single\";\nexport let disable_click = false;\nexport let root: string;\nexport let hidden = false;\n```\n\n----------------------------------------\n\nTITLE: Generating HTML for Harm Level Indicator in Python\nDESCRIPTION: This function creates an HTML string for displaying a harm level indicator. It uses a color map to assign colors to different harm levels and returns a styled div element.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef html_src(harm_level):\n    return f\"\"\"\n<div style=\"display: flex; gap: 5px;\">\n  <div style=\"background-color: {color_map[harm_level]}; padding: 2px; border-radius: 5px;\">\n  {harm_level}\n  </div>\n</div>\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Authenticating with Gradio API using curl\nDESCRIPTION: Makes a POST request to login to a Gradio app with authentication, saving cookies to a file for subsequent requests.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST $URL/login \\\n     -d \"username=$USERNAME&password=$PASSWORD\" \\\n     -c cookies.txt\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseGallery Component Properties (JavaScript)\nDESCRIPTION: This snippet exports several configurable properties for the BaseGallery component, allowing control over gallery behavior and appearance in a Svelte or JavaScript context. Dependencies include the @gradio/gallery package and any required type definitions (e.g., FileData, I18nFormatter). Parameters such as show_label, label, root, root_url, value, columns, rows, height, preview, allow_preview, object_fit, show_share_button, show_download_button, i18n, and selected_index can be customized to modify the gallery's functionality. Inputs expect specific types (e.g., arrays, booleans, strings), and outputs depend on property configurations; limitations include the need for correct type assignment and valid property values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/gallery/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let show_label = true;\\n\\texport let label: string;\\n\\texport let root = \"\";\\n\\texport let root_url: null | string = null;\\n\\texport let value: { image: FileData; caption: string | null }[] | null = null;\\n\\texport let columns: number | number[] | undefined = [2];\\n\\texport let rows: number | number[] | undefined = undefined;\\n\\texport let height: number | \"auto\" = \"auto\";\\n\\texport let preview: boolean;\\n\\texport let allow_preview = true;\\n\\texport let object_fit: \"contain\" | \"cover\" | \"fill\" | \"none\" | \"scale-down\" =\\n\\t\\t\"cover\";\\n\\texport let show_share_button = false;\\n\\texport let show_download_button = false;\\n\\texport let i18n: I18nFormatter;\\n\\texport let selected_index: number | null = null;\n```\n\n----------------------------------------\n\nTITLE: Downloading CSS File for Demo\nDESCRIPTION: Downloads a CSS file from the Gradio GitHub repository for use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/code/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/code/file.css\n```\n\n----------------------------------------\n\nTITLE: File Input Request\nDESCRIPTION: Demonstrates how to make a request with file inputs using URL paths.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST https://gradio-image-mod.hf.space/call/predict -H \"Content-Type: application/json\" -d '{\n  \"data\": [{\"path\": \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\"}] \n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Timeout for Duplicated Spaces in Gradio\nDESCRIPTION: Demonstrates how to set a timeout value in minutes for duplicated Gradio spaces using the Client.duplicate method. The timeout parameter determines when the duplicated space will go to sleep.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_18\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\ttimeout: 5\n});\n```\n\n----------------------------------------\n\nTITLE: Initializing Interactive and Static Textboxes in Gradio (Python)\nDESCRIPTION: Demonstrates creating two `gr.Textbox` components within a `gr.Blocks` layout. The `interactive` parameter controls whether the user can edit the textbox. Setting `interactive=True` allows editing, while `interactive=False` makes it read-only (disabled). Requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/02_key-component-concepts.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n   gr.Textbox(value=\"Hello\", interactive=True)\n   gr.Textbox(value=\"Hello\", interactive=False)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Gallery Component Demo\nDESCRIPTION: Sets up a Gradio Blocks interface with a Gallery component. The gallery includes a mix of online and local image and video sources, displayed in a 4-column layout.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_component/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gallery_items = [\n        (\"https://upload.wikimedia.org/wikipedia/commons/0/09/TheCheethcat.jpg\", \"cheetah1\"),\n        (\"https://nationalzoo.si.edu/sites/default/files/animals/cheetah-003.jpg\", \"cheetah2\"),\n        (\"https://videos.pexels.com/video-files/3209828/3209828-uhd_2560_1440_25fps.mp4\", \"world\"),\n        (\"files/cheetah.jpg\", \"cheetah3\"),\n        (\"files/world.mp4\", \"world2\")\n    ]\n    gr.Gallery(value=gallery_items, columns=4)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Example BigQuery Service Account Key JSON Structure\nDESCRIPTION: Illustrates the typical structure of a Google Cloud service account key file in JSON format. This file contains credentials like project ID, private key, and client email, necessary for authenticating applications to access Google Cloud services like BigQuery.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"type\": \"service_account\",\n\t\"project_id\": \"your project\",\n\t\"private_key_id\": \"your private key id\",\n\t\"private_key\": \"private key\",\n\t\"client_email\": \"email\",\n\t\"client_id\": \"client id\",\n\t\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n\t\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n\t\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n\t\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\n}\n```\n\n----------------------------------------\n\nTITLE: Setting Cache Mode\nDESCRIPTION: Configures how examples are cached (lazy or eager).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_13\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_CACHE_MODE=\"lazy\"\n```\n\n----------------------------------------\n\nTITLE: Defining Image Segmentation Function in Python\nDESCRIPTION: This function performs image segmentation on the input image. It converts the image to grayscale, applies a threshold, and returns a binary mask. The function also handles different input types (file path or PIL Image).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/gradio/test_data/flagged_no_log/a.txt#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef segment(image):\n    if isinstance(image, str):\n        image = Image.open(image)\n    image = image.convert('L')\n    return np.array(image) > 128\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Basic Gradio Flagging\nDESCRIPTION: Illustrates the directory structure created when data is flagged using the basic Gradio setup. A 'flagged' directory is created, containing a 'logs.csv' file where the flagged data is stored.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_1\n\nLANGUAGE: text\nCODE:\n```\n+-- flagged/\n|   +-- logs.csv\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Widget JavaScript Functionality\nDESCRIPTION: JavaScript code that handles the chat widget's functionality including connection to Gradio client, message handling, and UI interactions. Uses the Gradio JavaScript Client to communicate with a Gradio space.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/08_creating-a-website-widget-from-a-gradio-chatbot.md#2025-04-23_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n<script type=\"module\">\n    import { Client } from \"https://cdn.jsdelivr.net/npm/@gradio/client/dist/index.min.js\";\n    \n    async function initChatWidget() {\n        const client = await Client.connect(\"https://abidlabs-gradio-playground-bot.hf.space\");\n        \n        const chatToggle = document.getElementById('chat-toggle');\n        const chatContainer = document.getElementById('chat-container');\n        const closeChat = document.getElementById('close-chat');\n        const chatInput = document.getElementById('chat-input');\n        const sendButton = document.getElementById('send-message');\n        const messagesContainer = document.getElementById('chat-messages');\n    \n        chatToggle.addEventListener('click', () => {\n            chatContainer.classList.remove('hidden');\n        });\n    \n        closeChat.addEventListener('click', () => {\n            chatContainer.classList.add('hidden');\n        });\n    \n        async function sendMessage() {\n            const userMessage = chatInput.value.trim();\n            if (!userMessage) return;\n\n            appendMessage(userMessage, 'user');\n            chatInput.value = '';\n\n            try {\n                const result = await client.predict(\"/chat\", {\n                    message: {\"text\": userMessage, \"files\": []}\n                });\n                const message = result.data[0];\n                console.log(result.data[0]);\n                const botMessage = result.data[0].join('\\n');\n                appendMessage(botMessage, 'bot');\n            } catch (error) {\n                console.error('Error:', error);\n                appendMessage('Sorry, there was an error processing your request.', 'bot');\n            }\n        }\n    \n        function appendMessage(text, sender) {\n            const messageDiv = document.createElement('div');\n            messageDiv.className = `message ${sender}-message`;\n            \n            if (sender === 'bot') {\n                messageDiv.innerHTML = marked.parse(text);\n            } else {\n                messageDiv.textContent = text;\n            }\n            \n            messagesContainer.appendChild(messageDiv);\n            messagesContainer.scrollTop = messagesContainer.scrollHeight;\n        }\n    \n        sendButton.addEventListener('click', sendMessage);\n        chatInput.addEventListener('keypress', (e) => {\n            if (e.key === 'Enter') sendMessage();\n        });\n    }\n    \n    initChatWidget();\n</script>\n```\n\n----------------------------------------\n\nTITLE: Package Configuration for PDF Component\nDESCRIPTION: Package.json configuration with required dependencies for the PDF display component including pdfjs-dist and Gradio packages\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n{\n  \"name\": \"gradio_pdf\",\n  \"version\": \"0.2.0\",\n  \"description\": \"Gradio component for displaying PDFs\",\n  \"type\": \"module\",\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"private\": false,\n  \"main_changeset\": true,\n  \"exports\": {\n    \".\": \"./Index.svelte\",\n    \"./example\": \"./Example.svelte\",\n    \"./package.json\": \"./package.json\"\n  },\n  \"devDependencies\": {\n    \"pdfjs-dist\": \"3.11.174\"\n  },\n  \"dependencies\": {\n    \"@gradio/atoms\": \"0.2.0\",\n    \"@gradio/statustracker\": \"0.3.0\",\n    \"@gradio/utils\": \"0.2.0\",\n    \"@gradio/client\": \"0.7.1\",\n    \"@gradio/upload\": \"0.3.2\",\n    \"@gradio/icons\": \"0.2.0\",\n    \"@gradio/button\": \"0.2.3\",\n    \"pdfjs-dist\": \"3.11.174\"\n  }\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Loading Data for Gradio Dashboard\nDESCRIPTION: This snippet imports necessary libraries, loads data from a CSV file, and prepares it for use in the Gradio interface. It sets up the foundation for the interactive dashboard.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/DESCRIPTION.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pandas as pd\nimport plotly.express as px\n\ndf = pd.read_csv(\"pypi-data.csv\")\nlibraries = df[\"library\"].unique().tolist()\nmetrics = [\"monthly_downloads\", \"monthly_new_contributors\", \"monthly_new_releases\", \"monthly_new_repos\"]\n```\n\n----------------------------------------\n\nTITLE: Setting Draw Brush Color via API (TypeScript)\nDESCRIPTION: Sets the brush color specifically for the drawing mode of the Brush Tool. It accepts a `color` parameter. This distinguishes the drawing color setting from potentially other color settings within the tool. This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nset_brush_color(color)\n```\n\n----------------------------------------\n\nTITLE: Implementing SHAP Text Explanation with Comet ML Logging in Python\nDESCRIPTION: Defines a prediction function that generates SHAP values for input text and creates a visualization. If a Comet experiment is active, it logs the message context and the HTML visualization to the experiment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\ndef predict(text, state, message):\n    experiment = state\n\n    shap_values = explainer([text])\n    plot = shap.plots.text(shap_values, display=False)\n\n    if experiment is not None:\n        experiment.log_other(\"message\", message)\n        experiment.log_html(plot)\n\n    return plot\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Text Reversal Demo\nDESCRIPTION: Creates a Gradio interface with a text input box and button that reverses the input text when clicked. Uses Gradio's Blocks API to construct the interface and define the interaction logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/input_output/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef image_mod(text):\n    return text[::-1]\n\ndemo = gr.Blocks()\n\nwith demo:\n    text = gr.Textbox(label=\"Input-Output\")\n    btn = gr.Button(\"Run\")\n    btn.click(image_mod, text, text)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting Port Range for Gradio Server\nDESCRIPTION: Defines the number of ports to try when starting the Gradio server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport GRADIO_NUM_PORTS=200\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Generator Function in Python\nDESCRIPTION: Demonstrates how to create a basic generator function that yields a sequence of numbers up to a given value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/02_streaming-outputs.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef my_generator(x):\n    for i in range(x):\n        yield i\n```\n\n----------------------------------------\n\nTITLE: Streaming Audio with Gradio\nDESCRIPTION: Shows how to create a Gradio interface that streams audio by repeatedly yielding an audio file. It uses a microphone input and an audio output component with streaming enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/02_streaming-outputs.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom time import sleep\n\ndef keep_repeating(audio_file):\n    for _ in range(10):\n        sleep(0.5)\n        yield audio_file\n\ngr.Interface(keep_repeating,\n             gr.Audio(sources=[\"microphone\"], type=\"filepath\"),\n             gr.Audio(streaming=True, autoplay=True)\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing a Custom Button Component using Gradio's BaseButton in Svelte\nDESCRIPTION: This snippet demonstrates how to create a custom button component using Gradio's BaseButton. It imports the necessary components, sets up event handling, and configures the button with various customization props like variant, size, icon, and more. The component dispatches a 'click' event when clicked.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/README.md#2025-04-23_snippet_0\n\nLANGUAGE: svelte\nCODE:\n```\n<script>\n\timport { BaseButton } from \"@gradio/button\";\n\timport { createEventDispatcher, tick, getContext } from \"svelte\";\n\tconst dispatch = createEventDispatcher();\n</script>\n\n<BaseButton\n\t{value}\n\t{variant}\n\t{elem_id}\n\t{elem_classes}\n\t{size}\n\t{scale}\n\t{link}\n\t{icon}\n\t{min_width}\n\t{visible}\n\t{root}\n\t{root_url}\n\ton:click={() => dispatch(\"click\")}\n>\n\t{\"My Button\"}\n</Button>\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio Application\nDESCRIPTION: This snippet lists the required Python packages and their versions for a Gradio application. It includes holidays for date handling, prophet for time series forecasting, pandas for data manipulation, pypistats for PyPI download statistics, and plotly for data visualization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timeseries-forecasting-with-prophet/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\nholidays==0.24\nprophet==1.1.2\npandas\npypistats\nplotly\n```\n\n----------------------------------------\n\nTITLE: Loading and Filtering Airbnb Data with Pandas and Datasets in Python\nDESCRIPTION: This snippet loads the 'gradio/NYC-Airbnb-Open-Data' dataset from Hugging Face Hub using the `datasets` library and converts it to a Pandas DataFrame. It also defines the initial part of a function `filter_map` which takes minimum price, maximum price, and a list of boroughs as input. Inside the function, it filters the main DataFrame based on these criteria and extracts lists of Airbnb names and prices to be used later for map labels.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/plot-component-for-maps.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\ndf = dataset.to_pandas()\n\ndef filter_map(min_price, max_price, boroughs):\n    new_df = df[(df['neighbourhood_group'].isin(boroughs)) &\n            (df['price'] > min_price) & (df['price'] < max_price)]\n    names = new_df[\"name\"].tolist()\n    prices = new_df[\"price\"].tolist()\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\n```\n\n----------------------------------------\n\nTITLE: Launching Gradio Theme Builder Demo\nDESCRIPTION: This snippet imports the theme builder demo from Gradio and launches it. It uses a conditional statement to ensure the demo is only launched when the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_builder/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio.themes.builder_app import demo\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Object Detection Demo\nDESCRIPTION: Downloads a sample video file and a custom drawing utility from the Gradio GitHub repository for use in the object detection demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rt-detr-object-detection/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/rt-detr-object-detection/3285790-hd_1920_1080_30fps.mp4\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/rt-detr-object-detection/draw_boxes.py\n```\n\n----------------------------------------\n\nTITLE: Defining Image Classification Prediction Function (Python)\nDESCRIPTION: This snippet defines a Python function `classify_image` that takes an image as a NumPy array, preprocesses it for the MobileNetV2 model (reshaping, applying specific preprocessing), performs prediction using the previously loaded `inception_net`, and returns a dictionary mapping class labels (downloaded from a specified URL) to their corresponding confidence scores.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/image-classification-in-tensorflow.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport requests\n\n# Download human-readable labels for ImageNet.\nresponse = requests.get(\"https://git.io/JJkYN\")\nlabels = response.text.split(\"\\n\")\n\ndef classify_image(inp):\n  inp = inp.reshape((-1, 224, 224, 3))\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n  prediction = inception_net.predict(inp).flatten()\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n  return confidences\n```\n\n----------------------------------------\n\nTITLE: Implementing Clear Event Handler with UUID State\nDESCRIPTION: Demonstrates clear event handling with state management using UUID generation and ChatInterface integration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/05_chatbot-specific-events.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom uuid import uuid4\nimport gradio as gr\n\n\ndef clear():\n    print(\"Cleared uuid\")\n    return uuid4()\n\n\ndef chat_fn(user_input, history, uuid):\n    return f\"{user_input} with uuid {uuid}\"\n\n\nwith gr.Blocks() as demo:\n    uuid_state = gr.State(\n        uuid4\n    )\n    chatbot = gr.Chatbot(type=\"messages\")\n    chatbot.clear(clear, outputs=[uuid_state])\n\n    gr.ChatInterface(\n        chat_fn,\n        additional_inputs=[uuid_state],\n        chatbot=chatbot,\n        type=\"messages\"\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Connecting to a Private Hugging Face Space\nDESCRIPTION: Shows how to connect to a private Hugging Face Space by providing an authentication token with the hf_token parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/my-private-space\", hf_token=\"...\")\n```\n\n----------------------------------------\n\nTITLE: Creating Timer Application with Gradio\nDESCRIPTION: This snippet creates a Gradio application with a timer, timestamp display, and random number generator. It includes buttons to control the timer's behavior. The application updates the timestamp every second and generates a random number between 1 and 10.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timer_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\nimport time\n\nwith gr.Blocks() as demo:\n  timer = gr.Timer(1)\n  timestamp = gr.Number(label=\"Time\")\n  timer.tick(lambda: round(time.time()), outputs=timestamp)\n\n  number = gr.Number(lambda: random.randint(1, 10), every=timer, label=\"Random Number\")\n  with gr.Row():\n    gr.Button(\"Start\").click(lambda: gr.Timer(active=True), None, timer)\n    gr.Button(\"Stop\").click(lambda: gr.Timer(active=False), None, timer)\n    gr.Button(\"Go Fast\").click(lambda: 0.2, None, timer)\n\nif __name__ == \"__main__\":\n  demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Setting Allowed Paths\nDESCRIPTION: Specifies paths that Gradio is allowed to serve.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_9\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_ALLOWED_PATHS=\"/mnt/sda1,/mnt/sda2\"\n```\n\n----------------------------------------\n\nTITLE: Defining BaseMultimodalTextbox Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseMultimodalTextbox component. It includes various options for customizing the textbox, such as value, placeholder, lines, disabled state, and more. These properties allow for flexible configuration of the textbox component in Gradio interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/multimodaltextbox/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value = \"\";\nexport let value_is_output = false;\nexport let lines = 1;\nexport let placeholder = \"Type here...\";\nexport let label: string;\nexport let info: string | undefined = undefined;\nexport let disabled = false;\nexport let show_label = true;\nexport let container = true;\nexport let max_lines: number;\nexport let type: \"text\" | \"password\" | \"email\" = \"text\";\nexport let show_copy_button = false;\nexport let rtl = false;\nexport let autofocus = false;\nexport let text_align: \"left\" | \"right\" | undefined = undefined;\nexport let autoscroll = true;\n```\n\n----------------------------------------\n\nTITLE: Generating Random Plotly Scatter Plot in Python\nDESCRIPTION: This function creates a random scatter plot using Plotly Express with Iris dataset. It plots sepal width vs sepal length, colored by species, with petal length determining point size.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef random_plot():\n    df = px.data.iris()\n    fig = px.scatter(\n        df,\n        x=\"sepal_width\",\n        y=\"sepal_length\",\n        color=\"species\",\n        size=\"petal_length\",\n        hover_data=[\"petal_width\"],\n    )\n    return fig\n```\n\n----------------------------------------\n\nTITLE: Making POST Request with Authentication Cookies\nDESCRIPTION: Uses the saved cookies from login to make an authenticated POST request to call a Gradio API endpoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_16\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST $URL/call/$API_NAME -b cookies.txt -H \"Content-Type: application/json\" -d '{\n  \"data\": $PAYLOAD\n}'\n```\n\n----------------------------------------\n\nTITLE: Configuring Static File Access in Gradio\nDESCRIPTION: Demonstrates how to set up static file paths and display local images in a Gradio application using absolute paths.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/08_file-access.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nimport gradio as gr\n\ngr.set_static_paths(paths=[Path.cwd().absolute()/\"assets\"]])\n\nwith gr.Blocks() as demo:\n    gr.HTML(\"<img src='/gradio_api/file=assets/logo.png'>\")\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample CSV File for Gradio Demo\nDESCRIPTION: This snippet first creates a directory named 'files' using Python's `os` module. Then, it executes a shell command via `!` to download the `titanic.csv` file from a GitHub repository into the newly created 'files' directory using `wget`. The `-q` flag makes the download quiet, and `-O` specifies the output file path.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/zip_files/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/titanic.csv https://github.com/gradio-app/gradio/raw/main/demo/zip_files/files/titanic.csv\n```\n\n----------------------------------------\n\nTITLE: Connecting to a Public Hugging Face Space\nDESCRIPTION: Demonstrates connecting to a public Hugging Face Space that provides English to French translation functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/en2fr\")  # a Space that translates from English to French\n```\n\n----------------------------------------\n\nTITLE: Chat History Save Support\nDESCRIPTION: Feature implementation that added support for saving chat history in Gradio's ChatInterface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10191](https://github.com/gradio-app/gradio/pull/10191) [`5ce2832`](https://github.com/gradio-app/gradio/commit/5ce28324971e974ae24dc9a229b2160793140fb2) - Support saving chat history in `gr.ChatInterface`.\n```\n\n----------------------------------------\n\nTITLE: Chat History Structure Example\nDESCRIPTION: Example showing the structure of chat history using OpenAI-style dictionaries\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n[\n    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n    {\"role\": \"assistant\", \"content\": \"Paris\"}\n]\n```\n\n----------------------------------------\n\nTITLE: Text Difference Visualization Implementation\nDESCRIPTION: Creates a Gradio interface that compares two text inputs and highlights their differences. Uses Python's difflib.Differ to compute text differences and displays them with color-coded highlighting (red for additions, green for deletions). The interface includes two text input boxes with default values and a highlighted text output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/diff_texts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom difflib import Differ\n\nimport gradio as gr\n\ndef diff_texts(text1, text2):\n    d = Differ()\n    return [\n        (token[2:], token[0] if token[0] != \" \" else None)\n        for token in d.compare(text1, text2)\n    ]\n\ndemo = gr.Interface(\n    diff_texts,\n    [\n        gr.Textbox(\n            label=\"Text 1\",\n            info=\"Initial text\",\n            lines=3,\n            value=\"The quick brown fox jumped over the lazy dogs.\",\n        ),\n        gr.Textbox(\n            label=\"Text 2\",\n            info=\"Text to compare\",\n            lines=3,\n            value=\"The fast brown fox jumps over lazy dogs.\",\n        ),\n    ],\n    gr.HighlightedText(\n        label=\"Diff\",\n        combine_adjacent=True,\n        show_legend=True,\n        color_map={\"+\": \"red\", \"-\": \"green\"}),\n    theme=gr.themes.Base()\n)\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Demo Interface for JoJoGAN\nDESCRIPTION: Code to create a Gradio web interface for the JoJoGAN model. This snippet defines a simple user interface that takes an input image and displays the stylized output image.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ntitle = \"JoJoGAN\"\ndescription = \"JoJoGAN 的 Gradio 演示：一次性面部风格化。要使用它，只需上传您的图像，或单击示例之一加载它们。在下面的链接中阅读更多信息。\"\n\ndemo = gr.Interface(\n    inference,\n    gr.Image(type=\"pil\"),\n    gr.Image(type=\" 文件 \"),\n    title=title,\n    description=description\n)\n\ndemo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Exporting Value Property in BaseJSON (HTML/JavaScript)\nDESCRIPTION: This snippet sets up an exportable 'value' property initialized as an empty object. It enables two-way data binding or external control of the value used by the BaseJSON component, as typically done in Svelte components. There are no external dependencies aside from the overall expected Svelte or similar setup. The 'value' parameter holds any data, acting as input/output for the JSON data represented by BaseJSON. Limitations: This code assumes a JavaScript-based component framework that supports export syntax (such as Svelte).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/README.md#2025-04-23_snippet_1\n\nLANGUAGE: html\nCODE:\n```\n\\texport let value: any = {};\n```\n\n----------------------------------------\n\nTITLE: Building Gradio UI with Rows and Columns Layout\nDESCRIPTION: Creates a Gradio UI layout using nested rows and columns to organize components. The layout includes textboxes, a dropdown, buttons, and an image with specified scaling and minimum width properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rows_and_columns/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        text1 = gr.Textbox(label=\"t1\")\n        slider2 = gr.Textbox(label=\"s2\")\n        drop3 = gr.Dropdown([\"a\", \"b\", \"c\"], label=\"d3\")\n    with gr.Row():\n        with gr.Column(scale=1, min_width=300):\n            text1 = gr.Textbox(label=\"prompt 1\")\n            text2 = gr.Textbox(label=\"prompt 2\")\n            inbtw = gr.Button(\"Between\")\n            text4 = gr.Textbox(label=\"prompt 1\")\n            text5 = gr.Textbox(label=\"prompt 2\")\n        with gr.Column(scale=2, min_width=300):\n            img1 = gr.Image(\"images/cheetah.jpg\")\n            btn = gr.Button(\"Go\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Interface with System Prompt\nDESCRIPTION: Creates a chat interface using Gradio that echoes messages with system prompts and controlled token output. The implementation includes a streaming response effect and allows customization of system prompt and response length through additional inputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_system_prompt/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef echo(message, history, system_prompt, tokens):\n    response = f\"System prompt: {system_prompt}\\n Message: {message}.\"\n    for i in range(min(len(response), int(tokens))):\n        time.sleep(0.05)\n        yield response[: i + 1]\n\ndemo = gr.ChatInterface(\n    echo,\n    type=\"messages\",\n    additional_inputs=[\n        gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\"),\n        gr.Slider(10, 100),\n    ],\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Illustrating Default Nested Gradio Layout Rendering Python\nDESCRIPTION: Shows the default Gradio implementation for nested layouts using `with` statements. A `Row` layout containing `Textbox` components is nested within a `Tab` layout. Both the `Textbox` components and the `Row` itself are implicitly rendered within their respective parent contexts.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith Tab():\n    with Row():\n        first_textbox = Textbox(value=\"first_textbox\")\n        second_textbox = Textbox(value=\"second_textbox\")\n```\n\n----------------------------------------\n\nTITLE: Implementing File Explorer Component\nDESCRIPTION: Creates a simple Gradio interface that displays a FileExplorer component. The demo is created using Blocks API and launched for interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.FileExplorer()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Detecting Changes in Example.svelte for Gradio Custom Components\nDESCRIPTION: This update allows Gradio custom component dev mode to detect changes to the Example.svelte file, improving the development workflow for custom components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\n// Code not provided in the changelog\n```\n\n----------------------------------------\n\nTITLE: Manual FRP Client Installation Instructions (Shell/Text Output)\nDESCRIPTION: Provides troubleshooting guidance for cases where the automatic FRP Client download fails, often because of antivirus interference. This text block gives the user a sequence of shell-like commands and steps for downloading, renaming, and moving the required binary to enable share link functionality. No code execution is performed, but the shell/text output should be followed exactly for successful manual installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/understanding-gradio-share-links.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nCould not create share link. Missing file: /Users/.../frpc_darwin_arm64_v0.3. \\n\\nPlease check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \\n\\n1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\\n2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\\n3. Move the file to this location: /Users/...\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Color Picker Demo\nDESCRIPTION: This snippet imports Gradio, creates a Blocks interface with a ColorPicker component, and launches the demo. The ColorPicker allows users to select colors visually.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/colorpicker_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.ColorPicker()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring the FilePreview Component in Gradio Svelte (JavaScript)\nDESCRIPTION: Specifies the exported properties for FilePreview, which provides a preview display of file data within the Gradio UI. The props enable file data input (single or multiple), toggling selection, custom height, and localization. Inputs are of type FileData or arrays, with outputs guiding the preview rendering logic.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: FileData | FileData[];\\n\\texport let selectable = false;\\n\\texport let height: number | undefined = undefined;\\n\\texport let i18n: I18nFormatter;\\n\n```\n\n----------------------------------------\n\nTITLE: Unit Tests for ColorPicker Component\nDESCRIPTION: This code defines unit tests for the ColorPicker component, testing various functionalities including preprocessing, postprocessing, serialization, configuration, and interface integration as both input and output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/creating-a-new-component.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass TestColorPicker(unittest.TestCase):\n    def test_component_functions(self):\n        \"\"\"\n        Preprocess, postprocess, serialize, save_flagged, restore_flagged, tokenize, get_config\n        \"\"\"\n        color_picker_input = gr.ColorPicker()\n        self.assertEqual(color_picker_input.preprocess(\"#000000\"), \"#000000\")\n        self.assertEqual(color_picker_input.preprocess_example(\"#000000\"), \"#000000\")\n        self.assertEqual(color_picker_input.postprocess(None), None)\n        self.assertEqual(color_picker_input.postprocess(\"#FFFFFF\"), \"#FFFFFF\")\n        self.assertEqual(color_picker_input.serialize(\"#000000\", True), \"#000000\")\n\n        color_picker_input.interpretation_replacement = \"unknown\"\n\n        self.assertEqual(\n            color_picker_input.get_config(),\n            {\n                \"value\": None,\n                \"show_label\": True,\n                \"label\": None,\n                \"style\": {},\n                \"elem_id\": None,\n                \"visible\": True,\n                \"interactive\": None,\n                \"name\": \"colorpicker\",\n            },\n        )\n\n    def test_in_interface_as_input(self):\n        \"\"\"\n        接口、处理、解释\n        \"\"\"\n        iface = gr.Interface(lambda x: x, \"colorpicker\", \"colorpicker\")\n        self.assertEqual(iface.process([\"#000000\"]), [\"#000000\"])\n\n    def test_in_interface_as_output(self):\n        \"\"\"\n        接口、处理\n\n        \"\"\"\n        iface = gr.Interface(lambda x: x, \"colorpicker\", gr.ColorPicker())\n        self.assertEqual(iface.process([\"#000000\"]), [\"#000000\"])\n\n    def test_static(self):\n        \"\"\"\n        后处理\n        \"\"\"\n        component = gr.ColorPicker(\"#000000\")\n        self.assertEqual(component.get_config().get(\"value\"), \"#000000\")\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio NER Demo (Python)\nDESCRIPTION: This command uses pip, the Python package installer, to quietly (-q) install the necessary libraries: `gradio` for building the web interface, `torch` as the backend for the Transformers model, and `transformers` for accessing the pre-trained NER pipeline.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/ner_pipeline/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch transformers\n```\n\n----------------------------------------\n\nTITLE: HTML Frontend Template\nDESCRIPTION: HTML template for the web interface including styling and video gallery display\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_6\n\nLANGUAGE: html\nCODE:\n```\n<!DOCTYPE html> <html> <head> <title>Video Gallery</title>\n<style> body { font-family: sans-serif; margin: 0; padding: 0;\nbackground-color: #f5f5f5; } h1 { text-align: center; margin-top: 30px;\nmargin-bottom: 20px; } .gallery { display: flex; flex-wrap: wrap;\njustify-content: center; gap: 20px; padding: 20px; } .video { border: 2px solid\n#ccc; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.2); border-radius: 5px; overflow:\nhidden; width: 300px; margin-bottom: 20px; } .video video { width: 100%; height:\n200px; } .video p { text-align: center; margin: 10px 0; } form { margin-top:\n20px; text-align: center; } input[type=\"file\"] { display: none; } .upload-btn {\ndisplay: inline-block; background-color: #3498db; color: #fff; padding: 10px\n20px; font-size: 16px; border: none; border-radius: 5px; cursor: pointer; }\n.upload-btn:hover { background-color: #2980b9; } .file-name { margin-left: 10px;\n} </style> </head> <body> <h1>Video Gallery</h1> {% if videos %}\n<div class=\"gallery\"> {% for video in videos %} <div class=\"video\">\n<video controls> <source src=\"{{ url_for('static', path=video) }}\"\ntype=\"video/mp4\"> Your browser does not support the video tag. </video>\n<p>{{ video }}</p> </div> {% endfor %} </div> {% else %} <p>No\nvideos uploaded yet.</p> {% endif %} <form action=\"/uploadvideo/\"\nmethod=\"post\" enctype=\"multipart/form-data\"> <label for=\"video-upload\"\nclass=\"upload-btn\">Choose video file</label> <input type=\"file\"\nname=\"video\" id=\"video-upload\"> <span class=\"file-name\"></span> <button\ntype=\"submit\" class=\"upload-btn\">Upload</button> </form> <script> //\nDisplay selected file name in the form const fileUpload =\ndocument.getElementById(\"video-upload\"); const fileName =\ndocument.querySelector(\".file-name\"); fileUpload.addEventListener(\"change\", (e)\n=> { fileName.textContent = e.target.files[0].name; }); </script> </body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Implementing Video Component with Data Model\nDESCRIPTION: Example showing how to define a Video component using GradioModel for data validation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/04_backend.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio.data_classes import FileData, GradioModel\n\nclass VideoData(GradioModel):\n    video: FileData\n    subtitles: Optional[FileData] = None\n\nclass Video(Component):\n    data_model = VideoData\n```\n\n----------------------------------------\n\nTITLE: Defining Multi-Input Examples in Gradio using log.csv (CSV)\nDESCRIPTION: This snippet shows the structure of a `log.csv` file used by Gradio to load examples from a directory for an interface with multiple inputs (e.g., a calculator). Column headers (`num`, `operation`, `num2`) correspond to input components, and each row represents a complete set of example inputs. This format is specified when setting the `examples` parameter of `gr.Interface` to a directory path containing this file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/02_building-interfaces/03_more-on-examples.md#2025-04-23_snippet_0\n\nLANGUAGE: csv\nCODE:\n```\nnum,operation,num2\n5,\"add\",3\n4,\"divide\",2\n5,\"multiply\",3\n```\n\n----------------------------------------\n\nTITLE: Implementing render event listener for gradio-app web component\nDESCRIPTION: Demonstrates how to add an event listener for the render event on the gradio-app web component, which fires when an embedded space has finished rendering.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: html\nCODE:\n```\n<script>\n  function handleLoadComplete() {\n    console.log(\"Embedded space has finished rendering\");\n  }\n  const gradioApp = document.querySelector(\"gradio-app\");\n  gradioApp.addEventListener(\"render\", handleLoadComplete);\n</script>\n```\n\n----------------------------------------\n\nTITLE: Implementing File Upload and Clear Handlers in TypeScript\nDESCRIPTION: Defines functions to handle file uploads and clear operations. These functions update the component state and dispatch Gradio events to notify the application of changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_10\n\nLANGUAGE: typescript\nCODE:\n```\nasync function handle_clear() {\n    _value = null;\n    await tick();\n    gradio.dispatch(\"change\");\n}\n\nasync function handle_upload({detail}: CustomEvent<FileData>): Promise<void> {\n    value = detail;\n    await tick();\n    gradio.dispatch(\"change\");\n    gradio.dispatch(\"upload\");\n}\n```\n\n----------------------------------------\n\nTITLE: Accessing Gradio Files URL Structure\nDESCRIPTION: Demonstrates the URL format used to access files exposed by a Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/08_file-access.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nhttp://<your-gradio-app-url>/gradio_api/file=<local-file-path>\n```\n\n----------------------------------------\n\nTITLE: Embedding Gradio App with IFrames\nDESCRIPTION: Example showing how to embed a Gradio app using an iframe element.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<iframe src=\"https://$your_space_host.hf.space\"></iframe>\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio Files for Speaker Verification\nDESCRIPTION: This code creates a 'samples' directory and downloads sample audio files from the Gradio demo repository for testing the speaker verification model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unispeech-speaker-verification/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('samples')\n!wget -q -O samples/cate_blanch.mp3 https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/cate_blanch.mp3\n!wget -q -O samples/cate_blanch_2.mp3 https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/cate_blanch_2.mp3\n!wget -q -O samples/cate_blanch_3.mp3 https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/cate_blanch_3.mp3\n!wget -q -O samples/heath_ledger.mp3 https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/heath_ledger.mp3\n!wget -q -O samples/heath_ledger_2.mp3 https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/heath_ledger_2.mp3\n!wget -q -O samples/kirsten_dunst.wav https://github.com/gradio-app/gradio/raw/main/demo/unispeech-speaker-verification/samples/kirsten_dunst.wav\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio Tabbed Interface in Python\nDESCRIPTION: This Python script demonstrates the creation of a Gradio application with multiple tabs. It imports the Gradio library, defines two simple `gr.Interface` instances (`hello_world`, `bye_world`) and one `gr.ChatInterface`. These interfaces are then combined into a `gr.TabbedInterface` with specified tab titles. Finally, it launches the web interface using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabbed_interface_lite/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nhello_world = gr.Interface(lambda name: \"Hello \" + name, \"text\", \"text\")\nbye_world = gr.Interface(lambda name: \"Bye \" + name, \"text\", \"text\")\nchat = gr.ChatInterface(lambda *args: \"Hello \" + args[0])\n\ndemo = gr.TabbedInterface([hello_world, bye_world, chat], [\"Hello World\", \"Bye World\", \"Chat\"])\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching Gradio Video Identity Interface\nDESCRIPTION: This snippet defines a video_identity function that returns the input video, creates a Gradio Interface with video input and output, and launches the demo. It includes an example video file path.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_identity/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef video_identity(video):\n    return video\n\ndemo = gr.Interface(video_identity,\n                    gr.Video(),\n                    \"playable_video\",\n                    examples=[\n                        os.path.join(os.path.abspath(''),\n                                     \"video/video_sample.mp4\")],\n                    cache_examples=True)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Multiple Input Components Request\nDESCRIPTION: Example of making a POST request with multiple input types including text, boolean, and numerical values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://gradio-hello-world-3.hf.space/call/predict -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Hello\", true, 5]\n}'\n```\n\n----------------------------------------\n\nTITLE: Enhancing gr.File Component in Gradio\nDESCRIPTION: Allows setting a height to the gr.File component and improves its UI.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n- [#5221](https://github.com/gradio-app/gradio/pull/5221) [`f344592a`](https://github.com/gradio-app/gradio/commit/f344592aeb1658013235ded154107f72d86f24e7) - Allows setting a height to `gr.File` and improves the UI of the component. Thanks [@abidlabs](https://github.com/abidlabs)!\n```\n\n----------------------------------------\n\nTITLE: Setting Hardware Configuration for Duplicated Spaces\nDESCRIPTION: Shows how to specify hardware configuration when duplicating a Gradio space. Allows selection from various hardware tiers ranging from basic CPU to high-end GPU options.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_19\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true,\n\thardware: \"a10g-small\"\n});\n```\n\n----------------------------------------\n\nTITLE: Defining BaseModel3DUpload Component in Gradio\nDESCRIPTION: This snippet defines the properties for the BaseModel3DUpload component. It is similar to BaseModel3D but includes an additional 'root' property. This component is likely used for handling 3D model file uploads in Gradio interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/model3D/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: null | FileData;\nexport let clear_color: [number, number, number, number] = [0, 0, 0, 0];\nexport let label = \"\";\nexport let show_label: boolean;\nexport let root: string;\nexport let i18n: I18nFormatter;\nexport let zoom_speed = 1;\n\n// alpha, beta, radius\nexport let camera_position: [number | null, number | null, number | null] = [\n\tnull,\n\tnull,\n\tnull\n];\n```\n\n----------------------------------------\n\nTITLE: Extending Gradio Theme Core Sizing in Constructor - Python (String Shortcuts)\nDESCRIPTION: Shows how to update the core spacing and radius variables for the theme by passing string shortcuts to the gr.themes.Default() constructor. Here, 'spacing_size' and 'radius_size' are set to 'sm' and 'none', respectively. This affects element padding and border radius. Requires Gradio. Place UI components within the context block.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Default(spacing_size=\\\"sm\\\", radius_size=\\\"none\\\")) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Setting up Full-Context Speech Recognition Demo\nDESCRIPTION: Referenced but not shown in text. Creates a function for full-context ASR using Gradio's Audio component and textbox for output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/05_real-time-speech-recognition.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Code referenced as $code_asr but not provided in the text\n```\n\n----------------------------------------\n\nTITLE: File Handling with Python Gradio Client\nDESCRIPTION: Example demonstrating how to handle file uploads with the updated Gradio client API. Shows proper usage of the handle_file method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client, handle_file\n\nclient = Client(\"gradio/image_captioner\")\nclient.predict(handle_file(\"cute_cat.jpg\"))\n```\n\n----------------------------------------\n\nTITLE: Building for Production with Gulp (Bash)\nDESCRIPTION: This Bash command uses Gulp to execute a build task specifically configured for a production environment, indicated by the '--prod' flag. This is part of the Dillinger build instructions within the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ngulp build --prod\n```\n\n----------------------------------------\n\nTITLE: Connecting to a Gradio App via URL\nDESCRIPTION: Shows how to connect to a Gradio application running on a custom URL, such as a temporary share link.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"https://bec81a83-5b5c-471e.gradio.live\")\n```\n\n----------------------------------------\n\nTITLE: Connecting to Private Spaces\nDESCRIPTION: Example showing how to connect to private Hugging Face Spaces using an authentication token.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"abidlabs/my-private-space\", { hf_token: \"hf_...\" })\n```\n\n----------------------------------------\n\nTITLE: Configuring PR Comment Workflows\nDESCRIPTION: Describes the implementation of a queued commenting system for pull requests using GitHub Actions, ensuring serialized comment updates across multiple jobs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_4\n\nLANGUAGE: yaml\nCODE:\n```\ncomment-queue.yml:\\nconcurrency:\\n  group: pr-${{ github.event.pull_request.number }}\n```\n\n----------------------------------------\n\nTITLE: Handling Blob Objects with handle_file\nDESCRIPTION: Shows how to process Blob objects using handle_file utility. The upload is deferred until predict or submit is called.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_23\n\nLANGUAGE: typescript\nCODE:\n```\nimport { handle_file } from \"@gradio/client\";\n\n// not uploaded yet\nconst blob_ref = handle_file(new Blob([\"Hello, world!\"]));;\n\nconst app = await Client.connect(\"user/space-name\");\n\n// upload happens here\nconst result = await app.predict(\"/predict\", {\n\tblob: blob_ref,\n});\n```\n\n----------------------------------------\n\nTITLE: Embedding W&B Reports in Gradio Apps\nDESCRIPTION: Code to embed Weights & Biases reports within a Gradio application using iframes. This allows for displaying W&B dashboards and visualizations directly in the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef wandb_report(url):\n    iframe = f'<iframe src={url} style=\"border:none;height:1024px;width:100%\">'\n    return gr.HTML(iframe)\n\nwith gr.Blocks() as demo:\n    report_url = 'https://wandb.ai/_scott/pytorch-sweeps-demo/reports/loss-22-10-07-16-00-17---VmlldzoyNzU2NzAx'\n    report = wandb_report(report_url)\n\ndemo.launch(share=True)\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in package.json\nDESCRIPTION: Updates the version of @gradio/icons, @gradio/atoms, and @gradio/statustracker dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/highlightedtext/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"dependencies\": {\n  \"@gradio/icons\": \"0.3.1\",\n  \"@gradio/atoms\": \"0.3.1\",\n  \"@gradio/statustracker\": \"0.4.1\"\n}\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server\nDESCRIPTION: Command to start the development server for testing and hot-reloading the custom component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/01_custom-components-in-five-minutes.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc dev\n```\n\n----------------------------------------\n\nTITLE: Accessing Configuration of a Gradio Application\nDESCRIPTION: Example showing how to access the configuration properties of a connected Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_15\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconsole.log(app.config);\n```\n\n----------------------------------------\n\nTITLE: Handling Streaming Audio Output with Gradio Client in Python\nDESCRIPTION: This Python code demonstrates how to use the `gradio_client` library (version 0.5.0+) to interact with a Gradio application that streams audio output. It shows connecting to a specific Gradio space (`gradio/stream_audio_out`), using `client.predict` to get the final audio file directly, and using `client.submit` for asynchronous processing to access both individual streamed chunks (`job.outputs()`) and the complete result (`job.result()`). The `gradio_client` library is required.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport gradio_client as grc\nclient = grc.Client(\"gradio/stream_audio_out\")\n\n# Get the entire generated audio as a local file\nclient.predict(\"/Users/freddy/Pictures/bark_demo.mp4\", api_name=\"/predict\")\n\njob = client.submit(\"/Users/freddy/Pictures/bark_demo.mp4\", api_name=\"/predict\")\n\n# Get the entire generated audio as a local file\njob.result()\n\n# Each individual chunk\njob.outputs()\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages including Gradio, NumPy, TensorFlow, and Requests using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy tensorflow requests\n```\n\n----------------------------------------\n\nTITLE: Queue Position Monitoring Example\nDESCRIPTION: Example showing how to monitor the queue position of a submitted job using the Python client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/diffusion_model\")\n\njob = client.submit(\"A cute cat\")\nwhile not job.done():\n    status = job.status()\n    print(f\"Current in position {status.rank} out of {status.queue_size}\")\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Fraud Detection Demo in Python\nDESCRIPTION: This snippet installs the required packages (Gradio and Pandas) using pip. These libraries are necessary for creating the web interface and handling data operations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fraud_detector/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Size Limits in Gradio Python\nDESCRIPTION: Demonstrates how to set maximum file size limits for uploads in a Gradio interface. The limit can be specified either as a string value like '5mb' or as bytes using the FileSize enum.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/simpleimage/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits in Gradio\nDESCRIPTION: Demonstrates how to set a maximum file size limit for uploads in a Gradio interface using the 'max_file_size' parameter in the launch() method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: GitHub Actions Event Context and Branch Reference - Markdown Documentation\nDESCRIPTION: Detailed documentation in markdown format explaining GitHub Actions workflow triggers, branch contexts, and security considerations. Includes information about different event types (pull_request, pull_request_target, push, workflow_dispatch, workflow_run) and their implications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n#### The problem\n\nWe have the following constraints and challenges:\n\n- We have a relatively comprehensive CI suite, different components have their own idiosyncracies.\n- Many of our jobs need access to secrets but security is a high priority.\n- We are an open source project and want the same experience for contributors (PRs from forks) as the core team have (PRs from repo branches).\n- We want to make all of the important checks required.\n- We want CI to be fast, certain jobs should be skipped where appropriate. These jobs may still be 'required' to pass if—and only if—they run.\n- CI should give confidence over time, we don't want to be overlooking the odd ❌ as a 'normal' part of our CI, even for optional jobs. This will erode trust.\n- Many of our CI jobs share the same steps. We want to avoid excessive duplication where possible for maintenance reasons.\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat Interface with Code Display\nDESCRIPTION: Creates a Gradio chat interface that responds to user queries about Python or JavaScript by displaying corresponding fibonacci function implementations. The interface is split into two columns - one for chat interaction and another for code display.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_artifacts/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\npython_code = \"\"\"\ndef fib(n):\n    if n <= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fib(n-1) + fib(n-2)\n\"\"\"\n\njs_code = \"\"\"\nfunction fib(n) {\n    if (n <= 0) return 0;\n    if (n === 1) return 1;\n    return fib(n - 1) + fib(n - 2);\n}\n\"\"\"\n\ndef chat(message, history):\n    if \"python\" in message.lower():\n        return \"Type Python or JavaScript to see the code.\", gr.Code(language=\"python\", value=python_code)\n    elif \"javascript\" in message.lower():\n        return \"Type Python or JavaScript to see the code.\", gr.Code(language=\"javascript\", value=js_code)\n    else:\n        return \"Please ask about Python or JavaScript.\", None\n\nwith gr.Blocks() as demo:\n    code = gr.Code(render=False)\n    with gr.Row():\n        with gr.Column():\n            gr.Markdown(\"<center><h1>Write Python or JavaScript</h1></center>\")\n            gr.ChatInterface(\n                chat,\n                examples=[\"Python\", \"JavaScript\"],\n                additional_outputs=[code],\n                type=\"messages\"\n            )\n        with gr.Column():\n            gr.Markdown(\"<center><h1>Code Artifacts</h1></center>\")\n            code.render()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Interface with Flagging Options (Python)\nDESCRIPTION: Demonstrates configuring the Gradio Interface to provide specific reasons for flagging. By passing a list of strings to the `flagging_options` parameter, users are presented with buttons corresponding to these options (e.g., 'Flag as wrong sign'). The selected option is logged along with the data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    flagging_mode=\"manual\",\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"]\n)\n\niface.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Checkbox Component\nDESCRIPTION: Creates a simple checkbox component using Gradio's Blocks interface and launches the demo. The checkbox is created without any customization options using the default settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/checkbox_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Checkbox()\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy Dependencies using pip\nDESCRIPTION: Installs the `gradio` and `numpy` libraries using pip. The `-q` flag ensures a quiet installation, suppressing output except for errors. These libraries are prerequisites for running the subsequent Gradio demo code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_frames/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy \n```\n\n----------------------------------------\n\nTITLE: Implementing Disease Detection Demo with Gradio\nDESCRIPTION: This code creates a Gradio interface for disease detection from medical scans. It defines models for X-ray and CT scan analysis, sets up the user interface with tabs for different scan types, and includes options for selecting diseases and uploading results.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_xray/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndisease_values = [0.25, 0.5, 0.75]\n\ndef xray_model(diseases, img):\n    return [{disease: disease_values[idx] for idx,disease in enumerate(diseases)}]\n\ndef ct_model(diseases, img):\n    return [{disease: 0.1 for disease in diseases}]\n\nwith gr.Blocks(fill_width=True) as demo:\n    gr.Markdown(\n        \"\"\"\n# Detect Disease From Scan\nWith this model you can lorem ipsum\n- ipsum 1\n- ipsum 2\n\"\"\"\n    )\n    gr.DuplicateButton()\n    disease = gr.CheckboxGroup(\n        info=\"Select the diseases you want to scan for.\",\n        choices=[\"Covid\", \"Malaria\", \"Lung Cancer\"], label=\"Disease to Scan For\"\n    )\n    slider = gr.Slider(0, 100)\n\n    with gr.Tab(\"X-ray\") as x_tab:\n        with gr.Row():\n            xray_scan = gr.Image()\n            xray_results = gr.JSON()\n        xray_run = gr.Button(\"Run\")\n        xray_run.click(\n            xray_model,\n            inputs=[disease, xray_scan],\n            outputs=xray_results,\n            api_name=\"xray_model\"\n        )\n\n    with gr.Tab(\"CT Scan\"):\n        with gr.Row():\n            ct_scan = gr.Image()\n            ct_results = gr.JSON()\n        ct_run = gr.Button(\"Run\")\n        ct_run.click(\n            ct_model,\n            inputs=[disease, ct_scan],\n            outputs=ct_results,\n            api_name=\"ct_model\"\n        )\n\n    upload_btn = gr.Button(\"Upload Results\", variant=\"primary\")\n    upload_btn.click(\n        lambda ct, xr: None,\n        inputs=[ct_results, xray_results],\n        outputs=[],\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Streaming from Gradio App in Python\nDESCRIPTION: Example showing how to stream results from a Gradio app using the Python client in 5 lines of code\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/llm_stream\")\n\nfor result in client.submit(\"What's the best UI framework in Python?\"):\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Gradio Gallery Demo\nDESCRIPTION: Creates a 'files' directory and downloads sample image and video files from the Gradio GitHub repository using wget.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/cheetah.jpg https://github.com/gradio-app/gradio/raw/main/demo/gallery_component/files/cheetah.jpg\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/gallery_component/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseInteractiveHighlightedText Component - JavaScript\nDESCRIPTION: This snippet defines the exported props for the BaseInteractiveHighlightedText component in Svelte. The 'value' prop expects an array of tokens with associated class or confidence data, and additional props include 'show_legend', 'color_map', and 'selectable' for customizing the component's display and interactivity. This code is intended as a Svelte prop configuration with JavaScript/TypeScript syntax.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/highlightedtext/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n  export let value: {\n    token: string;\n    class_or_confidence: string | number | null;\n  }[] = [];\n  export let show_legend = false;\n  export let color_map: Record<string, string> = {};\n  export let selectable = false;\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Dashboard (Shell)\nDESCRIPTION: This command uses pip to install the required Python packages: gradio, numpy, pandas, and plotly. These libraries are necessary for running the Gradio live dashboard application. The '-q' flag ensures a quiet installation, suppressing verbose output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/live_dashboard/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio numpy pandas plotly \n```\n\n----------------------------------------\n\nTITLE: BaseInteractiveAudio Component Properties\nDESCRIPTION: Defines the properties for the BaseInteractiveAudio component, which allows recording or uploading audio. It includes properties for the audio value, input sources (microphone/upload), state handling, and display settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/audio/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let root: string;\n\texport let show_label = true;\n\texport let sources:\n\t\t| [\"microphone\"]\n\t\t| [\"upload\"]\n\t\t| [\"microphone\", \"upload\"]\n\t\t| [\"upload\", \"microphone\"] = [\"microphone\", \"upload\"];\n\texport let pending = false;\n\texport let streaming = false;\n\texport let autoplay = false;\n\texport let i18n: I18nFormatter;\n\texport let waveform_settings = {};\n\texport let dragging: boolean;\n\texport let active_source: \"microphone\" | \"upload\";\n\texport let handle_reset_value: () => void = () => {};\n```\n\n----------------------------------------\n\nTITLE: Updating i18n Tokens and Locale Files in Gradio\nDESCRIPTION: Updates internationalization tokens and locale files in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n- [#5216](https://github.com/gradio-app/gradio/pull/5216) [`4b58ea6d`](https://github.com/gradio-app/gradio/commit/4b58ea6d98e7a43b3f30d8a4cb6f379bc2eca6a8) - Update i18n tokens and locale files. Thanks [@hannahblair](https://github.com/hannahblair)!\n```\n\n----------------------------------------\n\nTITLE: Styling for PDF Canvas Container in Svelte\nDESCRIPTION: Adds CSS styling to center the PDF canvas in its container using flexbox layout properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_9\n\nLANGUAGE: svelte\nCODE:\n```\n<style>\n    .pdf-canvas {\n        display: flex;\n        justify-content: center;\n        align-items: center;\n    }\n</style>\n```\n\n----------------------------------------\n\nTITLE: Creating a Scatter Plot with Gradio\nDESCRIPTION: This snippet creates a simple Gradio application that displays a scatter plot using the downloaded dataset. It plots the relationship between weight and height from the provided dataframe.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.ScatterPlot(df, x=\"weight\", y=\"height\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Submitting Requests with Gradio Client\nDESCRIPTION: Example of using the submit method for more flexible API calls that provide status updates and support complex endpoint types.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_9\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst submission = app.submit(\"/predict\", { name: \"Chewbacca\" });\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies with PNPM\nDESCRIPTION: Command to install all package dependencies in the Gradio UI monorepo using PNPM package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npnpm i\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Code Components\nDESCRIPTION: Imports the base code-related components from the Gradio code module including BaseCode, BaseCopy, BaseDownload, BaseWidget, and BaseExample.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseCode, BaseCopy, BaseDownload, BaseWidget, BaseExample} from \"gradio/code\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Python Data Science Package Requirements\nDESCRIPTION: Core Python packages required for data visualization and analysis, including Plotly for interactive charts, NumPy for numerical operations, Pandas for data manipulation, and Matplotlib for static plotting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nplotly\nnumpy\npandas\nmatplotlib\n```\n\n----------------------------------------\n\nTITLE: Including Server Block Configurations in Nginx - Bash\nDESCRIPTION: This snippet demonstrates how to adjust the Nginx main configuration file by including all configuration files from the sites-enabled directory. This enables modular management of multiple server blocks for different applications or domains. The include directive should be added to the http block of /etc/nginx/nginx.conf.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-gradio-on-your-web-server-with-nginx.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ninclude /etc/nginx/sites-enabled/*;\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio Image Editor Demo in Python\nDESCRIPTION: This Python script demonstrates the use of the Gradio `ImageEditor` component. It imports Gradio, defines a `predict` function to extract the composite image, and sets up a Gradio interface using `gr.Blocks`. The interface includes an `ImageEditor` for image manipulation, an `Image` component for previewing the composite result, and counters for tracking upload, change, and input events. Event listeners are attached to the `ImageEditor` to update the counters and the preview image dynamically. Finally, it launches the Gradio application if run as the main script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\n\ndef sleep(im):\n    time.sleep(5)\n    return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1], im[\"composite\"]]\n\n\ndef predict(im):\n    return im[\"composite\"]\n\n\nwith gr.Blocks() as demo:\n    with gr.Row():\n        im = gr.ImageEditor(\n            type=\"numpy\",\n            crop_size=\"1:1\",\n        )\n        im_preview = gr.Image()\n    n_upload = gr.Number(0, label=\"Number of upload events\", step=1)\n    n_change = gr.Number(0, label=\"Number of change events\", step=1)\n    n_input = gr.Number(0, label=\"Number of input events\", step=1)\n\n    im.upload(lambda x: x + 1, outputs=n_upload, inputs=n_upload)\n    im.change(lambda x: x + 1, outputs=n_change, inputs=n_change)\n    im.input(lambda x: x + 1, outputs=n_input, inputs=n_input)\n    im.change(predict, outputs=im_preview, inputs=im, show_progress=\"hidden\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseStaticHighlightedText Component - JavaScript\nDESCRIPTION: This snippet defines exported props for a Svelte component wrapping BaseStaticHighlightedText. The 'value' prop should be an array of objects representing tokens and their associated classes or confidence scores. Other props control the display of a legend, in-line category labels, color mappings for classes, and whether tokens are selectable. It requires knowledge of the token data structure and is meant for use in Svelte with typed JavaScript or TypeScript.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/highlightedtext/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n  export let value: {\n    token: string;\n    class_or_confidence: string | number | null;\n  }[] = [];\n  export let show_legend = false;\n  export let show_inline_category = true;\n  export let color_map: Record<string, string> = {};\n  export let selectable = false;\n```\n\n----------------------------------------\n\nTITLE: Viewing Playwright Test Traces\nDESCRIPTION: Command for viewing Playwright test traces using the trace viewer tool.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnpx playwright show-trace test-results/<directory-name>/trace.zip\n```\n\n----------------------------------------\n\nTITLE: Aggregating Scatter Plot Values with Nominal X-Axis Categories in Python\nDESCRIPTION: Demonstrates data aggregation in a `gr.ScatterPlot` when the x-axis is nominal (string type). The unique values in the x-axis column automatically act as category bins. The `y_aggregate` argument defines how values within each category are aggregated. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_aggregate_nominal\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Gradio App with @gr.on (Python)\nDESCRIPTION: This Python script defines a simple Gradio application using `gr.Blocks`. It includes an input Textbox (`name`), an output Textbox (`output`), and a Button (`greet_btn`). The `greet` function is decorated with `@gr.on` to listen for both the `submit` event on the `name` Textbox and the `click` event on the `greet_btn`. When triggered, it takes the input `name`, constructs a greeting string, and displays it in the `output` Textbox. The application is launched using `demo.launch()` when the script is executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_decorator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n\n    @gr.on(triggers=[name.submit, greet_btn.click], inputs=name, outputs=output)\n    def greet(name):\n        return \"Hello \" + name + \"!\"\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Comet Configuration File Format\nDESCRIPTION: Example format for .comet.config file to store Comet credentials.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n[comet]\napi_key=<Your API Key>\nworkspace=<Your Workspace Name>\nproject_name=<Your Project Name>\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseStaticImage Props (JavaScript)\nDESCRIPTION: This snippet exports properties for the BaseStaticImage component. Key props include the image value (null or FileData), label, visibility of label and download/share buttons, selectability, as well as root and i18n internationalization support. It enables static display and optional sharing or downloading of images and must be configured using these exported props.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: null | FileData;\\n\\texport let label: string | undefined = undefined;\\n\\texport let show_label: boolean;\\n\\texport let show_download_button = true;\\n\\texport let selectable = false;\\n\\texport let show_share_button = false;\\n\\texport let root: string;\\n\\texport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Progress Demo\nDESCRIPTION: Installs the necessary Python packages: gradio for creating the web interface, tqdm for progress tracking, and datasets for loading example data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio tqdm datasets\n```\n\n----------------------------------------\n\nTITLE: Adding Feature in Markdown Changelog\nDESCRIPTION: This snippet demonstrates how a new feature is documented in the changelog, including a pull request reference and commit hash.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#5498](https://github.com/gradio-app/gradio/pull/5498) [`287fe6782`](https://github.com/gradio-app/gradio/commit/287fe6782825479513e79a5cf0ba0fbfe51443d7) - Publish all components to npm. Thanks [@pngwn](https://github.com/pngwn)!\n```\n\n----------------------------------------\n\nTITLE: Handling Local File Paths in Node Environment\nDESCRIPTION: Shows how to use handle_file with local file paths in a Node.js environment. The file upload occurs when predict or submit is called.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_21\n\nLANGUAGE: typescript\nCODE:\n```\nimport { handle_file } from \"@gradio/client\";\n\n// not uploaded yet\nconst file_ref = handle_file(\"path/to/file\");\n\nconst app = await Client.connect(\"user/space-name\");\n\n// upload happens here\nconst result = await app.predict(\"/predict\", {\n\tfile: file_ref,\n});\n```\n\n----------------------------------------\n\nTITLE: UV-Generated Python Dependencies List\nDESCRIPTION: A complete list of Python package dependencies with exact versions and their dependency chains. This includes both direct dependencies and their sub-dependencies, with comments indicating the dependency relationships.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/test/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\n# This file was autogenerated by uv via the following command:\n#    uv pip compile test/requirements.in -o test/requirements.txt\naiofiles==23.2.1\n    # via gradio\naltair==5.5.0\n    # via -r test/requirements.in\nannotated-types==0.7.0\n    # via pydantic\nanyio==4.8.0\n    # via\n    #   gradio\n    #   httpx\n    #   starlette\n```\n\n----------------------------------------\n\nTITLE: Connecting to a Private Gradio Space with Authentication\nDESCRIPTION: Example of connecting to a private Gradio space using a Hugging Face token for authentication.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\", { hf_token: \"hf_...\" });\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Color Generator\nDESCRIPTION: This snippet installs the necessary Python libraries (gradio, opencv-python, and numpy) for the color generator application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_generator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio opencv-python numpy\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio TTS App\nDESCRIPTION: Defines the necessary Python libraries for the Gradio TTS application. It specifies installing `parler-tts` directly from its GitHub repository, along with `accelerate` for hardware optimization, `spaces` for Hugging Face Spaces integration, `torch` for deep learning capabilities, `pydub` for audio processing tasks, and `transformers` and `huggingface_hub` for interacting with Hugging Face models and the platform. These dependencies are typically installed using a package manager like `pip`, often via a command like `pip install -r <filename>`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/magic_8_ball/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngit+https://github.com/huggingface/parler-tts.git\naccelerate\nspaces\ntorch\npydub\ntransformers\nhuggingface_hub\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Gradio Sidebar Component in Svelte\nDESCRIPTION: This snippet shows how to import the Sidebar component from the @gradio/sidebar package and use it in a Svelte template. The Sidebar component is imported and then used as a custom element in the HTML template.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/sidebar/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { Sidebar } from \"@gradio/sidebar\";\n</script>\n\n<Sidebar>\n</Sidebar>\t\n```\n\n----------------------------------------\n\nTITLE: Duplicating a Gradio Space\nDESCRIPTION: Example demonstrating how to duplicate a Gradio space and connect to the duplicated instance.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_16\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\"\n});\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio demo with CheckboxGroup component\nDESCRIPTION: This snippet demonstrates how to create a simple Gradio interface using the Blocks API. It includes a CheckboxGroup component with three predefined choices and launches the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/checkboxgroup_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.CheckboxGroup(choices=[\"First Choice\", \"Second Choice\", \"Third Choice\"])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: BaseDataFrame Component Properties in Gradio\nDESCRIPTION: Defines the properties for the BaseDataFrame component which handles the display and manipulation of tabular data. Properties include data structure configuration, display options, and internationalization settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let datatype: Datatype | Datatype[];\nexport let label: string | null = null;\nexport let headers: Headers = [];\nlet values: (string | number)[][];\nexport let value: { data: Data; headers: Headers; metadata: Metadata } | null;\nexport let col_count: [number, \"fixed\" | \"dynamic\"];\nexport let row_count: [number, \"fixed\" | \"dynamic\"];\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[];\n\nexport let editable = true;\nexport let wrap = false;\nexport let root: string;\nexport let i18n: I18nFormatter;\n\nexport let height = 500;\nexport let line_breaks = true;\nexport let column_widths: string[] = [];\n```\n\n----------------------------------------\n\nTITLE: BlockLabel Component Props Definition\nDESCRIPTION: Defines the available props for the BlockLabel component, which displays a label with optional icon and configuration for positioning and visibility.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let label: string | null = null;\n\texport let Icon: any;\n\texport let show_label = true;\n\texport let disable = false;\n\texport let float = true;\n```\n\n----------------------------------------\n\nTITLE: Defining Markdown Content in Python\nDESCRIPTION: This Python snippet imports the Gradio library and defines a multi-line string variable `md` containing extensive Markdown text. This Markdown content includes headers, lists, links, code blocks, and tables, sourced from an example.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n# sample md stolen from https://dillinger.io/\n\nmd = \"\"\"# Dillinger\n## _The Last Markdown Editor, Ever_\n\nThis is some `inline code`, it is good.\n\n[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)\n\nDillinger is a cloud-enabled, mobile-ready, offline-storage compatible,\nAngularJS-powered HTML5 Markdown editor.\n\n- Type some Markdown on the left\n- See HTML in the right\n- ✨Magic ✨\n\n## Features\n\n- Import a HTML file and watch it magically convert to Markdown\n- Drag and drop images (requires your Dropbox account be linked)\n- Import and save files from GitHub, Dropbox, Google Drive and One Drive\n- Drag and drop markdown and HTML files into Dillinger\n- Export documents as Markdown, HTML and PDF\n\nMarkdown is a lightweight markup language based on the formatting conventions\nthat people naturally use in email.\nAs [John Gruber] writes on the [Markdown site][df1]\n\n> The overriding design goal for Markdown's\n> formatting syntax is to make it as readable\n> as possible. The idea is that a\n> Markdown-formatted document should be\n> publishable as-is, as plain text, without\n> looking like it's been marked up with tags\n> or formatting instructions.\n\nThis text you see here is *actually- written in Markdown! To get a feel\nfor Markdown's syntax, type some text into the left window and\nwatch the results in the right.\n\n## Tech\n\nDillinger uses a number of open source projects to work properly:\n\n- [AngularJS] - HTML enhanced for web apps!\n- [Ace Editor] - awesome web-based text editor\n- [markdown-it] - Markdown parser done right. Fast and easy to extend.\n- [Twitter Bootstrap] - great UI boilerplate for modern web apps\n- [node.js] - evented I/O for the backend\n- [Express] - fast node.js network app framework [@tjholowaychuk]\n- [Gulp] - the streaming build system\n- [Breakdance](https://breakdance.github.io/breakdance/) - HTML\nto Markdown converter\n- [jQuery] - duh\n\nAnd of course Dillinger itself is open source with a [public repository][dill]\n on GitHub.\n\n## Installation\n\nDillinger requires [Node.js](https://nodejs.org/) v10+ to run.\n\nInstall the dependencies and devDependencies and start the server.\n\n```bash\ncd dillinger\nnpm i\nnode app\n```\n\nFor production environments...\n\n```bash\nnpm install --production\nNODE_ENV=production node app\n```\n\n## Plugins\n\nDillinger is currently extended with the following plugins.\nInstructions on how to use them in your own application are linked below.\n\n| Plugin | README |\n| ------ | ------ |\n| Dropbox | [plugins/dropbox/README.md][PlDb] |\n| GitHub | [plugins/github/README.md][PlGh] |\n| Google Drive | [plugins/googledrive/README.md][PlGd] |\n| OneDrive | [plugins/onedrive/README.md][PlOd] |\n| Medium | [plugins/medium/README.md][PlMe] |\n| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |\n\n## Development\n\nWant to contribute? Great!\n\nDillinger uses Gulp + Webpack for fast developing.\nMake a change in your file and instantaneously see your updates!\n\nOpen your favorite Terminal and run these commands.\n\nFirst Tab:\n\n```bash\nnode app\n```\n\nSecond Tab:\n\n```bash\ngulp watch\n```\n\n(optional) Third:\n\n```bash\nkarma test\n```\n\n#### Building for source\n\nFor production release:\n\n```bash\ngulp build --prod\n```\n\nGenerating pre-built zip archives for distribution:\n\n```bash\ngulp build dist --prod\n```\n\n## Docker\n\nDillinger is very easy to install and deploy in a Docker container.\n\nBy default, the Docker will expose port 8080, so change this within the\nDockerfile if necessary. When ready, simply use the Dockerfile to\nbuild the image.\n\n```bash\ncd dillinger\ndocker build -t <youruser>/dillinger:${package.json.version} .\n```\n\nThis will create the dillinger image and pull in the necessary dependencies.\nBe sure to swap out `${package.json.version}` with the actual\nversion of Dillinger.\n\nOnce done, run the Docker image and map the port to whatever you wish on\nyour host. In this example, we simply map port 8000 of the host to\nport 8080 of the Docker (or whatever port was exposed in the Dockerfile):\n\n```bash\ndocker run -d -p 8000:8080 --restart=always --cap-add=SYS_ADMIN --name=dillinger <youruser>/dillinger:${package.json.version}\n```\n\n> Note: `--capt-add=SYS-ADMIN` is required for PDF rendering.\n\nVerify the deployment by navigating to your server address in\nyour preferred browser.\n\n```bash\n127.0.0.1:8000\n```\n\n```python\nimport gradio as gr\n\ngr.Blocks() as demo:\n    gr.Markdown(value=md)\n\ndemo.launch()\n```\n\n```js\nfunction fancyAlert(arg) {\n    if(arg) {\n        $.facebox({div:'#foo'})\n    }\n}\n```\n\n## License\n\nMIT\n\n**Free Software, Hell Yeah!**\n\n[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)\n\n   [dill]: <https://github.com/joemccann/dillinger>\n   [git-repo-url]: <https://github.com/joemccann/dillinger.git>\n   [john gruber]: <http://daringfireball.net>\n   [df1]: <http://daringfireball.net/projects/markdown/>\n   [markdown-it]: <https://github.com/markdown-it/markdown-it>\n   [Ace Editor]: <http://ace.ajax.org>\n   [node.js]: <http://nodejs.org>\n   [Twitter Bootstrap]: <http://twitter.github.com/bootstrap/>\n   [jQuery]: <http://jquery.com>\n   [@tjholowaychuk]: <http://twitter.com/tjholowaychuk>\n   [express]: <http://expressjs.com>\n   [AngularJS]: <http://angularjs.org>\n   [Gulp]: <http://gulpjs.com>\n\n   [PlDb]: <https://github.com/joemccann/dillinger/tree/master/plugins/dropbox/README.md>\n   [PlGh]: <https://github.com/joemccann/dillinger/tree/master/plugins/github/README.md>\n   [PlGd]: <https://github.com/joemccann/dillinger/tree/master/plugins/googledrive/README.md>\n   [PlOd]: <https://github.com/joemccann/dillinger/tree/master/plugins/onedrive/README.md>\n   [PlMe]: <https://github.com/joemccann/dillinger/tree/master/plugins/medium/README.md>\n   [PlGa]: <https://github.com/RahulHP/dillinger/blob/master/plugins/googleanalytics/README.md>\n\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Video Files\nDESCRIPTION: Creates a 'files' directory and downloads three sample video files from the Gradio GitHub repository for demonstration purposes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/a.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_component/files/a.mp4\n!wget -q -O files/b.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_component/files/b.mp4\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_component/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Defining Python Dependencies for Gradio Project\nDESCRIPTION: This snippet, typically found in a `requirements.txt` file, lists the core Python dependencies for a Gradio project. It specifies installing the `transformers` library directly from its GitHub repository using git+, the `gradio` library from PyPI, and the `torch` deep learning library from PyPI. These packages provide the necessary foundation for building and running machine learning web applications with Gradio and Hugging Face models.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/text_generation/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngit+https://github.com/huggingface/transformers\ngradio\ntorch\n```\n\n----------------------------------------\n\nTITLE: Caching App Submit Errors\nDESCRIPTION: Implementation to cache and display errors from app.submit() on the frontend\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\n595ebf74c5e09ad90fca0ca8a9a312f161a981aa\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Size Limits in Gradio\nDESCRIPTION: Example showing how to set a maximum file size limit of 5MB for uploads using either a string size format or bytes integer value.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Styling Navigation Buttons in Svelte\nDESCRIPTION: Adds CSS styling for the page navigation buttons and page counter. The buttons are arranged in a row with the counter centered between them.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_14\n\nLANGUAGE: svelte\nCODE:\n```\n<style>\n    .button-row {\n        display: flex;\n        flex-direction: row;\n        width: 100%;\n        justify-content: center;\n        align-items: center;\n    }\n\n    .page-count {\n        margin: 0 10px;\n        font-family: var(--font-mono);\n    }\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and LangChain Dependencies in Python\nDESCRIPTION: This snippet uses pip to install the required Python packages: `gradio` for the web UI, `langchain` for the core LLM framework, and `langchain-openai` for integrating with OpenAI models. The `-q` flag ensures a quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_langchain/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio langchain langchain-openai\n```\n\n----------------------------------------\n\nTITLE: Generating Documentation for Custom Components\nDESCRIPTION: Command line usage for automatically generating documentation and README for custom components with type hints and docstrings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc docs\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio\nDESCRIPTION: Lists the core Python package dependencies required for the Gradio application, including NumPy for numerical computations, TensorFlow for machine learning capabilities, and requests for HTTP operations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\ntensorflow\nrequests\n```\n\n----------------------------------------\n\nTITLE: BaseCode Component Props Definition\nDESCRIPTION: Defines the props for the BaseCode component which handles code display and editing. Includes options for styling, language specification, line count, and editing behavior.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let class_names = \"\";\n\texport let value = \"\";\n\texport let dark_mode: boolean;\n\texport let basic = true;\n\texport let language: string;\n\texport let lines = 5;\n\texport let extensions: Extension[] = [];\n\texport let use_tab = true;\n\texport let readonly = false;\n\texport let placeholder: string | HTMLElement | null | undefined = undefined;\n```\n\n----------------------------------------\n\nTITLE: Rendering Pandas Styler in Gradio DataFrame - Python\nDESCRIPTION: This snippet shows how to display a previously styled Pandas Styler object in a Gradio app. It uses the Gradio Blocks interface and the DataFrame component. Dependencies: gradio. The key parameter is the Styler object as the DataFrame's data argument. The input is an already created Styler, and the output is a web-based, stylized data table. Interactivity is possible depending on how the DataFrame is set up.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/styling-the-gradio-dataframe.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Dataframe(styler)\n    \ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Alternative Host Header Setting for Raw IP Deployment - Bash\nDESCRIPTION: This simple bash snippet indicates the use of the $host variable in Nginx header setting directives. When serving content on an IP address and port rather than a domain, using $http_host may be necessary for correct routing and header forwarding. These lines go inside a location block for fine-tuned header management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-gradio-on-your-web-server-with-nginx.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Host $host;\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio Chatbot Demo\nDESCRIPTION: This snippet installs the necessary Python packages for the Gradio chatbot demo, including gradio, plotly, numpy, pandas, and matplotlib.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio plotly numpy pandas matplotlib\n```\n\n----------------------------------------\n\nTITLE: Defining Abstract Event Attachment Method in LayoutBase Python\nDESCRIPTION: Defines the `attach_event` method signature within the `LayoutBase` class. It is declared as an abstract method by raising `NotImplementedError`, indicating that concrete subclasses must provide their own implementation for attaching Gradio events. The method accepts a dictionary (`block_dict`) containing all blocks in the application, keyed by name.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n    # other LayoutBase implementations\n\n    def attach_event(self, block_dict: Dict[str, Block]) -> None:\n        raise NotImplementedError\n```\n\n----------------------------------------\n\nTITLE: Private Space Authentication Request\nDESCRIPTION: Shows how to make an authenticated request to a private Gradio space using a Hugging Face token.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST https://private-space.hf.space/call/predict -H \"Content-Type: application/json\" -H \"Authorization: Bearer $HF_TOKEN\" -d '{\n  \"data\": [\"Hello, my friend.\"] \n}'\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio-Comet Integration\nDESCRIPTION: Command to install required Python packages including comet_ml, torch, transformers, gradio and other dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\npip install comet_ml torch torchvision transformers gradio shap requests Pillow\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates the @gradio/utils, @gradio/atoms, and @gradio/upload dependencies for the Gradio File component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_15\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.0.2\n\n### Patch Changes\n\n- Updated dependencies []:\n  - @gradio/utils@0.0.2\n  - @gradio/atoms@0.0.2\n  - @gradio/upload@0.0.2\n```\n\n----------------------------------------\n\nTITLE: Custom PDF Upload Text Component\nDESCRIPTION: Svelte component for customized PDF upload text display with styling\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_4\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n\timport { Upload as UploadIcon } from \"@gradio/icons\";\n\texport let hovered = false;\n\n</script>\n\n<div class=\"wrap\">\n\t<span class=\"icon-wrap\" class:hovered><UploadIcon /> </span>\n    Drop PDF\n    <span class=\"or\">- or -</span>\n    Click to Upload\n</div>\n\n<style>\n\t.wrap {\n\t\tdisplay: flex;\n\t\tflex-direction: column;\n\t\tjustify-content: center;\n\t\talign-items: center;\n\t\tmin-height: var(--size-60);\n\t\tcolor: var(--block-label-text-color);\n\t\tline-height: var(--line-md);\n\t\theight: 100%;\n\t\tpadding-top: var(--size-3);\n\t}\n\n\t.or {\n\t\tcolor: var(--body-text-color-subdued);\n\t\tdisplay: flex;\n\t}\n\n\t.icon-wrap {\n\t\twidth: 30px;\n\t\tmargin-bottom: var(--spacing-lg);\n\t}\n\n\t@media (--screen-md) {\n\t\t.wrap {\n\t\t\tfont-size: var(--text-lg);\n\t\t}\n\t}\n\n\t.hovered {\n\t\tcolor: var(--color-accent);\n\t}\n</style>\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Image Interface with Remote URLs\nDESCRIPTION: Implements a Gradio interface that accepts an image input (initialized with a remote URL) and returns both the input image and a new remote image URL. The interface includes example inputs and supports image preview functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_remote_url/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef fn(im):\n    return im, \"https://picsum.photos/400/300\"\n\ndemo = gr.Interface(\n    fn=fn,\n    inputs=gr.Image(\"https://picsum.photos/300/200\", label=\"InputImage\"),\n    outputs=[gr.Image(label=\"Loopback\"), gr.Image(label=\"RemoteImage\")],\n    examples=[\n        [\"https://picsum.photos/640/480\"]\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gpt2_xl/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Adding Canvas Element for PDF Rendering in Svelte\nDESCRIPTION: Adds a canvas element within a div container to display the PDF. The canvas is bound to the canvasRef variable to allow direct manipulation from JavaScript.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_8\n\nLANGUAGE: svelte\nCODE:\n```\n<div class=\"pdf-canvas\" style=\"height: {height}px\">\n    <canvas bind:this={canvasRef}></canvas>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Setting Debug Mode\nDESCRIPTION: Enables debug mode for better error reporting in environments like Google Colab.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_4\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_DEBUG=1\n```\n\n----------------------------------------\n\nTITLE: Creating a Private Duplicate of a Gradio Space\nDESCRIPTION: Example showing how to create a private duplicate of a Gradio space using the private option.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_17\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.duplicate(\"user/space-name\", {\n\thf_token: \"hf_...\",\n\tprivate: true\n});\n```\n\n----------------------------------------\n\nTITLE: Defining Tooltip Component Properties\nDESCRIPTION: This snippet defines the properties of the Tooltip component. It includes text content, x and y coordinates for positioning, and a color property. These are likely used to configure the appearance and behavior of the tooltip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tooltip/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let text: string;\nexport let x: number;\nexport let y: number;\nexport let color: string;\n```\n\n----------------------------------------\n\nTITLE: Installing the Gradio Library using Pip in Bash (Windows)\nDESCRIPTION: Uses the pip package installer to download and install the latest version of the Gradio library and its dependencies into the currently active Python virtual environment on Windows. Requires an active internet connection and the virtual environment to be activated.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install gradio\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio App with Customized Markdown Component\nDESCRIPTION: This Python snippet defines a Gradio Blocks interface using a `with` statement. It adds a Markdown component initialized with the `md` variable's content and customizes its appearance by enabling header links (`header_links=True`) and setting a specific height (`height=400`). Finally, it launches the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n    gr.Markdown(value=md, header_links=True, height=400)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Change Types Definition for Changelogs\nDESCRIPTION: Defines the semantic change types used for organizing the changelog: fix (bug fixes), feature (new capabilities), and highlight (prominent changes to feature in changelog).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- `fix` - we fixed a thing.\n- `feature` - we added a new capability.\n- `highlight` - we did something that we want to feature prominently in the changelog.\n```\n\n----------------------------------------\n\nTITLE: Saving a Gradio Theme to Disk\nDESCRIPTION: This snippet shows how to save a Gradio theme to disk as a JSON file, which can later be uploaded via the command line interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nseafoam.dump(filename=\"seafoam.json\")\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Highlighted Text Components - HTML\nDESCRIPTION: This snippet demonstrates how to import the BaseStaticHighlightedText and BaseInteractiveHighlightedText components from the `@gradio/highlightedtext` npm package within a Svelte `<script>` block. It requires the `@gradio/highlightedtext` package to be installed as a project dependency, and is intended for use in Svelte components for text highlighting functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/highlightedtext/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseStaticHighlightedText, BaseInteractiveHighlightedText } from `@gradio/highlightedtext`;\n</script>\n```\n\n----------------------------------------\n\nTITLE: Implementing Reversible Data Flow in Gradio Blocks with Python\nDESCRIPTION: Illustrates how Gradio Blocks in Python can handle multiple, potentially reversible, data flows. It defines two separate event listeners: one where `num1` updates `num2` and another where `num2` updates `num1`, showcasing flexibility beyond the single-direction flow of standard Interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n$code_reversible_flow\n```\n\n----------------------------------------\n\nTITLE: Processing Video to Remove Background Music\nDESCRIPTION: Function that processes a video file by extracting its audio, removing background music using the acapellify function, and then combining the new audio with the original video.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport subprocess\n\ndef process_video(video_path):\n    old_audio = os.path.basename(video_path).split(\".\")[0] + \".m4a\"\n    subprocess.run(['ffmpeg', '-y', '-i', video_path, '-vn', '-acodec', 'copy', old_audio])\n\n    new_audio = acapellify(old_audio)\n\n    new_video = f\"acap_{video_path}\"\n    subprocess.call(['ffmpeg', '-y', '-i', video_path, '-i', new_audio, '-map', '0:v', '-map', '1:a', '-c:v', 'copy', '-c:a', 'aac', '-strict', 'experimental', f\"static/{new_video}\"])\n    return new_video\n```\n\n----------------------------------------\n\nTITLE: Building the Rust Sepia Filter Program using Cargo\nDESCRIPTION: A Bash command that uses Cargo, the Rust package manager and build tool, to compile the Rust project in release mode (`--release`). This command builds the executable (e.g., `sepia`) with optimizations, typically placing it in the `target/release/` directory. This compiled binary is then called by the Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ncargo build --release\n```\n\n----------------------------------------\n\nTITLE: Defining BaseMarkdown Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseMarkdown component, including options for element ID, classes, visibility, value, minimum height, right-to-left text, HTML sanitization, line breaks, and LaTeX delimiters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let elem_id = \"\";\nexport let elem_classes: string[] = [];\nexport let visible = true;\nexport let value: string;\nexport let min_height = false;\nexport let rtl = false;\nexport let sanitize_html = true;\nexport let line_breaks = false;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[];\n```\n\n----------------------------------------\n\nTITLE: Creating Scatter Plot with Nominal X-Axis\nDESCRIPTION: Creates a Gradio interface with a scatter plot visualization using the downloaded data. The plot shows the relationship between ethnicity (categorical x-axis) and height (numerical y-axis).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter_nominal/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom data import df\n\nwith gr.Blocks() as demo:\n    gr.ScatterPlot(df, x=\"ethnicity\", y=\"height\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs necessary Python packages including Gradio, PyTorch, Transformers, NumPy, Pillow, Jinja2, and Open3D.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/depth_estimation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch git+https://github.com/nielsrogge/transformers.git@add_dpt_redesign#egg=transformers numpy Pillow jinja2 open3d\n```\n\n----------------------------------------\n\nTITLE: Configuring Build Settings in pyproject.toml\nDESCRIPTION: Configuration for build artifacts and wheel package settings in pyproject.toml.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n[tool.hatch.build]\nartifacts = [\"/backend/supertextbox/templates\", \"*.pyi\"]\n\n[tool.hatch.build.targets.wheel]\npackages = [\"/backend/supertextbox\"]\n```\n\n----------------------------------------\n\nTITLE: Loading Icons in Gradio Backend\nDESCRIPTION: This snippet demonstrates how to load icons in Gradio's backend code using the `get_icon_path` utility function from the `gradio.utils` module. This function is used to retrieve the file path of icons, which can then be used to populate icons in various components of the application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/gradio/icons/README.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ngradio.utils.get_icon_path\n```\n\n----------------------------------------\n\nTITLE: Uploading Data to HuggingFace - JavaScript\nDESCRIPTION: Provides an asynchronous function to upload either base64-encoded data or URLs to the HuggingFace platform. Requires the input data as a string and a type to designate if it's a 'base64' blob or a URL. The function returns a promise that resolves to a string, which is expected to be a resulting file URL, identifier, or similar output from HuggingFace. Assumes network and authentication requirements are managed elsewhere.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/utils/README.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nexport async function uploadToHuggingFace(\n\t\tdata: string,\n\t\ttype: \"base64\" | \"url\"\n\t): Promise<string>\n```\n\n----------------------------------------\n\nTITLE: Implementing Python Code Completion\nDESCRIPTION: Adds Jedi-based Python code completion functionality to gr.Code component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_1\n\n\n\n----------------------------------------\n\nTITLE: Specifying Python Package Requirements with Pip Requirements File - Plaintext\nDESCRIPTION: This snippet lists exact Python dependencies for a project using PyTorch, TorchVision, TorchAudio, Librosa, and Gdown. The file allows pip to install the correct versions, ensuring consistency when setting up virtual environments. Required for reproducible deep learning experiments and seamless installation; version pinning prevents compatibility issues. This file should be named requirements.txt and placed in the project root.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/musical_instrument_identification/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch==1.12.0\ntorchvision==0.13.0\ntorchaudio==0.12.0\nlibrosa==0.9.2\ngdown\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rapid_generation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Supabase Python Client\nDESCRIPTION: Command to install the Supabase Python package using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-supabase-data.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install supabase\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio package with pip\nDESCRIPTION: Installs the Gradio package quietly using pip. This is a prerequisite for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_quantitative/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Fraud Dataset for Gradio Demo in Python\nDESCRIPTION: This code downloads the fraud dataset CSV file from the Gradio GitHub repository. The file is essential for running the fraud detection demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fraud_detector/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/fraud_detector/fraud.csv\n```\n\n----------------------------------------\n\nTITLE: Implementing OAuth Login and Organization Listing with Gradio Blocks - Python\nDESCRIPTION: Defines a Gradio Blocks app that lets users authenticate via their Hugging Face account, displays a personalized greeting, and lists their organizations from the Hugging Face API. Relies on Gradio (including OAuthProfile and OAuthToken types), the Hugging Face Hub Python library, and an interactive interface with Markdown display. Inputs and outputs are managed through Gradio components; OAuth tokens and profiles are required for certain functions. Should be run on a Hugging Face Spaces instance to fully access OAuth and organization listing features.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/login_with_huggingface/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport gradio as gr\nfrom huggingface_hub import whoami\n\ndef hello(profile: gr.OAuthProfile | None) -> str:\n    if profile is None:\n        return \"I don't know you.\"\n    return f\"Hello {profile.name}\"\n\ndef list_organizations(oauth_token: gr.OAuthToken | None) -> str:\n    if oauth_token is None:\n        return \"Please deploy this on Spaces and log in to list organizations.\"\n    org_names = [org[\"name\"] for org in whoami(oauth_token.token)[\"orgs\"]]\n    return f\"You belong to {', '.join(org_names)}.\"\n\nwith gr.Blocks() as demo:\n    gr.LoginButton()\n    m1 = gr.Markdown()\n    m2 = gr.Markdown()\n    demo.load(hello, inputs=None, outputs=m1)\n    demo.load(list_organizations, inputs=None, outputs=m2)\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseExample component. It includes options for content value, type (gallery or table), selection state, HTML sanitization, line breaks, and LaTeX delimiters. This component is used for rendering example content in Markdown format.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\nexport let sanitize_html: boolean;\nexport let line_breaks: boolean;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[];\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages including Gradio, PyTorch, torchvision, and requests using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classification/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch torchvision requests\n```\n\n----------------------------------------\n\nTITLE: Implementing Webcam Constraints in Gradio for Video and Image Inputs\nDESCRIPTION: This code creates a Gradio interface with webcam constraints for both video and image inputs. It includes functions to process video and image inputs, returning their dimensions. The interface is organized into tabs and includes explanatory markdown.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/webcam_constraints/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport cv2\n\ndef get_video_shape(video):\n    cap = cv2.VideoCapture(video)\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    cap.release()\n    return {\"width\": width, \"height\": height}\n\ndef image_mod(image):\n    width, height = image.size\n    return {\"width\": width, \"height\": height}\n\n\nvideo = gr.Interface(\n    fn=get_video_shape,\n    inputs=gr.Video(webcam_constraints={\"video\": {\"width\": 800, \"height\": 600}}, sources=\"webcam\"),\n    outputs=gr.JSON()\n)\n\nimage = gr.Interface(\n        image_mod,\n        gr.Image(type=\"pil\", webcam_constraints={\"video\": {\"width\": 800, \"height\": 600}}, sources=\"webcam\"),\n        gr.Json())\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"\"\"# Webcam Constraints\n                The webcam constraints are set to 800x600 with the following syntax:\n                ```python\n                gr.Video(webcam_constraints={\"video\": {\"width\": 800, \"height\": 600}}, sources=\"webcam\")\n                ```\n                \"\"\")\n    with gr.Tabs():\n        with gr.Tab(\"Video\"):\n            video.render()\n        with gr.Tab(\"Image\"):\n            image.render()\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating a Gradio Interface for a C++ Program using Subprocess in Python\nDESCRIPTION: This Python script uses the `gradio` library to create a web interface for an external C++ program (`./add`). The `add_numbers` function executes the compiled C++ program using `subprocess.Popen`, sends two numbers (`a`, `b`) as input via stdin, captures the sum from stdout, and handles potential errors from stderr. A `gr.Interface` is configured with two `gr.Number` inputs and a `gr.Textbox` output to display the result.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport subprocess\n\ndef add_numbers(a, b):\n    process = subprocess.Popen(\n        ['./add'], \n        stdin=subprocess.PIPE, \n        stdout=subprocess.PIPE, \n        stderr=subprocess.PIPE\n    )\n    output, error = process.communicate(input=f\"{a} {b}\\n\".encode())\n    \n    if error:\n        return f\"Error: {error.decode()}\"\n    return float(output.decode().strip())\n\ndemo = gr.Interface(\n    fn=add_numbers, \n    inputs=[gr.Number(label=\"Number 1\"), gr.Number(label=\"Number 2\")], \n    outputs=gr.Textbox(label=\"Result\")\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Environment Variables in .env File\nDESCRIPTION: Example of setting multiple environment variables in a .env file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_20\n\nLANGUAGE: sh\nCODE:\n```\nGRADIO_SERVER_PORT=8000\nGRADIO_SERVER_NAME=\"localhost\"\n```\n\n----------------------------------------\n\nTITLE: Using the ImageEditor Component in Python\nDESCRIPTION: This snippet demonstrates how to use the new ImageEditor component in Gradio, showing various configuration options like setting sources, crop size, transforms, and customizing the brush.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef fn(im):\n    im[\"composite\"] # the full canvas\n    im[\"background\"] # the background image\n    im[\"layers\"] # a list of individual layers\n\n\nim = gr.ImageEditor(\n    # decide which sources you'd like to accept\n    sources=[\"upload\", \"webcam\", \"clipboard\"],\n    # set a cropsize constraint, can either be a ratio or a concrete [width, height]\n    crop_size=\"1:1\",\n    # enable crop (or disable it)\n    transforms=[\"crop\"],\n    # customise the brush\n    brush=Brush(\n      default_size=\"25\", # or leave it as 'auto'\n      color_mode=\"fixed\", # 'fixed' hides the user swatches and colorpicker, 'defaults' shows it\n      default_color=\"hotpink\", # html names are supported\n      colors=[\n        \"rgba(0, 150, 150, 1)\", # rgb(a)\n        \"#fff\", # hex rgb\n        \"hsl(360, 120, 120)\" # in fact any valid colorstring\n      ]\n    ),\n    brush=Eraser(default_size=\"25\")\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package using pip\nDESCRIPTION: Installs the Gradio package quietly without showing the typical installation output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_split/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Titanic Survival Prediction\nDESCRIPTION: This snippet installs the necessary Python libraries for the Titanic survival prediction demo, including Gradio, scikit-learn, numpy, and pandas.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/titanic_survival/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio scikit-learn numpy pandas\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio Files Using Gradio Client in Python\nDESCRIPTION: This code demonstrates how to use the gradio_client Python library to interact with a remote Gradio 'whisper' application for transcribing audio files. The dependency is the 'gradio_client' package, which should be installed beforehand. The key parameters are the app identifier (Hugging Face Space slug 'abidlabs/whisper') and the input audio file (\"audio_sample.wav\"). It returns the transcribed string output as predicted by the underlying speech recognition model. Limitations include requiring the audio file to exist and network connectivity to the Hugging Face Space.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"abidlabs/whisper\")\nclient.predict(\"audio_sample.wav\")\n\n>> \"This is a test of the whisper speech recognition model.\"\n\n```\n\n----------------------------------------\n\nTITLE: Empty Component Props Definition\nDESCRIPTION: Defines the available props for the Empty component, which displays an empty state with configurable size and padding options.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let size: \"small\" | \"large\" = \"small\";\n\texport let unpadded_box = false;\n```\n\n----------------------------------------\n\nTITLE: Connecting Upload Components with Event Handlers in Svelte\nDESCRIPTION: Connects the ModifyUpload and Upload components with their respective event handlers. The ModifyUpload component handles file clearing while the Upload component captures new file uploads.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_11\n\nLANGUAGE: svelte\nCODE:\n```\n<ModifyUpload i18n={gradio.i18n} on:clear={handle_clear} absolute />\n\n...\n\n<Upload\n    on:load={handle_upload}\n    filetype={\"application/pdf\"}\n    file_count=\"single\"\n    {root}\n>\n    <PdfUploadText/>\n</Upload>\n```\n\n----------------------------------------\n\nTITLE: Directory Structure for Gradio Flagging with File Data\nDESCRIPTION: Illustrates the directory structure created when flagging data that includes file inputs/outputs (e.g., Images, Audio). In addition to 'logs.csv', separate subdirectories are created within 'flagged/' to store the actual flagged files, named after the corresponding input/output components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n+-- flagged/\n|   +-- logs.csv\n|   +-- image/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Coqui TTS Plugin using Pip in Python\nDESCRIPTION: This snippet uses the `pip` package installer to install the `gradio` library and a specific version of the `neon-tts-plugin-coqui` library. The `-q` flag ensures a quiet installation with minimal output. These packages are prerequisites for running the text-to-speech Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/neon-tts-plugin-coqui/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio neon-tts-plugin-coqui==0.4.1a9\n```\n\n----------------------------------------\n\nTITLE: Stateful Session Requests\nDESCRIPTION: Shows how to maintain session state across multiple requests using session_hash parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\ncurl -X POST https://gradio-chatinterface-random-response.hf.space/call/chat -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Are you sentient?\"],\n  \"session_hash\": \"randomsequence1234\"\n}'\n\ncurl -X POST https://gradio-chatinterface-random-response.hf.space/call/chat -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Really?\"],\n  \"session_hash\": \"randomsequence1234\"\n}'\n\ncurl -X POST https://gradio-chatinterface-random-response.hf.space/call/chat -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Are you sentient?\"],\n  \"session_hash\": \"newsequence5678\"\n}'\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio using pip in Python\nDESCRIPTION: This command installs or upgrades Gradio using pip, the Python package installer. It's recommended to run this in a virtual environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/01_getting-started/01_quickstart.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade gradio\n```\n\n----------------------------------------\n\nTITLE: Supporting Message Format in Chatbot with Gradio\nDESCRIPTION: Example of using the Messages API in Gradio's Chatbot component, demonstrating how to handle chat messages with role and content fields.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/_website/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef chat_greeter(msg, history):\n    history.append({\"role\": \"assistant\", \"content\": \"Hello!\"})\n    return history\n```\n\n----------------------------------------\n\nTITLE: Custom Retrying Assertions with toPass\nDESCRIPTION: Shows how to implement custom retrying assertions using Playwright's toPass method for cases where built-in retrying assertions aren't available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nawait expect(async () => {\n\tconst response = await page.request.get(\"https://api.example.com\");\n\texpect(response.status()).toBe(200);\n}).toPass();\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with pip - Python\nDESCRIPTION: Installs the Gradio Python library using pip to allow further usage of Gradio components. This step is required before importing or using any Gradio features in subsequent code. The '-q' flag suppresses output for cleaner installation logs; ensure your environment supports pip and has network access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Adding Page Navigation UI in Svelte\nDESCRIPTION: Adds UI controls for navigating between PDF pages. This includes previous and next buttons along with a page counter display showing the current page and total pages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_13\n\nLANGUAGE: svelte\nCODE:\n```\n<ModifyUpload i18n={gradio.i18n} on:clear={handle_clear} absolute />\n<div class=\"pdf-canvas\" style=\"height: {height}px\">\n    <canvas bind:this={canvasRef}></canvas>\n</div>\n<div class=\"button-row\">\n    <BaseButton on:click={prev_page}>\n        ⬅️\n    </BaseButton>\n    <span class=\"page-count\"> {currentPage} / {numPages} </span>\n    <BaseButton on:click={next_page}>\n        ➡️\n    </BaseButton>\n</div>\n```\n\n----------------------------------------\n\nTITLE: Displaying CSV Content for Sepia Interface Flagging\nDESCRIPTION: Shows the content of the logs.csv file created when flagging occurs in a sepia image processing interface. It demonstrates how file paths are logged for input and output images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/02_flagging.md#2025-04-23_snippet_3\n\nLANGUAGE: csv\nCODE:\n```\nim,Output\nim/0.png,Output/0.png\nim/1.png,Output/1.png\n```\n\n----------------------------------------\n\nTITLE: Setting Brush Size via API (TypeScript)\nDESCRIPTION: Sets the brush size for the Brush Tool. This method likely affects both drawing and erasing modes. It accepts a `size` parameter to define the desired brush diameter or radius. This is part of the Brush Tool's customization API for programmatic control.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_0\n\nLANGUAGE: typescript\nCODE:\n```\nsetBrushSize(size)\n```\n\n----------------------------------------\n\nTITLE: Frontend Component Properties and Imports\nDESCRIPTION: TypeScript code defining the component properties and importing required Gradio modules\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nimport { tick } from \"svelte\";\nimport type { Gradio } from \"@gradio/utils\";\nimport { Block, BlockLabel } from \"@gradio/atoms\";\nimport { File } from \"@gradio/icons\";\nimport { StatusTracker } from \"@gradio/statustracker\";\nimport type { LoadingStatus } from \"@gradio/statustracker\";\nimport type { FileData } from \"@gradio/client\";\nimport { Upload, ModifyUpload } from \"@gradio/upload\";\n\nexport let elem_id = \"\";\nexport let elem_classes: string[] = [];\nexport let visible = true;\nexport let value: FileData | null = null;\nexport let container = true;\nexport let scale: number | null = null;\nexport let root: string;\nexport let height: number | null = 500;\nexport let label: string;\nexport let proxy_url: string;\nexport let min_width: number | undefined = undefined;\nexport let loading_status: LoadingStatus;\nexport let gradio: Gradio<{\n\tchange: never;\n\tupload: never;\n}>;\n\nlet _value = value;\nlet old_value = _value;\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files\nDESCRIPTION: Creates a 'files' directory and downloads sample files for the demo from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/Bunny.obj https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/Bunny.obj\n!wget -q -O files/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/cantina.wav\n!wget -q -O files/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/cheetah1.jpg\n!wget -q -O files/time.csv https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/time.csv\n!wget -q -O files/titanic.csv https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/titanic.csv\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/dataset/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Configuring Webcam Component Props (JavaScript)\nDESCRIPTION: This export block defines the properties accepted by the Webcam component, including streaming and pending state booleans, mode (either 'image' or 'video'), webcam mirroring, audio inclusion, and i18n formatting. It sets up capturing images or videos via webcam and should be used within a Svelte context where media device access is available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let streaming = false;\\n\\texport let pending = false;\\n\\n\\texport let mode: \"image\" | \"video\" = \"image\";\\n\\texport let mirror_webcam: boolean;\\n\\texport let include_audio: boolean;\\n\\texport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Importing DataFrame Components in Gradio\nDESCRIPTION: This snippet shows how to import the core components from the @gradio/dataframe module in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseDataFrame, BaseExample } from \"@gradio/dataframe\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Reading File Content in Python\nDESCRIPTION: This function reads the content of a file, handling potential encoding issues. It attempts to read with UTF-8 encoding first, falling back to ISO-8859-1 if that fails.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir3/dir4/dir5/dir5_foo.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndef read_file(file_path):\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            return file.read()\n    except UnicodeDecodeError:\n        with open(file_path, \"r\", encoding=\"ISO-8859-1\") as file:\n            return file.read()\n```\n\n----------------------------------------\n\nTITLE: Defining BaseMarkdown Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseMarkdown component. It includes options for element ID, classes, visibility, content value, minimum height, right-to-left text, HTML sanitization, line breaks, and LaTeX delimiters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let elem_id = \"\";\nexport let elem_classes: string[] = [];\nexport let visible = true;\nexport let value: string;\nexport let min_height = false;\nexport let rtl = false;\nexport let sanitize_html = true;\nexport let line_breaks = false;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[];\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Gradio Button Component in HTML/Svelte\nDESCRIPTION: This snippet demonstrates how to import the Button component from @gradio/button and use it in an HTML/Svelte template. The button can be configured with different types and an optional href attribute. It also shows how to handle click events.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tootils/README.md#2025-04-23_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<script>\n\timport { Button } from \"@gradio/button\";\n</script>\n\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\n\tcontent\n</button>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode. This is a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_outputs/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Configuring Project URLs in pyproject.toml (TOML)\nDESCRIPTION: This TOML snippet exemplifies how to define the GitHub repository URL and the Hugging Face Space URL within the `[project.urls]` section of a `pyproject.toml` file. These URLs are automatically used by the documentation generator to provide relevant links for the project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_8\n\nLANGUAGE: toml\nCODE:\n```\n[project.urls]\nrepository = \"https://github.com/user/repo-name\"\nspace = \"https://huggingface.co/spaces/user/space-name\"\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Data for Gradio Demo\nDESCRIPTION: Downloads the required data file for the demo from the Gradio GitHub repository. The data file contains a DataFrame with time series data used for plotting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetime/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_datetime/data.py\n```\n\n----------------------------------------\n\nTITLE: Verifying Gradio Installation and Version in Python (Windows)\nDESCRIPTION: This Python code snippet, intended to be run in a Python interpreter session within the activated virtual environment on Windows, imports the installed Gradio library as `gr` and prints its version (`__version__`) to confirm successful installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nprint(gr.__version__)\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits Example in Python\nDESCRIPTION: Python code example demonstrating how to set a maximum file size limit for uploads using the launch() method in Gradio. This can be specified either as a string or an integer corresponding to the size in bytes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/checkbox/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reversible_flow/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_list_and_dict/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Configuring the BaseExample Component in Gradio Svelte (JavaScript)\nDESCRIPTION: Defines the BaseExample component's exported props to support rendering example file entries in either gallery or table style, with selection support. It requires a FileData input, a type specifier, and an optional selected state. This facilitates sample file visualization in test or demo scenarios; output is a configured component structure for UI use.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/README.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: FileData;\\n\\texport let type: \"gallery\" | \"table\";\\n\\texport let selected = false;\\n\n```\n\n----------------------------------------\n\nTITLE: Implementing HighlightedText Component\nDESCRIPTION: Creates a simple Gradio interface with a HighlightedText component configured to combine adjacent highlighted sections. The component is created within a Blocks context and launched as a demo interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlightedtext_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.HighlightedText(\n        combine_adjacent=True,\n    )\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency in Python\nDESCRIPTION: Installs the Gradio library using pip, ensuring that the required package is present before running the demo. This line should be executed in an environment where Gradio is not already installed. It uses the -q flag for quiet output, which suppresses unnecessary information during installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/matrix_transpose/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Applying Filters to Webcam Stream in Gradio\nDESCRIPTION: Creates a demo where users can choose a filter (edge-detection, cartoon, or vertical flip) to apply to their webcam stream. It uses gr.Image for input and output, with a gr.Radio for filter selection.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/03_streaming-inputs.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport cv2\nimport numpy as np\nimport gradio as gr\n\ndef apply_filter(img, filter):\n    if filter == \"edge_detection\":\n        return cv2.Canny(img, 100, 200)\n    elif filter == \"cartoon\":\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        gray = cv2.medianBlur(gray, 5)\n        edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 9, 9)\n        color = cv2.bilateralFilter(img, 9, 300, 300)\n        return cv2.bitwise_and(color, color, mask=edges)\n    elif filter == \"vertical_flip\":\n        return cv2.flip(img, 0)\n    else:\n        return img\n\ndemo = gr.Interface(\n    apply_filter,\n    [gr.Image(source=\"webcam\", streaming=True), gr.Radio([\"none\", \"edge_detection\", \"cartoon\", \"vertical_flip\"])],\n    gr.Image(streaming=True),\n    live=True\n).launch()\n```\n\n----------------------------------------\n\nTITLE: Button Redesign Implementation\nDESCRIPTION: Pull request information showing the redesign of gr.Button() component with a reference to the commit that implemented the change.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- [#9167](https://github.com/gradio-app/gradio/pull/9167) [`e9e737e`](https://github.com/gradio-app/gradio/commit/e9e737eeeb61d0bbf43277c75b6ffed8b34aa445) - Redesign `gr.Button()`.\n```\n\n----------------------------------------\n\nTITLE: Improving Startup Performance and Markdown Support in Gradio\nDESCRIPTION: Implements improvements to startup performance and markdown support in Gradio, including better syntax highlighting, more consistent styling, and various performance optimizations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.0\n\n### Highlights\n\n#### Improve startup performance and markdown support ([#5279](https://github.com/gradio-app/gradio/pull/5279) [`fe057300`](https://github.com/gradio-app/gradio/commit/fe057300f0672c62dab9d9b4501054ac5d45a4ec))\n\n##### Improved markdown support\n\nWe now have better support for markdown in `gr.Markdown` and `gr.Dataframe`. Including syntax highlighting and Github Flavoured Markdown. We also have more consistent markdown behaviour and styling.\n\n##### Various performance improvements\n\nThese improvements will be particularly beneficial to large applications.\n\n- Rather than attaching events manually, they are now delegated, leading to a significant performance improvement and addressing a performance regression introduced in a recent version of Gradio. App startup for large applications is now around twice as fast.\n- Optimised the mounting of individual components, leading to a modest performance improvement during startup (~30%).\n- Corrected an issue that was causing markdown to re-render infinitely.\n- Ensured that the `gr.3DModel` does re-render prematurely.\n\nThanks [@pngwn](https://github.com/pngwn)!\n```\n\n----------------------------------------\n\nTITLE: Formatting Method/Function Docstrings for Documentation (Python)\nDESCRIPTION: Shows the required format for method and function docstrings to be parsed correctly by the Gradio documentation generator. It must include specific sections like `Parameters:` and `Returns:`, followed by indented descriptions for each parameter and the return value, respectively. Note that Markdown within these descriptions is not rendered.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_4\n\nLANGUAGE: py\nCODE:\n```\n\"\"\"\nParameters:\n    param_one: A description for this parameter.\n    param_two: A description for this parameter.\nReturns:\n    A description for this return value.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and OpenAI Packages in Python\nDESCRIPTION: This snippet demonstrates how to install the required Python dependencies, specifically 'gradio' and 'openai' (version 1.0.0 or higher), using pip. This must be executed in an environment where pip is available prior to running any subsequent code that imports or uses these packages. Required for ensuring the OpenAI API and Gradio chat functionality can be used in later scripts.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_openai/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio openai>=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Displaying Queue Position with Gradio Python Client\nDESCRIPTION: This snippet demonstrates how to use the Gradio Python client to submit a job to a diffusion model and display the current queue position while waiting for completion.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/diffusion_model\")\n\njob = client.submit(\"A cute cat\")\nwhile not job.done():\n    status = job.status()\n    print(f\"Current in position {status.rank} out of {status.queue_size}\")\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseExample component. It includes options for setting the value, type (gallery or table), and selected state. These properties are likely used to configure example inputs or displays in Gradio interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/multimodaltextbox/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Configuring Component Exports in package.json\nDESCRIPTION: Defines the export configuration for component files including the main Index.svelte and Example.svelte files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_0\n\nLANGUAGE: json\nCODE:\n```\n\"exports\": {\n    \".\": \"./Index.svelte\",\n    \"./example\": \"./Example.svelte\",\n    \"./package.json\": \"./package.json\"\n},\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates multiple dependencies including @gradio/client, @gradio/icons, @gradio/utils, @gradio/upload, @gradio/atoms, and @gradio/statustracker.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.1\n\n### Patch Changes\n\n- Updated dependencies [[`119c8343`](https://github.com/gradio-app/gradio/commit/119c834331bfae60d4742c8f20e9cdecdd67e8c2), [`abf1c57d`](https://github.com/gradio-app/gradio/commit/abf1c57d7d85de0df233ee3b38aeb38b638477db), [`79d8f9d8`](https://github.com/gradio-app/gradio/commit/79d8f9d891901683c5a1b7486efb44eab2478c96)]:\n  - @gradio/client@0.3.0\n  - @gradio/icons@0.1.0\n  - @gradio/utils@0.1.0\n  - @gradio/upload@0.2.0\n  - @gradio/atoms@0.1.1\n  - @gradio/statustracker@0.1.1\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for Audio Reversal in Python\nDESCRIPTION: Implements a function to reverse audio data using NumPy and creates a Gradio interface with custom waveform styling. The interface allows users to record audio via microphone or upload files, then outputs the reversed version.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n\nimport numpy as np\n\nimport gradio as gr\n\ndef reverse_audio(audio):\n    sr, data = audio\n    return (sr, np.flipud(data))\n\ninput_audio = gr.Audio(\n    sources=[\"microphone\"],\n    waveform_options=gr.WaveformOptions(\n        waveform_color=\"#01C6FF\",\n        waveform_progress_color=\"#0066B4\",\n        skip_length=2,\n        show_controls=False,\n    ),\n)\ndemo = gr.Interface(\n    fn=reverse_audio,\n    inputs=input_audio,\n    outputs=\"audio\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: TypeScript Streaming Example\nDESCRIPTION: Example showing how to stream results from a Gradio app using the TypeScript/JavaScript client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"gradio/llm_stream\")\nconst job = client.submit(\"/predict\", {\"text\": \"What's the best UI framework in Python?\"})\n\nfor await (const msg of job) console.log(msg.data)\n```\n\n----------------------------------------\n\nTITLE: Displaying Templates Command\nDESCRIPTION: Command to view available built-in templates for custom components\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/06_frequently-asked-questions.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc show\n```\n\n----------------------------------------\n\nTITLE: Making API Predictions with Payload Parameters\nDESCRIPTION: Example demonstrating how to pass payload parameters when making a prediction with the Gradio client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_8\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"user/space-name\");\nconst result = await app.predict(\"/predict\", {\n\tinput: 1,\n\tword_1: \"Hello\",\n\tword_2: \"friends\"\n});\n```\n\n----------------------------------------\n\nTITLE: Uploading a Custom Gradio Theme to Hugging Face Hub\nDESCRIPTION: This code demonstrates how to upload a custom Gradio theme to the Hugging Face Hub using the push_to_hub method. It requires a Hugging Face account token for authentication.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nseafoam.push_to_hub(repo_name=\"seafoam\",\n                    version=\"0.0.1\",\n\t\t\t\thf_token=\"<token>\")\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Pandas Dependencies\nDESCRIPTION: Installs the required Gradio and Pandas packages using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Defining Props for the ModifyUpload Component in JavaScript/TypeScript\nDESCRIPTION: This snippet defines exported properties (props) for a potential `ModifyUpload` component, likely in JavaScript or TypeScript for Svelte. It includes properties like `editable`, `undoable`, `absolute`, and `i18n` (for internationalization) to control the modification features of an uploaded file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/upload/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let editable = false;\nexport let undoable = false;\nexport let absolute = true;\nexport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Test Files with wget in Python\nDESCRIPTION: This snippet imports the os module and uses shell commands via Jupyter magic to download several Python test case files from a remote GitHub repository. These files serve as example cases for validating or demonstrating Gradio chat interface functionality. The dependencies include availability of wget and internet access, and the files are downloaded quietly to the current working directory for subsequent import or execution.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_examples/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_examples/eager_caching_examples_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_examples/lazy_caching_examples_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_examples/multimodal_messages_examples_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_examples/multimodal_tuples_examples_testcase.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_examples/tuples_examples_testcase.py\n```\n\n----------------------------------------\n\nTITLE: Feature Addition: Gradio Sketch UI Builder\nDESCRIPTION: This snippet describes a major feature addition in version 0.6.0, introducing a UI-based Gradio skeleton builder called 'gradio sketch'. It includes the pull request number and commit hash.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/sketchbox/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10630](https://github.com/gradio-app/gradio/pull/10630) [`77432c7`](https://github.com/gradio-app/gradio/commit/77432c7fa84c56ef76364bf23f4273e889a94a71) - gradio sketch - UI based gradio skeleton builder.  Thanks @aliabid94!\n```\n\n----------------------------------------\n\nTITLE: Setting Draw Brush Size via API (TypeScript)\nDESCRIPTION: Sets the brush size specifically for the drawing mode of the Brush Tool. It accepts a `size` parameter. This allows separate size control for drawing compared to erasing. This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nset_brush_size(size)\n```\n\n----------------------------------------\n\nTITLE: Defining BaseTextbox Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseTextbox component, including value, lines, placeholder, label, and various configuration options. It specifies the types and default values for these properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value = \"\";\nexport let value_is_output = false;\nexport let lines = 1;\nexport let placeholder = \"Type here...\";\nexport let label: string;\nexport let info: string | undefined = undefined;\nexport let disabled = false;\nexport let show_label = true;\nexport let container = true;\nexport let max_lines: number;\nexport let type: \"text\" | \"password\" | \"email\" = \"text\";\nexport let show_copy_button = false;\nexport let rtl = false;\nexport let autofocus = false;\nexport let text_align: \"left\" | \"right\" | undefined = undefined;\nexport let autoscroll = true;\nexport let max_length: number | undefined = undefined;\n```\n\n----------------------------------------\n\nTITLE: Initializing Tokenizer and SHAP Explainer for Text Generation in Python\nDESCRIPTION: Creates an AutoTokenizer from a pre-trained model and initializes a SHAP Explainer with the model and tokenizer. This setup enables explainability for the text generation model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nexplainer = shap.Explainer(model, tokenizer)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy\nDESCRIPTION: Installs the required packages Gradio and NumPy using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Setting Max File Size in Gradio Launch Parameters\nDESCRIPTION: This code demonstrates how to set a maximum file size limit for uploads in Gradio using the max_file_size parameter. The parameter can be specified either as a string (like '5mb') or as an integer representing bytes using the FileSize enumeration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode to suppress verbose output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_merge_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the data.py file from the Gradio GitHub repository that contains the dataset needed for the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_nominal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_series_nominal/data.py\n```\n\n----------------------------------------\n\nTITLE: Loading a Hosted Sklearn Model Interface with Gradio and Skops in Python\nDESCRIPTION: This snippet demonstrates initializing a pre-built Gradio tabular interface for a sklearn model hosted on Hugging Face Hub, using the skops integration. The gr.load call retrieves the interface by model repository path and optionally sets the UI title and description. Required dependencies: gradio and access to the remote model via huggingface_hub; the remote config must include column metadata. Inputs and outputs are auto-configured from the model's metadata. Limitations include the need for proper model packaging and compatible config.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-for-tabular-workflows.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\n# title and description are optional\\ntitle = \\\"Supersoaker Defective Product Prediction\\\"\\ndescription = \\\"This model predicts Supersoaker production line failures. Drag and drop any slice from dataset or edit values as you wish in below dataframe component.\\\"\\n\\ngr.load(\\\"huggingface/scikit-learn/tabular-playground\\\", title=title, description=description).launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseExample Component Props (JavaScript)\nDESCRIPTION: This snippet exports the configuration properties for the BaseExample component, allowing for specification of a value (string), samples directory, UI display type ('gallery' or 'table'), and a boolean to toggle selection. The component is for rendering selectable example assets in a Gradio image interface. Required props must be provided when the component is used.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/README.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let value: string;\\n\\texport let samples_dir: string;\\n\\texport let type: \"gallery\" | \"table\";\\n\\texport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets\nDESCRIPTION: Creates a files directory and downloads sample animal images from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/fake_gan_2/files/cheetah1.jpg\n!wget -q -O files/elephant.jpg https://github.com/gradio-app/gradio/raw/main/demo/fake_gan_2/files/elephant.jpg\n!wget -q -O files/tiger.jpg https://github.com/gradio-app/gradio/raw/main/demo/fake_gan_2/files/tiger.jpg\n!wget -q -O files/zebra.jpg https://github.com/gradio-app/gradio/raw/main/demo/fake_gan_2/files/zebra.jpg\n```\n\n----------------------------------------\n\nTITLE: Loading Initial Review Data from SQLite - Python\nDESCRIPTION: The function loads the latest reviews and their count from the SQLite database at application startup, returning them as a pandas DataFrame and a total count. It expects the previously defined `get_latest_reviews` function and the global `DB_FILE`. There are no input parameters, and it returns review data for immediate display in the Gradio UI.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-background-tasks.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef load_data():\n    db = sqlite3.connect(DB_FILE)\n    reviews, total_reviews = get_latest_reviews(db)\n    db.close()\n    return reviews, total_reviews\n```\n\n----------------------------------------\n\nTITLE: Generating English and German Text Using Loaded Gradio Blocks\nDESCRIPTION: This snippet demonstrates how to load and use a previously created Gradio Blocks app as a function. It generates English text and then translates it to German using the loaded app, showcasing the composition of functionality across different Gradio apps.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/07_using-blocks-like-functions.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\n\nenglish_generator = pipeline(\"text-generation\", model=\"distilgpt2\")\nenglish_translator = gr.Blocks.load(name=\"gradio/english_translator\")\n\ndef generate_text(text):\n    english = english_generator(text)[0][\"generated_text\"]\n    german = english_translator(english, api_name=\"translate-to-german\")\n    return english, german\n\nwith gr.Blocks() as demo:\n    text = gr.Textbox(label=\"Text prompt\")\n    english = gr.Textbox(label=\"Generated English text\")\n    german = gr.Textbox(label=\"Translated German text\")\n    generate_btn = gr.Button(\"Generate\")\n    generate_btn.click(generate_text, inputs=text, outputs=[english, german])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring Root Path\nDESCRIPTION: Sets the root path for running Gradio behind a reverse proxy.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_7\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_ROOT_PATH=\"/myapp\"\n```\n\n----------------------------------------\n\nTITLE: Space Duplication with Hardware Configuration\nDESCRIPTION: Example demonstrating how to duplicate a Space with custom hardware and timeout settings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.duplicate(\"abidlabs/whisper\", {\n\thf_token: \"hf_...\",\n\ttimeout: 60,\n\thardware: \"a10g-small\"\n});\n```\n\n----------------------------------------\n\nTITLE: Installing the Gradio Library using pip in Python\nDESCRIPTION: This command uses pip to install the Gradio library quietly (`-q`). This is a prerequisite for using Gradio to build the web interface. It's typically run in a Jupyter Notebook or similar environment where shell commands can be executed directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/longest_word/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_with_additional_inputs/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution Function Implementation\nDESCRIPTION: Implements a function to run tasks in parallel using ThreadPoolExecutor. Takes a function and number of parallel executions as parameters.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef run_in_parallel(func, n):\n    # Ensure the callable and repetitions are valid\n    if not callable(func) or not isinstance(n, int) or n < 1:\n        raise ValueError(\"Invalid function or number of repetitions\")\n    \n    # Define a wrapper function to execute\n    def task_wrapper():\n        return func()\n    \n    # Use ThreadPoolExecutor to run tasks in parallel\n    with ThreadPoolExecutor(max_workers=n) as executor:\n        futures = [executor.submit(task_wrapper) for _ in range(n)]\n        \n        # Wait for all futures to complete and collect results\n        results = [future.result() for future in futures]\n    \n    return results\n```\n\n----------------------------------------\n\nTITLE: Formatting Class Docstrings for Documentation (Python)\nDESCRIPTION: Illustrates the standard format for a Python class docstring that the Gradio documentation generator recognizes. The docstring must be a multi-line string literal placed immediately after the class definition and should contain a description of the class. Markdown formatting within this docstring will be rendered in the generated documentation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_3\n\nLANGUAGE: py\nCODE:\n```\n\"\"\"\nA description of the class.\n\nThis can span multiple lines and can _contain_ *markdown*.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Specifying Pandas Dependency\nDESCRIPTION: Simple text file specifying pandas as a required package dependency for the gradio-app project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fraud_detector/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas\n```\n\n----------------------------------------\n\nTITLE: Multiple Outputs Response Example\nDESCRIPTION: Example of a response from an endpoint that returns multiple values (text and a number).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\nevent: complete\ndata: [\"Good morning Hello. It is 5 degrees today\", -15.0]\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Interface for PyPI Stats Dashboard in Python\nDESCRIPTION: This code snippet sets up a Gradio interface that creates a dashboard displaying PyPI download statistics for specified Python libraries. It uses the 'pypistats' library to fetch download data and 'plotly' to create visualizations. The interface updates automatically when loaded.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timeseries-forecasting-with-prophet/DESCRIPTION.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport pypistats\nimport plotly.express as px\n\ndef get_downloads(packages):\n    data = []\n    for package in packages.split(','):\n        package = package.strip()\n        downloads = pypistats.overall(package, total=True, format=\"pandas\")\n        downloads['package'] = package\n        data.append(downloads)\n    return px.line(data, x='date', y='downloads', color='package', title='PyPI Downloads')\n\ndemo = gr.Interface(\n    fn=get_downloads,\n    inputs=gr.Textbox(value=\"gradio,streamlit,dash\", label=\"Packages (comma-separated)\"),\n    outputs=\"plot\",\n    title=\"PyPI Downloads Dashboard\",\n    description=\"Enter comma-separated package names to see their PyPI download statistics.\",\n    allow_flagging=\"never\",\n    examples=[[\"fastapi,flask,django\"]],\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring TailwindCSS Vite Plugin in Gradio Components\nDESCRIPTION: Configuration for integrating TailwindCSS with Gradio custom components by adding the TailwindCSS Vite plugin to gradio.config.js.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_7\n\nLANGUAGE: typescript\nCODE:\n```\nimport tailwindcss from \"@tailwindcss/vite\";\nexport default {\n    plugins: [tailwindcss()]\n};\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and OpenAI Libraries using pip\nDESCRIPTION: This shell command, often run in a notebook environment, uses pip to install the `gradio` library for building the web interface and the `openai` library (version 1.0.0 or higher). The `-q` flag ensures a quiet installation, suppressing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_claude/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio openai>=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Importing StatusTracker Components in Svelte\nDESCRIPTION: This snippet shows how to import the StatusTracker, Toast, and Loader components from the @gradio/statustracker package in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import {StatusTracker, Toast, Loader} from `@gradio/statustracker`;\n</script>\n```\n\n----------------------------------------\n\nTITLE: Importing 3D Model Components in Gradio\nDESCRIPTION: This snippet imports the base components for 3D model handling in Gradio. It includes BaseModel3D for display, BaseModel3DUpload for file uploads, and BaseExample for example data management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/model3D/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import {BaseModel3D, BaseModel3DUpload, BaseExample } from `@gradio/model3d`;\n</script>\n```\n\n----------------------------------------\n\nTITLE: Referencing GitHub Pull Request in Markdown\nDESCRIPTION: This snippet demonstrates how to reference a GitHub pull request in a Markdown changelog entry. It includes the PR number, commit hash, and description.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/state/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: Markdown\nCODE:\n```\n[#9163](https://github.com/gradio-app/gradio/pull/9163) [`2b6cbf2`](https://github.com/gradio-app/gradio/commit/2b6cbf25908e42cf027324e54ef2cc0baad11a91) - fix exports and generate types.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Setting Gradio Server Port\nDESCRIPTION: Sets the port number for running the Gradio application server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport GRADIO_SERVER_PORT=8000\n```\n\n----------------------------------------\n\nTITLE: Loading CSS with Reuse Prevention\nDESCRIPTION: The wasm_proxied_mount_css function is modified to not reuse existing style elements, preventing CSS style conflicts\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: css\nCODE:\n```\nf67759dcee665cfd7c44f102f36ab23128ee2c2c - Fix wasm_proxied_mount_css to not reuse an existing style element\n```\n\n----------------------------------------\n\nTITLE: Google Cloud Service Account Credentials JSON Example - JSON\nDESCRIPTION: This snippet provides an example format of a Google Cloud service account credential JSON file needed to authenticate programmatic access to private Google Sheets. Required for the gspread-based workflow. Parameters and fields include type, project_id, client_email, private_key, URIs, and certificate URLs. Users must replace fields with actual credential information. The file should be kept secure and loaded by authentication libraries such as gspread.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_3\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"type\": \"service_account\",\n\t\"project_id\": \"your project\",\n\t\"private_key_id\": \"your private key id\",\n\t\"private_key\": \"private key\",\n\t\"client_email\": \"email\",\n\t\"client_id\": \"client id\",\n\t\"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n\t\"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n\t\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n\t\"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\n}\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Retrieves a Python data file from the Gradio GitHub repository that contains a dataset needed for the visualization demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_interactive/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_interactive/data.py\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Images using Wget in Python\nDESCRIPTION: Downloads three example image files (two cheetah JPEGs with different extensions and one lion JPG) from the Gradio GitHub repository using the `wget` command executed via the shell. The '-q' flag suppresses output during download. These images are intended for use as examples within the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_interface_load/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_classifier_interface_load/cheetah1.jpeg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_classifier_interface_load/cheetah1.jpg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_classifier_interface_load/lion.jpg\n```\n\n----------------------------------------\n\nTITLE: Recommended DOM-based Testing Pattern\nDESCRIPTION: The recommended approach for testing UI interactions using DOM elements and retrying assertions instead of network calls.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nconst uploadButton = page...\nawait uploadButton.click();\nawait expect(page.getByTestId(\"file-component\")).toHaveValue(..., {timeout?: 5000});\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Environment on MacOS/Linux using Bash\nDESCRIPTION: This command uses the Python `venv` module to create a new isolated virtual environment named `gradio-env` in the current directory on a MacOS or Linux system. It requires Python 3.10 or higher to be installed and accessible via the `python` (or potentially `python3`) command in the terminal.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv gradio-env\n```\n\n----------------------------------------\n\nTITLE: Hugging Face Button Variant Addition\nDESCRIPTION: Code change that introduced a new \"huggingface\" button variant and made it the default for LoginButton and DuplicateButton components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- [#9254](https://github.com/gradio-app/gradio/pull/9254) [`03f3735`](https://github.com/gradio-app/gradio/commit/03f3735fba1fd4f1978b5431af9e67de3b6e7945) - Adds a \"huggingface\" button variant, and makes it the default for `gr.LoginButton` and `gr.DuplicateButton`.\n```\n\n----------------------------------------\n\nTITLE: Setting Eraser Size via API (TypeScript)\nDESCRIPTION: Sets the eraser size specifically for the eraser mode of the Brush Tool. It accepts a `size` parameter. This allows separate size control for erasing compared to drawing. This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nset_eraser_size(size)\n```\n\n----------------------------------------\n\nTITLE: Creating a Virtual Environment on Windows using Bash\nDESCRIPTION: This command uses the Python `venv` module to create a new isolated virtual environment named `gradio-env` in the current directory on a Windows system. It requires Python 3.10 or higher to be installed and accessible via the `python` command in the Command Prompt.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv gradio-env\n```\n\n----------------------------------------\n\nTITLE: Interface with Additional Inputs\nDESCRIPTION: Demonstrates how to create an interface with additional inputs hidden in an accordion. Shows how to organize multiple inputs to prevent UI clutter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/00_the-interface-class.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef image_classifier(image, threshold=0.5, top_k=3):\n    return [\"cat\", \"dog\", \"bird\"]\n\ndemo = gr.Interface(\n    fn=image_classifier,\n    inputs=gr.Image(label=\"Input Image\"),\n    additional_inputs=[\n        gr.Slider(0, 1, value=0.5, label=\"Confidence Threshold\"),\n        gr.Number(value=3, label=\"Top K\")\n    ],\n    outputs=[gr.Label(label=\"Classification Results\")]\n)\n```\n\n----------------------------------------\n\nTITLE: Listing Python Dependencies for Gradio Application\nDESCRIPTION: This snippet enumerates the essential Python libraries needed to run the Gradio application. It includes NumPy for numerical computations, Requests for making HTTP requests, and Pillow for image manipulation tasks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/annotatedimage_component/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\nrequests\nPillow\n```\n\n----------------------------------------\n\nTITLE: Importing ColorPicker in Gradio's __init__.py\nDESCRIPTION: This code snippet shows how to import the newly created ColorPicker component in the __init__.py file to make it available throughout the Gradio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/creating-a-new-component.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio.components import (\n    ...\n    ColorPicker,\n    ...\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package silently using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_file_limit_test/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files\nDESCRIPTION: Downloads required test case files from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_multimodal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/chatbot_multimodal/tuples_testcase.py\n```\n\n----------------------------------------\n\nTITLE: Importing BaseMultimodalTextbox and BaseExample Components in Svelte\nDESCRIPTION: This snippet imports the BaseMultimodalTextbox and BaseExample components from the @gradio/multimodaltextbox package. These components are likely used to create customizable text input interfaces in Gradio applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/multimodaltextbox/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseMultimodalTextbox, BaseExample } from \"@gradio/multimodaltextbox\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio Analytics\nDESCRIPTION: Controls whether Gradio analytics are enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_3\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_ANALYTICS_ENABLED=\"True\"\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Bar Plot Demo\nDESCRIPTION: Installs the required Python packages (gradio and pandas) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot_demo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod_default_image/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Defining BaseHTML Component Properties in Gradio TypeScript\nDESCRIPTION: This snippet defines several exported properties for a component, likely `BaseHTML` or a derived component. It includes `elem_id` (string), `elem_classes` (array of strings), `value` (string representing HTML content), `visible` (boolean), and `min_height` (boolean). These properties control the identification, styling, content, and visibility of the rendered HTML element. TypeScript type annotations specify the data type for each property.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/html/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let value: string;\n\texport let visible = true;\n\texport let min_height = false;\n```\n\n----------------------------------------\n\nTITLE: Sharing a Gradio Demo with a Public URL in Python\nDESCRIPTION: This code shows how to create a simple Gradio interface and share it with a public URL. The share=True parameter in the launch method generates a public link for the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/01_getting-started/01_quickstart.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter 🚀\n```\n\n----------------------------------------\n\nTITLE: Required Dependencies for Gradio Authentication\nDESCRIPTION: Lists essential dependencies required for Gradio's authentication and session management functionality: authlib for authentication and itsdangerous for Starlette's SessionMiddleware.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/requirements-oauth.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nauthlib\nitsdangerous # required for starlette SessionMiddleware\n```\n\n----------------------------------------\n\nTITLE: Streaming Output Response Example\nDESCRIPTION: Example showing how streaming outputs appear as a sequence of generating events followed by a complete event.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_12\n\nLANGUAGE: bash\nCODE:\n```\nevent: generating\ndata: [\"Hello, w!\"]\nevent: generating\ndata: [\"Hello, wo!\"]\nevent: generating\ndata: [\"Hello, wor!\"]\nevent: generating\ndata: [\"Hello, worl!\"]\nevent: generating\ndata: [\"Hello, world!\"]\nevent: complete\ndata: [\"Hello, world!\"]\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages: gradio, gradio_pdf, and pymupdf for PDF handling and UI components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlight_pdf/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio gradio_pdf>=0.0.22 pymupdf>=1.25.3\n```\n\n----------------------------------------\n\nTITLE: Making Components SSR Compatible\nDESCRIPTION: Update to make all components, including Annotated Image, Server-Side Rendering compatible in beta version 0.7.2-beta.1.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#9187](https://github.com/gradio-app/gradio/pull/9187) [`5bf00b7`](https://github.com/gradio-app/gradio/commit/5bf00b7524ebf399b48719120a49d15bb21bd65c) - make all component SSR compatible.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio and Transformers\nDESCRIPTION: This snippet installs the necessary Python libraries (gradio, transformers, and torch) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_english_german/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio transformers torch\n```\n\n----------------------------------------\n\nTITLE: Exporting Properties for BaseDropdown with Gradio in JavaScript\nDESCRIPTION: This JavaScript snippet defines the exported properties for the BaseDropdown component in a Svelte application. It specifies configurable props like label, info, value (supporting string, number, or array values), output flag, list of choices as pairs, disabled state, label display, container usage, custom value allowance, and filtering capability. There are no external dependencies beyond Svelte and the parent component; inputs include user-provided configuration, and outputs are UI behaviors as governed by these props.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dropdown/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let label: string;\\nexport let info: string | undefined = undefined;\\nexport let value: string | number | (string | number)[] | undefined = [];\\nexport let value_is_output = false;\\nexport let choices: [string, string | number][];\\nexport let disabled = false;\\nexport let show_label: boolean;\\nexport let container = true;\\nexport let allow_custom_value = false;\\nexport let filterable = true;\n```\n\n----------------------------------------\n\nTITLE: Installing mdsvex for Markdown in Svelte Components\nDESCRIPTION: Command to install mdsvex, a Markdown preprocessor for Svelte, to enhance Gradio custom components with Markdown support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nnpm install mdsvex\n```\n\n----------------------------------------\n\nTITLE: Loading CSV Example Data for Gradio Interface\nDESCRIPTION: This CSV file demonstrates the structure for providing example inputs to a Gradio interface with multiple inputs. It includes columns for two numbers and an operation to be performed between them.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/01_more-on-examples.md#2025-04-23_snippet_0\n\nLANGUAGE: csv\nCODE:\n```\nnum,operation,num2\n5,\"add\",3\n4,\"divide\",2\n5,\"multiply\",3\n```\n\n----------------------------------------\n\nTITLE: BaseExample Component Properties\nDESCRIPTION: Defines the properties for the BaseExample component, which handles example audio files. It accepts a value string, a type (gallery or table), and a selected state boolean.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/audio/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Defining Single-Input Processing Function in Python\nDESCRIPTION: This code defines a Python function `trim_words` designed to process a single input sample. It accepts a `word` string and a `length` (convertible to integer), returning the word truncated to that length. This function signature is suitable for Gradio event listeners where batch processing is disabled (`batch=False`).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/setting-up-a-demo-for-maximum-performance.md#2025-04-23_snippet_1\n\nLANGUAGE: py\nCODE:\n```\nimport time\n\ndef trim_words(word, length):\n    return word[:int(length)]\n\n```\n\n----------------------------------------\n\nTITLE: Creating requirements.txt for PDF Component Demo\nDESCRIPTION: This snippet shows the contents of the requirements.txt file needed for the PDF component demo, including necessary packages for document question-answering.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_17\n\nLANGUAGE: text\nCODE:\n```\ntorch\ntransformers\npdf2image\npytesseract\n```\n\n----------------------------------------\n\nTITLE: Installing Google BigQuery Python Client with Pandas Support\nDESCRIPTION: Provides the shell command using pip to install the `google-cloud-bigquery` Python library. It specifically includes the optional `pandas` dependency, enabling direct conversion of BigQuery query results into pandas DataFrames.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-dashboard-from-bigquery-data.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install google-cloud-bigquery[pandas]\n```\n\n----------------------------------------\n\nTITLE: UploadText Component Props Definition\nDESCRIPTION: Defines the available props for the UploadText component, which displays upload instructions with configurable file type and internationalization support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_7\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let type: \"video\" | \"image\" | \"audio\" | \"file\" | \"csv\" = \"file\";\n\texport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Initializing Lite Client\nDESCRIPTION: Sets up client initialization with fake host for Lite server and handles request processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_3\n\n\n\n----------------------------------------\n\nTITLE: Setting Chat Flagging Mode\nDESCRIPTION: Controls message flagging in chat interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_19\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_CHAT_FLAGGING_MODE=\"manual\"\n```\n\n----------------------------------------\n\nTITLE: Expected Stream Response Format\nDESCRIPTION: Shows the expected format of streaming responses from a Gradio endpoint, consisting of event types and corresponding data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nevent: ... \ndata: ...\nevent: ... \ndata: ...\n...\n```\n\n----------------------------------------\n\nTITLE: Installing the reticulate R Package\nDESCRIPTION: An R command to install the `reticulate` package from the Comprehensive R Archive Network (CRAN). The `reticulate` package is essential for enabling interoperability between R and Python, allowing R users to call Python code and use Python libraries directly within R.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_6\n\nLANGUAGE: r\nCODE:\n```\ninstall.packages(\"reticulate\")\n```\n\n----------------------------------------\n\nTITLE: Defining and Launching a Hyperbolic LLM Chatbot with Gradio in Python\nDESCRIPTION: This snippet implements a Python-based chatbot using Gradio and the Hyperbolic API via the OpenAI client. It expects the HYPERBOLIC_API_KEY environment variable to be set for authentication. The 'predict' function maintains chat history, calls the Hyperbolic API's streaming endpoint, and yields partial responses to Gradio's chat UI. Inputs are user messages and conversation history; outputs are generated model responses. The script launches a Gradio web interface on execution and requires the gradio and openai Python packages, as well as a valid Hyperbolic API key.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hyperbolic/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This is a simple general-purpose chatbot built on top of Hyperbolic API. \n# Before running this, make sure you have exported your Hyperbolic API key as an environment variable:\n# export HYPERBOLIC_API_KEY=\"your-hyperbolic-api-key\"\n\nimport os\nimport gradio as gr\nfrom openai import OpenAI\n\napi_key = os.getenv(\"HYPERBOLIC_API_KEY\")\n\nclient = OpenAI(\n    base_url=\"https://api.hyperbolic.xyz/v1/\",\n    api_key=api_key,\n)\n\ndef predict(message, history):\n    history.append({\"role\": \"user\", \"content\": message})\n    stream = client.chat.completions.create(messages=history, model=\"gpt-4o-mini\", stream=True)\n    chunks = []\n    for chunk in stream:\n        chunks.append(chunk.choices[0].delta.content or \"\")\n        yield \"\".join(chunks)\n\ndemo = gr.ChatInterface(predict, type=\"messages\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Making Gradio Dev Tools a Local Dependency\nDESCRIPTION: Modification to change Gradio dev tools from a bundled component to a local dependency in version 0.5.13, implemented in pull request #8066.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: markdown\nCODE:\n```\n### Fixes\n\n- [#8066](https://github.com/gradio-app/gradio/pull/8066) [`624f9b9`](https://github.com/gradio-app/gradio/commit/624f9b9477f74a581a6c14119234f9efdfcda398) - make gradio dev tools a local dependency rather than bundling.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Defining the Command Interface for Undo/Redo Operations - TypeScript\nDESCRIPTION: This TypeScript interface enforces the Command pattern to support undo/redo in the editor. Commands encapsulate state changes and must provide execute and undo methods for reversible operations. Implementers should ensure operations are fully reversible and manage any resources affected. Typical dependencies include the editor state and any data required to reconstruct/undo image modifications; commands expect no direct input or output, operating through side effects.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/IMAGE_EDITOR_OVERVIEW.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Command {\n  execute(): void;\n  undo(): void;\n}\n```\n\n----------------------------------------\n\nTITLE: Running the FastAPI Application\nDESCRIPTION: Command to start the FastAPI application using uvicorn server\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\n$ uvicorn main:app\n```\n\n----------------------------------------\n\nTITLE: Version Update Dependencies Section\nDESCRIPTION: Shows updated package dependency versions for the UploadButton component\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Updated dependencies []:\n  - @gradio/upload@0.7.4\n  - @gradio/button@0.2.22\n```\n\n----------------------------------------\n\nTITLE: Fetching Demo Asset Files - Python\nDESCRIPTION: Downloads necessary UI, styling, and data assets for the leaderboard demo, storing them in an 'assets' directory. Uses os to create the directory and shell commands to fetch Python, CSS, and JSON files from a GitHub repository. Requires OS shell and network access; designed for setup prior to launching the UI.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/mini_leaderboard/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n```python\\n# Downloading files from the demo repo\\nimport os\\nos.mkdir('assets')\\n!wget -q -O assets/__init__.py https://github.com/gradio-app/gradio/raw/main/demo/mini_leaderboard/assets/__init__.py\\n!wget -q -O assets/custom_css.css https://github.com/gradio-app/gradio/raw/main/demo/mini_leaderboard/assets/custom_css.css\\n!wget -q -O assets/leaderboard_data.json https://github.com/gradio-app/gradio/raw/main/demo/mini_leaderboard/assets/leaderboard_data.json\\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with pip in Python\nDESCRIPTION: This code snippet installs the Gradio Python library using pip, ensuring that all necessary dependencies for running Gradio applications are available in the environment. It is typically run in a Jupyter notebook or similar interactive Python environment. No parameters are required; upon execution, Gradio will be available for import in subsequent code cells.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3d_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: File Size Upload Limit Configuration in Python\nDESCRIPTION: Example showing how to set maximum file upload size limits in Gradio using either string or byte values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/video/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Creating a Sentence Builder Interface with Gradio\nDESCRIPTION: Defines a sentence builder function and creates a Gradio interface with various input components. The function takes inputs like quantity, animal type, countries, place, activities, and time of day to generate a formatted sentence. The interface includes examples for demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sentence_builder/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef sentence_builder(quantity, animal, countries, place, activity_list, morning):\n    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n\ndemo = gr.Interface(\n    sentence_builder,\n    [\n        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose between 2 and 20\"),\n        gr.Dropdown(\n            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n        ),\n        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n        gr.Dropdown(\n            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n        ),\n        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n    ],\n    \"text\",\n    examples=[\n        [2, \"cat\", [\"Japan\", \"Pakistan\"], \"park\", [\"ate\", \"swam\"], True],\n        [4, \"dog\", [\"Japan\"], \"zoo\", [\"ate\", \"swam\"], False],\n        [10, \"bird\", [\"USA\", \"Pakistan\"], \"road\", [\"ran\"], False],\n        [8, \"cat\", [\"Pakistan\"], \"zoo\", [\"ate\"], True],\n    ]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Component in Gradio\nDESCRIPTION: This snippet defines the properties for the BaseExample component. It includes a value, type (either 'gallery' or 'table'), and a selected state. This component is likely used for managing example data in Gradio interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/model3D/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip\nDESCRIPTION: This snippet uses pip, the Python package installer, to install the Gradio library. The '-q' flag indicates a quiet installation, minimizing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Creating a Thread-Safe Comet ML Experiment Function in Python\nDESCRIPTION: Defines a function to initialize a thread-safe Comet ML API experiment for logging inferences. It retrieves workspace and project information from Comet configuration and returns the experiment object along with a status message.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ndef start_experiment():\n    \"\"\"Returns an APIExperiment object that is thread safe\n    and can be used to log inferences to a single Experiment\n    \"\"\"\n    try:\n        api = comet_ml.API()\n        workspace = api.get_default_workspace()\n        project_name = comet_ml.config.get_config()[\"comet.project_name\"]\n\n        experiment = comet_ml.APIExperiment(\n            workspace=workspace, project_name=project_name\n        )\n        experiment.log_other(\"Created from\", \"gradio-inference\")\n\n        message = f\"Started Experiment: [{experiment.name}]({experiment.url})\"\n\n        return (experiment, message)\n\n    except Exception as e:\n        return None, None\n```\n\n----------------------------------------\n\nTITLE: Creating Static Gradio Blocks Interface\nDESCRIPTION: This code creates a Gradio Blocks interface with static components. It includes an image from an external URL, a textbox with default text, and a number input with a default value. The interface is launched if the script is run directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_static/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Blocks()\n\nwith demo:\n    gr.Image(\n        \"https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=387&q=80\"\n    )\n    gr.Textbox(\"hi\")\n    gr.Number(3)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Login Button Behavior Fix\nDESCRIPTION: Fixed behavior of gr.LoginButton component for both local environments and Hugging Face Spaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n- [#9659](https://github.com/gradio-app/gradio/pull/9659) [`b1a0f6d`](https://github.com/gradio-app/gradio/commit/b1a0f6db0d6900cb4089f4d5809a5f1d5e2609ee) - Fix the behavior of `gr.LoginButton` locally and on Spaces.\n```\n\n----------------------------------------\n\nTITLE: Inspecting Gradio Client API Usage Info for Stateful App\nDESCRIPTION: Shows the typical output format when inspecting the API usage information of a Gradio app with state using the Python client. Notice that the state component (`words` in the previous example) is not listed as an explicit input or output parameter for the `predict` function, as the client handles state management internally.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_13\n\nLANGUAGE: csv\nCODE:\n```\nClient.predict() Usage Info\n---------------------------\nNamed API endpoints: 1\n\n - predict(word, api_name=\"/count\") -> value_31\n    Parameters:\n     - [Textbox] word: str (required)  \n    Returns:\n     - [Number] value_31: float \n```\n\n----------------------------------------\n\nTITLE: Declaring NumPy Dependency\nDESCRIPTION: This line lists 'numpy', signifying a dependency on the NumPy library, essential for numerical computing in Python. This is likely part of a requirements file or environment specification for the Gradio project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package silently using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_mixer/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio ASR Streamer (Python)\nDESCRIPTION: This command installs the required Python libraries: Gradio for the web interface, PyTorch and Torchaudio for audio processing and deep learning, and Transformers for accessing the pre-trained ASR model (Whisper). The `-q` flag ensures a quiet installation with minimal output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_asr/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio torch torchaudio transformers\n```\n\n----------------------------------------\n\nTITLE: Exporting Properties for BaseExample with Gradio in JavaScript\nDESCRIPTION: This JavaScript snippet exports the configuration for a BaseExample component, providing settings for value (as a string), type (either 'gallery' or 'table'), and selection state. No external dependencies besides Svelte; intended for parent components to manage and display example data visually. Inputs are value, type, and selected, with outputs used for state or display updates.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dropdown/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\\nexport let type: \"gallery\" | \"table\";\\nexport let selected = false;    \n```\n\n----------------------------------------\n\nTITLE: Using Named Arguments in TypeScript Client\nDESCRIPTION: Example showing how to use the same keyword arguments as the original Gradio app in the TypeScript client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"http://127.0.0.1:7860/\");\nconst result = await client.predict(\"/chat\", { \t\t\n\t\tmessage: \"Hello!!\", \t\t\n\t\tsystem_prompt: \"Hello!!\", \t\t\n\t\ttokens: 10, \n});\n\nconsole.log(result.data);\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages: gradio, vega_datasets, and pandas using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio vega_datasets pandas\n```\n\n----------------------------------------\n\nTITLE: Downloading Streamer Helper File (Shell)\nDESCRIPTION: This shell command uses wget to download the 'streamer.py' file from the Gradio GitHub repository. This file likely contains helper code, specifically the `ParlerTTSStreamer` class used for streaming audio generation with the Parler-TTS model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/magic_8_ball/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/magic_8_ball/streamer.py\n```\n\n----------------------------------------\n\nTITLE: Starting a Svelte Development Server\nDESCRIPTION: Commands to start a development server after creating a Svelte project and installing dependencies. The second command opens the app in a new browser tab automatically.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Demo\nDESCRIPTION: Installs the necessary Python packages (gradio, numpy, pandas) for creating a data visualization web interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_line/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy pandas \n```\n\n----------------------------------------\n\nTITLE: Configuring mdsvex in Gradio Components\nDESCRIPTION: Configuration for enabling mdsvex in Gradio custom components by adding the Svelte preprocessor to gradio.config.js. This setup allows .svx files to be compiled to .svelte files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\nimport { mdsvex } from \"mdsvex\";\n\nexport default {\n    svelte: {\n        preprocess: [\n            mdsvex()\n        ],\n        extensions: [\".svelte\", \".svx\"]\n    }\n};\n```\n\n----------------------------------------\n\nTITLE: Displaying Directory Structure for Calculator Interface Flagging\nDESCRIPTION: Shows the directory structure created when flagging is used in a calculator interface. It includes a logs.csv file within a flagged directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/02_flagging.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n+-- calculator.py\n+-- flagged/\n|   +-- logs.csv\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip with the quiet flag to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_quantitative/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Setting Maximum File Upload Size in Gradio (Python)\nDESCRIPTION: This Python snippet demonstrates how to set a maximum file size limit for uploads when launching a Gradio application. It initializes a simple Gradio Interface and uses the `launch()` method with the `max_file_size` parameter, showing options for specifying the size as a string (e.g., '5mb') or using the `gr.FileSize` enum (e.g., `5 * gr.FileSize.MB`).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/gallery/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio Audio Demo\nDESCRIPTION: Installs the necessary Python packages (gradio and numpy) required for the audio reversal demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy \n```\n\n----------------------------------------\n\nTITLE: Duplicating Spaces - Python\nDESCRIPTION: Example of duplicating a Space for private use to avoid rate limiting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\nfrom gradio_client import Client, handle_file\n\nHF_TOKEN = os.environ.get(\"HF_TOKEN\")\n\nclient = Client.duplicate(\"abidlabs/whisper\", hf_token=HF_TOKEN)\nclient.predict(handle_file(\"audio_sample.wav\"))\n\n>> \"This is a test of the whisper speech recognition model.\"\n```\n\n----------------------------------------\n\nTITLE: Adding Height and Overflow Scrollbar to Markdown Component\nDESCRIPTION: Adds an optional 'height' parameter and overflow scrollbar to the Markdown Component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n- [#8528](https://github.com/gradio-app/gradio/pull/8528) [`2b0c157`](https://github.com/gradio-app/gradio/commit/2b0c1577b27fcf30920196f815ec7be604893b19) - Added an optional `height` and overflow scrollbar for the Markdown Component.\n```\n\n----------------------------------------\n\nTITLE: Example CSV Log for Basic Gradio Flagging (CSV)\nDESCRIPTION: Shows the format and example content of the 'logs.csv' file generated by the basic flagging setup. It includes columns for each input component ('num1', 'operation', 'num2'), the output component ('Output'), and a 'timestamp'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_2\n\nLANGUAGE: csv\nCODE:\n```\nnum1,operation,num2,Output,timestamp\n5,add,7,12,2022-01-31 11:40:51.093412\n6,subtract,1.5,4.5,2022-01-31 03:25:32.023542\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseExample component, including value, type, and selected state. It specifies the types for these properties.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Uploading a Gradio Theme via Command Line\nDESCRIPTION: This bash command shows how to upload a previously saved Gradio theme to the Hugging Face Hub using the command line interface, specifying version and authentication token.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_15\n\nLANGUAGE: bash\nCODE:\n```\nupload_theme\\\n\"seafoam.json\"\\\n\"seafoam\"\\\n--version \"0.0.1\"\\\n--hf_token \"<token>\"\n```\n\n----------------------------------------\n\nTITLE: Declaring Python Package Dependencies\nDESCRIPTION: Specifies the minimum required versions of 'transformers' and 'torch' libraries for the Gradio app using a pip-compatible requirements format. This file ensures that anyone setting up the environment installs versions of these packages that are known to be compatible, preventing compatibility issues. The main inputs are package version specifiers, and the output is installation via 'pip install -r requirements.txt'. This snippet is limited to plain text and must be included at the root of the Python project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hf_transformers/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Plain Text\nCODE:\n```\ntransformers>=4.46.0\\ntorch>=2.3.1\n```\n\n----------------------------------------\n\nTITLE: Setting up Nginx Configuration for Gradio Load Testing\nDESCRIPTION: Instructions for configuring Nginx as a reverse proxy for Gradio applications in a production-like environment for load testing. The configuration should be added to the nginx.conf.d directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\nInstall nginx and add `nginx.conf` to `/etc/nginx/conf.d/*.conf` on the machine running gradio\n```\n\n----------------------------------------\n\nTITLE: Enabling Component Remounting with Previous Data\nDESCRIPTION: Feature to ensure components can be remounted while retaining their previous data. This improves the state management and user experience in Gradio applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10192](https://github.com/gradio-app/gradio/pull/10192) [`4fc7fb7`](https://github.com/gradio-app/gradio/commit/4fc7fb777c42af537e4af612423fa44029657d41) - Ensure components can be remounted with their previous data.\n```\n\n----------------------------------------\n\nTITLE: Installing and Importing Gradio in R using reticulate\nDESCRIPTION: R code that first loads the `reticulate` library. It then uses `py_install` to install the Python `gradio` library via pip into the Python environment managed by `reticulate`. Finally, it imports the installed `gradio` Python module into the R session using `import`, assigning it to the variable `gr` for subsequent use.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_7\n\nLANGUAGE: r\nCODE:\n```\nlibrary(reticulate)\n\npy_install(\"gradio\", pip = TRUE)\n\ngr <- import(\"gradio\") # import gradio as gr\n```\n\n----------------------------------------\n\nTITLE: Updating ESLint Dependency to Version 9\nDESCRIPTION: Dependency update for ESLint to version 9 in version 0.6.0, as part of regular maintenance in pull request #8121.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#8121](https://github.com/gradio-app/gradio/pull/8121) [`f5b710c`](https://github.com/gradio-app/gradio/commit/f5b710c919b0ce604ea955f0d5f4faa91095ca4a) - chore(deps): update dependency eslint to v9.  Thanks @renovate!\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Webcam Demo\nDESCRIPTION: This snippet installs the necessary libraries (Gradio and OpenCV) for the webcam demo using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/webcam_constraints/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio opencv-python\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio library using pip\nDESCRIPTION: This snippet installs the Gradio library quietly using pip. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/checkboxgroup_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Frontend Directory Path\nDESCRIPTION: Python code showing how to configure custom frontend directory path in the component class.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nclass SuperTextbox(Component):\n    FRONTEND_DIR = \"../../frontend/\"\n```\n\n----------------------------------------\n\nTITLE: Importing BaseChatBot Component in Svelte\nDESCRIPTION: Demonstrates how to import the BaseChatBot component from the @gradio/chatbot module in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/chatbot/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { BaseChatBot } from \"@gradio/chatbot\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Improving Icon Button Consistency\nDESCRIPTION: Enhancements to improve the consistency of icon buttons across the application in version 0.8.0, implemented in pull request #8843.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#8843](https://github.com/gradio-app/gradio/pull/8843) [`6f95286`](https://github.com/gradio-app/gradio/commit/6f95286337459efbccb95c9cfac63355669df9ee) - Improve Icon Button consistency\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: Lists required Python packages: matplotlib for creating visualizations and pandas for data manipulation and analysis.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/kitchen_sink_random/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nmatplotlib\npandas\n```\n\n----------------------------------------\n\nTITLE: Configuring Default Web Crawler Access in robots.txt\nDESCRIPTION: This robots.txt configuration allows all web crawlers (User-agent: *) unrestricted access to the entire website by not specifying any disallowed paths (Disallow: is empty).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/component-test/static/robots.txt#2025-04-23_snippet_0\n\nLANGUAGE: robots.txt\nCODE:\n```\n# https://www.robotstxt.org/robotstxt.html\nUser-agent: *\nDisallow:\n```\n\n----------------------------------------\n\nTITLE: Defining CSS Styles for Gradio Storybook Introduction Page\nDESCRIPTION: Defines CSS styles for various elements on the Gradio Storybook introduction page, including image responsiveness, container layout, headings, and link colors.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/storybook/Introduction.mdx#2025-04-23_snippet_2\n\nLANGUAGE: CSS\nCODE:\n```\nimg {\n      margin: 1rem;\n      display: flex;\n      justify-content: left;\n\n      @media (max-width: 600px) {\n        width: 200px;\n      }\n    }\n\n    .container {\n      margin: 0 auto;\n      padding: 0 1rem;\n    }\n\n    .heading {\n      font-size: 2rem;\n      margin: 0 auto;\n    }\n\n    .subheading {\n      font-size: 1rem;\n      margin: 1rem auto;\n    }\n\n    ul {\n      list-style: none;\n      padding-left: 0;\n      margin: 0;\n    }\n\n    li a {\n      color: #ff7c01 !important;\n    }\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio and Audio Processing - Python\nDESCRIPTION: This snippet installs all required dependencies for running the demo, including Gradio, PyTorch, torchvision, torchaudio, librosa, and gdown. Dependencies are crucial for audio processing, model inference, and interface rendering. Must be run in a compatible Python environment prior to using the rest of the code; installs exact package versions for consistency and reproducibility.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/musical_instrument_identification/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 librosa==0.9.2 gdown\n```\n\n----------------------------------------\n\nTITLE: Specifying Numpy Dependency for Gradio\nDESCRIPTION: This snippet defines numpy as a required package for the Gradio application. It does not specify a version, which typically means the latest version will be used.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_selections/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Adding Copy Button to Markdown Component\nDESCRIPTION: Adds a copy button functionality to the gr.Markdown component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n- [#8851](https://github.com/gradio-app/gradio/pull/8851) [`914b193`](https://github.com/gradio-app/gradio/commit/914b1935de27c3b379ac9e759b6d10747e3b881a) - Add copy button to `gr.Markdown`.\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (gradio and numpy) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_segmentation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Configuring BaseImageUploader Props (JavaScript)\nDESCRIPTION: This snippet exports the configuration options for the BaseImageUploader component. It specifies allowable sources for image upload ('clipboard', 'webcam', 'upload') and flags for streaming, pending state, webcam mirroring, selectability, as well as root and i18n formatter injection. The component is designed to allow flexible image acquisition and must receive the appropriate props from its parent Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\\texport let sources: (\"clipboard\" | \"webcam\" | \"upload\")[] = [\\n\\t\\t\"upload\",\\n\\t\\t\"clipboard\",\\n\\t\\t\"webcam\"\\n\\t];\\n\\texport let streaming = false;\\n\\texport let pending = false;\\n\\texport let mirror_webcam: boolean;\\n\\texport let selectable = false;\\n\\texport let root: string;\\n\\texport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Importing Tooltip Component from Gradio\nDESCRIPTION: This snippet shows how to import the Tooltip component from the @gradio/tooltip package. This is typically used at the beginning of a file where the Tooltip component is needed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tooltip/README.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Tooltip } from \"@gradio/tooltip\";\n```\n\n----------------------------------------\n\nTITLE: Specifying numpy Package Requirement\nDESCRIPTION: A requirements.txt entry specifying numpy as a project dependency without version constraints.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_segmentation/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: txt\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Creating a Sine Wave Plot and Displaying it with Gradio\nDESCRIPTION: Generates a sine wave using NumPy, plots it with Matplotlib, and displays the plot in a Gradio interface using the Plot component. The example uses a sample rate of 8000 Hz and a 5 Hz sine wave.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nFs = 8000\nf = 5\nsample = 8000\nx = np.arange(sample)\ny = np.sin(2 * np.pi * f * x / Fs)\nplt.plot(x, y)\n\nwith gr.Blocks() as demo:\n    gr.Plot(value=plt)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Example CSV Log for Gradio Flagging with Options (CSV)\nDESCRIPTION: Shows the format and example content of 'logs.csv' when `flagging_options` are used. An additional column, 'flag', is included to store the specific option selected by the user when they flagged the data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_6\n\nLANGUAGE: csv\nCODE:\n```\nnum1,operation,num2,Output,flag,timestamp\n5,add,7,-12,wrong sign,2022-02-04 11:40:51.093412\n6,subtract,1.5,3.5,off by one,2022-02-04 11:42:32.062512\n```\n\n----------------------------------------\n\nTITLE: Markdown Code Block - Feature Highlights\nDESCRIPTION: Shows a formatted markdown section highlighting performance improvements and markdown support features.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tootils/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n[#5279](https://github.com/gradio-app/gradio/pull/5279) [`fe057300`](https://github.com/gradio-app/gradio/commit/fe057300f0672c62dab9d9b4501054ac5d45a4ec)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Stock Forecast Demo - Python\nDESCRIPTION: This snippet installs the required dependencies, namely Gradio, NumPy, and Matplotlib, using the pip package manager. All packages are installed quietly to set up the environment for the interactive demo app. This setup step is necessary before running the Gradio interface for stock forecast visualization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stock_forecast/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy matplotlib\n```\n\n----------------------------------------\n\nTITLE: Configuring Trusted IP Addresses\nDESCRIPTION: Sets trusted IP addresses for forwarded traffic in reverse proxy setups.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_11\n\nLANGUAGE: sh\nCODE:\n```\nexport FORWARDED_ALLOW_IPS=\"127.0.0.1,192.168.1.100\"\n```\n\n----------------------------------------\n\nTITLE: Installing Production Dependencies and Starting Node.js App (Bash)\nDESCRIPTION: This Bash snippet shows how to install only production dependencies for a Node.js application using `npm install --production` and then start the application in a production environment by setting the `NODE_ENV` variable. This is part of the Dillinger setup instructions within the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nnpm install --production\nNODE_ENV=production node app\n```\n\n----------------------------------------\n\nTITLE: Feature Addition: Event Listeners in Gradio Sketch\nDESCRIPTION: This snippet describes a feature addition in version 0.6.1, introducing event listeners to the Gradio sketch component. It includes the pull request number and commit hash.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/sketchbox/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10694](https://github.com/gradio-app/gradio/pull/10694) [`16244f3`](https://github.com/gradio-app/gradio/commit/16244f3c1cb1a65ac1f719142f8fab67512fbb25) - Event Listeners in gradio sketch.  Thanks @aliabid94!\n```\n\n----------------------------------------\n\nTITLE: File Response Example Terminal Output\nDESCRIPTION: Example of how a file response appears in the terminal, showing the complete JSON structure returned by the API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_14\n\nLANGUAGE: bash\nCODE:\n```\nevent: complete\ndata: [{\"path\": \"/tmp/gradio/359933dc8d6cfe1b022f35e2c639e6e42c97a003/image.webp\", \"url\": \"https://gradio-image-mod.hf.space/c/file=/tmp/gradio/359933dc8d6cfe1b022f35e2c639e6e42c97a003/image.webp\", \"size\": null, \"orig_name\": \"image.webp\", \"mime_type\": null, \"is_stream\": false, \"meta\": {\"_type\": \"gradio.FileData\"}}]\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Chicago Bikeshare Dashboard\nDESCRIPTION: This snippet installs the necessary Python packages for the Gradio demo, including gradio, psycopg2, matplotlib, SQLAlchemy, and pandas.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chicago-bikeshare-dashboard/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio psycopg2 matplotlib SQLAlchemy pandas\n```\n\n----------------------------------------\n\nTITLE: Basic Response Example\nDESCRIPTION: Example of a complete response from a simple text translation endpoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\nevent: complete\ndata: [\"Bonjour, mon ami.\"]\n```\n\n----------------------------------------\n\nTITLE: Defining BaseExample Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the BaseExample component, including value, type (gallery or table), and selected state.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/radio/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: A plaintext list of Python packages required for the project: numpy for numerical computing and pandas for data manipulation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_kinematics/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nnumpy\npandas\n```\n\n----------------------------------------\n\nTITLE: Configuring Python Exports in __init__.py\nDESCRIPTION: Example of configuring top-level Python exports for the custom component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom .mytextbox import MyTextbox\nfrom .mytextbox import AdditionalClass, additional_function\n\n__all__ = ['MyTextbox', 'AdditionalClass', 'additional_function']\n```\n\n----------------------------------------\n\nTITLE: Error Handler Implementation\nDESCRIPTION: Implementation of error handling mechanism that converts error objects caught in the worker to be cloneable for better error management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: typescript\nCODE:\n```\nrun_code()\n```\n\nLANGUAGE: typescript\nCODE:\n```\nrun_file()\n```\n\n----------------------------------------\n\nTITLE: TypeScript Interface for Gradio Space Status\nDESCRIPTION: TypeScript interfaces defining the structure of space status information returned by the status callback.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_6\n\nLANGUAGE: typescript\nCODE:\n```\ninterface SpaceStatusNormal {\n\tstatus: \"sleeping\" | \"running\" | \"building\" | \"error\" | \"stopped\";\n\tdetail:\n\t\t| \"SLEEPING\"\n\t\t| \"RUNNING\"\n\t\t| \"RUNNING_BUILDING\"\n\t\t| \"BUILDING\"\n\t\t| \"NOT_FOUND\";\n\tload_status: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tmessage: string;\n}\n\ninterface SpaceStatusError {\n\tstatus: \"space_error\";\n\tdetail: \"NO_APP_FILE\" | \"CONFIG_ERROR\" | \"BUILD_ERROR\" | \"RUNTIME_ERROR\";\n\tload_status: \"error\";\n\tmessage: string;\n\tdiscussions_enabled: boolean;\n\ntype SpaceStatus = SpaceStatusNormal | SpaceStatusError;\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Gradio Magic 8 Ball Demo (Shell)\nDESCRIPTION: This shell command installs the required Python libraries for the Gradio Magic 8 Ball demo using pip. It includes Gradio for the UI, parler-tts (directly from GitHub) for text-to-speech, accelerate and torch for deep learning operations, spaces for Hugging Face Spaces integration, pydub for audio manipulation, transformers and huggingface_hub for model interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/magic_8_ball/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio git+https://github.com/huggingface/parler-tts.git accelerate spaces torch pydub transformers huggingface_hub \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependencies\nDESCRIPTION: Installs required Gradio packages including the PDF extension module.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gradio_pdf_demo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio gradio_pdf==0.0.7\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the required Python packages gradio and numpy using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flipper/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Creating Interactive Dataframe with Gradio\nDESCRIPTION: Creates an interactive dataframe component using Gradio Blocks interface. The dataframe is set to be interactive allowing user manipulation. Launches the interface in a browser.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Dataframe(interactive=True)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Improving Embed and CDN Handling in Gradio\nDESCRIPTION: This feature improves the handling of Embed and CDN in Gradio, and fixes related bugs. It enhances the functionality of embedding Gradio components and using content delivery networks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: JavaScript\nCODE:\n```\n// Code not provided in the changelog\n```\n\n----------------------------------------\n\nTITLE: Specifying External Dependencies for Gradio\nDESCRIPTION: This snippet lists the external dependencies required for the Gradio project. It includes the Hugging Face Transformers library installed directly from GitHub, and the torchaudio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unispeech-speaker-verification/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ngit+https://github.com/huggingface/transformers\ntorchaudio\n```\n\n----------------------------------------\n\nTITLE: Launching Gradio App on a Subpath - Python\nDESCRIPTION: This Python snippet shows a minimal Gradio app configured to run behind Nginx on a specified subpath using the root_path argument. It defines a simple function as the interface, introduces a delay to simulate processing, and instructs Gradio to queue requests and launch at /gradio-demo. Dependencies include the 'gradio' Python package. Inputs and outputs are textboxes, and the code is designed to run on the same port as the Nginx proxy_pass setting.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/running-gradio-on-your-web-server-with-nginx.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport time\n\ndef test(x):\n    time.sleep(4)\n    return x\n\ngr.Interface(test, \"textbox\", \"textbox\").queue().launch(root_path=\"/gradio-demo\")\n```\n\n----------------------------------------\n\nTITLE: Implementing AnimeGANv2 Gradio Interface\nDESCRIPTION: Sets up a Gradio interface for the AnimeGANv2 model, including model loading, inference function, and UI configuration. Supports two versions of the model with different stylization and robustness trade-offs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/animeganv2/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport torch\n\nmodel2 = torch.hub.load(\n    \"AK391/animegan2-pytorch:main\",\n    \"generator\",\n    pretrained=True,\n    progress=False\n)\nmodel1 = torch.hub.load(\"AK391/animegan2-pytorch:main\", \"generator\", pretrained=\"face_paint_512_v1\")\nface2paint = torch.hub.load(\n    'AK391/animegan2-pytorch:main', 'face2paint',\n    size=512,side_by_side=False\n)\n\ndef inference(img, ver):\n    if ver == 'version 2 (🔺 robustness,🔻 stylization)':\n        out = face2paint(model2, img)\n    else:\n        out = face2paint(model1, img)\n    return out\n\ntitle = \"AnimeGANv2\"\ndescription = \"Gradio Demo for AnimeGanv2 Face Portrait. To use it, simply upload your image, or click one of the examples to load them. Read more at the links below. Please use a cropped portrait picture for best results similar to the examples below.\"\narticle = \"<p style='text-align: center'><a href='https://github.com/bryandlee/animegan2-pytorch' target='_blank'>Github Repo Pytorch</a></p> <center><img src='https://visitor-badge.glitch.me/badge?page_id=akhaliq_animegan' alt='visitor badge'></center></p>\"\nexamples=[['groot.jpeg','version 2 (🔺 robustness,🔻 stylization)'],['gongyoo.jpeg','version 1 (🔺 stylization, 🔻 robustness)']]\n\ndemo = gr.Interface(\n    fn=inference,\n    inputs=[gr.Image(type=\"pil\"),gr.Radio(['version 1 (🔺 stylization, 🔻 robustness)','version 2 (🔺 robustness,🔻 stylization)'], type=\"value\", value='version 2 (🔺 robustness,🔻 stylization)', label='version')],\n    outputs=gr.Image(type=\"pil\"),\n    title=title,\n    description=description,\n    article=article,\n    examples=examples)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Updating View API Container Z-Index\nDESCRIPTION: CSS update to adjust the z-index of the View API container for proper layering\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\n1c99570f3cbf28f020d6e92527754dd4cae3bcdb\n```\n\n----------------------------------------\n\nTITLE: Importing BaseUploadButton with Svelte Syntax in HTML\nDESCRIPTION: Demonstrates how to import the BaseUploadButton component from the @gradio/uploadbutton package using Svelte/HTML syntax. This snippet is intended for use within a Svelte component file and requires the @gradio/uploadbutton package installed as a dependency. The entry point sets up the file upload button for further configuration and rendering within the UI; no parameters or props are set in this import.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n    import { BaseUploadButton } from \"@gradio/uploadbutton\";\\n<\\/script>\n```\n\n----------------------------------------\n\nTITLE: Fixing Custom JS Function Caller\nDESCRIPTION: Fix to concatenate dependency outputs with inputs as arguments in custom JS function calls\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: JavaScript\nCODE:\n```\nd665f409704b4938d57bee6476a2d000617643c8\n```\n\n----------------------------------------\n\nTITLE: Importing BaseGallery Component with Svelte Syntax (HTML)\nDESCRIPTION: This snippet imports the BaseGallery component from the @gradio/gallery package using Svelte-style script tags. It prepares the component for use in a Svelte-based application and requires the @gradio/gallery dependency to be installed in the project. No configurable parameters are shown in this snippet; it focuses solely on the import process.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/gallery/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n\\timport { BaseGallery } from \"@gradio/gallery\";\\n<\\/script>\n```\n\n----------------------------------------\n\nTITLE: Using a Theme from Hub with Version Constraints in Gradio\nDESCRIPTION: This example shows how to use a theme directly from the Hugging Face Hub with semantic versioning constraints to ensure compatibility with specific theme versions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=\"gradio/seafoam@>=0.0.1,<0.1.0\") as demo:\n    ....\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Speaker Verification Demo\nDESCRIPTION: Installs the required Python packages for the speaker verification demo including Gradio, Transformers library, and torchaudio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/same-person-or-different/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio git+https://github.com/huggingface/transformers torchaudio \n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Video File via Wget (Shell)\nDESCRIPTION: Downloads a sample MP4 video file from a GitHub repository using the 'wget' command. The '-q' flag enables quiet mode, and '-O' specifies the output path and filename within the previously created 'video' directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_video_out/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\n!wget -q -O video/compliment_bot_screen_recording_3x.mp4 https://github.com/gradio-app/gradio/raw/main/demo/stream_video_out/video/compliment_bot_screen_recording_3x.mp4\n```\n\n----------------------------------------\n\nTITLE: Streaming from Gradio App in TypeScript\nDESCRIPTION: Example showing how to stream results from a Gradio app using the TypeScript client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"gradio/llm_stream\")\nconst job = client.submit(\"/predict\", {\"text\": \"What's the best UI framework in Python?\"})\n\nfor await (const msg of job) console.log(msg.data)\n```\n\n----------------------------------------\n\nTITLE: Fixing LaTeX Rendering in Markdown\nDESCRIPTION: Bug fix to improve LaTeX rendering within Markdown content. This ensures mathematical expressions are correctly displayed in Gradio components using Markdown.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10765](https://github.com/gradio-app/gradio/pull/10765) [`3232cdd`](https://github.com/gradio-app/gradio/commit/3232cddc00be4a8ac441177e4fe408fb193fdb0f) - fix: latex rendering of markdown.\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependencies\nDESCRIPTION: Installs the required Python packages (gradio and numpy) using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_selections/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: A simple requirements list specifying matplotlib for data visualization and numpy for numerical computing. These are common dependencies for Python projects involving data analysis, scientific computing, or machine learning.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_component/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nmatplotlib\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Feature Addition Entry\nDESCRIPTION: Describes a feature addition for UploadButton icon support\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#6584](https://github.com/gradio-app/gradio/pull/6584) [`9bcb1da`](https://github.com/gradio-app/gradio/commit/9bcb1da189a9738d023ef6daad8c6c827e3f6371) - Feat: make UploadButton accept icon. Thanks [@Justin-Xiang](https://github.com/Justin-Xiang)!\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Demo in Python\nDESCRIPTION: Installs required Python packages (Gradio, NumPy, Pillow) using pip. This prepares the environment for running the Gradio app and supporting image processing operations. No parameters or outputs; must be run in a shell or notebook cell with network access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_cleanup/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy Pillow \n```\n\n----------------------------------------\n\nTITLE: Running Dillinger Docker Container (Bash)\nDESCRIPTION: This Bash command runs the previously built Dillinger Docker image as a detached container (`-d`), maps host port 8000 to container port 8080 (`-p`), sets it to always restart (`--restart=always`), adds a necessary capability for PDF rendering (`--cap-add=SYS_ADMIN`), names the container 'dillinger', and specifies the image name. This is from the Docker setup instructions in the Markdown.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_10\n\nLANGUAGE: bash\nCODE:\n```\ndocker run -d -p 8000:8080 --restart=always --cap-add=SYS_ADMIN --name=dillinger <youruser>/dillinger:${package.json.version}\n```\n\n----------------------------------------\n\nTITLE: Enabling Server-Side Rendering\nDESCRIPTION: Controls whether server-side rendering is enabled.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_15\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_SSR_MODE=\"True\"\n```\n\n----------------------------------------\n\nTITLE: ML Dependencies List\nDESCRIPTION: Lists required Python machine learning libraries: PyTorch, Transformers, and Diffusers. These are common dependencies for AI/ML applications using Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plain\nCODE:\n```\ntorch\ntransformers\ndiffusers\n```\n\n----------------------------------------\n\nTITLE: Downloading Dependency File using wget in Python\nDESCRIPTION: This snippet executes a shell command using `wget` to download a `packages.txt` file from the Gradio GitHub repository. The `-q` flag suppresses `wget`'s output. This file likely contains necessary configurations or package information for the demo, although its specific use isn't shown in the subsequent code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/neon-tts-plugin-coqui/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/neon-tts-plugin-coqui/packages.txt\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (Gradio and OpenCV) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gif_maker/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio opencv-python\n```\n\n----------------------------------------\n\nTITLE: Initializing Dependencies for Gradio Testing\nDESCRIPTION: Imports required libraries for HTTP requests, WebSocket connections, and JSON handling. Installs websocket-client package.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport time\nimport uuid\nimport requests\nimport json\n!pip install -q websocket-client\nimport websocket\n```\n\n----------------------------------------\n\nTITLE: Setting Temporary Directory\nDESCRIPTION: Specifies custom directory for storing temporary files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_6\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_TEMP_DIR=\"/path/to/temp\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Package Name in pyproject.toml\nDESCRIPTION: Example showing how to modify the package name in pyproject.toml configuration file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n[project]\nname = \"supertextbox\"\n```\n\n----------------------------------------\n\nTITLE: Importing ColorPicker Components\nDESCRIPTION: Import statement for Gradio's ColorPicker components, showing how to import BaseColorPicker and BaseExample from the @gradio/colorpicker package.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/colorpicker/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseColorPicker, BaseExample } from \"@gradio/colorpicker\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Setting Up Gradio Chatbot Demo\nDESCRIPTION: This snippet imports the required libraries (gradio, os, plotly, random) and includes a comment describing the chatbot demo's features. It sets up the foundation for implementing the multimodal input chatbot using Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n# type: ignore\nimport gradio as gr\nimport os\nimport plotly.express as px\nimport random\n\n# Chatbot demo with multimodal input (text, markdown, LaTeX, code blocks, image, audio, & video). Plus shows support for streaming text.\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library quietly using pip, which is required to run the demo application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/browserstate/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_subtitle/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy Dependencies\nDESCRIPTION: Installs the required packages (Gradio and NumPy) using pip in a quiet mode. These libraries are necessary for creating the interactive UI and performing numerical operations on images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flag/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Button Icon Centering Fix\nDESCRIPTION: Pull request that fixed the icon centering issue in buttons when no text is present.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n- [#9405](https://github.com/gradio-app/gradio/pull/9405) [`bf27ff4`](https://github.com/gradio-app/gradio/commit/bf27ff4ac8ada33ea03dd26d5c1c1115aa1f318a) - Center icon in button when no text is present.\n```\n\n----------------------------------------\n\nTITLE: Building a Svelte Project for Production\nDESCRIPTION: Command to create a production version of a Svelte application. After building, the production version can be previewed using npm run preview.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio-Lite JavaScript and CSS in HTML\nDESCRIPTION: This snippet shows how to import the necessary JavaScript and CSS files for @gradio/lite in an HTML file. It uses CDN links to load the required resources.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/lite/README.md#2025-04-23_snippet_0\n\nLANGUAGE: HTML\nCODE:\n```\n<html>\n\t<head>\n\t\t<script type=\"module\" crossorigin src=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.js\"></script>\n\t\t<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/@gradio/lite/dist/lite.css\" />\n\t</head>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio Component Interactivity in Python\nDESCRIPTION: Shows how to explicitly set the interactivity of a Gradio component (Textbox) using the `interactive=True` argument during its instantiation in Python. This overrides the default behavior where components acting only as outputs are typically rendered non-interactive.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\noutput = gr.Textbox(label=\"Output\", interactive=True)\n```\n\n----------------------------------------\n\nTITLE: Setting Max File Size Limit in Gradio (Python)\nDESCRIPTION: This Python code demonstrates how to set a maximum file size limit for uploads within a Gradio application using the `launch()` method. The `max_file_size` parameter accepts either a string representation (e.g., \"5mb\") or an integer value derived from `gr.FileSize` constants (e.g., `5 * gr.FileSize.MB`). This feature was introduced in version 0.6.0.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Video Subtitle Demo\nDESCRIPTION: Creates a 'files' directory and downloads sample video and subtitle files from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_subtitle/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/a.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_subtitle/files/a.mp4\n!wget -q -O files/b.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_subtitle/files/b.mp4\n!wget -q -O files/s1.srt https://github.com/gradio-app/gradio/raw/main/demo/video_subtitle/files/s1.srt\n!wget -q -O files/s2.vtt https://github.com/gradio-app/gradio/raw/main/demo/video_subtitle/files/s2.vtt\n```\n\n----------------------------------------\n\nTITLE: Web Component Render Event Handler\nDESCRIPTION: JavaScript code showing how to handle the render event from an embedded Gradio web component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_3\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\tfunction handleLoadComplete() {\n\t\tconsole.log(\"Embedded space has finished rendering\");\n\t}\n\n\tconst gradioApp = document.querySelector(\"gradio-app\");\n\tgradioApp.addEventListener(\"render\", handleLoadComplete);\n</script>\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files in Python\nDESCRIPTION: This code downloads necessary files (avatar image and audio) for the chatbot demo from the Gradio GitHub repository. It creates a 'files' directory and uses wget to fetch the resources.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_examples/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/avatar.png https://github.com/gradio-app/gradio/raw/main/demo/chatbot_examples/files/avatar.png\n!wget -q -O files/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/chatbot_examples/files/cantina.wav\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode. It's a prerequisite for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/concurrency_with_queue/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Translation Interface with Transformers\nDESCRIPTION: This code snippet sets up a Gradio interface for text translation. It uses the Transformers library to load a pre-trained translation model and tokenizer. The interface allows users to input text, select source and target languages, and outputs the translated text.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/translation/DESCRIPTION.md#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport gradio as gr\nfrom transformers import pipeline\n\ntranslator = pipeline(\"translation\", model=\"t5-small\")\n\ndef translate(text, source_lang, target_lang):\n    return translator(text, src_lang=source_lang, tgt_lang=target_lang)[0]['translation_text']\n\ndemo = gr.Interface(\n    fn=translate,\n    inputs=[\n        gr.Textbox(label=\"Text to translate\"),\n        gr.Dropdown([\"en\", \"fr\", \"de\", \"es\"], label=\"Source language\"),\n        gr.Dropdown([\"en\", \"fr\", \"de\", \"es\"], label=\"Target language\")\n    ],\n    outputs=\"text\",\n    title=\"Translation\",\n    description=\"Enter text, choose source and target languages, and click submit to translate.\",\n    examples=[[\"Hello, how are you?\", \"en\", \"fr\"]]\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Kinematics Demo\nDESCRIPTION: Installs the necessary Python packages: Gradio for the web interface, NumPy for calculations, and Pandas for data manipulation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_kinematics/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy pandas \n```\n\n----------------------------------------\n\nTITLE: Documenting Version 0.1.0-beta.3 Features (Markdown)\nDESCRIPTION: Details the features added in version 0.1.0-beta.3, including swapping 'mode' to 'interactive' on the frontend to match the backend.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/simpledropdown/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.0-beta.3\n\n### Features\n\n- [#6149](https://github.com/gradio-app/gradio/pull/6149) [`90318b1dd`](https://github.com/gradio-app/gradio/commit/90318b1dd118ae08a695a50e7c556226234ab6dc) - swap `mode` on the frontned to `interactive` to match the backend. Thanks [@pngwn](https://github.com/pngwn)!\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Wav2Vec Demo (Bash)\nDESCRIPTION: This command installs the required Python packages (`gradio`, `torch`, `transformers`) using pip. The `-q` flag ensures a quiet installation with minimal output. These packages are prerequisites for running the subsequent Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_wav2vec/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio torch transformers \n```\n\n----------------------------------------\n\nTITLE: Defining and Rendering Components Separately in Gradio Blocks (Python)\nDESCRIPTION: Illustrates how to define components outside of the gr.Blocks() scope and render them later using the .render() method. This is useful for scenarios where component definition order matters, such as with gr.Examples.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/02_controlling-layout.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ninput_textbox = gr.Textbox()\n\nwith gr.Blocks() as demo:\n    gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\n    input_textbox.render()\n```\n\n----------------------------------------\n\nTITLE: Inspecting NER Pipeline Output in Bash\nDESCRIPTION: This Bash-formatted snippet shows the typical output structure from the Hugging Face NER pipeline, presented as a list of dictionaries. Each dictionary contains keys for 'entity', 'score', 'index', 'word', 'start', and 'end', providing span information and entity type for each recognized token. This output illustrates the data passed to visualization components or further processing scripts.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/named-entity-recognition.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n[{'entity': 'I-LOC',\\n  'score': 0.9988978,\\n  'index': 2,\\n  'word': 'Chicago',\\n  'start': 5,\\n  'end': 12},\\n {'entity': 'I-MISC',\\n  'score': 0.9958592,\\n  'index': 5,\\n  'word': 'Pakistani',\\n  'start': 22,\\n  'end': 31}]\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Installing required Python packages Gradio and Weights & Biases using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install gradio wandb\n```\n\n----------------------------------------\n\nTITLE: Fixing Dev Mode in Gradio Custom Components\nDESCRIPTION: This code snippet fixes the dev mode for Gradio custom components. It likely includes changes to improve the development experience when working on custom components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\n// Code not provided in the changelog\n```\n\n----------------------------------------\n\nTITLE: Downloading ImageNet Label Files - Python\nDESCRIPTION: This snippet creates a new directory named 'files' and downloads the ImageNet label file (in JSON format) from the Gradio demo repository using wget. It uses the os module to manage the local directory and obtains the label file required for predictions. There are no input parameters. Limitations: assumes that 'files' does not yet exist and that wget is available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/imagenet_labels.json https://github.com/gradio-app/gradio/raw/main/demo/image_classifier_2/files/imagenet_labels.json\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Lists required Python packages plotly (for interactive plotting) and pandas (for data manipulation) as project dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nplotly\npandas\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio App Setup in Python\nDESCRIPTION: Example of creating a minimal Gradio application with a button component using Blocks interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n   gr.Button()\n    \nif __name__ == \"__main__\":\n   demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Downloading CSV Data using Wget in Python\nDESCRIPTION: This snippet first imports the `os` module (though it's not strictly used here) and then uses the `wget` command, executed via the `!` operator in a Python environment, to silently download a CSV file (`polars_sort.csv`) from a specified GitHub URL. This CSV file contains the data that will be used as input for the Gradio sorting demo. The `wget` command must be available in the execution environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sort_records/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/sort_records/polars_sort.csv\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File using wget\nDESCRIPTION: Downloads the required data file from the Gradio GitHub repository. The file contains the dataset needed for the plotting demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom_sync/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_zoom_sync/data.py\n```\n\n----------------------------------------\n\nTITLE: Importing BaseLabel Component in Svelte\nDESCRIPTION: This snippet shows how to import the BaseLabel component from the @gradio/label package in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/label/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { BaseLabel } from \"@gradio/label\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Flask Integration Example\nDESCRIPTION: Example showing how to integrate the Gradio client with a Flask server using gevent\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom gevent import monkey\nmonkey.patch_all()\n\nfrom gradio_client import Client\nfrom flask import Flask, send_file\nimport time\n\napp = Flask(__name__)\n\nimageclient = Client(\"gradio/diffusion_model\")\n\n@app.route(\"/gen\")\ndef gen():\n      result = imageclient.predict(\n                \"A cute cat\",\n                api_name=\"/predict\"\n              )\n      return send_file(result)\n\nif __name__ == \"__main__\":\n      app.run(host=\"0.0.0.0\", port=5000)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library quietly using pip. It's a prerequisite for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_textbox_max_lines/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/latex/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Creating a Line Plot with Pandas DataFrame in Python\nDESCRIPTION: This snippet demonstrates how to create a simple `gr.LinePlot` using a pandas DataFrame as input. It specifies the columns for the x and y axes using the `x` and `y` arguments. Requires pandas and gradio libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_line\n```\n\n----------------------------------------\n\nTITLE: Verifying Gradio Installation and Version in Python (MacOS/Linux)\nDESCRIPTION: This Python code snippet, intended to be run in a Python interpreter session within the activated virtual environment on MacOS/Linux, imports the installed Gradio library as `gr` and prints its version (`__version__`) to confirm successful installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nprint(gr.__version__)\n```\n\n----------------------------------------\n\nTITLE: Building and Running the Gradio Docker Container via Bash\nDESCRIPTION: This Bash snippet shows the commands to build a Docker image named 'gradio-app' from the Dockerfile and run it with port 7860 exposed for external connections. It assumes Docker is installed and configured. The 'docker build' command packages everything into an image, and 'docker run' starts a detached container, mapping the container's port 7860 to the host's port 7860 for browser access. Prerequisites include a functional Docker environment and both the Dockerfile and app.py present in the current directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/deploying-gradio-with-docker.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ndocker build -t gradio-app .\\ndocker run -p 7860:7860 gradio-app\n```\n\n----------------------------------------\n\nTITLE: Gradio with Command Line Arguments\nDESCRIPTION: Gradio application that accepts command line arguments using argparse, demonstrating how to pass arguments to the application when using reload mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--name\", type=str, default=\"User\")\nargs, unknown = parser.parse_known_args()\n\nwith gr.Blocks() as demo:\n    gr.Markdown(f\"# 欢迎 {args.name}！\")\n    inp = gr.Textbox()\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: x, inputs=inp, outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Creating New Gradio Component\nDESCRIPTION: Command to create a new custom Gradio component using a template. Creates a directory structure with backend, frontend, and demo folders.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/01_custom-components-in-five-minutes.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc create MyComponent --template SimpleTextbox\n```\n\n----------------------------------------\n\nTITLE: Setting Custom Favicon for Gradio PWA\nDESCRIPTION: Example showing how to set a custom favicon for a Gradio Progressive Web App by specifying the favicon_path parameter in the launch method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/07_sharing-your-app.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\ndemo.launch(pwa=True, favicon_path=\"./hf-logo.svg\")  # Use a custom icon for your PWA\n```\n\n----------------------------------------\n\nTITLE: Initializing Deployment Previews Description\nDESCRIPTION: Documents the three main preview environments (storybook, website, spaces) deployed for pull requests, including the custom wheel building process and cleanup procedures.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_3\n\nLANGUAGE: text\nCODE:\n```\n- storybook: frontend component previews\\n- website: documentation and guide changes\\n- spaces: live Gradio app previews on Hugging Face Spaces\n```\n\n----------------------------------------\n\nTITLE: Gradio Web Component Integration\nDESCRIPTION: HTML code for embedding Gradio demos on websites using web components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<gradio-app space=\"akhaliq/JoJoGAN\"> </gradio-app>\n```\n\n----------------------------------------\n\nTITLE: Setting Upload File Size Limit in Gradio - Python\nDESCRIPTION: This Python code snippet shows how to set the maximum file upload size in a Gradio app by providing the 'max_file_size' parameter to the launch() method of a Gradio Interface. It demonstrates two approaches: using a human-readable string (e.g., '5mb') and using the predefined gr.FileSize.MB constant for explicit byte calculation. Dependencies: gradio must be installed (typically via pip). The snippet creates a simple image-to-image demo that echoes the input, and applies the upload limit to all input files. Inputs are images; outputs are also images. Note: This limit applies separately to each uploaded file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/image/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\\n\\ndemo.launch(max_file_size=\"5mb\")\\n# or\\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio File\nDESCRIPTION: Downloads a sample audio file (cantina.wav) from the Gradio GitHub repository to use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_debugger/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/audio_debugger/cantina.wav\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio Files using Wget in Shell and Python\nDESCRIPTION: Creates a directory named 'audio' using Python's `os.mkdir` function and then downloads two sample WAV audio files (`cantina.wav`, `recording1.wav`) from a GitHub repository using the `wget` command. The `-q` flag suppresses output, and `-O` specifies the output filename. These files serve as examples for the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/main_note/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('audio')\n!wget -q -O audio/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/main_note/audio/cantina.wav\n!wget -q -O audio/recording1.wav https://github.com/gradio-app/gradio/raw/main/demo/main_note/audio/recording1.wav\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and spaCy Dependencies using pip\nDESCRIPTION: This command uses pip, the Python package installer, to install the `gradio` library for creating the web UI and the `spacy` library for natural language processing. The `-q` flag ensures a quiet installation, minimizing console output. This step is a prerequisite for running the subsequent Python code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/text_analysis/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio spacy\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Audio Files\nDESCRIPTION: Downloads various audio files required for the demo from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_neural_instrument_coding/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/flute.wav\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/new-sax-1.mp3\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/new-sax-1.wav\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/new-sax.wav\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/sax.wav\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/sax2.wav\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_neural_instrument_coding/trombone.wav\n```\n\n----------------------------------------\n\nTITLE: Listing AI/ML Dependencies in Python\nDESCRIPTION: This snippet lists two essential Python libraries for AI and machine learning: PyTorch and Transformers. PyTorch is a popular deep learning framework, while Transformers is a library for natural language processing tasks, often used with pre-trained models.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unified_demo_text_generation/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch\ntransformers\n```\n\n----------------------------------------\n\nTITLE: Importing and Configuring Transformers.js in Python\nDESCRIPTION: This snippet imports the necessary modules and sets up the configuration for using Transformers.js in a Python environment. It includes setting the cache directory and importing the pipeline function.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/lite/examples/transformers_basic/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport os\nfrom huggingface_hub import snapshot_download\nfrom transformers_js import import_transformers_js, pipeline\n\nos.environ[\"TRANSFORMERS_CACHE\"] = \"/tmp/transformers\"\nimport_transformers_js()\n\nmodel_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\nsnapshot_download(model_id, local_dir=\"/tmp/transformers\")\n```\n\n----------------------------------------\n\nTITLE: Building a Svelte app for production\nDESCRIPTION: Command to create a production-ready build of a Svelte application. The build can be previewed using npm run preview.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/component-test/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates the dependencies for the Gradio File component, including @gradio/icons, @gradio/atoms, @gradio/statustracker, and @gradio/upload.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [[`8f0fed857`](https://github.com/gradio-app/gradio/commit/8f0fed857d156830626eb48b469d54d211a582d2)]:\n  - @gradio/icons@0.2.0\n  - @gradio/atoms@0.1.3\n  - @gradio/statustracker@0.2.1\n  - @gradio/upload@0.3.1\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio and OpenAI in Bash\nDESCRIPTION: This command uses pip, the Python package installer, to install the necessary libraries: `gradio` for building the web interface and `openai` (version 1.0.0 or higher) to interact with the SambaNova API, which provides an OpenAI-compatible interface. The `-q` flag ensures a quiet installation, minimizing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_sambanova/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio openai>=1.0.0 \n```\n\n----------------------------------------\n\nTITLE: Adding Python Dependencies\nDESCRIPTION: Configuration for adding Python package dependencies in pyproject.toml.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ndependencies = [\"gradio\", \"numpy\", \"PIL\"]\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Bokeh Plots in Gradio\nDESCRIPTION: Installs the necessary Python packages including Gradio, Bokeh (version 3.0 or higher), and xyzservices for map data providers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bokeh_plot/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio bokeh>=3.0 xyzservices\n```\n\n----------------------------------------\n\nTITLE: Documenting Version 0.1.0-beta.2 Features (Markdown)\nDESCRIPTION: Records the features added in version 0.1.0-beta.2, specifically the implementation of a simple dropdown component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/simpledropdown/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.0-beta.2\n\n### Features\n\n- [#5996](https://github.com/gradio-app/gradio/pull/5996) [`9cf40f76f`](https://github.com/gradio-app/gradio/commit/9cf40f76fed1c0f84b5a5336a9b0100f8a9b4ee3) - V4: Simple dropdown. Thanks [@freddyaboulton](https://github.com/freddyaboulton)!\n```\n\n----------------------------------------\n\nTITLE: Starting Gradio Web App Development Server\nDESCRIPTION: Command to start the development server for the Gradio web application front-end.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Version Bump Types Definition\nDESCRIPTION: Defines the semantic versioning bump types used for package versioning: patch (no API changes), minor (API additions), and major (breaking changes).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- `patch` - No API changes, these are typically bug fixes, refactors, and docstring changes.\n- `minor` - API additions, everything works as it did before but new API may have been added.\n- `major` - breaking changes.\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio and Transformers in Python\nDESCRIPTION: This snippet installs the required Python packages: gradio, transformers (from GitHub), and torch. The installation is performed using pip and is necessary before running the demo. Users should ensure that they have internet access and sufficient permissions to install Python packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/text_generation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio git+https://github.com/huggingface/transformers gradio torch\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image for Demo\nDESCRIPTION: Creates an 'images' directory and downloads a sample cheetah image from the Gradio GitHub repository for use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rows_and_columns/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('images')\n!wget -q -O images/cheetah.jpg https://github.com/gradio-app/gradio/raw/main/demo/rows_and_columns/images/cheetah.jpg\n```\n\n----------------------------------------\n\nTITLE: Importing BaseCheckbox Component in Svelte\nDESCRIPTION: This snippet demonstrates how to import the BaseCheckbox component from the @gradio/checkbox package in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/checkbox/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseCheckbox } from \"@gradio/checkbox\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip in Python\nDESCRIPTION: This command uses pip, the Python package installer, to silently install the Gradio library. The '-q' flag suppresses output during installation. This is a necessary prerequisite for using Gradio components in the subsequent code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/multimodaltextbox_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_neural_instrument_coding/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip package manager in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_consecutive/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio PDF Interface\nDESCRIPTION: Creates a Gradio interface that handles PDF files using the PDF component. Sets up a simple pass-through function with example PDF file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gradio_pdf_demo/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio_pdf import PDF\nfrom pathlib import Path\n\ncurrent_dir = Path(__file__).parent\n\ndemo = gr.Interface(lambda x: x,\n                    PDF(),\n                    gr.File(),\n                    examples=[[str(current_dir / \"contract.pdf\")]])\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (Gradio and Vega datasets) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/lineplot_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio vega_datasets\n```\n\n----------------------------------------\n\nTITLE: Adding Copy Event to Markdown Components\nDESCRIPTION: Adds a copy event to gr.Markdown, gr.Chatbot, and gr.Textbox components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- [#9979](https://github.com/gradio-app/gradio/pull/9979) [`e7629f7`](https://github.com/gradio-app/gradio/commit/e7629f7eacdc2a8960fae7472669b60405a4a06c) - Adds copy event to `gr.Markdown`, `gr.Chatbot`, and `gr.Textbox`.\n```\n\n----------------------------------------\n\nTITLE: Block Component Props Definition\nDESCRIPTION: Defines the available props for the Block component, which serves as a container element with configurable styling options like borders, padding, visibility, and dimensions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let height: number | undefined = undefined;\n\texport let width: number | undefined = undefined;\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let variant: \"solid\" | \"dashed\" | \"none\" = \"solid\";\n\texport let border_mode: \"base\" | \"focus\" = \"base\";\n\texport let padding = true;\n\texport let type: \"normal\" | \"fieldset\" = \"normal\";\n\texport let test_id: string | undefined = undefined;\n\texport let explicit_call = false;\n\texport let container = true;\n\texport let visible = true;\n\texport let allow_overflow = true;\n\texport let scale: number | null = null;\n\texport let min_width = 0;\n```\n\n----------------------------------------\n\nTITLE: Fixing Component Exports and Type Generation\nDESCRIPTION: Bug fix addressing export issues and improvements to type generation in beta version 0.7.2-beta.0, as documented in pull request #9163.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n### Fixes\n\n- [#9163](https://github.com/gradio-app/gradio/pull/9163) [`2b6cbf2`](https://github.com/gradio-app/gradio/commit/2b6cbf25908e42cf027324e54ef2cc0baad11a91) - fix exports and generate types.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Building Python Packages for Gradio-Lite\nDESCRIPTION: Command to rebuild Python packages for Gradio-Lite after code changes\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npnpm --filter @gradio/lite pybuild\n```\n\n----------------------------------------\n\nTITLE: Creating and Launching a Gradio Interface with MultimodalTextbox in Python\nDESCRIPTION: This Python code snippet demonstrates the basic usage of Gradio's MultimodalTextbox. It first imports the Gradio library as 'gr'. Then, it creates a Gradio Blocks interface context ('with gr.Blocks() as demo:'). Inside this context, an interactive MultimodalTextbox is instantiated. Finally, 'demo.launch()' starts the Gradio web server, making the interface accessible in a browser.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/multimodaltextbox_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.MultimodalTextbox(interactive=True)\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Checking ffmpeg Installation\nDESCRIPTION: Command to verify if ffmpeg is installed on the system, which is required for video and audio processing in the application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ffmpeg version\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Images\nDESCRIPTION: Creates an images directory and downloads sample images from the Gradio GitHub repository for use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/examples_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('images')\n!wget -q -O images/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/examples_component/images/cheetah1.jpg\n!wget -q -O images/lion.jpg https://github.com/gradio-app/gradio/raw/main/demo/examples_component/images/lion.jpg\n!wget -q -O images/lion.webp https://github.com/gradio-app/gradio/raw/main/demo/examples_component/images/lion.webp\n!wget -q -O images/logo.png https://github.com/gradio-app/gradio/raw/main/demo/examples_component/images/logo.png\n```\n\n----------------------------------------\n\nTITLE: Defining Component Props Types\nDESCRIPTION: TypeScript type definitions for the required props that Gradio components must expose.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nimport type { LoadingStatus } from \"@gradio/statustracker\";\nimport type { Gradio } from \"@gradio/utils\";\n\nexport let gradio: Gradio<{\n    event_1: never;\n    event_2: never;\n}>;\n\nexport let elem_id = \"\";\nexport let elem_classes: string[] = [];\nexport let scale: number | null = null;\nexport let min_width: number | undefined = undefined;\nexport let loading_status: LoadingStatus | undefined = undefined;\nexport let mode: \"static\" | \"interactive\";\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Video Watermarking Demo\nDESCRIPTION: This code block creates a 'files' directory and downloads sample video and watermark image files from the Gradio GitHub repository. These files are used as examples in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_watermark/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/a.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_watermark/files/a.mp4\n!wget -q -O files/b.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_watermark/files/b.mp4\n!wget -q -O files/w1.jpg https://github.com/gradio-app/gradio/raw/main/demo/video_watermark/files/w1.jpg\n!wget -q -O files/w2.png https://github.com/gradio-app/gradio/raw/main/demo/video_watermark/files/w2.png\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio\nDESCRIPTION: This snippet lists the core Python package dependencies required for the Gradio application. It includes numpy for numerical computations, requests for making HTTP requests, and Pillow for image processing capabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion_with_gif/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\nrequests\nPillow\n```\n\n----------------------------------------\n\nTITLE: Reload Mode Console Output Example\nDESCRIPTION: Example of the console output when running a Gradio application in reload mode, showing the application is watching for file changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nLaunching in *reload mode* on: http://127.0.0.1:7860 (Press CTRL+C to quit)\n\nWatching...\n\nWARNING:  The --reload flag should not be used in production on Windows.\n```\n\n----------------------------------------\n\nTITLE: Exporting Properties for BaseMultiselect with Gradio in JavaScript\nDESCRIPTION: This JavaScript snippet details the exported properties for the BaseMultiselect component, supporting multiple selections in a dropdown. It includes props for label, info, value (supporting arrays), output indicators, maximum number of allowed choices, the choices themselves as labeled pairs, disabled state, label display, container wrapping, custom value allowance, filterability, and internationalization via an i18n formatter. The component expects arrays or primitive values as inputs and emits selected options as outputs, requiring an i18n formatter if localization is needed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dropdown/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let label: string;\\nexport let info: string | undefined = undefined;\\nexport let value: string | number | (string | number)[] | undefined = [];\\nexport let value_is_output = false;\\nexport let max_choices: number | null = null;\\nexport let choices: [string, string | number][];\\nexport let disabled = false;\\nexport let show_label: boolean;\\nexport let container = true;\\nexport let allow_custom_value = false;\\nexport let filterable = true;\\nexport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Refactoring Full Screen Logic in Annotated Image Component\nDESCRIPTION: Implementation of reusable full screen logic in the Annotated Image component from version 0.9.0, referenced in pull request #10098.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#10098](https://github.com/gradio-app/gradio/pull/10098) [`9a6ce6f`](https://github.com/gradio-app/gradio/commit/9a6ce6f6b089d94c06da0b8620f28967f39f8383) - Refactor full screen logic to be reusable.  Thanks @hannahblair!\n```\n\n----------------------------------------\n\nTITLE: Specifying PDF-related Dependencies for Gradio\nDESCRIPTION: This snippet defines the minimum version requirements for two Python packages: gradio_pdf and pymupdf. These dependencies are crucial for PDF processing and rendering functionality in the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlight_pdf/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\ngradio_pdf>=0.0.22\npymupdf>=1.25.3\n```\n\n----------------------------------------\n\nTITLE: Repository Clone Command\nDESCRIPTION: Example command to clone a custom component repository (PDF component)\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/06_frequently-asked-questions.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngit clone https://huggingface.co/spaces/freddyaboulton/gradio_pdf\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Sine Curve Demo (Shell)\nDESCRIPTION: This shell command uses pip, the Python package installer, to quietly (-q) install the necessary libraries: Gradio for the web interface, NumPy for numerical operations (generating the sine curve data), and Plotly for creating the interactive plot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sine_curve/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio numpy plotly \n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Slider Component Demo in Python\nDESCRIPTION: This snippet creates and launches a basic Gradio app using the Blocks API, featuring a single slider UI component. 'gradio' must be installed beforehand. The code constructs a UI block with 'gr.Blocks()', inserts 'gr.Slider()' to allow user input, and starts the local server with 'demo.launch()'. Input is through the slider widget, and a simple interactive web interface is generated. No advanced configuration or data handling is shown; this is for basic demonstration purposes only.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/slider_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Slider()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Downloading Data File for Flight Analysis\nDESCRIPTION: Downloads the data.py file from the Gradio GitHub repository, which contains flight data for the demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_filters_events/data.py\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies\nDESCRIPTION: This snippet lists Python package dependencies required for a project, likely intended for use with package managers like pip. It includes Pillow for image manipulation, PyTorch and Torchvision for deep learning tasks, and Requests for making HTTP requests. Each line specifies a package to be installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_2/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npillow\ntorch\ntorchvision\nrequests\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Text Generation Demo\nDESCRIPTION: This snippet installs the necessary Python libraries (Gradio, PyTorch, and Transformers) using pip. These libraries are required for creating the text generation demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unified_demo_text_generation/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch transformers\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample PDF File\nDESCRIPTION: Downloads a sample contract PDF file from the Gradio GitHub repository for demonstration purposes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gradio_pdf_demo/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/gradio_pdf_demo/contract.pdf\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for AnimeGANv2 Demo\nDESCRIPTION: Installs required Python packages including Gradio, PyTorch, and other dependencies needed for the anime transformation demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/animeganv2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch torchvision Pillow gdown numpy scipy cmake onnxruntime-gpu opencv-python-headless\n```\n\n----------------------------------------\n\nTITLE: Adding Column Widths to Dataframe\nDESCRIPTION: Code snippet demonstrating how to add column widths to a Gradio Dataframe component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ngr.Dataframe(column_widths=[100, 200, 300])\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: This command uses pip, the Python package installer, to install the Gradio library. The `-q` flag ensures the installation runs quietly, minimizing output. This is a prerequisite for running the subsequent Gradio application code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files for Gradio Plots using wget\nDESCRIPTION: This snippet executes several `wget` shell commands within the Python environment to download required Python source files from the Gradio GitHub repository. These files (`bar_plot_demo.py`, `data.py`, `line_plot_demo.py`, `scatter_plot_demo.py`) contain the implementation details for generating the plots used in the Gradio demo. The `-q` flag suppresses the standard output from `wget`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/native_plots/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/native_plots/bar_plot_demo.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/native_plots/data.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/native_plots/line_plot_demo.py\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/native_plots/scatter_plot_demo.py\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dropdown_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Implementing Browser State for User Credentials in Gradio\nDESCRIPTION: This example demonstrates how to use browser state in a Gradio application to persist user credentials across sessions. It uses gr.BrowserState to store username and password in the browser's localStorage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/03_state-in-blocks.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndef save_credentials(username, password):\n    return f\"Credentials saved: {username}\"\n\nwith gr.Blocks() as demo:\n    username = gr.BrowserState(value=\"\", key=\"username\")\n    password = gr.BrowserState(value=\"\", key=\"password\")\n    \n    username_input = gr.Textbox(label=\"Username\")\n    password_input = gr.Textbox(label=\"Password\", type=\"password\")\n    save_button = gr.Button(\"Save Credentials\")\n    output = gr.Textbox(label=\"Status\")\n    \n    save_button.click(\n        save_credentials,\n        inputs=[username_input, password_input],\n        outputs=[output, username, password]\n    )\n    \n    # Load saved credentials when the page loads\n    demo.load(lambda u, p: (u, p), inputs=[username, password], outputs=[username_input, password_input])\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/custom_css/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Simulating Nested Layout Rendering Manually Python\nDESCRIPTION: Demonstrates how the custom rendering approach handles nested layouts. Child components (`first_textbox`, `second_textbox`) are rendered within the inner layout's context (`row_main_layout`). Then, the inner layout (`row_main_layout`) is rendered within the outer layout's context (`tab_main_layout`). Finally, the outer layout (`tab_main_layout`) is rendered. This explains the necessity of `self.main_layout.render()` in the `LayoutBase.render` method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith tab_main_layout:\n    with row_main_layout:\n        first_textbox.render()\n        second_textbox.render()\n\n    row_main_layout.render()\n\ntab_main_layout.render()\n```\n\n----------------------------------------\n\nTITLE: Basic Interface with Custom Components\nDESCRIPTION: Demonstrates creating a Gradio interface with customized Textbox and Slider components. The slider ranges from 1-10 with a default of 2, and the output textbox is configured with a label and larger size.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/00_the-interface-class.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ngr.Interface(\n    fn=greet,\n    inputs=[\n        gr.Textbox(label=\"Name\"),\n        gr.Slider(minimum=1, maximum=10, value=2, label=\"How many times to greet?\")\n    ],\n    outputs=gr.Textbox(label=\"Output\", lines=3)\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies for Gradio Spectrogram Demo\nDESCRIPTION: This shell command uses pip to install the required Python libraries: Gradio for the web interface, SciPy for signal processing (spectrogram calculation), NumPy for numerical operations, and Matplotlib for plotting. The '-q' flag ensures a quiet installation with less output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/spectogram/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio scipy numpy matplotlib\n```\n\n----------------------------------------\n\nTITLE: Setting Blocked Paths\nDESCRIPTION: Specifies paths that Gradio is not allowed to serve.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_10\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_BLOCKED_PATHS=\"/users/x/gradio_app/admin,/users/x/gradio_app/keys\"\n```\n\n----------------------------------------\n\nTITLE: Custom CSS Media Queries\nDESCRIPTION: Enhanced custom CSS support to allow @media, @keyframes and @import rules\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: css\nCODE:\n```\n46b45683e1ea9eb40013121a8de5bee7aa98bf0b - Allow applying @media, @keyframes and @import in custom CSS\n```\n\n----------------------------------------\n\nTITLE: Running Python Test Server for Gradio\nDESCRIPTION: Commands to navigate to the kitchen_sink demo directory and run the Python test server for local development.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ncd demo/kitchen_sink\npython run.py\n```\n\n----------------------------------------\n\nTITLE: W&B Experiment Tracking Setup\nDESCRIPTION: Configures W&B experiment tracking for StyleGAN model training, including logging of images and loss metrics.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nalpha =  1.0\nalpha = 1-alpha\n\npreserve_color = True\nnum_iter = 100\nlog_interval = 50\n\nsamples = []\ncolumn_names = [\"Reference (y)\", \"Style Code(w)\", \"Real Face Image(x)\"]\n\nwandb.init(project=\"JoJoGAN\")\nconfig = wandb.config\nconfig.num_iter = num_iter\nconfig.preserve_color = preserve_color\nwandb.log(\n{\"Style reference\": [wandb.Image(transforms.ToPILImage()(target_im))]},\nstep=0)\n\n# load discriminator for perceptual loss\ndiscriminator = Discriminator(1024, 2).eval().to(device)\nckpt = torch.load('models/stylegan2-ffhq-config-f.pt', map_location=lambda storage, loc: storage)\ndiscriminator.load_state_dict(ckpt[\"d\"], strict=False)\n\n# reset generator\ndel generator\ngenerator = deepcopy(original_generator)\n\ng_optim = optim.Adam(generator.parameters(), lr=2e-3, betas=(0, 0.99))\n\n# Which layers to swap for generating a family of plausible real images -> fake image\nif preserve_color:\n    id_swap = [9,11,15,16,17]\nelse:\n    id_swap = list(range(7, generator.n_latent))\n\nfor idx in tqdm(range(num_iter)):\n    mean_w = generator.get_latent(torch.randn([latents.size(0), latent_dim]).to(device)).unsqueeze(1).repeat(1, generator.n_latent, 1)\n    in_latent = latents.clone()\n    in_latent[:, id_swap] = alpha*latents[:, id_swap] + (1-alpha)*mean_w[:, id_swap]\n\n    img = generator(in_latent, input_is_latent=True)\n\n    with torch.no_grad():\n        real_feat = discriminator(targets)\n    fake_feat = discriminator(img)\n\n    loss = sum([F.l1_loss(a, b) for a, b in zip(fake_feat, real_feat)])/len(fake_feat)\n\n    wandb.log({\"loss\": loss}, step=idx)\n    if idx % log_interval == 0:\n        generator.eval()\n        my_sample = generator(my_w, input_is_latent=True)\n        generator.train()\n        my_sample = transforms.ToPILImage()(utils.make_grid(my_sample, normalize=True, range=(-1, 1)))\n        wandb.log(\n        {\"Current stylization\": [wandb.Image(my_sample)]},\n        step=idx)\n    table_data = [\n            wandb.Image(transforms.ToPILImage()(target_im)),\n            wandb.Image(img),\n            wandb.Image(my_sample),\n        ]\n    samples.append(table_data)\n\n    g_optim.zero_grad()\n    loss.backward()\n    g_optim.step()\n\nout_table = wandb.Table(data=samples, columns=column_names)\nwandb.log({\"Current Samples\": out_table})\n```\n\n----------------------------------------\n\nTITLE: Formatting Backend Code\nDESCRIPTION: Platform-specific commands for formatting the backend code before submission\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\nbash scripts/format_backend.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\nscripts\\format_backend.bat\n```\n\n----------------------------------------\n\nTITLE: Defining Loader Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the Loader component, which is likely used to display loading indicators in the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nexport let margin = true;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Client from pip\nDESCRIPTION: Shows how to install the gradio_client package using pip. The package works with Python 3.10 or higher.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install gradio_client\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample PDF\nDESCRIPTION: Downloads a sample PDF file from the Gradio demo repository for testing purposes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlight_pdf/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/highlight_pdf/Lorem_ipsum.pdf\n```\n\n----------------------------------------\n\nTITLE: Accessing Google Sheets Shareable Link - HTML\nDESCRIPTION: This snippet provides an example URL for a Google Sheets document as obtained from the 'Get shareable link' feature. The URL will be used and modified in subsequent Python code to access sheet data, either via direct CSV export (for public sheets) or with gspread (for private sheets). No special dependencies are required, but you must replace this with your sheet's actual URL.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\nhttps://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements\nDESCRIPTION: Lists required Python packages with version constraints. Specifies bokeh version 3.0 or higher and xyzservices package.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bokeh_plot/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nbokeh>=3.0\nxyzservices\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Pillow in Python\nDESCRIPTION: This snippet installs the required Python packages \"gradio\" and \"Pillow\" using pip. It is essential to run this command before any subsequent code to ensure all dependencies are available for the Gradio UI and image manipulation. The output is suppressed for cleaner installation, and there are no input parameters or outputs other than updating the Python environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sub_block_render/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio Pillow \n```\n\n----------------------------------------\n\nTITLE: Configuring SharedWorker Fallback\nDESCRIPTION: Checks if SharedWorker is available in the current runtime and falls back to DedicatedWorker if not available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_0\n\n\n\n----------------------------------------\n\nTITLE: Defining OpenAI Package Dependency in Requirements File\nDESCRIPTION: This line specifies a dependency on the `openai` Python library for the project. It ensures that a version of `openai` equal to or greater than 1.0.0 is installed when setting up the project environment using tools like pip (e.g., `pip install -r requirements.txt`). This is crucial for ensuring compatibility with the project's code that utilizes the OpenAI API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_sambanova/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nopenai>=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Jupyter Magic Command for Gradio Blocks\nDESCRIPTION: Example of using the %%blocks magic command in Jupyter notebooks to simplify Gradio development by eliminating the need for boilerplate code like 'with gr.Blocks()' and 'demo.launch()'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n%%blocks\n\nimport gradio as gr\n\ngr.Markdown(\"# 来自Gradio的问候！\")\ninp = gr.Textbox(placeholder=\"您叫什么名字？\")\nout = gr.Textbox()\n\ninp.change(fn=lambda x: f\"欢迎，{x}！\",\n           inputs=inp,\n           outputs=out)\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Stable Diffusion Demo using Pip\nDESCRIPTION: This command uses pip to silently install the required Python packages: `gradio` for the web UI, `diffusers` (version 0.32.2) for the Stable Diffusion pipeline, and `torch` (version 2.5.1). These packages are prerequisites for running the subsequent Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stable-diffusion/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio diffusers==0.32.2 torch==2.5.1  \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip (Python)\nDESCRIPTION: This command uses pip, the Python package installer, to install the Gradio library quietly (`-q`). This step is a prerequisite for running the Gradio application defined in the subsequent snippet.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/load_model_with_token/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Running Karma Tests (Bash)\nDESCRIPTION: This Bash command runs tests using the Karma test runner. This is suggested as an optional step in the development workflow for Dillinger, as described in the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nkarma test\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Video for Demo\nDESCRIPTION: This snippet creates a 'video' directory and downloads a sample video file from the Gradio GitHub repository. It uses wget to fetch the file quietly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_identity/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('video')\n!wget -q -O video/video_sample.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_identity/video/video_sample.mp4\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Demo\nDESCRIPTION: This snippet installs the necessary libraries (Gradio and OpenCV) for running the demo. It uses pip to quietly install the packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/white_noise_vid_not_playable/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio opencv-python\n```\n\n----------------------------------------\n\nTITLE: Defining Toast Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the Toast component, which is likely used for displaying notification messages in the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/statustracker/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let messages: ToastMessage[] = [];\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for XGBoost Income Prediction Demo\nDESCRIPTION: This snippet installs the necessary Python libraries for the income prediction demo, including Gradio, NumPy, Matplotlib, SHAP, XGBoost, Pandas, and Datasets.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/xgboost-income-prediction-with-explainability/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy==1.23.2 matplotlib shap xgboost==1.7.6 pandas datasets\n```\n\n----------------------------------------\n\nTITLE: PDF Upload Component Template\nDESCRIPTION: Svelte template for the PDF upload interface with Block and Upload components\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_3\n\nLANGUAGE: svelte\nCODE:\n```\n<Block {visible} {elem_id} {elem_classes} {container} {scale} {min_width}>\n    {#if loading_status}\n        <StatusTracker\n            autoscroll={gradio.autoscroll}\n            i18n={gradio.i18n}\n            {...loading_status}\n        />\n    {/if}\n    <BlockLabel\n        show_label={label !== null}\n        Icon={File}\n        float={value === null}\n        label={label || \"File\"}\n    />\n    {#if _value}\n        <ModifyUpload i18n={gradio.i18n} absolute />\n    {:else}\n        <Upload\n            filetype={\"application/pdf\"}\n            file_count=\"single\"\n            {root}\n        >\n            Upload your PDF\n        </Upload>\n    {/if}\n</Block>\n```\n\n----------------------------------------\n\nTITLE: Specifying Numpy Dependency for Gradio App\nDESCRIPTION: This snippet specifies 'numpy' as a required package for the Gradio application. It's likely part of a requirements.txt file or similar configuration used for managing Python dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flag/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Audio Files for Gradio Demo\nDESCRIPTION: Creates an audio directory and downloads sample audio files from the Gradio GitHub repository to use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('audio')\n!wget -q -O audio/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/reverse_audio/audio/cantina.wav\n!wget -q -O audio/recording1.wav https://github.com/gradio-app/gradio/raw/main/demo/reverse_audio/audio/recording1.wav\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library using pip. This is a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timer/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio\nDESCRIPTION: This snippet enumerates the Python packages required for the Gradio application. It includes version specifications for some packages to ensure compatibility.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nfsspec\nhttpx>=0.24.1\nhuggingface_hub>=0.19.3\npackaging\ntyping_extensions~=4.0\nwebsockets>=10.0,<16.0\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Tone Generator\nDESCRIPTION: This snippet installs the necessary libraries (Gradio and NumPy) for the tone generation demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_tone/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Creating HTML Template for the Video Gallery\nDESCRIPTION: HTML template for the web application's frontend that displays uploaded videos in a gallery format and provides a form for users to upload new videos for processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_6\n\nLANGUAGE: html\nCODE:\n```\n<!DOCTYPE html> <html> <head> <title> 视频库 </title> <style>\nbody { font-family: sans-serif; margin: 0; padding: 0; background-color:\n#f5f5f5; } h1 { text-align: center; margin-top: 30px; margin-bottom: 20px; }\n.gallery { display: flex; flex-wrap: wrap; justify-content: center; gap: 20px;\npadding: 20px; } .video { border: 2px solid #ccc; box-shadow: 0px 0px 10px\nrgba(0, 0, 0, 0.2); border-radius: 5px; overflow: hidden; width: 300px;\nmargin-bottom: 20px; } .video video { width: 100%; height: 200px; } .video p {\ntext-align: center; margin: 10px 0; } form { margin-top: 20px; text-align:\ncenter; } input[type=\"file\"] { display: none; } .upload-btn { display:\ninline-block; background-color: #3498db; color: #fff; padding: 10px 20px;\nfont-size: 16px; border: none; border-radius: 5px; cursor: pointer; }\n.upload-btn:hover { background-color: #2980b9; } .file-name { margin-left: 10px;\n} </style> </head> <body> <h1> 视频库 </h1> {% if videos %}\n<div class=\"gallery\"> {% for video in videos %} <div class=\"video\">\n<video controls> <source src=\"{{ url_for('static', path=video) }}\"\ntype=\"video/mp4\"> 您的浏览器不支持视频标签。 </video> <p>{{ video\n}}</p> </div> {% endfor %} </div> {% else %} <p>\n尚未上传任何视频。</p> {% endif %} <form action=\"/uploadvideo/\"\nmethod=\"post\" enctype=\"multipart/form-data\"> <label for=\"video-upload\"\nclass=\"upload-btn\"> 选择视频文件 </label> <input type=\"file\" name=\"video\"\nid=\"video-upload\"> <span class=\"file-name\"></span> <button\ntype=\"submit\" class=\"upload-btn\"> 上传 </button> </form> <script> //\n在表单中显示所选文件名 const fileUpload =\ndocument.getElementById(\"video-upload\"); const fileName =\ndocument.querySelector(\".file-name\"); fileUpload.addEventListener(\"change\", (e)\n=> { fileName.textContent = e.target.files[0].name; }); </script> </body>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Installing Development Version of Gradio\nDESCRIPTION: Command to install Gradio in editable mode for development purposes\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Using mdsvex Components in Gradio Svelte Files\nDESCRIPTION: Example of how to import and use an mdsvex (.svx) component in a standard Svelte component for Gradio. This shows the integration between regular Svelte and Markdown-enhanced components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_13\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n    import HelloWorld from \"./HelloWorld.svx\";\n</script>\n\n<HelloWorld />\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files from GitHub\nDESCRIPTION: This code downloads the necessary files for the demo from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/clear_components/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/clear_components/__init__.py\n```\n\n----------------------------------------\n\nTITLE: Launching a Gradio Blocks Interface with Model3D in Python\nDESCRIPTION: This code snippet demonstrates how to create and launch a minimal Gradio Blocks interface utilizing the Model3D component for visualizing 3D models in the browser. It first imports the Gradio library, then constructs a Blocks layout with a single Model3D component, and finally calls the launch function to display the app. This depends on having Gradio installed, and is intended for Python environments; Inputs and outputs are managed through the UI, and limitations include the lack of a supplied model to the Model3D component, so the display will be empty unless configured further.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3d_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Model3D()\n\ndemo.launch()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies Command\nDESCRIPTION: Command to update the @gradio/preview package for component compatibility with Gradio 5.0\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/06_frequently-asked-questions.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nnpm update\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads a data file from the Gradio GitHub repository which contains the dataset used for the line plot demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_zoom/data.py\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Blocks App with Command Line Arguments in Python\nDESCRIPTION: This snippet demonstrates building a Gradio Blocks app that reads dynamic data from command line arguments using Python's `argparse` library. It takes a '--name' parameter and incorporates it into the app UI. The code allows forwarding of unknown arguments and can be run as `gradio run.py --name Gretel`. This approach is compatible with Gradio reload mode and facilitates customization by user input at app launch.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--name\", type=str, default=\"User\")\nargs, unknown = parser.parse_known_args()\n\nwith gr.Blocks() as demo:\n    gr.Markdown(f\"# Greetings {args.name}!\")\n    inp = gr.Textbox()\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: x, inputs=inp, outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and W&B Dependencies\nDESCRIPTION: Command to install the required Python packages (Gradio and W&B) for creating interactive machine learning demos and experiment tracking.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_0\n\nLANGUAGE: sh\nCODE:\n```\npip install gradio wandb\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies for Gradio App\nDESCRIPTION: This snippet lists the required Python packages for a Gradio application. It includes standard PyPI packages like torch, numpy, and Pillow, as well as a specific version of transformers from a Git repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/depth_estimation/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch\ngit+https://github.com/nielsrogge/transformers.git@add_dpt_redesign#egg=transformers\nnumpy\nPillow\njinja2\nopen3d\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Asset Images with wget in Python\nDESCRIPTION: This code snippet downloads two image files (cheetah.jpg, frog.jpg) from the Gradio demo repository using os and shell commands executed inside a Python cell. These images are prerequisites for the later UI demonstration, serving as sample assets for display logic. There are no inputs required from the user; the images are saved in the working directory for subsequent access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sub_block_render/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/sub_block_render/cheetah.jpg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/sub_block_render/frog.jpg\n```\n\n----------------------------------------\n\nTITLE: Creating Plot Function for Gradio Interface\nDESCRIPTION: This function generates a line plot using Plotly Express based on the selected library and metric. It filters the data and creates a visualization for the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/DESCRIPTION.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef plot(library, metric):\n    filtered_df = df[(df[\"library\"] == library)]\n    fig = px.line(filtered_df, x=\"timestamp\", y=metric, title=f\"{metric} for {library}\")\n    return fig\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Video File\nDESCRIPTION: Creates a 'files' directory and downloads a sample video file named 'world.mp4' from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/video_component_events/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Environment Support Table in Markdown\nDESCRIPTION: A markdown table defining the supported software versions and operating systems for running Gradio tests, including Python, Node, and Browser specifications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/quality-strategy.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| Software | Version(s)            | Operating System(s)               |\n| -------- | --------------------- | --------------------------------- |\n| Python   | `3.10.x`              | `ubuntu-latest`, `windows-latest` |\n| Node     | `18.x.x`              | `ubuntu-latest`                   |\n| Browser  | `playwright-chrome-x` | `ubuntu-latest`                   |\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio Webcam Filter App (Shell)\nDESCRIPTION: Installs the necessary Python libraries (`gradio`, `opencv-python`, `numpy`) using pip. The `-q` flag ensures a quiet installation, minimizing output. These libraries are required for building the Gradio interface, performing image processing, and handling numerical operations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_filter_unified/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio opencv-python numpy \n```\n\n----------------------------------------\n\nTITLE: Component Event Handler\nDESCRIPTION: Added key_up event listener to Dropdown component for enhanced interactivity\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n065c5b163c4badb9d9cbd06d627fb4ba086003e7 - Add .key_up event listener to gr.Dropdown()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode. This is a prerequisite step for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_layout/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_nested_thoughts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Dependencies List for ML/CV Python Application\nDESCRIPTION: Lists required Python packages including PyTorch for deep learning, Pillow and OpenCV for image processing, ONNX runtime for model inference, and other essential numerical/scientific computing packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/animeganv2/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch\ntorchvision\nPillow\ngdown\nnumpy\nscipy\ncmake\nonnxruntime-gpu\nopencv-python-headless\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (Gradio and Pillow) for running the demo\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_picker/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio Pillow\n```\n\n----------------------------------------\n\nTITLE: Using Container Parameter in Markdown Component\nDESCRIPTION: Implements the use of the 'container' parameter in the gr.Markdown component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n- [#8843](https://github.com/gradio-app/gradio/pull/8843) [`6f95286`](https://github.com/gradio-app/gradio/commit/6f95286337459efbccb95c9cfac63355669df9ee) - Use `container` param in `gr.Markdown`\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio ASR Demo\nDESCRIPTION: Installs the necessary Python packages for running the speech recognition demo, including Gradio, PyTorch, TorchAudio, and Transformers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/asr/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch torchaudio transformers\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Form Component in Svelte\nDESCRIPTION: This HTML snippet demonstrates importing the `Form` component from the `@gradio/form` library within a Svelte component's `<script>` tag. This step makes the `Form` component available for use within the Svelte template.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/form/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { Form } from \"@gradio/form\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly without showing installation logs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_temporal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets\nDESCRIPTION: Downloads a sample image file (cheetah.jpg) from the Gradio demo repository for testing the classification model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classification/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_classification/cheetah.jpg\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/timer_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Hello Blocks Application\nDESCRIPTION: Creates a Gradio application with a text input, output box, and greeting button. The app takes a name input and returns a personalized greeting message when the button is clicked. Uses Gradio's Blocks interface for more flexible layout control.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_blocks/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Demo\nDESCRIPTION: This snippet installs the necessary Python libraries (gradio, numpy, pandas) using pip. These libraries are required for creating the Gradio interface and working with DataFrames.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_datatype/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy pandas\n```\n\n----------------------------------------\n\nTITLE: Basic Slack Bot Implementation\nDESCRIPTION: Initial implementation of a Slack bot that responds to mentions with a simple message\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/07_creating-a-slack-bot-from-a-gradio-app.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom slack_bolt import App\nfrom slack_bolt.adapter.socket_mode import SocketModeHandler\n\nSLACK_BOT_TOKEN = # PASTE YOUR SLACK BOT TOKEN HERE\nSLACK_APP_TOKEN = # PASTE YOUR SLACK APP TOKEN HERE\n\napp = App(token=SLACK_BOT_TOKEN)\n\n@app.event(\"app_mention\")\ndef handle_app_mention_events(body, say):\n    user_id = body[\"event\"][\"user\"]\n    say(f\"Hi <@{user_id}>! You mentioned me and said: {body['event']['text']}\")\n\nif __name__ == \"__main__\":\n    handler = SocketModeHandler(app, SLACK_APP_TOKEN)\n    handler.start()\n```\n\n----------------------------------------\n\nTITLE: Defining Stateful Conversation Management with Dataclass - Python\nDESCRIPTION: This snippet defines an 'AppState' dataclass for managing per-session state in the chatbot app. It tracks the conversation history as a list, a boolean flag indicating whether speech detection has stopped, and a field for model outputs. This separation of state ensures each user session is independent, requiring 'dataclasses' for the @dataclass and 'field' decorators. The class is intended for instantiating per user and is referenced in Gradio state management.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass AppState:\n    conversation: list = field(default_factory=list)\n    stopped: bool = False\n    model_outs: Any = None\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: Installs the Gradio package silently using pip. The -q flag suppresses output messages during installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom_sync/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: This snippet uses the `pip` package manager command, executed via the `!` prefix (common in notebooks), to install the Gradio library quietly (`-q`). This is a prerequisite for running the subsequent Gradio application code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3D/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Data for Scatter Plot\nDESCRIPTION: This snippet downloads the necessary data file from the Gradio GitHub repository, which contains the dataset used for the scatter plot demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_scatter/data.py\n```\n\n----------------------------------------\n\nTITLE: Starting Node.js Application (Bash)\nDESCRIPTION: A simple Bash command to start a Node.js application assuming the entry point script is named 'app.js'. This is presented as part of the development workflow for Dillinger within the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nnode app\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image-simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: BaseChatBot Properties and Types Definition\nDESCRIPTION: Defines the properties and their types for the BaseChatBot component, including value structure, styling options, and functionality flags. This shows the component's configuration options and default values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/chatbot/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value:\n\t\t| [\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null,\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null\n\t\t  ][]\n\t\t| null;\n\tlet old_value:\n\t\t| [\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null,\n\t\t\t\tstring | { file: FileData; alt_text: string | null } | null\n\t\t  ][]\n\t\t| null = null;\n\texport let latex_delimiters: {\n\t\tleft: string;\n\t\tright: string;\n\t\tdisplay: boolean;\n\t}[];\n\texport let pending_message = false;\n\texport let selectable = false;\n\texport let likeable = false;\n\texport let show_share_button = false;\n\texport let rtl = false;\n\texport let show_copy_button = false;\n\texport let avatar_images: [string | null, string | null] = [null, null];\n\texport let sanitize_html = true;\n\texport let bubble_full_width = true;\n\texport let render_markdown = true;\n\texport let line_breaks = true;\n\texport let root: string;\n\texport let root_url: null | string;\n\texport let i18n: I18nFormatter;\n\texport let layout: \"bubble\" | \"panel\" = \"bubble\";\n```\n\n----------------------------------------\n\nTITLE: Setting Node Server Name\nDESCRIPTION: Defines the host name for the Gradio node server in SSR mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_16\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_NODE_SERVER_NAME=\"0.0.0.0\"\n```\n\n----------------------------------------\n\nTITLE: Downloading dataset file for the demo\nDESCRIPTION: Downloads the required data.py file from the Gradio GitHub repository. This file contains the dataset that will be used for the scatter plot visualization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_quantitative/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_series_quantitative/data.py\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits in Gradio (Python)\nDESCRIPTION: This Python code demonstrates how to set a maximum file upload size when launching a Gradio interface using the `max_file_size` parameter in the `launch()` method, highlighted in version 0.5.0's release notes. The limit can be specified as a string (e.g., '5mb') or using the `gr.FileSize` enum (e.g., `5 * gr.FileSize.MB`). This feature requires the `gradio` library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/highlightedtext/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Generating Distribution Archives with Gulp (Bash)\nDESCRIPTION: This Bash command uses Gulp to build the application for production and create distribution archives (likely zip files). This is part of the Dillinger build instructions within the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\ngulp build dist --prod\n```\n\n----------------------------------------\n\nTITLE: Creating Directory for Video Files (Python)\nDESCRIPTION: Uses the Python 'os' module to create a directory named 'video'. This directory is intended to store video files used or generated by the application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_video_out/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('video')\n```\n\n----------------------------------------\n\nTITLE: Initializing Comet in Python\nDESCRIPTION: Simple Python code to initialize Comet for interactive use in notebooks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport comet_ml\ncomet_ml.init()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This code snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/downloadbutton_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Dependencies - Python\nDESCRIPTION: This snippet installs all required Python packages using pip, including Gradio (for the web interface), Pillow (for image processing), Torch and Torchvision (for deep learning), and Requests (for HTTP file downloads). No parameters are required. It should be run in a shell or Jupyter notebook environment where these packages are not already installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pillow torch torchvision requests \n```\n\n----------------------------------------\n\nTITLE: Single WebSocket Request Test\nDESCRIPTION: Executes a single WebSocket request to test the connection.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nrequest()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode, which suppresses most of the installation output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_interactive/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/checkbox_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (Gradio and NumPy) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/json_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_chained_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Node Server Ports\nDESCRIPTION: Defines port range for the Gradio node server in SSR mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_17\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_NODE_NUM_PORTS=200\n```\n\n----------------------------------------\n\nTITLE: Component Installation Command\nDESCRIPTION: Command to install a custom component after cloning its repository\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/06_frequently-asked-questions.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc install\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode. It's a prerequisite for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_static/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Command to install or upgrade Gradio via pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/01_creating-a-chatbot-fast.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install --upgrade gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hangman/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip with the quiet flag to minimize output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_zoom/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading and Setting Up Demo Files\nDESCRIPTION: Creates directories and downloads sample files from the Gradio GitHub repository for the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('dir1')\n!wget -q -O dir1/bar.txt https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir1/bar.txt\n!wget -q -O dir1/foo.txt https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir1/foo.txt\nos.mkdir('dir2')\n!wget -q -O dir2/baz.png https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir2/baz.png\n!wget -q -O dir2/foo.png https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir2/foo.png\nos.mkdir('dir3')\n!wget -q -O dir3/dir3_bar.log https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir3/dir3_bar.log\n!wget -q -O dir3/dir3_foo.txt https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir3/dir3_foo.txt\n!wget -q -O dir3/dir4 https://github.com/gradio-app/gradio/raw/main/demo/file_explorer_component_events/dir3/dir4\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_save_history/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio PyPI Stats Demo\nDESCRIPTION: Installs the necessary Python packages for the Gradio demo: gradio for the UI, plotly for visualization, pypistats for fetching PyPI download data, and python-dateutil for date manipulation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_multiple_event_triggers/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio plotly pypistats python-dateutil \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with OAuth Support (Python/Shell)\nDESCRIPTION: This command uses pip to install the 'gradio' library along with its optional 'oauth' extras. The '-q' flag ensures a quiet installation with minimal output. This step is necessary to enable OAuth-based login features in Gradio, such as the LoginButton.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/loginbutton_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio gradio[oauth]\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Speech-to-Text Demo\nDESCRIPTION: This snippet installs the necessary Python packages (gradio, torch, and transformers) for running the demo. It uses pip to quietly install the dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_speech_text_sentiment/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch transformers\n```\n\n----------------------------------------\n\nTITLE: Using Built-in Gradio Events in Custom Components (Python)\nDESCRIPTION: Example code showing how to assign built-in Gradio events (like `Events.change` and `Events.upload` from `gradio.events`) to the `EVENTS` class attribute of a custom component. Using these predefined events ensures that their standard descriptions are automatically included in the generated documentation without requiring additional docstrings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/09_documenting-custom-components.md#2025-04-23_snippet_5\n\nLANGUAGE: py\nCODE:\n```\nfrom gradio.events import Events\n\nclass ParamViewer(Component):\n  ...\n\n  EVENTS = [\n    Events.change,\n    Events.upload,\n  ]\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Images\nDESCRIPTION: Downloads example images from the Gradio GitHub repository to use as demo samples.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/animeganv2/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/animeganv2/gongyoo.jpeg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/animeganv2/groot.jpeg\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip\nDESCRIPTION: Installs the Gradio library using pip with the quiet flag to reduce installation output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/autocomplete/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: BasePlayer Component Properties\nDESCRIPTION: Defines the properties for the BasePlayer component, which provides audio playback functionality. It includes properties for the audio value, event handling, display settings, and mode configuration for playing audio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/audio/README.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: null | { name: string; data: string } = null;\n\texport let label: string;\n\texport let autoplay: boolean;\n\texport let i18n: I18nFormatter;\n\texport let dispatch: (event: any, detail?: any) => void;\n\texport let dispatch_blob: (\n\t\tblobs: Uint8Array[] | Blob[],\n\t\tevent: \"stream\" | \"change\" | \"stop_recording\"\n\t) => Promise<void> = () => Promise.resolve();\n\texport let interactive = false;\n\texport let waveform_settings = {};\n\texport let mode = \"\";\n\texport let handle_reset_value: () => void = () => {};\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio Plotting\nDESCRIPTION: Installs the necessary Python packages (Gradio, NumPy, and Pandas) required for creating interactive plots with temporal data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_temporal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy pandas \n```\n\n----------------------------------------\n\nTITLE: Importing Libraries for Image Segmentation in Python\nDESCRIPTION: This snippet imports necessary libraries for image processing and Gradio interface creation. It includes PIL for image handling, numpy for numerical operations, and gradio for building the demo interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/gradio/test_data/flagged_no_log/a.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nimport numpy as np\nfrom PIL import Image\nimport gradio as gr\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies for Gradio Project\nDESCRIPTION: This snippet lists the required Python packages and their versions for the Gradio project. It includes safetensors for efficient tensor storage, OpenCV for computer vision tasks, Twilio for communication features, Gradio itself, a WebRTC module for Gradio, and ONNX Runtime for GPU acceleration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/yolov10_webcam_stream/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nsafetensors==0.4.3\nopencv-python\ntwilio\ngradio>=5.0,<6.0\ngradio-webrtc==0.0.1\nonnxruntime-gpu\n```\n\n----------------------------------------\n\nTITLE: Installing Required Packages for Gradio AnnotatedImage Demo\nDESCRIPTION: Installs the necessary Python packages for running the Gradio AnnotatedImage component demo, including gradio for the UI, numpy for array manipulation, requests for fetching images, and Pillow for image processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/annotatedimage_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy requests Pillow \n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies for Gradio HF Transformers Demo (Shell)\nDESCRIPTION: Installs the `gradio`, `transformers` (version >= 4.46.0), and `torch` (version >= 2.3.1) Python libraries using pip. The `-q` flag ensures a quiet installation. These packages are prerequisites for running the Gradio application with the Hugging Face transformer model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hf_transformers/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio transformers>=4.46.0 torch>=2.3.1 \n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits in Gradio Python Interface\nDESCRIPTION: Illustrates how to set a maximum file size for uploads in a Gradio Python interface using the \"max_file_size\" parameter in the launch() method. Requires the gradio Python package and valid definition of gr.FileSize constants. Inputs are images passed to the demo interface; output restricts uploadable file size to 5 MB, specified as a string or via multiplication with gr.FileSize.MB. Limitations include support for size strings or byte values; other file types or constraints are not directly demonstrated.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dropdown/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\\n\\ndemo.launch(max_file_size=\"5mb\")\\n# or\\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Breaking Out Scatter Plot Series by Quantitative Color in Python\nDESCRIPTION: Illustrates using the `color` argument in `gr.ScatterPlot` to differentiate plot series based on a quantitative (numeric) column in the DataFrame. Requires pandas and gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/01_creating-plots.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n$code_plot_guide_series_quantitative\n```\n\n----------------------------------------\n\nTITLE: Converting File Sizes in Python for Gradio\nDESCRIPTION: This function converts file sizes from bytes to human-readable formats (KB, MB, GB, TB). It handles different units and precision levels.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir1/foo.txt#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef file_size(size_in_bytes: Union[int, float]) -> str:\n    \"\"\"Convert bytes to a human-readable file size.\"\"\"\n    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n        if abs(size_in_bytes) < 1024.0:\n            return f\"{size_in_bytes:3.1f}{unit}B\"\n        size_in_bytes /= 1024.0\n    return f\"{size_in_bytes:.1f}YB\"\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies and Starting Node.js App (Bash)\nDESCRIPTION: This Bash snippet demonstrates navigating into a 'dillinger' directory, installing Node.js dependencies using npm, and then starting the Node.js application using `node app`. This is likely an example from the Markdown content related to setting up the Dillinger editor.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncd dillinger\nnpm i\nnode app\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the required data.py file from the Gradio GitHub repository for the temporal aggregation demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_temporal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_aggregate_temporal/data.py\n```\n\n----------------------------------------\n\nTITLE: Defining Exported Props for Gradio Form in Svelte/JS\nDESCRIPTION: This JavaScript snippet, using TypeScript syntax likely within a Svelte component, defines exported properties (`visible`, `scale`, `min_width`) with default values. These props control the visibility (boolean, default true), scaling behavior (number or null, default null), and minimum width (number, default 0) of the associated component, presumably the Gradio Form.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/form/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let visible = true;\n\texport let scale: number | null = null;\n\texport let min_width = 0;\n```\n\n----------------------------------------\n\nTITLE: URL Configuration\nDESCRIPTION: Sets the target URL for testing Gradio endpoints.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nURL = \"18.236.68.146\"\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Changelog (Markdown)\nDESCRIPTION: Updates the dependencies for @gradio/atoms and @gradio/statustracker packages in the changelog.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/simpledropdown/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- Updated dependencies [[`3cdeabc68`](https://github.com/gradio-app/gradio/commit/3cdeabc6843000310e1a9e1d17190ecbf3bbc780), [`fad92c29d`](https://github.com/gradio-app/gradio/commit/fad92c29dc1f5cd84341aae417c495b33e01245f)]:\n  - @gradio/atoms@0.2.1\n  - @gradio/statustracker@0.3.1\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Demo\nDESCRIPTION: This snippet installs the necessary Python libraries (gradio and numpy) for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library quietly using pip, which is necessary to run the interface demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_essay_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Starting a Svelte development server\nDESCRIPTION: Commands to start a development server for a Svelte project after installing dependencies. Includes an option to automatically open the app in a new browser tab.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/component-test/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Fake Diffusion Demo\nDESCRIPTION: This snippet installs the necessary Python libraries for the Gradio fake diffusion demo. It uses pip to quietly install gradio, numpy, requests, and Pillow.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion_with_gif/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy requests Pillow\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library - Python\nDESCRIPTION: This snippet installs the Gradio library using pip, enabling subsequent examples to utilize Gradio components. It is intended as the initial step before running any code that depends on Gradio. The snippet should be run in a terminal or notebook environment that supports shell commands.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/number_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library (Shell)\nDESCRIPTION: Installs the Gradio Python library using the pip package manager. The `-q` flag ensures a quiet installation with minimal output. This command is typically run in a shell or notebook environment to set up the necessary dependency before executing the Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/state_change/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: Installs the Gradio library using pip, the Python package installer. The `-q` flag ensures a quiet installation, suppressing most output. This command is typically run in a shell or notebook environment to ensure the necessary library is available before executing the Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3d_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: This snippet installs the Gradio library using pip directly within a Python environment or notebook. It is a prerequisite for running any Gradio app and should be executed before importing or using Gradio in the code. Outputs indicate successful or failed installation, and requires network access to PyPI.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_heavy_concurrently/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency\nDESCRIPTION: Installs the Gradio package quietly using pip. Gradio is a Python library for creating user interfaces around machine learning models and data visualizations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetime/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: BaseDownload Component Props Definition\nDESCRIPTION: Defines the props for the BaseDownload component which enables code downloading. Requires both the code value and language specification.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n\texport let language: string;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package quietly using pip. It's a prerequisite for running the theme builder demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_builder/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Using Decorator Syntax with gr.on for Multiple Gradio Triggers in Python\nDESCRIPTION: Illustrates the decorator syntax (`@gr.on(...)`) in Python for binding multiple event triggers (submit button's `click` and textbox's `submit`) to a single function (`greet`) in Gradio. This provides a more concise alternative to the standard `gr.on()` method call for achieving the same functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n$code_on_listener_decorator\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_streaming/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Brush Color via API (TypeScript)\nDESCRIPTION: Sets the brush color for the Brush Tool. It accepts a `color` parameter, likely a string representation (e.g., hex code, rgba) or a numerical value, to define the drawing color. This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_1\n\nLANGUAGE: typescript\nCODE:\n```\nsetBrushColor(color)\n```\n\n----------------------------------------\n\nTITLE: Basic Gradio Blocks Demo Implementation in Python\nDESCRIPTION: A simple Gradio Blocks application that creates a greeting interface with a text input box that dynamically updates a text output when the user types their name.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# 来自Gradio的问候！\")\n    inp = gr.Textbox(placeholder=\"您叫什么名字？\")\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: f\"欢迎，{x}！\",\n               inputs=inp,\n               outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Downloading Titanic Dataset for Gradio Demo\nDESCRIPTION: This code creates a 'files' directory and downloads the Titanic dataset CSV file from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/titanic_survival/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/titanic.csv https://github.com/gradio-app/gradio/raw/main/demo/titanic_survival/files/titanic.csv\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Requirements for Gradio\nDESCRIPTION: This snippet defines the Python package dependencies needed for a Gradio project. It includes tqdm for displaying progress bars and datasets for data management, likely the Hugging Face datasets library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntqdm\ndatasets\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates multiple dependencies including @gradio/statustracker, @gradio/client, @gradio/utils, @gradio/atoms, and @gradio/upload.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.2\n\n### Patch Changes\n\n- Updated dependencies [[`afac0006`](https://github.com/gradio-app/gradio/commit/afac0006337ce2840cf497cd65691f2f60ee5912), [`26fef8c7`](https://github.com/gradio-app/gradio/commit/26fef8c7f85a006c7e25cdbed1792df19c512d02)]:\n  - @gradio/statustracker@0.2.0\n  - @gradio/client@0.3.1\n  - @gradio/utils@0.1.1\n  - @gradio/atoms@0.1.2\n  - @gradio/upload@0.2.1\n```\n\n----------------------------------------\n\nTITLE: Gradio Blocks with Custom Demo Variable Name\nDESCRIPTION: Example showing how to create a Gradio Blocks application with a custom variable name ('my_demo' instead of the default 'demo') which requires a different launch command when using reload mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as my_demo:\n    gr.Markdown(\"# 来自Gradio的问候！\")\n    inp = gr.Textbox(placeholder=\"您叫什么名字？\")\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: f\"欢迎，{x}！\",\n               inputs=inp,\n               outputs=out)\n\nif __name__ == \"__main__\":\n    my_demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: This command uses pip, the Python package installer, to install the Gradio library quietly (`-q`). This is a prerequisite for running the Gradio application defined later in the file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/zip_files/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: BaseCheckbox Component Props Definition\nDESCRIPTION: This snippet defines the available props for the BaseCheckbox component, including the default value, label text, and interaction mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/checkbox/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value = false;\n\texport let label = \"Checkbox\";\n\texport let mode: \"static\" | \"interactive\";\n```\n\n----------------------------------------\n\nTITLE: Combined POST and GET Request using awk\nDESCRIPTION: Shows how to combine the POST and GET requests into a single command using awk and read to parse results.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -X POST https://abidlabs-en2fr.hf.space/call/predict -H \"Content-Type: application/json\" -d '{\n  \"data\": [\"Hello, my friend.\"] \n}' \\\n  | awk -F'\"' '{ print $4}'  \\\n  | read EVENT_ID; curl -N https://abidlabs-en2fr.hf.space/call/predict/$EVENT_ID\n\n>> event: complete\n>> data: [\"Bonjour, mon ami.\"]\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip. This is typically run in a notebook environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_plug/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (Gradio and Pandas) using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/barplot_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Demo\nDESCRIPTION: This snippet installs the necessary Python libraries for the Gradio demo, including Gradio itself, NumPy, pandas, and matplotlib.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/clear_components/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy pandas matplotlib\n```\n\n----------------------------------------\n\nTITLE: Updating Gradio Package Versions\nDESCRIPTION: Code snippet showing how to update Gradio package versions to use beta releases.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: json\nCODE:\n```\n\"@gradio\": \"^0.4.0-beta.1\"\n```\n\n----------------------------------------\n\nTITLE: Windows Install Commands\nDESCRIPTION: Batch commands for installing Gradio and its dependencies on Windows systems\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nscripts\\install_gradio.bat\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_streaming_echo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies using Pip in Shell\nDESCRIPTION: Installs the required Python packages (`gradio`, `scipy`, `numpy`, `matplotlib`) using the pip package installer. These libraries are essential for the Gradio interface, scientific computing (including FFT via scipy), numerical operations (numpy), and potentially plotting (matplotlib). The `-q` flag ensures quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/main_note/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio scipy numpy matplotlib\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode, which suppresses most of the output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/browser_state_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library using pip. This is a prerequisite for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_blocks_cached/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode. This is required before using any Gradio components in the application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_random_response/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_editable/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (gradio and pandas) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot_demo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates the @gradio/client and @gradio/upload dependencies to versions 0.4.0 and 0.3.0 respectively.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.3\n\n### Patch Changes\n\n- Updated dependencies [[`c57f1b75e`](https://github.com/gradio-app/gradio/commit/c57f1b75e272c76b0af4d6bd0c7f44743ff34f26), [`40de3d217`](https://github.com/gradio-app/gradio/commit/40de3d2178b61ebe424b6f6228f94c0c6f679bea), [`ea0e00b20`](https://github.com/gradio-app/gradio/commit/ea0e00b207b4b90a10e9d054c4202d4e705a29ba), [`75ddeb390`](https://github.com/gradio-app/gradio/commit/75ddeb390d665d4484667390a97442081b49a423)]:\n  - @gradio/client@0.4.0\n  - @gradio/upload@0.3.0\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependencies\nDESCRIPTION: Installs the Gradio library using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/automatic-speech-recognition/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: BaseCopy Component Props Definition\nDESCRIPTION: Defines the props for the BaseCopy component which provides functionality to copy code. It only requires a string value to be copied.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Checking Code Format with Prettier\nDESCRIPTION: Command to check code formatting using Prettier without making changes. Used for verifying code style compliance.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm format:check\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/imageeditor_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Defining Backend Data Models\nDESCRIPTION: Python classes defining the data structure for multimodal messages using Pydantic models.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass FileMessage(GradioModel):\n    file: FileData\n    alt_text: Optional[str] = None\n\n\nclass MultimodalMessage(GradioModel):\n    text: Optional[str] = None\n    files: Optional[List[FileMessage]] = None\n\n\nclass ChatbotData(GradioRootModel):\n    root: List[Tuple[Optional[MultimodalMessage], Optional[MultimodalMessage]]]\n\n\nclass MultimodalChatbot(Component):\n    ...\n    data_model = ChatbotData\n```\n\n----------------------------------------\n\nTITLE: Specifying Gradio PDF Dependency Version\nDESCRIPTION: This line specifies the exact version of the gradio_pdf package to be used. It requires version 0.0.7 of the gradio_pdf package, which is likely a component or extension for handling PDF files within Gradio applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gradio_pdf_demo/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\ngradio_pdf==0.0.7\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. The -q flag is used for quiet installation, suppressing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/colorpicker_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: ShareButton Component Props Definition\nDESCRIPTION: Defines the available props for the ShareButton component, which enables sharing functionality with a formatter function, value to share, and internationalization support.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_6\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let formatter: (arg0: any) => Promise<string>;\n\texport let value: any;\n\texport let i18n: I18nFormatter;\n```\n\n----------------------------------------\n\nTITLE: Publishing Custom Component\nDESCRIPTION: Command to publish the custom component to PyPI and/or Hugging Face Spaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/01_custom-components-in-five-minutes.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc publish\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/code/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Defining Package Requirements with pip - Python\nDESCRIPTION: Specifies exact versions of the Diffusers and Torch packages for installation via pip in a Python environment. The dependency lines are typically included in a requirements.txt file, which can be processed by tools such as pip or poetry for dependency resolution. Each line lists a package and an exact version required; inputs are package names and versions, outputs are installed packages; all lines must use the correct format (<package>==<version>).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stable-diffusion/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\ndiffusers==0.32.2\n```\n\nLANGUAGE: Python\nCODE:\n```\ntorch==2.5.1\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode to minimize output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_group/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Question-Answering Demo in Python\nDESCRIPTION: Installs the necessary Python packages (Gradio, PyTorch, and Transformers) for building a question-answering interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/question-answering/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch transformers\n```\n\n----------------------------------------\n\nTITLE: BaseExample Component Props\nDESCRIPTION: Defines the props available for the BaseExample component, including value, type, and selected with their types and default values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/colorpicker/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n\texport let type: \"gallery\" | \"table\";\n\texport let selected = false;\n```\n\n----------------------------------------\n\nTITLE: Function-as-Value Filtering Approach in Gradio\nDESCRIPTION: Alternative implementation of filtering using Gradio's function-as-value syntax for more concise code. Shows how to create interactive filters without explicit event listeners.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/03_filters-tables-and-stats.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n$code_plot_guide_filters\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip (Shell)\nDESCRIPTION: This snippet uses the pip package manager to install the Gradio library quietly (`-q` flag). This is a prerequisite for running the subsequent Python code that utilizes the Gradio framework.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_streaming_echo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library quietly using pip, which is required to run the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter_nominal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package silently using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_thoughts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_live/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_story/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Declaring Pandas Dependency\nDESCRIPTION: Specifies pandas as a required package dependency in a requirements.txt style file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot_demo/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\npandas\n```\n\n----------------------------------------\n\nTITLE: Package Requirement Entry - numpy\nDESCRIPTION: Specifies numpy as a required package dependency without version constraints.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_diffusion/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode. This is a prerequisite step before creating the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/score_tracker/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_gpt/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the necessary data file from the Gradio GitHub repository using wget.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_filters/data.py\n```\n\n----------------------------------------\n\nTITLE: Processing URLs with handle_file Utility\nDESCRIPTION: Demonstrates how to handle URL-based file references using the handle_file utility in Gradio client.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_22\n\nLANGUAGE: typescript\nCODE:\n```\nimport { handle_file } from \"@gradio/client\";\n\nconst url_ref = handle_file(\"https://example.com/file.png\");\n\nconst app = await Client.connect(\"user/space-name\");\nconst result = await app.predict(\"/predict\", {\n\turl: url_ref,\n});\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/unload_event_test/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Textbox Components in HTML\nDESCRIPTION: This snippet demonstrates how to import the BaseTextbox and BaseExample components from the @gradio/textbox package in an HTML file with a script tag.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseTextbox, BaseExample } from \"@gradio/textbox\";\n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio using Pip (Shell)\nDESCRIPTION: This shell command uses pip, the Python package installer, to install the Gradio library. The `-q` flag ensures that the installation process runs quietly, minimizing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_decorator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Creating Gradio Code Component Interface\nDESCRIPTION: Sets up a Gradio interface that accepts Python code as input and returns it as output. The interface includes example inputs with file paths and simple code snippets.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/code_component/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(\n    lambda x: x,\n    gr.Code(language=\"python\"),\n    gr.Code(language=\"python\"),\n    examples=[[(\"/Users/freddy/sources/gradio/demo/code_component/run.py\",)],\n               [\"print('Hello, World!')\"],\n               [(\"/Users/freddy/sources/gradio/demo/code/run.py\", )]]\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy using pip\nDESCRIPTION: This shell command uses pip to install the Gradio and NumPy libraries quietly (`-q`). These libraries are required dependencies for the subsequent Python script that builds the audio streaming demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio numpy \n\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits with Gradio Interface - Python\nDESCRIPTION: This snippet demonstrates how to limit the maximum uploadable file size in a Gradio interface using the 'max_file_size' parameter within the 'launch()' method. It supports both string and integer representations (in bytes), and utilizes the 'gr.FileSize' enum for unit conversions. Dependencies: Requires the 'gradio' Python package installed. The main parameters are the function to run (here, identity mapping), input type ('image'), output type ('image'), and the 'max_file_size' parameter. Expects uploads not exceeding 5 MB, and constrains per-file upload size; larger uploads will be rejected with an error. Outputs are standard Gradio UI components for image input/output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/fileexplorer/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Checking Gradio Job Status with Python Client\nDESCRIPTION: Initializes a `gradio_client.Client` connected to a specific Gradio application ('gradio/calculator'). It then submits a job to the '/predict' API endpoint with input values (5, \"add\", 4) and retrieves the job's current status using the `.status()` method. The output shows the initial status code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/01_getting-started-with-the-python-client.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(src=\"gradio/calculator\")\njob = client.submit(5, \"add\", 4, api_name=\"/predict\")\njob.status()\n\n>> <Status.STARTING: 'STARTING'>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_prefill/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/filter_records/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip with the quiet flag to minimize output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_tables_stats/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip - Python\nDESCRIPTION: Installs the Gradio library using pip within a Python environment. This dependency is required before importing and utilizing any Gradio components. No additional parameters are needed, and output is the installation of the Gradio package for subsequent code usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/paramviewer_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_watermark/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_with_tools/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: This snippet installs the Gradio library using pip with quiet mode enabled. It ensures that the required dependency is available for use in subsequent Gradio app code. This must be executed in a suitable environment (such as a notebook or script with shell access) before importing Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_basic/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Managing Version Control and Changesets\nDESCRIPTION: Details the changeset detection and version bumping logic, including package change detection, bump type determination, and change type classification.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_5\n\nLANGUAGE: javascript\nCODE:\n```\npackage.json:\\n{\\n  \"main_changeset\": true\\n}\n```\n\n----------------------------------------\n\nTITLE: Specifying NumPy Dependency\nDESCRIPTION: Lists NumPy as a required package dependency for the project. This is typically used in requirements.txt or similar dependency management files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_selections/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/event_trigger/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's executed in a quiet mode to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_blocks_decorator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Importing Radio Components in Svelte\nDESCRIPTION: This snippet shows how to import the BaseRadio and BaseExample components from the @gradio/radio package in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/radio/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseRadio, BaseExample } from \"@gradio/radio\"; \n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/copy_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_joined/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_js_load/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip with quiet mode enabled to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/rows_and_columns/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependencies in Python\nDESCRIPTION: This snippet installs the Gradio package using pip, which is required to run the rest of the application. It is meant to be executed in an environment such as Jupyter Notebook or Google Colab that supports notebook magics. No input or output is expected beyond the installation process, and an active internet connection is necessary.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/simple_state/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements\nDESCRIPTION: Lists required Python packages numpy and pandas, which are common libraries used for numerical computing and data manipulation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_datatype/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nnumpy\npandas\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This snippet installs the Gradio library using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_streaming/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Importing Dropdown Components with Gradio in HTML\nDESCRIPTION: This HTML snippet demonstrates how to import the BaseDropdown, BaseMultiselect, and BaseExample components from the @gradio/dropdown package using a Svelte-style script block. Dependencies include the @gradio/dropdown package. Expected input is the use of this script within a Svelte-compatible project; no outputs are produced directly, as this enables access to the components in the file's scope.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dropdown/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n    import {BaseDropdown, BaseMultiselect, BaseExample } from \"@gradio/dropdown\";\\n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for YOLOv10 Webcam Stream Demo\nDESCRIPTION: This snippet installs the necessary Python packages for the YOLOv10 webcam stream demo, including Gradio, SafeTensors, OpenCV, Twilio, and ONNX Runtime GPU.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/yolov10_webcam_stream/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio safetensors==0.4.3 opencv-python twilio gradio>=5.0,<6.0 gradio-webrtc==0.0.1 onnxruntime-gpu\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip in Bash\nDESCRIPTION: Installs the Gradio Python library quietly using the pip package manager. This command is executed within a Python environment using the '!' prefix, common in notebooks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_audio_out/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Implementing Data Preprocessing\nDESCRIPTION: Method to preprocess chatbot data before passing to Python functions.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef preprocess(\n    self,\n    payload: ChatbotData | None,\n) -> List[MultimodalMessage] | None:\n    if payload is None:\n        return payload\n    return payload.root\n```\n\n----------------------------------------\n\nTITLE: Generating Playwright Tests\nDESCRIPTION: Command for automatically generating Playwright tests by recording interactions with a running Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nnpx playwright codegen <url>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package with pip\nDESCRIPTION: Installs the Gradio package quietly using pip. This is a prerequisite for running the demo application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sentence_builder/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image\nDESCRIPTION: Downloads a sample rabbit.png image from the Gradio demo repository for testing the color picker\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_picker/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/color_picker/rabbit.png\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip with the quiet flag to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/audio_debugger/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode to suppress output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_merge/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Multiple Theme Variables Manually in Gradio\nDESCRIPTION: This snippet demonstrates manual setting of multiple theme variables to the same value. It explicitly sets background and border colors for a button to the same red color.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_10\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default().set(\n    button_primary_background_fill=\"#FF0000\",\n    button_primary_background_fill_hover=\"#FF0000\",\n    button_primary_border=\"#FF0000\",\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/code_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency using Pip (Shell)\nDESCRIPTION: This shell command uses pip, the Python package installer, to install the Gradio library quietly (-q). This is a prerequisite step to ensure the Gradio library is available for the Python script that follows.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/queue_full_e2e_test/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Updating Client Dependency in Gradio File Component\nDESCRIPTION: Updates the @gradio/client dependency to version 0.4.1.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.4\n\n### Patch Changes\n\n- Updated dependencies [[`78e7cf516`](https://github.com/gradio-app/gradio/commit/78e7cf5163e8d205e8999428fce4c02dbdece25f)]:\n  - @gradio/client@0.4.1\n```\n\n----------------------------------------\n\nTITLE: BaseWidget Component Props Definition\nDESCRIPTION: Defines the props for the BaseWidget component which serves as a code widget. Requires both the code value and language specification.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/code/README.md#2025-04-23_snippet_4\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let value: string;\n\texport let language: string;\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_js_methods/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_identity/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the todo list application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/todo_list/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Checking cURL Installation\nDESCRIPTION: Command to verify cURL installation on the system.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ncurl --version\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/interface_state/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/zip_to_json/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/datetimes/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency using pip (Python/Shell)\nDESCRIPTION: This snippet uses a shell command executed within a Python environment (likely a Jupyter notebook or similar) to install the Gradio library quietly (-q flag). This is a prerequisite for running the subsequent Gradio application code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_multimodal_examples/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Creating Custom Component from Template\nDESCRIPTION: Command to create a new custom component directory based on the Chatbot template.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc create MultimodalChatbot --template Chatbot\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_remote_url/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Configuring JavaScript Dependencies\nDESCRIPTION: JSON configuration for adding JavaScript/NPM dependencies in package.json.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n\"dependencies\": {\n    \"@gradio/atoms\": \"0.2.0-beta.4\",\n    \"@gradio/statustracker\": \"0.3.0-beta.6\",\n    \"@gradio/utils\": \"0.2.0-beta.4\",\n    \"your-npm-package\": \"<version>\"\n}\n```\n\n----------------------------------------\n\nTITLE: Importing BaseHTML Component in Gradio JavaScript\nDESCRIPTION: This snippet imports the `BaseHTML` class from the `@gradio/html` package. This class likely serves as the foundation for creating or managing HTML elements within a Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/html/README.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nimport { BaseHTML } from \"@gradio/html\";\n```\n\n----------------------------------------\n\nTITLE: Initializing Gradio Blocks App with Auto-Reload Support in Python\nDESCRIPTION: This Python snippet shows how to initialize a Gradio Blocks application, using a standard structure for interactive input and output through text boxes. It demonstrates event handling with callbacks and launches the app when run as the main script. Intended to be used with Gradio's auto-reload mode (invoked via the `gradio` CLI), this template requires the `gradio` Python package and optionally UTF-8 encoded source code. Inputs are provided through a textbox, with outputs dynamically updated via input change events.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Greetings from Gradio!\")\n    inp = gr.Textbox(placeholder=\"What is your name?\")\n    out = gr.Textbox()\n\n    inp.change(fn=lambda x: f\"Welcome, {x}!\",\n               inputs=inp,\n               outputs=out)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Importing pandas library in Python\nDESCRIPTION: A simple import statement for the pandas library, which is used for data manipulation and analysis in Python. This import makes the pandas functionality available in the current Python environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatter_plot_demo/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npandas\n```\n\n----------------------------------------\n\nTITLE: Downloading Audio File for Gradio Demo in Python\nDESCRIPTION: Downloads the 'beep.mp3' audio file from the official Gradio demo repository using wget, ensuring the necessary asset is present for playback in the demo. The snippet first imports the os module and then executes a shell command. There is a dependency on internet connectivity and on 'wget' being available in the environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sound_alert/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/sound_alert/beep.mp3\n```\n\n----------------------------------------\n\nTITLE: Implementing Message Postprocessing\nDESCRIPTION: Method to postprocess chat messages and handle file mime types.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/08_multimodal-chatbot-part1.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef _postprocess_chat_messages(\n    self, chat_message: MultimodalMessage | dict | None\n) -> MultimodalMessage | None:\n    if chat_message is None:\n        return None\n    if isinstance(chat_message, dict):\n        chat_message = MultimodalMessage(**chat_message)\n    chat_message.text = inspect.cleandoc(chat_message.text or \"\")\n    for file_ in chat_message.files:\n        file_.file.mime_type = client_utils.get_mimetype(file_.file.path)\n    return chat_message\n```\n\n----------------------------------------\n\nTITLE: Real-Time DataFrame and LinePlot Visualization with Gradio for Private Sheet - Python\nDESCRIPTION: This snippet is identical in structure to the public sheet visualization but is intended to be used after fetching private sheet data with gspread. It displays the authenticated, refreshed data as both a DataFrame and a line plot, updating every 5 seconds. Requires 'gradio', a data-fetching function (get_data) set up for authenticated access, and properly handled dependencies. The structure remains consistent, with focus on refresh intervals and plot configuration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# \\ud83d\\udcc8 Real-Time Line Plot\")\n    with gr.Row():\n        with gr.Column():\n            gr.DataFrame(get_data, every=gr.Timer(5))\n        with gr.Column():\n            gr.LinePlot(get_data, every=gr.Timer(5), x=\"Date\", y=\"Sales\", y_title=\"Sales ($ millions)\", overlay_point=True, width=500, height=500)\n\ndemo.queue().launch()  # Run the demo with queuing enabled\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This code snippet installs the Gradio package using pip. The -q flag is used for quiet installation, suppressing output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/datetime_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_3/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_tab/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_inputs/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the Gradio demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Plot Component\nDESCRIPTION: Installs the necessary Python packages: Gradio for creating the web interface, Matplotlib for plotting, and NumPy for numerical operations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio matplotlib numpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_artifacts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_3/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's executed quietly (-q flag) to reduce output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: Installs the Gradio library using pip in a quiet mode, which suppresses most of the output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_1/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits with Gradio in Python\nDESCRIPTION: This code snippet demonstrates setting a maximum file upload size for a Gradio interface using the `max_file_size` parameter in the `launch()` method. It supports both string-based file size formats (like '5mb') and computations using the `gr.FileSize` enumeration. Dependencies required are the `gradio` Python package and its `FileSize` submodule. Inputs are images, and the upload limit applies individually to each file uploaded, ensuring files exceeding the limit are not accepted.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\ndemo = gr.Interface(lambda x: x, \\\"image\\\", \\\"image\\\")\\n\\ndemo.launch(max_file_size=\\\"5mb\\\")\\n# or\\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\\n\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in a quiet mode to suppress unnecessary output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_update/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_multimodal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio\nDESCRIPTION: Installs the Gradio library using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/change_vs_input/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Package Dependencies\nDESCRIPTION: This snippet lists the required Python packages and their versions for the project. It includes NumPy, Matplotlib, SHAP, XGBoost, Pandas, and Datasets. Some packages have specific version requirements, while others are left open-ended.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/xgboost-income-prediction-with-explainability/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Text\nCODE:\n```\nnumpy==1.23.2\nmatplotlib\nshap\nxgboost==1.7.6\npandas\ndatasets\n```\n\n----------------------------------------\n\nTITLE: Commit Reference in Dependencies\nDESCRIPTION: Git commit hash reference for dependency updates.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n[[`abf1c57d`](https://github.com/gradio-app/gradio/commit/abf1c57d7d85de0df233ee3b38aeb38b638477db)]\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the rest of the code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via Pip in Python\nDESCRIPTION: This snippet installs the Gradio package using pip directly from within a Python environment. No inputs or outputs are produced other than command-line output. It is necessary to execute this command prior to using Gradio functionalities. Requires an environment where shell commands can be run via the '!' syntax (e.g., Jupyter or Colab notebooks).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/skip/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip (Shell)\nDESCRIPTION: This command uses the `pip` package manager to install the `gradio` library. The `-q` flag ensures a quiet installation, suppressing most output messages. This step is a prerequisite for running the subsequent Python code that utilizes the Gradio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/variable_outputs/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Changelog Entry Format - Markdown\nDESCRIPTION: Standard changelog entry format showing version numbers, links to pull requests, commit hashes, and descriptions of changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n- [#4717](https://github.com/gradio-app/gradio/pull/4717) [`ab5d1ea0`](https://github.com/gradio-app/gradio/commit/ab5d1ea0de87ed888779b66fd2a705583bd29e02) Thanks [@whitphx](https://github.com/whitphx)! - Fix the package description\n\n## 0.1.3\n\n### Patch Changes\n\n- [#4357](https://github.com/gradio-app/gradio/pull/4357) [`0dbd8f7f`](https://github.com/gradio-app/gradio/commit/0dbd8f7fee4b4877f783fa7bc493f98bbfc3d01d) Thanks [@pngwn](https://github.com/pngwn)! - Various internal refactors and cleanups.\n\n## 0.1.2\n```\n\n----------------------------------------\n\nTITLE: Building Docker Image for Dillinger (Bash)\nDESCRIPTION: This Bash snippet shows the command to build a Docker image for the Dillinger application. It navigates into the 'dillinger' directory and uses `docker build`, tagging the image with a username and version derived from `package.json`. This is from the Docker setup instructions in the Markdown.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\ncd dillinger\ndocker build -t <youruser>/dillinger:${package.json.version} .\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies for Gradio\nDESCRIPTION: Lists required Python packages for a Gradio application: transformers and torch (PyTorch) libraries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/english_translator/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ntransformers\\ntorch\n```\n\n----------------------------------------\n\nTITLE: Enabling Example Caching\nDESCRIPTION: Controls whether examples are cached by default.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_12\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_CACHE_EXAMPLES=\"true\"\n```\n\n----------------------------------------\n\nTITLE: Development Server Command\nDESCRIPTION: Command to start the development server with hot reload functionality\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/06_frequently-asked-questions.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc dev\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: This snippet demonstrates how to install the Gradio library in a Python environment using pip. The installation command is prefixed with an exclamation mark, denoting its intended usage within Jupyter notebooks or interactive shells. It suppresses pip's output with the -q flag. There are no parameters aside from the package name, and the output is installation logs (suppressed).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/live_with_vars/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Implementing Process Example Method\nDESCRIPTION: Method for processing example data in a SimpleDropdown component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/04_backend.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef process_example(self, input_data):\n    return next((c[0] for c in self.choices if c[1] == input_data), None)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_scroll/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Parallel WebSocket Test with 25 Workers\nDESCRIPTION: Runs WebSocket requests in parallel with 25 workers and calculates average duration and message count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\noutput = run_in_parallel(request, 25)\navg_duration = sum(o[0] for o in output) / len(output)\navg_msg = sum(o[1] for o in output) / len(output)\nprint(avg_duration, avg_msg)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/input_output/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Removing Unnecessary Scrollbar from File Preview in Gradio\nDESCRIPTION: Removes the scrollbar from the File preview when it is not needed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_10\n\nLANGUAGE: markdown\nCODE:\n```\n- [#5265](https://github.com/gradio-app/gradio/pull/5265) [`06982212`](https://github.com/gradio-app/gradio/commit/06982212dfbd613853133d5d0eebd75577967027) - Removes scrollbar from File preview when not needed. Thanks [@abidlabs](https://github.com/abidlabs)!\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets\nDESCRIPTION: Creates necessary directories and downloads required files including ImageNet labels and example images from the Gradio demo repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/imagenet_labels.json https://github.com/gradio-app/gradio/raw/main/demo/image_classifier/files/imagenet_labels.json\nos.mkdir('images')\n!wget -q -O images/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_classifier/images/cheetah1.jpg\n!wget -q -O images/lion.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_classifier/images/lion.jpg\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_login/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_thoughts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Files for Speaker Verification Demo\nDESCRIPTION: Sets up the project directory structure and downloads necessary files including sample audio recordings of different speakers for testing the verification model.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/same-person-or-different/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/same-person-or-different/packages.txt\nos.mkdir('samples')\n!wget -q -O samples/cate_blanch.mp3 https://github.com/gradio-app/gradio/raw/main/demo/same-person-or-different/samples/cate_blanch.mp3\n!wget -q -O samples/cate_blanch_2.mp3 https://github.com/gradio-app/gradio/raw/main/demo/same-person-or-different/samples/cate_blanch_2.mp3\n!wget -q -O samples/heath_ledger.mp3 https://github.com/gradio-app/gradio/raw/main/demo/same-person-or-different/samples/heath_ledger.mp3\n```\n\n----------------------------------------\n\nTITLE: Gradio-Lite with Additional Requirements\nDESCRIPTION: Implementation showing how to include additional Python package requirements using gradio-requirements tags.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/05_gradio-lite.md#2025-04-23_snippet_3\n\nLANGUAGE: html\nCODE:\n```\n<gradio-lite>\n\n<gradio-requirements>\ntransformers_js_py\n</gradio-requirements>\n\n<gradio-file name=\"app.py\" entrypoint>\nfrom transformers_js import import_transformers_js\nimport gradio as gr\n\ntransformers = await import_transformers_js()\npipeline = transformers.pipeline\npipe = await pipeline('sentiment-analysis')\n\nasync def classify(text):\n\treturn await pipe(text)\n\ndemo = gr.Interface(classify, \"textbox\", \"json\")\ndemo.launch()\n</gradio-file>\n\n</gradio-lite>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: This command uses pip, the Python package installer, to install the Gradio library. The `-q` flag ensures a quiet installation, minimizing output to the console. This step is a prerequisite for running the Gradio application code that follows.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_split_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy Dependencies\nDESCRIPTION: Installs the required packages Gradio and NumPy using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dropdown_key_up/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's executed quietly (-q flag) to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_nested_thoughts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Running Gulp Watch Task (Bash)\nDESCRIPTION: This Bash command executes the 'watch' task defined in a Gulp configuration file. This task typically monitors files for changes and triggers rebuilds automatically during development. This is part of the Dillinger development instructions within the Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\ngulp watch\n```\n\n----------------------------------------\n\nTITLE: Showing Gradio Block Auto-Rendering in Constructor Python\nDESCRIPTION: Shows a simplified snippet of the `gradio.blocks.Block` constructor. It highlights that the block's `render()` method is called automatically during initialization if the `render` parameter is true, explaining the behavior seen in default Gradio layout usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/wrapping-layouts.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass Block:\n    # constructor parameters are omitted for brevity\n    def __init__(self, ...):\n        # other assign functions \n\n        if render:\n            self.render()\n```\n\n----------------------------------------\n\nTITLE: Python Package Dependencies\nDESCRIPTION: List of required Python package dependencies including database connectors (psycopg2, SQLAlchemy), data analysis tools (pandas), and visualization libraries (matplotlib).\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chicago-bikeshare-dashboard/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npsycopg2\nmatplotlib\nSQLAlchemy\npandas\n```\n\n----------------------------------------\n\nTITLE: Setting Examples Cache Location\nDESCRIPTION: Specifies the location for cached example files.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_14\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_EXAMPLES_CACHE=\"custom_cached_examples/\"\n```\n\n----------------------------------------\n\nTITLE: Explicit gr.on Equivalent for Direct Component Value Binding in Python\nDESCRIPTION: Provides the explicit `gr.on` implementation in Python that is functionally equivalent to the shorthand syntax for direct component value binding. It demonstrates how `gr.on` listens to the `change` events of the input components (`num1`, `num2`) and the demo's `load` event to call the lambda function and update the `product` component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/03_building-with-blocks/01_blocks-and-event-listeners.md#2025-04-23_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks() as demo:\n  num1 = gr.Number()\n  num2 = gr.Number()\n  product = gr.Number()\n\n  gr.on(\n    [num1.change, num2.change, demo.load], \n    lambda a, b: a * b, \n    inputs=[num1, num2], \n    outputs=product\n  )\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/cancel_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets\nDESCRIPTION: Creates directories and downloads image and video files for the demo from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/event_trigger/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('img')\n!wget -q -O img/a.jpg https://github.com/gradio-app/gradio/raw/main/demo/event_trigger/img/a.jpg\n!wget -q -O img/b.jpg https://github.com/gradio-app/gradio/raw/main/demo/event_trigger/img/b.jpg\nos.mkdir('mp4')\n!wget -q -O mp4/a.mp4 https://github.com/gradio-app/gradio/raw/main/demo/event_trigger/mp4/a.mp4\n!wget -q -O mp4/b.mp4 https://github.com/gradio-app/gradio/raw/main/demo/event_trigger/mp4/b.mp4\n```\n\n----------------------------------------\n\nTITLE: Model Save and Load Implementation\nDESCRIPTION: Functions for saving, downloading, and loading the StyleGAN model, including setup for inference.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom PIL import Image\nimport torch\ntorch.backends.cudnn.benchmark = True\nfrom torchvision import transforms, utils\nfrom util import *\nimport math\nimport random\nimport numpy as np\nfrom torch import nn, autograd, optim\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\nimport lpips\nfrom model import *\nfrom e4e_projection import projection as e4e_projection\n\nfrom copy import deepcopy\nimport imageio\n\nimport os\nimport sys\nimport torchvision.transforms as transforms\nfrom argparse import Namespace\nfrom e4e.models.psp import pSp\nfrom util import *\nfrom huggingface_hub import hf_hub_download\nfrom google.colab import files\n\ntorch.save({\"g\": generator.state_dict()}, \"your-model-name.pt\")\n\nfiles.download('your-model-name.pt')\n\nlatent_dim = 512\ndevice=\"cuda\"\nmodel_path_s = hf_hub_download(repo_id=\"akhaliq/jojogan-stylegan2-ffhq-config-f\", filename=\"stylegan2-ffhq-config-f.pt\")\noriginal_generator = Generator(1024, latent_dim, 8, 2).to(device)\nckpt = torch.load(model_path_s, map_location=lambda storage, loc: storage)\noriginal_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\nmean_latent = original_generator.mean_latent(10000)\n\ngenerator = deepcopy(original_generator)\n\nckpt = torch.load(\"/content/JoJoGAN/your-model-name.pt\", map_location=lambda storage, loc: storage)\ngenerator.load_state_dict(ckpt[\"g\"], strict=False)\ngenerator.eval()\n\nplt.rcParams['figure.dpi'] = 150\n\ntransform = transforms.Compose(\n    [\n        transforms.Resize((1024, 1024)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ]\n)\n\ndef inference(img):\n    img.save('out.jpg')\n    aligned_face = align_face('out.jpg')\n\n    my_w = e4e_projection(aligned_face, \"out.pt\", device).unsqueeze(0)\n    with torch.no_grad():\n        my_sample = generator(my_w, input_is_latent=True)\n\n    npimage = my_sample[0].cpu().permute(1, 2, 0).detach().numpy()\n    imageio.imwrite('filename.jpeg', npimage)\n    return 'filename.jpeg'\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_custom_styling/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installation of the Gradio package using pip package manager in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/concurrency_without_queue/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip in Python\nDESCRIPTION: This snippet uses the `pip install` command, executed via the `!` operator within a Python environment (like a Jupyter notebook or Google Colab), to silently install the Gradio library. Gradio is a dependency required for building the web interface demonstrated in the subsequent code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sort_records/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This snippet installs the Gradio library using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_button_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/function_values/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Parallel WebSocket Test with 100 Workers\nDESCRIPTION: Runs WebSocket requests in parallel with 100 workers and calculates average duration and message count.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_9\n\nLANGUAGE: python\nCODE:\n```\noutput = run_in_parallel(request, 100)\navg_duration = sum(o[0] for o in output) / len(output)\navg_msg = sum(o[1] for o in output) / len(output)\nprint(avg_duration, avg_msg)\n```\n\n----------------------------------------\n\nTITLE: Example Server Address (Bash)\nDESCRIPTION: This snippet shows an example local server address (127.0.0.1:8000) that would be used to access the running Dillinger application, likely after deploying it via Docker as described previously in the Markdown content. Although not executable code, it's presented within a code block.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_11\n\nLANGUAGE: bash\nCODE:\n```\n127.0.0.1:8000\n```\n\n----------------------------------------\n\nTITLE: Python Streaming Example\nDESCRIPTION: Example showing how to stream results from a Gradio app using the Python client in 5 lines of code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/gradio_client/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/llm_stream\")\n\nfor result in client.submit(\"What's the best UI framework in Python?\"):\n    print(result)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/highlightedtext_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_series_nominal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/count_generator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Listing Python ML Dependencies\nDESCRIPTION: Lists required Python machine learning libraries - transformers for NLP tasks and PyTorch as the deep learning framework.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_english_german/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\ntransformers\\ntorch\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip\nDESCRIPTION: Installs the Gradio Python library using the pip package manager. This command is typically run in a shell or Jupyter notebook environment. The `-q` flag ensures a quiet installation with minimal output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Demonstrating Tool Use in Gradio Chatbot\nDESCRIPTION: Python code example showing how to display tool usage and intermediate steps in a Gradio chatbot using the new messages format with metadata.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/chatbot/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nimport time\n\ndef generate_response(history):\n    history.append(ChatMessage(role=\"user\", content=\"What is the weather in San Francisco right now?\"))\n    yield history\n    time.sleep(0.25)\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"In order to find the current weather in San Francisco, I will need to use my weather tool.\")\n                               )\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"API Error when connecting to weather service.\",\n                              metadata={\"title\": \"💥 Error using tool 'Weather'\"}))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"I will try again\",\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"Weather 72 degrees Fahrenheit with 20% chance of rain.\",\n                                metadata={\"title\": \"🛠️ Used tool 'Weather'\"}\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"Now that the API succeeded I can complete my task.\",\n                              ))\n    yield history\n    time.sleep(0.25)\n\n    history.append(ChatMessage(role=\"assistant\",\n                               content=\"It's a sunny day in San Francisco with a current temperature of 72 degrees Fahrenheit and a 20% chance of rain. Enjoy the weather!\",\n                              ))\n    yield history\n\n\nwith gr.Blocks() as demo:\n    chatbot  = gr.Chatbot(type=\"messages\")\n    button = gr.Button(\"Get San Francisco Weather\")\n    button.click(generate_response, chatbot, chatbot)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Transcribing Audio with Whisper on Groq - Python\nDESCRIPTION: This function sends audio files to the Groq-hosted Whisper model for speech-to-text transcription. It opens the provided 'file_name', sends it to the API, and parses the detailed JSON output using a helper. Dependencies include a configured Groq client, an audio file to transcribe, and error handling for API issues. Inputs are the client and file path, outputs are the processed transcription or an error message. Limitations: audio file must exist and be accessible, and the API key must be valid.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/06_automatic-voice-detection.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef transcribe_audio(client, file_name):\n    if file_name is None:\n        return None\n\n    try:\n        with open(file_name, \"rb\") as audio_file:\n            response = client.audio.transcriptions.with_raw_response.create(\n                model=\"whisper-large-v3-turbo\",\n                file=(\"audio.wav\", audio_file),\n                response_format=\"verbose_json\",\n            )\n            completion = process_whisper_response(response.parse())\n            return completion\n    except Exception as e:\n        print(f\"Error in transcription: {e}\")\n        return f\"Error in transcription: {str(e)}\"\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_4/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Importing Meta Component from Storybook in JavaScript\nDESCRIPTION: Imports the Meta component from Storybook's blocks package, which is used to define metadata for the Storybook page.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/storybook/Introduction.mdx#2025-04-23_snippet_0\n\nLANGUAGE: JavaScript\nCODE:\n```\nimport { Meta } from \"@storybook/blocks\";\n```\n\n----------------------------------------\n\nTITLE: Specifying Pandas Dependency\nDESCRIPTION: Lists pandas as a required Python package dependency for the project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\npandas\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_component_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Demo\nDESCRIPTION: This snippet installs the necessary libraries (Gradio and pandas) using pip. It's executed quietly to suppress output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_colorful/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas\n```\n\n----------------------------------------\n\nTITLE: Declaring LlamaIndex Python Package Dependency\nDESCRIPTION: This line specifies the `llama-index` Python package as a required dependency. This library is a data framework for building LLM applications, often used for retrieval-augmented generation (RAG) and managing external data sources with language models.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_llamaindex/requirements.txt#2025-04-23_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nllama-index\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This code snippet installs the Gradio library using pip. It's a prerequisite for running the webcam demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/webcam/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with pip in Python\nDESCRIPTION: Installs the Gradio library using pip, allowing for the creation of interactive machine learning web demos. The command should be run in a Python environment that has pip available. There are no required inputs or outputs; the dependency becomes available for later imports.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sound_alert/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_block-ui-test/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip, suppressing unnecessary output during installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/save_file_no_output/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: MacOS/Linux Install Commands\nDESCRIPTION: Shell commands for installing Gradio and its dependencies on Unix-based systems\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nbash scripts/install_gradio.sh\n```\n\n----------------------------------------\n\nTITLE: CDN Integration Example\nDESCRIPTION: Complete HTML example showing how to integrate and use the Gradio client via CDN for web projects.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <script type=\"module\">\n        import { Client } from \"https://cdn.jsdelivr.net/npm/@gradio/client/dist/index.min.js\";\n        const client = await Client.connect(\"abidlabs/en2fr\");\n        const result = await client.predict(\"/predict\", {\n            text: \"My name is Hannah\"\n        });\n        console.log(result);\n    </script>\n</head>\n</html>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode to enable creating interactive web interfaces for the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_nominal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/diff_texts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Up TailwindCSS Styles in Gradio Components\nDESCRIPTION: CSS file that imports TailwindCSS for use in Gradio custom components. This is imported into the Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_8\n\nLANGUAGE: css\nCODE:\n```\n@import \"tailwindcss\";\n```\n\n----------------------------------------\n\nTITLE: Package Version Declaration\nDESCRIPTION: Declares the version number for the current release\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.4.7\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip package manager in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Dependency Update Listing for @gradio/sketchbox in Markdown\nDESCRIPTION: This snippet lists the dependency updates for @gradio/sketchbox version 0.6.6. It includes updates to @gradio/statustracker, @gradio/atoms, @gradio/utils, and @gradio/column.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/sketchbox/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- @gradio/statustracker@0.10.9\n- @gradio/atoms@0.15.2\n- @gradio/utils@0.10.2\n- @gradio/column@0.2.0\n```\n\n----------------------------------------\n\nTITLE: Alternative Gradio Client Setup with Token\nDESCRIPTION: Alternative initialization of Gradio client using a Hugging Face token for private access\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client.duplicate(\"abidlabs/music-separation\", hf_token=YOUR_HF_TOKEN)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_selection/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Citation Reference for Gradio Academic Paper\nDESCRIPTION: BibTeX citation entry for the academic paper 'Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild' published in ICML HILL 2019.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/readme_template.md#2025-04-23_snippet_0\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{abid2019gradio,\n  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\n  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\n  journal = {arXiv preprint arXiv:1906.02569},\n  year = {2019},\n}\n```\n\n----------------------------------------\n\nTITLE: Defining MarkdownCode Component Properties in JavaScript\nDESCRIPTION: This snippet defines the properties for the MarkdownCode component, including options for chatbot mode, message content, HTML sanitization, LaTeX delimiters, markdown rendering, and line breaks.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let chatbot = true;\nexport let message: string;\nexport let sanitize_html = true;\nexport let latex_delimiters: {\n\tleft: string;\n\tright: string;\n\tdisplay: boolean;\n}[] = [];\nexport let render_markdown = true;\nexport let line_breaks = true;\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the data.py file from the Gradio GitHub repository which contains the dataset used in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_tables_stats/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_tables_stats/data.py\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample 3D Model Files using Wget\nDESCRIPTION: This Python snippet first imports the `os` module and creates a directory named `files`. It then uses the `wget` command (executed via `!`) to download various 3D model files (.obj, .glb, .gltf, .stl) and a text file from a specified GitHub repository into the newly created `files` directory. These files serve as examples for the Gradio interface defined later.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/model3D/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/Bunny.obj https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/Bunny.obj\n!wget -q -O files/Duck.glb https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/Duck.glb\n!wget -q -O files/Fox.gltf https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/Fox.gltf\n!wget -q -O files/face.obj https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/face.obj\n!wget -q -O files/sofia.stl https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/sofia.stl\n!wget -q -O files/source.txt https://github.com/gradio-app/gradio/raw/main/demo/model3D/files/source.txt\n```\n\n----------------------------------------\n\nTITLE: Basic Discord Bot Setup\nDESCRIPTION: Initial Discord bot implementation to test connectivity and basic functionality.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/06_creating-a-discord-bot-from-a-gradio-app.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# bot.py\nimport discord\n\nTOKEN = #PASTE YOUR DISCORD BOT TOKEN HERE\n\nclient = discord.Client()\n\n@client.event\nasync def on_ready():\n    print(f'{client.user} has connected to Discord!')\n\nclient.run(TOKEN)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with pip in Python\nDESCRIPTION: This code installs the Gradio library in a Python environment using pip with the quiet flag to suppress output. It is required before running any Gradio demos or interfaces. The cell should be executed at the start of a notebook or script to ensure Gradio is available for import.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_examples/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Version Headers in Markdown\nDESCRIPTION: Version numbers and change type headers used to organize the changelog entries.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n### Patch Changes\n\n## 0.0.11\n\n### Patch Changes\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator_blocks/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode, which is typically used in notebook environments.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_3/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Listing Python Package Dependencies\nDESCRIPTION: Lists required Python packages: vega_datasets for accessing common data visualization datasets, and pandas for data manipulation and analysis.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/line_plot/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nvega_datasets\npandas\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_soft/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Handling File Inputs in Python for Gradio\nDESCRIPTION: This function processes file inputs for Gradio, handling various file types including images, audio, video, and documents. It validates file types and sizes, and returns appropriate outputs.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir1/foo.txt#2025-04-23_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\ndef handle_file_upload(\n    file: Union[str, Dict, None],\n    file_types: List[str],\n    max_file_size: Optional[int] = None,\n) -> Union[Dict[str, str], Dict[str, Any], None]:\n    \"\"\"Handle file uploads for various types (image, audio, video, file).\"\"\"\n    if file is None:\n        return None\n    if isinstance(file, str):\n        return {\"name\": file, \"data\": None, \"size\": None, \"is_file\": False}\n    file_path = file.name\n    if max_file_size and os.path.getsize(file_path) > max_file_size:\n        raise ValueError(f\"File size too large. Maximum allowed size is {max_file_size} bytes.\")\n    if not any(file_path.endswith(file_type) for file_type in file_types):\n        raise ValueError(f\"Invalid file type. Expected: {', '.join(file_types)}\")\n    with open(file_path, \"rb\") as file_data:\n        if any(file_path.endswith(image_type) for image_type in ['.png', '.jpg', '.jpeg', '.gif']):\n            mime_type = mimetypes.guess_type(file_path)[0]\n            b64 = base64.b64encode(file_data.read()).decode('utf-8')\n            data = f\"data:{mime_type};base64,{b64}\"\n        elif file_path.endswith(('.wav', '.mp3')):\n            data = file_data.read()\n        elif file_path.endswith(('.mp4', '.avi', '.mov')):\n            data = file_data.read()\n        else:\n            data = file_data.read().decode('utf-8')\n    return {\n        \"name\": os.path.basename(file_path),\n        \"data\": data,\n        \"size\": os.path.getsize(file_path),\n        \"is_file\": True\n    }\n```\n\n----------------------------------------\n\nTITLE: Specifying Python Dependencies for a Machine Learning Project\nDESCRIPTION: This snippet lists two Python package dependencies: transformers from Hugging Face's GitHub repository and torchaudio. These packages are commonly used for natural language processing and audio processing in machine learning applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/same-person-or-different/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ngit+https://github.com/huggingface/transformers\ntorchaudio\n```\n\n----------------------------------------\n\nTITLE: Ensuring Correct Audio Translations in Gradio\nDESCRIPTION: Ensures that translations for audio components work correctly in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_11\n\nLANGUAGE: markdown\nCODE:\n```\n- [#5264](https://github.com/gradio-app/gradio/pull/5264) [`46a2b600`](https://github.com/gradio-app/gradio/commit/46a2b600a7ff030a9ea1560b882b3bf3ad266bbc) - ensure translations for audio work correctly. Thanks [@hannahblair](https://github.com/hannahblair)!\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip, which is necessary to run the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_hello/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Importing Pandas Library in Python\nDESCRIPTION: This code snippet imports the pandas library, making it available for use in the current Python script or module. Pandas is a popular library for data manipulation and analysis in Python.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/bar_plot_demo/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\npandas\n```\n\n----------------------------------------\n\nTITLE: Creating GPT-2 XL Gradio Interface\nDESCRIPTION: This code creates a Gradio interface for the GPT-2 XL model. It sets up the input textbox, title, and example prompts. The interface is loaded from Hugging Face and launched for user interaction.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gpt2_xl/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ntitle = \"gpt2-xl\"\n\nexamples = [\n    [\"The tower is 324 metres (1,063 ft) tall,\"],\n    [\"The Moon's orbit around Earth has\"],\n    [\"The smooth Borealis basin in the Northern Hemisphere covers 40%\"],\n]\n\ndemo = gr.load(\n    \"huggingface/gpt2-xl\",\n    inputs=gr.Textbox(lines=5, max_lines=6, label=\"Input Text\"),\n    title=title,\n    examples=examples,\n)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Package Dependencies Update\nDESCRIPTION: Update references to package dependencies with their respective commit hashes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- @gradio/icons@0.1.0\n- @gradio/utils@0.1.0\n- @gradio/atoms@0.1.1\n- @gradio/statustracker@0.1.1\n```\n\n----------------------------------------\n\nTITLE: Accessing Google Sheets Shareable Link - HTML (Private Example)\nDESCRIPTION: A second example of a Google Sheets shareable link, intended for use with the gspread authentication workflow for a private sheet. Used as an input in Python code and authentication setup. The URL format is the same as for public sheets.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/creating-a-realtime-dashboard-from-google-sheets.md#2025-04-23_snippet_6\n\nLANGUAGE: html\nCODE:\n```\nhttps://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Vega Datasets\nDESCRIPTION: Installs the required dependencies for the demo: Gradio for the UI components and vega_datasets for the sample data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatterplot_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio vega_datasets\n```\n\n----------------------------------------\n\nTITLE: Declaring OpenAI Python Package Dependency\nDESCRIPTION: This line specifies the `openai` Python package as a required dependency. Including this package allows the application to interact with OpenAI APIs for functionalities such as accessing GPT models.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_llamaindex/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nopenai\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: This snippet installs the Gradio Python package silently using pip, preparing the environment for running Gradio-based applications. No additional parameters are required beyond a working pip installation. The command should be run in a Python environment prior to executing Gradio scripts to ensure all dependencies are available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabs/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Pull Request Reference\nDESCRIPTION: Reference to pull request #5324 with commit hash and description.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/textbox/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n[#5324](https://github.com/gradio-app/gradio/pull/5324) [`31996c99`](https://github.com/gradio-app/gradio/commit/31996c991d6bfca8cef975eb8e3c9f61a7aced19)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_new_step_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Defining Temporary File Location Comment\nDESCRIPTION: Comment indicating the purpose of the directory for storing temporary files\nSOURCE: https://github.com/gradio-app/gradio/blob/main/test/tmp/tmp.txt#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# tmp files saved here\n```\n\n----------------------------------------\n\nTITLE: Importing CSS in Svelte Component for Gradio\nDESCRIPTION: Example of importing the TailwindCSS style file into a Svelte component for Gradio. Note that you must import the CSS file rather than using an @import in a style tag.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_9\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n[...]\nimport \"./style.css\";\n[...]\n</script>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NLTK dependencies with pip in Python\nDESCRIPTION: This snippet installs the required libraries 'gradio' and 'nltk' using pip. It is intended to be run in a Jupyter notebook or interactive Python environment where shell commands prefixed by '!' are supported. Installing these dependencies is necessary before running any code that uses Gradio for the UI or NLTK for sentiment analysis.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sentiment_analysis/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio nltk\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Index.svelte Component\nDESCRIPTION: A minimal implementation of the main Index.svelte component showing basic structure and prop handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_2\n\nLANGUAGE: svelte\nCODE:\n```\n<script lang=\"ts\">\n\timport type { LoadingStatus } from \"@gradio/statustracker\";\n    import { Block } from \"@gradio/atoms\";\n\timport { StatusTracker } from \"@gradio/statustracker\";\n\timport type { Gradio } from \"@gradio/utils\";\n\n\texport let gradio: Gradio<{\n\t\tevent_1: never;\n\t\tevent_2: never;\n\t}>;\n\n    export let value = \"\";\n\texport let elem_id = \"\";\n\texport let elem_classes: string[] = [];\n\texport let scale: number | null = null;\n\texport let min_width: number | undefined = undefined;\n\texport let loading_status: LoadingStatus | undefined = undefined;\n    export let mode: \"static\" | \"interactive\";\n</script>\n\n<Block\n\tvisible={true}\n\t{elem_id}\n\t{elem_classes}\n\t{scale}\n\t{min_width}\n\tallow_overflow={false}\n\tpadding={true}\n>\n\t{#if loading_status}\n\t\t<StatusTracker\n\t\t\tautoscroll={gradio.autoscroll}\n\t\t\ti18n={gradio.i18n}\n\t\t\t{...loading_status}\n\t\t/>\n\t{/if}\n    <p>{value}</p>\n</Block>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip with the quiet flag to reduce installation output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_form/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Displaying Version and Change Information in Markdown\nDESCRIPTION: This code snippet shows how version information, change descriptions, and related links are formatted in the changelog using Markdown syntax.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tooltip/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.2\n\n### Fixes\n\n- [#9163](https://github.com/gradio-app/gradio/pull/9163) [`2b6cbf2`](https://github.com/gradio-app/gradio/commit/2b6cbf25908e42cf027324e54ef2cc0baad11a91) - fix exports and generate types.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Implementing Fake GAN Image Generation with Gradio Interface\nDESCRIPTION: This code creates a Gradio interface for a fake image generation demo. It defines a function that randomly selects images from a predefined list and sets up a Gradio Blocks interface with a gallery and a generate button.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# This demo needs to be run from the repo folder.\n# python demo/fake_gan/run.py\nimport random\n\nimport gradio as gr\n\ndef fake_gan():\n    images = [\n        (random.choice(\n            [\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1151ce9f4b2043de0d2e3b7826127998.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-116b5e92936b766b7fdfc242649337f7.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1163530ca19b5cebe1b002b8ec67b6fc.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-1116395d6e6a6581eef8b8038f4c8e55.jpg\",\n                \"http://www.marketingtool.online/en/face-generator/img/faces/avatar-11319be65db395d0e8e6855d18ddcef0.jpg\",\n            ]\n        ), f\"label {i}\")\n        for i in range(3)\n    ]\n    return images\n\nwith gr.Blocks() as demo:\n    gallery = gr.Gallery(\n        label=\"Generated images\", show_label=False, elem_id=\"gallery\"\n    , columns=[3], rows=[1], object_fit=\"contain\", height=\"auto\")\n    btn = gr.Button(\"Generate images\", scale=0)\n\n    btn.click(fake_gan, None, gallery)\n\nif __name__ == \"__main__\":\n    demo.launch()\n```\n\n----------------------------------------\n\nTITLE: Configuring Flagging Mode\nDESCRIPTION: Controls the ability to flag inputs/outputs in the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_5\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_FLAGGING_MODE=\"never\"\n```\n\n----------------------------------------\n\nTITLE: BlockTitle Component Props Definition\nDESCRIPTION: Defines the available props for the BlockTitle component, which controls the display of a title with optional information tooltip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/atoms/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\n\texport let show_label = true;\n\texport let info: string | undefined = undefined;\n```\n\n----------------------------------------\n\nTITLE: Commit URLs in Markdown\nDESCRIPTION: Links to specific commit references in the Gradio repository used throughout the changelog.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/uploadbutton/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: markdown\nCODE:\n```\n[`4e62b8493`](https://github.com/gradio-app/gradio/commit/4e62b8493dfce50bafafe49f1a5deb929d822103)\n```\n\nLANGUAGE: markdown\nCODE:\n```\n[`796145e2c`](https://github.com/gradio-app/gradio/commit/796145e2c48c4087bec17f8ec0be4ceee47170cb)\n```\n\n----------------------------------------\n\nTITLE: Commit Hash Example\nDESCRIPTION: Example of a commit hash reference in the changelog, used for tracking specific changes in the codebase.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: markdown\nCODE:\n```\n`48eeea4eaab7e24168688e3c3fbafb30e4e78d51`\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in quiet mode, which is required for creating interactive interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: This snippet installs the Gradio package quietly using pip. It's a prerequisite for running the Gradio interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gpt2_xl_unified/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in package.json\nDESCRIPTION: Example of updating dependencies in a package.json file for a Gradio project. This shows the syntax for specifying exact versions of Gradio packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/plot/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: JSON\nCODE:\n```\n\"dependencies\": {\n  \"@gradio/atoms\": \"0.5.3\",\n  \"@gradio/icons\": \"0.3.3\",\n  \"@gradio/statustracker\": \"0.4.7\"\n}\n```\n\n----------------------------------------\n\nTITLE: Creating a New Svelte Project using create-svelte\nDESCRIPTION: Commands to create a new Svelte project either in the current directory or in a specified directory. These commands use npm to initialize a new project with the latest version of create-svelte.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/app/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# create a new project in the current directory\nnpm create svelte@latest\n\n# create a new project in my-app\nnpm create svelte@latest my-app\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: Installs the Gradio package using pip to allow usage of Gradio components in the environment. This step is required before importing or using Gradio functionality. No parameters; the output is an updated environment with Gradio available. Should be run in a notebook or shell prior to main application code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/slider_release/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Specifying NumPy Dependency\nDESCRIPTION: Declares NumPy as a required dependency for the project. This single-line requirement ensures that NumPy is installed when the project dependencies are installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/reverse_audio_2/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Markdown Code Block - Version Links\nDESCRIPTION: Shows a GitHub pull request link and commit reference for version 0.2.4 features.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/tootils/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#7345](https://github.com/gradio-app/gradio/pull/7345) [`561579d`](https://github.com/gradio-app/gradio/commit/561579d9b7b860c5cb3f8131e0dced0c8114463f)\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets using wget (Python/Shell)\nDESCRIPTION: This snippet downloads necessary files for the Gradio demo from a GitHub repository using `wget`. It first downloads a Python script (`cached_testcase.py`), creates a 'files' directory, and then downloads an image (`avatar.png`) and an audio file (`cantina.wav`) into that directory. These files are used as examples in the multimodal chat interface.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/test_chatinterface_multimodal_examples/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_multimodal_examples/cached_testcase.py\nos.mkdir('files')\n!wget -q -O files/avatar.png https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_multimodal_examples/files/avatar.png\n!wget -q -O files/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/test_chatinterface_multimodal_examples/files/cantina.wav\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip\nDESCRIPTION: This shell command uses pip, the Python package installer, to install the Gradio library. The `-q` flag ensures a quiet installation, suppressing most output. This step is a prerequisite for executing the subsequent Python code which relies on the Gradio library.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stt_or_tts/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Retrieving Results from Gradio API\nDESCRIPTION: Demonstrates how to fetch results using the event ID returned from the initial POST request.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -N https://abidlabs-en2fr.hf.space/call/predict/$EVENT_ID\n\n>> event: complete\n>> data: [\"Bonjour, mon ami.\"]\n```\n\n----------------------------------------\n\nTITLE: Starting Development Server\nDESCRIPTION: Command to start the development server from the website directory\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npnpm dev\n```\n\n----------------------------------------\n\nTITLE: Specifying NumPy Dependency\nDESCRIPTION: Simple package requirement specifying numpy as a dependency for the project. This indicates that numpy is a required package that needs to be installed.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Testing Gradio-Lite Release Build\nDESCRIPTION: Command to start a local server for testing the Gradio-Lite release build\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npython -m http.server --directory js/lite\n```\n\n----------------------------------------\n\nTITLE: Adding Dockerfile Instructions for HuggingFace Space\nDESCRIPTION: This snippet provides additional Dockerfile instructions needed for the HuggingFace Space to properly run the PDF component demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/07_pdf-component-example.md#2025-04-23_snippet_19\n\nLANGUAGE: dockerfile\nCODE:\n```\nRUN mkdir -p /tmp/cache/\nRUN chmod a+rwx -R /tmp/cache/\nRUN apt-get update && apt-get install -y poppler-utils tesseract-ocr\n\nENV TRANSFORMERS_CACHE=/tmp/cache/\n```\n\n----------------------------------------\n\nTITLE: Streaming from Gradio App in JavaScript\nDESCRIPTION: Example showing how to stream results from a Gradio app using the JavaScript client's submit method\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"gradio/llm_stream\")\nconst job = client.submit(\"/predict\", {\"text\": \"What's the best UI framework in Python?\"})\n\nfor await (const msg of job) console.log(msg.data)\n```\n\n----------------------------------------\n\nTITLE: MySQL Database Connection Setup\nDESCRIPTION: Example of creating a connection engine for MySQL database using SQLAlchemy.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/06_data-science-and-plots/04_connecting-to-a-database.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nengine = create_engine('mysql://username:password@host:port/database_name')\n```\n\n----------------------------------------\n\nTITLE: Building a Svelte Project for Production\nDESCRIPTION: Command to create a production-ready build of a Svelte application. The build can be previewed locally before deployment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/_spaces-test/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Extending Gradio Theme Core Sizing Using Size Objects - Python\nDESCRIPTION: Demonstrates theming with explicit Size objects for spacing and border radius using Gradio\\'s theme system. Custom Size objects (e.g., gr.themes.sizes.spacing_sm) are provided for fine-grained control. Integrate this within a 'with gr.Blocks ...' block. Requires Gradio, and all necessary size objects are imported via the 'gr' namespace.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Default(spacing_size=gr.themes.sizes.spacing_sm, radius_size=gr.themes.sizes.radius_none)) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Configuring Examples Cache Reset\nDESCRIPTION: Controls whether to reset examples cache on app start.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/04_additional-features/10_environment-variables.md#2025-04-23_snippet_18\n\nLANGUAGE: sh\nCODE:\n```\nexport GRADIO_RESET_EXAMPLES_CACHE=\"True\"\n```\n\n----------------------------------------\n\nTITLE: API Endpoint Inspection Response\nDESCRIPTION: Example JSON response showing the structure of API endpoints when inspecting a Gradio app.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_5\n\nLANGUAGE: json\nCODE:\n```\n{\n\t\"named_endpoints\": {\n\t\t\"/predict\": {\n\t\t\t\"parameters\": [\n\t\t\t\t{\n\t\t\t\t\t\"label\": \"text\",\n\t\t\t\t\t\"component\": \"Textbox\",\n\t\t\t\t\t\"type\": \"string\"\n\t\t\t\t}\n\t\t\t],\n\t\t\t\"returns\": [\n\t\t\t\t{\n\t\t\t\t\t\"label\": \"output\",\n\t\t\t\t\t\"component\": \"Textbox\",\n\t\t\t\t\t\"type\": \"string\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t},\n\t\"unnamed_endpoints\": {}\n}\n```\n\n----------------------------------------\n\nTITLE: Commit URL Example\nDESCRIPTION: Example of a pull request URL format used in the changelog for linking to specific changes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_9\n\nLANGUAGE: markdown\nCODE:\n```\n[#8477](https://github.com/gradio-app/gradio/pull/8477)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_sidebar/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Specifying NumPy Dependency\nDESCRIPTION: Lists NumPy as a required package dependency for the gradio-app project. The file uses standard pip requirements.txt format.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/generate_tone/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Cancelling Generator Jobs with Timeout in JavaScript\nDESCRIPTION: Shows how to cancel a generator job after a specified timeout period. This example connects to a generator endpoint, logs the data as it arrives, and cancels the job after 3 seconds.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/02_getting-started-with-the-js-client.md#2025-04-23_snippet_11\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst app = await Client.connect(\"gradio/count_generator\");\nconst job = app.submit(0, [9]);\n\nfor await (const message of job) {\n\tconsole.log(message.data);\n}\n\nsetTimeout(() => {\n\tjob.cancel();\n}, 3000);\n```\n\n----------------------------------------\n\nTITLE: Initializing LLM Agent with Gradio Tools in Python\nDESCRIPTION: Example showing how to initialize and use multiple Gradio tools with a Langchain agent, including Stable Diffusion and Image Captioning tools. Requires OpenAI API key as an environment variable.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/04_gradio-and-llm-agents.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nif not os.getenv(\"OPENAI_API_KEY\"):\n    raise ValueError(\"OPENAI_API_KEY must be set\")\n\nfrom langchain.agents import initialize_agent\nfrom langchain.llms import OpenAI\nfrom gradio_tools import (StableDiffusionTool, ImageCaptioningTool, StableDiffusionPromptGeneratorTool,\n                          TextToVideoTool)\n\nfrom langchain.memory import ConversationBufferMemory\n\nllm = OpenAI(temperature=0)\nmemory = ConversationBufferMemory(memory_key=\"chat_history\")\ntools = [StableDiffusionTool().langchain, ImageCaptioningTool().langchain,\n         StableDiffusionPromptGeneratorTool().langchain, TextToVideoTool().langchain]\n\n\nagent = initialize_agent(tools, llm, memory=memory, agent=\"conversational-react-description\", verbose=True)\noutput = agent.run(input=(\"Please create a photo of a dog riding a skateboard \"\n                          \"but improve my prompt prior to using an image generator.\"\n                          \"Please caption the generated image and create a video for it using the improved prompt.\"))\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode, which reduces the installation output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: TypeScript Interface for Gradio Status Updates\nDESCRIPTION: TypeScript interface defining the structure of status updates received during a submission.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_11\n\nLANGUAGE: typescript\nCODE:\n```\ninterface Status {\n\tqueue: boolean;\n\tcode?: string;\n\tsuccess?: boolean;\n\tstage: \"pending\" | \"error\" | \"complete\" | \"generating\";\n\tsize?: number;\n\tposition?: number;\n\teta?: number;\n\tmessage?: string;\n\tprogress_data?: Array<{\n\t\tprogress: number | null;\n\t\tindex: number | null;\n\t\tlength: number | null;\n\t\tunit: string | null;\n\t\tdesc: string | null;\n\t}>;\n\ttime?: Date;\n}\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Markdown Components\nDESCRIPTION: This snippet imports the BaseMarkdown, MarkdownCode, and BaseExample components from the @gradio/markdown package. These components are used for rendering various types of Markdown content in Gradio applications.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseMarkdown, MarkdownCode, BaseExample } from `@gradio/markdown`;\n</script>\n```\n\n----------------------------------------\n\nTITLE: Creating a Private Gradio Client with Hugging Face Token\nDESCRIPTION: Alternative code that creates a private duplicate of the music separation Space using a Hugging Face token, which can help bypass queues for faster processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client.duplicate(\"abidlabs/music-separation\", hf_token=YOUR_HF_TOKEN)\n```\n\n----------------------------------------\n\nTITLE: Customizing Gradio Theme Fonts with GoogleFont - Python\nDESCRIPTION: Shows how to set the primary font for a Gradio app using a list of fonts including GoogleFont instances. The example sets 'font' to use 'Inconsolata' from Google Fonts, with fallbacks to Arial and a generic sans-serif. For use within any Gradio Blocks context. Requires Gradio and internet access for downloading Google Fonts. The font list increases flexibility and robust font selection.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nwith gr.Blocks(theme=gr.themes.Default(font=[gr.themes.GoogleFont(\\\"Inconsolata\\\"), \\\"Arial\\\", \\\"sans-serif\\\"])) as demo:\n    ...\n\n```\n\n----------------------------------------\n\nTITLE: Renaming Component Directory Command\nDESCRIPTION: Bash command to rename the component directory structure.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/03_configuration.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmv backend/gradio_mytextbox backend/supertextbox\n```\n\n----------------------------------------\n\nTITLE: Getting Prediction Results with curl\nDESCRIPTION: Makes a GET request to stream the results of a prediction using the event ID. The -N flag enables streaming of the response.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_8\n\nLANGUAGE: bash\nCODE:\n```\n$ curl -N $URL/call/$API_NAME/$EVENT_ID\n```\n\n----------------------------------------\n\nTITLE: Setting Maximum File Upload Size in Gradio (Python)\nDESCRIPTION: This Python code snippet demonstrates how to set a limit on the size of files uploaded through a Gradio interface. It utilizes the `max_file_size` parameter within the `launch()` method, showing two ways to specify the limit: using a string representation (e.g., '5mb') or programmatically using `gr.FileSize`. This feature was introduced in Gradio version 0.9.0.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/chatbot/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio with pip in Python\nDESCRIPTION: This snippet installs the Gradio library using pip, enabling access to all its features for building interactive user interfaces in Python. This is a prerequisite for running subsequent Gradio code. Run this command in a Python environment or notebook to ensure Gradio is available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/on_listener_live/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Files\nDESCRIPTION: Creates a 'files' directory and downloads sample audio, image, and video files for the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/change_vs_input/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/cantina.wav https://github.com/gradio-app/gradio/raw/main/demo/change_vs_input/files/cantina.wav\n!wget -q -O files/lion.jpg https://github.com/gradio-app/gradio/raw/main/demo/change_vs_input/files/lion.jpg\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/change_vs_input/files/world.mp4\n```\n\n----------------------------------------\n\nTITLE: Specifying NumPy Dependency\nDESCRIPTION: A plain text specification of the NumPy package as a dependency. This format is typically used in requirements.txt files or similar dependency declaration files in Python projects.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flipper/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Markdown Component Style Documentation\nDESCRIPTION: Style configuration tables for Gradio UI components showing property names, types, and descriptions for customizing appearance of interface elements.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/style.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n| name        | type                                 | description                    |\n| ----------- | ------------------------------------ | ------------------------------ |\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of text input          |\n| `border`    | `bool` or `(bool, bool, bool, bool)` | borders of text input          |\n| `container` | `bool`                               | show or hide the container box |\n```\n\n----------------------------------------\n\nTITLE: BaseExample Component Properties in Gradio\nDESCRIPTION: Defines the properties for the BaseExample component which is used to display example data entries in Gradio interfaces. Properties include value data, display type, and selection state.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/README.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nexport let gradio: Gradio;\nexport let value: (string | number)[][] | string;\nexport let type: \"gallery\" | \"table\";\nexport let selected = false;\nexport let index: number;\n```\n\n----------------------------------------\n\nTITLE: Referencing Core Color Variables in Gradio Themes in Python\nDESCRIPTION: This snippet demonstrates how to reference core color variables in a Gradio theme using the asterisk prefix. It sets button background colors to use primary color palette values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/theming-guide.md#2025-04-23_snippet_8\n\nLANGUAGE: python\nCODE:\n```\ntheme = gr.themes.Default(primary_hue=\"blue\").set(\n    button_primary_background_fill=\"*primary_200\",\n    button_primary_background_fill_hover=\"*primary_300\",\n)\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Gradio File Component\nDESCRIPTION: Updates the @gradio/client and @gradio/upload dependencies for the Gradio File component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_14\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.0.3\n\n### Patch Changes\n\n- Updated dependencies [[`61129052`](https://github.com/gradio-app/gradio/commit/61129052ed1391a75c825c891d57fa0ad6c09fc8), [`667875b2`](https://github.com/gradio-app/gradio/commit/667875b2441753e74d25bd9d3c8adedd8ede11cd), [`67265a58`](https://github.com/gradio-app/gradio/commit/67265a58027ef1f9e4c0eb849a532f72eaebde48), [`8b4eb8ca`](https://github.com/gradio-app/gradio/commit/8b4eb8cac9ea07bde31b44e2006ca2b7b5f4de36)]:\n  - @gradio/client@0.2.0\n  - @gradio/upload@0.0.3\n```\n\n----------------------------------------\n\nTITLE: Bash Command for Running Gradio in Reload Mode\nDESCRIPTION: Terminal command to run a Gradio application in reload mode, which automatically detects file changes and refreshes the application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/developing-faster-with-reload-mode.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ngradio run.py\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Hugging Face Hub - Shell\nDESCRIPTION: Installs the required Python packages for the application: Gradio for building the user interface and Hugging Face Hub for API authentication and user info queries. Run this command in your terminal or notebook before running the main application. No parameters are needed; outputs are pip install logs or errors if not run in a shell environment.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/login_with_huggingface/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio huggingface_hub \n```\n\n----------------------------------------\n\nTITLE: Importing BaseJSON Component in HTML (JavaScript)\nDESCRIPTION: This snippet shows how to import the BaseJSON component from the @gradio/json package within a script tag in an HTML document. It is intended for use in environments that support JavaScript ES module imports, such as frameworks like Svelte. The purpose is to prepare the BaseJSON component for use in the application, and it requires the @gradio/json package to be installed and available. No inputs or outputs are defined by this snippet itself; it establishes a dependency for later use.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\\n\\timport { BaseJSON } from \"@gradio/json\";\\n</script>\n```\n\n----------------------------------------\n\nTITLE: Building Gradio UI for Production\nDESCRIPTION: Command to build the production-ready version of the Gradio UI, creating necessary files in the js/app/public and gradio/templates/frontend directories.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npnpm build\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies for Gradio\nDESCRIPTION: A requirements specification file that lists all required Python packages with their version constraints. Includes conditional dependencies based on Python version and platform, particularly handling emscripten platform and Python 3.13+ compatibility.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: pip\nCODE:\n```\naiofiles>=22.0,<25.0\nanyio>=3.0,<5.0\naudioop-lts<1.0; python_version >= \"3.13\"\nfastapi>=0.115.2,<1.0\nffmpy\ngroovy~=0.1\ngradio_client==1.8.0\nhttpx>=0.24.1\nhuggingface_hub>=0.28.1\nJinja2<4.0\nmarkupsafe>=2.0,<4.0\nnumpy>=1.0,<3.0\norjson~=3.0\npackaging\npandas>=1.0,<3.0\npillow>=8.0,<12.0\npydantic>=2.0,<2.12\npython-multipart>=0.0.18\npydub\npyyaml>=5.0,<7.0\nruff>=0.9.3; sys.platform != 'emscripten'\nsafehttpx>=0.1.6,<0.2.0\nsemantic_version~=2.0\nstarlette>=0.40.0,<1.0; sys.platform != 'emscripten'\ntomlkit>=0.12.0,<0.14.0\ntyper>=0.12,<1.0; sys.platform != 'emscripten'\ntyping_extensions~=4.0\nurllib3~=2.0; sys.platform == 'emscripten'\nuvicorn>=0.14.0; sys.platform != 'emscripten'\n```\n\n----------------------------------------\n\nTITLE: Fixing File Upload in Gradio File Component\nDESCRIPTION: Ensures that the File component in Gradio uploads files to the server correctly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n### Fixes\n\n- [#5253](https://github.com/gradio-app/gradio/pull/5253) [`ddac7e4d`](https://github.com/gradio-app/gradio/commit/ddac7e4d0f55c3bdc6c3e9a9e24588b2563e4049) - Ensure File component uploads files to the server. Thanks [@pngwn](https://github.com/pngwn)!\n```\n\n----------------------------------------\n\nTITLE: Downloading Auxiliary Data Files for Gradio Demo - Python\nDESCRIPTION: Downloads the 'data_setups.py' script from the specified repository using wget. This file contains custom preprocessing functions crucial for model inference. Must be run in an environment with wget and internet access; required prior to loading and preprocessing any audio data.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/musical_instrument_identification/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/musical_instrument_identification/data_setups.py\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple C++ Program for Addition\nDESCRIPTION: A basic C++ program (`add.cpp`) that reads two double-precision numbers from standard input using `std::cin`, calculates their sum, and prints the result to standard output using `std::cout`. This program is designed to be executed externally, receiving input via stdin and providing output via stdout.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_0\n\nLANGUAGE: cpp\nCODE:\n```\n// add.cpp\n#include <iostream>\n\nint main() {\n    double a, b;\n    std::cin >> a >> b;\n    std::cout << a + b << std::endl;\n    return 0;\n}\n```\n\n----------------------------------------\n\nTITLE: Configuring Max File Size in Gradio Interface (Python)\nDESCRIPTION: This Python snippet demonstrates how to limit the maximum file size for uploads in a Gradio interface by providing the max_file_size parameter to the launch() method. It requires the gradio Python package and optionally uses gr.FileSize for specifying byte sizes programmatically. Parameters include max_file_size (either as a string like '5mb' or as an integer in bytes). Input is an image, and the output is an image; files larger than the set limit are rejected. This code is compatible with Gradio versions supporting the max_file_size parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/colorpicker/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\n\ndemo.launch(max_file_size=\"5mb\")\n# or\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Displaying GitHub Pull Request Reference in Markdown\nDESCRIPTION: This snippet shows how to format a reference to a GitHub pull request in a changelog using Markdown. It includes the PR number, link, and commit hash.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/sidebar/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n[#10694](https://github.com/gradio-app/gradio/pull/10694) [`16244f3`](https://github.com/gradio-app/gradio/commit/16244f3c1cb1a65ac1f719142f8fab67512fbb25) - Event Listeners in gradio sketch.\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and NumPy Dependencies via Pip\nDESCRIPTION: Installs the necessary Python libraries 'gradio' and 'numpy' using the pip package installer. The '-q' flag ensures a quiet installation with minimal output. This step is required before running the main application code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sepia_filter/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n!pip install -q gradio numpy \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and OpenAI Dependencies in Python\nDESCRIPTION: This snippet installs the gradio and openai Python packages, with the openai version required to be at least 1.0.0. It should be run in a shell or notebook environment before running the main application to ensure all dependencies are available. No inputs or outputs except for package installation; must be run prior to importing gradio or openai.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hyperbolic/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio openai>=1.0.0 \n```\n\n----------------------------------------\n\nTITLE: Importing Libraries and Configuring Gemini Client in Python\nDESCRIPTION: Imports the Gradio and Google Generative AI libraries necessary for the chatbot. It configures the Gemini API using a placeholder API key (replace \"your-gemini-api-key\" with an actual key) and initializes the specific \"gemini-2.0-flash-thinking-exp-1219\" model for use in the application. Requires `gradio` and `google-generativeai` packages to be installed and a valid Google Gemini API key.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/03_agents-and-tool-usage.md#2025-04-23_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nfrom gradio import ChatMessage\nfrom typing import Iterator\nimport google.generativeai as genai\n\ngenai.configure(api_key=\"your-gemini-api-key\")\nmodel = genai.GenerativeModel(\"gemini-2.0-flash-thinking-exp-1219\")\n```\n\n----------------------------------------\n\nTITLE: Stripping Dangling Svelte Imports in Gradio\nDESCRIPTION: This update removes dangling Svelte imports from the Gradio codebase, likely improving the build process and reducing unnecessary code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: JavaScript\nCODE:\n```\n// Code not provided in the changelog\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Assets\nDESCRIPTION: Creates a files directory and downloads necessary demo assets including audio, avatar, text, and video files from the Gradio repository\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components_simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/audio.wav https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components_simple/files/audio.wav\n!wget -q -O files/avatar.png https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components_simple/files/avatar.png\n!wget -q -O files/sample.txt https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components_simple/files/sample.txt\n!wget -q -O files/world.mp4 https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components_simple/files/world.mp4\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/chatbot_core_components_simple/messages_testcase.py\n```\n\n----------------------------------------\n\nTITLE: Defining Python Project Dependencies\nDESCRIPTION: This text lists required Python packages: 'scipy' for scientific and technical computing, 'numpy' for numerical operations (arrays, matrices), and 'matplotlib' for creating static, animated, and interactive visualizations. This format, with one package per line, is standard for `requirements.txt` files used by pip to install project dependencies.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/main_note/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nscipy\nnumpy\nmatplotlib\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Data for the Demo\nDESCRIPTION: Downloads the necessary data file from the Gradio GitHub repository for use in the demo application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_datetimerange/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_datetimerange/data.py\n```\n\n----------------------------------------\n\nTITLE: Updating Dependencies in Markdown Changelog\nDESCRIPTION: This snippet shows how dependencies are updated in a markdown changelog entry. It uses GitHub-style links to reference commit hashes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/json/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n- Updated dependencies [[`5727b92`](https://github.com/gradio-app/gradio/commit/5727b92abc8a00a675bfc0a921b38de771af947b), [`c60ad4d`](https://github.com/gradio-app/gradio/commit/c60ad4d34ab5b56a89bf6796822977e51e7a4a32)]:\n  - @gradio/utils@0.2.1\n  - @gradio/atoms@0.5.0\n  - @gradio/statustracker@0.4.4\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Data File\nDESCRIPTION: Downloads the data.py file from the Gradio repository, which contains the dataset needed for the scatter plot demonstration.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_scatter_nominal/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_scatter_nominal/data.py\n```\n\n----------------------------------------\n\nTITLE: Importing Gradio Markdown Components in Svelte\nDESCRIPTION: This snippet shows how to import the BaseMarkdown, MarkdownCode, and BaseExample components from the @gradio/markdown package in a Svelte component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n    import { BaseMarkdown, MarkdownCode, BaseExample } from `@gradio/markdown`;\n</script>\n```\n\n----------------------------------------\n\nTITLE: Setting Up NPM Package Previews\nDESCRIPTION: Implementation of NPM previews for all Gradio packages including Annotated Image in version 0.7.1, as part of pull request #9118.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/annotatedimage/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: markdown\nCODE:\n```\n### Features\n\n- [#9118](https://github.com/gradio-app/gradio/pull/9118) [`e1c404d`](https://github.com/gradio-app/gradio/commit/e1c404da1143fb52b659d03e028bdba1badf443d) - setup npm-previews of all packages.  Thanks @pngwn!\n```\n\n----------------------------------------\n\nTITLE: Downloading Example Images\nDESCRIPTION: Creates an examples directory and downloads sample images and configuration files from the Gradio demo repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/depth_estimation/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.mkdir('examples')\n!wget -q -O examples/1-jonathan-borba-CgWTqYxHEkg-unsplash.jpg https://github.com/gradio-app/gradio/raw/main/demo/depth_estimation/examples/1-jonathan-borba-CgWTqYxHEkg-unsplash.jpg\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/depth_estimation/packages.txt\n```\n\n----------------------------------------\n\nTITLE: Creating a Basic Calculator Interface with Flagging in Python\nDESCRIPTION: This code creates a basic calculator interface with Gradio that allows users to manually flag examples. The calculator can perform addition, subtraction, multiplication, and division operations between two numbers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/07_other-tutorials/using-flagging.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\n\ndef calculator(num1, operation, num2):\n    if operation == \"add\":\n        return num1 + num2\n    elif operation == \"subtract\":\n        return num1 - num2\n    elif operation == \"multiply\":\n        return num1 * num2\n    elif operation == \"divide\":\n        return num1 / num2\n\n\niface = gr.Interface(\n    calculator,\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n    \"number\",\n    allow_flagging=\"manual\"\n)\n\niface.launch()\n```\n\n----------------------------------------\n\nTITLE: Compiling the C++ Addition Program using g++\nDESCRIPTION: A Bash command that utilizes the g++ compiler to compile the `add.cpp` source file. The `-o add` flag specifies that the output executable file should be named `add`. This compiled executable is required by the accompanying Python script to run the C++ logic via `subprocess`.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-gradio-in-other-programming-languages.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ng++ -o add add.cpp\n```\n\n----------------------------------------\n\nTITLE: Configuring Gradio Demo Interface in Python\nDESCRIPTION: This code snippet sets up a Gradio interface for a demo application. It defines UI components including text inputs, buttons, and image displays. The interface is configured to handle text generation and image processing functionalities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir3/dir4/dir_4_foo.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Gradio Demo\")\n    with gr.Tab(\"Text\"):\n        text_input = gr.Textbox(label=\"Input\")\n        text_output = gr.Textbox(label=\"Output\")\n        text_button = gr.Button(\"Generate\")\n    \n    with gr.Tab(\"Image\"):\n        image_input = gr.Image()\n        image_output = gr.Image()\n        image_button = gr.Button(\"Process\")\n\n    text_button.click(generate_text, inputs=text_input, outputs=text_output)\n    image_button.click(process_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Flagging in Gradio Blocks (Python - Placeholder)\nDESCRIPTION: This placeholder represents the concept of implementing flagging within a `gradio.Blocks` application. It requires manually setting up a `FlaggingCallback` instance (e.g., `CSVLogger`) using its `.setup()` method and then calling its `.flag()` method within a button's event listener, passing the relevant component values as arguments.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n$code_blocks_flag\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Image\nDESCRIPTION: Downloads a sample cheetah image from the Gradio demo repository for use in the image editor.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_many/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image_editor_many/cheetah.jpg\n```\n\n----------------------------------------\n\nTITLE: Installing Dependencies\nDESCRIPTION: Required package installations for the video object detection system\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/03_object-detection-from-video.md#2025-04-23_snippet_0\n\nLANGUAGE: text\nCODE:\n```\nopencv-python\ntorch\ntransformers>=4.43.0\nspaces\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Images\nDESCRIPTION: Creates an images directory and downloads sample images (cheetah, lion, and logo) from the Gradio demo repository\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod_default_image/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('images')\n!wget -q -O images/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_mod_default_image/images/cheetah1.jpg\n!wget -q -O images/lion.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_mod_default_image/images/lion.jpg\n!wget -q -O images/logo.png https://github.com/gradio-app/gradio/raw/main/demo/image_mod_default_image/images/logo.png\n```\n\n----------------------------------------\n\nTITLE: Displaying Directory Structure for Sepia Interface Flagging\nDESCRIPTION: Illustrates the directory structure created when flagging is used in a sepia image processing interface. It includes a logs.csv file and separate folders for input and output images.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/02_building-interfaces/02_flagging.md#2025-04-23_snippet_2\n\nLANGUAGE: text\nCODE:\n```\n+-- sepia.py\n+-- flagged/\n|   +-- logs.csv\n|   +-- im/\n|   |   +-- 0.png\n|   |   +-- 1.png\n|   +-- Output/\n|   |   +-- 0.png\n|   |   +-- 1.png\n```\n\n----------------------------------------\n\nTITLE: Building Custom Component\nDESCRIPTION: Command to build the custom component package, creating distribution files in the dist/ directory.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/01_custom-components-in-five-minutes.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\ngradio cc build\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image for Demo\nDESCRIPTION: This code creates a 'files' directory and downloads a sample cheetah image from the Gradio GitHub repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_joined/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('files')\n!wget -q -O files/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/blocks_joined/files/cheetah1.jpg\n```\n\n----------------------------------------\n\nTITLE: JavaScript Function using jQuery Facebox\nDESCRIPTION: This JavaScript snippet defines a function `fancyAlert` that takes one argument. If the argument is truthy, it uses jQuery's Facebox plugin (`$.facebox`) to display the content of an HTML element with the ID 'foo' in a modal dialog. This snippet is likely part of the example Markdown content.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_example/run.ipynb#2025-04-23_snippet_13\n\nLANGUAGE: javascript\nCODE:\n```\nfunction fancyAlert(arg) {\n    if(arg) {\n        $.facebox({div:'#foo'})\n    }\n}\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip package manager in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Pandas Dependencies - Python\nDESCRIPTION: Installs the required Python packages for the demo, specifically Gradio for UI components and pandas for data manipulation. Requires a Python environment with pip available. Run this in a Jupyter environment or notebook cell to prepare prerequisites for the rest of the code. Outputs no data directly.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/mini_leaderboard/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n```python\\n!pip install -q gradio pandas \\n```\n```\n\n----------------------------------------\n\nTITLE: Example CSV Log for Gradio Flagging with File Data (CSV)\nDESCRIPTION: Shows the format and example content of 'logs.csv' when flagging interfaces with file components. The CSV stores the relative paths to the saved files within the 'flagged' directory structure, along with a timestamp.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/using-flagging.md#2025-04-23_snippet_4\n\nLANGUAGE: csv\nCODE:\n```\nim,Output timestamp\nim/0.png,Output/0.png,2022-02-04 19:49:58.026963\nim/1.png,Output/1.png,2022-02-02 10:40:51.093412\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image for Demo\nDESCRIPTION: Downloads a sample lion image from the Gradio GitHub repository for use in the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_inputs/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/blocks_inputs/lion.jpg\n```\n\n----------------------------------------\n\nTITLE: Downloading Demo Images\nDESCRIPTION: Creates an images directory and downloads sample images from the Gradio GitHub repository for demonstration purposes.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\nos.mkdir('images')\n!wget -q -O images/cheetah1.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_mod/images/cheetah1.jpg\n!wget -q -O images/lion.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_mod/images/lion.jpg\n!wget -q -O images/logo.png https://github.com/gradio-app/gradio/raw/main/demo/image_mod/images/logo.png\n!wget -q -O images/tower.jpg https://github.com/gradio-app/gradio/raw/main/demo/image_mod/images/tower.jpg\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for CI/CD Pipeline\nDESCRIPTION: A detailed markdown document explaining the Gradio project's CI/CD pipeline including quality checks, deployment processes, and versioning strategy. Contains configuration details and workflow explanations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/ci.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Continous Integration\n\nThe CI for Gradio uses GitHub Actions and almost all of the configuration to run the CI exists within the repo.\n\nThe two cardinal rules that we have for CI are that:\n\n- CI should run on _all_ pull requests, whether those PRs are made from forks or from a branch within the repo.\n- These runs must be secure and _never_ leak any secrets, even if the run needs to have access to secrets in order to run successfully.\n\nMore information on how we achieve this can be found in the [architecture section of this document](#architecture).\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/button_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Button Component Feature Example (For Lite Mode)\nDESCRIPTION: Code example showing how the Button component and Blocks.serve_static_file were fixed to work with Gradio Lite mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/button/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10594](https://github.com/gradio-app/gradio/pull/10594) [`f0e4fd0`](https://github.com/gradio-app/gradio/commit/f0e4fd0522dd0f02701e0c4d3e694f6e6198db9d) - Fix `Blocks.serve_static_file` and `Button.svelte` to work on Lite.\n```\n\n----------------------------------------\n\nTITLE: Adding Mermaid.js Support in Markdown Component\nDESCRIPTION: Adds support for mermaid.js diagrams in the Markdown component and other components that use Markdown like gr.Chatbot.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10854](https://github.com/gradio-app/gradio/pull/10854) [`1649b00`](https://github.com/gradio-app/gradio/commit/1649b0038482402d7f0ccdbf86ba65d82b4a12c9) - Add support for `mermaid.js` in `Markdown` component (as well as components like `gr.Chatbot` that use Markdown).\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip\nDESCRIPTION: This snippet uses the `pip` command, often executed within a Jupyter Notebook or similar environment (indicated by the `!`), to quietly install the Gradio library (`-q` flag suppresses output). This installation is a prerequisite for using Gradio components.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/radio_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Adding SVG Tags Support in Markdown\nDESCRIPTION: Fix to add SVG tags for markdown when allow_tags=True is set. This enhances the flexibility of the Markdown component.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- [#11010](https://github.com/gradio-app/gradio/pull/11010) [`9219e62`](https://github.com/gradio-app/gradio/commit/9219e62cd21243fd9f5abecbe991e3b29039c76e) - fix: add svg tags for markdown when `allow_tags=True`.\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's executed quietly (-q flag) to reduce output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_1/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Image\nDESCRIPTION: Downloads a sample cheetah image from the Gradio demo repository using wget\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image-simple/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/image-simple/cheetah.jpg\n```\n\n----------------------------------------\n\nTITLE: Importing and Using Gradio Button Component in Svelte\nDESCRIPTION: This snippet demonstrates how to import the Button component from the @gradio/button package and use it in a Svelte component. It shows the basic structure of a button element with type, href attribute, and click event handling.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/accordion/README.md#2025-04-23_snippet_0\n\nLANGUAGE: html\nCODE:\n```\n<script>\n\timport { Button } from \"@gradio/button\";\n</script>\n\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\n\tcontent\n</button>\n```\n\n----------------------------------------\n\nTITLE: Launching Gradio Interface for Interactive Dashboard\nDESCRIPTION: This snippet creates and launches the Gradio interface. It sets up dropdown components for library and metric selection, and uses the plot function to generate the output graph.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/DESCRIPTION.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndemo = gr.Interface(\n    plot,\n    [\n        gr.Dropdown(choices=libraries, label=\"Select a library\"),\n        gr.Dropdown(choices=metrics, label=\"Select a metric\")\n    ],\n    gr.Plot(),\n    title=\"Python Library Stats\",\n    description=\"Select a library and a metric to plot over time.\",\n)\n\ndemo.launch()\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the required Gradio and NumPy packages using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/gallery_selections/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio numpy\n```\n\n----------------------------------------\n\nTITLE: Downloading Sample Data for Gradio Demo\nDESCRIPTION: Downloads the necessary data file from the Gradio GitHub repository for use in the demo. The data file contains a DataFrame with height and weight values.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_aggregate_quantitative/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n# Downloading files from the demo repo\nimport os\n!wget -q https://github.com/gradio-app/gradio/raw/main/demo/plot_guide_aggregate_quantitative/data.py\n```\n\n----------------------------------------\n\nTITLE: Setting Up Example Files\nDESCRIPTION: Creates an examples directory and downloads a sample CSV file from the Gradio repository.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/calculator/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport os\nos.mkdir('examples')\n!wget -q -O examples/log.csv https://github.com/gradio-app/gradio/raw/main/demo/calculator/examples/log.csv\n```\n\n----------------------------------------\n\nTITLE: Adding allow_tags Feature to Chatbot\nDESCRIPTION: Feature addition to include an allow_tags option in the Chatbot component. This allows for more flexible content rendering in chat interfaces.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/markdown-code/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: markdown\nCODE:\n```\n- [#10507](https://github.com/gradio-app/gradio/pull/10507) [`3748e4c`](https://github.com/gradio-app/gradio/commit/3748e4c902683ff406fdd246fa8c07dbbbed3ad5) - Chatbot `allow_tags`.\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Using pip in Python\nDESCRIPTION: This code snippet installs the Gradio library using pip to prepare the Python environment for building web-based UIs. The required dependency is 'gradio', and installation should be run in a Jupyter, Google Colab, or local terminal. No code parameters or outputs are involved, but successful installation is a prerequisite for running Gradio apps.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/slider_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Translation Demo\nDESCRIPTION: This snippet installs the necessary Python libraries (gradio, transformers, and torch) using pip. These libraries are required for creating the translation interface and performing the translation task.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/english_translator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio transformers torch\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip in Python\nDESCRIPTION: Installs the Gradio library using pip. This is a prerequisite dependency for running any Gradio-based application. No parameters or outputs—run once before importing Gradio, and ensure network access is available.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tax_calculator/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Implementing Retrying Assertions in Playwright Tests\nDESCRIPTION: Demonstrates how to use Playwright's retrying assertions with a checkbox example. Shows both the retrying toBeChecked method with a configurable timeout and the non-retrying isChecked method.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\n// 5 seconds\nawait expect(page.getByTestId('checkbox')).toBeChecked({timeout?: 5000});\n```\n\nLANGUAGE: javascript\nCODE:\n```\nawait expect(page.getByTestId(\"checkbox\").isChecked());\n```\n\n----------------------------------------\n\nTITLE: Activating a Virtual Environment on MacOS/Linux using Bash\nDESCRIPTION: Executes the activate script located within the `bin` directory of the `gradio-env` virtual environment using the `source` command to activate it in the current MacOS/Linux terminal session. This modifies the shell's environment variables to use the virtual environment's resources.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nsource gradio-env/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Embedding Gradio App in Websites\nDESCRIPTION: HTML code to embed a Gradio demo from Hugging Face Spaces into any website or documentation. This allows users to interact with the model directly from external sites.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md#2025-04-23_snippet_5\n\nLANGUAGE: html\nCODE:\n```\n<gradio-app space=\"akhaliq/JoJoGAN\"> <gradio-app>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/html_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using pip\nDESCRIPTION: This snippet uses the `pip` package installer to install the `gradio` library. The `-q` flag ensures the installation runs quietly, suppressing most output. This step is necessary to make the Gradio library available for the subsequent Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/streaming_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Creating a new Svelte project with create-svelte\nDESCRIPTION: Commands to create a new Svelte project either in the current directory or in a specified directory. Uses npm create svelte@latest to initialize the project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/component-test/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# create a new project in the current directory\nnpm create svelte@latest\n\n# create a new project in my-app\nnpm create svelte@latest my-app\n```\n\n----------------------------------------\n\nTITLE: Automatically Fixing Code Format Issues\nDESCRIPTION: Command to automatically fix code formatting issues using Prettier, ensuring consistent style across the codebase.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npnpm format:write\n```\n\n----------------------------------------\n\nTITLE: Creating Markdown-based Svelte Component with mdsvex\nDESCRIPTION: Example of a Markdown-based Svelte component created using mdsvex in a .svx file. This demonstrates how to combine Markdown with Svelte script and components in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/08_custom-components/05_frontend.md#2025-04-23_snippet_12\n\nLANGUAGE: markdown\nCODE:\n```\n<!-- HelloWorld.svx -->\n\n<script lang=\"ts\">\n    import { Block } from \"@gradio/atoms\";\n\n    export let title = \"Hello World\";\n</script>\n\n<Block label=\"Hello World\">\n\n# {title}\n\nThis is a markdown file.\n\n</Block>\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: Installs the Gradio library quietly using pip. This is a dependency installation step required before importing and using Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_essay/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies with pip\nDESCRIPTION: Command to install the necessary Python packages: gradio_client, fastapi, and uvicorn\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install gradio_client fastapi uvicorn\n```\n\n----------------------------------------\n\nTITLE: Querying Job Status with Python Gradio Client\nDESCRIPTION: Example showing how to monitor the queue position of a submitted job using the Gradio client library. Demonstrates creating a client connection and checking job status in a loop.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/python/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"gradio/diffusion_model\")\n\njob = client.submit(\"A cute cat\")\nwhile not job.done():\n    status = job.status()\n    print(f\"Current in position {status.rank} out of {status.queue_size}\")\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/examples_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Python Package Requirements\nDESCRIPTION: Lists the required Python packages needed for the project. Includes deep learning frameworks (PyTorch and TorchVision) and the HTTP library Requests.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classification/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\ntorch\ntorchvision\nrequests\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_world_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_sketchpad/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Citation BibTeX Entry for Gradio Paper\nDESCRIPTION: BibTeX citation entry for the academic paper 'Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild' published in ICML HILL 2019.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bibtex\nCODE:\n```\n@article{abid2019gradio,\n  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\n  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\n  journal = {arXiv preprint arXiv:1906.02569},\n  year = {2019},\n}\n```\n\n----------------------------------------\n\nTITLE: Running Functional Tests for Gradio UI\nDESCRIPTION: Commands to set up and run functional browser tests using Playwright, including installing test dependencies and running the full test suite.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\npip install -r demo/outbreak_forecast/requirements.txt\npnpm exec playwright install chromium\npnpm exec playwright install-deps chromium\npnpm test:browser:full\n```\n\n----------------------------------------\n\nTITLE: Defining Gradio Custom Component Metadata in YAML\nDESCRIPTION: This YAML frontmatter defines metadata for a Gradio custom component, including tags, title, description, colors, SDK, and app file.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/gradio/cli/commands/components/files/README.md#2025-04-23_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\n---\ntags: [gradio-custom-component<<template>><<tags>>]\ntitle: <<title>>\nshort_description: <<short-description>>\ncolorFrom: blue\ncolorTo: yellow\nsdk: gradio\npinned: false\napp_file: space.py\n---\n```\n\n----------------------------------------\n\nTITLE: Building Frontend and Backend of Gradio Custom Components\nDESCRIPTION: This feature adds the ability to build the frontend and backend of custom components in preparation for publishing to PyPI using the command 'gradio_component build'.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ngradio_component build\n```\n\n----------------------------------------\n\nTITLE: Network Call Testing Anti-pattern\nDESCRIPTION: Example of how not to rely on internal network calls for testing, showing an approach that should be avoided.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/testing-guidelines/playwright.md#2025-04-23_snippet_2\n\nLANGUAGE: javascript\nCODE:\n```\nconst uploadButton = page...\nawait uploadButton.click();\nawait page.waitForRequest(\"**/upload?*\");\nawait expect(page.getByTestId(\"file-component\")).toHaveValue(...)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependencies\nDESCRIPTION: Installs the Gradio library using pip package manager in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_webcam/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/hello_blocks/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Declaring OpenAI Python Package Dependency\nDESCRIPTION: Specifies a requirement for the Python 'openai' package using pip's requirements file format. It ensures that version 1.0.0 or a newer compatible version of the library is installed in the environment. This dependency is crucial for Python projects interacting with the OpenAI API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/llm_hyperbolic/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nopenai>=1.0.0\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio library using pip\nDESCRIPTION: This command uses the pip package manager to install the Gradio library. The '!' prefix indicates it's typically run in a Jupyter Notebook or IPython environment as a shell command. The '-q' flag ensures a quiet installation with minimal output. This step is required before importing and using the Gradio library in Python.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/load_space/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_page_load/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Dependency List Declaration\nDESCRIPTION: Lists required Python package dependencies for the project including key data science libraries for numerical computing, data analysis and visualization.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/live_dashboard/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\npandas\nplotly\n```\n\n----------------------------------------\n\nTITLE: Stripping Vite Import Warning in Gradio\nDESCRIPTION: This feature removes the Vite import warning from the Gradio build process, potentially improving the development experience by reducing unnecessary warnings.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/preview/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: JavaScript\nCODE:\n```\n// Code not provided in the changelog\n```\n\n----------------------------------------\n\nTITLE: Using Keyword Arguments in JavaScript Client\nDESCRIPTION: Example demonstrating how to use keyword arguments when making predictions with the JavaScript client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: javascript\nCODE:\n```\nimport { Client } from \"@gradio/client\";\n\nconst client = await Client.connect(\"http://127.0.0.1:7860/\");\nconst result = await client.predict(\"/chat\", { \t\t\n\t\tmessage: \"Hello!!\", \t\t\n\t\tsystem_prompt: \"Hello!!\", \t\t\n\t\ttokens: 10, \n});\n\nconsole.log(result.data);\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/request_ip_headers/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the Gradio application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_simple_squares/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Agent Chatbot\nDESCRIPTION: This snippet installs the necessary libraries (Gradio and Transformers) for the chatbot application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/agent_chatbot/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio transformers>=4.47.0\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_webcam/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio and Pandas Dependencies\nDESCRIPTION: Installs the required Python packages (Gradio and Pandas) for running the scatter plot demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatter_plot_demo/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_xray/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip\nDESCRIPTION: Command to install or upgrade Gradio using pip package manager. Requires Python 3.10 or higher as a prerequisite.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Command to install the necessary Python packages gradio and slack-bolt for creating the Slack bot\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/05_chatbots/07_creating-a-slack-bot-from-a-gradio-app.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install --upgrade gradio slack-bolt~=1.0\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. The '-q' flag is used for a quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/textbox_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip in Python\nDESCRIPTION: Installs the Gradio library using the pip package manager. The '-q' flag ensures a quiet installation with minimal console output. This step is a prerequisite for using any Gradio functionalities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_classifier_interface_load/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Activating a Virtual Environment on Windows using Bash\nDESCRIPTION: Executes the activate script located within the `Scripts` directory of the `gradio-env` virtual environment to activate it in the current Windows Command Prompt session. This modifies the shell's environment variables, like PATH, to prioritize the virtual environment's Python interpreter and packages.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/installing-gradio-in-a-virtual-environment.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n.\\gradio-env\\Scripts\\activate\n```\n\n----------------------------------------\n\nTITLE: Getting Results with Authentication Cookies\nDESCRIPTION: Uses the saved cookies to make an authenticated GET request to retrieve prediction results from a Gradio API endpoint.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/03_querying-gradio-apps-with-curl.md#2025-04-23_snippet_17\n\nLANGUAGE: bash\nCODE:\n```\ncurl -N $URL/call/$API_NAME/$EVENT_ID -b cookies.txt\n```\n\n----------------------------------------\n\nTITLE: Connecting to Gradio Space with Source Parameter\nDESCRIPTION: Example showing how to connect to a Gradio space using just the source parameter.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/README.md#2025-04-23_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\nClient.connect(\"user/space-name\");  \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency using Pip\nDESCRIPTION: This command uses pip, the Python package installer, to install the Gradio library. The '-q' flag ensures a quiet installation, suppressing most of the output. This step is necessary to make the Gradio library available for import in the subsequent Python script.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabbed_interface_lite/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_core_components_simple/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Importing the vega_datasets package in Python\nDESCRIPTION: A simple import statement for the vega_datasets package, which provides access to various data collections commonly used for visualization examples and testing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/scatterplot_component/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nvega_datasets\n```\n\n----------------------------------------\n\nTITLE: Running TypeScript Type Checking\nDESCRIPTION: Command to run TypeScript static type checking on the codebase to identify type-related issues.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/README.md#2025-04-23_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npnpm ts:check\n```\n\n----------------------------------------\n\nTITLE: Setting Comet Environment Variables\nDESCRIPTION: Shell commands to configure Comet credentials through environment variables for API access.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/10_other-tutorials/Gradio-and-Comet.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nexport COMET_API_KEY=\"<Your API Key>\"\nexport COMET_WORKSPACE=\"<Your Workspace Name>\"\nexport COMET_PROJECT_NAME=\"<Your Project Name>\"\n```\n\n----------------------------------------\n\nTITLE: Lite WebSocket Implementation\nDESCRIPTION: Adds WebSocket queueing functionality to the Lite version of Gradio, improving real-time communication capabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/wasm/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: typescript\nCODE:\n```\nisMessagePort()\n```\n\n----------------------------------------\n\nTITLE: Checking FFmpeg Installation\nDESCRIPTION: Command to verify if FFmpeg is installed on the system\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/09_gradio-clients-and-lite/07_fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n$ ffmpeg version\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_echo_multimodal/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installation of Gradio package using pip package manager in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/label_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the chatbot demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatbot_examples/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Applying Styling to Dataframe\nDESCRIPTION: Code snippet showing how to apply styling to a Gradio Dataframe using a pandas Styler object.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nstyled_df = df.style.highlight_max()\ngr.DataFrame(styled_df)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's executed quietly (-q flag) to reduce output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/theme_extended_step_4/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_visibility/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_system_prompt/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/video_identity_2/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library using Pip (Shell)\nDESCRIPTION: Installs the Gradio Python library using the pip package manager. The `-q` flag ensures a quiet installation, minimizing output. This step is necessary before running the subsequent Python code.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/markdown_with_mermaid/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries with pip\nDESCRIPTION: Command to install the necessary Python packages for the Acappellify application: gradio_client for accessing ML models, fastapi for creating the web app, and uvicorn for running the server.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/cn/06_client-libraries/fastapi-app-with-the-gradio-client.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ pip install gradio_client fastapi uvicorn\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via Pip in Python\nDESCRIPTION: This snippet installs the Gradio library using pip, a necessary prerequisite for running the interactive image inpainting demo. It uses a notebook-friendly command to suppress output and ensure Gradio is available for subsequent imports. No other dependencies are installed by this command.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_inpainting/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip package manager.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataframe_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip with the quiet flag to minimize output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_random_slider/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio library quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/plot_guide_filters_events/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/clearbutton_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Running Gradio-Lite Development Server\nDESCRIPTION: Platform-specific commands for starting the Gradio-Lite development server\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nbash scripts/run_lite.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\nscripts\\run_lite.bat\n```\n\n----------------------------------------\n\nTITLE: Defining Python Package Dependencies\nDESCRIPTION: Specifies numpy as a required package dependency in a requirements.txt file format\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/json_component/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Requiring NumPy Package\nDESCRIPTION: Specifies NumPy as a required package dependency for the Python project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/kitchen_sink/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: requirements\nCODE:\n```\nnumpy\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_button/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Writing Content to File in Python\nDESCRIPTION: This function writes content to a file, creating the directory if it doesn't exist. It uses UTF-8 encoding by default.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir3/dir4/dir5/dir5_foo.txt#2025-04-23_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\ndef write_file(file_path, content):\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(content)\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: This snippet installs the Gradio package using pip. The -q flag is used for quiet installation.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/uploadbutton_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Required Libraries for Gradio Dashboard\nDESCRIPTION: This snippet installs the necessary Python libraries (Gradio, Plotly, and Pandas) for creating the interactive dashboard.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dashboard/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio plotly pandas \n```\n\n----------------------------------------\n\nTITLE: Installing Python Dependencies via Pip (Shell)\nDESCRIPTION: Installs the required Python libraries 'gradio' and 'opencv-python' using the pip package installer. The '-q' flag ensures a quiet installation with minimal output.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/stream_video_out/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n!pip install -q gradio opencv-python\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/duplicatebutton_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library\nDESCRIPTION: This snippet installs the Gradio library using pip in a quiet mode. It's a prerequisite for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/dataset_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Comparing Version Strings in Python\nDESCRIPTION: This function compares two version strings. It returns -1 if version1 is older, 1 if version1 is newer, and 0 if they are equal. It handles both numeric and string components in version numbers.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/file_explorer_component_events/dir3/dir4/dir5/dir5_foo.txt#2025-04-23_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\ndef compare_versions(version1, version2):\n    def normalize(v):\n        return [int(x) if x.isdigit() else x for x in re.split(r'([0-9]+)', v)]\n    return (normalize(version1) > normalize(version2)) - (normalize(version1) < normalize(version2))\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in a quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/upload_and_download/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing required packages for Gradio Progress Component Demo\nDESCRIPTION: Installs the necessary packages (Gradio and tqdm) required to run the progress component demo. The -q flag keeps the installation output quiet.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/progress_component/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio tqdm\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies for Gradio Sales Projections Demo\nDESCRIPTION: Installs the necessary Python packages (gradio, pandas, numpy, matplotlib) for running the sales projections demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/sales_projections/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio pandas numpy matplotlib\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip, which is required for running the demo.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_tests/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/chatinterface_options/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Setting Brush Opacity via API (TypeScript)\nDESCRIPTION: Sets the brush opacity for the Brush Tool. It accepts an `opacity` parameter, typically a value between 0 (fully transparent) and 1 (fully opaque), to control the transparency of the brush strokes. This is part of the Brush Tool's customization API.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/imageeditor/shared/brush/BRUSH_TOOL.md#2025-04-23_snippet_2\n\nLANGUAGE: typescript\nCODE:\n```\nsetBrushOpacity(opacity)\n```\n\n----------------------------------------\n\nTITLE: Starting a Svelte Development Server\nDESCRIPTION: Commands for starting a development server after project creation and dependency installation. Includes an option to automatically open the app in a new browser tab.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/_spaces-test/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpm run dev\n\n# or start the server and open the app in a new browser tab\nnpm run dev -- --open\n```\n\n----------------------------------------\n\nTITLE: Rendering Heavy Gradio UI Blocks Concurrently in Python\nDESCRIPTION: This snippet defines a Gradio web application with two rendering functions, each generating 500 Textboxes filled with random numbers and a Button. It uses @gr.render decorators to register these render functions inside a Row layout, and launches the demo with an explicit concurrency limit of 64 to handle heavy loads. Dependencies include gradio and Python standard libraries, and key parameters include the concurrency setting and component counts. The demo serves UI elements at runtime and is suitable for stress testing or concurrent rendering demonstrations.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/render_heavy_concurrently/run.ipynb#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport random\n\nwith gr.Blocks() as demo:\n\n    with gr.Row():\n\n        @gr.render()\n        def render():\n            for _ in range(500):\n                gr.Textbox(str(random.randint(0, 100)))\n            gr.Button(\"DONE 1\")\n\n        @gr.render()\n        def render2():\n            for _ in range(500):\n                gr.Textbox(str(random.randint(0, 100)))\n            gr.Button(\"DONE 2\")\n\nif __name__ == \"__main__\":\n    demo.queue(default_concurrency_limit=64).launch()\n\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package in Python\nDESCRIPTION: This snippet installs the Gradio package using pip. It's executed quietly (-q flag) to reduce output verbosity.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/fake_gan_no_input/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio via pip - Python\nDESCRIPTION: This snippet installs the Gradio library non-interactively using pip, ensuring the required dependency is available for subsequent code execution. It uses the special shell escape syntax for Jupyter-like environments. There are no parameters, and it runs quietly without verbose output. The output is not required for further usage.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_layers/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Gradio 3.x WebSocket Implementation\nDESCRIPTION: Implements a request function for Gradio 3.x using WebSocket connections. Handles session management and message processing.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/scripts/load_test/load.ipynb#2025-04-23_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef request():\n    start_time = time.time()\n    url = f\"ws://{URL}/\"\n    session_hash = uuid.uuid4().hex\n    output = None\n    message_count = 0\n    start_time = time.time()\n    try:\n        # Connect to WebSocket server\n        ws = websocket.create_connection(f\"{url}queue/join\")\n\n        while True:\n            message = ws.recv()  # Wait and receive incoming message\n            message_count += 1\n            message = json.loads(message)\n            msg = message[\"msg\"]\n\n            if msg == \"send_hash\":\n                ws.send(json.dumps({\"session_hash\": session_hash, \"fn_index\": 0}))\n\n            if msg == \"send_hash\":\n                ws.send(json.dumps({\"data\":[\"test\"],\"event_data\":None,\"fn_index\":0,\"session_hash\":session_hash})\t)\n\n            if msg == \"process_completed\":\n                output = message[\"output\"][\"data\"]\n                break\n\n\n    finally:\n        ws.close()  # Ensure the connection is closed properly\n        \n    duration = time.time() - start_time\n    return duration, message_count, output\n```\n\n----------------------------------------\n\nTITLE: Creating a New Svelte Project with create-svelte\nDESCRIPTION: Commands for initializing a new Svelte project either in the current directory or in a specified folder. Uses the create-svelte tool which provides everything needed to build a Svelte project.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/_spaces-test/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n# create a new project in the current directory\nnpm create svelte@latest\n\n# create a new project in my-app\nnpm create svelte@latest my-app\n```\n\n----------------------------------------\n\nTITLE: Dependency Version Updates\nDESCRIPTION: Lists updated version numbers for various Gradio packages and components including video, atoms, icons, utils and more.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/core/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n@gradio/video@0.11.0-beta.1\n@gradio/atoms@0.8.1-beta.1\n@gradio/icons@0.8.0-beta.1\n@gradio/statustracker@0.8.0-beta.1\n@gradio/utils@0.7.0-beta.1\n@gradio/client@1.6.0-beta.1\n@gradio/image@0.16.0-beta.1\n@gradio/upload@0.12.4-beta.1\n@gradio/markdown@0.9.4-beta.1\n@gradio/wasm@0.13.1-beta.1\n@gradio/theme@0.3.0-beta.1\n@gradio/gallery@0.13.0-beta.1\n@gradio/plot@0.6.5-beta.1\n@gradio/tabs@0.3.0-beta.1\n@gradio/column@0.2.0-beta.0\n@gradio/button@0.3.0-beta.1\n@gradio/textbox@0.7.0-beta.1\n@gradio/code@0.9.1-beta.1\n@gradio/paramviewer@0.4.22-beta.1\n@gradio/file@0.9.4-beta.1\n@gradio/checkbox@0.4.0-beta.1\n```\n\n----------------------------------------\n\nTITLE: Implementing Gradio Image Rotation Interface\nDESCRIPTION: Creates a Gradio interface that rotates images by 45 degrees. The interface includes a default image (cheetah), example images (lion and logo), and flagging options. The maximum file size is limited to 70kb.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_mod_default_image/run.ipynb#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\nimport os\n\ndef image_mod(image):\n    return image.rotate(45)\n\ncheetah = os.path.join(os.path.abspath(''), \"images/cheetah1.jpg\")\n\ndemo = gr.Interface(image_mod, gr.Image(type=\"pil\", value=cheetah), \"image\",\n    flagging_options=[\"blurry\", \"incorrect\", \"other\"], examples=[\n        os.path.join(os.path.abspath(''), \"images/lion.jpg\"),\n        os.path.join(os.path.abspath(''), \"images/logo.png\")\n        ])\n\nif __name__ == \"__main__\":\n    demo.launch(max_file_size=\"70kb\")\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package using pip in quiet mode.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/image_editor_many/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Package\nDESCRIPTION: Installs the Gradio package quietly using pip\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/deep_link/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Dependency with pip in Python\nDESCRIPTION: This code installs the Gradio library using pip inside a Python environment. It is required to run any subsequent examples using Gradio components. The '-q' flag ensures the installation process outputs minimal logs and is generally run as a preliminary setup cell in notebook-based workflows.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/tabs_visibility/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio \n```\n\n----------------------------------------\n\nTITLE: Documenting Version 0.1.0 Changes (Markdown)\nDESCRIPTION: Records the changes for version 0.1.0, including updates to dependencies such as @gradio/icons, @gradio/utils, @gradio/atoms, and @gradio/statustracker.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/simpledropdown/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n## 0.1.0\n\n### Patch Changes\n\n- Updated dependencies [[`287fe6782`](https://github.com/gradio-app/gradio/commit/287fe6782825479513e79a5cf0ba0fbfe51443d7), [`287fe6782`](https://github.com/gradio-app/gradio/commit/287fe6782825479513e79a5cf0ba0fbfe51443d7), [`287fe6782`](https://github.com/gradio-app/gradio/commit/287fe6782825479513e79a5cf0ba0fbfe51443d7)]:\n  - @gradio/icons@0.2.0\n  - @gradio/utils@0.2.0\n  - @gradio/atoms@0.2.0\n  - @gradio/statustracker@0.3.0\n```\n\n----------------------------------------\n\nTITLE: Using Keyword Arguments in Python Client\nDESCRIPTION: Example demonstrating how to use keyword arguments when making predictions with the Python client\nSOURCE: https://github.com/gradio-app/gradio/blob/main/client/js/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom gradio_client import Client\n\nclient = Client(\"http://127.0.0.1:7860/\")\nresult = client.predict(\n\t\tmessage=\"Hello!!\",\n\t\tsystem_prompt=\"You are helpful AI.\",\n\t\ttokens=10,\n\t\tapi_name=\"/chat\"\n)\nprint(result)\n```\n\n----------------------------------------\n\nTITLE: Installing Required Dependencies\nDESCRIPTION: Installs the necessary Python packages (gradio, torch, transformers, diffusers) using pip.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/diffusers_with_batching/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio torch transformers diffusers\n```\n\n----------------------------------------\n\nTITLE: Installing Gradio Library in Python\nDESCRIPTION: This snippet installs the Gradio library using pip. It's a prerequisite for running the flashcard application.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/blocks_flashcards/run.ipynb#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n!pip install -q gradio\n```\n\n----------------------------------------\n\nTITLE: Restoring Missing Border on File Component in Gradio\nDESCRIPTION: Restores a missing part of the bottom border on the file component in Gradio.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/file/CHANGELOG.md#2025-04-23_snippet_13\n\nLANGUAGE: markdown\nCODE:\n```\n- [#5313](https://github.com/gradio-app/gradio/pull/5313) [`54bcb724`](https://github.com/gradio-app/gradio/commit/54bcb72417b2781ad9d7500ea0f89aa9d80f7d8f) - Restores missing part of bottom border on file component. Thanks [@abidlabs](https://github.com/abidlabs)!\n```\n\n----------------------------------------\n\nTITLE: Formatting Frontend Code\nDESCRIPTION: Platform-specific commands for formatting the frontend code before submission\nSOURCE: https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md#2025-04-23_snippet_9\n\nLANGUAGE: bash\nCODE:\n```\nbash scripts/format_frontend.sh\n```\n\nLANGUAGE: bash\nCODE:\n```\nscripts\\format_frontend.bat\n```\n\n----------------------------------------\n\nTITLE: Implementing Response Generation with Hugging Face Inference\nDESCRIPTION: Handles audio transcription using Whisper and generates responses using Mistral-7B-Instruct LLM through Hugging Face's Inference API. Includes magic 8 ball specific prompt engineering.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/guides/07_streaming/01_streaming-ai-generated-audio.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom huggingface_hub import InferenceClient\n\nclient = InferenceClient(token=os.getenv(\"HF_TOKEN\"))\n\ndef generate_response(audio):\n    gr.Info(\"Transcribing Audio\", duration=5)\n    question = client.automatic_speech_recognition(audio).text\n\n    messages = [{\"role\": \"system\", \"content\": (\"You are a magic 8 ball.\"\n                                              \"Someone will present to you a situation or question and your job \"\n                                              \"is to answer with a cryptic adage or proverb such as \"\n                                              \"'curiosity killed the cat' or 'The early bird gets the worm'.\"\n                                              \"Keep your answers short and do not include the phrase 'Magic 8 Ball' in your response. If the question does not make sense or is off-topic, say 'Foolish questions get foolish answers.'\"\n                                              \"For example, 'Magic 8 Ball, should I get a dog?', 'A dog is ready for you but are you ready for the dog?'\")},\n                {\"role\": \"user\", \"content\": f\"Magic 8 Ball please answer this question -  {question}\"}]\n    \n    response = client.chat_completion(messages, max_tokens=64, seed=random.randint(1, 5000),\n                                      model=\"mistralai/Mistral-7B-Instruct-v0.3\")\n\n    response = response.choices[0].message.content.replace(\"Magic 8 Ball\", \"\").replace(\":\", \"\")\n    return response, None, None\n```\n\n----------------------------------------\n\nTITLE: Specifying Pillow Package Requirement\nDESCRIPTION: Simple requirements file entry specifying the Pillow package as a dependency. Pillow is a Python Imaging Library fork that adds image processing capabilities.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/demo/color_picker/requirements.txt#2025-04-23_snippet_0\n\nLANGUAGE: plaintext\nCODE:\n```\nPillow\n```\n\n----------------------------------------\n\nTITLE: Setting File Upload Limits with Gradio - Python\nDESCRIPTION: This Python snippet demonstrates how to use Gradio's 'launch' function with the 'max_file_size' parameter, allowing developers to set a maximum allowable file size for uploads. It shows both string-based (e.g., '5mb') and integer (using 'gr.FileSize.MB') approaches for specifying the limit. The sample requires Gradio installed, uses an identity lambda for demonstration, and supports both human-readable and byte specification for size; inputs not conforming to the limit will be rejected.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/dataframe/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport gradio as gr\\n\\ndemo = gr.Interface(lambda x: x, \"image\", \"image\")\\n\\ndemo.launch(max_file_size=\"5mb\")\\n# or\\ndemo.launch(max_file_size=5 * gr.FileSize.MB)\n```\n\n----------------------------------------\n\nTITLE: Defining BaseLabel Component Props in JavaScript\nDESCRIPTION: This snippet defines the props for the BaseLabel component, including the value object structure, color, and selectable flag. The value prop can contain a label and an array of confidences.\nSOURCE: https://github.com/gradio-app/gradio/blob/main/js/label/README.md#2025-04-23_snippet_1\n\nLANGUAGE: javascript\nCODE:\n```\nexport let value: {\n\tlabel?: string;\n\tconfidences?: { label: string; confidence: number }[];\n};\nexport let color: string | undefined = undefined;\nexport let selectable = false;\n```"
  }
]