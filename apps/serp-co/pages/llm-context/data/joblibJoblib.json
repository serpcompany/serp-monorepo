[
  {
    "owner": "joblib",
    "repo": "joblib",
    "content": "TITLE: Persist object using joblib Python\nDESCRIPTION: Saves a Python object to a file using `joblib.dump`. This function efficiently serializes and saves the object, handling large NumPy arrays effectively.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> import joblib\n>>> joblib.dump(to_persist, filename)  # doctest: +ELLIPSIS\n['...test.joblib']\n```\n\n----------------------------------------\n\nTITLE: Parallel For Loop with Joblib\nDESCRIPTION: This snippet demonstrates a basic parallel for loop using joblib. It calculates the square root of the square of each number in a range and distributes the computation across multiple CPU cores using `joblib.Parallel` and `joblib.delayed`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> from math import sqrt\n>>> [sqrt(i ** 2) for i in range(10)]\n[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n```\n\n----------------------------------------\n\nTITLE: Caching Function Output\nDESCRIPTION: This snippet shows how to use the @memory.cache decorator to cache the output of a function. The function is only executed the first time it is called with a specific argument; subsequent calls retrieve the result from the cache.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> @memory.cache\n... def f(x):\n...     print('Running f(%s)' % x)\n...     return x\n\n>>> print(f(1))\nRunning f(1)\n1\n>>> print(f(1))\n1\n>>> print(f(2))\nRunning f(2)\n2\n```\n\n----------------------------------------\n\nTITLE: Load persisted object using joblib Python\nDESCRIPTION: Loads a Python object from a file using `joblib.load`. This function deserializes the object, effectively retrieving the data that was previously saved using `joblib.dump`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> joblib.load(filename)\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n```\n\n----------------------------------------\n\nTITLE: Protecting main loop with multiprocessing backend\nDESCRIPTION: This snippet shows how to structure Python code to avoid recursive spawning of subprocesses when using the `'multiprocessing'` backend under Windows. It emphasizes the importance of placing executable code within an `if __name__ == '__main__'` block.  Imports and function definitions should be placed outside the block.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport ....\n\ndef function1(...):\n    ...\n\ndef function2(...):\n    ...\n\n...\nif __name__ == '__main__':\n    # do stuff with imports and functions defined about\n    ...\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution with Specified Jobs\nDESCRIPTION: This snippet demonstrates how to parallelize a for loop using `joblib` and specify the number of jobs to use. It calculates the square root of the square of each number in a range, distributing the computation across 2 CPU cores.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> from math import sqrt\n>>> from joblib import Parallel, delayed\n>>> Parallel(n_jobs=2)(delayed(sqrt)(i ** 2) for i in range(10))\n[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n```\n\n----------------------------------------\n\nTITLE: Compress object using joblib Python\nDESCRIPTION: Compresses the saved object using the `compress` argument in `joblib.dump`. This example shows saving the data with the 'zlib' compression method.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> joblib.dump(to_persist, filename + '.compressed', compress=True)  # doctest: +ELLIPSIS\n['...test.joblib.compressed']\n```\n\n----------------------------------------\n\nTITLE: Initializing Memory Cache\nDESCRIPTION: This snippet demonstrates how to instantiate the Memory class from joblib, specifying a location for the cache directory and setting the verbosity level.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> from joblib import Memory\n>>> location = 'your_cache_location_directory'\n>>> memory = Memory(location, verbose=0)\n```\n\n----------------------------------------\n\nTITLE: Persist with file objects using joblib Python\nDESCRIPTION: Demonstrates persisting and loading data using file objects instead of filenames with `joblib.dump` and `joblib.load`. It uses the `with open()` context manager for safe file handling.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> with open(filename, 'wb') as fo:  # doctest: +ELLIPSIS\n...    joblib.dump(to_persist, fo)\n>>> with open(filename, 'rb') as fo:  # doctest: +ELLIPSIS\n...    joblib.load(fo)\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n```\n\n----------------------------------------\n\nTITLE: Manual Memmap Creation and Management\nDESCRIPTION: This code demonstrates the manual creation and management of NumPy memmaps for use with joblib. It covers creating a large array, dumping it to a file using `joblib.dump`, loading it back as a memmap using `joblib.load`, and manipulating the memmap including slicing and converting to a standard numpy array. It also includes garbage collection.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel_numpy.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> large_array = np.ones(int(1e6))\n\n>>> import tempfile\n>>> import os\n>>> from joblib import load, dump\n\n>>> temp_folder = tempfile.mkdtemp()\n>>> filename = os.path.join(temp_folder, 'joblib_test.mmap')\n>>> if os.path.exists(filename): os.unlink(filename)\n>>> _ = dump(large_array, filename)\n>>> large_memmap = load(filename, mmap_mode='r+')\n\n>>> large_memmap.__class__.__name__, large_array.nbytes, large_array.shape\n('memmap', 8000000, (1000000,))\n\n>>> np.allclose(large_array, large_memmap)\nTrue\n\n>>> del large_array\n>>> import gc\n>>> _ = gc.collect()\n\n>>> small_memmap = large_memmap[2:5]\n>>> small_memmap.__class__.__name__, small_memmap.nbytes, small_memmap.shape\n('memmap', 24, (3,))\n\n>>> small_array = np.asarray(small_memmap)\n>>> small_array.__class__.__name__, small_array.nbytes, small_array.shape\n('ndarray', 24, (3,))\n```\n\n----------------------------------------\n\nTITLE: Configuring Backend with parallel_config\nDESCRIPTION: This snippet shows how to use the `parallel_config` context manager to set the backend and number of jobs for `joblib.Parallel`.  This is useful for configuring joblib when called within a library where you don't want to directly expose backend selection.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> from joblib import parallel_config\n>>> with parallel_config(backend='threading', n_jobs=2):\n...    Parallel()(delayed(sqrt)(i ** 2) for i in range(10))\n[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n```\n\n----------------------------------------\n\nTITLE: Register Custom Backend in Joblib\nDESCRIPTION: Registers a custom backend with Joblib using the `register_parallel_backend` function. This allows the backend to be used with the `parallel_config` context manager.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# Register the backend so it can be used with parallel_config\nregister_parallel_backend('custom', MyCustomBackend)\n```\n\n----------------------------------------\n\nTITLE: Reusing a pool of workers with joblib.Parallel\nDESCRIPTION: This snippet illustrates how to reuse a pool of workers with joblib.Parallel using the context manager API. This approach is more efficient than calling joblib.Parallel multiple times in a loop, as it avoids the overhead of creating and destroying worker pools repeatedly. It showcases a `with` statement to manage the worker pool.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> with Parallel(n_jobs=2) as parallel:\n...    accumulator = 0.\n...    n_iter = 0\n...    while accumulator < 1000:\n...        results = parallel(delayed(sqrt)(accumulator + i ** 2)\n...                           for i in range(5))\n...        accumulator += sum(results)  # synchronization barrier\n...        n_iter += 1\n...\n>>> (accumulator, n_iter)                            # doctest: +ELLIPSIS\n(1136.596..., 14)\n```\n\n----------------------------------------\n\nTITLE: Compression string argument joblib Python\nDESCRIPTION: Demonstrates using a string to specify the compression method in `joblib.dump`. This uses the default compression level for the given method.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n>>> joblib.dump(to_persist, filename + '.gz', compress='gzip')  # doctest: +ELLIPSIS\n['...test.joblib.gz']\n```\n\n----------------------------------------\n\nTITLE: Caching a Pure Function with joblib Memory\nDESCRIPTION: This snippet shows the recommended way to use joblib's Memory for caching within a class.  A pure function `compute_func` is decorated with `@memory.cache`, and the cached function is called within the `compute` method of the `Foo` class. This avoids issues related to caching methods directly.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\n@memory.cache\ndef compute_func(arg1, arg2, arg3):\n    # long computation\n    return result\n\n\nclass Foo(object):\n    def __init__(self, args):\n        self.data = None\n\n    def compute(self):\n        self.data = compute_func(self.arg1, self.arg2, 40)\n```\n\n----------------------------------------\n\nTITLE: Shelving Cached Values\nDESCRIPTION: This snippet explains how to use call_and_shelve to get a reference to a cached result instead of the result itself, and then how to use get to retrieve the cached value, and clear to remove the cached value.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> result = g.call_and_shelve(4)\nA long-running calculation, with parameter 4\n>>> result  #doctest: +ELLIPSIS\nMemorizedResult(location=\"...\", func=\"...g...\", args_id=\"...\")\n>>> result.get()\narray([0.08, 0.77, 0.77, 0.08])\n>>> result.clear()\n>>> result.get()  #doctest: +SKIP\nTraceback (most recent call last):\n...\nKeyError: 'Non-existing cache value (may have been cleared.\\nFile ... does not exist'\n```\n\n----------------------------------------\n\nTITLE: Thread-Based Parallelism\nDESCRIPTION: This example demonstrates thread-based parallelism using `joblib`. It is more efficient than process-based parallelism when the function releases the GIL, such as in Cython code. The `prefer=\"threads\"` argument hints at the use of threads.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> Parallel(n_jobs=2, prefer=\"threads\")(\n...     delayed(sqrt)(i ** 2) for i in range(10))\n[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n```\n\n----------------------------------------\n\nTITLE: Use Custom Backend with parallel_config\nDESCRIPTION: Demonstrates how to use a registered custom backend within a `parallel_config` context manager to execute a parallel computation.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom joblib import Parallel, delayed, parallel_config\n\nwith parallel_config(\"custom\"):\n    res = Parallel(2)(delayed(id)(i) for i in range(10))\n```\n\n----------------------------------------\n\nTITLE: Minimal Custom Backend Factory Example\nDESCRIPTION: Presents a minimal example of a custom backend factory using `ThreadPoolExecutor` to run tasks in parallel. It showcases the key methods that need to be implemented, such as `configure`, `terminate`, `effective_n_jobs`, `submit`, and `retrieve_result_callback`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom joblib import ParallelBackendBase\nfrom joblib import register_parallel_backend\n\n\nclass MyCustomBackend(ParallelBackendBase):\n\n    supports_retrieve_callback = True\n\n    def configure(self, n_jobs=1, parallel=None, **backend_kwargs):\n        \"\"\"Configure the backend for a specific instance of Parallel.\"\"\"\n        self.n_jobs = n_jobs\n\n        n_jobs = self.effective_n_jobs(n_jobs)\n        self._executor = ThreadPoolExecutor(n_jobs)\n\n        # Return the effective number of jobs\n        return n_jobs\n\n    def terminate(self):\n        \"\"\"Clean-up the resources associated with the backend.\"\"\"\n        self._executor.shutdown()\n        self._executor = None\n\n    def effective_n_jobs(self, n_jobs):\n        \"\"\"Determine the number of jobs that can be run in parallel.\"\"\"\n        return n_jobs\n\n    def submit(self, func, callback):\n        \"\"\"Schedule a function to be run and return a future-like object.\n\n        This method should return a future-like object that allow tracking\n        the progress of the task.\n\n        If ``supports_retrieve_callback`` is False, the return value of this\n        method is passed to ``retrieve_result`` instead of calling\n        ``retrieve_result_callback``.\n\n        Parameters\n        ----------\n        func: callable\n            The function to be run in parallel.\n\n        callback: callable\n            A callable that will be called when the task is completed. This callable\n            is a wrapper around ``retrieve_result_callback``. This should be added\n            to the future-like object returned by this method, so that the callback\n            is called when the task is completed.\n\n            For future-like backends, this can be achieved with something like\n            ``future.add_done_callback(callback)``.\n\n        Returns\n        -------\n        future: future-like\n            A future-like object to track the execution of the submitted function.\n        \"\"\"\n        future = self._executor.submit(func)\n        future.add_done_callback(callback)\n        return future\n\n    def retrieve_result_callback(self, future):\n        \"\"\"Called within the callback function passed to `submit`.\n\n        This method can customise how the result of the function is retrieved\n        from the future-like object.\n\n        Parameters\n        ----------\n        future: future-like\n            The future-like object returned by the `submit` method.\n\n        Returns\n        -------\n        result: object\n            The result of the function executed in parallel.\n        \"\"\"\n        return future.result()\n```\n\n----------------------------------------\n\nTITLE: Caching Numpy Arrays\nDESCRIPTION: This snippet illustrates using the Memory class with numpy arrays. The g(x) function computes a Hamming window, and h(x) computes the Vandermonde matrix. The functions are cached, and subsequent calls with the same arguments retrieve the precomputed arrays.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n\n>>> @memory.cache\n... def g(x):\n...     print('A long-running calculation, with parameter %s' % x)\n...     return np.hamming(x)\n\n>>> @memory.cache\n... def h(x):\n...     print('A second long-running calculation, using g(x)')\n...     return np.vander(x)\n\n>>> a = g(3)\nA long-running calculation, with parameter 3\n>>> a\narray([0.08, 1.  , 0.08])\n>>> g(3)\narray([0.08, 1.  , 0.08])\n>>> b = h(a)\nA second long-running calculation, using g(x)\n>>> b2 = h(a)\n>>> b2\narray([[0.0064, 0.08  , 1.    ],\n       [1.    , 1.    , 1.    ],\n       [0.0064, 0.08  , 1.    ]])\n>>> np.allclose(b, b2)\nTrue\n```\n\n----------------------------------------\n\nTITLE: Automated Memmap Conversion using Parallel\nDESCRIPTION: This snippet showcases joblib's automatic array-to-memmap conversion based on size.  Arrays exceeding `max_nbytes` are automatically memmapped. It demonstrates how to use `Parallel` with `delayed` to apply the `is_memmap` function to arrays of varying sizes, showing when the automatic conversion kicks in.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel_numpy.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> Parallel(n_jobs=2, max_nbytes=1e6)(\n...     delayed(is_memmap)(np.ones(int(i)))\n...     for i in [1e2, 1e4, 1e6])\n[False, False, True]\n```\n\n----------------------------------------\n\nTITLE: Caching a Method and Ignoring the 'self' Argument\nDESCRIPTION: This snippet demonstrates how to use the `ignore` parameter of `memory.cache` to prevent the cached result from being recomputed when attributes of `self` change, if the method's result does not depend on `self`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nself.method = memory.cache(self.method, ignore=['self'])\n```\n\n----------------------------------------\n\nTITLE: Using shared memory with joblib.Parallel\nDESCRIPTION: This snippet demonstrates how to use shared memory semantics with joblib.Parallel by setting `require='sharedmem'`.  It shows how to allow parallel functions to mutate a common Python object (in this case, a set) defined in the main program.  It emphasizes that relying on shared-memory semantics may impact performance due to lock contention.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> shared_set = set()\n>>> def collect(x):\n...    shared_set.add(x)\n...\n>>> Parallel(n_jobs=2, require='sharedmem')(\n...     delayed(collect)(i) for i in range(5))\n[None, None, None, None, None]\n>>> sorted(shared_set)\n[0, 1, 2, 3, 4]\n```\n\n----------------------------------------\n\nTITLE: Create temporary directory Python\nDESCRIPTION: Creates a temporary directory using the `tempfile` module and joins it with a filename to create a path for persistence. It imports the necessary modules `tempfile` and `os`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> from tempfile import mkdtemp\n>>> savedir = mkdtemp()\n>>> import os\n>>> filename = os.path.join(savedir, 'test.joblib')\n```\n\n----------------------------------------\n\nTITLE: Use parallel_config with Backend Arguments\nDESCRIPTION: Demonstrates how to pass arguments to a custom backend through the `parallel_config` context manager.  These arguments are used during the instantiation of the backend.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nwith parallel_config(backend='custom', endpoint='http://compute',\n                     api_key='42'):\n    Parallel()(delayed(some_function)(i) for i in range(10))\n```\n\n----------------------------------------\n\nTITLE: Automatic compression joblib Python\nDESCRIPTION: Demonstrates automatic compression based on the filename extension using `joblib.dump`.  If the extension is recognized (e.g., '.z'), the appropriate compression method is automatically applied.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> joblib.dump(to_persist, filename + '.z')  # doctest: +ELLIPSIS\n['...test.joblib.z']\n```\n\n----------------------------------------\n\nTITLE: Registering External Backend with Joblib\nDESCRIPTION: This snippet demonstrates how to register a custom parallel backend within the Joblib codebase using the `EXTERNAL_BACKENDS` dictionary. This allows users to seamlessly use the custom backend with the `parallel_config` context manager without requiring manual import statements. The registration involves defining a function that imports the custom backend library and assigning it to the `EXTERNAL_BACKENDS` dictionary.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_7\n\nLANGUAGE: Python\nCODE:\n```\ndef _register_custom():\n    try:\n        import my_custom_library\n    except ImportError:\n        raise ImportError(\"an informative error message\")\n\nEXTERNAL_BACKENDS['custom'] = _register_custom\n```\n\n----------------------------------------\n\nTITLE: Caching NumPy ufuncs with joblib Memory\nDESCRIPTION: This snippet demonstrates how to use joblib's Memory object to cache the results of a NumPy ufunc (universal function), specifically `np.sin`. The `memory.cache` decorator is used to wrap the function, and subsequent calls with the same input will retrieve the result from the cache.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n>>> from joblib import Memory\n>>> location = 'optional_cachedir'\n>>> memory = Memory(location, verbose=0)\n>>> sin = memory.cache(np.sin)\n>>> print(sin(0))\n0.0\n```\n\n----------------------------------------\n\nTITLE: Installing joblib with pip to /usr/local\nDESCRIPTION: Installs the joblib package with pip in the /usr/local directory.  This is useful on Unix environments to avoid conflicts with system packages.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\npip install --prefix /usr/local joblib\n```\n\n----------------------------------------\n\nTITLE: Parallel Execution with Generator Output\nDESCRIPTION: This snippet shows how to use `joblib` to create a parallel computation that returns a generator. The generator yields results as they become available. This can reduce memory usage.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n>>> from math import sqrt\n>>> from joblib import Parallel, delayed\n>>> parallel = Parallel(n_jobs=2, return_as=\"generator\")\n>>> output_generator = parallel(delayed(sqrt)(i ** 2) for i in range(10))\n>>> print(type(output_generator))\n<class 'generator'>\n>>> print(next(output_generator))\n0.0\n>>> print(next(output_generator))\n1.0\n>>> print(list(output_generator))\n[2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n```\n\n----------------------------------------\n\nTITLE: Installing joblib using pip for specific user\nDESCRIPTION: Installs the joblib package using pip only for the current user.  Requires Python 2.7 or above.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_2\n\nLANGUAGE: python\nCODE:\n```\npip install --user joblib\n```\n\n----------------------------------------\n\nTITLE: Installing joblib in a local environment\nDESCRIPTION: Installs the joblib package in a local environment.  This allows for installation without administrator privileges and keeps changes local to the user's account.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\npython -m pip install --user .\n```\n\n----------------------------------------\n\nTITLE: Configuring inner_max_num_threads with parallel_config\nDESCRIPTION: This snippet demonstrates how to programmatically override the default number of threads used by worker processes using the `inner_max_num_threads` argument of the `joblib.parallel_config` function. It sets a limit on the number of threads each worker process is allowed to use, preventing over-subscription of CPU resources when using libraries like NumPy with internal thread pools. The backend is explicitly set to 'loky'.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom joblib import Parallel, delayed, parallel_config\n\nwith parallel_config(backend=\"loky\", inner_max_num_threads=2):\n    results = Parallel(n_jobs=4)(delayed(func)(x, y) for x, y in data)\n```\n\n----------------------------------------\n\nTITLE: Installing joblib using pip\nDESCRIPTION: Installs the joblib package using pip for all users. This typically requires administrator privileges.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\npip install joblib\n```\n\n----------------------------------------\n\nTITLE: Installing joblib for all users\nDESCRIPTION: Installs the joblib package for all users on the system.  Requires administrator privileges and running the command from the expanded joblib tarball directory.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\npython -m pip install .\n```\n\n----------------------------------------\n\nTITLE: Using Memmapping for Cached Arrays\nDESCRIPTION: This snippet demonstrates how to use memmapping with the Memory class to speed up cache loading for large numpy arrays. It shows how to initialize Memory with mmap_mode and cache a function that uses numpy arrays. It also shows how to delete the memmap to avoid file locking on windows.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> location2 = 'your_2nd_cache_location_directory'\n>>> memory2 = Memory(location2, mmap_mode='r')\n>>> square = memory2.cache(np.square)\n>>> a = np.vander(np.arange(3)).astype(float)\n>>> square(a)\n________________________________________________________________________________\n[Memory] Calling numpy.square...\nsquare(array([[0., 0., 1.],\n       [1., 1., 1.],\n       [4., 2., 1.]]))\n___________________________________________________________square - ...min\nmemmap([[ 0.,  0.,  1.],\n        [ 1.,  1.,  1.],\n        [16.,  4.,  1.]])\n>>> res = square(a)\n>>> print(repr(res))\nmemmap([[ 0.,  0.,  1.],\n        [ 1.,  1.,  1.],\n        [16.,  4.,  1.]])\n>>> del res\n```\n\n----------------------------------------\n\nTITLE: Installing Joblib using pip\nDESCRIPTION: This command installs the Joblib package using pip, the Python package installer. This installs the latest version of Joblib from PyPI.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\npip install joblib\n```\n\n----------------------------------------\n\nTITLE: Compression with gzip object Python\nDESCRIPTION: Uses a `gzip.GzipFile` object to compress the data with `joblib.dump`.  This provides more control over the compression process. It also demonstrates loading the compressed file using `joblib.load`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\n>>> # Dumping in a gzip.GzipFile object using a compression level of 3.\n>>> import gzip\n>>> with gzip.GzipFile(filename + '.gz', 'wb', compresslevel=3) as fo:  # doctest: +ELLIPSIS\n...    joblib.dump(to_persist, fo)\n>>> with gzip.GzipFile(filename + '.gz', 'rb') as fo:  # doctest: +ELLIPSIS\n...    joblib.load(fo)\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n```\n\n----------------------------------------\n\nTITLE: Installing Joblib in Editable Mode\nDESCRIPTION: This command installs Joblib in editable mode from the source directory using pip. This allows you to modify the source code and have the changes immediately reflected in your Python environment. Requires being run from the root of the joblib project.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\npip install -e .\n```\n\n----------------------------------------\n\nTITLE: Cancelling Tasks in Custom Backend\nDESCRIPTION: Illustrates how to implement the `abort_everything` method in a custom backend to abort running tasks when an exception is raised. The `ensure_ready` parameter indicates whether the backend should be left in an operating state for future tasks.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef abort_everything(self, ensure_ready=True):\n    \"\"\"Abort any running tasks\n\n    This is called when an exception has been raised when executing a task\n    and all the remaining tasks will be ignored and can therefore be\n    aborted to spare computation resources.\n\n    If ensure_ready is True, the backend should be left in an operating\n    state as future tasks might be re-submitted via that same backend\n    instance.\n\n    If ensure_ready is False, the implementer of this method can decide\n    to leave the backend in a closed / terminated state as no new task\n    are expected to be submitted to this backend.\n\n    Setting ensure_ready to False is an optimization that can be leveraged\n    when aborting tasks via killing processes from a local process pool\n    managed by the backend it-self: if we expect no new tasks, there is no\n    point in re-creating new workers.\n    \"\"\"\n    pass\n```\n\n----------------------------------------\n\nTITLE: Ignoring Arguments with joblib Memory\nDESCRIPTION: This snippet shows how to use the `ignore` parameter of `@memory.cache` to prevent certain arguments from affecting the cache key. In this case, the `debug` argument is ignored, so changes to its value do not cause the function to be re-evaluated if the other arguments remain the same.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\n>>> @memory.cache(ignore=['debug'])\n... def my_func(x, debug=True):\n...     print('Called with x = %s' % x)\n>>> my_func(0)\nCalled with x = 0\n>>> my_func(0, debug=False)\n>>> my_func(0, debug=True)\n>>> # my_func was not reevaluated\n```\n\n----------------------------------------\n\nTITLE: Setting Up Nested Parallelism\nDESCRIPTION: Shows how to implement the `get_nested_backend` method in a custom backend to configure the backend for nested parallel calls.  This example uses LokyBackend for the nested backend.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef get_nested_backend(self):\n    \"\"\"Backend instance to be used by nested Parallel calls.\n\n    By default a thread-based backend is used for the first level of\n    nesting. Beyond, switch to sequential backend to avoid spawning too\n    many threads on the host.\n    \"\"\"\n    nesting_level = getattr(self, \"nesting_level\", 0) + 1\n    return LokyBackend(nesting_level=nesting_level), None\n```\n\n----------------------------------------\n\nTITLE: Using Joblib with an unregistered backend\nDESCRIPTION: Illustrates an attempt to use a custom backend without prior registration. This snippet shows that a `KeyError` will be raised, indicating that the backend is not recognized by Joblib.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_8\n\nLANGUAGE: Python\nCODE:\n```\n>>> import joblib\n>>> with joblib.parallel_config(backend='custom'):  # doctest: +SKIP\n...     ...  # this fails\nKeyError: 'custom'\n```\n\n----------------------------------------\n\nTITLE: Caching a Method at Instantiation Time\nDESCRIPTION: This snippet illustrates the correct way to cache a method using joblib's Memory if it cannot be avoided. The caching is done at instantiation time within the `__init__` method, rather than at class definition. This is necessary because the `self` argument is bound at instantiation.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nclass Foo(object):\n\n    def __init__(self, args):\n        self.method = memory.cache(self.method)\n\n    def method(self, ...):\n        pass\n```\n\n----------------------------------------\n\nTITLE: Compression with level using joblib Python\nDESCRIPTION: Specifies a specific compression method and level using the `compress` argument in `joblib.dump`. Also demonstrates loading the compressed file using `joblib.load`.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\n>>> # Dumping in a gzip compressed file using a compress level of 3.\n>>> joblib.dump(to_persist, filename + '.gz', compress=('gzip', 3))  # doctest: +ELLIPSIS\n['...test.joblib.gz']\n>>> joblib.load(filename + '.gz')\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n>>> joblib.dump(to_persist, filename + '.bz2', compress=('bz2', 3))  # doctest: +ELLIPSIS\n['...test.joblib.bz2']\n>>> joblib.load(filename + '.bz2')\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n```\n\n----------------------------------------\n\nTITLE: Lambda Functions Gotcha\nDESCRIPTION: This snippet illustrates the gotcha when using lambda functions with the Memory class in Python 2.7. Because lambda functions cannot be easily separated, caching multiple lambdas will produce unpredictable results.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_6\n\nLANGUAGE: python\nCODE:\n```\n>>> def my_print(x):\n...     print(x)\n\n>>> f = memory.cache(lambda : my_print(1))\n>>> g = memory.cache(lambda : my_print(2))\n\n>>> f()\n1\n>>> f()\n>>> g() # doctest: +SKIP\nmemory.rst:0: JobLibCollisionWarning: Cannot detect name collisions for function '<lambda>'\n2\n>>> g() # doctest: +SKIP\n>>> f() # doctest: +SKIP\n1\n```\n\n----------------------------------------\n\nTITLE: Name Collisions Gotcha\nDESCRIPTION: This snippet demonstrates the gotcha related to function name collisions across sessions. If two functions with the same name are cached, their caches can override each other, potentially leading to unexpected re-runs. This is because cache is identified by the function's name.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\n>>> @memory.cache\n... def func(x):\n...     print('Running func(%s)' % x)\n\n>>> func2 = func\n\n>>> @memory.cache\n... def func(x):\n...     print('Running a different func(%s)' % x)\n\n>>> func(1)\nRunning a different func(1)\n>>> # FIXME: The next line should create a JolibCollisionWarning but does not\n>>> # memory.rst:0: JobLibCollisionWarning: Possible name collisions between functions 'func' (<doctest memory.rst>:...) and 'func' (<doctest memory.rst>:...)\n>>> func2(1)  #doctest: +ELLIPSIS\nRunning func(1)\n>>> func(1) # No recomputation so far\n>>> func2(1) # No recomputation so far\n>>> import joblib.memory\n>>> joblib.memory._FUNCTION_HASHES.clear()\n>>> # FIXME: The next line will should create a JoblibCollisionWarning but does not. Also it is skipped because it does not produce any output\n>>> # memory.rst:0: JobLibCollisionWarning: Possible name collisions between functions 'func' (<doctest memory.rst>:...) and 'func' (<doctest memory.rst>:...)\n>>> func(1) #doctest: +ELLIPSIS +SKIP\nRunning a different func(1)\n>>> func2(1)  #doctest: +ELLIPSIS +SKIP\nRunning func(1)\n>>> func(1) # No recomputation now\n>>> func2(1) # No recomputation now\n```\n\n----------------------------------------\n\nTITLE: LZ4 Compression joblib Python\nDESCRIPTION: Uses LZ4 compression with `joblib.dump`, if the `lz4` package is installed.  Demonstrates saving and loading data with the '.lz4' extension.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\n>>> joblib.dump(to_persist, filename + '.lz4')  # doctest: +ELLIPSIS\n['...test.joblib.lz4']\n>>> joblib.load(filename + '.lz4')\n[('a', [1, 2, 3]), ('b', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))]\n```\n\n----------------------------------------\n\nTITLE: Building the Joblib Documentation\nDESCRIPTION: This command builds the Joblib documentation using make. Requires the installation of the documentation dependencies. The generated HTML files are located in the doc/_build/html directory.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_7\n\nLANGUAGE: Shell\nCODE:\n```\nmake doc\n```\n\n----------------------------------------\n\nTITLE: Installing Documentation Dependencies\nDESCRIPTION: This command installs the dependencies required to build the Joblib documentation using pip. Sphinx is required to build the docs. The command reads the dependencies from the .readthedocs-requirements.txt file.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_6\n\nLANGUAGE: Shell\nCODE:\n```\npip install -U -r .readthedocs-requirements.txt\n```\n\n----------------------------------------\n\nTITLE: Using Joblib with a registered backend\nDESCRIPTION: Illustrates an attempt to use a custom backend after importing its registration. This snippet shows that the backend should work properly after the import.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_9\n\nLANGUAGE: Python\nCODE:\n```\n# Import library to register external backend\n>>> import my_custom_backend_library  # doctest: +SKIP\n>>> with joblib.parallel_config(backend='custom'):  # doctest: +SKIP\n...     ... # this works\n```\n\n----------------------------------------\n\nTITLE: Running the Joblib Test Suite\nDESCRIPTION: This command runs the Joblib test suite using pytest. Pytest and coverage modules are required for this to work. Run from the root of the project directory.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\npytest joblib\n```\n\n----------------------------------------\n\nTITLE: Custom Backend with Constructor Parameters\nDESCRIPTION: Shows how to create a custom backend class that accepts constructor parameters, such as endpoint and API key, which can be used for connecting to a remote cluster computing service.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/custom_parallel_backend.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass MyCustomBackend(ParallelBackendBase):\n\n    def __init__(self, endpoint, api_key, nesting_level=0):\n       super().__init__(nesting_level=nesting_level)\n       self.endpoint = endpoint\n       self.api_key = api_key\n\n    ...\n    # Do something with self.endpoint and self.api_key somewhere in\n    # one of the method of the class\n\nregister_parallel_backend('custom', MyCustomBackend)\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit hooks\nDESCRIPTION: This command installs the pre-commit hooks which runs code style checks before each commit. This help to maintain a consistent code style across the project. Requires the pre-commit package to be installed.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\npip install pre-commit\npre-commit install\n```\n\n----------------------------------------\n\nTITLE: Disabling pre-commit checks for a commit\nDESCRIPTION: This command disables the pre-commit checks for a single commit. This is useful when you want to commit changes that don't conform to the code style guidelines.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\ngit commit -n\n```\n\n----------------------------------------\n\nTITLE: Custom Cache Validation with joblib Memory\nDESCRIPTION: This snippet demonstrates how to use the `cache_validation_callback` parameter of `@memory.cache` to define a custom function that determines whether a cached result should be reused.  In this example, the callback checks if the function call took more than 1 second; if so, the result is retrieved from the cache; otherwise, the function is re-evaluated.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\n>>> import time\n>>> def cache_validation_cb(metadata):\n...     # Only retrieve cached results for calls that take more than 1s\n...     return metadata['duration'] > 1\n\n>>> @memory.cache(cache_validation_callback=cache_validation_cb)\n... def my_func(delay=0):\n...     time.sleep(delay)\n...     print(f'Called with {delay}s delay')\n\n>>> my_func()\nCalled with 0s delay\n>>> my_func(1.1)\nCalled with 1.1s delay\n>>> my_func(1.1)  # This result is retrieved from cache\n>>> my_func()  # This one is not and the call is repeated\nCalled with 0s delay\n```\n\n----------------------------------------\n\nTITLE: Creating a Source Tarball\nDESCRIPTION: This command creates a source tarball for Joblib using the build module. The tarball is created in the dist directory. pip and build are required to be installed.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_8\n\nLANGUAGE: Shell\nCODE:\n```\npip install build\npython -m build --sdist\n```\n\n----------------------------------------\n\nTITLE: Cloning the Joblib Repository\nDESCRIPTION: This command clones the Joblib repository from GitHub using Git. Git is required to be installed on your system.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\ngit clone https://github.com/joblib/joblib.git\n```\n\n----------------------------------------\n\nTITLE: Creating a Release and Uploading to PyPI\nDESCRIPTION: This command creates a source distribution and a wheel package, then uploads them to PyPI using twine. This command is intended for project managers only. The dist directory will contain the generated files. The build and twine modules are required.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_9\n\nLANGUAGE: Shell\nCODE:\n```\npip install build\npython -m build --sdist --wheel\ntwine upload dist/*\n```\n\n----------------------------------------\n\nTITLE: Parallel Processing with Existing Memmaps\nDESCRIPTION: This example demonstrates how to use pre-existing numpy memmaps and arrays backed by memmaps with joblib.Parallel. The code shows that even with `max_nbytes=None`, the `Parallel` function recognizes that the arrays are already backed by shared memory and avoids unnecessary copying.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel_numpy.rst#_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n>>> Parallel(n_jobs=2, max_nbytes=None)(\n...     delayed(is_memmap)(a)\n...     for a in [large_memmap, small_memmap, small_array])\n[True, True, True]\n```\n\n----------------------------------------\n\nTITLE: Generating Changelog Lines\nDESCRIPTION: This command uses git log to generate lines for the changelog. It shows commit messages with abbreviated commit hashes and short dates, excluding merge commits and using sparse output.\nSOURCE: https://github.com/joblib/joblib/blob/main/README.rst#_snippet_10\n\nLANGUAGE: Shell\nCODE:\n```\ngit log --abbrev-commit --date=short --no-merges --sparse\n```\n\n----------------------------------------\n\nTITLE: Generating Class Documentation (Jinja2)\nDESCRIPTION: This Jinja2 snippet generates documentation for a class using the `autoclass` directive. The `objname` variable specifies the class name, and the `:members:` option includes all class members in the documentation.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/_templates/class.rst#_snippet_2\n\nLANGUAGE: Jinja2\nCODE:\n```\n.. autoclass:: {{ objname }}\n   :members:\n```\n\n----------------------------------------\n\nTITLE: Cache Expiration with joblib expires_after\nDESCRIPTION: This snippet demonstrates how to use the `expires_after` function with `cache_validation_callback` in `joblib.Memory.cache` to define a validity duration for cached results. The cached result will be considered valid for the specified duration.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\n>>> from joblib import expires_after\n>>> import time\n>>> @memory.cache(cache_validation_callback=expires_after(seconds=0.5))\n... def my_func():\n...     print(f'Function run')\n>>> my_func()\nFunction run\n>>> my_func()\n>>> time.sleep(0.5)\n>>> my_func()\nFunction run\n```\n\n----------------------------------------\n\nTITLE: Escaping and Underlining Full Name (Jinja2)\nDESCRIPTION: This Jinja2 snippet escapes the `fullname` variable and underlines it, likely for creating a title in reStructuredText.  The `escape` filter ensures that any special characters in `fullname` are properly escaped for the output format.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/_templates/class.rst#_snippet_0\n\nLANGUAGE: Jinja2\nCODE:\n```\n{{ fullname | escape | underline }}\n```\n\n----------------------------------------\n\nTITLE: Creating a Backreference Link (Jinja2)\nDESCRIPTION: This Jinja2 snippet creates a backreference link using the `fullname` variable.  The link is named `sphx_glr_backreferences_{{ fullname }}`. This link allows navigation back to specific sections within the documentation.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/_templates/class.rst#_snippet_3\n\nLANGUAGE: Jinja2\nCODE:\n```\n.. _sphx_glr_backreferences_{{ fullname }}:\n```\n\n----------------------------------------\n\nTITLE: Setting Current Module (Jinja2)\nDESCRIPTION: This Jinja2 snippet sets the current module using the `module` variable.  This is likely used to properly scope the documentation generation to the specified module.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/_templates/class.rst#_snippet_1\n\nLANGUAGE: Jinja2\nCODE:\n```\n.. currentmodule:: {{ module }}\n```\n\n----------------------------------------\n\nTITLE: Installing joblib to /usr/local (all users)\nDESCRIPTION: Installs the joblib package to the /usr/local directory.  This installation method is suggested for Unix systems to avoid system interference, and needs to be run from the expanded joblib tarball directory.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/installing.rst#_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npython -m pip install --prefix /usr/local .\n```\n\n----------------------------------------\n\nTITLE: Illustrating Incorrect Keyword Argument Error\nDESCRIPTION: This code demonstrates the error message that occurs when an incorrect keyword argument is passed to a cached function using joblib.Memory. It highlights the need for a more informative error message.\nSOURCE: https://github.com/joblib/joblib/blob/main/TODO.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom joblib import Memory\nmem = Memory(cachedir='cache')\n\ndef f(a=0, b=2):\n\treturn a, b\n\ng = mem.cache(f)\ng(c=2)\n```\n\n----------------------------------------\n\nTITLE: Generating a Mini-Gallery (Jinja2)\nDESCRIPTION: This Jinja2 snippet generates a mini-gallery using the `minigallery` directive.  The `fullname` variable likely points to a directory containing example files. The `:add-heading:` option adds a heading to the gallery.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/_templates/class.rst#_snippet_4\n\nLANGUAGE: Jinja2\nCODE:\n```\n.. minigallery:: {{ fullname }}\n    :add-heading:\n```\n\n----------------------------------------\n\nTITLE: Checking for Cache Hit with MemorizedFunc\nDESCRIPTION: This snippet demonstrates how to use the `check_call_in_cache` method of a `MemorizedFunc` object to check if a call to a decorated function would result in a cache hit without actually executing the function.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\n>>> @memory.cache\n... def func(x):\n...     print('Running func(%s)' % x)\n...     return x\n>>> type(func)\n<class 'joblib.memory.MemorizedFunc'>\n>>> func(1)\nRunning func(1)\n1\n>>> func.check_call_in_cache(1)  # cache hit\nTrue\n>>> func.check_call_in_cache(2)  # cache miss\nFalse\n```\n\n----------------------------------------\n\nTITLE: Checking for Memmap Instances with joblib\nDESCRIPTION: This code snippet demonstrates how to check if an object is a NumPy memmap instance using the `isinstance` function. It defines the `is_memmap` function for this purpose.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel_numpy.rst#_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n>>> from joblib import Parallel, delayed\n>>> def is_memmap(obj):\n...     return isinstance(obj, np.memmap)\n```\n\n----------------------------------------\n\nTITLE: Create object to persist Python\nDESCRIPTION: Creates a list of tuples containing a string and either a list or a NumPy array, which will be saved to disk. It relies on the `numpy` module.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/persistence.rst#_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n>>> import numpy as np\n>>> to_persist = [('a', [1, 2, 3]), ('b', np.arange(10))]\n```\n\n----------------------------------------\n\nTITLE: Cleaning up joblib Memory Cache Directory\nDESCRIPTION: This snippet demonstrates how to remove the cache directory after use, which is important for cleaning up resources. It uses `shutil.rmtree` to remove the directory, handling potential `OSError` exceptions.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\n>>> import shutil\n>>> try:\n...     shutil.rmtree(location)\n...     shutil.rmtree(location2)\n... except OSError:\n...     pass  # this can sometimes fail under Windows\n```\n\n----------------------------------------\n\nTITLE: Cleaning up Temporary Folder\nDESCRIPTION: This code snippet shows how to clean up the temporary folder created for memmap files using `shutil.rmtree`. It includes a try-except block to handle potential errors on some operating systems.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/parallel_numpy.rst#_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n>>> import shutil\n>>> try:\n...     shutil.rmtree(temp_folder)\n... except OSError:\n...     pass  # this can sometimes fail under Windows\n```\n\n----------------------------------------\n\nTITLE: Hashing Arguments for Debugging Cache Misses\nDESCRIPTION: This snippet demonstrates how to hash the arguments of a cached function call to help debug cache misses caused by objects with non-deterministic pickle representations.\nSOURCE: https://github.com/joblib/joblib/blob/main/doc/memory.rst#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom joblib import hash\n\nfor x in args:\n  print(f\"{hash(x)}\")\nfor k, x in kwargs.items():\n  print(f\"hash({k})={hash(x)}\")\n```"
  }
]