[
  {
    "owner": "sartography",
    "repo": "spiffworkflow-frontend",
    "content": "TITLE: Running the Development Server (npm)\nDESCRIPTION: Starts the React application in development mode using the `npm start` command. It opens the app at http://localhost:3000, enables hot reloading for changes, and displays lint errors in the console.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_0\n\nLANGUAGE: Shell\nCODE:\n```\nnpm start\n```\n\n----------------------------------------\n\nTITLE: Building for Production (npm)\nDESCRIPTION: Builds the React application for production deployment using `npm run build`. This process bundles React in production mode, optimizes the build for performance, minifies the code, and includes hashes in filenames. The output is placed in the `build` folder.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_2\n\nLANGUAGE: Shell\nCODE:\n```\nnpm run build\n```\n\n----------------------------------------\n\nTITLE: Running Tests (npm)\nDESCRIPTION: Launches the test runner in interactive watch mode using the `npm test` command. Refer to Create React App documentation for more details on running tests.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_1\n\nLANGUAGE: Shell\nCODE:\n```\nnpm test\n```\n\n----------------------------------------\n\nTITLE: Ejecting from Create React App (npm)\nDESCRIPTION: Executes the `npm run eject` command, a one-way operation that removes the single build dependency (`react-scripts`). It copies all configuration files (webpack, Babel, ESLint) and transitive dependencies directly into the project, giving full control but requiring manual management.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_3\n\nLANGUAGE: Shell\nCODE:\n```\nnpm run eject\n```\n\n----------------------------------------\n\nTITLE: Checking Code Linting (npm)\nDESCRIPTION: Runs the linter to check the codebase for potential style issues and errors using the `npm run lint` command.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_4\n\nLANGUAGE: Shell\nCODE:\n```\nnpm run lint\n```\n\n----------------------------------------\n\nTITLE: Automatically Fixing Lint Issues (npm)\nDESCRIPTION: Executes the linter and automatically fixes detected issues using the `npm run lint:fix` command. This command also runs Prettier for code formatting.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_5\n\nLANGUAGE: Shell\nCODE:\n```\nnpm run lint:fix\n```\n\n----------------------------------------\n\nTITLE: Formatting Code (npm)\nDESCRIPTION: Formats the code using a formatter, likely Prettier, via the `npm run format` command. The documentation suggests using `npm run lint:fix` instead, as it includes formatting.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_6\n\nLANGUAGE: Shell\nCODE:\n```\nnpm run format\n```\n\n----------------------------------------\n\nTITLE: Configuring Frontend Routing Strategy (Environment Variables)\nDESCRIPTION: Sets the application's routing strategy at runtime using the `SPIFFWORKFLOW_FRONTEND_RUNTIME_CONFIG_APP_ROUTING_STRATEGY` environment variable within the Docker image. Set to `subdomain_based` (e.g., api.spiffworkflow.org) or `path_based` (e.g., spiffworkflow.org/api) to control how the frontend directs requests to the backend API.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/README.md#_snippet_7\n\nLANGUAGE: Environment Variables\nCODE:\n```\nSPIFFWORKFLOW_FRONTEND_RUNTIME_CONFIG_APP_ROUTING_STRATEGY=subdomain_based\nSPIFFWORKFLOW_FRONTEND_RUNTIME_CONFIG_APP_ROUTING_STRATEGY=path_based\n```\n\n----------------------------------------\n\nTITLE: Configuring Robots.txt\nDESCRIPTION: This snippet defines the rules for the robots.txt file, which instructs web crawlers on which parts of the website they are allowed to access. The `User-agent: *` rule applies to all web crawlers. The `Disallow:` rule specifies the paths or sections of the website that the crawlers are not allowed to access. In this case, nothing is explicitly disallowed, so crawlers are generally allowed to access all the site content. This file is crucial for SEO and website control.\nSOURCE: https://github.com/sartography/spiffworkflow-frontend/blob/main/public/robots.txt#_snippet_0\n\nLANGUAGE: text\nCODE:\n```\n# https://www.robotstxt.org/robotstxt.html\nUser-agent: *\nDisallow:\n```"
  }
]