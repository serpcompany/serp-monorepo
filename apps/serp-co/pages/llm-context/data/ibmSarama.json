[
  {
    "owner": "ibm",
    "repo": "sarama",
    "content": "TITLE: Running Sarama Consumer Group CLI Example\nDESCRIPTION: Command line instruction for running the Sarama consumer group example. It connects to a Kafka broker at localhost:9092, subscribes to the 'sarama' topic, and uses 'example' as the consumer group name.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/consumergroup/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ go run main.go -brokers=\"127.0.0.1:9092\" -topics=\"sarama\" -group=\"example\"\n```\n\n----------------------------------------\n\nTITLE: Running Sarama Exactly-Once Example in Go\nDESCRIPTION: Command to execute the Sarama exactly-once example. It specifies Kafka broker address, input topics, destination topic, and consumer group.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/exactly_once/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ go run main.go -brokers=\"127.0.0.1:9092\" -topics=\"sarama\" -destination-topic=\"destination-sarama\" -group=\"example\"\n```\n\n----------------------------------------\n\nTITLE: Running Sarama Transactional Producer Example in Go\nDESCRIPTION: Command to run the main.go file with specific parameters. It connects to a Kafka broker at 127.0.0.1:9092, produces to the 'sarama' topic using 10 producer instances, each sending 10,000 records.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/txn_producer/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ go run main.go -brokers=\"127.0.0.1:9092\" -topic \"sarama\" -producers 10 -records-number 10000\n```\n\n----------------------------------------\n\nTITLE: Explaining Kafka Producer Usage in Go HTTP Server\nDESCRIPTION: This markdown snippet describes the implementation of an HTTP server that uses Kafka's AsyncProducer and SyncProducer. It explains how to send request data and access logs to Kafka, and highlights the thread-safety of the producers for concurrent request handling.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/http_server/README.md#2025-04-23_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# HTTP server example\n\nThis HTTP server example shows you how to use the AsyncProducer and SyncProducer, and how to test them using mocks. The server simply sends the data of the HTTP request's query string to Kafka, and send a 200 result if that succeeds. For every request, it will send an access log entry to Kafka as well in the background.\n\nIf you need to know whether a message was successfully sent to the Kafka cluster before you can send your HTTP response, using the `SyncProducer` is probably the simplest way to achieve this. If you don't care, e.g. for the access log, using the `AsyncProducer` will let you fire and forget. You can send the HTTP response, while the message is being produced in the background.\n\nOne important thing to note is that both the `SyncProducer` and `AsyncProducer` are **thread-safe**. Go's `http.Server` handles requests concurrently in different goroutines, but you can use a single producer safely. This will actually achieve efficiency gains as the producer will be able to batch messages from concurrent requests together.\n```\n\n----------------------------------------\n\nTITLE: Kafka Consumer with Offset Configuration\nDESCRIPTION: Examples of consuming messages from specific offsets (oldest or newest) in a Kafka topic.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_3\n\nLANGUAGE: shell\nCODE:\n```\nkafka-console-consumer -topic=test -offset=oldest\nkafka-console-consumer -topic=test -offset=newest\n```\n\n----------------------------------------\n\nTITLE: Running SASL SCRAM Kafka Client\nDESCRIPTION: Command line example showing how to run a Kafka client with SASL SCRAM authentication. Demonstrates required parameters including broker address, username, password, topic name, TLS flag, and choice of SHA256 or SHA512 algorithm.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/sasl_scram_client/README.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\n./sasl_scram_client -brokers localhost:9094 -username foo -passwd a_password -topic topic_name -tls -algorithm [sha256|sha512]\n```\n\n----------------------------------------\n\nTITLE: Configuring Producer Interceptors in Sarama (Go)\nDESCRIPTION: Demonstrates how to add interceptors to a Sarama producer configuration. The interceptors can be used to add tracing and modify message headers.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/interceptors/README.md#2025-04-23_snippet_0\n\nLANGUAGE: go\nCODE:\n```\nconf.Producer.Interceptors = []sarama.ProducerInterceptor{xxx}\n```\n\n----------------------------------------\n\nTITLE: Kafka Consumer with Partition Selection\nDESCRIPTION: Demonstrates how to consume messages from specific partitions of a Kafka topic using a comma-separated list.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_4\n\nLANGUAGE: shell\nCODE:\n```\nkafka-console-consumer -topic=test -partitions=1,2,3\n```\n\n----------------------------------------\n\nTITLE: Kafka Consumer with Environment Variables\nDESCRIPTION: Shows how to use environment variables to specify Kafka broker addresses and consume messages from a topic.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nexport KAFKA_PEERS=kafka1:9092,kafka2:9092,kafka3:9092\nkafka-console-consumer -topic=test\n```\n\n----------------------------------------\n\nTITLE: Basic Kafka Producer Usage Examples\nDESCRIPTION: Various usage examples of the kafka-console-producer tool, including basic message production, using environment variables, reading from stdin, specifying keys, and different partitioning strategies.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-producer/README.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n# Minimum invocation\nkafka-console-producer -topic=test -value=value -brokers=kafka1:9092\n\n# It will pick up a KAFKA_PEERS environment variable\nexport KAFKA_PEERS=kafka1:9092,kafka2:9092,kafka3:9092\nkafka-console-producer -topic=test -value=value\n\n# It will read the value from stdin by using pipes\necho \"hello world\" | kafka-console-producer -topic=test\n\n# Specify a key:\necho \"hello world\" | kafka-console-producer -topic=test -key=key\n\n# Partitioning: by default, kafka-console-producer will partition as follows:\n# - manual partitioning if a -partition is provided\n# - hash partitioning by key if a -key is provided\n# - random partitioning otherwise.\n#\n# You can override this using the -partitioner argument:\necho \"hello world\" | kafka-console-producer -topic=test -key=key -partitioner=random\n\n# Display all command line options\nkafka-console-producer -help\n```\n\n----------------------------------------\n\nTITLE: Basic Usage of Kafka Console Partition Consumer\nDESCRIPTION: Demonstrates the minimum required command line arguments to run the tool, specifying the topic, partition, and broker addresses.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-partitionconsumer/README.md#2025-04-23_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\n# Minimum invocation\nkafka-console-partitionconsumer -topic=test -partition=4 -brokers=kafka1:9092\n```\n\n----------------------------------------\n\nTITLE: Specifying Offsets in Kafka Console Partition Consumer\nDESCRIPTION: Examples of how to specify the starting offset when consuming messages, using either keywords like 'oldest' and 'newest' or a specific numeric offset.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-partitionconsumer/README.md#2025-04-23_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n# You can specify the offset you want to start at. It can be either\n# `oldest`, `newest`, or a specific offset number\nkafka-console-partitionconsumer -topic=test -partition=3 -offset=oldest\nkafka-console-partitionconsumer -topic=test -partition=2 -offset=1337\n```\n\n----------------------------------------\n\nTITLE: Running Minimal Kafka Producer Performance Test\nDESCRIPTION: Example of minimal command line invocation for testing Kafka producer performance, specifying brokers, message load, message size, and topic.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-producer-performance/README.md#2025-04-23_snippet_2\n\nLANGUAGE: shell\nCODE:\n```\nkafka-producer-performance \\\n\t\t-brokers=kafka:9092 \\\n\t\t-message-load=50000 \\\n\t\t-message-size=100 \\\n\t\t-topic=producer_test\n```\n\n----------------------------------------\n\nTITLE: Implementing Producer and Consumer Interceptors in Go\nDESCRIPTION: Adds support for producer and consumer interceptors as described in KIP-42 for the Sarama Kafka client library.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_6\n\nLANGUAGE: go\nCODE:\n```\n#1730 - @d1egoaz - KIP-42 Add producer and consumer interceptors\n```\n\n----------------------------------------\n\nTITLE: Basic Kafka Consumer Usage\nDESCRIPTION: Demonstrates the minimum required parameters to consume messages from a Kafka topic, specifying the topic name and broker addresses.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkafka-console-consumer -topic=test -brokers=kafka1:9092\n```\n\n----------------------------------------\n\nTITLE: Updating default Kafka protocol version in Sarama config\nDESCRIPTION: The default Kafka protocol version in the Sarama config has been updated to 2.1.0 in preparation for Kafka 4.0 dropping support for older protocol versions.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_4\n\nLANGUAGE: Go\nCODE:\n```\nvar DefaultVersion = V2_1_0_0\n```\n\n----------------------------------------\n\nTITLE: Configuring Kerberos Fast Negotiation in Go\nDESCRIPTION: Exposes configuration options for Kerberos fast negotiation in the Sarama Kafka client library.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_5\n\nLANGUAGE: go\nCODE:\n```\n#1466 - @rubenvp8510  - Expose kerberos fast negotiation configuration\n```\n\n----------------------------------------\n\nTITLE: Running the Interceptors Example (Shell)\nDESCRIPTION: Shows how to run the interceptors example using Go, either directly with go run or by building the binary first. Includes available command-line parameters.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/interceptors/README.md#2025-04-23_snippet_1\n\nLANGUAGE: sh\nCODE:\n```\ngo build && ./interceptors --h\nUsage of ./interceptors:\n  -brokers string\n        The Kafka brokers to connect to, as a comma separated list (default \"localhost:9092\")\n  -topic string\n        The Kafka topic to use (default \"default_topic\")\n```\n\n----------------------------------------\n\nTITLE: Using Environment Variables with Kafka Console Partition Consumer\nDESCRIPTION: Shows how to use the KAFKA_PEERS environment variable to specify Kafka broker addresses instead of using the command line argument.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-partitionconsumer/README.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\n# It will pick up a KAFKA_PEERS environment variable\nexport KAFKA_PEERS=kafka1:9092,kafka2:9092,kafka3:9092\nkafka-console-partitionconsumer -topic=test -partition=4\n```\n\n----------------------------------------\n\nTITLE: Implementing Gzip Compression Sync Pool in Go\nDESCRIPTION: Adds a sync pool for gzip compression levels 1-9 to improve performance in the Sarama Kafka client.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_8\n\nLANGUAGE: go\nCODE:\n```\n#1560 - @iyacontrol - add sync pool for gzip 1-9\n```\n\n----------------------------------------\n\nTITLE: Configuring TLS ServerName for Kafka Brokers in Go\nDESCRIPTION: Sets the TLS ServerName only for the current broker connection to fix TLS configuration issues in the Sarama library.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_7\n\nLANGUAGE: go\nCODE:\n```\n#1692 - @d1egoaz - Set tls ServerName to fix issue: either ServerName or InsecureSkipVerify must be specified in the tls.Config\n```\n\n----------------------------------------\n\nTITLE: Preventing infinite locking in ConsumerGroup.Close() for Sarama\nDESCRIPTION: Fixed an issue where ConsumerGroup.Close() could potentially lock indefinitely under certain conditions.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_3\n\nLANGUAGE: Go\nCODE:\n```\nfunc (c *ConsumerGroup) Close() error {\n  // Implementation to prevent infinite locking\n}\n```\n\n----------------------------------------\n\nTITLE: Returning KError instead of errors in Sarama API methods\nDESCRIPTION: The AlterConfigs and DescribeConfig methods now return KError instead of standard errors for more specific error handling.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_1\n\nLANGUAGE: Go\nCODE:\n```\nfunc (b *Broker) AlterConfigs(resources []*AlterConfigsResource, validateOnly bool) (*AlterConfigsResponse, error) {\n  // Method implementation\n  return response, KError(response.ErrorCode)\n}\n```\n\n----------------------------------------\n\nTITLE: Fixing backoff logic for member ID required error in Sarama\nDESCRIPTION: Optimized the backoff logic to avoid wasting time on member ID required errors in the consumer group implementation.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_2\n\nLANGUAGE: Go\nCODE:\n```\nif err == ErrMemberIDRequired {\n  // Skip backoff for this specific error\n  continue\n}\n// Apply backoff for other errors\n```\n\n----------------------------------------\n\nTITLE: Inspecting Kafka Messages with Headers (Shell)\nDESCRIPTION: Uses kafkacat to read messages from a Kafka topic and display their content along with headers that were added by the interceptor, such as trace_id and span_id.\nSOURCE: https://github.com/ibm/sarama/blob/main/examples/interceptors/README.md#2025-04-23_snippet_2\n\nLANGUAGE: sh\nCODE:\n```\nkafkacat -Cb localhost:9092 -t default_topic -f '\\n- %s\\nheaders: %h'\n```\n\n----------------------------------------\n\nTITLE: Handling Broker Session IDs in Go\nDESCRIPTION: Fixes an issue where brokers were continually allocating new Session IDs, potentially causing performance problems.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_9\n\nLANGUAGE: go\nCODE:\n```\n#1644 - @KJTsanaktsidis - Fix brokers continually allocating new Session IDs\n```\n\n----------------------------------------\n\nTITLE: Installing Sarama Tools with Go\nDESCRIPTION: Command to install all Sarama tools using Go's package manager. This will download and install all the command line utilities in the tools directory.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngo install github.com/IBM/sarama/tools/...@latest\n```\n\n----------------------------------------\n\nTITLE: Installing Kafka Console Consumer with Go\nDESCRIPTION: Command to install the kafka-console-consumer tool using Go's package manager.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_0\n\nLANGUAGE: shell\nCODE:\n```\ngo get github.com/IBM/sarama/tools/kafka-console-consumer\n```\n\n----------------------------------------\n\nTITLE: Installing Kafka Console Producer with Go\nDESCRIPTION: Command to install the kafka-console-producer tool using Go's package manager.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-producer/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngo get github.com/IBM/sarama/tools/kafka-console-producer\n```\n\n----------------------------------------\n\nTITLE: Installing Kafka Producer Performance Tool with Go\nDESCRIPTION: Command to install the kafka-producer-performance tool using Go's package manager. The tool is part of the IBM/sarama project and is used for testing Kafka producer performance.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-producer-performance/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngo get github.com/IBM/sarama/tools/kafka-producer-performance\n```\n\n----------------------------------------\n\nTITLE: Installing the Kafka Console Partition Consumer\nDESCRIPTION: Instructions for installing the kafka-console-partitionconsumer tool using Go's package manager.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-partitionconsumer/README.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngo get github.com/IBM/sarama/tools/kafka-console-partitionconsumer\n```\n\n----------------------------------------\n\nTITLE: Displaying Kafka Producer Performance Tool Options\nDESCRIPTION: Command to display all available command line options for the kafka-producer-performance tool.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-producer-performance/README.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\nkafka-producer-performance -help\n```\n\n----------------------------------------\n\nTITLE: Displaying Kafka Consumer Help\nDESCRIPTION: Command to show all available command line options for the kafka-console-consumer tool.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-consumer/README.md#2025-04-23_snippet_5\n\nLANGUAGE: shell\nCODE:\n```\nkafka-console-consumer -help\n```\n\n----------------------------------------\n\nTITLE: Displaying Help Information for Kafka Console Partition Consumer\nDESCRIPTION: Command to display all available command line options for the kafka-console-partitionconsumer tool.\nSOURCE: https://github.com/ibm/sarama/blob/main/tools/kafka-console-partitionconsumer/README.md#2025-04-23_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\n# Display all command line options\nkafka-console-partitionconsumer -help\n```\n\n----------------------------------------\n\nTITLE: Updating go.mod directive to Go 1.18 in Sarama\nDESCRIPTION: The go.mod directive has been updated to require Go 1.18 as the minimum version. This was necessary to continue receiving updates from third-party dependencies used for compression.\nSOURCE: https://github.com/ibm/sarama/blob/main/CHANGELOG.md#2025-04-23_snippet_0\n\nLANGUAGE: Go\nCODE:\n```\ngo 1.18\n```\n\n----------------------------------------\n\nTITLE: Creating a Signed-off-by Commit Message Manually\nDESCRIPTION: Example of how to manually format a commit message with a Signed-off-by line for DCO compliance. This format shows the required structure with a commit message followed by the Signed-off-by line containing the contributor's name and email.\nSOURCE: https://github.com/ibm/sarama/blob/main/CONTRIBUTING.md#2025-04-23_snippet_0\n\nLANGUAGE: git\nCODE:\n```\nfeat: this is my commit message\n\nSigned-off-by: Random J Developer <random@developer.example.org>\n```\n\n----------------------------------------\n\nTITLE: Using Git's -s Flag for Automatic Sign-off\nDESCRIPTION: Command demonstrating how to use Git's built-in -s flag to automatically append the Signed-off-by line to commit messages for DCO compliance.\nSOURCE: https://github.com/ibm/sarama/blob/main/CONTRIBUTING.md#2025-04-23_snippet_1\n\nLANGUAGE: shell\nCODE:\n```\n$ git commit -s -m 'This is my commit message'\n```"
  }
]