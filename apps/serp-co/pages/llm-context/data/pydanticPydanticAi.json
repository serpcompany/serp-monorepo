[
  {
    "owner": "pydantic",
    "repo": "pydantic-ai",
    "content": "TITLE: Advanced PydanticAI Implementation with Tools and Dependency Injection\nDESCRIPTION: A comprehensive example demonstrating how to create a bank support agent using PydanticAI with dependency injection, tools, dynamic system prompts, and structured responses. The agent interacts with a database to retrieve customer information and provide support based on customer queries.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent, RunContext\n\nfrom bank_database import DatabaseConn\n\n\n# SupportDependencies is used to pass data, connections, and logic into the model that will be needed when running\n# system prompt and tool functions. Dependency injection provides a type-safe way to customise the behavior of your agents.\n@dataclass\nclass SupportDependencies:\n    customer_id: int\n    db: DatabaseConn\n\n\n# This pydantic model defines the structure of the output returned by the agent.\nclass SupportOutput(BaseModel):\n    support_advice: str = Field(description='Advice returned to the customer')\n    block_card: bool = Field(description=\"Whether to block the customer's card\")\n    risk: int = Field(description='Risk level of query', ge=0, le=10)\n\n\n# This agent will act as first-tier support in a bank.\n# Agents are generic in the type of dependencies they accept and the type of output they return.\n# In this case, the support agent has type `Agent[SupportDependencies, SupportOutput]`.\nsupport_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=SupportDependencies,\n    # The response from the agent will, be guaranteed to be a SupportOutput,\n    # if validation fails the agent is prompted to try again.\n    output_type=SupportOutput,\n    system_prompt=(\n        'You are a support agent in our bank, give the '\n        'customer support and judge the risk level of their query.'\n    ),\n)\n\n\n# Dynamic system prompts can make use of dependency injection.\n# Dependencies are carried via the `RunContext` argument, which is parameterized with the `deps_type` from above.\n# If the type annotation here is wrong, static type checkers will catch it.\n@support_agent.system_prompt\nasync def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:\n    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\n    return f\"The customer's name is {customer_name!r}\"\n\n\n# `tool` let you register functions which the LLM may call while responding to a user.\n# Again, dependencies are carried via `RunContext`, any other arguments become the tool schema passed to the LLM.\n# Pydantic is used to validate these arguments, and errors are passed back to the LLM so it can retry.\n@support_agent.tool\nasync def customer_balance(\n        ctx: RunContext[SupportDependencies], include_pending: bool\n) -> float:\n    \"\"\"Returns the customer's current account balance.\"\"\"\n    # The docstring of a tool is also passed to the LLM as the description of the tool.\n    # Parameter descriptions are extracted from the docstring and added to the parameter schema sent to the LLM.\n    balance = await ctx.deps.db.customer_balance(\n        id=ctx.deps.customer_id,\n        include_pending=include_pending,\n    )\n    return balance\n\n\n...  # In a real use case, you'd add more tools and a longer system prompt\n\n\nasync def main():\n    deps = SupportDependencies(customer_id=123, db=DatabaseConn())\n    # Run the agent asynchronously, conducting a conversation with the LLM until a final response is reached.\n    # Even in this fairly simple case, the agent will exchange multiple messages with the LLM as tools are called to retrieve an output.\n    result = await support_agent.run('What is my balance?', deps=deps)\n    # The `result.output` will be validated with Pydantic to guarantee it is a `SupportOutput`. Since the agent is generic,\n    # it'll also be typed as a `SupportOutput` to aid with static type checking.\n    print(result.output)\n    \"\"\"\n    support_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1\n    \"\"\"\n\n    result = await support_agent.run('I just lost my card!', deps=deps)\n    print(result.output)\n    \"\"\"\n    support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions.\" block_card=True risk=8\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Programmatic Agent Hand-off Implementation\nDESCRIPTION: Demonstrates programmatic agent hand-off pattern where multiple agents are called in sequence with application code controlling the flow. Shows flight search and seat preference handling.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Literal, Union\nfrom pydantic import BaseModel, Field\nfrom rich.prompt import Prompt\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.messages import ModelMessage\nfrom pydantic_ai.usage import Usage, UsageLimits\n\nclass FlightDetails(BaseModel):\n    flight_number: str\n\nclass Failed(BaseModel):\n    \"\"\"Unable to find a satisfactory choice.\"\"\"\n\nflight_search_agent = Agent[None, Union[FlightDetails, Failed]](\n    'openai:gpt-4o',\n    output_type=Union[FlightDetails, Failed],\n    system_prompt=(\n        'Use the \"flight_search\" tool to find a flight '\n        'from the given origin to the given destination.'\n    ),\n)\n\n@flight_search_agent.tool\nasync def flight_search(\n    ctx: RunContext[None], origin: str, destination: str\n) -> Union[FlightDetails, None]:\n    return FlightDetails(flight_number='AK456')\n\nusage_limits = UsageLimits(request_limit=15)\n\nasync def find_flight(usage: Usage) -> Union[FlightDetails, None]:\n    message_history: Union[list[ModelMessage], None] = None\n    for _ in range(3):\n        prompt = Prompt.ask(\n            'Where would you like to fly from and to?',\n        )\n        result = await flight_search_agent.run(\n            prompt,\n            message_history=message_history,\n            usage=usage,\n            usage_limits=usage_limits,\n        )\n        if isinstance(result.output, FlightDetails):\n            return result.output\n        else:\n            message_history = result.all_messages(\n                output_tool_return_content='Please try again.'\n            )\n\nclass SeatPreference(BaseModel):\n    row: int = Field(ge=1, le=30)\n    seat: Literal['A', 'B', 'C', 'D', 'E', 'F']\n```\n\n----------------------------------------\n\nTITLE: Vending Machine Graph Definition\nDESCRIPTION: Defines a stateful graph representing a vending machine using pydantic-graph. The graph includes nodes for inserting coins, selecting products, and purchasing items, managing the user's balance and product selection as state. The graph utilizes dataclasses for state management and Pydantic's BaseNode for node definition.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom rich.prompt import Prompt\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass MachineState:  # (1)!\n    user_balance: float = 0.0\n    product: str | None = None\n\n\n@dataclass\nclass InsertCoin(BaseNode[MachineState]):  # (3)!\n    async def run(self, ctx: GraphRunContext[MachineState]) -> CoinsInserted:  # (16)!\n        return CoinsInserted(float(Prompt.ask('Insert coins')))\n\n\n@dataclass\nclass CoinsInserted(BaseNode[MachineState]):\n    amount: float  # (5)!\n\n    async def run(\n        self, ctx: GraphRunContext[MachineState]\n    ) -> SelectProduct | Purchase:  # (17)!\n        ctx.state.user_balance += self.amount  # (6)!\n        if ctx.state.product is not None:  # (7)!\n            return Purchase(ctx.state.product)\n        else:\n            return SelectProduct()\n\n\n@dataclass\nclass SelectProduct(BaseNode[MachineState]):\n    async def run(self, ctx: GraphRunContext[MachineState]) -> Purchase:\n        return Purchase(Prompt.ask('Select product'))\n\n\nPRODUCT_PRICES = {  # (2)!\n    'water': 1.25,\n    'soda': 1.50,\n    'crisps': 1.75,\n    'chocolate': 2.00,\n}\n\n\n@dataclass\nclass Purchase(BaseNode[MachineState, None, None]):  # (18)!\n    product: str\n\n    async def run(\n        self, ctx: GraphRunContext[MachineState]\n    ) -> End | InsertCoin | SelectProduct:\n        if price := PRODUCT_PRICES.get(self.product):  # (8)!\n            ctx.state.product = self.product  # (9)!\n            if ctx.state.user_balance >= price:  # (10)!\n                ctx.state.user_balance -= price\n                return End(None)\n            else:\n                diff = price - ctx.state.user_balance\n                print(f'Not enough money for {self.product}, need {diff:0.2f} more')\n                #> Not enough money for crisps, need 0.75 more\n                return InsertCoin()  # (11)!\n        else:\n            print(f'No such product: {self.product}, try again')\n            return SelectProduct()  # (12)!\n\n\nvending_machine_graph = Graph(  # (13)!\n    nodes=[InsertCoin, CoinsInserted, SelectProduct, Purchase]\n)\n\n\nasync def main():\n    state = MachineState()  # (14)!\n    await vending_machine_graph.run(InsertCoin(), state=state)  # (15)!\n    print(f'purchase successful item={state.product} change={state.user_balance:0.2f}')\n    #> purchase successful item=crisps change=0.25\n```\n\n----------------------------------------\n\nTITLE: Agent Delegation with Dependencies in PydanticAI\nDESCRIPTION: Shows how to implement agent delegation with shared dependencies between agents. Demonstrates proper dependency initialization and passing between parent and delegate agents.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\nimport httpx\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass ClientAndKey:\n    http_client: httpx.AsyncClient\n    api_key: str\n\njoke_selection_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=ClientAndKey,\n    system_prompt=(\n        'Use the `joke_factory` tool to generate some jokes on the given subject, '\n        'then choose the best. You must return just a single joke.'\n    ),\n)\njoke_generation_agent = Agent(\n    'gemini-1.5-flash',\n    deps_type=ClientAndKey,\n    output_type=list[str],\n    system_prompt=(\n        'Use the \"get_jokes\" tool to get some jokes on the given subject, '\n        'then extract each joke into a list.'\n    ),\n)\n\n@joke_selection_agent.tool\nasync def joke_factory(ctx: RunContext[ClientAndKey], count: int) -> list[str]:\n    r = await joke_generation_agent.run(\n        f'Please generate {count} jokes.',\n        deps=ctx.deps,\n        usage=ctx.usage,\n    )\n    return r.output\n\n@joke_generation_agent.tool\nasync def get_jokes(ctx: RunContext[ClientAndKey], count: int) -> str:\n    response = await ctx.deps.http_client.get(\n        'https://example.com',\n        params={'count': count},\n        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},\n    )\n    response.raise_for_status()\n    return response.text\n```\n\n----------------------------------------\n\nTITLE: Implementing Reflection and Self-Correction in Pydantic AI Tools\nDESCRIPTION: This example demonstrates how to implement retry mechanisms in Pydantic AI tools. It shows how to use ModelRetry exceptions to request that the model make another attempt when validation fails, with customizable retry limits for tools and agents.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent, RunContext, ModelRetry\n\nfrom fake_database import DatabaseConn\n\n\nclass ChatResult(BaseModel):\n    user_id: int\n    message: str\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=DatabaseConn,\n    output_type=ChatResult,\n)\n\n\n@agent.tool(retries=2)\ndef get_user_by_name(ctx: RunContext[DatabaseConn], name: str) -> int:\n    \"\"\"Get a user's ID from their full name.\"\"\"\n    print(name)\n    #> John\n    #> John Doe\n    user_id = ctx.deps.users.get(name=name)\n    if user_id is None:\n        raise ModelRetry(\n            f'No user found with name {name!r}, remember to provide their full name'\n        )\n    return user_id\n\n\nresult = agent.run_sync(\n    'Send a message to John Doe asking for coffee next week', deps=DatabaseConn()\n)\nprint(result.output)\n\"\"\"\nuser_id=123 message='Hello John, would you be free for coffee sometime next week? Let me know what works for you!'\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: SQL Query Validation with Output Validator\nDESCRIPTION: Implements asynchronous SQL query validation using output validator functions. Demonstrates handling both successful queries and invalid requests.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Union\n\nfrom fake_database import DatabaseConn, QueryError\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent, RunContext, ModelRetry\n\n\nclass Success(BaseModel):\n    sql_query: str\n\n\nclass InvalidRequest(BaseModel):\n    error_message: str\n\n\nOutput = Union[Success, InvalidRequest]\nagent: Agent[DatabaseConn, Output] = Agent(\n    'google-gla:gemini-1.5-flash',\n    output_type=Output,  # type: ignore\n    deps_type=DatabaseConn,\n    system_prompt='Generate PostgreSQL flavored SQL queries based on user input.',\n)\n\n\n@agent.output_validator\nasync def validate_sql(ctx: RunContext[DatabaseConn], output: Output) -> Output:\n    if isinstance(output, InvalidRequest):\n        return output\n    try:\n        await ctx.deps.execute(f'EXPLAIN {output.sql_query}')\n    except QueryError as e:\n        raise ModelRetry(f'Invalid query: {e}') from e\n    else:\n        return output\n\n\nresult = agent.run_sync(\n    'get me users who were last active yesterday.', deps=DatabaseConn()\n)\nprint(result.output)\n#> sql_query='SELECT * FROM users WHERE last_active::date = today() - interval 1 day'\n```\n\n----------------------------------------\n\nTITLE: Complete Example with Dependencies in System Prompts, Tools, and Output Validators\nDESCRIPTION: A comprehensive example showing dependencies used across all PydanticAI components: system prompts, tools, and output validators. Each component receives the RunContext parameter to access dependencies for HTTP requests and API authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport httpx\n\nfrom pydantic_ai import Agent, ModelRetry, RunContext\n\n\n@dataclass\nclass MyDeps:\n    api_key: str\n    http_client: httpx.AsyncClient\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=MyDeps,\n)\n\n\n@agent.system_prompt\nasync def get_system_prompt(ctx: RunContext[MyDeps]) -> str:\n    response = await ctx.deps.http_client.get('https://example.com')\n    response.raise_for_status()\n    return f'Prompt: {response.text}'\n\n\n@agent.tool  # (1)!\nasync def get_joke_material(ctx: RunContext[MyDeps], subject: str) -> str:\n    response = await ctx.deps.http_client.get(\n        'https://example.com#jokes',\n        params={'subject': subject},\n        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},\n    )\n    response.raise_for_status()\n    return response.text\n\n\n@agent.output_validator  # (2)!\nasync def validate_output(ctx: RunContext[MyDeps], output: str) -> str:\n    response = await ctx.deps.http_client.post(\n        'https://example.com#validate',\n        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},\n        params={'query': output},\n    )\n    if response.status_code == 400:\n        raise ModelRetry(f'invalid response: {response.text}')\n    response.raise_for_status()\n    return output\n\n\nasync def main():\n    async with httpx.AsyncClient() as client:\n        deps = MyDeps('foobar', client)\n        result = await agent.run('Tell me a joke.', deps=deps)\n        print(result.output)\n        #> Did you hear about the toothpaste scandal? They called it Colgate.\n```\n\n----------------------------------------\n\nTITLE: Managing Multi-Run Conversations\nDESCRIPTION: Shows how to maintain conversation context across multiple runs using message history.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o')\n\n# First run\nresult1 = agent.run_sync('Who was Albert Einstein?')\nprint(result1.output)\n#> Albert Einstein was a German-born theoretical physicist.\n\n# Second run, passing previous messages\nresult2 = agent.run_sync(\n    'What was his most famous equation?',\n    message_history=result1.new_messages(),\n)\nprint(result2.output)\n#> Albert Einstein's most famous equation is (E = mc^2).\n```\n\n----------------------------------------\n\nTITLE: GenAI Email Feedback Graph\nDESCRIPTION: This code defines a Pydantic Graph that uses Pydantic-AI Agents to generate a welcome email and provide feedback on it. It defines dataclasses for `User`, `Email`, and `State`, and uses `Agent` to write and provide feedback on the email. The `WriteEmail` and `Feedback` nodes handle the email generation and review processes, respectively. It requires the `pydantic`, `pydantic_ai`, and `pydantic_graph` libraries.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations as _annotations\n\nfrom dataclasses import dataclass, field\n\nfrom pydantic import BaseModel, EmailStr\n\nfrom pydantic_ai import Agent, format_as_xml\nfrom pydantic_ai.messages import ModelMessage\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass User:\n    name: str\n    email: EmailStr\n    interests: list[str]\n\n\n@dataclass\nclass Email:\n    subject: str\n    body: str\n\n\n@dataclass\nclass State:\n    user: User\n    write_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n\nemail_writer_agent = Agent(\n    'google-vertex:gemini-1.5-pro',\n    output_type=Email,\n    system_prompt='Write a welcome email to our tech blog.',\n)\n\n\n@dataclass\nclass WriteEmail(BaseNode[State]):\n    email_feedback: str | None = None\n\n    async def run(self, ctx: GraphRunContext[State]) -> Feedback:\n        if self.email_feedback:\n            prompt = (\n                f'Rewrite the email for the user:\\n'\n                f'{format_as_xml(ctx.state.user)}\\n'\n                f'Feedback: {self.email_feedback}'\n            )\n        else:\n            prompt = (\n                f'Write a welcome email for the user:\\n'\n                f'{format_as_xml(ctx.state.user)}'\n            )\n\n        result = await email_writer_agent.run(\n            prompt,\n            message_history=ctx.state.write_agent_messages,\n        )\n        ctx.state.write_agent_messages += result.new_messages()\n        return Feedback(result.output)\n\n\nclass EmailRequiresWrite(BaseModel):\n    feedback: str\n\n\nclass EmailOk(BaseModel):\n    pass\n\n\nfeedback_agent = Agent[None, EmailRequiresWrite | EmailOk](\n    'openai:gpt-4o',\n    output_type=EmailRequiresWrite | EmailOk,  # type: ignore\n    system_prompt=(\n        'Review the email and provide feedback, email must reference the users specific interests.'\n    ),\n)\n\n\n@dataclass\nclass Feedback(BaseNode[State, None, Email]):\n    email: Email\n\n    async def run(\n        self, ctx: GraphRunContext[State],\n    ) -> WriteEmail | End[Email]:\n        prompt = format_as_xml({'user': ctx.state.user, 'email': self.email})\n        result = await feedback_agent.run(prompt)\n        if isinstance(result.output, EmailRequiresWrite):\n            return WriteEmail(email_feedback=result.output.feedback)\n        else:\n            return End(self.email)\n\n\nasync def main():\n    user = User(\n        name='John Doe',\n        email='john.joe@example.com',\n        interests=['Haskel', 'Lisp', 'Fortran'],\n    )\n    state = State(user)\n    feedback_graph = Graph(nodes=(WriteEmail, Feedback))\n    result = await feedback_graph.run(WriteEmail(), state=state)\n    print(result.output)\n    \"\"\"\n    Email(\n        subject='Welcome to our tech blog!',\n        body='Hello John, Welcome to our tech blog! ...',\n    )\n    \"\"\"\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Static and Dynamic System Prompts in Pydantic AI Agents\nDESCRIPTION: This example demonstrates how to create an agent with both static system prompts (defined at creation time) and dynamic system prompts (defined via decorated functions that run at execution time). It showcases how to incorporate runtime information like dependencies and current date.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nfrom pydantic_ai import Agent, RunContext\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=str,  # (1)!\n    system_prompt=\"Use the customer's name while replying to them.\",  # (2)!\n)\n\n\n@agent.system_prompt  # (3)!\ndef add_the_users_name(ctx: RunContext[str]) -> str:\n    return f\"The user's name is {ctx.deps}.\"\n\n\n@agent.system_prompt\ndef add_the_date() -> str:  # (4)!\n    return f'The date is {date.today()}.'\n\n\nresult = agent.run_sync('What is the date?', deps='Frank')\nprint(result.output)\n#> Hello Frank, the date today is 2032-01-02.\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Evaluators in Python\nDESCRIPTION: Shows how to create and add custom evaluators to a dataset, including both built-in and user-defined evaluators.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom simple_eval_dataset import dataset\n\nfrom pydantic_evals.evaluators import Evaluator, EvaluatorContext\nfrom pydantic_evals.evaluators.common import IsInstance\n\ndataset.add_evaluator(IsInstance(type_name='str'))\n\n\n@dataclass\nclass MyEvaluator(Evaluator):\n    async def evaluate(self, ctx: EvaluatorContext[str, str]) -> float:\n        if ctx.output == ctx.expected_output:\n            return 1.0\n        elif (\n            isinstance(ctx.output, str)\n            and ctx.expected_output.lower() in ctx.output.lower()\n        ):\n            return 0.8\n        else:\n            return 0.0\n\n\ndataset.add_evaluator(MyEvaluator())\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Dependencies in Python\nDESCRIPTION: Example showing how to create a custom dependency class for a Pydantic-AI agent with HTTP client integration and system prompt factory. Demonstrates dependency injection pattern for agent configuration and runtime behavior.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport httpx\n\nfrom pydantic_ai import Agent, RunContext\n\n\n@dataclass\nclass MyDeps:\n    api_key: str\n    http_client: httpx.AsyncClient\n\n    async def system_prompt_factory(self) -> str:  \n        response = await self.http_client.get('https://example.com')\n        response.raise_for_status()\n        return f'Prompt: {response.text}'\n\n\njoke_agent = Agent('openai:gpt-4o', deps_type=MyDeps)\n\n\n@joke_agent.system_prompt\nasync def get_system_prompt(ctx: RunContext[MyDeps]) -> str:\n    return await ctx.deps.system_prompt_factory()  \n\n\nasync def application_code(prompt: str) -> str:  \n    ...\n    ...\n    # now deep within application code we call our agent\n    async with httpx.AsyncClient() as client:\n        app_deps = MyDeps('foobar', client)\n        result = await joke_agent.run(prompt, deps=app_deps)  \n    return result.output\n```\n\n----------------------------------------\n\nTITLE: Implementing Request Limits with Infinite Loop Prevention\nDESCRIPTION: Shows how to implement request limits to prevent infinite loops in tool calling scenarios using UsageLimits.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom typing_extensions import TypedDict\n\nfrom pydantic_ai import Agent, ModelRetry\nfrom pydantic_ai.exceptions import UsageLimitExceeded\nfrom pydantic_ai.usage import UsageLimits\n\n\nclass NeverOutputType(TypedDict):\n    \"\"\"\n    Never ever coerce data to this type.\n    \"\"\"\n\n    never_use_this: str\n\n\nagent = Agent(\n    'anthropic:claude-3-5-sonnet-latest',\n    retries=3,\n    output_type=NeverOutputType,\n    system_prompt='Any time you get a response, call the `infinite_retry_tool` to produce another response.',\n)\n\n\n@agent.tool_plain(retries=5)\ndef infinite_retry_tool() -> int:\n    raise ModelRetry('Please try again.')\n\n\ntry:\n    result_sync = agent.run_sync(\n        'Begin infinite retry loop!', usage_limits=UsageLimits(request_limit=3)\n    )\nexcept UsageLimitExceeded as e:\n    print(e)\n    #> The next request would exceed the request_limit of 3\n```\n\n----------------------------------------\n\nTITLE: Advanced Bank Support Agent with Tools and Dependency Injection\nDESCRIPTION: Implements a bank support agent using PydanticAI with structured output validation, dependency injection, dynamic system prompts, and tool functions. Shows integration with external services and type-safe implementation patterns.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent, RunContext\n\nfrom bank_database import DatabaseConn\n\n\n@dataclass\nclass SupportDependencies:\n    customer_id: int\n    db: DatabaseConn\n\n\nclass SupportOutput(BaseModel):\n    support_advice: str = Field(description='Advice returned to the customer')\n    block_card: bool = Field(description=\"Whether to block the customer's card\")\n    risk: int = Field(description='Risk level of query', ge=0, le=10)\n\n\nsupport_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=SupportDependencies,\n    output_type=SupportOutput,\n    system_prompt=(\n        'You are a support agent in our bank, give the '\n        'customer support and judge the risk level of their query.'\n    ),\n)\n\n\n@support_agent.system_prompt\nasync def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:\n    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\n    return f\"The customer's name is {customer_name!r}\"\n\n\n@support_agent.tool\nasync def customer_balance(\n    ctx: RunContext[SupportDependencies], include_pending: bool\n) -> float:\n    \"\"\"Returns the customer's current account balance.\"\"\"\n    return await ctx.deps.db.customer_balance(\n        id=ctx.deps.customer_id,\n        include_pending=include_pending,\n    )\n\n\nasync def main():\n    deps = SupportDependencies(customer_id=123, db=DatabaseConn())\n    result = await support_agent.run('What is my balance?', deps=deps)\n    print(result.output)\n    \"\"\"\n    support_advice='Hello John, your current account balance, including pending transactions, is $123.45.' block_card=False risk=1\n    \"\"\"\n\n    result = await support_agent.run('I just lost my card!', deps=deps)\n    print(result.output)\n    \"\"\"\n    support_advice=\"I'm sorry to hear that, John. We are temporarily blocking your card to prevent unauthorized transactions.\" block_card=True risk=8\n    \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Running PostgreSQL with Docker for SQL Validation\nDESCRIPTION: Command to run PostgreSQL in a Docker container for validating the generated SQL queries. It runs on port 54320 to avoid conflicts with other PostgreSQL instances.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndocker run --rm -e POSTGRES_PASSWORD=postgres -p 54320:5432 postgres\n```\n\n----------------------------------------\n\nTITLE: Generating YAML Test Dataset with Pydantic Models in Python\nDESCRIPTION: Demonstrates how to create a structured test dataset using Pydantic models for question-answer pairs. Defines input schema, output schema, and metadata models, then generates and saves the dataset in YAML format with accompanying JSON schema.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nfrom pathlib import Path\n\nfrom pydantic import BaseModel, Field\n\nfrom pydantic_evals import Dataset\nfrom pydantic_evals.generation import generate_dataset\n\n\nclass QuestionInputs(BaseModel, use_attribute_docstrings=True):\n    \"\"\"Model for question inputs.\"\"\"\n\n    question: str\n    \"\"\"A question to answer\"\"\"\n    context: str | None = None\n    \"\"\"Optional context for the question\"\"\"\n\n\nclass AnswerOutput(BaseModel, use_attribute_docstrings=True):\n    \"\"\"Model for expected answer outputs.\"\"\"\n\n    answer: str\n    \"\"\"The answer to the question\"\"\"\n    confidence: float = Field(ge=0, le=1)\n    \"\"\"Confidence level (0-1)\"\"\"\n\n\nclass MetadataType(BaseModel, use_attribute_docstrings=True):\n    \"\"\"Metadata model for test cases.\"\"\"\n\n    difficulty: str\n    \"\"\"Difficulty level (easy, medium, hard)\"\"\"\n    category: str\n    \"\"\"Question category\"\"\"\n\n\nasync def main():\n    dataset = await generate_dataset(\n        dataset_type=Dataset[QuestionInputs, AnswerOutput, MetadataType],\n        n_examples=2,\n        extra_instructions=\"\"\"\n        Generate question-answer pairs about world capitals and landmarks.\n        Make sure to include both easy and challenging questions.\n        \"\"\",\n    )\n    output_file = Path('questions_cases.yaml')\n    dataset.to_file(output_file)\n```\n\n----------------------------------------\n\nTITLE: Using Instructions with Pydantic AI Agents\nDESCRIPTION: This snippet shows how to use instructions with a Pydantic AI agent. Unlike system prompts, instructions are only included in the current request and not retained in the message history for subsequent requests, making them more suitable for most use cases.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent(\n    'openai:gpt-4o',\n    instructions='You are a helpful assistant that can answer questions and help with tasks.',  # (1)!\n)\n\nresult = agent.run_sync('What is the capital of France?')\nprint(result.output)\n#> Paris\n```\n\n----------------------------------------\n\nTITLE: Unit Testing PydanticAI Weather Forecast Agent\nDESCRIPTION: Comprehensive unit test implementation for the weather forecast agent using TestModel, pytest, and dirty-equals. The test verifies the agent's behavior, message flow, and database interactions without making real LLM calls.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/testing.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import timezone\nimport pytest\n\nfrom dirty_equals import IsNow, IsStr\n\nfrom pydantic_ai import models, capture_run_messages\nfrom pydantic_ai.models.test import TestModel\nfrom pydantic_ai.messages import (\n    ModelResponse,\n    SystemPromptPart,\n    TextPart,\n    ToolCallPart,\n    ToolReturnPart,\n    UserPromptPart,\n    ModelRequest,\n)\n\nfrom fake_database import DatabaseConn\nfrom weather_app import run_weather_forecast, weather_agent\n\npytestmark = pytest.mark.anyio\nmodels.ALLOW_MODEL_REQUESTS = False\n\nasync def test_forecast():\n    conn = DatabaseConn()\n    user_id = 1\n    with capture_run_messages() as messages:\n        with weather_agent.override(model=TestModel()):\n            prompt = 'What will the weather be like in London on 2024-11-28?'\n            await run_weather_forecast([(prompt, user_id)], conn)\n\n    forecast = await conn.get_forecast(user_id)\n    assert forecast == '{\"weather_forecast\":\"Sunny with a chance of rain\"}'\n\n    assert messages == [\n        ModelRequest(\n            parts=[\n                SystemPromptPart(\n                    content='Providing a weather forecast at the locations the user provides.',\n                    timestamp=IsNow(tz=timezone.utc),\n                ),\n                UserPromptPart(\n                    content='What will the weather be like in London on 2024-11-28?',\n                    timestamp=IsNow(tz=timezone.utc),\n                ),\n            ]\n        ),\n        ModelResponse(\n            parts=[\n                ToolCallPart(\n                    tool_name='weather_forecast',\n                    args={\n                        'location': 'a',\n                        'forecast_date': '2024-01-01',\n                    },\n                    tool_call_id=IsStr(),\n                )\n            ],\n            model_name='test',\n            timestamp=IsNow(tz=timezone.utc),\n        ),\n        ModelRequest(\n            parts=[\n                ToolReturnPart(\n                    tool_name='weather_forecast',\n                    content='Sunny with a chance of rain',\n                    tool_call_id=IsStr(),\n                    timestamp=IsNow(tz=timezone.utc),\n                ),\n            ],\n        ),\n        ModelResponse(\n            parts=[\n                TextPart(\n                    content='{\"weather_forecast\":\"Sunny with a chance of rain\"}',\n                )\n            ],\n            model_name='test',\n            timestamp=IsNow(tz=timezone.utc),\n        ),\n    ]\n```\n\n----------------------------------------\n\nTITLE: Installing Pydantic Evals Package\nDESCRIPTION: Commands to install the Pydantic Evals package and its optional dependency logfire for OpenTelemetry traces and evaluation result logging.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add pydantic-evals\n```\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add 'pydantic-evals[logfire]'\n```\n\n----------------------------------------\n\nTITLE: Type Safety Implementation Example\nDESCRIPTION: Demonstrates PydanticAI's type safety features with examples of type checking and common mistakes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom pydantic_ai import Agent, RunContext\n\n\n@dataclass\nclass User:\n    name: str\n\n\nagent = Agent(\n    'test',\n    deps_type=User,\n    output_type=bool,\n)\n\n\n@agent.system_prompt\ndef add_user_name(ctx: RunContext[str]) -> str:\n    return f\"The user's name is {ctx.deps}.\"\n\n\ndef foobar(x: bytes) -> None:\n    pass\n\n\nresult = agent.run_sync('Does their name start with \"A\"?', deps=User('Anne'))\nfoobar(result.output)\n```\n\n----------------------------------------\n\nTITLE: Dynamic Tool Description Customization in PydanticAI\nDESCRIPTION: Demonstrates how to dynamically modify tool parameter descriptions using a prepare function. Uses the Tool dataclass to create a tool with context-dependent parameter descriptions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\nfrom typing import Literal\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.models.test import TestModel\nfrom pydantic_ai.tools import Tool, ToolDefinition\n\ndef greet(name: str) -> str:\n    return f'hello {name}'\n\nasync def prepare_greet(ctx: RunContext[Literal['human', 'machine']], tool_def: ToolDefinition) -> ToolDefinition | None:\n    d = f'Name of the {ctx.deps} to greet.'\n    tool_def.parameters_json_schema['properties']['name']['description'] = d\n    return tool_def\n\ngreet_tool = Tool(greet, prepare=prepare_greet)\ntest_model = TestModel()\nagent = Agent(test_model, tools=[greet_tool], deps_type=Literal['human', 'machine'])\n\nresult = agent.run_sync('testing...', deps='human')\nprint(result.output)\nprint(test_model.last_model_request_parameters.function_tools)\n```\n\n----------------------------------------\n\nTITLE: Saving and Loading Datasets in Python\nDESCRIPTION: Demonstrates how to save a dataset to a YAML file and load it back, showcasing dataset persistence capabilities.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nfrom judge_recipes import CustomerOrder, Recipe, recipe_dataset\n\nfrom pydantic_evals import Dataset\n\nrecipe_transforms_file = Path('recipe_transform_tests.yaml')\nrecipe_dataset.to_file(recipe_transforms_file)\nprint(recipe_transforms_file.read_text())\n```\n\n----------------------------------------\n\nTITLE: Run Question Graph with Persistence\nDESCRIPTION: This script demonstrates running the question-answering graph with state persistence using `FileStatePersistence`. It loads the graph's state from a file, gets the user's answer from the command line, and continues the graph execution. It showcases how to load the previous state, run the next node, and persist the state for future runs.  Dependencies include `sys`, `pathlib`, and the graph definition from `ai_q_and_a_graph.py`.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_15\n\nLANGUAGE: python\nCODE:\n```\nimport sys\nfrom pathlib import Path\n\nfrom pydantic_graph import End\nfrom pydantic_graph.persistence.file import FileStatePersistence\nfrom pydantic_ai.messages import ModelMessage  # noqa: F401\n\nfrom ai_q_and_a_graph import Ask, question_graph, Evaluate, QuestionState, Answer\n\n\nasync def main():\n    answer: str | None = sys.argv[1] if len(sys.argv) > 1 else None  # (1)!\n    persistence = FileStatePersistence(Path('question_graph.json'))  # (2)!\n    persistence.set_graph_types(question_graph)  # (3)!\n\n    if snapshot := await persistence.load_next():  # (4)!\n        state = snapshot.state\n        assert answer is not None\n        node = Evaluate(answer)\n    else:\n        state = QuestionState()\n        node = Ask()  # (5)!\n\n    async with question_graph.iter(node, state=state, persistence=persistence) as run:\n        while True:\n            node = await run.next()  # (6)!\n            if isinstance(node, End):  # (7)!\n                print('END:', node.data)\n                history = await persistence.load_all()  # (8)!\n                print([e.node for e in history])\n                break\n            elif isinstance(node, Answer):  # (9)!\n                print(node.question)\n                #> What is the capital of France?\n                break\n            # otherwise just continue\n```\n\n----------------------------------------\n\nTITLE: Define Question Graph with Pydantic-AI\nDESCRIPTION: Defines a question-answering graph using pydantic-graph and pydantic-ai. The graph involves asking a question, getting an answer, evaluating the answer, and reprimanding if incorrect. It uses `Agent` from `pydantic-ai` to ask and evaluate questions and answers. The `QuestionState` dataclass is used to persist the state of the question-answering process.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations as _annotations\n\nfrom dataclasses import dataclass, field\n\nfrom groq import BaseModel\nfrom pydantic_graph import (\n    BaseNode,\n    End,\n    Graph,\n    GraphRunContext,\n)\n\nfrom pydantic_ai import Agent, format_as_xml\nfrom pydantic_ai.messages import ModelMessage\n\nask_agent = Agent('openai:gpt-4o', output_type=str, instrument=True)\n\n\n@dataclass\nclass QuestionState:\n    question: str | None = None\n    ask_agent_messages: list[ModelMessage] = field(default_factory=list)\n    evaluate_agent_messages: list[ModelMessage] = field(default_factory=list)\n\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Answer:\n        result = await ask_agent.run(\n            'Ask a simple question with a single correct answer.',\n            message_history=ctx.state.ask_agent_messages,\n        )\n        ctx.state.ask_agent_messages += result.new_messages()\n        ctx.state.question = result.output\n        return Answer(result.output)\n\n\n@dataclass\nclass Answer(BaseNode[QuestionState]):\n    question: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Evaluate:\n        answer = input(f'{self.question}: ')\n        return Evaluate(answer)\n\n\nclass EvaluationResult(BaseModel, use_attribute_docstrings=True):\n    correct: bool\n    \"\"\"Whether the answer is correct.\"\"\"\n    comment: str\n    \"\"\"Comment on the answer, reprimand the user if the answer is wrong.\"\"\"\n\n\nevaluate_agent = Agent(\n    'openai:gpt-4o',\n    output_type=EvaluationResult,\n    system_prompt='Given a question and answer, evaluate if the answer is correct.',\n)\n\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState, None, str]):\n    answer: str\n\n    async def run(\n        self,\n        ctx: GraphRunContext[QuestionState],\n    ) -> End[str] | Reprimand:\n        assert ctx.state.question is not None\n        result = await evaluate_agent.run(\n            format_as_xml({'question': ctx.state.question, 'answer': self.answer}),\n            message_history=ctx.state.evaluate_agent_messages,\n        )\n        ctx.state.evaluate_agent_messages += result.new_messages()\n        if result.output.correct:\n            return End(result.output.comment)\n        else:\n            return Reprimand(result.output.comment)\n\n\n@dataclass\nclass Reprimand(BaseNode[QuestionState]):\n    comment: str\n\n    async def run(self, ctx: GraphRunContext[QuestionState]) -> Ask:\n        print(f'Comment: {self.comment}')\n        ctx.state.question = None\n        return Ask()\n\n\nquestion_graph = Graph(\n    nodes=(Ask, Answer, Evaluate, Reprimand), state_type=QuestionState\n)\n```\n\n----------------------------------------\n\nTITLE: Handling Model Errors in Pydantic AI Agents\nDESCRIPTION: This snippet demonstrates how to handle unexpected model behavior and errors in Pydantic AI. It uses the capture_run_messages context manager to access the message exchange history for debugging purposes when errors occur during agent execution.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_14\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, ModelRetry, UnexpectedModelBehavior, capture_run_messages\n\nagent = Agent('openai:gpt-4o')\n\n\n@agent.tool_plain\ndef calc_volume(size: int) -> int:  # (1)!\n    if size == 42:\n        return size**3\n    else:\n        raise ModelRetry('Please try again.')\n\n\nwith capture_run_messages() as messages:  # (2)!\n    try:\n        result = agent.run_sync('Please get me the volume of a box with size 6.')\n    except UnexpectedModelBehavior as e:\n        print('An error occurred:', e)\n        #> An error occurred: Tool exceeded max retries count of 1\n        print('cause:', repr(e.__cause__))\n        #> cause: ModelRetry('Please try again.')\n        print('messages:', messages)\n        \"\"\"\n        messages:\n        [\n            ModelRequest(\n                parts=[\n                    UserPromptPart(\n                        content='Please get me the volume of a box with size 6.',\n                        timestamp=datetime.datetime(...),\n                        part_kind='user-prompt',\n                    )\n                ],\n                instructions=None,\n                kind='request',\n            ),\n            ModelResponse(\n                parts=[\n                    ToolCallPart(\n                        tool_name='calc_volume',\n                        args={'size': 6},\n                        tool_call_id='pyd_ai_tool_call_id',\n                        part_kind='tool-call',\n                    )\n                ],\n                model_name='gpt-4o',\n                timestamp=datetime.datetime(...),\n                kind='response',\n            ),\n            ModelRequest(\n                parts=[\n                    RetryPromptPart(\n                        content='Please try again.',\n                        tool_name='calc_volume',\n                        tool_call_id='pyd_ai_tool_call_id',\n                        timestamp=datetime.datetime(...),\n                        part_kind='retry-prompt',\n                    )\n                ],\n                instructions=None,\n                kind='request',\n            ),\n            ModelResponse(\n                parts=[\n                    ToolCallPart(\n                        tool_name='calc_volume',\n                        args={'size': 6},\n                        tool_call_id='pyd_ai_tool_call_id',\n                        part_kind='tool-call',\n                    )\n                ],\n                model_name='gpt-4o',\n                timestamp=datetime.datetime(...),\n                kind='response',\n            ),\n        ]\n        \"\"\"\n    else:\n        print(result.output)\n```\n\n----------------------------------------\n\nTITLE: Iterating Graph with GraphRun.next\nDESCRIPTION: This example demonstrates manual iteration over a graph using `GraphRun.next`. It utilizes the `CountDown` graph from the previous example and shows how to control the execution flow by selectively running nodes. The code also demonstrates the use of `FullStatePersistence` to track the history of state changes during the graph execution. It breaks the loop when the counter reaches 2, showcasing the ability to terminate the execution early. The result is None because it didn't finish the run, and the state history is shown.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_12\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_graph import End, FullStatePersistence\nfrom count_down import CountDown, CountDownState, count_down_graph\n\n\nasync def main():\n    state = CountDownState(counter=5)\n    persistence = FullStatePersistence()  # (7)!\n    async with count_down_graph.iter(\n        CountDown(), state=state, persistence=persistence\n    ) as run:\n        node = run.next_node  # (1)!\n        while not isinstance(node, End):  # (2)!\n            print('Node:', node)\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            if state.counter == 2:\n                break  # (3)!\n            node = await run.next(node)  # (4)!\n\n        print(run.result)  # (5)!\n        #> None\n\n        for step in persistence.history:  # (6)!\n            print('History Step:', step.state, step.state)\n            #> History Step: CountDownState(counter=5) CountDownState(counter=5)\n            #> History Step: CountDownState(counter=4) CountDownState(counter=4)\n            #> History Step: CountDownState(counter=3) CountDownState(counter=3)\n            #> History Step: CountDownState(counter=2) CountDownState(counter=2)\n\n```\n\n----------------------------------------\n\nTITLE: Implementing Chat App Backend with FastAPI in Python\nDESCRIPTION: Python code that runs the chat application backend using FastAPI. This file handles the server-side logic, including message processing and response streaming.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/chat-app.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/chat_app.py\n```\n\n----------------------------------------\n\nTITLE: Implementing MCP SSE Client\nDESCRIPTION: Python implementation of an MCP client using HTTP SSE transport to connect to an MCP server. Demonstrates how to create an agent and execute commands through the MCP server.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.mcp import MCPServerHTTP\n\nserver = MCPServerHTTP(url='http://localhost:3001/sse')\nagent = Agent('openai:gpt-4o', mcp_servers=[server])\n\n\nasync def main():\n    async with agent.run_mcp_servers():\n        result = await agent.run('How many days between 2000-01-01 and 2025-03-18?')\n    print(result.output)\n    #> There are 9,208 days between January 1, 2000, and March 18, 2025.\n```\n\n----------------------------------------\n\nTITLE: Manual Agent Iteration using .next() Method - Python\nDESCRIPTION: Demonstrates manual control of agent iteration using the .next() method. Shows how to inspect, modify, or skip nodes during execution while collecting all processed nodes in a list.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_graph import End\n\nagent = Agent('openai:gpt-4o')\n\nasync def main():\n    async with agent.iter('What is the capital of France?') as agent_run:\n        node = agent_run.next_node\n\n        all_nodes = [node]\n\n        while not isinstance(node, End):\n            node = await agent_run.next(node)\n            all_nodes.append(node)\n\n        print(all_nodes)\n```\n\n----------------------------------------\n\nTITLE: Implementing OpenTelemetry Integration\nDESCRIPTION: Python code showing OpenTelemetry integration with Pydantic Evals, including span tree analysis and performance evaluation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom typing import Any\n\nimport logfire\n\nfrom pydantic_evals import Case, Dataset\nfrom pydantic_evals.evaluators import Evaluator\nfrom pydantic_evals.evaluators.context import EvaluatorContext\nfrom pydantic_evals.otel.span_tree import SpanQuery\n\nlogfire.configure(\n    send_to_logfire='if-token-present'\n)\n\nclass SpanTracingEvaluator(Evaluator[str, str]):\n    def evaluate(self, ctx: EvaluatorContext[str, str]) -> dict[str, Any]:\n        span_tree = ctx.span_tree\n        if span_tree is None:\n            return {'has_spans': False, 'performance_score': 0.0}\n\n        processing_spans = span_tree.find(lambda node: 'processing' in node.name)\n        total_processing_time = sum(\n            (span.duration.total_seconds() for span in processing_spans), 0.0\n        )\n        error_query: SpanQuery = {'name_contains': 'error'}\n        has_errors = span_tree.any(error_query)\n        performance_score = 1.0 if total_processing_time < 0.5 else 0.5\n\n        return {\n            'has_spans': True,\n            'has_errors': has_errors,\n            'performance_score': 0 if has_errors else performance_score,\n        }\n```\n\n----------------------------------------\n\nTITLE: Processing Document Input Using BinaryContent in Pydantic AI\nDESCRIPTION: Shows how to process a local document using BinaryContent class. The example reads a PDF file and passes it directly to the LLM as binary data with the appropriate media type.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/input.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\nfrom pydantic_ai import Agent, BinaryContent\n\npdf_path = Path('document.pdf')\nagent = Agent(model='anthropic:claude-3-sonnet')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        BinaryContent(data=pdf_path.read_bytes(), media_type='application/pdf'),\n    ]\n)\nprint(result.output)\n# > The document discusses...\n```\n\n----------------------------------------\n\nTITLE: Processing Image Input Using BinaryContent in Pydantic AI\nDESCRIPTION: Shows how to process a local image using BinaryContent class. The example downloads an image and passes it directly to the LLM as binary data with the appropriate media type.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/input.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport httpx\n\nfrom pydantic_ai import Agent, BinaryContent\n\nimage_response = httpx.get('https://iili.io/3Hs4FMg.png')  # Pydantic logo\n\nagent = Agent(model='openai:gpt-4o')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        BinaryContent(data=image_response.content, media_type='image/png'),\n    ]\n)\nprint(result.output)\n# > This is the logo for Pydantic, a data validation and settings management library in Python.\n```\n\n----------------------------------------\n\nTITLE: Implementing Parallel Evaluation in Python\nDESCRIPTION: Python code demonstrating parallel evaluation of test cases with concurrency control, including timing measurements and result reporting.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport time\n\nfrom pydantic_evals import Case, Dataset\n\n# Create a dataset with multiple test cases\ndataset = Dataset(\n    cases=[\n        Case(\n            name=f'case_{i}',\n            inputs=i,\n            expected_output=i * 2,\n        )\n        for i in range(5)\n    ]\n)\n\n\nasync def double_number(input_value: int) -> int:\n    \"\"\"Function that simulates work by sleeping for a second before returning double the input.\"\"\"\n    await asyncio.sleep(0.1)  # Simulate work\n    return input_value * 2\n\n\n# Run evaluation with unlimited concurrency\nt0 = time.time()\nreport_default = dataset.evaluate_sync(double_number)\nprint(f'Evaluation took less than 0.3s: {time.time() - t0 < 0.3}')\n\n# Run evaluation with limited concurrency\nt0 = time.time()\nreport_limited = dataset.evaluate_sync(double_number, max_concurrency=1)\nprint(f'Evaluation took more than 0.5s: {time.time() - t0 > 0.5}')\n```\n\n----------------------------------------\n\nTITLE: Iterating Over Agent Graph Nodes\nDESCRIPTION: Demonstrates how to iterate over an agent's underlying graph nodes using async iteration. Shows how to capture and inspect each step of the agent's execution process.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o')\n\n\nasync def main():\n    nodes = []\n    # Begin an AgentRun, which is an async-iterable over the nodes of the agent's graph\n    async with agent.iter('What is the capital of France?') as agent_run:\n        async for node in agent_run:\n            # Each node represents a step in the agent's execution\n            nodes.append(node)\n    print(nodes)\n    print(agent_run.result.output)\n    #> Paris\n```\n\n----------------------------------------\n\nTITLE: Implementing Dice Game with PydanticAI Function Tools\nDESCRIPTION: Example showing how to create a dice game using PydanticAI function tools with both @agent.tool and @agent.tool_plain decorators. The code demonstrates dependency injection and tool context usage.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\nfrom pydantic_ai import Agent, RunContext\n\nagent = Agent(\n    'google-gla:gemini-1.5-flash',\n    deps_type=str,\n    system_prompt=(\n        \"You're a dice game, you should roll the die and see if the number \"\n        \"you get back matches the user's guess. If so, tell them they're a winner. \"\n        \"Use the player's name in the response.\"\n    ),\n)\n\n@agent.tool_plain\ndef roll_die() -> str:\n    \"\"\"Roll a six-sided die and return the result.\"\"\"\n    return str(random.randint(1, 6))\n\n@agent.tool\ndef get_player_name(ctx: RunContext[str]) -> str:\n    \"\"\"Get the player's name.\"\"\"\n    return ctx.deps\n\ndice_result = agent.run_sync('My guess is 4', deps='Anne')\nprint(dice_result.output)\n```\n\n----------------------------------------\n\nTITLE: Implementing Agent Delegation with PydanticAI\nDESCRIPTION: Demonstrates a simple agent delegation pattern where a joke selection agent uses a joke generation agent via a tool. Shows usage tracking across multiple agents and basic error handling.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.usage import UsageLimits\n\njoke_selection_agent = Agent(\n    'openai:gpt-4o',\n    system_prompt=(\n        'Use the `joke_factory` to generate some jokes, then choose the best. '\n        'You must return just a single joke.'\n    ),\n)\njoke_generation_agent = Agent(\n    'google-gla:gemini-1.5-flash', output_type=list[str]\n)\n\n@joke_selection_agent.tool\nasync def joke_factory(ctx: RunContext[None], count: int) -> list[str]:\n    r = await joke_generation_agent.run(\n        f'Please generate {count} jokes.',\n        usage=ctx.usage,\n    )\n    return r.output\n\nresult = joke_selection_agent.run_sync(\n    'Tell me a joke.',\n    usage_limits=UsageLimits(request_limit=5, total_tokens_limit=300),\n)\nprint(result.output)\nprint(result.usage())\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Tool Schema Generation in Python with PydanticAI\nDESCRIPTION: Example showing how to create a tool with documented parameters using Google-style docstrings and print its generated schema. The function demonstrates parameter type annotations and docstring parsing capabilities.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.messages import ModelMessage, ModelResponse, TextPart\nfrom pydantic_ai.models.function import AgentInfo, FunctionModel\n\nagent = Agent()\n\n@agent.tool_plain(docstring_format='google', require_parameter_descriptions=True)\ndef foobar(a: int, b: str, c: dict[str, list[float]]) -> str:\n    \"\"\"Get me foobar.\n\n    Args:\n        a: apple pie\n        b: banana cake\n        c: carrot smoothie\n    \"\"\"\n    return f'{a} {b} {c}'\n\ndef print_schema(messages: list[ModelMessage], info: AgentInfo) -> ModelResponse:\n    tool = info.function_tools[0]\n    print(tool.description)\n    print(tool.parameters_json_schema)\n    return ModelResponse(parts=[TextPart('foobar')])\n\nagent.run_sync('hello', model=FunctionModel(print_schema))\n```\n\n----------------------------------------\n\nTITLE: Defining an Intermediate or End Node in pydantic-graph (Python)\nDESCRIPTION: This example extends the previous one to show how a node can optionally end the graph execution. It demonstrates how to use the End type to return a value and terminate the graph, depending on a condition.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_2\n\nLANGUAGE: Python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, GraphRunContext\n\n\n@dataclass\nclass MyNode(BaseNode[MyState, None, int]):  # (1)!\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext[MyState],\n    ) -> AnotherNode | End[int]:  # (2)!\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return AnotherNode()\n```\n\n----------------------------------------\n\nTITLE: Using Model-Specific Settings with Safety Controls\nDESCRIPTION: Demonstrates the use of model-specific settings like GeminiModelSettings with custom safety thresholds.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, UnexpectedModelBehavior\nfrom pydantic_ai.models.gemini import GeminiModelSettings\n\nagent = Agent('google-gla:gemini-1.5-flash')\n\ntry:\n    result = agent.run_sync(\n        'Write a list of 5 very rude things that I might say to the universe after stubbing my toe in the dark:',\n        model_settings=GeminiModelSettings(\n            temperature=0.0,\n            gemini_safety_settings=[\n                {\n                    'category': 'HARM_CATEGORY_HARASSMENT',\n                    'threshold': 'BLOCK_LOW_AND_ABOVE',\n                },\n                {\n                    'category': 'HARM_CATEGORY_HATE_SPEECH',\n                    'threshold': 'BLOCK_LOW_AND_ABOVE',\n                },\n            ],\n        ),\n    )\nexcept UnexpectedModelBehavior as e:\n    print(e)\n```\n\n----------------------------------------\n\nTITLE: Demonstrating Different Agent Execution Methods\nDESCRIPTION: Shows three different ways to run a PydanticAI agent: synchronous execution, asynchronous execution, and streaming. Uses simple geography questions to demonstrate each method.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o')\n\nresult_sync = agent.run_sync('What is the capital of Italy?')\nprint(result_sync.output)\n#> Rome\n\n\nasync def main():\n    result = await agent.run('What is the capital of France?')\n    print(result.output)\n    #> Paris\n\n    async with agent.run_stream('What is the capital of the UK?') as response:\n        print(await response.get_output())\n        #> London\n```\n\n----------------------------------------\n\nTITLE: Processing Document Input Using DocumentUrl in Pydantic AI\nDESCRIPTION: Demonstrates how to analyze a document using DocumentUrl class with a direct URL. The example uses the Anthropic Claude model to analyze the content of a PDF document.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/input.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, DocumentUrl\n\nagent = Agent(model='anthropic:claude-3-sonnet')\nresult = agent.run_sync(\n    [\n        'What is the main content of this document?',\n        DocumentUrl(url='https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf'),\n    ]\n)\nprint(result.output)\n# > This document is the technical report introducing Gemini 1.5, Google's latest large language model...\n```\n\n----------------------------------------\n\nTITLE: Testing Weather Forecast with FunctionModel in Python\nDESCRIPTION: Implementation of a test case using FunctionModel to simulate AI model responses for weather forecasting. The test includes custom function handling, date extraction, and database interaction verification.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/testing.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport re\n\nimport pytest\n\nfrom pydantic_ai import models\nfrom pydantic_ai.messages import (\n    ModelMessage,\n    ModelResponse,\n    TextPart,\n    ToolCallPart,\n)\nfrom pydantic_ai.models.function import AgentInfo, FunctionModel\n\nfrom fake_database import DatabaseConn\nfrom weather_app import run_weather_forecast, weather_agent\n\npytestmark = pytest.mark.anyio\nmodels.ALLOW_MODEL_REQUESTS = False\n\n\ndef call_weather_forecast(\n    messages: list[ModelMessage], info: AgentInfo\n) -> ModelResponse:\n    if len(messages) == 1:\n        # first call, call the weather forecast tool\n        user_prompt = messages[0].parts[-1]\n        m = re.search(r'\\d{4}-\\d{2}-\\d{2}', user_prompt.content)\n        assert m is not None\n        args = {'location': 'London', 'forecast_date': m.group()}\n        return ModelResponse(parts=[ToolCallPart('weather_forecast', args)])\n    else:\n        # second call, return the forecast\n        msg = messages[-1].parts[0]\n        assert msg.part_kind == 'tool-return'\n        return ModelResponse(parts=[TextPart(f'The forecast is: {msg.content}')])\n\n\nasync def test_forecast_future():\n    conn = DatabaseConn()\n    user_id = 1\n    with weather_agent.override(model=FunctionModel(call_weather_forecast)):\n        prompt = 'What will the weather be like in London on 2032-01-01?'\n        await run_weather_forecast([(prompt, user_id)], conn)\n\n    forecast = await conn.get_forecast(user_id)\n    assert forecast == 'The forecast is: Rainy with a chance of sun'\n```\n\n----------------------------------------\n\nTITLE: Reusing Message History in PydanticAI Conversations - Python\nDESCRIPTION: Demonstrates how to maintain conversation context by reusing message history across multiple agent runs. Shows message history passing and response handling.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')\n\nresult1 = agent.run_sync('Tell me a joke.')\nprint(result1.output)\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\nresult2 = agent.run_sync('Explain?', message_history=result1.new_messages())\nprint(result2.output)\n#> This is an excellent joke invented by Samuel Colvin, it needs no explanation.\n\nprint(result2.all_messages())\n```\n\n----------------------------------------\n\nTITLE: Running PydanticAI Example with Default Model\nDESCRIPTION: Command to run the Pydantic model example using the default OpenAI GPT-4o model. Requires dependencies to be installed and environment variables to be set beforehand.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/pydantic-model.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.pydantic_model\n```\n\n----------------------------------------\n\nTITLE: Configuring Perplexity AI Integration with Pydantic\nDESCRIPTION: Sets up a connection to the Perplexity AI API using Pydantic AI library. Requires a Perplexity API key and uses the 'sonar-pro' model through the OpenAI-compatible interface.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\nmodel = OpenAIModel(\n    'sonar-pro',\n    provider=OpenAIProvider(\n        base_url='https://api.perplexity.ai',\n        api_key='your-perplexity-api-key',\n    ),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Implementing Roulette Wheel Agent with PydanticAI\nDESCRIPTION: Creates an agent that simulates a roulette wheel game using OpenAI's GPT-4 model. The agent takes an integer dependency and returns a boolean indicating if the player won. Includes a tool function to check winning numbers.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, RunContext\n\nroulette_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=int,\n    output_type=bool,\n    system_prompt=(\n        'Use the `roulette_wheel` function to see if the '\n        'customer has won based on the number they provide.'\n    ),\n)\n\n\n@roulette_agent.tool\nasync def roulette_wheel(ctx: RunContext[int], square: int) -> str:\n    \"\"\"check if the square is a winner\"\"\"\n    return 'winner' if square == ctx.deps else 'loser'\n\n\n# Run the agent\nsuccess_number = 18\nresult = roulette_agent.run_sync('Put my money on square eighteen', deps=success_number)\nprint(result.output)\n#> True\n\nresult = roulette_agent.run_sync('I bet five is the winner', deps=success_number)\nprint(result.output)\n#> False\n```\n\n----------------------------------------\n\nTITLE: Accessing Messages from StreamedRunResult in PydanticAI - Python\nDESCRIPTION: Shows how to access messages from an asynchronous streamed agent run, demonstrating both incomplete messages before stream completion and complete messages after streaming finishes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')\n\n\nasync def main():\n    async with agent.run_stream('Tell me a joke.') as result:\n        # incomplete messages before the stream finishes\n        print(result.all_messages())\n        \"\"\"\n        []\n            ModelRequest(\n                parts=[\n                    SystemPromptPart(\n                        content='Be a helpful assistant.',\n                        timestamp=datetime.datetime(...),\n                        dynamic_ref=None,\n                        part_kind='system-prompt',\n                    ),\n                    UserPromptPart(\n                        content='Tell me a joke.',\n                        timestamp=datetime.datetime(...),\n                        part_kind='user-prompt',\n                    ),\n                ],\n                instructions=None,\n                kind='request',\n            )\n        ]\n        \"\"\"\n\n        async for text in result.stream_text():\n            print(text)\n            #> Did you hear\n            #> Did you hear about the toothpaste\n            #> Did you hear about the toothpaste scandal? They called\n            #> Did you hear about the toothpaste scandal? They called it Colgate.\n\n        # complete messages once the stream finishes\n        print(result.all_messages())\n```\n\n----------------------------------------\n\nTITLE: Using Tavily Search Tool with PydanticAI Agent\nDESCRIPTION: Example of how to use the Tavily search tool with a PydanticAI agent. It demonstrates importing the tool, setting up the API key, creating an agent, and running a search query.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport os\n\nfrom pydantic_ai.agent import Agent\nfrom pydantic_ai.common_tools.tavily import tavily_search_tool\n\napi_key = os.getenv('TAVILY_API_KEY')\nassert api_key is not None\n\nagent = Agent(\n    'openai:o3-mini',\n    tools=[tavily_search_tool(api_key)],\n    system_prompt='Search Tavily for the given query and return the results.',\n)\n\nresult = agent.run_sync('Tell me the top news in the GenAI world, give me links.')\nprint(result.output)\n\"\"\"\nHere are some of the top recent news articles related to GenAI:\n\n1. How CLEAR users can improve risk analysis with GenAI  Thomson Reuters\n   Read more: https://legal.thomsonreuters.com/blog/how-clear-users-can-improve-risk-analysis-with-genai/\n   (This article discusses how CLEAR's new GenAI-powered tool streamlines risk analysis by quickly summarizing key information from various public data sources.)\n\n2. TELUS Digital Survey Reveals Enterprise Employees Are Entering Sensitive Data Into AI Assistants More Than You Think  FT.com\n   Read more: https://markets.ft.com/data/announce/detail?dockey=600-202502260645BIZWIRE_USPRX____20250226_BW490609-1\n   (This news piece highlights findings from a TELUS Digital survey showing that many enterprise employees use public GenAI tools and sometimes even enter sensitive data.)\n\n3. The Essential Guide to Generative AI  Virtualization Review\n   Read more: https://virtualizationreview.com/Whitepapers/2025/02/SNOWFLAKE-The-Essential-Guide-to-Generative-AI.aspx\n   (This guide provides insights into how GenAI is revolutionizing enterprise strategies and productivity, with input from industry leaders.)\n\nFeel free to click on the links to dive deeper into each story!\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Defining an Intermediate Node in pydantic-graph (Python)\nDESCRIPTION: This example shows how to define a node in pydantic-graph that represents an intermediate step in a graph. It uses dataclasses and type hints to define the node's parameters and return type, demonstrating the basic structure for creating a node that doesn't end the graph execution.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_1\n\nLANGUAGE: Python\nCODE:\n```\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, GraphRunContext\n\n\n@dataclass\nclass MyNode(BaseNode[MyState]):  # (1)!\n    foo: int  # (2)!\n\n    async def run(\n        self,\n        ctx: GraphRunContext[MyState],  # (3)!\n    ) -> AnotherNode:  # (4)!\n        ...\n        return AnotherNode()\n```\n\n----------------------------------------\n\nTITLE: Creating Custom TypeAdapter for Messages\nDESCRIPTION: Shows how to create a custom TypeAdapter for handling ModelMessage lists as an alternative to using the built-in ModelMessagesTypeAdapter.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import TypeAdapter\nfrom pydantic_ai.messages import ModelMessage\nModelMessagesTypeAdapter = TypeAdapter(list[ModelMessage])\n```\n\n----------------------------------------\n\nTITLE: Handling Box Dimensions with Union Types\nDESCRIPTION: Shows how to handle both structured data and text responses using Union types. The agent extracts box dimensions or returns an error message if information is incomplete.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Union\n\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent\n\n\nclass Box(BaseModel):\n    width: int\n    height: int\n    depth: int\n    units: str\n\n\nagent: Agent[None, Union[Box, str]] = Agent(\n    'openai:gpt-4o-mini',\n    output_type=Union[Box, str],  # type: ignore\n    system_prompt=(\n        \"Extract me the dimensions of a box, \"\n        \"if you can't extract all data, ask the user to try again.\"\n    ),\n)\n\nresult = agent.run_sync('The box is 10x20x30')\nprint(result.output)\n#> Please provide the units for the dimensions (e.g., cm, in, m).\n\nresult = agent.run_sync('The box is 10x20x30 cm')\nprint(result.output)\n#> width=10 height=20 depth=30 units='cm'\n```\n\n----------------------------------------\n\nTITLE: Streaming Text Output with Delta Updates\nDESCRIPTION: Demonstrates streaming text responses with delta updates, showing only the new content at each step.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('google-gla:gemini-1.5-flash')\n\n\nasync def main():\n    async with agent.run_stream('Where does \"hello world\" come from?') as result:\n        async for message in result.stream_text(delta=True):\n            print(message)\n            #> The first known\n            #> use of \"hello,\n            #> world\" was in\n            #> a 1974 textbook\n            #> about the C\n            #> programming language.\n```\n\n----------------------------------------\n\nTITLE: Testing Agent Dependencies with Overrides in Python\nDESCRIPTION: Unit test implementation showing how to override agent dependencies for testing purposes. Demonstrates creating test-specific dependency implementations and using context managers for dependency injection.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom joke_app import MyDeps, application_code, joke_agent\n\n\nclass TestMyDeps(MyDeps):  \n    async def system_prompt_factory(self) -> str:\n        return 'test prompt'\n\n\nasync def test_application_code():\n    test_deps = TestMyDeps('test_key', None)  \n    with joke_agent.override(deps=test_deps):  \n        joke = await application_code('Tell me a joke.')  \n    assert joke.startswith('Did you hear about the toothpaste scandal?')\n```\n\n----------------------------------------\n\nTITLE: Using DuckDuckGo Search Tool with PydanticAI Agent\nDESCRIPTION: Example of how to use the DuckDuckGo search tool with a PydanticAI agent. It demonstrates importing the tool, creating an agent, and running a search query.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n\nagent = Agent(\n    'openai:o3-mini',\n    tools=[duckduckgo_search_tool()],\n    system_prompt='Search DuckDuckGo for the given query and return the results.',\n)\n\nresult = agent.run_sync(\n    'Can you list the top five highest-grossing animated films of 2025?'\n)\nprint(result.output)\n\"\"\"\nI looked into several sources on animated boxoffice performance in 2025, and while detailed\nrankings can shift as more money is tallied, multiple independent reports have already\nhighlighted a couple of recordbreaking shows. For example:\n\n Ne Zha 2  News outlets (Variety, Wikipedia's \"List of animated feature films of 2025\", and others)\n    have reported that this Chinese title not only became the highestgrossing animated film of 2025\n    but also broke records as the highestgrossing nonEnglish animated film ever. One article noted\n    its run exceeded US$1.7 billion.\n Inside Out 2  According to data shared on Statista and in industry news, this Pixar sequel has been\n    on pace to set new records (with some sources even noting it as the highestgrossing animated film\n    ever, as of January 2025).\n\nBeyond those two, some entertainment trade sites (for example, a Just Jared article titled\n\"Top 10 Highest-Earning Animated Films at the Box Office Revealed\") have begun listing a broader\ntop10. Although full consolidated figures can sometimes differ by source and are updated daily during\na boxoffice run, many of the industry trackers have begun to single out five films as the biggest\nearners so far in 2025.\n\nUnfortunately, although multiple articles discuss the \"top animated films\" of 2025, there isn't yet a\nsingle, universally accepted list with final numbers that names the complete top five. (Boxoffice\nrankings, especially midyear, can be fluid as films continue to add to their totals.)\n\nBased on what several sources note so far, the two undisputed leaders are:\n1. Ne Zha 2\n2. Inside Out 2\n\nThe remaining top spots (35) are reported by some outlets in their \"Top10 Animated Films\"\nlists for 2025 but the titles and order can vary depending on the source and the exact cutoff\ndate of the data. For the most uptodate and detailed ranking (including the 3rd, 4th, and 5th\nhighestgrossing films), I recommend checking resources like:\n Wikipedia's \"List of animated feature films of 2025\" page\n Boxoffice tracking sites (such as Box Office Mojo or The Numbers)\n Trade articles like the one on Just Jared\n\nTo summarize with what is clear from the current reporting:\n1. Ne Zha 2\n2. Inside Out 2\n35. Other animated films (yet to be definitively finalized across all reporting outlets)\n\nIf you're looking for a final, consensus list of the top five, it may be best to wait until\nthe 2025 yearend boxoffice tallies are in or to consult a regularly updated entertainment industry source.\n\nWould you like help finding a current source or additional details on where to look for the complete updated list?\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Count Down Graph with File Persistence\nDESCRIPTION: This code demonstrates how to use `FileStatePersistence` with `pydantic-graph` to persist the state of a `count_down_graph` and resume execution from the persisted state. It initializes the graph, runs nodes iteratively, and checks for the end of the graph.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_13\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nfrom pydantic_graph import End\nfrom pydantic_graph.persistence.file import FileStatePersistence\n\nfrom count_down import CountDown, CountDownState, count_down_graph\n\n\nasync def main():\n    run_id = 'run_abc123'\n    persistence = FileStatePersistence(Path(f'count_down_{run_id}.json'))  # (1)!\n    state = CountDownState(counter=5)\n    await count_down_graph.initialize(  # (2)!\n        CountDown(), state=state, persistence=persistence\n    )\n\n    done = False\n    while not done:\n        done = await run_node(run_id)\n\n\nasync def run_node(run_id: str) -> bool:  # (3)!\n    persistence = FileStatePersistence(Path(f'count_down_{run_id}.json'))\n    async with count_down_graph.iter_from_persistence(persistence) as run:  # (4)!\n        node_or_end = await run.next()  # (5)!\n\n    print('Node:', node_or_end)\n    # > Node: CountDown()\n    # > Node: CountDown()\n    # > Node: CountDown()\n    # > Node: CountDown()\n    # > Node: CountDown()\n    # > Node: End(data=0)\n    return isinstance(node_or_end, End)  # (6)!\n```\n\n----------------------------------------\n\nTITLE: Handling Fallback Model Failures in Python 3.11+\nDESCRIPTION: Shows error handling implementation for FallbackModel when all models fail, using Python 3.11's exception handling syntax. Demonstrates how to catch and process ModelHTTPError exceptions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/index.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.exceptions import ModelHTTPError\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.models.fallback import FallbackModel\nfrom pydantic_ai.models.openai import OpenAIModel\n\nopenai_model = OpenAIModel('gpt-4o')\nanthropic_model = AnthropicModel('claude-3-5-sonnet-latest')\nfallback_model = FallbackModel(openai_model, anthropic_model)\n\nagent = Agent(fallback_model)\ntry:\n    response = agent.run_sync('What is the capital of France?')\nexcept* ModelHTTPError as exc_group:\n    for exc in exc_group.exceptions:\n        print(exc)\n```\n\n----------------------------------------\n\nTITLE: Basic Streaming User Profile Implementation with Pydantic-AI\nDESCRIPTION: Demonstrates basic streaming of a user profile using Pydantic-AI's Agent with TypedDict. The code shows how to process streaming responses for user profile data including name, date of birth, and biography fields.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic_ai import Agent\n\n\nclass UserProfile(TypedDict, total=False):\n    name: str\n    dob: date\n    bio: str\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    output_type=UserProfile,\n    system_prompt='Extract a user profile from the input',\n)\n\n\nasync def main():\n    user_input = 'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n    async with agent.run_stream(user_input) as result:\n        async for profile in result.stream():\n            print(profile)\n            #> {'name': 'Ben'}\n            #> {'name': 'Ben'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n```\n\n----------------------------------------\n\nTITLE: Custom Mistral Provider Configuration\nDESCRIPTION: Python code showing how to initialize a MistralModel with a custom provider and API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.mistral import MistralModel\nfrom pydantic_ai.providers.mistral import MistralProvider\n\nmodel = MistralModel(\n    'mistral-large-latest', provider=MistralProvider(api_key='your-api-key')\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Advanced Streaming User Profile with Error Handling\nDESCRIPTION: Shows a more sophisticated implementation with fine-grained validation control and error handling. Uses stream_structured and validate_structured_output methods with debouncing for better control over the streaming process.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom datetime import date\n\nfrom pydantic import ValidationError\nfrom typing_extensions import TypedDict\n\nfrom pydantic_ai import Agent\n\n\nclass UserProfile(TypedDict, total=False):\n    name: str\n    dob: date\n    bio: str\n\n\nagent = Agent('openai:gpt-4o', output_type=UserProfile)\n\n\nasync def main():\n    user_input = 'My name is Ben, I was born on January 28th 1990, I like the chain the dog and the pyramid.'\n    async with agent.run_stream(user_input) as result:\n        async for message, last in result.stream_structured(debounce_by=0.01):\n            try:\n                profile = await result.validate_structured_output(\n                    message,\n                    allow_partial=not last,\n                )\n            except ValidationError:\n                continue\n            print(profile)\n            #> {'name': 'Ben'}\n            #> {'name': 'Ben'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the '}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyr'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n            #> {'name': 'Ben', 'dob': date(1990, 1, 28), 'bio': 'Likes the chain the dog and the pyramid'}\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Dependencies with Dataclasses in Python\nDESCRIPTION: Example demonstrating how to define a dependency class using dataclasses and provide it to an Agent. This shows the pattern of defining a dependency type, specifying it in the Agent constructor, and passing an instance when running the agent.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport httpx\n\nfrom pydantic_ai import Agent\n\n\n@dataclass\nclass MyDeps:  # (1)!\n    api_key: str\n    http_client: httpx.AsyncClient\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=MyDeps,  # (2)!\n)\n\n\nasync def main():\n    async with httpx.AsyncClient() as client:\n        deps = MyDeps('foobar', client)\n        result = await agent.run(\n            'Tell me a joke.',\n            deps=deps,  # (3)!\n        )\n        print(result.output)\n        #> Did you hear about the toothpaste scandal? They called it Colgate.\n```\n\n----------------------------------------\n\nTITLE: Implementing MCP Server with PydanticAI Tool\nDESCRIPTION: Creates an MCP server with a poetry generation tool powered by PydanticAI's Agent using Claude 3. The server exposes a 'poet' endpoint that generates rhyming poems based on given themes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/server.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp.server.fastmcp import FastMCP\n\nfrom pydantic_ai import Agent\n\nserver = FastMCP('PydanticAI Server')\nserver_agent = Agent(\n    'anthropic:claude-3-5-haiku-latest', system_prompt='always reply in rhyme'\n)\n\n\n@server.tool()\nasync def poet(theme: str) -> str:\n    \"\"\"Poem generator\"\"\"\n    r = await server_agent.run(f'write a poem about {theme}')\n    return r.output\n\n\nif __name__ == '__main__':\n    server.run()\n```\n\n----------------------------------------\n\nTITLE: Running the Chat App Example using Python\nDESCRIPTION: Command to run the chat application example using Python or uv-run. This assumes dependencies are installed and environment variables are set.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/chat-app.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.chat_app\n```\n\n----------------------------------------\n\nTITLE: Evaluating Recipe Generation with LLMJudge in Python\nDESCRIPTION: Illustrates the use of LLMJudge for evaluating a complex task of generating recipes based on customer orders with dietary restrictions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent, format_as_xml\nfrom pydantic_evals import Case, Dataset\nfrom pydantic_evals.evaluators import IsInstance, LLMJudge\n\n\nclass CustomerOrder(BaseModel):\n    dish_name: str\n    dietary_restriction: str | None = None\n\n\nclass Recipe(BaseModel):\n    ingredients: list[str]\n    steps: list[str]\n\n\nrecipe_agent = Agent(\n    'groq:llama-3.3-70b-versatile',\n    output_type=Recipe,\n    system_prompt=(\n        'Generate a recipe to cook the dish that meets the dietary restrictions.'\n    ),\n)\n\n\nasync def transform_recipe(customer_order: CustomerOrder) -> Recipe:\n    r = await recipe_agent.run(format_as_xml(customer_order))\n    return r.output\n\n\nrecipe_dataset = Dataset[CustomerOrder, Recipe, Any](\n    cases=[\n        Case(\n            name='vegetarian_recipe',\n            inputs=CustomerOrder(\n                dish_name='Spaghetti Bolognese', dietary_restriction='vegetarian'\n            ),\n            expected_output=None,\n            metadata={'focus': 'vegetarian'},\n            evaluators=(\n                LLMJudge(\n                    rubric='Recipe should not contain meat or animal products',\n                ),\n            ),\n        ),\n        Case(\n            name='gluten_free_recipe',\n            inputs=CustomerOrder(\n                dish_name='Chocolate Cake', dietary_restriction='gluten-free'\n            ),\n            expected_output=None,\n            metadata={'focus': 'gluten-free'},\n            evaluators=(\n                LLMJudge(\n                    rubric='Recipe should not contain gluten or wheat products',\n                ),\n            ),\n        ),\n    ],\n    evaluators=[\n        IsInstance(type_name='Recipe'),\n        LLMJudge(\n            rubric='Recipe should have clear steps and relevant ingredients',\n            include_input=True,\n            model='anthropic:claude-3-7-sonnet-latest',\n        ),\n    ],\n)\n\n\nreport = recipe_dataset.evaluate_sync(transform_recipe)\nprint(report)\n```\n\n----------------------------------------\n\nTITLE: Custom OpenAI Provider Configuration\nDESCRIPTION: Configuration of OpenAI model with custom provider settings including API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\nmodel = OpenAIModel('gpt-4o', provider=OpenAIProvider(api_key='your-api-key'))\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI Examples Dependencies\nDESCRIPTION: Command to install PydanticAI with examples dependencies using pip or uv package managers.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai[examples]\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Fireworks AI Integration with Pydantic\nDESCRIPTION: Implements connection to Fireworks AI using Pydantic AI library. Uses the OpenAI-compatible interface with Fireworks' model library and requires a Fireworks API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\nmodel = OpenAIModel(\n    'accounts/fireworks/models/qwq-32b',  # model library available at https://fireworks.ai/models\n    provider=OpenAIProvider(\n        base_url='https://api.fireworks.ai/inference/v1',\n        api_key='your-fireworks-api-key',\n    ),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Customizing Mermaid Diagrams in Pydantic Graph (Python)\nDESCRIPTION: This code snippet demonstrates how to customize Mermaid diagrams generated by Pydantic Graph. It adds labels to edges, adds a note to the `Ask` node, highlights the `Answer` node, and saves the diagram as a PNG image. This example requires the `pydantic_graph` library and assumes the existence of `QuestionState`, `Answer`, `Reprimand` and related classes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_17\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Annotated\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext, Edge\n\n...\n\n@dataclass\nclass Ask(BaseNode[QuestionState]):\n    \"\"\"Generate question using GPT-4o.\"\"\"\n    docstring_notes = True\n    async def run(\n        self, ctx: GraphRunContext[QuestionState]\n    ) -> Annotated[Answer, Edge(label='Ask the question')]]:\n        ...\n\n...\n\n@dataclass\nclass Evaluate(BaseNode[QuestionState]):\n    answer: str\n\n    async def run(\n            self,\n            ctx: GraphRunContext[QuestionState],\n    ) -> Annotated[End[str], Edge(label='success')] | Reprimand:\n        ...\n\n...\n\nquestion_graph.mermaid_save('image.png', highlighted_nodes=[Answer])\n```\n\n----------------------------------------\n\nTITLE: Handling Olympics Location Data with Pydantic-AI\nDESCRIPTION: Demonstrates using Pydantic-AI to extract structured location data about Olympic games using a Gemini model. Shows how to define output types and access usage statistics.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent\n\n\nclass CityLocation(BaseModel):\n    city: str\n    country: str\n\n\nagent = Agent('google-gla:gemini-1.5-flash', output_type=CityLocation)\nresult = agent.run_sync('Where were the olympics held in 2012?')\nprint(result.output)\n#> city='London' country='United Kingdom'\nprint(result.usage())\n#> Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65, details=None)\n```\n\n----------------------------------------\n\nTITLE: Reusing Messages Across Different AI Models\nDESCRIPTION: Shows how to reuse conversation messages between different AI models (OpenAI GPT-4 and Google Gemini) while maintaining conversation context.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')\n\nresult1 = agent.run_sync('Tell me a joke.')\nprint(result1.output)\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\nresult2 = agent.run_sync(\n    'Explain?',\n    model='google-gla:gemini-1.5-pro',\n    message_history=result1.new_messages(),\n)\nprint(result2.output)\n#> This is an excellent joke invented by Samuel Colvin, it needs no explanation.\n\nprint(result2.all_messages())\n```\n\n----------------------------------------\n\nTITLE: Running the Weather Agent from Command Line (Bash)\nDESCRIPTION: Command to run the weather agent example with Python. This requires having the dependencies installed and environment variables set.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/weather-agent.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.weather_agent\n```\n\n----------------------------------------\n\nTITLE: Defining a Simple Graph in pydantic-graph (Python)\nDESCRIPTION: This example demonstrates how to define a simple graph with two nodes: DivisibleBy5 and Increment. It shows how to define the nodes, create the graph, and run it synchronously.  The example requires Python 3.10+.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_3\n\nLANGUAGE: Python\nCODE:\n```\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass DivisibleBy5(BaseNode[None, None, int]):  # (1)!\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext,\n    ) -> Increment | End[int]:\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return Increment(self.foo)\n\n\n@dataclass\nclass Increment(BaseNode):  # (2)!\n    foo: int\n\n    async def run(self, ctx: GraphRunContext) -> DivisibleBy5:\n        return DivisibleBy5(self.foo + 1)\n\n\nfives_graph = Graph(nodes=[DivisibleBy5, Increment])  # (3)!\nresult = fives_graph.run_sync(DivisibleBy5(4))  # (4)!\nprint(result.output)\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client Configuration for Gemini\nDESCRIPTION: Shows how to customize the HTTP client settings for Gemini API requests.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_gla import GoogleGLAProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = GeminiModel(\n    'gemini-2.0-flash',\n    provider=GoogleGLAProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Running the SQL Generation Example\nDESCRIPTION: Command to run the SQL generation example module with dependencies installed and environment variables set.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.sql_gen\n```\n\n----------------------------------------\n\nTITLE: Conditional Tool Registration with PydanticAI\nDESCRIPTION: Shows how to implement a dynamic tool that is only available when a specific condition is met. Uses a prepare function to conditionally include the tool based on a dependency value.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Union\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.tools import ToolDefinition\n\nagent = Agent('test')\n\nasync def only_if_42(ctx: RunContext[int], tool_def: ToolDefinition) -> Union[ToolDefinition, None]:\n    if ctx.deps == 42:\n        return tool_def\n\n@agent.tool(prepare=only_if_42)\ndef hitchhiker(ctx: RunContext[int], answer: str) -> str:\n    return f'{ctx.deps} {answer}'\n\nresult = agent.run_sync('testing...', deps=41)\nprint(result.output)\nresult = agent.run_sync('testing...', deps=42)\nprint(result.output)\n```\n\n----------------------------------------\n\nTITLE: Registering Function Tools via Constructor Arguments\nDESCRIPTION: Example demonstrating how to register PydanticAI function tools using the Agent constructor's tools parameter, showing both direct function registration and Tool class usage.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport random\n\nfrom pydantic_ai import Agent, RunContext, Tool\n\nsystem_prompt = \"\"\"\nYou're a dice game, you should roll the die and see if the number\nyou get back matches the user's guess. If so, tell them they're a winner.\nUse the player's name in the response.\n\"\"\"\n\ndef roll_die() -> str:\n    \"\"\"Roll a six-sided die and return the result.\"\"\"\n    return str(random.randint(1, 6))\n\ndef get_player_name(ctx: RunContext[str]) -> str:\n    \"\"\"Get the player's name.\"\"\"\n    return ctx.deps\n\nagent_a = Agent(\n    'google-gla:gemini-1.5-flash',\n    deps_type=str,\n    tools=[roll_die, get_player_name],\n    system_prompt=system_prompt,\n)\nagent_b = Agent(\n    'google-gla:gemini-1.5-flash',\n    deps_type=str,\n    tools=[\n        Tool(roll_die, takes_ctx=False),\n        Tool(get_player_name, takes_ctx=True),\n    ],\n    system_prompt=system_prompt,\n)\n\ndice_result = {}\ndice_result['a'] = agent_a.run_sync('My guess is 6', deps='Yashar')\ndice_result['b'] = agent_b.run_sync('My guess is 4', deps='Anne')\nprint(dice_result['a'].output)\nprint(dice_result['b'].output)\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client Configuration for Mistral\nDESCRIPTION: Python code demonstrating how to configure a MistralModel with a custom HTTP client and timeout settings.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.mistral import MistralModel\nfrom pydantic_ai.providers.mistral import MistralProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = MistralModel(\n    'mistral-large-latest',\n    provider=MistralProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Running the Streaming Whales Example with Python/UV\nDESCRIPTION: Command to run the whale information streaming example using Python/UV package manager, assuming dependencies are installed and environment variables are set.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-whales.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.stream_whales\n```\n\n----------------------------------------\n\nTITLE: Initializing Cohere Model by Name\nDESCRIPTION: Python code demonstrating how to initialize a Cohere model using the simplified name-based approach.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('cohere:command')\n...\n```\n\n----------------------------------------\n\nTITLE: Implementing Pydantic Logfire Instrumentation in Python\nDESCRIPTION: Code example showing how to set up Pydantic Logfire instrumentation for monitoring agent behavior. Demonstrates configuration of logfire, asyncpg instrumentation, and agent setup with monitoring enabled.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n...\nfrom pydantic_ai import Agent, RunContext\n\nfrom bank_database import DatabaseConn\n\nimport logfire\n\nlogfire.configure()  # (1)!\nlogfire.instrument_asyncpg()  # (2)!\n\n...\n\nsupport_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=SupportDependencies,\n    output_type=SupportOutput,\n    system_prompt=(\n        'You are a support agent in our bank, give the '\n        'customer support and judge the risk level of their query.'\n    ),\n    instrument=True,\n)\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI Slim with Multiple Integrations\nDESCRIPTION: Installation command showing how to install slim version with multiple optional dependencies (OpenAI, VertexAI, and Logfire).\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[openai,vertexai,logfire]\"\n```\n\n----------------------------------------\n\nTITLE: Example Pydantic Model Implementation File Reference\nDESCRIPTION: Reference to the example Python file that demonstrates how to use PydanticAI to create Pydantic models from text input. The actual code is not shown but is referenced by its path.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/pydantic-model.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/pydantic_model.py\n```\n\n----------------------------------------\n\nTITLE: Implementing Multi-Agent Flight Booking System in Python\nDESCRIPTION: The main Python script for the flight booking system. It contains the implementation of the multi-agent workflow, including agent definitions, delegation logic, and the booking process.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/flight-booking.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/flight_booking.py\n```\n\n----------------------------------------\n\nTITLE: Creating Pytest Fixture for Weather Agent Override\nDESCRIPTION: Example of creating a pytest fixture to override the weather agent model with TestModel. This approach allows for reusable test configurations across multiple test cases.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/testing.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport pytest\nfrom weather_app import weather_agent\n\nfrom pydantic_ai.models.test import TestModel\n\n\n@pytest.fixture\ndef override_weather_agent():\n    with weather_agent.override(model=TestModel()):\n        yield\n\n\nasync def test_forecast(override_weather_agent: None):\n    ...\n    # test code here\n```\n\n----------------------------------------\n\nTITLE: Running PydanticAI Example with Gemini Model\nDESCRIPTION: Command to run the Pydantic model example using Google's Gemini 1.5 Pro model instead of the default. This demonstrates the flexibility to switch between different AI models.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/pydantic-model.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nPYDANTIC_AI_MODEL=gemini-1.5-pro python/uv-run -m pydantic_ai_examples.pydantic_model\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI Slim with OpenAI Integration\nDESCRIPTION: Installation command for the slim version of PydanticAI with OpenAI model support only.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[openai]\"\n```\n\n----------------------------------------\n\nTITLE: Direct OpenAI Model Initialization\nDESCRIPTION: Explicit initialization of an OpenAI model using the OpenAIModel class.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\n\nmodel = OpenAIModel('gpt-4o')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Basic Hello World Agent Implementation in Python with PydanticAI\nDESCRIPTION: Demonstrates basic usage of PydanticAI by creating a simple agent that uses Gemini 1.5 Flash model to answer a question with a concise response. Shows agent initialization, system prompt configuration, and synchronous execution.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent(\n    'google-gla:gemini-1.5-flash',\n    system_prompt='Be concise, reply with one sentence.',\n)\n\nresult = agent.run_sync('Where does \"hello world\" come from?')\nprint(result.output)\n\"\"\"\nThe first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Configuring Together AI Integration with Pydantic\nDESCRIPTION: Establishes connection to Together AI platform using Pydantic AI library. Configures the OpenAI-compatible interface for Together's Llama model and requires a Together AI API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\nmodel = OpenAIModel(\n    'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free',  # model library available at https://www.together.ai/models\n    provider=OpenAIProvider(\n        base_url='https://api.together.xyz/v1',\n        api_key='your-together-api-key',\n    ),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Graph with Dependency Injection\nDESCRIPTION: Demonstrates dependency injection in a pydantic-graph using a `ProcessPoolExecutor`. The `GraphDeps` dataclass holds the executor dependency. The `Increment` node uses the executor to run the `compute` function in a separate process.  This is a contrived example; `ProcessPoolExecutor` wouldn't actually improve performance in this example.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_16\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport asyncio\nfrom concurrent.futures import ProcessPoolExecutor\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass GraphDeps:\n    executor: ProcessPoolExecutor\n\n\n@dataclass\nclass DivisibleBy5(BaseNode[None, GraphDeps, int]):\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext[None, GraphDeps],\n    ) -> Increment | End[int]:\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return Increment(self.foo)\n\n\n@dataclass\nclass Increment(BaseNode[None, GraphDeps]):\n    foo: int\n\n    async def run(self, ctx: GraphRunContext[None, GraphDeps]) -> DivisibleBy5:\n        loop = asyncio.get_running_loop()\n        compute_result = await loop.run_in_executor(\n            ctx.deps.executor,\n            self.compute,\n        )\n        return DivisibleBy5(compute_result)\n\n    def compute(self) -> int:\n        return self.foo + 1\n\n\nfives_graph = Graph(nodes=[DivisibleBy5, Increment])\n\n\nasync def main():\n    with ProcessPoolExecutor() as executor:\n        deps = GraphDeps(executor)\n        result = await fives_graph.run(DivisibleBy5(3), deps=deps)\n    print(result.output)\n    # the full history is quite verbose (see below), so we'll just print the summary\n    print([item.data_snapshot() for item in result.history])\n```\n\n----------------------------------------\n\nTITLE: RAG Search Implementation in Python\nDESCRIPTION: This code snippet represents the main implementation of the RAG search example. It includes the full content of the rag.py file, which likely contains the PydanticAI agent setup, tool definitions, and search functionality.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/rag.py\n```\n\n----------------------------------------\n\nTITLE: Custom Provider Configuration for Gemini\nDESCRIPTION: Demonstrates how to configure a custom GoogleGLAProvider with API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_gla import GoogleGLAProvider\n\nmodel = GeminiModel(\n    'gemini-2.0-flash', provider=GoogleGLAProvider(api_key='your-api-key')\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Handling Fallback Model Failures in Python <3.11\nDESCRIPTION: Demonstrates fallback model error handling for Python versions before 3.11 using the exceptiongroup backport package. Shows implementation of custom error handlers for ModelHTTPError exceptions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/index.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom exceptiongroup import catch\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.exceptions import ModelHTTPError\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.models.fallback import FallbackModel\nfrom pydantic_ai.models.openai import OpenAIModel\n\n\ndef model_status_error_handler(exc_group: BaseExceptionGroup) -> None:\n    for exc in exc_group.exceptions:\n        print(exc)\n\n\nopenai_model = OpenAIModel('gpt-4o')\nanthropic_model = AnthropicModel('claude-3-5-sonnet-latest')\nfallback_model = FallbackModel(openai_model, anthropic_model)\n\nagent = Agent(fallback_model)\nwith catch({ModelHTTPError: model_status_error_handler}):\n    response = agent.run_sync('What is the capital of France?')\n```\n\n----------------------------------------\n\nTITLE: Initializing Bedrock Model by Name\nDESCRIPTION: Example of creating an Agent instance using a Bedrock model identifier\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('bedrock:anthropic.claude-3-sonnet-20240229-v1:0')\n...\n```\n\n----------------------------------------\n\nTITLE: Direct MCP Client Usage Example\nDESCRIPTION: Example showing how to use the MCP Run Python server directly with the Python MCP client to execute NumPy operations.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/run-python.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\ncode = \"\"\"\nimport numpy\na = numpy.array([1, 2, 3])\nprint(a)\na\n\"\"\"\nserver_params = StdioServerParameters(\n    command='deno',\n    args=[\n        'run',\n        '-N',\n        '-R=node_modules',\n        '-W=node_modules',\n        '--node-modules-dir=auto',\n        'jsr:@pydantic/mcp-run-python',\n        'stdio',\n    ],\n)\n\n\nasync def main():\n    async with stdio_client(server_params) as (read, write):\n        async with ClientSession(read, write) as session:\n            await session.initialize()\n            tools = await session.list_tools()\n            print(len(tools.tools))\n            #> 1\n            print(repr(tools.tools[0].name))\n            #> 'run_python_code'\n            print(repr(tools.tools[0].inputSchema))\n            \"\"\"\n            {'type': 'object', 'properties': {'python_code': {'type': 'string', 'description': 'Python code to run'}}, 'required': ['python_code'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}\n            \"\"\"\n            result = await session.call_tool('run_python_code', {'python_code': code})\n            print(result.content[0].text)\n            \"\"\"\n            <status>success</status>\n            <dependencies>[\\\"numpy\\\"]</dependencies>\n            <output>\n            [1 2 3]\n            </output>\n            <return_value>\n            [\n              1,\n              2,\n              3\n            ]\n            </return_value>\n            \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Initializing Mistral Agent by Model Name\nDESCRIPTION: Python code showing how to initialize a Mistral agent using the shorthand model name notation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('mistral:mistral-large-latest')\n...\n```\n\n----------------------------------------\n\nTITLE: Configuring Recipe Transform Tests in YAML\nDESCRIPTION: YAML configuration for recipe transformation test cases specifying dietary restrictions and evaluation criteria using LLM judges.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_6\n\nLANGUAGE: yaml\nCODE:\n```\ncases:\n- name: vegetarian_recipe\n  inputs:\n    dish_name: Spaghetti Bolognese\n    dietary_restriction: vegetarian\n  metadata:\n    focus: vegetarian\n  evaluators:\n  - LLMJudge: Recipe should not contain meat or animal products\n- name: gluten_free_recipe\n  inputs:\n    dish_name: Chocolate Cake\n    dietary_restriction: gluten-free\n  metadata:\n    focus: gluten-free\n  evaluators:\n  - LLMJudge: Recipe should not contain gluten or wheat products\nevaluators:\n- IsInstance: Recipe\n- LLMJudge:\n    rubric: Recipe should have clear steps and relevant ingredients\n    model: anthropic:claude-3-7-sonnet-latest\n    include_input: true\n```\n\n----------------------------------------\n\nTITLE: Processing Image Input Using ImageUrl in Pydantic AI\nDESCRIPTION: Demonstrates how to analyze an image using ImageUrl class with a direct URL. The example shows how to query an LLM about the content of an image using the OpenAI GPT-4 model.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/input.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent, ImageUrl\n\nagent = Agent(model='openai:gpt-4o')\nresult = agent.run_sync(\n    [\n        'What company is this logo from?',\n        ImageUrl(url='https://iili.io/3Hs4FMg.png'),\n    ]\n)\nprint(result.output)\n# > This is the logo for Pydantic, a data validation and settings management library in Python.\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Fallback Model in Python\nDESCRIPTION: Demonstrates how to implement a fallback mechanism between OpenAI and Anthropic models using FallbackModel. Shows configuration of multiple models and handling of fallback responses.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/index.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.models.fallback import FallbackModel\nfrom pydantic_ai.models.openai import OpenAIModel\n\nopenai_model = OpenAIModel('gpt-4o')\nanthropic_model = AnthropicModel('claude-3-5-sonnet-latest')\nfallback_model = FallbackModel(openai_model, anthropic_model)\n\nagent = Agent(fallback_model)\nresponse = agent.run_sync('What is the capital of France?')\nprint(response.data)\n#> Paris\n\nprint(response.all_messages())\n```\n\n----------------------------------------\n\nTITLE: Single Parameter Tool Schema with Pydantic Model\nDESCRIPTION: Demonstrates how to create a tool with a single Pydantic model parameter and inspect the generated schema using TestModel. Shows simplified schema generation for single-parameter tools.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\n\nagent = Agent()\n\nclass Foobar(BaseModel):\n    \"\"\"This is a Foobar\"\"\"\n    x: int\n    y: str\n    z: float = 3.14\n\n@agent.tool_plain\ndef foobar(f: Foobar) -> str:\n    return str(f)\n\ntest_model = TestModel()\nresult = agent.run_sync('hello', model=test_model)\nprint(result.output)\nprint(test_model.last_model_request_parameters.function_tools)\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI Base Package\nDESCRIPTION: Basic installation command for the full PydanticAI package using pip or uv package manager. Requires Python 3.9+.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add pydantic-ai\n```\n\n----------------------------------------\n\nTITLE: Direct Mistral Model Initialization\nDESCRIPTION: Python code demonstrating direct initialization of a MistralModel with a specific model name.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.mistral import MistralModel\n\nmodel = MistralModel('mistral-small-latest')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Setting Custom OpenTelemetry Providers\nDESCRIPTION: Configuration for custom TracerProvider and EventLoggerProvider in OpenTelemetry\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom opentelemetry.sdk._events import EventLoggerProvider\nfrom opentelemetry.sdk.trace import TracerProvider\n\nfrom pydantic_ai.agent import InstrumentationSettings\n\ninstrumentation_settings = InstrumentationSettings(\n    tracer_provider=TracerProvider(),\n    event_logger_provider=EventLoggerProvider(),\n)\n```\n\n----------------------------------------\n\nTITLE: Installing Pydantic-AI with Cohere Support\nDESCRIPTION: Command to install Pydantic-AI with Cohere integration using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[cohere]\"\n```\n\n----------------------------------------\n\nTITLE: Complete Evaluation Process Example in Python\nDESCRIPTION: Demonstrates a full evaluation process, including dataset creation, custom evaluator implementation, and result reporting.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_evals import Case, Dataset\nfrom pydantic_evals.evaluators import Evaluator, EvaluatorContext, IsInstance\n\ncase1 = Case(\n    name='simple_case',\n    inputs='What is the capital of France?',\n    expected_output='Paris',\n    metadata={'difficulty': 'easy'},\n)\n\n\nclass MyEvaluator(Evaluator[str, str]):\n    def evaluate(self, ctx: EvaluatorContext[str, str]) -> float:\n        if ctx.output == ctx.expected_output:\n            return 1.0\n        elif (\n            isinstance(ctx.output, str)\n            and ctx.expected_output.lower() in ctx.output.lower()\n        ):\n            return 0.8\n        else:\n            return 0.0\n\n\ndataset = Dataset(\n    cases=[case1],\n    evaluators=[IsInstance(type_name='str'), MyEvaluator()],\n)\n\n\nasync def guess_city(question: str) -> str:\n    return 'Paris'\n\n\nreport = dataset.evaluate_sync(guess_city)\nreport.print(include_input=True, include_output=True, include_durations=False)\n```\n\n----------------------------------------\n\nTITLE: Implementing Usage Limits in PydanticAI\nDESCRIPTION: Demonstrates how to set and handle usage limits for token consumption and request counts using the UsageLimits structure. Shows examples of both successful and limited responses.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.exceptions import UsageLimitExceeded\nfrom pydantic_ai.usage import UsageLimits\n\nagent = Agent('anthropic:claude-3-5-sonnet-latest')\n\nresult_sync = agent.run_sync(\n    'What is the capital of Italy? Answer with just the city.',\n    usage_limits=UsageLimits(response_tokens_limit=10),\n)\nprint(result_sync.output)\n#> Rome\nprint(result_sync.usage())\n\"\"\"\nUsage(requests=1, request_tokens=62, response_tokens=1, total_tokens=63, details=None)\n\"\"\"\n\ntry:\n    result_sync = agent.run_sync(\n        'What is the capital of Italy? Answer with a paragraph.',\n        usage_limits=UsageLimits(response_tokens_limit=10),\n    )\nexcept UsageLimitExceeded as e:\n    print(e)\n    #> Exceeded the response_tokens_limit of 10 (response_tokens=32)\n```\n\n----------------------------------------\n\nTITLE: Initializing Seat Preference Agent with GPT-4\nDESCRIPTION: Defines an AI agent for extracting user seat preferences using GPT-4. The agent handles window seats (A and F) and rows with extra legroom (1, 14, and 20).\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nseat_preference_agent = Agent[None, Union[SeatPreference, Failed]](\n    'openai:gpt-4o',\n    output_type=Union[SeatPreference, Failed],  # type: ignore\n    system_prompt=(\n        \"Extract the user's seat preference. \"\n        'Seats A and F are window seats. '\n        'Row 1 is the front row and has extra leg room. '\n        'Rows 14, and 20 also have extra leg room. '\n    ),\n)\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Command to set the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Visualizing Multi-Agent Workflow with Mermaid\nDESCRIPTION: A Mermaid graph illustrating the control flow of the multi-agent flight booking system. It shows the sequence of interactions between different agents and human interventions in the booking process.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/flight-booking.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TD\n  START --> search_agent(\"search agent\")\n  search_agent --> extraction_agent(\"extraction agent\")\n  extraction_agent --> search_agent\n  search_agent --> human_confirm(\"human confirm\")\n  human_confirm --> search_agent\n  search_agent --> FAILED\n  human_confirm --> find_seat_function(\"find seat function\")\n  find_seat_function --> human_seat_choice(\"human seat choice\")\n  human_seat_choice --> find_seat_agent(\"find seat agent\")\n  find_seat_agent --> find_seat_function\n  find_seat_function --> buy_flights(\"buy flights\")\n  buy_flights --> SUCCESS\n```\n\n----------------------------------------\n\nTITLE: Bank Support Agent Implementation in Python\nDESCRIPTION: This Python script implements a bank support agent using PydanticAI. The code is located in the file 'bank_support.py' within the 'examples/pydantic_ai_examples/' directory.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/bank-support.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/bank_support.py\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Environment Variable\nDESCRIPTION: Command to set up the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: MCP Client Implementation for PydanticAI Server\nDESCRIPTION: Demonstrates how to create an MCP client that connects to the poetry server using stdio communication. The client initializes a session, calls the 'poet' tool with a theme, and prints the generated poem.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/server.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport os\n\nfrom mcp import ClientSession, StdioServerParameters\nfrom mcp.client.stdio import stdio_client\n\n\nasync def client():\n    server_params = StdioServerParameters(\n        command='uv', args=['run', 'mcp_server.py', 'server'], env=os.environ\n    )\n    async with stdio_client(server_params) as (read, write):\n        async with ClientSession(read, write) as session:\n            await session.initialize()\n            result = await session.call_tool('poet', {'theme': 'socks'})\n            print(result.content[0].text)\n            \"\"\"\n            Oh, socks, those garments soft and sweet,\n            That nestle softly 'round our feet,\n            From cotton, wool, or blended thread,\n            They keep our toes from feeling dread.\n            \"\"\"\n\n\nif __name__ == '__main__':\n    asyncio.run(client())\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI Examples Package\nDESCRIPTION: Installation command for PydanticAI examples package to access and run example code.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai[examples]\"\n```\n\n----------------------------------------\n\nTITLE: Async Seat Finding Function\nDESCRIPTION: Implements an async function to handle user seat selection. It continuously prompts for input until a valid seat preference is obtained.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nasync def find_seat(usage: Usage) -> SeatPreference:\n    message_history: Union[list[ModelMessage], None] = None\n    while True:\n        answer = Prompt.ask('What seat would you like?')\n\n        result = await seat_preference_agent.run(\n            answer,\n            message_history=message_history,\n            usage=usage,\n            usage_limits=usage_limits,\n        )\n        if isinstance(result.output, SeatPreference):\n            return result.output\n        else:\n            print('Could not understand seat preference. Please try again.')\n            message_history = result.all_messages()\n```\n\n----------------------------------------\n\nTITLE: Setting Groq API Key Environment Variable\nDESCRIPTION: Command to set up the Groq API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport GROQ_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Generating Mermaid Diagram Code for a pydantic-graph (Python)\nDESCRIPTION: This snippet demonstrates how to generate Mermaid diagram code from a defined pydantic-graph. This code can be used to visualize the graph structure using Mermaid syntax.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_4\n\nLANGUAGE: Python\nCODE:\n```\nfrom graph_example import DivisibleBy5, fives_graph\n\nfives_graph.mermaid_code(start_node=DivisibleBy5)\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire Integration for Pydantic Evals\nDESCRIPTION: Shows how to set up Logfire integration with Pydantic Evals for trace recording and monitoring of evaluation results.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/pydantic_evals/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure(\n    send_to_logfire='if-token-present',\n    environment='development',\n    service_name='evals',\n)\n\n...\n\nmy_dataset.evaluate_sync(my_task)\n```\n\n----------------------------------------\n\nTITLE: Displaying Mermaid Diagram in Jupyter Notebook (Python)\nDESCRIPTION: This code shows how to display a Mermaid diagram within a Jupyter Notebook using IPython.display.Image. It retrieves the diagram image from the graph and displays it in the notebook.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_6\n\nLANGUAGE: Python\nCODE:\n```\nfrom graph_example import DivisibleBy5, fives_graph\nfrom IPython.display import Image, display\n\ndisplay(Image(fives_graph.mermaid_image(start_node=DivisibleBy5)))\n```\n\n----------------------------------------\n\nTITLE: Rendering Chat App Frontend with HTML\nDESCRIPTION: HTML code for the chat application's frontend. This simple page provides the structure for rendering the chat interface in the browser.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/chat-app.md#2025-04-22_snippet_2\n\nLANGUAGE: html\nCODE:\n```\n#! examples/pydantic_ai_examples/chat_app.html\n```\n\n----------------------------------------\n\nTITLE: Iterating Graph with Graph.iter\nDESCRIPTION: This code demonstrates how to use `Graph.iter` to iterate over a graph and access each node as it executes. It defines a `CountDown` graph that decrements a counter in the `CountDownState`. The `async with` statement allows iterating over the graph's nodes using `async for`, and the final result is obtained from `run.result.output`. This requires `pydantic_graph` library.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations as _annotations\n\nfrom dataclasses import dataclass\nfrom pydantic_graph import Graph, BaseNode, End, GraphRunContext\n\n\n@dataclass\nclass CountDownState:\n    counter: int\n\n\n@dataclass\nclass CountDown(BaseNode[CountDownState, None, int]):\n    async def run(self, ctx: GraphRunContext[CountDownState]) -> CountDown | End[int]:\n        if ctx.state.counter <= 0:\n            return End(ctx.state.counter)\n        ctx.state.counter -= 1\n        return CountDown()\n\n\ncount_down_graph = Graph(nodes=[CountDown])\n\n\nasync def main():\n    state = CountDownState(counter=3)\n    async with count_down_graph.iter(CountDown(), state=state) as run:  # (1)!\n        async for node in run:  # (2)!\n            print('Node:', node)\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: CountDown()\n            #> Node: End(data=0)\n    print('Final output:', run.result.output)  # (3)!\n    #> Final output: 0\n\n```\n\n----------------------------------------\n\nTITLE: Setting Up CLI Autocompletion\nDESCRIPTION: Commands to enable command-line argument autocompletion for both bash and zsh shells.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nregister-python-argcomplete pai >> ~/.bashrc  # for bash\nregister-python-argcomplete pai >> ~/.zshrc   # for zsh\n```\n\n----------------------------------------\n\nTITLE: Creating and Testing Agents with FunctionModel in Python\nDESCRIPTION: Example showing how to create a custom model function to control agent behavior for testing. The code demonstrates setting up a test agent, defining a model function that processes messages and agent info, and writing a unit test using pytest. The function returns a controlled response for predictable testing.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/function.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.messages import ModelMessage, ModelResponse, TextPart\nfrom pydantic_ai.models.function import FunctionModel, AgentInfo\n\nmy_agent = Agent('openai:gpt-4o')\n\n\nasync def model_function(\n    messages: list[ModelMessage], info: AgentInfo\n) -> ModelResponse:\n    print(messages)\n    \"\"\"\n    [\n        ModelRequest(\n            parts=[\n                UserPromptPart(\n                    content='Testing my agent...',\n                    timestamp=datetime.datetime(...),\n                    part_kind='user-prompt',\n                )\n            ],\n            instructions=None,\n            kind='request',\n        )\n    ]\n    \"\"\"\n    print(info)\n    \"\"\"\n    AgentInfo(\n        function_tools=[], allow_text_output=True, output_tools=[], model_settings=None\n    )\n    \"\"\"\n    return ModelResponse(parts=[TextPart('hello world')])\n\n\nasync def test_my_agent():\n    \"\"\"Unit test for my_agent, to be run by pytest.\"\"\"\n    with my_agent.override(model=FunctionModel(model_function)):\n        result = await my_agent.run('Testing my agent...')\n        assert result.output == 'hello world'\n```\n\n----------------------------------------\n\nTITLE: Specifying Model Selection\nDESCRIPTION: Example command showing how to use the CLI with a specific model selection.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\n$ pai --model=openai:gpt-4 \"What's the capital of France?\"\n```\n\n----------------------------------------\n\nTITLE: Importing and Rendering Pydantic Graph Visualization using Mermaid in Markdown\nDESCRIPTION: This snippet demonstrates how to include a Pydantic graph visualization using Mermaid syntax in a markdown document. The triple colon syntax indicates a custom rendering directive that would import and display the graph from the pydantic_graph.mermaid module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_graph/mermaid.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_graph.mermaid\n```\n\n----------------------------------------\n\nTITLE: Accessing Messages from RunResult in PydanticAI - Python\nDESCRIPTION: Demonstrates how to access messages from a synchronous agent run using RunResult object. Shows message retrieval and output formatting with a simple joke example.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')\n\nresult = agent.run_sync('Tell me a joke.')\nprint(result.output)\n#> Did you hear about the toothpaste scandal? They called it Colgate.\n\n# all messages from the run\nprint(result.all_messages())\n\"\"\"\n[]\n    ModelRequest(\n        parts=[\n            SystemPromptPart(\n                content='Be a helpful assistant.',\n                timestamp=datetime.datetime(...),\n                dynamic_ref=None,\n                part_kind='system-prompt',\n            ),\n            UserPromptPart(\n                content='Tell me a joke.',\n                timestamp=datetime.datetime(...),\n                part_kind='user-prompt',\n            ),\n        ],\n        instructions=None,\n        kind='request',\n    ),\n    ModelResponse(\n        parts=[\n            TextPart(\n                content='Did you hear about the toothpaste scandal? They called it Colgate.',\n                part_kind='text',\n            )\n        ],\n        model_name='gpt-4o',\n        timestamp=datetime.datetime(...),\n        kind='response',\n    ),\n]\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Resolving Jupyter Event Loop Conflicts with nest-asyncio\nDESCRIPTION: Code snippet demonstrating how to resolve event loop conflicts in Jupyter notebooks, Google Colab, and Marimo environments when using PydanticAI by implementing nest-asyncio.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/troubleshooting.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport nest_asyncio\n\nnest_asyncio.apply()\n```\n\n----------------------------------------\n\nTITLE: Ollama Local Usage Example\nDESCRIPTION: Example of using Ollama locally with Pydantic-AI for model inference.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\n\nclass CityLocation(BaseModel):\n    city: str\n    country: str\n\n\nollama_model = OpenAIModel(\n    model_name='llama3.2', provider=OpenAIProvider(base_url='http://localhost:11434/v1')\n)\nagent = Agent(ollama_model, output_type=CityLocation)\n\nresult = agent.run_sync('Where were the olympics held in 2012?')\nprint(result.output)\nprint(result.usage())\n```\n\n----------------------------------------\n\nTITLE: Generating JSON Test Dataset with Pydantic Models in Python\nDESCRIPTION: Shows how to generate a test dataset in JSON format using previously defined Pydantic models. Generates the same question-answer dataset structure but outputs in JSON format with schema reference.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom pathlib import Path\n\nfrom generate_dataset_example import AnswerOutput, MetadataType, QuestionInputs\n\nfrom pydantic_evals import Dataset\nfrom pydantic_evals.generation import generate_dataset\n\n\nasync def main():\n    dataset = await generate_dataset(\n        dataset_type=Dataset[QuestionInputs, AnswerOutput, MetadataType],\n        n_examples=2,\n        extra_instructions=\"\"\"\n        Generate question-answer pairs about world capitals and landmarks.\n        Make sure to include both easy and challenging questions.\n        \"\"\",\n    )\n    output_file = Path('questions_cases.json')\n    dataset.to_file(output_file)\n```\n\n----------------------------------------\n\nTITLE: Streaming Text Output with Complete Response\nDESCRIPTION: Shows how to stream text responses with complete text updates at each step using the Gemini model.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('google-gla:gemini-1.5-flash')\n\n\nasync def main():\n    async with agent.run_stream('Where does \"hello world\" come from?') as result:\n        async for message in result.stream_text():\n            print(message)\n            #> The first known\n            #> The first known use of \"hello,\n            #> The first known use of \"hello, world\" was in\n            #> The first known use of \"hello, world\" was in a 1974 textbook\n            #> The first known use of \"hello, world\" was in a 1974 textbook about the C\n            #> The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n```\n\n----------------------------------------\n\nTITLE: Reference to the Stream Whales Python Example File\nDESCRIPTION: Reference link to the stream_whales.py example file that demonstrates streaming structured output from GPT-4 with validation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-whales.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/stream_whales.py\n```\n\n----------------------------------------\n\nTITLE: In-Memory Service Account Configuration\nDESCRIPTION: Sets up VertexAI authentication using service account information stored in memory.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_vertex import GoogleVertexProvider\n\nservice_account_info = json.loads(\n    '{\"type\": \"service_account\", \"project_id\": \"my-project-id\"}'\n)\nmodel = GeminiModel(\n    'gemini-2.0-flash',\n    provider=GoogleVertexProvider(service_account_info=service_account_info),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Running MCP Server with Deno\nDESCRIPTION: Command to run the MCP server using Deno with necessary permissions for network access and node_modules management. Supports different transport modes including stdio, sse, and warmup.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/mcp-run-python/README.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndeno run \\\n  -N -R=node_modules -W=node_modules --node-modules-dir=auto \\\n  jsr:@pydantic/mcp-run-python [stdio|sse|warmup]\n```\n\n----------------------------------------\n\nTITLE: HTTPX Instrumentation Example\nDESCRIPTION: Complete example showing HTTPX instrumentation with an Agent query\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom pydantic_ai import Agent\n\nlogfire.configure()\nlogfire.instrument_httpx(capture_all=True)\n\nagent = Agent('openai:gpt-4o', instrument=True)\nresult = agent.run_sync('What is the capital of France?')\nprint(result.output)\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Settings in PydanticAI\nDESCRIPTION: Example of configuring model behavior using ModelSettings to set temperature and other parameters.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o')\n\nresult_sync = agent.run_sync(\n    'What is the capital of Italy?', model_settings={'temperature': 0.0}\n)\nprint(result_sync.output)\n#> Rome\n```\n\n----------------------------------------\n\nTITLE: Implementing Weather Forecast Agent with PydanticAI\nDESCRIPTION: Example application code demonstrating a weather forecast agent implementation using PydanticAI. The code includes an Agent setup with weather forecast tool and an async function to process multiple weather requests.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/testing.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom datetime import date\n\nfrom pydantic_ai import Agent, RunContext\n\nfrom fake_database import DatabaseConn\nfrom weather_service import WeatherService\n\nweather_agent = Agent(\n    'openai:gpt-4o',\n    deps_type=WeatherService,\n    system_prompt='Providing a weather forecast at the locations the user provides.',\n)\n\n@weather_agent.tool\ndef weather_forecast(\n    ctx: RunContext[WeatherService], location: str, forecast_date: date\n) -> str:\n    if forecast_date < date.today():\n        return ctx.deps.get_historic_weather(location, forecast_date)\n    else:\n        return ctx.deps.get_forecast(location, forecast_date)\n\nasync def run_weather_forecast(\n    user_prompts: list[tuple[str, int]], conn: DatabaseConn\n):\n    \"\"\"Run weather forecast for a list of user prompts and save.\"\"\"\n    async with WeatherService() as weather_service:\n\n        async def run_forecast(prompt: str, user_id: int):\n            result = await weather_agent.run(prompt, deps=weather_service)\n            await conn.store_forecast(user_id, result.output)\n\n        # run all prompts in parallel\n        await asyncio.gather(\n            *(run_forecast(prompt, user_id) for (prompt, user_id) in user_prompts)\n        )\n```\n\n----------------------------------------\n\nTITLE: Visualizing ModelMessage Structure with Mermaid\nDESCRIPTION: A graph diagram showing the hierarchical structure of ModelMessage class and its relationships with different message part types including SystemPromptPart, UserPromptPart, ToolReturnPart, RetryPromptPart, TextPart, and ToolCallPart.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/messages.md#2025-04-22_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph RL\n    SystemPromptPart(SystemPromptPart) --- ModelRequestPart\n    UserPromptPart(UserPromptPart) --- ModelRequestPart\n    ToolReturnPart(ToolReturnPart) --- ModelRequestPart\n    RetryPromptPart(RetryPromptPart) --- ModelRequestPart\n    TextPart(TextPart) --- ModelResponsePart\n    ToolCallPart(ToolCallPart) --- ModelResponsePart\n    ModelRequestPart(\"ModelRequestPart<br>(Union)\") --- ModelRequest\n    ModelRequest(\"ModelRequest(parts=list[...])\") --- ModelMessage\n    ModelResponsePart(\"ModelResponsePart<br>(Union)\") --- ModelResponse\n    ModelResponse(\"ModelResponse(parts=list[...])\") --- ModelMessage(\"ModelMessage<br>(Union)\")\n```\n\n----------------------------------------\n\nTITLE: Installing pydantic-graph with pip/uv\nDESCRIPTION: This command shows how to install the pydantic-graph library using pip or uv, which is a required dependency of pydantic-ai.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_0\n\nLANGUAGE: Bash\nCODE:\n```\npip/uv-add pydantic-graph\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI with Tavily Search Tool\nDESCRIPTION: Command to install pydantic-ai-slim with the Tavily optional group for using the Tavily search tool.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[tavily]\"\n```\n\n----------------------------------------\n\nTITLE: Generated Mermaid Diagram Example\nDESCRIPTION: This is an example of a Mermaid diagram generated by Pydantic Graph, demonstrating edge labels, node notes, and highlighted nodes. It visually represents the flow of a question answering system, including asking a question, answering it, evaluating the answer, and taking actions based on the evaluation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_18\n\nLANGUAGE: mermaid\nCODE:\n```\n---\ntitle: question_graph\n---\nstateDiagram-v2\n  Ask --> Answer: Ask the question\n  note right of Ask\n    Judge the answer.\n    Decide on next step.\n  end note\n  Answer --> Evaluate\n  Evaluate --> Reprimand\n  Evaluate --> [*]: success\n  Reprimand --> Ask\n\nclassDef highlighted fill:#fdff32\nclass Answer highlighted\n```\n\n----------------------------------------\n\nTITLE: Serving documentation locally with mkdocs\nDESCRIPTION: Command to run the documentation website locally using mkdocs through the uv runner.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\nuv run mkdocs serve\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire Integration with Pydantic Evals in Python\nDESCRIPTION: Demonstrates how to integrate Pydantic Evals with Logfire for trace monitoring. Shows configuration setup including environment settings and service name definition for OpenTelemetry trace collection.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_11\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nfrom judge_recipes import recipe_dataset, transform_recipe\n\nlogfire.configure(\n    send_to_logfire='if-token-present',\n    environment='development',\n    service_name='evals',\n)\n\nrecipe_dataset.evaluate_sync(transform_recipe)\n```\n\n----------------------------------------\n\nTITLE: Enabling Agent Instrumentation\nDESCRIPTION: Code to enable instrumentation for individual agents or globally for all agents\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o', instrument=True)\n# or instrument all agents to avoid needing to add `instrument=True` to each agent:\nAgent.instrument_all()\n```\n\n----------------------------------------\n\nTITLE: Visualizing Question Graph Flow with Mermaid\nDESCRIPTION: Mermaid diagram showing the flow of the question graph, including states for asking a question, answering, evaluating the response, and congratulating or castigating based on the evaluation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/question-graph.md#2025-04-22_snippet_2\n\nLANGUAGE: mermaid\nCODE:\n```\n---\ntitle: question_graph\n---\nstateDiagram-v2\n  [*] --> Ask\n  Ask --> Answer: ask the question\n  Answer --> Evaluate: answer the question\n  Evaluate --> Congratulate\n  Evaluate --> Castigate\n  Congratulate --> [*]: success\n  Castigate --> Ask: try again\n```\n\n----------------------------------------\n\nTITLE: Copying PydanticAI Examples\nDESCRIPTION: Command to copy PydanticAI examples to a local directory for editing.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_6\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples --copy-to examples/\n```\n\n----------------------------------------\n\nTITLE: Running PydanticAI Bank Support Example\nDESCRIPTION: This bash command demonstrates how to run the bank support example using Python or uv-run. It also shows an alternative command using the PYDANTIC_AI_MODEL environment variable.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/bank-support.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.bank_support\n```\n\n----------------------------------------\n\nTITLE: Referencing Pydantic Evals Dataset Module in Documentation\nDESCRIPTION: This snippet uses a specialized documentation directive (likely for MkDocs or a similar documentation generator) to include or reference the documentation for the pydantic_evals.dataset module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_evals/dataset.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_evals.dataset\n```\n\n----------------------------------------\n\nTITLE: Installing MCP Run Python with Deno\nDESCRIPTION: Command to install and run the MCP Run Python server using Deno with necessary permissions for network access and module management.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/run-python.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ndeno run \\\n  -N -R=node_modules -W=node_modules --node-modules-dir=auto \\\n  jsr:@pydantic/mcp-run-python [stdio|sse|warmup]\n```\n\n----------------------------------------\n\nTITLE: Direct Anthropic Model Initialization\nDESCRIPTION: Example of directly initializing an AnthropicModel instance and creating an Agent.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\n\nmodel = AnthropicModel('claude-3-5-sonnet-latest')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Main Async Function for Flight Booking\nDESCRIPTION: Main application logic that coordinates flight search and seat selection processes. Demonstrates the complete booking flow.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nasync def main():\n    usage: Usage = Usage()\n\n    opt_flight_details = await find_flight(usage)\n    if opt_flight_details is not None:\n        print(f'Flight found: {opt_flight_details.flight_number}')\n        #> Flight found: AK456\n        seat_preference = await find_seat(usage)\n        print(f'Seat preference: {seat_preference}')\n        #> Seat preference: row=1 seat='A'\n```\n\n----------------------------------------\n\nTITLE: Module Reference for Common Tools\nDESCRIPTION: Documentation reference structure for DuckDuckGo and Tavily integration tools in the pydantic-ai common_tools package.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/common_tools.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.common_tools`\n\n::: pydantic_ai.common_tools.duckduckgo\n\n::: pydantic_ai.common_tools.tavily\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic AI Exceptions in Python\nDESCRIPTION: This code snippet represents the exceptions module in the Pydantic AI project. It contains custom exception classes used throughout the library for error handling and reporting specific issues related to Pydantic AI operations.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/exceptions.md#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n::: pydantic_ai.exceptions\n```\n\n----------------------------------------\n\nTITLE: One-line PydanticAI Example Execution\nDESCRIPTION: Complete one-liner command to run a PydanticAI example with API key and dependencies setup using uv.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nOPENAI_API_KEY='your-api-key' \\\n  uv run --with \"pydantic-ai[examples]\" \\\n  -m pydantic_ai_examples.pydantic_model\n```\n\n----------------------------------------\n\nTITLE: Customizing Bedrock Model Settings\nDESCRIPTION: Example of configuring Bedrock model with custom guardrail and performance settings\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.bedrock import BedrockConverseModel, BedrockModelSettings\n\n# Define Bedrock model settings with guardrail and performance configurations\nbedrock_model_settings = BedrockModelSettings(\n    bedrock_guardrail_config={\n        'guardrailIdentifier': 'v1',\n        'guardrailVersion': 'v1',\n        'trace': 'enabled'\n    },\n    bedrock_performance_configuration={\n        'latency': 'optimized'\n    }\n)\n\n\nmodel = BedrockConverseModel(model_name='us.amazon.nova-pro-v1:0')\n\nagent = Agent(model=model, model_settings=bedrock_model_settings)\n```\n\n----------------------------------------\n\nTITLE: Creating a Simple Evaluation Dataset in Python\nDESCRIPTION: Demonstrates how to create a basic Dataset with a single Case for evaluation purposes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/evals.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_evals import Case, Dataset\n\ncase1 = Case(\n    name='simple_case',\n    inputs='What is the capital of France?',\n    expected_output='Paris',\n    metadata={'difficulty': 'easy'},\n)\n\ndataset = Dataset(cases=[case1])\n```\n\n----------------------------------------\n\nTITLE: Direct Groq Model Initialization\nDESCRIPTION: Example of directly initializing a Groq model using GroqModel class and creating an agent instance.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.groq import GroqModel\n\nmodel = GroqModel('llama-3.3-70b-versatile')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: OpenAI Responses API Implementation\nDESCRIPTION: Implementation of OpenAI's Responses API with web search capabilities.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom openai.types.responses import WebSearchToolParam\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIResponsesModel, OpenAIResponsesModelSettings\n\nmodel_settings = OpenAIResponsesModelSettings(\n    openai_builtin_tools=[WebSearchToolParam(type='web_search_preview')],\n)\nmodel = OpenAIResponsesModel('gpt-4o')\nagent = Agent(model=model, model_settings=model_settings)\n\nresult = agent.run_sync('What is the weather in Tokyo?')\nprint(result.output)\n```\n\n----------------------------------------\n\nTITLE: Mermaid Diagram for Simple Graph Example\nDESCRIPTION: This is the mermaid representation of the graph defined above.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_5\n\nLANGUAGE: Mermaid\nCODE:\n```\n---title: fives_graph---\nstateDiagram-v2\n  [*] --> DivisibleBy5\n  DivisibleBy5 --> Increment\n  DivisibleBy5 --> [*]\n  Increment --> DivisibleBy5\n```\n\n----------------------------------------\n\nTITLE: Exporting Members from pydantic_graph.nodes Module in Python\nDESCRIPTION: This code block lists the exported members from the pydantic_graph.nodes module, including type definitions and classes. The members include state types, context handlers, node definitions, and edge connections for building graph structures.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_graph/nodes.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: pydantic_graph.nodes\n    options:\n        members:\n            - StateT\n            - GraphRunContext\n            - BaseNode\n            - End\n            - Edge\n            - DepsT\n            - RunEndT\n            - NodeRunEndT\n```\n\n----------------------------------------\n\nTITLE: Installing and Running the Weather Agent UI with Gradio (Bash)\nDESCRIPTION: Commands to install Gradio and run the weather agent UI. Requires Python 3.10+ and installs Gradio version 5.9.0 or higher.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/weather-agent.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install gradio>=5.9.0\npython/uv-run -m pydantic_ai_examples.weather_agent_gradio\n```\n\n----------------------------------------\n\nTITLE: Documenting Pydantic AI Models Module Structure\nDESCRIPTION: Module documentation structure showing the key components and classes exposed in the pydantic_ai.models module, including model definitions, request parameters, tool definitions, and response handling utilities.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/base.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.models`\n\n::: pydantic_ai.models\n    options:\n      members:\n        - KnownModelName\n        - ModelRequestParameters\n        - Model\n        - AbstractToolDefinition\n        - StreamedResponse\n        - ALLOW_MODEL_REQUESTS\n        - check_allow_model_requests\n        - override_allow_model_requests\n```\n\n----------------------------------------\n\nTITLE: Referencing Pydantic Graph Module in Documentation\nDESCRIPTION: This code snippet uses a specific documentation syntax to reference and include the contents of the pydantic_graph.graph module. It's likely used to generate API documentation for the module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_graph/graph.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_graph.graph\n```\n\n----------------------------------------\n\nTITLE: Processing Colors and Sizes with Multiple Tools\nDESCRIPTION: Demonstrates using Union types to register multiple tools for handling different types of lists (strings for colors and integers for sizes).\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/output.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Union\n\nfrom pydantic_ai import Agent\n\nagent: Agent[None, Union[list[str], list[int]]] = Agent(\n    'openai:gpt-4o-mini',\n    output_type=Union[list[str], list[int]],  # type: ignore\n    system_prompt='Extract either colors or sizes from the shapes provided.',\n)\n\nresult = agent.run_sync('red square, blue circle, green triangle')\nprint(result.output)\n#> ['red', 'blue', 'green']\n\nresult = agent.run_sync('square size 10, circle size 20, triangle size 30')\nprint(result.output)\n#> [10, 20, 30]\n```\n\n----------------------------------------\n\nTITLE: Basic Gemini Agent Initialization\nDESCRIPTION: Initializes a Gemini agent using the google-gla provider with a specific model.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('google-gla:gemini-2.0-flash')\n...\n```\n\n----------------------------------------\n\nTITLE: Markdown Module Reference for pydantic_evals.otel\nDESCRIPTION: Module reference documentation marker using markdown code block to identify the pydantic_evals.otel module path.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_evals/otel.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_evals.otel`\n\n::: pydantic_evals.otel\n```\n\n----------------------------------------\n\nTITLE: Documenting Pydantic AI Provider Modules\nDESCRIPTION: Index of provider modules showing the package structure for various AI service integrations in pydantic-ai.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/providers.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.providers`\n\n::: pydantic_ai.providers.Provider\n\n::: pydantic_ai.providers.google_vertex\n\n::: pydantic_ai.providers.openai\n\n::: pydantic_ai.providers.deepseek\n\n::: pydantic_ai.providers.bedrock\n\n::: pydantic_ai.providers.groq\n\n::: pydantic_ai.providers.azure\n\n::: pydantic_ai.providers.cohere\n\n::: pydantic_ai.providers.mistral\n```\n\n----------------------------------------\n\nTITLE: Running MCP SSE Server\nDESCRIPTION: Command to start the MCP SSE server using Deno with necessary permissions and configurations.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\ndeno run \\\n  -N -R=node_modules -W=node_modules --node-modules-dir=auto \\\n  jsr:@pydantic/mcp-run-python sse\n```\n\n----------------------------------------\n\nTITLE: Installing Mistral Dependencies with pip/uv\nDESCRIPTION: Command to install pydantic-ai-slim with Mistral dependencies using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[mistral]\"\n```\n\n----------------------------------------\n\nTITLE: Implementing Basic Evaluation with Pydantic Evals\nDESCRIPTION: Demonstrates how to create and run evaluations using Pydantic Evals, including defining test cases, custom evaluators, and running evaluations on a simple question-answering function.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/pydantic_evals/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_evals import Case, Dataset\nfrom pydantic_evals.evaluators import Evaluator, EvaluatorContext, IsInstance\n\n# Define a test case with inputs and expected output\ncase = Case(\n    name='capital_question',\n    inputs='What is the capital of France?',\n    expected_output='Paris',\n)\n\n# Define a custom evaluator\nclass MatchAnswer(Evaluator[str, str]):\n    def evaluate(self, ctx: EvaluatorContext[str, str]) -> float:\n        if ctx.output == ctx.expected_output:\n            return 1.0\n        elif isinstance(ctx.output, str) and ctx.expected_output.lower() in ctx.output.lower():\n            return 0.8\n        return 0.0\n\n# Create a dataset with the test case and evaluators\ndataset = Dataset(\n    cases=[case],\n    evaluators=[IsInstance(type_name='str'), MatchAnswer()],\n)\n\n# Define the function to evaluate\nasync def answer_question(question: str) -> str:\n    return 'Paris'\n\n# Run the evaluation\nreport = dataset.evaluate_sync(answer_question)\nreport.print(include_input=True, include_output=True)\n```\n\n----------------------------------------\n\nTITLE: Adding Logfire Instrumentation\nDESCRIPTION: Code snippet showing how to add Logfire instrumentation to visualize MCP interactions and debug the execution flow.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_pydantic_ai()\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client for VertexAI\nDESCRIPTION: Shows how to configure a custom HTTP client for VertexAI API requests.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_10\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_vertex import GoogleVertexProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = GeminiModel(\n    'gemini-2.0-flash',\n    provider=GoogleVertexProvider(region='asia-east1', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Defining Pydantic Graph Exception Classes in Python\nDESCRIPTION: This code defines the exception hierarchy for the pydantic-graph package. It includes a base exception `PydanticGraphError` and several specialized exceptions for handling different error conditions in graph operations.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_graph/exceptions.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass PydanticGraphError(Exception):\n    \"\"\"Base exception for pydantic-graph.\"\"\"\n\n\nclass CycleError(PydanticGraphError):\n    \"\"\"Exception raised when a cycle is detected in a graph.\"\"\"\n\n\nclass InvalidModelReferenceError(PydanticGraphError):\n    \"\"\"Exception raised when a model reference is invalid.\"\"\"\n\n\nclass NotFoundError(PydanticGraphError):\n    \"\"\"Exception raised when a model is not found.\"\"\"\n\n\nclass ValidationError(PydanticGraphError):\n    \"\"\"Exception raised when validation fails.\"\"\"\n\n\nclass RenderError(PydanticGraphError):\n    \"\"\"Exception raised when rendering fails.\"\"\"\n\n\nclass ExporterError(PydanticGraphError):\n    \"\"\"Exception raised when export fails.\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Module Import Reference Declaration in Markdown\nDESCRIPTION: Markdown documentation structure specifying the module components to be documented including Agent classes, run-related types, and instrumentation settings.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/agent.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.agent\n    options:\n        members:\n            - Agent\n            - AgentRun\n            - AgentRunResult\n            - EndStrategy\n            - RunOutputDataT\n            - capture_run_messages\n            - InstrumentationSettings\n```\n\n----------------------------------------\n\nTITLE: Installing Logfire Dependencies with pip\nDESCRIPTION: Command to install Pydantic-AI with Logfire support using pip or uv package manager\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai[logfire]\"\n```\n\n----------------------------------------\n\nTITLE: Weather Service Agent with Streaming - Python\nDESCRIPTION: Implements a weather service agent with streaming capability using async iteration. Includes weather forecast and historical weather data handling with detailed event streaming and output formatting.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/agents.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom dataclasses import dataclass\nfrom datetime import date\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.messages import (\n    FinalResultEvent,\n    FunctionToolCallEvent,\n    FunctionToolResultEvent,\n    PartDeltaEvent,\n    PartStartEvent,\n    TextPartDelta,\n    ToolCallPartDelta,\n)\nfrom pydantic_ai.tools import RunContext\n\n@dataclass\nclass WeatherService:\n    async def get_forecast(self, location: str, forecast_date: date) -> str:\n        return f'The forecast in {location} on {forecast_date} is 24C and sunny.'\n\n    async def get_historic_weather(self, location: str, forecast_date: date) -> str:\n        return f'The weather in {location} on {forecast_date} was 18C and partly cloudy.'\n\nweather_agent = Agent[WeatherService, str](\n    'openai:gpt-4o',\n    deps_type=WeatherService,\n    output_type=str,\n    system_prompt='Providing a weather forecast at the locations the user provides.',\n)\n\n@weather_agent.tool\nasync def weather_forecast(\n    ctx: RunContext[WeatherService],\n    location: str,\n    forecast_date: date,\n) -> str:\n    if forecast_date >= date.today():\n        return await ctx.deps.get_forecast(location, forecast_date)\n    else:\n        return await ctx.deps.get_historic_weather(location, forecast_date)\n\noutput_messages: list[str] = []\n\nasync def main():\n    user_prompt = 'What will the weather be like in Paris on Tuesday?'\n    async with weather_agent.iter(user_prompt, deps=WeatherService()) as run:\n        async for node in run:\n            # Node processing logic here\n            pass\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Importing Pydantic AI Gemini Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the pydantic_ai.models.gemini module. It's part of the documentation explaining how to use the custom Gemini API interface.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/gemini.md#2025-04-22_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n::: pydantic_ai.models.gemini\n```\n\n----------------------------------------\n\nTITLE: Direct Cohere Model Initialization\nDESCRIPTION: Python code showing direct initialization of a Cohere model using CohereModel class.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.cohere import CohereModel\n\nmodel = CohereModel('command')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Direct Bedrock Model Initialization\nDESCRIPTION: Example of explicitly creating a BedrockConverseModel instance\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.bedrock import BedrockConverseModel\n\nmodel = BedrockConverseModel('anthropic.claude-3-sonnet-20240229-v1:0')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Direct JSON Serialization of Messages\nDESCRIPTION: Demonstrates direct JSON serialization of messages using to_json function and validation using ModelMessagesTypeAdapter.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_core import to_json\n...\nas_json_objects = to_json(history_step_1)\nsame_history_as_step_1 = ModelMessagesTypeAdapter.validate_json(as_json_objects)\n```\n\n----------------------------------------\n\nTITLE: Importing Groq Model in Pydantic AI\nDESCRIPTION: This code snippet demonstrates how to import the Groq model module in Pydantic AI. It uses a special import syntax to include all contents of the groq module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/groq.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.models.groq\n```\n\n----------------------------------------\n\nTITLE: Setting Anthropic API Key Environment Variable\nDESCRIPTION: Command to set the Anthropic API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport ANTHROPIC_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Configuring Path for Pydantic AI Documentation Examples\nDESCRIPTION: Documentation note indicating that this directory is added to sys.path during test execution to support example code testing.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/tests/example_modules/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n# docs examples imports\n```\n\n----------------------------------------\n\nTITLE: Bedrock Model Documentation Link\nDESCRIPTION: Markdown code block showing a reference link to detailed Bedrock model configuration documentation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/bedrock.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.models.bedrock`\n\n## Setup\n\nFor details on how to set up authentication with this model, see [model configuration for Bedrock](../../models/bedrock.md).\n\n::: pydantic_ai.models.bedrock\n```\n\n----------------------------------------\n\nTITLE: Implementing MCP stdio Client\nDESCRIPTION: Python implementation of an MCP client using stdio transport to connect to an MCP server running as a subprocess. Shows server configuration and command execution.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.mcp import MCPServerStdio\n\nserver = MCPServerStdio(\n    'deno',\n    args=[\n        'run',\n        '-N',\n        '-R=node_modules',\n        '-W=node_modules',\n        '--node-modules-dir=auto',\n        'jsr:@pydantic/mcp-run-python',\n        'stdio',\n    ]\n)\nagent = Agent('openai:gpt-4o', mcp_servers=[server])\n\n\nasync def main():\n    async with agent.run_mcp_servers():\n        result = await agent.run('How many days between 2000-01-01 and 2025-03-18?')\n    print(result.output)\n    #> There are 9,208 days between January 1, 2000, and March 18, 2025.\n```\n\n----------------------------------------\n\nTITLE: Basic Agent Implementation with PydanticAI\nDESCRIPTION: A simple example showing how to create and use a basic PydanticAI agent with a static system prompt. The agent uses the Google Gemini model to answer a query about the origin of 'hello world' with a concise response.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\n# Define a very simple agent including the model to use, you can also set the model when running the agent.\nagent = Agent(\n    'google-gla:gemini-1.5-flash',\n    # Register a static system prompt using a keyword argument to the agent.\n    # For more complex dynamically-generated system prompts, see the example below.\n    system_prompt='Be concise, reply with one sentence.',\n)\n\n# Run the agent synchronously, conducting a conversation with the LLM.\n# Here the exchange should be very short: PydanticAI will send the system prompt and the user query to the LLM,\n# the model will return a text response. See below for a more complex run.\nresult = agent.run_sync('Where does \"hello world\" come from?')\nprint(result.output)\n\"\"\"\nThe first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n\"\"\"\n```\n\n----------------------------------------\n\nTITLE: Running PostgreSQL with pgvector using Docker\nDESCRIPTION: This bash command sets up a Docker container running PostgreSQL with pgvector extension. It mounts a local directory for data persistence and exposes the database on port 54320.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir postgres-data\ndocker run --rm \\\n  -e POSTGRES_PASSWORD=postgres \\\n  -p 54320:5432 \\\n  -v `pwd`/postgres-data:/var/lib/postgresql/data \\\n  pgvector/pgvector:pg17\n```\n\n----------------------------------------\n\nTITLE: Serializing Messages to JSON with Pydantic AI\nDESCRIPTION: Demonstrates how to serialize conversation messages to JSON format using TypeAdapter and continue conversations with stored history. Uses the ModelMessagesTypeAdapter for handling message serialization.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/message-history.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_core import to_jsonable_python\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.messages import ModelMessagesTypeAdapter  # (1)!\n\nagent = Agent('openai:gpt-4o', system_prompt='Be a helpful assistant.')\n\nresult1 = agent.run_sync('Tell me a joke.')\nhistory_step_1 = result1.all_messages()\nas_python_objects = to_jsonable_python(history_step_1)  # (2)!\nsame_history_as_step_1 = ModelMessagesTypeAdapter.validate_python(as_python_objects)\n\nresult2 = agent.run_sync(  # (3)!\n    'Tell me a different joke.', message_history=same_history_as_step_1\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Graph-based State Machine with Pydantic Graph\nDESCRIPTION: Demonstrates creation of a graph that finds the next number divisible by 5. Uses two node types: DivisibleBy5 checks if current number is divisible by 5, and Increment increments the number. Shows type-safe node definitions and graph execution.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/pydantic_graph/README.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\n\nfrom pydantic_graph import BaseNode, End, Graph, GraphRunContext\n\n\n@dataclass\nclass DivisibleBy5(BaseNode[None, None, int]):\n    foo: int\n\n    async def run(\n        self,\n        ctx: GraphRunContext,\n    ) -> Increment | End[int]:\n        if self.foo % 5 == 0:\n            return End(self.foo)\n        else:\n            return Increment(self.foo)\n\n\n@dataclass\nclass Increment(BaseNode):\n    foo: int\n\n    async def run(self, ctx: GraphRunContext) -> DivisibleBy5:\n        return DivisibleBy5(self.foo + 1)\n\n\nfives_graph = Graph(nodes=[DivisibleBy5, Increment])\nresult = fives_graph.run_sync(DivisibleBy5(4))\nprint(result.output)\n#> 5\n```\n\n----------------------------------------\n\nTITLE: Using Synchronous Dependencies in PydanticAI\nDESCRIPTION: Example demonstrating how to use synchronous dependencies in PydanticAI. This shows using a synchronous HTTP client and a regular function (not a coroutine) for the system prompt, which will be executed in a thread pool by PydanticAI.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport httpx\n\nfrom pydantic_ai import Agent, RunContext\n\n\n@dataclass\nclass MyDeps:\n    api_key: str\n    http_client: httpx.Client  # (1)!\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=MyDeps,\n)\n\n\n@agent.system_prompt\ndef get_system_prompt(ctx: RunContext[MyDeps]) -> str:  # (2)!\n    response = ctx.deps.http_client.get(\n        'https://example.com', headers={'Authorization': f'Bearer {ctx.deps.api_key}'}\n    )\n    response.raise_for_status()\n    return f'Prompt: {response.text}'\n\n\nasync def main():\n    deps = MyDeps('foobar', httpx.Client())\n    result = await agent.run(\n        'Tell me a joke.',\n        deps=deps,\n    )\n    print(result.output)\n    #> Did you hear about the toothpaste scandal? They called it Colgate.\n```\n\n----------------------------------------\n\nTITLE: Basic OpenAI Model Initialization\nDESCRIPTION: Simple initialization of an OpenAI model using the Agent class with model name reference.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('openai:gpt-4o')\n...\n```\n\n----------------------------------------\n\nTITLE: Regional Configuration for VertexAI\nDESCRIPTION: Demonstrates how to specify a regional endpoint for VertexAI requests.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_vertex import GoogleVertexProvider\n\nmodel = GeminiModel(\n    'gemini-2.0-flash', provider=GoogleVertexProvider(region='asia-east1')\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Custom Groq Provider Configuration\nDESCRIPTION: Example of initializing a Groq model with a custom provider and API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.groq import GroqModel\nfrom pydantic_ai.providers.groq import GroqProvider\n\nmodel = GroqModel(\n    'llama-3.3-70b-versatile', provider=GroqProvider(api_key='your-api-key')\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Accessing Dependencies in System Prompt Functions\nDESCRIPTION: Example showing how to access dependencies through the RunContext parameter in a system prompt function. The RunContext is typed with the dependency class, enabling type checking and providing access to the dependencies through the .deps attribute.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/dependencies.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom dataclasses import dataclass\n\nimport httpx\n\nfrom pydantic_ai import Agent, RunContext\n\n\n@dataclass\nclass MyDeps:\n    api_key: str\n    http_client: httpx.AsyncClient\n\n\nagent = Agent(\n    'openai:gpt-4o',\n    deps_type=MyDeps,\n)\n\n\n@agent.system_prompt  # (1)!\nasync def get_system_prompt(ctx: RunContext[MyDeps]) -> str:  # (2)!\n    response = await ctx.deps.http_client.get(  # (3)!\n        'https://example.com',\n        headers={'Authorization': f'Bearer {ctx.deps.api_key}'},  # (4)!\n    )\n    response.raise_for_status()\n    return f'Prompt: {response.text}'\n\n\nasync def main():\n    async with httpx.AsyncClient() as client:\n        deps = MyDeps('foobar', client)\n        result = await agent.run('Tell me a joke.', deps=deps)\n        print(result.output)\n        #> Did you hear about the toothpaste scandal? They called it Colgate.\n```\n\n----------------------------------------\n\nTITLE: Instrumenting HTTPX Requests\nDESCRIPTION: Basic setup for instrumenting HTTPX requests in a Pydantic-AI application\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\nlogfire.configure()\nlogfire.instrument_httpx(capture_all=True)\n```\n\n----------------------------------------\n\nTITLE: Querying the RAG Search Agent\nDESCRIPTION: This command demonstrates how to ask a question to the RAG search agent. It uses the rag module to search for information about configuring logfire with FastAPI.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.rag search \"How do I configure logfire to work with FastAPI?\"\n```\n\n----------------------------------------\n\nTITLE: Custom Provider Configuration for Anthropic Model\nDESCRIPTION: Example of initializing an AnthropicModel with a custom provider configuration including API key.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.providers.anthropic import AnthropicProvider\n\nmodel = AnthropicModel(\n    'claude-3-5-sonnet-latest', provider=AnthropicProvider(api_key='your-api-key')\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Handling Chat App Client-side Logic with TypeScript\nDESCRIPTION: TypeScript code for client-side rendering of messages in the chat application. This code is passed to the browser as plain text and transpiled in the browser for simplicity.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/chat-app.md#2025-04-22_snippet_3\n\nLANGUAGE: typescript\nCODE:\n```\n#! examples/pydantic_ai_examples/chat_app.ts\n```\n\n----------------------------------------\n\nTITLE: Integrating MCP Run Python with PydanticAI\nDESCRIPTION: Example demonstrating how to use the MCP Run Python server with PydanticAI, including server configuration, agent setup, and execution of Python code. Shows integration with logging using logfire.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/mcp-run-python/README.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.mcp import MCPServerStdio\n\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_mcp()\nlogfire.instrument_pydantic_ai()\n\nserver = MCPServerStdio('deno',\n    args=[\n        'run',\n        '-N',\n        '-R=node_modules',\n        '-W=node_modules',\n        '--node-modules-dir=auto',\n        'jsr:@pydantic/mcp-run-python',\n        'stdio',\n    ])\nagent = Agent('claude-3-5-haiku-latest', mcp_servers=[server])\n\n\nasync def main():\n    async with agent.run_mcp_servers():\n        result = await agent.run('How many days between 2000-01-01 and 2025-03-18?')\n    print(result.output)\n    #> There are 9,208 days between January 1, 2000, and March 18, 2025.w\n\nif __name__ == '__main__':\n    import asyncio\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Basic VertexAI Model Initialization\nDESCRIPTION: Initializes a Gemini model using the VertexAI provider with default credentials.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\n\nmodel = GeminiModel('gemini-2.0-flash', provider='google-vertex')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Instrumenting a Specific Model\nDESCRIPTION: Example of instrumenting a specific model instance with custom settings\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.instrumented import InstrumentationSettings, InstrumentedModel\n\nsettings = InstrumentationSettings()\nmodel = InstrumentedModel('gpt-4o', settings)\nagent = Agent(model)\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI CLI Package\nDESCRIPTION: Command to install PydanticAI with CLI support using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai[cli]\"\n```\n\n----------------------------------------\n\nTITLE: Inline Script Metadata Example\nDESCRIPTION: Demonstrates using inline script metadata for declaring dependencies in Python code executed through MCP Run Python.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/run-python.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom mcp import ClientSession\nfrom mcp.client.stdio import stdio_client\n\n# using `server_params` from the above example.\nfrom mcp_run_python import server_params\n\ncode = \"\"\"\\\n# /// script\n# dependencies = [\\\"pydantic\\\", \\\"email-validator\\\"]\n# ///\nimport pydantic\n\nclass Model(pydantic.BaseModel):\n    email: pydantic.EmailStr\n\nprint(Model(email='hello@pydantic.dev'))\n\"\"\"\n\n\nasync def main():\n    async with stdio_client(server_params) as (read, write):\n        async with ClientSession(read, write) as session:\n            await session.initialize()\n            result = await session.call_tool('run_python_code', {'python_code': code})\n            print(result.content[0].text)\n            \"\"\"\n            <status>success</status>\n            <dependencies>[\\\"pydantic\\\",\\\"email-validator\\\"]</dependencies>\n            <output>\n            email='hello@pydantic.dev'\n            </output>\n            \"\"\"\n```\n\n----------------------------------------\n\nTITLE: Message Flow Diagram for PydanticAI Dice Game\nDESCRIPTION: Mermaid sequence diagram showing the interaction flow between Agent and LLM components in the dice game implementation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/tools.md#2025-04-22_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\nsequenceDiagram\n    participant Agent\n    participant LLM\n\n    Note over Agent: Send prompts\n    Agent ->> LLM: System: \"You're a dice game...\"\nUser: \"My guess is 4\"\n    activate LLM\n    Note over LLM: LLM decides to use\na tool\n\n    LLM ->> Agent: Call tool\nroll_die()\n    deactivate LLM\n    activate Agent\n    Note over Agent: Rolls a six-sided die\n\n    Agent -->> LLM: ToolReturn\n\"4\"\n    deactivate Agent\n    activate LLM\n    Note over LLM: LLM decides to use\nanother tool\n\n    LLM ->> Agent: Call tool\nget_player_name()\n    deactivate LLM\n    activate Agent\n    Note over Agent: Retrieves player name\n    Agent -->> LLM: ToolReturn\n\"Anne\"\n    deactivate Agent\n    activate LLM\n    Note over LLM: LLM constructs final response\n\n    LLM ->> Agent: ModelResponse\n\"Congratulations Anne, ...\"\n    deactivate LLM\n    Note over Agent: Game session complete\n```\n\n----------------------------------------\n\nTITLE: Azure OpenAI Client Configuration\nDESCRIPTION: Setup for using Azure OpenAI API with custom client configuration.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncAzureOpenAI\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.openai import OpenAIModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n\nclient = AsyncAzureOpenAI(\n    azure_endpoint='...',\n    api_version='2024-07-01-preview',\n    api_key='your-api-key',\n)\n\nmodel = OpenAIModel(\n    'gpt-4o',\n    provider=OpenAIProvider(openai_client=client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI with MCP Support\nDESCRIPTION: Command to install pydantic-ai-slim with MCP optional dependencies using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/client.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[mcp]\"\n```\n\n----------------------------------------\n\nTITLE: Using TestModel for Unit Testing PydanticAI Agents\nDESCRIPTION: Example showing how to use TestModel to unit test an AI agent implementation. The code demonstrates setting up a test agent, overriding its model with TestModel, and verifying the agent's behavior and function tool usage.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/test.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\n\nmy_agent = Agent('openai:gpt-4o', system_prompt='...')\n\n\nasync def test_my_agent():\n    \"\"\"Unit test for my_agent, to be run by pytest.\"\"\"\n    m = TestModel()\n    with my_agent.override(model=m):\n        result = await my_agent.run('Testing my agent...')\n        assert result.output == 'success (no tool calls)'\n    assert m.last_model_request_parameters.function_tools == []\n```\n\n----------------------------------------\n\nTITLE: Running Pydantic Model Example\nDESCRIPTION: Specific command to run the pydantic_model example module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.pydantic_model\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI with Logfire Integration\nDESCRIPTION: Installation command for PydanticAI with Logfire integration for viewing and understanding agent runs.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/install.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai[logfire]\"\n```\n\n----------------------------------------\n\nTITLE: Running Stream Markdown Example via Command Line\nDESCRIPTION: Command to execute the markdown streaming example using Python or uv package manager\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-markdown.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.stream_markdown\n```\n\n----------------------------------------\n\nTITLE: Custom Provider Configuration for Cohere\nDESCRIPTION: Python code demonstrating how to initialize a Cohere model with a custom provider configuration.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.cohere import CohereModel\nfrom pydantic_ai.providers.cohere import CohereProvider\n\nmodel = CohereModel('command', provider=CohereProvider(api_key='your-api-key'))\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Setting Mermaid Diagram Direction (Python)\nDESCRIPTION: This code snippet demonstrates how to set the direction of a Mermaid state diagram using the `direction` parameter in `Graph.mermaid_code`. The example sets the direction to Left to Right ('LR'). This requires the `vending_machine` module and its associated graph `vending_machine_graph`.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_19\n\nLANGUAGE: python\nCODE:\n```\nfrom vending_machine import InsertCoin, vending_machine_graph\n\nvending_machine_graph.mermaid_code(start_node=InsertCoin, direction='LR')\n```\n\n----------------------------------------\n\nTITLE: Initializing Groq Model Using Agent\nDESCRIPTION: Example of initializing a Groq model using the Agent class with a model string identifier.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('groq:llama-3.3-70b-versatile')\n...\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI with DuckDuckGo Search Tool\nDESCRIPTION: Command to install pydantic-ai-slim with the DuckDuckGo optional group for using the DuckDuckGo search tool.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/common-tools.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[duckduckgo]\"\n```\n\n----------------------------------------\n\nTITLE: Installing VertexAI Dependencies\nDESCRIPTION: Command to install PydanticAI with VertexAI support.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[vertexai]\"\n```\n\n----------------------------------------\n\nTITLE: Using Custom BedrockProvider with Boto3 Client\nDESCRIPTION: Example of creating a BedrockProvider using a pre-configured boto3 client\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport boto3\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.bedrock import BedrockConverseModel\nfrom pydantic_ai.providers.bedrock import BedrockProvider\n\n# Using a pre-configured boto3 client\nbedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')\nmodel = BedrockConverseModel(\n    'anthropic.claude-3-sonnet-20240229-v1:0',\n    provider=BedrockProvider(bedrock_client=bedrock_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Installing PydanticAI and dependencies using make\nDESCRIPTION: Command to install PydanticAI, all its dependencies, and pre-commit hooks using the make command.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nmake install\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client Configuration for Groq\nDESCRIPTION: Example of setting up a Groq model with a custom HTTP client configuration including timeout settings.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.groq import GroqModel\nfrom pydantic_ai.providers.groq import GroqProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = GroqModel(\n    'llama-3.3-70b-versatile',\n    provider=GroqProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Building the RAG Search Database\nDESCRIPTION: This command builds the search database using the rag module. It requires the OPENAI_API_KEY environment variable to be set, as it will call the OpenAI embedding API multiple times.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/rag.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.rag build\n```\n\n----------------------------------------\n\nTITLE: Cloning and navigating to the PydanticAI repository\nDESCRIPTION: Commands to clone your fork of the PydanticAI repository and navigate into the project directory.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\ngit clone git@github.com:<your username>/pydantic-ai.git\ncd pydantic-ai\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client Configuration for Anthropic Provider\nDESCRIPTION: Example of setting up an AnthropicModel with a custom HTTP client configuration including timeout settings.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.anthropic import AnthropicModel\nfrom pydantic_ai.providers.anthropic import AnthropicProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = AnthropicModel(\n    'claude-3-5-sonnet-latest',\n    provider=AnthropicProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Loading External Changelog with JavaScript\nDESCRIPTION: A JavaScript snippet that fetches the external changelog HTML file and injects it into the current document. It targets the 'display-changelog' element and replaces its content with the fetched changelog if the request is successful.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/changelog.md#2025-04-22_snippet_0\n\nLANGUAGE: javascript\nCODE:\n```\nfetch('/changelog.html').then(r => {\n  if (r.ok) {\n    r.text().then(t => {\n      document.getElementById('display-changelog').innerHTML = t;\n    });\n  }\n});\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key\nDESCRIPTION: Command to set the OpenAI API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY='your-api-key-here'\n```\n\n----------------------------------------\n\nTITLE: Setting Mistral API Key Environment Variable\nDESCRIPTION: Command to set the Mistral API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/mistral.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport MISTRAL_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Configuring Event Mode for Instrumentation\nDESCRIPTION: Example showing how to configure the event mode for OpenTelemetry instrumentation\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.agent import InstrumentationSettings\n\ninstrumentation_settings = InstrumentationSettings(event_mode='logs')\n\nagent = Agent('openai:gpt-4o', instrument=instrumentation_settings)\n# or instrument all agents:\nAgent.instrument_all(instrumentation_settings)\n```\n\n----------------------------------------\n\nTITLE: Running the Flight Booking Example with Python\nDESCRIPTION: A bash command to run the flight booking example using Python. It assumes that dependencies are installed and environment variables are set as per the usage instructions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/flight-booking.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.flight_booking\n```\n\n----------------------------------------\n\nTITLE: Direct Gemini Model Initialization\nDESCRIPTION: Creates a Gemini model instance directly with explicit provider specification.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\n\nmodel = GeminiModel('gemini-2.0-flash', provider='google-gla')\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Custom HTTP Client Configuration for Cohere\nDESCRIPTION: Python code showing how to configure a Cohere model with a custom HTTP client including timeout settings.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom httpx import AsyncClient\n\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.cohere import CohereModel\nfrom pydantic_ai.providers.cohere import CohereProvider\n\ncustom_http_client = AsyncClient(timeout=30)\nmodel = CohereModel(\n    'command',\n    provider=CohereProvider(api_key='your-api-key', http_client=custom_http_client),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Referencing OpenAI Module in Pydantic-AI Documentation\nDESCRIPTION: This code snippet is a Markdown directive that includes the documentation for the pydantic_ai.models.openai module. It's used to embed the module's documentation within the current page.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/openai.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.models.openai\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini API Key Environment Variable\nDESCRIPTION: Sets up the environment variable for Gemini API key authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport GEMINI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Mermaid Diagram Generation\nDESCRIPTION: Generates a Mermaid diagram for the vending machine graph. It requires the `vending_machine_graph` object defined in the previous snippet and visualizes the graph's structure and transitions between nodes, using the `mermaid_code` method.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom vending_machine import InsertCoin, vending_machine_graph\n\nvending_machine_graph.mermaid_code(start_node=InsertCoin)\n```\n\n----------------------------------------\n\nTITLE: Setting Cohere API Key Environment Variable\nDESCRIPTION: Command to set the Cohere API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/cohere.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport CO_API_KEY='your-api-key'\n```\n\n----------------------------------------\n\nTITLE: Documenting format_as_xml Module Reference\nDESCRIPTION: Module reference documentation using triple-colon syntax to import and display the format_as_xml module documentation\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/format_as_xml.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.format_as_xml\n```\n\n----------------------------------------\n\nTITLE: Mermaid Diagram with Left-to-Right Direction\nDESCRIPTION: This is an example of a Mermaid diagram generated with the 'LR' (Left to Right) direction. It represents a vending machine's state diagram, showing the flow from inserting a coin to selecting a product and making a purchase.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_20\n\nLANGUAGE: mermaid\nCODE:\n```\n---\ntitle: vending_machine_graph\n---\nstateDiagram-v2\n  direction LR\n  [*] --> InsertCoin\n  InsertCoin --> CoinsInserted\n  CoinsInserted --> SelectProduct\n  CoinsInserted --> Purchase\n  SelectProduct --> Purchase\n  Purchase --> InsertCoin\n  Purchase --> SelectProduct\n  Purchase --> [*]\n```\n\n----------------------------------------\n\nTITLE: Installing pre-commit tool using uv\nDESCRIPTION: Command to install the pre-commit tool using the uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuv tool install pre-commit\n```\n\n----------------------------------------\n\nTITLE: Importing pydantic_evals.generation Module in MkDocs\nDESCRIPTION: This markdown snippet shows how to include auto-documentation for the pydantic_evals.generation module in MkDocs documentation. The ::: syntax is used to automatically import and render documentation for the specified module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_evals/generation.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_evals.generation\n```\n\n----------------------------------------\n\nTITLE: Service Account Authentication for VertexAI\nDESCRIPTION: Configures VertexAI authentication using a service account JSON file.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/gemini.md#2025-04-22_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.gemini import GeminiModel\nfrom pydantic_ai.providers.google_vertex import GoogleVertexProvider\n\nmodel = GeminiModel(\n    'gemini-2.0-flash',\n    provider=GoogleVertexProvider(service_account_file='path/to/service-account.json'),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for Cohere Integration\nDESCRIPTION: Documentation segment explaining the Cohere model module location and linking to authentication setup instructions.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/cohere.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.models.cohere`\n\n## Setup\n\nFor details on how to set up authentication with this model, see [model configuration for Cohere](../../models/cohere.md).\n\n::: pydantic_ai.models.cohere\n```\n\n----------------------------------------\n\nTITLE: Configuring Logfire in Python\nDESCRIPTION: Basic setup to initialize Logfire in a Python application\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/logfire.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport logfire\n\nlogfire.configure()\n```\n\n----------------------------------------\n\nTITLE: Listing available make commands\nDESCRIPTION: Command to display help information showing all available make commands for the project.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nmake help\n```\n\n----------------------------------------\n\nTITLE: Dependency Version Specification Example\nDESCRIPTION: Shows how to specify package versions using inline script metadata in Python code.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/mcp/run-python.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n# /// script\n# dependencies = [\\\"rich<13\\\"]\n# ///\n```\n\n----------------------------------------\n\nTITLE: Control Flow Diagram\nDESCRIPTION: Mermaid diagram showing the control flow between flight search and seat selection processes.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/multi-agent-applications.md#2025-04-22_snippet_6\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph TB\n  START --> ask_user_flight[\"ask user for flight\"]\n\n  subgraph find_flight\n    flight_search_agent --> ask_user_flight\n    ask_user_flight --> flight_search_agent\n  end\n\n  flight_search_agent --> ask_user_seat[\"ask user for seat\"]\n  flight_search_agent --> END\n\n  subgraph find_seat\n    seat_preference_agent --> ask_user_seat\n    ask_user_seat --> seat_preference_agent\n  end\n\n  seat_preference_agent --> END\n```\n\n----------------------------------------\n\nTITLE: Installing Anthropic Dependencies with Package Manager\nDESCRIPTION: Command to install Pydantic-AI with Anthropic support using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[anthropic]\"\n```\n\n----------------------------------------\n\nTITLE: Running the Question Graph Example with UV\nDESCRIPTION: Command to run the question graph example using uv-run.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/question-graph.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.question_graph\n```\n\n----------------------------------------\n\nTITLE: Installing Deno runtime\nDESCRIPTION: Command to install the Deno JavaScript runtime using their official shell script installer.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\ncurl -fsSL https://deno.land/install.sh | sh\n```\n\n----------------------------------------\n\nTITLE: Running PydanticAI Examples\nDESCRIPTION: Command to run specific example modules from the PydanticAI package.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.<example_module_name>\n```\n\n----------------------------------------\n\nTITLE: Installing Pydantic-AI with Groq Support\nDESCRIPTION: Command to install Pydantic-AI with Groq support using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/groq.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[groq]\"\n```\n\n----------------------------------------\n\nTITLE: Documenting the pydantic_ai.result Module with MkDocs\nDESCRIPTION: This code block defines documentation for the pydantic_ai.result module. It uses MkDocs syntax to import and display documentation for specific members of the module, including OutputDataT and StreamedRunResult.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/result.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_ai.result`\n\n::: pydantic_ai.result\n    options:\n        inherited_members: true\n        members:\n            - OutputDataT\n            - StreamedRunResult\n```\n\n----------------------------------------\n\nTITLE: Importing and Documenting pydantic_ai.tools Module in Markdown\nDESCRIPTION: This code snippet uses a documentation syntax to import and display the contents of the pydantic_ai.tools module. It's likely part of a larger documentation system that automatically generates API documentation from code.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/tools.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.tools\n```\n\n----------------------------------------\n\nTITLE: Using Custom BedrockProvider with Credentials\nDESCRIPTION: Example of creating a BedrockProvider with direct AWS credentials\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.bedrock import BedrockConverseModel\nfrom pydantic_ai.providers.bedrock import BedrockProvider\n\n# Using AWS credentials directly\nmodel = BedrockConverseModel(\n    'anthropic.claude-3-sonnet-20240229-v1:0',\n    provider=BedrockProvider(\n        region_name='us-east-1',\n        aws_access_key_id='your-access-key',\n        aws_secret_access_key='your-secret-key',\n    ),\n)\nagent = Agent(model)\n...\n```\n\n----------------------------------------\n\nTITLE: Installing Pydantic-AI OpenAI Integration\nDESCRIPTION: Command to install Pydantic-AI with OpenAI support using pip or uv package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/openai.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[openai]\"\n```\n\n----------------------------------------\n\nTITLE: Importing Pydantic Graph Persistence Module\nDESCRIPTION: This code snippet shows how to import the pydantic_graph.persistence module and its submodules (in-memory and file-based persistence) in documentation format.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_graph/persistence.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `pydantic_graph.persistence`\n\n::: pydantic_graph.persistence\n\n::: pydantic_graph.persistence.in_mem\n\n::: pydantic_graph.persistence.file\n```\n\n----------------------------------------\n\nTITLE: Documenting Pydantic AI Settings Module Structure\nDESCRIPTION: MkDocs documentation configuration for pydantic_ai.settings module, specifying options for inherited members and target classes ModelSettings and UsageLimits.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/settings.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_ai.settings\n    options:\n      inherited_members: true\n      members:\n        - ModelSettings\n        - UsageLimits\n```\n\n----------------------------------------\n\nTITLE: Python Module Path Reference\nDESCRIPTION: File path reference for the example implementation showing where the streaming markdown code is located\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/stream-markdown.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/stream_markdown.py\n```\n\n----------------------------------------\n\nTITLE: Importing pydantic_ai.usage Module in Python\nDESCRIPTION: This code snippet demonstrates how to import the usage module from the pydantic_ai package. It uses Python's import statement to make the module's contents available for use in the current script or module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/usage.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: pydantic_ai.usage\n```\n\n----------------------------------------\n\nTITLE: Setting Gemini API Environment Variable\nDESCRIPTION: Command to set up the Google Gemini API key as an environment variable for authentication.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/index.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport GEMINI_API_KEY=your-api-key\n```\n\n----------------------------------------\n\nTITLE: Python Question Graph Implementation Reference\nDESCRIPTION: Reference to the Python file containing the question graph implementation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/question-graph.md#2025-04-22_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/question_graph.py\n```\n\n----------------------------------------\n\nTITLE: Importing Pydantic Evals Reporting Module Reference\nDESCRIPTION: Markdown directive to include documentation for the pydantic_evals.reporting module.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/pydantic_evals/reporting.md#2025-04-22_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: pydantic_evals.reporting\n```\n\n----------------------------------------\n\nTITLE: Initializing Anthropic Model Using Agent String Reference\nDESCRIPTION: Example of creating an Agent instance using a string reference to an Anthropic model.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/anthropic.md#2025-04-22_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic_ai import Agent\n\nagent = Agent('anthropic:claude-3-5-sonnet-latest')\n...\n```\n\n----------------------------------------\n\nTITLE: Running with UV Package Manager\nDESCRIPTION: Command to run the PydanticAI CLI using the UV package manager.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/cli.md#2025-04-22_snippet_4\n\nLANGUAGE: bash\nCODE:\n```\nuvx --from pydantic-ai pai\n```\n\n----------------------------------------\n\nTITLE: Importing Mistral Model in Pydantic AI\nDESCRIPTION: This code snippet demonstrates how to import the Mistral model module in Pydantic AI. It uses a special documentation syntax to reference the module contents.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/api/models/mistral.md#2025-04-22_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: pydantic_ai.models.mistral\n```\n\n----------------------------------------\n\nTITLE: SQL Generation Example Code Reference\nDESCRIPTION: Reference to the main Python file that contains the SQL generation example code. The actual code is not included in the snippet, only the file path.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#2025-04-22_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n#! examples/pydantic_ai_examples/sql_gen.py\n```\n\n----------------------------------------\n\nTITLE: Running all code quality checks\nDESCRIPTION: Command to run code formatting, linting, static type checks, and tests with coverage report generation.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/contributing.md#2025-04-22_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nmake\n```\n\n----------------------------------------\n\nTITLE: Running the SQL Generation Example with Custom Prompt\nDESCRIPTION: Command to run the SQL generation example with a custom prompt provided as an argument.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/examples/sql-gen.md#2025-04-22_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npython/uv-run -m pydantic_ai_examples.sql_gen \"find me errors\"\n```\n\n----------------------------------------\n\nTITLE: Installing Pydantic-AI with Bedrock Support\nDESCRIPTION: Command to install pydantic-ai-slim with Bedrock integration support\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip/uv-add \"pydantic-ai-slim[bedrock]\"\n```\n\n----------------------------------------\n\nTITLE: Setting AWS Environment Variables\nDESCRIPTION: Configuration of AWS credentials and region using environment variables\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/models/bedrock.md#2025-04-22_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nexport AWS_ACCESS_KEY_ID='your-access-key'\nexport AWS_SECRET_ACCESS_KEY='your-secret-key'\nexport AWS_DEFAULT_REGION='us-east-1'  # or your preferred region\n```\n\n----------------------------------------\n\nTITLE: Mermaid Diagram\nDESCRIPTION: Represents the vending machine graph as a Mermaid diagram. It visualizes the flow between different states (nodes) such as InsertCoin, CoinsInserted, SelectProduct, and Purchase, demonstrating the possible transitions based on user input and state conditions. The diagram shows the start and end points of the graph.\nSOURCE: https://github.com/pydantic/pydantic-ai/blob/main/docs/graph.md#_snippet_9\n\nLANGUAGE: mermaid\nCODE:\n```\n---\ntitle: vending_machine_graph\n---\nstateDiagram-v2\n  [*] --> InsertCoin\n  InsertCoin --> CoinsInserted\n  CoinsInserted --> SelectProduct\n  CoinsInserted --> Purchase\n  SelectProduct --> Purchase\n  Purchase --> InsertCoin\n  Purchase --> SelectProduct\n  Purchase --> [*]\n```"
  }
]