[
  {
    "owner": "openai",
    "repo": "openai-agents-python",
    "content": "TITLE: Creating Project and Virtual Environment - Bash\nDESCRIPTION: Commands to create a new project directory and initialize a Python virtual environment.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmkdir my_project\ncd my_project\npython -m venv .venv\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Agents SDK with pip\nDESCRIPTION: Command to install the OpenAI Agents package using pip package manager.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install openai-agents\n```\n\n----------------------------------------\n\nTITLE: Configuring Basic Agent with Weather Tool in Python\nDESCRIPTION: Demonstrates basic agent configuration with a custom weather tool function. Shows how to set up an agent with instructions, model specification, and function tools.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, ModelSettings, function_tool\n\n@function_tool\ndef get_weather(city: str) -> str:\n    return f\"The weather in {city} is sunny\"\n\nagent = Agent(\n    name=\"Haiku agent\",\n    instructions=\"Always respond in haiku form\",\n    model=\"o3-mini\",\n    tools=[get_weather],\n)\n```\n\n----------------------------------------\n\nTITLE: Creating Multiple Specialized Agents - Python\nDESCRIPTION: Creating multiple agents with specific roles and handoff descriptions for different subjects.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent\n\nhistory_tutor_agent = Agent(\n    name=\"History Tutor\",\n    handoff_description=\"Specialist agent for historical questions\",\n    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n)\n\nmath_tutor_agent = Agent(\n    name=\"Math Tutor\",\n    handoff_description=\"Specialist agent for math questions\",\n    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Running a Basic OpenAI Agent\nDESCRIPTION: Example demonstrating how to create a simple AI agent that generates a haiku about recursion. Shows basic agent initialization and execution using the Runner class.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/index.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\n\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\nprint(result.final_output)\n\n# Code within the code,\n# Functions calling themselves,\n# Infinite loop's dance.\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Agents SDK with pip\nDESCRIPTION: Command to install the OpenAI Agents SDK via pip. Also includes an optional command for installing with voice support.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npip install openai-agents\n```\n\n----------------------------------------\n\nTITLE: Basic Hello World Example with OpenAI Agents SDK\nDESCRIPTION: A simple example demonstrating how to create an agent and run it to generate a haiku about recursion. The code initializes an agent with basic instructions and uses the Runner to execute a query.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ja/index.md#2025-04-23_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\n\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\nprint(result.final_output)\n\n# Code within the code,\n# Functions calling themselves,\n# Infinite loop's dance.\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAIVoiceModelProvider Class in Python\nDESCRIPTION: This class implements the VoiceModelProvider interface for OpenAI's voice models. It handles text-to-speech conversion, speech-to-text transcription, and provides metadata about available models.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass OpenAIVoiceModelProvider(VoiceModelProvider):\n    \"\"\"A provider for voice models by OpenAI (text-to-speech and speech-to-text).\"\"\"\n\n    def __init__(\n        self,\n        models: Optional[dict[str, OpenAIVoiceModel]] = None,\n        tts_models: Optional[dict[str, Model]] = None,\n        stt_models: Optional[dict[str, Model]] = None,\n        openai_client: Optional[OpenAI] = None,\n    ):\n        \"\"\"Initialize with models.\n\n        Args:\n            models: A dictionary of model_id to OpenAIVoiceModel. Deprecated, use tts_models and stt_models.\n            tts_models: A dictionary of model_id to text-to-speech Model.\n            stt_models: A dictionary of model_id to speech-to-text Model.\n            openai_client: An OpenAI client.\n        \"\"\"\n        super().__init__()\n\n        self._store_deprecated_models(models)\n\n        self.tts_models = {} if tts_models is None else tts_models\n        self.stt_models = {} if stt_models is None else stt_models\n\n        self.client: OpenAI = get_openai_client() if openai_client is None else openai_client\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent with Structured Output Using Pydantic in Python\nDESCRIPTION: Example of configuring an agent to produce structured outputs using Pydantic models. Shows how to define a custom output type for calendar events.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom agents import Agent\n\n\nclass CalendarEvent(BaseModel):\n    name: str\n    date: str\n    participants: list[str]\n\nagent = Agent(\n    name=\"Calendar extractor\",\n    instructions=\"Extract calendar events from text\",\n    output_type=CalendarEvent,\n)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Agent Handoffs for Task Delegation in Python\nDESCRIPTION: Demonstrates how to configure agent handoffs for task delegation. Shows creation of specialized agents and a triage agent that can delegate to them.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent\n\nbooking_agent = Agent(...)\nrefund_agent = Agent(...)\n\ntriage_agent = Agent(\n    name=\"Triage agent\",\n    instructions=(\n        \"Help the user with their questions.\"\n        \"If they ask about booking, handoff to the booking agent.\"\n        \"If they ask about refunds, handoff to the refund agent.\"\n    ),\n    handoffs=[booking_agent, refund_agent],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Hosted Tools with OpenAI Agents\nDESCRIPTION: Demonstrates how to use hosted tools like WebSearchTool and FileSearchTool with an OpenAI agent. Shows basic agent setup with multiple tools for searching web and vector stores.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tools.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, FileSearchTool, Runner, WebSearchTool\n\nagent = Agent(\n    name=\"Assistant\",\n    tools=[\n        WebSearchTool(),\n        FileSearchTool(\n            max_num_results=3,\n            vector_store_ids=[\"VECTOR_STORE_ID\"],\n        ),\n    ],\n)\n\nasync def main():\n    result = await Runner.run(agent, \"Which coffee shop should I go to, taking into account my preferences and the weather today in SF?\")\n    print(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Using Agents as Tools\nDESCRIPTION: Demonstrates how to use agents as tools for other agents, allowing for agent orchestration. Shows setup of specialized agents and their use as tools by an orchestrator agent.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tools.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\nimport asyncio\n\nspanish_agent = Agent(\n    name=\"Spanish agent\",\n    instructions=\"You translate the user's message to Spanish\",\n)\n\nfrench_agent = Agent(\n    name=\"French agent\",\n    instructions=\"You translate the user's message to French\",\n)\n\norchestrator_agent = Agent(\n    name=\"orchestrator_agent\",\n    instructions=(\n        \"You are a translation agent. You use the tools given to you to translate.\"\n        \"If asked for multiple translations, you call the relevant tools.\"\n    ),\n    tools=[\n        spanish_agent.as_tool(\n            tool_name=\"translate_to_spanish\",\n            tool_description=\"Translate the user's message to Spanish\",\n        ),\n        french_agent.as_tool(\n            tool_name=\"translate_to_french\",\n            tool_description=\"Translate the user's message to French\",\n        ),\n    ],\n)\n\nasync def main():\n    result = await Runner.run(orchestrator_agent, input=\"Say 'Hello, how are you?' in Spanish.\")\n    print(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Creating Function Tools with Type Annotations\nDESCRIPTION: Shows how to create function tools using Python type annotations and decorators. Includes examples of custom type definitions, docstring usage, and function tool configuration.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tools.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport json\n\nfrom typing_extensions import TypedDict, Any\n\nfrom agents import Agent, FunctionTool, RunContextWrapper, function_tool\n\n\nclass Location(TypedDict):\n    lat: float\n    long: float\n\n@function_tool\nasync def fetch_weather(location: Location) -> str:\n    \"\"\"Fetch the weather for a given location.\n\n    Args:\n        location: The location to fetch the weather for.\n    \"\"\"\n    return \"sunny\"\n\n\n@function_tool(name_override=\"fetch_data\")\ndef read_file(ctx: RunContextWrapper[Any], path: str, directory: str | None = None) -> str:\n    \"\"\"Read the contents of a file.\n\n    Args:\n        path: The path to the file to read.\n        directory: The directory to read the file from.\n    \"\"\"\n    return \"<file contents>\"\n\n\nagent = Agent(\n    name=\"Assistant\",\n    tools=[fetch_weather, read_file],\n)\n\nfor tool in agent.tools:\n    if isinstance(tool, FunctionTool):\n        print(tool.name)\n        print(tool.description)\n        print(json.dumps(tool.params_json_schema, indent=2))\n        print()\n```\n\n----------------------------------------\n\nTITLE: Markdown Documentation for OpenAI Agents Runner Results\nDESCRIPTION: Comprehensive markdown documentation explaining the return types and properties of Runner.run methods, including RunResult, RunResultStreaming, and RunResultBase classes along with their key properties and usage patterns.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/results.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Results\n\nWhen you call the `Runner.run` methods, you either get a:\n\n-   [`RunResult`][agents.result.RunResult] if you call `run` or `run_sync`\n-   [`RunResultStreaming`][agents.result.RunResultStreaming] if you call `run_streamed`\n\nBoth of these inherit from [`RunResultBase`][agents.result.RunResultBase], which is where most useful information is present.\n\n## Final output\n\nThe [`final_output`][agents.result.RunResultBase.final_output] property contains the final output of the last agent that ran. This is either:\n\n-   a `str`, if the last agent didn't have an `output_type` defined\n-   an object of type `last_agent.output_type`, if the agent had an output type defined.\n\n!!! note\n\n    `final_output` is of type `Any`. We can't statically type this, because of handoffs. If handoffs occur, that means any Agent might be the last agent, so we don't statically know the set of possible output types.\n\n## Inputs for the next turn\n\nYou can use [`result.to_input_list()`][agents.result.RunResultBase.to_input_list] to turn the result into an input list that concatenates the original input you provided, to the items generated during the agent run. This makes it convenient to take the outputs of one agent run and pass them into another run, or to run it in a loop and append new user inputs each time.\n\n## Last agent\n\nThe [`last_agent`][agents.result.RunResultBase.last_agent] property contains the last agent that ran. Depending on your application, this is often useful for the next time the user inputs something. For example, if you have a frontline triage agent that hands off to a language-specific agent, you can store the last agent, and re-use it the next time the user messages the agent.\n\n## New items\n\nThe [`new_items`][agents.result.RunResultBase.new_items] property contains the new items generated during the run. The items are [`RunItem`][agents.items.RunItem]s. A run item wraps the raw item generated by the LLM.\n\n-   [`MessageOutputItem`][agents.items.MessageOutputItem] indicates a message from the LLM. The raw item is the message generated.\n-   [`HandoffCallItem`][agents.items.HandoffCallItem] indicates that the LLM called the handoff tool. The raw item is the tool call item from the LLM.\n-   [`HandoffOutputItem`][agents.items.HandoffOutputItem] indicates that a handoff occurred. The raw item is the tool response to the handoff tool call. You can also access the source/target agents from the item.\n-   [`ToolCallItem`][agents.items.ToolCallItem] indicates that the LLM invoked a tool.\n-   [`ToolCallOutputItem`][agents.items.ToolCallOutputItem] indicates that a tool was called. The raw item is the tool response. You can also access the tool output from the item.\n-   [`ReasoningItem`][agents.items.ReasoningItem] indicates a reasoning item from the LLM. The raw item is the reasoning generated.\n\n## Other information\n\n### Guardrail results\n\nThe [`input_guardrail_results`][agents.result.RunResultBase.input_guardrail_results] and [`output_guardrail_results`][agents.result.RunResultBase.output_guardrail_results] properties contain the results of the guardrails, if any. Guardrail results can sometimes contain useful information you want to log or store, so we make these available to you.\n\n### Raw responses\n\nThe [`raw_responses`][agents.result.RunResultBase.raw_responses] property contains the [`ModelResponse`][agents.items.ModelResponse]s generated by the LLM.\n\n### Original input\n\nThe [`input`][agents.result.RunResultBase.input] property contains the original input you provided to the `run` method. In most cases you won't need this, but it's available in case you do.\n```\n\n----------------------------------------\n\nTITLE: Implementing Custom Function Tools\nDESCRIPTION: Example of creating custom function tools without using the function decorator. Shows how to define schema, arguments, and invoke handlers manually.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tools.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\nfrom agents import RunContextWrapper, FunctionTool\n\n\ndef do_some_work(data: str) -> str:\n    return \"done\"\n\n\nclass FunctionArgs(BaseModel):\n    username: str\n    age: int\n\n\nasync def run_function(ctx: RunContextWrapper[Any], args: str) -> str:\n    parsed = FunctionArgs.model_validate_json(args)\n    return do_some_work(data=f\"{parsed.username} is {parsed.age} years old\")\n\n\ntool = FunctionTool(\n    name=\"process_user\",\n    description=\"Processes extracted user data\",\n    params_json_schema=FunctionArgs.model_json_schema(),\n    on_invoke_tool=run_function,\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Local Context with RunContextWrapper in Python\nDESCRIPTION: This example demonstrates how to implement local context in openai-agents-python using a dataclass as the context object. It shows how to create a context object, pass it to tool functions via RunContextWrapper, and use it in a complete agent workflow.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/context.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom dataclasses import dataclass\n\nfrom agents import Agent, RunContextWrapper, Runner, function_tool\n\n@dataclass\nclass UserInfo:  # (1)!\n    name: str\n    uid: int\n\n@function_tool\nasync def fetch_user_age(wrapper: RunContextWrapper[UserInfo]) -> str:  # (2)!\n    return f\"User {wrapper.context.name} is 47 years old\"\n\nasync def main():\n    user_info = UserInfo(name=\"John\", uid=123)\n\n    agent = Agent[UserInfo](  # (3)!\n        name=\"Assistant\",\n        tools=[fetch_user_age],\n    )\n\n    result = await Runner.run(  # (4)!\n        starting_agent=agent,\n        input=\"What is the age of the user?\",\n        context=user_info,\n    )\n\n    print(result.final_output)  # (5)!\n    # The user John is 47 years old.\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Complete Agent Implementation - Python\nDESCRIPTION: Full implementation combining all components including agents, guardrails, and runner logic.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_9\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, InputGuardrail, GuardrailFunctionOutput, Runner\nfrom pydantic import BaseModel\nimport asyncio\n\nclass HomeworkOutput(BaseModel):\n    is_homework: bool\n    reasoning: str\n\nguardrail_agent = Agent(\n    name=\"Guardrail check\",\n    instructions=\"Check if the user is asking about homework.\",\n    output_type=HomeworkOutput,\n)\n\nmath_tutor_agent = Agent(\n    name=\"Math Tutor\",\n    handoff_description=\"Specialist agent for math questions\",\n    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n)\n\nhistory_tutor_agent = Agent(\n    name=\"History Tutor\",\n    handoff_description=\"Specialist agent for historical questions\",\n    instructions=\"You provide assistance with historical queries. Explain important events and context clearly.\",\n)\n\n\nasync def homework_guardrail(ctx, agent, input_data):\n    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n    final_output = result.final_output_as(HomeworkOutput)\n    return GuardrailFunctionOutput(\n        output_info=final_output,\n        tripwire_triggered=not final_output.is_homework,\n    )\n\ntriage_agent = Agent(\n    name=\"Triage Agent\",\n    instructions=\"You determine which agent to use based on the user's homework question\",\n    handoffs=[history_tutor_agent, math_tutor_agent],\n    input_guardrails=[\n        InputGuardrail(guardrail_function=homework_guardrail),\n    ],\n)\n\nasync def main():\n    result = await Runner.run(triage_agent, \"who was the first president of the united states?\")\n    print(result.final_output)\n\n    result = await Runner.run(triage_agent, \"what is life\")\n    print(result.final_output)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Implementing Context-Aware Agent with UserContext in Python\nDESCRIPTION: Shows how to create a context-aware agent using dependency injection. Demonstrates type hinting with a custom UserContext class containing user data and methods.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n@dataclass\nclass UserContext:\n    uid: str\n    is_pro_user: bool\n\n    async def fetch_purchases() -> list[Purchase]:\n        return ...\n\nagent = Agent[UserContext](\n    ...,\n)\n```\n\n----------------------------------------\n\nTITLE: Creating and Visualizing Agent Relationships\nDESCRIPTION: Example demonstrating how to create agents with tools and handoffs, and generate a visual representation using draw_graph. Shows the creation of a triage agent with language-specific sub-agents and a weather tool.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/visualization.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, function_tool\nfrom agents.extensions.visualization import draw_graph\n\n@function_tool\ndef get_weather(city: str) -> str:\n    return f\"The weather in {city} is sunny.\"\n\nspanish_agent = Agent(\n    name=\"Spanish agent\",\n    instructions=\"You only speak Spanish.\",\n)\n\nenglish_agent = Agent(\n    name=\"English agent\",\n    instructions=\"You only speak English\",\n)\n\ntriage_agent = Agent(\n    name=\"Triage agent\",\n    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n    handoffs=[spanish_agent, english_agent],\n    tools=[get_weather],\n)\n\ndraw_graph(triage_agent)\n```\n\n----------------------------------------\n\nTITLE: Implementing Input Guardrail for Detecting Math Homework\nDESCRIPTION: This example shows how to implement an input guardrail that checks if a user is asking the agent to solve math homework. It uses a separate guardrail agent that analyzes the input and triggers a tripwire if math homework is detected.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/guardrails.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom agents import (\n    Agent,\n    GuardrailFunctionOutput,\n    InputGuardrailTripwireTriggered,\n    RunContextWrapper,\n    Runner,\n    TResponseInputItem,\n    input_guardrail,\n)\n\nclass MathHomeworkOutput(BaseModel):\n    is_math_homework: bool\n    reasoning: str\n\nguardrail_agent = Agent( # (1)!\n    name=\"Guardrail check\",\n    instructions=\"Check if the user is asking you to do their math homework.\",\n    output_type=MathHomeworkOutput,\n)\n\n\n@input_guardrail\nasync def math_guardrail( # (2)!\n    ctx: RunContextWrapper[None], agent: Agent, input: str | list[TResponseInputItem]\n) -> GuardrailFunctionOutput:\n    result = await Runner.run(guardrail_agent, input, context=ctx.context)\n\n    return GuardrailFunctionOutput(\n        output_info=result.final_output, # (3)!\n        tripwire_triggered=result.final_output.is_math_homework,\n    )\n\n\nagent = Agent(  # (4)!\n    name=\"Customer support agent\",\n    instructions=\"You are a customer support agent. You help customers with their questions.\",\n    input_guardrails=[math_guardrail],\n)\n\nasync def main():\n    # This should trip the guardrail\n    try:\n        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n        print(\"Guardrail didn't trip - this is unexpected\")\n\n    except InputGuardrailTripwireTriggered:\n        print(\"Math homework guardrail tripped\")\n```\n\n----------------------------------------\n\nTITLE: Python Agent Orchestration Patterns Reference\nDESCRIPTION: Documentation of core agent orchestration patterns including structured outputs, agent chaining, evaluation loops, and parallel execution using asyncio. These patterns provide deterministic and predictable task execution.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/multi_agent.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n- Using [structured outputs] to generate well formed data that you can inspect with your code\n- Chaining multiple agents by transforming the output of one into the input of the next\n- Running the agent that performs the task in a `while` loop with an agent that evaluates\n- Running multiple agents in parallel, e.g. via Python primitives like `asyncio.gather`\n```\n\n----------------------------------------\n\nTITLE: Agent Handoffs Example in OpenAI Agents SDK\nDESCRIPTION: An example showing how to create multiple agents (English and Spanish) with a triage agent that hands off to the appropriate agent based on the language of the request.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\nimport asyncio\n\nspanish_agent = Agent(\n    name=\"Spanish agent\",\n    instructions=\"You only speak Spanish.\",\n)\n\nenglish_agent = Agent(\n    name=\"English agent\",\n    instructions=\"You only speak English\",\n)\n\ntriage_agent = Agent(\n    name=\"Triage agent\",\n    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n    handoffs=[spanish_agent, english_agent],\n)\n\n\nasync def main():\n    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n    print(result.final_output)\n    # ¡Hola! Estoy bien, gracias por preguntar. ¿Y tú, cómo estás?\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining the AgentOutput Class in Python\nDESCRIPTION: The AgentOutput class encapsulates the result of an agent execution, providing properties to access content, function calls, and tool calls. It supports both single and multiple function call scenarios, with methods to validate and process the response.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/agent_output.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom typing import Any, Dict, List, Optional, Sequence, Union, cast\n\nfrom openai.types.beta.threads import Run\nfrom openai.types.chat import ChatCompletion, ChatCompletionMessage\nfrom pydantic import BaseModel, Field, field_validator, model_validator\n\nfrom .modeling.function import FunctionCall\n\n\nclass AgentOutput(BaseModel):\n    \"\"\"Represents the result of an agent execution.\n\n    This class encapsulates the output of an agent execution and provides\n    helper properties to access various parts of the output.\n    \"\"\"\n\n    message: ChatCompletionMessage\n    \"\"\"The raw message from the agent.\"\"\"\n\n    run: Optional[Run] = None\n    \"\"\"The run object if available.\"\"\"\n\n    @property\n    def content(self) -> str:\n        \"\"\"Text content from the agent.\n\n        If the agent did not return any content, this returns an empty string.\n        \"\"\"\n        if self.message.content is None:\n            return \"\"\n        elif isinstance(self.message.content, str):\n            return self.message.content\n        elif isinstance(self.message.content, list):\n            all_text_content = []\n            for content_part in self.message.content:\n                if content_part.type == \"text\":\n                    all_text_content.append(content_part.text)\n            return \"\".join(all_text_content)\n        return \"\"\n\n    @property\n    def function_call(self) -> Optional[FunctionCall]:\n        \"\"\"Get the function call if the agent wants to make one.\n\n        Only supports a single function call. If the agent wants to make multiple\n        function calls, this returns the first one it wants to make.\n        Use function_calls to get all function calls.\n        \"\"\"\n        if self.message.function_call is not None:\n            return FunctionCall(\n                name=self.message.function_call.name,\n                arguments=self.message.function_call.arguments,\n            )\n        elif self.message.tool_calls is not None and len(self.message.tool_calls) == 1:\n            tool_call = self.message.tool_calls[0]\n            if tool_call.type == \"function\":\n                return FunctionCall(\n                    name=tool_call.function.name,\n                    arguments=tool_call.function.arguments,\n                )\n        return None\n\n    @property\n    def function_calls(self) -> List[FunctionCall]:\n        \"\"\"Get all function calls the agent wants to make.\"\"\"\n        function_calls: List[FunctionCall] = []\n\n        if self.message.function_call is not None:\n            function_calls.append(\n                FunctionCall(\n                    name=self.message.function_call.name,\n                    arguments=self.message.function_call.arguments,\n                )\n            )\n\n        if self.message.tool_calls is not None:\n            for tool_call in self.message.tool_calls:\n                if tool_call.type == \"function\":\n                    function_calls.append(\n                        FunctionCall(\n                            name=tool_call.function.name,\n                            arguments=tool_call.function.arguments,\n                        )\n                    )\n\n        return function_calls\n\n    @property\n    def tool_calls(self) -> Sequence[Dict[str, Any]]:\n        \"\"\"Get all tool calls the agent wants to make.\"\"\"\n        if self.message.tool_calls is None:\n            return []\n        return self.message.tool_calls\n```\n\n----------------------------------------\n\nTITLE: LiteLLM Agent Implementation with Weather Function\nDESCRIPTION: Complete example demonstrating LiteLLM integration with OpenAI Agents, including a weather function tool and command-line argument handling. The agent is configured to respond only in haikus and includes model/API key input handling.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/litellm.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom agents import Agent, Runner, function_tool, set_tracing_disabled\nfrom agents.extensions.models.litellm_model import LitellmModel\n\n@function_tool\ndef get_weather(city: str):\n    print(f\"[debug] getting weather for {city}\")\n    return f\"The weather in {city} is sunny.\"\n\n\nasync def main(model: str, api_key: str):\n    agent = Agent(\n        name=\"Assistant\",\n        instructions=\"You only respond in haikus.\",\n        model=LitellmModel(model=model, api_key=api_key),\n        tools=[get_weather],\n    )\n\n    result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n    print(result.final_output)\n\n\nif __name__ == \"__main__\":\n    # First try to get model/api key from args\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, required=False)\n    parser.add_argument(\"--api-key\", type=str, required=False)\n    args = parser.parse_args()\n\n    model = args.model\n    if not model:\n        model = input(\"Enter a model name for Litellm: \")\n\n    api_key = args.api_key\n    if not api_key:\n        api_key = input(\"Enter an API key for Litellm: \")\n\n    asyncio.run(main(model, api_key))\n```\n\n----------------------------------------\n\nTITLE: Basic Agent Handoff Implementation in Python\nDESCRIPTION: Demonstrates basic setup of agent handoffs using direct agent references and the handoff() function. Shows how to create multiple agents and establish handoff relationships between them.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/handoffs.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, handoff\n\nbilling_agent = Agent(name=\"Billing agent\")\nrefund_agent = Agent(name=\"Refund agent\")\n\n# (1)!\ntriage_agent = Agent(name=\"Triage agent\", handoffs=[billing_agent, handoff(refund_agent)])\n```\n\n----------------------------------------\n\nTITLE: Implementing Guardrails - Python\nDESCRIPTION: Example of implementing custom guardrails for input validation using Pydantic models.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_8\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import GuardrailFunctionOutput, Agent, Runner\nfrom pydantic import BaseModel\n\nclass HomeworkOutput(BaseModel):\n    is_homework: bool\n    reasoning: str\n\nguardrail_agent = Agent(\n    name=\"Guardrail check\",\n    instructions=\"Check if the user is asking about homework.\",\n    output_type=HomeworkOutput,\n)\n\nasync def homework_guardrail(ctx, agent, input_data):\n    result = await Runner.run(guardrail_agent, input_data, context=ctx.context)\n    final_output = result.final_output_as(HomeworkOutput)\n    return GuardrailFunctionOutput(\n        output_info=final_output,\n        tripwire_triggered=not final_output.is_homework,\n    )\n```\n\n----------------------------------------\n\nTITLE: Streaming Token-by-Token Response from OpenAI Agent\nDESCRIPTION: Example showing how to stream raw response events from an OpenAI agent, outputting text generation token-by-token. Uses ResponseTextDeltaEvent to capture and display incremental text updates.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/streaming.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nfrom openai.types.responses import ResponseTextDeltaEvent\nfrom agents import Agent, Runner\n\nasync def main():\n    agent = Agent(\n        name=\"Joker\",\n        instructions=\"You are a helpful assistant.\",\n    )\n\n    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n    async for event in result.stream_events():\n        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n            print(event.data.delta, end=\"\", flush=True)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Customizing Agent Handoff Configuration in Python\nDESCRIPTION: Shows how to create a customized handoff with overrides for tool names, descriptions, and callback functions. Includes example of handling handoff context.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/handoffs.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, handoff, RunContextWrapper\n\ndef on_handoff(ctx: RunContextWrapper[None]):\n    print(\"Handoff called\")\n\nagent = Agent(name=\"My agent\")\n\nhandoff_obj = handoff(\n    agent=agent,\n    on_handoff=on_handoff,\n    tool_name_override=\"custom_handoff_tool\",\n    tool_description_override=\"Custom description\",\n)\n```\n\n----------------------------------------\n\nTITLE: OpenAI Agents Python SDK Examples Structure\nDESCRIPTION: Directory structure and categorization of example implementations showcasing different capabilities and patterns of the OpenAI Agents Python SDK. Categories include agent patterns, basic implementations, tool examples, model providers, handoffs, MCP, customer service, research bot, and voice agent examples.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/examples.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Examples\n\nCheck out a variety of sample implementations of the SDK in the examples section of the [repo](https://github.com/openai/openai-agents-python/tree/main/examples). The examples are organized into several categories that demonstrate different patterns and capabilities.\n\n\n## Categories\n\n- **[agent_patterns](https://github.com/openai/openai-agents-python/tree/main/examples/agent_patterns):**\n  Examples in this category illustrate common agent design patterns, such as\n\n    - Deterministic workflows\n    - Agents as tools\n    - Parallel agent execution\n\n- **[basic](https://github.com/openai/openai-agents-python/tree/main/examples/basic):**\n  These examples showcase foundational capabilities of the SDK, such as\n\n    - Dynamic system prompts\n    - Streaming outputs\n    - Lifecycle events\n\n- **[tool examples](https://github.com/openai/openai-agents-python/tree/main/examples/tools):**\n  Learn how to implement OAI hosted tools such as web search and file search,\n   and integrate them into your agents.\n\n- **[model providers](https://github.com/openai/openai-agents-python/tree/main/examples/model_providers):**\n  Explore how to use non-OpenAI models with the SDK.\n\n- **[handoffs](https://github.com/openai/openai-agents-python/tree/main/examples/handoffs):**\n  See practical examples of agent handoffs.\n\n- **[mcp](https://github.com/openai/openai-agents-python/tree/main/examples/mcp):**\n  Learn how to build agents with MCP.\n\n- **[customer_service](https://github.com/openai/openai-agents-python/tree/main/examples/customer_service)** and **[research_bot](https://github.com/openai/openai-agents-python/tree/main/examples/research_bot):**\n  Two more built-out examples that illustrate real-world applications\n\n    - **customer_service**: Example customer service system for an airline.\n    - **research_bot**: Simple deep research clone.\n\n- **[voice](https://github.com/openai/openai-agents-python/tree/main/examples/voice):**\n  See examples of voice agents, using our TTS and STT models.\n```\n\n----------------------------------------\n\nTITLE: Defining Model Abstract Base Class for OpenAI Agents in Python\nDESCRIPTION: Implements the Model abstract base class which defines the interface that all model implementations must follow. It includes abstract methods for completions, chat completions, embeddings, and tool usage capabilities.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/models/interface.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Model(ABC):\n    \"\"\"Interface for different model implementations.\"\"\"\n\n    @abstractmethod\n    def completions(\n        self,\n        prompt: str,\n        **kwargs,\n    ) -> CompletionResult:\n        \"\"\"Call the model with a text prompt.\"\"\"\n        ...\n\n    @abstractmethod\n    def chat_completions(\n        self,\n        messages: list[dict],\n        **kwargs,\n    ) -> ChatCompletionResult:\n        \"\"\"Call the model with a chat prompt.\"\"\"\n        ...\n\n    @abstractmethod\n    def embeddings(\n        self,\n        text: str | list[str],\n        **kwargs,\n    ) -> EmbeddingResult:\n        \"\"\"Get an embedding of the given text.\"\"\"\n        ...\n\n    @property\n    @abstractmethod\n    def has_tool_use(self) -> bool:\n        \"\"\"Whether the model can use tools.\"\"\"\n        ...\n```\n\n----------------------------------------\n\nTITLE: Setting Up Recommended Prompts for Agent Handoffs in Python\nDESCRIPTION: Demonstrates how to incorporate recommended prompt prefixes for better LLM understanding of handoff functionality.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/handoffs.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent\nfrom agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\n\nbilling_agent = Agent(\n    name=\"Billing agent\",\n    instructions=f\"\"\"{RECOMMENDED_PROMPT_PREFIX}\n    <Fill in the rest of your prompt here>.\"\"\",\n)\n```\n\n----------------------------------------\n\nTITLE: ConfigurableHandoffFilter Implementation in Python\nDESCRIPTION: Implements a configurable handoff filter that allows handoffs based on a provided configuration dictionary. This filter enables fine-grained control over which agents can hand off to which other agents.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/handoff_filters.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nclass ConfigurableHandoffFilter(HandoffFilter):\n    \"\"\"\n    A filter that allows handoffs based on a provided configuration.\n\n    The configuration is a dictionary mapping from agent names to lists of agent names.\n    Each key-value pair in the dictionary indicates that the agent named by the key\n    can hand off to any of the agents named in the value list.\n    \"\"\"\n\n    def __init__(self, config: Dict[str, List[str]]):\n        \"\"\"\n        Args:\n            config: A dictionary mapping from agent names to lists of agent names\n                that they can hand off to.\n        \"\"\"\n        self.config = config\n\n    def can_handoff(self, from_agent_name: str, to_agent_name: str) -> bool:\n        \"\"\"\n        Returns True if the handoff is allowed based on the configuration.\n\n        Args:\n            from_agent_name: The name of the agent initiating the handoff.\n            to_agent_name: The name of the agent receiving the handoff.\n\n        Returns:\n            True if the handoff is allowed based on the configuration, False otherwise.\n        \"\"\"\n        if from_agent_name not in self.config:\n            return False\n        return to_agent_name in self.config[from_agent_name]\n```\n\n----------------------------------------\n\nTITLE: Configuring Custom OpenAI Client in Python\nDESCRIPTION: This code shows how to create and set a custom OpenAI client using the AsyncOpenAI class and set_default_openai_client() function, allowing for customization of the base URL and API key.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom openai import AsyncOpenAI\nfrom agents import set_default_openai_client\n\ncustom_client = AsyncOpenAI(base_url=\"...\", api_key=\"...\")\nset_default_openai_client(custom_client)\n```\n\n----------------------------------------\n\nTITLE: Configuring Agent with MCP Servers in Python\nDESCRIPTION: Demonstrates how to create an Agent instance with multiple MCP servers, allowing the Agent to access tools from different MCP sources.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/mcp.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nagent=Agent(\n    name=\"Assistant\",\n    instructions=\"Use the tools to achieve the task\",\n    mcp_servers=[mcp_server_1, mcp_server_2]\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Dynamic Instructions for Agents in Python\nDESCRIPTION: Shows how to implement dynamic instructions using a function that receives context and agent parameters. Enables context-aware instruction generation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef dynamic_instructions(\n    context: RunContextWrapper[UserContext], agent: Agent[UserContext]\n) -> str:\n    return f\"The user's name is {context.context.name}. Help them with their questions.\"\n\n\nagent = Agent[UserContext](\n    name=\"Triage agent\",\n    instructions=dynamic_instructions,\n)\n```\n\n----------------------------------------\n\nTITLE: Cloning and Modifying Agents in Python\nDESCRIPTION: Demonstrates how to clone an existing agent and modify its properties. Shows creation of variants with different personalities while maintaining core functionality.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/agents.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\npirate_agent = Agent(\n    name=\"Pirate\",\n    instructions=\"Write like a pirate\",\n    model=\"o3-mini\",\n)\n\nrobot_agent = pirate_agent.clone(\n    name=\"Robot\",\n    instructions=\"Write like a robot\",\n)\n```\n\n----------------------------------------\n\nTITLE: Managing Conversation Thread with Runner\nDESCRIPTION: Shows how to maintain a conversation thread across multiple turns using the Runner class and trace functionality for tracking conversation context.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/running_agents.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nasync def main():\n    agent = Agent(name=\"Assistant\", instructions=\"Reply very concisely.\")\n\n    with trace(workflow_name=\"Conversation\", group_id=thread_id):\n        # First turn\n        result = await Runner.run(agent, \"What city is the Golden Gate Bridge in?\")\n        print(result.final_output)\n        # San Francisco\n\n        # Second turn\n        new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"What state is it in?\"}]\n        result = await Runner.run(agent, new_input)\n        print(result.final_output)\n        # California\n```\n\n----------------------------------------\n\nTITLE: Implementing Higher Level Traces in OpenAI Agents SDK\nDESCRIPTION: Example demonstrating how to wrap multiple Runner.run() calls in a single trace using the trace() context manager. This code creates a joke generator agent that tells a joke and then rates it, with both operations being part of the same trace.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tracing.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner, trace\n\nasync def main():\n    agent = Agent(name=\"Joke generator\", instructions=\"Tell funny jokes.\")\n\n    with trace(\"Joke workflow\"): # (1)!\n        first_result = await Runner.run(agent, \"Tell me a joke\")\n        second_result = await Runner.run(agent, f\"Rate this joke: {first_result.final_output}\")\n        print(f\"Joke: {first_result.final_output}\")\n        print(f\"Rating: {second_result.final_output}\")\n```\n\n----------------------------------------\n\nTITLE: Custom Agent Tool Implementation\nDESCRIPTION: Shows how to create a custom tool implementation using Runner.run directly, allowing for more advanced configuration options than the basic as_tool method.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/tools.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n@function_tool\nasync def run_my_agent() -> str:\n  \"\"\"A tool that runs the agent with custom configs\".\n\n    agent = Agent(name=\"My agent\", instructions=\"...\")\n\n    result = await Runner.run(\n        agent,\n        input=\"...\",\n        max_turns=5,\n        run_config=...\n    )\n\n    return str(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Running Basic Agent with Runner\nDESCRIPTION: Demonstrates how to create and run a basic agent asynchronously using the Runner class to generate a haiku about recursion.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/running_agents.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\n\nasync def main():\n    agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\n    result = await Runner.run(agent, \"Write a haiku about recursion in programming.\")\n    print(result.final_output)\n    # Code within the code,\n    # Functions calling themselves,\n    # Infinite loop's dance.\n```\n\n----------------------------------------\n\nTITLE: Initializing Tracing with Configuration Options in Python\nDESCRIPTION: Sets up tracing for OpenAI agents with configurable options for different output formats and destinations. Supports console output, file output, and LangChain integration with customizable output formats (text, json) and filtering capabilities.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/setup.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef setup_tracing(\n    to_console: bool = True,\n    console_format: Literal[\"text\", \"json\"] = \"text\",\n    to_file: bool = False,\n    file_path: Optional[Path] = None,\n    file_format: Literal[\"text\", \"json\"] = \"text\",\n    langchain: bool = False,\n    filter_internal: bool = True,\n) -> None:\n    \"\"\"Set up the tracing system for Agents.\n\n    Args:\n        to_console: Whether to output traces to the console. Defaults to True.\n        console_format: Format for console output (\"text\" or \"json\"). Defaults to \"text\".\n        to_file: Whether to output traces to a file. Defaults to False.\n        file_path: Path to the file where traces should be written. Defaults to None.\n        file_format: Format for file output (\"text\" or \"json\"). Defaults to \"text\".\n        langchain: Whether to enable LangChain tracing. Defaults to False.\n        filter_internal: Whether to filter internal traces. Defaults to True.\n    \"\"\"\n    handlers = []\n\n    if to_console:\n        handler = logging.StreamHandler()\n\n        if console_format == \"text\":\n            formatter = TextFormatter(filter_internal=filter_internal)\n        else:  # json\n            formatter = JSONFormatter(filter_internal=filter_internal)\n\n        handler.setFormatter(formatter)\n        handlers.append(handler)\n\n    if to_file:\n        if file_path is None:\n            file_path = Path(\"agents_trace.log\")\n        handler = logging.FileHandler(file_path)\n\n        if file_format == \"text\":\n            formatter = TextFormatter(filter_internal=filter_internal)\n        else:  # json\n            formatter = JSONFormatter(filter_internal=filter_internal)\n\n        handler.setFormatter(formatter)\n        handlers.append(handler)\n\n    if langchain:\n        try:\n            from langchain.callbacks import OpenAICallbackHandler\n\n            handler = OpenAICallbackHandler()\n            handlers.append(handler)\n        except ImportError:\n            logger.warning(\n                \"LangChain tracing enabled but LangChain not installed. \"\n                \"Install with `pip install langchain`.\"\n            )\n\n    if not handlers:\n        return\n\n    handler = TraceHandler(handlers=handlers)\n    trace_logger.addHandler(handler)\n    trace_logger.setLevel(logging.INFO)\n```\n\n----------------------------------------\n\nTITLE: Using Non-OpenAI Models with LiteLLM in Python\nDESCRIPTION: Example of creating Agent instances using non-OpenAI models (Claude and Gemini) through the LiteLLM integration.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/index.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclaude_agent = Agent(model=\"litellm/anthropic/claude-3-5-sonnet-20240620\", ...)\ngemini_agent = Agent(model=\"litellm/gemini/gemini-2.5-flash-preview-04-17\", ...)\n```\n\n----------------------------------------\n\nTITLE: Setting Up OpenAI Agents with Weather Tool\nDESCRIPTION: Implementation of OpenAI agents including a weather tool function and two agents - a main assistant and a Spanish-speaking agent with handoff capabilities.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport random\n\nfrom agents import (\n    Agent,\n    function_tool,\n)\nfrom agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n\n\n@function_tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather for a given city.\"\"\"\n    print(f\"[debug] get_weather called with city: {city}\")\n    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n    return f\"The weather in {city} is {random.choice(choices)}.\"\n\n\nspanish_agent = Agent(\n    name=\"Spanish\",\n    handoff_description=\"A spanish speaking agent.\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n    ),\n    model=\"gpt-4o-mini\",\n)\n\nagent = Agent(\n    name=\"Assistant\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n    ),\n    model=\"gpt-4o-mini\",\n    handoffs=[spanish_agent],\n    tools=[get_weather],\n)\n```\n\n----------------------------------------\n\nTITLE: Implementing Output Guardrail for Detecting Math Content\nDESCRIPTION: This example demonstrates how to implement an output guardrail that checks if the agent's response contains mathematical content. It uses a separate guardrail agent to analyze the output and triggers a tripwire if math is detected in the response.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/guardrails.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\nfrom agents import (\n    Agent,\n    GuardrailFunctionOutput,\n    OutputGuardrailTripwireTriggered,\n    RunContextWrapper,\n    Runner,\n    output_guardrail,\n)\nclass MessageOutput(BaseModel): # (1)!\n    response: str\n\nclass MathOutput(BaseModel): # (2)!\n    reasoning: str\n    is_math: bool\n\nguardrail_agent = Agent(\n    name=\"Guardrail check\",\n    instructions=\"Check if the output includes any math.\",\n    output_type=MathOutput,\n)\n\n@output_guardrail\nasync def math_guardrail(  # (3)!\n    ctx: RunContextWrapper, agent: Agent, output: MessageOutput\n) -> GuardrailFunctionOutput:\n    result = await Runner.run(guardrail_agent, output.response, context=ctx.context)\n\n    return GuardrailFunctionOutput(\n        output_info=result.final_output,\n        tripwire_triggered=result.final_output.is_math,\n    )\n\nagent = Agent( # (4)!\n    name=\"Customer support agent\",\n    instructions=\"You are a customer support agent. You help customers with their questions.\",\n    output_guardrails=[math_guardrail],\n    output_type=MessageOutput,\n)\n\nasync def main():\n    # This should trip the guardrail\n    try:\n        await Runner.run(agent, \"Hello, can you help me solve for x: 2x + 3 = 11?\")\n        print(\"Guardrail didn't trip - this is unexpected\")\n\n    except OutputGuardrailTripwireTriggered:\n        print(\"Math output guardrail tripped\")\n```\n\n----------------------------------------\n\nTITLE: Hello World Example with OpenAI Agents SDK\nDESCRIPTION: A simple example demonstrating how to create and run an agent that generates a haiku about recursion in programming. Requires the OPENAI_API_KEY environment variable to be set.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner\n\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\nprint(result.final_output)\n\n# Code within the code,\n# Functions calling themselves,\n# Infinite loop's dance.\n```\n\n----------------------------------------\n\nTITLE: Defining Voice Input Class for OpenAI Agents in Python\nDESCRIPTION: This code snippet defines the Input class for handling voice input in OpenAI agents. It includes methods for recording audio, converting speech to text, and managing different input modes.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/input.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass Input:\n    \"\"\"Voice input for agents.\"\"\"\n\n    def __init__(self):\n        self.mode = 'voice'  # 'voice' or 'text'\n        self.recognizer = sr.Recognizer()\n        self.mic = sr.Microphone()\n\n    def record(self):\n        \"\"\"Record audio from microphone.\"\"\"\n        with self.mic as source:\n            self.recognizer.adjust_for_ambient_noise(source)\n            audio = self.recognizer.listen(source)\n        return audio\n\n    def speech_to_text(self, audio):\n        \"\"\"Convert speech to text.\"\"\"\n        try:\n            text = self.recognizer.recognize_google(audio)\n            return text\n        except sr.UnknownValueError:\n            print(\"Speech recognition could not understand audio\")\n        except sr.RequestError as e:\n            print(f\"Could not request results from speech recognition service; {e}\")\n\n    def get_input(self):\n        \"\"\"Get input based on mode.\"\"\"\n        if self.mode == 'voice':\n            audio = self.record()\n            return self.speech_to_text(audio)\n        elif self.mode == 'text':\n            return input(\"Enter text: \")\n\n    def set_mode(self, mode):\n        \"\"\"Set input mode.\"\"\"\n        self.mode = mode\n```\n\n----------------------------------------\n\nTITLE: Mixing Models in OpenAI Agents Workflow\nDESCRIPTION: Demonstrates how to use different models for each agent in a single workflow, including specifying model names and using Model implementations.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/index.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\nimport asyncio\n\nspanish_agent = Agent(\n    name=\"Spanish agent\",\n    instructions=\"You only speak Spanish.\",\n    model=\"o3-mini\", # (1)!\n)\n\nenglish_agent = Agent(\n    name=\"English agent\",\n    instructions=\"You only speak English\",\n    model=OpenAIChatCompletionsModel( # (2)!\n        model=\"gpt-4o\",\n        openai_client=AsyncOpenAI()\n    ),\n)\n\ntriage_agent = Agent(\n    name=\"Triage agent\",\n    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n    handoffs=[spanish_agent, english_agent],\n    model=\"gpt-3.5-turbo\",\n)\n\nasync def main():\n    result = await Runner.run(triage_agent, input=\"Hola, ¿cómo estás?\")\n    print(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Setting Up Voice Pipeline\nDESCRIPTION: Creation of a voice pipeline using SingleAgentVoiceWorkflow for processing audio inputs and outputs.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents.voice import SingleAgentVoiceWorkflow, VoicePipeline\npipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))\n```\n\n----------------------------------------\n\nTITLE: Implementing Typed Handoff Inputs with Pydantic in Python\nDESCRIPTION: Demonstrates how to implement structured data inputs for handoffs using Pydantic models. Shows handling of typed input data in handoff callbacks.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/handoffs.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom pydantic import BaseModel\n\nfrom agents import Agent, handoff, RunContextWrapper\n\nclass EscalationData(BaseModel):\n    reason: str\n\nasync def on_handoff(ctx: RunContextWrapper[None], input_data: EscalationData):\n    print(f\"Escalation agent called with reason: {input_data.reason}\")\n\nagent = Agent(name=\"Escalation agent\")\n\nhandoff_obj = handoff(\n    agent=agent,\n    on_handoff=on_handoff,\n    input_type=EscalationData,\n)\n```\n\n----------------------------------------\n\nTITLE: Configuring Model Settings for an Agent\nDESCRIPTION: Shows how to use ModelSettings to configure additional parameters like temperature for an agent's model.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/index.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, ModelSettings\n\nenglish_agent = Agent(\n    name=\"English agent\",\n    instructions=\"You only speak English\",\n    model=\"gpt-4o\",\n    model_settings=ModelSettings(temperature=0.1),\n)\n```\n\n----------------------------------------\n\nTITLE: Running Agent Orchestration - Python\nDESCRIPTION: Basic example of running an agent workflow using the Runner class.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_7\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Runner\n\nasync def main():\n    result = await Runner.run(triage_agent, \"What is the capital of France?\")\n    print(result.final_output)\n```\n\n----------------------------------------\n\nTITLE: Defining Agent Handoffs - Python\nDESCRIPTION: Creating a triage agent with handoff options to specialist agents.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ntriage_agent = Agent(\n    name=\"Triage Agent\",\n    instructions=\"You determine which agent to use based on the user's homework question\",\n    handoffs=[history_tutor_agent, math_tutor_agent]\n)\n```\n\n----------------------------------------\n\nTITLE: Complete Voice Agent Implementation\nDESCRIPTION: Full implementation combining all components including agent setup, voice pipeline configuration, and audio processing with async execution.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport random\n\nimport numpy as np\nimport sounddevice as sd\n\nfrom agents import (\n    Agent,\n    function_tool,\n    set_tracing_disabled,\n)\nfrom agents.voice import (\n    AudioInput,\n    SingleAgentVoiceWorkflow,\n    VoicePipeline,\n)\nfrom agents.extensions.handoff_prompt import prompt_with_handoff_instructions\n\n\n@function_tool\ndef get_weather(city: str) -> str:\n    \"\"\"Get the weather for a given city.\"\"\"\n    print(f\"[debug] get_weather called with city: {city}\")\n    choices = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]\n    return f\"The weather in {city} is {random.choice(choices)}.\"\n\n\nspanish_agent = Agent(\n    name=\"Spanish\",\n    handoff_description=\"A spanish speaking agent.\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. Speak in Spanish.\",\n    ),\n    model=\"gpt-4o-mini\",\n)\n\nagent = Agent(\n    name=\"Assistant\",\n    instructions=prompt_with_handoff_instructions(\n        \"You're speaking to a human, so be polite and concise. If the user speaks in Spanish, handoff to the spanish agent.\",\n    ),\n    model=\"gpt-4o-mini\",\n    handoffs=[spanish_agent],\n    tools=[get_weather],\n)\n\n\nasync def main():\n    pipeline = VoicePipeline(workflow=SingleAgentVoiceWorkflow(agent))\n    buffer = np.zeros(24000 * 3, dtype=np.int16)\n    audio_input = AudioInput(buffer=buffer)\n\n    result = await pipeline.run(audio_input)\n\n    # Create an audio player using `sounddevice`\n    player = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\n    player.start()\n\n    # Play the audio stream as it comes in\n    async for event in result.stream():\n        if event.type == \"voice_stream_event_audio\":\n            player.write(event.data)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Running the Voice Pipeline\nDESCRIPTION: Implementation of audio processing pipeline execution with sounddevice for audio playback.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport numpy as np\nimport sounddevice as sd\nfrom agents.voice import AudioInput\n\n# For simplicity, we'll just create 3 seconds of silence\n# In reality, you'd get microphone data\nbuffer = np.zeros(24000 * 3, dtype=np.int16)\naudio_input = AudioInput(buffer=buffer)\n\nresult = await pipeline.run(audio_input)\n\n# Create an audio player using `sounddevice`\nplayer = sd.OutputStream(samplerate=24000, channels=1, dtype=np.int16)\nplayer.start()\n\n# Play the audio stream as it comes in\nasync for event in result.stream():\n    if event.type == \"voice_stream_event_audio\":\n        player.write(event.data)\n```\n\n----------------------------------------\n\nTITLE: Configuring OpenAI Agents Python Settings\nDESCRIPTION: Core configuration functions for setting up OpenAI API credentials, tracing, and logging behavior in the OpenAI Agents Python library. Includes functions for setting default API keys, configuring clients, managing tracing exports, and controlling logging output.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\noptions:\n    members:\n        - set_default_openai_key\n        - set_default_openai_client\n        - set_default_openai_api\n        - set_tracing_export_api_key\n        - set_tracing_disabled\n        - set_trace_processors\n        - enable_verbose_stdout_logging\n```\n\n----------------------------------------\n\nTITLE: Defining Runner and RunConfig Classes in Python for OpenAI Agents\nDESCRIPTION: This code snippet defines the Runner class and RunConfig, which are core components for executing and configuring agent runs in the OpenAI Agents Python framework. The Runner class likely handles the execution of agents, while RunConfig probably contains configuration settings for these runs.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n# `Runner`\n\n::: agents.run\n\n    options:\n        members:\n            - Runner\n            - RunConfig\n```\n\n----------------------------------------\n\nTITLE: Configuring Input Filters for Agent Handoffs in Python\nDESCRIPTION: Shows how to implement input filtering for handoffs using pre-built filter functions to modify conversation history during handoffs.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/handoffs.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent, handoff\nfrom agents.extensions import handoff_filters\n\nagent = Agent(name=\"FAQ agent\")\n\nhandoff_obj = handoff(\n    agent=agent,\n    input_filter=handoff_filters.remove_all_tools, # (1)!\n)\n```\n\n----------------------------------------\n\nTITLE: Getting TTS Model Information Method in OpenAI Provider\nDESCRIPTION: Method that retrieves and returns information about text-to-speech models. It returns a standardized format with model ID, pricing, and capabilities.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\ndef get_tts_models(self) -> dict[str, Model]:\n    \"\"\"Get the TTS models.\n\n    Returns:\n        A dictionary of model_id to Model.\n    \"\"\"\n    if not self.tts_models:\n        result = {}\n        for model_id in list_tts_models():\n            result[model_id] = Model(\n                id=model_id,\n                pricing={\n                    \"input\": {\n                        \"unit\": \"character\",\n                        \"price\": 0.015 if model_id == \"tts-1\" else 0.030,\n                    },\n                },\n                capabilities={\"text-to-speech\": True},\n            )\n        return result\n\n    return self.tts_models\n```\n\n----------------------------------------\n\nTITLE: Defining ProcessorInterface ABC for Tracing in OpenAI Agents Python\nDESCRIPTION: This code defines an abstract base class for processors used in the tracing system of OpenAI Agents. It includes abstract methods for initialization, handling events, transforming messages, and finalizing traces that must be implemented by concrete processor classes.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/processor_interface.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom ..messages import Message\n\nT = TypeVar(\"T\")\n\n\nclass ProcessorInterface(ABC):\n    \"\"\"Base processor interface.\"\"\"\n\n    @abstractmethod\n    def init(self) -> None:\n        \"\"\"Initialize the processor.\"\"\"\n        pass\n\n    @abstractmethod\n    def handle_event(self, name: str, data: Dict[str, Any]) -> None:\n        \"\"\"Handle an event.\"\"\"\n        pass\n\n    @abstractmethod\n    def transform_message(self, message: Message) -> Message:\n        \"\"\"Transform a message.\"\"\"\n        pass\n\n    @abstractmethod\n    def finalize(self) -> T:\n        \"\"\"Finalize and return the processed trace.\"\"\"\n        pass\n```\n\n----------------------------------------\n\nTITLE: RunContext Class Definition in OpenAI Agents Python\nDESCRIPTION: The RunContext class maintains contextual information during an agent's execution. It tracks the current thread ID, run ID, and other metadata needed for agent operations.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run_context.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass RunContext:\n    \"\"\"Maintains context during an agent's execution.\n\n    This class is used to track the current thread ID, run ID, and other metadata\n    needed for agent operations. It's structured so that multiple threads can\n    maintain their own contexts.\n    \"\"\"\n\n    __contexts: ClassVar[Dict[int, Self]] = {}\n\n    def __init__(self, *, run_id: Optional[str] = None, thread_id: Optional[str] = None):\n        self.run_id = run_id\n        self.thread_id = thread_id\n```\n\n----------------------------------------\n\nTITLE: Getting STT Model Information Method in OpenAI Provider\nDESCRIPTION: Method that retrieves and returns information about speech-to-text models. It returns a standardized format with model ID, pricing, and capabilities.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\ndef get_stt_models(self) -> dict[str, Model]:\n    \"\"\"Get the STT models.\n\n    Returns:\n        A dictionary of model_id to Model.\n    \"\"\"\n    if not self.stt_models:\n        result = {}\n        for model_id in list_stt_models():\n            result[model_id] = Model(\n                id=model_id,\n                pricing={\n                    \"input\": {\n                        \"unit\": \"minute\",\n                        \"price\": 0.006 if model_id == \"whisper-1\" else 0.006,\n                    },\n                },\n                capabilities={\"speech-to-text\": True},\n            )\n        return result\n\n    return self.stt_models\n```\n\n----------------------------------------\n\nTITLE: Defining the Traces class for OpenAI Agents in Python\nDESCRIPTION: Class implementation for Traces, which manages trace data for OpenAI agents. The class maintains a mapping of trace IDs to TraceGroup objects and provides methods for trace creation and retrieval.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/traces.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass Traces:\n    \"\"\"A collection of trace groups.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize trace groups.\"\"\"\n        self._trace_groups: dict[str, TraceGroup] = {}\n```\n\n----------------------------------------\n\nTITLE: Current RunContext Retrieval Method in OpenAI Agents Python\nDESCRIPTION: A class method that retrieves the RunContext for the current thread. It looks up the context by thread ID and returns None if no context exists for the current thread.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run_context.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\n    @classmethod\n    def current(cls) -> Optional[Self]:\n        \"\"\"Get the RunContext for the current thread.\n\n        Returns:\n            Optional[RunContext]: The RunContext for the current thread, or None if no\n                context exists for the current thread.\n        \"\"\"\n        return cls.__contexts.get(threading.get_ident())\n```\n\n----------------------------------------\n\nTITLE: Listing Available Model Information Methods in OpenAI Provider\nDESCRIPTION: Methods that return information about available OpenAI voice models. These include utility functions for listing models, getting model details, and generating model identifiers.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\ndef get_models(self) -> dict[str, Model]:\n    \"\"\"Get all models.\n\n    Returns:\n        A dictionary of model_id to Model.\n    \"\"\"\n    return {**self.get_tts_models(), **self.get_stt_models()}\n\n\ndef list_tts_models() -> list[str]:\n    \"\"\"List all TTS models.\n\n    Returns:\n        A list of model_ids.\n    \"\"\"\n    return [\"tts-1\", \"tts-1-hd\"]\n\n\ndef list_stt_models() -> list[str]:\n    \"\"\"List all STT models.\n\n    Returns:\n        A list of model_ids.\n    \"\"\"\n    return [\"whisper-1\"]\n```\n\n----------------------------------------\n\nTITLE: Initializing MCP Filesystem Server in Python\nDESCRIPTION: Example showing how to initialize and use the official MCP filesystem server using MCPServerStdio class with specified parameters for command execution.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/mcp.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nasync with MCPServerStdio(\n    params={\n        \"command\": \"npx\",\n        \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", samples_dir],\n    }\n) as server:\n    tools = await server.list_tools()\n```\n\n----------------------------------------\n\nTITLE: Creating a new trace in the Traces collection with Python\nDESCRIPTION: Method for creating a new trace with a unique ID. It generates a trace ID, creates a corresponding TraceGroup, and returns the ID and the created trace.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/traces.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef create(self) -> tuple[str, Trace]:\n    \"\"\"Create a new trace.\n\n    Returns:\n        A tuple of trace_id and the root trace.\n    \"\"\"\n    trace_id = str(uuid4())\n    group = TraceGroup(id=trace_id, run_id=trace_id)\n    self._trace_groups[trace_id] = group\n    return trace_id, group.root\n```\n\n----------------------------------------\n\nTITLE: Voice Pipeline Flow Diagram\nDESCRIPTION: Mermaid diagram showing the flow of audio processing through the voice pipeline, including speech-to-text, code execution, and text-to-speech stages.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_1\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph LR\n    %% Input\n    A[\"🎤 Audio Input\"]\n\n    %% Voice Pipeline\n    subgraph Voice_Pipeline [Voice Pipeline]\n        direction TB\n        B[\"Transcribe (speech-to-text)\"]\n        C[\"Your Code\"]:::highlight\n        D[\"Text-to-speech\"]\n        B --> C --> D\n    end\n\n    %% Output\n    E[\"🎧 Audio Output\"]\n\n    %% Flow\n    A --> Voice_Pipeline\n    Voice_Pipeline --> E\n\n    %% Custom styling\n    classDef highlight fill:#ffcc66,stroke:#333,stroke-width:1px,font-weight:700;\n```\n\n----------------------------------------\n\nTITLE: Creating Basic Math Tutor Agent - Python\nDESCRIPTION: Example of creating a simple agent with name and instructions for math tutoring.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import Agent\n\nagent = Agent(\n    name=\"Math Tutor\",\n    instructions=\"You provide help with math problems. Explain your reasoning at each step and include examples\",\n)\n```\n\n----------------------------------------\n\nTITLE: Importing Span Classes from agents.tracing.spans\nDESCRIPTION: Reference to the spans module in the agents.tracing package, listing the key span-related classes: Span, NoOpSpan, and SpanImpl. These classes are likely used for tracing execution flow in the OpenAI agents framework.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/spans.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nagents.tracing.spans\n```\n\n----------------------------------------\n\nTITLE: Visualizing Voice Pipeline Flow with Mermaid\nDESCRIPTION: Diagram showing the flow of audio processing through the Voice Pipeline, from audio input through transcription, custom code execution, and text-to-speech conversion to audio output.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/pipeline.md#2025-04-21_snippet_0\n\nLANGUAGE: mermaid\nCODE:\n```\ngraph LR\n    %% Input\n    A[\"🎤 Audio Input\"]\n\n    %% Voice Pipeline\n    subgraph Voice_Pipeline [Voice Pipeline]\n        direction TB\n        B[\"Transcribe (speech-to-text)\"]\n        C[\"Your Code\"]:::highlight\n        D[\"Text-to-speech\"]\n        B --> C --> D\n    end\n\n    %% Output\n    E[\"🎧 Audio Output\"]\n\n    %% Flow\n    A --> Voice_Pipeline\n    Voice_Pipeline --> E\n\n    %% Custom styling\n    classDef highlight fill:#ffcc66,stroke:#333,stroke-width:1px,font-weight:700;\n```\n\n----------------------------------------\n\nTITLE: Converting Text to Speech with OpenAI Models\nDESCRIPTION: Method that converts text to speech using OpenAI's text-to-speech API. It validates inputs, creates the API request, and returns the audio content in the specified format.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef text_to_speech(\n    self,\n    text: str,\n    model: str,\n    voice: str,\n    speed: float = 1.0,\n    response_format: Union[str, None] = None,\n) -> bytes:\n    \"\"\"Convert text to speech using OpenAI TTS API.\n\n    Args:\n        text: The text to convert to speech.\n        model: The TTS model to use.\n        voice: The voice to use.\n        speed: The speed of the voice.\n        response_format: The format of the response. One of \"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\".\n\n    Returns:\n        The audio as bytes.\n\n    Raises:\n        ValueError: If the text is not provided.\n        ValueError: If the model is not found.\n    \"\"\"\n    if not text:\n        raise ValueError(\"text must be provided\")\n\n    if model not in self.tts_models and model not in list_tts_models():\n        raise ValueError(f\"Model {model} not found\")\n\n    args = {\n        \"model\": model,\n        \"voice\": voice,\n        \"input\": text,\n    }\n\n    if speed != 1.0:\n        args[\"speed\"] = speed\n\n    if response_format is not None:\n        args[\"response_format\"] = response_format\n\n    response = self.client.audio.speech.create(**args)\n    content = BytesIO()\n    for chunk in response.iter_bytes():\n        content.write(chunk)\n\n    return content.getvalue()\n```\n\n----------------------------------------\n\nTITLE: Defining Handoff Prompt Constants and Functions in Python\nDESCRIPTION: This snippet defines a constant for the recommended prompt prefix and a function to generate a prompt with handoff instructions. The function combines a custom prompt with standardized handoff instructions.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/handoff_prompt.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nRECOMMENDED_PROMPT_PREFIX = \"\"\"You are a helpful AI assistant. Your role is to assist users with their questions and tasks to the best of your ability. If you don't know the answer to something, it's okay to say so. If you need more information to answer a question, please ask for clarification.\n\nPlease respond to the following request or question:\n\n\"\"\"\n\ndef prompt_with_handoff_instructions(prompt: str) -> str:\n    handoff_instructions = \"\"\"\n    \nIf at any point you are unable to complete the task or answer the question, please respond with the following:\n\n[UNABLE TO COMPLETE TASK: Brief explanation of why]\n\nThis will signal that the conversation needs to be handed off to a human operator for further assistance.\n\"\"\"\n    return prompt + handoff_instructions\n```\n\n----------------------------------------\n\nTITLE: Setting Default OpenAI API Key in Python\nDESCRIPTION: This snippet demonstrates how to set the default OpenAI API key using the set_default_openai_key() function when unable to set the OPENAI_API_KEY environment variable.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import set_default_openai_key\n\nset_default_openai_key(\"sk-...\")\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAI Agents Base Exception\nDESCRIPTION: Base exception class for all OpenAI Agents-related errors. All other exceptions in the package inherit from this class.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/exceptions.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: agents.exceptions\n```\n\n----------------------------------------\n\nTITLE: HandoffFilter Abstract Base Class Definition in Python\nDESCRIPTION: Defines the HandoffFilter abstract base class which provides the interface for all handoff filter implementations. Handoff filters determine whether an agent can hand off to another agent based on specific conditions.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/handoff_filters.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nclass HandoffFilter(abc.ABC):\n    \"\"\"\n    A filter that determines whether a handoff is allowed.\n    \"\"\"\n\n    @abc.abstractmethod\n    def can_handoff(self, from_agent_name: str, to_agent_name: str) -> bool:\n        \"\"\"\n        Returns True if the handoff is allowed, False otherwise.\n\n        Args:\n            from_agent_name: The name of the agent initiating the handoff.\n            to_agent_name: The name of the agent receiving the handoff.\n\n        Returns:\n            True if the handoff is allowed, False otherwise.\n        \"\"\"\n        pass\n```\n\n----------------------------------------\n\nTITLE: Setting up Python Environment for OpenAI Agents SDK\nDESCRIPTION: Commands to create a Python virtual environment and activate it, which is a prerequisite for installing the OpenAI Agents SDK.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m venv env\nsource env/bin/activate\n```\n\n----------------------------------------\n\nTITLE: Managing Tracer Initialization in OpenAI Agents\nDESCRIPTION: Function that retrieves an existing tracer from the global registry or creates a new one if it doesn't exist. This ensures consistent tracing throughout the application.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/util.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef get_or_init_tracer() -> Optional[\"Tracer\"]:\n    \"\"\"Get the tracer, or initialize a new one if it doesn't exist.\"\"\"\n    from agents.tracing.tracer import get_tracer\n\n    tracer = get_tracer()\n    if tracer is None and (TRACE_LOG_FILE_ENV_VAR in os.environ or TRACE_COLLECT_ENV_VAR in os.environ):\n        from agents.tracing.tracer import init_tracer\n\n        init_tracer()\n        tracer = get_tracer()\n\n    return tracer\n```\n\n----------------------------------------\n\nTITLE: NoHandoffFilter Implementation in Python\nDESCRIPTION: Implements a handoff filter that never allows handoffs between any agents. This can be used to completely disable handoff functionality in an agent system.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/handoff_filters.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nclass NoHandoffFilter(HandoffFilter):\n    \"\"\"\n    A filter that never allows handoffs.\n    \"\"\"\n\n    def can_handoff(self, from_agent_name: str, to_agent_name: str) -> bool:\n        \"\"\"\n        Always returns False, preventing any handoffs.\n\n        Args:\n            from_agent_name: The name of the agent initiating the handoff.\n            to_agent_name: The name of the agent receiving the handoff.\n\n        Returns:\n            False, indicating that handoffs are never allowed.\n        \"\"\"\n        return False\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Agents SDK - Bash\nDESCRIPTION: Command to install the OpenAI Agents package using pip.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\npip install openai-agents # or `uv add openai-agents`, etc\n```\n\n----------------------------------------\n\nTITLE: Handling Voice Pipeline Events in Python\nDESCRIPTION: Example code demonstrating how to process different types of events from a Voice Pipeline stream, including audio events, lifecycle events, and error handling.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/pipeline.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nresult = await pipeline.run(input)\n\nasync for event in result.stream():\n    if event.type == \"voice_stream_event_audio\":\n        # play audio\n    elif event.type == \"voice_stream_event_lifecycle\":\n        # lifecycle\n    elif event.type == \"voice_stream_event_error\"\n        # error\n    ...\n```\n\n----------------------------------------\n\nTITLE: AllowAllHandoffFilter Implementation in Python\nDESCRIPTION: Implements a handoff filter that allows all handoffs between any agents. This provides the most permissive handoff configuration, enabling agents to freely hand off to any other agent.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/handoff_filters.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nclass AllowAllHandoffFilter(HandoffFilter):\n    \"\"\"\n    A filter that allows all handoffs.\n    \"\"\"\n\n    def can_handoff(self, from_agent_name: str, to_agent_name: str) -> bool:\n        \"\"\"\n        Always returns True, allowing any handoff.\n\n        Args:\n            from_agent_name: The name of the agent initiating the handoff.\n            to_agent_name: The name of the agent receiving the handoff.\n\n        Returns:\n            True, indicating that all handoffs are allowed.\n        \"\"\"\n        return True\n```\n\n----------------------------------------\n\nTITLE: Installing Voice Dependencies for OpenAI Agents\nDESCRIPTION: Command to install the optional voice-related dependencies for the OpenAI Agents SDK.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/quickstart.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install 'openai-agents[voice]'\n```\n\n----------------------------------------\n\nTITLE: Streaming High-Level Agent Events and Updates\nDESCRIPTION: Implementation showing how to handle higher-level streaming events including tool calls, tool outputs, and message outputs. Includes a custom random joke number generator tool and demonstrates agent state updates monitoring.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/streaming.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\nimport random\nfrom agents import Agent, ItemHelpers, Runner, function_tool\n\n@function_tool\ndef how_many_jokes() -> int:\n    return random.randint(1, 10)\n\n\nasync def main():\n    agent = Agent(\n        name=\"Joker\",\n        instructions=\"First call the `how_many_jokes` tool, then tell that many jokes.\",\n        tools=[how_many_jokes],\n    )\n\n    result = Runner.run_streamed(\n        agent,\n        input=\"Hello\",\n    )\n    print(\"=== Run starting ===\")\n\n    async for event in result.stream_events():\n        # We'll ignore the raw responses event deltas\n        if event.type == \"raw_response_event\":\n            continue\n        # When the agent updates, print that\n        elif event.type == \"agent_updated_stream_event\":\n            print(f\"Agent updated: {event.new_agent.name}\")\n            continue\n        # When items are generated, print them\n        elif event.type == \"run_item_stream_event\":\n            if event.item.type == \"tool_call_item\":\n                print(\"-- Tool was called\")\n            elif event.item.type == \"tool_call_output_item\":\n                print(f\"-- Tool output: {event.item.output}\")\n            elif event.item.type == \"message_output_item\":\n                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n            else:\n                pass  # Ignore other event types\n\n    print(\"=== Run complete ===\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Defining OpenAI API Response Models in Python\nDESCRIPTION: This code snippet defines various classes for handling OpenAI API responses. It includes data models for representing text responses, message objects, and response content formats using BaseModel from pydantic for data validation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/models/openai_responses.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\nfrom enum import Enum\nfrom typing import Dict, List, Optional, Union, Any\n\nfrom pydantic import BaseModel, Field, field_validator\n\n\nclass FinishReason(str, Enum):\n    \"\"\"An enumeration of potential finish reasons for a text completion or chat completion.\"\"\"\n\n    STOP = \"stop\"\n    LENGTH = \"length\"\n    CONTENT_FILTER = \"content_filter\"\n    TOOL_CALLS = \"tool_calls\"\n    FUNCTION_CALL = \"function_call\"\n\n\nclass ToolType(str, Enum):\n    \"\"\"An enumeration of potential tool types for a chat completion.\"\"\"\n\n    FUNCTION = \"function\"\n\n\nclass MessageRole(str, Enum):\n    \"\"\"An enumeration of potential message roles for a chat completion.\"\"\"\n\n    SYSTEM = \"system\"\n    USER = \"user\"\n    ASSISTANT = \"assistant\"\n    TOOL = \"tool\"\n    FUNCTION = \"function\"\n\n\nclass TextCompletionChoice(BaseModel):\n    \"\"\"A choice returned by the Completions API.\"\"\"\n\n    text: str\n    index: int\n    logprobs: Optional[Dict[str, Any]] = None\n    finish_reason: Optional[str] = None\n\n\nclass ChatCompletionFunctionCallParam(BaseModel):\n    \"\"\"A function call parameter for a chat completion.\"\"\"\n\n    name: str\n    arguments: str\n\n\nclass ChatCompletionMessageToolCall(BaseModel):\n    \"\"\"A tool call for a chat completion.\"\"\"\n\n    id: str\n    type: ToolType\n    function: ChatCompletionFunctionCallParam\n\n\nclass ChatCompletionMessage(BaseModel):\n    \"\"\"A message for a chat completion.\"\"\"\n\n    role: MessageRole\n    content: Optional[str] = None\n    tool_calls: Optional[List[ChatCompletionMessageToolCall]] = None\n    # A legacy type for function calls, which are now implemented as tool calls.\n    function_call: Optional[ChatCompletionFunctionCallParam] = None\n\n\nclass FusedChatCompletionMessage(BaseModel):\n    \"\"\"A fused chat completion message.\n\n    This class is used for the delta messaging of a streaming API response and is not intended to\n    be directly used by users. Its name is inspired by the implementation choices in the JS\n    SDK.\n    \"\"\"\n\n    role: Optional[MessageRole] = None\n    content: Optional[str] = None\n    tool_calls: Optional[List[ChatCompletionMessageToolCall]] = None\n    # A legacy type for function calls, which are now implemented as tool calls.\n    function_call: Optional[ChatCompletionFunctionCallParam] = None\n\n\nclass ChatCompletionChoice(BaseModel):\n    \"\"\"A choice returned by the ChatCompletions API.\"\"\"\n\n    message: ChatCompletionMessage\n    index: int\n    finish_reason: Optional[FinishReason] = None\n    logprobs: Optional[Dict[str, Any]] = None\n\n\nclass ChatCompletionChunkChoice(BaseModel):\n    \"\"\"A chunk choice returned by the ChatCompletions streaming API.\"\"\"\n\n    delta: FusedChatCompletionMessage\n    index: int\n    finish_reason: Optional[FinishReason] = None\n    logprobs: Optional[Dict[str, Any]] = None\n\n\nclass Usage(BaseModel):\n    \"\"\"Usage information for a completion.\"\"\"\n\n    prompt_tokens: int\n    completion_tokens: int\n    total_tokens: int\n\n\nclass TextCompletion(BaseModel):\n    \"\"\"A response from the Completions API.\"\"\"\n\n    id: str\n    object: str\n    created: int\n    model: str\n    choices: List[TextCompletionChoice]\n    usage: Usage\n\n\nclass ChatCompletion(BaseModel):\n    \"\"\"A response from the ChatCompletions API.\"\"\"\n\n    id: str\n    object: str\n    created: int\n    model: str\n    choices: List[ChatCompletionChoice]\n    usage: Usage\n    system_fingerprint: Optional[str] = None\n\n\nclass ChatCompletionChunk(BaseModel):\n    \"\"\"A response chunk from the streaming ChatCompletions API.\"\"\"\n\n    id: str\n    object: str\n    created: int\n    model: str\n    choices: List[ChatCompletionChunkChoice]\n    usage: Optional[Usage] = None\n    system_fingerprint: Optional[str] = None\n\n\nclass RunnerChoice(BaseModel):\n    \"\"\"A choice returned by the Runner API.\"\"\"\n\n    outputs: Dict[str, Any]\n    input_tokens: Optional[int] = None\n    output_tokens: Optional[int] = None\n    attempts: Optional[List[Any]] = None\n\n\nclass RunnerOutput(BaseModel):\n    \"\"\"A response from the Runner API.\"\"\"\n\n    choices: List[RunnerChoice]\n    model: str\n    input_tokens: Optional[int] = None\n    output_tokens: Optional[int] = None\n    total_tokens: Optional[int] = None\n\n\nclass AssistantTools(BaseModel):\n    \"\"\"Assistant Tools is a JSON array of tool objects. Either 'code_interpreter' or 'function' type.\"\"\"\n\n\nclass CodeInterpreterTool(AssistantTools):\n    \"\"\"A type of Assistant Tool that lets the Assistant execute code, typically to analyze\n    uploaded data or to solve a problem.\"\"\"\n\n    type: str = Field(\"code_interpreter\", const=True)\n\n\nclass FunctionTool(AssistantTools):\n    \"\"\"A type of Assistant Tool that enables the Assistant to call external API or app.\"\"\"\n\n    type: str = Field(\"function\", const=True)\n    function: Dict[str, Any]\n\n\nclass AssistantResponse(BaseModel):\n    \"\"\"A response from the Assistant API that represents an assistant resource.\"\"\"\n\n    id: str\n    object: str\n    created_at: Optional[int] = None\n    name: Optional[str] = None\n    description: Optional[str] = None\n    model: Optional[str] = None\n    instructions: Optional[str] = None\n    tools: Optional[List[Union[CodeInterpreterTool, FunctionTool]]] = []\n    tool_resources: Optional[Dict[str, Any]] = None\n    temperature: Optional[float] = None\n    top_p: Optional[float] = None\n    response_format: Optional[Dict[str, str]] = None\n    metadata: Optional[Dict[str, str]] = None\n\n    @field_validator(\"tools\", mode=\"before\")\n    @classmethod\n    def validate_tools(cls, v: Optional[List[Dict[str, Any]]]) -> List[Union[CodeInterpreterTool, FunctionTool]]:\n        \"\"\"Validate the tools field.\"\"\"\n        if v is None:\n            return []\n\n        result = []\n        for tool in v:\n            if tool is None:\n                continue\n\n            tool_type = tool.get(\"type\")\n            if tool_type == \"code_interpreter\":\n                result.append(CodeInterpreterTool())\n            elif tool_type == \"function\":\n                result.append(FunctionTool(function=tool[\"function\"]))\n\n        return result\n```\n\n----------------------------------------\n\nTITLE: Customizing Python Logging for OpenAI Agents\nDESCRIPTION: This snippet shows how to customize Python logging for the OpenAI Agents SDK, including setting log levels and adding handlers.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_6\n\nLANGUAGE: python\nCODE:\n```\nimport logging\n\nlogger = logging.getLogger(\"openai.agents\") # or openai.agents.tracing for the Tracing logger\n\n# To make all logs show up\nlogger.setLevel(logging.DEBUG)\n# To make info and above show up\nlogger.setLevel(logging.INFO)\n# To make warning and above show up\nlogger.setLevel(logging.WARNING)\n# etc\n\n# You can customize this as needed, but this will output to `stderr` by default\nlogger.addHandler(logging.StreamHandler())\n```\n\n----------------------------------------\n\nTITLE: Installing LiteLLM Integration for OpenAI Agents\nDESCRIPTION: Command to install the LiteLLM dependency group for OpenAI Agents, enabling support for non-OpenAI models.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/index.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"openai-agents[litellm]\"\n```\n\n----------------------------------------\n\nTITLE: Storing Deprecated Models Method in OpenAI Voice Provider\nDESCRIPTION: Method that handles the deprecated models parameter by converting them to the new format. It separates models into text-to-speech and speech-to-text categories.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef _store_deprecated_models(self, models: Optional[dict[str, OpenAIVoiceModel]] = None):\n    \"\"\"Store deprecated models.\n\n    Args:\n        models: A dictionary of model_id to OpenAIVoiceModel.\n    \"\"\"\n    if models is None:\n        return\n\n    self.tts_models = {}\n    self.stt_models = {}\n\n    for model_id, model in models.items():\n        if model.capabilities.get(\"text-to-speech\"):\n            self.tts_models[model_id] = model\n        if model.capabilities.get(\"speech-to-text\"):\n            self.stt_models[model_id] = model\n```\n\n----------------------------------------\n\nTITLE: Converting Speech to Text with OpenAI Models\nDESCRIPTION: Method that transcribes audio files to text using OpenAI's speech-to-text API. It supports different audio formats and additional parameters for transcription customization.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_provider.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef speech_to_text(\n    self,\n    audio: bytes,\n    model: str,\n    file_format: str = \"mp3\",\n    prompt: Union[str, None] = None,\n    language: Union[str, None] = None,\n    temperature: Union[float, None] = None,\n) -> str:\n    \"\"\"Convert speech to text using OpenAI STT API.\n\n    Args:\n        audio: The audio to convert to text.\n        model: The STT model to use.\n        file_format: The format of the audio.\n        prompt: Optional text to guide the model's style or continue a previous audio segment.\n        language: The language of the audio.\n        temperature: The sampling temperature, between 0 and 1.\n\n    Returns:\n        The transcribed text.\n\n    Raises:\n        ValueError: If the audio is not provided.\n        ValueError: If the model is not found.\n    \"\"\"\n    if not audio:\n        raise ValueError(\"audio must be provided\")\n\n    if model not in self.stt_models and model not in list_stt_models():\n        raise ValueError(f\"Model {model} not found\")\n\n    audio_file = BytesIO(audio)\n    audio_file.name = f\"audio.{file_format}\"\n\n    args = {\n        \"model\": model,\n        \"file\": audio_file,\n    }\n\n    if prompt is not None:\n        args[\"prompt\"] = prompt\n\n    if language is not None:\n        args[\"language\"] = language\n\n    if temperature is not None:\n        args[\"temperature\"] = temperature\n\n    transcript = self.client.audio.transcriptions.create(**args)\n    return transcript.text\n```\n\n----------------------------------------\n\nTITLE: Installing Visualization Dependencies\nDESCRIPTION: Instructions for installing the optional visualization dependency group for OpenAI Agents.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/visualization.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"openai-agents[viz]\"\n```\n\n----------------------------------------\n\nTITLE: Voice Pipeline Tracing Configuration Fields Reference\nDESCRIPTION: Reference documentation listing the key configuration fields available in VoicePipelineConfig for controlling tracing behavior in voice pipelines. Includes fields for enabling/disabling tracing, controlling sensitive data inclusion, and trace organization.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/voice/tracing.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n-   [`tracing_disabled`][agents.voice.pipeline_config.VoicePipelineConfig.tracing_disabled]: controls whether tracing is disabled. By default, tracing is enabled.\n-   [`trace_include_sensitive_data`][agents.voice.pipeline_config.VoicePipelineConfig.trace_include_sensitive_data]: controls whether traces include potentially sensitive data, like audio transcripts. This is specifically for the voice pipeline, and not for anything that goes on inside your Workflow.\n-   [`trace_include_sensitive_audio_data`][agents.voice.pipeline_config.VoicePipelineConfig.trace_include_sensitive_audio_data]: controls whether traces include audio data.\n-   [`workflow_name`][agents.voice.pipeline_config.VoicePipelineConfig.workflow_name]: The name of the trace workflow.\n-   [`group_id`][agents.voice.pipeline_config.VoicePipelineConfig.group_id]: The `group_id` of the trace, which lets you link multiple traces.\n-   [`trace_metadata`][agents.voice.pipeline_config.VoicePipelineConfig.tracing_disabled]: Additional metadata to include with the trace.\n```\n\n----------------------------------------\n\nTITLE: Defining Event Classes for OpenAI Voice Agents in Python\nDESCRIPTION: This snippet defines several event classes used in the OpenAI Voice Agents system. These classes represent different types of events that can occur during voice interactions, such as speech recognition results, transcription updates, and audio playback events.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/events.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass Event:\n    \"\"\"Base class for all events.\"\"\"\n    pass\n\nclass SpeechRecognitionResult(Event):\n    \"\"\"Event for speech recognition results.\"\"\"\n    def __init__(self, text: str, is_final: bool):\n        self.text = text\n        self.is_final = is_final\n\nclass TranscriptionEvent(Event):\n    \"\"\"Event for transcription updates.\"\"\"\n    def __init__(self, text: str):\n        self.text = text\n\nclass AudioPlaybackStarted(Event):\n    \"\"\"Event for when audio playback starts.\"\"\"\n    pass\n\nclass AudioPlaybackFinished(Event):\n    \"\"\"Event for when audio playback finishes.\"\"\"\n    pass\n\nclass ConversationTurnStarted(Event):\n    \"\"\"Event for when a conversation turn starts.\"\"\"\n    pass\n\nclass ConversationTurnFinished(Event):\n    \"\"\"Event for when a conversation turn finishes.\"\"\"\n    pass\n```\n\n----------------------------------------\n\nTITLE: Setting Tracing Export API Key in Python\nDESCRIPTION: This code demonstrates how to set a specific API key for tracing exports using the set_tracing_export_api_key() function.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import set_tracing_export_api_key\n\nset_tracing_export_api_key(\"sk-...\")\n```\n\n----------------------------------------\n\nTITLE: Defining Voice Model Class in Python\nDESCRIPTION: This code defines a Model class for voice-related functionality. It includes a constructor that takes a model name as a parameter and sets it as an instance attribute.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/model.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\nclass Model:\n    def __init__(self, name: str):\n        self.name = name\n```\n\n----------------------------------------\n\nTITLE: Generating UUID for Tracing in Python\nDESCRIPTION: Function that generates a random UUID string using Python's uuid module. This is used for unique identification within the tracing system.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/util.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\ndef gen_uuid() -> str:\n    \"\"\"Generate a random UUID string.\"\"\"\n    return str(uuid.uuid4())\n```\n\n----------------------------------------\n\nTITLE: Disabling Tracing in Python\nDESCRIPTION: This snippet shows how to disable tracing entirely using the set_tracing_disabled() function.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import set_tracing_disabled\n\nset_tracing_disabled(True)\n```\n\n----------------------------------------\n\nTITLE: Checking Tracer Enabled Status in OpenAI Agents\nDESCRIPTION: Function that determines if tracing is enabled by checking if a valid tracer exists. Used to conditionally execute tracing-related code throughout the application.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/util.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndef is_tracer_enabled() -> bool:\n    \"\"\"Check if tracing is enabled.\"\"\"\n    return get_or_init_tracer() is not None\n```\n\n----------------------------------------\n\nTITLE: Saving Graph to File\nDESCRIPTION: Example showing how to save the generated agent graph to a file instead of displaying it.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/visualization.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\ndraw_graph(triage_agent, filename=\"agent_graph\")\n```\n\n----------------------------------------\n\nTITLE: Enabling Verbose Stdout Logging in Python\nDESCRIPTION: This code demonstrates how to enable verbose logging to stdout using the enable_verbose_stdout_logging() function.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_5\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import enable_verbose_stdout_logging\n\nenable_verbose_stdout_logging()\n```\n\n----------------------------------------\n\nTITLE: Retrieving a trace by ID in Python\nDESCRIPTION: Method to get a trace group by its ID. It returns the TraceGroup object if it exists, otherwise raises an exception.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/traces.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndef get(self, trace_id: str) -> TraceGroup:\n    \"\"\"Get a trace group by id.\n\n    Args:\n        trace_id: The ID of the trace group to retrieve.\n\n    Returns:\n        The TraceGroup object with the specified ID.\n\n    Raises:\n        KeyError: If a TraceGroup with the specified ID does not exist.\n    \"\"\"\n    if trace_id not in self._trace_groups:\n        raise KeyError(f\"Trace group with ID {trace_id} does not exist\")\n    return self._trace_groups[trace_id]\n```\n\n----------------------------------------\n\nTITLE: Setting Default OpenAI API in Python\nDESCRIPTION: This snippet illustrates how to change the default OpenAI API from Responses to Chat Completions using the set_default_openai_api() function.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\nfrom agents import set_default_openai_api\n\nset_default_openai_api(\"chat_completions\")\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Command to set the required OPENAI_API_KEY environment variable for authentication with OpenAI services.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/index.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=sk-...\n```\n\n----------------------------------------\n\nTITLE: Getting Current Timestamp in ISO Format for Tracing\nDESCRIPTION: Function that returns the current UTC timestamp in ISO 8601 format with microsecond precision. This is used for timestamping events in the tracing system.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/util.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\ndef get_timestamp() -> str:\n    \"\"\"Get the current UTC timestamp in ISO 8601 format.\"\"\"\n    return datetime.utcnow().isoformat() + \"Z\"\n```\n\n----------------------------------------\n\nTITLE: Documented Python Agent Patterns Overview\nDESCRIPTION: Markdown documentation describing six main agent patterns: deterministic flows, handoffs and routing, agents as tools, LLM-as-a-judge, parallelization, and guardrails. Each pattern includes a reference to its corresponding implementation file.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/agent_patterns/README.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# Common agentic patterns\n\nThis folder contains examples of different common patterns for agents.\n\n## Deterministic flows\n\nA common tactic is to break down a task into a series of smaller steps. Each task can be performed by an agent, and the output of one agent is used as input to the next. For example, if your task was to generate a story, you could break it down into the following steps:\n\n1. Generate an outline\n2. Generate the story\n3. Generate the ending\n\nEach of these steps can be performed by an agent. The output of one agent is used as input to the next.\n\nSee the [`deterministic.py`](./deterministic.py) file for an example of this.\n```\n\n----------------------------------------\n\nTITLE: Context Manager Implementation for RunContext in OpenAI Agents Python\nDESCRIPTION: Implementation of the context manager protocol, allowing RunContext to be used with 'with' statements. It sets the context upon entering and clears it upon exiting.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run_context.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\n    def __enter__(self) -> Self:\n        self.__prev_ctx = self.__class__.current()\n        self.__class__.set_current(self)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        if self.__prev_ctx is not None:\n            self.__class__.set_current(self.__prev_ctx)\n        else:\n            self.__class__.clear_current()\n```\n\n----------------------------------------\n\nTITLE: Importing the agents.tool module in Python\nDESCRIPTION: This code snippet demonstrates how to import the 'tool' module from the 'agents' package. It's likely a placeholder for future documentation on available tools and their usage within the OpenAI Agents Python framework.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tool.md#2025-04-21_snippet_0\n\nLANGUAGE: Python\nCODE:\n```\n::: agents.tool\n```\n\n----------------------------------------\n\nTITLE: Financial Analyst Writer Agent Prompt\nDESCRIPTION: Base prompt template for the writer agent that synthesizes search results and specialist analyses into a comprehensive financial report.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/financial_research_agent/README.md#2025-04-21_snippet_2\n\nLANGUAGE: plaintext\nCODE:\n```\nYou are a senior financial analyst. You will be provided with the original query\nand a set of raw search summaries. Your job is to synthesize these into a\nlong‑form markdown report (at least several paragraphs) with a short executive\nsummary. You also have access to tools like `fundamentals_analysis` and\n`risk_analysis` to get short specialist write‑ups if you want to incorporate them.\nAdd a few follow‑up questions for further research.\n```\n\n----------------------------------------\n\nTITLE: Setting Current RunContext in OpenAI Agents Python\nDESCRIPTION: A class method that sets the provided RunContext instance as the current context for the active thread, replacing any existing context.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run_context.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\n    @classmethod\n    def set_current(cls, ctx: Self) -> None:\n        \"\"\"Set the provided RunContext as the current context for this thread.\n\n        Args:\n            ctx: The RunContext to set as current for this thread.\n        \"\"\"\n        cls.__contexts[threading.get_ident()] = ctx\n```\n\n----------------------------------------\n\nTITLE: Disabling Sensitive Data Logging in Bash\nDESCRIPTION: These bash commands show how to set environment variables to disable logging of sensitive data, including LLM inputs/outputs and tool inputs/outputs.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/config.md#2025-04-21_snippet_7\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_AGENTS_DONT_LOG_MODEL_DATA=1\n\nexport OPENAI_AGENTS_DONT_LOG_TOOL_DATA=1\n```\n\n----------------------------------------\n\nTITLE: Launching Git MCP Server\nDESCRIPTION: Command to start the Git MCP server using the UVX package manager. This launches the server that provides Git-related tools to the agent.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/mcp/git_example/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nuvx mcp-server-git\n```\n\n----------------------------------------\n\nTITLE: Clearing Current RunContext in OpenAI Agents Python\nDESCRIPTION: A class method that removes the RunContext for the current thread, if one exists. This helps in cleanup operations after a run is completed.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/run_context.md#2025-04-21_snippet_3\n\nLANGUAGE: python\nCODE:\n```\n    @classmethod\n    def clear_current(cls) -> None:\n        \"\"\"Remove the RunContext for the current thread, if one exists.\"\"\"\n        cls.__contexts.pop(threading.get_ident(), None)\n```\n\n----------------------------------------\n\nTITLE: Setting Environment Variables for Custom LLM Provider\nDESCRIPTION: Configuration of environment variables required for connecting to a custom LLM provider, including base URL, API key, and model name.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nexport EXAMPLE_BASE_URL=\"...\"\nexport EXAMPLE_API_KEY=\"...\"\nexport EXAMPLE_MODEL_NAME\"...\"\n```\n\n----------------------------------------\n\nTITLE: Running Static Voice Demo Script\nDESCRIPTION: Command to execute the static voice demo application from the command line using Python's module execution syntax.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/voice/static/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m examples.voice.static.main\n```\n\n----------------------------------------\n\nTITLE: Voice Utils Module Header\nDESCRIPTION: Module header documentation for voice utility functions in OpenAI Python agents\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/utils.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Utils`\n\n::: agents.voice.utils\n```\n\n----------------------------------------\n\nTITLE: Displaying Graph in Separate Window\nDESCRIPTION: Code for showing the generated agent graph in a separate window instead of inline display.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/visualization.md#2025-04-21_snippet_2\n\nLANGUAGE: python\nCODE:\n```\ndraw_graph(triage_agent).view()\n```\n\n----------------------------------------\n\nTITLE: Running Voice Demo Script - Python\nDESCRIPTION: Command to execute the streamed voice demo application from the terminal. The script initializes a voice pipeline with a single agent workflow that handles audio input/output and agent interactions.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/voice/streamed/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m examples.voice.streamed.main\n```\n\n----------------------------------------\n\nTITLE: Importing Usage Module in Python for OpenAI Agents\nDESCRIPTION: This code snippet demonstrates how to import the usage module from the agents package in the OpenAI Agents Python project. It uses a special documentation syntax to reference the module contents.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/usage.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: agents.usage\n```\n\n----------------------------------------\n\nTITLE: Installing LiteLLM Dependencies\nDESCRIPTION: Command to install the optional LiteLLM dependency group for OpenAI Agents\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/models/litellm.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"openai-agents[litellm]\"\n```\n\n----------------------------------------\n\nTITLE: Fixing Broken Snapshot Tests\nDESCRIPTION: Command to fix broken snapshot tests using the make utility. Should be followed by running make tests to verify fixes.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/tests/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nmake snapshots-fix\n```\n\n----------------------------------------\n\nTITLE: Model Settings Header Documentation\nDESCRIPTION: Markdown header defining the model settings section of the documentation\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/model_settings.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Model settings`\n\n::: agents.model_settings\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key - Bash\nDESCRIPTION: Command to set the OpenAI API key as an environment variable.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_3\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=sk-...\n```\n\n----------------------------------------\n\nTITLE: Creating New Snapshot Tests\nDESCRIPTION: Command to update or create new snapshot tests using the make utility. Should be followed by running make tests to verify changes.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/tests/README.md#2025-04-21_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nmake snapshots-update\n```\n\n----------------------------------------\n\nTITLE: Documenting OpenAI Agent Lifecycle Config Block\nDESCRIPTION: Configuration block that specifies documentation generation options, with source code display disabled\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/lifecycle.md#2025-04-21_snippet_0\n\nLANGUAGE: yaml\nCODE:\n```\noptions:\n    show_source: false\n```\n\n----------------------------------------\n\nTITLE: Setting OpenAI API Key Environment Variable\nDESCRIPTION: Command to set the required OPENAI_API_KEY environment variable before running the OpenAI Agents examples.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ja/index.md#2025-04-23_snippet_2\n\nLANGUAGE: bash\nCODE:\n```\nexport OPENAI_API_KEY=sk-...\n```\n\n----------------------------------------\n\nTITLE: OpenAI Agents Module Import Directive\nDESCRIPTION: A documentation directive that references the agents.agent module, indicating that this file imports or includes the content from the agents.agent module as part of the API documentation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/agent.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: agents.agent\n```\n\n----------------------------------------\n\nTITLE: MCP Filesystem Server Initialization\nDESCRIPTION: Command to initialize the MCP filesystem server using npx, specifying the samples directory for file access.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/mcp/filesystem_example/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nnpx -y \"@modelcontextprotocol/server-filesystem\" <samples_directory>\n```\n\n----------------------------------------\n\nTITLE: Pipeline Documentation Header\nDESCRIPTION: Markdown header defining the Pipeline documentation section with a reference to the agents.voice.pipeline module.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/pipeline.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Pipeline`\n\n::: agents.voice.pipeline\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Agents SDK with pip\nDESCRIPTION: Command to install the OpenAI Agents SDK Python package using pip.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ja/index.md#2025-04-23_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install openai-agents\n```\n\n----------------------------------------\n\nTITLE: Importing Tracing Module in Python\nDESCRIPTION: Shows how to import the tracing module from the agents package in Python. The triple colon syntax indicates this is a documentation directive that will be expanded to show the complete module documentation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/index.md#2025-04-21_snippet_0\n\nLANGUAGE: python\nCODE:\n```\n::: agents.tracing\n```\n\n----------------------------------------\n\nTITLE: Running Research Bot Python Module\nDESCRIPTION: Command to execute the research bot example from the command line. The bot is implemented as a Python module that handles web searching and report generation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/research_bot/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m examples.research_bot.main\n```\n\n----------------------------------------\n\nTITLE: Activating Virtual Environment - Bash\nDESCRIPTION: Command to activate the Python virtual environment.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/quickstart.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\nsource .venv/bin/activate\n```\n\n----------------------------------------\n\nTITLE: LiteLLM Models Module Reference\nDESCRIPTION: Module reference documentation header for LiteLLM models implementation in OpenAI Agents\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/extensions/litellm.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `LiteLLM Models`\n\n::: agents.extensions.models.litellm_model\n```\n\n----------------------------------------\n\nTITLE: Running Research Bot via UV Python\nDESCRIPTION: Terminal command to execute the research bot example using UV run command\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/research_bot/sample_outputs/product_recs.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ uv run python -m examples.research_bot.main\n```\n\n----------------------------------------\n\nTITLE: Pipeline Config Documentation Marker\nDESCRIPTION: Markdown header and directive indicating documentation location for voice pipeline configuration. Uses a documentation directive to reference agents.voice.pipeline_config.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/pipeline_config.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Pipeline Config`\n\n::: agents.voice.pipeline_config\n```\n\n----------------------------------------\n\nTITLE: Guardrails Module Reference Documentation\nDESCRIPTION: A markdown documentation stub indicating the presence of a Guardrails module within the agents package. Uses directives to reference the module location.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/guardrail.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Guardrails`\n\n::: agents.guardrail\n```\n\n----------------------------------------\n\nTITLE: Running Research Bot Terminal Command\nDESCRIPTION: Terminal command and output showing the execution of the research bot with a query about Caribbean vacation spots\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/research_bot/sample_outputs/vacation.txt#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\n$ uv run python -m examples.research_bot.main\nWhat would you like to research? Caribbean vacation spots in April, optimizing for surfing, hiking and water sports\nView trace: https://platform.openai.com/traces/trace?trace_id=trace_....\nStarting research...\n✅ Will perform 15 searches\n✅ Searching... 15/15 completed\n✅ Finishing report...\n✅ Report summary\n```\n\n----------------------------------------\n\nTITLE: OpenAI TTS Module Reference\nDESCRIPTION: Markdown header and module reference for OpenAI's Text-to-Speech implementation\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_tts.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `OpenAI TTS`\n\n::: agents.voice.models.openai_tts\n```\n\n----------------------------------------\n\nTITLE: Documenting Scope Module Path\nDESCRIPTION: Module path declaration for the scope tracing functionality in OpenAI Agents Python library.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/scope.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Scope`\n\n::: agents.tracing.scope\n```\n\n----------------------------------------\n\nTITLE: Running MCP Filesystem Example\nDESCRIPTION: Command to execute the main Python script for the MCP filesystem example using uv package manager.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/mcp/filesystem_example/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv run python examples/mcp/filesystem_example/main.py\n```\n\n----------------------------------------\n\nTITLE: OpenAI STT Module Header\nDESCRIPTION: Header documentation for the OpenAI Speech-to-Text module, indicating the path to the module's implementation.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/models/openai_stt.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `OpenAI STT`\n\n::: agents.voice.models.openai_stt\n```\n\n----------------------------------------\n\nTITLE: Voice Workflow Module Reference\nDESCRIPTION: A documentation directive referencing the voice workflow module path agents.voice.workflow\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/voice/workflow.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n::: agents.voice.workflow\n```\n\n----------------------------------------\n\nTITLE: Running Custom LLM Provider Example\nDESCRIPTION: Example command to execute the custom provider implementation script, which demonstrates a sample output of a haiku generated by the model.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/model_providers/README.md#2025-04-21_snippet_1\n\nLANGUAGE: bash\nCODE:\n```\npython examples/model_providers/custom_example_provider.py\n\nLoops within themselves,\nFunction calls its own being,\nDepth without ending.\n```\n\n----------------------------------------\n\nTITLE: Markdown Header for Stream Events Documentation\nDESCRIPTION: Markdown heading defining the documentation section for streaming events functionality.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/stream_events.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Streaming events`\n\n::: agents.stream_events\n```\n\n----------------------------------------\n\nTITLE: MCP Server Documentation Directive\nDESCRIPTION: Documentation generator directive that references the agents.mcp.server module path.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/mcp/server.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `MCP Servers`\n\n::: agents.mcp.server\n```\n\n----------------------------------------\n\nTITLE: Example Query Input - Financial Analysis\nDESCRIPTION: Sample user query demonstrating the type of financial analysis request the agent can process.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/financial_research_agent/README.md#2025-04-21_snippet_1\n\nLANGUAGE: plaintext\nCODE:\n```\nWrite up an analysis of Apple Inc.'s most recent quarter.\n```\n\n----------------------------------------\n\nTITLE: Items Class Heading in Markdown\nDESCRIPTION: Markdown heading for the Items class documentation section.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/items.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Items`\n```\n\n----------------------------------------\n\nTITLE: Running Financial Research Agent Example - Bash Command\nDESCRIPTION: Command to execute the financial research agent example from the command line.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/financial_research_agent/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npython -m examples.financial_research_agent.main\n```\n\n----------------------------------------\n\nTITLE: OpenAI Chat Completions Model Documentation Header\nDESCRIPTION: Markdown header for OpenAI Chat Completions model documentation section\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/models/openai_chatcompletions.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `OpenAI Chat Completions model`\n\n::: agents.models.openai_chatcompletions\n```\n\n----------------------------------------\n\nTITLE: Development Setup Commands for OpenAI Agents SDK\nDESCRIPTION: Commands for setting up a development environment for working on the OpenAI Agents SDK, including dependency installation and running tests, type checking, and linting.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_5\n\nLANGUAGE: bash\nCODE:\n```\nuv --version\nmake sync\nmake tests  # run tests\nmake mypy   # run typechecker\nmake lint   # run linter\n```\n\n----------------------------------------\n\nTITLE: Running SSE Example Command\nDESCRIPTION: Command to execute the SSE example using the uv package runner\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/mcp/sse_example/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv run python examples/mcp/sse_example/main.py\n```\n\n----------------------------------------\n\nTITLE: Installing OpenAI Agents with LiteLLM Support\nDESCRIPTION: This command installs the OpenAI Agents package with the optional LiteLLM dependency group, enabling support for LiteLLM integration.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ja/models/litellm.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\npip install \"openai-agents[litellm]\"\n```\n\n----------------------------------------\n\nTITLE: Running Git Example Script\nDESCRIPTION: Command to execute the main Git example script using the UV package manager.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/mcp/git_example/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nuv run python examples/mcp/git_example/main.py\n```\n\n----------------------------------------\n\nTITLE: Running Project Tests with Make\nDESCRIPTION: Command to execute the test suite using the make utility. Requires uv to be installed and make sync to be run beforehand.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/tests/README.md#2025-04-21_snippet_0\n\nLANGUAGE: bash\nCODE:\n```\nmake tests\n```\n\n----------------------------------------\n\nTITLE: Using LiteLLM with OpenAI Agents Python SDK\nDESCRIPTION: This Python script demonstrates how to create an agent using LitellmModel, which allows the use of various AI models through LiteLLM. It includes a weather function tool and prompts the user for a model name and API key if not provided as command-line arguments.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ja/models/litellm.md#2025-04-21_snippet_1\n\nLANGUAGE: python\nCODE:\n```\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom agents import Agent, Runner, function_tool, set_tracing_disabled\nfrom agents.extensions.models.litellm_model import LitellmModel\n\n@function_tool\ndef get_weather(city: str):\n    print(f\"[debug] getting weather for {city}\")\n    return f\"The weather in {city} is sunny.\"\n\n\nasync def main(model: str, api_key: str):\n    agent = Agent(\n        name=\"Assistant\",\n        instructions=\"You only respond in haikus.\",\n        model=LitellmModel(model=model, api_key=api_key),\n        tools=[get_weather],\n    )\n\n    result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n    print(result.final_output)\n\n\nif __name__ == \"__main__\":\n    # First try to get model/api key from args\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, required=False)\n    parser.add_argument(\"--api-key\", type=str, required=False)\n    args = parser.parse_args()\n\n    model = args.model\n    if not model:\n        model = input(\"Enter a model name for Litellm: \")\n\n    api_key = args.api_key\n    if not api_key:\n        api_key = input(\"Enter an API key for Litellm: \")\n\n    asyncio.run(main(model, api_key))\n```\n\n----------------------------------------\n\nTITLE: Research Bot Interactive Query Response\nDESCRIPTION: Shows the bot's response process including search status and report generation for a surfboard recommendation query\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/research_bot/sample_outputs/product_recs.txt#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\nWhat would you like to research? Best surfboards for beginners. I can catch my own waves, but previously used an 11ft board. What should I look for, what are my options? Various budget ranges.\nView trace: https://platform.openai.com/traces/trace?trace_id=trace_...\nStarting research...\n✅ Will perform 15 searches\n✅ Searching... 15/15 completed\n✅ Finishing report...\n✅ Report summary\n```\n\n----------------------------------------\n\nTITLE: Generated Markdown Report Structure\nDESCRIPTION: Markdown structure for the comprehensive report on Caribbean vacation destinations, including table of contents and detailed sections\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/examples/research_bot/sample_outputs/vacation.txt#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n# Caribbean Adventure in April: Surfing, Hiking, and Water Sports Exploration\n\nThe Caribbean is renowned for its crystal-clear waters, vibrant culture, and diverse outdoor activities. April is an especially attractive month for visitors: warm temperatures, clear skies, and the promise of abundant activities. This report explores the best Caribbean destinations in April, with a focus on optimizing your vacation for surfing, hiking, and water sports.\n\n---\n\n## Table of Contents\n\n1. [Introduction](#introduction)\n2. [Why April is the Perfect Time in the Caribbean](#why-april-is-the-perfect-time-in-the-caribbean)\n3. [Surfing in the Caribbean](#surfing-in-the-caribbean)\n    - 3.1 [Barbados: The Tale of Two Coasts](#barbados-the-tale-of-two-coasts)\n    - 3.2 [Puerto Rico: Rincón and Beyond](#puerto-rico-rinc%C3%B3n-and-beyond)\n    - 3.3 [Dominican Republic and Other Hotspots](#dominican-republic-and-other-hotspots)\n4. [Hiking Adventures Across the Caribbean](#hiking-adventures-across-the-caribbean)\n    - 4.1 [Trekking Through Tropical Rainforests](#trekking-through-tropical-rainforests)\n    - 4.2 [Volcanic Peaks and Rugged Landscapes](#volcanic-peaks-and-rugged-landscapes)\n5. [Diverse Water Sports Experiences](#diverse-water-sports-experiences)\n    - 5.1 [Snorkeling, Diving, and Jet Skiing](#snorkeling-diving-and-jet-skiing)\n    - 5.2 [Kiteboarding and Windsurfing](#kiteboarding-and-windsurfing)\n6. [Combining Adventures: Multi-Activity Destinations](#combining-adventures-multi-activity-destinations)\n7. [Practical Advice and Travel Tips](#practical-advice-and-travel-tips)\n8. [Conclusion](#conclusion)\n```\n\n----------------------------------------\n\nTITLE: Function Tools Example with OpenAI Agents SDK\nDESCRIPTION: An example demonstrating how to create and use function tools with an agent. The example creates a get_weather function tool that the agent can call to retrieve weather information.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/README.md#2025-04-21_snippet_4\n\nLANGUAGE: python\nCODE:\n```\nimport asyncio\n\nfrom agents import Agent, Runner, function_tool\n\n\n@function_tool\ndef get_weather(city: str) -> str:\n    return f\"The weather in {city} is sunny.\"\n\n\nagent = Agent(\n    name=\"Hello world\",\n    instructions=\"You are a helpful agent.\",\n    tools=[get_weather],\n)\n\n\nasync def main():\n    result = await Runner.run(agent, input=\"What's the weather in Tokyo?\")\n    print(result.final_output)\n    # The weather in Tokyo is sunny.\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n```\n\n----------------------------------------\n\nTITLE: Creating Traces and Spans Markdown Header\nDESCRIPTION: Markdown section header for documenting trace and span creation functionality\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/tracing/create.md#2025-04-21_snippet_0\n\nLANGUAGE: markdown\nCODE:\n```\n# `Creating traces/spans`\n\n::: agents.tracing.create\n```\n\n----------------------------------------\n\nTITLE: Items Class Reference Directive\nDESCRIPTION: Documentation directive for referencing the agents.items module or class.\nSOURCE: https://github.com/openai/openai-agents-python/blob/main/docs/ref/items.md#2025-04-21_snippet_1\n\nLANGUAGE: markdown\nCODE:\n```\n::: agents.items\n```"
  }
]